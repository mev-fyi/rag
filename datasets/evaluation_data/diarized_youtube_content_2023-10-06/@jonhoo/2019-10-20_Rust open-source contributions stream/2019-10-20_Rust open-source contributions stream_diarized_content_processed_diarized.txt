00:00:01.160 - 00:00:35.015, Speaker A: All right. Hi, everyone. Welcome back to yet another stream. I'll do the spiel from the beginning just before we get into the stream. So I'm John. I do a bunch of these live coding streams, sort of various different things, but in general, the goal is to write somewhat more intermediate or advanced Rust material for people who have some beginning grasp on the language or is coming to it from. From a programming background and want to learn or see the language being used in sort of more advanced ways, or to build real stuff.
00:00:35.015 - 00:01:10.105, Speaker A: I have a Patreon page where I post updates whenever I do video streams or recordings from past streams, or I solicit suggestions for what streams to do next. So if you want to, like, watch me there, you can do that. Otherwise, I also post basically all the announcements to Twitter, so. So either is basically fine. I post all of the recordings to YouTube afterwards. So if you go to, like, this page. So on my YouTube channel, there's a playlist for all the Rust live coding sessions we've done.
00:01:10.105 - 00:02:19.987, Speaker A: It's really slow today, so if you go into this playlist, it has all of the old videos and I'll keep adding new ones there as long as we record them. So this stream is a little bit different and I don't quite know yet how it's going to work out, but I have this idea of, like, over the course of my Rust programming, there are lots of times where I sit down and I, like, want to use something that someone else has written. I don't always want to write everything from scratch, even though it's fun. And so every now and again, you end up using some software other people have used, either as a library or a binary. You. You need to depend on it in some way, or even if you just want to, like, expand your knowledge of Rust and you want to contribute to something someone else has built, then usually what ends up happening is I open up, I end up in some GitHub or GitLab repository and like, now what? And I figured it would be pretty cool to try to show what that experience is like to come to someone else's code base and, like, figure out what's going on, figure out how the crate is organized and so. And also how we might contribute to it.
00:02:19.987 - 00:03:08.235, Speaker A: And so sorry is I can't imagine not using other crates. It's possible you often don't want to do it, but. But. So, for example, one of the things that I've done a lot is write relatively primitive crates, like things that are like data structures, for example, where you often end up not depending on any other crates, or if you do very few, or like only for testing and benchmarking. But in any case, I sat down and figured, like, how about we just do a stream where I do open source contributions, which is a little bit terrifying, I'm not going to lie, because it means I'm going to dive into some code base I know nothing about and have never used and going to try to modify it live. We'll see how it goes. And so I outlined this on Twitter and I got a bunch of responses where people seem pretty excited about it.
00:03:08.235 - 00:04:01.045, Speaker A: And the basic idea is we're going to look at some crates that people have suggested. We're going to look at how the crate is organized, try to figure out what it does. Like, look at the readme, the documentation, how the source sort of fits together and try to give some feedback on those, either if the authors are watching or just for our own sake. Like, which things do we feel like they've done well, which things would you perhaps do differently if you were to write this project from scratch? And then we're going to try, although we'll see how well this works, to see if we can contribute to the code in some way, like whether that is improving the documentation, improving the readme, adding some feature to the code, looking for a known bug. It depends a little bit on the crate and what kind of, sort of how sophisticated it is and also how well developed it is. Some of these are relatively early on in their development and some are later on. And so we're going to look at the bug tracker and see what we can find there.
00:04:01.045 - 00:05:05.489, Speaker A: And we'll see, like, my hope is to spend maybe an hour to an hour and a half per crate, but we'll see. It depends a little bit on how expensive the changes we want to make are. Remember that this is. This sort of ends up being pretty collaborative, right? I know very little more about these crates than you do. So if you see something that you think we should change, something we should point out to the, to the authors, something you would like us to try to change, or something you don't understand and want to know why is there, then feel free to like, ask and chat and I will try to address them and also sort of go along with you and we'll, we'll see how this goes. One thing I would like is after the stream is over, I'll take like a few minutes just to sort of sum up things with you and see if I can get any feedback on how you think this format worked. Whether you think this was interesting, whether there are particular crates you would like me to see me do next, whether you'd even like me to like to see me do this again, but we'll see.
00:05:05.489 - 00:05:19.925, Speaker A: We'll see. I think it could be fun. I also want to point out Nathan linitz just donated $50 a month on Patreon, which I think is really cool. This is a person. I have no idea who he is, but he decided to give me money. And that's amazing. Thanks.
00:05:19.925 - 00:05:58.389, Speaker A: All right, let's see. Before we start, there was some. How about reviewing the reg. Okay, so I have gotten a couple of recommendations for like really large crates or really sophisticated and mature crates, like Cargo, Regex, Servo and a couple. And like just the compiler. And while that would be interesting, that is a very different sort of monster. So in a sense, what I wanted to do here was look at things are sort of still in flux and still in development and where there's some hope that we can understand what's going on in 90 minutes.
00:05:58.389 - 00:06:27.191, Speaker A: This is not true for any of the large and very sophisticated crates. Right. Like even just Regex, which is a somewhat smaller crate, is a really sophisticated beast of a crate right now. Even though I know, I happen to know that, pretty well developed. Trying to dive into that and do something useful in 90 minutes is going to be pretty hard. One thing we could do is do a stream where we pick a crate and just try to understand it without even trying to contribute anything. We could do that.
00:06:27.191 - 00:07:00.145, Speaker A: There would be a lot less programming in it and more just reading code, but we'll see. It's not. It's not a bad idea. It's just hard to balance. Do you already have crates picked or do you need suggestions? I do have some crate picked. So I did a Twitter poll over the couple of suggestions I got and this was sort of the winner. This is a part of GraphQL implemented in Rust and so specifically the Hyper bindings for that we're going to look at.
00:07:00.145 - 00:07:41.055, Speaker A: Then we're going to look at Tokyo Beanstalkd, which is a Tokyo implementation of working with the Beanstalk protocol, which is sort of similar but same simpler than the Zookeeper stream we did in the past. And then Argonautica is implementation of a Rust password hashing algorithm, or it's a password hashing algorithm and the implementation of it in Rust. And so I feel like these are three relatively different things. And so that's why I feel like they match up pretty well and they all got some decent Amount of interest. There are some others too that maybe we'll get around to look at later. If you have other suggestions and ping me on Twitter or something and I'll try to queue them up. Yeah, Nathan, I saw.
00:07:41.055 - 00:08:02.555, Speaker A: I appreciate it. In a sense, it would be great to get to 150, but that's also a bunch of work. So it's like. I do really appreciate it, but this particular week is also a lot of stuff is going on. There was a deadline, so I was like. But it worked out. Thanks though.
00:08:02.555 - 00:08:30.785, Speaker A: Let's see. Ooh, author of the. Okay, so we have the author of this crate here. Fantastic. You can of course still suggest more crates. We probably won't get around to them in the stream, but if you like put them in the chat or tweet them at me or something, then I will add them to my ever growing list of things I want to cover in streams. Sadly, I only have so much time.
00:08:30.785 - 00:09:06.135, Speaker A: All right, let's dig into Juniper Hyper first. So in sort of the same spirit as with all the previous streams, I've tried to not do any work ahead of the stream. This is in part so that you don't feel like you're missing anything, like any part of the experience. It's also so that you can observe my entire process of going through something new as opposed to me having like fully prepared before we sit down and know where everything is. Because I don't think that would be helpful to you. And it's sort of disingenuous because that's not really what the experience is like. And I want.
00:09:06.135 - 00:09:25.135, Speaker A: I want people to realize that programming is like not. It doesn't just happen. Right. You need to invest some work. All right, so Juniper Hyper. Let's find out what Juniper is first. So Juniper GraphQL okay, so it's some kind of data query language.
00:09:25.135 - 00:10:09.085, Speaker A: And this is a Rust implementation, does not include a web server. Okay, so it's like sort of like a database, but without a web server or any kind of web API and integrations for Hyper. All right, so I'm taking a wild stab here, but it seems like this is a. It's like a way to set up. I mean, just judging from the name, you set up graphs of data structures and then you have some way of querying those data structures. And the hyper thing is going to be a wrapper around that so that you can make requests to the stored data over the network. Let's look and see if I got it right.
00:10:09.085 - 00:10:27.907, Speaker A: Okay. Data query language. This is pretty unhelpful how do I use it? Give me an example. Examples. There is no examples Directory. What about here? No. Getting started.
00:10:27.907 - 00:10:41.627, Speaker A: Quick start. Great. Quick start. Yeah, yeah. Okay, so it's like you said, obstructs. They have relationships to one another and there's probably like. Okay, yeah.
00:10:41.627 - 00:10:59.815, Speaker A: So you declare objects and you can search the object. Okay, yeah. So it's just. You're querying for data in some structured manner. All right, now the question is, what is Juniper Hyper? Because that's the thing we're actually looking at. We're not going to look at all of Juniper. Pinpoint Delicate for pinning.
00:10:59.815 - 00:11:28.701, Speaker A: Ooh, yeah. Can you. Can you ping me with that on Twitter? Because this will get lost in the chat. Why not ask the author here? Well, I mean, we could, but usually you're not able to ask the authority. Also, I think he's the author just of the hyper part, but I might be wrong. Okay, so let's see what we got here. Ooh, example.
00:11:28.701 - 00:11:39.825, Speaker A: Good. All right. Example is a good start. Let's look at the example. Oh, future CPU pool. That looks weird. I don't think future CPU pool should be here.
00:11:39.825 - 00:12:11.735, Speaker A: Why do I need to build a CPU pool? Isn't this Tokyo? This is using Hyper. This should just be a Tokyo pool. That way you wouldn't have to clone the pool in here. Regardless. So they're setting up a Hyper service. So hyper, for those who aren't aware, HYPR is a rust web framework both for clients and servers, and it's sort of built entirely asynchronously around Futures and. And Tokyo.
00:12:11.735 - 00:12:31.411, Speaker A: And the idea is that you set up a bunch of services and every service is responsible for routing the request it gets in. You're basically like, you're sort of given a. You're given a request and you have to populate a response. And it's all asynchronous. And so a service is a thing that can reply to requests. In this case. Yeah.
00:12:31.411 - 00:12:48.461, Speaker A: So here, you see, this is basically doing routing, right? Like it's looking at the method in the URI and then it's doing some stuff in response. Okay, so this. This is. This example is then basically the. The hyper part. Why is this in the example? Okay, so the thing. What does this.
00:12:48.461 - 00:13:16.195, Speaker A: Let's look at the docs. Okay, so Juniper Hyper provides these two functions. Interesting. I wonder why just those two. That seems like a weird thing for this crate to provide. Like, I would expect a crate that's supposed to provide web bindings. To provide web bindings, whereas it looks like from this example, it looks like the user has to come up with the actual routing.
00:13:16.195 - 00:13:44.689, Speaker A: Right? Because this is in the example code. So the idea is this would be in your code. And so I guess the question is what are these functions? Right, because it's routing, it's routing these different things. So it looks like get/iql. Okay, so what's the difference? These two names are not clear. What's the difference between these two? Oh, that. I would say that the first thing that's lacking in this grid is documentation.
00:13:44.689 - 00:14:07.735, Speaker A: So in theory that is something we could provide. Graph. You just forward the request to Juniper. I see, I see. So but if you're just forwarding, then why is this crate necessary? That's. I guess I want to know what this function does. That's a good source.
00:14:07.735 - 00:14:45.565, Speaker A: So iQL, this just uses Juniper directly to request an end point and just construct a body. Okay, so this is extremely straightforward, right? Like this method is just calling whatever that method is. And that's notice specifically this is in the Juniper crate, not in Juniper Hyper. So this wrapper seems pretty straightforward. What is the. I feel like it should be named something else. Twitch don't have communities anymore and don't have a game Creative.
00:14:45.565 - 00:15:21.179, Speaker A: Oh, I mean my stream isn't game programming. So Graphical is a UI for the GraphQL backend. Yeah, but why. I see. So the response. So what you're saying is this call here just essentially print some HTML of some kind. We could probably just run this.
00:15:21.179 - 00:15:59.215, Speaker A: I just want to. I like exploring the high level part of the crate first before trying to run anything myself. Because it might not be that we even need to run this. All right, so this is just like I guess is for index maybe. So this just provides you with the graphical index, the ui. Alright, so what does this other thing do? Because that, that's what all the seemingly interesting endpoints go to, right? You go to/graphql then something else happens. So this takes a CPU pool, which I think is really weird.
00:15:59.215 - 00:16:29.557, Speaker A: All right, so this further matches on the method. Fascinating. I feel like some of this stuff should probably go. There should be like a wrapper that's provided by the crate. So that might be something we could build. So this takes root node here. Root node is the root of the data structure we're searching over.
00:16:29.557 - 00:17:04.125, Speaker A: CTX is db, which is database. Okay, so I don't know the difference. Okay, so database is like the entire collection of objects and root node is the one we start searching for would be my guess. And then pool Unclear why they Need a pool? I guess we'll find out later. And then they're passing the Request in this GraphQL. So GraphQL is the main thing provided by this grid. It seems like it matches on the method, and if it does a get, then.
00:17:04.125 - 00:17:39.464, Speaker A: I see. Okay. So mainly what this crate is doing is mapping HTTP requests to GraphQL requests and then taking the responses and mapping them back, it seems like. Right. So if you get a. If you get a post, you essentially parse the body, you make it into a request. Yeah.
00:17:39.464 - 00:18:22.657, Speaker A: So here, for example, notice it's basically taking the body of the request, turning it into a string, parsing it as JSON into a GraphQL request, and then doing this execute request business and the response that comes back. Oh, I see. So Execute request is really the thing we want to look at. Execute request. I wonder why this uses pool spawn. Like, why does this not use Tokyo spawn? Why are they using, like this future CPU pool? That seems odd. Request execute.
00:18:22.657 - 00:18:41.841, Speaker A: So Request is the GraphQL request. Okay, that's fine. Yeah. So that's what we parsed it into. Yeah. Okay. And then it just does a new response, which is presumably then mapping a GraphQL response into whatever web response we want to give.
00:18:41.841 - 00:19:19.935, Speaker A: So where is new response? Yeah. Okay, great. So it just creates a response. Right. So the sort of main stuff of this is really mapping then between HTTP and the underlying GraphQL. It also looks like all of this, a single file, which is a little SA C pupil is needed because Hyper is async and Juniper is blocking. So Tokyo has Tokyo blocking, which I think fixes that problem for you.
00:19:19.935 - 00:19:58.265, Speaker A: So that's another thing we could do is we could use Tokyo blocking to get rid of the future CPU pool and just have it be Tokyo all the way to make it a little bit nicer to work with. And you would also avoid having two thread pools. So currently you end up both with the hyper thread pool and the future CPU pool, which is a little unfortunate. Currently, the stream is not easily discoverable for anyone who's not already aware you're streaming. Oh, there's a programming category. Sure, let's fix that while we're at it. Actually, should we do that? Sure.
00:19:58.265 - 00:20:15.533, Speaker A: Well, it's the worst that could happen. Dashboard, I think. No. Maybe channel. No Dashboard. Sorry, you want the category here to be programming. Great.
00:20:15.533 - 00:20:39.835, Speaker A: Update. Great. It's now a programming channel. Nice. Not really sure what the difference is between CPU pool and Tokyo's thread pool. So Tokyo's thread pool does work stealing, and it's also where HYPR will be executing. So because hypr is based on Tokyo, Hyper spins up a bunch of futures and it spawns them on a Tokyo thread pool normally.
00:20:39.835 - 00:21:32.945, Speaker A: And so now, by using future CPU pool, you have two thread pools running. You have the CPU pool that you explicitly constructed, and also the thread pool that Tokyo started. In particular here when you do Server Bind. So that's a hyper server. And if you look at hyper, I mean, unless you're depending on a very old version of, let's see, cargo tunnel of Hyper. No, zero, one, two. Okay, so if you look at server, server, server, Server bind returns a builder, right? So what do you do with this builder? You call dot serve builder.
00:21:32.945 - 00:22:10.377, Speaker A: Yeah, so if you call dot serve, if I remember right. So the thing you get back needs to be spawned somewhere. So currently, this example, this server that you get back, you run RT run and rt. So hyper rt, if we go back here, hyper RT default runtime. So the default runtime for hyper is a Tokyo runtime, and a Tokyo runtime starts up its own CPU pool. And so what you end up is this is starting a. This is already starting a thread pool for managing all the Hyper futures.
00:22:10.377 - 00:23:01.161, Speaker A: And then in addition, you're creating a separate thread pool for doing Juniper request processing. This is no longer necessary because if you look at Tokyo Executor, where is the. Oh, I guess this is probably now in Tokyo Executor run preloop runtime. Runtime, where is blocking? That's a good question. So there's a. There's a blocking. There's a blocking function now that gives you a future that runs a blocking operation.
00:23:01.161 - 00:23:30.735, Speaker A: Tokyo thread pool. Tokyo thread pool. This function. Yeah, so this takes a function and gives you back a thing you can pull. And so basically it gives you back a future, but it makes sure that it still reuses the various threads that are already in the pool to execute the job. So this is probably what you want rather than have a separate CPU pool. And this might be the conversion we want to make on this crate.
00:23:30.735 - 00:23:59.533, Speaker A: The creative category. Okay, yeah, that's fine. I think. I think the change I made was correct. Right to the Twitch category. All right, so blocking seems like a good candidate here because it would avoid spinning up two thread pools. And let's see, the other thing it's doing is really just mapping between hyper requests and GraphQL requests and GraphQL responses and hyper responses.
00:23:59.533 - 00:24:47.075, Speaker A: Right? So GraphQL execute really just does an execute. And what does it do with the response? So it does execute and then graphQL response is one of these. So this suggests that really it's just like JSON encoding the response, probably. All right, so the crate itself seems pretty straightforward. Like, I think this is basically the entire contents of it. The thing we'll want to. So I think that the two things we could do here, one would be to get rid of this extra pool, which I think is a pretty nice change to the crate.
00:24:47.075 - 00:25:26.769, Speaker A: The second would be to add some documentation to it, which, like, is maybe interesting, but it's unclear. The third thing we could do here, the third thing we could do is this business we could probably wrap up instead of it being an example. In fact, this is part of this example. Code should probably be in the documentation too. But instead of this just being in the example, it seems pretty reasonable for this crate to provide this. Provide this service explicitly. Like, there's no reason for every user of this crate to have to write this code.
00:25:26.769 - 00:26:01.085, Speaker A: Right. I guess the question is like, what if they have other things they want to match on? Maybe. Maybe. I guess this does let you change the URL pattern, but it might be nice to provide like a shortcut for users who just want the bindings. In fact, I almost wonder whether this shouldn't be an example, but instead just be a binary. Just like a straight binary, maybe in a PR. Oh, let's look at PRs.
00:26:01.085 - 00:26:40.565, Speaker A: Hyper. Hyperters. Yeah, see, I don't think it should need CPU pool. So that's separate. Oh, hey, I know dgc. Or rather I've contributed with him on a different crate. No, that's fine.
00:26:40.565 - 00:27:37.121, Speaker A: Yeah, so, okay, so this is the observation, right? Yeah. Okay, so maybe the goal then should just be to be able to simplify the example. Right? So they can write whatever integration they want. All right, let's get. Let's give this a try. So I guess we're going to do something like fork PR230. That's the one I had open, right? I think.
00:27:37.121 - 00:28:17.885, Speaker A: 230, yeah. This one I read. All right, we have a fork. So usually what I like to do is if I'm contributing to a crate, I usually have two remotes, So I have origin point to my branch, and then I have one called upstream. Upstream. This one let's also do. And then I point master to upstream, so the master is not pointing to my fork.
00:28:17.885 - 00:28:38.095, Speaker A: And then I make a new branch. So in this case, what we're going to do is remove CPU pool. Remove hyper CPU pool, and then juniper Hyper. Let's do our cargo check. Let's See if we can build this thing in the first place. That would be. That would be handy.
00:28:38.095 - 00:29:14.059, Speaker A: Okay, so the real question we need to deal with now is if I can get back to the docs somehow. Oh, great, we can build it. Fantastic. All right, so we basically need this function to not take a CPU pool. Right. Instead it should just give you back a future. Yeah, this could probably be impulse future.
00:29:14.059 - 00:29:41.445, Speaker A: I don't think this needs to be box. Depends how performance critical this is. But I guess let's focus on getting rid of the pool. So here's what we're going to do. Oh no. Oh, it's almost rust formatted. Nope.
00:29:41.445 - 00:30:06.995, Speaker A: Oh, that formatted everything. Okay, so Juniper is not formatted. Fine. This though, I guess. Fine, we'll just ignore that change later. Right. So over here, I guess we would need to change cargo tumult to get rid of the CPU pool and move Tokyo to be a dependency.
00:30:06.995 - 00:30:35.195, Speaker A: Moving Tokyo to be dependency is actually fine because hyper already pulls in Tokyo. So we're not actually adding a dependency, we're making an implicit dependency explicit. Should be fine. So now there will no longer be a future CPU pool. Instead there will be Tokyo always Hypergrade itself should be rest format. So it mostly is. I'm running the latest nightly, which is probably why it's.
00:30:35.195 - 00:30:59.493, Speaker A: Why it's complaining specifically. The only real diff is this business down here. That's the only diff it makes. So that's probably a rust format nightly change. So I would not worry about it. So now it's obviously not going to compile. Okay, so we need to figure out how we want this to work.
00:30:59.493 - 00:31:35.245, Speaker A: So specifically, I guess the concern is when you call GraphQL, we're going to have to do something that's blocking, which is fine. So we're going to use Tokyo blocking for that, which means we have to pull in Tokyo thread pool because that's where the blocking function lives. Tokyo has been moving this direction of. Instead of. Instead of having all the things exposed through the Tokyo crate, they have lots of other crates. And then Tokyo just exposes like the really essentials that are not expecting to change. The reason for this is they can improve the other crates without having to issue like breaking changes or anything to Tokyo itself.
00:31:35.245 - 00:32:20.235, Speaker A: So in this case, we'll need Tokyo thread pool017 and then we're gonna get external thread pool. All right. So yeah, so the question is, what are we gonna do about GraphQL? I think it does not need to take a thread pool. Instead, what it's going to do is just call. So I guess Execute request is the part that's blocking. So I think all it really has to do is return a blocking thing. These arguments are not pretty, but I guess it's fine.
00:32:20.235 - 00:33:04.179, Speaker A: I think this can also just be Impulse Future does not need to be boxed. Yeah. So down here I guess Execute request and Execute request. Oh yeah, they both use Execute requests, so that's really. We can just modify Execute request here, right? Graph IQL this can also be import future. Oh. I guess the reason why Ample future is a little annoying here is because we have different return values depending on.
00:33:04.179 - 00:33:31.985, Speaker A: We have. We have different futures that return depending on whether it's a get or a get or a post or anything else. That's probably why it was originally a box. We can get around this using either. So futures. I think it's in future either. So we would do either A either A.
00:33:31.985 - 00:33:57.281, Speaker A: The AA is a little annoying, but I'll show you in a second why it's necessary. B. So either is A is A either. So there are only two options, right? It's left or right or A and B. And in this case we want to return three different things. Specifically this is one, this is two, and this is three. And the way you get three from two binaries is you wrap the binary.
00:33:57.281 - 00:34:52.779, Speaker A: So in this case this would be either B. Right? So the type of A A contains an either B is just this. So now that can be implefuture. This can just be impulse directly anyway. New HTML response Sir, isn't this a blocking call? I guess we don't really know, but to me this seems like something that might block. But given the current writing, I guess is the call to Graph IQL source blocking. Because if it is, this should be wrapped in Tokyo blocking, right? Like we should.
00:34:52.779 - 00:35:16.101, Speaker A: We should mark this as also being a blocking future. So now Execute request is going to return something that's an impulse. Okay, that's great. So here impulfuture was used already. So my guess is for the box is because they didn't. They tried impulfuture, it didn't compile and they were just like ah, let's just box it. The reason is because input future only works when there's a single future type that's being returned.
00:35:16.101 - 00:36:04.645, Speaker A: If you have. So if you try to do like fnfuture and then you do like if A else and like this is some future and this is some other future, this will not work because impulfuture is going to say there's no one type. So you think of ample future as like, there is a single type here. I just don't want to name it. Right. But in this case, there is no single type for the return value because these two futures, this and this, have different types, even though they both implement future the same way, they're different things. And so the way you get around this is by doing either A and either B.
00:36:04.645 - 00:36:34.355, Speaker A: And so now there's only a single type that's being returned, and that's an either, which is generic over its left and right future. All right, great. So we got rid of a heap allocation. That's good. Oh yeah, either is fantastic. Let's see what else we have. Okay, so we got rid of the pool from here, and now the question is down here, what do we do? So this doesn't actually have to be lazy anymore.
00:36:34.355 - 00:37:28.453, Speaker A: This is now really just wait, why does this. Oh, did I put the wrong number of parentheses somewhere? Probably yes. Here, and also here and also somewhere else. 52 and an extra comma and another extra comma. Great. So it was interesting. Okay, so the code now actually compiled even though there's no pool.
00:37:28.453 - 00:38:22.227, Speaker A: And the reason for this is now we're just like executing this request directly on the current thread. And so you should think of Tokyo as it spins up a pool of threads, and those threads are supposed to keep processing futures. And if, and what happens if you put an expensive blocking call somewhere? Imagine you do an expensive file system operation, or even just you do a loop that just spins forever. Then that thread pool worker, that one worker in Tokyo, cannot process any more futures. And so imagine that you had four futures and all of them just did a spinny loop or they did something that blocks. Now, if you only had four cores, there would only be four threads in that pool. If all of them are just spinning, then none of the other futures you have get executed.
00:38:22.227 - 00:39:16.759, Speaker A: So like, if there are another HTTP request that comes in or something, it will not be processed. And so the way we deal with this is that we tell Tokyo that a given, given worker is now blocking. So it's doing something so that it's not going to be able to handle futures for a while. And then Tokyo is going to respond to that by essentially spinning up some extra threads or keeping some extra threads to make sure that the rest of the world continues working. So in this case, what we're really going to do is we're going to do Tokyo thread pool blocking. So blocking is going to do this? Yes. So this is going to return us a future.
00:39:16.759 - 00:39:55.485, Speaker A: And then. And Then the response of that is we're going to do this mapping that originally happened. I guess this. Does this even do anything? I think this is the map. I don't think this needs to be an N. Then this is the map. Interesting.
00:39:55.485 - 00:40:21.739, Speaker A: Oh, I guess. Actually we probably want the blocking stuff to happen all the way in at request execute. So we're going to have request execute return a few an impul. Future. Yeah. So execute. Where are you here? So this is now going to do.
00:40:21.739 - 00:40:44.751, Speaker A: It's going to return an impulse future where the item is this and the error is blocking error. This thing. Now this is not something we want to expose to the user. In fact, why is this pub. Why is this not. That makes no sense. Request is not pub.
00:40:44.751 - 00:41:08.255, Speaker A: So this is not published. Yeah. So if you try to execute a request, what we're really going to do is we're going to execute it, we're going to return a future that will eventually result to it being it having finished. And in this case. Oh, I see. This does multiple blocking requests. Fascinating.
00:41:08.255 - 00:42:06.475, Speaker A: All right, so this business, What's a Juniper GraphQL request? Okay, so this is the actual blocking call. So here is where we're going to have Tokyo thread pool. Blocking takes a closure that's going to execute and then we're going to map that into a single response. Great. If you get a batch of requests, then we're going to do. Oh, I don't know if it's going to be okay for this execute to be on a ref to self. I guess this is where we have to find out what the Juniper API is like.
00:42:06.475 - 00:42:57.475, Speaker A: So the is it GraphQL request, I guess. GraphQL request HTTP maybe here request. Oh, execute returns a response is tied to the request. That's awesome. Yeah, that's kind of awkward. So the problem here, of course, is that this future is just like spun up in the background. Hum, hum, hum, hum, hum.
00:42:57.475 - 00:43:33.655, Speaker A: Specifically, execute return something that borrows request. And I wonder if blocking blocking need to be static. Maybe not. It does not. Specifically closure does not. Hmm. This might not compile, which is a little sad.
00:43:33.655 - 00:44:36.735, Speaker A: Let's see. Why don't I suit the whole thing in a blocking call? So that is basically what we're doing. It's just that it wouldn't help. So if blocking requires its argument to be static, then we can't give it any closure because any closure is going to have to borrow the GraphQL request. Wait a second. So the execute up here is given the request. Wait, why? Oh, I see.
00:44:36.735 - 00:45:05.821, Speaker A: So really we do have self here. The problem is just what do we. What's the lifetime of the return future? Oh, I see. That's why it took. This might actually work. Let's try this. So specifically, if we get a batch of requests, what we want to do is we want to do an execute for all of them.
00:45:05.821 - 00:45:31.175, Speaker A: So there are a couple of ways to do this in Tokyo. If you have. You want to essentially wait on a bunch of futures. And the way to do this is 0.1. Let's see. Future join all I think is the one we want. Yeah.
00:45:31.175 - 00:45:49.023, Speaker A: And a join all I think is a stream. No, it's a vec. Okay, great. Yeah. So that is what we want. So specifically what we're gonna do here is we're gonna do a futures Future join all. I guess this comes from.
00:45:49.023 - 00:46:38.885, Speaker A: If we just use the Tokyo Prelude, that brings in future as well and it brings in future. We might as well bring this in. That's fine. So we're gonna do a join all across request Iter map this. Right? And this is now going to be a blocking. So we don't need to collect anymore. The join all is going to produce a vector for us that we can then just map into the final batch.
00:46:38.885 - 00:47:06.455, Speaker A: And this is now an either. Right. Because the two different match arms are different types, it's probably going to complain all over the place. That's fine. 95. All right. It's going to complain that the error here.
00:47:06.455 - 00:47:51.417, Speaker A: Why is this generic over the error type? I don't think that's true. I think this is specifically a Tokyo thread pool. Now, down the line, this error might have to be more refined. Specifically, I think that error type is going to have to be something like derived from the juniper error type so that you can also return juniper errors. Right. I guess the question is whether Juniper execute. Yeah, so execute here will.
00:47:51.417 - 00:48:25.601, Speaker A: My guess is at some point we'll return a result. But I guess the response maybe contains that error anyway. 192 Sorry, what is it complaining about? It's complaining about a lot of things. All right, let's look at 51 first. So here it's saying type mismatch. The error should be a GraphQL request error. Right? Because here I see.
00:48:25.601 - 00:49:15.951, Speaker A: So up here we're making the Error type B GraphQL request error. So the question is what do we even want to do here? I think what we want to do is ignore the blocking error and just make it a GraphQL request error. Sure. Invalid. I mean, it's not really invalid, but there's going to be something like no more capacity to execute requests. So this would happen if we already have lots and lots of threads that are. We have lots and lots of threads that are already executing these blocking requests.
00:49:15.951 - 00:49:52.245, Speaker A: And Tokyo is saying, I'm refusing to spin up any more thread. You can set the limit on the pool for what. What you want that limit to be. In fact, we could hoist this, could put this further in. But I think for now we're just going to put it here. Now what type mismatch on 208. So here it's saying expected signature FN.
00:49:52.245 - 00:50:20.067, Speaker A: Oh, right. What does blocking actually returns Returns a poll. Oh, I see. That's awkward. So we need a poll offend is what you're saying. This is so blocking. If I'm reading this correctly, then blocking doesn't return a future.
00:50:20.067 - 00:50:55.185, Speaker A: It just returns whether it is currently executing that blocking call or not. So it might return you a blocking error if that thing is not yet ready, if there are no threads available to do the blocking call. And so I think what we want here. So imagine that you have four cores you're currently executing for blocking futures. And Tokyo goes, no, I'm not going to spin up another thread for you. Then the call to blocking is going to return an error. And so really what we want to do in that case is every now and again retry it.
00:50:55.185 - 00:51:30.829, Speaker A: Essentially we want to poll whether there are available threads. And the way we do that is by using future polyphen, which really just tries to execute the future until it succeeds, which is what we want in this case. So here I guess the question is what is a blocking error? Then why does it. That's unhelpful. Return. Oh, if the thread pool is shut down. I see.
00:51:30.829 - 00:52:20.345, Speaker A: So really this should just like not. This is not. No more capacity because that would return not ready. So in this case this is just. This is really like thread pool has shut down, which I think should never happen. So I think we can just do unreachable because this shouldn't ever happen. And so this is going to be a pole fn around this and same here.
00:52:20.345 - 00:53:03.073, Speaker A: All right, now 198. Right. So actually we need. It's a little awkward so because we're carrying along the root node and the context into the closure in here and that might like we might return from this function almost immediately. Right. Because we. We try to put it on the thread pool and it like is there aren't enough threads and so it's going to run it later and so these references need to stay alive for as long as this future is alive.
00:53:03.073 - 00:53:37.535, Speaker A: And so what we're going to do then is we're going to have a tick F and these and the future are tick F. And then we're also going to have to say that tick A outlives tick F. So basically, the reference to self also has to live as long as F, because otherwise the future wouldn't resolve. Right. And now it's probably going to complain about all sorts of ownership issues. So 109 here. Request does not live long enough.
00:53:37.535 - 00:54:19.883, Speaker A: Wait, why are all these things borrowing? They don't need to be borrowing if they are not borrowing. That makes this a lot easier because now this is no longer a reference, this is an arc to that. This is no longer a reference, it's an arc to that. Now this doesn't have to be F anymore. So we're going to move into here. This. Let's see what else we have.
00:54:19.883 - 00:54:51.701, Speaker A: Mismatched types. 2, 6. I guess this is now going to borrow these. 198. Explicit lifetime required in the type of root node. Oh, root node takes a lifetime too. All right.
00:54:51.701 - 00:55:30.925, Speaker A: 109. Request does not live long enough. Well, the request is actually owned, so let's just have this. Just take self instead. And this now has to be generic over a. But just for the root node. Yeah, that's unfortunate.
00:55:30.925 - 00:56:19.835, Speaker A: Hmm, that's a good question. Okay, so the problem here is that the response we're giving back is tied to the request, so we can't produce a result. So the reason this is awkward, actually, is because we want the ability to have this freestanding execute request bit because this thing changes. Okay, so let me rephrase. The problem we're running into is that we're trying to do a request. We're execute a request, and that's going to take a while. And the response is tied to the lifetime of the request.
00:56:19.835 - 00:56:58.955, Speaker A: The problem then is that means that the request has to live for as long as we want to run this thing for. But we own the request and we want to move it into where we execute it. The problem is then the response is still tied to that lifetime. So to phrase that differently, when we exit the thing we get back from executing, the request still borrows the request. So if we just hear return, then request would be dropped, and then the response is no longer valid. Right. So I think really the thing to do here is to provide a map.
00:56:58.955 - 00:57:28.287, Speaker A: Yeah, so we're gonna consume self. Yeah. Okay. So crucially, the problem here is the response only lives for as long as request is alive. Request is still alive here when we execute, but the moment we return, request is dropped. So the response is no longer valid. Which means that we basically need to map the response in here to get rid of its lifetime.
00:57:28.287 - 00:58:14.967, Speaker A: So what we're going to do is we're going to allow execute to be given a mapping function. And so there's going to be an F and an R and this is going to return an R. Let's see. So F is going to be an FN mute and it's going to be given a GraphQL response and going to have to give us an R. Right. Does that make sense? So what we're now going to do is we're going to have this dot map map and same here. And so now notice the response is no longer time to the lifetime itself.
00:58:14.967 - 00:59:54.385, Speaker A: This can now be moved into the function. I think that should do it. Now199, the execute function that we had up here somewhere, this is now going to pass in the map enclosure directly. 199 expected GraphQL response found type parameter. Why? Yeah, that's kind of awkward. Okay, so the real way to fix this is just to not have this be a separate method, but I don't really want to pull that out. Okay, so the problem now is our mapping function is over a GraphQL response, but the problem is that we don't have the GraphQL response until we've resolved all of these and they are still all borrowing request.
00:59:54.385 - 01:00:28.915, Speaker A: Although that might be fine. We might be able to have this just not move into this not map here. So then the request is still borrowed at this point. This is now an either A. All right, we already did that. And then the future that comes back from this. We map with map before we end up dropping self.
01:00:28.915 - 01:01:47.915, Speaker A: Maybe. I don't know if that's going to work specifically now. A reference to the request is going to be passed in there. Yeah, the problem is there's no. There's no well defined owner of request is really what's going on. Yeah, mixing blocking and asynchronous code like this is always a bit of a pain. Yeah, I wonder whether it's just really problematic that the.
01:01:47.915 - 01:02:23.651, Speaker A: Why is the response tied to the lifetime of the request? This seems really odd. Juniper, why have you done this? So execute to the response. Why is the response. What does it contain? Oh, the TK is only there for the error. Oh, that's awful. Oh man, that's a bad choice. Juniper, that's not worth it.
01:02:23.651 - 01:03:00.391, Speaker A: Errors should be rare. That's awful. Yeah, that makes us a pain. So notice that if executes response was not tied to the request, none of this would be a problem. The problem is specifically that the tick a of self here is tied to the tick a in the response. No, because. Well, the input bytes are only used if you return an error and if you are returning an error, then cloning is fine.
01:03:00.391 - 01:04:31.345, Speaker A: Right? The standard operation should be not getting errors. So it's fine to make the errors a little bore, a little more expensive. Well then yeah, yeah. The real problem here is just like that the request ends up being dropped. But I don't know how to avoid that easily. So the way we could do this is like wrap the request in an arc because like okay, this case is trivial because here we just map graphql response single map map. So that part is fine I think because there we know the request doesn't get dropped.
01:04:31.345 - 01:06:20.763, Speaker A: Can't be after the poll. It's like match on this and if it is OK async ready V so if we get the value out, then we want to produce map of gracql single right? So this erases the lifetime. So that's fine. And anything else? If we get O so we guess okay, async ready. If we get okay async not ready then we really just. Oh, I guess actually the nicer way to do this would be wow, that's one ugly future. So the idea is that we try to do this blocking and if it's succeeds then we immediately map the result.
01:06:20.763 - 01:07:19.551, Speaker A: And this is still happening I guess here this is still happening while we have a reference to the request and so that's all fine. The problematic case is this business because here we can't pull the same trick because there are multiple of this request. So this is going to be into error and each. Yeah, so here the real problem is we can't call map on the entire batch. Maybe you can convert it early on into GraphQL request error. Now the problem is specifically that this is actually a GraphQL response, right? I need to get the value from the response and there's no way of getting the value as far as I can tell, which is kind of silly. The.
01:07:19.551 - 01:07:58.805, Speaker A: Okay, so the other way to do this is to specialize this code a bit more and just have this happen in line. So what does. Wait, this only looks at the. Yeah, this is serializes the response anyway. Okay, we can make this a lot simpler by just. We're just going to Erase this lifetime and sorry, what does this do? So this is if it's okay then new response from the code. All right, so really all this needs to return.
01:07:58.805 - 01:08:55.475, Speaker A: Let's ignore this map function. This just needs to return string which is the JSON encoding actually it needs to return a hyperbody which is the body we're going to include and it needs to return whether or not it's an error. I think that's all this code relies on. So if that's the case then this is pretty trivial because it's just. It is just going to be here I guess this we're not going to produce a GraphQL response at all. We're just going to do whatever value we get back. Sorry, bear with me here.
01:08:55.475 - 01:11:17.937, Speaker A: So we're just going to do this blocking and if it succeeds then we are going to do the where's the other execute Just going to do this let body is this and then we're going to do is okay is v dot is okay I guess we can call this res and this is res and this returns now is OK embody and then we're gonna have to do the same thing down here fold right. So this join all is a little bit more problematic but we can pull a similar kind of trick actually which is we're going to do for each one we're going to try Ready? And then I'm going to do that not going to give a response instead it's going to move into here. No, this is missing something. This is missing a future poll offend this. All right, so we're going to pull for all of them. We're going to try to execute it synchronously. The problem now is what this join all is going to be is it's going to be a bunch of already JSON serialized responses.
01:11:17.937 - 01:12:41.225, Speaker A: It just so happens that given those we can easily produce the final JSON string. It's a little less efficient than what we would probably like. But we're going to do now a map of this. So what a what the join all is going to produce is it produces a vector of results where each result is an isokay and a body and we need to produce a single single is OK body and you can concatenate JSON pretty easily, right? So really what we want to do here is just ISOK is results iter.all specifically the request is okay if all of them are okay and concatenate JSON bodies as array which is what we want to do right? Like if what this would have been Produced if we just. If we did the whole thing and then JSON serialized it, that would really just give us a serialization of a vec of them. And a serialization of a vec of things is just comma separated and start with a open bracket.
01:12:41.225 - 01:13:21.937, Speaker A: And so we just need to modify the body to do something like body is results into iter fold body empty. And for each one, we're going to have the, I guess all and body. And we're going to have to produce what the new body is going to be. And the initial body is going to be actually this. Right. So we're going to start out with an open square bracket. And then we're going to just add all the things with commas in between.
01:13:21.937 - 01:13:48.255, Speaker A: And then finally this is going to return to is. Okay. And body. So we now need docs RS hyper. So hyper body. One of these. What is this? Ooh, ooh, that's even better.
01:13:48.255 - 01:14:12.437, Speaker A: Yeah, let's do that. All right, so watch this. This is even better. So TX and body, it's gonna be hyper body channel. And then we're gonna do. We're gonna send one of these. What does this.
01:14:12.437 - 01:14:45.315, Speaker A: What do I have to send on the sender? Oh, it's not an unbounded sender. That's awkward. How do I add? I can only asynchronously add to one. All right, that's fine. Sure, that's fine. So we're just gonna make the body up here. Not gonna be a map down here.
01:14:45.315 - 01:15:37.141, Speaker A: So we're gonna start out our body up here. Sure. So we're basically going to be streaming. We're going to be streaming the body into this. So this channel, we're going to stream the body as the results come in. So here, what we really want to do is as these come back, I'm gonna do something like. And then our results is.
01:15:37.141 - 01:16:01.175, Speaker A: Okay. Is gonna be a little bit trickier this way. But the idea would be that instead of doing a join all we're just gonna do. I guess we just want to wait for all of them. We don't really care about the order. I think. I know we do.
01:16:01.175 - 01:16:54.855, Speaker A: We have to produce the responses in order to. Huh. So the real way to do this is then probably dot. What's the thing to turn. We really want to turn an iterator into a stream. I think really what we're going to do here, which we can do with future stream deprecated for iter. Okay.
01:16:54.855 - 01:17:21.503, Speaker A: And iter result. Yes, we want iter. Okay. So what we're going to do is instead of this join all business because we don't actually need them that way. In order, we're going to do futures stream iter okay. That turns this iterator into a stream. So that gives us an inner okay, which is going to be a stream.
01:17:21.503 - 01:18:14.017, Speaker A: And on the stream we're going to map each item, each request. I guess it's going to be an N then. Yeah. So for each value we're going to do this blocking business and then for each result we get back. So for each result that finishes the blocking. This does mean that we're not going to execute them in parallel, which is a little sad, but it might be fine. I wish we could, but I guess if this is in fact an ordered batch, then it's not OK to issue them in parallel anyway, so this is fine.
01:18:14.017 - 01:18:39.721, Speaker A: So we're just going to iterate over the request one by one, which produces an asynchronous stream. For each one we're going to do a blocking call. When the blocking call finishes with the result, then we are going to. We need to do something to manage this is okay value and then we're really just going to forward. I guess this is going to be inspect to do some business. Don't know how we're going to deal with this. Okay.
01:18:39.721 - 01:19:04.603, Speaker A: Yet. And then we're going to dot forward into tx. Right. Does that roughly make sense? So we're going to iterate over all of the. Essentially this is going to be a street over all of the graphql responses and for each one we're going to forward them into this body. Right. So my guess is that hyper was the sender is a sink.
01:19:04.603 - 01:19:32.145, Speaker A: I hope it is not. It's so unhelpful. Why? Ooh. Rap stream. Yeah. Okay, so we can just do that instead then. So this is going to be.
01:19:32.145 - 01:20:21.697, Speaker A: All right. Let's wait for the iter for now. So this is going to produce a body. I guess here we're going to map this into result handle is okay. And this is going to be mapped into result body. So for each one this is going to be is OK and body and it's going to be the body. Right.
01:20:21.697 - 01:21:19.485, Speaker A: So this body now is the concatenation of all of the streams. We're also going to have to inject comma and the characters to wrap around. See? Do I have a good way to even do that? I think the way to do that is we sort of have to chain onto the stream. Right? We don't have a good way of doing that. I Think can I chain streams? Is that a thing that's doable? Is there an FN chain? There is. There's also a concat. But that's not what I want.
01:21:19.485 - 01:21:49.695, Speaker A: Yeah. Okay. So we can do this by doing stream iter. Okay. And we're going to use standard iter once to produce a single element thing and that's going to be this. Right. And then we're going to chain that with this future.
01:21:49.695 - 01:22:22.885, Speaker A: So a lot of stuff. All right, so we're going to produce an iterator that first produces an open square bracket then produces each of these. And then I guess here what we really want is for this to alternate between producing body and comma. So we could probably use zip for that. Yeah. No, that produces a pair. That's not really what I want.
01:22:22.885 - 01:23:06.015, Speaker A: Merge also know what I want. Why do they make this so difficult? I also realized that this is fairly involved code. But hey, this is all what trying to build an asynchronous code base works like. All right, so we're going to produce the open square bracket. I feel like this should be easier actually. All right. There is a way to make this much easier.
01:23:06.015 - 01:23:33.413, Speaker A: It's going to be less performant but that's probably fine. All right, let's do this the simpler way. Futures I guess Future join all. So we go back to the join all we're going to take. We're going to map. This is going to give us results. Let is.
01:23:33.413 - 01:24:08.915, Speaker A: Okay, so this is basically the code we had before Results iter all. This is technically one of these. And then we're just going to concatenate the JSON bodies. And it's a little bit sad like it is definitely less performant than it could be. But much ado about nothing. We're going to do this by doing string concatenation. So for result in results.
01:24:08.915 - 01:24:44.645, Speaker A: I guess this is going to be results we're going to do. Actually we're going to do better than that. We have to join them. So it's going to be. It's awful. Fine. Bodies is results into iter map.
01:24:44.645 - 01:25:23.665, Speaker A: And then we're going to say that body is format. This, this this of body.join, all right. And then we're going to return is okay. Embodied. Let's see what it says about that. This is an either B that is true.
01:25:23.665 - 01:25:50.543, Speaker A: 198. This is a bool. 209 semicolon. 217 semicolon. There we go. That's better. Try ready? Is a macro futures.
01:25:50.543 - 01:27:03.965, Speaker A: So we do macro use 232. I guess this is going to be bodies 110, right? This is now going to map over is okay and body. This is now just going to be is okay code. This is just going to be body 110 right there. This is no longer now generic over the F and R. We no longer need the tick A. We also don't need it here.
01:27:03.965 - 01:28:20.505, Speaker A: 2&5 future is not implemented for GraphQL requests join all map. Oh, what did I do wrong? So consider giving bodies a type. Oh, let's just have this not make a body. It should just make a string and expected string found body. That's because this is now going to be a body from this. Yeah. So this formatting is really sad.
01:28:20.505 - 01:28:47.595, Speaker A: Maybe use body chunks instead. Lifetime static is required. I see. Yeah. So we do need this. No, this. Just because this is tied to a ticket and this is tied to a ticket, that should be fine.
01:28:47.595 - 01:30:03.125, Speaker A: The query T also needs to live long enough. It's true 99 context also long enough. All right, so close this. So this is one thing that could also be made more efficient. It shouldn't be necessary to. Actually, it might not be necessary at all. We might be that we can get around with this by doing this and then we want to move in because we want to move in the request, but we don't want to move in the.
01:30:03.125 - 01:30:36.385, Speaker A: The root node. All right, who. So it's complaining about what exactly. So the thing we move in here. Yeah, it's not gonna like that. Yeah, it's arch. It is arch indeed.
01:30:36.385 - 01:31:23.095, Speaker A: Yeah. Fine. And now this is going to have to be this. All right, now that compiles, these clones are set. And now GraphQL response is never used. And 19 GraphQL response is never used. Who are there tests? I don't think there are tests.
01:31:23.095 - 01:31:56.199, Speaker A: I don't think I saw any. Ooh. Oh, yeah. This OpenSSL business is really sad. I don't think there's much to do about it, sadly. Yeah, my guess is the juniper depends on something. Juniper Depending on some like old version of open SSL somewhere.
01:31:56.199 - 01:32:55.915, Speaker A: It's pretty sad through. No. Why does it. Oh, they just haven't run cargo update in a while. How about now? Really? What is it? That's depending on cargo tree D What is depending on OpenSSL in work? Fine. Something is depending on an old version of openss hypertls. Oh, it's an old version of request request 09.
01:32:55.915 - 01:33:24.161, Speaker A: Great. Now this might not actually compile, but all right. In theory. In theory, that's all we need in practice. Who knows. It's funny because it's a very elaborate way to remove a relatively minor thing. But it does mean that this becomes a lot nicer.
01:33:24.161 - 01:33:50.285, Speaker A: Because now this pool can go away. This can go away. This can go away. This can go away. Now this can go away. The example is simpler. Wait, what? Source lib 285 no builder.
01:33:50.285 - 01:34:15.575, Speaker A: What does it need a builder for? No pool. No pool. No pool. So satisfying. Removing stuff from code 322. Oh, that's awful. This is because that has changed.
01:34:15.575 - 01:34:52.971, Speaker A: Question. Would it also be possible to use a single Tokyo blocking around the execution request function? So the problem is the lifetime association between request and response. So that I think that's what makes it hard to do the blocking outside. But it might work. Yeah, that might. That might work too. It might simplify the code.
01:34:52.971 - 01:35:50.065, Speaker A: Although I'm not sure you could try it. Header value. Why did they change all of this? It makes me so sad. This is in response headers get which gives you an option T header value. And what this is trying to do is print it. Which I think has to be if let to straight. So pool Spawn has different lifetime requirements.
01:35:50.065 - 01:36:12.665, Speaker A: Well, it's more that pool spawn is not asynchronous whereas Tokyo blocking is. That's what makes it tricky. You need to keep pulling so Tokyo blocking can return not ready. Whereas that's not true for future CPU pool. Future CPU pool always succeeds and just queues up the request. That is not true for Tokyo blocking. That's what makes them different.
01:36:12.665 - 01:37:06.833, Speaker A: If matches either A either B. I guess this needs to use futures. Future either. And now there's no longer a need for the extreme crate in the example. Go away CPU pool. Go away and where. Right.
01:37:06.833 - 01:37:32.335, Speaker A: These are now all different. So this is either A either. I really wish it was a nicer way to express these because this just becomes ridiculous. Specifically this one. So let's call these both B. Then this is B. Then this is a B.
01:37:32.335 - 01:38:03.889, Speaker A: So this is one of those places where like the box is definitely nicer and we need to use futures. Yeah. Maybe we should just let this stay boxed. That's probably right. Especially given that it's an example. You really just want to show the user how the code works and you don't want them. You don't want the example code to do like low level optimizations.
01:38:03.889 - 01:38:43.179, Speaker A: Right. So let's just get rid of this for now. Much arm with incompatible type. Really? All right. I guess this is going to be something item. I don't care. An error.
01:38:43.179 - 01:39:31.085, Speaker A: I don't care. So the problem is that box new will normally just so this is going to return a box of type impulse. This is also going to return a box of impulse, but the two impulses are different specific types. And so we needed to turn this into box future and needs to make the compiler realize that we actually want box of a trait. Wait. Cannot be sent between threads safely. Huh? Ooh, great.
01:39:31.085 - 01:40:08.145, Speaker A: All right, that was a process, but I think that's all I think now we're all the way through. So let's submit a pull request. Hey, that's not bad on time either. Good job, team. So this is where we want to be helpful. Let's see. Remove separate thread pool.
01:40:08.145 - 01:41:25.405, Speaker A: Use only a single thread pool for Juniper Hyper. I don't know if actually moving this window down makes any difference, but all right, and now let's make this a little bit more helpful. Ooh, why is thread pool underscored thread pool? That's weird. All right, the previous implementation. So usually when I write commit notes like this, I like to try to explain what the previous thing did and how this is different and why the change is better. It's like a good way to follow these. Previous implementation used a futures CPU pool operations which caused their.
01:41:25.405 - 01:42:37.081, Speaker A: No prezimpletion Used a future CPU pool for executing blocking Juniper operations. This pool comes in addition to the thread pool started by Hyper through Tokyo or executing Hyper features. This patch uses Tokyo blocking to implement to perform the blocking Juniper operations while reusing the same thread pool as Hyper. I feel like maybe thread is two words unclear. I don't know. It's a good question. Which simplifies the code and also the API and.
01:42:37.081 - 01:43:07.755, Speaker A: And also reduce. Great, let's do that. Push you origin this branch. All right. Juniper. Ooh, that's new. Great.
01:43:07.755 - 01:43:41.405, Speaker A: And then we. It's kind of nice because most people don't know about this blocking function. I'm also going to do this. Where did that go? Over here somewhere. I'm also going to link to this great pull request. All right, good job, team. We did it.
01:43:41.405 - 01:44:07.265, Speaker A: We implemented pull requests in open source repository and it's been a little bit over 90 minutes, but not that bad. I think I'm decently happy with that. All right, we did it. Developers now. Oh joy. All right, we successfully contributed to open source. Woohoo.
01:44:07.265 - 01:44:43.365, Speaker A: Now we move on to the next project. I realized there was probably a lot of like there's a lot of fiddling going on there. That's sort of fairly low level and it's unclear whether it's useful or helpful. But like often this is the case when you're digging into a code, especially making a change that's so oriented around async stuff like it might be hard to follow. Hopefully going back to watch the stream again might help you, but let's hope it was useful. Certainly the. I think the commit makes this project better, which is good.
01:44:43.365 - 01:45:17.605, Speaker A: All right, now we're moving on to project number two, Tokyo Beanstalk D. All right, let's see. What is Beanstalk D? A simple fast work queue. Oh, I see. So this is similar to. Right, right. This is similar to Sidekick or Factory, it seems like.
01:45:17.605 - 01:45:57.255, Speaker A: So you like issue. You issue jobs. Yeah. Okay, so you issue arguments for jobs to some work server it distributes to workers and the workers pull that job from the pool and then do some stuff. Uh, well I'm glad you learned something. You are biased in that this is your crate and so you presumably know more of the low level stuff, but hopefully it's useful to other people too. Like I also did not know anything about this, so hopefully I've explained the process that we went through.
01:45:57.255 - 01:46:18.241, Speaker A: Okay, so Beanstalk D to do list for your distributed application. Yeah. So you queue up jobs and then workers take jobs. Yeah, that seems nice. Okay, so this is kind of cool. So I. There's.
01:46:18.241 - 01:46:46.575, Speaker A: There are many of these, but there's another one called Factory which is pretty similar that I actually wrote the API bindings for. So it'll be interesting to see what the API bindings are like here. Although my bindings are not asynchronous, whereas this one is. So that'll be interesting to see. Okay, so let's look at this crate. Uh huh. ASCII based.
01:46:46.575 - 01:47:11.645, Speaker A: Yes. Crate is like a package and cargo is like npm. That is basically accurate. This library can serve as a client for both the application and the worker. Okay, so yeah, so this is. It provides bindings both for issuing jobs and for processing jobs. That's fun.
01:47:11.645 - 01:47:51.455, Speaker A: This is basically the same library as I wrote that's kind of fun. Just for entirely different backend and also async futures and create expenditure and Tokyo runtime. Yeah, you connect to a thing and then you can do a bunch of operations. Okay, this is funny. So this person has very clearly watched one of the previous streams, specifically Tokyo Zookeeper. So compare. This is the example that's given there of operations interspersed with inspector assert equals.
01:47:51.455 - 01:48:35.587, Speaker A: And this is the same. So I think this person has watched this stream or past stream, which is kind of funny. That's cool. Okay, so you can put a job reserve, I think takes a job how you started to do commits in open source? So I usually. I actually got started basically because I found bugs that I wanted to fix. And so I started looking at the code and trying to figure out what the bug I observed was the problem, right? Trying to look for what was the source saying and what was the. Essentially whether I could track down the bug in the source and then I try to fix it.
01:48:35.587 - 01:49:28.461, Speaker A: And then slowly but surely you find, if you think about it, just all of the software you use, anytime something doesn't do exactly what you want, it is probably something you could fix and you just need to be willing to like actually go in and fix it. And then that introduces you to open source a lot, actually. What is Rust even good for? I don't know how to answer that question, except I have. Rust is the first language in a very long time that I really enjoy working with. Like, I actually want to write Rust code. This, this is part of the reason for these streams, right? Why prefer it over Go? You can prefer it over Go in part because it has a better type system. So you have things like enumerations that actually can contain data, which is really neat.
01:49:28.461 - 01:50:01.575, Speaker A: Go does not have this. You have generics, which GO does not yet have. And the proposal is kind of stupid. You have much lower level control over things like memory management, if you care about that, but you also don't have to care about that. You can like use RCS and clones and whatever. I would say that if you're writing, if you don't care about performance and you want to just like write a very large code base that lots of other developers are going to be using, Go is nice for like network programming, so that's one place you might want to use it. C And C.
01:50:01.575 - 01:50:47.365, Speaker A: You want to prefer Rust because it is a much nicer language. It's a much higher level language without giving up any of the low level things you can do in C. And C, it's just a nicer language to work with. Like, I, I think at this point there, there are very few reasons to write C or maybe even C, because the experience of writing Rust is better than writing C. They both compile with llvm, at least most of the time, and you can link between the two. So like, unless you have this huge code base that's already in C, like, I don't see why you would, why you would. All right, so I don't know what this reserve business is.
01:50:47.365 - 01:51:12.489, Speaker A: Release It'd be nice to have comments in this to explain what it's doing. I guess we could take a look at the. Oh, I guess this is the thing to recon. So put adds a job reserve, gives you a job, delete, removes the job. This is a nice way to phrase that. I like this. What VM are using.
01:51:12.489 - 01:51:36.067, Speaker A: Oh, there's a. Just. Because I'm probably going to get this question again. So I did a stream a little while ago where we looked at my setup. So if you look for this video, then that has all the details about all the setup that I have. We can close all of these now. Ooh, that's nice.
01:51:36.067 - 01:51:55.641, Speaker A: Bye. Bye. If a worker cannot finish, can release. Great. All right, so that makes a little bit more sense. So you put a job to the server. A worker reserves a job to operate on it.
01:51:55.641 - 01:52:14.505, Speaker A: It deletes it when it's done and it releases it if it can't. I don't know what touches. I don't know what Barry is explained up here. No. Yeah, that might be handy. All right. Okay, let's look at the document.
01:52:14.505 - 01:52:54.615, Speaker A: So I think this example is pretty contrived because usually you wouldn't ever write this program as a user. I mean, it does say it's a contrived example, but as a user, you would never write this code. Right. You're probably either a client or a worker. And so it might be good to give the examples for the two separate separately. Like basically give an example of here's a workflow for a client and here's a workload for a worker. So split them into multiple examples, maybe under different headlines.
01:52:54.615 - 01:53:33.255, Speaker A: Link to what exactly? If you just go to. Just go to YouTube and search for my name or just. I guess maybe I can post it here somehow. Like you're. Oh, I guess if you're on Twitch, you can't see it here. I think I can do this without it being too sad. Wait, really? It's not gonna give me a chat? Oh, my Internet might not like this add URL.
01:53:33.255 - 01:54:12.455, Speaker A: Yeah, I would probably split this into multiple examples, each one for a different use case. So if we look at the crate I have for a similar kind of use case, notice that it has an example for if you want to submit jobs, if you want to accept jobs. And I think that's a lot clearer for the user. Instead of. This is a test, really. It's not actually how anyone would write code operate on it. It would also be nice if these were links.
01:54:12.455 - 01:55:31.985, Speaker A: So you now have short links. Where is this. Why do I always struggle to find this? I feel like I search for this issue, like every single stream. Well, not terribly important, but you can. So in Rust, if you're writing some doc comment, if you just put square brackets around like anything, like, I guess, let's say. What was the example we had over here? Delete. Yeah.
01:55:31.985 - 01:56:03.575, Speaker A: So this automatically produces a link to the appropriate functions documentation. As you want to do this, like pretty. You want to rely on this pretty heavily, actually, because it interconnects your documentation a lot better. So that would mean that I could like click on all of these to get to the appropriate documentation, which would be pretty nice. There is an issue though, where I don't know if this uses. Yeah. Okay.
01:56:03.575 - 01:56:28.935, Speaker A: So given that you generate the readme manually, it should be fine. What Rust project are you working on for the stream or in general? So for the stream, we're currently looking at this one. We're gonna. The hope is to go to multiple. Right. Have you thought about streaming advent of code 2019 maybe? To me, advent of code is not that interesting. I mean, it's interesting, but it's not.
01:56:28.935 - 01:57:16.835, Speaker A: It's not advanced Rust in the same way. Like, the goal of these streams is sort of to expose people to real world development in Rust. And Advent of Code is not really real code. You're not building any real code base. But maybe, I mean, who knows? All right, so the other problem with this example being so long, actually is all the stuff that you really want to get to is at the bottom and really far down. So it looks like the only thing that you really want to look at here as Beanstalk D. Dropping the struct will close the connection gives you connect.
01:57:16.835 - 01:58:01.387, Speaker A: What's error here? It's a failure error. Okay, so this is relying on the failure crate for error handling, which is nice. The only thing I could imagine here is if I try to connect, I might actually care why it failed to connect, which failure will not give me. You might want to have a. So I have this in Fantoni, I think. So this is a crate for interacting with web browsers or for automating and manipulating web browsers. And most of them just have this generic error response.
01:58:01.387 - 01:58:56.535, Speaker A: But new has a new session error. The reason for this is because I specifically want to be able to highlight reasons why connecting failed. So you can imagine that the user cares about whether it failed because of the network or it failed because of like its connection was denied. The way to think about this is sort of whether to use failure error or not depends on whether the caller will care about which specific error. Like are they going to match on it? And in the case of Connect, they might actually match on it. Oh, here's a weird error or weird put. What is this? Uh, so put returns a self.
01:58:56.535 - 01:59:18.295, Speaker A: Okay, so it consumes self. Yeah, this is. This is one of those things that in the. In the world of Async, we haven't really figured out yet. Like what kind of receiver should you take for methods like should you take self or. Or a ref self or mute self. In this case, it looks like he's opting for self.
01:59:18.295 - 01:59:53.063, Speaker A: I don't know if he see he. I don't know. They are opting to use self to consume self, which means you can only issue one command at a time and you need to chain them, which is. Which means that this will be a little annoying actually to use with Async Await. Because with async Await, it would mean that your. So let's say that I have some bean. Whatever.
01:59:53.063 - 02:00:18.633, Speaker A: It's not important. So the current code is going to look something like you do a put a foo and then. And then what you get back is a is the bean. Because the call to put consumed bean and also the response, there'll be some other stuff too, but that's not important. And then you will do something like bean dot. Other things are there reserve. Right? And then you'll do an and then.
02:00:18.633 - 02:01:02.033, Speaker A: And that will give you another bean and a res. And you end up writing code like this. Right? And that's all fine. It's like a little annoying to have to change them, but that's just how futures work. Now with Async Await, what we'll get is actually the ability to do something like let res is await bean put foo, which is much nicer. Right? The problem is this won't actually work in the setup. If you consume self, this is going to have to be this, right? Which works just fine.
02:01:02.033 - 02:01:48.255, Speaker A: It's just. It would be nicer if the code was just this, which it can be with a weight, but only if these methods take mute self. If they take self, then they always return self. So you have to do this game where you keep returning it. The problem of course, is that if you take mute self and you're not using a wait, then this gets really awkward because the real way you do this is like this. And then you do. It basically becomes no better because you then do this map move.
02:01:48.255 - 02:02:19.835, Speaker A: It's awful. Bean res. And then. And then your next line is going to be this. So notice that if you take mute self then you can make it look like it consumed self. It does mean that you have to take take care that none of your. That you never have this pattern.
02:02:19.835 - 02:03:05.303, Speaker A: Right? Because if you have this pattern, then you. When you call put, imagine the put had this pattern. When you call put, the bean is a part of this future and you're not allowed to move it into this closure because it's still owned by the future. And so this becomes really problematic. So the way I've ended up writing this is if. If I have any of these. So I turn any of these into one that consumes self and then all others are new to self.
02:03:05.303 - 02:03:31.685, Speaker A: And that I think ends up being a roughly this the right compromise. But it is a little bit awkward and I don't have a good way to transition between them or to choose which one is better. It just. They're just very different. But so. So I would probably recommend to have these do mu itself. And it also simplifies the return value.
02:03:31.685 - 02:04:27.809, Speaker A: Okay, so why do they return self and a result? And the future has an error type. Okay, so that's documenting the arguments to this ID Priority delay response. Okay, so I think this is trying a little bit to be generic. So first of all, I would probably take a struct for this instead of having like four arguments is a little annoying to deal with. And the response here is weird. Like this error I feel should just be a part of this error. Although this, that comes down to this error needs to be introspected.
02:04:27.809 - 02:04:56.715, Speaker A: Right. Specifically, you need to know the difference between you tried to put a job and there's something wrong with the job you tried to put. And you try to put a job and the server crashed. Because in one case you can just retry the job or issue a request to the user. If the server crashed, there's no reason to retry. And so this is one of those cases where having a structured return value is probably better for you. So I think that's what I would do here.
02:04:56.715 - 02:05:30.845, Speaker A: So in Fantuccini I think I made this change, but I could be wrong. No, this just has generic errors. Where did I make this change? In Tokyo Zookeeper is where I made that change. So if you look. Yeah, so Tokyo Zookeeper has the exact same problem. Right. This is also somewhere where I should split up this example.
02:05:30.845 - 02:05:59.495, Speaker A: Although to be fair, in Zookeeper you might actually want to do all these things in order. I don't think that's the case in beansokdi. I think in beansog D you're one or the other, but that should arguably be split up. So here. So I do do this here as well. Okay, so this is another case where I'm pretty sure they've just followed what we did in Tokyo Zookeeper. Because notice here, we're also consuming self and we're also taking lots of arguments and we're also returning a triple.
02:05:59.495 - 02:06:42.235, Speaker A: So arguably Tokyo Zookeeper should be updated to follow what I just said. This is something I've only recently notice myself, so I would not blame this person for doing this at all, given that I did the same thing. But yeah, so notice here, the error for each given operation is actually a specific one. So if you look to create, these are all the ways in which a create can fail. Now, arguably this. This error type could be hoisted to this one and then have create also include like a protocol error. Yeah, I guess this is the reason to keep them separate is that the inner result.
02:06:42.235 - 02:07:04.975, Speaker A: It means that all of these error enumerations don't also have to list like protocol error. So maybe this is. It's unclear actually. I don't know that one of these patterns better than the other. It's just a little weird to see double error. Specifically, I think what, what I'm reacting to maybe is the fact that this one is not introspective. Right.
02:07:04.975 - 02:07:37.525, Speaker A: Like if the put failed with this error, I don't know how it failed. So ideally this should be like put error. If. If there is. If there are in fact multiple ways in which a put can fail, which I assume there are if you go to beans D client libraries, maybe protocol is there not. Ah, protocol doc. Great.
02:07:37.525 - 02:08:29.609, Speaker A: So what does put return? Yeah, so notice here there are actually responses you get to doing a put right. And if you get job too big, like that's something you want to expose to the client and they should be able to match on. And so I think, I think you'll probably want to have these be semantically relevant errors. All right. Apart from that, these seem pretty reasonable. Actually I have the same objection here to the response. So the response.
02:08:29.609 - 02:08:54.573, Speaker A: Oh, I see, so this is where buried comes in. I see. So some of these are in fact parsed because buried is parsed, but like this or this are not parsed and just returned as a generic error. That seems odd. But crucially all of these. So there's one. There's just one giant response type here.
02:08:54.573 - 02:09:36.805, Speaker A: Whereas in reality in real, the responses to a put are only these. Right. So it's not. The current API indicates that put can return any of These things. But we know that that is not true. Put can only return one of these and I think ideally this is something this API would expose. So maybe that should be the change we'll make is to make all the responses be only of the appropriate type.
02:09:36.805 - 02:10:09.915, Speaker A: This probably doesn't have to be a static string like the impl future can probably just return a tick A like this could be generic or TK for any str. Same here. Okay, what else is there? So there's error and response. Ok, so the setup is pretty straightforward. Let's see if there are any known issues here. Known issues. Great, great.
02:10:09.915 - 02:10:26.745, Speaker A: Better documentation. Well, I don't know what to do about that. I guess we could tag it as something we're working on. Protocol commands. Ok, that seems good. All right, well I guess we're working towards that then. So we'll fork.
02:10:26.745 - 02:10:57.195, Speaker A: Great. Specifically we'll need the protocol docs to find these and we'll refine that. In fact, someone should probably do the same thing to so to Tokyo Zookeeper. Note that it does parse the result. It only gives the appropriate result for each one. But someone should go through and if you want to replace all these self. Self with just meanself.
02:10:57.195 - 02:11:51.195, Speaker A: All right, let's see. So we now have a fork of this. So let's do a this. No, that's not what I'm going to do. We want the original one to be upstream. So I want to point master to upstream. And now we're going to do checkout a new and we're going to say precise returns.
02:11:51.195 - 02:12:24.155, Speaker A: Specifically we're gonna have to figure out how this library works. So what's in source lib and proto. What's in proto? Proto response. Yeah. So this thing is a lie I guess. Let's first check that we don't do any ah, cargo format does lots of things Cargo format. All right.
02:12:24.155 - 02:13:00.359, Speaker A: Just I like to do all the formatting in a separate commit just so I don't have to think about it. So I can just save normally my editor because it's formats on save. So proto response and I guess here. So we know they're using failure, right? Yeah. So really what we want to do here is server error. I guess these aren't errors. Actually I have to go now finish watching the uploaded video.
02:13:00.359 - 02:13:27.005, Speaker A: Thanks again. No, of course. Hope you enjoyed it. All right, so let's look at what these operations are. So it's put reserve using a bunch of them. All right, so for each one we're basically going to do something like here. So this is going to be a put response.
02:13:27.005 - 02:14:15.739, Speaker A: And a put response which we load from the protocol can be inserted or buried or this thing which is an error. This thing which is an error. And draining, which is an error. So these are the only things that are actually possible to get back now for what was the other one? So using. Wait, what? So this should really be use, not using. But all right, so the only response to use is using. So a using response.
02:14:15.739 - 02:14:52.395, Speaker A: Let's see. So put does not return that. It's a put response. Protomod put response. So this returns a put response. And this, this here response. All right, using.
02:14:52.395 - 02:15:33.759, Speaker A: Oh, I guess these not in order. That's annoying. Reserve. All right, Reserve returns a reserve response. I think this is just going to be. Let's make this instead be pub create response. And then this is going to be a pub use proto response.
02:15:33.759 - 02:16:30.839, Speaker A: So we don't have to enumerate them all the time. I think pre job is also just pub crate. And I think job is also probably just pub crate. So a reserve response can only be deadline soon, which is not one of these timed out, which is also an error. Reserved. This is a reserve response can only be reserved. All right, so maybe we can simplify these a lot actually.
02:16:30.839 - 02:16:55.435, Speaker A: So a put response can be a bunch of different things. A reserve response can only be reserved, which gives you a job. Great. So job is actually pub. Oh, pre job is also pub. Okay, fine. So a reserve does in fact give you a job.
02:16:55.435 - 02:17:37.974, Speaker A: Using gives you a tube. And a tube is a super tube. So this gives you back a tube. Right, so we don't need reserved response because the only response to reserve is a job. We don't need using response because the only response is a tube. What about delete? Delete. The only response to delete that is successful is deleted.
02:17:37.974 - 02:18:11.125, Speaker A: So deleted is really just nothing because not found would be an error. So here delete is really just one of these. That could be an option failure error. But I think we can just ignore that. Release can return, released or buried. Right? Sorry. Yeah.
02:18:11.125 - 02:18:50.255, Speaker A: Release can return, released, buried or not found, Released or buried. Okay, so this is going to be release response and that can be either buried or released. So this is going to be release response. Touch. What does touch do? Oh, I guess Barry. But we'll get to Berry. So touch returns touched or not found.
02:18:50.255 - 02:19:20.325, Speaker A: And touched has no contents and so therefore this returns nothing. Burry returns buried or an error. Yep. So barrier returns nothing. Watch. Watch. Returns watching.
02:19:20.325 - 02:20:04.941, Speaker A: Watch Returns watching. I guess let's keep around the old one for any response. So watching is a U32. So this returns a U32 ignore returns either watching or not ignored. And not ignored. Or not ignored is an okay response according to this. But all right, sure.
02:20:04.941 - 02:20:42.623, Speaker A: So watching. Where's fn Watch? No F and ignore. So that is a ignore response. Ignore response. And so we have this here ignore response. And that is either watching or not ignored. What else do we have? That's the last one.
02:20:42.623 - 02:21:16.215, Speaker A: Great. Now this is obviously not going to compile. Ooh, Tokyo Beanstalk. It's obviously not going to compile because we haven't actually made it use any of these new values, new types we've added. But in particular, I think protomod, this here currently gives a response somewhere. So this gives an any response. Depending on the structure of this any response.
02:21:16.215 - 02:21:51.925, Speaker A: Oh, this is using Tokyo codec. We should probably use that for Tokyo Zookeeper too. All right. Yeah. So notice now the compiler we're getting is that. Look, you've promised that this was supposed to return one of these, but you really gave us an any response. What's going on? Which is what we're expecting to see.
02:21:51.925 - 02:22:33.245, Speaker A: Right. Source lib310 so here, I guess all of these are any response. That example is also going to become a lot simpler now, which is nice. Any response? No. So this is now put response. That's put response. This is now this is successful reservation job, which is a job.
02:22:33.245 - 02:23:23.225, Speaker A: This the only reply is tube. So notice how we can simplify this a lot now. In fact, it doesn't even need to say this. It could say, I guess we could just have this be job. Right. So this simplifies the documentation a lot as well, right? Yeah. Yep.
02:23:23.225 - 02:24:08.047, Speaker A: Here, this no longer needs to talk about deleted this release response. So this is now a release response, which is different because. So it used to say that a successful thing is a release response, but that missed buried. So I guess the question is whether buried should be considered an error. It wasn't previously, so that might be something worth looking into. Any touch. We don't need to talk about it all, Berry.
02:24:08.047 - 02:24:56.237, Speaker A: We don't need to talk about the return type at all. This is going to be this. This is just a U32. Now this, I guess is watch. And so there was another one release response, I guess. So the successful one is. What did we say the successful one was for? Release.
02:24:56.237 - 02:25:29.275, Speaker A: Released. Released. So this is going to be variant. Variant dot least. All right, now, of course, now when we try to compile this, it'll still yell at us because we haven't fixed that. Cannot find response in response. I don't think we care about display.
02:25:29.275 - 02:26:05.515, Speaker A: It shouldn't implement display. Cannot find tube. That's a good question. Cub use prototube. And this no longer needs to include that. All right, so now we just need to map all the response types. So let's see.
02:26:05.515 - 02:26:44.365, Speaker A: Release so it gets a thing back. Okay, so release. It is an error. Okay, so it does remap release. Okay, so release response is just nothing as well. So release response here is really just this. So in this case there's nothing.
02:26:44.365 - 02:27:12.521, Speaker A: Map that into. Great. All right, so I guess really what has to happen here is. Oh, handle response. What does handler response do? Handle response is. Oh, it's really just doing the mapping. Right.
02:27:12.521 - 02:27:48.045, Speaker A: So what we want to do here is dot map R and we want to match on R. And if R is actually. It's a little more awkward than that. It's going to be let. This is R0. Then we're gonna match on R1 in the dock of release. You would.
02:27:48.045 - 02:28:15.631, Speaker A: Oh, yeah. So this can go away now. Good catch. How long did it take you to get comfortable with Rust? That's a good question. Depends a little on how. What you mean by comfortable. Like, I think I.
02:28:15.631 - 02:29:00.295, Speaker A: There are still times when I get confused about why it's yelling at me. But at the same time, at the same time, I think. I think it's pretty fast that you become relatively proficient in the language. It's mostly like every now and again you'll get really stuck and it's really annoying. But I think that applies to almost any language. The difference is just in Rust, you'll get stuck at compile time. In many other languages, you'll get stuck with some bug at runtime that you can't track down.
02:29:00.295 - 02:29:40.105, Speaker A: And so I don't think it actually takes that long to become comfortable with it. Like, I'd say it will probably take you at least a few months of, like, regular programming. And then of course, it depends on how comfortable you want to be. Response, response. Did I do something stupid? No, I did want to delete that? Release no longer returns a response. The return is always just okay because buried is turned into an error. I'm also going to make our life a little bit easier here by having handlerespawns also let you do a map.
02:29:40.105 - 02:30:49.687, Speaker A: And I guess this is going to be. This is a closure. I think it's going to be this. So this is now going to be given a response. Oh, actually, no, it's gonna be even better than that where is this? It's not gonna be a map, it's gonna be a mapping and we're gonna. Great. So this is going to be this and it's going to be a.
02:30:49.687 - 02:31:39.211, Speaker A: Any response? Oh, in fact it can be even better. I mean the question is how fancy do we want to do this macro but do I even remember how to write this Rust macros. Where's the there's a thing macro book maybe I specifically want. Yeah, I'm gonna write a funky macro. Yay. Rust macro book in terms of syndics and standard library. Oh that I think goes pretty quickly for almost any language.
02:31:39.211 - 02:32:48.705, Speaker A: Like I think it takes you a few months and then you're proficient proceed macro rules and I want the thing that lets me do multi matches which is like this bit. Yeah, specifically what's the rust hashmap macro. Yeah this is what I want to write. So I want a thing that gives me a and a. Actually this might be over complicating things I think. I think this is probably fine. I just trying to make it even shorter but I don't think it might matters.
02:32:48.705 - 02:33:13.957, Speaker A: You look like Charlie from It's Always Sunny in Philadelphia. I have been told that before. I have not seen the show so I don't know to what extent it's true but let's see. So any response? No. So put is supposed to give us. What do we decide it was supposed to give us? Inserted or buried? Inserted which has. Oops.
02:33:13.957 - 02:34:17.725, Speaker A: Which has an ID in which case that should map to a. Oh, it can't map to an OK necessarily. That's why. So that would map to an OK put response Inserted. I guess I'm a little surprised that buried is not considered an error for put seems wrong but fine, let's not change the semantics of the application at least. So that's going to be any response inserted and buried apparently is not an error. Any other response though is an error.
02:34:17.725 - 02:35:54.155, Speaker A: So where's this business? So what does it do if it gets something else does this. Oh, it's not considered an error because for bury buried is what you expect expect I think put response should just not. Should just return an id. I think we should do this and have this return and then this now uses tube and ID which is the integer ID of the new job because now inserted gives you that and buried gives you this and anything else gives you. Oh, there is a put error Then why aren't these exposed? That's so weird. I don't actually know why they've chosen not to do that also, if you can get. Can you actually get buried to a put? I don't think you can, but you can.
02:35:54.155 - 02:36:24.725, Speaker A: And buried still gives you an id. That seems wrong. Oh, I see. Because technically this is not a consumer error. I feel like this is just wrong. Like it might actually be buried. But specifically, I think put.
02:36:24.725 - 02:37:30.229, Speaker A: I think this is specifically add to bury, because now this can be error put buried. You see, I don't think these should be wrapped in failure error. I think this should actually give you a put error and. Yeah, let's just do that. Right. So now we can semantically return what the actual error was without sort of trying to obscure it somehow. Oh, I guess that doesn't.
02:37:30.229 - 02:37:53.705, Speaker A: No, that should work. Yeah. So if you got buried, that's one thing. And now we can actually, like, actually interact with all of these. Right. So if we got. Oh, but the others are protocol errors, right? What are the other responses? Yeah, the errors are actually Fine, fine.
02:37:53.705 - 02:38:33.397, Speaker A: We can tidy that up later. So if we did not get inserted and we did not get buried, then this is some other error that we don't know what is. And in that case, I think what we want is unexpected response, put response, this. Let's see if it. Ooh, yeah. Okay. So now it's expecting the same from all the others, which is fine.
02:38:33.397 - 02:39:50.501, Speaker A: So for all these others, See, this is why I wanted the macro to do this, because then the last clause could be handled the same by all, but it's fine. So I guess here we're expecting a reserved job and that gives a job, and anything else is an unexpected reserve response. And I guess all of these are going to complain, so we might as well do all of them while we're at this. Are you doing programming as a hobby or doing it professionally? Both. So I'm a PhD student in computer science and so like I do Rust programming for my main research project as well, which is why I get away with this. So using. That's a using response, which is a tube.
02:39:50.501 - 02:40:13.307, Speaker A: Tube is funny. It's a funny word. I like tube using. What else could you get from tube? Just using. Right. Yeah. Delete is similar, except what we're expecting to get is deleted.
02:40:13.307 - 02:40:47.385, Speaker A: Right? Yeah. And otherwise we got unexpected deleted response or I guess delete response. And this is really used even though the function is using. Oh, and I guess this is a Tuple release. Already does the right thing. So that's great. Touch does not do the right thing yet because this should say touched.
02:40:47.385 - 02:41:51.485, Speaker A: Berry should say buried. I guess here we want this to Say touch response. We want this to say berry response. So Barry should give you buried watch. Watch should give you watching. And ignore should give you either watching in which case it's an ignore ignore response. N Or if it got.
02:41:51.485 - 02:42:27.039, Speaker A: Or it got not exactly ignore like so ignore. Let's see what it thinks now. Variant not found. Did I misspell that? Probably. I'm always wondering if I'm the only person who uses his right hand sphere fingers for navigating in vim. His right hand's fingers. Who would use any other fingers? I'm confused.
02:42:27.039 - 02:43:06.085, Speaker A: I mean, I've disabled my arrow keys in bim. I don't know if that counts. Error is not implemented for string. Oh, what's the. This is supposed to be format error. I think error from failure. Error from format should be format error.
02:43:06.085 - 02:44:01.181, Speaker A: Think. Hey Kapals, great. I navigate VIM using my left foot's toes. Actually, have you seen the VIM pedals? So someone bought like racing game pedals and then mapped them to escape and insert mode. So they use their feet to switch between modes, which is fantastic. Let's see how this works. This definitely changes the API, but I think it changes it for the better.
02:44:01.181 - 02:44:24.935, Speaker A: Ooh. Oh, right now it's going to complain about the. Alright, so that's sort of what we wanted to happen specifically using. No longer need that. In fact, you no longer need this or that. See, this is gonna make this. This is why we made this change, right? Like this goes away.
02:44:24.935 - 02:45:41.631, Speaker A: This goes away. This goes away here also. So usually for this kind of code, if you're just asserting that something is true, you might as well use unwrap. That's what it's for, right? So I think this should just say assert equal response unwrap data, right? There's no need for this extra song and dance. This similarly should just be bean touch response unwrap. Although we'll have to be a little bit careful here because this is an asref. This is just going to be response unwrap just to check that it's.
02:45:41.631 - 02:46:29.095, Speaker A: Indeed we do this, then we do this, then we do response unwrap id. So that makes that much simpler. Do I need to have Beanstalk D installed or something? Probably. I don't really want to do that here. We're really just checking that it was released. So this is just going to be response unwrap. I guess as ref unwrap.
02:46:29.095 - 02:47:30.953, Speaker A: See how much nicer that code ends up. Now the reason you want to use unwrap instead of ISOK is because it Will actually print the error if it went wrong. I guess we want there to be no return value. So why is this not let me do that. Currently it wants it there but it doesn't care here, which is a little weird. Oh well, here it's doing the same thing. So this is just going to be job or this is going to be response unwrap.
02:47:30.953 - 02:49:03.135, Speaker A: Id this is another one that just responds as ref unwrap. Did I mess up here? Expected that. Found that. Oh, that's why slacking that this should be another response sref unwrap this is going to be. Ooh yeah, put we already know just does unwrap so much code like so don't need any of these. I guess the question here is. Okay, so we can leave this code comment in place because you might want to do that.
02:49:03.135 - 02:50:03.165, Speaker A: Then bean watch and then this is going to be assert equals response unwrap is two and then this is going to be response unwrap. Wait, how did this test ever pass? That's not what you're supposed to get from that, right? What does ignore return ignore response. Oh no. That is what you give. Okay, fine. So that's an ignore response. Watching.
02:50:03.165 - 02:51:20.865, Speaker A: Do you have a GitHub or GitLab account? Yes, they're both under the username John who like this477 I cannot move out of borrowed contexts. That is also accurate. Oops. 505. 508. It's gonna enable to spawn server. Yeah, so I probably need Beanstalk to actually run the tests, which is a little sad.
02:51:20.865 - 02:52:18.265, Speaker A: Makes me a little sad to have to do this, but compile all the things. Nice. All right, how about now? Hey, it passed. Oh, it failed. What? Use of undeclared type or module. Any response on 46? Oh, the doc test. That's awkward.
02:52:18.265 - 02:53:28.685, Speaker A: That used to be the same is the real question here. I think that's the same. I think we can just do this and then do this and then do. I guess are these similarly indented? No two less just to minimize the diff a little. Let's see how that works. Hey, great. And I guess the readme as well.
02:53:28.685 - 02:54:14.795, Speaker A: Readme as well. So that's going to be also the same code because we're not aiming to do all that stuff too. So this minus three. All right, let's look at the diff. So that's simplified. That's simplified. Great.
02:54:14.795 - 02:54:45.673, Speaker A: It passed all the tests. So I guess we submit it. Make all method Return only Return only possible. Let's check that. That's pub Crate. Yeah. Oh, I guess we should probably.
02:54:45.673 - 02:56:06.875, Speaker A: Probably document this, huh? Fine, let's. So where's ignore here? Return only possible. Or I guess refine return types for all methods. That's really what we do. Previously, all methods returned a generic response. However, only certain return type return variants are possible responses to each command. This patch.
02:56:06.875 - 02:57:05.115, Speaker A: This forces users to manually match on the returned types, even when that shouldn't be necessary. This patch does the matching inside the library so that only the expected return value is exposed. Simplify other return. If an incorrect variant according to the protocol is returned, an error is returned dead. This simplifies the API. Let's not say that. All right.
02:57:05.115 - 02:57:33.655, Speaker A: Precise returns the first three hours. Yeah, time zones are hard. I don't know how to. How to get better at this. Like, I tried. There's a page called Every time zone that I use occasionally, which shows you, like, when the time is in various local times. I should start linking to that again.
02:57:33.655 - 02:58:17.085, Speaker A: Ooh, I guess really what I wanted is this. So let's use that instead. All right. We submitted another pull request. Good job, team. Yeah, we started noon Eastern standard time, which is about three hours ago, and we've been so, so good at keeping on schedule. So it's now three hours in and we've covered two crates, so that's an hour and a half per crate.
02:58:17.085 - 02:58:56.315, Speaker A: Actually, let's check up on a little birdie told me that GraphQL pull requests close. Hey, look at that. Our pull request was merged. We did open source software. This is why we needed cheese requests. Wee. Hey, how about that? We made the world better.
02:58:56.315 - 02:59:08.985, Speaker A: At least in theory. Although a little unclear why it failed the test. Oh, just an app failure I don't believe in. Great. We did that. Did that. We did that.
02:59:08.985 - 02:59:45.915, Speaker A: We did all of these. Nice Rust Pointer protection is all right. But why Rust is hard to code. I'm not sure what you mean by pointer protection. I guess you mean ownership. So Rust is hard to code because it's really hard to write your code in such a way that you guarantee that there are no data races, and the compiler enforces that in Rust, and that forces you to reason a lot more through your code. It's empty in here.
02:59:45.915 - 03:00:07.129, Speaker A: What do you mean? Don't know what you mean by empty in here. All right, great. Third crate. Third and final crate for the day. Argonautica RS. So this is an implementation of the Argon 2 hashing algorithm. My bio? I don't know.
03:00:07.129 - 03:00:32.371, Speaker A: Is there a twitch bio? Should I fill out a twitch bio? Important. I mean, I guess I can do that. So the Argon 2 hashing algorithm. So this one I actually know a little bit about. So a while ago there was a competition to come up with a new password hashing scheme. Like there are a bunch of people that just use like do like a SHA256 or MD5/ASH or something of passwords, which is generally a bad idea. You want to sort them correctly.
03:00:32.371 - 03:01:09.565, Speaker A: You want to make the hash expensive to compute so that if someone downloads your database and get all the hashes, they can't easily compute the corresponding passwords. And Argon 2 was the winner of the Password Hashing Competition 2015. And then this is apparently the Rust implementation of or one Rust implementation of Argon 2. Do you ever work with Rocket? I have done very little with Rocket. So I guess the question is, what do we want to do with this? Great. So it's designed to be easy to use, robust, and follow the Rust API guidelines. Oh, I love these.
03:01:09.565 - 03:01:30.555, Speaker A: Great. Feature complete. That's a good read me. Yep. Passure. Uh huh. Yeah.
03:01:30.555 - 03:02:05.845, Speaker A: So there are a couple of others. Oh, it uses simd. That's neat. I'm going to ID the default configuration for hasher and verifier, which was to be reasonably secure. Okay. That's a lot of texts. Yeah.
03:02:05.845 - 03:02:31.345, Speaker A: This is basically the Tokyo blocking stuff we talked about earlier. Although my guess is this uses. Actually that's a good question. What's the CPU pool it uses? Uses future CPU pool. But my guess is this crate doesn't actually do any. Huh. Why.
03:02:31.345 - 03:03:05.279, Speaker A: Why are these not dev dependencies? I think these should be dev dependencies. But yeah, so my guess is they use future CPU pool just for the CPU pool and not for any Tokyo stuff. Like I didn't see a Tokyo listed here. Oh, scope guard is nice too. Yeah. So there's no, there's no async stuff going on here. I think they're quite literally just using CPU pool for compute and not for anything else.
03:03:05.279 - 03:03:41.605, Speaker A: So I don't think this is one of those cases where we want to eliminate the additional pool. Yeah, they basically want to expose a. Interesting. People want to expose an asynchronous implementation. There's a question of whether they should rely on Tokyo for that. So instead of spinning up their own thread pool, they could have a thing that relies on Tokyo for that instead. That way the user doesn't have to configure this explicitly here.
03:03:41.605 - 03:04:09.415, Speaker A: Like you can imagine that if you did this it would just spin up. It would just use Tokyo spawn to run the Hashing on Tokyo spawn with a blocking to run the hashing on a separate. On whatever thread is available in the pool and then return a receiver to that. So that might be one way to get a. Get rid of the CPU pool here. For the non blocking methods. It does mean that they're now relying on Tokyo.
03:04:09.415 - 03:04:51.155, Speaker A: So you might. It could be that we want to add it behind a feature flag, but any chance you give impressions of Tokyo Beansakdi so we've already covered Tokyo Beansokdi or actually. So I'm gonna post the video and the. So you actually just missed it. Specifically we did it from. So when the video eventually gets posted, if you go to like about an hour 30 into it, that's when we start being sucked in and we talk about it for an hour and a half. So you actually just missed it.
03:04:51.155 - 03:05:10.153, Speaker A: Sorry, that. But the recording is there though. The day the CPU pool died. Yeah, you're not wrong. It's more that like thread pools and CPU pools are really hard to get right. And we. It's good if we don't have many of them.
03:05:10.153 - 03:05:46.655, Speaker A: Right. And especially because the intention here is to interact well with future heavy code. Like you can do it on a CPU pool. It just means that you're now likely to have more than one pool. It would be nice if this could share the pool somehow. Of course, relying on Tokyo means that if you have some other executor, then you are now relying on Tokyo instead, which is unfortunate. Multiple threats.
03:05:46.655 - 03:06:21.295, Speaker A: Oh, interesting. And yet they still do this business even though they might already spin up multiple threads here. That seems unfortunate. I like this form of documentation though I. I do worry that this is maybe slightly too verbose. Like I would have a less verbose description here with a link to the. To the actual docs.
03:06:21.295 - 03:06:36.737, Speaker A: This is a really nice read me. Like I'm a big fan. Major props. BC Meyers have written stuff before, but that's really cool. Let's look at the docs and see what we can find. Yeah. Okay.
03:06:36.737 - 03:06:52.083, Speaker A: So the docs are pretty much the same. Which. Yeah. Okay. So they're using Cargo readme. That's why Cargo read me is fantastic because it means that you can generate the read me from the source lib. I wish Rustock didn't set this ugly as font Specifically.
03:06:52.083 - 03:07:11.091, Speaker A: Why are they doing that? Just don't do that and let me use my own font. Stop setting my font. See? See how much nicer that is. Rustock, stop setting the font. Maybe that's the thing we should do. Rust. I guess.
03:07:11.091 - 03:08:16.445, Speaker A: Rustling Rustock fin Rustock source Source no tools Rustock main that's unhelpful. Library maybe feel like this is something I. I want to submit a PR that just removes the font overrides because you should. You should never be doing font overrides. Librustock in dot dot slash Libra There is no Libra stock. Rustock themes that's so unhelpful. Restock.
03:08:16.445 - 03:10:02.749, Speaker A: That's still pretty unhelpful. Where did this light.css I know this is slightly tangential, but Lib Rustock theme All right, well, where is the external files? Rs? Where's the CSS Really? Cheat sheet CSS in HTML Static. Aha, great. Where is it that it's overriding my font? Where is it overriding my font? If I go back to this. All right, where do these font stuff come from? Style css oh, this is probably set by docs RS actually docs RS needs to stop that immediately. All right, well, I'll do this later.
03:10:02.749 - 03:10:28.355, Speaker A: Seems not worth it. But I guess templates no. Yes. Style I will fix this later. Stop doing that. All right, so back to argument. Rust docs aren't run by the Rust team last time I checked.
03:10:28.355 - 03:10:55.905, Speaker A: So it's not about the. No, docst is not. It's true. The handover is probably place I was thinking the style was set by Rustock when it generated the file. It's actually set by docs RS and so that's why I'm gonna so submit a PR to get rid of these because it shouldn't be setting my font. Let's see. Okay, so we have these docs and the question is what's down here? So there's a nice.
03:10:55.905 - 03:11:23.171, Speaker A: See, I like this. That was very good. I mean I still have an example here. It's probably not terribly important, just these things from your master machine. This though the default hasher does not have a CPU pool. It's only for hash non blocking and hash raw non blocking. Oh, I see.
03:11:23.171 - 03:12:13.565, Speaker A: So that's why they've set it up this way. So if you try to call it and you haven't set up a CPU pool, then everything will be fine. Whereas with Tokyo that wouldn't be the case. Like specifically if we tried to spawn the hasher. If we tried to spawn the hasher, then then there might not be a Tokyo runtime running. And if there isn't a runtime running, it would just fail. So we're adding this like implicit dependency on Tokyo hash non blocking.
03:12:13.565 - 03:13:09.635, Speaker A: And let's look at what this does Hash raw non blocking. This one? Yeah. Oh, that's interesting. So it actually. Oh, it moves the hasher. What does scope guard guard do again? Scope guard Scope guard colon colon guard. Owning the with deferred closure.
03:13:09.635 - 03:13:36.985, Speaker A: Right. But it's not owning V. It's just mute self. Yeah. So I think if I remember correctly, Tokyo Spawn requires the future to be. Oh no, it does. Hasher to owned.
03:13:36.985 - 03:14:33.635, Speaker A: Okay, I see. And scope guard has a two owned. I guess the D refs. That's pretty weird. Why does this use a scope guard guard? Because this to owned is going to go through the hasher is going to go through the scope guard and just call toowned immediately. So this is really just going to clear immediately before spawning? I guess so this is just equivalent to calling clear on the original hasher after you call toowned. Unless I'm missing something.
03:14:33.635 - 03:14:49.195, Speaker A: I think that's right. Yeah. I think this should be fine. Let's try to get rid of the CPU pool. We have been making this the mission for the day, so we might as well continue. Right. So we'll do the same thing as we've done before.
03:14:49.195 - 03:15:49.495, Speaker A: We will clone this and then we will go to here remote and upstream this. This make master track upstream. And then we're going to do no more Tokyo over CPU pool. And now I guess we specifically want to edit argonautio rs. Just see that that actually compiles. I assume that it does. I wonder if that's the only place they use the scope card.
03:15:49.495 - 03:16:31.635, Speaker A: Using hash raw too. Feel like that guard is just not necessary. Hello. Failed to run. Why? Source path. It's not an existing regular file. What? What? I mean, I guess build RS line 43.
03:16:31.635 - 03:17:07.545, Speaker A: So get sub module. That's why. Great. All right. So it does test all the things. That's good. All right.
03:17:07.545 - 03:17:47.889, Speaker A: So I think really what this is going to do is it's going to do a. It's going to create. So usually the trick here is to create a one shot channel if you're going to have something run on the pool and then eventually tell you when it finishes. What we're really going to do is we're going to set up a one shot channel, give the sender to the future that we spawn and then just send on it whenever the hashing finishes. Are there any other places where this CPU pool shows up? I guess would be not but configure and then hashraw. Okay. I am using vim.
03:17:47.889 - 03:18:33.545, Speaker A: Well, neovim technically, but stop doing that. So. Oh no. Yeah, that's annoying. Fine. All right, let's see. So the question now is where do we want to change this? So it's really just source or hashing.
03:18:33.545 - 03:19:18.805, Speaker A: All right. And Cargo TOML is going to no longer have future CPU pool. It is instead going to have Tokyo 0.1. We also need Tokyo thread pool 01 because we need the blocking function source lib down here. We're also going to need extern create Tokyo and Tokyo thread pool up here. We're going to use. I guess CPU pool is going to eventually go away.
03:19:18.805 - 03:20:01.465, Speaker A: That's going to go away. This. Okay, so I don't think the scope guard here is necessary. Although it's fine. Like I don't need to change it. But instead of doing this, it's gonna do Tokyo spawn move. Well, I guess so Tokyo Spawn takes a future and in this case the future is gonna be A.
03:20:01.465 - 03:20:17.233, Speaker A: So this is the same trick as we played in Beanstalk D Right. It's gonna. Sorry. In. Well, in Beanstalk as well. It's in fact we played all through the day is using this like blocking stuff. Right.
03:20:17.233 - 03:21:11.985, Speaker A: So we're going to need futures. We have futures here. Tokyo Prelude Star and then we're going to do this going to be future Polo fan move. There's going to be Tokyo thread pool blocking move and not move. And that's going to be hasher hash raw. We're going to make a TX and an RX which is going to be a few. We are going to need futures and we have futures sync one shot channel.
03:21:11.985 - 03:22:09.875, Speaker A: And then really what's going to happen here is we're going to dot map this is the final hash and that we're going to send on the transmitter of the channel and then we're going to return to the user this is the RX part of the channel and that should be. All right, so the setup is what is error here? That's a good question. Tokyo thread. How can I. Oh, I guess. Okay, so that is a result. Yeah, I think that's right.
03:22:09.875 - 03:22:49.795, Speaker A: TX send and this is going to be A. Then specifically we need to match out the R. So so this can be futures. Let's look at what the one shot channel is. So it's under sync. I don't want future 02 sync one shot receiver. So the error would be cancelled, which is if the sender is dropped, which shouldn't happen, but it could happen.
03:22:49.795 - 03:23:17.005, Speaker A: So this is going to be a result. Result. And this is going to be an error. I guess. What is a cancel? Where is it? Canceled Lived Futures Futures Sync. One shot cancel. So the question is, what is that going to be? I don't know yet.
03:23:17.005 - 03:24:12.611, Speaker A: We do have to use Tokyo thread pool. What did I go into the. Oh no, that's annoying. Argonautica. Argonautica rs. Right. So the other question here is I guess if the blocking error, that's if the thread pool if Tokyo is shutting down and so if Tokyo is shutting down, we're just going to drop the sender and then handle that is canceled.
03:24:12.611 - 03:24:52.303, Speaker A: So all of those are just going to fall into the same sort of category. So I think here we just do math Error. Let me just ignore that error. Ignore error. Because it will. It is handled by the cancelled case below. There is no longer a default CPU pool.
03:24:52.303 - 03:25:46.275, Speaker A: We don't need that. There is is. We do need to use Tokyo for Tokyo spawn config defaults. It's no longer a CPU pool. So this goes away. Oh, why is that? Why is that default CPU pool Serde? It's not actually used by anything, so I don't know why that's even there. Verifier.
03:25:46.275 - 03:26:12.945, Speaker A: So that goes away. This goes away, I guess. Oh, verifier also has a CPU pool. I mean it'll work basically the same way. Right. So we're gonna go back to our hasher down wherever that was. Ah, I was right there, saw it.
03:26:12.945 - 03:26:53.035, Speaker A: So for the verifier it's basically going to be the same thing. We're going to spin up a thing, we're going to move the hasher, we're going to move the verifier. I'm going to do verifier dot verify. I'm going to send. That's just going to be an OK and that's going to be returned there. Remove that. And of course now we need all the.
03:26:53.035 - 03:27:24.045, Speaker A: All these users don't need this and don't need that hasher config no longer has a CPU pool. So. Oh, that's why it was there. Okay, that's fine. CPU pool is going to go away. CPU pool is going to go away. CPU pool is going to go away.
03:27:24.045 - 03:28:00.175, Speaker A: There's also a verifier config that goes away. That goes away. Isn't it beautiful when so many things disappear? That goes away. That goes away. That goes away. Source Verifier 242 no longer needs the CPU pool hasher I guess 244. No, that's the same one.
03:28:00.175 - 03:28:35.905, Speaker A: What else do we do wrong? Verifier 172. Oh right. This needs to still have this line. All right. 282 oh, this send can fail. Really? Okay. This thing.
03:28:35.905 - 03:29:22.989, Speaker A: I guess the problem here is really this. We. I think we know that this can't fail because the sender hasn't been dropped. So we could do dot expect there's going to be. There's no way for that to be dropped. Really. Actually no, there is.
03:29:22.989 - 03:30:03.355, Speaker A: So if the user just drops the future we give back then the send would fail. Which is fine. It's okay if the user decides they don't care about them result. And same down here where. Right. That's all fine. So now of course the problem is now you need to run this under Tokyo to work.
03:30:03.355 - 03:30:51.415, Speaker A: I don't care about that. We also still need to figure out what to do if it was canceled. So it'll be canceled if. If the thread pool shuts down, which it shouldn't be. I guess the question is what errors do we even have to express something like that. So what did the old code do with the CPU pool? So the old code just did spawn FN and that just worked. So let's look at future CPU pool.
03:30:51.415 - 03:32:09.125, Speaker A: So what does CPU pool spawn offend? It gives you a CPU future and a CPU future implements. Really? How is that possible? So what this is saying is that there's no way for this to fail except the. Except in the ways that the return future from this closure fails. Which seems bizarre. Like I don't know that I believe it. Actually here's probably the way to do this actually. Instead of we don't really need to do a Tokyo spawn here.
03:32:09.125 - 03:32:51.757, Speaker A: We could just do a holofen blocking. Yeah, I don't think we need the spawn which is nicer. Actually. This can just be that. Right? Because we don't this right. Because we don't particularly care. So Tokyo spawn is just going to put the execute and the verifier on a different thread.
03:32:51.757 - 03:33:48.201, Speaker A: We don't necessarily care about that. All we care about is the fact that we're not blocking the current pool thread. I think this is better. It does still rely on there being a Tokyo thread pool running, but that should be fine. And so I guess really here the only then thing we need to do here is the thread pool is exiting. So then what do we do? And now it's complaining about what exactly. I guess we should just do then R and then match on R.
03:33:48.201 - 03:34:28.471, Speaker A: And if it's any kind of regular thing it's just going to be R. And if it's error it's going to be Tokyo thread pool blocking error. And then the question is what do we do? So I think that should satisfy it. Yeah. Okay. And then down here, why is this jumping around in this file? It's very frustrating. Yeah.
03:34:28.471 - 03:35:22.695, Speaker A: So this is also going to be simplified because it's now just going to be here, hasher, hashraw and then it's going to do the same thing. Yes. The question is what do we want to do if the thread pool is exiting and this is a case that like the old implementation just ignored? I feel like it just panics. That would be my guess. Drop. I mean it could be that the right thing to do is just to panic. But where does the error come from? Error.
03:35:22.695 - 03:36:42.705, Speaker A: The error is an error kind and a display. Now the question is just like do we want to panic here? Basically trying to figure out whether there are other places they unwrap or panic. That's all in testing. Yeah, it doesn't look like it. So I guess what we do here is we return an error where the error kind is something like what is error kind here? Add context. I think we do error new dot add context thread cool shutdown while hashing and then this. I guess the question is what, what are the error kinds Use error kind.
03:36:42.705 - 03:37:50.835, Speaker A: What's an error kind? Oh, I see. I think probably what we want to do here is then add something like we'll just add a new one. I guess that is pool. The thread pool used to. I feel like thread pool needs to be two words. The thread pool used to asynchronously execute operations exited prematurely and without full stop apparently. Because now this can just be an error kind.
03:37:50.835 - 03:38:33.425, Speaker A: Pool terminator and same in verifier. Let's take a look at that. Oh, it's Argonne 2. Yes, it is indeed Argon 2 unused import. That is true. We no longer need the import of Tokyo or Tokyo maybe even more futures. And also in hasher.
03:38:33.425 - 03:39:45.255, Speaker A: We don't need any of those. Ah, do need that. Okay, now I guess we still need to. Okay, so this goes away. This goes away. And then here we need to say the hashing is performed is performed on the current thread. That changes performed to the current tread thread.
03:39:45.255 - 03:41:20.205, Speaker A: Actually, let's start with putting it here. Dangling references aren't welcome performed on the current thread. But I guess that is also a good question. So we have changed the semantics of non blocking here a little bit because if you just wait on. I guess you shouldn't wait on this future. The semantics of this now is the current thread is going to be used to do the hashing. But the current thread is wherever you spawn the future on whatever thread runs this future is another question is what happens if you call blocking and you are not currently running under Tokyo? Probably panics would be my guess.
03:41:20.205 - 03:42:10.905, Speaker A: We should find out. Probably. I guess we'll have to look at the source. Yeah, I'm pretty sure this panics because I think worker with current is going to panic. All right. So I guess the hashing is performed on whatever thread executes the returned future. It will not.
03:42:10.905 - 03:43:43.525, Speaker A: But I guess we should link to this. But Tokyo blocking I guess. But with a Tokyo blocking annotation to ensure that the thread pool that the time is not blocked from polling other futures. Note that I guess we do have to say that it now depends on Tokyo Leave at least two blank lines between functions. So I would also normally leave two blank lines between functions or at least one. But this is the way this project is set up and so I'm not going to change it. You want to conform to what the original authors are doing, right? It's not your job to set the code style policy for someone else's code base is not blocked from pulling other features.
03:43:43.525 - 03:45:21.525, Speaker A: Note that the returned future relies on being executed by Tokyo and will not and will panic if that is not the case. And same for verifier. The verification is performing whatever threads is the future. All right. And then I guess I CPU pool okay, so we're gonna have to run that example Arc Arctics I wonder why this is. Oh, this has to return a future. Huh? So the question is whether Actix.
03:45:21.525 - 03:46:00.465, Speaker A: I think Actix Weg does use Tokyo. What? Oh come on. Six really on top of Tokyo. Okay, so this should all just work fine. Just without the CPU pool. Without the CPU pool. Without the CPU pool.
03:46:00.465 - 03:46:52.593, Speaker A: Don't need the CPU pool anymore. Don't need the CPU pool. Great. Source Lib still has some cpu. We'll stuff it it that goes away. That goes away. This entirely goes away.
03:46:52.593 - 03:47:52.295, Speaker A: Which is fantastic. I guess. CPU pool CPU stuff there we can get rid of. All right. So it's only the readme readme diff readme did not change any of those. Only thing I changed was no change. That did change this.
03:47:52.295 - 03:48:15.033, Speaker A: Did change this. Did change this. I'll change this. Sorry. Just to see that we haven't included any weird changes here. I don't think so. I think this is a pretty straightforward change.
03:48:15.033 - 03:50:17.163, Speaker A: Really. Remove futures futures CPU pool in favor of Tokyo. Previously a dedicated CPU pool was spun up to run hashing and verification in a non blocking fashion. This is unfortunate given that there is usually already a CPU a thread pool running with Tokyo thread pool. Ideally this patch changes the code to run non blocking hashing and verification on the Tokyo thread pool. Instead, to avoid configuring and creating a separate one, it uses Tokyo thread pool blocking to ensure that it does not hold up other features while doing so. So one thing that's good to do is if you're submitting something that like changes something relatively deep like changes the essentially changes the API without expressing that in the API.
03:50:17.163 - 03:52:29.055, Speaker A: So we've removed some functions right? But it's not really expressed in the API Here then we want to explicitly point out the fact that this does break the API. This makes a major change to the API that would probably require a major version bump. Note that this removes the ability to the number of threads used to perform non blocking compute and instead places that responsibility on whomever sets up the Tokyo runtime. This is probably better but does change the API. Furthermore, the non blocking method now only work under Tokyo and will not work. I guess here we could point out Actix uses Tokyo and will not work in other async in non Tokyo Asynchronous asynchronous deployments, although those should be there. All right, Origin Tokyo over CPU pool Argonautica we have a pull request for you issues here.
03:52:29.055 - 03:53:56.235, Speaker A: Nope, nope. Compare pull requests and nope. I want see why is it not being helpful here and using the latter commit or the bigger commitment rather And I guess we'll do the we'll be nice and do the same thing we did that we did in the other pull request which is add some links to the relevant thing. So this should link to Tokyo blocking. This should link probably to Tokyo thread pool on the Tokyo thread pool instead on Tokyo's I guess we probably want to link to Tokyo the Tokyo runtime specifically runtime. All right. Like so create pull request.
03:53:56.235 - 03:55:57.145, Speaker A: We did it. We have now contributed to Argonautica as well. This is a slightly weirder change. I guess one thing I will point them to is I sort of actually want to get rid of the rust format. Can I do that? I'm gonna swap these two around do so basically what I'm doing is getting rid of my rust format commit now after the fact CPU cool and I guess verifier config in both of them like this is be straightforward config hasher and verifier and now it's going to be the same and I think all of these Are should all be just the rust format changes. So we're going to do reset and then we git pushforce. And now this should only have the one diff that we actually care about and the files change should be much more reasonable.
03:55:57.145 - 03:56:17.129, Speaker A: Beautiful. Beautiful is what it is. All right. I guess now we check whether anything has happened. What was the previous one we did? We did Beanstalk. This one pull request. Oh, hasn't been merged yet.
03:56:17.129 - 03:56:49.795, Speaker A: Oh, well, it did pass the test though, so that's nice. How do you get the Firefox bar tab bar at the bottom? I did a live stream a few weeks ago where I went through my entire, like, desktop and editor setup. So you can just look up the video for that in the YouTube channel. But basically. So Firefox lets you write CSS for the browser Chrome. And so I wrote this thing. So this CSS file, if you add that, it moves the tab bar to the bottom.
03:56:49.795 - 03:57:38.701, Speaker A: It's not perfect, it's just. I like it a lot better that way. Okay, let's see. So we now have this, this, and where's the last one? So that was the first, this is the second, and now this. I think that's a pretty good day's work. We submitted a pull request for Juniper for 100 lines plus 100 byte minus 1, for Beanstalk with two 300 lights minus 200 lines plus, and for Argonautica, 200 lines minus 50 lines plus. It's pretty good.
03:57:38.701 - 03:58:12.623, Speaker A: I think we did well. I hope. I hope you feel that was useful. I think we're gonna stop there and not do another one. There are a couple of other that would be fun to do, but I think, like, it's been about four hours now, and I think it's probably a good place to stop if you feel like. So I'm going to repeat the message from the beginning. If you feel like this was useful, like, if you feel like this, this format of going through other people's code and trying to make changes was interesting and useful, then please, please let me know, because then I will probably do more of them.
03:58:12.623 - 03:58:44.585, Speaker A: It's still a little bit stressful. And it is one thing that's hard is it's hard to predict how complicated the changes are going to be and how viewer friendly they're gonna be. Like, I think some of them are just like really nitty gritty details that may not be interesting to watch and may not be something you learn from watching. But if you feel like the format was useful, please let me know. If you feel like there are crates you would like us to take a look at. Please let me know if you feel like it wasn't useful or you'd like to see something else. Then you're probably not still watching, but if you are, please let me know.
03:58:44.585 - 03:59:18.505, Speaker A: I'm not entirely sure what the next stream will be. I've also some ideas to try to do some more data structure work, so we'll see. Maybe that's something we would do something from the standard library. I should do like a big poll at some point to figure out what we're going to do for the next stream. It will probably be a little while because I have some conferences coming up, but at least I think we I think this is useful. I will post a recording as usual on YouTube. Afterwards I'll make sure to try to link into where we like useful checkpoints in the video of where we started.
03:59:18.505 - 03:59:52.491, Speaker A: A new crate, for example. So if you want to go back and look at some of the things we did and maybe look at them at like lower speed and look at the code at the same time, that's a useful way to do that I guess. Let's check if there are any last minute questions. Your desktop video made me really want to dig into mine. Yeah, I There are still things I want to change. So one thing I found since last time is this is an addendum at the last point of the video. If you have any last minute questions you should ask them now so I can check them out.
03:59:52.491 - 04:00:26.905, Speaker A: So sixiv is great. It's a really simple image viewer that just has vim bindings. It's really handy if you live your life on the command line like I do. The other is Dunstable. So Dunce is a nice way if you're not running like Gnome or KDE or something and you still want configurable pop up notifications for things like receiving email and changing Spotify songs and stuff. This is really easy to set up and configure. I've been really happy with it.
04:00:26.905 - 04:01:01.605, Speaker A: I'm also considering switching my window manager away from X Monad. I just need to find something to switch it to. But yeah, I mean I think the setup was pretty fun. For some reason all of these links are dark blue, which is unhelpful. Let's see. Yeah, the YouTube channel. Sorry, the YouTube channel is just slash C slash my name or that link.
04:01:01.605 - 04:01:34.515, Speaker A: I think this one is easier but all right, sounds good. Well I hope you found that interesting. Follow me on Twitter or Patreon or something if you want to see upcoming streams. You could also, of course, subscribe to these pull requests and see whether there's any activity, whether they end up getting merged or not. And I guess thanks for watching and have a good rest of Sunday for those of you who are still on Sunday, given your time zone. All right, bye everyone. That was a joy to stream for you again.

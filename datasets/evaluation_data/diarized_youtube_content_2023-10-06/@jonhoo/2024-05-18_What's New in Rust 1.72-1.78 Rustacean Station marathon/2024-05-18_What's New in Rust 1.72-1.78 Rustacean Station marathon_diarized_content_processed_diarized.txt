00:09:57.135 - 00:10:00.383, Speaker A: They can hear you. But Nami, now they can hear me. And maybe they can hear me.
00:10:00.399 - 00:10:01.431, Speaker B: I wasn't talking.
00:10:01.623 - 00:10:05.927, Speaker A: Well, no, but they couldn't hear me because I was muted. And they couldn't hear you because you weren't talking.
00:10:05.991 - 00:10:06.715, Speaker B: I see.
00:10:07.655 - 00:10:20.493, Speaker A: And now Chat is complaining that there's no sound. But I think they're complaining because they're like five seconds ago. They live in the past. Okay, they've already spotted your cat. That's good.
00:10:20.589 - 00:10:21.453, Speaker B: Very good.
00:10:21.629 - 00:10:28.085, Speaker A: The I constantly get hounded for cats. Get it? Get it? Hounded, Hound.
00:10:28.205 - 00:10:29.677, Speaker B: No, I don't get it. Can you explain?
00:10:29.861 - 00:10:32.465, Speaker A: No, no, I'm terrible at explaining.
00:10:34.005 - 00:10:35.985, Speaker B: Not one of your strong suits, honestly.
00:10:36.765 - 00:11:08.825, Speaker A: Okay, Chat, we're going to do a little experiment here. And the experiment has in fact already started. You just don't know that you're part of it, which is Ben and I have never done a video based live stream before. I have separately, but not with someone else. And Ben has not at all with his setup. And so the question is, does this work? Like, can you hear us? Can you see us? I think we've accomplished both of those. Is the audio level of Ben roughly equal to the audio level of me? And also, are you all doing okay?
00:11:09.935 - 00:11:18.287, Speaker B: I have problems with volume control. Not in my computer hardware, in my meat hardware. And so I'm not sure that equalizing for my volume will do you any good in the long run.
00:11:18.391 - 00:11:35.833, Speaker A: Nice. We have at least one person already who claims that we have given them a heart attack with the jump scare at the beginning. So that's a success. Roughly equal audio. Ben is a little quieter. Okay, let me make Ben a little louder. Ben is now a little louder.
00:11:35.889 - 00:11:37.325, Speaker B: Ben a little louder.
00:11:38.265 - 00:11:44.205, Speaker A: Ben's volume is noticeably lower. Okay, Ben is now louder.
00:11:45.665 - 00:11:46.405, Speaker B: Great.
00:11:46.905 - 00:11:48.833, Speaker A: What have you been drinking, Ben?
00:11:48.889 - 00:12:04.813, Speaker B: They're asking you by being drinking. This is. So I've been on a chai kick recently and Trader Joe's has this chai powder in a jar. You can like scoop it into your thing and put water in. But the thing is, they also have a chai syrup. I think I prefer the chai syrup to the chai powder.
00:12:04.949 - 00:12:09.301, Speaker A: A chai syrup. That sounds tasty. All right, let's see.
00:12:09.413 - 00:12:10.385, Speaker B: Concentrate.
00:12:10.885 - 00:12:19.585, Speaker A: So now the next question is. Oh, I got. YouTube is telling me error. Try again. But I didn't try anything, so I don't know what it's saying. That's fine. Chat is still working.
00:12:19.585 - 00:12:31.121, Speaker A: Main thing. Now, Ben, if you have Chat open on your side, remember in the top corner it says top Chat. Change it to live chat. Because otherwise a bunch of people's comments will go away.
00:12:31.313 - 00:12:32.805, Speaker B: I want to see the rabble.
00:12:33.705 - 00:12:35.801, Speaker A: Yeah, I don't want whatever the algorithm.
00:12:35.833 - 00:12:38.273, Speaker B: Thinks the aristocracy wants to see.
00:12:38.369 - 00:12:39.605, Speaker A: That's exactly right.
00:12:39.905 - 00:12:41.325, Speaker B: Poor you're tired.
00:12:41.745 - 00:13:11.973, Speaker A: Let's now see if I can also make this share my screen. So if I now do this, I think chat should now see Ben and me on the left and then the Rustation Station podcast website in the center. Let's see if chat can confirm this chat will not be silenced. Video layout looks good. Okay, I think. I think we're almost ready, Ben. So what I'm going to do is.
00:13:11.989 - 00:13:16.025, Speaker B: I'm going to record it on separate audio tracks that in the future we could mix this.
00:13:18.685 - 00:13:37.075, Speaker A: That is a good question. Let me see if I can make OBS do that. Audio stream. Output audio. I'm going to go with probably not.
00:13:37.855 - 00:13:41.235, Speaker B: Okay. So I was thinking maybe we could overlay some music to.
00:13:41.975 - 00:13:43.279, Speaker A: That would have been nice just if.
00:13:43.287 - 00:13:46.199, Speaker B: We were like digging through patch notes and not say anything.
00:13:46.247 - 00:14:01.685, Speaker A: But don't think OBS is going to be happy with that. Especially because we're also streaming at the same time. So we're just going to make the audio editor's life hell. There is a way to do a multi track recording, but I don't know if it also lets you do multitrack streaming because YouTube doesn't like it.
00:14:03.665 - 00:14:10.929, Speaker B: Yeah. I encourage chat to find your nearest lo fi hip hop radio station, put.
00:14:10.937 - 00:14:26.151, Speaker A: It on the background. We can also do this with chatception, which is the most fun thing to do, where they now get to see obs, which shows the screen of obs, which shows the screen of OBS all the way down. All right. You can see my screen though, right, Ben?
00:14:26.223 - 00:14:30.231, Speaker B: The chat section screen. Because if so, that's a vector for malware.
00:14:30.343 - 00:14:30.783, Speaker A: That's right.
00:14:30.839 - 00:14:32.635, Speaker B: Suddenly take over your computer.
00:14:33.055 - 00:14:39.395, Speaker A: Okay. How about I start us recording, Ben, and then we'll just shoot for a marathon.
00:14:40.295 - 00:14:40.687, Speaker B: All right.
00:14:40.711 - 00:14:43.395, Speaker A: Yeah. See if it ends up being a sprint.
00:14:44.135 - 00:14:45.675, Speaker B: Yeah, we'll see.
00:14:46.695 - 00:14:54.805, Speaker A: This is a marathon, not a sequence of sprinkles. And so we will. We should liberally take breaks as needed. The goal is just to get through all of them.
00:14:55.625 - 00:15:00.113, Speaker B: If Chad has any ideas for fun games to play in the intermission, we.
00:15:00.129 - 00:15:02.325, Speaker A: Can also just sing the intermission song.
00:15:03.105 - 00:15:04.529, Speaker B: Of course. The intermission song.
00:15:04.577 - 00:15:07.553, Speaker A: Uh huh. I'm particularly thinking of the GPT to.
00:15:07.569 - 00:15:09.465, Speaker B: Remind me what the intermission song lyrics are.
00:15:09.585 - 00:15:42.415, Speaker A: So the one I'm thinking of is the intermission track from the Offspring that Just goes. And you can just hear that it's intermission anyway. I'm. That's neither here nor there. I'm gonna hit the record button and then I'll let the audio person cut the beginning when they want. Oh, Obs Ninja now says we are on air. How does Obs Ninja know this? Well, all right, well, we're good to go anyway.
00:15:42.415 - 00:15:45.195, Speaker A: We are now recording. Hello, Ben.
00:15:45.935 - 00:15:46.999, Speaker B: Hello, John.
00:15:47.167 - 00:15:57.915, Speaker A: This is going to be an interesting thing for us to navigate because people will be listening to this audio only, but they are also watching it with video. Why are they doing that, Ben?
00:15:58.455 - 00:16:06.333, Speaker B: We'll have to make sure that if we do any sign language, we'll just need to say what we're doing at the same time or transcribe it in a way so that text to speech can at some point do that for us.
00:16:06.439 - 00:16:20.965, Speaker A: That's right. I think we're going to have to keep. Keep chat, make chat, keep us honest here. And whenever we refer to things on screen, force us to say it out loud. But Ben, why is there even chat? Why is there anyone watching us? What's going on?
00:16:21.505 - 00:16:54.979, Speaker B: Well, I think what happened is that, you know, sometimes life gets in the way. I think it's important to emphasize that in the Rust Project, people have a history of possibly working themselves too hard and then kind of burning out a little bit. And so it's important to emphasize to everyone that if you need a break, just take a break. And so I think just, you don't need to feel pressure. It's all a volunteer stuff. And we do this because we enjoy doing it. And in our case, at least in my case, at least, last year, the library that I always go to record, they changed their website and I couldn't find the link to reserve the room to record in.
00:16:54.979 - 00:17:26.653, Speaker B: And so I blame the Boston Public Library, which are lovely, did eventually find the link, but like monthsly, I had to actually go to the library and ask them, where is the link? I can't find it anywhere in your website. And so. But by that point we were already like six places behind. So John proposed this. And so now we are here live, unless you're listening to this in the past, in which case if you're a time traveler, come back to YouTube.com rust station/john.ben.org and you will come and see our, our website, which is this stream.
00:17:26.749 - 00:18:00.755, Speaker A: And that is obviously the correct link. So I guess what we're, what we're going to try to do today is a sort of. I called it a marathon. I Don't know if marathon is the appropriate term, but we're going to go through rust releases from 172 up to and including 178. And if you're listening to this, then this will cut it into episodes so that you at least know which episode we're talking about. But for those watching live, it's just going to be one continuous stream of Rust version after Rust version after Rust version.
00:18:01.215 - 00:18:07.715, Speaker B: Yeah, I wouldn't call it a marathon. It's more like the Tour de France, really. Like, you know, one stretch and then they, like, take a day off and they do the next stretch.
00:18:08.735 - 00:18:17.155, Speaker A: See, now I feel like we should be on those, like, exercise bikes next, or under our desk, and then just not pedal, of course, but we should sit on a bike.
00:18:19.045 - 00:18:22.557, Speaker B: Well, even just balancing on a bike, if you know it's exercise, that's core strength.
00:18:22.661 - 00:18:36.345, Speaker A: That's true. That's true. All right. I think in that case, we should just kick off with the very first Rust release. So let's rewind our brains back to, I guess, August of 2023. Ben.
00:18:36.925 - 00:18:51.973, Speaker B: Well, I mean, actually, you made. But in fact, it was today. It is May 18, which means it is three days past the ninth anniversary of Rust 1.0. So we could just start at 1.0 and work our way up. Oh, so you've heard of marathons? How about ultra marathons?
00:18:52.069 - 00:18:53.741, Speaker A: Oh, I like that.
00:18:53.853 - 00:18:54.509, Speaker B: This could.
00:18:54.637 - 00:19:19.371, Speaker A: This could maybe be like, marathon number two is us doing, like, what's the. What's the first Rust like, version release we did? That was Rust 136, actually. Yeah, 136 is the first one we did. And so we could do a marathon of Rust versions 1.0 until 1:35. Oh, no, that sounds terrible. That would take so long.
00:19:19.371 - 00:19:38.969, Speaker A: Yes. Stay tuned. All right, let's rewind to August 2023 to rust 172. And then let's talk about what's in it. And I will admit that at this point, I have cheated in the sense that I've read these announcements before. So we're not.
00:19:39.017 - 00:19:41.969, Speaker B: I've read them before, too, but it might have been back in December, so.
00:19:42.017 - 00:19:49.085, Speaker A: No, no, no. Remember, we've rewinded our brains to August 2023. And so we have just read this one. Right, Ben?
00:19:49.705 - 00:19:50.965, Speaker B: Of course, of course.
00:19:51.505 - 00:20:08.025, Speaker A: The first exciting new thing in Rust 172, which I can't wait to start using, is that Rust now reports potentially useful config disabled items in errors. I think to explain this one, we need to start with what are Config disabled items, Ben?
00:20:09.405 - 00:20:57.449, Speaker B: I wouldn't say they're config disabled. I think rather config enabled is a better way of doing it in general. I guess how I put this way of thinking about it, where conditional compilation exists and honestly it's a huge pain. I don't know of any language I can do this properly. There are languages that do it better and worse and Rust doesn't do it the worst. But in general, the idea is that you have based on something that happens at build time, you have different code gets turned on. And that may sound like, oh, that's generics metaprogramming and it is metaprogramming, but in a way that's really hard to test for because the way that you the conditions compilation might be like, oh, I'm on this platform and it's hard to mock out being on this platform without just being on the platform.
00:20:57.449 - 00:21:25.005, Speaker B: It's hard to testify if it's config. I'm on Mac os. Well, now I kind of need a Mac machine or emulate a Mac somehow, which is often kind of a difficult proposition. And then if you have multiple config blocks, then making sure that they're all coherent at the same time is actually like a nightmare. It's a huge pain. And so this in this case kind of just makes it easier to figure out when you might have something enabled or disabled.
00:21:25.765 - 00:22:06.649, Speaker A: Yeah, and I think this is specifically sort of a nod to Rust in general trying to be really helpful with error messages. Right. So it's super annoying when you have, you know, you take some dependency, you try to use something from it, a method, a type, whatever, you name it in your use string and then you get told, oh, there's no such method, or there's no such type. And the reason there's no such type is just because of conditional compilation. Like that thing had a, you know, config when this feature is enabled, being an example of a conditional compilation you could have. But the other thing being like this is only available on macOS for instance. But in the past, like before 172, the only thing Rust would tell you is this thing doesn't exist.
00:22:06.649 - 00:22:26.685, Speaker A: And now the error actually tells you this thing doesn't exist because of conditional compilation, because of, you know, that these are the conditions of the underlying reason that that this particular item is masked. And I think this sort of gets at the general Rust tries to be helpful in error messages kind of situation.
00:22:27.825 - 00:22:51.669, Speaker B: Although I think also, I guess looking at the example here, I forgot, right. The really great thing about this is that it will tell you if you need to enable a feature to get something that you currently have. And so it's fairly common, right? If you're pulling lots of libraries like disable features, say no default features, I want to figure out what I want here and then. Oh, you try and use the thing. Oh, I forgot. This feature that I need, it doesn't exist. This method I want to call doesn't exist.
00:22:51.669 - 00:23:15.933, Speaker B: What do I need to actually figure out? You got to go in the docs and dig through and figure it out. And maybe some features require other features. It's kind of a pain. Making cargo more feature aware is always a great thing. In this case it's still not quite the ideal. I'd say the ideal would be having able to query a crate and say, hey, what are the features? And what item does every feature turn on? And that kind of thing. But this gets you a large part of the way.
00:23:15.933 - 00:23:25.065, Speaker B: There's. I'd say and so great, great thing. I want to commend all the cargo people. They've done lots of great stuff in the past like you know, six or so releases.
00:23:25.365 - 00:23:29.505, Speaker A: And by that you mean rust 166 to 72, right?
00:23:30.005 - 00:23:35.637, Speaker B: Yeah, uh huh. Of course we rebound our. I mean even then it's also true, but I'm sure.
00:23:35.781 - 00:24:05.951, Speaker A: No, totally true, totally true. There is a sort of related. I think it's still a nightly feature, even in sort of 2024, which is the doc config thing which allows you to in Rust doc highlight that a particular item is only available under certain features. For instance, so this at least if you go to like docs slash Tokyo or something, you can see that I don't know. The like TCP module is only available with the feature. Net enabled. And so that will show you in the docs.
00:24:05.951 - 00:24:08.915, Speaker A: But this will tell you in the error messages as well, which is super nice.
00:24:10.375 - 00:24:13.475, Speaker B: It's not a nightly feature though, right? In the docs. I think it works right now.
00:24:14.655 - 00:24:19.927, Speaker A: No, I think it's. It only works right now because docs RS compiles on nightly.
00:24:20.071 - 00:24:21.151, Speaker B: Oh, okay.
00:24:21.303 - 00:24:46.215, Speaker A: And so a bunch of crates are now making use of like if I am on docs rs, then use the doc config attribute to set. You know, this is the thing. At least I don't think it's been stabilized yet. The next thing that's in 172 is that Const evaluation time is now unlimited. Ben, it is unlimited. Do you know any of the context for this?
00:24:47.875 - 00:25:20.465, Speaker B: Well, it sounds Similar. Okay, so I don't know the exact context, but there are things in the compiler that are limits. Right. And so if you've done like, you know, extensive stuff, I think before with I think anymore, but in the past, I know using some serious async use cases would have a problem where you'd be. You'd hit limits on the complexity of your types and that kind of thing. And so Rust has upper bounds on certain things to try and prevent infinite loops or again, halting problem. And so there's always the chance that whatever limit you set is actually too low.
00:25:20.465 - 00:25:51.915, Speaker B: And so there's been. You need to provide ways to configure it so users can override it in case like, oh no, actually I really need to have this really, really complex type. And so in this case it looks like it wasn't really they say that evaluation times unlimited, but in the explanation they say maximum number of statements that could be run was unlimited. And Obviously statements take non0time. But in terms of it wasn't like a timer that was running, it was kind of like counting the number of actual statements that were being executed. And so I guess it's been removed.
00:25:52.075 - 00:26:28.979, Speaker A: Yeah, I think maybe what they were getting at here is that CONST evaluation happens perhaps obviously at compile time. And so if you have an infinite loop in a CONST expression, it just means your compiler never exits. And those are way harder to debug than if you have an infinite loop at runtime because then you can just look at what your program is doing. It's very weird when Rust C just takes forever. Right. And so this was probably a way to try to guard against that, to just put some hard upper limit that they expected you would never hit. And then it just turns out that people want to do really fancy things with CONST expressions and so ended up running into this limit a bunch.
00:26:28.979 - 00:26:31.895, Speaker A: So I think it is still a lint. It's just allowed now.
00:26:32.375 - 00:27:16.777, Speaker B: We could also do some audience participation stuff here where we could ask people if they've actually ever had this problem. Because I know maybe someone out there who's actually using CONST in anger and was like, oh, I really need to run this super long loop of compile time, which it's a reasonable thing to want if you're doing, I don't know, maybe perfect hashing or something. There are some reasonable things where you might actually want to do a big, huge long unbending computation at compile time. It does say here that it will still print out warnings every so often. So like, you know, if you're waiting for a long time, it might say, hey, like, you know, you're, you know, currently we're compiling a big long thing, or you're evaluating a big long cost expression, and so go ahead and keep waiting. Or, you know, control C if you really don't like it. And apparently it will still by default, eventually stop you and exit.
00:27:16.777 - 00:27:19.017, Speaker B: But that is overrideable, if you allow.
00:27:19.081 - 00:27:21.925, Speaker A: That's some very high number, it looks like.
00:27:22.425 - 00:27:23.991, Speaker B: I'm curious what the actual number is.
00:27:24.113 - 00:27:27.011, Speaker A: Yeah, I am too. You have a cat on the shelf.
00:27:27.203 - 00:27:37.867, Speaker B: We're here for a marathon, John. Do you want to just do it right now? Just like constant infinite loop and then we'll figure out. Yeah, let's go look, time execution, and then we'll come back in two hours and figure out.
00:27:37.971 - 00:27:47.055, Speaker A: That's right. I mean, this should be fast to find, right? Const eval. Wow, there's no PR that mentions const eval. Long running.
00:27:47.395 - 00:27:52.845, Speaker B: Yeah, just share your screen and let's go. Go to the playground. Or pull up.
00:27:53.265 - 00:28:25.295, Speaker A: I got it here. It's defined as a diag long running warn. Let's see where long running worn comes from in the compiler. Const eval machine. All right. Lint terminator limit. It is 2 million steps.
00:28:25.295 - 00:28:47.045, Speaker A: When hitting this many interpreted terminators, we emit a deny by default lint that notifies the user that their constant takes a long time to evaluate. Yeah. So 2 million terminators, whatever a terminator is here, I guess it's probably like one constant expression being evaluated.
00:28:48.545 - 00:28:58.001, Speaker B: Yeah, I mean, Mary is an interpreter, right? And so like, you know, as an interpreter, maybe, you know, number of, you know, instructions evaluated. Yeah, I'm not sure what miri is. Yeah, yeah.
00:28:58.113 - 00:29:24.535, Speaker A: Nice. Well, we found it. 2 million. For those who were really concerned about this number, you now know that it is 2 million high. The next bit in the release notes is a bunch of uplifted lints from Clippy. And I don't think we necessarily need to talk about all of these specifically, but I am curious on your take about sort of this general pattern of lint's moving from Clippy and into Rust C. Do you know what the policy is there?
00:29:25.955 - 00:29:50.895, Speaker B: So in the past, the idea was, well, so it's a long history here, right? And so Clippy wasn't always shipped with RustUp. It was a separate component for a long time and required nightly for a long time. And now these days you can get it with RustUp. And it's very nice. But the idea was traditionally right now, traditionally in C and C compilers or in any of your compiler in the past there's been this wariness of adding too many warnings. People start ignoring the warnings. There's so many.
00:29:50.895 - 00:30:18.315, Speaker B: It's like oh, it's whatever, I don't care. And then Rust has actually been very good about having a culture of oh, we don't ignore the warnings. We actually care about being warning clean. And in exchange, the Rust developers have been like, well, we'll be. In order to keep this reasonable, we're only going to add so many maximum number of warnings per version so that nobody ever upgrades. Only has a giant warning spew and kind of look, man, I just want to upgrade. And then they ignore it once and suddenly they mess up forever.
00:30:18.315 - 00:30:45.945, Speaker B: So I do generally my opinion is I like having more warnings, but they do need to be applicable. They need to be warnings. You can actually actionable warnings and correct precise warnings and so not things you have to. I don't want to have any ignores. You can in any warning go on the item and say hey, just for this file or just for this function, just for this block, ignore the warning, that's ugly. I don't want that in my code. I want you to only uplift warnings that are super.
00:30:45.945 - 00:30:49.549, Speaker B: No false positives, right?
00:30:49.637 - 00:31:04.735, Speaker A: Yeah, I guess no false positives is a big one. And presumably also the things that are denied by default for things like correctness seem like pretty obvious candidates, especially as long as the. The false positive rate is low.
00:31:07.155 - 00:32:14.561, Speaker B: So denied by default is actually a much higher bar where that's not just annoying users with warnings, that's a backwards compatibility thing. And so again, for a long time, the early Rust there were concerns about oh, if you have a big huge crate graph and someone up in your dependencies has a warning, then you compile your code, it might print warnings to your thing and if you have deny all warnings on in your final code in your binary or your end user library, it'll stop compiling because there was some warning somewhere up in dependency tree. It took several releases to actually address that. Where Cargo will even if you have denied by default warnings, it will not cause your compilation to fail if the warning is in dependency somewhere. Again, the whole point is to make sure the upgrading is clean and easy because the last thing you want is for users to have so much trouble operating that they decide I'm not going to bother anymore. Because that's a problem in C and C where, where people are on these old versions for years and years and years because they're just like afraid to upgrade because it's so painful and Rust does not want to have that. One of the reasons that one of the reasons why Rust is has the very fast release cycle to condition users.
00:32:14.561 - 00:32:39.971, Speaker B: Hey, it's going to be small, short releases that will be easy to upgrade and you don't need to every six weeks. But if you want to, you can. And it's not a big deal too. Again, I like the idea of adding more lints and they shouldn't be too intrusive. You would hope one, that they're not going to affect many people kind of like they are for an obvious error. Three, there's no false positives and four, easy to correct. And so if they have any links that meet this bar, sure, uplift them.
00:32:39.971 - 00:32:40.895, Speaker B: That sounds great.
00:32:41.435 - 00:33:06.055, Speaker A: Yeah, that sounds about right to me. I mean, looking through some of these, some of them, and especially the ones that have been promoted into deny are things that just feel very obvious to lint against. One of them is if you use the like string from UTF8 unchecked method and you give a literal and the literal is not valid. UTF8, like that's just clearly just. It's just wrong.
00:33:06.755 - 00:33:13.707, Speaker B: Yes, that's nothing you'd ever want. It's a great idea. No false positives. Like, this is just wrong. You yourself have said this is wrong, that you don't want this.
00:33:13.891 - 00:34:09.667, Speaker A: Like, we know it'll panic at runtime, so we're just going to stop now at compile time instead looking through. So we have a bunch of stabilized APIs as well as always, some of these kind of interesting. So one of them is an implementation of sync for NPSC senders when T is send. And this one, I actually went a bit digging when I saw it because I was like, this seems weird. Why, first of all, why were NPSC senders not already sync? But also why is it valuable to make them sync now? And it turns out that the reason for this is the standard library implementation of MPSC changed a couple of releases ago in August 2023. A couple of releases ago. So it used to be this custom implementation that had a bunch of optimizations.
00:34:09.667 - 00:34:45.661, Speaker A: And one of the optimizations was I can some. Was it an unsafe cell? It was some or like a ref cell or something, and an optimization where the sender kept like a thread local slot that it used to buffer the message you were about to send if the queue was full. And so therefore you couldn't send from another thread because it wouldn't have access to that thread. Local optimization slot. But when the MPSC implementation was completely swapped out for I think the implementation was in crossbeam. Yeah. Then that optimization went away.
00:34:45.661 - 00:35:18.607, Speaker A: And so senders no longer have thread local state. And so now they can be synced. And then someone observed that because sender NPSC send or send on NPSC sender only takes a shared reference to self, then you can in theory send from an MPC sender that's in an arc. Oh, the camera is panning to a cat. Nice. Love it. And so the idea here was simply we can now enable more use cases for NPSC senders.
00:35:18.607 - 00:35:20.395, Speaker A: So we should just do it. Why not?
00:35:20.815 - 00:35:31.663, Speaker B: And by the way, so the sender is. If you use channels in rust and send library, you get like a sender and a receiver channel. And this is the sender itself is now send. So you can send the sender across a channel.
00:35:31.759 - 00:35:36.121, Speaker A: So the sender was always send. It just wasn't sync. This is what was weird.
00:35:36.153 - 00:35:37.521, Speaker B: Oh yeah, right. Sync. Okay.
00:35:37.553 - 00:36:09.341, Speaker A: Yeah. So this is like the optimization I know because it wasn't actually thread local state, but it was something that. I think it was a cell that meant that you couldn't. You couldn't have concurrent access for multiple threads, but you could send it across thread boundaries. The other thing that we got was, was string leak, which is similar to box leak, but is different in that it leaks. So a string behind the scenes is growable. Right.
00:36:09.341 - 00:36:45.257, Speaker A: It's really the same as a vector. And a box leak will just take, you know, the. If you have a box str, for example, it'll just take that heap allocation, never free it, and give you a static reference to it. And string leak will do the same to a string, but it will not reduce the vector to be just the size of the string currently. So it'll leak you a thing that might have a bunch of additional capacity. Why you want this? I'm not sure, but they did add it because you already have on strings for them.
00:36:45.321 - 00:36:45.761, Speaker B: So.
00:36:45.873 - 00:36:56.155, Speaker A: Yeah, but it's weird, right? Because string already has this into boxed STR method on it. So if I can maybe time to.
00:36:56.155 - 00:36:59.935, Speaker B: Do some investigation then into boxed STR.
00:37:01.435 - 00:37:38.809, Speaker A: On string, there's an into boxed stir that consumes the string and returns a box str and it drops it. Specifically in the documentation says it will drop any excess capacity. And we've had that since like Rust140. Sorry. 1414014. You know, same thing, but in for string leak it gives you a mutable ref. A mutable reference to a stir and it's not clear why that's useful to me.
00:37:38.809 - 00:37:51.125, Speaker A: Because you can't push to it because it's a stir and not a string. And so what. What. What is it for? Like why not just use into box stirrer plus a box leak?
00:37:51.545 - 00:37:54.409, Speaker B: Maybe it's just behind the issue for it.
00:37:54.577 - 00:37:58.817, Speaker A: Yeah, let's see here. I think it's in the chamber.
00:37:58.841 - 00:38:09.765, Speaker B: People are getting a look into the process of. Normally we do this before we record, but now it's all live. Let's go here to make these podcasts.
00:38:10.105 - 00:39:12.183, Speaker A: That's unhelpful. String leak string leak maybe PRs stabilize string leak. But why? ACP proposal problem statement from 2022 when working in a resource constrained environment like webassembly, it can be useful to leak a small number of strings to avoid cloning later on. However, the existing box leak string into boxed STR may unnecessarily reallocate the string, which is presumably why Vecleak exists. I see. So specifically, if you want to avoid the reallocation and copy that is associated with the into box third that has to drop the excess capacity. So I guess it's in a.
00:39:12.183 - 00:39:15.359, Speaker A: In a very performance oriented setting. You might want to.
00:39:15.407 - 00:39:18.755, Speaker B: Does the documentation for string leak mention that like specific?
00:39:20.375 - 00:39:22.015, Speaker A: No, no, it just.
00:39:22.095 - 00:39:23.115, Speaker B: You really should.
00:39:23.495 - 00:39:40.065, Speaker A: Yeah, it just says. It just says it does not reallocate or string shrink the string. So the leaked allocation may include unused capacity does not part of the return slice. If you want to do that, call into Boxster and then box leak. But it doesn't say why you might want to do that.
00:39:40.145 - 00:39:49.937, Speaker B: So that might be worth opening PR just to do a PR live right now. PR to rust C oh no. How easy it is.
00:39:50.041 - 00:40:17.985, Speaker A: That's too stressful. Oh man. I would need to find where the code is now. But the other question here is do would we want the documentation to change for string leak or for string into box stir? Because arguably it's the documentation for into box stir that should say that the reallocation might come with a copy cost.
00:40:18.365 - 00:40:27.305, Speaker B: By the way, if you ever want to know where any code lives in the REST standard library, just click the source link like John just did and you can read the URL and it will tell you the exact path to the file.
00:40:28.925 - 00:40:46.829, Speaker A: I'm curious though whether this makes me curious whether slicely casts the same thing. Really? I can't do this. That makes me sad. I thought I could do this.
00:40:46.917 - 00:40:48.265, Speaker B: Just the word slice.
00:40:49.765 - 00:40:58.575, Speaker A: Well that gives me slice. But I was hoping that what I'm.
00:40:58.655 - 00:41:00.247, Speaker B: That many Leaks in the.
00:41:00.351 - 00:41:23.015, Speaker A: Yeah, I guess I'll. I'll go back and search leak. Oh, maybe Wait, now I'm confused. If you look at the source for into box stir, it calls. Oh, it calls vec into box slice. All right. Into boxed slice.
00:41:23.015 - 00:41:54.055, Speaker A: On back source it. Yeah. So it basically it's the shrink to fit call. So what does shrink to fit? I see. So into box slice on vec does document that. It calls shrink to fit. Interesting.
00:41:54.055 - 00:42:07.071, Speaker A: Okay, so if we now PR. All right, all right, all right. Live PR. I'm going to file the PR from the GitHub editor. Just. Just to be difficult. Source.
00:42:07.071 - 00:42:38.605, Speaker A: Alex, String source. No, library. See, this is this introduction of the library sub directory broke. The ability to just follow the path from here because you need to know to look under library STD source. Very sad. And then what was it? Alloc string. So it's not even in std, actually, it's in alloc alloc, source string.
00:42:38.605 - 00:42:48.895, Speaker A: And so here we have leak and we have into boxed stir. The worst thing is someone might beat this. Beat me to this.
00:42:49.355 - 00:42:58.815, Speaker B: I guess we could have a bounty. We could have chat race. You have like 10 different people all submit PRs to fix this one documentation thing, and then they'll be very confused.
00:42:59.475 - 00:43:35.125, Speaker A: And I think actually what I want to do is the same shrink to fit. Yeah, I want to use the same language that we used in vec for the into box size, which is this, like so. And just to see that I've line wrapped this correctly because otherwise the line wrapping police will come after me. I will do it this way.
00:43:39.105 - 00:43:39.489, Speaker B: And.
00:43:39.537 - 00:44:24.005, Speaker A: I will take this guy. No, great, don't need this guy and don't need this. And this will be shrink string. And then for leak, it does not reallocate or shrink the string. So the leaked allocation may include unused capacity is not part of the returned slice. The upshot of this is that it will also not reallocate or.
00:44:27.135 - 00:44:27.479, Speaker B: How do.
00:44:27.487 - 00:45:44.265, Speaker A: I want to word this? The opt out of this is that it avoids the potential for reallocation via shrink. For the reallocation that shrink to fit may incur. And then this then becomes a new paragraph. If you want to discard excess capacity, call into box string and then box leak instead. Great. I don't know what upshot means. Okay, the advantage of this, what do you think, Ben? The advantage of this is that it avoids the potential for the reallocation that shrink to fit may incur, may cause.
00:45:44.265 - 00:46:11.885, Speaker A: Result in. I mean, I like incur, but it is a more complicated word. But the Potential reallocation shrink may perform. There we go. Commit change. Make it clearer what string leak is useful for. Propose change.
00:46:11.885 - 00:46:29.325, Speaker A: Create pull request Create pull request. Hey, we have a PR to rust. That was very stressful.
00:46:33.105 - 00:46:35.705, Speaker B: Well, I think it's good to encourage people. Kind of like if you see a thing that's wrong.
00:46:35.745 - 00:46:36.945, Speaker A: No, it's true. It's true.
00:46:37.025 - 00:46:39.585, Speaker B: Nothing's better unless someone makes it better.
00:46:39.705 - 00:46:40.525, Speaker A: It's true.
00:46:41.945 - 00:46:44.129, Speaker B: To do a thing if you're not going to do it yourself.
00:46:44.297 - 00:47:07.323, Speaker A: That's right. The other advantage that we have here is that we can always just tell the audio people to cut that part out for the audio part because it's not going to be very interesting to what to listen to me plan what I'm writing. Okay, back to rust 172. Let's see what we have for the other stabilized APIs. There are some more cons that aren't super interesting. So I think we're then on.
00:47:07.419 - 00:47:21.283, Speaker B: I'd love to just go through and make a graph of standard library and like, you know, chart like, you know, proportion of APIs that are const that to those that aren't const over time and see if the const proportion grows faster than the general standard library.
00:47:21.339 - 00:47:25.555, Speaker A: Oh yeah. Like, are we percentage wise, is the amount of const increasing?
00:47:25.715 - 00:47:31.715, Speaker B: We can. Yeah, like, you know, extrapolate. When will we converge? When will. When will 100% of the library be constructed?
00:47:31.745 - 00:47:36.479, Speaker A: Hey, Ben, you know, it could be that that's already happened and we just don't know it yet.
00:47:36.647 - 00:47:38.406, Speaker B: It could be. It could have happened in 1.72.
00:47:38.500 - 00:47:39.346, Speaker A: That's right.
00:47:39.440 - 00:47:39.816, Speaker B: 173.
00:47:39.910 - 00:47:42.995, Speaker A: Because we're in August 2023 right now.
00:47:44.535 - 00:47:47.543, Speaker B: Well, time is an illusion, so yeah, it's true.
00:47:47.719 - 00:48:08.961, Speaker A: The other bits here, I guess is the change log. And then there's a note about future Windows compatibility. They're going to drop Support for Windows 7, 8 and 8.1 in Rust 175. Luckily, we know that in the future we're going to cover 175. Oh, it's moved to 178. See, you're a time traveler, Ben.
00:48:08.961 - 00:48:21.689, Speaker A: I've always said it. Yeah, that's right. So I think we'll talk about this when we get to that release rather than talk about the fact that it will happen later here, do you want.
00:48:21.697 - 00:48:23.513, Speaker B: To go through the detailed release notes?
00:48:23.609 - 00:49:18.235, Speaker A: Yeah. So this one, I prepared this one beforehand in the sense that I've already read through the change log so that we don't have to read it Live and picked up a couple of things that I thought was interesting, but this is just clicking the Rust cargo and Clippy links under other changes and then just looking for things that stand out. And here are some of the things that stood out to me. The first one is this one, which is that now in with Rust C you can pass dash o dash to indicate that the result of running Rust C should be printed to standard out. And this may seem kind of stupid because why would you want to print binary stuff to standard out? I think there are two reasons why this is useful. The first of them is that it's just more standard. Like most command line tools expect that if you pass dash as a file name somewhere, it means either standard in for inputs or standard out for outputs.
00:49:18.235 - 00:50:07.039, Speaker A: But the other is there are some rusty invocations where the output is actually useful to pipe into other tools. So this could be things like, you know, if you tell rusty to emit assembly, for instance, rather than emitting the raw binary code, and then you pass that into, you know, whatever, a text file for that matter. But you know, something that does analysis on the assembly, it just allows you to now not have to go via a temporary file. Yeah, I don't actually have a use for it, but it's just. It just seems like a nice thing to clean up. The next one is that Rust doc search should allow space as a separator in addition to double colon. Now this one is not that interesting in and of itself because it.
00:50:07.039 - 00:50:46.461, Speaker A: The thing is just if you search for like vec push that you should be able to search for vec space push and get it rather than having to search for vec push. And that was neat. It seems like an obvious win for typing things out and not having to write colons all the time. What was interesting to me is that this indicates that they're doing a bunch of work on Rustock search, which has me very excited. And the time traveler in me also knows that there's some really cool Rustock search features coming in later releases that we can talk about when we get there. The nice thing though is that this, the Rustock search is not just stuff that you get on docs rs. It's also when you run Cargo doc yourself.
00:50:46.461 - 00:51:30.311, Speaker A: The generated thing uses the same search engine. So this is for anything that you document with Rustock. And this is in fact the next tab that I was going to talk about. This is the one that made me think, oh, this is pretty cool. So this is in Rustoc, you can search for slices and Arrays by type using just square brackets. That in and of itself doesn't sound that impressive, but the preview searches of things that this enable is what really got me going. Because it turns out, and I did not know this before this, that you can search for function signatures that match a given pattern using rustock now.
00:51:30.311 - 00:52:12.813, Speaker A: So you can search for things like option and then, you know, dash, open angle brackets, like an arrow and then square bracket. And what that will tell you is all of the functions in the standard library that take a option and return a slice or similarly you can do like, you know, square bracket, U8N, square bracket, arrow, stir and it will give you all of the functions in the standard library that take a bite, slice and return a str. And I did not know that Rust Doc search could do this. Like it actually search on function signatures in this way. But this is super neat. This is like something I've seen in Haskell but did not know Rust could also do in its search.
00:52:12.909 - 00:52:36.973, Speaker B: Right. I always assumed that that was how it worked when I came to Rust originally or came to Rust Doc originally, but it was like, I can't actually just search for types. Weird, because there's always, if you just do a random search, I search for leak or whatever, it shows you the tabs where it's like, oh, maybe we'll find this thing, this type in the signature of the return type or whatever. And I'm not really sure if that ever works. I've tried it and it's been like, you know, strangely weird for me.
00:52:37.069 - 00:52:52.037, Speaker A: But yeah, and I think, you know, this is certainly indicating that they're working towards that goal. Right. They might not have gotten there yet, but it is the thing that they're working on is like being able to generally search for function signatures, which I think is pretty neat.
00:52:52.101 - 00:53:05.679, Speaker B: Sounds very helpful. I think once you have that way to search for signatures, you could even suggest things in compiler output where it's like, hey, it looks like you have this and you're trying to do this, but what you actually want is this.
00:53:05.767 - 00:53:54.871, Speaker A: Yeah, exactly. Like in the help text for error messages, there is a method that matches the signature you were after. It's called something completely different, but it at least has the right signature. And then in the Cargo release notes, there was one thing that stood out. Actually, there were two things that stood out to me. The first one is that Cargo will now start bailing out if a custom build script like a build RS uses Cargo to indicate some kind of build command. So Cargo has a bunch of these cargo colon Things you can print out in a build script, such as, you know, rerun if ENV changed.
00:53:54.871 - 00:54:53.971, Speaker A: So this is something that's that a build script can print a standard out as part of running the build script that tells cargo, rerun this build script if this environment variable's value changed. And this is so that you know, otherwise cargo just has to assume that it has to rerun your build script every time. And so this is one way for the build script to communicate to cargo information about its own execution. And this one stuck out to me because here we're now saying that it's going to bail out if it sees cargo colon, colon. And it turns out if you dig a little bit deeper, the reason for this is because in the list of cargo colon, like special things you can emit from your build script, one of them is cargo colon key equals value. And this is a way for a build script to set an environment variable for the subsequent build. The problem is that because they have cargo colon key equals value where the build script gets to decide what the key is.
00:54:53.971 - 00:56:04.141, Speaker A: It is technically possible for a build script to say, I want to output an environment variable that has an arbitrary name. Like the build script gets to choose the environment name. This means the cargo team is not allowed to add any more build script like special cargo build script output commands, because any one that they add might conflict with an environment variable the build script might have chosen. And so the reason why they started erroring for cargo colon colon is because in an upcoming release, they're planning to say all of the cargo build commands that come out of a build script need to start with cargo colon, colon. And in the sort of new namespace that they're starting there, they're not going to have a thing where there's an arbitrary, you know, build script defined key at the bottom of them so that they can keep adding new things to there. So I think in the cargo namespace, the way to set an environment variable is something like cargo colon, colon set env colon key equals value. And so that way they have the ability to extend that set over time.
00:56:04.293 - 00:56:10.497, Speaker B: And so this is in the next six releases in the future, right? Some new cargo built.
00:56:10.561 - 00:56:14.369, Speaker A: I've heard rumors, yeah, I've heard rumors from time travelers that this feature is.
00:56:14.497 - 00:56:28.745, Speaker B: Coming with colon colon. Yeah, yeah. So I'm not sure if there's like a. No, it's not too hard to upgrade. It'd be nice if there was an automatic cargo fix kind of thing. But, like, it's just. Yeah, this is notifying people that they should upgrade.
00:56:28.825 - 00:56:30.529, Speaker A: Yeah, and also the hard one is.
00:56:30.537 - 00:56:33.081, Speaker B: That they don't have to upgrade because they're not adding any more.
00:56:33.193 - 00:57:31.055, Speaker A: So yeah, the nice thing, right, is that we can keep supporting the old cargo colon version for basically forever because, you know, it works. It's just that we can't add anything new to it. So all new cargo build script commands need to be added to the cargo workspace instead. And then we can, you know, they can start warning on anyone who uses just the single colon version. And I think the last thing I had for 172 is that they added a warning to any cargo workspace that does not explicitly set the cargo resolver version. And this one was weird to me because like, you know, there was a while ago we changed from the default cargo resolver going from version one to version two where version two is smarter about how it resolves feature flag between like dev dependencies and normal dependencies and build time dependencies. But that default did not change for workspaces.
00:57:31.055 - 00:58:05.639, Speaker A: And I'm not entirely sure why. I think there was a good reason. I just don't remember what the reason was. But what that meant is if you had a workspace, you were still using the old resolver, but you might not realize. And so with Rust 172, Cargo has now started explicitly warning you if you haven't specified the resolver key in your workspace cargo toml and telling you you should just always set it explicitly in your workspace Cargo tomls All I had for 172.
00:58:05.687 - 00:58:57.999, Speaker B: There's two more small things to mention here is that if you're using cargo ad, apparently there was a bug where it would reformat your features section, which can be a pain. So Cargo ad, let's do a PSA is a cargo feature that lets you type cargo ad regex and it will automatically go into your cargo tunnel and then pick out the newest version of Regex and plug it right in there for you. So you don't need to go to Chrysler IO and copy the thing out and paste it in for you. But things if it does that, then the compiler, I guess cargo in this case is going through and modifying your file. And so it needs to make sure that the file it reads in the entire file it's not doing searching replacement, it has to read in the file, parse it and then write it back out. And so it has to cleverly try to preserve if you have formagnum in there that's precise. In this case, it's now getting smarter about preserving your core tunnel.
00:58:57.999 - 00:59:45.535, Speaker B: So you don't need to necessarily go through and reformat your tunnel. If you use this feature and the whole point of the feature is to be convenient, so you don't want to have to make users avoid it for the sake of non convenience then the other thing about that in this release is that Let else is now properly formatted with Rust format again. Psa let else if. You know what if let is where it lets you have a branch that's conditional, like an if branch, right? Conditional on the state of a current enum. Let else lets you have kind of pull that it's kind of the opposite, right? So an if and you have if you have like if let some foo equals you know an option, right? Then inside the branch will do some logic. If foo is sum and not if it's none. But if that's like your happy path and you have multiple of these, you have like more and more indentation for all the ifs.
00:59:45.535 - 01:00:18.237, Speaker B: Alternatively, if you do now let some foo equals whatever option you have else you can now have a block for the else branch. And so you are now required to bail out, must diverge or loop or panic or return in some way. That means that your happy path can stay nice and unindented. That's a newish feature, but it wasn't being properly formatted by Rust format, so now it is. That's great. It's an interesting thing. You'd think that the Rust format would be, you know, required thing to stabilize and I think they were just wanted to get it out.
01:00:18.237 - 01:00:21.345, Speaker B: I'm not sure why they stabilized it before this happened. Maybe it was an oversight.
01:00:22.765 - 01:00:46.711, Speaker A: Yeah, I also I've been using Let else so much since it was stabilized, like just all over and it was pretty frustrating when it was not being formatted correctly. So I was very happy when this change landed. I also realized that I messed up because the cargo colon colon thing is actually for Rust 173 which isn't even out yet. So I was clearly lying. Ben. I don't know what I was doing.
01:00:46.783 - 01:00:47.615, Speaker B: It'll be out.
01:00:47.735 - 01:01:35.035, Speaker A: But there was one more thing that I wanted to talk about for 172, which is a thing that's in the nightly only section of the cargo change log that caught my eye and that is the Dash Z script command line. Flag is an experimental feature to add unstable support for single file packages in cargo so we can explore the design and resolve questions with an implementation to collect feedback on. Now this is something I've wanted for A very long time, which is the ability to just write single file scripts that get run as Rust code. And I don't need to write a cargo toml. I don't need a whole project or anything, just single file. And it's really cool to see experimentation sort of continuing in this path. It's nightly only, so it's not technically in this release, but I did think it's pretty cool.
01:01:35.625 - 01:02:08.843, Speaker B: Right. And so actually if we're allowed to break the facade here and talk about some things happening in the present, the real present, it was blocked for a while on syntax. The idea being, okay, so if we have a single crate, where does the cargo tunnel live? It's a single file. We don't want to have to have a separate tunnel file and the RS file. And so we want to be able to encode the tunnel file somehow in the Rust source file. And so how do you do that? It's kind of an unresolved question. And because the idea here is that there's separation between cargo and Rust C, you don't want to have to have cargo understand a full Rust parser just to get.
01:02:08.843 - 01:02:36.031, Speaker B: So doing it maybe in comments might not be a good idea. Maybe doing doc comments is different. Maybe you could have a macro for it. But I think the idea eventually is that it settled on a front matter syntax that is inspired by markdown. I'm not sure if you have a sensation blog repo or where you can kind of show people hey, in a markdown file there's this kind of way that you can specify metadata. It's called front matter where it's kind of like a code fence. It looks a little bit different.
01:02:36.143 - 01:02:37.239, Speaker A: I have one somewhere.
01:02:37.327 - 01:03:12.181, Speaker B: I believe they've recently the RFC to determine the syntax has been accepted. Not sure if implemented and stabilized, but that is actually coming now. And so it is kind of like this where you have these three dashes and I think that's just like a cargo specific syntax where it will be stripped out before it goes to rest C and then you'll put your right in there. And so files can even highlight it if you have a syntax highlighter that understands the front matter. And so yeah, that's kind of just the new ish thing. I suppose it's not stable yet. I don't think so.
01:03:12.181 - 01:03:22.855, Speaker B: Not stable or even possibly in past stabilization. But it is accepted and we have syntax for it that we know what it will be unless it changes. Right? Yeah, that's coming along nice.
01:03:24.875 - 01:03:40.611, Speaker A: I think that's all for 172, which means it's time to turn to my Mr. To Rust, which failed because I had a trailing white space. Because I had a space here. So I'm going to do it this way, which I know is noisy.
01:03:40.803 - 01:03:46.735, Speaker B: It would be so great if we could have this in the pipeline. Except by the end of the marathon, we could have.
01:03:47.065 - 01:03:50.657, Speaker A: I know. Well, I'm trying. I'll check back in on it as we go.
01:03:50.721 - 01:03:57.085, Speaker B: Who do we know that we can like, ping to fast track the review? Is anyone currently watching a reviewer.
01:03:58.785 - 01:04:05.161, Speaker A: Here? I'll put the PR link in chat. Amazing.
01:04:05.353 - 01:04:09.713, Speaker B: Well, I mean, anyone can review a PR. That's just how GitHub works. It's kind of annoying where you just have like, you know.
01:04:09.809 - 01:04:13.079, Speaker A: Yeah, no, we need someone who can actually ride.
01:04:13.237 - 01:04:18.695, Speaker B: Yeah, someone who is allowed to merge things to the Rust repo should go and review that.
01:04:19.435 - 01:04:28.339, Speaker A: Okay, let's move on to the next Rust release, which is. So we're now. We're now forwarding our brains to September 19, 2023.
01:04:28.387 - 01:04:33.615, Speaker B: Should we do the. Do the time travel noise?
01:04:34.035 - 01:04:35.135, Speaker A: Yeah, of course.
01:04:37.475 - 01:04:39.083, Speaker B: That's terrible. Don't do it again.
01:04:39.219 - 01:04:57.107, Speaker A: Sorry. I'll never do it again, Ben. I apologize. I went overboard. So September 19th we got a new Rust release, which was unexpected because it hasn't been six weeks yet. We got rust 172.1. I don't think there's too much to talk about this one.
01:04:57.107 - 01:05:09.675, Speaker A: It looks like it's mostly sort of a couple of regressions that were found in 1.72, which is usually what the point releases are for. It's either regressions or security incidents. Do you spot any of these you specifically want to talk about? Ben?
01:05:09.975 - 01:05:35.347, Speaker B: I'm just going through them right now because often these are platform specific things. But. So this one is about SIMD miscompilation, which sounds reasonable because even in the PR it's like that fixes this. It's unclear what makes this not work sometimes because it often does work. So for now we'll just disable it just to be safe. And so who knows if it's ever been. It will ever be turned back on.
01:05:35.347 - 01:05:41.747, Speaker B: I think it's one of those things where it just. Oh no. People are hitting this. That's a problem we don't have time to investigate. We're just going to turn it off for now and figure it out later.
01:05:41.931 - 01:05:57.255, Speaker A: Which I think is usually a sound strategy for point releases anyway. Rather for a point release, you don't really want to do a bigger change to fix. You just want to Unbreak and then you do the bigger real fix for the next major version release.
01:06:03.045 - 01:06:23.131, Speaker B: Yes, I believe there is an issue tracking turning it back on. The idea was that this is an optimization in SIMD that is nice to have and people were like, hey, we should do this. And they did this and actually it messed up sometimes and no one really understands why. Be safe. This isn't the first time that random miscompilations have happened in llvm. People are like, oh no, just turn it off. Just turn off all that stuff.
01:06:23.131 - 01:06:26.439, Speaker B: Yep, that is the correct approach.
01:06:26.567 - 01:06:29.955, Speaker A: Wouldn't compilers be a lot easier if you just didn't have optimizations?
01:06:30.695 - 01:06:47.487, Speaker B: I mean, how long is this marathon? Because I could talk at you for a long time about my increasingly radical idea that we just don't need optimizers or not need optimizers are terrifying. Ever since the XZ thing. What's xz? I don't know. I think that's going to happen in the next few months.
01:06:47.511 - 01:06:56.615, Speaker A: I'm sure that's true. We're in September of last year, so XC sounds like a really good dependency to take right now. Make sure you stay on the bleeding edge.
01:06:57.515 - 01:07:02.747, Speaker B: Definitely use Arch Linux and make sure you always update your XE library whenever you can.
01:07:02.851 - 01:07:14.855, Speaker A: That's right. Okay, so now we can, we can wind further forward to October 2023. And now it is on a normal six weeks cadence and we have Rust 173.0.
01:07:15.155 - 01:07:19.179, Speaker B: Is this like an intermission real quick? Like you just do a stretch as soon as it's a marathon?
01:07:19.267 - 01:07:19.979, Speaker A: Well, I was going to play a.
01:07:19.987 - 01:07:20.751, Speaker B: Game with the chat.
01:07:20.843 - 01:07:26.435, Speaker A: Yeah, I was actually going to say, should we do another intro to the podcast? Like, hi, Ben.
01:07:26.935 - 01:07:30.199, Speaker B: Normally we always do two in a row, so we'll do an intro every other one.
01:07:30.287 - 01:07:35.063, Speaker A: Yeah, but we have an opportunity now to do an intro for each one and just seem like we've been really on our game.
01:07:35.119 - 01:07:52.647, Speaker B: Listen, we'll just use ChatGPT and say, hey, make an intro for us. Generate audio for an intro using our voices, train, fine tune an AI on our voices and then eventually at some point it'll be automated. We don't even need to do this anymore. Like, you know, our entire lives we're just gonna be living in a, in a GPU somewhere in the Microsoft cloud.
01:07:52.751 - 01:07:59.755, Speaker A: So I think we all live there already. I'm pretty sure it's possible. Everything, everything runs on Windows, you know.
01:08:00.175 - 01:08:00.719, Speaker B: Mm.
01:08:00.807 - 01:08:04.675, Speaker A: Yeah, we can, we can do some stretching. What's your favorite stretch?
01:08:06.695 - 01:08:10.255, Speaker B: I have lots of stretches like we can, we can go through, do a little yoga.
01:08:10.335 - 01:08:16.025, Speaker A: See, I have one of those chairs where the back has room for like legs. It's like one of these guys.
01:08:16.405 - 01:08:17.245, Speaker B: Uh huh.
01:08:17.365 - 01:08:41.905, Speaker A: So I can sit on it backwards, turn it around, and I can even like put my legs up on the things so I can be like. I can sit with my legs up and just rest them on the chair. It's quite nice. It's not good for a long period of time, but for just sitting differently for a little while, it's pretty good.
01:08:44.265 - 01:08:48.165, Speaker B: A question in the chat for the one know what that chair is called? Answer that while I get a new drink.
01:08:48.545 - 01:09:32.435, Speaker A: This one is called the Hog Kapisko and I think it's actually a Norwegian design chair, which of course makes me excited given that I am now in Norway. Fine tune an AI with our time travel sound effects. I don't know what is a good time travel sound effect though, because, you know, time travel isn't. Isn't real for anyone but Ben and I yet. But I feel like it either has to be like a sort of modem like sound, or it just has to be something very outer worlds sounding. I don't think there's a correct answer to this question. Just cue the Doctor who intro.
01:09:32.435 - 01:09:59.463, Speaker A: It's been a while since I watched that show. Oh, how does it go? It goes. It. It like plays in my head, but I don't know how to translate it into sounds. The Jetsonship sound. Okay, let's see. We have, we have chat trying to describe the Doctor who theme.
01:09:59.463 - 01:10:18.085, Speaker A: It goes. Boo. That doesn't sound right. I don't think that's the right writing of that sound. Don't use the sound the TARDIS makes and you'll lose control over where and when you travel to. That's also true. And also we'd probably be sued.
01:10:18.085 - 01:10:45.795, Speaker A: I feel like there are probably rules. I wonder. Let's see if my. How's my. How's my PR doing? Ben, we have a. We have a. An inline review.
01:10:46.655 - 01:10:47.927, Speaker B: Oh yeah. Do we?
01:10:48.111 - 01:11:24.275, Speaker A: It says when I read that there's no reallocations, that I wouldn't expect a sentence, that it's somehow an advantage over some other seemingly unrelated method to leaking. Ah. So this should probably say. Instead of talking about shrink to fit, it should talk about. Yeah, they're not wrong. Oh, I can't. That's annoying.
01:11:24.275 - 01:13:30.895, Speaker A: I think what I actually want this to say is, I guess something like it does not reallocate or shrink the string. So delete allocation may include unused capacity that is not part of the returned slice. If you want to discard access capacity, call into box str and then box leak instead. Though, keep in mind that this may that though keep in mind that trimming the capacity may result in a reallocation and copy. How's that? It does not reallocate or shrink the string, so the leaked allocation may include unused capacity that is not part of the return slice. If you want to discard excess capacity, call into box str and then boxleak instead. However, keep in mind that trimming the capacity may result in a reallocation and copy.
01:13:30.895 - 01:13:42.225, Speaker A: How's that? I think that's pretty decent. And then this goes away, of course.
01:13:42.725 - 01:13:49.173, Speaker B: And then while you're at do you want to add any kind of note at all to into box stir mentioning leak I know they're like I did together.
01:13:49.269 - 01:13:50.085, Speaker A: I already changed it.
01:13:50.125 - 01:13:50.813, Speaker B: Oh, you did? Okay.
01:13:50.869 - 01:13:59.845, Speaker A: Yeah. I said before doing the conversion, this method discards exit capacity like shrink to fit. I guess I could say this may.
01:14:01.785 - 01:14:03.169, Speaker B: Reallocate, which is the reason I want.
01:14:03.177 - 01:14:31.585, Speaker A: To ask with shrink to fit notes that the shrink to fit call may reallocate and copy the bytes of the string, for example.
01:14:39.085 - 01:14:45.885, Speaker B: Is that a question? Yeah, sure. You asked me to write an example.
01:14:45.925 - 01:14:49.585, Speaker A: Or I mean, no, I'm asking whether that sentence looks okay to you.
01:14:50.175 - 01:15:00.623, Speaker B: Yeah, I think mentioning the. So the reason that leak exists is because someone realized oh, like this might reallocate and we don't want that. And so mentioning that sounds reasonable in the docs to avoid someone having to in the future discover that on their own.
01:15:00.719 - 01:15:58.015, Speaker A: Yeah. The reason why I'm mentioning shrink to fit here just because someone asked his chat is because the VEC into Boxster does this line is exactly the same thing that is there for Vec into Boxster or into Boxed Slice. I think this is. Okay, let's do that. All right. Do you want to move on to 173? Sure.
01:15:58.355 - 01:16:04.723, Speaker B: Let me just. I'm just mentioning this live stream to people in my. In the local Boston user group Discord.
01:16:04.779 - 01:16:05.375, Speaker A: Nice.
01:16:06.195 - 01:16:08.521, Speaker B: It's actually the east Coast Discord. We have a channel there.
01:16:08.643 - 01:16:09.305, Speaker A: So.
01:16:11.365 - 01:16:21.065, Speaker B: I didn't make the Discord for anyone who's be about Discord. I use Matrix for many things. Don't worry. And Zulip. I love. I love Zulip so much.
01:16:29.885 - 01:16:38.965, Speaker A: Ha. We have a person from Boston. Amazing. Oh, they've joined already. Is it someone Brian Myers?
01:16:39.665 - 01:16:50.137, Speaker B: Okay. Hello, Brian. If you. I guess I'm here. I'll. I'll share the Boston Rust meetup link if you want to come say, hasten time. We do lunches every eight or so days, just all around Boston.
01:16:50.201 - 01:16:56.325, Speaker A: So every eight days is a weird cadence for lunches, is it? So that it's never on the same day.
01:16:56.825 - 01:17:16.961, Speaker B: How long is this marathon? Because I can. I have been tweaking this schedule for, like, I have, like. I have charts. I have, like, you know, Charlie. The thing with, like, you know, Charlie in the wall and the strings between him, I could talk to you about for days about, like, how I, like, meticulously plan these things and schedule them, and nobody wants to hear that. It's like listening someone describe their dreams. It's, like, only to me.
01:17:16.961 - 01:17:31.411, Speaker B: Does anyone care about, like, the meticulous. I have, like, a document that's, like, a kilobyte long of just, like, trying to, like, plan out and schedule things. That's, like, perfect. Don't. Don't even get me started on this. You don't want to know how this rabbit hole goes.
01:17:31.563 - 01:17:33.615, Speaker A: You're not ready for the truth.
01:17:34.995 - 01:17:43.331, Speaker B: Anyway, so. Hello. Here's our Boston Rust meetup. We do. Yeah, lunches. Our next one's next Monday.
01:17:43.523 - 01:17:44.067, Speaker A: Nice.
01:17:44.171 - 01:17:44.815, Speaker B: So.
01:17:47.075 - 01:18:25.449, Speaker A: Okay, I think it's time to kick off for rust 173 from October 5th, 2023. Um, and this one, I was pretty happy about this first one. It's something that has been a constant paper cut that it just. I just hadn't thought about fixing, and then it just got fixed, and it made me happy. Uh, so this first one is cleaner panic messages. The change here is that if you have a panic, then before Rust 173, it would print as a. You know, if you do a panic, you know, oh, no, before 173 would print, like, thread main panicked at.
01:18:25.449 - 01:19:03.293, Speaker A: And then a quote and then the message. The panic message. Like, oh, no, and then end quote. And then, you know, the location in the file where the panic happened all on one line. And in Rust 173, this has changed so that the output now reads thread main panicked at, and then the location in the file, and then a new line and then the message that you wrote in the panic all on its own line. And the reason this makes such a difference is because now it is much easier to see the message that you put in there rather than it being, like, somewhere further to the right and, like, awkwardly quoted somewhere. And so this.
01:19:03.293 - 01:19:04.665, Speaker A: This one made me happy.
01:19:07.645 - 01:19:27.367, Speaker B: You know, the pending message is one of those, like, you know, really, really, like, old things dates from, like, you know, ancient Rust that hasn't changed for like, a long time. Like maybe. Maybe the thread name might be like, maybe it used to be like zero or something like that. Right. But to me, this is kind of like changing an ancient artifact and seeing it changes. Actually, you're right. Honestly, it is better this way.
01:19:27.367 - 01:19:29.915, Speaker B: You know what? Actually, we did it wrong for you. Yeah.
01:19:30.215 - 01:20:17.551, Speaker A: And I don't know how no one just thought to change it before because it just seems pretty clearly better. And I think we see this with. They also change the assert EQ and assert ne as in not equal macros that have now moved it so that there's no longer a sort of long message to the right of the message you printed. And this is the thing that we're getting at with the panic too, that if you had a really long panic message, or in the case of asserte or assert not equal, if you had very long debug outputs for a given type, then because it was all concatenated together, the location where the panic happened was sort of pushed really far. Right. Because it ended up to the right of the output that you controlled. But now it's on its own line.
01:20:17.551 - 01:20:29.955, Speaker A: And so therefore you never have to sort of scroll right to try to find it. And the two things that were asserted to be equal or not equal are now, you know, directly above or below each other with no other noise to the side.
01:20:35.065 - 01:20:46.205, Speaker B: Yeah. Actually, so out of curiosity, I did just use Rust up to install Rust 1.0.0, and it is largely unchanged, but there were. There used to be angle brackets around main. That's the only difference.
01:20:46.985 - 01:20:50.345, Speaker A: Angle brackets around main. Oh, in the panic message.
01:20:50.465 - 01:20:51.965, Speaker B: Name of the thread. Yeah.
01:20:52.465 - 01:20:55.761, Speaker A: Nice. That seems like an improvement. I'll take that. Yeah.
01:20:55.793 - 01:21:16.765, Speaker B: It's also, I mean, still, like, I think the reason I've noticed this show for so long is the fact that, like, you know, if you're just writing like, you know, a simple program and you're not using threads, seeing thread main might be a little bit confusing. If you say, if you're a new programmer. Right. Like, I'm not using threads, like, why is there a thread here? To knock our fine china off the dresser.
01:21:16.885 - 01:21:22.545, Speaker A: That's right. It's also the best place to keep fine china is up at the top of a dresser, obviously.
01:21:23.085 - 01:21:24.265, Speaker B: Tempting fate.
01:21:25.525 - 01:21:53.845, Speaker A: The next thing we got in 173 is thread local initialization, specifically for the local key type, which is what you get back when you access a thread local. So something. A static that's created with the. Or I say static, and I have air quotes up here. That is inside of the thread local macro. Then when you access one of those, normally you would call like dot with. And the thing that you get passed in there is a local key.
01:21:53.845 - 01:22:14.567, Speaker A: It's a thing that lets you access the thread local and you have to do that in the context of closure. And with Rust 173, if the static type that you have is either a cell or a ref cell, then now there are a bunch of other methods you get directly on it. So you don't need to deal with the closure. Do you want to talk about why this is useful, Ben? Do you have some context for this?
01:22:14.751 - 01:22:29.239, Speaker B: Not really. Honestly, I've tried to stay away from thread locals. I think for a long time they've been kind of like, right, so there's the unstable support for thread locals in the compiler as well. For nightly only. It's been know for like years and years. I've kind of just like not used them at all. Honestly, I cannot comment on these.
01:22:29.407 - 01:23:18.153, Speaker A: So. So I have a little bit of context here, which is the reason why thread locals have this weird setup where the only way to access them is like, if you have a thread local called things that you have to do things.with and that you get a reference to the thing in the thread local as an argument to that closure. The reason why it's set up that way is because there is no lifetime you could give to that reference, right? You couldn't really give back something that would. It would need to have like a reference with a lifetime of thread, right? Or like the caller's scope or something. But with closures you can do this because you can say this, this, borrow this. This reference that we give to the closure is valid only for the lifetime of the closure.
01:23:18.153 - 01:23:31.025, Speaker A: When the closure returns, then this reference is no longer valid as you can guarantee basically that it doesn't go outside of that closure. And while that closure executes, you know, you're still in the same thread, so you know the thread local is still alive.
01:23:31.525 - 01:24:00.819, Speaker B: Yeah, I'm honest here. So as a user of Rust, I kind of, I abhor mutable global state, right? And so kind of one of the big things. Oh, okay. If you get rid of all your globals, it makes things much easier to reason about, right? And I see thread locals as kind of like, honestly, they give me the same icky as a global state. Kind of like, yeah, sure, it's not global, it's thread local, but it's still kind of like, you know, who knows where it's being updated or mutated and Kind of like, you know what? I avoid it. I don't like it when I make my Rust 2.0 language.
01:24:00.819 - 01:24:04.775, Speaker B: Someday we're going to just entirely. You don't need that.
01:24:05.115 - 01:24:49.559, Speaker A: Well, it's interesting because I've ended up using them a couple of times, but mostly in the context of very low level libraries. So in tracing, it's being used to keep track of like the global logger, and in Tokyo it's used to keep track of which worker thread a future is currently executing on. Because both of those are thread local state. They genuinely are like, where are you right now? In a way where there's not really a good mechanism for grabbing that state without. Without a thread local. And very often for thread locals. And this is why this change came in as well, I think, is because very often the thread locals are either cells or ref cells.
01:24:49.559 - 01:25:29.751, Speaker A: And the reason they're often cells is because if they are cells, you never have this problem of it being a reference, because with a cell, a cell never gives out a reference to its inner value. The only thing you can do is either set it or take it out of there and leave a default in its place. Right? You never get a reference into a cell. And so that's sort of the acknowledgement that's been done here with this introduction of get set, take and replace methods on thread locals. Whose type is a cell or a ref cell. Is that because these types are. If we know that that is the inner type, then we can actually give you a nicer API.
01:25:29.751 - 01:25:35.035, Speaker A: And it's worth giving that nicer API because these are by far the most common thread local types.
01:25:35.335 - 01:25:38.315, Speaker B: But what if we had monads, though? We wouldn't need to worry about all this.
01:25:39.175 - 01:25:46.105, Speaker A: That's true. Monads do solve all problems. And if you don't think they solve all problems just because you haven't understood monads properly yet.
01:25:47.005 - 01:25:53.973, Speaker B: By the way, the timeout, I forgot to plug my computer in and I'm about to go extinct. So let me do that real quick.
01:25:54.029 - 01:25:55.109, Speaker A: Yeah, go for it.
01:25:55.277 - 01:25:57.305, Speaker B: Play the music in the animation.
01:26:10.175 - 01:26:41.805, Speaker A: Ah. Bum bum bum bum bum bum bum bum bum bum bum bum bum bum bum bum bum bum bum bum bum bum bum bum bum bada bada bum. But now I ran out of intermission music. What do I do now? I guess I could play it again. I wonder if anyone else has heard that song. It's called the Intermission Song by the Offspring. It's great.
01:26:41.805 - 01:27:00.393, Speaker A: This is not the Doctor who theme. No, that's because we're not time traveling right now. We are watching Ben live plug in his. His charger. And so as a result, there's no time traveling going. Going on here. Can I use that year ring to Absolutely.
01:27:00.393 - 01:27:17.421, Speaker A: Go for it? Yeah. The Offspring made that. They had a. An album that was like particularly heavy and then they needed a song in the middle to let you give. Give you a breather. It was great. A dance, an associated dance.
01:27:17.421 - 01:27:31.453, Speaker A: I don't think we're going to have. Ben has pointed our camera, his camera away. Oh, no. Maybe he's no longer there. That's because he's getting in his time machine. Ben, I. I hummed the.
01:27:31.453 - 01:27:45.355, Speaker A: The intermission song and now someone wants it as their ringtone. Your microphone is up so we can't hear you.
01:27:46.855 - 01:27:51.247, Speaker B: I was thinking about. Oh, the days when I didn't just have my phone on mute all the time.
01:27:51.391 - 01:27:52.159, Speaker A: I know, right?
01:27:52.247 - 01:27:53.887, Speaker B: Ringtones. A more innocent time.
01:27:53.991 - 01:28:16.965, Speaker A: Yeah, it's true. All right, so we got through Thread locals, so let's move on to 173 stabilized APIs. There are a couple of things apart from all the local key changes we just talked about, there's also these next multiple of things for integers. Ben, can you tell me what these are useful for?
01:28:19.025 - 01:28:51.193, Speaker B: So I have these specifically, but I do know that. So for example, in the implementation in standard library of. If you're writing the vec, for example, whenever you reallocate, let's say your vec gets too big, you push to a thing and it's too large for the backing array and it reallocates, it needs to compute the next size of a power of 2. Say. I'm not sure if these support power of 1.4. If you want to do golden ratio increases, but what's that on integers only. Okay.
01:28:51.249 - 01:28:52.393, Speaker A: It looks like it has to be an integer.
01:28:52.449 - 01:29:14.253, Speaker B: Yeah, I see. Yeah. So just a little convenient thing. I appreciate. I think what I always say about the standard library of Rust is that it doesn't really unlike say, Python, where it's very broad, gives you all kinds of stuff. Rust is very deep and so it gives you very. For what it does give you.
01:29:14.253 - 01:29:48.139, Speaker B: It gives you lots and lots and lots of helpers and I think nice to avoid. So if you use JavaScript, you have lots of these libraries that provide very nice, convenient things. There's underscore, and I'm not sure if, you know, I've done front end dev for years, but I'm not sure people use underscore anymore. Still lodash. But the idea is that in Rust we don't want to have to force the royal. We force people to just resort to these nice convenience libraries that should just exist. And so there's been a history of slowly pulling these in the standard library.
01:29:48.139 - 01:30:18.841, Speaker B: So for things like the Iterator data tools crate, slowly adding things like that, I think especially in the context of supply chain security, which is a big topic these days, if anything happens, say an XZ Create or an XE I didn't mean to create XZ library happens to get backdoored for whatever reason, it's going to be a big deal to think about where your code's coming from. And I think having a big center library increasingly so is going to be an important mitigation factor in languages in the next few years.
01:30:18.913 - 01:30:49.931, Speaker A: So yeah, I think that's true. And I've certainly, you know, found myself appreciative whenever there's something weird I want to do with an integer in Rust and there's just a method for it so I don't have to. Even though it's not complicated to compute, I don't need to have this like weird, you know, multiply, add one and then divide by two in order to do a division ceiling. I don't have to have that code in that little weird arithmetic in my code. I can just call the method that does the thing right.
01:30:49.963 - 01:31:10.235, Speaker B: And so if you go through all the standard library, it's fun to read through and I'm not sure it's fun. Maybe I'm a weirdo. It's fun to read through the standard library docs for integers and say, oh, what is this? I can just invert the bits. That's cool that I can do that. I can count every single. All the ones in a number in binary. Oh, that's cool.
01:31:10.235 - 01:31:29.831, Speaker B: I can count all the trailing ones only. That's cool. I can rotate them. Lots of really nice things that you can just. Again, very specific things you might not need to do. But if you want to avoid people having to resort to bitwise hackery, it's great to have self documenting methods that just do all this for you.
01:31:29.903 - 01:31:36.475, Speaker A: It's true. I wonder what the weirdest method we could get into the standard library for bitwise manipulation of numbers is.
01:31:37.465 - 01:31:50.353, Speaker B: I was going to say when you said that I think we should task our chat for doing during this live stream. By the end of the chat, find the weirdest, most specific stable API in Standard Lib that's like, you know, and figure out what it's useful for.
01:31:50.529 - 01:32:39.965, Speaker A: Yeah, it's the figure out what it's useful part that's interesting, right? Interesting. All right, so those are the stabilized APIs. We have a couple of more consts, but I think that's all. So I think it's time for the deep dive on the change log. Let's go through here and see what we have. I spotted one that was interesting, which is in 173, it's always been the case that if you have like infinite recursion in your function, that it can be highlighted like unconditional recursion, then the compiler will just say, you know, you have function foo and function foo calls function foo, and there are no conditionals on that call, then the compiler will actually detect this and lint on it. So it's not.
01:32:39.965 - 01:33:19.275, Speaker A: It's not quite the halting problem, right? It's. It's not trying to compute whether. It's whether this, this recursion chain terminates. It's that if you have unconditional recursion, you must have an infinite loop. And it turns out that there was an interesting case that wasn't caught, which was if you have a type that implements drop, and in its own drop implementation it creates an instance of itself, then you also have unconditional recursion. And so in 173, that is now also caught, which I thought was a neat addition. I don't know if this ever triggered for anyone because I feel like it would just be an infinite hang.
01:33:19.275 - 01:33:44.625, Speaker A: So, like, it would just be really painful to debug, but it would be obvious that something was wrong. But it is nice that now he's just caught at compile time. The next one, I thought that was interesting is kind of niche. And when I say kind of niche, I mean it talks about the different loading sections. Oh, we lost Ben.
01:33:46.685 - 01:33:52.279, Speaker B: Oh, I'm here. Ben vanished. I was just. I was doing a Rust UP update, actually, and so.
01:33:52.437 - 01:33:53.091, Speaker A: Nice.
01:33:53.243 - 01:33:53.915, Speaker B: Do you hear me?
01:33:53.995 - 01:34:12.259, Speaker A: Yeah, I can hear you, but chat may not be able to. Let me, let me see. I might have to add you back. Oh, no, chat does. See you. Okay, good, good, good, good, good. So, yeah, I was going to say one of the.
01:34:12.259 - 01:34:58.845, Speaker A: One of the things that's a little bit niche. And I say a little bit, but it's talking about, like the specific sections of ELF binaries. And the weird part here is specifically that Rust C will now write its own version into the comments section of ELF binaries. And so now, you know, if you. If you do like an ELF dump of your binaries produced by Rust C, it will now actually show you which version of Rust they were compiled with. This is in line with what GCC does, what Clang does, and you can turn it off, but it is just a handy way to be able to quickly see what version some given binary you produced in the past was compiled with.
01:35:01.865 - 01:35:07.521, Speaker B: Is there any standardized way to actually get this information besides like going into the ELF yourself and parsing it?
01:35:07.673 - 01:35:25.841, Speaker A: I don't think so. It does seem like the sort of comments section here in the ELF binaries is what's used by a bunch of different tools. So in that sense it's standard, but it's not actually standard. And I don't know of a tool that knows how to read this information apart from like, you know, readelf dash.
01:35:25.873 - 01:36:02.275, Speaker B: P. Okay, because again, on the topic of supply chain security, it's a big idea of okay, if I built this binary, what are all the dependencies as binary? And the compiler obviously is an important dependency of the any binary. And so I think there are a few projects right now people are trying to figure out a standardized ways of. Let's have a cargo plugin that lets you, you know, list every dependency and version that you've used to build this thing and have a nice JSON output that you can use to feed it in other things, other tools like CI stuff that can automatically check and make sure and you know, that kind of stuff. And so I think it's again, important for the future. It seems like a great, a great way of working towards that.
01:36:02.395 - 01:37:09.485, Speaker A: Yeah, I mean there's been some really interesting work on taking your entire sort of supply manifest of information about all of your transitive dependencies and sort of computing them in cargo is one thing, but also putting them in your binary, like in the ELF section, for example. So the downstream tools get a binary with the associated manifest of all of the dependencies that was used when built it. There are a bunch of nuances to get right here. There are also some interesting questions about how you can compose this. Like if you get a dot so like a dynamic library file from something else and you link against it, how can you incorporate information from that into the binary that you produce? So there are some really interesting questions, but it is a field that's very actively being explored, including in the sort of cargo Rust world, which I think is pretty neat. Another one I saw that was added and I was surprised. This doesn't show up in the list of stabilized APIs, which is that the read, write and seek traits are now implemented for arc of file.
01:37:09.485 - 01:37:56.825, Speaker A: And the idea here is that a file in Rust is you know represents a file handle. And on basically all of the platforms they're just like a number that indicates the file and you're allowed to read or write to that handle from multiple threads concurrently. If you do, like, who knows what you're going to read back? Like they're sort of going to. If you read from two, they're going to get disjoint set of bytes, for example, like they'll both. If you seek from two different concurrent threads, which seek wins is sort of anyone's guess, but it is safe. Like it doesn't cause any memory corruption or memory safety violations. And so if you can do that on a reference to a file, then there's no reason you can't do it to an arc of a file too, because that's really just a reference.
01:37:56.825 - 01:38:05.635, Speaker A: And so I thought this was sort of neat addition and it sort of foreshadows some other implementations of the same kind that are added elsewhere down the line.
01:38:11.335 - 01:38:35.787, Speaker B: Other things to mention too, is that in Cargo News, some Cargo's health output. So Cargo Help has been seeing continual improvements and it's improving in this one and also in the next one. I'm going to again jump forward in time. If you're currently on rust up on 1.78 and your friend Cargo Help, you'll see nice, colorful, well formatted output which has been part of the ongoing improvements that they've done for the past. You want to show it right now?
01:38:35.931 - 01:38:47.855, Speaker A: Yeah, I'm trying to find it. So you said it's 173? Yeah, cargo. Which one are you after?
01:38:49.235 - 01:38:50.651, Speaker B: I'm not sure it's even listed.
01:38:50.763 - 01:38:52.737, Speaker A: Make Cargo Help easier to browse.
01:38:52.891 - 01:39:28.095, Speaker B: There you go. So I want to shout out to E page for all the work that he does on Cargo and making the experience better. Because I think at this point, right, Rust is kind of getting very mature as a language. I'm kind of tip my hand here where I like C as a language in terms of lots of things that C does. C is relatively easy to implement, C is kind of easy to translate to machine code. And C again, one of the advantages of C is it's been stable for 40 years. Basically it's added almost nothing in the past since 1989, 1998, something like around there.
01:39:28.095 - 01:40:04.011, Speaker B: And I think someday I'd love for Rust to be seen as stable as that. Maybe not within the next 20 or so years, but someday. But I think that Rust is trending towards that. But things that we really want to keep working on are all the dev tooling around Rust. Not just language itself, the compiler, but all the Cargo and Rust up and everything that's in the surrounding regions, all the IDE support. I think having pivoting from let's add features to Rust to let's just make the dev experience as good as possible. Including everything around the compiler is a good approach and so Epage is definitely pushing forward that all the Cargo team too.
01:40:04.011 - 01:40:05.867, Speaker B: So way hang low and all that.
01:40:06.011 - 01:40:40.425, Speaker A: Yeah, I think that's true. I was just looking at the PR that added this and it looks like specifically what it does, it splits the sort of help information that comes out of Cargo into sections so that you have sort of if you the flags that have to do with which package you're operating on, for example, get printed under the package selection section of the help output and the things that have to do with which target Cargo is building, like binaries versus examples versus tests versus benchmarks, whatever, are printed in the target selection section rather than all being grouped together in one long list.
01:40:41.775 - 01:41:08.753, Speaker B: And I want to kind of also the idea of Rust is, oh, Rust is cool. It's fast as C and it's memory is safe. What a great idea. People love this language. A lot of the reason people like Wreck Rust is not because it has a sound type system and has pattern matching. People like it because it's so easy to use Cargo. It's like compared to if you ever set up a file written in C or a project, it's kind of like, oh, I got to install these dependencies and figure out their make file.
01:41:08.753 - 01:41:35.679, Speaker B: It's like, how do I configure this? And with Cargo it's just so much easier. The biggest link in point of Rust is that it's just like it's Cargo. I use Rust, I evangelize Rust because of the whole memory stuff. I want to use software that's all memory safe. But the reason people in general use Rust is probably because of the tooling support is so good, let's be honest here. So it's a nice happy accident that the fact is this new language is really cool. People want to use, is also memory safe and very efficient and has lots of other good things going on.
01:41:35.807 - 01:41:51.195, Speaker A: Yeah, I think it's definitely like a major selling point or you might even argue it's a major staying point. I think the thing that gets people to Rust is often other things that they want out of the language, but the reason they stay is because of Cargo or at least in part because of Cargo.
01:41:51.575 - 01:42:06.051, Speaker B: Yeah, there are several projects where I'm Like, I would like to contribute to these, but I just get so painful to go back to C and C. I'm like, oh, if I was going to contribute, I'd just be rewriting in Rust. And I'm kind of like, you know what, let's not be that person. Let's just move on.
01:42:06.183 - 01:42:37.999, Speaker A: Yeah, no, it's true. I had, I think two more. One of them is also about sort of the IO traits and stuff, which is that there are two special types, or I don't know if they're really that special, but there are two types in the standard library, IO sync and IO empty. And they are basically dev null, but in the type system. So IO sync is a type that implements write, and anything that gets written into it just gets discarded. So it's like a trash can for writes. And then you have IO empty, which is the same, but for read.
01:42:37.999 - 01:43:21.599, Speaker A: It's a thing that if you try to read from it, you immediately get endo file. And you know, in Unix philosophy this is a little weird because we have dev null, which is both a sink and empty, so you can write to it and it just absorb all the things you write to it. And if you read from it, you immediately just get into file. And in Rust these are different types where one implements write sync and one implements read empty. And what happened in 173 is now IO empty started also implementing write. So now we have a single type that implements both read and write by discarding all the written bytes and reading zero bytes ever. And so it's just a handy way to have a single type that does both.
01:43:21.599 - 01:43:35.555, Speaker A: But it also allows you to now, if you have an API that takes something that implements both read and write, you can now pass in IO empty, whereas previously there was no type you could use there. You would have to sort of set up your own version of these now.
01:43:35.595 - 01:43:48.315, Speaker B: Though, does that like, you know, can you imagine someone actually wanting this behavior of not implementing read or write for one of these types and say, hey, I want to have like this different kind of thing? Because sometimes it's useful to have that. Or is it generally not a big deal?
01:43:48.435 - 01:44:16.067, Speaker A: I think usually these get used in testing, right? It's pretty rare. You use it for anything but testing. And in testing it's just handy to have one type you can just throw in anywhere and it sort of satisfied both read and write bounds, because you know that nothing will be written, or you. You know that nothing will be read. But you do need a connection type in there of some kind. And that's where these are useful. And I think there's not really a great reason to have them be different types.
01:44:16.067 - 01:44:59.181, Speaker A: Like, them being different types doesn't really give you anything. Whereas having one type that does both means that it is more versatile. And then I had one last one, and this one I thought was kind of interesting. This is an implementation of slice index of stir for a tuple of a usize bound and a usize bound. And this requires a little bit of parsing. So the slice index trait is a way that is the thing that allows you to put square brackets on things and slice into them. So this is not getting a single element out of something, it's getting a sort of range output out of something.
01:44:59.181 - 01:46:11.425, Speaker A: So for example, there's an implementation of slice index of slice of t for you size usize, right? So you can take a slice and you can give it a range of you can give it a range and you get back a slice that corresponds to that subrange of the original slice. But interestingly, there wasn't an implementation of slice index of stir, which is like being able to slice things out of strings for bound of usize, the bound of usage. So this is something like, for example, if you say 0 dot dot, that turns into an included bound of zero on the one end of the tuple and a unbounded bound on the other side of the tuple. And where this gets interesting is there already was an implementation of slice index str for range, which this is an example of, right? If you write 0dot, it's actually a. There's a range type. There are multiple one for well, there are a bunch of them. One for they're inclusive on both ends, one for exclusive on the end, one for unbounded on one end, one for unbounded on the other end.
01:46:11.425 - 01:46:46.295, Speaker A: But if you think about it, a range is really just a tuple, mostly with a couple of additional semantics of two numbers, where the two numbers, you know, one or the other one can be left out in order to indicate that the range should be open or closed. And so now you can index into a string by giving a tuple where the two elements of the tuple are these bound types that let you say inclusive, exclusive or unbounded. And so this was a weird missing impulse that does exist for slices, but didn't exist for strings.
01:46:49.235 - 01:46:51.295, Speaker B: Always good to make things more consistent.
01:46:52.355 - 01:47:02.115, Speaker A: I like I dug up the PR for this and the only description for the PR is this impl is conspicuously missing. No further explanation.
01:47:06.615 - 01:47:21.087, Speaker B: And with that I think we're the mindset of someone who's like, you know, who finds this out. Like it seems like someone's like I really wish this existed or they think it exists and how to go through the docs and realize it doesn't. And they went through and they made it just like you went through with your PR and made your pr. So it's true.
01:47:21.151 - 01:47:26.675, Speaker A: It's true. Okay, I think we're then done with 173.
01:47:27.705 - 01:47:54.405, Speaker B: Yeah, I wanted to just say too, I always go through the Reddit threads and see what people are talking about and the maintainer of the Redx crate commented, oh, actually one of the new APIs that's release is the div sealing on integers and actually linked to a place in regex that he had to implement himself his own version of this. So very useful to have these things around so people can do it themselves because they're prone to off by one errors if you don't do it right. Or overflow errors too.
01:47:54.505 - 01:48:20.347, Speaker A: So nice. Yeah, no, it's true. The Reddit thread I think is really useful for discovering those. Those tiny things that you might have missed, but that actually really matters for someone. So I was going back to check the. The. The PR and we got an answer from a Rust reviewer who says, I don't think this change really matches the PR description.
01:48:20.347 - 01:48:34.595, Speaker A: It doesn't really make it much clearer what it's useful for. Still, this is a good docs improvement that I'm happy to approve after you squash the commits and see how it passes. Interesting. Okay, do I actually have to squash manually? I was trying to hope that I didn't have to check this out locally.
01:48:36.535 - 01:48:39.391, Speaker B: Hmm. Right. That's what you get for using the.
01:48:39.543 - 01:48:42.527, Speaker A: Yeah, I was trying to take a shortcut. I was trying to take a shortcut.
01:48:42.591 - 01:48:49.679, Speaker B: Is there a button somewhere that says like. I guess they don't. There's probably in GitHub a squash and merge thing, but we don't use that. We use rustbot.
01:48:49.807 - 01:49:08.475, Speaker A: No, it's fine, it's fine. We'll get clone. The problem is that I now have to. I now have to git clone Rust, which takes forever. It doesn't actually take forever, it just takes longer than I would like.
01:49:09.735 - 01:49:24.553, Speaker B: I thought the Linux repo at some point just like prune their entire history and say, you know what, it's fine to have like, you know, five years of history and not have the entire thing. Maybe at some point Rush should do that too where like you have a backup somewhere for historical basis and Just like, you know, chop off the end, maybe.
01:49:24.649 - 01:49:37.485, Speaker A: Maybe as long as you have the backup so that people can, like, go back and bisect. But it does make bisection a lot harder, like doing like a get blame, for example, to jump back, back over the discontinuity point.
01:49:38.305 - 01:49:39.085, Speaker B: Mm.
01:49:42.865 - 01:49:53.555, Speaker A: Let's see. I'll let this clone in the background. Okay. Should we jump straight into 74, or do you want to take another stretching break?
01:49:54.295 - 01:50:04.543, Speaker B: Let's get in the habit of doing a break. Let everyone get some. Some water, some tea. I'm gonna put on some tea and then. Oh, yeah, nicely warm. By the end of the next thing.
01:50:04.679 - 01:50:27.057, Speaker A: I've started making my tea in a thermos. And it's a great idea because it means that I can. Yeah, well, no, it means that I can pour out one small cup of tea and so it cools relatively quickly and I can drink it while it's still hot and then I can just pour another one. I don't have to go make it each time. Although my thermos is now empty, so it doesn't work anymore.
01:50:27.121 - 01:50:29.825, Speaker B: All right, great. Time to go make some more tea then.
01:50:29.985 - 01:54:54.281, Speaker A: Let's do that. All right, Chad, we're going to do a quick break and then we'll be back. All right, while. While Ben is finishing his tea, how about we fix up that PR git? Remote add upstream, fetch upstream, reset hard master, patch one, rebase master. Make it clear how string Leak differs from. I'm just tidying up my. My pr.
01:54:54.353 - 01:54:57.615, Speaker B: Ben, the slide continues.
01:54:57.995 - 01:55:46.121, Speaker A: Clarify how string leak differs from into boxed stir. Yeah, I'll put in here. I was. I'm not gonna say bullied, but I was encouraged. I was encouraged. That's a good word.
01:55:46.213 - 01:55:49.925, Speaker B: I was instantly encouraged by chat to.
01:55:52.945 - 01:56:24.083, Speaker A: To submit this while doing a live stream. And so my attention to detail is somewhat compromised. Have squashed now and rejected. No, I think it'll be okay.
01:56:24.099 - 01:56:27.575, Speaker B: Look at this streamer. Trying to bully us into taking his BRs.
01:56:29.235 - 01:57:20.075, Speaker A: And then let's go ahead and change the title of this to match the commitment. Note that this phrasing app phrasing was taken from vec into Boxed Slice. So if this should be changed, it should be changed there as well. Nice. And then hopefully CI will make us happy. Okay, you ready to do 174, Ben?
01:57:20.975 - 01:57:26.279, Speaker B: I love this progression of the PR in the background. It's a great, like, overarching narrative to the podcast.
01:57:26.327 - 01:57:26.463, Speaker A: Right.
01:57:26.479 - 01:57:34.331, Speaker B: In the first press release notes, we make the pr. Second one we update for feedback. Maybe it'll get reviewed and approved within the next few ones.
01:57:34.403 - 01:57:36.715, Speaker A: I believe in. I believe in us. I believe in us.
01:57:36.755 - 01:57:38.339, Speaker B: All right, so we new intro.
01:57:38.467 - 01:57:45.683, Speaker A: Well, now we just need them to also push a Rust patch release to include our change during the stream.
01:57:45.739 - 01:57:47.347, Speaker B: Oh, yeah, during the stream.
01:57:47.411 - 01:57:47.723, Speaker A: Yeah.
01:57:47.779 - 01:57:51.763, Speaker B: So we won't stop streaming until they do a patch release with this stock update.
01:57:51.939 - 01:58:06.351, Speaker A: So Chat is happy about how my git commit message stayed within the length limit for git. And I want to note it's not 80 characters, it's 72 for the first line, it's 80 for the body of the get commit message. But 72 for the title.
01:58:06.463 - 01:58:09.288, Speaker B: Isn't it, like, even less than that? Isn't like 60 or something like that?
01:58:09.345 - 01:58:23.732, Speaker A: I think it's 72. I mean, my editor is set up for this, so I can check Git Commit amend. Oh, yeah, I guess it's 50, right?
01:58:23.814 - 01:58:25.787, Speaker B: It's like, it's low. Yeah.
01:58:25.869 - 01:58:31.605, Speaker A: And I'm within 50, so we're fine. Because one more letter is red.
01:58:32.745 - 01:58:43.473, Speaker B: Yeah. Honestly, I have the same thing going on and, like, it's kind of a pain. We're like, 50 is definitely kind of hard to fit any meaningful thing into much of the time if it was like 80 or like 90.
01:58:43.538 - 01:58:48.377, Speaker A: I don't even remember where I have the 50 from because.
01:58:48.481 - 01:58:49.687, Speaker B: Built into your.
01:58:49.881 - 01:59:08.495, Speaker A: No, I think I got it from the kernel. Let's see 50. Yeah, I don't. I have no idea where I have that config from. Maybe it's just what vim ship was with for git commits in the first place. Oh, actually, maybe this is in. Oh, I don't know.
01:59:08.495 - 01:59:19.675, Speaker A: All right, well, back to. Back to serious stuff. Yeah, we can do a new intro. But how do we want to do this? This alternative intro? This intro. That is not an intro.
01:59:21.735 - 01:59:34.835, Speaker B: We should have everyone listening live. They should all leave. Everyone just go. Just quit alt F4 and then we'll do the intro. Then they come back and we'll wait until everyone comes back. We won't continue until literally everybody has.
01:59:35.255 - 01:59:37.635, Speaker A: Yeah, we're watching you. We're watching all of you.
01:59:39.175 - 01:59:46.289, Speaker B: I think it should be the intro. We should just like start. It started like three seconds ago. Let's just go. Let's continue on. Everyone should know this was. This is streamed live.
01:59:46.417 - 01:59:46.681, Speaker A: Yeah.
01:59:46.713 - 01:59:57.485, Speaker B: On Johnset. Goo. Who you YouTube with. Live live. Very important hashtag.
01:59:58.225 - 02:00:18.175, Speaker A: So I think, Ben, the best way to start is without context. And so therefore, let us now start with Rust 174.0. Let's do it in 174.0 we got linked configuration through Cargo and now I have to ask you, is this something that you have seen and are excited about?
02:00:18.715 - 02:00:36.895, Speaker B: Yes, actually. So I think it's pretty cool. So it's pretty common when you open a create root file and you see like I don't common but like in some cases, some crates are like very meticulous about like having every single lint that they allow or deny in their crate route. It's kind of just noise. It feels like. Right. It's not.
02:00:36.895 - 02:01:16.909, Speaker B: I don't know, theoretically you'd like for. Let's just back up. Right. One of the cool things about Rust is that if you say compiling in GCC code, you need to remember to pass warn W all W whatever for your warnings and in Rust, because command invocations are kind of like nebulous and hard to codify, putting that somewhere in your source code is nice. That's an improvement. Where I can say, hey, when I the author of this code built this, I think it should be clean with these warnings. And so I don't need to worry about my users compiling like this or a contributor threatening to do this thing that I'm warning about.
02:01:16.909 - 02:01:44.633, Speaker B: It's there in the source code. So let's roll than a command identification, a CLI with the compiler. But it is kind of a little bit noisy where you just have it here because you'd like in theory for your source code to only contain things that affect actually how it gets built and not just like a warning output. And so I can totally see where people don't want to have this in their source file in their create root. And so having it in the cargo file is a good alternative. It's not going away. The ability to do it in the source file, if you want to do it there, you can.
02:01:44.633 - 02:01:53.841, Speaker B: But I do like the idea of putting it here and also because with workspaces it means that you can share these links across the entire workspace really easily. And so that's cool, I think.
02:01:53.953 - 02:02:33.571, Speaker A: Yeah, I agree. I think there's some debate about whether, you know, this isn't really about how I build my crate, it's about the style of the crate. And I think there was some debate about, you know, should this really be a part of Cargo as opposed to Rust C. Right. So, you know, the cargo tunnel thing is entirely a cargo construct, but lints are a rusty construct. And so by putting in the cargo, this now means that if the project was built by something that's not cargo, it might no longer build because the source code triggers, let's say a deny by default lint that the cargo toml allows. So I think that was some of the reason why it's taken us as long to actually get it.
02:02:33.723 - 02:02:45.947, Speaker B: Well, if you're. I assume that if you have the lint, like if you have a deny in your crate route and you have the allow in cargo, the crate root deny will override. That's what I assume. I haven't checked.
02:02:45.971 - 02:02:46.707, Speaker A: That's probably true.
02:02:46.771 - 02:02:47.619, Speaker B: That's how I'd reasonably.
02:02:47.667 - 02:02:48.587, Speaker A: Yeah, that's probably assume it.
02:02:48.651 - 02:03:03.519, Speaker B: So again, the source code is ultimately the source of truth. And honestly you'd probably hope there would be a warning if you had both the lint level enabled. Maybe not. Maybe it's fine to have a general default over here and then a fine grained deny over here. Maybe that's a totally reasonable thing to have.
02:03:03.567 - 02:03:29.179, Speaker A: I think it's actually more about if you don't have anything in your source, but you have an explicit allow of a deny rule in your cargo tomlints table. Because that way if you compiled it with some other tool like let's say you compiled it with Bazel, that does invoke Rust C, it would no longer build, but it would build with cargo because cargo knows to look at the cargo tunnel and sees that that lint should be allowed based on the cargo Tumblr lint.
02:03:29.347 - 02:03:58.623, Speaker B: That is only a problem if there is a deny by default lint in Rusty that you are allowing. And so if it's a lint and clippy, it's not a big deal, not a problem, right? If it's like you know, a loud lint or a worn lint or anything else, that's not going to be a problem. And generally deny by default lints and rust are very severe. There are a few in our previous 171 they added the new Clippy Lancer. You're doing a thing that is immediate undefined behavior that's just wrong. We're just going to make that an error. You can override it.
02:03:58.623 - 02:04:25.739, Speaker B: I'm not sure if there's really any reason to ever want to again. There is an even stronger ability in rustc above Deny there is a compiler blessed thing called forbid. A forbid lint can't be overridden. It's just an error. Effectively you just can't override it. And so you could say, hey, if we think it's going to be immediately, why isn't it just for a bit, maybe it should be forbid. But I think it's being conservative and maybe somebody somewhere has a reason to allow this.
02:04:25.739 - 02:04:52.955, Speaker B: And in the future, some things Arjuna might become forbid just to make things easier for it to maintain. It's nicer to have them as compiler errors as opposed to having them as LIN passes. Right. So I don't know. I think it's a very specific use case where you'd have to worry about, oh, I'm building it with Basil now and it stops building. But even if you did, the error message is pretty self evident where it's kind of like, oh, it's not wondering what went wrong, it's oh, you now have this deny land. And the reason it's not building now, not building might be a problem.
02:04:52.955 - 02:05:00.451, Speaker B: Oh, they have the lint configured in the cognitive tunnel. Okay. That's a reasonable thing to have, but it's still like a pretty niche. I don't think it's really a big thing to worry about.
02:05:00.603 - 02:05:01.611, Speaker A: Yeah, I think that's right.
02:05:01.763 - 02:05:04.427, Speaker B: It's a little bit. There's a separation of concerns question here.
02:05:04.531 - 02:05:30.875, Speaker A: No, but I think that's right. And I think that's also why ultimately this did go through and this is why we got it in Rust 174. Right. Is because ultimately there weren't enough serious concerns to make us not do it. Right. Like this being an example of something where realistically, if you did run into a use case like this, what you should probably do is allow the lint in your source file instead of in your cargo tunnel for that particular case.
02:05:31.895 - 02:05:49.571, Speaker B: Yeah. And so, yeah, I don't know. I think it's a reasonable thing. It's like, it is important to make sure that projects remain rust projects and not cargo projects left the time. Right. The whole point is that cargo is not tightly tied to language where cargo still has to use the Rust SQL interface cli. It doesn't get any kind of like blessed thing.
02:05:49.571 - 02:06:04.243, Speaker B: It still has to pass all of its values through environment variables and command line flags. And you can always tell cargo, hey, like, I think I forget what the option is, but if you're like running cargo, there's. There is a command line flag for cargo that says, hey, don't actually invoke Rust C. Just print out what you would invoke and you can run it yourself.
02:06:04.339 - 02:06:05.923, Speaker A: Yep. No, it's totally true.
02:06:06.019 - 02:06:16.621, Speaker B: And so that's a. It's like, that's a cool thing. It decouples cargo from Rusty and allows things like Basil or if you're doing some weird thing that you can't use cargo for to exist and I guess.
02:06:16.653 - 02:06:33.485, Speaker A: For those who are just listening to us and not watching us live now, you know, for those who. For those who are only listening to this and just got into the episode, you might also be surprised to realize that this is live because Ben and I are such good producers that it doesn't.
02:06:33.645 - 02:06:35.011, Speaker B: Definitely didn't make that clear.
02:06:35.133 - 02:07:20.645, Speaker A: Yeah, but the way that this is represented in source code or in your cargo toml rather, is that there's a new root level table in cargo toml that sort of square bracket lints. And it has two subtables, Rust and clippy. Might be more down the line, who knows. And inside each subtable you can define name of lint equals and then a string. And that string can be allow, warn, deny or forbid in order to set what level you want that particular lint to be at when building the creating question. And as Ben was alluding to, you can also set this in a workspace by setting workspace the workspace lints table. And then you can inherit from that in any given package by saying lint's table workspace equals true to inherit from the workspace table.
02:07:22.305 - 02:07:47.395, Speaker B: And I will say, in regard to your concern, I think if there exists a crate that builds with cargo, I think it's reasonable for the crate authors to expect it will only be built with cargo and that it might require some tweaks, get it built something else. A totally reasonable thing. Right? Shouldn't be overly burdensome, but I think it's not a big problem conceptually to say, hey, as a create author, we thought you'd be using cargo for this, and if you wanted something else that's kind of on you, I think that's right.
02:07:47.975 - 02:08:20.523, Speaker A: The next thing we got is also a cargo feature, which is cargo registry authentication. And this one I know has been a long time coming. Trying to. I know the cargo team has spent a long time trying to figure out what is exactly the right way to land this. And it's really two features that come that sort of come together to bring this whole idea of having registry authentication. The first of them is credential providers. So the idea here is that you can now configure cargo and tell it how to get credentials for a given registry.
02:08:20.523 - 02:09:22.755, Speaker A: So previously you would just need to put a like a string in cargo credentials TOML in your home directory, which is, you know, totally fine way to work around it. But it was very, it was a very like static way to configure it. It's also not the most secure because now you have your secret you're like token being stored in a file somewhere. And so what has come with 174 is the idea of a credential provider, which is essentially a cargo, now knows about a particular set of other utilities, like third party utilities that can provide it with credentials. So an example of this would be like the keychain on macOS, I forget what the thing for Windows is called, Lib Secret on Linux. And also this idea of a credential process which just some external program the cargo will execute for you with a predefined set of arguments. And it's expected that it will output the credential the cargo should use to standard out.
02:09:22.755 - 02:10:48.321, Speaker A: And so this way you can now have both sort of a secure place to store your credentials. It doesn't have to be in a config file in your home directory. But it also means that if you have an alternative registry, something that's not crates IO and it needs some very particular kind of token and it wants to get those tokens in a very particular way, then you can now write a credentials provider for cargo that knows how to grab, you know, authentication tokens for that registry and sort of feed them through so that cargo will present them to that alternate registry when it's also used. And so that's then the second part of this is support for alternative registries, like private registries, for example, to specifically be able to ask for credentials for all cargo operations and to say that they should come in through one of these additional credential providers. There's a bunch more nuance here too. So if you, if you're curious about this, the cargo docs are pretty good about this because there's been a long time coming of figuring out what the process should look like and you know, what the, what the protocol should look like for the credential providers and for the alternative registries. But the nice thing here, as a user of Rust that we should hopefully end up seeing is more support for, for having private or custom Rust registries that are not just crates IO.
02:10:48.321 - 02:11:36.435, Speaker A: So this could be things like you could have a custom registry for use at work, for example, that other people don't have access to because it publishes, let's say company internal code. And previously that was possible, but securing them was really hard. And so now we have a better mechanism for doing so in such a way that you can imagine larger companies also are in a better position to provide sort of Rust or cargo registries as a feature that you could sort of buy or use for your company from somewhere. Else the next thing in 174 is projections in opaque return types. What do you know of this one, Ben?
02:11:37.775 - 02:12:15.257, Speaker B: Well, it's kind of just a way to make opaque return types refers to impultrate. So you have a function that returns a thing that has a trait that all you know about it is it implements some trait. And so you write it as arrow return, arrow impulse. And so in the past there were some limitations there, and this is just lifting some limitations. Kind of like things that you expect should work now just work. Although with regard to understanding why they didn't previously work or what projections really means, that's beyond me. I think hopefully the idea here is that we should just, rather than trying to explain to the user why it doesn't work, just make it work and don't worry about what a projection is.
02:12:15.257 - 02:12:18.445, Speaker B: Do you happen to know in compiler jargon what projection refers to?
02:12:21.145 - 02:13:10.621, Speaker A: I have to dig back into my compiler stuff, but I think projections here are like. The idea is that if you have some type from the sort of input space that are represented in the output space but not visible in the source code. So an example here would be like. Well, I guess there's an example given in the in the code snippet for this part of the change log where you have a method on some wrapper type. So you have an impul wrapper, you have a function async fn that returns self. Then the source code just says self, but it actually includes the wrapper type. The wrapper type there being a little bit obvious, but the wrapper type also has an associated lifetime and generic type.
02:13:10.621 - 02:14:09.045, Speaker A: And that associated lifetime and that generic type have to be projected into the return type of that asynchronous function because they are there, they're just not named anywhere. And so I think that's what projection in general means. But I'm on risky ground here and I believe this has to do with, I mean, given that this is also indicated in the code sample, this specifically has to do with lifetimes. So I think in the past, the sort of projection handling code for things like async functions in traits or general like return position impul trait in traits as well, didn't know how to project lifetimes correctly and so therefore they just disallowed them. If they detected that the input type had a lifetime in it and you tried to use it in the output type using self, then it would just reject that code just because the machinery for doing the production correctly wasn't implemented there. And now, as you say, that Limitation is raised. And that is sort of the most important thing.
02:14:09.425 - 02:14:40.091, Speaker B: Thanks. Physically here, right? You can now, without having to worry about late terms or whatever, you can now say hey. So in an impl trait you can say, hey, the associated type of this trait that I'm impling for, I can give it, I can say what it is. And in this case you say the item is equal to self. Implementer Iterator has associated a type called item, which is the thing that returned from the iterator. And the examples here are, okay, item can be self where self is a type that returns some lifetimes or has lifetimes inside of it. Or it can be associated type, which is thing you couldn't do before.
02:14:40.091 - 02:15:00.185, Speaker B: So it's kind of like a thing that you expect to be able to use types in type position in general. And so it's kind of one of the things we don't need to talk about it or teach it. It's just like, hey, take these two features and compose them and it should just work. And now it's one of those things where it's kind of like, hey, it would make the language more complex to not allow this and people can now do it. And it's just a nice good thing.
02:15:02.405 - 02:16:09.777, Speaker A: We also have a bunch of stabilized APIs in this release. I think there's, there's like one in particular that stands out to me, which is the error type in the standard IO modules. This specifically IO errors has gained a method called other and this is really just a shorthand for stdio error new where you pass in the error kind other and then some message or that message can be anything that implements the error trait. And now there's sort of a convenience method for constructing IO errors of the other type just by specifically calling the other constructor on IO error. So you can now do, you know, std IO error, colon, colon, other and then pass in something that implements error or rather technically something that implements into box din error. And that includes things like just normal strings. And it also includes, you know, most things that implement the error trait I think can be turned into boxed in errors.
02:16:09.777 - 02:16:24.805, Speaker A: And so it's just a convenient type for turning errors or strings into IO errors, which are often the error type used in sort of these relatively low level libraries where the thing you bubble up is always an IO error, because that's usually what you get from below.
02:16:26.345 - 02:17:02.525, Speaker B: I think one of things I like here in the stable APIs is this core num saturating and I'm not sure is this like it's one of those things where you think would exist before. Right. And so in rust. Right again, soapboxing. I'm trying to avoid it right here, but if you want to add a thing, it's like, well, if it overflows, do I want to panic, do I want to wrap, do I want to saturate? Is a thing you can always do. And in this case saturating means, hey, if this value would overflow, if I have 255 and I add one to it, is it going to panic or is it going to wrap back to zero or is it going to stay at 255? That's ladder behavior saturating. It just says, hey, once you overflow the bound, just cap it right here and don't go any higher.
02:17:02.525 - 02:17:34.795, Speaker B: In Ross inserted library, there's different ways of doing this. You can either have just a normal integer, a normal int type I32, say, and then call wrapping, add, saturating add or much of what they expected. Maybe it's called saturating add or absence rating. But the idea here is that you can say, hey, I just had this normal type. Just do a single operation this way. Or for wrapping types, it leaves there is an actual type where you can put your int inside the type and now all operations become wrapping. In this case, it looks like there's now a saturating type where you put your intake and now operations become saturating.
02:17:34.795 - 02:17:38.655, Speaker B: So one of those things that you would think should exist and would have had for a long time, but I guess it just didn't.
02:17:39.875 - 02:17:49.187, Speaker A: Yeah, I was surprised to see that this was added here separately from wrapping because wrapping was added ages ago, I think. I'm not sure why why 1.0.
02:17:49.211 - 02:17:51.112, Speaker B: I'm pretty sure, yeah, look it up.
02:17:51.208 - 02:18:37.397, Speaker A: So it's like surprising that saturating was only added now, but I guess maybe no one had a use for it. I think one of my favorite of these like wrapping types is reversed or reversed. So this is a wrapper type that the only thing it does is it when it implements partial or an ord for the underlying type, it inverts the ordering. So if you have a, you know, if you have a vector of usize and you call sort, they get sorted in ascending order. But if you have a vector of reversed usize then and then call vex sort, then you get them in descending order. Apart from that, it just directly gives you access to the underlying type. Does not implement any other semantics.
02:18:37.397 - 02:19:21.815, Speaker A: The only thing it does is it reverses sort order. And the main use for This, I think, is for binary heaps, because it allows you to turn the max heap that we have in the standard library into a min heap by just wrapping. Oh yeah, STD comp reverse. Because. Because the binary heap implementation just makes use of partial Lord. We have a couple more compatibility notes in 174 as well. So previously we were talking about how a couple of Windows platforms were being deprecated in an upcoming Release, and in 174, a couple of Apple platforms have been deprecated.
02:19:21.815 - 02:19:48.405, Speaker A: So in particular macOS versions prior to Sierra, iOS prior to version 10, and TVOs prior to version 10. And I think here we're actually going to hold off on talking about this because there's an upcoming release where I have seen into the future and I know that there's a change that lets me talk about why it's important to deprecate old platforms. And so I'm going to not talk about this here, I think, if that's okay with you, Ben.
02:19:49.265 - 02:20:09.307, Speaker B: Sure. With regard to some of these library stabilizations here, I think I kind of want to talk about a little bit. So Corem Transmute Copy is now stable in cons contexts. Right. And so I'm trying to think. So it implies Transmute Copy is just transmute, but more. Right.
02:20:09.331 - 02:20:16.811, Speaker A: So Transmute Copy is like the worst, it's like the worst of crime you can commit in Rust. Right? You can do with Transmute Copy.
02:20:16.923 - 02:20:28.923, Speaker B: I think mem initialized is still the worst crime. It's, it's. It's Transmute Copy is like, you know, imagine one of those things where it's like, it's not illegal, but you shouldn't do it. Whereas MEM initialized is illegal. Just like, just don't. No, no. Right to jail.
02:20:28.923 - 02:20:50.275, Speaker B: Right. And so I'm just curious why I'm going to go look at transmute and see when that was const. Stable, and I'm wondering why Transmute Copy presumably took longer. So, yeah, so transmute was Constable in 1.56. So it took 20 more releases for Transmute Copy. I'm not sure if nobody actually wanted it. Maybe it was kind of like, ew, gross, I don't want to use that.
02:20:50.275 - 02:20:53.915, Speaker B: Or if it was actually some better reason. So I'm not quite sure.
02:20:54.075 - 02:21:03.341, Speaker A: I don't know. It's a good question. I mean, I wonder if it has to do with the generics involved. No, they have the same generics.
02:21:03.413 - 02:21:06.053, Speaker B: They have the same. The same signature.
02:21:06.229 - 02:21:18.101, Speaker A: So source reference transmute. No, Transmute Copy takes a reference instead of Taking the owned version. So maybe it has to do with.
02:21:18.173 - 02:21:19.637, Speaker B: Never use it enough to.
02:21:19.821 - 02:21:29.517, Speaker A: Yeah, it might be that it has to do with using accessing references for const. In const context. Maybe. Okay, I don't know.
02:21:29.621 - 02:21:30.385, Speaker B: Interesting.
02:21:30.885 - 02:21:36.145, Speaker A: Or maybe they weren't sure that it was sound. I don't know. I have not used transmute copy for anything.
02:21:36.565 - 02:21:43.893, Speaker B: I can't imagine it would be like, you know, any more unsound than transmute in terms of like Miri's ability to understand it.
02:21:43.949 - 02:22:19.182, Speaker A: So I don't know. I just love that it's. It's in the sort of description here. It says, oh, where is this? I think there used to be a line in here, I thought that said, like, this is worse than transmute, but it seems like it is not. Maybe. Maybe it's just a fever dream I've had. I think it's time for the change log review of 174.
02:22:19.182 - 02:23:35.103, Speaker A: One of the things that cargo gained in 174 is the keep going flag, which I love the name of this one. So this is a flag that you can pass to Cargo build and cargo test and it specifically tells and cargo check and it tells cargo to continue building or running checks or whatever, even if it has hit a hard error. So imagine that you're doing a build of your crate and it has like a bunch of different targets. Like imagine it has a library and a binary being a good example, and the library on the binary maybe have different sets of dependencies or something. Or you could have a workspace where you have crates that are different dependencies and cargo starts building and then it hits a an error in a dependency that is only used for one of the targets that it's building. Like it's only used for the test things that you're building, for example, but it might still be able to build the library in the normal case. If you run cargo check like dash, dash all targets for instance, then what it will do is it will, the moment it hits the first build error, cargo will exit and it will sort of finish up any current concurrent builds it's doing, but then it will exit.
02:23:35.103 - 02:24:18.705, Speaker A: The keep going flag tells cargo to build as much as it can. So even if it's hit an error so it knows the compilation will ultimately fail, it tells it to keep trying to build all the other dependencies that you can still build, build all the other targets you might still be able to build. And I think the idea for this one was in part to just give me the. Give me as many Errors as possible on screen so that I don't have to like get one error and then fix it and then build again and then get one error and then fix it and then do it again. To just have Cargo give me all of them all at once, or at least as many as you can. It's also just motivational in its naming. Keep going, Cargo, you could do it.
02:24:18.705 - 02:25:08.389, Speaker A: Another one that I had that is pretty neat is for this is also a cargo one. So there are some of the cargo commands and I think update is probably the most common of them, where you can pass the dash p flag to say, you know, cargo update dash P serde. And what that will do is we'll specifically update serde but not update any of your other dependencies. So like if you're in Cargo update, it's going to update all of the dependencies in your lock file at once. But cargo update dash P lets you say, just update this one. But if you have multiple major versions of a dependency by that name, then Cargo will error and say, you need to tell me which of them. So it might say, let's say you do cargo update P hyper.
02:25:08.389 - 02:25:49.941, Speaker A: Then it might say, well, but you have hyper 0.14.7 and you have hyper 1.0.0. Which of them do you want me to update? And previously Cargo would require that you give the full version string in order to update. So you would have to say like cargo update p hyper at 0.14.7, even though all that you really needed was 0.14 or if you wanted to update one, all you really needed was hyper at one. And so in 174, cargo update and similar commands that take P got smarter and now they only require you to give as much of the version as is necessary.
02:25:49.941 - 02:27:11.917, Speaker A: So basically the major version in order to complete the command that you or disambiguate the choice that you had. So this is another one of those like developer experience improvements that is really appreciated. And then I have some Rust doc things that I thought were neat. One of them is Rustock now supports warning blocks. So in the doc string for a function, a type, whatever, you know, you can already put markdown, you can put bold and paragraphs and images and whatever you want. But now you can also specifically by using inline HTML, make Rustock print like a warning box that shows up as a warning box in the output of the function, like in the in the docs that get rendered. And you do it by writing it's open angle bracket div class equals and then double quotes warning and Then end, angle, bracket and it needs the start and the end div need to be on their own line because Markdown and inline HTML are weird but anything you put in between those div lines will render as like a little warning thing with an orange bar on the left to indicate to people this is serious.
02:27:11.917 - 02:27:13.545, Speaker A: Make sure you look at this carefully.
02:27:13.925 - 02:27:18.645, Speaker B: I'm curious why this needed to be a support. I thought Markdown just supported inline HTML.
02:27:18.805 - 02:27:22.557, Speaker A: So it does. The difference here is that now they're.
02:27:22.621 - 02:27:33.245, Speaker B: Styled so otherwise standardized. Okay, yeah, they were previously piggybacking on like some warning class that was already existing somewhere.
02:27:33.365 - 02:27:40.665, Speaker A: I don't actually know. I don't know if you could do this before or whether if you put div class warning it would just be a div but it wouldn't be styled any specially.
02:27:41.085 - 02:27:56.493, Speaker B: Well, I mean Rustock, look at the output. There are things that are like warning like in the output that you could have said, hey, I'm just going to reuse this class for the fact that you're colliding with the pre provided CSS from Rustock to a blessed way of doing it. So now we're not going to break this.
02:27:56.669 - 02:29:04.455, Speaker A: No, now it's like officially supported and then the other one and this gets at the search things that have been improved. Last time in 174 we got support for generic type parameters in signature search in Rustock search. So now you can do things like in the in the rustock search field, right option of option of T, arrow option of T and it will give you all functions whose signature takes an option of option of T and returns an option of the same type T. Like it recognizes that the T's here should be the same. You can similarly also search for things like option of T to option of U to indicate that it turns one option into a different type of option. And so I think it's a really cool indication that this sort of signature based search in Rostock is getting, you know, it's not, it's not full featured, but it is at least getting pretty damn useful.
02:29:04.955 - 02:29:26.717, Speaker B: But now I'm curious though, because I assume, I think actually in the past at least that Rust doc search was all local. Like it was just like had like a local index of like everything in the crate and it was just doing like a text search over it. It wasn't doing a network request. And so is there like some kind of like type parser or like logic for doing type relative searches now in Rustock like running in JavaScript in your.
02:29:26.741 - 02:30:05.275, Speaker A: Browser, you Know, I don't really know. I, my, my guess here is that there's some like, additional file that's included somewhere. Maybe they like, maybe they do it all from JavaScript. I'm not sure. Let's look at the PR here. How to read Rustock, the search interface. Searching by type signature search md, HTML render.
02:30:05.275 - 02:30:39.125, Speaker A: There's a search index, search corrections. You know, I'm not sure how they do this, but it could actually be that this is all like implemented in pure JavaScript. Because I'm looking at a JavaScript file here now called function check generics and it calls a function unify function types.
02:30:39.425 - 02:30:44.037, Speaker B: Which I'm wondering if they had unification, which in JavaScript, which makes me think.
02:30:44.061 - 02:31:09.865, Speaker A: That they might actually have implemented this whole thing in JavaScript, which is nuts. Someone in chat is saying it's all from JavaScript. There's a local index file storing all the necessary information. I see. So, so like all the type signatures get dumped some file as part of the output of Rustock. And so JavaScript just has a access to a list of all the type signatures. I guess.
02:31:11.675 - 02:31:18.979, Speaker B: You'D still need to know that a T and a T and a U and a T are representing different things.
02:31:19.067 - 02:31:57.837, Speaker A: Yeah, it's true. I don't know, it's just really neat. And again, an indication that the rustock search is getting pretty good. And this is something that Haskell's search is notoriously good at. And it's nice to see that investment is being made in the direction of Rust too. It's just now people need to also be aware of it because once you're aware of the power of searching by type signatures, you start to get addicted to it. There were a couple of other things that were buried in the changelog that I thought were interesting.
02:31:57.837 - 02:32:34.200, Speaker A: One of them was an implementation of the step trait for IP addresses. And this was wild to me. So the step trait is the thing that lets you say, lets you construct a range. So the range type is like, you know, if you do a range from 1 to 4, like 1/4. It works because usize implements step. And so there is a way to step from 1 to 2 to 3 to 4. And an implementation of step for IP addresses means that you can now say, you know, you can create an IP address for 1.0.0.0.1
02:32:34.200 - 02:32:45.755, Speaker A: and an IP address for 1.0 Dot 0.0.255 and you can write for IP in IP1 IP2 and it works.
02:32:46.415 - 02:32:59.111, Speaker B: Does step is step the thing that lets ranges work or Is it just the thing that lets you go by a specific step for every individual range? Does it already exist range iterators over IP addresses or is this.
02:32:59.183 - 02:33:06.595, Speaker A: No, I don't think it does. I don't think there's already a range of IP addresses. I think it's specifically step that lets you do it.
02:33:08.895 - 02:33:09.715, Speaker B: Okay.
02:33:10.215 - 02:33:35.895, Speaker A: Which I think is just super neat. I don't, I don't really have a use case for this, but like it's neat that you can do this. And, and I think the reason you're able to. Right. Is because IP IPv4 addresses are just 32 bit integers and IPv6 addresses are just 64 bit integers. So clearly they implement step because it's just increment the underlying U32 or let's see.
02:33:36.435 - 02:33:55.445, Speaker B: Also the question is there are some invalid depending on what your context. Right. Like the local 127os are all for local use only, that kind of thing. And so it's not, you know, something. It's not like a flat namespace. There are like, you know, reserved addresses. Like, you know, there's address.
02:33:55.605 - 02:34:23.645, Speaker A: It doesn't look like it deals with any of those. It just increments the number. The ACP is all about extended logic for IP networks and it talks about implementing not bit and bit or leading zeros, leading ones, trailing zeros, trailing ones. It says the primary use case for most workflows would be filtering, such as allow listing or deny listing ranges of ips for connections. Although more dedicated networking code that routes traffic among several hosts could also benefit from this.
02:34:25.305 - 02:34:30.025, Speaker B: Okay, so somebody was writing a firewall in Rust and wanted to be able to say, hey, block this IP range.
02:34:30.185 - 02:34:33.645, Speaker A: Yeah, I guess so. It's neat.
02:34:34.225 - 02:34:35.045, Speaker B: Yeah.
02:34:39.105 - 02:34:59.035, Speaker A: The other thing that there are two more things that changed in 174. One of them was a lint called Private in Public that got very much changed in 174. And I think you were part of these discussions, Ben, is that right?
02:35:00.775 - 02:35:06.655, Speaker B: Possibly, in some degree, but I was not the driver for this because I think not really. Yeah, yeah.
02:35:06.695 - 02:35:48.925, Speaker A: Well, I was going to say, I think you're. I think your name was mentioned in the, in the discussion for this. Let me see if I can dig it up. Private in public lint. So the private and public lint, the intent of it is to warn you if you have a public type that is in a private module. So it's not actually accessible anywhere, but the visibility modifier on the thing suggests that it should be. And now I can't find The.
02:35:53.985 - 02:36:01.761, Speaker B: This is a very old discussion, so I wouldn't be surprised if I'm in here somewhere. But I might not have the context from a discussion from 10 years ago paged in.
02:36:01.873 - 02:36:02.481, Speaker A: No, that's.
02:36:02.553 - 02:37:14.315, Speaker B: I mean, I think if I can think about what my opinion would be, I think I am extremely in favor of making sure that in Rust, unsafe code is a thing. Unsafe blocks are a thing. One of the things about unsafe blocks is that if you're in a module, a Rust module that contains an unsafe block, well, what is the danger? Because an unsafe block represents some invariant, so that must be upheld and is currently being manually upheld, then if you make any change in the module, you might be in some way invalidating the invariant that unsafe block assumes. So whenever you make a change in a module that contains an unsafe block, you need to check to make sure that every unsafe block in that module, the invariant has remained the same. It's kind of like, oh, no, it's like, where is the boundary of this? If I need to change this unsafe block and the entire crate graph and the boundary, at best, is the module level. And the reason this is the module level is because of privacy. It's because whenever you are in a module, you have access to every field, public or private, of any type defined in that module.
02:37:14.315 - 02:37:51.295, Speaker B: It means that in theory, the burden of you as a module author is to make sure that your public API is, you know, contains either things that cannot violate invariants or that can, but are marked as unsafe functions. Right. And so in theory, you kind of want to make sure that privacy is a very strict sort of thing, because you don't want any. You don't know what kind of thing might go wrong if a thing that you think assume is private actually is public and makes sense of how. And so, I mean, there is some. It's harder than you think.
02:37:51.715 - 02:38:30.587, Speaker A: Yeah. I think what's interesting here is that the compiler is very strict about enforcing that things that aren't supposed to be public don't make it public. Like you can't accidentally leak something, it has to be marked as pub for exactly the reasons you outlined. The private and public lints, I think, are trying to get at the opposite problem, which is if you meant to make something public, that's why you wrote like pubfn, but because of your module structure or something, there's like a parent module that's not pub, and therefore the type you thought was public wasn't. And so that is going to be confusing to your users.
02:38:30.771 - 02:38:42.935, Speaker B: Yeah, that's the question Though, did you actually mean it? The reason go through and say oh, you did mean this is because you can have a type that is public in this module, but not public exposed from the entire crate or to this module over here.
02:38:43.635 - 02:39:09.487, Speaker A: I think what was really interesting when I was skimming through this for 174 was that one of the things that's happened is that the private and public lint has basically been removed and it's been replaced with two or three more specific lints. One that talks about types, one that talks about traits, and one that talks about Voldemort types. And I don't exactly know what Voldemort types are, but they're described in the rfc.
02:39:09.551 - 02:39:15.541, Speaker B: Opaque. Yeah, so. So that's what d the language calls them Voldemort types because they cannot be named.
02:39:15.703 - 02:39:16.873, Speaker A: Nice. I like that.
02:39:16.929 - 02:39:23.353, Speaker B: He who must not be named. And so I kind of don't like clever names like that. I don't even like Impulse. I prefer saying opaque types.
02:39:23.489 - 02:39:26.845, Speaker A: Nice. So what about existential types?
02:39:27.185 - 02:39:29.045, Speaker B: No, never. Don't even dare.
02:39:30.865 - 02:40:15.115, Speaker A: Well, what I do. What I did find interesting though was reading through this RFC that talks about both why the lint was split and what these new defined lints are like. So this is RFC 2145. So if anyone's curious about the sort of nuances of private and public visibility, I recommend giving that a read. I at least thought it was pretty interesting. And I think the last thing I have for 174 at least is there was a change to the cargo recommendation for what to do with cargo lock files. So previously before 174, Cargo generally recommended that libraries should not check in their cargo lock, but binaries should.
02:40:15.115 - 02:41:18.727, Speaker A: And the change that happened in 174 is that the cargo new command will no longer ignore like put cargo.lock in your gitignore incentivizing you to check it in. And in fact there was a longer blog post as well talking about this change in policy and why it is and I recommend you go read it. I think the high level summary is that it is useful to have cargo lock checked in so you can more easily do things like git bisect the history of your crate in order to find where an issue was reproduced and actually build with the dependencies at the time. It makes things like keeping a minimum supported rust version easier and the cost of checking in your lock file has gone down because we have tools like dependabot and renovate that will bump it for you. And so that combination of factors means that now the sort of trade off is more in favor of checking in your cargo lock and then just having additional mechanisms for the things that not checking in a cargo lock would normally buy you.
02:41:18.871 - 02:41:22.871, Speaker B: Right. And still doesn't change the actual behavior of cargo, which is to ignore log files and libraries.
02:41:22.943 - 02:41:31.129, Speaker A: And so it's important to understand that's totally true. I think that's all I had for 174. Did you have anything else?
02:41:31.297 - 02:41:35.529, Speaker B: That's all I have for 174. But we do have a point release 1.74.1.
02:41:35.617 - 02:41:37.073, Speaker A: Oh man, I love point releases.
02:41:37.089 - 02:42:22.359, Speaker B: I don't feel like there's really anything super interesting in here, some like, you know, some LLVM thing. But I did see talking before, we were joking before about how your current PR bring back the meta narrative, the overarching narrative, your current pr. We should wait for a point release to get this in there. One of the items of in this release is just like a single line change or a single word change to standard MEM discriminants. Just to clarify the actual rules of what you can and cannot transmute. And it's very funny to see the change being okay, go from talking about lifetimes to about free lifetimes and saying it was important enough to have a point release for.
02:42:22.447 - 02:42:26.999, Speaker A: See, I think that means there's hope for our pr and I think it's a good.
02:42:27.087 - 02:42:44.015, Speaker B: We just need to. Okay, again, now we're on act two of our narrative here, which is now we need to find a severe security flaw in Rough C and patch it within the next two hours so that we can then justify a point release and say while you're at it, oh, might as well go through and improve his PR too. Why not?
02:42:44.055 - 02:42:57.065, Speaker A: Yeah, and then we can point to the to 174.1 that commit and say, here's an example of where you've done it before. Actually, I guess given we're done with 174, we can go look at the PR and see how it's doing.
02:42:57.485 - 02:43:01.145, Speaker B: Oh yeah, let's bring it back around. Any progress?
02:43:01.965 - 02:43:21.759, Speaker A: Let's see. My PR has two hearts now. That's good. I'll take that. That common thread is resolved. This thread is going, oh, this is a discussion about the side effect of shrink. Shrink to fit.
02:43:21.759 - 02:43:49.401, Speaker A: Oh, I know what this is talking about. I'll show you in a second. And then this is me apologizing for it being a live live stream and Nil's giving a thumbs up. I'll take it. Let's see so this is here. So we changed the documentation for into boxed STR to say before doing the conversion, this method discards X's capacity like shrink to fit. And then we.
02:43:49.401 - 02:44:09.571, Speaker A: So that is already what's on vec into box slice. But we added the line note that the shrink to fit call may reallocate and copy the bytes of the string. And I think the call out here is that it's. It feels weird to talk about a side effect of a different method in the documentation for this method.
02:44:09.763 - 02:44:10.091, Speaker B: Right.
02:44:10.123 - 02:44:36.215, Speaker A: Like this is the documentation for into box string, but it talks about the side effect of shrink to fit because that's the thing that we call. And I think that's an interesting one. I guess one of the ways we could fix this is to just say note that this call may reallocate and copy the bytes of the string just to avoid the mention here.
02:44:36.375 - 02:44:37.075, Speaker B: Sure.
02:44:37.575 - 02:44:49.775, Speaker A: All right. Oh, now I need to remember where that is again. Yeah. Library alloc source string.
02:44:49.895 - 02:44:55.967, Speaker B: No, I'm going to get a head start in the intermission between releases here and refill my team.
02:44:56.071 - 02:46:17.985, Speaker A: Go for it. How about we do note that this call may reallocate and copy the bytes of the string. If you don't want that behavior, prefer use leak instead. But that's also not quite true because leak isn't the same because it doesn't give you a box back. So leak isn't really the alternative to this. It would have to be a variant that gives you a box stir. Okay, let's maybe just leave it as this then.
02:46:17.985 - 02:47:16.885, Speaker A: Oh no. Rust format tried to format the code of the standard library. That feels like a bad idea. And I guess I could also do. That's fine. Push force. Change the side effect writing to not talk about shrink to fit, causing the the Rust CI to spin more than should otherwise be needed.
02:47:16.885 - 02:48:17.385, Speaker A: And I will also edit this so that the eyes are visible to indicate my. My captivity. Excellent. I still think there's hope that this will land. I guess now we're up to the last release of 2023. Feels like yesterday. I have so many t.
02:48:17.385 - 02:48:58.105, Speaker A: It's not 2024 yet. You're confused. It's 2023. It is in fact currently, because we haven't started the next release yet. It is currently December 7th. I guess maybe December 8th. Maybe we didn't see it the the same day.
02:48:58.105 - 02:49:36.727, Speaker A: It's exciting. This release came out on my birthday, which means it's the day after my birthday now. That's pretty exciting. What else do we have over here? Oh boy. That's a chunker if I ever saw one. Happy birthday for yesterday. Thank you.
02:49:36.727 - 02:50:16.603, Speaker A: Thank you. Yeah, but see, birthday song for intermission doesn't work because I can't sing my own birthday song. So you, as in chat, would all need to sing the birthday song, which we can't hear because you don't have microphones. So. Ben, we have discovered that it's actually my birthday because it's currently December 7, 2023.
02:50:16.779 - 02:50:18.155, Speaker B: Oh, congratulations.
02:50:18.235 - 02:50:41.465, Speaker A: Thank you. Thank you. So chat is singing me happy birthday, but they don't have microphones. Okay, you ready to jump into 75?
02:50:42.845 - 02:50:49.425, Speaker B: Give me one second. And we're still on the same podcast episode, in theory.
02:50:50.285 - 02:50:53.661, Speaker A: What even does same mean anymore, Ben? I don't even know.
02:50:53.733 - 02:50:54.985, Speaker B: I'm lost in time.
02:51:02.055 - 02:51:26.765, Speaker A: See there. Here we have the Doctor who theme. Great. I was trying to hum it earlier and I failed miserably. I feel like either we need that or we need the. What's the X Files theme song? That's the one. That's the one.
02:51:26.765 - 02:51:34.205, Speaker A: And I feel like that's the thing we should use, given that I'll. I'm about to say. And soon thereafter, it was three weeks later.
02:51:35.305 - 02:51:39.205, Speaker B: Three weeks later, I guess. Yeah, from point one.
02:51:42.465 - 02:51:46.565, Speaker A: Oh, yeah. We've used Transmute Copy in order to get to December 28th.
02:51:46.955 - 02:51:47.619, Speaker B: Mm.
02:51:47.747 - 02:51:56.015, Speaker A: Transmute copy lets you do everything, including moving through time, because it ignores lifetimes.
02:51:57.835 - 02:52:03.715, Speaker B: I'm pretty sure that undefined behavior can cause time travel. There's like a great. John Reger has a post about that.
02:52:03.795 - 02:52:36.115, Speaker A: Almost certainly true. Okay, Ben, it is now suddenly December 28, 2023, and a very, very serious, severe thing has happened, which is that Rust 175 has released. And it is one that the. I'm just setting the scene here. The crowd has gone silent, waiting for this day. Because finally, in Rust 175 we got async fn and return position infiltrate in traits. And the crowd goes wild.
02:52:36.195 - 02:52:38.655, Speaker B: Let's move on to pointer byte offset APIs.
02:52:39.665 - 02:52:51.485, Speaker A: The crowd has gone wild and we can't even hear ourselves over the sounds of the masses. Ben, why did this take so so long? And why is it exciting?
02:52:53.985 - 02:53:18.595, Speaker B: Okay, so Async FN is kind of a big deal. The idea here is that it came in 2018. The ability to return a future from a trade. And this is not kind of like the functionality that landed in 2018. Lots of stuff landed in that kind of push for Async in Rust in general. But the Async offend stuff was not that interesting. It was Kind of just in a general function.
02:53:18.595 - 02:53:34.945, Speaker B: Async fn is just sugar for a function that returns a future. And so kind of like there is the type that you type. Async fn returns foo. It'll return, actually. Oh, it's a future of foo. Item equals foo. Is it item in the future? Yeah, Right? Yeah.
02:53:34.945 - 02:53:38.065, Speaker B: No, output.
02:53:38.365 - 02:53:39.505, Speaker A: It's output.
02:53:40.245 - 02:53:56.747, Speaker B: Output equals foo. Yeah. And then so, but so trait methods, right? Methods are just functions that live inside of an input block. What's the big deal? And so. Oh, wow. Just like so much to unpack here of why it's a big deal. I know that's the question you asked and that's why you want me to.
02:53:56.747 - 02:54:08.555, Speaker B: To talk about this, but the idea here is that the thing that you return. Actually it's not. Do you have a better way of putting it? You're the async guy. You wrote a whole book about this.
02:54:09.855 - 02:54:17.355, Speaker A: Okay, let me try. So I actually, I gave a talk about this too, a little bit before it stabilized because I'm a time traveler.
02:54:18.175 - 02:54:25.263, Speaker B: The question I am, why is the return type of an async function an associated type? Why can't it just be a normal type? Right.
02:54:25.439 - 02:55:26.065, Speaker A: Okay, so there are a bunch of ways in which this is real weird, but the most straightforward way to explain it is when you implement a trait that has an asynchronous function or indeed any function that returns an impulse trait. Because really, async fn is a sugar for a function that returns an impulse and then internally contains an async block. So async offends are not any harder really than a return position impul trait in traits. So why are those hard? Well, the reason why having return position impul trait in traits is hard is because when you implement the trait, you need to. You need to say how large? And you need to say what the type is of the thing that you return. And the reason why you need to know what the type is is because imagine that I have something that implements the trait. I don't know what's an example of a trait? Iterator.
02:55:26.065 - 02:55:54.173, Speaker A: Iterator is a bad example of this. Let's say that I have some trait and that trait has a method that returns impul trait. Someone who calls that method needs to put the return value somewhere. That means that they need to allocate space on their stack to. To put that value. The problem is they don't know what that type is. They just don't know that it's something that implements trait.
02:55:54.173 - 02:56:27.525, Speaker A: And so you could Say, well, the implementer of the trait knows what the type is, sure, but they don't have anywhere to put that type because there's no associated type that holds that type information that the caller can then look at. So one of the reasons why this was complicated was to figure out how do we get the type through all of the machinery so that the callers actually know at least how much space to allocate for the return type and then know how to call the appropriate methods on it.
02:56:27.985 - 02:56:36.961, Speaker B: Right? But I guess the question here then is why was it so much harder for trait methods and not for functions, but still use impulse trait for their future stuff?
02:56:37.073 - 02:57:27.571, Speaker A: So the reason why it's easier for functions is because for functions, when you call the function, you have direct access to the function definition, right? Because they're one and the same. When you have a trait in between, all you know at the call site is that you have something that implements the trait. At that point you don't know the specific type. And this gets into monomorphization versus dynamic dispatch. In the dynamic dispatch case, right? Imagine you have a, an ampersand DIN trait. Then you don't have the underlying type at all. You just have a pointer to the data and you have a pointer to the V table, right? So you have no information about the actual underlying type, which means that the only information you have is what is in the V table, the stuff that got preserved as part of turning it into a dynamic trait object in the monomorphized case.
02:57:27.571 - 02:58:01.877, Speaker A: So if you call a function that is generic over T, where T is this trait that has a return position implementation, then for each monomorphization of that function, you do know the original type. And so you could figure out what the return position type is. But they're like, you need code to handle this case, you need code in the monomorphization code to figure out what is the true type that goes in this particular method call. And so the real problem is that you're sort of, you're one removed from the definition. When you go through a trait, you're.
02:58:01.901 - 02:58:29.421, Speaker B: Correct, that information takes its runtime. But I mean, the counterpoint to that is that this is all a compile time construct and we are allocating space in the stack and we do know the return type of the impulse thing, the actual type of the opaque type that will be returned. If we're the compiler, maybe in a different crate, it could be different, might need some kind of metadata to actually transmit that information. But why is it harder for functions like right there is this trait level interposing here. But why is the compiler have a hard time understanding what the actual type is?
02:58:29.493 - 02:59:30.933, Speaker A: So there are two parts of this. The first of them is that once you start bringing trait objects and dynamic dispatch into the picture here, the compiler doesn't know either because it might be determined at runtime which specific type gets passed in. Because you could have something that's like if the user pressed A, then construct a value of this type, turn it into a box din of the trait and then call this function. And if the user pressed B, then use this other type and construct it, turn it into a trait object and add it to this function. And so in that case the compiler cannot know. So for trait objects it's actually complicated regardless because the compiler doesn't have the information, although that is something that they have some ideas for how to implement but was not I think in the V1 here. But on this, on the, on the sort of static side, on the non trait object side, you're totally right that the compiler does have all the information, which in some sense is why we have now gotten this feature is because the compiler does have the information.
02:59:30.933 - 03:00:44.185, Speaker A: I think much of the complexity came from how do we, how does the compiler thread all that information through in such a way that we actually know we've covered all the cases, we do it all correctly. It's all sound, both type theoretically, but also sort of memory safety implementation wise. And there are a bunch of nuances here too around lifetime captures and the like that I don't think we should get into here. But there's a bunch of sort of related but not quite the same problem. And to give a sort of a little bit of color to that, as an example of why it's complicated, imagine that you have an asynchronous function in a trait and it takes an argument that is a reference to a foo, and it uses that reference to a foo inside of the returned future. And so now the future that you return actually has an associated lifetime with it as well, because it's tied to the lifetime borrow of foo. And so now you do you need an async offense to always declare in all of your return types which lifetimes from the inputs they borrow from, because that would be a pain.
03:00:44.185 - 03:01:42.895, Speaker A: And also you don't even have a way to express this to say that, you know, if you define an async FN bar that takes a reference to a foo argument, where would you write that the future that this asynchronous function returns is tied to the lifetime of the foo argument because you would need to be able to talk about your own return value, that is the return value of the function, not of the asynchronous function. Right? It's a property of the future and not the return type of the future. And so there's a bunch of these like weird nuances of how do you even express this? And we're still not fully there. There are still a bunch of things that the machinery that was landed in 175 can't do. Some examples of this being, I think, trait objects. And it also can't really easily express being generic over send bounds. So you can't for example, have a trait that has an async event.
03:01:42.895 - 03:01:51.555, Speaker A: And you want to say where this type implements this trait and the futures are sent is not a thing that you can Express in 175.
03:01:52.335 - 03:02:21.185, Speaker B: I think the underlying question of why was this harder for methods as opposed to free functions really partially comes down to the lifetime issue, because the lifetimes are tied to the trait here in some cases, and the implementer might determine that. And so trying to figure out how to express this is the reason that we needed to express the return future as an associated type. And then once you do that, there's another problem, which is that associated types in traits couldn't be generic until very recently. Right. And so what Was that like 72? Something like that?
03:02:21.306 - 03:02:30.260, Speaker A: It was 2021, I think, because 72 we've talked about, and we didn't talk about that. So therefore it must be 170 or.
03:02:30.393 - 03:03:09.315, Speaker B: 71 that once, because of references and late times, that you need your futures to be associated types on the traits. Now you need to think, okay, well now all the other problems, associated types of limitations that exist currently in the whatever infiltrate stuff or associated type stuff, now we need to fix those two. And that took a long time. And so it's been like 2018 was the first release of stable Async, Await and Rust. And now in 2023 was like five years later of first of all, what do we do need to do? How do we do it? And then doing it and then testing it and does it work is actually like fit. And I think in between they realized, oh, this is actually like a huge extension. This is like the biggest extension to the type system since 1.0.
03:03:09.315 - 03:03:46.597, Speaker B: And they actually created a new team in the Rust organization, the types team. I think in response to this, we're kind of like, hey, we're worried that if we do this wrong, we will make our type system no longer sound. We'll totally break the language. And so we want to have a lot of assurance that what we're doing is actually correct. And so there is now a types team whose job is just to think hard about like any type system extension and make sure that they haven't invalidated the entire point of the language, which is to have a sound type system to enforce memory safety. And so that's, that's the goal here. I think why it took so long is because it was actually lots of this requires this, requires this, requires this.
03:03:46.597 - 03:04:11.975, Speaker B: And you end up yak shaving for years in, you know, ankle deep in a type checker, which is one of those things that's kind of like very like, you know, you need a certain kind of knowledge. It's like not super common. You need to have, you know, some like type theory background and like, you know, be very meticulous about what you're doing. And it just like took a long time. Things will happen unless someone does them right. It's a volunteer project. And so somebody had to, who knew, had the expertise needed to actually go through and think about all this stuff for years and years.
03:04:11.975 - 03:04:20.931, Speaker B: And so I'm thankful they did. It's like, you know, you know, people who are unsung heroes of the project who like spent all this time working on this stuff and I applaud you.
03:04:21.043 - 03:05:26.251, Speaker A: Yeah, I think you're right. I think the other thing that's interesting is it was also a matter of. It was not just a matter of there's a long chain of things we need to do and they're all kind of complicated. It was also a matter of discovery. Right? Like when we thought that we were ready to, okay, we have all the parts now discovering another instance of oh, but we haven't thought of or oh, but what about like, I think the sendbound stuff being one example of something where I think there was an indication early on that we probably needed something like return type notation. But I don't think it became quite visible how severe that limitation was until we got closer to stabilization to the point where like the announcement post that talks about async event is very clearly stipulating that you probably don't want to use this for anything where you want to be generic over a trait that has async offense where you care about whether the functions are sent. I do love the line in the 175 release notes though, as to say it's expected that these limitations will be lifted in future releases.
03:05:26.251 - 03:05:30.335, Speaker A: And I'm very curious to see how far ahead those future releases are.
03:05:30.875 - 03:05:57.549, Speaker B: I mean, it's better to have to not have it once you are. As long as you're not sure you're not like, you know, like doing a thing you need to regret later and ping corner, it's still like, you know, it's better to get it out and people's hands because, I mean, at that point it creates pressure on you to actually do it. Lots of things in Rust are kind of like they have been in nightly for years. Can be like, where is the progress on this? And it's kind of like, well, do we wait until it's perfect to get it out or do we try and do an MVP and the MVP approach ends up being the actual thing that actually ships.
03:05:57.717 - 03:07:14.579, Speaker A: I think there's an even stronger argument here actually, because I was following some of the debate about do we stabilize what we have so far or not. And there is actually a decent argument for stabilizing this because it's useful even without the other things that we know are needed for some parts of adoption. So one of the arguments I saw was that in embedded programming there are a bunch of cases where you really want the ability to have async offendent traits, for example, but you don't care about send because you only have a single core anyway, as all of the runtimes in that space aren't multithreaded, they don't require send. And so please give this to us, even though that like don't block on the send stuff because we don't care about it and it would be super useful for us to have what you have already. I think we should move on to the other headline feature of 175, which is of course pointer bytes, byte offset APIs. This one too though is interesting because I think this has also been in the works for quite some time, but for I think, very different reasons. So the idea here is that when you have raw pointers in Rust, so this being const and mut, when you add to them, when you do arithmetic on them, you do arithmetic in units of the size of T.
03:07:14.579 - 03:08:10.135, Speaker A: So if you add one to a star const T pointer, what you're really adding in terms of like the actual number that makes up the pointer is you add the size of T to the the sort of number of bytes in that pointer. And that's usually what you want anyway, right? If you think of something like using a pointer to move through an array, you want to add if you add one, you want that to move you to the next element in the array, not to move you one into the element, the first element of the array. But there are use cases where you truly want to operate on the bytes. And I think one of the things that that held this up because it landed in 175 with the method names being byte add, byte offset by offset from and byte sub and then also wrapping byte add, wrapping byte offset, wrapping byte sub. And I think the naming held this up a decent amount. Like what should this actually be called?
03:08:10.675 - 03:08:15.307, Speaker B: This happens a lot. Yeah, yeah. Bike shooting is real, Bike shining is real.
03:08:15.371 - 03:08:46.235, Speaker A: But I also do think it's kind of important because you want to pick names that are, I don't want to say guessable, but are sort of in line with the rest of the language so that you can generally things feel the same when you move from one place to another. And even things like should it be wrapping byte add or should it be byte wrapping add? And it doesn't matter. But if everything in the standard library had the words in different orders, it would be pretty confusing. And so when you're establishing a new.
03:08:46.275 - 03:08:51.975, Speaker B: Precedent, totally valid wrapping by add and by wrapping. So it's kind of just like pick one and be consistent in the future.
03:08:52.275 - 03:08:58.859, Speaker A: And so is addbyte wrapping. It's just not consistent with what the standard library does elsewhere.
03:08:58.947 - 03:09:03.339, Speaker B: I think wrapping add already has precedence from other integer operations.
03:09:03.427 - 03:09:03.955, Speaker A: Yeah, exactly.
03:09:04.035 - 03:09:12.259, Speaker B: We don't want to just take whatever is expected and we already have wrapping add and so put the byte somewhere in there. But put wrapping before add, that's all we know.
03:09:12.347 - 03:09:38.215, Speaker A: Yep. But at least now we have them. I mean previously you could do this too. It was just pretty annoying. But now there's sort of a nice method you can call that does the thing that you expect it would. And I think specifically the way you would do this in the past is you would cast it to a star const u8 and then add one or add however many bytes and then cast it back, which works. It's just really inconvenient.
03:09:38.215 - 03:10:32.545, Speaker A: The next one is code layout optimizations for Rust C. So specifically the Rust compiler is now built with Bolt, which is this fancy optimization, like binary optimization thing that I think came out of Clang and lvm. So the idea here is you build your program, you run your program on a bunch of like real inputs or real looking inputs and you run a profiler while you run the program, and then you recompile your program and you give the profiler output to the compiler so that it knows which functions are most called in reality. Like it basically gives the compiler more information about the actual execution patterns of the code to try to make better decisions about things like inlining.
03:10:33.895 - 03:11:01.795, Speaker B: Well, I think so Bolt though. So you're talking about pgo, right? So PGO is the thing where you, you know, it's kind of like a gi. So a git in Java, right? You have your git and like a thing that a git can do that at time. Compiler like Rust normally can't do is that it can look at the actual, like how the code's being used and optimize it based on kind of like if you can't decide, if you're probably ahead of time, oh, you have to guess about maybe I should inline this function. Maybe I should inline this. If you're doing a git you can say, hey, I know this is being used. Inline that for sure.
03:11:01.795 - 03:11:12.589, Speaker B: And so if you have. Is there a thing called PGO where you run a program and you create a profile of it? Like, so Firefox uses this, Chrome uses this to say, hey, what are the general standard?
03:11:12.717 - 03:11:16.705, Speaker A: It's called like profile. It's PGO short for Profile Guided Optimization.
03:11:17.365 - 03:11:38.037, Speaker B: And so we click this profile, which is like, you know, it says how this is actually being used. Then we use this to optimize so we can say, hey, okay, we can see at runtime this is actually being used a lot. So inline this. Bolt here is something different. Bolt is about optimizing the layout of the actual for the linker. And so it puts, you know, it puts less. It's about right.
03:11:38.037 - 03:12:04.615, Speaker B: So when you run code, there is the actual data that is your code that goes in the cache in the cpu. And like if it loads things more efficiently, your code can run faster because it's less fetching of code from the binary. And so this actually like a jigsaw puzzle, it rearranges the sections in your binary so that the linker is more effective or I guess the loader is more effective whenever it loads them. So it's a link time thing.
03:12:06.275 - 03:12:09.815, Speaker A: I thought it could optimize the code as well, but maybe I'm just completely.
03:12:10.315 - 03:12:18.455, Speaker B: When I first looked at it years ago, it was just a way of the layout of the binary so that when it gets loaded is more efficient.
03:12:19.395 - 03:12:22.843, Speaker A: I remember this is a while ago now, so it could be.
03:12:22.979 - 03:12:24.799, Speaker B: Let's look at it in real time and see who's correct.
03:12:24.907 - 03:13:31.429, Speaker A: Yeah, so one of the differences that I seem to remember about Bolt was That it allows you to, it allows you to optimize based on a profile that's gathered with a binary that was built by someone else. So one of the problems you have with PGO is that you need to build the binary and then you need to profile with the binary that you built and then you need to compile with the output from the profiling with the exact same tool chain so that all of the like it needs more information about things like the internals of the compiler at the time of building that leak over through the profiling and back into the compiler. Whereas I think for Bolt it only cares about the symbols that make it into Dwarf anyway. And so it's easier to take the binary and ship it out to a bunch of places and then recompile it later on elsewhere and still make use of the profiling information. So I thought that was one of.
03:13:31.437 - 03:13:46.463, Speaker B: The benefits of a profile, but I don't think it's going to. So it's not like a code gen level thing unlike PGO and llvm. I don't think it's going to make an optimization decision beyond rearranging how things are laid out in the binary. Click the link. Click link and find out.
03:13:46.639 - 03:14:04.863, Speaker A: It says this is the documentation from the LLVM project. Bolt is a post link optimizer developed to speed up large applications. It achieves the improvements by optimizing applications code layout based on execution profile gathered by sampling profilers such as the perf tool. Well, there we go. It's only linker. I'm entirely wrong.
03:14:04.919 - 03:14:31.927, Speaker B: Still an improvement. So yeah, and I think, I believe Rust C has been built with PGO for a while now. And it also talks about here how we're talking about now we're building Rust C with code units equals one and so like the maximum performance profile eke out that 1.5% improvement in the benchmarks, which is important. If you ship a compiler to a million people and they all save 1.5% of their compile time, which they compile frequently, that's like a lot of time save which I mean these steps take a lot of time. Like, right.
03:14:31.927 - 03:14:55.767, Speaker B: I don't know about Rusty, but I know that in Firefox and Chrome a full like release build takes over a day, 24 hours or more because they do all this like super optimization with the profile and like the PGO and all that stuff. And so you know, if obviously for, if you have, you know, users, 100 million users using your browser, then you know, saving a single millisecond Adds up over time and so that's what's worth doing.
03:14:55.871 - 03:15:10.855, Speaker A: So it is interesting though that it says here in the announcements too that the optimizations are limited to x86 64 Linux. Do you know anything about the expansion, the extension of this to like other architectures and other platforms?
03:15:11.395 - 03:15:38.527, Speaker B: I think part of the difficulty is getting CI to have like, you know, like the builders for Macs are like slower, I think, like the bottleneck. And so if you like make those even slower, then suddenly everything gets slower. And so it might just be a timing thing where like Linux ones are already idle, although it'd be every single one. Or you'll need to build these on release ones. But I mean, still it's a big deal. And I think again, it's like kind of like lld, right? Another project where like it might just be more mature next gnu as opposed to Windows or Mac.
03:15:38.631 - 03:15:49.887, Speaker A: Yeah, I don't know, I was even thinking like AR64, like ARM processors, but for Linux maybe. No, maybe no one cares about Arch64 for Linux.
03:15:49.991 - 03:16:04.384, Speaker B: Go back to the BOLT page and see what they support. Again, it's all just ELF though, right? It's just like rearranging your elf, I assume it's just like you have an ELF binary rerange and it shouldn't really matter if it's Arch or X86. And so honestly it does say that.
03:16:04.474 - 03:16:06.795, Speaker A: Bolt supports AR64 elf binaries.
03:16:07.855 - 03:16:17.595, Speaker B: Yeah. And so macOS, like if it might not know about MAKO binaries, might not know about whatever Windows uses. And that's probably why they don't support those. But yeah, I don't see why ARM wouldn't be supported.
03:16:19.175 - 03:16:55.403, Speaker A: I think we can move on to the stabilized APIs this time. We talked about some of them, right? So the byte operations on pointers. One that stood out to me here is that the atomic types now have a from pointer constructor. So the setup here is that, you know, you have atomic use. Yeah, I was going to say like atomic use, atomic U64, atomic bool, etc. They now have a from pointer construction constructor which takes a raw pointer, like a star mute usize for atomic usize and they give you back an atomic usize. It's an unsafe.
03:16:55.539 - 03:16:58.615, Speaker B: Well, it's a reference to atomic usize, so.
03:16:59.715 - 03:17:43.425, Speaker A: Oh yeah, it gives you a reference to an atomic use. So it takes a star mute usize. It gives you back a reference to an atomic us and it's an unsafe function. The idea here is that if you have a RAW pointer to Something in memory. And you know that all of the other accessors of that memory, even you know they could be across FFI boundaries, for example, but you know that all of the ones who accesses are using atomics, then you should be able to access them using atomics from Rust as well. And this is one of the ways in which you could do that. You could take this, this raw pointer that you have, turn it into a reference to an atomic usize so that you can then do atomic operations of it from rust with the normal sort of atomic use size machinery.
03:17:43.425 - 03:18:36.723, Speaker A: It does have a bunch of requirements though in the sort of safety requirements for this unsafe block, including things like it needs to be valid as though it was an atomic usage. So that means it needs to be sort of of at least the size of an atomic US size. It needs to be the alignment that an atomic use size requires. It needs to be valid as an atomic use size for the entirety of the lifetime that you ask for it for. So this includes things like for, I guess for atomic use all bit patterns are valid question mark. But it, it cannot be accessed by non atomic operations while you have an atomic use size reference to it, for instance. And so there's a bunch of requirements, but if you meet them, this is a good way for you to be able to do atomic operations on arbitrary memory.
03:18:36.723 - 03:19:34.575, Speaker A: Especially useful for things like FFI. Another set of things that were stabilized in 175 is some helper. Both functions and types for setting and getting file times for files in the file system. So there's things like when it was last accessed, when it was last modified, both changing and reading that information out. You have been able to do this in sort of OS specific ways for a while, I think, but now there is sort of a standard cross OS way to do so which just extends, you know, the amount of things you can do without something like a config Unix or config Windows, which I think is really nice. Nice. Do you have any insights Ben, into why file times took this long before we got an OS independent version of it?
03:19:35.235 - 03:20:03.575, Speaker B: I'm not quite sure. Yeah, I don't know any in particular. WI file times would be a hard thing. Again, it's one of those things where it might just be nobody needed or maybe, you know, maybe it was good enough for a long time that the OS specific ones were there and you didn't like, you know, no one really cared to ask for a generic platform independent one. So I also thought could be interesting if you want to look it up.
03:20:04.035 - 03:20:18.015, Speaker A: I Also thought it was interesting that options now have an ass slice method. So if you have an option T, you can get back a slice of T that is of length 0 or 1 depending on whether the option is some or none.
03:20:18.585 - 03:20:20.245, Speaker B: That's funny, right?
03:20:20.585 - 03:20:25.965, Speaker A: I don't really know what this is useful for, but I guess it could be useful.
03:20:26.665 - 03:20:46.045, Speaker B: Yeah. We definitely need to have C has the obfuscated C competition or the underhanded C competition right too. And then we should have the most strangely specific head scratchingly like who actually needs this API? I'm not saying it shouldn't exist, I'm just saying that I have no use for this, but it's interesting that it exists.
03:20:46.355 - 03:21:31.559, Speaker A: The best thing I can think of here is that you're trying to call something that requires a slice, like some API that requires a slice and all you have is an option and in order to do that you want to avoid the copy or the clone rather. So if you have an option and you want to call a slice API, then if the option is some previously you would have to either clone the thing out of the option, put it in an array and then give a reference to the array to the thing, which is obviously incurs a clone unnecessarily or you would have to write some unsafe code to transmute the reference into a slice reference, which is probably what this does under the hood. Right. Option.
03:21:31.647 - 03:21:39.645, Speaker B: Someone must have asked for it like you know, it is, it is rare again things like that, unless somebody asked for it and somebody wanted this. And so I'm really curious what their use case was. Was.
03:21:40.065 - 03:22:10.445, Speaker A: It's interesting too because I'm looking at the implementation of the method now and it's not as obvious as you would think. Like it uses slice from raw parts, but it has to be a little bit careful to specifically get the offset of the field inside of the option. I think it tries very hard to never create a reference to the field inside the option directly. But again, not sure why, it's just interesting.
03:22:11.705 - 03:22:16.241, Speaker B: Yeah, well it's also funnily it uses the byte ad that also just got stabilized.
03:22:16.313 - 03:22:17.769, Speaker A: Stabilized, yeah, I saw that.
03:22:17.857 - 03:22:24.489, Speaker B: Not that it needs to be stable because it's in a library, but I mean it is funny that it's just right there. So clearly it's good for something.
03:22:24.617 - 03:23:26.339, Speaker A: Yep. In the change log there are a couple of things I found. One of them is we now implement buff read for vecdq vec dec of U8. So buff read is the thing that gives you like dot lines and dot read until and it's the reason why often if you have something like a file or something, you wrap it in a buff reader, both often to improve performance, but also so that you get access to methods that work better if they have a buffer that they're reading into, so that you can read a bunch of stuff into the buffer and check whether certain properties hold in the buffer and then return a subset of the buffer to the user. So lines being a good example where if you do a read from a file, you might get multiple lines back, but the thing you want to yield from a call to sort of next line is just a subset of the stuff you got out of the kernel. And so that's where something like a buffreader comes in. And buff read is the trait for things that can behave in that way.
03:23:26.339 - 03:24:02.525, Speaker A: So that includes things like line and it used to be implemented for vec of U8 and now it's also implemented for vec deck of U8. And I think this is just one of those completeness things. VES are handy because you can access them from both sides. So it's a useful way where you can sort of push by you push bytes to the end or you can grab bytes from the beginning, but I don't know that they're super widely used for like representing, reading and writing bytes from a network or file or something. Usually in a. In a test kind of set setting. Like I don't know that the.
03:24:02.525 - 03:24:13.185, Speaker A: The ability to operate on the front of the thing matters that much there, but I guess finally someone actually came in and had a need for it and so now it's in there.
03:24:16.735 - 03:24:41.399, Speaker B: Oh actually so I was in the Reddit thread for this and one of the top voted comments was actually someone happy about option as slice. It has a 200 upvotes, so clearly it was a great. So Ellogic, who's one of the editors for this week in Rust for a long time has a long comment describing what they like about this. So do you want to. I'll put the link there in the chat and then John, if you want to read it.
03:24:41.487 - 03:24:42.591, Speaker A: Yeah, sure, I'll pull it up.
03:24:42.663 - 03:24:45.155, Speaker B: Go ahead and see their reasoning.
03:24:50.055 - 03:24:51.595, Speaker A: In which chat?
03:24:52.455 - 03:24:54.815, Speaker B: In the. The YouTube chat. So anyone can see.
03:24:54.935 - 03:24:57.395, Speaker A: Oh yeah. Have you posted comments here?
03:24:57.735 - 03:25:02.383, Speaker B: I did, yes. Are you in live chat or only in top chat?
03:25:02.439 - 03:25:06.555, Speaker A: I think I'm in live chat, but I don't see it.
03:25:07.865 - 03:25:15.769, Speaker B: Okay, weird. I'll send to you via Discord then. Maybe I'm a Shadow banned from YouTube.
03:25:15.937 - 03:25:18.685, Speaker A: Yeah, maybe. Here we go.
03:25:22.225 - 03:25:23.365, Speaker B: Strange. Okay.
03:25:26.385 - 03:25:59.695, Speaker A: It'S because Reddit knows your shenanigans. No, YouTube knows your shenanigans here. I'm so happy about optional slice. Oh, I guess slice from pointer is the thing you could use in order to avoid the clone as well. Although I think that that is still unsafe. I see. So this is branch free as well.
03:25:59.695 - 03:26:47.435, Speaker A: Okay. Yeah, I guess, I guess I can see that. So it's a safe way that avoids a clone and also avoids a branch. So it's just a sort of very low overhead implementation of this pattern. I still don't know what it's useful for, but I like the addition. The other thing I had was, and this is sort of a minor, minor little improvement, which is now if you run Cargo new inside of a workspace, it will automatically add the new crate you created to the list of members in the workspace.
03:26:47.975 - 03:26:52.429, Speaker B: That's nice. We'll also add the inherit workspace blind your car.
03:26:52.477 - 03:27:26.911, Speaker A: I don't think so. No, it'll. But it will add the path to the members list. But I think that's all it adds. At least if I, if I look at the diff here out cargo toml members. No, it doesn't add anything to the dependency or to the. To the new crate.
03:27:26.911 - 03:28:05.035, Speaker A: It just modifies the cargo tunnel of the workspace. And then another one I saw, and this one is, is pretty cool. I think you might have opinions on this one, Ben, which is now, uh, when you match on a U size or I think in general it's like U size and eye size, um, then now you no longer get an error. If your range, if your aim, if your ranges are exhaustive because you have a half open range in both directions, for example, then Rust now knows that your matching is exhaustive.
03:28:06.135 - 03:28:06.543, Speaker B: Very.
03:28:06.599 - 03:28:30.815, Speaker A: So the example they give here is that if you have a match of a usize and you have a single arm and it's 0 dot dot, then Rust will be happy with your code. But if you write for example match over usize, you write 0dot.usize max it will complain that you didn't cover usize max. So it actually catches that. That that version is not exhaustive.
03:28:32.035 - 03:28:32.975, Speaker B: Very cool.
03:28:35.085 - 03:28:53.845, Speaker A: I don't know how smart it is. Like if I did an ARM that's like a zero or an arm that's until four and an arm that's five and onwards, would it then still catch that it's exhaustive? I guess it's. It's easy to test.
03:28:53.885 - 03:28:55.425, Speaker B: Try it out. Try.
03:28:57.125 - 03:29:41.559, Speaker A: It. Let's see. Let's first of all switch this be light so that it's easier to see for chat and then make it bigger. So if I do a. If I do a match on 0, use size and I do 0, I do 1 to 5 and I do 6 onwards. Is it happy? I need to write correct Rust, it's happy. And if I do seven, what does it say? Non exhaustive pattern six is not covered.
03:29:41.559 - 03:30:29.007, Speaker A: Nice. That's cool. I like that. And then this last one I saw, which I'm surprised got buried, but it's really neat. So Rust will now automatically enable cross crate inlining for small functions. So one of the things that's interesting here is when you have. Because Rust compiles every crate separately, when you have a function in one crate that calls a function from another crate, the function from the other crate does not get inlined into the caller unless that function specifically says, you know, has the attribute inline.
03:30:29.007 - 03:30:56.693, Speaker A: If it doesn't, then Rust will not inline it into the caller. But that changed in Rust 175. Now there's like a little bit more of a heuristic to decide when to actually allow an inline. And it goes beyond just it needs to have the attribute. And this matters a lot for smaller functions where the cost of calling them might actually dominate the cost of them executing. So inlining could have a huge advantage, right?
03:30:56.789 - 03:31:41.089, Speaker B: To dig a bit deeper there, inlining the thing that LLVM performs. And it has heuristics generally to say whether or not it should be inline, because inline can easily make your code slower if you do it wrong. Rust, whatever it tries to inline things. It doesn't necessarily have the code needed to inline a thing. But sometimes it does though. And so in your case, to invalidate what you just said, if you have a generic function, it can inline those things sometimes because in order to monomorphize generic function, it already has to encode the code required for the actual body of the function in an abstract way, so that information already exists. And so normally the role of the inline attribute is to make that information exist.
03:31:41.089 - 03:32:02.379, Speaker B: Like you had, like it was a generic function. And then also inline always if you want to force it to be inline, which is often a bad idea and you shouldn't do that. And this case just says, hey, like we'll, you know, we don't need you to actually mark it as inline. We'll just automatically let export the metadata if you have a small enough function, which I'm curious to know what small means, but maybe it's kind of just a good enough.
03:32:02.497 - 03:32:25.235, Speaker A: The PR is pretty vague about what small means. I think what it specifically says is we only infer in line ability for functions whose optimized mirror does not contain any calls or. Asserts. So it's functions that don't make any other function calls. Yeah.
03:32:27.455 - 03:32:36.183, Speaker B: Well, there's also some. You still don't want to. If you have a giant function, you still probably wouldn't want to inline that. And so there probably is some. Still some size constraint. Yeah.
03:32:36.199 - 03:32:41.995, Speaker A: But I think it's interesting, right, because how large of a function can you write where it doesn't call any other functions?
03:32:42.775 - 03:33:17.715, Speaker B: Well, I know that. So I mean you just have like, you know, I guess is math. Like are intrinsic like two plus two, like, you know, is that really a function call? Depends on how they define it, right? I think so in Go, the language Go, they have their own heuristic where it's just like if you are one statement and so it's like statement oriented. And so again it's a heuristic. And I think in JavaScript it's like the number of bytes that your function body is, which includes comments because it's JavaScript. And so if you need to take comments out of your code, if you want your code to be inlined more by the jit, that's their heuristic. Right.
03:33:17.715 - 03:33:20.347, Speaker B: And so it's all people guessing what might be good.
03:33:20.531 - 03:33:47.995, Speaker A: Yeah, I mean the PR does say that the heuristic that's implemented in this first PR is deliberative, deliberately conservative, and that the plan is to adjust this over time as they come up with a better heuristic. But at least now there is a heuristic as opposed to. If your function isn't generic, you have to put the inline attribute there if you want it to be inlined. I think that's all I had for 175. Do you have anything else?
03:33:50.295 - 03:34:14.377, Speaker B: So in Cargo news, E page wanted to highlight that. Okay, here's a cool thing. PSA, right? So terminals, right? Made in the 70s before there was an idea of what colors were. The world was all black and white back then. And at some point they realized, hey, colors are cool. Let's add these weird little antsy escape codes where now you can have blue things in your terminal. The background can be bright or whatever, right.
03:34:14.377 - 03:35:03.087, Speaker B: So there's so many of these. And one of the things you'd never think about is that your terminal probably supports hyperlinks. And so if you like, you might need to in your terminal, if you see a link, try holding control and mousing over it and see if it highlights it and click on it and see if it actually opens it in your browser for terminals to support it. Cargo is now emitting the anti escape codes to hyperlink various things. Example is if you run Cargo build timings, it generates a graph of the timings just to figure out where's my compile time being spent when I build this thing. And it makes it as an HTML file which is locally loaded by your computer. And now in certain browsers or in certain terminals, you can open that with hyperlink support and just click on it and open it immediately.
03:35:03.087 - 03:35:05.895, Speaker B: And so it's kind of just a nice little quality of life thing.
03:35:06.055 - 03:35:16.965, Speaker A: Yeah, that is really nice. I didn't even realize that you needed specific ANSI escape codes for this to work. I thought it was the terminal auto detection feature. Regex match.
03:35:17.125 - 03:35:37.585, Speaker B: Some terminals do. I imagine you probably could in some terminals, but I think that in this case the output of Cargo build timings is not like a web address. There's no HTTPs, there's no protocol field. It looks like a path. It's just a path that ends in HTML.
03:35:38.085 - 03:35:43.395, Speaker A: I see. Because it's a local path. Oh, that's really interesting.
03:35:44.455 - 03:35:55.075, Speaker B: By the way. Try out right now. Go to your favorite crate and do cargo bill dash of timings and check out the output. It's like a lovely little web app they've made here. Very simple and clean.
03:35:56.215 - 03:36:02.527, Speaker A: Let's do dev miner. What do we have here? Let's do a tone. What am I doing?
03:36:02.631 - 03:36:04.855, Speaker B: Cargo, Cargo build timings.
03:36:04.935 - 03:36:12.209, Speaker A: Build timings. No, it's not a link.
03:36:12.257 - 03:36:14.393, Speaker B: Your terminal support. Not a link.
03:36:14.489 - 03:36:16.233, Speaker A: My terminal does support links.
03:36:16.289 - 03:36:20.017, Speaker B: But what terminal you're using and what like you're using a tmuxer.
03:36:20.121 - 03:36:21.993, Speaker A: This is TMUX and Alacrity.
03:36:22.169 - 03:36:30.505, Speaker B: Yeah, they mentioned that TMUX does not currently support these and so it's probably turned off, but apparently Z does. So.
03:36:30.585 - 03:36:43.895, Speaker A: But I got my timing though. Look at that. Look at that timing graph. This crate has no dependencies. It's cogen was 0.0 seconds.
03:36:44.755 - 03:36:49.855, Speaker B: It might do a cargo clean first because it might be saying, hey, like you. You have everything is totally cached.
03:36:51.795 - 03:36:58.695, Speaker A: No, but it like literally this crate has no dependencies. Okay, but I can find you one that does. This one does.
03:37:08.365 - 03:37:08.693, Speaker B: Yeah.
03:37:08.709 - 03:37:15.025, Speaker A: So here there are dependencies. Scale, scale more. More.
03:37:16.325 - 03:37:18.105, Speaker B: It might change the graph down below.
03:37:19.405 - 03:37:22.385, Speaker A: Oh yeah. But why is it so scrunched?
03:37:22.925 - 03:37:26.611, Speaker B: Maybe you. You scaled it because your scale. Try turning it back down.
03:37:26.643 - 03:37:29.755, Speaker A: But if I scale it down, it's worse. It's more of a lot.
03:37:29.795 - 03:37:30.615, Speaker B: Oh, I see.
03:37:31.755 - 03:37:34.563, Speaker A: I need to scale it more, but I can't scale it enough.
03:37:34.739 - 03:37:39.415, Speaker B: Well, it's all HTML, just like hack the control shift C. That's right. Hack the code.
03:37:40.395 - 03:37:49.571, Speaker A: Nice. All right, in that case, how about we move on to 176? There were no point releases for 175.
03:37:49.643 - 03:37:50.861, Speaker B: No points at this time.
03:37:51.003 - 03:37:57.285, Speaker A: So we should move on to a quick break. And we also definitely check in on our pr.
03:37:58.145 - 03:38:00.833, Speaker B: Right, let's see the pr. The saga continues.
03:38:01.009 - 03:38:10.817, Speaker A: Saga continues. Refresh, just in case. Still only three hearts. Wow. This thread. I resolved it as people are happy to resolve it. Yes, seems so.
03:38:10.817 - 03:38:16.365, Speaker A: That's good. So now it's just waiting on CI.
03:38:17.755 - 03:38:21.171, Speaker B: Okay. Is it all squashed and ready to merge? Once one approves it, yeah.
03:38:21.243 - 03:38:22.895, Speaker A: I mean there's only one commit.
03:38:25.355 - 03:38:26.215, Speaker B: All right.
03:38:26.595 - 03:38:27.775, Speaker A: I think there's hope.
03:38:28.275 - 03:38:29.415, Speaker B: Bring up the.
03:38:29.755 - 03:38:37.815, Speaker A: Oh, it's got a. It's got a tada now. Nice. Yeah. Let me bring up Boris.
03:38:38.155 - 03:38:40.179, Speaker B: If people haven't looked at the build.
03:38:40.227 - 03:38:59.925, Speaker A: Bot, what is it? Homu. No, it's boars.rustlang.org and then search for string. This guy.
03:39:01.745 - 03:39:17.421, Speaker B: Right. So if you ever want to see what is currently being worked on in Rust CI, you can just come to this page and see what's there, what's currently been approved or is in the process of building or what might roll up soon or merge or that kind of stuff. So yeah, it's a great little page.
03:39:17.533 - 03:39:25.301, Speaker A: It is at least mergeable. I'll take that. All right then. I'm going to get some water and be back.
03:39:25.493 - 03:39:27.185, Speaker B: All right, Drink.
03:42:25.835 - 03:42:52.035, Speaker A: All right, let's check in on the pr. Oh, all checks have passed. Now we just need Boars. Now we just need Boris. Although Boris will probably take a while before it runs our thing. It's so far down the list. I guess.
03:42:52.035 - 03:43:16.345, Speaker A: Actually it doesn't get run until it gets approved. Anyway, starting to panic. Yeah, I know. Is that I. I love that pause message. So good. Let's see here.
03:43:16.345 - 03:43:39.713, Speaker A: Oh, we only have three more releases. What are we at time wise? Let's see, it's 8. 14. We started at 4. 14 my times. It's. No, we started at 4.
03:43:39.713 - 03:43:58.205, Speaker A: Let's call it 45. That's not too bad. It's not too bad. Three and a half hours. Yeah, my guess was five hours and I think we're gonna be pretty close to five hours.
03:44:03.145 - 03:44:03.965, Speaker B: Oh.
03:44:11.025 - 03:47:32.885, Speaker A: I still think maybe there's hope. Maybe it won't land because the Bors queue is pretty long, but maybe It'll be R plused by the time the stream is done. See how many bennies you can see. There's so many. Bend.
03:47:45.715 - 03:47:47.059, Speaker B: Marathon continues.
03:47:47.147 - 03:48:07.508, Speaker A: I know, right? Well, we only have three left. I think my original estimate of five hours is roughly right. Also, 176 is going to be pretty short, I think. Oh, good call. I should have done the same. 176 is pretty short. 177 is like medium.
03:48:07.508 - 03:48:24.515, Speaker A: And 178 I think is decently large. And also our, the CI on our Mr. Has passed. It's all green. So now we just need, now we just need to be approved so it gets to run.
03:48:24.555 - 03:48:25.895, Speaker B: Make it a roll up pr.
03:48:26.315 - 03:48:29.787, Speaker A: So yeah, so it might land sooner. It's true.
03:48:29.971 - 03:48:57.877, Speaker B: People, people who don't know the Rust terminology. You know, Rust runs CI every PR. But some PRs are like obviously not going to cause problems. And so you can say, hey, roll this up. In which case a roll up PR is let's take like 10 PRs, merge them all together and then test them just once. And then because we're pretty sure these aren't going to fail, just like just a matter of policy, we always test every PR that lands, but these ones aren't going to cause a problem. And so just together, test them once.
03:48:57.877 - 03:49:15.849, Speaker B: And that is one of the most efficient ways of actually getting PRs through. Because on every. Testing every PR, I guess every configuration of Rust on every platform actually takes a while. And so PRs are how things get done. Do you have the ability to tell Boris, do a roll up?
03:49:16.017 - 03:49:22.561, Speaker A: No. Well, I was wondering whether I can tell Boris that this should be a roll up because I can't r it.
03:49:22.593 - 03:49:27.827, Speaker B: Probably not, but you can request the person who approved it to come through just like ping them and say, hey.
03:49:27.921 - 03:49:38.375, Speaker A: Yeah, but I don't really want to ping them. That feels, that makes me feel bad. We'll see. I'll give them some time.
03:49:38.415 - 03:49:42.031, Speaker B: Leave a comment. Maybe you're saying, hey, if anyone wants to make us a roll up, go ahead.
03:49:42.223 - 03:49:57.045, Speaker A: Yeah, no, I'm just gonna leave it. I don't wanna.
03:49:59.665 - 03:50:04.497, Speaker B: What's occurring, queue position or Q.
03:50:04.561 - 03:50:06.625, Speaker A: Well, we're not approved, so we don't.
03:50:06.705 - 03:50:11.073, Speaker B: We're not queued to run, so it'll be last. There's currently six things in the queue.
03:50:11.209 - 03:50:56.425, Speaker A: But there is a roll up coming. Right, so. Well, we're not gonna be part of that roll up. But there's always a rollout. Yeah, I wish, I wish Rusta or no, I wish Boris had a wait for the author to Indicate that they think it should be a roll up in the future, but I don't think it does. Oh, maybe it does. Maybe you could do it separately from our plus.
03:50:56.425 - 03:51:43.685, Speaker A: Let me try. Do I need to also? No. Let's see what Bor says. Wow. Boris just threw the key at me. The cat sniffing.
03:51:46.305 - 03:51:47.205, Speaker B: She is.
03:51:49.505 - 03:52:18.975, Speaker A: Yeah. My cat also always wants to sniff. Generally dislikes everything she smells, but she wants to sniff anyway. I can make you bigger so people can see more. Cat.
03:52:26.565 - 03:52:27.385, Speaker B: Retreat.
03:52:40.365 - 03:52:59.315, Speaker A: Nailed it. And then. And then the tail that just goes past. All right, let's see. 176. I guess we got a new. Do another intro.
03:53:01.935 - 03:53:06.175, Speaker B: So we're gonna do about the. The fact that we have three. We're gonna try and lift all three.
03:53:06.335 - 03:53:18.215, Speaker A: No, I think we should do two. I think we should do two. And then we should do 178 on its own. Because obviously this was all planned for us to get to a cadence of one episode per episode. One release per episode.
03:53:18.255 - 03:53:21.715, Speaker B: Okay. Oh, yeah, okay. Sure.
03:53:22.375 - 03:53:24.635, Speaker A: This is all planned, Ben. Remember?
03:53:25.615 - 03:53:27.955, Speaker B: Oh, my. Your plans, your machinations are.
03:53:31.295 - 03:53:52.445, Speaker A: All right, let's see. Wow. Only chat only now caught up to the cat. Okay, here we go. All right, Ben. Welcome to 2024.
03:53:55.065 - 03:53:58.897, Speaker B: John, I don't know about you, but for me time is slipping. It's an illusion.
03:53:59.001 - 03:54:09.765, Speaker A: I know, I know. It feels like. It feels like we were just in 2023 for a number of reasons. And yet 2024 feels oddly familiar.
03:54:10.355 - 03:54:13.763, Speaker B: It's almost like we were on a thread that was slept for a few weeks.
03:54:13.899 - 03:54:29.739, Speaker A: That's right. That's right. 176 is actually a pretty small release. And the release knows acknowledge this. So they say this release is relatively minor, but as always, even incremental improvements lead to a greater whole. I like that a lot.
03:54:29.907 - 03:54:34.523, Speaker B: The previous one came out like December 28th, and so this one was like, during the holidays.
03:54:34.619 - 03:54:35.965, Speaker A: Yep, pretty much.
03:54:36.045 - 03:54:50.437, Speaker B: And so it's like, you know what this is like, you know, this began being developed at Christmas and then had like two weeks of just being holidays. And so it's like, you know what? Maybe it's totally fine. People take their holidays and have a smaller release once in a while.
03:54:50.621 - 03:55:29.505, Speaker A: And I think, you know, this is one of the things that you end up with when you have regular release trains is that some releases are bigger than others. But that's fine. There's always another release later. And it's also fine to have some releases that are small. The first one, in fact, is entirely a documentation change, or almost entirely at Least which is the ABI compatibility updates. So there's now sort of in the function pointer documentation, there's a new section on ABI compatibility that just describes what it means for function signatures to be ABI compatible. Do you want to talk about what ABIs are, Ben?
03:55:30.985 - 03:55:34.257, Speaker B: Sure. So this should be easy, right?
03:55:34.321 - 03:55:35.257, Speaker A: Cover this real quick.
03:55:35.321 - 03:56:31.097, Speaker B: If you, you've heard of APIs, right? Like, you know, if you're like, you know, I guess, you know, my experience as people who have done like, you know, coding boot camps is that APIs are like the big thing that you would do in programming. It's kind of like you have an API and you attach a thing to it, right? And you can think of maybe an a, an ABI as like a very low level API where it's like, you know, imagine assembly as to JavaScript is ABI as to an API where an API is a very broad thing. It could be a JSON endpoint or a server, or it could be in rust, some method, some function on options. Very abstract. We're calling this function the ABI is how it actually happens under the hood. That's how your platform knows your OS knows that when you call this function, what's actually happening there is a stack somewhere and there are arguments on that stack and as a return value and something happens. I need to actually read what's compatible in here, what they are now specifying.
03:56:31.097 - 03:57:09.411, Speaker B: But the idea here is that generally the ABI is how your system knows how to call a function. There are some things in there too. It might know how data is laid out in memory in some cases, but mostly for the purposes of calling a function. It differs from platform to platform even for C and C. They aren't like there's no actual de Jor standards, only de facto standards that some compilers have implemented. And if you are a compiler, you do need to know how to actually do this or invent your own way of doing it. I believe Clang and GCC agree on what to do for C and C, but other than that there's no stable abi.
03:57:09.411 - 03:58:16.501, Speaker B: So if you're compiling C on your own random compiler for a totally random platform, it's not a stable thing. And having a stable API is kind of a. It's difficult. And so the Swift language has a stable API, which they can do because they went to monumental effort and years of breaking changes and like language design contortions to like make a thing that works pretty well if you're on an Apple platform, right? And so but what it gives Them is the ability to say, hey, like, you know, what's cool about being API compatible, Like, du jour Swift has, and de facto C has, is that if you have a library over here compiled with one version of some random compiler, and a library over here with a different version of some other random compiler, you can link them together and it all works out. There's no mismatch between what this function, this binary, expects from this way of calling into this thing. Rust does not have that. Notably the default API, the abi, for a Rust function that you export from a library, it can change between compiler versions.
03:58:16.501 - 03:58:58.085, Speaker B: And if there was more than one Rust compiler in use, it could change between compilers too. The idea here is that normally in Rust, if you want to do this thing where you have one version of Rust, C has compiled this, one version of Rust, C has compiled this, and link them together, you need to use the API that is, and say, hey, we're going to export for it, we're going to pretend that we're C. And because C is de facto stable and everyone agrees on this one platform compiler, what a C thing should look like at the binary level, then we can just, you know, it doesn't matter that you have two versions of Rust C, they're both, you know, they're using the stable C abi. And so I'm not sure is this case that again, I haven't actually even read what this is yet. Is this about the Rust abi?
03:58:58.205 - 03:59:07.925, Speaker A: Yeah. So this is specifically documenting the Rust ABI for the purposes of, I think, function pointers in Rust to Rust calls.
03:59:08.425 - 04:00:08.211, Speaker B: Right. Again, Rust doesn't have a wholly stable API, but there are some parts of Rust that are stable. For example, if you have an option that contains a reference that is always going to be guaranteed by the compiler, that will always be just a pointer at runtime. You can rely on this for things like if you wanted to optimize your code like that, there are a handful of things that are guaranteed. And so again, it's not the entire API, because stabilizing entire API is a monumental task that also constrains you a lot in the future with what you can actually provide. So one of the reasons that Rust does not say, guarantee the layout of struct fields, unlike C, for example, is because, oh, sometimes we can achieve sweetups if we actually go through and rearrange your structs for you, which is actually really important for generic code, in fact. So staying unstable in some cases is good for performance, also good for flexibility in the future.
04:00:08.211 - 04:00:43.873, Speaker B: Of oh, we realize a new way of doing this, that we would be bringing change if we had a stable abi, which you can see in C is actually a big problem. We're trying to evolve the language while remaining ABI stable is one of the biggest problems in C. It's actually like one of the things that holds them back the most. And there's a lot of people who are kind of like, just break it. Who cares? Folks were like, no, no, no, don't do that. And so one of the biggest rifts, I think in terms of modern day driving folks to have post C things like carbon or seafront or like a CPP front. I'm not sure what it's called herbs such as thing, but is like the debate over like should we have a stable abi and Russell don't have that.
04:00:43.873 - 04:00:53.417, Speaker B: But I mean people so kind of like, hey, it does. We could guarantee that a CARE is always a U32. That's kind of nice to have. Right. Is there any risk with that? It's kind of like not really. Which I think is what's happening here. Right.
04:00:53.417 - 04:01:02.525, Speaker B: They're saying hey, like, you know, in this case we can just, it's not a problem. Just say, hey, in the future, going forward, we'll always guarantee that a care and a U32 have the same ABI. So you can use them interchangeably.
04:01:02.945 - 04:01:50.499, Speaker A: Yeah. And yeah, I think it's important too to stress that an ABI does not guarantee semantic compatibility. Right. It's not saying that the, you know, if you, if there's some function that's defined in some other thing that is built by Rust C that you link against and then you define a, you know, a header or the function definition for that remotely defined function. Then if you declare one argument as a star mut and they declare it as a ref mu t, then those are ABI compatible. Like the two signatures are ABI compatible, but you still can't call it with something that violates the guarantees on the other end. If you do, you end up with undefined behavior.
04:01:50.499 - 04:02:40.697, Speaker A: But it's not ABI incompatible. It is just the semantics of the thing you're calling are wrong or like you're calling them and not meeting all of its, its semantic requirements. ABI is purely on the sort of mechanical level of how is this function actually called or executed. And I think in this particular Rust release, basically all that they did was document the guarantees that they do and do not give. Things like, you know, star const t and star mute t are ABI compatible. Or, you know, an i32 is ABI compatible with a non zero i32. And similarly, things that are not guaranteed like i32 and F32 are not compatible with each other, even though there's the same number of bytes, they're not ABI compatible.
04:02:40.697 - 04:02:51.525, Speaker A: I think the only thing that they changed is what. What Ben was alluding to as well is that car and U32 are now guaranteed to be ABI compatible.
04:02:52.185 - 04:02:54.609, Speaker B: You say car Care.
04:02:54.777 - 04:02:55.369, Speaker A: Char.
04:02:55.497 - 04:02:56.553, Speaker B: I say care.
04:02:56.729 - 04:03:04.975, Speaker A: Care. Oh, it's. It's too hard. Character. Is that not how you pronounce it? Character.
04:03:06.075 - 04:03:06.867, Speaker B: Character.
04:03:06.931 - 04:03:31.023, Speaker A: A character. Yeah, I think that's how it's definitely pronounced. The next thing in Rust176 is type names from. For. From references. So in the standard library, there's long been this function called in the std, any module called type name. It's a generic function that takes no arguments.
04:03:31.023 - 04:04:05.111, Speaker A: You call the function with a generic type parameter and it will. It will return to you a string representation of that type. So the idea is that this is handy for like, debug purposes. If you just want to print out what a given type is. You can't really guarantee on this being like, unique for different types necessarily. It is just a debugging tool, I think, since Rust 138. But the problem with type name with that's generic over T and takes no arguments, is that you can't always name the type that you want to print.
04:04:05.111 - 04:04:45.895, Speaker A: Sometimes, like if you're in like a macro or in some kind of generic code, you don't have a handle to that type. You can't put it in there in the generic type parameters. And so in rust176 they added a function called typename of val which takes a reference to any T and then it prints out the type name of that T. So if you have an instance of a type, you can now also print the name of that type. So this is more of a. This is sort of an extension to the debugging tool for the cases where you can't name that generic type in the first place. Think of things like a closure, for instance, that you couldn't name and pass to a the type name function that just takes a generic type parameter.
04:04:45.895 - 04:05:21.105, Speaker A: Iterators being in other example that commonly come up like especially iterators that either use impul trait like impulse iterator or that have like closures inside of them, so you can't really name them. And when I said that this was a short release, I wasn't Kidding. Like Those are the two mainline things in 176 that sort of made it into the release notes. And then we have a couple of stabilized APIs that we can talk about, but that's sort of the end of the major things they wanted to get across. Do any of the stabilized APIs stick out to you, particularly here? Ben.
04:05:22.965 - 04:05:24.945, Speaker B: Let me go through real quick.
04:05:27.605 - 04:05:30.345, Speaker A: I think one that struck me actually. Oh, go ahead.
04:05:30.765 - 04:06:28.133, Speaker B: I was going to say if you don't know what the inspect function is, it's a cool little debugging thing where normally you wouldn't use this for normal code. What's stabilized in this release is result inspect and option inspect. Normally the inspect the thing that you would do if you had an iterator and you had a chain of things you're mapping, folding, doing things, you just want to know, hey, somewhere in this chain what's actually the value of everything? You can do an inspect, it will just give you a thing. It'd be pass a closure to inspect and then it'll give you the value of whatever it is currently at that point in the pipeline. And then you can have it, you know, do like a print line or a debug dbg, right? And just like have it, you know, see what it is. And that's kind of all you want to do with it, right? And just a way of debugging your pipelines or your iterator chains saying hey, like you know right now, what is the value of this? And so it's a little thing you should know about. And results and option are iterators technically.
04:06:28.133 - 04:06:30.785, Speaker B: And so you can inspect those two.
04:06:31.465 - 04:07:25.127, Speaker A: And I think the other thing that's neat about this, right, is that the alternative is really painful. So if you have some, you're doing a bunch of map and folds and stuff, or even if it's not iterators, you're doing a bunch of map and thens and map errors. If you actually wanted to print out what it is partway through something, then the way you would have to do it before is break up your chain of function calls and do if let sum equals and then print the thing or just print the whole thing and then continue your chain. Whereas with inspect you can just sort of inject the dot inspect along the sort of chained function calls and the inspect just gets a reference to the current value, does not return anything and does not change the thing that's inside the result or the option. It's just like as Ben says, sort of inject the debug point into Your code, that's really handy, right?
04:07:25.151 - 04:07:47.997, Speaker B: And also it only runs the closure that you pass it for Inspect if in the result case, if it's an okay, and in the option case if it's a sum, right. And so it's already unwrapped for you, you're not going to get like debug of a sum 42 or a none. It's going to be like 42 or no error in there too. So yeah, inspect error, if you wanted that.
04:07:48.151 - 04:08:20.435, Speaker A: Yeah. So someone pointed out in chat too that one of the things you could do, right, and before we got inspect is you could dot map DBG of the input value. So DBG takes a value and debug, prints it and then returns it. So it is semantically the same. The nice thing with Inspect is that you don't have to also deal with returning it. So if you wanted to do something else, you wanted to like print line it, but in hex or something that you could do that pretty easily. Whereas with the map case you have to have something that actually returns the value to continue the chain.
04:08:21.695 - 04:08:34.955, Speaker B: Right? And so the closure that you pass to Inspect, it has no return value and it gives you a thing by immutable reference. And so it's kind of hard to mutate. And so you're not going to be using this for any kind of actual work. It's just for side effects.
04:08:35.735 - 04:09:04.639, Speaker A: Another thing that got stabilized is the unwrap or clone function for ARC and rc. And this one is, you know, also just mostly a convenience thing. Like you. There's nothing you couldn't do here with stable code before. But the idea is that if you have an ARC and you want to get an owned version of the things that inside the arc. So let's say you had a. You know, an ARC of a bool is a bad example because it's copy.
04:09:04.639 - 04:09:13.373, Speaker A: But you have an ARC of a file. Then imagine you wanted a clone of the underlying file. File is bad too, because it doesn't.
04:09:13.429 - 04:09:15.265, Speaker B: You can't clone a file string.
04:09:15.805 - 04:09:48.775, Speaker A: Yeah, you're right. Arc a string. Fine, fine, fine. Okay, you have an ARC of a string and you want to get an owned version of the underlying string. So you could just call dot clone and then you would take get a reference to the string behind the arc, you would be cloning it. So you allocate a new string, you copy over all the bytes and now you have a known string. But there's an optimization you can do here, which is if you are the only one holding the ARC like there are no other references to this arc, then you can just sort of steal the string from inside this arc and drop that arc.
04:09:48.775 - 04:10:07.645, Speaker A: And then that way you, in the case where you are the only owner, you don't need to do an allocation, you don't need to do a copy. And so unwrapper clone implements this behavior. So the idea being that if you own the ARC and no one else's references to it, then you get the inner value. Otherwise it clones the value that's inside and gives you back the clone.
04:10:08.105 - 04:10:12.305, Speaker B: It's kind of like if you know what copy and write is, this is kind of a copy on read, so.
04:10:12.465 - 04:10:20.809, Speaker A: Yeah, exactly. Right. Do you know anything about this default hasher and random state being moved into STD hash?
04:10:20.857 - 04:10:41.465, Speaker B: It's just exported. I'm not sure it's been moved. I think it's just that they have now export them from insert library. There is both a standard hash thing and a standard collections hash map. Right. And so I believe it's probably just now exposing these things that are exceptionally hashes from the standard hash module.
04:10:42.125 - 04:11:12.585, Speaker A: Yeah, I guess the motivation originally was that the default hasher and random state were really just almost implementation details of hashmap. They weren't really something that you should use for other things. They were just used for hashmaps but they needed to be public because they were part of the public type signatures of hashmaps. And I guess the reason they moved into STD hash or were re exported into STD hash were presumably because they recognized that actually the default hasher might be useful for other things as well.
04:11:13.325 - 04:11:31.175, Speaker B: I think these aren't newly exposed and so default hasher and these things are from 1.7. And so it's just that this is just announcing that they now are available in new places. They have been, they have been moved and their old, I believe locations have become typedefs to the new locations.
04:11:31.795 - 04:11:40.535, Speaker A: I guess what I'm getting at is I'm wondering why they were moved. Like presumably that's an acknowledgement that these types are useful beyond just hashmap collections.
04:11:41.355 - 04:11:54.417, Speaker B: Okay. I mean, yeah, I don't know. Like if you, if you have a hash and you want to get the state, I think, you know, it's, you know, fine to say, hey, it's independent of hash maps because hashes are useful for things.
04:11:54.561 - 04:12:09.565, Speaker A: Yeah, the only thing that's tricky, right, the default hasher is like non defined. Like it doesn't define which hasher it's using, so you can't really rely on it. Producing any particular hash, which is usually what you use hashing for. Right.
04:12:11.105 - 04:12:33.855, Speaker B: But it's the hasher used by random state, which is, again, you know, that's true. A thing that is specific to. I mean, there is that hilarious hack where if you have. If you don't want to pull in a dependency for rng, I just want to have a random value. Well, random. Random state. Random state for hashes is random per thread.
04:12:35.235 - 04:12:39.619, Speaker A: That's terrible. Ben, you should not be telling people this. They will start using it for a long time.
04:12:39.707 - 04:12:46.327, Speaker B: Tokyo did this because they didn't want to have a dependency on random. So I don't know if they still do it, but they did for a long time.
04:12:46.471 - 04:12:47.455, Speaker A: That's funny.
04:12:47.615 - 04:12:57.035, Speaker B: I mean, I want randomness. I don't need the ran crate entirely. But what I want is all of the underlying entropy sources to be available from std. I think it should be in standard IO.
04:12:57.415 - 04:13:10.837, Speaker A: Yeah, I mean, you're not. You're not wrong. You're not wrong. There's another thing that's added here, which is pointer adder equals. That I thought was an interesting addition. No, it's a function. So it.
04:13:10.837 - 04:13:41.185, Speaker A: It's a function that takes two star consts and it checks whether they point to the same address. So it does not change whether check whether their values are the same, but whether they point to the same address for the data section of them. And looking at the docs here, it specifically is, I think relevant for FAT pointers. So if you have fat pointer, this will only compare the data section and not the other part, like the length for slices or the vtable for trait objects.
04:13:42.245 - 04:13:54.213, Speaker B: Interesting. So if you had a vector and you took two different slices to it and one slice was longer than the other, they would not compare equals, but they would compare, add or equals, right?
04:13:54.229 - 04:13:54.397, Speaker A: Yes.
04:13:54.421 - 04:13:55.381, Speaker B: Is that how it goes?
04:13:55.453 - 04:13:55.765, Speaker A: Yep.
04:13:55.805 - 04:13:56.425, Speaker B: Okay.
04:13:58.445 - 04:15:00.233, Speaker A: And similarly, if you had two DIN references for different traits, but they were actually the same underlying object, then they would add or equal the same. Like I construct a foo and foo implements the two traits bar and baz. And so I create a ref DIN bar from foo and a ref DIN baz from foo. So from the same foo, then those two ref dins would add or ik because they're pointing out the same foo, even though they have different vtables. And I think this is probably in preparation for the. The stabilization of things like pointer metadata, which we don't really have yet, but it's sort of getting there of the ability to specifically get at the two parts of a FAT pointer. Like the sort of metadata associated with the vtable, for example.
04:15:00.233 - 04:15:31.875, Speaker A: And breaking that apart from the data pointer, would the someone in chat is asking would the expectation be that in something like Cherry, this would compare the address portion of two capabilities? I think so. I don't know whether this is going to also be architecture dependent or whether it's just talking about specifically Rust fat pointers. I'm guessing probably only the data portion of Rust fat pointers and not extend architecture.
04:15:31.955 - 04:15:57.029, Speaker B: Right. I feel like, because Cherry. It's a matter of semantics. Right. Like do we consider Cherry pointers fat pointers or thin pointers? I kind of assuming that they'd be thin pointers. I think we mostly care in the Rust case. Are these what Rust considers fat pointers and and not what the OS considers metadata in a pointer? Yeah, I don't know.
04:15:57.029 - 04:15:58.141, Speaker B: It's a good question.
04:15:58.293 - 04:16:07.469, Speaker A: Yeah, it is curious. I do wonder, when we see the implementation of adder eq, is it going to be architecture dependent?
04:16:07.597 - 04:16:29.421, Speaker B: Well, yeah, let's look at the implement right now. So it's a single line adder equal. It's just we cast each pointer to star construction nil and then we compare them and so it's kind of like throwing away imagining that this was a pointer to nil. What is the actual address which seems like in Sherry would create a thin pointer like a fat pointer.
04:16:29.493 - 04:16:30.701, Speaker A: Yeah, I think that's probably.
04:16:30.853 - 04:16:37.837, Speaker B: I'm not sure from user space you could really modify even like kernel space shouldn't be able to mess with metadata in a sharing point.
04:16:37.861 - 04:16:48.075, Speaker A: Yeah, I think you're right. I think you're right. It would be weird, right, if Rust started masking out bits of the pointer before comparing them, depending on your architecture.
04:16:48.455 - 04:16:52.395, Speaker B: Yeah, I guess it's arguable what they want or what people need this for.
04:16:57.215 - 04:17:41.387, Speaker A: Apart from that, I don't think there's anything that stuck out to me, although I think we've talked about basically all of the stabilized APIs at this point, so I guess they were all interesting. In the change log there was only really one thing that stuck out to me, which was another Rustock improvement. They're really just Rustock is on fire these days, which is that they now allow resizing the sidebar and hiding the top bar in Rustock, which was not previously the case, but now you can drag and pull on the sidebar and get rid of the top bar to really, really focus in on the reading. Did you find anything in the Reddit thread this time that people are particularly excited about?
04:17:41.411 - 04:17:43.339, Speaker B: People just like happy About Inspect.
04:17:43.507 - 04:17:43.883, Speaker A: Nice.
04:17:43.939 - 04:17:46.667, Speaker B: So functional. Programmers were rejoicing.
04:17:46.771 - 04:17:54.859, Speaker A: Yeah, that checks out. In that case, I think we can jump straight to 177. This one was a piece of cake.
04:17:54.947 - 04:17:58.375, Speaker B: Yeah. Easy, easy. Intermission.
04:17:58.855 - 04:18:03.327, Speaker A: Yeah, we need the intermission tune again. What intermission tune do you want to do this time?
04:18:03.431 - 04:18:07.855, Speaker B: We can. We can all light it. It's like a no op this time. And so rust scene has optimized out the intermission.
04:18:07.975 - 04:18:22.355, Speaker A: No, I have a. I have a perfect intermission. Which is. Which is the Pokemon center healing sound when you bring in your Pokemon. Yep. Which feels like a good intermission. Right.
04:18:22.355 - 04:18:44.605, Speaker A: So we're forwarding our brains now, Ben. We have to do something we've never done before, which is time travel from February until March of 2024. And in 177, the first thing that we got is C string literals. What are C strings, Ben?
04:18:45.705 - 04:19:08.355, Speaker B: Right, so C strings were a mistake. Anyway, there's. Back in the 70s, there were two different ways of thinking about. Okay, well, we have a string. It's a bunch of data. It's a buffer full of data. How long is this buffer? Who should be responsible for determining how long this is when you want to read it? There's the Pascal way of doing it, and there's the C way of doing it.
04:19:08.355 - 04:19:24.861, Speaker B: The C way of doing it is you have your bytes in a row. When you get to a null, that's the end. How do you store a null in your string? Just don't do that. And the Pascal way of doing it is you have metadata, which kind of like rust slices. It's just. It's literally the exact same thing. Rust slices, where you have, you know, your string is a fat pointer.
04:19:24.861 - 04:19:49.659, Speaker B: It has the capacity up front, and then you have the data. Right. And again, it's, you know, in 70s. And so your capacity might be limited to like, you know, I don't know, a single byte possibly. And so not, you know, ideal Citrink could be longer in theory. Right. But I think, you know, nowadays people have realized, oh, it's actually kind of a big problem to have these null terminated strings where if you look at like, you know, I want to concatenate 2c strings.
04:19:49.659 - 04:20:06.147, Speaker B: Be careful how you do that. Yeah, I want to, like, you know, I want to slice it. Be careful how you do that especially we're kind of like, oh, okay, great, I have a C string. Let's just take a substring of that. And now let's run off the end of memory. Because there's no null anywhere in that because we sliced off the end which had the null on it. And it's kind of just like, you know what, maybe we should just care about the length of the.
04:20:06.147 - 04:20:36.837, Speaker B: How things hold their data, about how long they are, if we need to have that. But if you want to interact with C, you need C strings. There are types for these. There's both C STR and cstring, which are the same things as STR and string, and Rust, where one is a view and one is the actual allocation behind it backing it. But they have null terminators on them, so you can safely pass them to and from C. And this is just a way of making them have support for string literals. Right.
04:20:36.837 - 04:21:11.875, Speaker B: And so in the past, I assume you would have had to do like, see, like how you might see string, you know, capital S string, colon, colon from a literal. And I assume the past, you had to do a C string colon, colon from. And then like, you know, maybe have it as ref to get a C STR out of it. In this case, now you can just put the letter lowercase C your string data, end quote, quote. And this is using the feature of Rust 2021, which allows you to have arbitrary prefixes, allows the compiler to reserve the syntax to put prefixes on top of string literals. That was my rfc, so you're welcome.
04:21:12.655 - 04:21:15.075, Speaker A: Thank you, Ben. When are we getting F strings?
04:21:15.615 - 04:21:20.235, Speaker B: F strings? That's beyond me. I wrote the RFC for F strings and.
04:21:22.375 - 04:21:40.499, Speaker A: Someday I think the argument for C string literals rather is specifically that it allows you to not have to do an allocation. Right? So if you have a. If you have a standard Rust literal and you try to turn it into a C STR with like C string from.
04:21:40.587 - 04:21:42.275, Speaker B: It's too short. You need one more byte.
04:21:42.355 - 04:21:52.691, Speaker A: Yeah, exactly. You need one more byte. And so therefore you can no longer use the thing that you had in memory. You need to allocate a thing and then you need to copy all the bytes over and then add a null at the end.
04:21:52.883 - 04:22:11.309, Speaker B: I believe that some languages like it might be go might do. I'm not sure if it's go or not, so it could be lying here. But some languages that are Pascal, like where they keep the buffer length around, you always allocate a null at the end, just to be safe, in case you cast it to a C string and there's going to be a null somewhere. So that's one thing Rust could have done.
04:22:11.477 - 04:22:20.505, Speaker A: I am curious how this interacts with. So we have byte strings, we have the B prefix. Do you know how B and C interact here?
04:22:21.165 - 04:22:29.097, Speaker B: I would conservatively say start with just an MVP and don't let them interact. But I mean, try it. Pull up your playground.
04:22:29.241 - 04:22:40.439, Speaker A: I'm guessing that they don't, right? Because a C string is. It already returns a C str and a B string just makes it return. A U8 returns.
04:22:40.535 - 04:22:42.765, Speaker B: Yeah, the U8 slice.
04:22:44.105 - 04:22:46.313, Speaker A: So if I do maybe it returns.
04:22:46.329 - 04:22:49.643, Speaker B: A null terminated U8 slice, which I mean is a thing that you might want from mc.
04:22:49.779 - 04:22:52.347, Speaker A: So let's see, what if I wouldn't.
04:22:52.371 - 04:22:58.323, Speaker B: Even say I would do like, you know, let colon nil equals BC and see what it spits out at you.
04:22:58.419 - 04:23:08.323, Speaker A: Well, I was going to do this. Okay, so if I print line colon, colon X question marks to get the.
04:23:08.339 - 04:23:11.219, Speaker B: Hex name of VAL thing, it was stabilized.
04:23:11.307 - 04:23:55.672, Speaker A: Oh yeah, you're right. I guess I can do that instead. So STD any type of VAL bifu. This is too many characters to type run. Type of what? Of Val. It's type name of Val type name of Val. That's a U83.
04:23:55.672 - 04:24:10.345, Speaker A: Okay, so a B foo gives you a UA3, that's fine. A C foo gives you a core FFI C string seir a B seafood does not compile. Prefix BC is unknown.
04:24:10.505 - 04:24:14.313, Speaker B: Could we do raw? Can we do RC foo?
04:24:14.449 - 04:24:24.125, Speaker A: Oh, RC foo. RC is also unknown. What about CR.
04:24:26.065 - 04:24:28.465, Speaker B: Works? There we go. So it's CF. Is it CR?
04:24:28.625 - 04:24:37.197, Speaker A: Okay, so there you go. So R meaning that you don't get any escaping in there and double quotes don't have to be escaped.
04:24:37.381 - 04:24:40.845, Speaker B: I assume BR is the same way. Where you can't do rb, you must do br.
04:24:41.005 - 04:24:55.821, Speaker A: Yeah, probably R, B, R works, RB does not. That makes sense, right? Because I think the R needs to be next to the delimiter that you want to use the.
04:24:56.013 - 04:24:58.589, Speaker B: The hash maps, the octothorps. Sorry.
04:24:58.717 - 04:25:32.515, Speaker A: Yeah, interesting. Okay, the next thing that we got in 177 is support for recursion in asynchronous functions. And here I think this is one of those things that has been an open issue for a while. So this didn't really have anything to do with the sort of async offending traits or anything. This was purely about asynchronous functions recursing. Do you know why this didn't work or why this was difficult?
04:25:34.055 - 04:25:45.175, Speaker B: Async functions is compiled to state machines, right? So I see no reason why a state machine couldn't loop over itself. It says they could not call themselves. It's possible that it was a name.
04:25:45.215 - 04:25:59.155, Speaker A: Resolution well, they certainly need to be sized, right? So if you have an async fn food that calls itself, then how much space do you allocate in the state machine for the future? That foo returns when you call it recursively.
04:25:59.235 - 04:26:00.763, Speaker B: So the state machine is calling.
04:26:00.899 - 04:26:06.819, Speaker A: Yeah, so you do need some kind of indirection here, which this also points to. Like, you need to, like, box pin.
04:26:06.867 - 04:26:09.147, Speaker B: Your call to sell requires indirection.
04:26:09.251 - 04:26:29.265, Speaker A: So it requires indirection. I guess my. What I'm wondering is why it was hard before. Like, if you did do the indirection, why was that not sufficient? And it might be because it, like, didn't recognize that the box pin, for example, was sufficient to make it sized. I'm not sure.
04:26:32.045 - 04:26:33.101, Speaker B: Oh, we have.
04:26:33.293 - 04:26:57.879, Speaker A: We have Nils in chat. This is helpful. So Nil says the problem was that the coroutine. I'll prefix this with the same prefixes, which is. If I recall correctly, the problem was that the coroutine witness type used for auto traits, et cetera, contained the stuff in itself, causing it to be recursive. Causing an infinite type that doesn't work. Oh, I see.
04:26:57.879 - 04:27:33.131, Speaker A: So it's not about what you put in the state machine. It is the type that expresses the type of the state machine. That type ended up having a recursive type in its name, and so it got confused. So even though the state machine would actually be sized, the type signature, if you will, or the type of. The type of the state machine would infinitely recurse. And I guess that has now been fixed. And presumably the fix is to add a similar kind of indirection to the state machine type as well.
04:27:33.131 - 04:27:47.865, Speaker A: Or the witness type, as it's called. Nice. This seems like an obvious win. Previously you could not have recursive async functions, and now you can have asynchronous functions that recurse. That seems pretty great.
04:27:48.445 - 04:27:54.197, Speaker B: Great. Then Neil Streeb, while you're here, if you want to roll up our PR so we can get it merged before the stream ends.
04:27:54.381 - 04:27:57.905, Speaker A: Aha. It has been R plus rollup.
04:27:58.205 - 04:28:02.413, Speaker B: Oh, great. Saga continues.
04:28:02.589 - 04:28:22.085, Speaker A: This is great. Meow once or twice for them. Now we even have a real cat. See, the problem is if I meow, then Sophie might come and attack Ben, don't worry. Oh, damn it. Excellent. Okay, our PR is on its way to be.
04:28:22.085 - 04:28:37.369, Speaker A: To be rolled up and merged. This is pretty exciting. All right, let's go look. All right, home. What do we got? Yeah, it's here. It's down here. We have a.
04:28:37.369 - 04:28:56.623, Speaker A: But there are a bunch of roll up always. So there There might be hope, but we're behind these guys though now. We'll see. We'll see. It's a, it's. The race is on low priority, so that seems reasonable. Okay, next thing in 177 is a good one.
04:28:56.623 - 04:29:03.215, Speaker A: Yeah, this one's good. Offset of this is a macro. What is this? Bend. And also why is it needed?
04:29:04.555 - 04:29:14.531, Speaker B: Right. And so it's one of those things that, like, you know, if you're a C programmer, you think about all the time. In rust, generally not so much. So, okay, let's imagine you have a struct.
04:29:14.683 - 04:29:16.307, Speaker A: Okay, I'm imagining it.
04:29:16.411 - 04:29:18.339, Speaker B: You're imagining in your mind palace you've got a struct.
04:29:18.387 - 04:29:19.003, Speaker A: I have a struct.
04:29:19.059 - 04:29:36.745, Speaker B: Okay. And it has two fields. You have like, you know, a U8 and they're both UAS X and Y. They're both UAS for point structs. Classic. So you take the address of that struct because of the way that things are lit up memory. The address of the struct is also the address of the first element in that struct.
04:29:36.745 - 04:30:03.575, Speaker B: What's the address of the second element in the struct? Well, you could just get the field and take the address. But if you want to know for more arcane reasons, you're doing something some other lower level stuff. The offset of macro is a way of getting the offset of any field in a struct. If you already know the point of the struct, it probably even requires. Is it the type name or is it the type?
04:30:03.695 - 04:30:04.831, Speaker A: The type name Type.
04:30:04.863 - 04:30:21.475, Speaker B: Okay. Yeah. So it's. And the idea is talked about this before is that in Rust, the ABI discussion, Rust ABI isn't stable. It's allowed to change over time. And in fact, if you have a generic type, then every instantiation of that type might have a different field order that's allowed. I'm not sure if axure does that, but it is allowed.
04:30:21.475 - 04:30:59.817, Speaker B: Offset of is a way of saying, hey, for this type, what actually is the number of bytes from the start of the address where I can find this field? If you want to go in there and do any kind of unsafe code which requires it sometimes, generally, I think before you could make it a repr C structure and then just like count the bits and then know which is how you do it. In C In C there is offset of. In C I don't write that much C. I don't do that kind of offset of level stuff, but it exists certainly. I'm not sure if it's in C or C. It exists, I think in.
04:30:59.841 - 04:31:08.325, Speaker A: C. Okay, so then the obvious follow up question, Ben is why is this not take a reference to the field, take a reference to the start of the struct and just subtract the two.
04:31:11.195 - 04:31:16.415, Speaker B: I mean, for the same reason that it exists in C, right?
04:31:17.675 - 04:31:31.403, Speaker A: Yeah. And I think that the leading part of the question here is because of packed fields or packed structs. So references in Rust have to be aligned. They are not allowed to be unaligned accesses.
04:31:31.459 - 04:31:32.275, Speaker B: Oh, there you go.
04:31:32.395 - 04:32:03.571, Speaker A: If you have a struct that has the little repper packed on it, then Rust is forced to put all the fields next to each other with no padding in between. This could mean that if you have a U64 field then it. It's supposed to be aligned as a U64. So it's supposed to be aligned on an 8 byte boundary. So an 8 byte aligned address. But in a packed struct it might be at like a 4 byte alignment or something. Rust does not allow references to such fields and in fact it is.
04:32:03.571 - 04:32:49.283, Speaker A: It used to be the Rust would allow you taking those references. That's now disallowed because it's just wrong. It's. It violates a validity invariant of Rust references. This gets complicated because people don't generally know that this is the case. So if you were to implement offset of yourself and you tried to take a reference of the field and then subtract, you know, turn it into a pointer and subtract that reference, subtract the pointer to the start of the struct, then you've actually gone into undefined behavior because you took a reference to a packed field and so the offset off macro understands how to compute this without taking any references. So you just give the name of the struct and the name of the field and it gives you what the offset is.
04:32:49.283 - 04:33:05.465, Speaker A: And I think there is a variant of it that takes a pointer to a struct instead in a field and does the same thing. But again with the particular sneaky trick that allows it to never take a reference to a packed field and so still give you the value in a. In a safe way.
04:33:07.885 - 04:33:17.709, Speaker B: I don't know about that. There is a pointer offset method. Is that what you mean? I don't see an offset of variant that takes a reference. So maybe it's nightly only.
04:33:17.757 - 04:33:23.075, Speaker A: I don't know. I'm thinking of is it adder of?
04:33:24.375 - 04:33:31.807, Speaker B: There's. There's add or of is a thing. But again, another reason you know that exists is because it's not always safe to take a reference and cast it to an unsafe pointer.
04:33:31.911 - 04:34:15.837, Speaker A: Right? So that. That was my point that you can take. You use add or of and you give it a. If you have a foo, let's say a variable foo that is a pointer to a packed struct and you want to get the address of the field x of that packed str, you have to call adder the adder of macro add of foo x. You cannot do reference adder x as star const. That would be undefined behavior because you're taking a reference to an unaligned field. And so that's why you need the add of macro and then moving on from dark incantations of alignment of pointers.
04:34:15.837 - 04:35:34.088, Speaker A: The next thing we have is a cargo change which is to enable strip in release profiles by default. There's a lot to unpack here, but the basic setting here is that cargo allows you to set a bunch of options in cargo toml for basically how to compile your crate, things like how much debug info to include, what debug info to remove, what level of optimizations to use, etc. One thing that's pretty common to set is to set debug equals zero for release builds where you don't want to include any debug info in your release build so that your binary ends up smaller. But where this gets tricky is that the standard library in Rust is pre compiled. It ships like from Rust to your computer with debug info in it, but also built in release mode. And so in your final binary, when you linked the program you built with the standard library, you now end up with a binary that does still have some debug info in it, even though you Specify Debug equals 0 in your in your cargo toml or cargo config. And so the change that happened in 177 is that now in by default, in release profiles which have debug equals zero, it also now sets strip equals debug info.
04:35:34.088 - 04:35:50.825, Speaker A: So again, this is not a change like whenever you set debug equals zero, it's specifically in the release profile that ships by default with cargo, it will now strip the debug info from your entire binary, including what comes with the standard library. You can opt back into it. But that's sort of the change that landed.
04:35:51.685 - 04:35:59.885, Speaker B: Well, I believe that if you had. If you were already at that, I believe the release profile already had debug equals zero. It was just. This is just library stuff.
04:35:59.925 - 04:36:08.556, Speaker A: Yep, that's Right, Yeah, so it already did have debug equals zero, but it would still keep the debug info from the standard library. And so that's the thing that you.
04:36:08.580 - 04:36:34.825, Speaker B: Often see in people comparing the size of Rust binaries or like I want to make a smaller Rust binary. The first thing you always do is you use the Strip tool in your environment. I'm not sure what it's called on Windows or Mac or whatever. Right. But it's called Strip in Linux and you just kind of like cuts out all the text sections that probably aren't needed. And yeah, generally real drastic improvements to binary size, but improvements. If you don't want that info, if you do want it, then keep it around.
04:36:34.825 - 04:36:48.453, Speaker B: That's why it's in the first place. But yeah, so this does it by default. So yeah, it's a nice little. It should hopefully result in some people writing blog posts about Rust binary size to give rustliss a hard time.
04:36:48.589 - 04:36:59.185, Speaker A: Well, I think in past releases too, we've talked about this idea of split debug info. Right. So the debug info going into a separate file, which obviously also helps with this in a less severe way.
04:37:01.085 - 04:37:08.677, Speaker B: I'm not sure if that's like, you know, that's like how it works by default on Windows and I think Mac it is now supported. I'm not sure how well it's supported on Linux.
04:37:08.821 - 04:37:10.305, Speaker A: Yeah, I don't remember either.
04:37:13.165 - 04:37:25.778, Speaker B: We should be reading the chat here too. There they give us nuggets of information. Right. I want to call back to the. Previously I mentioned before that I said maybe it was golang. That always allocates a null after every string. Someone saying that's not go.
04:37:25.778 - 04:37:30.694, Speaker B: Not sure which language is, but some language out there that does this. Right.
04:37:32.634 - 04:37:47.054, Speaker A: I think we're then to stabilized APIs. Ooh, we have a core net module. What's core net? Oh, this is just all of the IP stuff that has moved into Core. Is that right?
04:37:47.705 - 04:38:04.145, Speaker B: Right. And so it's not like, you know, it's not about, you know, doing. The idea of Core versus STD split is that, you know, core is the thing you don't need an OS for. And one of the things you need an OS for is like, you know, networking probably. You probably don't have like, you know, a driver for a network card in your like bare metal OS unless you want to provide it yourself. Right. And so, but these are the types.
04:38:04.145 - 04:38:22.505, Speaker B: And so this is what, if you are writing an OS in Rust, say this is what would let you write Your own module using only Core, your own networking library using only Core is compatible with the rest of the world of things written in Rust. And so yeah, it's just moving the types here.
04:38:22.845 - 04:38:37.825, Speaker A: Yep. And presumably because, well, like the IP address type has nothing to do with the OS, it is just how to turn like a U32 into an IPv4 address or a U128 into an IPv6 address.
04:38:38.725 - 04:38:59.344, Speaker B: So like we're not here to open sockets, we're just here to turn a tuple of some U32s into a struct of U32s. Effectively. Yeah, I definitely, at my job we definitely took use of this because we are implementing. You have a no STD thing where we implement a network stack. So yeah, that's cool.
04:38:59.504 - 04:39:32.814, Speaker A: Nice. I think we also have a candidate here for a pretty obscure function which is F32 round ties even so this is if you have an F32, you call this function in order to round numbers such that a number that is exactly halfway between one integer and the next gets rounded to the even of those two integers. That feels pretty. Pretty specific.
04:39:32.984 - 04:40:04.285, Speaker B: Just some of these case, the idea of rounding in floating point is difficult in the first place. There's all kinds of quote unquote wrong ways to do it. If you care about statistics, it's like, well, if you always round down, then your negative number is going to be a little bit lower on average than your positive numbers. If you always round towards zero, then okay, well depending on the vagaries of how flitting represent, it might have something. And so I think this. I don't know the exact reason behind what this specific way of rounding provides, but I think some people really want this.
04:40:04.445 - 04:40:41.131, Speaker A: Yeah, I'm sure there was probably a demand for this. I can't think of the use case, but I'm sure there is one. We've also got another cool function that was added here which is clear. Poison was added to Mutex in RW lock. And you know, the notion of a poisoned lock is something the Rust has where if a thread panics while it's holding a mutex or read a writer lock, then the mutex gets poisoned. Then the. And if you try to take a poisoned Mutex then you also panic.
04:40:41.131 - 04:41:47.801, Speaker A: The idea here being that, you know, if a thread panics while holding the lock, who knows what state the data inside of that mutex now is in, like the thread might have. Let's say you have a Mutex over some struct that has two fields and the thread Updates one of the fields and then it's supposed to update the other field to be consistent with the first, but it panicked in between. Then now, you know, it releases the mutex, but because it panicked, the Mutex is in an inconsistent state. And so the idea of poison is to make sure that that sort of idea of the Mutex now being tainted moves on to other threads, and that if they try to access it, they also panic instead of doing something wrong. The thinking behind clear poison for this is if you have something that detects that a mutex has been poisoned and then realizes that it has some way to recover from that mistake, it can, like put the state in the Mutex back together into consistent state. It can then call clear poison on the Mutex to indicate that you no longer need to have threads panic when they take this lock anymore. Because I've fixed the state, which previously I think was just not possible.
04:41:47.801 - 04:42:27.085, Speaker A: Or maybe you could replace the mutex with a new mutex, but that's not always an option. So this seems like a nice sort of ability to do something we couldn't do before. We've also gotten a helper for file. So on file, you have the create method and you have the open method. So open is open a file that already exists, and create is make a file at this path. But create tells us this weird property where it's sort of a create or overwrite. Like if a file already exists here, then create a new empty file there and sort of truncate the old file.
04:42:27.085 - 04:42:50.315, Speaker A: And if no file exists, then make a new one. But what this new method, create new does is it will only create the file if it does not already exist. So we'll never truncate an existing file sort of accidentally, if you will. It was possible to do this before. So there's a. There's a type in the standard library called open options. I think that's the name of it.
04:42:50.315 - 04:43:24.375, Speaker A: Yeah. So if you call file colon colon options, you get back this type called open options that allows you to configure how a file should be open. Things like, should we error if it already exists? Should we truncate a file if it already exists? Should we? Well, a bunch of different properties you can set for the file open. And so you were able to do this, but it required this, like really long chain of builder methods on open options to get it. And so now you just have a simple helper method to say, I just want this file to be created and I want it to be an error. If that would overwrite something.
04:43:24.835 - 04:43:39.465, Speaker B: I think also the important thing here is that there might be. It might not possible to actually do this right now. Where the intent of this method, I believe is to prevent the case where you check to the file exists and then the file suddenly exists and then you open it.
04:43:40.285 - 04:43:45.261, Speaker A: So that is still possible with File Options. So with file Options with create new.
04:43:45.293 - 04:43:47.301, Speaker B: Is designed to prevent that. And so it's atomic.
04:43:47.413 - 04:43:50.853, Speaker A: No, no, no, that's not what I mean. So with File Options you can achieve the same outcome.
04:43:50.909 - 04:43:51.365, Speaker B: Oh, can you?
04:43:51.405 - 04:43:53.357, Speaker A: So yeah, so with File Options, file.
04:43:53.381 - 04:43:57.027, Speaker B: Doesn'T exist and it'll like stop it if you get a negative result, it'll stop it from existing.
04:43:57.131 - 04:44:47.405, Speaker A: So, so File options is more like you configure the single call to the kernel that's going to do open. So it's not a sequence of things that you do. File Options is more like a builder for the one call to open that you will do. So you can do, you know, file colon colon options. You get back in open options and then you call dot read true dot write true dot CREATE true dot TRUNCATE false and then dot open and then that final call to open is like a build and that is the one atomic point where something happens or doesn't happen. And then there's a bunch of chunking methods on slices that I don't think are too interesting to talk about. They're useful if you need them, but I don't think it's worth diving too deep into.
04:44:47.405 - 04:44:51.455, Speaker A: So I think we're down to the changelog then.
04:44:54.035 - 04:45:19.609, Speaker B: While you're looking at the changelog, I want to go through here on Reddit before we're talking about what is offsetofgoodfrom. Someone here is saying their use case for offsetof is they need to make sure that the structs that they define match up with some spec and something they're using. And so they have asserteq offset of they guarantee that the offset is what they think and then you can because asserts are now usable in context these days these could be compile time asserts.
04:45:19.737 - 04:45:20.817, Speaker A: Oh, that's really cool.
04:45:20.881 - 04:45:22.245, Speaker B: And so yeah.
04:45:26.985 - 04:46:09.555, Speaker A: Yeah, looking at the change log, one of the things that came up was to disallow references to static mutes. And this I think puts on all of all of Ben's alarm bells when it comes to static mutes, which is a static mute is a static. So it's completely global state that is also mutable. So you have mutable global state, which is awful in all sorts of ways. And one of the things that's really interesting when you have a static mute is that it is always unsafe to access, right? Because it's global mutable from any thread, so it has to be unsafe. But it's interesting because it's. It's undefined behavior to even take a reference to a static mute.
04:46:09.555 - 04:46:32.223, Speaker A: Because the whole point of a static mute is someone can just mutate it out of nowhere. It's global. And that means that taking a reference to it could be immediately undefined behavior if someone else is modifying it, even if you're not reading from it. And so I don't know whether this landed as a thing that will happen only in the next edition or whether it actually landed in 177 like the.
04:46:32.359 - 04:46:34.479, Speaker B: Chase warning that landed.
04:46:34.647 - 04:46:38.875, Speaker A: Yeah, it might just be the one. Yeah, you should never be doing this.
04:46:39.495 - 04:47:02.495, Speaker B: I mean, if you are a binary crate and you can guarantee that you never use threading. So the invariant. So it's unsafe. The invariant you need to uphold for unsafe static mute whenever you access them is that there must only ever be one thread in this process. So the only person who can possibly uphold this is the binary. If you ever write a library with static mute, don't.
04:47:02.795 - 04:47:12.455, Speaker A: Yep, yep. Especially if it's a mute that's also gnome angle, then you're just setting yourself up for failure.
04:47:14.395 - 04:47:14.683, Speaker B: But.
04:47:14.699 - 04:47:32.525, Speaker A: So I thought it was just an interesting observation that even creating a reference to a static mute is very often just like instant undefined behavior. And so that is at least now linted against, if not outright denied, or at least it will probably be denied in an upcoming edition.
04:47:33.145 - 04:48:01.065, Speaker B: To be clear, the idea is that if you need static mute and you need to actually wherever you need it for you, I need this. There are alternatives that aren't static mute you can use. There are patterns where you can have a version of unsafe cell that is just like sync, but that can be static. And then you just put that in a normal static. You don't have a static mute, you have a static. And then you can do the usual unsafe cell thing to better uphold the invariants and take references to it, because that's safe. That's guaranteed to be safe.
04:48:01.365 - 04:48:10.105, Speaker A: I think there's even a nightly only type, at least for now, called sync unsafe cell that is specifically for this kind of purpose.
04:48:10.445 - 04:48:39.633, Speaker B: Yeah, if you look back on the deprecate static mute issue in Rust, which I might have been the one to file like 10 years ago, the answer is people are like, hey, well I need this though. What can I do instead? And people are talking about, hey, there's this idea that's called Sync Unsafe Cell. We could just use this, and we should have been shipping it years and years ago. But those things that nobody ever gets around to. I think for a long time people were waiting. For a long time we couldn't. Constructors in statics were anemic.
04:48:39.633 - 04:48:50.325, Speaker B: And so we couldn't do. For a long time we couldn't do foo, colon, colon, new. Because there weren't const fns back then. And so it was kind of like, well, until we have const fns, there's no point in trying to pursue this.
04:48:50.905 - 04:49:24.517, Speaker A: It's like this whole chain of dependencies until it becomes actually realistic. This next one I thought was interesting because I think it's the first time I've seen an example of undeprecating a lint. So there's a lint called Unstable Features, which is specifically intended to be. To indicate that you should not be using Unstable features in your code because they are unstable. They only work on Nightly. And this lint was being deprecated because. Well, it was just.
04:49:24.517 - 04:50:18.015, Speaker A: I think it was just implemented in the compiler that you can't call Unstable Features when you're not on Nightly. It wasn't really a lint, but now they've decided to bring it back as a lint because there are some of the crates in Rust C that they want to compile on Stable because they're used by Rust Analyzer, which has a no Nightly policy, and they want to deny it then. So they want to deny Unstable features in this crate, but they needed to be a lint because Rust cbootstrap is set to one for the Rust build. So it's very easy to accidentally use Unstable Features in those crates. And if you did, it wouldn't be caught by rustci, but it would end up negatively impacting Rust Analyzer. And so they want to bring this lint back and then deny it in those crates.
04:50:23.515 - 04:50:31.723, Speaker B: That's kind of funny. Yeah, I can see it. I mean, like, you know. Yeah, Bootstrapper. Weird. And a pain in the butt in many ways.
04:50:31.779 - 04:51:07.135, Speaker A: Yeah. Yeah. Specifically, it's like the Rusty Lexer and the Rusty Parse format crates that they're that are used outside of Rusty, like by Rust Analyzer. And then there was another, and this one has a bunch more history to it that people can dig into if they're curious about it. And I think you were part of this discussion too. I think I saw your name mentioned here somewhere, which is always a terrifying thing to say. But we'll See, so this is deny braced macro invocations in let else.
04:51:07.135 - 04:51:57.357, Speaker A: So specifically, the thing to deny is if you have, you know, we talked about let else earlier, but the idea is that if you have something like, you know, let pattern equals expression else diverging branch, the expression is not allowed to be a macro invocation that uses curly brackets. And in particular the idea here is that the the original RFC for let else said that the expression in a let else is not allowed to end in a curly bracket. And the implementation in the compiler until Rust177 disallowed all sorts of contracts that end in curly brackets except for macro invocations. And so now this finally sort of closes the hole and also denies braced macro invocations as the expression in a let el.
04:51:57.531 - 04:52:27.699, Speaker B: Yeah. So for the reference, if you have a macro, little known Rust tip is let's say the vec macro. You know, the vec macro making a vec and you know, vec exclamation point, square bracket, right? It's like a square bracket, like an array, right? But macros don't care what bracket you use. You can do vec exclamation point, parenthesis, you can use vec exclamation point, curly bracket. It's all just a matter of convention, right? It's no actual enforcement of any of this. And so there's never a case where you need to invoke a macro with curly bracelet. You can always use a different bracket there.
04:52:27.699 - 04:52:59.067, Speaker B: So I'm not sure, I'm sure there's some parsing reason to do this. Rust kind of in some ways does bend over backwards to make to do things with brackets. And so for example, I think there's some weirdness in the Rust grammar with regard to if and struct literals where, like maybe you can't use them together in certain ways unless you do a certain thing like parentheses around it. Maybe that's been lifted years ago, I don't even know. But back in the day, like 1.0, it was kind of like, oh crap, our grammar is ambiguous with regards to if and then some struct literal happens. It's kind of like we just got to get rid of this.
04:52:59.067 - 04:53:10.363, Speaker B: Just require premises around it. And so yeah, there's been a. It turns out keyboard just need more bracket types, right? Only three is not enough angle brackets, not even enough. We need more than that.
04:53:10.499 - 04:54:04.833, Speaker A: Well, so clicking through this one a little bit, I got to this comment by David Tolnay and it says based on a suggestion in Zulip by B Street shortly before the publication of this rfc. So who knows? But. But the. I think the long and short of it is that the One of the reasons why they want to disallow any expression that ends with a curly bracket in let else is so that it is always possible to distinguish when you look at the else clause, whether this is an else for an if or an else for a let else. Because if you disallow could be if. Right, Exactly. And how to read the else branch really differs depending on whether it's a let else or the else for an if.
04:54:04.833 - 04:54:22.975, Speaker A: Because if it's an else for an if, you know that the code is going to continue executing after. But if it's a let else, you know it's going to diverge. But if they both start with end curly bracket else start curly bracket. Just as a human, it's harder to understand what's going on from a glance. And so that I think was one of the primary reasons.
04:54:23.355 - 04:54:29.135, Speaker B: Let some foo equals if and then suddenly done done have an else in the end.
04:54:30.235 - 04:55:03.372, Speaker A: And so this is where the original RFC just said no ending curly brackets in the expression. And then over the sort of time since the RFC landed, there have been a bunch of changes that limit what kind of expressions you can have in there. But there was been like disallow block expression, disallow loops, disallow conditionals, but ultimately there was nothing that captures anything that ends with a curly bracket. And so macro invocations were missed as a sort of missing case there that are now finally denied in 177.
04:55:03.769 - 04:55:07.336, Speaker B: And then.
04:55:07.733 - 04:55:51.685, Speaker A: Right, so 177 is when we finally got support for Cargo Colon colon, which we talked about ages ago, you know, like almost half a year ago. Ben, if you remember the. The move from cargo with a single colon until cargo with a double colon for cargo instructions from Build scripts in order to allow them to extend the set of invocations that you can have from build scripts. So that landed in 177. This one I don't think it's worth talking about, so I'm going to skip it. This one is also not worth talking about. I think that's all I had for 177.
04:55:51.685 - 04:55:56.405, Speaker A: Do you have anything else from the Reddit thread?
04:55:58.125 - 04:56:21.341, Speaker B: Hmm. So I talked before about some of the supply chain security, you know, stuff that's kind of like moving through the world of programming. And apparently in this one, Cargo metadata now uses the same format as cargo package ID for identifying packages, which unlocks passing IDs to other cargo commands and cross referencing this data within the cargo.
04:56:21.413 - 04:56:28.373, Speaker A: Lock file, this is one of the PRs I had open. It was like, it's not worth talking about. But I guess if Reddit is excited about it, we can talk about it.
04:56:28.469 - 04:56:37.029, Speaker B: 75 people uploaded this. All right. System is I guess getting centralizing on things, so it's nice.
04:56:37.117 - 04:57:19.875, Speaker A: It's pretty fast to talk about. So Cargo has traditionally had a couple of different ways to name a specific version of a specific crate that were used. There was a different way to specify that in the output of cargo metadata and the input of cargo commands and what appears in lock files, they weren't all like fully aligned with each other. And with 177, all of these now use the exact same format for describing a specific version of a specific crate in your dependency graph. And so by making them all have the same representation, you can now like read an ID out of cargo metadata and pass it into something like cargo update P. And it all just sort of works because they're all the same format.
04:57:23.615 - 04:57:40.035, Speaker B: And then with regard to the new stabilized APIs, some of the slice stuff, I saw someone be excited about those. Let's see. So chunk by and first chunk. Oh yeah.
04:57:42.015 - 04:58:25.535, Speaker A: Yeah. So this is stuff that I think used to be in ITER tools and now it's sort of in the standard library. So chunk by, for example on slice takes a predicate function and returns an iterator over the slice, producing non overlapping runs of elements using the predicate to separate them. Oh, I see. So it's like iterates over a slice and uses the function to check adjacent elements. And if the adjacent elements return, if the function returns false for two adjacent elements, then it considers everything up to that point a chunk and it considers starting there a new chunk.
04:58:26.355 - 04:58:32.531, Speaker B: It's only for adjacent things. And so it's not like doing a passover first and then coming back and doing it. It's still all in memory. Single pass?
04:58:32.603 - 04:58:47.855, Speaker A: I think so, yeah. Not sure what it's used for though. I guess you can use it to find runs of elements, right? Like give me all the numbers that are sequences of numbers that are the same in this slice.
04:58:51.275 - 04:59:11.005, Speaker B: And then I guess, you know, first chunk on slice is a says, you know, array first chunk obviously behaves similar to array split at actually array split at checked but is great for avoiding try into casts when you're going from slices to arrays. So.
04:59:11.905 - 04:59:46.097, Speaker A: Oh, interesting. Oh, I see what this does. Okay, so this is a method. I'm excited about this now too. So you take a, you have a slice, you Call first chunk on the slice and it's const generic over some n and it gives you back an array, a reference to an array of the slice item type of length n or none. So it's an option of that. And so if the slice is at least n long, then it gives you back an array reference of that length.
04:59:46.097 - 05:00:19.203, Speaker A: Otherwise it returns none. And if you were to do this with the array from slice instead, what you get back is. Or rather in the try from implementation that exists on arrays from slices, you get back a result instead. And so you need to like unwrap the result rather than getting just an option straight away. But I mean, I don't care that much whether I get a result or an option. I think they're both. They're both the monad.
05:00:19.203 - 05:00:33.267, Speaker A: So I think, I think we can move on then to 177.1. We got a point release.
05:00:33.451 - 05:00:36.135, Speaker B: We've actually. We have two point releases for this.
05:00:36.475 - 05:00:38.491, Speaker A: Oh wow. Okay.
05:00:38.523 - 05:00:42.940, Speaker B: The first one is features in 77. So it's natural.
05:00:43.055 - 05:00:58.923, Speaker A: Yeah. 77.1 it looks like just doesn't work on Windows or was broken on Windows with the MSVC toolchain. Yep. Debug stripping does not behave in the.
05:00:58.979 - 05:01:00.027, Speaker B: Probably too strong.
05:01:00.131 - 05:01:11.015, Speaker A: It says debugging. Debugging for stripping does not behave in the expected way on Windows with Ms. Vc. What does behave in the expected way?
05:01:18.295 - 05:01:23.599, Speaker B: They might have totally broken backtraces on Windows or only msvc. That is so.
05:01:23.687 - 05:01:28.399, Speaker A: Oh yeah, it does look like it broke backtraces for Windows, which is funny.
05:01:28.447 - 05:01:32.755, Speaker B: Because like Windows has a split debug info to begin with and so they don't even really care about stripping.
05:01:33.695 - 05:01:48.537, Speaker A: That's interesting. Okay, so 77.1 just disabled the new cargo behavior on Windows for targets that use MSVC. Great. So that one's straightforward. And then we got 77.2. This was.
05:01:48.537 - 05:02:35.935, Speaker A: Oh, this was a CVE fix for. Okay, there's a little bit of context needed here. So on Windows, when you. Or in general when you spawn a process from inside any language. But when you spawn a process, the way that you do so is OS dependent. And the way that you pass arguments to like a program that you execute programmatically is also different depending on the platforms. In C on I think all platforms it goes via or at least on Linux, the way that you pass arguments to a program is you put them in this particular part of memory.
05:02:35.935 - 05:03:45.495, Speaker A: When you execute the thing in the system call to Linux, you pass in the arguments and Linux makes sure that they end up in a Way in a place in the memory of the newly created process where LIBC knows to look for them. And crucially, it's an array of string pointers. This means that the arguments have well defined boundaries. So if I pass two arguments to you, it's not as though they're like white space split or something. They are two separate pointers to string literals that end up in my address space. And so I can clearly tell what is the first argument, what is the second on Windows specifically for certain kinds of executables, like specifically things that need to be invoked via CMD exe. So things like BAT files and CMD files, those you have to execute through CMD exe, which means you have to pass the arguments as a single string and then you have to escape them so that they match the argument splitting logic of CMD exe.
05:03:45.495 - 05:04:56.511, Speaker A: And it turned out that the way that Rust was escaping the arguments specifically for BAT and CMD files on Windows was slightly wrong, such that an attacker could inject arguments that caused CMD exe to execute arbitrary code. So it was like potentially pretty bad if you were passing arguments sort of blind trustedly from users into these kinds of programs. On Windows, it was fixed. There's a bunch of write up about why this happened and the kind of escaping that's needed and some of the subtleties around exactly when it triggers. But the fix in 77.2 was not really to fix the escaping to make it perfect, but rather to acknowledge that sometimes the escaping can't be perfect and then we will actually issue an error when you try to execute such a program rather than allowing it to go through with potentially some things being unescaped. Oh, someone in chat is saying that Windows is always a single string for the arguments.
05:04:56.511 - 05:05:14.005, Speaker A: It's just that the escaping logic for CMD is just different. That's even worse and scarier. So depending on whether you're executing a command, bat file file, or just executing some other program, you need to escape the argument list differently. That's rough.
05:05:14.305 - 05:05:15.045, Speaker B: Strange.
05:05:15.585 - 05:05:16.685, Speaker A: Seems bad.
05:05:17.385 - 05:05:46.057, Speaker B: Yeah, I mean I wouldn't mind the whole idea of having your arguments be a single string, honestly. Sounds kind of nice. Sometimes use behavior isn't bad, but it's kind of annoying that if you have they're just like whitespace limited and so you have X you get three. If you say X equals Y you get one. That's kind of a pain and you'll have to manually parse your stuff. And so I've wanted some time to kind of say don't Worry about parsing this yourself. Just give me the actual full string.
05:05:46.057 - 05:05:52.445, Speaker B: But definitely want to make sure that all your parsing agrees on what actually is an argument. Not.
05:05:53.225 - 05:06:06.385, Speaker A: Yeah, it sounds painful though, to have to mirror the escaping logic. Right? Because we don't control what Windows does. We just have to mirror what they do on the de escaping side. That sounds like a losing battle.
05:06:07.485 - 05:06:11.941, Speaker B: Yeah, well, it sounds like they should provide. If they care about escaping, they should provide an API to escape a thing safely.
05:06:12.053 - 05:06:24.585, Speaker A: Yeah, you're not wrong. I think that's all for 177 Star. I think we're on our last rust release, which I think means it's time for an intermission.
05:06:25.115 - 05:06:25.975, Speaker B: Intermission.
05:06:26.715 - 05:06:47.735, Speaker A: Intermission time. Go intermission. What? What's the verb version of intermice? Go intermise. I'll take it. All right. I will get some water.
05:06:50.325 - 05:06:51.065, Speaker B: It.
05:08:35.405 - 05:08:44.545, Speaker A: Intermissing. Intermit. No, you can't say let's go intermit now. That's. That doesn't sound like a word.
05:08:59.495 - 05:09:00.315, Speaker B: Oh.
05:09:06.175 - 05:09:42.241, Speaker A: Let'S check our HOMU queue. Oh, there's a roll up. There's a roll up now. There's still hope. Yeah, but take a. Take an intermission is boring. It needs to be a single word.
05:09:42.241 - 05:10:16.135, Speaker A: We gotta verbify it. You can emit, so why not intermit? I suppose, but it just feels weird to say we're going to go intermit now. I mean, it feels the same to say we're gonna go emit now also feels strange. Ben, someone proposed that roll ups should be called burritos instead.
05:10:18.315 - 05:10:35.915, Speaker B: Hmm, I don't know. We have a bike shooting thing here. Like, so there's like burritos. That's like a wrap, right? We could just call them wraps. Like taquitos. Really, really thin roll ups. Like it should depend on how many things are in the roll up, right? If it's like a big thing, like a burrito, it's like, yeah, maybe even a calzone.
05:10:35.915 - 05:10:37.215, Speaker B: If it's like really big.
05:10:38.155 - 05:10:52.985, Speaker A: That would be pretty funny. If roll ups were like, this is a calzone size roll up, then you know you're in for. In for some problems. Oh, we're. We're in a roll up now, Ben, our PR Right here.
05:10:53.285 - 05:10:54.045, Speaker B: Thank you.
05:10:54.165 - 05:10:55.985, Speaker A: Yeah, we're. We're in this one.
05:10:56.845 - 05:10:58.749, Speaker B: Okay. But it's not. The roll up is not currently being.
05:10:58.797 - 05:11:03.265, Speaker A: Wait, what is this? Rename unsafe to safety.
05:11:04.845 - 05:11:05.725, Speaker B: What is this?
05:11:05.845 - 05:11:07.105, Speaker A: What? What is this?
05:11:16.095 - 05:11:16.815, Speaker B: It's a mirror.
05:11:16.855 - 05:11:26.395, Speaker A: Oh, this is something. Okay. This is something inside of. Okay, that's fine. I was like, this seems like A severe change. We're just going to stop having unsafe.
05:11:27.175 - 05:11:30.263, Speaker B: He thought nobody knows. But we caught him live on stream.
05:11:30.359 - 05:11:41.335, Speaker A: That's right. Just trying to sneak it in there. Wow, wow, wow, wow. I think there might be hope, Ben, depending on how far along this.
05:11:41.715 - 05:12:00.495, Speaker B: If I talk a bit fast. We've noticed actually before, if I just talk very slowly, maybe the poll request will finish.
05:12:01.525 - 05:12:10.269, Speaker A: Or the alternative is that we just go through rust 178 commit by commit. I think that would also do it again.
05:12:10.357 - 05:12:22.485, Speaker B: Or we could just find a security flaw, a CVE in Rust live on stream and then say you must patch this right now. We got to get. Is Neil Strip still here? We got to get this new patch release out.
05:12:22.565 - 05:12:23.385, Speaker A: That's right.
05:12:24.925 - 05:12:28.691, Speaker B: Can we argue that the unsafe keyword is a CVE should be called safe and then.
05:12:28.723 - 05:12:34.843, Speaker A: Yeah, yeah, I like it. Is there anything else in the roll up we could say is a. Oh yeah.
05:12:34.859 - 05:12:42.347, Speaker B: What are our neighbors? 3. 3 is not a burrito. Right? 3 is definitely less than burrito.
05:12:42.411 - 05:12:43.895, Speaker A: It's barely around.
05:12:44.435 - 05:12:50.691, Speaker B: Maybe like chimichanga. Is that larger than burrito? I think it's more narrow than a burrito.
05:12:50.803 - 05:12:58.825, Speaker A: Maybe it's more like. It's almost like a maki. Three ingredients like rice, fish and avocado.
05:12:59.125 - 05:13:09.397, Speaker B: All right. I mean, I guess sushi is also a role. I'd say a sushi. It's like a one or two. Maybe even two or three. You got yet your rice, your tuna, and like some other thing in there.
05:13:09.461 - 05:13:31.435, Speaker A: Well, I mean this is clearly worth the point release, right? Only make gats ambiguous in something that sounds like they're unambiguous at the moment and they shouldn't be clearly worth a point release. Well, I'll keep it open to monitor. Okay. Ben, we only have one left.
05:13:35.095 - 05:13:48.155, Speaker B: It's time. The end is in sight. You want to. Would you get copyright struck if we played like the dun dun dun dun dun dun dun dun dun dun dun the entire time we do this?
05:13:48.455 - 05:14:01.159, Speaker A: I feel like we do need to do that. That's. That's clearly. Really what I wish is. I wish I had the. The sound. The like intro soundboard for the Restation music track, which I think.
05:14:01.159 - 05:14:06.715, Speaker A: I think. I think I have it somewhere.
05:14:07.975 - 05:14:10.475, Speaker B: Just pull up Zen Hub or not Zen Zencaster.
05:14:10.855 - 05:14:33.025, Speaker A: Oh, yeah, I suppose I can. Huh? Oh, but it's not gonna play through obs. Oh man. Oh, but maybe I can. Here's what I'll do. I'll just do recession station. No, what is it? Audio dot rotation station slash file intro.
05:14:33.025 - 05:14:57.551, Speaker A: And then I'll send it in YouTube chat and. Oh actually maybe I can if I go to obs and unmute my desktop audio. And now people are going to hear you twice. So just don't say anything right now. And then I play this.
05:14:57.623 - 05:15:05.645, Speaker B: I'll just say half of. Are you playing the here?
05:15:32.475 - 05:15:47.455, Speaker A: Amazing. Amazing. Nailed. It was went great for everyone. All right. Is 178. Did we say we're going to do that as a new episode?
05:15:48.115 - 05:15:52.523, Speaker B: I'd say just do it part of the same one. Unless you want to come back and tack on.
05:15:52.699 - 05:15:56.937, Speaker A: How about we we brand it as a. As a bonus thing in this episode.
05:15:57.041 - 05:15:57.521, Speaker B: Bonus?
05:15:57.593 - 05:16:17.685, Speaker A: Yes. We go something like. And you think this episode should have been. You think this episode was supposed to be over. But wait, there's more. We have decided to be so gracious that we are including.
05:16:19.625 - 05:16:23.427, Speaker B: You come out on stage and like a turtleneck and you say actually there's one more thing.
05:16:23.571 - 05:16:25.215, Speaker A: Just one more thing.
05:16:25.595 - 05:16:29.339, Speaker B: Our biggest Rust release notes podcast yet.
05:16:29.507 - 05:16:39.175, Speaker A: That's right. May 2nd a new thing hits the world. No one could have seen it coming. It is going to change everything.
05:16:39.915 - 05:16:50.505, Speaker B: I do like the idea of there being kind of like you know, a random oracle that eventually just this cuts releases randomly just says aha. This is now the release and no one knows when it will ever happen.
05:16:51.525 - 05:16:53.945, Speaker A: We should have it just be the Fibonacci sequence.
05:16:55.965 - 05:16:58.265, Speaker B: So what's the 78th Fibonacci number?
05:16:58.605 - 05:16:59.385, Speaker A: Yes.
05:17:01.485 - 05:17:13.341, Speaker B: Well, we going to ask Rust. I'm sure Rust knows. This is now an interview. John, I want to see your ability to code Fibonacci level on stream. Finally the 78th. Okay.
05:17:13.373 - 05:17:15.653, Speaker A: Ah, wait.
05:17:15.709 - 05:17:16.021, Speaker B: No.
05:17:16.093 - 05:17:19.875, Speaker A: Damn it. Not what you wanted. See, this is how you fail.
05:17:20.855 - 05:17:23.047, Speaker B: Yeah, yeah, clearly.
05:17:23.191 - 05:17:33.475, Speaker A: Oh boy. See, this is what our real programmers do it Fibonacci number compute Linux bash.
05:17:34.855 - 05:17:37.635, Speaker B: We're gonna do it in bash. Be blazingly fast.
05:17:38.175 - 05:17:39.075, Speaker A: Flast.
05:17:40.215 - 05:17:41.035, Speaker B: Yep.
05:17:44.465 - 05:18:17.725, Speaker A: No, that's not what I wanted. Well, I need to have it be a BASH program because how else would I pipe it out so that I can get the 78 number? Wow. N is just hard coded. See, I made it dynamic for you. Boom. Right there, Ben.
05:18:18.265 - 05:18:29.265, Speaker B: Okay, so let's assume every number is one day. So how many days is 5,527? 939,788. 4,757.
05:18:29.385 - 05:18:38.705, Speaker A: Oh, that's easy. Google knows this one days in millennia. It's only that many millennium.
05:18:39.125 - 05:18:43.165, Speaker B: Okay, great. Have I used to the universe.
05:18:43.325 - 05:18:44.225, Speaker A: That's right.
05:18:45.845 - 05:18:50.181, Speaker B: It might be a while until we get like. It's a shame because Inline Cons was just about to land.
05:18:50.293 - 05:18:54.465, Speaker A: Yeah, I know. Oh, we missed the train. We have to wait another. Damn it.
05:18:55.405 - 05:18:57.685, Speaker B: 4 billion ages of the universe.
05:18:57.765 - 05:19:05.275, Speaker A: That's right. Oh, you. You're right. That might be fib 77. It's okay. It's it. That just means that it's worse.
05:19:06.175 - 05:19:09.639, Speaker B: There's the last number is the 78 episode.
05:19:09.727 - 05:19:25.035, Speaker A: I was gonna say the last number is left as an exercise to the reader. So, Ben Rust 178. This one I actually think is pretty cool. The. This idea of diagnostic attributes. Do you want to talk about this one?
05:19:26.585 - 05:19:49.845, Speaker B: Yeah, sure. Actually, I'm not sure. I'd love to know what other languages have a thing like this. For example, in Rust, right now, normally say you're writing a proc macro, a thing that runs compile time. If you have an error, oops, I panned my proc macro. It's going to print that as a compiler error because it literally is a compiler error. It's a thing running in the compiler that address space.
05:19:49.845 - 05:20:14.985, Speaker B: There are ways to customize whatever compiler error you want to give the compiler. There's also ways of doing it beyond out of prepare records too. There's the compiler error macro, which if I forget under how you actually use this. Let's look it up. So the macro compiler error. And so it says it causes compilation to fail when encountered. So it's for conditional compilation.
05:20:14.985 - 05:21:08.087, Speaker B: So if you have a conditional compilation branch and you want to hit a compiler error when you hit this, you can do this. And so for example, if say you had compilation or condition compilation on certain platforms only say you had your crate contains an assembly block and you can't predict the assembly for every platform in existence. And so you only have assembly for Mac and Windows and I guess x86 and arm, and someone tries to run your crate on a totally random architecture, you could just say, hey, we are configured to give you a compiler error, rather than just failing, or totally bizarre, obscure kind of assembler error. And so that's a cool thing. The idea that Rust gives you the ability as a library author to customize compiler errors is great, because Rust, you catch so many errors at compiler time. Normally things that you would encounter at runtime are now at compiler time. And so if you want to give a nice experience, you want to be able to customize these things if you're a library author.
05:21:08.087 - 05:21:54.339, Speaker B: So in this case, it's a new way of customizing the output of the compiler where anytime that the compiler would Emit the unimplemented, which is the actual E0277, which is whenever you're trying to invoke a method from a trait and the type that you're using it on doesn't actually implement that trait, you can now customize the output of that message. So it's done in a generic way. So in the future they could add more things like this to the diagnostic attribute here, which is super cool. I think this is. Again, I'd love to know what other languages are doing this or for us it's on the forefront of just giving users the ability to customize compiler output because it's super great. I love it a lot.
05:21:54.507 - 05:22:42.365, Speaker A: Yeah. And I guess to describe this for the audio audience as well. The idea here is that there's a new attribute called diagnostic, and diagnostic is always suffixed with some name that is a particular type of diagnostic. So the only one that's currently being stabilized is the attribute diagnostic on unimplemented. And it's an attribute that you put on a trait and it lets you customize what error someone gets if they, as Ben said, tries to use a method from that trait on a type that does not implement that trait. So it lets you customize that message rather than getting just the generic the trait bound. Whatever implements trait is not satisfied.
05:22:42.365 - 05:23:16.685, Speaker A: The idea here being that you might be able for a given trait to give more help to the user about what it means not to implement this trait, or things you might not have thought of, or things that often need to happen in order for something to implement the TR trait. And the hope is that over time we might get other sort of variants of these diagnostics that you can put on other things like types or methods or something that allows you to further augment the output that you get from compiler error messages that are related to that type or function or trait or whatever it might be.
05:23:17.905 - 05:23:55.979, Speaker B: Yeah, and I will steal the example provided by Reddit here, which is kind of imagine you have an API where the user is supposed to implement a helper trait or a side trait, and then there is a blanket impulse somewhere that implements some other trait for any trait that implements that side trait. And then you try to call a method on a random type on the original trait, not realizing that you have to implement the side trait. This way the error message can tell you, hey, actually it looks like you're trying to call this method, but you need to actually, if you want to use the API properly, implement this method over here, totally random other method. And then this Blanket impl that applies over here will give you this for free. And so, yeah, it's cool stuff.
05:23:56.107 - 05:24:32.227, Speaker A: Yeah. The other example that's given in the change log is for the sized trait, which the compiler already does something like this. It doesn't actually use the diagnostic attribute, but it sort of could. And the idea here is that if you have a type that doesn't implement sized, the compiler actually gives you a message that doesn't just say this type doesn't implement sized. It says the size for values of this type cannot be known at compile time. And then, you know, it indicates the particular type and says this type doesn't have a size known at compile time, which is specific to sized. Right.
05:24:32.227 - 05:25:16.935, Speaker A: You couldn't output that message for any trait implementation except for sized. And so it's a customization of the error specifically tailored to the trait in question. It's important to point out though, that this is not a thing that's guaranteed to happen. It's intended to be a sort of hint for the compiler or advice for the compiler about how it could improve the error message. The compiler is not required to actually take this diagnostic into account. There is. There's another cool thing that I think is added in Rust 178, which is the ability to assert unsafe preconditions.
05:25:16.935 - 05:25:22.335, Speaker A: And there's actually a little bit more history here. Do you know more of the history for this change, Ben?
05:25:23.235 - 05:25:50.749, Speaker B: I mean, I'm not sure this lets the users assert. I think this is for assert to happen. Library we mentioned before, obviously about how for the inscript in the strip discussion, how standard library is not shipped as a thing that you compile within the users, like a dependency. It is shipped as a binary. It means you get whatever settings are compiled in whenever they compiled it. Here's the thing. An assertion is code that runs at runtime and then panics if it fails.
05:25:50.749 - 05:26:18.629, Speaker B: You have the idea uphold your invariance and we need to make sure for sure that this thing equals this thing, otherwise just bail out because this got horribly wrong. But assertions are contained are usually a runtime cost. There's a branch there and a check. If you want to have, just have an assertion that only in debug mode is called debug assertion or debug assert where it is a macro like assert but inside the macro it also says, hey, if we're in debug mode, just become a no op entirely.
05:26:18.677 - 05:26:20.065, Speaker A: In release mode, you mean?
05:26:20.405 - 05:27:12.957, Speaker B: Yeah, in release mode. So the macro will be like, hey, compile away in release mode. And here's the thing though, the STD library contains various debug asserts because it wants to be fast and only test things in debug mode. But the thing is, most people only ever run thread library in release mode because it is being shipped as a binary to end users. These were almost never being used. This is a cool thing, it looks like, where the check for debug mode, rather than happening at compilation time, like when you actually go from source code to a Rust archive, actually happens at code gen time now. So you can have a library with debug asserts compiled in release mode, but those will be compiled out if the end user is in release mode and left in if the end user is in debug mode.
05:27:12.957 - 05:27:24.563, Speaker B: So there is still no runtime cost if you don't want to have them in release mode. But you can now actually ship a library that does this. That's the background here.
05:27:24.699 - 05:28:19.769, Speaker A: Yeah, and I think they're only really doing this for the standard library for now at least. It's not a general purpose thing that you can use for your libraries, at least as of yet. But the tie in here to unsafe, which is what's mentioned in the changelog as well, is that a lot of these debug asserts are specifically for a lot of Rust's unsafe functions, where there's actually a bunch of debug asserts in the standard library code specifically for the unsafe functions to try to check some of the safety invariants that those functions assume of their callers. Things like, you know, this is not past the null pointer or this, this pointer is aligned to match the alignment of the T that you pass in. And those things are not. They don't want to check them at release time because doing so without a bunch of overhead, but they do. It's sort of a nice sanity check to have.
05:28:19.769 - 05:29:20.695, Speaker A: And so now, as Ben says, like it'll be really nice to now be able to have those assertions be run like those standard library assertions be run when running your code in debug mode. One thing I thought was really interesting about this, I highly recommend taking a look at the the PR that implements this for those following along. It's PR number 125 94. Just to see how this was moved from being just a straight like config exclamation mark debug assertions into something that happened at cogen time. Because the way it actually happens is through they introduce another intrinsic which does get expanded at cogen time. And so it's a really neat Trick essentially for making this happen that I thought it was pretty fun to read through the actual diff of. Do you think this is something that we might get for libraries that are not the standard library? Ben?
05:29:21.235 - 05:29:45.091, Speaker B: I'm not sure. Well, right. I'm not sure if it doesn't currently happen. I just think that normally because you tribute libraries as source, it doesn't really matter. I mean you can imagine maybe somebody is like I do want to attribute my library as a binary in which case it might matter. Right? Because I think for now if you are compiling from source, it doesn't have any actual. Yeah, that's fairly between generating the compile time versus at code gen time.
05:29:45.243 - 05:30:00.283, Speaker A: But once we start having people cache like cargo dependencies for example and provide pre built cargo dependencies on crates IO, which I'm sure is right around the corner, then this would matter, right?
05:30:00.299 - 05:30:29.155, Speaker B: And I suppose so there's a thing where if you are making a library and you have some dependency that's just really slow in debug mode. Some crypto crates where you always want to have them in release mode because otherwise they're really slow. Then normally in Kark you would say hey, I have a profile where for these crates these dependencies always put them in release mode no matter what mode I'm in. In that case I'm not sure what happens. I assume that if they had debug assertions they would get turned off.
05:30:29.815 - 05:30:34.025, Speaker A: I think so. So that would actually suppose to be an example.
05:30:34.885 - 05:30:46.853, Speaker B: So yeah, I'm not sure today what happens. I don't know. I mean it seems like if it works for central Library, I don't see why it wouldn't work for everyone else. Maybe it does, maybe they don't mention it because it's kind of a rarer use case. So it's worth trying out.
05:30:46.949 - 05:30:59.897, Speaker A: Yeah, the trick, at least as far as I understood the pr, is really to add an intrinsic. So just a function inside of the stood or core intrinsics module instead of.
05:30:59.961 - 05:31:04.165, Speaker B: Instead of debug assert though, which I assume is still using the standard debug assert.
05:31:04.785 - 05:31:39.185, Speaker A: No, so it's a slightly different thing. It's a. It's an intrinsic function that returns a bool but the bool it expands to is checked at cogen time. And so in theory, like it's a. It's a const fn and so it's something that you could call like in instead of using debug or if config assertions or debug assertions. If this intrinsic was stabilized, I Think you could call it in your own libraries too. It's just I don't know that there's currently any plan to.
05:31:39.185 - 05:31:41.005, Speaker A: To stabilize this intrinsic.
05:31:41.345 - 05:31:52.683, Speaker B: Right. Well, I mean, you know, as long as the assertions are talking about here are using the debug assert macro, I don't see why they wouldn't apply for anyone using it as opposed to. But I mean, there's an example here in the.
05:31:52.819 - 05:32:00.707, Speaker A: They don't. So in the standard library parts, right? Yeah, but they're not using debug asserts I think so my read of this.
05:32:00.731 - 05:32:04.883, Speaker B: Is that in the standard library assert unsafe precondition.
05:32:04.979 - 05:32:17.045, Speaker A: Yes. So there's a specific helper in the standard library that's used to check these and it's the helper that's been updated to use this intrinsic. It's not the general debug assert e or debug assert set of macros.
05:32:17.735 - 05:32:18.887, Speaker B: I see. Okay.
05:32:19.071 - 05:32:51.241, Speaker A: Although in theory they could be extended to those. It would be interesting to see that too. The next change we have in 178is deterministic realignment. This one I know very little about. I think my understanding here is this is mostly a documentation change. Where previously Rust wouldn't commit to certain guarantees, but now they have. Do you know anything more about this one?
05:32:51.393 - 05:32:57.401, Speaker B: Well, I think you know. So. Yeah, in. In const mode. So in, you know. Yeah. The idea here is that for.
05:32:57.401 - 05:33:35.335, Speaker B: For various reasons really do with, you know, soundness and type safety. Const, you know, you know, constant contexts. Right. They need to have the same semantics as runtime context as non cons context because you might use the output of a cons function or something as the type or might end up somehow in the type signature of a thing that gets run at runtime. And so if you compute run these run one compile time, run at one time and compare the results, they should compare equal. Otherwise it could be type N safety. As a result, CONST compilation has to be very conservative.
05:33:35.335 - 05:34:03.565, Speaker B: And I think that this was a case where CONST was just being too conservative as a kind of a defensive measure. Let's see. I'm trying to see these caveats primarily existed as a hedge against CONST evaluation, but they're only stable for non const use anyway. So the idea is that they were previously being conservative because they were worried you might use these in cons context. But they're kind of like actually let's not just not allowed them at all in cons context.
05:34:04.065 - 05:35:11.113, Speaker A: So yeah, I think there's an example here of the pointer align offset Method function method I suppose, which is a method on a pointer where you give it an alignment and it tells you how off the pointer is from that alignment so that you can then add to the pointer to make it be aligned. And it actually specifically says if it's not possible to align the pointer, the implementation returns us max. But then it also says when this is called during compile time evaluation, which is unstable, the implementation may return us max in cases where that can never happen at runtime. So this is I guess somewhere where it. It sort of diverges between constant non const context because in const context you might not know and therefore you have to return it's impossible. Whereas in runtime context you will know and so you can return a definite answer. Interesting, right?
05:35:11.129 - 05:35:23.599, Speaker B: So I think this is mostly kind of a. If you are doing. I don't know if you're doing some strange things, you might care about this. Other than that, I think it's not really that big of a deal.
05:35:23.687 - 05:35:25.007, Speaker A: Yeah, I think that's probably right.
05:35:25.031 - 05:35:27.151, Speaker B: Other things that are more interesting.
05:35:27.343 - 05:35:53.503, Speaker A: Someone points out in chat about the previous thing on debug assertions that opt levels and debug assertions are separate settings in the profile. So you could compile your dependencies with opt level 3, for example, but debug assertions still are. That is the thing you could do. But it would be nice if you didn't have to. Right? If you could just say full optimizations. But you still got all of their debug assertions. But it is true that setting them.
05:35:53.503 - 05:36:41.915, Speaker A: Yeah, because the thing I guess you have to be careful about is that debug assertions could be pretty expensive, right? That's the reason why they're debug assertions. And so you might. It might actually be like if you included them in a release mode build, the resulting release mode build might still be too slow if the debug assertions were on just because they're like expensive to compute, for example, which I know is one thing that they were worried about for this change in the standard library was sort of to make sure that all of the things that use this new feature aren't things that end up being too slow in the consuming code, like things that use the standard library methods. I think we're then on to stabilized APIs.
05:36:43.895 - 05:36:44.635, Speaker B: Right?
05:36:46.775 - 05:36:53.395, Speaker A: I actually don't think too many of these are interesting. Most of them are sort of smaller things any that stick out to you.
05:36:54.655 - 05:37:02.631, Speaker B: So the question for impl read for reference to standard N I guess question is why doesn't already exist. Like what took us so long?
05:37:02.663 - 05:38:34.805, Speaker A: Yeah, site, I think it was because there's already an implementation of write for a reference to stdout, so it feels pretty obvious to impl read for reference to stdin. The only thing I can think about is that it has to take the standard in lock each time, but that should be the case for stdout 2, so that it feels like just an oversight. The other thing that was added here is there's a bunch of method or trait implementations for the standard library error type that just accidentally didn't specify a lifetime specifier and therefore got assumed to be static when they didn't need to be. And so a bunch of those have been sort of loosened up to allow returning boxed in errors, for example, with arbitrary lifetimes, as opposed to specifically with the static lifetime. And I think this is related to the fact that when you write boxed in and then a trait, if you don't specify like plus tick lifetime then the compiler infers that to be plus tick static. Unlike everywhere else in Rust, where if you don't specify a lifetime it means it doesn't have a lifetime for boxed in it specifically means this thing is static. And so that sort of relaxation of a requirement is probably useful to someone.
05:38:34.805 - 05:38:55.695, Speaker A: Although I don't immediately see where you would specifically want a non static error, but I'm sure there are some someone saying that the intrinsic that the compiler uses that the standard library uses in core.
05:38:56.435 - 05:39:03.315, Speaker B: Well, right, so core intrinsics is almost all unstable by design, right? So yeah, but it's not usable.
05:39:03.435 - 05:39:49.103, Speaker A: But it's not even listed as being. Oh no, it is assert unsafe precondition. The core macro is in nightly only. I wonder if the intrinsic it uses this as well. Core intrinsics L debug no, it doesn't look like it. The underlying intrinsic is not just the sort of helper that the standard library uses to express unsafe preconditions. Um, and then in compatibility notes, this is another release where Rust is increasing its minimum requirement for a bunch of targets, specifically Windows this time.
05:39:49.103 - 05:40:46.307, Speaker A: Uh, so with Rust 178, Windows 7 and 8 and 8.1 are all unsupported. So the minimum requirement for Windows is now Windows 10. Um, and I want to talk about that for a sec because there is an interesting thing when I started digging into the release notes that I thought was neat. So first in the detailed release notes, one of the things that came up there is a replacement of the implementation of reader writer locks on Unix systems to not use pthreads but Instead use a custom implementation. So they've written basically a faster Reader Writer lock that uses uses thread parking and unparking under the hood. But other than that does not interact with the OS level, some OS level thing like P threads, because the performance characteristics of not going through P threads are actually quite good.
05:40:46.307 - 05:41:25.331, Speaker A: And you get rid of some of the limitations of P threads like having to box the Mutex or the Reader Writer lock on Linux like few taxes, sort of. So, so on Linux you can use few taxes, but on like generic Unix there is no such thing as a few text. And so there it fell back to P thread mutexes which are generally just worse. So this is actually a custom implementation of a Reader Writer lock using like a, an intrusive queue. And I think it's based on the Windows design of slim Reader Writer locks. But it's just, it's a custom implementation. It's actually pretty cool to read the code.
05:41:25.331 - 05:42:36.585, Speaker A: It's pretty well documented about how the algorithm works, but it truly is like implementing a Reader Writer lock algorithm from scratch. The cool thing about this is that it enables us to use non P thread Reader Writer locks in all Unix settings. And in fact all it really requires is that you have access to thread parking and unparking. And so one of the things that we're able to do with this change is actually improved the Windows 7 and 8 and 8.1 Reader Writer locks because one of the things they did in 178 was to switch the Windows implementation of Mutexes to use a newer better version of Mutexes in Windows that's only available in Windows 10 and onwards. And people were worried that this meant that the Reader Writer lock and the mutex on Windows 7 for example, would just be bad forever because it has some like known deadlocks and such. But because they had this improved Reader Writer lock that only relies on parking, they could now take that implementation and also use it for the older versions of Windows.
05:42:36.585 - 05:43:45.095, Speaker A: And so now the older versions of Windows, even though they're unsupported, still get a better Reader Writer lock. But the reason I went down this path is because this example of moving the Windows Mutex to a way better implementation that relies on APIs that were only standardized in Windows 10 is the example of why it is so important for Rust to be willing to drop old versions of targets over time. It's because if you were stuck with we have to support, you know, every target we've ever supported. Not only is it hard to test for, but it also means that you can't as easily make use of these new APIs and new improvements because you need to keep all the sort of backboards and fixes around, including things like working around broken implementations that might exist in certain versions of the operating system. So this is a cool example of Rust taking making use of a newer version of a Target and also an example of being able to reimplement a primitive and using it across multiple versions or multiple targets afterwards. That was a long rant, but I thought it was cool.
05:43:46.395 - 05:44:20.355, Speaker B: Yeah, that's not even the only known note here, which is the Rust 1.78 has upgraded its LLVM to version 18 which. So okay, there's another thing here, which is that we talked about ABI previously, where an ABI is how you know this library, knows how to talk about this library. If you call a function between here and here. I mentioned before that there is a de facto ABI for C that both Clang and GC agree on. There's actually a lie. Gankra has a great blog post, maybe even 2, about how ABIs are a lie and a big pain.
05:44:20.355 - 05:45:05.915, Speaker B: One of the biggest, most important differences between the ABI for Clang and GCC, even for just compiling C code together, is that 128 bit integers had a different ABI in Clang. Probably. I think everyone agreed that Clang had the wrong abi, but it took a long time for everyone to agree. It was time to break it. I'm not even sure if Clang I know that kind of stuff. Clang and LLVM are pretty tightly coupled, right? And so for a long time Rust just inherited whatever Clang did because Rust uses LLVM behind the hood. And so I'm not sure if Clang has yet switched to using this, but LLVM now actually offer let you lets you use the quote unquote proper ABI for 128 bit integers.
05:45:05.915 - 05:45:41.135, Speaker B: And so Rust has now begun using that. And so Rust has now broken its API, which comes all the time, it's not a big deal. And so yeah, it means that there's also a blog post I saw that was talking about someone who was like benchmarking and said hey now if you were using these integers now because alignment has been fixed, because previously I think alignment was half what it should be, that now you should be properly aligned if you are actually and you might result in a 5% improvement if you have heavy numeric code using 128 bit integers. This is one of those little API notes that's a neat Little thing under the hood.
05:45:41.555 - 05:46:14.595, Speaker A: I pulled up the compatibility table. There's a pretty good blog post write up of this. This change to layout in 177 and 178 and there's. There's this giant table of which things are compatible with which things when it comes to layout. And I love that they also include GCC and Clang. So GCC is fully compatible with Clang 18 and above, but it's not compatible with Clang below 18. Oh yeah, and it's because of this.
05:46:14.595 - 05:46:45.655, Speaker A: What do we have here? No, here. Right. Where? No, that's also wrong. I can't find the table now, but there are so many tables. This is a great write up if you're curious about this. The changes to U128 and i128 layout in 177 and 178 and it has lots of tables about how things are incompatible with other things.
05:46:47.035 - 05:46:51.075, Speaker B: Yeah. And we'll link to Gankra's two blog posts about abi.
05:46:51.195 - 05:46:51.935, Speaker A: Yeah.
05:46:52.835 - 05:46:54.095, Speaker B: For further reading.
05:46:55.675 - 05:48:11.555, Speaker A: The next thing I have is this one's not interesting, but is that in 178 it became a hard error to have consts in match arm patterns if those cons don't implement partial eek. So this requires a little bit of explaining I think, especially for the audio followers. If you have something like you have a. Let's say you just have a U size, so you have a const that is defined to have the value seven, you do a match over usize and in one of the arms the pattern is the name of that const, then that is fine because Rust knows that that constant, its value is 7 and so it knows that this is equivalent to a match whose arm has seven there. It gets more complicated. If you have. If you're matching on like a struct for instance, and you have a const that holds an instance of that struct because now it's not entirely clear how Rust is supposed to check whether the struct matches that const.
05:48:11.555 - 05:49:22.163, Speaker A: The goal is for for Rust to use partial E to compare them. What would actually happen in older versions of Rust is that this would be permitted and could read lead to really weird results. I'm trying to see if I can dig up the example of this being weird. Oh, I can't find the write up now that's annoying. Constants and patterns maybe. So the idea here is that we should require that the type implement partial equ because how else would you check that the incoming the value to the match actually matches the value in the arm. And there are actually some caveats to this where what you really need is structural eek and not just partial eek.
05:49:22.163 - 05:50:07.625, Speaker A: But that's getting into the future that we haven't arrived at yet. But the general idea here is that there's been a forward a future incompatibility lint on this for a while to have constants in match arms that do not implement partial E. And now that's become a hard error in Rust 178. So this is an interesting example of something that was a future incompatibility warning which we've talked about in the past, that do surface from your dependencies that has now actually become a hard error within the same edition because it's deemed so troublesome to have code like this because it behaves just wrong. Do you happen to remember what the issue is when matching on cons that don't implement at this?
05:50:08.365 - 05:50:09.745, Speaker B: Not even remotely.
05:50:14.885 - 05:50:18.865, Speaker A: It's frustrating. I feel like I found it earlier and now I cannot find it again.
05:50:21.605 - 05:50:23.465, Speaker B: I'm surprised it ever worked.
05:50:24.405 - 05:51:31.315, Speaker A: Yeah, well, it's not too important to dig up. I just. I feel like I found it easily when I was looking through this previously and then now I'm not just not finding it. That's all right. Like specifically why the forward compatibility thing even existed, but, oh well, we can move on. Another thing I found was, and this is just a sort of improvement to the compiler errors that you get. So macro rules is a little bit weird in that unlike basically every other item in Rust, you have to define a macro above where you use it and above here, meaning literally in the source code file, the macro rules has to be defined further up in the file than where you call it.
05:51:31.315 - 05:52:32.451, Speaker A: This is not true for like anything else, you can define function foo and function bar, and function foo can still call function bar, but the same is not true for macros. And this can be really confusing because the error you get is there is no such macro, even if you have the macro right below the place you're calling it from. And so finally in 178, the error output for this thing now got better and it will actually tell you if there is a macro in the same file by the same name that just happens to be too far down and suggests that you move it up, because that is the way to fix it. This feels like a long time coming. I don't know why we didn't have this until now, but it is a. It is a really nice improvement. I think the what Else do I have? Ah.
05:52:32.451 - 05:53:31.695, Speaker A: The Cargo team also stabilized the version 4 of the lock file format. So Cargo lock files do actually change their format over time. So we have had, well now four different versions of it. And the difference is like, Cargo doesn't like to change the lock file format because it causes a bunch of churn in git, right? Like now your entire lock file changed just because the format changed, not because your dependencies changed. The reason why they changed or incremented the new lock file format is specifically because they found that the way that they were serializing URLs into the lock file was lossy, or rather it wasn't encoding URLs correctly. And so some dependencies ended up with just the wrong encoding in the lock file. The problem is they can't fix this within the same version because if they started writing encoded URLs into the lock file, older versions of Cargo that didn't know about this encoding would read it out and get the wrong value.
05:53:31.695 - 05:54:31.931, Speaker A: And so they had to release a new version of the lock file. It's not on by default yet. The default is still version three, but it seems like version four is sort of going to come pretty soon to fix the issues here that I think is specifically related to things like if you have a Git dependency whose branch includes a plus in the name, then it's going to be encoded incorrectly because they don't escape it the way that the URL library wants them to. There's another couple of really nice changes to Cargo. One of them is the Cargo update will now tell you if you did an update, but there is a newer version available. So imagine something like, you know, you took a dependency on, I don't know, nom 5, and you previously had nom 5.4.3 and it's been updated to 5.6.8.
05:54:31.931 - 05:55:34.025, Speaker A: Then cargo will tell you, okay, I'm updating NOM from this version to that version and will also tell you the latest version of nom is version 7. So in other words, it warns you that you're not on the latest version that you could be. But I did update you as far as I could. And so I think this is a really nice way to indicate to people that they're behind even though Cargo update succeeded. And then the other thing that happened is 178, and this has sort of been a long time coming as well, is that Cargo a long time ago decided that they want to use TOML for configuration files and they want those TOML files to have the dot toml extension, but they still accepted both. So you could have a cargo slash config and you could have a cargo config toml, and if you had both, the toml file would sort of win out. But with 178, they've now officially deprecated the support for non extension files.
05:55:34.025 - 05:56:36.065, Speaker A: And so at this point you now actually get a warning if you have a config file that doesn't have the TOML extension. Again, not really that big of a difference because this has already been the case for a while, but at least now it's made visible, sort of similar to the cargo update thing, that it's visible that you're. You're not getting quite what you wanted. And I think that's all I really wanted to talk about for 178. There's a clippy lint actually that I noticed. I don't normally look at all the clipper links because there are so many, but there was one last one that I saw that struck me as interesting, which is if you have code that does something like foo equals bar dot clone, where foo is a value you already have, like you're not creating a new foo, then clippy will now lint you. Telling you, instead of doing foo equals bar dot clone do use clone from.
05:56:36.065 - 05:57:37.171, Speaker A: So if you don't know what clone from is, the clone trait actually has two methods, not one. The clone trait has the clone method, which we all know and love and use all the time, but it also has the clone from method, which specifically is it takes a mutable reference to self and a shared reference to another instance of self, and then it clones from that other one into self. The idea here being that for a bunch of types, you can actually avoid some allocations this way by reusing the values that already are stored in self, things like vectors. And so this might save you some allocations, but if you do foo equals bar clone, you can't make use of those because the foo is never given into the cloning process. And so in general for those, you should always prefer to clone from bar. So foo clone from bar rather than just reassigning a new clone. And so I thought that was an interesting clippy lint that I'm happy to see land.
05:57:37.171 - 05:57:42.655, Speaker A: It is probably going to trigger a lot for people, which is why I thought it was probably worth highlighting.
05:57:45.955 - 05:58:49.905, Speaker B: On the topic of clippy lints, there is another one called incompatible MSRV here where it's actually beginning to. So MSRV is the minimum supported rust version and the idea here is that a crate can in their current automobile file say, hey, this crate only supports rusts of this and above the minimum version. The idea here being that if you say send, a library comes out with new APIs all the time if you want to use that new API in your library. But somebody, one of your downstream users isn't on a version of Rust new enough to actually have the API in their version of Rust previously, they get a pretty bad error this way. The idea of MSRV is that you can say, hey, downstream users, it looks like you're trying to compile with version of Rust some old thing, but it requires at least this version. So upgrade your compiler if you want to compile my library. And so this new clippy lint now actually enforces it in your library.
05:58:49.905 - 05:59:12.515, Speaker B: I think that's what this does. Right. So this lint checks that no function newer than the defined MSRV is used in the crate. And so when your crate defines an msrv, previously it was kind of just like as a crate author, I kind of just happen to know what MSRV is. Correct. But now this is actually a way to check it for you. And so I think it's at a good next step for actually enforcing msrv.
05:59:12.635 - 05:59:18.855, Speaker A: Yeah, And I think it reads it out of the Rust version field of your package in your cargo toml. Right.
05:59:19.515 - 05:59:20.295, Speaker B: Yeah.
05:59:22.755 - 05:59:25.455, Speaker A: Is there anything from the Reddit thread that we should talk about?
05:59:27.395 - 05:59:37.137, Speaker B: E page more cargo stuff. Wanted to just kind of like highlight some stuff, which is that if you do cargo new, it no longer adds like a boilerplate comment in your little hello world file there.
05:59:37.241 - 05:59:38.125, Speaker A: Oh, nice.
05:59:40.225 - 05:59:56.297, Speaker B: So if you get an error for this package is declared to be incompatible with your Rust version. So more MSRV stuff. And now reports all of them at once rather than having to go through one at a time. And you mentioned the cargo update thing, so that's the only thing.
05:59:56.401 - 06:00:12.827, Speaker A: Yeah, the cargo update thing makes me very happy. I think it happens so much that people are behind on their dependencies and they just never realize. And at that point you never get updates either. Right. Because you're on an old major version. And so there's just no, no indication that you should probably upgrade.
06:00:12.931 - 06:00:18.483, Speaker B: Yeah, it's a trap where you get stuck at the newest version of the oldest old major version.
06:00:18.659 - 06:00:28.135, Speaker A: Exactly. And I think, I think with that we're. We're all done, Ben. We got all the way through.
06:00:31.305 - 06:00:33.405, Speaker B: Dun, dun, dun, dun, dun.
06:00:34.265 - 06:00:34.649, Speaker A: Nice.
06:00:34.697 - 06:00:37.961, Speaker B: We made it. We crossed the line. We did the fire.
06:00:38.073 - 06:00:53.161, Speaker A: We did end up at almost six hours. So it was longer than I thought it would be. But we've somehow survived, which I think is pretty exciting stuff. Although I can feel my brain is not fully present anymore.
06:00:53.353 - 06:00:57.165, Speaker B: So the RPR is still in the roll up. That's fine. That's. That's reasonable.
06:00:59.445 - 06:01:06.717, Speaker A: It is, yeah. It's not even pending yet. That's sad. We're so close.
06:01:06.901 - 06:01:20.745, Speaker B: That's all right. We made great progress here today. It occurs to me that we forgot to record outros for all the previous versions. We just record one once and then just reuse it. Yeah, just slam to silence.
06:01:22.285 - 06:01:32.683, Speaker A: I think the way we would do this is we would just say, and now for something completely different and then just cut it there. And then the next episode just picks up from like the editor just takes.
06:01:32.699 - 06:01:35.467, Speaker B: That sound bite from you just now and uses that. Yeah, there you go. Perfect.
06:01:35.571 - 06:01:57.493, Speaker A: Yep, Great. We've had it. We have every transition we could ever need. Oh, so good. So good. Okay, I think. I think we can call it there then.
06:01:57.493 - 06:02:03.745, Speaker A: I'll. I'll monitor this PR in the background. I'll switch so that people can't see my screen now. They can just see our faces.
06:02:04.325 - 06:02:10.453, Speaker B: Just make the live stream the home O here so that people can stay here all day, like glued at the screen waiting for this.
06:02:10.509 - 06:02:17.943, Speaker A: That's true. Actually, I guess I could. I could just leave this up, remove our faces and it's just the home. You queue until it lands within like.
06:02:17.959 - 06:02:20.951, Speaker B: Probably about four hours or so at least. So. Right. At most.
06:02:21.063 - 06:02:46.361, Speaker A: But I have to zoom in way more though, so that they make sure they know that it's this one. I. I believe in. I believe in chat here. Well, in that case, I'm going to. I'm going to say thanks to Ben because It is now 10:30pm here and I need to start to go to bed. And thanks to chat because it's way more fun to do this with chat than without chat, otherwise we would have died.
06:02:46.361 - 06:03:03.281, Speaker A: I think, Ben, we need someone to keep us going. But now that we are back up to speed now maybe we can hit a normal release cadence. But even if we don't, it's fine. It doesn't matter. We did so much fun.
06:03:03.313 - 06:03:06.385, Speaker B: We should just, you know, wait another six months before doing it again and.
06:03:06.425 - 06:03:17.995, Speaker A: Maybe that's going to be. Have been intentional all along. All right, well, bye everyone. Thanks for coming. So long. Farewell, Alfie to send. Goodbye and thanks for all the fish.

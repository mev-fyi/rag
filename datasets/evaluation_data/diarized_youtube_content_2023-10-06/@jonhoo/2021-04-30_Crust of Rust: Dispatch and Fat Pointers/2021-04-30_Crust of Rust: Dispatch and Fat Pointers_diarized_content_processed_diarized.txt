00:00:07.200 - 00:01:03.660, Speaker A: Hello, folks. Welcome back to yet another crust of rust. This one I'm hoping I didn't bite off too much to cover in like an hour and a half to 2 hours. I guess by the time you watch this recording, afterwards you'll, you'll see whether I succeeded or not. So for this one, what I wanted to cover was a sort of chunk of semi related topics around traits and dynamic and static dispatch, the size trait like wide or fat pointers, and some of the things around like v tables, coherence, they all have this, they're all sort of tied together, some more so than others. And I get a lot of questions about each one. And I figured I should just do one stream where we talk through how all of this stuff works and how it fits together.
00:01:03.660 - 00:01:59.136, Speaker A: I'm hoping that we don't end up too far down any one rathole. I think what I'll try to do is cover most of it in sort of workable detail, and then we might do sort of a deep dive on one of them in some later stream. But in order to try to contain it to the time, you might find that I skip over some of the detail and hopefully that'll be okay. So I actually wanted to start this time on the Rust book. So the rust book has a chapter on generic types and traits and lifetimes. And this is one subsection in there on the performance of code using generics. And this is a section that, like, if you've read the book, and I highly recommend you do, if you haven't already, might have like, struck you as you might have read it and be like, that sounds like magic.
00:01:59.136 - 00:02:35.596, Speaker A: And in some sense, what this stream is all about is trying to deconstruct that magic and figure out what's inside. And in particular, it talks about this idea of monomorphization. And monomorphization is the, as the text says, the process of turning generic code into specific code by filling in the concrete types that are used when compiled. But that's sort of abstract. So let's try to pick up a slightly more concrete example and then work from there. Let's go with new lib. We're going to call this one.
00:02:35.596 - 00:03:06.542, Speaker A: We're going to call this one. Hmm. Naming is hard. It doesn't matter, but that makes it even harder because there's no constraints. We're going to go with example. Example written in region. All right, let's get rid of this test.
00:03:06.542 - 00:03:40.670, Speaker A: We don't need no test. So let's say that you have a function greater. It is generic over t. Actually, let's go even simpler. Let's say that we're going to have a function sterling, and it's going to take anything that implements as ref stir and it's going to give you back a usage. So we're going to do as ref. Lena, real simple function here.
00:03:40.670 - 00:04:17.800, Speaker A: Let me make it a little bit larger. So this is a generic function. You could just as well have written it as s is s to use size, where s implements sref, stir. These two are equivalent. Sref when, and I guess we'll make these pub to make the oops, to make the compiler stop complaining. So these two are equivalent. They're not quite equivalent, but they do the same thing.
00:04:17.800 - 00:05:13.560, Speaker A: And both of them are generic functions that can take in any type that implements, that can be turned into a reference to a stir, which is what this says and same as what this trait Bob does. What happens is if we write any function, let's say foo and it calls strlen of let's say hello world, and then it also calls strlen of string from hello in Norwegian. This is a good handy shortcut for picking examples. So this just to sort of see why these are different. Right. This is giving in a type of static stir. Oops.
00:05:13.560 - 00:05:54.100, Speaker A: This is giving in the type of string. Whoa. Right. So this is where we get into the point of this function is generic. It doesn't just accept a string reference, it accepts any type that can be turned into a string reference. So string, for example, implements as ref stir, because if you have a reference to a string, you can trivially get a reference to a stir, because the internal representation of a string is a star, right? So here we immediately see sort of why generics are useful. It is because it enables you to call into a given function in a more flexible or ergonomic manner.
00:05:54.100 - 00:06:59.282, Speaker A: And behind the scenes, what happens, and this is what the, the rust book is talking about when it talks about monomorphization, is that the compiler actually generates two copies of this function, one for each of these types. So at compile time, what we're actually going to end up with is like a stirl and ref star, which actually takes a stir and calls S len. And we're going to end up, and we're going to end up with a strlen string, which takes a string and does the same thing. Right? So this one generic definition gets turned by the compiler into these multiple non generic implementations. That's the process of monomorphization. And this is sort of key to how generics work in rust. And this process doesn't just happen for functions, they happen for types too.
00:06:59.282 - 00:07:36.052, Speaker A: So imagine that you have a hashmap that's generic over like the key and the value. You actually get a full copy of the entire struct and all of its methods, one for each type that it is used by. Notice that it doesn't generate copies of this for types that we didn't invoke it with. This is not like a generate for every possible type. It is generate for any type, like sort of on demand, but on demand determined at compile time. If you see code that needs this function for a given type, then generate it at that point in time. And a type would be the same like hashmap would.
00:07:36.052 - 00:08:38.910, Speaker A: Only, a particular instance of the hash map type would only be generated if that type combination actually appeared somewhere in the, in the code. This is actually also one of the reasons why it's a little bit hard to make rust to compile rust code and then ship people a binary that they can use as a library. Because imagine that if you had this in a, in your rust library that you wanted to sort of distribute in binary form, think like dynamically linked libraries and stuff. Um, it's actually fairly complicated because the contract is that rust is supposed to generate distinct copies of this function for each type, but it might be instantiated with a type in a consumer that isn't defined where the source function is defined in the originating library. Um, and therefore you need the source in order to generate all those instances. Um, and the reason why monomorphization is great is because you end up, um, producing potentially much more efficient code. Right.
00:08:38.910 - 00:09:51.030, Speaker A: Sterling is a bit of a bad example here, but let's imagine that we had something a little more complex. Actually, a good example is hash map. I'm not going to write out the full definition of a hashmap here, but what do you end up with? Hashmap is because you'd get a copy of the type for each concrete type you use. Imagine that one instance of the hashmap has the key be a string, and another instance has the key be a number. You would actually end up with the compiler when it generates the code for each of the methods of the hashmap it would generate, like it would sort of inline the definition of, say, the hashing function for each key type. So the hashmap version of the code that uses string would sort of put in the code for hashing a string directly into the hashmap code, and it could optimize that code based on the fact that that type is a string. Similarly, for something like a number, it might be able to skip hashing altogether because it realizes once it sort of monomorphizes all the generics, that actually the hash is just the value of the number.
00:09:51.030 - 00:11:14.220, Speaker A: That might not actually be true, but you get the sense of like the compiler gets to see the concrete written out code for the particular types that are used, which lets it optimize a lot better. Does this all make sense before we move on to the sort of more complicated aspects of this, does the general idea of sort of generics and why monomization is nice make sense? So the downside someone observed in chat is. Yeah, for, for monomorphization, one of the downsides is that your binary ends up being larger because you need to generate a copy of the type or the function for every type that it's used with. It's not quite as bad as like just multiply by the number of types. One of the reasons is because for hashmap, for example, you might only use a subset of the methods for any given type combination, and it will, it won't generate like, like if you ever have a hashmap that has string as the key type, it generates the entire hashmap. Like all of the methods for hashmap, for the string key type, it will only generate the methods you actually end up calling. So that amortizes the cost a little bit.
00:11:14.220 - 00:12:32.348, Speaker A: But, but it is true that it leads to more code in the, in the final binary. And a sort of side effect of that is that your code can be a little less efficient in the sense that now, rather than having one function called Stirlen, that like one sequence of like assembly, like machine code really, that the computer can jump to, and then it can keep those lines of machine code like in cache, which lets it execute it more, more efficiently the next time around. What you end up with instead is you have two different functions, and some code jumps to one and some code jumps to the other, and they have to be cached separately because they're separate regions of memory. As you actually end up with a slightly worse cache efficiency for your instruction cache, which is a downside. It's also a little bit expensive in the sense that the compiler does need to generate these copies. But, but usually that's not too much of a cost like actually generating these, unless you end up instantiating with, with a very large number of types. Is that one of the primary reasons rust binaries are larger than c one s so that that is slightly different.
00:12:32.348 - 00:14:05.780, Speaker A: Rust binaries statically compile more stuff, which might be part of the reason part of it is monomorphization. Part of it is I forget the exact details, but I think there's more stuff from the standard library that gets up compiled in. And another really big one is that rust often builds in debug symbols, which if you don't strip them from the binary, you end up with a binary that has very little actual machine code, but a lot of debug symbols, as you might want to try to just strip the binary. Will the compiler try to inline generated functions? Yeah, so this is one of the reasons why monomorphization is really good, is because it doesn't just like in life, whether it's string or stir. But if you have, say a pubfen like a bool, then which takes a boolean and it takes an f, which is a function, and it returns you an option till, and then let's say the implementation is something like if b then sum f else. And this, this function actually just landed in the standard library, although as a method on bool. So here, if you ever ran this function with a particularly provided closure or function, it would actually generate a copy of bool.
00:14:05.780 - 00:15:01.752, Speaker A: Then with the code for the closure you passed in directly inline into this function, and so it could be optimized accordingly. See, it does end up inlining, or inlining is the wrong word here it has the option of inlining and optimizing as based on that. It doesn't have to, it's just that because it gets monomorphized to the particular type, it knows exactly what that type is, and it can choose to inline if it wishes, which is an important distinction. Big reason for larger size is standard lib. That's not quite true, because only the parts of the standard library that you actually use end up getting put into your binary. It is true though that if you're using a lot of generics from the standard library, that ends up growing the size. How big of a cost is duplication of methods? Basically none.
00:15:01.752 - 00:15:56.700, Speaker A: I think the actual generation of multiple functions isn't that important. But what is important is if you generate many copies of a function, you have to compile each of them into machine code, which slows down the compilation process. Wouldn't Sterlin string take ref string rather than just string by value? It can take either. Actually, they will both work, which is one of the reasons why taking as ref star is nice. How do dynamic libraries handle generics? They don't this is like one of the reasons why it's challenging to do dynamic linking of rust libraries, or even just distributing rust libraries in binary form. And it's something that I think in swift they've been trying to stabilize something like this. We don't quite know how to use it for rust yet.
00:15:56.700 - 00:16:52.240, Speaker A: And yeah, you can't use it for something like, if you want a c dialib, like a dynamically linked library in rust that has a bunch of like extern functions. Those can't be generic. All right, so now that we have an idea of what monomorphization is, I want to talk a little bit about what the actual process of dispatch here. So dispatch is the idea of actually, let me give you a slightly better example that we can work with for a little bit longer throughout the stream. So let's define our own trait. We're going to call this trait, just call it hello. It's simple enough.
00:16:52.240 - 00:17:41.460, Speaker A: Or I guess let's go with the norwegian high. And it just has one method, and let's say it actually returns nothing. It just has a symbol as a single function that just lets you say hello in a region. And we can imagine that we implement that trait for, let's say stir. And all that's going to do is it's going to print line self oops. And then we're going to do, I guess let's just go with j. Hi.
00:17:41.460 - 00:18:35.070, Speaker A: Ah, can't type today. All right, so, so what happens behind the scenes here is that when the compiler tries to generate the code for this, right, it needs to, it determines the, the type of this. Then it looks up like what it looks at, which methods are available on just the stir reference type. It doesn't find one called hi. And then it looks at the traits that are in scope, it finds that there is a high method on this which is implemented for the receiver type, and so it ends up calling. That seems fine. Now let's imagine that we have a sort of generic version of this where we take something that implements high and I guess h and it's just going to call hi.
00:18:35.070 - 00:19:12.996, Speaker A: So this one's trickier, right? When the compiler has a generate the machine code for this, it needs to somehow call this method, but it doesn't actually know the type of h. And this was where monomorphization comes into play, right. That in reality what's going to end up being generated is a bar stir, which has hb stir. Right. And now dispatching this like figuring out where to, what to call here is trivial. Because we know the concrete type. So this is what's known as static dispatch.
00:19:12.996 - 00:20:31.040, Speaker A: That is, at compile time, the compiler knows what the actual type is, and therefore when it tries to call this method, it just knows that that is this method. And it can just jump to like, this basically becomes a call and like assembly code to call this function, which is at some known level location in memory, right. Because it's just where this method is. Does that make sense for static dispatch? Right. That actually figuring out how to compile this code becomes trivial once you can generate this method, because this method is really the same as this, and these are both trivial to figure out where the hive method lives. So now that we've looked at this sort of static dispatch, you might wonder, well, what is the alternative, right? What if we don't want to generate a bunch of different copies for this? So this is where we go back to dynamically sized types of, oh, sorry. Yeah, impl high here is just syntactic sugar for generics.
00:20:31.040 - 00:22:12.040, Speaker A: This is equivalent, like I showed with sterling before, this is equivalent to h is high h. These, these two are equivalent. Yeah. So what then is the alternative? We don't want this monomorphization, we don't want multiple copies. Or the other reason why you might imagine this is, let's say that you want to, let's say you have a vector of things that implement high, right? So I want to, in foo here, I want to have a vector of this and I want to do like for h in this vector, call h dot hi. That's fine if they're all the same type, but what if I wanted a sort of collection or sequence or set in some way of things that are high, but I don't, I don't need them to actually be the same type. All I care about is that they implement this trait, right? So, so more concretely, imagine that I want to write bar and I want to take anything that is a say slice of like impul hi, let's start, start with this version, right? So for h in s h, dot hi, this works fine.
00:22:12.040 - 00:23:06.562, Speaker A: I can call bar with, say a, with something like this that works just fine, that compiles just fine. Similarly, I can do, I can turn each of them into strings. That also works just fine. Ooh, oh, right. I didn't implement this for stringental, so that was just fine. But let's imagine that I want to be able to call it with like, this should really be fine, but I can't do that, right? Like the, I can't create a vector of things that are different types. That's not a thing that I can make in the first place.
00:23:06.562 - 00:23:34.010, Speaker A: What I really. But, but in this case, I don't actually care what the concrete type is. I don't care that these are strings. All I care about is the fact that I want them to implement the height trait. That's all that matters to me. So I should be able to create a vector of things that have this behavior without caring about the concrete type. And this is where we get into the sort of area of dynamic dispatch and trait objects.
00:23:34.010 - 00:24:27.332, Speaker A: And the book has a chapter on this too. Let me find where that one is. I've opened it in the wrong order, which was silly of me. Sorry about the jumping around. It is down here in the chapter here. So the book has a pretty decent chapter where it talks about the ability to treat things that are different concrete types as the same type. So another example that they use is in a, in the case of like a gui, you might have lots of things that are drawable, like they implement a draw trait and you might be able to take, you might want to have like a draw function that just takes a sort of list or iterator of all of the things to draw.
00:24:27.332 - 00:25:13.400, Speaker A: And some of those might be buttons, some of those might be images, some of them might be text boxes, but it doesn't really matter for the draw function. All it cares about is that it gets an iterator of things that are drawable, which has a similar sort of flavor to this, right, where we want to just take a slice of things that I can call high on. And what you need is what's known as a trait object. A trait object is where you see the din keyword. This is actually going to compile. So what I'm going to do is sort of, this is sort of what I want, right? So impl remember is a shortcut for. And this is where it'll be useful to actually write out the types as a shortcut for this.
00:25:13.400 - 00:25:46.366, Speaker A: And this sort of gives a clue to what's going on. Bar is generic over one type, which has to be either a string. It can't be both because it's only generic over one type. And you can imagine we had like an h two high here. But given that we're taking a slice or let's say an iterator, um, there is nowhere to put h two. There is only the one iterator, which only have, has items of one type. So this won't really work in some sense.
00:25:46.366 - 00:26:21.826, Speaker A: What we want to say is that each of the things is a high. It, it doesn't have any other concrete type that we care about. And in fact, if we write this, we get a compiler error saying, let me pull this up in a new screen. It says trait objects without an explicit din are deprecated. Okay, let's get rid of the warning first it's saying we need to put din here, so we're just going to do that. And now it says the size for values of type din. Hi cannot be noted.
00:26:21.826 - 00:26:48.190, Speaker A: Compilation time. Right. So it points to this and says doesn't have a size note compilation type. The trait sized is not implemented for Din. High slice and array elements must have a size type. This is an error that you might have come across before. And part of what we're going to be talking about for some of the remainder of the stream is why we get this error, what it means, what the fix is, what size means, and sort of how this ties into dynamic dispatch and trait objects.
00:26:48.190 - 00:27:52.930, Speaker A: Let me pause here for a second because I've just thrown a bunch of stuff at you. Let's see whether it makes sense. So there's a bunch of discussion of dark mode and light mode. So really what we want to say is which you can think of this as sort of type erasure, right? We want to say that I want to take a collection of things that, and I only care about the fact that they implement this trait. I sort of want to take an abstract notion of this trait. All right, so the challenge of the compiler is pointing out is in this case, where are we going to even start with this? All right, I think we need to talk about sized first. Um, so let's go to the sized trait.
00:27:52.930 - 00:28:20.054, Speaker A: So the size trait has no methods. It is a marker trait, is what is in the, the marker module. And the description just says types with a constant size known at compile time. Now, most types are sized. Like if you create a struct foo, it's probably sized. Most types in the standard library are sized. In fact, there are very few types that aren't sized.
00:28:20.054 - 00:29:04.790, Speaker A: So few, in fact, that every trait bound you have, even if it's just like a foo t, has an implicit bound of requiring that the type is sized. And to see why, think about what happens when. Let's just sort of comment this out for a second. Let and comment this out for a second. I just want to get, actually, I guess I can do this smarter. So let's sort of go back to our very simple stirling example. In the very beginning right.
00:29:04.790 - 00:30:22.850, Speaker A: It's going to be generic over sum s that implements SreF stir, it takes that s and it returns usize, right? So imagine that some, something wants to call Sterling. Well, Sterling takes an argument that is that s. So it has to be past a thing at like somehow it needs to be passed that argument. Well, the argument that it gets passed has to take up space on the stack or has to be passed in a register either, Orlando. Which sort of means that the compiler has to make sure that there's sort of code in the resulting assembly that like allocates the required space on the stack for whatever this argument is. And that requires the compiler knows how large the argument is. Right? If, if s here, I guess think of the concrete implementation, right? So strlen str here, this is just a, let's go with the string implementation.
00:30:22.850 - 00:32:00.422, Speaker A: So string is really just a, it's sort of two numbers and a pointer, right? It's the length of the string, it's the size of the allocation, and it's a pointer to the first character in the actual string on the heap. So it's size, the compiler knows that the size of this argument is three words, three use sizes, if you will. Right? And so it can generate the assembly code for this function and for calling this function trivially because it knows how much space the arguments take up. You can imagine something similar, right, where if we were generic over the return type, it would need to know how much space to actually allocate for the return type on the stack. And so even though we didn't specifically say that s is sized here, it just is basically always a requirement that the type is sized because if it wasn't, the compiler wouldn't know how to generate the required code for it. Right? All right, so why, why then is it compiling when we're trying to use this? Well, didn't, high is really just saying anything that implements high, like just something that generates high without giving a concrete value. Because remember we want this to be a slice of potentially like string and STR and whatever other types might implement this trait.
00:32:00.422 - 00:32:46.096, Speaker A: And those are all different sizes, right? A string is two numbers on a pointer, a stir is one number and a pointer. And you can imagine that we have some type foo that is like, like a gigabyte large as a struct or something insane, right? And we implement high for it. And that is also something that we might want to pass in here. So this slice doesn't have a size, it's, it's just not like if you, if you a slice is really just a contiguous piece of memory, right? Where each chunk is the same size. It's an array where all of them are the same size. But if we don't know the size of them, we can't guarantee that they are the same size. If I told you, if I gave you one of these, so didn't.
00:32:46.096 - 00:33:51.260, Speaker A: High here is not sized, right? Because it could be any type that was high, which could be any size. And I asked you, give me the fourth element. Normally in an array, because all the elements are the same size, the fourth element is just the pointer to the start plus like three times the size of one element, right? This is a pointer arithmetic to get to the fourth element. But, but if they're different sizes, you can't generate that code. And this is why it's saying slice and array elements must have a size type, because otherwise the type just doesn't make sense. So how can we fix this? Like, we really want to be able to do this, right? It would be insane if Rust didn't give you the ability to talk about things that implement a trait as a collection. And arrays aren't the only problem here, right? Even if we took, even if we wrote, what's a good example of this? Let's say we had a sterling two here that took a like din as ref star.
00:33:51.260 - 00:34:41.530, Speaker A: It has the same problem, right? If we, if I try to compile this, you see it says the same thing. Let me get rid of the other message. It says the size for values of type didn't as ref stir cannot be known at compilation time. Sized is not implemented for Dina function arguments must have a statically known size. Borrow types always have a known size, and then it tries to give you a suggestion for how to fix it. But this is sort of the key insight again that we need to, the compiler needs to know how large the type of an argument is, otherwise it can't generate the function call code. And so this is sort of like a fundamental requirement of the compiler that these types are sized.
00:34:41.530 - 00:35:29.406, Speaker A: Does that make sense so far? Like why this is a problem? Um, can you show us implementing sized? So sized is auto implemented for any type that can implement it. So if you do like, uh, struct foo with no fields, it is sized. If you add a string in there, string is sized. So foo is sized. If you add another bool like this, type is now still sized. Types are always sized if they can be. The exception would be if I did something like, and in fact, even if I did foo t.
00:35:29.406 - 00:35:55.430, Speaker A: And so that this holds a t, it's still sized, because remember that there's an implicit requirement for every trait bound that it is sized. So there's sort of an implicit t sized here. And so that means the t is sized. So all the fields are sized. So therefore foo t is sized for any t. So you never implement sized yourself. It is only ever used as an auto trait.
00:35:55.430 - 00:37:27.660, Speaker A: The issue is not stack size. The issue is not that it might not fit on the stack, it's that in order to call a function just at the machine code layer, or think of it as the assembly layer, in order to call a function, you need to know when you call that function, how much space do you allocate for the like stack variables of that function? We might include some of its arguments. Or on the caller side, when you have to allocate the space for the return value, how large should that space be? Fundamentally, that just requires that you know how large the space is, because you can't generate the machine code for making that stack. There are like sneaky ways you could do this, but basically you require the compiler, in order to generate efficient code, has to know the size of these things. Let's see what things aren't sized. So we've talked about bear traits. So this is, if I write pub Fn Foo and I just say that I take a high, right? Hi.
00:37:27.660 - 00:38:08.320, Speaker A: Here is a trait, and lots of things implement a trait and they might all be different sizes. So this doesn't have a defined size. If I say impul here, right, impl is a shortcut for hi. So this, the h is sized because we get a copy of foo for every concrete type, and for each of those copies, the size of the type is known. So if we use static dispatch here from monomorphization, this is fine. But if we just try to take like the trait itself, saying basically this function takes anything that implements the trait. This won't work because this is not sized.
00:38:08.320 - 00:39:05.560, Speaker A: And this is equivalent to writing didn hi, this is not sized. We'll talk in a second about how you, how you make something like this sized. The other example is something like, if we go back to my, my struct foo, if you try to have it hold a stir, stir is not sized because a string can be any size. Sort of. If you think about not the pointer to the string, but the string itself can be any size. The same with like this, just like a slice without a reference is also not sized because you don't know how many elements there are, right? So it doesn't have a well defined size. Those are the two best examples I know of, of things that aren't sized and then anything that in turn contains those types.
00:39:05.560 - 00:39:55.138, Speaker A: There's a lot of discussion in chat trying to explain the things that I'm about to explain on how we fix this and why you need references and stuff. I will get to it, I promise. Great. So I think roughly where we've gotten to so far makes sense, it seems like. So the question now becomes, how can we resolve the situation? Right. We want to be able to take a, for our sterling two here, let's call it sterling din. Maybe we want to be able to have a method like this that doesn't get monomorphized, but this is in size.
00:39:55.138 - 00:40:29.522, Speaker A: So what do we do? The trick here is to make this be a type that is always sized. And the way that we do that is by indirecting it through some type that is itself sized for any inner type. An example of this is a reference, right? So a reference is always the same size. It's just the size of a pointer, or in some cases two pointers. We'll get to that in a second. Right. This does have a size, right.
00:40:29.522 - 00:41:12.750, Speaker A: The compiler always knows how large one of these are, no matter what the type that follows is. Right. Because this is just a pointer. The same would be if you have a box. Right, a box also just a pointer to the heap. And so once we do this, the, the size of this argument is now known and we're fine. And this is in fact how you take something to take a trait itself without monomorphizing is you place it behind some kind of pointer type, like a reference, like a box, like an arc.
00:41:12.750 - 00:41:48.110, Speaker A: The way this works in practice is that if you look at the definition of box. So it has magic in it, right? It's not magic, but it has a bunch of stuff inside of it. Basically it just has a pointer. It's not quite true, but close enough. Box actually has a, has this definition on it. And the question mark here means does not have to be. So it's basically opting out of the auto bound that gets added of everything has to be sized, saying for box, the t does not have to be sized.
00:41:48.110 - 00:43:02.840, Speaker A: And that's why you can create a box of something that itself is not sized. And the reason this works, right, is that when you create the box initially, you make an allocation that's the size of whatever you're going to put inside of the box, right? So let's say the, let me sort of make a main here that's gonna exemplify this. At some point I have to do like box new of say string from hello. Right? And then I can say that now this is going to be a din as ref star should say Xdev and this should say stir. And then I can call Stirlen Din with y. So at some point when I created the box, I had to give it something with a concrete type and at that point it allocated on the heap space for that, that type. But the box is still of a known size because it's just the pointer.
00:43:02.840 - 00:44:07.540, Speaker A: When I turn it into a box for this, it's still just a pointer conceptually, even though the thing it points to might have an arbitrary size. But the actual argument that we pass to this function does have a size and therefore we can generate the relevant code. Does it make sense? Why indirection through a type like this, where the indirection type size is known? Does that make sense? We'll talk about combination of traits too. Let's see. I promise we'll get to multiple traits. Can't you just put Boxdin Sref stir directly on x? Yeah, so you can do this too. Sref stir, that's also fine.
00:44:07.540 - 00:45:02.318, Speaker A: But even so, you still had to provide a concrete type to box new that was sized. When should you use box over references? Like when you choose this over this, there's no hard and fast rule there. In general, the advantage of box is that it's static, so you can keep using it even after the stack frame of the caller goes away. So it's the same as when do you choose box over references normally. Can I also then give the function a reference to the stack? Yeah, exactly. So you can also do, let me do that down here so I can totally do. And then.
00:45:02.318 - 00:46:12.110, Speaker A: Sterling, why? Right? Yeah, so this, let's say I have a din two that takes this, and this can call din two. Why is this complaining? It's because box has an SRF method too. That's why the double asterif is needed. Yeah, so you see, I can do the same for something that's on the stack. I can create a sort of go through a pointer indirection here and then pass it to something that takes a reference din. And in fact, I think I can even do this. Yeah, that's fine.
00:46:12.110 - 00:46:39.430, Speaker A: It's not, not terribly important why that doesn't work. So what we just constructed is known as a trait object. It is an object that has the only, has the property that it represents a trait. So this is what trait objects are. They are things that only behave as some underlying trait. This is a trait object and this is a trait object. It doesn't matter what the wrapping type is.
00:46:39.430 - 00:47:28.970, Speaker A: Box is kind of a pointer type. Yep, box is a pointer type. Can I convert a trait object to its original concrete type? I'm gonna go with no, but technically yes, sometimes, but, but in general no. You can think of it as this is essentially type erasure. You can technically go back through like unsafe transmutes and stuff. But in general, the moment you turn it into a trade object, you erase the knowledge about what type it used to be. Yeah, there's like some magic around unsafe and some magic around the any trait that you can use, but in general you should ignore that.
00:47:28.970 - 00:48:07.960, Speaker A: Also note that when you do this, you only retain the ability to use this trait. You erase all other knowledge of what the concrete type was. So the only thing you can do on a boxed in SrEF stirrer is call asref on it, nothing else. Same thing here and we'll get into why in a second. All right, so this raises an interesting question. Let's, let's take the example. Let's make this the two and this the one, and just swap these around so this still compiles.
00:48:07.960 - 00:49:05.070, Speaker A: Let's now think about what actually happens when the compiler has to generate the machine code for this function, right? At some point it has to actually do the compilation and produce assembly code that it can in turn be turned into like runnable machine code. So s, here is some type that implements sref. In fact, let's go back to our high trait. That's going to be a little bit nicer. So let's go back to here and let's say that I want a say hi, which takes a din high returns nothing and just calls hi. Right? So this is going to be, this takes a trait object for the high trait, but when the compiler generates the code here, it doesn't know what type s is, right? It's just, it's the trait object. Like it, it's really just a pointer.
00:49:05.070 - 00:50:38.270, Speaker A: So how does it call the high method? Remember in the generic case static h. In this case we actually get a copy of this for each concrete type, right? So really this turns into this. And for this concrete implementation, generating the machine code is trivial because this is really just like an assembly call to like whatever it is to this line to line six. It's not actually line, it's memory locations in the binary. But you get the idea, right, that the compiler knows like statically at compile time where to go here. For the dynamic case, though, what do we call, we don't know that this is a stir or a string, right? So we don't know whether to generate the address of this, the address of this, or the address of something else entirely. So what machine code does this turn into? Well, this is where we get into dynamic dispatch and I V tables or virtual dispatch tables.
00:50:38.270 - 00:51:23.896, Speaker A: So the trick to constructing a trait object is that the, it's actually not quite true that the reference or the box is just one pointer wide. It actually carries a little bit of extra information about the type that is pointed to. So here, let's go back to the, back to the, the rust book. So the rust book has a chapter on dynamically sized types and the size traits. This is under the advanced type chapter. And what it's talking about is, in fact, it doesn't even talk about as much as we wanted to talk about here. All right, let's use the rust reference instead.
00:51:23.896 - 00:52:05.400, Speaker A: So the rust reference on dynamically sized types says most types of a fixed size that is known as compile time, and implement the type. The trait size, like we've talked about, a type with a size that is known only at runtime is called a dynamically sized type, or informally, an unsized type. And this is a slices and trait objects are two examples of dynamically sized types. The reason why this is only known at runtime is at compile time. We don't know what type is going to be, right. It's only at runtime that we'll know. And we can sort of, to give, to make this a little bit more concrete, imagine I have a main function where like I, if rand, I don't have a random number, random is four.
00:52:05.400 - 00:52:51.730, Speaker A: If random is four, then say hi of this. Otherwise, say hi of string from world, right? And let's imagine that random was more random than four. You don't know until runtime. Like, let's, let's say this was like, read from the user at compile time. You don't know which actual type is going to be used. Here. It's only determined at runtime by some input that can't be predicted at compile time.
00:52:51.730 - 00:54:06.280, Speaker A: Right? So that's why this is determined at runtime. And it says pointer types to dynamically sized types are sized, but have twice the size of pointers to size types. So pointers to trait objects also store a pointer to a V table. And this is where we get into what is a vtable. Well, when you have a trait object, something like add in hi. What actually gets stored in the, in the reference is one, a pointer to the actual concrete implementing implementing type and two a pointer to a V table for the referenced trait. So then what is a vtable? So a V table or a virtual dispatch table is a little data structure that has pointers to each of the methods for the trait for the type.
00:54:06.280 - 00:56:04.030, Speaker A: So in the concrete case of the high trait, so let's say we have a din high, the v table is going to be sort of, you can think of it as a high vtable struct that only has one member which is high, which is a pointer to an fn. And fn actually that itself takes a pointer to whatever the t is. So basically a different V table ends up being constructed for each concrete type turned into a trait object. So when we start out with let's say that we have a stir and we want to go to a din high, what actually gets constructed is a, let's say we have a, well, number one becomes a pointer to the str and number two becomes a high vtable where high is stir as high hi and a pointer to that. When you make this conversion, the compiler knows that it has to construct this vtable and it sticks the address of that vtable inside of that reference. So this reference contains two things, the pointer to the actual type and the pointer to the v table that the compiler generated during this particular conversion. So there'll be one such v table for each type that gets turned into a trait object.
00:56:04.030 - 00:57:19.290, Speaker A: And so now when this code, when the compiler tries to generate this code, what it actually generates is like s dot v table dot hi s dot pointer. And so if someone passed in and say a string instead, it would have a different vtable. So the s dot v table would be a different pointer. So in this case this would be where stir high like line six, right? So this would be a pointer to line six. But if we instead went, I'll stop for questions in a second. If this instead went from a string to didn high, it would be a pointer to the string and string as high, which is this method up here on line twelve. So in other words, this code that gets generated will work regardless of which type is passed in because we indirect through the vtable and each type has its own distinct vtable.
00:57:19.290 - 00:58:34.930, Speaker A: Alright, that was a lot to throw at you at once, but hopefully it wasn't too bad. Let's see, are the vtables themselves statically built at compile time or they also allocated dynamically? The vtables are the vtables are built at compile time, they're built statically. And so in general, the second part of the so this is what's known as a fat pointer or wide pointer, because it has two pointers in it, not just one. So anytime you see, anytime you see this, it's actually a wide pointer. And in general, the second pointer in there will always be known statically because it's determined by the original construction of the trait object. The reason I say generally is because you technically can construct it on the fly. Like there's, there's nothing in the calling here that requires that it was known statically.
00:58:34.930 - 00:59:51.314, Speaker A: So you could imagine manually constructing a vtable and this is used. We'll actually talk about that a little bit later. Ref stir also contains the length of the string slice, yes. So in general this will actually be this. So it's not a pointer to the actual string, it's actually a pointer to the stir reference, which itself holds the length. Can we debug print that vtable struct somehow? I don't know of a way to get the compiler to print its vtable struct, but it's basically just this. It just, there's a member for each method of the corresponding trait that this is a trait object for, where each member is, each member is a corresponding method, and the value is the pointer to the implementation of that method.
00:59:51.314 - 01:01:22.552, Speaker A: For the concrete type, then why are trait functions that don't take self not object safe? Couldn't the compiler just generate an FNM itself that doesn't use self? We'll talk about that in a second. Does it construct a new vtable every time we create an instance? No, the vtable is generally statically constructed for the type of it doesn't get constructed dynamically. Are identical vtables detected? No, there's no deduplication of these, and in fact they are guaranteed to not be duplicates. If you implement a trait for two different types of, then the implementations, even if they contain the same code, are still distinct locations in the source code and in the resulting binary, and so would have different addresses. Trait objects of more than one trait we'll get to in a second. So box din is a thin pointer that points to a wide pointer that points to the object. No, if you have a box din high, that box itself is a wide pointer.
01:01:22.552 - 01:02:10.360, Speaker A: So box is a little bit of a special type. Actually, it's not that special, it's just that box internally contains a muted high, and the rust compiler knows for references and pointers that if they are trait objects. They're actually with two. So box isn't special, but pointer types are. So box is itself wide. You don't end up with an extra indirection. Yeah, we'll talk about nightly APIs for trait objects too.
01:02:10.360 - 01:03:27.374, Speaker A: All right, so I think we're now at a point where that roughly makes sense. So there are a couple of reasons why trait objects are a little bit more constrained than being fully generic. So for example, let's imagine that you wanted to have a pub fn baz that took an s that is din din, let's say hi plus as ref stare, right? And we're going to do like s dot hi. And then we're also going to say let s is s dot Sref and then we're going to do s hi again because we know that strings themselves implement high. I guess maybe that's confusing, maybe I should just do lent. The compiler here is ambiguous. All right, let's get rid of the ambiguity.
01:03:27.374 - 01:04:18.090, Speaker A: It's not really relevant to the discussion. It still won't let me do it. Why not? Do I have to do this maybe for it to not be ambiguous? No. All right, I'm just going to let's pretend that the syntax worked for a second here. So basically I want to say that I want a trait object of two different traits. This won't actually compile. And ignoring the parsing error for a second, there's actually a bigger reason why this won't work, which is we need in order for this to work, we need to know both where the high method is and where the Sref method is.
01:04:18.090 - 01:05:06.606, Speaker A: But those are contained in two different v tables. One is the vtable for high for the concrete type, and one is the vtable for azref for the concrete type. And so what we'd actually need is not just a two wide pointer, but a three wide pointer, a pointer to the data, a pointer to the the V table for high, and a pointer to the vtable for the, for Sref. And that's possible. There's nothing that's sort of inherently impossible by that, but it would mean that as you add more traits, the size of this reference just keeps on growing. And that's probably not what you intended. And you might go, well, can't the compiler just generate a vtable for the combination and then pass that in? That is something that in theory it could do.
01:05:06.606 - 01:05:50.520, Speaker A: The rust compiler doesn't currently do this. I don't know of a proposal to do it. Part of the reason is because you can get away with, you can get around this by saying pub trait hi as ref and it requires that the type is both high and as ref stir with no methods of its own. And now I can do this right, because now there's only one vtable and that v table is high as ref. And the compiler knows when it has to generate the vtable for this trait. That includes all the methods from both of these traits. And so this vtable is going to be larger because it is going to have both the high method and the asteroid method.
01:05:50.520 - 01:06:57.962, Speaker A: And so I think part of the reason this hasn't landed in rust itself is because you can, you can opt into it yourself. And by not automatically turning the plus into a larger vtable, you basically tell the, you tell the developer that this might not have been what you meant, but if it is, you can do this thing instead. I agree, the compiler error here probably have been better, right. Summone Esteban Kuber that maybe we could sort of inform people that they can generate their own trait here. I think it's, someone wrote, I think it's high plus as ref stir. Let's see if that's true. Yeah.
01:06:57.962 - 01:07:26.490, Speaker A: Okay, so, so that is the, the way to get the right compiler error, which is only auto traits can be used as additional traits in a trait object, whereas here you have an example of two different traits that are, neither of them are auto traits. We'll talk about that in a second. And here it does actually give the suggestion we talked about. Right. Consider creating a new trait with all of these as super traits and using that trait here instead. Instead. And it also points out that auto traits like Send and sync are fine.
01:07:26.490 - 01:08:30.610, Speaker A: And basically the idea here is that for marker traits, like if I want to say hi plus send, send doesn't have any methods, so it's fine for the vtable to be empty, and therefore we don't need to store that additional part of the vtable because there aren't any methods in it. So that's why it's okay to have additional traits with no methods. I don't think you can use your own. Like if I did a Fuchs trait and I said this plus fuchs, I don't think that'll work. But there's been some proposal of having like a marker annotation to declare a trait as never having methods, but that's not something we currently have. So at least for the time being, this is the way that you should do it. Great.
01:08:30.610 - 01:09:03.960, Speaker A: All right, so that is how this works with combinations of traits. But that's not the only example where trait objects are a little bit limited. So the other one is, let's imagine that for, hi, we added a. Actually, let's start with saying that we added an associated type. Let's call it name. And we don't actually use it for anything, we just add one. The code already doesn't compile.
01:09:03.960 - 01:09:39.322, Speaker A: Why doesn't it compile? Well, the value of the associated, oh, that's the implementation. Let me do that. So this is going to be type name equals unit. Just going to use that for both of them because we don't actually care about the type. Yeah. So here it says the value of the associated type name from the trite high must be specified. So it says here where we take it in high, we actually need to specify the associated type.
01:09:39.322 - 01:10:26.538, Speaker A: We can't just say we take any high regardless of what is associated type is. And the reason here is because that information can't be captured in the vtable because this is a type. It's not, it doesn't have an address in the binary. It doesn't have anything we could stick in the V table and therefore this won't work with a trait object directly. Instead what you would have to say is I take a high where name is this and I think we need to do the same down here. And then that works because now we have a V table specifically for anything that implements high where the associated type is name. So that's fine.
01:10:26.538 - 01:11:08.958, Speaker A: Let's undo this because it's not a very interesting change. The other perhaps more interesting case is let's say that we want a, what do we call, I'm going to call it, we're going to call it like weird. We're going to have a weird function that does nothing, no one needs to implement it. And you see that this also does not compile. If I run cargo check, let's make this a little bit smaller so that hopefully it's a little easier to understand. Hopefully it's still readable. Ooh, that's very verbose.
01:11:08.958 - 01:11:43.426, Speaker A: Let me comment out the combination trait bit just to make the errors a little nicer. All right, so this says the trait high cannot be made into an object. So when we say didn't, hi the. Basically it's telling us that the high trait is not object safe. That is, it cannot be turned into a trait object. And it says for a trait to be object safe, it needs to allow building a vtable to allow the call to be resolvable dynamically. So this is what we've been talking around through so far.
01:11:43.426 - 01:12:27.816, Speaker A: And in particular here it says the trait cannot be made into an object because the associated function, weird has no self parameter. It doesn't really talk about why that's necessary, though. But let's try to work through it. So again, let's say that down here in our say hi. Right, we now try to call s dot weird. So imagine what, what would the compiler do if we wrote this code? Well, we can't really write this code, right? Because weird doesn't take self, it doesn't take a pointer to anything. And we can't just like randomly construct a pointer to it because that would mean that we need to have a valid instance to it to have a pointer to it.
01:12:27.816 - 01:13:45.514, Speaker A: So this is really just saying like didn hi, like colon, colon weird, which I don't have to tell you, seems weird because which type are we calling weird on here? There is no like nothing here specifies which actual weird implementation we want in this particular case, because it's an over, because it provides a default, you might think it's not a problem. Well, what if there was like an implementation of weird for string that was different from the one on the trait which is allowed, right? You can override a default implementation. Well, how would this know whether to call the one for stir or the one default for the trait or some entirely different one? It can't be in the v table because there is no s here, right? The weird method doesn't take itself, it's not associated with a given instance of any type. So this just doesn't work. It's not a meaningful thing to say. But what if you really wanted this? Like you wanted the weird function to exist, but you're like, I don't care about calling this through a trait object. I only care about the high thing through a trait object.
01:13:45.514 - 01:14:43.098, Speaker A: So I want hi to be traits, trait object safe. But if you have a trait object to hi, I'm fine if you can't call it weird. So you can do this, this, and let me go back down here, have this bee hi again, s dot. Hey. So what we're saying here is that the weird function requires that self, that is, the type that implements the trait, is sized. And we remember that traits aren't sized if you just have like din high that's not sized. It's only sized if it's behind a pointer type.
01:14:43.098 - 01:15:29.350, Speaker A: So this is basically a way to opt out of the vtable is the way that you can think about it. It's saying this function shouldn't be placed in the vtable and crucially, shouldn't be callable through a trait object. What this means is in here. Let me get rid of the static versions because they're just in the way. What this means is now the code compiles just fine. I can call hi, I can make a trade object for it, but if in here, in fact I can go even further and say, let's say that this did have a self, but I wanted to opt out, then this still compiles. I can still make a trait object for it, but let's say that I try to call weird in here.
01:15:29.350 - 01:16:21.360, Speaker A: The compiler is going to tell me the weird method cannot be invoked on a trait object because the method has a sized requirement. And so this is the way to opt out for any given function from having it be included in order to make sure that the, the trait remains object safe. You can also opt, you can also say that the entire trait should not be possible to turn into trait object by saying where self is sized. So if you do this, you're basically disallowing using this trait as a trait object. It's rare that you see this in practice. Usually the trait will like the trait just isn't object safe because there's a methods in it. Opting into disallowing trait objects is rare.
01:16:21.360 - 01:17:26.190, Speaker A: Sometimes people do it for backwards compatibility reasons. Like if you know that you might add non object safe methods later, you might add this proactively, but it's pretty rare. All right, do the restrictions so far make sense? Does the associated type problem also occur with static dispatch? No, it doesn't. And the reason is with static dispatch, because it gets monomorphized, you actually know the concrete type for any given function implementation. S colon, colon weird could be possible. So this is back when we had the fn weird, right? And let's say we also had an override here and now. Let's say you wanted to be able to, like, let's say we added like special syntax like this saying for the type of s called the weird method.
01:17:26.190 - 01:18:21.380, Speaker A: You could imagine that weird got included in the v table for, for the trait object, but it like knows to not call it with the self argument. The challenge here, right, is that this is sort of odd, right? Like if you require an instance of the type anyway in order to call it, then why doesn't it just take self, right? The traditional example of this, right, is that weird is actually called new or something like new, right? Where it doesn't. If you already have an instance of the type, you wouldn't need to call the method in the first place. It would just take self. So I agree. Like something like this maybe could be possible. I think in practice it's just not usually very useful and that's why it hasn't been a priority.
01:18:21.380 - 01:19:25.570, Speaker A: There might be a deeper reason why it's not added too. I'm not sure. Does where self colon sized also disallow implementing the trait for concrete dsts? You know, that's a good question. So the question is basically, if you have where self assized, can I implement high for box din as ref for example? I believe I can. The reason I say this should be possible is because, yeah, this, this now won't work because it can't be a trait object. But you can still have this implementation, I believe. Why does this, right, because it's a box.
01:19:25.570 - 01:20:10.024, Speaker A: So we need to have the double sref. This is fine because this is not a dynamically sized type. Right? Again, like when you wrap it behind a pointer, it now has a size is not dynamically sized. So it doesn't prevent that even if you have self sized on the trait. Um, the associated type restriction feels weird because the point of associated types is that only one exists for any given concrete type. So shouldn't the vtable know what the associated type should be like? It can't have a pointer to the type, but the implementation of the trait should know what the type is when it's compiled. Yeah, so the problem is that the type is erased.
01:20:10.024 - 01:20:38.304, Speaker A: All that remains is the v table. And so you can't tell from the v table what the concrete type used to be. There, there is an exception to this, which is the any trait. So the any trait has a method that returns a descriptor of the type of the concrete type that it used to be. If you didn't follow that, that's fine, ignore it. But basically there are some ways to sort of finagle around this. But basically trait objects are type erased.
01:20:38.304 - 01:21:20.430, Speaker A: Like you don't get to keep information about the, the type it used to be. Oh, you meant types such as stir you. Wait, no, you can't do that. Self has to be sized. When you have, where self is sized, there's one other restriction that you get with trait objects, which is that the methods cannot be generic. And for this, rather than sort of keep working on our weird high trait, I'm actually going to go to the standard library and look at the from iterator trait. So the from iterator trait is something that's implemented by VEc.
01:21:20.430 - 01:21:48.822, Speaker A: For example, this is how collect works is that VEC implements from iterator. And when you have. Well, so if we look at iterator collect, I guess is the best way to do it. Collect on an iterator requires that the thing that you collect into implements from iterator. So that's why you can have an iterator and collect into effect is because VEC implements from iterator. The from iterator trait is a little weird though. It a.
01:21:48.822 - 01:22:09.280, Speaker A: The. The a type of the trait is the type of the items of the iterator. But you also see that the from iterator type itself takes a t. And the t here is the type of the iterator, right. Because it has to be Vec. For example, it doesn't care what the iterator is. It can be.
01:22:09.280 - 01:22:34.146, Speaker A: It can. You can construct a vec from any type of iterator as long as the I. Well, you can create a vec t from any iterator where the item is t. This arguably should be called I for iter, but it's not terribly important here. A is the. The sort of thing that you'll end up with a vec of. So if this a was, say bool, you would end up with a Veca bools.
01:22:34.146 - 01:23:20.150, Speaker A: And the t is the type of the iterator, which might be something like, I don't know, like a hash map into it or whatever. Whatever that type ends up being. This poses a problem for a trait object though, right? Let's imagine that we try to write code against this. So I'm going to erase this for a second. In fact, I'm going to erase all of the remainder of this file. And I'm going to have, like, what are we going to do here? Let's do collect standard iter from iterator. We're going to take a from iterator of bool and we're going to return a vec.
01:23:20.150 - 01:23:48.480, Speaker A: And I'm going to do s dot collect. Oh, where I do. I did something weird tonight. Great. So this seems like it should be fine, right? I take anything that can I take. Well, actually, this is weird for a number of reasons. Maybe from iterator is a bad example here because it doesn't excel feather.
01:23:48.480 - 01:24:15.120, Speaker A: So it actually requires self to be sized. Anyway, extend is a better one. Let me dig up extend here. Great. So we're going to use extend instead. And it's going to have to take a mute then. So we're going to do let mute v is vec new then we're going to do v extend.
01:24:15.120 - 01:25:09.624, Speaker A: Actually, we're not even gonna do that. We're gonna take, this is gonna be the v, we're gonna do v dot extend and we're gonna give it just iter once true. So we're gonna just extend it with a extended, with a single bool add true, right? So we take in anything that can be extended with an iterator of bools, and then we try to extend it with an iterator that yields a single bool. So we're just going to add true. We're going to pen true to whatever thing we get. And here too, it tells us the trait extend cannot be made into an object because extend is, is not object safe. If we look at extend, that doesn't immediately make sense from what we've seen so far, right? So again, it's generic over the type of the items of the iterator.
01:25:09.624 - 01:25:44.090, Speaker A: That's fine. Extend take self. So we do have something we can stick into the vtable. And given an instance, we, we sort of know how to call this method. But again, notice that it's generic over the type of the iterator. And this is where it gets really weird. You can imagine that like inside of Vec, right? There's going to be impul taiden extend t for Vect and it's going to have this implementation.
01:25:44.090 - 01:27:29.552, Speaker A: I'm going to go ahead and call this I because I think it's more helpful. And who knows what's going to be in here, right? Just to get rid of that warning, I'm going to do this, I guess be a little bit more helpful. Myvec, like this implementation is going to exist somewhere in the standard library except just for Vec instead. But this method is generic. So we know from the monomorphization discussion that actually at compile time we don't end up with a single extend, we end up with multiple copies of this method, right? We end up with like an extend bool that takes no, an extend, I guess, hash map into iter, which takes a standard collection, hash mapdeh map into iterator, right? And in fact, even more than that, we're actually going to end up with, because the whole impul is generic. We're actually going to have this, that is the actual method that gets implemented or gets sort of generated by the compiler. Assuming that someone tries to extend using a hashmap iterator of bools, there is no one extend.
01:27:29.552 - 01:28:26.482, Speaker A: There is one for every combination of iterator and item types. So what gets put in the v table we've nailed down that we want to extend bool. So that's good, right? So, so there's only, we don't have to consider the, the t up here because we've already had chosen that t. But for extended self, we really, in the v table really needs to have a pointer to extending for this iterator type over bool. But that's not, that's not expressed in the type of the function, and we don't even have a way to express it. Right. You could sort of imagine like wherever, like v's implementation of extend is standard iter once bool or something super weird like that.
01:28:26.482 - 01:29:09.370, Speaker A: But the way that it's written, nothing here says that we want the vtable to point to the extend implementation for a standard iter once. And therein lies the problem. When the compiler tries to generate this code, there is no pointer to the appropriate implementation of extend. Therefore the vtable can't be generated. You can't generate a vtable for didn't extend because it would have an infinite number of entries, one for each possible implementation of extend. And so therefore the answer just didn't extend cannot exist. You cannot create a trait object for extend.
01:29:09.370 - 01:30:40.720, Speaker A: All right, does that make sense? That's a somewhat intricate explanation, but hopefully it all sort of ties together here. Could rust C add a monomorphized version of extendextend for each t it's called with to each type that implements extend. That's tempting, but it's not always possible, right? So imagine that you're compiling this code, but I mean, even just for the standard library, right? Like the standard library has a bunch of uses of extend, but in crates that depend on that crate, they might call extend with even more types. So the size of the V table, like when you compile the bottommost crate, if you will, like the, the standard library. Essentially the, that would mean that the V tables for DIN extend in the standard library is different than the vtable for DIN extend in other crates further up, because there are more possible iterator implementations that you might want to use as you, you now end up with lots of different vtable implementations or lots of different v tables for DIN extend. And that's like, it would be a combinatorial explosion kind of problem. And it would also mean that you can't pass a din extend from the standard library to a thing that takes didn't extend in a crate further up because their vtable types are different.
01:30:40.720 - 01:31:50.364, Speaker A: All right, so this is the reason why you can't have like the, basically in order for a trait to be object safe, it needs to not have generic methods. It needs to, all of its methods need to have a receiver that includes self. And there's another requirement which is that it, the trait can't have a type that returns self. So if we backtrack a little here and say clone, and we want to take a thing that is didn't clone, and we're just going to call clone because it's the only thing we can do with it in clone, right. If you have a din clone, you can literally only do the things that the trait lets you do. And the only thing clone lets you do is clone. So this says the trait clone cannot be made into an object.
01:31:50.364 - 01:32:33.240, Speaker A: This is now an error that we've seen a decent amount. The reason why you can't do this is because the clone trait, right, has a Fn clone that takes self and returns self, alright? So let's say, I say let x is v dot clone. What's the size of x? Didn't clone. It's just any type that is cloneable. And we're supposed, it's reported to return self like not the reference. So it's not supposed to return a reference din clone, it's return, supposed to return self given a reference. So that sort of means that it should return din clone because that's what self is here.
01:32:33.240 - 01:33:23.028, Speaker A: Because we don't, we've erased the concrete type. But din clone isn't sized. So it would mean that the return value of this method isn't sized and the return type of a function must be sized for us to generate code for it. Therefore this can't work. So you can't have methods that return self for a trait to be object safe. And that's why you can't you clone. Now there are some cases where you have a, you have a trait where, as we talked about with hi, right, you, you might have some methods that are object safe and are still useful on their own, but you have a bunch of other methods that are, would make the trait non object safe, but you want to include them for types that aren't going through a trait object because, just because it's convenient.
01:33:23.028 - 01:34:23.340, Speaker A: And in fact, a good example of this is if we look at the iterator trait. So the iterator trait, right, has the associated type item, that's fine, it has next. And next is object safe. But it also has a bunch of methods like chain, which is generic, it has enumerate, which returns self, it has biref, which returns mute self. It has collect which depends on from iterator, which we already know isn't, isn't object safe? So how can iterator be object safe? Because it is right if we do, if I say it here and I say I want to take a din iterator where item is bool we collected. Oops. Iterator.
01:34:23.340 - 01:35:12.168, Speaker A: Well, I can't call collect because this method cannot be invoked on a trait object. But I can call next. I'm allowed to call next on this mute, otherwise it doesn't work. That works fine. And the way that the iterator trait has achieved this is that if you look real carefully, you'll see that if I actually go to the source of the iterator trait, you should see this. Let me just find here. So count for example, which consumes self, right? So it's not allowed to go behind a reference which would make it sized, has where self is size.
01:35:12.168 - 01:36:24.470, Speaker A: If we scroll down to last, which is the same self is sized. If we look to chain, you see the chain, which is generic, so normally would make the trait non object safe has where self is sized. And the reason for this is you can basically, this is the same thing we did for the weird function, right? You can use the where self assize bound to say ignore this function for the purposes of using this trait as a trait object. Basically, don't try to put it into the vtable. What that means is if someone has a trait object, they can't call the method, but if they don't have a trait object, if they actually have like a vec intuator or like they have the concrete type, then they can call this method. And so this is a way to have a trait that has some methods that are nice to have, but wouldn't be object safe without making the whole trait object not object safe. Can the receiver be anything that includes self, or does it have to be ref self or mute self? So the rules for this are actually, where do I have this? I have it open somewhere.
01:36:24.470 - 01:37:08.738, Speaker A: Give me a second here. So this is from the rust language reference on object safety. And in fact, by now we've covered most of these things. All the super traits must also be object safe, right? Because we construct a vtable from the union of all the all the super traits, size would not be a supertrate. So that is if we require a self dot self colon sized, it's not object safe, must not have any associated constants. This again is because you don't have anywhere to put the constants theory maybe you could put them in the vtable, but now the vtable becomes really large. And also the values in the vtables are no longer all like function pointers.
01:37:08.738 - 01:37:45.234, Speaker A: They might be arbitrarily sized things. All associated functions must either be dispatchable from a trait object or be explicitly non dispatchable. So dispatchable functions require that they don't have type parameters, so they're not generic. They have to be a method that does not use the self type, right, the concrete type, except in the type of receiver. So this we can't have something that returns self. For example, it can't have a receiver with anything but the following types, right? So it can be a reference to self, it could be immutable reference itself. It can be a box self, RC self, arc self, or pin self pin to self rather.
01:37:45.234 - 01:39:00.240, Speaker A: So anything that's behind a pointer, basically anything that can take that, anything that can turn something that's not sized into something that is sized. And you can see that explicitly excludes where self is sized bounds so that you can have an object safe trait, even if some of the methods aren't object safe. This is the non dispatchable functions. Should library writers always consider adding where self assize to non object safe methods just in case someone downstream wants to use it as a trait object? I think yes, it depends a little bit on whether your trait is even usable. So if your trait isn't usable as a trait object, like think of clone, right? Then sure, you could add where self assize to the clone method so that people could create a trait object clone, but they wouldn't even be able to call the main function of that trait. So it's probably not worthwhile. But I do think that in general, if you have a trait where it is useful, even if you could only call the objective methods, then it might make sense to opt out for the other ones so that the trait overall is objective.
01:39:00.240 - 01:40:20.790, Speaker A: Did iterator last have the seist restriction? Iterator last, I think does the reason why last has where self is sized, you can't see it here, it gets hidden by Rustdoc is because its receiver doesn't go behind a reference, it consumes self, which means that it takes self, and self is a dIN iterator, which is not sized, and function arguments must be sized. Therefore last can't be called through a trait object. There's one more thing I haven't told you. Well, there are many things I haven't told you, but there's at least one when it comes to trait objects, which is that there's a little bit of a secret with trait objects. So let us say that I have pubtrate, actually just do this. This is a drop is actually object safe. You might think that it's weird.
01:40:20.790 - 01:40:57.830, Speaker A: Like if all you can do with an object is drop it, then is it really that interesting? It turns out this is useful in a couple of situations. Like, I know crossbeam does this, for example, where you want to do garbage collection, but you don't want to drop objects immediately. You want to stick them in a linked list or something and then periodically go and collect all the garbage. Because you want to store lots of potentially different things in one type, you need trait objects. And so it just stores muted drops. I think technically boxed in drops, but same effect. You can't actually do anything with this.
01:40:57.830 - 01:41:55.770, Speaker A: But here when v, where when v goes out of scope, drop, drop is called through the vtable. This should make you go, wait a second, because let's go with our say hi, right? We take the din as ref, stir, or actually let's even go with box. What happens when s goes out of scope? Think about this for a second. We get a box, we have a memory allocation on the heap. We might use that in here, might call SrefEn. This can be high, whatever. But then we drop s when this function returns.
01:41:55.770 - 01:42:43.640, Speaker A: But when we drop a box, we have to free the memory. But this is a trait object, so the only method it has is SREF. The answer to this is every vtable includes drop. You can sort of think of this as like an implicit drop here. But in practice, the v table for any trait object includes a pointer to the drop function for the concrete type, because it's just, it's just necessary. It also technically includes a little bit of extra information, includes the size and alignment of the concrete type. The reason those are in there is because for something like a box where you have to deallocate the memory, that information is necessary to pass to the allocator to do the deallocation.
01:42:43.640 - 01:43:49.560, Speaker A: And so every trait object includes the v or the vtable. For every trait object includes the methods for the trait plus drop, plus size, plus alignment. Normally you don't have to think about this, but it's just worth knowing. While we're on the topic, to shift gears a little bit, so far we've only really talked about trait objects, but there are other types that aren't sized. So for example, like we know that didn't rate is not sized, but u eight is also not sized and stir is not sized. This one gets turned when you place it behind a reference or a pointer, right? Gets turned into a tuple of like mute, a pointer to the data and a pointer to the vtable. This one, if you make it sized or put it behind a pointer, also becomes a wide pointer where one is a pointer to the data, but the other is the US size, which is the length of the slice.
01:43:49.560 - 01:44:57.968, Speaker A: And same thing for start as a pointer to the data and a use size of the length. So this is why if you try to write a function foo that takes a u eight, the compiler is going to yell at you and say that the size for the value of type u eight is not known because u eight, this is just saying an arbitrarily long list of u eight s which is not sized. Therefore we can't call the function with it as the argument. Same as if you try to return just a straight up u eight sequence, right? If I had a bar which returned a u eight, it also complains. Is it even going to let me do that? There we go. I constructed the type, see here it says the same thing. The size for the value of type u eight cannot be known, and the return type of a function must have a statically known size.
01:44:57.968 - 01:45:35.964, Speaker A: This is the same problem. And here too, the way that we go from something that isn't sized to something that is sized is we place it behind a type thing, sort of mask the unsizedness which you do with a, with a reference. Or you can do it box. So you can also do box of this. I think I'm allowed to do this. Great. So this is fine because it's now sized.
01:45:35.964 - 01:46:32.950, Speaker A: The size of it is a pointer that is wide, where one part is the data and the other size is the length. And the compiler then knows that when you access this type, it knows to sort of deconstruct the pointer to get the length. Same with something like box or raw pointers for that matter, and same for string. So these are a little bit magical. There's been some work on trying to standardize this, so currently the sort of dynamically sized types are a little bit special in the compiler, because you need to know whether the pointer is sort of wide or not. So it's fairly hard to sort of deal with unsized types yourself. Like if you wanted to implement box yourself and take a type that wasn't sized, it's possible it gets pretty annoying once you get into casting and allowing trait objects and stuff.
01:46:32.950 - 01:47:51.918, Speaker A: But there was recently an RFC that landed RFC number 25 80, which talks about adding a generic API for manipulating the metadata of fat pointers. So this lets you do things like say what the type of the second part of the fat pointer is, right? So in the case of, in fact we can scroll down here a little and look at a din trait now becomes a pointy where the metadata is din metadata and where din metadata is a pointer to a v table that represents all the information such as type size, type alignment, a pointer to drop in place and a pointer to all the methods for the types implementation of the trait. So exactly what we just talked about. Similarly you could imagine that the, this pointy trait would be implemented for something like a, a u eight slice without the reference where the metadata would be a u size that is the length of the thing. This is still very much like new and experimental. I do recommend you read through this RFC. It's really fascinating if you want to learn more about this.
01:47:51.918 - 01:48:52.180, Speaker A: It has things like the trait alias thin which is any type that implements pointy where the metadata is empty, which would be anything that doesn't have associated metadata in the pointer. So anything that is a thin pointer and not a fat pointer. And it has essentially methods for introspecting the metadata of a pointer so that you can do things like actually look at the vtable. There were some questions about this in chat earlier. This RFC would actually let you introspect that information and crucially construct vtables on the fly so you could have one that isn't known at compile time but you build at runtime. And in fact this already is something that exists one place in the standard library as far as I know, which is for wakers instead of the land of async. So the waker trait, we're not going to go too much into detail, but the waker trait which I'll show you here, the waker, that's, I'm lying.
01:48:52.180 - 01:49:29.620, Speaker A: I mean the wake trade awake, not the wake trait, the raw waker. Oh there isn't a trait for it. That's why let's go show you context actually. So context gives you a waker. Waker is a struct that has the methods wake, wake by ref will awaken from raw and you can drop it and clone it. But in practice waker is really generic. It's just that it isn't generic when you look at it.
01:49:29.620 - 01:50:20.960, Speaker A: But inside of a waker is a raw waker. And a raw waker if you look inside of it is a data pointer and a vtable pointer. So it really is dynamic dispatch. But in sort of a hidden way. And the vtable is a raw waker vtable, and a raw waker vtable you construct by giving the function pointers for the clone method, for the wake method, for the wakebyref and for drop. And so it's basically a manually constructed vtable that gives you dynamic dispatch through a type rather than a trait. I'm not going to go into too much detail of this, but I just wanted to show it as like an example of a manually constructed vtable in the standard library.
01:50:20.960 - 01:50:55.192, Speaker A: Is there anything more I wanted to talk about from here? I don't think so. All right, let's do questions because I've rented for a little while. I thought a reference to U eight had a start pointer and an end pointer, not a length. I think it has the length. It doesn't. The two are basically equivalent. You might be right, I forget.
01:50:55.192 - 01:52:11.220, Speaker A: In fact, I wonder whether this reference says yes. You see, this RFC also deprecates the trait object stuff that exists in nightly because this is a replacement pointy trait thin metadata from raw parts where is the definition of it does actually give yeah, I was hoping it would say here with the actual associated metadata type is for slices, but I don't see it. I think it's just the length. Can we make our own types dynamically size types? Sort of. So you can write this foo here is now not sized. In fact you can add more fields. You can't add a field after though.
01:52:11.220 - 01:52:30.556, Speaker A: After this is not sized. Right. So if I tried to do this, it'll tell me. The size for values of u eight cannot be known at compile time. Only the last field of a struct may have a dynamically sized type. Change the fields type to have a statically known size. Borrow types always have a statically known size.
01:52:30.556 - 01:53:37.900, Speaker A: So what this is getting at is if it's the last field, then think back to the argument I made very early on, right? If you have a non slice type in the middle here, and I asked you like if I want to look up like food x and you only have a pointer to foo, how do you get a pointer to x when the type in the middle can have an arbitrary size and the answer is you can't? There's no, you don't know how to get the address of x because t is arbitrarily sized. But if it's at the end, then it's fine. You can statically know the offset of f, the offset of x, and the offset of t. And the only information that's needed in order to make this sized would be the length of the last field. As you are allowed to construct a type like this. This type is now not sized, but if you have an, then that type will be sized by storing the pointer to the foo alongside with the length of t. So you can create your own dynamically sized types this way.
01:53:37.900 - 01:54:12.744, Speaker A: Is box u eight the same thing as a vecu eight? So this is, if you have a box of a u eight slice not behind reference is vec u eight. They're not the same. So, no, I guess let's do this. They're not the same. They feel the same, but they're not the same. Oops. Evacuate can grow.
01:54:12.744 - 01:54:44.330, Speaker A: So vectu eight, first of all has its three, three words. It's the pointer to the vector on the heap. It's the length of the vector, and it's the capacity of the vector. And this is so that if the, if you try to push beyond the capacity or below the capacity, the length just gets incremented. If you try to push beyond the capacity, then the entire vector reallocates itself, copies over, and then changes you with a box you ate. You can't do that. This, this will never grow or shrink.
01:54:44.330 - 01:55:48.650, Speaker A: You can't push to it. It's just, think of it as a, it really is just a slice. You can turn a vecu eight into a box you ate and you can also go the other way around. But they're not, they're not the same. No. What's the difference between a din fn and an fn? So basically I can write a fn food that takes a din fn and I can write an fn bar that takes an fn. What's the difference between these? These are not the same.
01:55:48.650 - 01:56:29.434, Speaker A: This is a, this has to be a function. It can't be a closure. And the reason for this is fn is really a function pointer. Like it's just a single pointer that has to be an address. This is a vtable. It's a trait object, which means that it both has a sort of, the vtable you can think of here has a pointer to calling the function, but it also has a data pointer. Right? Because the v, the structure of this is that it's a wide pointer where one part is the vtable, which has the pointer to call actually calling the function, but the other part is a data pointer.
01:56:29.434 - 01:57:42.510, Speaker A: And crucially, the difference here is that if I have fn main, I can call foo with a closure. So I can do this. But I can't do the same with bar. Why is it complaining? Oh, right. So I can call foo with a closure, because this captures Xdev, right? So, so the, it's not just the function pointer, it's a function pointer. And the, the data that the closure captures from its environment, that is, it needs to, when you call the closure, you also need to supply the address of x because it's needed by the body of the closure. And that's what's passed in the data part of the, the white pointer for bar, it requires an actual just function pointer, which means you can't pass a closure because you wouldn't have anywhere just to the data.
01:57:42.510 - 01:58:58.670, Speaker A: When we use din fn over impl fn. Yeah, so there's also baz f imple fn. And I can call Baz with a closure. What is it, what's it complaining about? I can call Baz with a closure because remember, impl fn is sort of sugar for a generic function over anything that is fn. So we actually had a concrete copy of Bas for every type of closure that's passed in. And therefore you can trivially pass in the data as well, because it's monomorphized to each individual closure. The question then becomes, when do you use a dinfn? When you use an implfen, the basic answer is implfen is more generally usable.
01:58:58.670 - 01:59:58.182, Speaker A: Like you don't have to indirect behind a pointer, for example, but you end up generating copy of Baz for each closure type you pass, in which, which might become quite a lot. And the other reason is because sometimes you want to take a trait object instead of making it generic, because otherwise you have to propagate the generic type up. So imagine that I had a struct wrapper. Then internally I wanted to contain a function pointer. If I have it hold, like I could write this, right, I could do this. But this means that anyone who wants to, any user of my library that wants to hold a wrapper would also themselves need to be generic over f or name the type of f. Whereas if this instead stored a box din fn, the now wrapper is no longer generic.
01:59:58.182 - 02:00:40.130, Speaker A: So my callers don't have to think about and propagate that generic parameter. So sometimes it cleans up your interface and makes it just nicer to use. There's also the example of trait making traits object safe. So if I have a trait x that has an fn foo, if I make this take an impul fn, then x is not object safe. I couldn't write a crocs, I guess. Let's have this. Take self.
02:00:40.130 - 02:01:50.878, Speaker A: The trait x is not object safe because this is generic, right? Impl of n is equivalent to saying f is fn and this is f, right? And this cannot be made object safe like we talked about. But on the other hand, if I made this din fn, it can be object safe because there's only one foo, right? So we don't have this problem of you need an infinite number of entries in the vtable. There's only one foo, and it itself takes a wide pointer, which then works for any type that can be objective. So there's not a clear cut answer here. Nice. Okay. I think.
02:01:50.878 - 02:03:13.710, Speaker A: I think that captures everything I wanted to talk about. So the one thing that we didn't get around to talking about is coherence. I think coherence is different enough that we're not going to talk about it. This stream, and I might just do a separate stream on it, especially because we're on like the two hour mark. So I think this is a good time to stop and then just do this separately. Are there any sort of questions towards the end about all the stuff we've talked about so far? Is the general difference between static dispatch and dynamic dispatch, the size trait v tables, object safety wide and fat pointers? Does all of that roughly make sense now? Or is there anything more I can go through to sort of help crystallize it in your mind and make it clear why we have these, what they're for, what their limitations are? I'm happy to take some questions towards the end here. Could runtime trait detection be implemented in the future using a types v table? If I understand your question correctly, I don't think it can.
02:03:13.710 - 02:05:08.400, Speaker A: So the idea is that can you take a trait object or can you take a wide pointer and figure out which traits it implements just by looking at its vtable? I don't think you can. Part of the reason is because there like a different vtable gets generated for each trait object. So it's not like there's one v table for string, right? There are many vtables for string. There's one vtable for string for each dinner trait, right? And so there's not just one, one v table that you can then look at to figure out what, what traits it implements. Like if you had like a find traits that took an s that was a din, like didn't trait, then like the only things in the vtable would be whatever methods are on the trait that you name here, you wouldn't get a vtable of all possible methods on the provided type. So no, I don't think you can do dynamic dynamic detection of which traits something implements this way. Does calling a dinofen involve a double dereference? One's for the vtable pointer, one's for the actual function pointer within? Or does that get optimized away? So if I do call takes an f of fn and in here I do f, you know that's a good question.
02:05:08.400 - 02:06:14.850, Speaker A: I think it'll end up being a double dereference because you first have to go through it's not quite a double dereference because this is a wide pointer, right? It's not a pointer to a tuple of a pointer and a vtable, right? It's really what gets passed in is a pointer to some t. You just don't know what the t is. And a pointer to tease fnv table right? That's, that's really what's passed in here. And so this ends up calling like this sort of ends up calling like vtable dot call of tache. Um, and so there is a dereference here. Like this is a pointer to the vtable. So you do have to dereference the vtable.
02:06:14.850 - 02:06:57.808, Speaker A: I guess. I guess this is a better way to sort of type it out. So you do have to dereference the vtable to get to the call. It's really I guess this, right? You have to dereference the vtable to find the address of the call that you then call. So it does end up being two dereferences. But it's not quite pointer chasing either. It is true.
02:06:57.808 - 02:08:21.148, Speaker A: Okay, so there is one thing that's a little bit funky, right? Which is if you have an x that takes an s of let's say din as ref stir then one thing you could do, and this was mentioned in chat like with the new pointer vtable dynamic metadata RFC. You could imagine like s, like if s dot v table is equal to like string as din as ref star dot v table, then like s as reference fs dot data as reference to string dot. I guess if this was a mute push, right? Like maybe you could do some really weird ugly magic like this. I would recommend just don't do it. But yeah you could imagine you could compare vtables this way. I don't know if this is even a guarantee that the compiler will uphold that a type will always have only exactly one vtable. And yeah the compiler does do a decent amount of optimization here too.
02:08:21.148 - 02:09:27.160, Speaker A: Like if you do a box din fn. I think it might not do a heap allocation always if you like, if just like escape analysis and stuff. But in general, if you use generics, like if you use an actual generic type parameter or an impl block, sorry, an impultrate. In those cases you will get better optimization just because the compiler gets full inside at compile time into what all the relevant types are and can co optimize based on the actual concrete implementations. Whereas once you have indirection through dynamic dispatch, the compiler loses some of the information it would otherwise have and be able to optimize based on. Can you do a quick example of the slice vec of dins? Oh yeah, say hi. So if you actually wanted to do like, I guess we had din high, but let's make it din as ref stir and you wanted like four h and s.
02:09:27.160 - 02:10:24.792, Speaker A: Let's make it v for SMV Sref. So to actually get this to work, what you end up with is you have to do this to make this sized right, so that all of the elements of the array are the same size, because arrays require that so you can find the given index right. And once you do that, this all just works. And you could put a box or arc or whatever for the inner type too. Different compilation units can lead to different vtables. That sounds about right. So this is a little bit anecdotal, but when you compile rust code, rust might compile one crate using multiple independent threads to compile different subsets of the crate to sort of speed up compilation.
02:10:24.792 - 02:11:18.910, Speaker A: But because you want those separate units to work in like entirely concurrently without too much synchronization, they might both encounter, say, string being used as a Din sref. They might both generate their own vtables because they don't want to coordinate about generating the vtables, and therefore you have multiple vtables even for the same type of the same trait. So that's one example why that invariant might not hold. That's a good point. And yeah, there is also any, which I haven't talked about. I'm not going to actually demo it, but so there's the any trait, and any is super magical. It's not actually like any is just a trait that has a function that returns an identifier for a type that is unique guaranteed by the compiler.
02:11:18.910 - 02:12:21.734, Speaker A: And so if you have something that's a trait object over any, you can use type id on it because it gets added to the v table to get a unique type identifier for that value. And then you can use that to downcast from a din any to the concrete type because we know what the type identifier is. I'm not going to go into any too much, but but any uses a lot of the stuff that we've talked about so far to actually be able to go from a din a din trait, as long as that trait includes any into a reference to the actual underlying type. It's really cool and actually surprisingly simple now that you know what you know. So I recommend you give a read to the standard any module documentation it talks about why this is safe. All right, I think we're going to end it there. 2 hours and 15.
02:12:21.734 - 02:12:42.900, Speaker A: I'm pretty happy with that. We covered a lot. I hope that was useful. I hope you feel like you learned something and some of this might actually stick. I have made a little bit of progress on my coding livestream that I really want to happen. I'm hoping it'll happen sooner rather than later, but it has not escaped me. I'm still on the case.
02:12:42.900 - 02:12:51.800, Speaker A: Thanks so for coming out and I will see you next time. So long. Farewell. Bye.

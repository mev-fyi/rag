00:00:00.880 - 00:00:44.059, Speaker A: Hi everyone. Welcome to this slightly different stream. It's also a different time of day. You can't tell this if you're looking at this recorded, but I decided to do a stream sort of impromptu and on a time that's more in line with like, you know, Asia Pacific time zones. Because I feel bad for you all, you don't get to like actually participate live. So I wanted to try that. And the impromptu stream I wanted to do is basically I maintain a decent number of different open source libraries at the moment and I've gotten some requests up over the months and years of people just being like, I want to know what open source stuff is.
00:00:44.059 - 00:01:44.445, Speaker A: Like it's a little weird to get into that space because you don't really know how am I supposed to review a pr? How am I supposed to work with issues? And it's hard to get that experience without already being in that position. So I wanted to do a stream where I just basically go through the sort of process of what I do when I deal with my GitHub notifications. This is not going to be a very formalized stream. Like I'm going to be watching chat a bunch. I'm going to sort of just be walking through these one at a time, chat of whatever comes up. I don't really know how this is going to turn out or whether it's going to be interesting, but we'll see if you know, I mean if you're watching this on recording, it's not gonna, you're not gonna get a lot out of the questions. But hopefully chat is gonna ask the questions you have about, you know, why are you looking at this notification first or why are you responding to this this way? Why are you doing the review this way? I'm really trying to give as much insight into my like code review and issue triage process as I can.
00:01:44.445 - 00:02:29.577, Speaker A: So chat, this is, this is on you. You gotta do the work for everyone watching afterwards and hopefully it's gon thing. So without further ado, let's dig into GitHub notifications. So as you can see, I have, this is not a lot of notifications, but I have a page full of things that are unread. I have more, but we're going to ignore those for now. Part of the reason why I have a bunch of these, where some you see are fairly old is because I don't often, you know, after a day of work doing programming I'm like, okay, I need to, you know, eat dinner and be with my girlfriend and play play video Games and stuff. And so I usually tend to do my open source work on weekends.
00:02:29.577 - 00:03:13.209, Speaker A: It's something over time, I'm hoping this is something that I can change where I can do more of it just as part of work, for example. But for the time being at least, this is entirely my thing separately from anything else. And so that means that in general, what I do is I sort of clear through my GitHub notifications on the weekend, and then the next weekend there's another backlog of people who have responded or new PRs and whatnot, and then I follow up on them from there. I'm not going to use the GitHub command line tool for this because I don't really like it all that much. I like the web UI for issue triage and code review in particular. I feel like it works just as well. If there is something where I really want the autocomplete, I want it in my editor, then I'll just fetch it with Git and open it locally.
00:03:13.209 - 00:03:45.335, Speaker A: I don't actually need the GitHub CLI for that. Same for merging, I'll just click the merge button. It's easy enough. You'll see first that there are a bunch of PRs here, some of which are fairly old, that are specifically PRs to Rustacean Station. So these, we're not going to merge any of these right now. These are all upcoming episodes to the Rustation Station podcast. So if you don't know about this rotation, Station Podcast is a podcast about the Rust language, where it's sort of a community podcast.
00:03:45.335 - 00:04:49.965, Speaker A: So we have multiple people contributing episodes, things like, you know, interviews with people doing cool things with Rust, or this week in rust, or every 12 weeks, Ben Striegel and I do an episode on the last two Rust releases where we go through the change logs in some more detail. And this is the GitHub repo for that podcast. And all of the episodes take the form of just a markdown file with some metadata, and then it has, you know, a little bit of a custom format for indicating timestamps and stuff. And so usually what happens with these is with the interviews in particular, they'll be done sort of in batch. And then this particular contributor will just like send me a bunch of like audio files and PRs with the show notes for those. I review them a little bit and then merge them and that makes the episode live. But because we don't really need to merge any of these now, because the next one isn't going to come out until Friday, I'm just going to mark this as unread and leave these behind.
00:04:49.965 - 00:05:53.109, Speaker A: You'll also see that I have some notifications here that are left in my inbox but are left as unread. These are usually things where I know I'm going to want to come back to them for particular other tasks I sort of have in my queue, or there are things that I know I want to reference, like in stuff that I'm doing at work, for example, or in other projects where I know that this is going to be relevant to something else that I'm doing, but it's not actionable immediately by me. So I leave them as unread but still in my inbox. And then there's this one. So this I've had open for a while. This is basically someone who watched one of the older Impel Rust streams on a bystander, which is this lock free to wait, free transformation library that we were looking at building. I don't want to get into that because this one is a little bit more of like can you explain what's going on and why it does what it.
00:05:53.109 - 00:06:42.063, Speaker A: Why the library or why the implementation in the stream doesn't do quite what we discussed? So I will answer this at some point, although it's been open for two weeks, but I'm going to leave that in my backlog because it requires a little bit longer of a process to write up a proper answer. Let's see. So the next one here, this one is. What is this? So I made a change to Cargo a little while back. This is an unstable feature that is related to how Cargo passes Rust flags to build artifacts that are only for the host. So imagine you're running. You're running cargo and you're trying to build.
00:06:42.063 - 00:07:46.605, Speaker A: You're essentially doing a cross compile. So you have a target specified on the command line, like dash, dash, target, muscle or something. But you're building on x86 Linux there is a Anything that gets built as a build script is not going to be cross compiled because build scripts need to be run as part of compilation, which means that build scripts need to be built for the host platform, not for the target platform. But there's a little bit of oddity in the way that Cargo handles cross compilation, in particular how it handles host artifacts. So for example, if you pass target and the name of the target is the same as the host platform, then the question becomes, okay, should those Rust flags apply to the build script? Because the build script is being compiled for that target, but it's not being used for the target. And this turns out to matter in a couple of cases. And it turns out the cargo's defaults are a little weird here.
00:07:46.605 - 00:08:26.675, Speaker A: And it seems like the fix I made to that feature meant that Rustock flags are not being handled correctly. This one. Oh, interesting. Yes. You see there's. They're referencing a PR of mine where I fixed some parts of that feature, but clearly not all of them. I don't think I'm going to dig into this one now because this is going to require a little bit more research and it's also something that's related to some stuff I've been doing at work.
00:08:26.675 - 00:09:02.725, Speaker A: So I'm just going to handle that separately at work. I don't think trying to debug this here would be super interesting anyway, so we're going to skip past that one. This is a PR to Hash Bag. So Hashbag is a library I built that is like a hash set, except it also keeps the cardinality, the count for every item. So you can stick a value in there. I mean, with sets, they're all arguably keys, but they're also all arguably values. You can stick a value in there multiple times and it will keep track of how many times an item has been added.
00:09:02.725 - 00:09:48.567, Speaker A: So, you know, with a normal set, if you try to insert a value into the set that's already there, the insert does nothing. It has no effect. Similarly, if you remove something from the set that was in the set previously, it will always be removed. With this, if you insert the count for that value goes up by one, and if you remove the count for the value goes down by one, and it only gets removed from the set when the count hits zero. So this is someone who contributed a PR that adds the Difference method to Hash Bag. So if you've looked on hash sets in the standard library, Hashset has this difference method where you give it. You have the current hash set, you give it a reference to a different hash set and it gives you.
00:09:48.567 - 00:10:50.455, Speaker A: I think Difference is an iterator. Yeah, it's a lazy iterator that produces the elements that are in the first set but not in the second set. And similarly, it has operations for intersection, union, and symmetric difference. We don't have this for Hashbag, partially because it wasn't something I needed, so I didn't build it, and partially because, and you'll see this when I go through the PR a little bit, it's not entirely clear what the semantics should be. Yeah, it's a multiset or also referred to often as A bag. So this person submitted the PR two weeks ago, and I responded saying, I wonder whether we want difference to produce the count of the difference and not just the set of items in the difference. So the original PR was that hashbag difference exactly like hash set difference returned an iterator that told you things that were in the first set, but not in the second.
00:10:50.455 - 00:12:24.717, Speaker A: But I, or rather I think the original one was, was not the count, but was just where the count in the first set is higher than the count in the second set. But it only returned not the difference in the count, but the values for which that was true. And my observation here, and you can sort of read through the discussion, I'll put the link in chat here, and the discussion here is whether which of these is better, right, should difference match the API that's in the standard library for hashset, or should we have our implementation difference give a different iterator value that includes the count, or should we have match the standard library hashset difference and then have a separate method to get an iterator that includes the counter? And so that's been the discussion that we've gone back and forth on a little bit. And my argument for why we should probably have it be have it include the count difference in the iterator is because it's pretty easy to remove that. Like you can always just map it out of the iterator. But it's, you know, if you take the one that doesn't have the count, you can't add it back in. And so chances are, or not, chances are, like, logically, one is just strictly more powerful than the other one.
00:12:24.717 - 00:13:34.597, Speaker A: So I feel like that one should get the more convenient name. And at that point, why even have the one that only returns the set difference? And there's a second question here of at that point, in order to compute the bag difference so the difference including the counts, you basically have to construct a hash bag to compute that difference, because you need to keep track of the difference count, which is itself a bag, a multiset. So the question is, should it return an Iterator still, or should it just straight up return a new hashbag that contains the difference? And in fact, this basically means, you know, that the difference ends up being the result of subtraction and it returns a new hashbag. And that was sort of where I think we landed with the last piece of discussion. And it seems the last update here from the other person is played around a little bit more with getting the value and the count. And it indeed wasn't so bad. Uh, let's go for that.
00:13:34.597 - 00:14:31.351, Speaker A: I pushed commit now to make it so. All right, so let's go and look at the difference. So it's add this adds a difference method to the hash bag. I don't think the explicit lifetimes are relevant here. So let's go ahead and say that this and this. I think we can rely on inference here and not use the explicit lifetime syntax. So we'll start a review here because there might be other comments too.
00:14:31.351 - 00:15:03.773, Speaker A: So there's sort of a question of at what point do you approve a pr? If. If this is the only comment, like as I go through, I would probably approve it because this sort of causes churn. Right. It means that realistically this is not going to get merged for like probably a week. Right. Because I leave this, they won't see it until, you know, in a couple of days maybe then submit their change and then I won't review it again until a week from now and maybe then I'll merge it. So if this was the only thing, this is not worth blocking for.
00:15:03.773 - 00:15:30.275, Speaker A: And worst case, I can always just override the change myself. And so I don't really want, you know, if this nit was the only thing to comment on, that doesn't seem worth blocking anything. Oh, you're right. It. I mean, it is inference, like elision is inference. But I think we can use. They're sort of equivalent here.
00:15:30.275 - 00:16:30.435, Speaker A: Yeah, so someone pointed out too. Well, we'll get to that when we look at this later, whether the count should be a usize or an I size here. And it's another good question where in order to compute the difference, we probably do need to keep. Well, we shouldn't need to keep negative values, but we are always going to compute the difference even if it is negative. So the question is just return a hashbag that includes negative cardinalities, like negative counts, or should it filter out all the ones that are negative? If it does include things for the negative count, then it needs to return an eyesize. But if it's going to filter them out, it should return a usize. I'm not entirely sure here what is better.
00:16:30.435 - 00:17:16.435, Speaker A: There is the argument that if we return the counts and allow them to be negative, then then we don't need a separate API for inverse difference. And you get more information out of this one API. But it also means that anyone who actually just wants the difference is going to have to do the filtering themselves, which is the most common use, presumably of a method called difference. I do. So it Looks like difference stores others. I don't think you can align the lifetimes. That's interesting.
00:17:16.435 - 00:17:44.045, Speaker A: I mean, this is. This should be easier to test out. So if I do, you know fn foo. No, I do struct foo. I do impulfu. Just so we don't give them an incorrect recommendation bar. If it takes self and other, which is a reference to self and then it returns a self.
00:17:44.045 - 00:18:14.135, Speaker A: So here I'm going to use elision and I do something like, you know, if true, then self, else other. Let's see what Russ says about this. I guess you're right. Yeah, because the. I think the rules for elision. No, you're totally right. The rules for religion is if there is a self, then you self.
00:18:14.135 - 00:18:40.843, Speaker A: Otherwise use the combined lifetimes of all the arguments that are references. So no, you're totally right. Which means this comment is simply false. Nice. Good catch. Well, so. So someone said the name is different, so I size would make sense.
00:18:40.843 - 00:19:15.385, Speaker A: But the documentation for this is returns an iterator that visits all values present in self that is not present in other. It's also unclear whether that should be the documentation. Right. Because arguably, arguably it doesn't return the ones that are not in other. Right. Not present is not the right phrasing here. The right phrasing here is something like returns an iterator that visits all values present in self.
00:19:15.385 - 00:19:44.555, Speaker A: That. I mean, that's also a question of semantics. You know, should it. Should we say that it returns anything, it returns the count for anything that's not in other. Or should we say it returns how many more there are of anything that there are more of in self. Right. Both of these are valid interpretations of difference.
00:19:44.555 - 00:20:13.235, Speaker A: I wonder what the sort of set definition, like the mathematical set definition of multiset intersection or multiset difference is. That's a good question. Right? Like what should the semantics here be? Should it be that. To make it more concrete. Right. Imagine that. Imagine that the left bag.
00:20:13.235 - 00:21:06.885, Speaker A: Left bag has a 2b1 and the right bag has a 1 and only a 1. Should the different. Is the difference a 1, b1 or is the difference just b1? Because the right bag did have A, its count was just different. Someone has the answer for us. What does stack overflow say? This is going to be bright, I think. Maybe. Okay, there's a lot of pop ups here.
00:21:06.885 - 00:22:27.095, Speaker A: Yeah, exactly. So this is that same question of both A and B contain one. So even though the count is more in A, is it still a result in the output? Interesting. That's good. I'm not sure there's a universally agreed upon definition of set theoretic difference for multisense. This is not where I wanted to go with stream, but that's interesting enough doing so this definition would yield. Yeah, yeah, I think I agree that I would expect it to return the difference in count.
00:22:27.095 - 00:24:18.755, Speaker A: The problem, right, is it's not strictly more powerful because if I give you an API that returns this, you don't have a way to turn it into this because you know the count is one. It's indistinguishable from this B1 unless you do something with it in relation to the original sets. So I think there's an argument for there really needs to be two different methods. One and someone pointed this out too, one of like set difference and one for bag difference. And the question, you know is what should difference do? We could just say we don't want to have a difference method because the answer is non obvious, right? So this is sort of the principle of least surprise, right? Where if it's not clear what the semantics of a method should be, then you shouldn't have that method. You should have two methods with clearly defined names that are distinguishable based on their names because otherwise people are going to guess and when people guess, they will guess wrong some of the time. So I think the way I'm going to approach this is something like this comment sent me down a rabbit hole of trying to figure out what difference what the semantics of difference for multisets even should be.
00:24:18.755 - 00:27:06.875, Speaker A: This stack Overflow article or post suggests that both that given A I guess we could do 112 minus B. One can feasibly be the given A equals this and B equals this. The intersection A dot intersect B can feasibly be both 1, 2 and 2. Since that means that the word difference here is ambiguous, I think we should instead have two methods. What should we even call them? So someone suggested set difference and bag difference and I don't know if that's the way to think about it, right? Because okay, let's say I told you this takes the set difference. Does that mean like if that's all I told you, does that tell you which of the semantics you get? I don't think it does. So I think what we want to call this is something like one option is something like count difference and unique difference is not bad.
00:27:06.875 - 00:28:03.615, Speaker A: Alternatively okay, so here's another to take it very differently. One is count difference and the other might be but not in. It's sort of an awful name. But if you think about it in terms of what you would write. You would write a dot but not in B, which isn't awful because it clearly is anything that's in A but not in B. Lazy and greedy. Difference, I don't think helps here.
00:28:03.615 - 00:28:56.993, Speaker A: Even. Even not in. Yeah, even not in is not bad. Yeah. Like multiplicity, cardinality, maybe collecting the hashbag into a hash set. So, I mean, we could tell the user we only support one of these, and then we tell them, you know, for each hash bag, turn it into a hash set and then take the difference if what you really want is the set difference. But that's not very satisfying because it means you have to allocate basically three hash sets.
00:28:56.993 - 00:29:47.861, Speaker A: Because you have to take the hash hash bike A and turn it into a hash set, hashtag, hash set, hash bag B and turn it into a hash set. And computing the difference of sets for sets, I don't think you need a bag. So for set, you might not need the third allocation. So one problem with count difference is that it might do C1. You know, there's. There's an argument that it should return A1, B1, C minus 1. You're right.
00:29:47.861 - 00:30:13.255, Speaker A: Sorry, I meant. I meant difference. The difference. Oh, you're right. Multiplicity is the number of occurrences of an element. Cardinality is the sum of the multiplicity. So basically the size of the bag.
00:30:13.255 - 00:31:14.701, Speaker A: Yeah, naming is hard. And, you know, this is one of the things that's hard about maintaining libraries is it's, you know, this doesn't happen all the time, but you do get a decent amount of contributions where the difficulty is not so much in the implementation, it's in terms of what is the right way to land this feature that is both, you know, good for the users of the library and something that I can maintain long term and that I don't think I'm going to have to break in the future. Yeah, so. So the argument here is count difference could arguably be interpreted as this, although I think this is more like compare than it is difference. Because when we say A minus B, which is sort of what difference means. Right. Difference is subtraction here, arguably.
00:31:14.701 - 00:31:40.727, Speaker A: And A minus B will never include C. Right. It's remove anything that is in B from A which shouldn't include a negative count for C. So I think we don't want. I don't think we're going to want negative counts. I think that's right. Yeah, exactly.
00:31:40.727 - 00:32:33.115, Speaker A: If you allow negatives, this is arguably just a different method. So I think what we'll do is I Think we should have two methods. So there's one that's not including or subtract. Subtract helps compared to difference because I think it's clear that if you subtract it, you really mean remove those elements. There's even, you know, it could be removed, but that seems weird. But I kind of like subtract. It's fairly straightforward.
00:32:33.115 - 00:33:04.581, Speaker A: You know, it's not a super complicated word. Yeah, let's. Let's do subtract and not in. Oh, without is not bad. A without. B. I don't.
00:33:04.581 - 00:33:33.495, Speaker A: I think without has the same problem as difference. It's not clear which of these outputs you would expect with without key difference and value difference. Mm. It's not really key and value in a bag, though. Like, it's not as though the count is the value and the key is. It's not as though the key is the. The element and the value is the count.
00:33:33.495 - 00:34:00.105, Speaker A: That is how it's implemented, but it's not really how the. The interface talks about the type. This is now diverging from hash set difference. But I don't. Because this is a bag and has different semantics. I actually don't think we should use the word difference because I don't think it. I think people are going to assume that it means the same as in the standard library and it just doesn't directly translate.
00:34:00.105 - 00:34:53.685, Speaker A: Yeah, okay, let's do this. And then the other thing that I like doing here is it's easy for me to go as a. The owner of this library to just be, we're going to do this. But I don't want to do that here because first of all, I don't want to tell them you need to implement both of these methods. It could be that they only need one of them and therefore, you know, I don't. It's okay for me if they change this PR to just have one of them. So what I'm going to do is, um, hope, hopefully it's clear which is expected to have which outcome.
00:34:53.685 - 00:35:33.389, Speaker A: Otherwise these names are bad too. I'll make that not a parenthetical because it's so long. What do you think? Happy to have this pr. Just include one of them if you don't want to implement the other. Yeah. The goal here. Right.
00:35:33.389 - 00:36:08.555, Speaker A: Is for both. Is for the names we choose to be unambiguous. They might not be great names, they might not align with other APIs, but the chances someone guesses and guesses incorrectly is what we want to get at. Right. Someone's suggesting in chat that we could use the semantics of joins here from relational algebra. So you could talk about this in terms of like a left join or a right join. It's not awful because like relational algebra is basically bags.
00:36:08.555 - 00:36:43.201, Speaker A: Like that's sort of kind of what relational algebra ends up operating on is. Is multisets. And so you know, this, this is arguably a. It's not a join though, is the thing, because you're. It's a remove a join. Which I don't know if there's a. An expression for like what's the inverse of a join in SQL, right? It's not a join if it was a join.
00:36:43.201 - 00:37:18.547, Speaker A: A join is more like the intersection. It's an anti join. Yeah, but I don't really. I don't think I want this to be anti join. I don't think that helps. So let's leave that as subtract and I'll start a review with that. And then I guess here, once we've chosen the semantics this function should implement.
00:37:18.547 - 00:38:24.175, Speaker A: I think we should also update the document here to specifically mention the interaction with counts. Right. So here as an example, it's. Wait, why is this constructing a hash set? Oh, I see. Okay, so if we have 1 2, 3, 3 and return and B is 2 3, then this API expects that the difference is 11 and 3 1. Okay, so this is subtract. If this was not in, then three wouldn't be in the output because it's also in B.
00:38:24.175 - 00:39:08.071, Speaker A: So instead of being cheeky over here, I'll say I believe this would be subtract to be more helpful for omnify. Yeah, that's always a good fallback. Great. Yep, that's fine. The bag with entries, we do not want to return upper bound for that. That's fine. That's also.
00:39:08.071 - 00:39:35.901, Speaker A: Okay, why not derive debug here? Because he's trying to hide the upper bound field. That's probably fine. I think I agree with this. You know, there's a. There's an argument for. The code is simpler if we derive debug, but I don't. I think it's actually nice to remove the upper bound here.
00:39:35.901 - 00:40:11.185, Speaker A: It's just noise in the output. It does mean that if we add other fields to the difference in the future, the debug will have less info. But I think cleaning it up now is worth doing. And then iterator for difference, it grabs the next from items, it looks up that element in the other. Oh, right. So it doesn't need to keep a bag of the difference, which makes sense because we Keep it as a bag. We keep the count per element, so you can just look it up directly.
00:40:11.185 - 00:40:32.255, Speaker A: And so this is. If other is less than N, then return the difference. Yeah. In which case this totally should be usize and this is indeed subtract. Whereas for not in this would be. That's a good question. Actually.
00:40:32.255 - 00:41:03.425, Speaker A: If I go to hash bag. Hash bag. So this has contains, which returns a usize and it has. Right. So for if we wanted to do this with. Oh, we could still use contains and just check if the value is zero in the other set. That would be the only case in which we return it from.
00:41:03.425 - 00:41:44.825, Speaker A: In which case we return T. And I think for not in the return would actually be a set, it would not include the count. So that's another thing we should add to this comment. So, and notably, not in Iterator would not include account or. Well, I'm less sure about that, actually. Okay, so this is another question about the API. Right? So let's say we're looking at the not in method here.
00:41:44.825 - 00:42:22.735, Speaker A: Should it return B1 or should it just return B? I guess it might as well just include the count. Yeah, I'll leave that in. It's fine. It can keep. Well, no. Right, so you can imagine that if B here was like 14, then the 14 here does carry meaning. Right.
00:42:22.735 - 00:43:14.585, Speaker A: If we instead returned a set of just B, it doesn't really help, you know, it just removes information. So I don't think there's a big reason to not include the count there. All right, that's fine. This makes sense. Looks good. I like the question mark operator here. Although this doesn't seem right because the upper bound for size hint should go down as we return elements.
00:43:14.585 - 00:43:51.605, Speaker A: Because we know that, you know, if we know that the thing is going to return. If we have a bag of N elements, we know that the upper bound initially is N, but the moment we remove, the moment we return an element, we know that that value is lower. In fact, every time we go through this loop, we know that the upper bound is one lower. So I think there's a missing upper bound. Check here. I like the tests. That's beautiful.
00:43:51.605 - 00:44:39.799, Speaker A: Do test difference. That seems fine. So where's the place we could construct this? Yeah, so the upper bound is initially set to the count. So I think here, I think this needs to. This is another thing that I try to do in in PRs is, you know, keep in mind that the other person, the person on the other end of this pr, you know, they both have other things to do. But Also, if all you give them are critical comments and like, stuff that's just like, this is wrong. It's really demotivating.
00:44:39.799 - 00:45:25.225, Speaker A: I don't know whether this is like this person's first PR or whether they've done a bunch before. And so I want to try to be encouraging for these and not be like, you're dumb stupid. Because that's not the reality of the situation. Like, this is a bug I could totally have done myself too. So I'm going to go ahead with. I think this needs to also reduce the upper bound for each iteration. Although it's not incorrect not to do so, but since the Iterator can be inspected at any time, we should tighten the bound as we can.
00:45:25.225 - 00:45:59.185, Speaker A: And again, like, it is true that it's not incorrect. Size hint is supposed to return an upper and lower bound, but it doesn't have to return the correct. Like it doesn't. It's not expected to actually return the exact size. And it has to be an upper bound here for bag because we don't know how many more elements we're going to return. It could be the. For all of the things that we have remaining in A, they're all in B with higher counts.
00:45:59.185 - 00:46:28.271, Speaker A: So even though the upper bound is the size of A or the remaining size of A that we haven't iterated over, it could be that the actual number of items returned is zero. So this is why we can't return. We can't implement exact size integrator for this because we don't know the result until we've computed. Oh, we got the Primogen in here. That's exciting. Hello. Apart from that, I think I'm pretty happy.
00:46:28.271 - 00:47:08.885, Speaker A: I'm going to go ahead and also leave positive comment because I reacted positively to it. The primogenit, the primary. The prime VEP rhyme agent. It's unclear, unclear, unclear how to pronounce. Primogen. Primogen. Did I get it right? The Primogen.
00:47:08.885 - 00:47:33.597, Speaker A: Does it have to be said with like a. A fierce, like, movie trailer voice? The primogen. Great. So I'm going to do that and I'm going to leave this as a request. Changes. Fantastic. All right, we're through One pr.
00:47:33.597 - 00:48:15.961, Speaker A: Someone asked and I think it's. I think it's a good question of, you know, this is a pretty thorough review that we just did for relatively small change. And it's not always that I'm this thorough, or rather it's not always I have this much to say or this much to think about. But that's sort of what I wanted to point out here is sometimes simple changes require a lot of thought from the maintainer's point of view, because even though the change is straightforward, the implications of it are not always. Sometimes I'll see a change and it'll be a large change, but it'll be sort of obviously correct or it'll be something that we've already talked a bunch about. So it's clear this is the right approach in this case. It's a small change, but whether the semantics of that change are right aren't clear.
00:48:15.961 - 00:49:13.117, Speaker A: And that's why it's very hard to anticipate how long it's going to take me to get through my notifications every week, for example, because sometimes I'll have like three notifications, but they're going to take me like all day to get through. But yeah, I do think of these PR reviews as more in terms of it's like asynchronous pair programming almost. And I think that's a much healthier way to approach them too than like, I'm going to see whether your code meets my bar. Right, like that's not useful. How do you feel about calling do test different so many times versus say taking a go table based test approach down here? I like this. I think this means that the tests are easy to read. You know, it could be that we can do a macro here with some nicer syntax, but I don't.
00:49:13.117 - 00:49:41.159, Speaker A: I think this is fine. This makes it very clear what's going on from like, you know, if we actually included the counts. I think it might be even harder to read these. You know, like looking at the set theory here, like, I think this was easier to read than if this said one colon too. There's more syntax, more noise. Sorry for the bright screen. All right, so I'm gonna mark that one as done and we can move on to the next one.
00:49:41.159 - 00:50:33.311, Speaker A: I took up more time than I had planned, but such is life. This is a PR that's landed. Ah, so this is something that this is a PR that I went through a decent amount of discussion on. There's not too much to say about it now, so it's just notifying me about some follow up comments. Basically the change here was this is in the OpenSSH SFTP client. So this is, I maintain a crate called OpenSSH that implements the client side of SSH connections using the standard Open SSH as the real client. So the origins of this was it would just wrap like Tokyo process and just shell out to the local SSH command.
00:50:33.311 - 00:51:56.235, Speaker A: The idea being that rather than implement all of the like crypto and stuff myself, I could just rely on the correct implementation of OpenSSH and get all the features like support for SSH Agent and stuff for free. And then nobody, zoo zhu don't know how to read their name, but this person came along and it was amazing, just came in and was like, I'm going to just implement the SSH multiplex protocol, which is basically the, the or MUX protocol rather. So this is the protocol that the SSH command line tool uses to talk to the local SSH daemon that represents a connection to a remote host. So that that daemon is the one that does all of the actual cryptography and authentication and stuff. And there's sort of a relatively simple protocol that's entirely local to your machine, talking between the SSH client and that MUX daemon. And this gives us a much nicer interface because it means that instead of like invoking commands and trying to read like standard error or reading the exit codes and try to infer what went wrong, we can actually talk the protocol and get real error messages back and stuff. And they've taken that work a little bit further now and implemented the SFTP protocol or a client for the SFTP protocol which runs over the SSH protocol.
00:51:56.235 - 00:52:47.535, Speaker A: And they've sort of ended up folding me into that work because it relies a lot on the OpenSSH client that I built. And in this particular change was the stuff they built originally has like unpin bounce everywhere because it makes it a lot easier to just get your code to work because you don't need to worry about PIN if every type is unpinned. But it's a little annoying sometimes because sometimes you truly have a type that just isn't unpin. Like if you have a an async block, for example, you don't want to have to box pin it. So a lot of this changes is removing the unpin bound. And in order to do that you need to make sure that the basically inner parts of your stack correctly PIN values so that they can be not unpin. I know the terminology gets weird here, but that's basically what's going on.
00:52:47.535 - 00:53:07.869, Speaker A: And the discussion that we've been having in this PR is basically whether. Let me see if I can dig up. Oh, beautiful. They added this. That's great. Let me see if I can find low level PIN utils. They basically added a little bit of unsafe code to enable them to write this.
00:53:07.869 - 00:53:56.425, Speaker A: And part of the reason they asked for my Review was like, can you check that this unsafety is actually safe? Let me send the URL over here. So this is. We actually went back and forth on this because the initial implementation wasn't safe. And so we sort of went back and forth trying to figure out how can we make it safe. Is this like something that's missing from the standard library? How do we go about it? And ultimately we landed on an API that ended up being a little bit more constrained, but was actually safe. And this was just the last little comment. Here was a sort of particular little loose thread of this is the thing we should stop.
00:53:56.425 - 00:54:38.777, Speaker A: All right, that's unnecessary. Let's go ahead and do this and go ahead and do that. Bye. Yeah, I got rid of them easy. Yeah. So this discussion was just that there was a particular unsafe block in their implementation that was only safe if certain other things were true about the. About the rest of the code.
00:54:38.777 - 00:55:02.525, Speaker A: And so I made the point that you should add a safety comment for this, explaining that this is safe because we don't do this anywhere else in the code. And they did. So this one can be marked as done. That's great. Let's go back here. I'm not going to review this particular one because, well, let's open it and see what there is. Feature resume.
00:55:02.525 - 00:56:04.357, Speaker A: Wait, I'm confused. There are clearly some file differences that are not being shown here. Oh, it was just showing me the difference from last time. Oh, this is actually not too bad. So this PR is when you use OpenSSH this way, when you have this local daemon and you have the actual client that talks to the daemon, the way the library previously worked was it will spin up the daemon for you for the particular connection to a host that you want, and then reuse that daemon for the duration of your program until you drop the session. But when it drops the session, it terminates the daemon. There are some times when either you might already have a connection to this host and you just want to use this library to continue using that connection, or you want to leave the connection open so that a subsequent invocation of your program can pick it back up.
00:56:04.357 - 00:56:47.155, Speaker A: And so this adds the mechanisms required to do that through a leak function. And I have some. I don't love that terminology, but it adds a function that lets you say, when the session type gets dropped, don't close the connection, don't close the daemon, just leave it running and it has a resume, which is don't start the daemon. Instead use the daemon that exists already on this local socket. And so that's sort of the primary thing that was being added here. And this is a PR that I've been through a review of before. Let's see.
00:56:47.155 - 00:57:14.405, Speaker A: I really hate that GitHub will close all comments that the other person has resolved because I might not agree with them for why they resolved the comment. So I have to open all of them and look through and see whether I still agree. So here, this was. Yeah, I don't want deny warnings in CI. And they reverted that change. Great. So I can get rid of that.
00:57:14.405 - 00:58:00.905, Speaker A: They fixed that. I saw it. This was in CI, there was a sleep 30. Right. So this is because in order to run CI for this, we spin up a docker container that itself runs an SSH server, and that takes a little while to spin up before the SSH server is actually available. So I think the sleep here was added to wait for the SSH server to be ready before we start actually running our tests. And the problem here is we don't have a good mechanism for wait until that other docker container over there in CI is ready to accept SSH connections.
00:58:00.905 - 00:58:31.785, Speaker A: And sleep 30 just seemed arbitrarily long. And on the long side, sleep 15, I guess that's fine. I don't love the fact that it's asleep. There's an argument here for maybe it should be like a command that we run in a loop instead. But then you run the risk of what if the SSH server never starts and now your CI just hangs forever? Maybe that's nicer. But I'm okay with the hacky workaround here. So here's the argument for leak.
00:58:31.785 - 00:59:39.007, Speaker A: So the way this was set up was you have a session type that represents your connection to the back end daemon. And the idea with leak being it consumes self and gives you back the information that you would need in order to resume later. And that primarily means a path. This is the path to the UNIX socket that local daemon is running on that you can use to connect to it in the future and optionally path to the log file that was opened for the daemon, which we might not know, right? If we have already, if we're resuming a past session, we don't know where that daemon keeps its logs. That's why this is an option. And so my point there was I don't love leak because it already has pretty strong meanings in the Rust ecosystem. And this ties back to the discussion we had on Hashbag, which is when people see a name that they recognize and have a strong association with, they tend to assume that it Means the same thing.
00:59:39.007 - 01:00:28.271, Speaker A: It has the same semantics. And Leak in Rust terminology means that the memory leak, right, it means that this thing is now going to be like it's a heap allocation and we're going to forget that it was a heap allocation, that we're not going to, you know, free it ever in the future, which is not what this is doing. That said, you know, Leak is kind of appropriate because that is what it's doing. It's not going to shut down the daemon for you. So I understand why the name was chosen, but I don't love it as a name. And so what I proposed instead was that we instead have a configuration option for sessions that is like Close on Drop and you can set it to true or false. And one of the reasons I like this is because Leak had to be a little bit special because imagine that we are resuming an existing session.
01:00:28.271 - 01:01:07.835, Speaker A: That implies that we also should not shut it down on drop, right? If we're resuming a session, chances are they want it to continue to be resumable. And so there was all this logic in here for if it was constructed through Resume, then Drop does nothing. If it was not, then close the daemon and then Leak had to do the same kind of checks. So my proposal here was just have a Close on Drop. That's a boolean that we use to determine in Drop what to do. So that way, if you're resuming a session, you still have the option of making us close it on Drop. Or if you opened it and that started the daemon, you still have the option of it not being shut down on Drop.
01:01:07.835 - 01:01:53.565, Speaker A: And then I propose, you know, if you don't want that. And again, this comes back to. I don't want to claim that I have the right answers here. There might be other API decisions that, you know, this person who contributes to this and therefore presumably has a use for it actually means that it really should be this way. Then I propose calling it Detach instead of Leak. Leak connection could work too. I'd like to keep it as it returns the path to the control socket and the path to the math or log, which is useful process mux done.
01:01:53.565 - 01:02:40.143, Speaker A: So I'm guessing that Done means here. Yeah, so they renamed it to Detach. I like Detach. I think Detach sort of says. Says what it does. I do still kind of like the idea of also having Close on Drop as a separate thing. Yes, a force terminate was another thing where that they had for the same reason that if you resume a session, then it wouldn't close the daemon or shut down the daemon on drop.
01:02:40.143 - 01:03:09.767, Speaker A: But they had a force terminate that would, when you call it, would definitely shut down the daemon no matter how the session was started. So let's see. Let me go back and look at what the diff now looks like. There are some times when I want to look at the full diff and not just the diff from last time because I want to get a sort of holistic sense for what the API looks like. This sleep 30 to 15. That's fine. Yeah.
01:03:09.767 - 01:03:31.755, Speaker A: And there's a comment here for wait for the startup. That seems great. Wait for the startup. I'm happy with that. So here's resume. It's fine. That ignores that.
01:03:31.755 - 01:04:39.965, Speaker A: So close is the right because so the normal implementation will. Or when you construct a session which also has to start the daemon for you, it constructs a temporary directory, which is where it sticks that socket file for the daemon. And so if we, if we created the daemon, then we know that tempdir directory and then on drop, we want to remove that tempdir directory again because we know we shut down the daemon as well. So this is just having the conditional here now, because now that it's possible to resume, we might not know the temporary directory, in which case we need to do this. So that seems fine. Detach will just take the path from the temporary directory without dropping it. So tempdir is a type here where it creates a temporary directory for you and automatically deletes it again on drop.
01:04:39.965 - 01:05:25.877, Speaker A: And so this is a way to tell it, no, don't delete on drop. That seems fine. That's fine, that's fine. And then I want to see what changed in the top level. So you'll see there's like a session RS for the process implementation. This is the thing that forks out to the SSH command and the native MUX implementation, which is the one that just talks directly to the socket daemon over the its own little protocol. And so let's see what we have on session now.
01:05:25.877 - 01:06:04.155, Speaker A: So we have resume and resume mux. So this is the way that you choose which of those backends you want to use. We have detach for saying don't drop this, don't close the connection on drop. And we have the tests down here. Well, I am kind of sad that there's not a close on drop. A session created this way will not be terminated on drop, but can be forced terminated by force terminate. That doesn't sound right.
01:06:04.155 - 01:06:42.797, Speaker A: I don't think that function is there anymore Unless I'm blind, which I could be. All commits. So in session we have resume. Yeah, see unresolved link to force terminate. Yeah, I think there's something missing. I think they forgot to add close on drop test. Force terminate.
01:06:42.797 - 01:07:30.293, Speaker A: And yet this doesn't call force terminate. Something's off here. Let's see if there's a more. I guess I can close this and I can close this. Move its functionality. So what did this commit actually do? Oh, I see. This doesn't seem right.
01:07:30.293 - 01:08:01.473, Speaker A: So this, what this is saying is when you call close, it will always terminate the. Oh, I see. Yeah. Okay, this makes some amount of sense. So the API now is. The API now is you can call close on a session and because you explicitly called close, it wasn't a drop, it was explicitly close. That will always shut down the daemon and the ultimately the connection to the host if you just let it drop.
01:08:01.473 - 01:08:29.419, Speaker A: If you don't call close, then the semantics are if it was resumed, then don't shut it down. If it wasn't resumed, like if we created the daemon, we also shut down the daemon. And so the idea here being the user still has the option of if they want to leave it running, they should always call detach. If they want it shut down, they should always call close. And if they just let it drop, then we do what we think think they probably meant. I think I like that. I think I'm okay with that.
01:08:29.419 - 01:09:58.309, Speaker A: It does mean though that this, this doesn't seem accurate anymore since there's no force terminate now. And same thing up here in the API where this should be called close. Now I think, and I think I want to add here too, that we should also update the documentation on close to mention that it will terminate the. It's called an SSH terminology. It's the control master that it will terminate the control master even if the session was resumed. Chat says if close historically didn't do that, you might want to hit a major change. So historically there was no way to resume a session so close.
01:09:58.309 - 01:10:43.045, Speaker A: If you called close, it would always terminate the session because that was the only semantic we had. So this is not a change to semantics. Luckily, same thing with drop. But it used to be and still is the case that if we create the session, which used to be the only thing you could do, then on drop we would also stop the session. So there's no change to semantics here. Great. Wouldn't something like exit be better instead of close because it's closer to the client's API? You're not wrong like the command to the control master is exit, not close.
01:10:43.045 - 01:11:26.167, Speaker A: But I don't know which is better here. I think close is okay because the way to think about this is you're closing the session right? In terms of the naming of the type you're calling it on, I feel like it's fairly clear, whereas exit isn't quite clear. Like what is exiting the session mean? Arguably that could mean detach. You know, it could be something like kill or terminate, but I feel like close is. Is semantically close enough, so to speak. Nice. Almost there.
01:11:26.167 - 01:12:12.960, Speaker A: I like the simplicity of where we ended up. Just some cleanup related to old references to force, terminate left and request a change. Great. All right, so we did that one update IO lifetimes requirement. Ah, so this is a PR from Dependabot also to OpenSSH. And the change it makes is just. It bumps the major version of one of our dependencies from 0.6
01:12:12.960 - 01:13:00.659, Speaker A: to 07. And at the time it just sort of. That looked fine and we just merged it without thinking too much more about it. But then we realized that the IO lifetime's crate is actually ends up showing up in our public interface for a real silly reason, which is we have this impulse. So STDIO is a public type in the crate and we implement from owned FD for stdio. This from implementation is something that we use internally in order to construct one of these from one of these. But the construction happens internally, so there's no real reason for anyone else to ever use this from implementation, but it is there.
01:13:00.659 - 01:13:47.453, Speaker A: So it's a part of our public interface. And this type comes from the IO lifetimes crate. And so what this technically means is that someone could have taken a dependency on this crate and also taken a dependency on the old version of IO lifetimes and depended on and expected that the type from our crate implements from of their type. So if we bump the major version of IO lifetimes, their code might stop compiling, which, you know, would be a problem. It's a backwards incompatible change. In practice, it seems extremely unlikely that someone depends on this change, partially because this is a very. This was only introduced in a very recent version.
01:13:47.453 - 01:14:49.605, Speaker A: So what we actually decided to do here was to hide this from implementation. So make instead of implementing the from trait, which ends up being a public part of the API, add a from method that is just internal to the crate to stdio that takes an owned FDA returns an STDIO that way it's not a part of our public interface anymore. And I think we should just do this change because even though it's theoretically breaking. In practice, it's not breaking and it enables us to disentangle our major version from that of the IO lifetimes crate, which means in the future we can do more of these updates without it having an impact on us. And nobody you agreed and filed this PR, which is probably going to be simple. Looks like iOS safety files can be stabilized in 163. Let's look at the changed file first.
01:14:49.605 - 01:15:40.625, Speaker A: Oh, I guess we weren't even using the from. Excellent. It's not so someone said being able to create an SDIO from any FD might be a problem anyway. It shouldn't be. In fact, this is something we kind of want to support. It's just that we don't want to tie that support to a major version that we don't control of a crate that is not essential to the API. One of the things that we're going to see is owned FD I think is landing in the standard library and that's what this latest comment is about, is that it looks like it's actually going to land in Rust itself.
01:15:40.625 - 01:16:53.975, Speaker A: So if we look over here, iosafety is an RFC that adds where do we have this owned fd which is that same type. This is basically what that crate was providing, was a sort of prototype of what was eventually going to land in the standard library anyway. And it seems like that has landed and is going to be released in Rust 163. I think what I want to do here is actually to land this anyway. Well, it's a good question, right? So the question is, is it worth removing this from implementation just to add it back once this lands in the standard library? I think it is because currently it would be a different from implementation. Like when this lands in the standard library, it would still be a change to the API move, moving it to what the standard library provides. Oh, is it safe to make a STD IO of a file FD or an epoll fd? It's safe.
01:16:53.975 - 01:17:03.275, Speaker A: It's just weird. Like it's not gonna. You're not gonna get any input from it. But it's. I mean it's safe. It doesn't cause any memory unsafety. It's just weird.
01:17:03.275 - 01:17:55.065, Speaker A: So I think what I'll reply here is I'd like to remove it anyway in the interim since as it stands it's. It's a breaking change problem waiting to happen. Happy to add it back after 163 without the dependency. Nice. So I guess I can resolve that conversation. I'm going to Merge this and then what I'll do. I guess I'll show you my release process for this.
01:17:55.065 - 01:19:33.315, Speaker A: So if I go to Miner openssh pull, let me do. Fantastic. So here we now have that change what even changed in cargo toml it looks an awful lot like nothing changed in cargo tunnel log P Cargo tunnel. Oh, it's just this dependency update. Okay, that's fine. So we have a change log here which is kept in source changelog and this is going to be 092. And what we changed was removed breaking change risk removed imple from owned FD for Studio as it was an unintentional part of the public API.
01:19:33.315 - 01:20:37.285, Speaker A: This is technically a breaking change but should in practice affect no one. And then I'll update the cargo toml change this to 092. So we'll commit that as release 092. And then I have this little script that is. I find it really handy. All it does is it walks back the git log of cargo toml and looks at which commit changed the version number and then tags each commit with the version in which it was created. So in this case, you see it found all the old tags and it tagged this latest commit that we just made with V092.
01:20:37.285 - 01:21:20.585, Speaker A: And then I just do git push tags and git push and cargo publish. Boom. And 092 is out. Fantastic. Shall we create a new release and yield? I think you mean yank all the other 09 releases. I. It seems all an awful lot like this person is also on stream given how quickly they responded.
01:21:20.585 - 01:22:14.205, Speaker A: Although I haven't seen their name in chat, but could be they are. So yanking is tricky. I'm not a huge fan of yanking versions unless there's actually like a security problem with them. Because yanking makes it so that anyone running an older version is forced to update. They're not actually forced, right? If they have a lock file they're just going to get like a warning and stuff. But it creates friction for users that you only really want to impose if there's like you gotta fix this or like you have a big problem on your hands. Things like, you know, for if you have a crypto library and it turns out that like it was leaking your private key to a public GitHub Gist gist gist gist.
01:22:14.205 - 01:23:23.435, Speaker A: Good question. Like that's something I would yank. This I don't think is important enough to to yank. I think this is quite worth the friction, the user friction of a yank, given that there isn't actually a security risk to this. The fact that there is a breaking change is mostly or is going to be mostly irrelevant to users released as 0.9.2 always with TADA. It's important.
01:23:23.435 - 01:23:59.323, Speaker A: Amazing. This means we closed an additional pr. So if we go back to the notification list now if I refresh it, this one's done. We got. We have more comments. Did Chad start commenting on this? Someone for I think this is somewhere for chat. I see you there.
01:23:59.323 - 01:24:50.661, Speaker A: I see this username self count is the total number of items including duplicates and the difference iterates over. Yep, I think you're entirely correct. Good comment. I approve. Dr. Eamon dreaming how do you pronounce a hyphen? I'm gonna ignore that. We're not realistically gonna get through all of these today.
01:24:50.661 - 01:25:52.661, Speaker A: I have to sleep at some point do something that's not openssh. Consider using text anchor for right Align strings so Inferno is the port we did of the Flame Graph library to Rust from Perl. And since we did the port we've actually made a decent number of changes to Inferno that aren't in Flame Graph. Things like improvements to the generated SVG and the embedded CSS and JavaScript, including the algorithm itself. I've used a somewhat modified version of the Inferno crate to construct Flame Graph for a blog post. Made a couple of changes I think some contributor here may be interested in implementing properly in the project proper. If two strings are expected to align to the right side of the image, right? So it generates an SVG that is a flame graph.
01:25:52.661 - 01:26:20.319, Speaker A: So this sort of stacked colored bar charts of where your program is spending its time, the search and reset search at the top and the matched statement at the bottom. Right now they're aligned by giving them 100 pixels of a space from the side which can fail to fit the string. Yeah, this is the classic like let's not absolutely position things. That's a bad idea. Instead. Instead consider using text anchor end. I didn't even know that this was a CSS specifier.
01:26:20.319 - 01:26:46.053, Speaker A: That's cool. Placing the text node at a constant location where the string should end. Oh yeah, that's a great point. I agree. That seems like a good change. Any takers? I'm looking at you chat and you people looking. We're looking at here from home.
01:26:46.053 - 01:27:39.715, Speaker A: If you want to submit a PR watch, I'm gonna get 10 PRs all making this exact change. I think CSS should be fine here. Although we do need to make sure that SVG supports all the relevant CSS constructs. I don't know that SVGs have full CSS support. Oh, this is not many GitHub notifications. Like if I go away for like two weeks, I have several pages, which is a good problem to have. But it also is like, you know, all these people are waiting.
01:27:39.715 - 01:28:04.497, Speaker A: They're not necessarily waiting on me. Some of them are just issues that I watch because I'm interested in the progress on like some Rust ticket, for example. I shouldn't call them tickets. Tickets is very enterprisey on Rust issues. But like knowing that a bunch of people are waiting on me or blocking on me is. Makes me sad. Yeah.
01:28:04.497 - 01:28:37.515, Speaker A: So an example here is. So this switchable buffering for standard out is a ticket in the standard library that I've been watching for a while. It's a PR to make it so that you can choose to make standard out be linked to the actual issue. You can make the. You can make standard out not do line based buffering if you want to. If you just want sort of raw standard out. And it's a.
01:28:37.515 - 01:29:00.545, Speaker A: It's not something I need very often, but I like to keep in touch with some of like the deeper details of how stuff works under the hood here. And this is a good example. And you know, it was open in October of 2020, so it's been going on for a while. Because here too it's not entirely clear what the right API should be like. It's pronounced Drayman. Oh, Drayman. Nice.
01:29:00.545 - 01:29:58.785, Speaker A: But yeah, so this is like an example of something that is, you know, it shows up as a notification, but it's not actually blocking on me. All right, so let's do the haphazard one just to sort of skip to another project. So haphazard is the. Yet another one of the streams that we've been doing which is implementing hazard pointers, a library for hazard pointers in Rust. And one of the things that I did since the last stream that I did more sort of asynchronously offline was try to tidy up the interface so that it's a little bit nicer to use. You know, giving a little bit higher types like atomic pointer that behind the scenes just deals with the fact that like makes everything box for you and stuff. I recognize this name.
01:29:58.785 - 01:30:48.879, Speaker A: I've been working on a concurrent hashmap with the help of Haphazard and have seemed to come across undefined behavior in safe code. No, they're probably right. I believe them already. So they have a family struct, they use atomic pointer, they create an atomic pointer to null. They create a new and an old and they compare exchange where they expect the current value to be old and the new value to be new. This will fail because the current value is null, it's not old. And so therefore this will fail.
01:30:48.879 - 01:31:54.485, Speaker A: And I forget what I set the cement. I think I see where this is going already. So if we look at atomic pointer and we look at Compare exchange week, it returns an option replaced and if it fails, it returns you. Right, so the idea here is if the compare exchange fails, then we want to return new because we never actually stuck it, we never actually gave it away, we never actually put it in a shared location and therefore it's safe for us to give the caller back the new. That's what this isn't supposed to be. And I'm guessing that this is not true. That's what I think this issue is going to actually be.
01:31:54.485 - 01:32:36.625, Speaker A: When run with cargo mirror run this produces box unique new unchecked raw. Right, so this is from box from raw, which is in practice what P from raw here actually means safety common for atomic pointer news as the P must be a valid reference to T or null. However, when the compare exchange fails inside Compare exchange week, the null pointer ends up in the air variant. Oh, so pointer here ends up not actually being new. Pointer here ends up being ends up being the. The old current. No, you're totally right.
01:32:36.625 - 01:33:35.325, Speaker A: Yeah. So I think where this is actually broken. So if we go over here to lib, the lib here is too long. I should break this into a separate file. Weak pointer. Yeah, because the semantics of a compare exchange in the standard library is if it fails, it returns. It doesn't return the thing you passed in as current, it returns what the value actually was given that it wasn't current.
01:33:35.325 - 01:34:17.345, Speaker A: The return value is a result indicated with a new pointer was written and containing the previous pointer. This should arguably be the current pointer as a better way to frame this. So the actual fix to this is. Let me. I'm gonna first open this separately because I'm gonna want to link to this in the response. But the fix to this is that here new here is a RAW pointer and RAW pointers are always copy. So we can just use new here.
01:34:17.345 - 01:35:38.085, Speaker A: That's the correct answer. So I think the answer here is L616. That's just straight up wrong. The bug is in compare. Oops, let me make that. Ooh, what am I doing? I was trying to make this larger, which I failed at the bugunison Compare Exchange week and I suspect also compare Exchange exchange. Assuming that the pointer version returns current on failure when in reality it returns the value stored in the standard sink atomic atomic pointer that wasn't current.
01:35:38.085 - 01:37:39.671, Speaker A: The solution here is luckily simple. We just need to change this and this is where I think this in order for this to be embedded correctly by GitHub I'm going to press Y and that way I get a commit specific URL and that way it's going to actually fill in the code block here and then I'm going to say instead we're going to change that. Two new was never shared and was a valid P so this should just be new and this can be a move which should work since new is just a mute T and that is copy. Want to file a PR for this and the non weak variant. And what I'll also say is we may also want to update the wording on the pointer method, the documentation wording on these methods to clarify what previous value means. Maybe it should say. I don't know what it should say here.
01:37:39.671 - 01:38:40.157, Speaker A: For example, let me link that issue here too. So this is some discussion in chat about where to discuss things. So whether you should discuss things in GitHub issues or whether you should discuss things in like Discord where you can have more real time whether you should try to have a voice call. You know, it's tricky. I do really like having these discussions on GitHub because it makes it more permanent. It means that there's sort of a track record of the discussion that's easier to follow. Sometimes though, it's true that it is useful to sort of actually have the back and forth, but even that, you know, if it's in the issue it's something you can link to.
01:38:40.157 - 01:39:23.379, Speaker A: You can link to individual comments. So it is a little slower to do it this way, but it can be. It's much more valuable sort of in the future it will be more valuable. And that doesn't mean that you could never take these discussions on Discord. Like if you feel like you're really just bike shedding something and you need the back and forth do it somewhere else and then come back and do summaries in the issue. That works pretty well. Voice chats are hard like both because you're strangers on the Internet but also because once you put either sort of synchronous voice or worse yet video youo feel put much more on the spot.
01:39:23.379 - 01:40:02.345, Speaker A: And I think for some people that's just like uncomfortable either because they don't feel confident expressing themselves that way or they worry about saying something wrong or they just worry about the other person being an asshole. Right. Like it's easier to in text measure out your responses and articulate your arguments well. So I do see the desire to not go all the way and actually have, you know, real conversations. Sometimes that is useful. But it's pretty rare that I take. I take someone up on an actual conversation like that unless there's someone that I've actually been interacting with a lot.
01:40:02.345 - 01:40:25.927, Speaker A: Internal. So I think for development within a team, it's very different. Right. If you work with. If you have co workers that you deal with on, you know, GitHub issues or something. I do calls with people like that pretty regularly because it is really valuable. But doing it as like I'm just going to do this with a random stranger that I'm collaborating a little bit with online is.
01:40:25.927 - 01:40:41.931, Speaker A: I think the bar is much higher and I don't want to put that pressure on them. That would be. If I reach out. If they reach out, I'm more open to it. Partially because I'm. I generally am pretty okay with just, you know, doing things on. On the spot.
01:40:41.931 - 01:41:10.977, Speaker A: But even then, you know, it's. It's more of a time commitment. It. Synchronous communication is pretty costly and. And it's not something that you should generally, I think, ask of other people unless you have a pretty strong reason for doing so. Yeah. And conferences and stuff are a great way to have those conversations in a little bit more of like a batch setting.
01:41:10.977 - 01:41:22.205, Speaker A: One of the many reasons why I miss conferences. Okay, so Troy is on stream. Hi, Troy. That's funny. Okay, great. So we got a response to that. I'm going to mark this one as done.
01:41:22.205 - 01:41:49.473, Speaker A: People should not be afraid to talk over voice. In person used to be the only way to communicate. That's true. But even though they shouldn't, that doesn't mean that they're not. And I think, you know, that there's like the reality of the situation that that's not everyone's preferred way of communicating. And that's okay. I don't think it's necessary.
01:41:49.473 - 01:42:32.775, Speaker A: And I think there are some serious upsides to doing it where there's sort of a log of the conversation too. Let's see. Okay, what else we got? Inferno move from Lacy static to one station. Okay, so this is. These are two crates that you, you may have heard of both. Lacy static is one that just like is everywhere in rust. Like it used to be basically the only way you accomplished what lacystatic does, which is it allows you to have a static variable in your program.
01:42:32.775 - 01:43:15.995, Speaker A: Whose constructor is not const. And they used to be much more important because so many things were not constant. But even now, you know, this is like, let's say you want to create a Mutex and you want to stick it in a static variable. The way you have to do that today is using Lacy Static. That is what's cool is that's changing with Rust 163 like the next release where Mutex new is actually const now, which is some awesome work that Mara has been doing. But there are a bunch of contexts where the constructor for your. Your static variable you basically want to only run once your program is run for the first time.
01:43:15.995 - 01:44:22.545, Speaker A: The idea here being that the constructor for a static thing needs to be const because you're basically going to run it at compile time and then stick the resulting like bits into the binary. So when the program runs for the like when the binary runs, it can just load those bits into a predefined version of the program memory at startup and not run any code to initialize it. What lacystatic does is basically when your program runs there's a little bit of a like a secret section in the binary of code that gets to run before like main sort of. And lacystatic is sort of takes advantage of that where it. It runs the setup code for your statics in there. So basically it makes the statics just be a blob of uninitialized memory. And then in that pre main little initialization code path, it runs the code to construct the thing and then fills the bits into the uninitialized memory and marks it as initialized.
01:44:22.545 - 01:45:10.685, Speaker A: So from that point forward you can access. And because it is in static memory, it continues to be A valid static 1 cell is a replacement of lacystatic that changes the API a little bit. It's also actively maintained, which is nice. But one of the reasons why it's nice is because you have control of when the initializations happens. So rather than just saying it runs in this pre main init bit, what you actually do with one cell is when you access the variable, like when you access the static, you also say how to initialize it. And that is the point at which it gets initialized. So you can think of this as it sort of gets lazily initialized, but only once, hence the name one cell.
01:45:10.685 - 01:45:48.235, Speaker A: And so what this PR is doing, and I haven't looked at the diff yet, is moving from the Lacy static crate, which is only passive maintained, to the one cell crate which generally has an API that's considered better. It's also a little faster and it's well maintained. I think one cell is also on path, on a path to being standardized in the standard library. There's a PR open for it, I believe, that's been open for a little while. So let's see what this changes. This does have to change a little bit because as I said, it's not a slot in replacement. It actually has to change where the initialization happens.
01:45:48.235 - 01:46:26.199, Speaker A: So let's see. Okay, this is. That's simple, right? So in this case we use the lacy static for keeping a track of the number of threads. And we do this because we have some. There's some part of the data structure where we want to shard it by the number of threads so that you get more efficient concurrent access. Because the threads don't all access the same variable. Instead they access a sort of per thread variable and then other threads have to read all of them.
01:46:26.199 - 01:46:58.435, Speaker A: So writes or things that need to access all of them are slower. But most operations you only need to access one, and so there's less contention on any one value. But the number of threads we sort of assume doesn't really change, or the number of cores rather, or the number of thread slots is the right way to phrase it. So calling num CPUs get is a little costly. It has to do a bunch of like operating system lookup calls and stuff. So we want to cache that value and we're going to be accessing it everywhere. So we would rather have it be in a static than having to pass it around our program everywhere.
01:46:58.435 - 01:47:22.241, Speaker A: So this here declares this as a static, uses the lazy type from one cell. Oh, that's nice. Okay, so it seems like, oh, I didn't even know that one cell had this. That's nice. So that means the diff is actually going to be pretty small. One cell has two APIs, it seems. So there's one cell which has new that gives you a thing.
01:47:22.241 - 01:48:04.815, Speaker A: And get. Where's the. Yeah, so and get or init on that which is going to initialize it if it doesn't exist with by running the closure. And then it also has lazy, which is a convenience type to streamline the pattern. And so that is when you call new, which is a const fn then you pass in the closure to run. And this presumably then uses the pattern we talked about of using the sort of initial section and runs this code for you before main. So this is just to encapsulate that particular pattern.
01:48:04.815 - 01:48:39.057, Speaker A: Nice. So that Means the diff here is actually going to be pretty small because we can just say when we construct a lazy that the constructor is numcpus get. So the first time someone tries to access this variable, run this function. Oh, you're right, it doesn't use live before main. You're totally right. It. It sticks a value in there where when you access, when you call get on this value, then it checks if it has been initialized and if it hasn't been initialized, then runs the initializer.
01:48:39.057 - 01:49:04.965, Speaker A: You're totally right. It doesn't run before main. There is a way to run things before main, but this is not using that. You're totally. So this is what that is doing is it's creating a one cell for you where calling get on. It will use this as the initializer if it hasn't already been initialized. So that's nice and easy.
01:49:04.965 - 01:49:35.675, Speaker A: This is n threads as a string. So that's just the same. This is also just the same. This is the same. And this is if multithreaded. Right. So this could technically be, you know, this is a tiny nit.
01:49:35.675 - 01:49:53.023, Speaker A: But this could just name the function similar to what they did in all the other files. I don't know. Or I guess it was just in the first. So you see up here. Here they used this syntax where you just give the name of the. Of the function. And here they gave a closure that immediately calls the function.
01:49:53.023 - 01:50:42.131, Speaker A: So that could just have used the same form as above. I'm not even going to comment on it. It's not quite worth it. What if more than one thread tries to initialize it the first time? Internally, there's like internally, both of these crates have a mechanism for detecting and making sure that only one thread does the initialization and the other threads will. Wait. Why use format instead of tostring? Good question. I don't think there's a particularly good reason, but that's sort of unrelated to this particular pr.
01:50:42.131 - 01:50:56.615, Speaker A: If you want to submit a PR that fixes that. Absolutely. Please go ahead. I love cleanup PRs because they're really easy to review. They make my future life easier and they make me happy. So, like, absolutely. Submit PRs that are just sort of tidying up things.
01:50:56.615 - 01:51:48.705, Speaker A: Why is this even a lazy static? Oh, it's because. So here the constructor is a. The constructor here is a constant. But because this same static we define under conditional compilation, it needs to have the same type because otherwise, you know, if you have the config or if you don't have the config every place that accesses it. Like, if it's a one cell, you need to use get. If it's not a one cell, you don't need to use get. And so therefore we just have them be the same type in both cases, which means that we need to use the Lacy initializer here.
01:51:48.705 - 01:52:12.157, Speaker A: So that's fine. This is. Right. This is in tests where we want to use the same input. For all the tests, we just stick it on a static. I don't know. There's a particularly compelling reason to use a static, but that's fine.
01:52:12.157 - 01:52:41.955, Speaker A: This is. I mean, it's just converting what was already there, so I'm not going to talk about that too much. This seems fine. Oh, this had incorrect indentation. It's because in the macro and this uses two strings, so we're clearly just inconsistent. Beautiful. Thank you.
01:52:41.955 - 01:53:32.885, Speaker A: Merge. So this was in Inferno. No, I really need to. The reason I run gitlug one line here is I want to see whether there were other changes since the last release. I did. It's a typo fix. I don't care too much about that.
01:53:32.885 - 01:54:42.019, Speaker A: So for the change log, arguably I should just use something like Cargo release here so I don't have to do this stuff manually. But I don't know, there's something kind of nice about doing it manually. I don't know. I don't really mind it. So here we're going to say 0115 was released 20220618 changed, moved from Lacy's Lacy static to one cell, and that was through PR number 249. Check the cargo toml sometimes what I'll also do is when I do a new version release, I'll also run, you know, cargo update, cargo outdated R. Just to see whether there are any dependencies that I should move to a new major version.
01:54:42.019 - 01:55:07.845, Speaker A: Usually, I mean, only if they're internal dependencies or private dependencies only. Right. But just because, you know, there's no reason not to bump those while we go, so we don't have to do it later. In this case, there are none. So the diff is easy enough. You'll notice here I start naming the new tag because I'm about to tag this with the correct tag. Beautiful.
01:55:07.845 - 01:55:29.351, Speaker A: All right, so we're just going to say release 0115. Run my little script. Push tags. Get push cargo publish. There's an argument here for I should wait for CI to pass in. Fine. Just to see that I'm not, you know, doing something very silly.
01:55:29.351 - 01:55:59.497, Speaker A: I'M going to run cargo test. CI already passed before I merged the cr. Right. So the pr. So this shouldn't. This really shouldn't matter. Is it okay to nitpick code inconsistency or quality if I'm the maintainer or is it considered rude? I would have a hard time accepting a PR without leaving knit comments, but my OCD could.
01:55:59.497 - 01:57:02.539, Speaker A: Yeah, so it's a good question. Me do you know, it could be considered mean. What I try to do is I try to be very clear in my review whether something is a niche that I'm willing to ignore or whether it's a blocker for merging. And I try to keep those straight in my mind. What I'll sometimes do is if there are other changes, like if there are changes I require to the PR that are not stylistic changes, then, you know, I'm more inclined to say, also fix the stylistic changes. If there's only stylistic changes left, then I tend. Unless they're, like, particularly egregious, I tend to just merge it and then just do those fixes myself after because it's.
01:57:02.539 - 01:57:47.945, Speaker A: It saves the back and forth and it makes that person feel better. And it saves me time too, because I don't need to keep going back and forth on it. That said, for stylistic things, if it's actually style, like, if it's code formatting, Rust format should take care of that. That should be run in CI. If it's like, this is the wrong name for this type, those things I will actually comment on because I care a lot about the public interface of my crates, whether that be the documentation, the types, the method names. So those I will comment on because I don't think they're nits, I don't think they're unimportant. But, you know, for anything else, you know, CI for me runs clippy and rust format, and they have to pass.
01:57:47.945 - 01:58:47.039, Speaker A: And if they don't, I tell them it doesn't pass because it doesn't pass clippy or rust format. So that's what they have to do. But it is a balancing act. And I think the thing that you train yourself on is where's the bar for when I say this is good enough, I can fix up the rest myself. What I will sometimes do, especially if I see that they're a new contributor, is when it gets close to when it's at like the 90% mark or something, where all the important bits are in place, what I'll do is usually merge. Sometimes I'll leave the comments and say, here are A couple of things, but even that is often not important because it becomes so nitpicky. So I'll sort of approve the PR merge fix myself and then go back to the PR and say, you know, something along the lines of I decided to do a few more stylistic tweaks or tweaks to fit the consistency of the current code base a little better.
01:58:47.039 - 01:59:38.987, Speaker A: If you're interested, take a look here. And then I link them the commit or the commit range that I just pushed so that they can see what I did differently. And the reason why that that sort of closing that loop is important is because imagine that they want to do another contribution later. You want them to learn if you just do the fix on your own. If they're one time contributor is not a problem, but the second time they come around, you're going to have to do that yourself again. So you would rather them learn, but this way you take away the cost from them for a one time contribution or first time contribution, but you do still give them an opportunity to learn going forward. So yeah, I think there are no right answers here, but in general I would say if you can group it with other changes that are required, then absolutely try to have them make that changes.
01:59:38.987 - 02:00:25.615, Speaker A: If you feel like there are too many of them, try to do only a few for each round of review and keep in mind the level of at what point should I just do the rest myself? And then make sure you close the loop and link them back to it. Great. So we did a new release of this, so I'm going to say published in 0.11.5 comment and again, remember to leave thank you messages. Remember to leave messages about. Again, this person took time out of their day to send a PR to my thing so that I didn't have to do it. So even if their change is like small, it saved me a bunch of time.
02:00:25.615 - 02:00:58.725, Speaker A: I didn't have to go do this. I probably it saved the people using this library a bunch of stuff because I wouldn't have gotten around to it for ages. And also tell people what version the change comes out in because six months from now someone's going to care. All right, done. Let's see what we got left. Close, close, close. What do we got left here? So this is more for OpenSSH.
02:00:58.725 - 02:01:23.151, Speaker A: This is more a design question around splitting low level and high level. I'll deal with that separately because I have to think about that. A closed pr. That's always interesting. This is. So this is a draft PR for Inferno. So Inferno supports bringing in profiler data from a bunch of different sources.
02:01:23.151 - 02:02:28.745, Speaker A: So it supports perfect, it supports D trace, it supports a couple of other like the X code output format and someone wanted a while back PHP X debug traces. And you know, the way you do this is you add a collapser, which is the ingest pipeline that turns the profiling data into a format that the visualization generator can understand. And I remember this starting up I guess 2019. Yeah, this draft started and we went through a couple of reviews because there were a bunch of things that were like not quite right or there were some edge cases that weren't captured. And ultimately I think this person ended up moving on from the pr. They didn't have a chance to come back for a while and I it looks like they recently discovered that they don't care anymore, which might be, you know, they don't use PHP anymore or something. So they're going to close the pr.
02:02:28.745 - 02:03:47.677, Speaker A: So heart because thank you for offering to do more work and thumbs up for understood. That seems good and I'll say closing seems reasonable. And then should someone need this in the future, they can always pick up from where you left off. Oh yeah, it's true. You can nitpick a lot more for, you know, company internal or private repositories or cases where you know other people. That said, even there, I think you should keep the same things in mind. You might have junior team members or you know, down the line someone might come back to look at this to figure out why a change was made or even just like you're up for promotion and the senior people above you are going to evaluate what are you like in reviews.
02:03:47.677 - 02:04:33.971, Speaker A: Like do people enjoy working with you or collaborating with you on code? And if they see that you're just endlessly nitpicking on everyone's crs. I keep calling them CRS because internally in AWS they're called crs, not prs for code review. So they're synonymous. But ultimately you should still A be nice to people, but B make sure you use their time and your time wisely. Sometimes it's just not worth the extra round trips and either you should do it yourself and then offer here's the commit where I made the last few changes myself to save us both some trouble. But you can still learn from it. But also don't you don't want to end up being the person that everyone's like.
02:04:33.971 - 02:05:03.205, Speaker A: I just don't want John to review my code because I know that it's just going to be pages and pages of nitpicking. Right? I don't want that either. Great. All right, so that's done. Let's do maybe one or two more. Ooh, different project. Let's do that.
02:05:03.205 - 02:05:39.597, Speaker A: Oh, okay. I already know this is going to be fun. It has Taiki and Ralph, who recently commented. Okay, this is great. Update dependencies, fix on soundness and CI failure from December 2020. All right, where did this go? Miri reports undefined behavior. So in 2020, I was like, I don't know what this error means, whether that.
02:05:39.597 - 02:06:22.015, Speaker A: Whether it's Miri that's broken. This is when Stack Borrows were in the earlier stages. Is this Miri being wrong? Like, is it a false positive? Is it a bug in Bus? Is it a little bit of both? That's funny. I left a review in December 2020 and two days ago Taiki made the change. That's great. Yeah. So this is something that I think I may be weird in this.
02:06:22.015 - 02:07:21.305, Speaker A: I really like having explicit drops for indicating that you shouldn't be using a thing anymore. Even though it doesn't semantically make a difference or performance way makes a difference. It just maybe it's like the literal literate programming part of my brain that's just like. I feel like this should go away now because it's confusing if it keeps living. So I guess this commit restores. Yeah, that's fine. Okay, so there was a myriad limitation here somewhere.
02:07:21.305 - 02:07:56.025, Speaker A: Ah, so, okay, I think I remember what happened here. It's part of what we do in Bus. So BUS is a broadcast channel. The idea being that you have. It's sort of the opposite of the channel you have. In the standard library, you have one sender, we have multiple receivers, and furthermore, it's broadcast. So any send goes to every receiver and the message doesn't go away from the channel until every receiver has seen it.
02:07:56.025 - 02:08:40.575, Speaker A: So if the sender sends 1, 2, 3, every receiver will receive 1, 2, 3, and in that order. And one of the things that was needed for this library was a way to drop values that have been received by all receivers. And I think what I ended up doing was spawning a separate thread to do that dropping. But I never wait for that thread to finish. That thread just sort of keeps running in the background. And it just assumes that when your program exits, that thread goes away. And it doesn't cost anything because it's just blocking if there's nothing to do.
02:08:40.575 - 02:09:33.745, Speaker A: And Miri doesn't like it when you have a thread. So just keep running because it's basically a leak I think that's what we ended up at here. Yeah. Right, so Miri checks for thread leaks, but that's also tied to memory leaks, because if you have a thread leak, anything that that thread owns also gets leaked, as in memory. Right. So I think that's where we ended up. And the reason why this sort of stalled was because this was a thing that needed to be added to Miri.
02:09:33.745 - 02:10:07.375, Speaker A: Miri. Oh, interesting. Okay, so it started up because there's an issue in cross BIM utils and this package depends on crossbeam utils. So ideally we should update crossbeam utils, which is what caused CI to fail in the first place through Miri. Miri currently fails in various projects to issues, although it's probably possible to work around them by disabling weak memory emulation preemption. This crate is not affected by that issue. Okay, that's good to know.
02:10:07.375 - 02:10:36.425, Speaker A: This create depends on atomic option with vulnerabilities that could affect this crate. Yeah, I haven't looked at this in ages. CI uses 1604 which is not only supported. Great. CI is now green, except code cov, which is angry that the comments I added were not covered. Yeah, code cover is very aggressive. Part of this is because it doesn't use the new LVM instrumented coverage.
02:10:36.425 - 02:11:22.675, Speaker A: It uses the like profiling based coverage, like the sampling based coverage. So it's not perfect. And then RALPH looks in and like why do you need to disable isolation? And we do that because there's a receive timeout function which relies on time and that means it can't be isolated, which arguably means I should just hide received timeout from the execution of Miri. Great, let's look at the actual diff. So this bumps parking lot core to.09. It removes atomic option, it bumps crossbeam channel. Great.
02:11:22.675 - 02:12:24.227, Speaker A: Azure pipelines, parking lot core, Ubuntu, Latest, grab Miri, install Rust, run Miri with disable isolation, ignore leaks, no preemption, no weak memory emulation. That's fine. Both of those are due to Miri issues preemption. I see. So this is a standard library Miri interaction which ends up affecting us. The few tech things apparently been fixed. When is it been fixed? Merged 14 hours ago.
02:12:24.227 - 02:12:54.665, Speaker A: Okay, so that means we could probably get rid of the weak memory emulation, but that's fine. I don't. I'm okay with landing that without it, I'll just leave this unresolved pumping. Latest bumping that. That seems fine. This skips an example from Miri. That seems fine.
02:12:54.665 - 02:13:43.685, Speaker A: I wonder why this Change changed. We used to drop the state outside of there, and now we drop the state inside of here. Because why. I wonder why this. There's got to be a change somewhere. Okay, can we. I want this to go away.
02:13:43.685 - 02:14:08.615, Speaker A: There we go. I need some more context for that change. Oh, I see. It's because we're using our own atomic option, which is null. It has a swap. What's the. Remove all annotations.
02:14:08.615 - 02:15:05.787, Speaker A: A. There we go. If old is null, then none. Oh, I see. Okay, so this is just a very trivial and obviously correct implementation. I should never say obviously correct for something like this, but seemingly clearly correct implementation of atomic option that doesn't rely on the atomic option crate and it only provides the operations we care about, which are swap and take. So that's fine.
02:15:05.787 - 02:16:19.645, Speaker A: And because that API changed, Replace now becomes swap, replace, none becomes take, and this becomes. That's very interesting. Why did this have to change? Why did this drop have to go inside of here? I don't understand that part of the change. So state here is a reference. I think that. I think this didn't need to be moved because it's still safe to access the inner value all the way until this fetch ad. So this.
02:16:19.645 - 02:16:50.288, Speaker A: This part of the diff isn't necessary. It's not wrong. But it could have stayed where it was. Yeah, my. The. The comment I've hidden here is just that there was a previous version of this PR where they just removed this drop entirely because it's not necessary. And I said I would like to keep the explicit drop because I want to signal that you can't use state anymore.
02:16:50.288 - 02:17:31.677, Speaker A: And I think what happened was when they restored it, they restored it in the wrong place because they restored it where they remembered it being, rather than where it actually was. It said something about putting the drop in the else branch. Kind of like in some sense, it's my little match. Oh, right, right, right. No, you're totally right. If we go back trying to reborrow for shared only. Right.
02:17:31.677 - 02:17:57.358, Speaker A: Miri complains it's not actually okay. Yeah, I see what happens. It's because trying to drop it out here means also trying to access it after we've mutably taken a reference to it here, which is not okay, but accessing in the else branches. Okay, that's fine. Yeah, yeah. So this is a correct change. That makes me happy.
02:17:57.358 - 02:18:33.725, Speaker A: Great. No, you're totally right. Okay, so this seems great. Thank you for following up on this after all this time. Heart and I don't care about the patch change that's fine. I also want to move this to use GitHub CI because the Azure stuff is a little annoying. So I'm going to merge that which is going to be.
02:18:33.725 - 02:19:05.215, Speaker A: And so I'm going to do this as this can be a minor release. To be honest. There's no new feature in this at all. There's all sorts of like buses. A fairly old crate at this point, arguably, you know, I should update it to the 212021 edition. I should move it over to use GitHub CI. I should get rid of the badges.
02:19:05.215 - 02:20:23.821, Speaker A: But I it's not important like what matters is fixing the the issues in it. I don't think there's even a change log for this. So I'm just going to do git commit dash a something like bump dependencies bump important dependent important dependency bumps release version I can't even git commit amend 224 release 2.2.4. This bumps multiple important dependencies and gets rid of the atomic option dependency. And if we tag this as a bunch of old tags here, that's fine. Git push tags and Cargo publish amazing. 2.2.4
02:20:23.821 - 02:21:08.325, Speaker A: is out and this is done. So I'll say released in 2.2.4. The reason to remove the badges from Cargo Toml is they've been deprecated. They're no longer a thing that they recommend that you put in Cargo toml. And the reason was because they realized people put it in the readme anyway and Crates IO renders your readme by default now. So you just ended up with the badges in two places and the badges on Crates IO needed like special code to support support them because you needed like for each badge kind, you needed code in Crates IO to generate the appropriate badge. So they were just like we should just render the readme and allow people to render their badges as they want.
02:21:08.325 - 02:22:07.205, Speaker A: Okay, I think we've now sampled a bunch of different crates. We've also released three new versions of different crates and it's getting pretty late over here, so I think that's where I'm going to cut it. Any questions? Sort of at the tail end here before we end for today. How would I know if I need to use Miri as CI? I would use Miri as CI for anything where you have unsafe code or where you're doing unsafe code is the primary indicator, I think. But anywhere where you're doing like concurrency or synchronization. Miri is also really useful because chances are under the hood you're using a library that does unsafe stuff around that. And Miri is pretty good at catching the undefined behavior, even through those layers of abstraction.
02:22:07.205 - 02:23:03.985, Speaker A: Totally unbiased. But this is a great time to stream. Yeah, I want to do more streams that are friendly to, like, time zones that are not just like Europe and the U or Western Europe and the U.S. it's just, it. It's a little harder for me to plan around, but it's. I want to pick more times like this too, and it's good to know that there are people here who will come watch. Oh, you mind scrolling up and making a comment on my question about staying motivated to learn during periods of discouragement? How do you avoid, you know, getting your curiosity stifled with all the stuff you have to deal with? You know, I don't know that I have great advice.
02:23:03.985 - 02:24:15.553, Speaker A: There are times when I get, you know, tired of the work that I'm doing, or tired of the open source stuff, or tired of following up on PRs all the time and feeling like at this point I'm just catching up all the time rather than working on things that I think are new and interesting. And that's sort of the curse of doing well in some of these areas. If you write a library that gets a lot of uptake, that means that a lot of people are using your thing, which means you need to spend a bunch of time on it to, to address issues and add new features and whatnot. I think the thing that has helped me the most is a, to realize these people don't have a claim on my time. I want to help the people who use what I build, but it's still ultimately essentially me volunteering my time and so it's okay for me to not work on them. I think one thing that helped me a lot was being I'm just not going to respond to things immediately and say I'm going to do three hours every weekend or something. And that just means that people will have to wait a week before I get back to them.
02:24:15.553 - 02:25:06.195, Speaker A: And it sucks, but that's the reality of what being a sort of volunteer maintainer is like. The second thing I would say is try to aggressively get co maintainers. And I don't mean aggressively as in that's how you should talk to them, but more like if someone submits a PR and it seems like, you know, they're interested, they have a good use case for it that seems like they're, they know what they're doing or they're willing to learn, give them permissions, like make them a co maintainer maybe don't give them, like publish permissions to crates IO immediately, but bring them on board. Try to engage them in conversations. Like when there are issues or PRs, loop them in. Like, if there's something where you're like, I'm not entirely sure what the right design decision here is. Like, cc them at them in that discussion thread to try to get their input, expose them to more of the project.
02:25:06.195 - 02:25:32.529, Speaker A: So this happened to me with the IMAP crate I maintained, for example. There was a person who reached out and was like, I would love to just get more involved with this crate. And I was like, great, let me start tagging you in things. Let me start if there are issues that I don't have the time or I don't know, I don't either have the time to follow up on or I know I won't do it for a long time. Let me give you some pointers. Try to do some mentorship. And that worked great.
02:25:32.529 - 02:26:24.789, Speaker A: Like, I loop them in whenever there's a design decision to be made, and then they start making contributions themselves and like, make progress towards issues that are tagged as the milestones for the next release. Same thing happened with the OpenSSH crate, where nobody Jew just like really stepped up to the plate. It was like PR after PR after pr, fixing issues, responding to people, filing issues. And that helps me a lot too. Not just in a technical sense, but in like feeling better about my work because I know there are other people dealing with it, there are other people addressing it, helping with it, and it's not all on me. And taking that weight off helps, like, my mental sanity too, and also my willingness to keep going on the other things that I have. And I think this is a lesson for the people who aren't maintainers too.
02:26:24.789 - 02:27:46.753, Speaker A: Like, maintainers have a lot on their plate. So if you are willing to step up and help a project, like, please reach out, I would love more people to do it. Unfortunately, it is the case that people are often enthusiastic in the beginning and then sort of lose interest over time, which is understandable, right? I would have done the same if I didn't own the project. But try to like keep up or give some indication of what kind of time commitment you're willing to give, but know that it is appreciated. Like, I get people who contact me on issues or I will explicitly ask on a PR and issue like, hey, would you be interested in like taking more ownership of this? I get people who email me or tweet at me or whatever, and I love the chance to Give away more parts of the things that I end up being the maintainer of because I know that I can't be a good responsible maintainer for all of these things if I do them all alone. That's the best I can. The best I can say if you have a crate that you don't want to maintain anymore, that one's harder because you don't really, you're not really in control of giving it away.
02:27:46.753 - 02:28:28.967, Speaker A: There is always the option of just like deprecating the crate and say, you know, this is gone now, I'm just not going to maintain it. And if people go, well, why not? I need it, then you say, well, here you go, I will give you all the permissions. There isn't really a path for like I'm going to look for someone to give it away to. That doesn't really happen. The closest you can do is like you can add Rust bus as a maintainer, which is like a group of people who have volunteered to sort of handle, be the backstop in a sense for these projects. But I don't know that that's meaningfully better than just saying, you know, this is at this point unsupported, unmaintained. And if you're interested, reach out to me and we can chat.
02:28:28.967 - 02:29:25.381, Speaker A: Put that in the readme. And that's just where we're at. Would you ever consider full time operating? Operating? When I see os, I start reading operating systems and it's OSS and it's different. Would you ever consider doing this full time, like again offering system open source software development? Maybe. It's hard to know whether it's sustainable. I think the, the path towards it would probably be more of a sort of combination of teaching, consulting, open source, maintenance and maybe something along the lines of like build on demand, which falls under consultancy. But I could imagine that a combination of those might actually fund me full time.
02:29:25.381 - 02:30:10.965, Speaker A: Probably not for a few years, but that would be really fun. If I was actually able to like maintain these as a full time thing and get sufficiently paid for it, I would probably come through something like, you know, GitHub sponsorships and maybe foundation fellowships, something like that. I think I would also love to do more streams, more education, more teaching, maybe do like develop a Rust class of some kind. And also I could imagine doing, you know, a consultancy where I take on both. You know, hey, we're a company and, or a project and we need someone to build a crate that does this. Will you build it for us? Sounds like a lot of fun. I get to work on different projects, although it would be more of a handover than me then maintaining it forever.
02:30:10.965 - 02:30:42.323, Speaker A: And a combination of that and, you know, we're a company and we're using Rust. Will you come help teach us or teach us about this thing or teach us how to use this library or whatever? And I can do that as sort of a paid gig. Maybe some combination of these is feasible to do full time. I don't know at the moment, no. But maybe in the future. All right, I think that's where I'm gonna cut it. Thank you all for coming out.
02:30:42.323 - 02:31:02.211, Speaker A: Hopefully this was interesting. If it was, then we'll do it again. If it wasn't, I don't know whether I'll ever know, but I guess. I guess the analytics will tell us afterwards. But thank you, everyone, for coming out, and I hope it was good. See you all. Oh, no, I don't exit obs.
02:31:02.211 - 02:31:03.155, Speaker A: I want to stop recording.

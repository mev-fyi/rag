00:00:01.440 - 00:00:32.435, Speaker A: All right. Hello, everyone. Welcome back to another stream. I'm John. I do a bunch of Rust streams, and I started doing these because I wanted to do some more intermediate Rust stuff that could sort of be learning materials for people either learning rust or have learned rust and want to see something more advanced being developed. I have a Patreon page where I go through, where I sort of post ideas for upcoming podcasts or, sorry, upcoming streams, or where I link to a bunch of projects. I maintain.
00:00:32.435 - 00:01:00.945, Speaker A: If you want to hear about upcoming streams, you can follow me there. You can follow me on Twitter and I'll post basically everywhere. Today we're doing a somewhat more advanced stream than some of the past ones. In particular, we're writing a client library for Apache Zookeeper, and we're going to write one that is fully asynchronous. So we're going to be using Tokyo. In particular, we'll be using the new Tokyo with the runtime as opposed to the sort of old Tokyo core stuff. So we'll be using the new Tokyo.
00:01:00.945 - 00:01:43.393, Speaker A: Tokyo still uses futures 0.1, even though futures are now in the process of being merged into rest of the language. But we'll be dealing with Tokyo because we're going to want things like timers and such, so it's just easier to do it this way. Now, Zookeeper is, as I discovered, actually really poorly documented in terms of how its protocol works. So basically the only page. Ooh, unless they posted something new, I don't think so. But basically the page you have to go on is this one, which mostly talks about sort of the high levels of the protocol and about the guarantees that the protocol gives you, but it doesn't really say, like, what the wire protocol is, which is what we want.
00:01:43.393 - 00:02:26.095, Speaker A: Normally, when you implement a protocol like this, you'll also be using Wireshark. So Wireshark is a really neat tool for. Actually, I should start Zookeeper. So normally you'd use Wireshark. You'd like watch on some interface and you look on the Zookeeper port and then normally Wireshark is smart enough. Let's see if we can Zkolli. Great.
00:02:26.095 - 00:03:04.495, Speaker A: So normally you'd use Wireshark and it will actually decode the protocol for you, and that makes it a lot easier to debug. Unfortunately, Wireshark also does not support Zookeeper yet, which is pretty unfortunate. Let's see. Set, slash, food bar. What? Can I not do that? Oh, do I have to create it first? That's annoying. Create food bar. Oh, it's on low closed Stop that.
00:03:04.495 - 00:03:59.261, Speaker A: Well, in any case, Wireshark won't actually help us all that much because it doesn't support the Zookeeper protocol. And so we're sort of left on our own, which is a little sad. Luckily, someone asked about this on Stack Overflow, like, what is the protocol? How do I understand this? And whoever this person is, Chris Nauroth posted a really good answer that sort of. It doesn't actually give you the full protocol description, but it does point you to all the places where you might want to start. In particular, Zookeeper uses something called Jute, which is a Java serialization and deserialization library, and it defines basically all the kinds of packets you can send over the wire. And so this will be a good reference for us. In addition, there are sort of Java definitions of all the classes that we might be able to use.
00:03:59.261 - 00:04:36.309, Speaker A: There's a file that has various constants that might come in handy. There's also in the Zookeeper code, so notice that I'm in Apache Zookeeper, the source code now. And the server has this method called Process packet, which sort of tells us at a very high level what does a request look like. And then we could dig from here into how it's actually parsed. In particular, we can see things like at first deserializes a header before it starts to switch on the type of the packet. So this is going to be useful for later. The other thing that is useful when implementing protocol is that we'll be using.
00:04:36.309 - 00:05:21.837, Speaker A: So there's a Rust Zookeeper crate already which is synchronous and that of course has the entire protocol implemented. So here there's a source proto which has a lot of these constants and the classes and basic process protocol and serialization stuff. I think IO is the thing that has. Yeah. So like how do you connect to Zookeeper? And so we'll be using this a lot, sort of digging through the existing code to try to build ours up. The other thing I found was that someone actually proposed a way to add Zookeeper support to Wireshark and have written a full disassembler for the Zookeeper protocol. So that's this one here, it's by ati.
00:05:21.837 - 00:05:55.925, Speaker A: Oh, this is called ati. That's why I was going to say it's weird for ATI to provide this, but this basically goes through. How do you parse an entire Zookeeper packet and determine what it is for and how do you set interesting metrics like Wireshark will normally give you? It hasn't been merged, it's also in Lua, I think, and not in C, so you can't directly be merged, but it might also help us. So I think we're basically going to get to it. Let's see just whether this has a. No, they haven't done our protocol. Okay.
00:05:55.925 - 00:06:47.735, Speaker A: If you have questions while we go like this will be fairly technical and we'll do a lot of sort of digging into protocol specifics. If you have questions, feel free to ask them on Twitch. And then I will try to answer whenever I can. I'll try to glance over every now and again and yeah, this is going to be like pretty low level stuff, but hopefully it'll be interesting. So we will start with here cargo New Lib and we're going to call it Tokyo Zookeeper because that's what it is at sort of a high level. Whenever you start a new crate, usually the thing that's good to start out with is, wow, that's not even at all. How that's built is to start with some core structures going to be the way that people interact with our library.
00:06:47.735 - 00:07:06.335, Speaker A: In this case it's going to be a Zookeeper thing. Right. And the Zookeeper thing you can use to issue additional commands and wait for responses and those kind of things. So we're definitely going to have the struct. It's not entirely clear what's going to be in there yet. There'll probably be something like a TCP connection. We'll find out that later.
00:07:06.335 - 00:07:41.111, Speaker A: And then on Zookeeper we're gonna have a bunch of methods. In particular, we're gonna have a connect method that's gonna give us a. What's a good question? Probably an ioresult. Actually it's gonna be a failure error. We're gonna use the failure crate, which is great result self and a failure error. So this lets us. Failure is a pretty neat crate that lets you do context wrapping for errors so you can propagate errors up, including what caused an error.
00:07:41.111 - 00:08:24.921, Speaker A: So you can have complex errors or chained errors with explanations and those kind of things. So we have a Connect method and just because we're building a protocol, the first thing we'll want to be able to do is to connect to Zookeeper. I have no idea how hard is it to be. I haven't interacted with Zookeeper before at an implementation level. But I think what we want is we're going to have something like, we're going to do something like, oh, actually this is going to be a connect future. So because we're in future Land remember that nothing is synchronous. And so in general, if you want to connect to something, that is also itself going to be asynchronous.
00:08:24.921 - 00:09:19.185, Speaker A: So in fact this might just return a connect future entirely. And so how we're going to test this sort of. The very first test we'll want to pass is we'll make a zookeeper and then we're going to need here futures 0.1 and Tokyo 0.1. We're going to need Stern crate futures, create Tokyo and then we're going to use Tokyo Prelude. So the Tokyo Prelude includes lots of different traits that are useful things like stream, sync, future. It again has most of the things you'll want that are not implementation details, but are for how to use Tokyo.
00:09:19.185 - 00:09:39.105, Speaker A: And so our test is basically just going to be connect and then disconnect. That's all we need to do. We want to be able to do that without there being an error. And so in this case we will just do Tokyo. Here we'll use Super. So we'll use everything from above. We're just going to use Tokyo Run.
00:09:39.105 - 00:10:10.081, Speaker A: Now, Tokyo Run is a little bit weird in that it. Tokyo Run doesn't really do much. Tokyo Run just. Sorry, it's very warm. Tokyo Run just spins up a runtime. So this is a Tokyo runtime. This is sort of a thread pool that executes futures, it spins up a bunch of timers, those kind of things, and then it runs the future that it's given to completion and then it returns and then it terminates the the runtime.
00:10:10.081 - 00:10:35.673, Speaker A: And that's basically what we want here. We could be more efficient by having to use the current thread and whatnot. But let's do this in the most straightforward way. There's going to be enough complexity anyway, so all we want to do is we want to be able to resolve the connect future. And so the question of course then is what is this connect future going to look like? Well, we're going to have to take some kind of address which is for now going to be just a string. Got it. Just in time.
00:10:35.673 - 00:11:15.505, Speaker A: Indeed. We. We have only just started. So this connect future is actually going to be pretty straightforward. Ooh, actually here we could do depending a little bit on how fancy we want to be. So we could here also use impul future and say that we return something where the item is self and where the error is fail, failure, failure. I don't remember what the current version of failure is.
00:11:15.505 - 00:11:31.905, Speaker A: It is 0.1 as well. Great. Failure. Yeah. So we could just use simple future here. Instead, let's do that just for now.
00:11:31.905 - 00:12:20.485, Speaker A: It might not actually work in the end because we might want to do more things in the connect future. But for now let's stick with this and see where that takes us. So for connect, the first thing we're going to have to do is we're going to have to connect to Zookeeper. So we'll use where's my docstokio? So for Tokyo we want nettcp TCP stream. TCP stream and we're going to connect to. Does it actually have to be a socket adder? That's a little sad. Fine, like so.
00:12:20.485 - 00:12:53.025, Speaker A: And once we have connected, I guess actually so this returns a result. And what we want here is we want to add context for basically all of these. We want to add a failure context. I'm going to skip over some of the context adding for now, just because we want to get to the protocol stuff. But here you could do something like this and say fail to connect to Zookeeper. I don't think that will actually currently work. So we will just ignore it.
00:12:53.025 - 00:14:00.009, Speaker A: So instead what we're going to say is after we've connected, that gives us a stream and that stream we're going to do a self handshake on stream. This means that there's going to be a handshake method which takes the stream that we have. So this is a Tokyo Net TCP stream and it's going to return an info future where the item itself and the error is failure error. So the idea here is that we connect and then we have to do some other business. Like we basically have to tell tell Zookeeper that we connected. And this is because Zookeeper might require a password or might require some configuration changes, but in general you usually have to do some kind of handshake when you negotiate with a new server. And that's what we're going to do here.
00:14:00.009 - 00:14:28.925, Speaker A: This is also of course asynchronous. Now this is where it starts getting interesting. So the connect message, let's see. So if we look at Rust Zookeeper, we look@sourceio so when you make an I O, it creates a bunch of stuff and then it sends a connect request. And a connect request is just a connect request. And notice this to len prefix buff. So we're going to see this a bunch.
00:14:28.925 - 00:15:29.601, Speaker A: If we look at the LUA file as well, the Wireshark dissector, it basically first looks at the first four bytes as a number and consider that the length of the payload. There are some exceptions to that, but then after that it then reads an XID from the next four bytes and then it adds an OP code which is the next four bytes. So basically I think this is in the stack overflow. If you get something like this, that's going to be a header that tells you how long is the following data. Which connection is this? And then which operation are you executing? In our case, if you look at connect request from. Did I have this open here somewhere? I think I used to, but source proto. So connection request contains all these fields and my guess is if we look at the jute file as well.
00:15:29.601 - 00:17:09.445, Speaker A: Yeah, connection request here just contains these things and is prefixed by this request header. So that's the other two fields that we saw. And so what we're really going to want here, this is a trick you often end up doing in protocols, is we're going to want some kind of a wrapper around a stream where we can write things and have them be automatically packaged and we can read things and have them be automatically packaged into the appropriate serialization protocol. So we'll probably add a mod proto and then this is going to do something like request is proto connection and it'll have some fields and then it will do something like it's going to wrap the entire stream that we have in one of these packetizers in a sense, so that we can write request things and it will serialize them correctly, including the headers. And then we'll be able to read back and we read back deserialized results that where the headers have been unwrapped. And so we'll do something like stream is going to be proto wrap stream and then we're going to do say like stream dot send the request. This is still just sort of pseudocode like remember we haven't written like proto connection, proto wrap or send at all.
00:17:09.445 - 00:18:04.801, Speaker A: We're just sort of setting up the infrastructure that we're going to use to communicate with the server because we want abstraction here instead of writing the serialization code over and over and over again manually. And so we're gonna send a request and then that's gonna. Yeah, that's a good question. What's the stream gonna give us back when we send something? It will probably give us the stream back actually. Yeah, we'll have to figure out exactly how that's gonna work. But then we're gonna do a stream dot receive and then that's going to give us back a response and a stream and hopefully from that we'll be able to construct A zookeeper. Right.
00:18:04.801 - 00:18:55.329, Speaker A: So the idea is we send a connection request to the server, eventually we get a response back and with that response that we get back, we can finally construct the zookeeper client state. And that will of course include the stream that we're dealing with. But also potentially with this, we might also need the state the server gives us back with the handshake. And so at this point, this is indeed a future that will return self and can error with a failure error. Ok, so the question is, what's going to be in proto? So at some sort of high level, the thing that's really going to be here is there's going to be a struct that's going to be a packetizer, if you will. I don't know what's going to be in it yet. And there's going to be a function wrap, which takes a Tokyo.
00:18:55.329 - 00:19:54.707, Speaker A: NET TCP stream which lets you both read and write and returns you a packetizer. Packetizer. And I guess technically, if we want it to be really good here, this would be over S. This would take an S, where S is Tokyo Prelude, where S is both Async read and async write. So the idea is that we can wrap anything where we can send requests and read them back. The reason we don't want to hardcode this to TCPstream is mostly for testing, but you could also imagine that you wanted to run this over some other kind of reliable protocol. I don't know if Zookeeper supports UNIX sockets, for example, but there's nothing inherently stopping us from supporting that.
00:19:54.707 - 00:20:33.831, Speaker A: And so we should make this generic over only the trait bounds that we need. So this will probably be fairly simple. It'll probably just be something like this. And then so that means this will hold a stream that's an S. But the more important thing is we're probably going to implement sync for packetizer. So sync is sort of a future concept of something you can stuff things into. So think of it as the sending end of a channel with implement sync.
00:20:33.831 - 00:21:03.945, Speaker A: So it's a sync where you can put values and they go somewhere where S is async. Right. So remember that for sending things to zookeeper, we don't actually need to read from the channel, least in theory. I don't know, the protocol could be different. We're about to find out. Right. So let's look at what the requirements for sync is.
00:21:03.945 - 00:21:41.793, Speaker A: What's the Prelude sync? So in order to implement sync, we need the following methods. So we will implement them. So a sync item is the Kind of things you can send on a sync and that's going to be zookeeper request and sync error is going to be just failure error because everything is going to be failures. Probably. Actually that's a good question. It might not be that we want this to be the case, it might be that we want to support protocol level errors as well. But that will probably be on the receive side.
00:21:41.793 - 00:22:23.307, Speaker A: Like you send a request and the thing you get back is a say that you tried to remove a key that wasn't there. We probably want to return a special kind of error that you can match on. Whereas failure error sort of masks the underlying error when you send though when you send the request, the type of error that you got is probably not important. What matters is in the response you got back. There might be some server defined error type that we want to expose. So the sync trait has two main methods, startsend and Poll complete. So startsend, the documentation has a bit more on them, but essentially the idea is that startsend just wraps the thing.
00:22:23.307 - 00:23:08.715, Speaker A: You get it so that it's ready to be sent, but it never does any blocking work. Poll complete is the thing that will actually drive the sending forward. And the rule is that for any given item you want to send, you should call StartSend until it gives you ready and then you call poll complete until that gives you ready. And that's the point at which you know it's been sent. Just waiting for Start send is not sufficient. So in our case, for example, Start send will probably do the serialization, but Poll complete is going to be the thing that does actually sends on the wire. And the reason for this is serializing is something we're going to have to do regardless.
00:23:08.715 - 00:23:41.841, Speaker A: And we sort of only want to do it once. Whereas Pull complete has to try sending on the TCP stream or whatever stream we have. And that might just like block. It might be the channel is full, in which case Pull complete would have to block. Whereas startsend we don't really want to have to block. So we're going to have this enum zookeeper request, right request. And the only thing we know for sure is that that's going to have a connection request.
00:23:41.841 - 00:24:34.807, Speaker A: It's gonna have one of these guys, and I trust the author of the original Zookeeper crate to have written this correctly. So there's gonna be one of those. Now here's the question. One of the things that often bites you in Async land is that you need to be able to have something only half complete. Like imagine that you're in this case, we're sending a request and you could imagine that the TCP socket that we're using only has room for, I don't know, half as many bytes as what you're trying to send at that point, the next time poll complete is called, you need to send only the remaining bytes. You don't get to send the first bytes again. There are many ways to deal with this.
00:24:34.807 - 00:25:24.775, Speaker A: The way we're going to deal with this is that we're going to have an outgoing buffer and an incoming buffer. And so when we serialize, we're just going to serialize and append all those bytes in one go and then pull complete is just going to try to flush that buffer. This will make sense pretty soon. So there's going to be an outbox, which is going to be a VECU 8 and there's going to be an inbox, it's going to be a VEC8. So the outbox is bytes we have not yet sent and the inbox is going to be bytes we have not yet deserialized. So in start send, what we're going to do is we're going to do something like. That's a good question.
00:25:24.775 - 00:25:54.871, Speaker A: We're basically, we're going to push a bunch of bytes. So we're going to serialize the request. Let's do this the slow way first. So we're going to take the item and let's say that we're going to require that zookeeper requests can be can be serialized in some meaningful way. So in this case we will do item dot serialize. Right. This is not going to be the final API because this might be fairly inefficient.
00:25:54.871 - 00:26:36.083, Speaker A: But let's go with this for now and then we're going to have to do something like. Oh, actually, ooh, that's a good question. So remember how in the protocol, where's the protocol here? So we have to send this request header as well. And the request header has a connection ID and a type. The type is basically the request that you sent. What type of request is it so that the receiver knows what to deserialize it as. In our case, we sort of want to add that automatically.
00:26:36.083 - 00:27:30.083, Speaker A: So my guess is the serialized method that we add on sukeeper request is also going to produce both the type and the bytes following it. Whereas the connection ID is only really known by the packetizer, by the stream. It's tied to the stream and the length as well. We don't really want serialized to have to deal with. We sort of want to be able to serialize all the data and then count the length and add it at the end. So this is going to be payload, it's going to be type and payload, right? And then xid is going to be some way to get the current xid. The length is going to be the length of type and payload plus however long the XID is.
00:27:30.083 - 00:28:25.055, Speaker A: In this case we know it's four bytes. And then we're going to do self outbox extend or I guess push. Okay, I'm going to write this in pseudocode first and then we can discuss after. So the idea is something roughly like this, right, where we first serialize the request itself, then we get the stuff that has to go at the beginning and then we push all of that to the outbox and then we return. Ok, so notice in this case, first of all, there's basically no way in which this can fail. It basically just pushes into a buffer and does nothing more and then pull complete. It actually turns out to be really straightforward too.
00:28:25.055 - 00:29:34.119, Speaker A: All it's really going to have to do is push stuff from the outbox that we have not yet pushed into the TCP stream. So we're going to have to keep track of prefix of outbox that has been sent, which is going to be out I or I guess out prefix of inbox. So the reason this is useful is that imagine that we have a buffer of 100 bytes and we want to send that to the underlying TCP stream. It comes back to us and says that it sent the first 50 bytes. Now what we could do, of course, is just remove the first 50 bytes from the buffer and just keep the last 50. But this is really inefficient because now the now we have to copy all the last 50 bytes to the beginning of the list of the vector instead. What we sort of want to do is just keep track of the fact that the first 50 have been sent and that the last 50 still need to be sent.
00:29:34.119 - 00:30:14.015, Speaker A: And then it's only whenever we've actually sent everything that's in the buffer, then we can clear everything. So this saves us a bunch of copies. It makes the code a little bit less nice, but I think it'll be fine. In this case, most of what we're doing is we're going to do self stream write and we're going to write self outbox self outspoken start dot dot. Right. And then we're going to use the try. Actually, it's a good question.
00:30:14.015 - 00:30:40.985, Speaker A: Yeah, I think there's a try. Ready? It should work with this. So N is going to be. So what Try Ready does is it's the macro often used in Futures land. The Try Ready macro will try to call this method. So it expects that the method is calling is something that returns something like this. So a result async with an error.
00:30:40.985 - 00:31:28.281, Speaker A: And if it gets async not ready or if it gets an error, then it returns, otherwise it gives you the value. So you can think of this as sort of as try or the question mark operator just for futures. And so N here is going to be the number of bytes that we wrote. And so in our case, what we want to do is solve out start plus equals n. And then if we've now written everything that was in the outbox, then we can clear the outbox and start from the beginning. So this means that the outbox actually could keep growing unboundedly if we get really unlucky with our TCP sense. But it doesn't mean that we have to do way fewer MEM copies.
00:31:28.281 - 00:32:15.505, Speaker A: So I think on the whole this is fine at the end, if it successfully wrote out everything that's in the stream, then we can return ok, Async ready. So this is saying that actually only if this is the case, otherwise we still have more stuff that needs to be written. So the idea here is that we try to write as many bytes as we can. We get told how many bytes were written. Yeah, thanks. I caught it without seeing it. Didn't cheat.
00:32:15.505 - 00:32:50.285, Speaker A: Good that you're watching me though. Yeah. So the idea is that if the stuff that's been written out is everything that we needed to write, then we're done. We can say that we've successfully pulled for completion. Otherwise there's still more bytes that have to be written. And so that's what we return. Of course, this code and start setting does not currently work and probably won't work for a little while in particular because we're going to need this zookeeper request, the serialize method.
00:32:50.285 - 00:33:34.587, Speaker A: So one question is, what is serialized going to even do? I think if we want to make this decently efficient. So remember, currently what this is going to do is say that serialize returned a vector, right? So let's imagine for a second that it's something like this. So imagine it was like this then. Now we're going to allocate a vector, we're going to return it here for type and payload, and then when we append it to the outbox, we're basically going to extend the outbox and then copy all the bytes. Now that's not a problem for a connect request, for example, that is pretty small. But in Zookeeper you can set and read relatively large values if you wanted to. And so we don't really want to copy all those bytes.
00:33:34.587 - 00:34:21.831, Speaker A: So what we're going to do instead is serialize into. We're going to take a. Let's just do this the ugly way for now. So what this is going to do is instead of returning a new vector, it's going to just extend the underlying vector. Now, we have to be a little bit careful here because remember, there also has to be room for X ID and length, and those have to come before the type and payload. And so what we're going to do here is we're going to do a little trick where we push a dummy value for xid and length. Actually, X ID we can probably get regardless, but for the length we'll just push push zeros and then we'll change them after we know how long it is.
00:34:21.831 - 00:34:56.269, Speaker A: So that way we never have to do this extra allocation and memory copy. So serialize into is unimplemented for now. The idea is that it's going to serialize all the bytes in the current request. It's probably just going to match on self. It's going to write out the fields in the appropriate order with the appropriate type into the buffer and it's going to return how many bytes it. It's going to be fairly straightforward. Could even be that we just want to implement serialize here.
00:34:56.269 - 00:35:25.376, Speaker A: But let's. We'll do it simple. So this means that now we're going to have some way to get the XID of a packetizer. My guess is that this has to just be stored in here. What is an xid? An int? What is an INT in Java? So let's see. Connect request is an int for protocol version and the Zookeeper Rust implementer chose that as an i32. So int is an i32.
00:35:25.376 - 00:36:11.891, Speaker A: So xid is going to be an i32 like so I wonder whether you can have multiple connections open. This connection ID makes me think that you can multiplex connections onto a single stream, which we might want to support later. But for now let's just ignore that. We'll probably want a way to set the XID of a packetizer. We'll probably also want a like a new for packetizer because we don't actually like the outbox, outstart inbox and in start we don't want to have to deal with. So this is going to be a pub crate. So you can only call it from within the same crate because we don't want users to create packetizers.
00:36:11.891 - 00:37:06.975, Speaker A: In fact, packetizer is not even going to be public. It will have to be available within the crate though, because we're going to use it from Source lib, for example. So new is going to take a stream, it's going to give you a packetizer S In theory, this could give you like an uninitialized packetizer. So we could have a separate type for when it has not yet been connected. But I don't think there's a good reason for us to do that, at least not for the time being. So a new packetizer is going to have that stream, it's going to have outbox be empty, it's going to have outstart be zero and and same for inbox and xid is initially going to be zero probably. Thanks.
00:37:06.975 - 00:37:45.101, Speaker A: So that gives you a packetizer. In fact, let's just have that be instead of this wrap function. Zookeeper request is also going to be public for the crate. Serialize into is not. So what we're going to do here is we're going to need a way to serialize and deserialize numbers into byte strings because we have say an i32 and we need to write the appropriate bytes onto the wire for this. One of the nice things to use is the byte order crate. So this does all sorts of endianness and whatnot.
00:37:45.101 - 00:39:03.211, Speaker A: So we go over here, say byte order is what version 1.2 we need extern create byteorder and I think this gives us a write bytext which is really convenient for these kind of things. Ah yes. So writebytes X basically gives us a. I guess we'll need stand no, it basically gives us the ability to take anything that implements write the write trait and call like write I32 write so we can write a value and have it be directly written and vecuates implement write directly and that just causes the vector to be extended, which is basically exactly what we want. So in our case, what this means is that here we can do self outbox dot write i32 and that's going to be the length. So actually let's check what that length is.
00:39:03.211 - 00:40:11.509, Speaker A: What type that length it doesn't really help. Where is a request header that's just xid My guess is an i32 but I figured I'd. No, that's just what it writes out big endian Great. So yeah, you see the other Zookeeper crate for Rust also uses byteorder because it's really convenient for this. And this is why this file is going to be a really nice reference for us. And this saves us a lot of work that we would have to reverse engineer from the Java implementation otherwise, notice that we have to tell it what endianness it is. So remember from your computer science background or, or not, when you have a number that's multiple bytes, whether you print out the highest value byte or the lowest value byte first differs between different computer architectures and between different network protocols.
00:40:11.509 - 00:40:56.925, Speaker A: And so in this case, what we're saying here is that the network protocol for Zookeeper is big Endian, so the big bytes come first. And so we have to tell when we write out this i32 onto the wire, we want to write it in that order. So we're going to use here this and Bigendian. So we're going to write i32 Bigendian. And remember that we don't know the length yet. So here we'll just write zero. And because this is a vector, we know that it will not error should never fail because this will just allocate a larger vector if need be.
00:40:56.925 - 00:42:00.485, Speaker A: Right? And then we will write out the xid, which is going to be the same self xid and then we will do item serialize into and we're going to give it a. We're going to give it the outbox. And this also should not ever fail. So this is going to give us the N, which is how many bytes it wrote. And here we now have to be a little bit tricky because here, remember how we wrote out a length of zero above there? We're going to have to overwrite that zero with the true value. This is a little bit more finicky, but basically what we're going to do is we're going to keep track of where like we can basically go N4 backwards in outbox. So this is going to be, uh, self outbox.
00:42:00.485 - 00:43:11.025, Speaker A: Um, length I is going to be self outbox len. And so from length I to length I +4, right? So that range is where the length is stored in the outbox. And then we just want to write, we want to do this right again. So in fact here we could, if we wanted to just like push four empty bytes. Maybe that's what we should do, just push 0 dummy length xid type and payload set true length. And then the question is, I think we can now just do length, right? I think mutable slices also implement. Right? But I'm not entirely sure.
00:43:11.025 - 00:43:57.925, Speaker A: No implement right for. Yep, it looks like it. How is that implemented? Right, so this will return. It would return an error if you tried to. If you tried to write. Well, if you try to write more than how long the slices it it would only write as long as the slice was and then tell you it only wrote that many bytes. In this case, we know that the slices of linked 4th so this should be all fine.
00:43:57.925 - 00:44:26.495, Speaker A: And so now we've basically eliminated that one copy that we would have had otherwise. And so that's pretty nice. We still of course are missing what serialize into is going to do. I think we might as well just write this straight away because we. We know we're gonna need it. Another question here is whether we'll even need. Whether serialize into should take self by like own self.
00:44:26.495 - 00:44:53.105, Speaker A: It could very well be because you can imagine some of these holding lots of bytes. Actually here's what we're gonna do. Well, unclear. Let's just leave it like this for now. So this is going to. Now we don't. We only have one request type and that is connect request.
00:44:53.105 - 00:45:51.257, Speaker A: Actually this does not need to be called connect. This does not need to be called requests, does not need to be called zookeeper. Keep it easy. So we're going to have a request request connect and if we get a request connect of it's a little annoying. We have to repeat these. See, this is one of the things that's a little bit annoying about Rust enums is when you have an enum that contains a struct, you can't in the code below, assume that it is that variant and start using like dot fields. If you hit the expect with should never fail, will it be easy to see something like enome? So if you run out of memory, there's actually no, you don't get an error from vectors if you run out of memory.
00:45:51.257 - 00:46:33.345, Speaker A: This is one of the things that people have been a little bit sad about with Rust is that it's not easy to detect whether you run out of memory. Like if. If you have a vector, if you call push, it doesn't have anything in the type to indicate that push can fail. Or rather you don't have a way of checking if push failed because you're out of memory, then the thread will just panic. This is why here as well, we know that the write to the vector will never fail, never return an error. It could panic if you run out of memory. But so if you get enum, what you'll see is a thread Panic.
00:46:33.345 - 00:47:46.915, Speaker A: Okay, so we actually need to deconstruct this here, which is a little bit sad, but I think we'll have to live with it. This has to be a reference. And so the question of course then is how do we serialize a request connect? Well, I mean that's pretty straightforward. We have to write an i32 which is going to be the request type. So this is when we need all these defs Pub enum opcode. This is going to be. Actually this is not going to be pub and this is going to be repr i32 it's going to be notification is 0 create this one.
00:47:46.915 - 00:49:09.055, Speaker A: Actually, let's do this. Actually, let's do QA D3W. What's the Vim shortcut for uppercasing a character? I can't actually remember. That's too bad. Oh no. Why is it complaining at me? Dev Miner Tokyo Zookeeper so the idea is that this opcode, because we define it as having the representation i32 in theory it should just interact nicely with with what we get from the wire. But it's complaining because this is now just request.
00:49:09.055 - 00:49:56.395, Speaker A: Oh, I didn't finish writing this opcode. Oh, is there not an opcode for connect? That seems weird. Where's our connect request? Right? Oh, I see. So connect does not send an opcode. Yeah, it probably then also does not send an X id. Okay, so we do have to handle connection requests separately. I guess we'll deal with that later then.
00:49:56.395 - 00:51:03.905, Speaker A: 120 try ready is not in scope these or various unrelated errors. All right, that's all fine. Wait, am I mistaken? Is try already actually in Tokyo? All right. Yeah. So we now have this opcode enum that contains all the all the different opcodes we need. What this sort of suggests to me is that when you create a new packetizer, I think it's going to have to immediately place there the connection request. Actually, it's a little awkward.
00:51:03.905 - 00:52:12.535, Speaker A: I guess we can actually work around this by if let request connect this item I want. If not let. But apparently I don't get to do that. Yeah, because we're also going to have to know that we shouldn't set the true length. Fine, fine, fine, fine. It's a little ugly, but it's how it's gonna have to be. The dummy length as well should only happen here.
00:52:12.535 - 00:52:53.455, Speaker A: The observation is that if you, when you initially connect, you don't send length and you don't send. And you don't send the X id, you basically don't send a request header, because it's not a request, it's the first connection. So if you see here, this is in the Rust Zookeeper crate. So he has a connect request and he implements Write to the Write to traits is the thing that Write to where you at? Yeah, so the write to trait. He rewinds it. That's how he does it. Oh, it's not terribly important.
00:52:53.455 - 00:53:30.465, Speaker A: Where's the. Oh, maybe it does have a request. It's a good question. Let's see. So where's the thing that does connect and connect request? Oh, no, there is an opcode. Okay, great. It's using auth.
00:53:30.465 - 00:54:10.769, Speaker A: So this can all go away. And this is going to write AUTHCODE authentication. Does that return anything for us? No. So we're going to have to keep track of the length. Initially we write 0 here, we've written 4 bytes as we can go back to this. So the RAW request here I think is just the way that he or she. I don't know who the author is, but if we look for here for RAW request.
00:54:10.769 - 00:54:52.115, Speaker A: No, let's see here. Source lib. No, Suite keeper Raw request. Okay. And how is this used? Well, that's unhelpful. Oh, ah, inflight and buffer. Okay, where is the thing that sends things.
00:54:52.115 - 00:56:06.561, Speaker A: Ready channel ready, timer, sender, self TX send. Okay, so they send RAW requests on a channel. So it looks like they have some kind of thread that's running in the background that does the buffer pushback connect request. Okay, so where is this buffer? So from Source lib, what do they do when you create a new zookeeper Zookeeper ZK thread? Okay, that's presumably the thread that they spin up. So connect creates a zkio and it has a watch thread and it's the watch that's the sender. So I think that's the thing that actually sends requests out onto the wire. And so, yeah, that looks like it.
00:56:06.561 - 00:57:07.455, Speaker A: So what does it do when it gets a new RAW request? Nothing. That doesn't seem very likely. So where is this Try write buff. So it really just calls connect request, pushes the request onto the buffer. This takes the request off the buffer. This writes the request's data. Wait, that doesn't seem right.
00:57:07.455 - 00:57:44.755, Speaker A: Where does it add the wrapping? I think it's this Try write buff. That would be my guess. Aha. So it first writes. Okay, that's unhelpful. Huh? So where does he write the length, though? So they create a channel KEYX and rx. They buffer up the RAW request, which is the connection.
00:57:44.755 - 00:59:00.985, Speaker A: And now the question Is where does that disappear to? So in source zookeeper, when you create a new one, they create a zkio, they get an iosender. I will run zookeeper zk thread IO.run. so what is a sender on IO? OK, okay, so that just sends IO things request header. Okay, so when you make a request, you make a request header to len prefix buff, request header and request. Oh, I wonder whether the data is actually the whole thing. That's why. Okay, so this business.
00:59:00.985 - 01:00:01.937, Speaker A: Yeah, so this is where they pull the same trick we do of allocating a vector, moving forward, then writing out the buffer and then moving back and then writing the length. But this to me suggests that. So if you look at the code that we had here, where was it here? Yeah. I think this connect request does not actually have an X id. I think the opcode here, the buff, is just the length in the connect request and then there's an opcode on the raw request. But that's not actually something that's sent, which is a little confusing. But.
01:00:01.937 - 01:00:32.285, Speaker A: All right, so I think what we're going to do here is, is I'm just gonna do. We're gonna treat connection separately. So connection we do something. And for the rest, we do all this business specifically for the, for the connect. All we really need to do. Oh, actually we do have a length regular. That's interesting.
01:00:32.285 - 01:01:37.825, Speaker A: So here we're just going to serialize the item, otherwise we're going to write out the xid and serial IC item. So this is really just saying n 0. Otherwise 4, let n is n plus this like so. And this has to write out N. So what we're doing here is we're always going to have to add the length and then if it's a connection, if it's a connect, then we don't add anything more like specifically we don't add a request header. Otherwise we do add the xid. So that adds four bytes and then we call serialize into.
01:01:37.825 - 01:02:28.901, Speaker A: And our serialize into for connect is just not going to write the opcode. And so that's how we end up not having a request buffer at all, a request header at all. It will just write the actual connection request. Whereas if we had, say, request, create or something, that would indeed write out the opcode as well and that would add another four bytes, making up the full request. All right, so the question then is what do we have to write out for connect requests? So here we can actually reuse code. We don't want to reinvent the wheel. So in this case, notice how because this person is writing directly into a writer, they have to try everything.
01:02:28.901 - 01:03:03.515, Speaker A: Whereas for us we don't actually have to do that. We know that this will always succeed. We can do this in this case. Protocol version Last XID scene timeout Session ID the password is a little interesting because the password, let's see. So that's a vecuate. So the question is, how are vecuates serialized? Again, we turn back to what this person is doing. So write two is the way that they write requests out.
01:03:03.515 - 01:04:03.855, Speaker A: And so the question of course becomes how is write 2 implemented for VECT? It is you write out the number of elements as an i32 and then you write each of the elements for a U8. That's just writing the U8. So in our case we will just do, we'll write an i32 which is going to be the password length, which is Len as i32 and then we will simply write all. So that's going to be using iowrite. So we're going to then also write out the entire password. And again, none of these should fail. One way we could do this in a sort of neat way is we can use this.
01:04:03.855 - 01:04:44.453, Speaker A: It's a little ugly. I don't really want to have to do that actually. Let's have this. Just return a result view size with a like an IO error. So the reason I want to do that is just because it makes this method easier to write because I don't have to unwrap everywhere. I can just have the question marks and then I can unwrap where we call serialize into. So in this case we write out these, it's all good.
01:04:44.453 - 01:05:50.535, Speaker A: And then we return and this is going to be then 4 for the protocol version. Plus actually we don't even have to really return the usize because we have this thing called magic. Watch this. So we can actually figure out what the length is specifically. That means we don't need this, don't need this, don't need this, don't even need any of this. It should never fail. And the N we have to write is written is self outbox len minus length.
01:05:50.535 - 01:06:53.125, Speaker A: So that's how long is the outbox now how long was it before we wrote the length minus the four bytes for the length? So that's how much we wrote out and that is indeed the length of the payload. That way we don't have to track this manually either, which is nice. These are all going to be buffer, right? So that writes out the connect and then of Course we need to have some way to pull out responses from this. And the way we're going to do that is we are going to take. So we're gonna. We have Sync for sending requests and we have Stream for getting the responses back. Packetizer S, where S implements Async read Now Tokyo Stream, sort of the inverse of sync has a very similar signature as well.
01:06:53.125 - 01:07:32.885, Speaker A: So there's an item and this is the streamite. So that's going to be a response error is still going to be a failure error. Although keep in mind, this is where we may want to provide more introspection. Like if the server returns us an error saying this node already exists or something, that's a message we might want to propagate to the user because they might want to do something with that particular error that happened. All right, let's see. So Stream as opposed to sync does not have two separate methods. It just has.
01:07:32.885 - 01:08:18.725, Speaker A: It just has Poll and poll should return. Async should return an error. If there's an error, it returns async not ready. If it does not yet have an item to release, it returns ready none. If the stream is completed and no more items will be yielded and it returns ok, Async ready sum and then an item, if an item is to be yielded. So here we have sort of a very similar problem to what we had for Sink, namely that we might do a read and only get an incomplete item, right? In which case we have to yield none. But we have to remember the bytes that we read because if we do another read, we're not going to get them back yet if we read again.
01:08:18.725 - 01:08:44.185, Speaker A: And so we're going to pull a fairly similar trick. So this is why we have the inbox on packetizer. It's basically going to do the same thing. I think we don't even need this in start. Let's leave it for now. So what Poll is going to do is it's first going to check whether it has a full item. So it's going to parse out the length.
01:08:44.185 - 01:09:08.219, Speaker A: What's the first minutes of the stream? Do you mind explaining what Zookeeper does? Oh, that's a good point. I don't think I even did this. So Zookeeper is a. You can think of it sort of as a key value store. So its API is fairly straightforward. You can create keys and keys are paths, so they're slash separated and hierarchical. And you can set any binary string as value for any key.
01:09:08.219 - 01:09:49.985, Speaker A: But it provides atomic guarantees such as if I set a value, I know that Everyone else will see that value. It provides things like compare and swap, sort of. So you can write a value only if its value is this value and has not changed. So this is one way you can use it to maintain a configuration or a cache. It's sort of like a very highly concentrated, consistent key value store. Now, in a sense, the API for Zookeeper has not really become important yet. So all we're trying to do now in the very beginning is be able to connect to Zookeeper at all and set up the internal infrastructure we're going to need in order to send and receive requests.
01:09:49.985 - 01:10:28.045, Speaker A: But down the line, of course, the API for Zookeeper will become important when we start designing the API for the library. I hope that roughly makes sense. So Zookeeper, you should just think of it as a very powerful key value store. It's not very fast, but that is because it is so highly consistent and gives these very strong operations you can't often do in other stores. You can also run it very fault tolerant. You can run it on many machines and if one machine goes down, the system still operates. And you're guaranteed to always have the same guarantees.
01:10:28.045 - 01:11:24.915, Speaker A: Sort of like Redis on steroids. Although you should think of it as it doesn't try to provide data storage. It is usually used more for a configuration where you have a large deployment of servers and they all need to agree on like who the primary server is, for example, or on the current configuration, or on where different files are located. Use Zookeeper for that kind of meta information to ensure that all the servers sees the same information and that even if there are faults, like some machine fails, you still have guarantees about. You still have guarantees about what servers see and what operations succeed and fail. Yes, it is indeed Apache Suki that is accurate. Ok, so our poll, what it's basically going to do is it's going to.
01:11:24.915 - 01:11:49.091, Speaker A: First it sort of has to check whether it has enough data. We don't want to do a read if we don't need to. We want to do a system call read. So imagine that you do a system call read and you get back two full requests. So you're filling up your buffer and it's now filled with two requests. If the user does one read, they get the first and that's also what filled the buffer. If they then do a read again, you already have a request in your buffer.
01:11:49.091 - 01:12:48.345, Speaker A: So you don't really want to do a new system call because that might block, although in this case it wouldn't. But you don't really want to do another system call because they're fairly expensive. You want to use the one that's already in your buffer. I'll write this code the straightforward way first and then we can iterate on it. We know that the length here we're going to need readbytes as well. We know that the length is going to be start read I32 big endian. We can use question mark here just because we know it's not going to fail and it's shorter than doing the opposite.
01:12:48.345 - 01:13:20.955, Speaker A: Yeah. So what we're going to do is we're going to look at our. Ooh. Actually, if so, sorry. The reason I'm pausing is because it might be that we don't even have enough bytes to read the length. So I think what we want to do is if self.inbox.len/self. It's called just in start or inbox.
01:13:20.955 - 01:14:35.985, Speaker A: Start in start is less than 4. So if we don't even have the length, then what we want to do is try to read from the underlying socket. We want to do. What's the prelude, Ace and greed. Oh, there's something like this for right as well, I think. But what's a buff mute? I have no idea what that is. Ooh, but it has nice.
01:14:35.985 - 01:15:05.355, Speaker A: Sorry, I got distracted. So what we want to do is we want to read from the underlying stream so that we get enough bytes to continue. So we're gonna do dog read. Can I do the same for the right. I think I just want to do right there. I think there's a recommendation to use poll write instead of write. No, that's when you implement.
01:15:05.355 - 01:16:06.709, Speaker A: Oh, we also sort of need to do flush here. Almost forgot about that. So here we now want to do self stream pole flush. So even if we've written out everything to the wire pull complete shouldn't complete until the stream has also been flushed. Which is what we're saying here for stream. What we want to do is we want to call the read method, I guess poll read and here mu self inbox self install. Now, some of you may already see what's wrong with this.
01:16:06.709 - 01:16:53.565, Speaker A: I'll just write it out and then we can talk through it. This code will not actually work, but I'll explain why in a second. But we're going to try to read some bytes and then while that is the case, if n is 0 then to do. I'll talk about why that's special later actually. If. Yeah, and self inbox. Let's do that later.
01:16:53.565 - 01:17:29.969, Speaker A: So we're going to try to read out the length. And then we are going to see whether len self.instart/4. So that's how many bytes we have available to parse. If that is less than length, then we are going to also do this. I realize this code is currently pretty messy. We're going to rewrite it a bunch. This is to get the flow ready.
01:17:29.969 - 01:18:12.035, Speaker A: So the idea is that if you don't have enough bytes, then you read more bytes. And so here, if we don't have enough bytes to read the length field, then we do reads until we can read the length field. Then if we don't have enough bytes to deserialize the object, because now we have the length, then we do another read. And then at this point we know that we must have enough bytes available. And so now we do. Now we sort of deserialize. Right? So we're going to do something like response parse.
01:18:12.035 - 01:19:03.223, Speaker A: I guess xid is going to be self inbox. So here self in start in start plus equals four because we've now read the length field and then self in. Actually we can just use this read I32. So this is reading out the xid, which we know is there. There's also the opcode, which we know is there. So at this point, plus equals 4 for the XID, plus equals for the opcode. Actually, let's not read out the OP code and then we par when then we want to call parse.
01:19:03.223 - 01:19:55.385, Speaker A: What we're going to do there is we're going to give parse self inbox from the start. So from right where the opcode starts to length minus 4 to the end of that payload. Does that roughly make sense? So the idea is we read until we know that we have enough to parse a request, and then we parse that request. That's what this piece is doing. It's extracting just the bytes that correspond to that request and trying to parse a response from that. Now, of course, this code is currently pretty messy and there are a bunch of extra cases we have to deal with. For example, if you try to read and you get zero bytes, what that means is the other side is hung up and you're not going to get any more items from it.
01:19:55.385 - 01:20:31.865, Speaker A: There's also the case that poll read will not extend the vector. So in this case our inbox is going to be pretty useless because poll read is going to try to read into the bytes that we already have, which is not at all what we wanted to do. And so this code is currently pretty Broken. But I hope you see roughly the approach that we're going to take. The way we're going to rewrite this to be a little bit simpler is we are going to. Hmm, that's a good question. Let mute need.
01:20:31.865 - 01:21:12.951, Speaker A: Need is four. So while this is less than need, then we're going to have some magic here. Magic to extend inbox. Actually, let's just write the magic straight away. So the idea is that if we find that we need more bytes, that we're going to grow inboxbytel and then we're going to call poll read. And if poll read succeeded, then we're all good. Then we try to parse.
01:21:12.951 - 01:22:18.955, Speaker A: If poll read did not succeed, then we shrink inbox again by changing its length. So here we're going to do self inbox dot spec. Where's the set len? I don't actually want setlen I want. Where's the method I want? Resize. That's one I want. So we know that the current length, so target length is going to be the current length plus. And then the question is how many bytes do we want to read at a time? Now one thing we could do is we could just say plus need.
01:22:18.955 - 01:22:57.049, Speaker A: So need here is going to be sort of a counter of how many more bytes we need. Need than what we currently have, or rather need is going to be how many bytes do we need in order to return. Ok, it's basically like how much, how much stuff do we need in order to correctly parse an element? So we could reserve just enough space for that. I think instead what we're going to do is just to amortize this cost a little. Actually. No, let's do that. This will be fine.
01:22:57.049 - 01:23:37.815, Speaker A: So our target length is that + need and so we're going to do self.inbox. resize. Now resize takes a new length and if it's shorter it will truncate. If it's larger, it will grow the vector if necessary and then some value to set the grown element to. In our case, we want to resize to targetlen and we're going to fill it with zeros. Then we are going to match on poll read from. Read from is going to be inbox length.
01:23:37.815 - 01:24:25.965, Speaker A: Right? So the idea here, the idea here is basically that we take all the bytes that we have so far and we allocate a bunch of memory at the end to make room for the more bytes that we have to read and then we try to read into that segment of memory. So resize creates that segment of Memory and then pull read tries to read into that segment of memory. If we get ok, then we get an N. Let's do ok. Zero. That's going to be special. Actually, no.
01:24:25.965 - 01:25:11.473, Speaker A: Or that with a question mark. Async read D or okay, Async not ready. So async not ready means that nothing was ready, that call would have blocked and so nothing was read. Let's check that. That actually is a guarantee that holds. Pretty sure it will. But n equals 0 implies that end of file.
01:25:11.473 - 01:25:59.021, Speaker A: Okay, so not ready specifically means that, ooh, what are they written for? Pal read if no data is available for reading. That's really vague. It doesn't explain whether you get a ready or a not ready on zero. I'm going to assume that they've done something sane. So not ready means that the underlying socket has not been closed, it's just blocking. And in that case what we'll want to do is we'll self inbox resize back to read from. Right.
01:25:59.021 - 01:26:42.577, Speaker A: Because we basically set the length back to what it was. I guess we have to get zero, but can I do truncate? Is that a thing? I think truncate is yep. So we basically we don't undo the allocation that we did, if any. We just shortened the vector so that when we go through this loop again, we'll return. And in this case we want to return async because we tried to read the more bytes we needed and we did not get them. So in that case, what that means is we're not able to yield another element yet. If we pull to read and get ready.
01:26:42.577 - 01:27:29.531, Speaker A: So some number of bytes were read then. Now what we want to do is self inbox dot truncate read from N. So this is saying that now we got n more bytes and. Yeah, okay, so so now the real length of the inbox is where we started to read, plus the N bytes that we read. And then we'll just let the while loop go again, which will show us whether or not we get to continue. Of course, here it could be that the. Let's see, the need might change here because we might read out the length.
01:27:29.531 - 01:28:20.759, Speaker A: So remember that we sort of in order to deserialize these things, we first need to read the first four bytes, which tell us how long the rest of the payload is, and then we need to read the rest of the payload. So that's why need is initially set to four, because initially we just need the length. Actually, let's do this separately, I guess. Yeah, gets a little bit unfortunate I don't really want to replicate this because. Good. So the silly way to replicate this is we then do this. So initially the need is 4, then the need is however long the length is.
01:28:20.759 - 01:29:44.606, Speaker A: So 4 plus this I guess we could do. And then we do the whole thing again. But see how this duplicates a lot of code that we don't really want to do. And so therefore what we're going to do is need is going to be if self.inbox.len minus self and start is greater than 4, then we know a length, we know how much we need, otherwise it's going to be four. So in this case it's going to be, we're going to read out the length and then it's going to be length plus four, right? So if we already have the length, then how much we're going to need to read is going to be length plus the payload size, otherwise we're going to at least need to read the length. And now here in the case where we, in the case where we truncate, in the case where we do get some number of bytes, we're going to have to check if self inbox, lan self.in
01:29:44.606 - 01:31:28.025, Speaker A: start I really want this to go away. Where's packetizer fn in len self.in box len -self insert self.in yeah, so if we, if the number of bytes that we have available to us is now greater than 4, and the need is not equal to 4, then we parse out the length and then we set need plus equals length, right? So now basically what this is saying is we're going to keep reading until we get the length, and when we get the length, we're going to increase how, how much bytes we need so that we keep reading. And so this while loop is going to continue until we do in fact have a full request available to us. And at that point we now know that need is set to length plus 4, because here, if n is equal to 0, we'll have to deal with that separately. So that's if the incoming can connection has been closed.
01:31:28.025 - 01:32:23.345, Speaker A: And now what we want to do is remove the. Well, we want to skip the length field when we start to decode, then we read the xid and then we skip the xid and then we want to parse what's left, which is basically going to be where we started plus how much we read minus the length, minus the xid, right? Because the need is from the very beginning of the buffer. So where in start was. But then we've removed the length and the xid, so we don't actually want to read those out. And that's what we're going to end up parsing. So that's going to be the response. In theory, this should have a question mark.
01:32:23.345 - 01:33:27.233, Speaker A: And then what we now need to do is self need and then we will return async ready sum. So at this point we successfully read out an element and now we can return that element. Now there's a little bit of tricky here. Like this is going to end up doing some copying, but let's just not deal with that right now. We also want if self int is equal to self inbox len, then self inbox clear and self install. This is just so that we don't end up accumulating more and more memory. Great.
01:33:27.233 - 01:34:25.085, Speaker A: So the only way in which this stream can stop yielding elements is if the connection to the server went away. And in that case what we want to return return is async ready. Okay, async ready. None. Now, in this case we might want to add some debug information, like if there were things left in the buffer and then it was an unexpected expected shutdown. So in fact, one way we can do this is if the. If there are bytes left in the buffer, then we want to return an error.
01:34:25.085 - 01:35:53.865, Speaker A: The question is, of course, what is that error going to be? In fact, we're going to just do bail. So bail is a macro from the failure crate that just produces an error, which is what we want in this case, bail with connection closed with vice left int buffer. All right, so now we have a way to distinguish between the case when the server closed, when the connection went away, when there were no more elements either, like add an element boundary and the server went away in the middle of sending a response and treating one as an error and one as the stream ending is probably what we want to do. All right, so we now have a stream that goes both ways. And so what we want the handshake to do is it is going to request is going to make a request connect. We now know that that has a bunch of fields like. So I don't know what those are going to be yet, so let's set them all to zero for the time being.
01:35:53.865 - 01:36:35.451, Speaker A: This is going to be a vec. This is going to be a packetizer new on top of the stream. And then what we're going to do is we're going to. Oh, that's a good question. If you have a sync, where's my sync docs? So remember the packetizer Implements both stream and sync. Sync is for sending things to the server, stream is for receiving things. And so in this case, when we do a handshake with the server, we've now sort of popped up a level.
01:36:35.451 - 01:37:18.255, Speaker A: So we used to be looking at the protocol implementation. Oh, actually come to think of it, we haven't written response parse either, but we used to look at the protocol version and now we're sort of stepping one step up to the Zookeeper library, trying to connect. So what it's going to do is it's going to construct a connection request, it's going to send that on the packetizer sync and then it's going to read back from the. That's going to read back the response from the server. So for the sync, what we're going to do is we're going to. Where's my. Where are the list of methods? I want send.
01:37:18.255 - 01:38:13.715, Speaker A: Yeah, so it's going to send the request and then what send gives back? So send is a future. Whose item is. Whose item is the sink? So it's in future land. Usually if you try to send on some channel, then the channel will be consumed by the send until the future resolves, which is sort of how you want things to work, right? Like imagine you have a TCP stream. If you send some bytes on it and you get a future back for when those bytes have been written. You don't want to be able to keep using the TCP stream as well, because then you would have two writers to the same stream. So instead the way Async write handles this, or at least the way the futures in general handle this, not actually for TCP sockets, but in general, is that when you try to send something, the send future consumes the sync you're sending into and then when the send completes, you get it back.
01:38:13.715 - 01:38:54.517, Speaker A: So that's why this and then is given a stream back. And now, of course, now that we send something to the server, we now want to read back. And the way we're going to do that is because we know that the Zookeeper connection, the packetizer, also implements stream. So we are going to then call. There's a lot of things on stream, but basically the thing we want is into future. Into future. So into future, if you call that on a stream, normally a stream is sort of like Iterator, so it just keeps yielding more and more elements.
01:38:54.517 - 01:39:48.965, Speaker A: In this case we only care about the next one. So what we're going to do is we're going to call into future, which is a future that Resolves to the next item and the stream whenever an item is available. So if we look at into future that implements future for StreamFuture, the item that we get back is an option item and the stream. So the response here is going to be an option response and the stream is going to be the packetizer. And so if response is none, that's bad. Otherwise this is going to return a. Actually this can just be a map.
01:39:48.965 - 01:40:50.143, Speaker A: So that's going to give back a zookeeper. That zookeeper is going to have a like a packets or a connection ZK So our zookeeper, we now know, is going to be over some S and it's going to hold internally a connection which is going to be a packetizer over that stream S. It's probably going to have some other things too. I don't know quite what yet, but at the very least, this is sort of the basic way in which we're going to set this up directly. This is now a future that will eventually resolve into a zookeeper connection instance that holds a packetizer internally. So now, of course, the last thing in theory that we need for this to all work out is that we're going to have to be able to parse the response. So this will now indeed send a connection request.
01:40:50.143 - 01:42:20.515, Speaker A: And the question is, what do we get back? So we're going to have a response and we're going to have a response type similar to the request type, and we're going to have a parse method on that. So we can probably split Proto into a request and response. So let's do. So we're going to move to Protomod and we're going to open request RS Request is going to have this and also this. I think I want the sync and stream implementation just be in Proto probably because the other things are going to get pretty large, whereas the sync and stream implementations probably won't change that much in size. So response is going to be pretty similar to request in that it will just be an enum and it'll be whatever we get back from connect. So this is just going to be a connect.
01:42:20.515 - 01:42:47.755, Speaker A: And similar to what we had for request, we're also going to have. This is just similar to what we have for request. We're going to need some kind of parse method. In our case, we could implement parse. So there's a parse trait in the standard library. I don't think I actually want to do that. I think I just want to do this for now at least.
01:42:47.755 - 01:43:50.785, Speaker A: Super. So the reason this has to be super is because we want to be able to call this method serialize into from our proto mod. If it were just fn, it would only be available from this file, which is not what we want. What do we call this? We call this parse. So parse takes a buffer, so sum U8 buffer and at least in theory gives back a response. It will probably actually be a result result response or failure error, because it could be that what we get from the server is malformed in some way, in which case we want to have a way to report that. So now the question is, how do we parse responses? Well, r stringreader bufferreader.
01:43:50.785 - 01:44:46.829, Speaker A: It's a good question. See what this does. So connect request just creates one of these. Try read buff let's try read buff do so try read buff. Well, that doesn't really help as much. Let's look at the LUA implementation. So dissect client, as far as I understand is when the client sends something, this is how it dissects it.
01:44:46.829 - 01:46:10.509, Speaker A: So notice here we recognize the length being the first bytes, the xid being the next four, and the op code being the next four. Dissect server is probably the next method we might guess. Also a length, also an XID request. Xids request time. Okay, so it looks like the response there looks like the response to a connect or the response to any request is actually dependent on the service current state state. So this makes me think that the server does not allow you to multiplex requests and responses on the same connection because it seems like there's a state of what did the client last ask for for this xid? It could of course be that different xids are multiplexed. Okay, so what this means is in theory, if we we know that we're expecting a connect response, we should just give that.
01:46:10.509 - 01:47:24.135, Speaker A: Although this is a little weird because it means that our stream doesn't have a way to know what it should return. In particular, I don't think it reads an XID back. See, that's a good question. So the response seems to always have a length. It does always have an xid. And then for the other kind of responses, there are a bunch of other fields as well that are always included. So here's the downside of us putting connect and response in the same enum as the others is that the connect response actually has very different fields, whereas all the other connect responses share at the very least these fields.
01:47:24.135 - 01:48:45.965, Speaker A: So maybe, yeah, no, I think I want it this way anyway. But it does mean that there's Actually no xid that comes back, it's just length and then payload. And the way we can tell what the response is is by which request was sent. So I think this means that the response type is just dictated by the request type, which to me suggests really that the packetizer should keep track of last sent opcode. What operation are we waiting for a response for? This is going to be an option opcode, I guess. No, it's going to be an opcode. Sent is going to be a.
01:48:45.965 - 01:50:04.905, Speaker A: No, it's going to be an option because remember that when you send a connection request, a connection request does not actually have an opcode. And so this means that when you start send, then what we're going to do is self last sent. Well, this is also a little weird. I think last sent actually has to be a vec DQ because the way we've set up this interface is you can actually have multiple requests in flight, right? You would push a bunch of requests and then the stream would resolve each one in turn. So I think this would be. Yeah, collections vecdqueue. It's a little sad for this to be a dq, but.
01:50:04.905 - 01:51:33.055, Speaker A: So this basically means that every time we send another request we push its opcode and every time we receive a request we pop the or we shift from the front of the queue which request that response must be in response to. So this means the last sent is initially going to be a vecdq new last sent pushback item opcode. So this means that. That on request we're also going to have a pub super opcode. Actually no here that's going to just match on self and if it is a request connect, it's going to be an op code Auth is it guaranteed to be responded in order? I don't actually know. So this is one of the problems with the protocol being so poorly, so poorly documented. I suspect that that's true.
01:51:33.055 - 01:52:28.345, Speaker A: Yeah. So you both asked this same question. So remember, one thing we could do is we could enforce that you can only send or receive. This is totally something that we could set up in the API that in fact it's not a stream or a sync, it's just a future where you send a request and you get a response. The reason I sort of wanted it to be a stream is so that you could have multiple requests pending. But it's really, in a sense you're making a good observation that if it is in fact a sender request, get a response kind of API, then we shouldn't really use sync or send we should just make the whole thing be a future that serializes the request and then reads the response and then returns. That's a good question.
01:52:28.345 - 01:53:04.315, Speaker A: I wonder. So this is one of the problems with the protocol being so poorly documented. Leader activation doesn't really help us. That definitely doesn't help us. The real question would be this X id. So in theory we could have an X ID per request or something which might let us have multiple outstanding requests. The reason I suspect that it supports this multiplexing is because you have the set watches thing.
01:53:04.315 - 01:54:24.725, Speaker A: So if we look at the Zookeeper thing here, one thing you can do with Zookeeper is you can set up a watch. Where is it? So a watcher. Where is this watch? Yeah, you can basically set up a thing that should be notified whenever a given path changes. So basically when a key changes and this to suggested, you must be able to send the server must be able to send us things even when we didn't ask for something. In fact, let's look at what that gives us. So if we go back to the Zookeeper class, give me source Zookeeper. So where's the thing that.
01:54:24.725 - 01:55:26.417, Speaker A: Okay, so a request is sent on that channel, sends the request and then it just receives a response. Although the. You know, see here. So he creates, in this case the. At least the author of the old library sets up a new transmit and receive channel for every request and then the response comes back on that channel. So this does suggest to me that you could have multiple things in flight. Of course, one way in which we could make this concrete without guaranteeing anything about the order with the ID until the response would the same ID get back.
01:55:26.417 - 01:55:55.775, Speaker A: Yeah, so one way we could do is just keep a mapping. Although it doesn't look like there are request IDs in the setup. Right. Unless these X IDs are that. But that's not really well defined. Yeah, it's sort of unhelpful because this X ID, I guess that could be transaction ID. So if it's transaction ID, that suggests the you could have multiple XIDs in flight.
01:55:55.775 - 01:56:50.295, Speaker A: Let's see how XID is incremented. Xid just request. It's an opal self xid. Ah, okay, so it does look like XID is a per transaction id. So this means that every request does have its own xt. The current project is writing a library, an asynchronous library for Zookeeper, for Apache, ZooKeeper. The AWS bot instances is still a library that's out there.
01:56:50.295 - 01:57:20.805, Speaker A: I haven't done any work on it for A little while. There are a bunch of videos on YouTube of recordings of past streams around it. So you might want to check those out if that was a project you thought was interesting. Okay, so this does suggest that every transaction has its own id, which means that it might be that we. Ah, here's what we want to do. Okay, I got it. So I think we still want the packetizer because the packetizer.
01:57:20.805 - 01:57:50.347, Speaker A: The packetizer is the way in which you send and receive things through the server. Right. So imagine that it does not. It doesn't really care what the XID is nor what the opcode is. Ah, here's what we want to do. Okay, so sorry, here's what I'm thinking. The stream is going to take requests.
01:57:50.347 - 01:58:42.865, Speaker A: What the. What the. I'm thinking we sort of wanted a demuxer here. So at the lowest level what you want to do is you send requests to the server and you get byte chunks back with an xid and then it's up to the server to look at which future should I resolve now that I got these bytes back? So the way this is going to be set up is when you send a request, what you get back is a future for that request. And so internally what then happens is that request is sent on the sync, that's the packetizer sync. And then at some point the packetizer will get a response for that future. Yeah, that's totally the way this should be.
01:58:42.865 - 02:00:14.345, Speaker A: Okay, the question is whether X IDs have to be strictly monotonic. That's a good question. Okay, so. So here's the way that would. This would be a hash map, I guess from i32 to a futures unsync one shot sender, an opcode and a sender response. So the idea here would be that you, the whole packetizer is really a future where you can queue up requests and then you just have to keep pulling it. And as you pull it, the appropriate other futures will also be woken up.
02:00:14.345 - 02:01:11.305, Speaker A: Yeah, I think that's the way we want to do this. All right, that's going to change the design a little bit, but I think it's going to be for the better. So we're no longer going to implement sync or send or sorry or stream. What we're going to do is we're going to have a, we're going to impul future for packetizer S, where S is async read and async write. The item is going to be nothing. The error is going to be a failure error. And then if we look at what's the prelude future.
02:01:11.305 - 02:02:07.241, Speaker A: And so the idea is that poll is going to both send things that are outstanding and read back things that are results. And then in addition we'll have a. I guess we can, we could call it startsend. So there will be a separate method onpacketizer for queuing up additional items. In this case, an item will be a request. Actually it will be a request and a unsync1shotsender response. Right.
02:02:07.241 - 02:03:01.705, Speaker A: So the idea here is that if you have a packetizer, you can sort of, you can enqueue a request and the thing you enqueue is both a request and where to send the response. Yeah. And then packetizer is also going to implement future in the sense that you can keep pulling it to try to. Oh, actually better yet, instead of this giving that, this gives you back a future. But the item is a response and the error is a failure error. Beautiful. And then this is going to be, this is going to make a channel that is going to send the response on.
02:03:01.705 - 02:03:54.975, Speaker A: Whether this is sync or unsync, I'm not entirely sure yet, but we'll stick with one. Right. So self do reply dot insert. That's going to be X ID is going to be some number. So the X ID and then we're going to register item dot opcode and the transmit channel and then we're going to return the RX channel. Does this make sense? So you have a. On a packetizer.
02:03:54.975 - 02:04:37.355, Speaker A: On the packetizer you have a way of enqueueing a request and that gives you back a future that will receive respond when that request finished. Unimplemented is a macro from the standard library. It's really handy. It basically panics if you ever end up calling it. You can also do like unimplemented, I have not done this yet or whatever. But usually unimplemented is sufficient. So the reason we want packetizer to implement future is because you need to keep polling it for it to keep doing reads and writes.
02:04:37.355 - 02:06:26.805, Speaker A: And at some point if the connection breaks down, then that's also when that future would resolve. So I think what we're going to do here is that, ooh, every time poll is called, we want to both try to write and to read. So we want to try to write out any buffered requests and we want to try to write out buffered try to read out more responses. Now, in order to make ourselves a bit more sane, actually going to split these into two methods. So we're going to have a poll. Right. And we're going to have a poly and neither of them are actually going to yield anything like so so notice that these are basically unchanged from the way they looked.
02:06:26.805 - 02:07:28.355, Speaker A: Wait, that means the response has to carry an X, right? Or am I completely blind? Because otherwise how would we know which response to pair it with? Okay, yeah, there is an XID in the response. So I was wrong down here. Give me back my XID down here somewhere. I'll read. Yeah, this. So the idea here would be that at this point to do. Ah, interesting.
02:07:28.355 - 02:09:23.825, Speaker A: So here we're going to find the waiting request and this is going to be opcode and TX is going to be self reply remove and then the xid and then I guess this is probably going to be what response doesn't have op code. So yes, you're right. So responses don't have opcodes but I was worried they don't have x IDs either but they do in fact even connect responses do have xid. So that's good. Find the waiting request future. Yeah, so here we probably return an error if XID was unknown and then what we're going to do is we're going to parse this, give it the opcode that the request was made with and then we're going to do a TX send and we're going to send that response and then we're going to just do async ready. I guess I don't really want it to be ready, do we? We want.
02:09:23.825 - 02:10:48.755, Speaker A: It's a good question. I think we actually want this to just be a giant loop while I want an outland as well. So we need to. We need to make sure that we always keep. We need to keep polling the underlying streams otherwise we won't get notified when new data is available. So while outland not equals zero, then this and then that and here we're going to do. This is just going to be a loop.
02:10:48.755 - 02:11:31.721, Speaker A: So the reason this has to be a loop is because imagine that we read one request and then just returned. The problem is there might still be a request sitting in our buffers and the future would never resolve. We'd never end up getting to that future. We wouldn't know that we need to poll again because the underlying stream might not have any more data for us. Imagine the server sends us two complete respons responses and then closes the channel we read and we return the first one. How does the caller know that they should poll us again? They don't because the stream isn't ready. The stream doesn't have any data on it.
02:11:31.721 - 02:12:06.635, Speaker A: And so this is why in general when you call poll it should do as much work as it can do without blocking. And that is basically what we're now telling it to do. So notice that this is not an infinite loop because if we do a try read read here. So we do a poll read. If that returns not ready then we return immediately from the loop which is indeed the behavior you want or opcodes zookeepers way to call some remote functions on it. Yeah, basically. So opcodes are the type of a request is the way to the way to look at it.
02:12:06.635 - 02:13:11.637, Speaker A: All right, why is this? I think this will actually never return something. I think we can do this but it might not work. 157 what did I do? Something silly. I must have so in queue and the. Oh no, what did I miss? I have a bracket problem here somewhere. There. Yeah.
02:13:11.637 - 02:14:41.505, Speaker A: So the idea now is that we keep track of all the xids we've sent, what opcode the request in that xid was for and where to send the response when we've parsed it. And now this is going to be a hashmap new Just make this a default Default. Why is it request opcode should be pub. Super55 should be a spawn Actually this should probably just do a pub Create use request request and response response because we're going to want to use those outside of here. Cannot find big Anyan that is true. That is because it's called big Endian. What else? Oh, I'm probably going to need a bunch of these users in request and in response.
02:14:41.505 - 02:16:05.965, Speaker A: Yeah, I'm probably not allowed to do that either, am I? Oh, and pars now takes an opcode code which is going to be a super request opcode. All right. So the idea now is that on the packetizer you get to enqueue things they give you futures back and as long as the packetizer keeps being run, we're all good. Of course we're going to have to create new xids which I think is just going to be as simple as to do xid as a usize and xid is going to be self xid one and self xid plus equals one Actually it's just going to be this. Let's see, it's probably going to complain for this. That's fine. We'll never actually get to that type.
02:16:05.965 - 02:16:48.135, Speaker A: All right, so poll. What poll is going to do is it's going to call self.poll read then it's going to go self poll. Right. It has to call both because even if we so imagine that both a read socket and both the read end and a write end of a socket is ready. If we just call poll read, then we wouldn't be woken up to write again. So we need to make sure that we do both.
02:16:48.135 - 02:17:40.395, Speaker A: And so I think calling both here is just fine. We if there's an error, we want to return it. If either of these return not ready, that's fine too. So I think we can just do this. If let match RW if they are both Async ready, if they're both async ready, then we also return Async ready. Although that should basically never be the case. Ah, that's the case.
02:17:40.395 - 02:18:30.924, Speaker A: So a right can be. Yeah. So write would return ready if it's written out everything and flushed it Read would return ready if the incoming stream has been closed. So yeah, so if both of them are ready, then we return. Then we resolve the packetizer's future because there are no more responses coming in and the incoming socket has been closed, at which point there's no point in trying to send anything more. If the incoming socket has been closed and the outgoing socket is not. Who knows what we even do in that case.
02:18:30.924 - 02:19:22.385, Speaker A: I think just in all other cases we do okay. Async not ready. You could imagine that if the incoming reply channel was closed but the outgoing channel was not, then we return an error because you could never get a response to those futures. But I think we will just not do that. Actually, we do have to do that. So in this case we really want to notice that. Fail Outstanding requests but response channel closed.
02:19:22.385 - 02:20:11.485, Speaker A: What are we missing? 95 yeah, this is going to be a failure error. This is going to be a failure error. And lib. Ooh, 16. Right. This is now over a stream Connect is going to give you a zookeeper over a Tokyo Net TCP stream. Ah, no, this will take nes.
02:20:11.485 - 02:20:42.135, Speaker A: That's so many errors. Oh, that's so sad. I can't read bytes from. I guess I need a cursor. It's too bad. Found IO error. Expected failure error.
02:20:42.135 - 02:21:29.835, Speaker A: I mean those we can deal with. I guess the next thing that we want to do on sort of the low level is that we want to parse responses. So here I think basically what we want to do is match on the opcode and then parse appropriately. In this case, we don't really have the connect response and the connect response. What does the connect response have? Where's our thingy? Connect response. Connect response. So a connect response is one of these.
02:21:29.835 - 02:22:08.529, Speaker A: I don't want any of these to be pub, at least not at the moment. What does that even mean? Is handled as i32. Okay, let's just make it an i32 though. Yep. And so we're gonna match on the opcode. Now, one thing that's a little awkward here is there's actually not an opcode for connecting as far as I can tell. So auth is actually used for authing.
02:22:08.529 - 02:22:40.123, Speaker A: I saw this somewhere. That auth. Yeah, there's this add auth thing and that uses the opcode auth. So I don't know if there's actually an opcode for connecting. Let's see whether there's a here. No. Huh.
02:22:40.123 - 02:23:38.495, Speaker A: That's a good question. So I wonder whether what we want to do is actually invent our own opcode because it's not actually going to get sent. Right. So we have here opcode. I think we want this just return connect and then I want connect to be like minus 100. So we're going to match the altcode if it is here, use that. So if we get an op, if we are deserializing a response to an opcode connect, then we know that what we should do is construct one of the connect responses and a connect response is made like this.
02:23:38.495 - 02:24:32.075, Speaker A: Nice. Now, in order for us to use the read methods, it turns out that you can't actually do a read straight from a buff. And that makes a lot of sense because imagine that we do a read i32 from the reader or from the buf in this case, and then we do another read I 30. Unless we have some other state to keep track of this, the second read would just read from the beginning of the buf again. And that's why just a plain buffer does not implement read. However. No, that's not what I want read Ioread.
02:24:32.075 - 02:25:53.991, Speaker A: So if you look at Ioread, it's implemented for about bunch of different things. In particular, read is implemented for a reference to a U8, but we have to look at it a little bit deeper in that read requires a mute self, so it requires a mutable reference to an immutable slice. In particular, we can do reader is ute, reader is buff mute reader. I think that will work. Could be wrong. So what this will do is the reader is going to change the slice so that it points later and later as you keep reading. Oh, that's right, yeah.
02:25:53.991 - 02:26:33.845, Speaker A: So for vectors, you basically read out a length field first. Hmm. How do we want to encapsulate that Nicely. So one way we could do this is just add a trait readbuff for our. Where our implements read and this is gonna. I mean this is basically. We can just probably copy the method from here.
02:26:33.845 - 02:27:44.435, Speaker A: Basically the same thing read from that one. I guess we'll probably want the string reader as well. But yeah, Notice that all this is really doing is reading out a length and then it reads that many things from the underlying stream. And so in our case this should be all that's needed. What Expected two type arguments. What do you mean expected to type arguments? Oh, results. Right.
02:27:44.435 - 02:29:25.407, Speaker A: It's going to be a failure error. We're going to want to go through and tidy up our errors a little. Yeah. So notice that proto 149 we have sort of the same issue that it's saying I can't read an i32 from what's just a buffer. Right. So really what we do is here it's going to be a little bit awkward here we're going to have let buff is self Buff is going to be a reference into this that lasts for here to self install need and buf is mutable and so this means that we can now read from buf and that this can just be plus equals need down here. Right.
02:29:25.407 - 02:30:30.495, Speaker A: So the length we already read out up here, although we can technically read that again down here I suppose. Read that xid read that and then this is going to be the rest. So this is kind of neat. So because the implementation of read for a mutable reference to a slice is basically that after it's read it changes the buffer or that it changes the slice to point only to the things that hasn't read yet. That means we don't have to keep track of how far we read, which actually makes for slightly nicer code 137. Yeah. So this doesn't actually work because this I think we need to do like this, which I don't know whether it'll let us do.
02:30:30.495 - 02:31:32.425, Speaker A: Oh yeah, how about that? 39 need plus equals length expected usize found i32 poll read is not found for s at line 122. Ah, right. It's because we've written packetizer to not actually acquire anything. Whereas pull read and pull write are only available where S is async read and async write. We could add these as wheres actually to the. Yeah, let's do that. Where S is async.
02:31:32.425 - 02:32:32.025, Speaker A: Right. And this is where s is async read 148 expected async found result. Right. I already have the question mark. So I don't need that. It's so warm. 119 this is the same thing where I need to give it a mutable reference so that it can try to advance the pointer 110 not error error from actually I guess here I could get give context.
02:32:32.025 - 02:34:44.753, Speaker A: Let's not do that for now. 100 try ready expected usize found async oh, that's a little weird because it shouldn't care. So why does it care? Expected usize found async so write will return the number of bytes written, whereas this function is supposed to return async unit so the question is why does this not? I mean in theory you could just get around this with this Async ready n return n async not ready I mean that's basically what try ready desugars to. So the question is what? That wouldn't work. 102 Expected view size found async oh, do I need to use pull right instead of right? It could totally be it async right? Yeah, I do need to use pull write so that's why so write is just the right system call from. Sorry, the right thing that's in the right trait. Whereas I actually want the poll version so that I can use try ready whereas the right one.
02:34:44.753 - 02:35:59.997, Speaker A: So if you look at async write, notice how it basically says that the write method from the write rate follows the following contract, whereas poll write is just one that sort of encapsulates this contract in a poll based API. So lets me use try ready here. Wait, that's not what I meant to do. Expect that i32 found use on like 89. Yes, that has to be as i32 no length found len78xid I want that to be an i32, not a usize. All right, 45 should be reply 19. Oh, it seems like we're getting closer.
02:35:59.997 - 02:36:59.469, Speaker A: So response for some reason ambiguous associated type oh, this is a connect. Okay, line 42. Wait, how is this ambiguous? Wait, response is not a trait. Response is an enum. Oh, okay, fine. I'm so confused. Why is it saying that response connect is ambiguous 42 that is what? Oh, I didn't rename it.
02:36:59.469 - 02:37:44.675, Speaker A: That's why that's a terrible compiler error message. Someone should fix that. Okay, we're almost there. I think source lib20 so this is now complaining that it's not actually getting an error. So this of course we can clean up some of these. So these for example, could be then our context and then fail to connect to zookeeper. I think it's technically like this.
02:37:44.675 - 02:38:28.373, Speaker A: Zookeeper Zookeeper. Sadly. But that's how it's spelled. 22 Do I really need to do this? That's kind of silly. Yeah. So the problem here is I have a result where the error type is IO error and I've told it that I'm going to return a failure error. I think I need to do this.
02:38:28.373 - 02:39:46.565, Speaker A: Maybe it's failing somewhere else. Now let's get rid of some of these warnings. So response does not need write bytes text does not need futures does not need hashmap does not need write or Tokyo. What else? Or Tokyo Prelude. That makes a lot of sense because there's nothing async in response. My guess is the point is the same for response does not need readbytes because it's just going to write stuff Protomod does not need Tokyo does not need self and write and does not need. That's what it is Response that means IO read request line 67 did you mean request connect? Is that not what I wrote? Oh right.
02:39:46.565 - 02:41:06.415, Speaker A: Lib cannot find packetizer so that's gonna be. So it has a mod proto right? So we're gonna have a modproto and this is gonna have a proto packetizer. Proto packetizer send Right. So now we're getting back into the fact that we changed packetizer makes this a little annoying now because you now sort of need to. We need to have a way to drive the packetizer. You can think of this as like whenever you want to send a request now you have to enqueue the thing on the packetizer and then you need to drive the packet forward so that the response eventually comes back on the reply chat the future you get back on the packetizer. So it's going to look something like this where you do enqueue request and that gives you a future.
02:41:06.415 - 02:41:54.595, Speaker A: And then the question now is we're going to have something like this is just going to be this map that. But of course the problem here is if we in fact wrote the code like this ZK would now be dropped which means the packetizer would go away and would not be driven any further. But it's a future that needs to continue to be resolved. So if you look at this now I guess we can make it compile just because it's not going to matter a lot. This bug is still going to be there. This does have to be self. This has to be self and then it's going to complain.
02:41:54.595 - 02:43:32.105, Speaker A: 159 that's fine. Where is it complaining 58 it's complaining because this failure error from Right. So this now maps just to a response. I guess we could move the ZK into here just to demonstrate the issue 34 read only is going to be false 21 complaints because expected type parameter ah. Zookeeper it's also a terrible error. Cannot infer it's for B yeah. So this is why I'm just gonna failure error from for now 39 guaranteed to always get a response there.
02:43:32.105 - 02:44:04.427, Speaker A: Sorry. Right now I'm just going through all the errors and fixing them up just so that when we do start tackling the actual problem in source lib I can talk about without having all the other errors get in the way. All of these others unimplemented compiler driven development Yeah, I know. I actually really like it. I think it's a. I think it's a pretty good way to to work through your program. But I.
02:44:04.427 - 02:44:52.955, Speaker A: Maybe I'm alone in that irrefutable let pattern. Why is it complaining about that? Requests. Fine. I'll add another request type foo should not be necessary. Unimplemented and unimplemented. Oh, almost there. Protomod86 Great.
02:44:52.955 - 02:45:26.405, Speaker A: All right, so now we get a bunch of warnings. But see that this whole thing now compiles. Right, but let me see if I can make this problem clear. So the packetizer is a future that deals with that needs to be pulled in order to send bytes to the network and read things back. When you enqueue something, all that means, remember from when we wrote in queue, is that you serialize the thing and put it in a buffer. But that won't be sent on the wire and your response won't be read until we drive that future forward. Right.
02:45:26.405 - 02:46:14.425, Speaker A: And so that is why this, this, this packetizer, unless you drive it, this request that you enqueue here, the future you get back will never be resolved. Because remember, it gets resolved when the response channel is sent on. It's only sent on when the server has sent us a response that we parsed and the server will only send that when we send the request. None of those things will happen unless the packetizer is being polled. So there are a couple of different ways to ensure that this will happen. The way we're going to do this is we're going to use the new Tokyo runtime API and basically just say Tokyo spawn zk. So if you spawn a future, it means that it will be on the pool of thread.
02:46:14.425 - 02:47:13.735, Speaker A: The Tokyo runtime is going to make sure that it Keeps polling. You can only call this from within the context of a future. Luckily, we know that we're in the context of a future because we're already in this and then of the TCP stream. The issue of course is that Spawn is going to move the packetizer. So at this point we don't have a way to enqueue future requests. We don't have a handle to the packetizer anymore. And so what we're going to have to do is, hmm, let enquure is going to be ZK enquiry en cure and cure.send
02:47:13.735 - 02:48:05.143, Speaker A: request don't move. Enquiry in cure is a really hard word to type. Wow. So let me see if I can explain why this happens or what we're really doing here. So the idea here is that we're going to spawn the packetizer on the Tokyo runtime. So that means that Tokyo is going to make sure that we keep pulling it. And then we're going to have the packetizer expose some way to send it things so that we can enqueue additional requests without holding onto the entire packetizer.
02:48:05.143 - 02:48:55.595, Speaker A: Now, there are a couple of different ways you can do this. I'm going to do this with a. In a very straightforward way, just with a. Just with a queue, just with a channel. Here we could choose whether we want to use a sync or an unsync channel. I think I want the channel to be sync probably. So we're going to add a channel here that's going to be incoming requests RX that's going to be a Futures sync MPSC receiver of request Next XID to issue.
02:48:55.595 - 02:49:59.513, Speaker A: I think I actually want the NQ just be returned when you make the packetizer. In fact, here's an even better API. This just returns a synced NPSC sender request. It does a Tokio spawn. So that way this does the Tokyo spawn for you. I should probably just import this, shouldn't I? Use future Sync npsc. So it's going to be an npsc.
02:49:59.513 - 02:51:00.385, Speaker A: This is going to be an NPC unbounded. Probably RX is going to be the RX and it returns the TX document that it calls Tokyo Spawn. So one thing to be aware of is that when you're using the Tokyo run and Tokyo Spawn methods, Tokyo Spawn assumes that there's currently a runtime running and that it is within the context of that runtime. So once you start using these methods, you are essentially adding a dependency on Tokyo that's sort of hidden from view. So you need to be sure to Document the fact that in this case packetizer new does require that you're in the context of a runtime, otherwise it will not work. I don't think this is particularly onerous. It's just something to be aware of.
02:51:00.385 - 02:51:47.075, Speaker A: This will be an unbounded receiver. All right. And now there will not actually be an enqueue method anymore. Instead what we'll have is a FN pole enqueue. Also going to take one of these. But how are we going to get the channel back? That's the reason it's annoying. Yeah, we're gonna have to work around this a little bit.
02:51:47.075 - 02:52:53.625, Speaker A: So it's actually gonna get a pair of request and one shot sender responds. So remember that we need to give the packetizer a way to send the response back as well. So the channel that we send back, we could just do this one shot sender response. Well, we could do this. I probably want to wrap that up in a slightly nicer API, but we'll deal with that in a second. We're going to have this polling queue business and what polling queue is going to do is it's going to be very similar to the poll write and poll read except in that. Oh, not did I knock in that? It is simply going to.
02:52:53.625 - 02:53:57.325, Speaker A: It is simply going to poll the thing that enqueues or that received the channel we have that receives incoming requests and then just serialize them. So it's basically the same as what we used to do when the enqueue method was called. But that process is going to be asynchronous as well. So in this case it'll simply be while actually I guess it's going to be a loop. It's going to be a let item is self rx poll. It's going to be a try ready on par. And I guess one question here is what if it errors? So I think this one in particular is going to be a npsc.
02:53:57.325 - 02:55:07.195, Speaker A: What is the error type for that to. Good question. Docs RS futures Where's our so in this case we have a why I don't want 0.2 where's sync sync NPSC? If you have an unbounded receiver and you call poll what do you get? What's the error type? There is no error type. So what we're going to do here is we're going to try ready and that might return an error if there are no more requests coming. So think of this as at some point the sending channel that we have in order to enqueue things is going to get dropped. At that point we want to disconnect from zookeeper.
02:55:07.195 - 02:55:56.175, Speaker A: Now, we don't currently have a good way of doing that, but in theory that would be this method returning an error saying I couldn't pull the enqueue anymore. So we'll have to deal with that in the poll method of packetizer's future implementation. And we'll see that in a second. So this is going to get an item and a tx. It will simply do this simply forever. So it will keep trying to read things from the enqueue channel until it would have blocked. So remember that this will not actually loop forever, right? This will loop until the enqueue channel is empty.
02:55:56.175 - 02:57:01.103, Speaker A: This could be called enqueue rx I guess. And so this is just going to keep going until then, and then we'll return and then what we'll do is we'll have our poll implementation. It will do also self poll enqueue and we're going to sort of match well, so we're gonna match on this. So if this is okay of any sort, then just continue. If this is error, what this means is no more requests will be enqueued. And at that point what we really want to do is if no more requests are going to be enqueued, then once poll read and poll write have finished, then we really want to stop them. Once poll write is then finished, then we can really just close that connection.
02:57:01.103 - 02:58:08.865, Speaker A: I don't know if there's an exit call, but if we look at Rust Zookeeper, is there a drop implementation or something? Self close. Yeah, close session. Wait, what is Create Session? I feel like Create session is what open is. Let's not invent our own connect and use Create session instead. Yeah, so once we hit this error case and we know there are no more requests coming in, then once pull read and pull write have both returned ready, then what we want to do is then issue a close and only when that finishes are we done. So it's here we're going to say exiting is false, exiting is a bool. Exiting is false.
02:58:08.865 - 02:59:18.175, Speaker A: And then we're going to say here, if not self exiting. Self exiting is false, is true. And then down here we're going to have a case where why is this complaining? All right. Ah, no, not what I meant to do. Oh, did I? I did something stupid, didn't I? Wait, this seems totally valid. Why is it complaining? Proto line 59 I mean I must have introduced a syntax error somewhere because it's really unhappy with me, but unexpected token tx. Oh that's why.
02:59:18.175 - 03:00:56.305, Speaker A: Yeah. So when we pull in the future implementation here, we're going to set ourselves to be in an exiting mode and we will only allow ourselves to exit when here if selves exiting. So it's only if we're exiting that we will let that happen. Otherwise, otherwise we are async not ready. Because we could still receive, we could still receive more requests right now here there's actually another mode which is when we first enter this case of everything has been flushed, everything has been replied to and actually I guess if the we now want to handle the case of the right channel has been emptied and we're exiting, I guess that doesn't mean that there are no outstanding features. That's a little awkward. It.
03:00:56.305 - 03:02:54.057, Speaker A: Yeah. So the question here is we sort of want to know when to send the request to close everything off, right? I don't have a like we want to send this close session request but I think for now we're just gonna not tear down things nicely. Even though we we ought to but I mean we're just gonna not deal with that for now. All right, how are we in compiling response? Right, this is now create session protomod is now. Wait, why is it complaining about this? Expected sender found unbounded. Yeah, so here I actually want this to be like an enqueuer. So there's going to be a pub struct or I guess crate enquiry.
03:02:54.057 - 03:03:49.929, Speaker A: So notice how almost all the code we've written is internal abstractions for our library. The external interface is still basically non existent but the hope is that most of what we written we can reuse really easily on the outside. We now have a good driver for running all of our internal features. So enquir is really just going to be a wrapper around this business. Where is it here it's going to be a wrapper around this and we're going to implement on enclosed going to be very straightforward. All it's really going to do is it's going to have a function that is enqueue. It takes a request and it returns a impul future items response and error is failure error.
03:03:49.929 - 03:05:36.215, Speaker A: So notice that here we're using impl future here just to sort of hide the mechanism mechanism we use because we could totally imagine there's some more efficient way than a one shot future channel maybe to communicate this. But we don't really want the user to know. All we want them to know is that you get a back a future that will eventually evaluate to the response that you got and all this really has to do is all it really wraps around what you gave it is it creates the channel for you. So it does a one shot channel and then it does self zero send and it will send a. I guess this is unbounded send so this is something that was recently added that I'm very happy about. So unbounded senders normally implement and remember how sync for the if you call send on a sync it consumes self but for unbounded senders you also have unbounded send which just consumes self by reference which is very nice because it means that we don't have to consume the enqueuer in this case we're going to send the request which is this and we will send the transmit channel to send things back on and then we return rx and we will map the error. So now in lib the enqueuer is going to be enqueue like so and we will then move the enqueuer into here.
03:05:36.215 - 03:07:30.901, Speaker A: Yeah, so this is actually going to give you the enqueuer like so this takes a Self does not need to be mutable no function new on packetizer oh right. NQ protomod all right. The other thing that's nice about this is the enqueuer is not tied to the type of the stream so you can make a packetizer and pass around enqueuers without the enqueuers having to know how we're communicating with zookeeper this might not matter in many other contexts but I think that's going to turn out to be nice for us for testing in particular expected option found tuple why would that be? So if you have an unbounded receiver it's very weird. Oh right, that gives me an option. So we're going to match actually match on poll so poll is going to give us. So we have an unbounded receiver here. Right.
03:07:30.901 - 03:09:45.753, Speaker A: So when we call poll what we get back is a no, it's not at all what we get back. Where's my prelude stream Poll we get one of these guys errors we want to propagate if we get an async actually I do want try ready? But if we get an OK item tx then we return itemtx if we get a none then we return an error It's a little weird actually because I don't think you can what? Oh return expected option found results expected sender found sender on 98 because this guy has to be one shot so I'm using futures sync instead of futures unsync here so that you can actually have many different threads sending and receiving responses from zookeeper at the same time. We're going to require that. That's a little sad, but yeah, we're going to require that ascend and static in order to make a new one. Packetizer. Yes. So the error that happened there was we were trying to call pull write and pull read and they were lumped in the same impl block.
03:09:45.753 - 03:10:57.595, Speaker A: But we actually only require send and static for new because it calls Tokyo spawn and Tokyo spawn might spawn things on a thread pool. For example, async read is not implemented right. And I guess here S where S needs to implement send, it needs to implement static, it needs to implement async read and it needs to implement async write. So it needs send on static because we're spawning it and spawning might happen on a thread pool. It needs to implement async read and async write because we've only implemented future for packetizer when S is async read and async write. 62 expected failure found nothing O right, we don't actually get to have this return an error. So that's also a little awkward.
03:10:57.595 - 03:12:52.555, Speaker A: The problem here is the packetizer is now sort of running out in some thread pool somewhere and so if this future errors Tokyo doesn't know where to return that error and we don't really have a good way of communicating it back. So I think the way we're going to deal with this for now is to just map out the error here, expose this user this error to. I don't actually know that the best way to get this back is one way might be to the next time the user tries to or that it just like resolves some future with that error instead. That way we're guaranteed that it gets propagated. I think what we're going to do for now is just drop, which isn't great, but do it for now. Stream s handshake stream S that will only work where S is. S is async read and async write send can static this needs to use Tokyo it does not need futures which is interesting.
03:12:52.555 - 03:13:29.859, Speaker A: All right, so 41, what's left? Expected response found tuple right does not get the concur, it just gets the response. And now there's no none. And this now holds. Ah, that's great. So this holds an enqueuer. Did I make the enqueuer pubcrate? Yes indeed. Oh, that's great.
03:13:29.859 - 03:15:05.165, Speaker A: So this now this no longer needs to be generic os, which is also beautiful. Because it means we can do this and it means we can do this and it means we can do still need to have that 7 handshake is generic over NES 22 wait. Cannot move oh, unbounded sen that's so it's nice. All right, so in theory, this should connect us the way we want to and make everything happy. Let's just throw it at the wall and see what sticks. Oh, I guess this maybe. Nah Error fail actually then no format error fail to enqueue this should just never fail.
03:15:05.165 - 03:15:39.215, Speaker A: Pretty sure this should just never fail because the. Because we know that our receiver shouldn't be terminating I guess the way this would fail. So this is sending a request to the packet writer failed. This would only fail if the packet writer has gone away. We know that normally the packet writer will keep reading until this channel the sender goes away. So it should always be available. So this would be if the packet writer went away and that can happen.
03:15:39.215 - 03:17:38.185, Speaker A: Fail to enqueue new request that can happen if the it's true that can happen if the packet writer goes away instead. Same here. Filled to E the other question here is oh, I probably want just my own sanity. Oops Drive debug cash E partially lord partial lord and then I want request to be debug and response to be debug protomod so. Oh, that's right. So the issue here is that this function doesn't actually return a result, right? It returns a future. And I sort of want to say that I want to return a future if this failed.
03:17:38.185 - 03:19:15.245, Speaker A: So the way I'm going to do that is I'm going to match on this and if it's. If it's okay, then I think. I think the okay from unbounded send does basically NothingWell sync NPSC Unbounded Sender Result of nothing so if nothing happened, then this and then we're going to use the either future combinator, which is also really handy. So I'm going to use future either. So then either A that or if there's an error then I want to return either. B Error format error I think this is legal results into future Great. Now it's complaining about a bunch of things particular request at 61 that's fine.
03:19:15.245 - 03:20:18.703, Speaker A: Poo a bunch of unused OP codes which isn't terribly surprising. N which is no longer in use response which we're not really using. Although I guess we could print it out now that we're debugging anyway. So this is going to eprint line response Proto Mod ignores length to 201. Let's just do +4. Skip the length questline 44 that's gone away. So what do we have now? There opcodes and cure connection.
03:20:18.703 - 03:21:30.425, Speaker A: So connection zookeepers never used and result on Protomod 208 does ascend and doesn't do anything with it, I think. Okay, so this is. We're trying to send the response to someone who enqueued a response but the receiver has been dropped and I think we just want to ignore that failing receiver doesn't care. We don't either. All right, Cargo t run a test. In theory we now have everything we need to connect into the handshake and all the other things should actually be a lot more straightforward. Takes one parameter rust net TCP stream See, I sort of want this.
03:21:30.425 - 03:22:21.645, Speaker A: That's really the signature I want for connect. The question of course is how does this choose super each adder. What's each adder? And can I even get one? Probably not. That's really unfortunate. I just want a nice API where people can. Fine. It will take a socket adder and we're just gonna have to do what? 127001 Port 2181 which is the zookeeper port.
03:22:21.645 - 03:23:53.531, Speaker A: Parse unwrap. All right, how about now? What? Isn't there a way for me to parse a socket? Add connect timeout. Does Tokyo have an I just want some code I can copy paste for connecting Tokyo. Oh, is that all I need connect and undo this great line 54ZK block on I think is an API we can use now. What was it complaining about? Not found in Tokyo. Okay, so Tokyo run is also a little bit stupid because Tokyo run takes a future and runs until that future completes. But that future can't return anything very often what you want is you want the ability to just use.
03:23:53.531 - 03:24:16.785, Speaker A: You want to resolve a future and get its result. But that's not something you can do easily that way. The way to get around it is you. You create a Tokyo runtime yourself. Unwrap and then you do rt Block on block on. All that I want. Maybe not.
03:24:16.785 - 03:25:08.681, Speaker A: Could not find runtime in Tokyo. Oh, runtime block on and then RT shutdown on idle. So this is saying keep running until this future resolves and then shut down once the pool is idle. No unwrap. Okay, how about this? Well, that's sort of progress. What is it saying? Failed. Failed to enqueue.
03:25:08.681 - 03:25:59.195, Speaker A: New request cancelled. Canceled you say? So enqueue didn't work. That's interesting. So we presumably get to the handshake part. About to handshake. Okay, first of all, I want these errors to go away. Variant is never constructed Request.
03:25:59.195 - 03:26:47.005, Speaker A: What is it? Allow rust. Allow enum variants variance unused. Wow, I cannot spell today. Unused enum variant. I'm gonna guess no. Allow dead code maybe. Yep, that seems to have done it.
03:26:47.005 - 03:27:25.085, Speaker A: And then I don't want. I just want the warnings to go away so that it's easier to read this code. This as well. Allow dead code for now. And this foo business I also want. Great, so this still now fails with fail to enqueue new request. If I run this with no capture, what does it say about to handshake? Okay, so it's.
03:27:25.085 - 03:28:25.985, Speaker A: It does get to the point where it tries to handshake, it makes the packetizer and so it's the in queue that fails. Canceled. Well, I guess we'll have to look at what the packetizer does. So packetizer pulled and we want to see whenever it decides that it's done, which is this place. Packetizer done. In theory, it shouldn't feel like it was done, right? Yeah, the packager is not done. Pack tracer is being pulled.
03:28:25.985 - 03:29:52.165, Speaker A: So why is it failing to enqueue the new request? Protomod27 so it's trying to receive the response and that's been canceled. So this suggests that the. When we send the TX to the packetizer, that TX is simply dropped. So why is that TX dropped? That means we're dropping something from reply or we're never inserting it into reply. So here, eprint request item. See, the idea of course, was that the TX would be stored here and then that somewhere down here. Where is the here? Recovering or handling response to xid this with opcode this to the opcode.
03:29:52.165 - 03:30:59.795, Speaker A: All right, let's see what we got. So it does receive. It receives the request. It does receive the request. The question is why does it then drop the sender? That is a very good question. Because that's the only place it could be removed. So that's a very good question why it would drop the response.
03:30:59.795 - 03:32:11.825, Speaker A: Actually, let me just. If other people want to follow along with the code, I'll make a repo for it. Tokyo Zookeeper first non working public draft Push push you origin master. And now of course the. Yeah, so now the code is here if you want to go see it. So it's at GitHub. John who? Tokyo Zookeeper.
03:32:11.825 - 03:33:44.375, Speaker A: So the question now is why is the receiver being cancelled given that it's not being removed? It's almost like the Packetizer isn't inserting it anywhere, but there's nothing that can fail between these. So it definitely got the request, which means it definitely inserted it here. So why on earth would it go away? Unless, of course, the whole packetizer is dropped. Let's see. I'm not sure why that would be the case either. It is being dropped, so that's the reason it's being cancelled. The question is, why is it being dropped? Because the packetizer should be returned here, which means it should be returned here.
03:33:44.375 - 03:34:29.955, Speaker A: I mean, we. It's true that we're dropping the and cure here, but we're not really dropping the packetizer because the packetizer is just being. The packetizer is just being spawned onto the Tokyo runtime, I guess. I guess it had an error that we just dropped. That's what we get for taking shortcuts. All right, let's see. Fail to fill hole buffer.
03:34:29.955 - 03:35:16.145, Speaker A: Failed to fill hole buffer. But that shouldn't really be a problem. Should be allowed to not fill the buffer. Hmm. So I guess let's dig into this some more. So eprint line poll in queue, pull read. I mean, my guess is it's in pull read.
03:35:16.145 - 03:36:23.915, Speaker A: All right, so it gets to pull read and then fails to fill the whole buffer. So somewhere here. Oh, that's totally what it is. No, though we shouldn't be calling that. So the question is here, I want to know where exactly that happens. I don't think it gives me a backtrace, though. Yeah, so the issue is specifically that at some point it's trying to read inside this function and instead of just returning would block.
03:36:23.915 - 03:37:24.135, Speaker A: It gets and error is saying that it failed to read the number of bytes. I think the only way that could happen is if we. Is if we use the Read i32 API and so the read bytes X because we give it just a slice, it knows that it reached the reaches the end of the stream and therefore it would give that error instead of would block, which I think means that it gets here. My guess is it fails and like response parsing or something. Yeah, it got there. So I'm going to guess that it gets here. I did not get there.
03:37:24.135 - 03:38:08.221, Speaker A: That's interesting. So I mean, this is the connect response. So maybe the length there is wrong or something. Not here with need equals four, but seems wrong. Oh, more than or equal to four. Ah, that's pretty silly. More than or equal to four means.
03:38:08.221 - 03:39:13.305, Speaker A: So we get the length I got here still says with four read more bites. Yeah, so this sort of suggests that it's not reading enough data. Read more bytes. Read more bytes have how many self inland shouldn't it be need equal equals 4 instead of not equal to 4. Where do you think it's not equal to 4? Read more bytes have 0. Read more bytes have 0. Here with need equals 4.
03:39:13.305 - 03:39:33.715, Speaker A: Oh yeah, you're totally right. You're totally right. Good catch. It passed. We successfully connected Zookeeper. You're totally right. Good catch.
03:39:33.715 - 03:40:06.205, Speaker A: And let's see what we get back. So we get back a look at that. That's something Zookeeper gave us, at least in theory. Don't know why it's read only true. Like these things look a little bit sketchy. But why would it give us a negative session id? But okay, that's progress. Let's get rid of these God here business.
03:40:06.205 - 03:40:42.215, Speaker A: I do probably want to keep in these for a while, but at least this is. Where's the packetizer? I don't want that. Commit can connect. Hooray. Git push. So now let's try to run some other operations. So in theory, my hope here at least is that writing more operations now should be basically trivial.
03:40:42.215 - 03:41:15.245, Speaker A: I mean it's probably not going to be, but I want it to be. So we're gonna derive clone and debug for this and then we're gonna have. If you have a Zookeeper you can. Let's see, what's the interface for this crate on Zookeeper. So like the simplest things we can create and exist. That seems great. Create, sure.
03:41:15.245 - 03:42:07.605, Speaker A: Actually no, let's make this as simple as we can for now. Will in fact just be this and it's going to give you back an impul future I guess string. I mean I don't know what's in there, but sure, why not? Failure error. This is one of those places where we probably want structured error type. And now what this is going to do is going to self.connection.enqueue now we're going to have to define the request. Find where's our friend? Over here somewhere.
03:42:07.605 - 03:43:13.515, Speaker A: So that's connect request Connect response request header, Reply header Create request request. Great. So it's going to be a new request type. It's going to be this. And if you're trying to write out a create request, what that's going to look like is create path data ACL flags. And like all of these are ref. We might want to make requests be.
03:43:13.515 - 03:43:58.083, Speaker A: Oh no, let's leave that alone for now. Flags. So this is going to be very, very, very similar to what we had in had for Connect because it's really just going to be. Oh, I just say write to. This is some funky stuff going on here. So this is going to be create. Oh, that's because these are all funky.
03:43:58.083 - 03:44:30.715, Speaker A: These are new types. So we have strings and vex of various different types. So this is why they've got this right tooth trait. Yeah, I think we want that trait. That seems like a good idea. So we're gonna keep this trait. So.
03:44:30.715 - 03:45:15.359, Speaker A: And there's an impul of write 2 for u8 for string and for vect. So and then also for acl. Although for now I don't really have the acl type yet. Do I want this acl type? Probably do, don't I lib. What's an acl? No acl. Oh yeah, I don't want this yet. It's too much stuff.
03:45:15.359 - 03:45:55.685, Speaker A: So we're going to claim that this is actually an empty beck to do. Right. And so now element self.iter elem. Write to. Why are there no oh T implements write to. Any other write to implementations here? Connect request, request header, et cetera, et cetera.
03:45:55.685 - 03:46:30.615, Speaker A: That's all fine. Ok. These are all the same. All right. So what this gives us is the ability to do path write to buffer data write to buffer ACL write to buffer. So my guess is that the encoding of vec is just the number of elements first. Yeah.
03:46:30.615 - 03:47:10.985, Speaker A: And for string, is this the length of the string first? Yeah. Okay. So these are very straightforward. It's just nice to have a. A convenient, convenient way to encapsulate it so that we don't have to repeat the same code for writing the length in advance each time. Oh, right. And these all return, I guess, ioresult IO results.
03:47:10.985 - 03:47:47.785, Speaker A: Ioresult IO results. Yeah. So this is going to enqueue a request we're going to. Here I'm just going to use proto request create. It's going to have a path which is going to be path into owned. We're going to have data which is going to be data into owned. Right.
03:47:47.785 - 03:48:52.247, Speaker A: What else is going to create ACL and flags ACL which is just going to be a vec for now and flags which is going to be zero for now request 108. Bye. For STR that's what I really want. And for that's what I really want. 108. I want draft. Why does it not give me draft? So I guess I'll just do this for ticket.
03:48:52.247 - 03:49:55.411, Speaker A: For ticket T and that's just going to call self dot WRITE to writer. What how about like that? Wait. Oh, it can't. Fine. Evacuate then. And then I think maybe I can now get rid of this. It's because unit doesn't implement.
03:49:55.411 - 03:50:48.999, Speaker A: Yeah, exactly. Unit doesn't implement and I don't really want to implement. Write two for unit seems not the right thing to do. And response also needs to be able to parse a create response Create response which is apparently a string string actually let's do it properly. And that is just a. So I guess this is the opposite trait which we probably also want to borrow from here. Right.
03:50:48.999 - 03:51:33.105, Speaker A: And this is very similar to the buffer reader that we already have. Like so. And now if we get an opcode here we do have this opcode create that's going to give us an OK response. Create response where it's just going to be response. So notice how usually the. The core protocol things end up looking very similar between async and non async things. It's just what it means when there are errors.
03:51:33.105 - 03:53:30.039, Speaker A: But now comma first this seems to be an IO result. I would rather have it be ioresult than all these failure errors on methods that are basically IO. Stick to that. It's going to complain about 32 because here there's going to be an error error kind I guess. I guess a wood block actually read buffer failed source lib55 this should be into string tostring I guess. Yeah. So what I was thinking earlier is we might want requests to have a lifetime so that you don't have to give owned things into it.
03:53:30.039 - 03:55:05.595, Speaker A: But it makes it a little annoying with the few future because you don't actually know. You're sort of going to have to guarantee that the reference is valid until you read the response. Which is a really weird lifetime to have and not one that's trivial. But we'll see how this works out and see if that's nice. 53 that's gonna enqueue and then map r iflet so this is one thing that's a little bit annoying is that. Sorry, just finish typing this first is this case that you send a request for a create and then you know the response also has to be a create but the compiler doesn't actually know that this is the case. We could sort of fix this by adding a trait bound here saying that in queue takes any type and returns a future that resolves into that types resolve type and then only implement like resolve the resolve type trait for create response for create request.
03:55:05.595 - 03:56:10.687, Speaker A: That way you'd be able to pair them up. But I Think this is nicer. That would. That would prevent abuse though, I guess. Let's find our protomod enqueue to do maybe. So the proposal is that we make enqueue take an R a rec and a rest self rec takes a wreck returns an impul future item is rest where wreck return something like that. So we could have a.
03:56:10.687 - 03:56:56.605, Speaker A: We could have that kind of a bound which would guarantee us that we wouldn't be able to cons to return a different response of the one that was requested. So that would be pretty nice I think for now. I mean we can do that. I'm more trying to figure out whether there's a better way than using unreachable. So I think this pattern bothers me a lot because it shouldn't be necessary. This type is going to mean that enqueue is a bit more of a pain to use though because it means that you don't really know what response you're going to get back. And we wouldn't have this convenient enum type either.
03:56:56.605 - 03:58:41.535, Speaker A: Got a non create response to create request spawn 63. Why is this? Oh, so now let's so see how straightforward that was to add. So we're going to do connect and then with the enqueuer then we're going to do zk.in queue no zk create foo0x42 that's all I want to write there. That gives me a future and I'm going to block on that future. Actually that's not even what I want to do. There's so many ways in which we could do this.
03:58:41.535 - 04:00:07.925, Speaker A: I think what I actually want to do is this. Oh, that's another thing. That's. No, actually that's fine. So this is going to give us a ZK and then we're going to do zk dot here we're going to do ZK create and then path eprint line created path like so it did not like that. How about now? Cannot infer type for T82 it doesn't like inspect. Anyway, let's see whatever we get this time.
04:00:07.925 - 04:01:42.965, Speaker A: So connect. Oh, read buffer failed. That's not great Hills. I mean I guess we did change read buffer but not by all that much. Wait, so this means that when a quest is failing read more bytes have four so how many bytes does it have when it tries to do this decoding? Wait, it works some of the time. That's terrible. Have 41 bytes.
04:01:42.965 - 04:03:00.635, Speaker A: So sometimes it works and sometimes it does not. And also the path it gets back is empty, which is A little disturbing. That's odd. So the times when it read buffer failed 41 bytes. Okay, let's try to inspect what these bytes actually are in each case. So here's a case where it fails, then we get those bytes. Byte.
04:03:00.635 - 04:04:13.353, Speaker A: Okay. And in case where it succeeds, we get these bytes. So that's kind of interesting. So they're the same number of bytes, but for whatever reason, one we can parse and the others we cannot. Oh, the XID we got back, we parsed just fine regardless. So let's look at our response parser. The response from a create session should be you first read the protocol version, which is 4 bytes.
04:04:13.353 - 04:04:44.345, Speaker A: Then you read the timeout, which is 4 bytes. Then YOU read the session ID, which is 8 bytes. 1, 2, 3, 4, 5, 6, 7, 8. I don't think that's true. I find it very hard to believe that the session ID is the same every time. But. Okay, then it reads the password.
04:04:44.345 - 04:05:32.867, Speaker A: Password you say, which is encoding a length. I don't believe that that's true. I think we're missing something. And then the read. Only because this read buffer. So read buffer reads 4 bytes and tries to read that many things. There's just.
04:05:32.867 - 04:06:45.039, Speaker A: There's just way too many bytes. So this can't be right. I feel like that password is like this zero or something. So when we parse this, this is a different kind of response though. So the thing we get from the server is first the length, which at this point we've already parsed out, right? Yes. And then the xid, which is the next four. So what is this then? This reads from four.
04:06:45.039 - 04:07:30.125, Speaker A: So this means you should not read the xid when it's a connect response. Oh, that's weird. Right? You see this? So it reads the length, which is 0,4, and then xid, which is 4,4. But then it reads offset 4, which is 4 for a connect reply, which to me implies that the X ID is not there. So I guess we. If we know that this is the first response. Yeah, the part that's changing is probably the session key.
04:07:30.125 - 04:08:28.965, Speaker A: I agree, but this just means that the X ID we shouldn't be reading for the connector reply, which is a little bit disturbing because it. It means that you basically have to know. It means we need to know whether we're decoding the first response or a subsequent response. So basically this is going to be if self first, then. So we're going to let xid is. Then it's zero, then we know it's the connect response, otherwise we're going to read the XID and then. And self versus False.
04:08:28.965 - 04:09:13.375, Speaker A: Yeah, I mean, that's. It's not really connected as much as it's first, but yeah, all right, that seems all good. So that's better. And then for. Okay, and then we're at Create. So create reads the response to Create should just be the path. Oh, and the opcode.
04:09:13.375 - 04:09:35.095, Speaker A: No. Oh, right, right. I've completely forgotten about these other features fields. That's right. So it also. Zookeeper also keeps track of a bunch of these timestamps that you need to pass around to ensure that you keep progressing. And we're not currently parsing those out, so we do need to parse those out.
04:09:35.095 - 04:10:45.905, Speaker A: Where does this parse those? Actually, that's a good question. Response. Yeah, so that's something that's just extracted over here somewhere by the thread that's spun up by. Where is this? Yeah, so these additional IDs are not generally something the user needs to know about here. Yeah, it's a reply header. This thing and the reply header, they parse here. Right.
04:10:45.905 - 04:11:38.953, Speaker A: And that reply header holds zxid. What else? Where does reply header come from? Proto, probably xid, zxid and error. Ah, right. Yeah. Technically this should probably be a connection state, as opposed to just first. But so let's see. ZXID is.
04:11:38.953 - 04:12:21.559, Speaker A: This actually is an i64 and error. So reply header is an i32 and i64 and an i32. What does it do with the error? Yes, this is also right. You can get a response to a close. That makes sense. This is where they handle connection responses. We don't currently implement timers and timeouts either, which is something.
04:12:21.559 - 04:12:58.765, Speaker A: We'll have to do this whole thing. But crucially, we do need to read out these fields. And this would be xid. We're going to need things like the Z, the zxid and the error we're going to need later. But for now we just need to make sure that we parse them out, otherwise they'll be a part of the response. See, empty. Empty is very few bytes.
04:12:58.765 - 04:14:11.795, Speaker A: Why is it empty? I mean, this sort of suggests that this. No, this can't be right. Length is 16, which is 8 plus 4 plus 4. So where's the content of the. Where's the create response? It's a very good question. Let's fire up Wireshark, shall we? And on loopback, I want port 2181 and then let's run this again. 2181.
04:14:11.795 - 04:15:06.340, Speaker A: All right? No, don't. Right, so now I want to follow the TCP straight stream. So we sent. So this is us sending the connection request, this is the connection response. This is us trying to create slash foo and this is the response we get back. All right, so this packet. So this first four is the length and that length is 16.
04:15:06.340 - 04:16:38.065, Speaker A: You see the 10 is 16 and that's correct because the length is 20. And then we get four bytes of ZXID, which is one, which is correct because that's the XID we assigned to the first request. And then we get 1, 2, 3, 4, 5, 6, 7, 8 so 53 is the ZX ID and then this is the error code ff. So maybe there was an error that occurred. Then how do we know what the error codes are? Hopefully that's also listed somewhere. Oh no error it's not gonna be easy to find is actually let's look at the rust one instead and see if there's any error parsing going on here. Source error security Aha.
04:16:38.065 - 04:20:09.701, Speaker A: That's what we want to see. So this, I want this whole thing. So we're going to haveerrorerror rs it's going to have this whole file and we're going to do here reprie 32 and also derived debug and this is going to be a this as ZK error. So protomod we're also going to have a mod error actually I guess we'll do this and then if error not equal to 0 then you print this error. So now it's a question how do I create one of these? I think I can just do this. What do I have to do from error? Do any of you remember off the top of your head? Don't really want to match you can use transmute that's not really ah numb macros I don't really want to depend on that. But what num derive Derive numeric traits I mean I guess that's what I want.
04:20:09.701 - 04:24:07.189, Speaker A: I'm a little sad I have to add a crate for it but num2 and then I want Z create and now we want this to also derive from primitive. Oh, I need macro use as well I guess Find derive macro from primitive in source that seems really unfortunate. Oh, did I do that stupidly can't find cross trait for num traits it seems weird. I don't really want to do this this way. So in that case let's just this pubfn from actually impulse from i32 for this from substitute with no I only want from here. Oh, did I do stupid? I did deny this Is regular expressions. What did I miss? Why is this not legal? The substitute preview, I think is new in neovim.
04:24:07.189 - 04:24:39.399, Speaker A: I don't remember exactly what the place. It's a good question. It's somewhere in here, I think. It's relatively new, but it's really nice. I don't remember. You'd have to look. It's somewhere in my vimrc, which is on GitHub.
04:24:39.399 - 04:25:11.415, Speaker A: If you look at my repositories, there's one called conf configs and that has all of this. So yeah, if you take a look there, you should find it. All right. What error did we get? It's saying marshalling error. Oh, so the request we sent to Zookeeper was wrong. Interesting. Well then it's not terribly surprising that it didn't want to do that.
04:25:11.415 - 04:26:21.703, Speaker A: I guess. Actually the what this gives you back is it resolves either with an error or a ZK error. And then here, that's awkward. And then use error zkerror. I'll probably tidy up that a little bit later. But 28 a result of this and zkerror this will hold a sender of resolve this. This looks like a place for a pipe alias.
04:26:21.703 - 04:28:15.685, Speaker A: But let's do it up a little bit because now here where we send the response we sort of want let moved error is none error code then error is sum this and then if let sum e is error then tx send that is okay, else we do this. Actually this is going to happen regardless. And now 239 this is going to send an okay, so basically this is just wrapping the one shot so that we can send errors back as well. We might want to just unify these and not have two separate errors. But for now let's do it this way. We're gonna match on R and if it's an okay this then we do this. If it's an error, then we panic with E and if it's anything else then it's unreachable.
04:28:15.685 - 04:29:28.315, Speaker A: I think Plain vim has this feature now as well, actually. But you'd have to check. Great. So now it actually errors the way we're expecting it to Marshaling error. So why is it that the string resend is wrong? I'm like fairly sure that it's request. So for some reason it doesn't like this. I mean, I'm like almost certain it's the acl or maybe it's the flags.
04:29:28.315 - 04:30:30.695, Speaker A: What do flags have to be? So for Zookeeper here, if you do create, you have to select the mode Ah yes, we probably do have to give some kind of mode here and that's what we're missing. So specifically, create request. When it makes this Create request, what does it make it with mode? As i32 and modes are probably not allowed to be zero. No, persistent is zero, so I should be allowed to do that. Ah, if the ACL is invalid or empty, invalid ACL is returned. So we have to send an acl. I don't want to.
04:30:30.695 - 04:31:15.801, Speaker A: That makes me really sad. I wanted something that was straightforward to implement. Ah, let's do exists instead. Yeah, let's do resistance then. So I don't think crate will actually be that hard, but. Except we'll have to also port the ACL stuff, which I don't want to do at the moment because we're already running like fairly late. So an exist request has a path and a watch and I'm guessing watch is like a U8 or something.
04:31:15.801 - 04:31:51.735, Speaker A: It's like a bool. Okay, so that's fine. What exactly is a. How do I find one? Proto. Give me proto. So an exists request is a string and bool request. Okay, so it really just is a UI and the response is a stat response.
04:31:51.735 - 04:32:40.005, Speaker A: The stat response is a stat. And what is a status? Oh no, data stat. Oh no, it has so many things. All right, fine, we'll get a stat. So I guess we'll do something like so source data resource. I sort of want to call it types, but it's not really types. Let's do types RS for now and then we'll deal with that later.
04:32:40.005 - 04:33:26.485, Speaker A: So stat is in types. This is going to have a mod types and it's going to pub use statistics. What is our what is exists returned here? An option stat. Okay, great. So we change this to be exists. It takes a path, it returns an option stat. It's going to not make a create but a exists with a path and a watch which is going to be zero and exists stat.
04:33:26.485 - 04:34:10.337, Speaker A: It's going to get back its stat. Alright, so what was the response to this? Exist response is a stat response which seems to always be sum. So when would this ever return? Oh, zkerror node. I see. So error zkerror. No node is none. So that's how it does.
04:34:10.337 - 04:35:39.395, Speaker A: It bailed. Oh right, we have. It actually finishes up. So this is going to be exists, takes a path and a watch which is just going to do buffer, write U8 watch exists exists. And now our test of course is going to call exists like so and I guess response. This is now gonna have exists which is gonna be a stat. So we're gonna use stat there.
04:35:39.395 - 04:36:37.685, Speaker A: We're gonna get a stat back, and we're gonna need a way to deserialize a stat. Guess. So what's the stat read from? So where is is read from? Implemented for stat. There we go. We probably want to borrow more of these traits. So this is one of. As I mentioned before, like if someone else has written the protocol before, especially in the same language, it just saves you so much work.
04:36:37.685 - 04:38:18.025, Speaker A: Like, these aren't necessarily all that hard to write. Like, if you look at them, it's not like there's something that we would have a really hard time writing once we have the struct. It's just really convenient not to have to. Because now in here, exists gives us an exists where stat is stat read from reader spawns 32 and I messed up my syntax here somewhere. Yep. What else do we have? Zkerror use types proto Z. There's pretty clearly a bunch of cleanup we could do for the organization of this library.
04:38:18.025 - 04:38:44.971, Speaker A: Just I want to get to the point where the. Where all the base functionality works. Actually, let's do. Oh, that's already there. So I just want Proto ZK. So now 59. This doesn't work because.
04:38:44.971 - 04:39:35.114, Speaker A: Expected result found option. Expected result found option. Oh, okay. Some stat. Okay, none. 87. All right, let's see.
04:39:35.114 - 04:40:42.813, Speaker A: Does foo exist? Still a marshalling error request exists. That's so weird. Is there a zookeeper log? Fail to process, establish session. Fail to process, get data. Unreasonable length. Oh, I know we're doing wrong when we're sending the request. Where is this? Let's see.
04:40:42.813 - 04:42:01.151, Speaker A: So give me port is 2181. What is it we're sending out? When we send out our request, this one, we send a length. Wait, the first four bytes should be the length. Why does it think that the length is very long? That's very long. Whereas clearly the length is set correctly for the connect. So I think this is the length for the string. So in the request we send out, we first give four bytes of length, then four bytes of XID, then four bytes of opcode, then a length and then the string 2F.
04:42:01.151 - 04:42:46.035, Speaker A: That seems far too long. Oh, wait. 4 1, 231234 and then 1, 2, 3, 4 and then 12 34. Yeah, something's not right here. Because we're supposed to send the length. No, I shouldn't need to send ZXID. The request header is just length followed by XID followed by opcode.
04:42:46.035 - 04:44:13.345, Speaker A: And all of those are 4 bytes request header. Yeah, the request header is just xid and opcode. And opcode is just an i32 and the length is an i32. Am I miscounting here? Because like if, if this is indeed where the, where the data starts, then 4 bytes for the length 12, 34 bytes for XID 1, 2, 3, 4 bytes for the opcode. What is opcode for exists? Opcode for exists is three. There's no three here. So this makes it seem like we don't actually send the opcode or like we send the first three bytes of the opcode and then it gets overwritten or something.
04:44:13.345 - 04:44:36.383, Speaker A: Oh, I wonder whether that's what it. It is. Yeah, it's. It's totally right here. We're not actually sending the. The opcode. This needs to send opcode.
04:44:36.383 - 04:45:19.125, Speaker A: Exactly. Great. So now we get back exacts exists, some whatever. And that's actually because I did it earlier. If I do ZK cli give me a command line interface, help delete, foo. And now if I run it, I get exists none. Right, Exists none.
04:45:19.125 - 04:46:08.547, Speaker A: And if I create food banana and then I run it now I get sum with a data length of 6, which is how long banana is. Yay. Okay, so we now have. We now have connect and we have just any arbitrary one of the calls specifically we have exists. I think that's pretty good. So this is basically how far I wanted to get today to get to the point where we have a fully running asynchronous client. It's obviously nowhere near feature complete, but as you've been following along, hopefully you've seen that we've sort of built all the internal infrastructure we wanted for the asynchronous stuff.
04:46:08.547 - 04:46:37.445, Speaker A: And you even saw just how simple it was to change from create to exists. It's very straightforward. And of course the hope would be that adding the other methods should be as well. There is still some more complication in terms of adding things like watchers. So if you look in the original API, there's also this notion of you can give it a watcher and. No, that's not it. There's like a way where you can.
04:46:37.445 - 04:47:17.523, Speaker A: Yeah, Listener I think is the one. So you can basically set it to watch or listen for changes in a given path and you'll be notified whenever that path changes. And of course, the way we could implement this is you could call watch on some path and it would give you back a stream over stats of that path, for example. Right. So that would be a way in which the user we could actually give a nicer API than what you can currently get from the current crate because we can integrate all of these very nicely. I think we're going to probably call it right around there. Is it Pub Sub? Yeah.
04:47:17.523 - 04:47:58.617, Speaker A: So I think with the Watcher API you can basically use Zookeeper as Pub sub, except that it's not quite Pub Sub. It's whether a given path has changed, so the contents of a path or its flags. It's not like you get an infinite queue that you can just keep pushing things to. You can watch a given path or I think you can watch anything under a given path. But I'm not sure we'd have to dig into that more, although hopefully. So one of the. So one of the reasons why I want to stop here is we've been running pretty long and we've sort of gotten to cover most of what I wanted to cover today.
04:47:58.617 - 04:49:12.595, Speaker A: The other reason I want to stop there is because the stuff that we've covered so far has basically been independent of Zookeeper. It's mostly been about like, how do you implement a protocol, how do you implement it Async, how do you use Tokyo on top of that? And sort of how do you package this and test this? At least in a somewhat trivial way. But the core that we have for Tokyo Zookeeper now is actually pretty solid. Like the way it's implemented internally, it's internal state machine is now extensible to the point where we could add another method or two and they were pretty straightforward to add to the existing setup. And so that means that the next stream in the series will probably be adding a bunch of the different methods and see how they tie into the infrastructure we've now built. And also add things like Listeners and Watchers and other things that are more Zookeeper oriented as opposed to just sort of like almost general protocol level infrastructure. In fact, one thing that would be really cool is if there was a way to take essentially the packetizer that we have and write it up in a more generic way so that you could have any protocol use this as its internal state machine.
04:49:12.595 - 04:50:01.905, Speaker A: But I think that's a. That's a task for a much later and different time. All right, I think that's where we're going to call it for today. If you have questions about as well, I'll push all the changes and, and maybe tidy up some of the debug output, but I'll push all of that. And if you have questions about the stream for today, if you have questions about Zookeeper or the implementation we're doing or upcoming streams then just ping me on Twitter or on Patreon and I'll take a look and try to get back to you. My plan going forward is that the next stream will be on this as well. It looks like it might be feasible for us to get pretty far with this library over the course of one more stream but I think it will be at most two more streams of this.
04:50:01.905 - 04:50:36.375, Speaker A: I also want to do some more things on standard library implementations like try to implement our own Mutex maybe, but there are a lot of cool projects we could tackle so if you have ideas for that as well then let me know. I hope you've found it interesting and educational and feel like you were debugging with me as opposed to just watching me turn my hair out. But yeah I think that's all for today. Thanks for coming out to watch and I'll see you next time I hope. All right, bye.

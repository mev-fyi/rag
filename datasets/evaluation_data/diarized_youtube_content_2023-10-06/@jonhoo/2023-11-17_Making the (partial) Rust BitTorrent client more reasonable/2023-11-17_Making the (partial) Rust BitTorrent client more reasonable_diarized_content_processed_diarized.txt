00:00:01.120 - 00:00:47.457, Speaker A: Hi folks, welcome back to another stream. This one's a follow up from the previous one where we, well, I'll show you. We implemented our own BitTorrent client by following the sort of sequence of challenges from a website. And when we were doing that, I thought it was a lot of fun. But when we got to the end, it felt like the code was written as though it was following a sequence of challenges. And I started thinking about, okay, how would I restructure this code in order to like, if I, if I were to build this for real, right? If I, if I actually wanted to build like a real BitTorrent client, how would I restructure the client? So I'm not talking necessarily here about like implementing all of the features of the protocol. Like that could be its own kind of interesting.
00:00:47.457 - 00:01:56.671, Speaker A: But even just the code that we have so far for, you know, splitting a file into these chunks, identifying how to download each chunk and you know, which sub blocks exist within each piece, that sort of stuff, all of that code was very like top to bottom imperative. And I wanted to think a little bit harder about how we download things in parallel, how do we prioritize which things to download first and in particular how do we structure the application in such a way that doing that is easier. Right, and that's what I want to take some time on today. So this time it won't be as much really guided by the challenges, because there's only one challenge left, which is download like a file which is just not. Like we might do that accidentally as part of this, but there are no steps guiding us to this. This is really just a sort of restructuring thing. The existing code is on GitHub and if you watch this after the fact, I guess you will end up seeing the code as it is at the end of the stream.
00:01:56.671 - 00:02:29.015, Speaker A: So I guess go back to this commit B7624AE and then that's where we're going to start out the stream. My drawing tablet is not working for some reason at the moment. It blinks up, it shows it's detected in Linux and everything. But for whatever reason, if I do anything on it, nothing happens. So where we need diagrams here, I'll try Excalidraw and see how well that holds up to this. Okay, so let's close this one. I'll leave this one just in case we want to actually do the challenge.
00:02:29.015 - 00:03:08.985, Speaker A: But I don't feel too compelled to that. So let's drive straight into the code here. So if you remember from last time, let's do a quick little recap. We have a main here which is the sort of entry point for the code crafters like BitTorrent Challenge. So it basically asks you to make a binary and they call the binary in different ways depending on which challenge you're in. So you see under command here we have like this I think is like step one through or challenge one through five. I don't remember the exact mappings right, but each one of these correspond to a challenge.
00:03:08.985 - 00:04:08.177, Speaker A: The last moment that we did last time was download piece where so a torrent file is logically it like tells you about which files are in the torrent, which and how many pieces is it split into. So the logical way that BitTorrent file works, in fact, maybe this is a good drawing candidate. So if you think about a BitTorrent file or really just a torrent, the torrent is like a little pointer thing over here. Oh no, I want another square over here. So the torrent file is a little thing over here. And logically what it does is it describes like this box kind of describes this one. And what this bigger box is is it's simultaneously a bunch of files and a bunch of pieces.
00:04:08.177 - 00:04:44.241, Speaker A: So what actually happens is that this is, you know, this might have a file hierarchy internally like slash. Oh, I want this to be left aligned. So logically inside of it it might have, you know, slash foo or at slash. Maybe it has foo text, maybe it has/bar/baz.text. maybe has/quarks/text. Whatever, it doesn't really matter. But it might have a bunch of files.
00:04:44.241 - 00:05:02.945, Speaker A: But logically it is single. It is encoded as just a single giant blob. And blob here in the sense of like a sequence of bytes, it is a single blob of bytes. And then what actually happens is that this is subdivided. I don't think I can actually use that one. I'll. I'll draw it out instead.
00:05:02.945 - 00:05:19.545, Speaker A: In reality what happens is that this file is further. Is. Is really just split into pieces. And I want these to be. I want my text further forward. It's fine, I'll. I'll make do.
00:05:19.545 - 00:06:37.841, Speaker A: This is where I would really like to just have my own drawing thing. But it gets split into pieces that are all of the same size except for one that is sort of the remainder. And then what this file list actually does is this file list is stored as a mapping of the bytes in the giant blob. So for example, it might say somewhere that food text is stored at bytes 500 to,008, right? Baz TXT is stored at 1090 to or depending on what we call these exclusive ranges, or not 1089-2 or 4096 and aux TXT is stored as 4096-8000 or whatever. Right? And so as a result, what you really need to do if you want to download a particular file from a torrent is you need to look at, okay, what is the byte range of the overall blob? Make sure that you download. Like, you know, if we imagine one starting to count over here, the diagram is a little weird at the moment, but like, if you imagine byte 1 is here, then byte 500 might be somewhere around here. Let me draw here what that might look like.
00:06:37.841 - 00:07:32.265, Speaker A: So let's say this is byte 500 and let's say further that over here is byte 1089. Then in order to download Foo TXT, you would need to download this piece and this piece and then read the end of this piece and the start of that piece. So that's the mapping from files into a giant blob. Right? And so it's a really fun puzzle problem in a sense, to figure out which files to grab out. Of course, if you want to download all of the files in a torrent, then it's much easier, or reasonably much easier, because you just download all of the pieces and then you stick them all one after the other and maybe write them to disk or something. And now you have like the entire torrent file. And then if you want to extract any particular file, you just pull out those bytes out of the giant blob by just by indexing.
00:07:32.265 - 00:08:51.985, Speaker A: It gets more interesting if you want to say only download food Txt, because in that case you don't want to download these two blobs or these two pieces because they are unnecessary. And then of course, this gets a little bit further complicated by the fact that each piece consists of multiple blocks, blocks looking like this. So basically every block in here, like, so every one of these is subdivided into blocks, and all the blocks are of the same size. And the, and what's the only thing that's guaranteed is when you try to connect to any given peer in the BitTorrent network, if they say that they have a particular piece, that means they have all of the blocks in that piece. But what you can do in order to speed up your downloads, right, is let's say you wanted to download this piece, you could get this block from one peer and simultaneously get this block from another peer. And so in theory you might get higher performance because you're polling now in parallel from multiple hosts, so you're not limited by the upload speed and any given other peer. So that's the sort of rough idea of why there are these two levels of division.
00:08:51.985 - 00:10:08.561, Speaker A: And currently what we built last time was this ability to download a particular piece. But of course, all of this infrastructure that I've talked about of like you might need to download multiple pieces, the mapping from file names to parts of a piece, even just downloading multiple pieces in parallel, downloading multiple blocks in parallel, which pieces do you download first? None of that we've implemented. And if we try to implement that in the way that the code is currently structured, I actually think it would be fairly annoying because when we look at the code here, if we look at like the download piece one, which is the most complete one that we have, right? It's really just an imperative piece of code. So it reads out the torrent file, it decodes the torrent file into like a torrent descriptor, which has information about what pieces there are and what files there are, for instance, and then it talks to the tracker, which is the. There are basically two modes for torrents to operate in. One is where you download all of the information about who has which piece from other peers, and the other is one where you talk to one server and say, hey, who has this piece? Who has that piece? It's that second mode that is all we support for now. And we're not going to change that in the stream.
00:10:08.561 - 00:11:05.121, Speaker A: I think we're just going to stick with the tracker based approach. So you contact the tracker and you get the information back from the tracker, which then tells you the hashes of the different pieces and who has that piece. So that's this tracker response bit that tells you what peers there are. Then we do a handshake with basically a randomly selected peer among the peers. And once we've done the handshake, now we have a connection with a single peer, and then we establish this encoded channel with them over tcp and then we send a message saying which pieces we want to download, like which pieces we're interested in. Then we tell that peer that they should start sending us data, and then we start reading out the data one block at a time. And after all of that we stick all the blocks together and then we hash them and then we write that out to the output, right? Which is all fine.
00:11:05.121 - 00:11:59.219, Speaker A: Like that is the sequence of steps, but it's not really how you want to describe this. The Moment you want to say download multiple pieces, right? Or map files to pieces. That's what we're going to do today, right? Is figuring out how to structure this in a less insane way. And so the way I actually want to go about doing this is I'm going to add a new bit here that's gonna be download. It's gonna take an output, it's gonna take a torrent, it's not gonna take a piece like so. And when I find here download piece. That's this one.
00:11:59.219 - 00:12:36.747, Speaker A: Yes. So download this and here's. So I've done this on a couple of streams before. I want to write the code that I would like to be here by the end. Right. What I would like this to look at is probably something like let torrent is torrent read of the torrent file. Right? That's probably going to return an error of some kind that we would want to lift Torrent read.
00:12:36.747 - 00:13:18.965, Speaker A: Sure. We can let that be async. That's fine too. And then I would want something like from this I would like to be able to print out torrent tree or maybe this even looks like print tree, right. So I want some way to basically print out. At this point I should know what all the files are, right. And then I should be able to do something like torrent.
00:13:18.965 - 00:14:35.913, Speaker A: So I think I either want the ability to do download all which is going to download everything into output, assuming that output is a directory, or I want the ability to say download some where I'm going to give something like I guess an iterator. We kind of have to decide what we would like download sum to look like. I was imagining something that's like impl iterator. So in this case it could be something like vec of output Assuming here that no vec of maybe tuples actually maybe this is the way it should look like. And then there could also be a download single if we really wanted that to be the case to output. Right. So all of these modes should be supported by whatever this torrent type is.
00:14:35.913 - 00:15:25.599, Speaker A: And you can imagine that internally. Right. These are all going to require in fact download single could return bytes. Now that I think about it like there's a way here in which we could say download all sort of to file. Right. But you could also imagine that we have a something like this where what it internally stores is the entire byte structure and the file list separately. And then, you know, in files you can then do something like for file in files or something.
00:15:25.599 - 00:15:44.749, Speaker A: Right. So. So this is really an iterable and actually maybe we just want to support Download all for now, and then we could. We could improve that with some kind of filtering later on, like only download the following ones. Maybe this is a nice interface. Actually, maybe I. Maybe I'm happy with that.
00:15:44.749 - 00:16:27.345, Speaker A: So here you could imagine that you can pass in a set of filters over the files that you want, and you could do that based on the output of print tree, for instance, and then Download all to File would basically be a variant of Download all. Great. So then we could, you know, std FS or I guess Tokyo FS write to output files.iter.first or something. Right. And you could even think. So files ITER is going to give us an iterative list.
00:16:27.345 - 00:17:00.093, Speaker A: Next is going to be the first of the files that are in there. Expect always one file and I want the bytes for that file as opposed to, for example, the name. Right. So this I think. And then you could imagine that Download all to File is really just going to walk this iterator. And there are some optimizations here, like maybe you write directly to disk rather than buffering them in all in memory. But that kind of optimization I don't think we need to worry too much about.
00:17:00.093 - 00:17:31.435, Speaker A: So maybe Download all to File actually internally just does this. It iterates over files and for each one it writes the. The corresponding bytes to disk. In which case Download all to File is not that important because Download all is the one that does all the. All the heavy lifting. So I think that's what I would like this to look like. And so now we can actually start to construct it so that it looks that way, if you remember the code structure that we have.
00:17:31.435 - 00:18:29.355, Speaker A: Yeah. So like, the reason why you wouldn't actually, the reason why you might want to optimize this further, right, is you could imagine that there are downloads that are many, many gigabytes large and you can't actually store them all in memory, in which case you might actually have to stream the individual pieces to disk. You actually kind of always have to, just because if you want to be able to resume seeding them later, for example, chances are you want the pieces on disk anyway. So we could make it so that what Download all will do is it will always store the pieces to disk and it might cache some of them in memory. That's also something that's totally fine for us to do here, but I'm going to treat that as a sort of implementation detail. So inside of source, you see we have main, which is this binary, we have lib and if you look at Lib, it's really just a bunch of sub modules. Peer here mostly holds the data types for interacting with a peer.
00:18:29.355 - 00:19:23.765, Speaker A: So things like the handshake message and what fields are in there. But it also holds definitions for message, like the kinds of messages that you can send, as well as the encoding protocol for sending and receiving messages from a given peer. Torrent mostly has the information that's actually stored in the torrent file, which is primarily the URL of the tracker. So this is where we get information about what peers are connected, as well as this info thing which holds information about basically which pieces there are in the file and which files there are. So whether it's a single file or whether it's a sort of multifile packed thing. And so this is all just like information about a torrent. And we can reuse this type as the, as the outer type of torrent.
00:19:23.765 - 00:20:23.525, Speaker A: Here we just need to add a read method, which should be straightforward enough. And then in addition to Lib, we have tracker, which has all the types that define how we interact with the trackers. In particular, what does the request we send them look like, what does a response look like? And that's mostly it. It has some special deserialization and serialization logic which we don't need to talk too much about here. We sort of figured that out last time. Okay, so before I go on, are there questions around like this structure of this is what we want to get. Does the implementation of each type of download function differ? Well, so the, the hope if we did have like download all to file, download all, download some, download single, the hope is that behind the scenes they all invoke the same logic.
00:20:23.525 - 00:21:10.197, Speaker A: And really what they do is they just differ in like avoiding to download pieces that aren't necessary for that particular download and sort of massaging the output or the result of what we download into a more convenient format for that call. So they're really mostly convenience functions. Disk sizes should be U64. I don't think there's a disk size here. Have you tried any other challenge? No, I haven't tried any of the other code crafter challenges. We're not directed by what codecrafters asks now. I don't think they have multifile torrents at all.
00:21:10.197 - 00:22:07.903, Speaker A: That's right, yeah. So at this point, the goal of this is not necessarily to meet any particular challenge. The goal here is just to structure the actual implementation of this crate the way that I think it should be done. If we were to do this more Sort of for real. Okay, so let's go ahead and start with the pub fan or I guess async FN read. So this is going to take a path to the torrent file and it's going to return, I suppose a anyhow result of self and I actually don't know. Oh, we did bring in anyhow.
00:22:07.903 - 00:22:42.445, Speaker A: Great. And for most of these, at least in the beginning, the hope would be that we can just take out parts of the original code that we had here and just stick it in there. Right. So this is going to be. This is async, right? Yeah. Okay, great. So we can just take the code from download piece which has a lot of the sub parts here and stick them into reads in particular here we're going to read the torrent file, we're going to parse out the torrent out of there and then we're going to return the torrent.
00:22:42.445 - 00:23:55.611, Speaker A: Great. And then what was the next thing we wanted? We wanted print tree to be something that you can do on a torrent. So we'll do fn print tree of self and what that's going to do is we'll probably need a helper function here which takes a subtree and we'll figure out what that. What goes there in a second. So the things that we have inside of self, right Is so we have the name which is the name of the top level thing. So I guess here we could say if let keys single file is self info keys. So if it's a single file, then all we really need to print here is the name.
00:23:55.611 - 00:24:43.457, Speaker A: So self name which is the name of that single file. And I guess we could actually match here instead. If on the other hand this is a multifile, then there's this files list that we then need to operate on. And so if we go down to files here for the purpose of the other keys and info, the multifile cases treated as only having a single file by concatenating files in the order they appear in the files list. Right. So this is how we get to that mapping of byte ranges. Right.
00:24:43.457 - 00:25:40.475, Speaker A: Is that the. In the overall blob that we have, the single overall blob, the files are laid out in the order dictated by this part of the of the torrent file. So they must be in this order. And for each file we're told what its length is. And so what we can do up here, given that we're we're just going to print the files, we might not even need subtree because there's no Notion of subtrees here we're just going to do for file in files eprint line file path. And you can imagine turning this into a more structured format, right, to actually store it as a tree basically. But given that the way it's stored in the torrent is really just as a linear sequence of paths, feels reasonable to just print out that list of paths here too.
00:25:40.475 - 00:26:24.243, Speaker A: Okay, so that's print tree. That's easy enough. And so now we get to download all. Okay, so obviously download all is going to be somewhat complicated. So download all is going to take a reference to self and it's going to return a downloaded. I suppose. Yeah, that feels fine.
00:26:24.243 - 00:27:21.155, Speaker A: Okay, so what would download all look like? We're going to need a downloaded type here too. And I think actually I want all the logic for downloading to be somewhere else. So what we'll do is we'll use super downloaded, downloaded or download. And then I want this to actually say download all. And then I want to make a new module here called download. Then I want all the logic that has to do with downloading to live over in that module. Okay, so we need an async fn all which is going to return an anyhow result of downloaded.
00:27:21.155 - 00:28:50.109, Speaker A: And this is obviously where a lot of our logic is going to live. Right? And we're going to have a pub struct downloaded. And what do we want that to support? Well, we want to implement into iterator. I can't type into iterator for a reference to downloaded where the item type. So the thing that this produces when you iterate over it is a reference to a file into iter is going to be download iter. Yeah, like so intuitor self returns self intuitor. So this is just to satisfy the sort of last bit of this, right? The ability to iterate over the files in there and grab each files bytes downloaded iter new of self and then we're going to need a pub struct downloaded iter which has a.
00:28:50.109 - 00:29:24.965, Speaker A: This is a lifetime reference to the downloaded. So what downloaded is going to hold at the end, right, Is going to hold not pub. It's going to hold a thing that holds all the bytes. And we might optimize this beyond having it be a VEC of U8. Right. You could imagine this being references to files. Instead you could imagine us using the bytes type so that we can easily grab out or merge together pieces without having to do a lot of mem copies to do maybe bytes.
00:29:24.965 - 00:30:29.765, Speaker A: It's from the bytes crate and we have the files list which is a vec of file which we're going to get from create. Whoa. There's a lot of these I want to use crate torrent file. This is going to hold the veca files and a downloaded iter is going to hold a file iter. It's going to hold a downloaded which is a reference to the downloaded so that we can get out the bytes. A file iter which is going to be a vec. I guess actually it's a slice iter a file.
00:30:29.765 - 00:31:09.495, Speaker A: Right. So this is an iterator over this files list and also an offset which is how far we are through bytes. So remember that for. For the any given file, the the location of that file in the bytes is the sum of all the lengths of the files that came before it. So we need to keep track of that. In theory we can instead keep an iterator over bytes. But I actually think offset here is going to be nicer.
00:31:09.495 - 00:32:08.895, Speaker A: And then we'll impull downloaded iter. We'll impel new and that's going to take a downloaded and return. A self downloaded is going to be d file iter is going to be d dot files iter and offset is going to be zero. And then we're going to implement iterator for iterator for downloaded iter. The item here is going to be a d of file. I actually don't think it's going to be a file. It's going to be a downloaded file which is a type we don't have yet.
00:32:08.895 - 00:33:09.275, Speaker A: And next is going to be let some file isself fileiter.next let else man instead of this actually I can do let file is dot next? Because option implements try. So the next file we're going to get at is this one. And the bytes for that should be self downloaded bytes. And we want that starting at self.offset and ending at self.offset/File. Length those are the bytes for this file.
00:33:09.275 - 00:34:20.275, Speaker A: And then we want to return some of downloaded file of file and bytes. And then of course that means we're going to need a downloaded file type which is going to have a pub struct file which is a file and a pub bytes which is going to be a. It's going to return a downloaded file D like so same thing up here. It's going to return downloaded file like this. Great. And we could have these be accessors instead if we really wanted to. So we could impl downloaded file.
00:34:20.275 - 00:35:29.575, Speaker A: And then if we look back at our Main what do we want here? Well, we wanted bytes at the very least. So we probably want something like path which returns a str, which is solve.file.path. why is that a vec of string? Oh, the paths are stored as. That's fine. So that's something that will actually be different in our torrent here is that this files list what file here actually is or what file path is. It's a vector of subdirectory names. So we'll actually want to join this by path main separator string.
00:35:29.575 - 00:36:05.975, Speaker A: So we're going to join it by slash basically, which is fine. And we also want bytes which is going to be the U8, which is self bytes, like so. Oh yeah. The trick with byte offsets is nice. So we can do this instead, which has the same effect, this one. Right. So we first slice from the beginning and then we slice to the end just so you don't have to repeat.
00:36:05.975 - 00:36:50.807, Speaker A: Self offset has the same effect. It's a nice trick. Okay, so now we have roughly what we want the returned things to look like. And you see the main thing that it needs is this file list which we get from the torrent and the bytes which we get from downloading the pieces. You could imagine that this is actually a V of peace which is really where you get in the bytes type, right? So if this was a vec of peace, then now suddenly the iteration logic becomes more complicated because you might. It becomes sort of obvious that the bytes for a given file might actually overlap multiple pieces. So then how do you bring them together? And so that's where something like the bytes create would come in.
00:36:50.807 - 00:38:04.653, Speaker A: But for now let's just stick them all in a single accuate and then we can improve afterwards. Okay, so it still raises the question of how do we actually do this download? Well, let's assume first that we're going to download everything and then we can refine the code afterwards to support filtering. Which things do you actually download? Well, we know that there is. This is where we'll go back to our main and grab the other bit of code here from download piece. So here, first thing all is going to have to do is it's going to have to grab the information from the tracker and I don't think we actually need that connection to necessarily stay open. The connection to the tracker that is. So this is actually something that could go in tracker where we could say tracker response.
00:38:04.653 - 00:38:55.545, Speaker A: Right. We could implement for tracker response Pub or Async fn. It doesn't even need to be Pub query. And so this code that's going to take a torrent and it has to send a request that has to give some peer ID for ourselves, which is fine. Port uploaded, downloaded aren't relevant here. Compact one is fine left. Here is the number of bytes left to download, which in this case is really the entire length of the torrent.
00:38:55.545 - 00:39:59.685, Speaker A: And I forget whether we actually need to compute that or whether the torrent will say use create torrent Torrent. So if I go over here and go to info the number of bytes in each piece. So that's just the size of the pieces but I think we actually need to compute it over the keys case I think it actually needs to be the sum. So what we'll do here is, we'll do. We'll have another sort of helper function here on torrent which is length, which is then match on self.info.keys and if it's this then that's just the length. Otherwise it's files.iter.map
00:39:59.685 - 00:41:03.171, Speaker A: file file length, sum. So the sum of the lengths of all the files is the total amount of the total length of the bytes in this torrent. And so that's what we're going to tell the tracker that we need to download. Now obviously here, this would change a little bit once we start seeding as well because then you might query the tracker and tell it that you or have a bunch of data. So we're not really dealing with resumes yet, but I think it should be relatively easy to modify this to allow resumes later on. Okay, so right, this is where we like URL encode the stuff to the tracker. I remember this was a bit of a pain last time.
00:41:03.171 - 00:41:19.437, Speaker A: We decode the tracker response and then tracker info is the thing that we give back. Great. So we now have a. This can probably be a pub crate. We don't want it to be fully public because this, I think this type isn't even public. Oh, it's public domain. Yeah.
00:41:19.437 - 00:42:05.195, Speaker A: But we, I don't think we actually want this to be. Yeah, we might start using this remain actually just to get information about a torrent, but for now let's keep it internal to the crate. So now that we have that, we can say that this is going to say peer info is going to be tracker response. Or you could even imagine this is just a freestanding function rather than being tied to tracker response. But I don't think it's super important. So we'll use here tracker tracker response. So this is going to use Query of oh, all needs to take torrent.
00:42:05.195 - 00:42:51.555, Speaker A: So it needs to do a query. We'll give some context here. We'll say query tracker for peer info. Right? So if we now go back to torrent, so download all here, we're going to pass in self and this we said which is going to be pubcrate instead. So the way that you access it is through the download all method on torrent. Okay, so we have the peer info. Let's go back to our main and see what we do next.
00:42:51.555 - 00:43:51.405, Speaker A: Now that we have the peer info now this is information about actually connecting to the peers and requesting the particular piece that we were after and all of the blocks in that piece. Okay. So this logic is very linear at the moment. And in reality what we want here is something like especially if we know we're going to download all of it, we sort of have two decisions to make. One of them is which piece do we download next? And the second one is which peers do we download from. Once you've decided to download a particular piece from a particular peer or a particular set of peers, then that, that part is easier because it's just you enumerate all the blocks and you request all the blocks from some number of the peers and then you're good. So I think what I want to get at here is I want to do this sort of inside out, which is let's assume that we have picked a piece to download and now we want to do the download of a particular piece.
00:43:51.405 - 00:44:40.165, Speaker A: So let's, let's encode what that might look like. Let's do something like ASIC event download piece. And so if you're told to download a particular piece, what information do you need? You're going to need. If we look up here, this is just grabbing out the peer info, which is not the bit I want to look at. I want to look at. We're interested is the thing that we send, we send unchoke, right. We send a request for a particular piece from a particular peer.
00:44:40.165 - 00:45:12.327, Speaker A: Right? Because we request. Yeah, we send a request for that particular block of that piece. And so the only thing that we really need in order to download a given piece is sort of a list of candidate peers. And I think the peer information here, if I find that. Right. Is peer here. This is the socket adder.
00:45:12.327 - 00:45:37.355, Speaker A: Great. So candidate appears that we could download a given piece from. And I think that's really it. Oh no. And we need the piece length which we probably extract here somewhere. Right. The piece hash and the piece size are the two things we need.
00:45:37.355 - 00:46:25.847, Speaker A: So the piece hash, which I think is just a UA20 and the piece size. And we'll figure out what this returns. I might change the signature a little bit later, but that's all the information we should really need in order to download a particular piece. Right. And then if I now say let's extract this further. So download piece block from. So this is going to be even more like this is we've picked a peer and we want block I and we want.
00:46:25.847 - 00:47:09.923, Speaker A: And we know the block size. What does that look like? And I don't think actually we want these functions is more. I'm trying to break this down into what are the, the smaller pieces. The reason I don't think we actually want this structure quite is because it is because you are probably going to have persistent connections to a given peer. You, you want to basically have a state machine that owns the connection to a given peer rather than like connect to it each time you want a particular block from one. So let's. Do we have a peer type here? We do.
00:47:09.923 - 00:47:47.555, Speaker A: Right. We have a piece which is information about the piece. We have message tag, but we don't actually have a peer type. So I think what I want here is a pubcrate peer type. It has an adder which is a socket adder V4 and it's a state machine that we're going to want to keep track of that state machine I think. But let's do impulpeer new and I have a stream which is going to be the. In main here.
00:47:47.555 - 00:48:37.315, Speaker A: When we connect to a peer we get one of these things. The peer here is the actual connection. It's a framed TCP stream with message framer. Framed TCP stream with message frame. So we're going to have some first class primitive of an ongoing connection to a given peer. Great. And that's this bit that we could just grab.
00:48:37.315 - 00:49:21.427, Speaker A: And so this is going to look like, oh, all right. We actually have to do the handshake. This is going to say, you know, peer. It's going to be a. We could be even nicer here but let's say socket adder V4 for now expected bang. Oh, struct. So in order to construct a new peer connection we're going to give in the peer address, connect to it, do the handshake and for these we could relax these a little bit.
00:49:21.427 - 00:50:25.755, Speaker A: So currently like if the handshake length is not the expected length or if this is not bitorrent rather than assertequal here we could use Anyhow, ensure, which is a macro that ensures that basically it's like an assert, but instead of panicking it returns an error. If this is not the case. Okay, that's fine. Then we establish the connection and here too. Anyhow, ensure and sure, I can't tell. And assuming that's all good, then we return self, which holds the adder, which we might not even need. And it holds the.
00:50:25.755 - 00:51:31.591, Speaker A: Well, I guess this is pure adder and the stream here is peer something else missing, which is the info hash has to be passed in here, which is the. Just to make sure that the peer actually has the same block contents we expect. Okay, that's too much spam in chat. Bye. Great. So we now have a thing that can establish a connection to a given peer. And the way to think about one of these peers is really that it keeps track of the connection we have to that particular peer and will do things like download a block if we tell it to do so.
00:51:31.591 - 00:52:35.773, Speaker A: Now the way that we want to do this is probably we basically need to think about whether we want to allow a given peer to be told to download multiple things or whether a given peer should only be allowed to download one thing at a time. I think we probably want it to be one thing at a time for now. So there's going to be an async FN download and it's going to take immutable reference to self. It's going to take a. I think it has to take a piece I, a block I and a block. Does it even need the block size? It doesn't need the block block size and it's going to return hopefully an anyhow result of vec of U8 typo. Socket outer V4.
00:52:35.773 - 00:53:22.835, Speaker A: No, I think that's right. Oh, socket outer V4. Nice. So what will download look like? Well, we already actually kind of have download here, which is this. Right. So again I'm just sort of splitting up the code that we had just in a long iterative mess in main and turning it into a more structured way of talking about persistent connection to appear, downloading a given block over that connection, and so on. So constructing the request here is.
00:53:22.835 - 00:54:08.295, Speaker A: Why does this say block max? Oh, right. Because the way you actually frame the request is you say I want to download starting at this byte offset and ending at this byte offset. And so the block I is going to be multiplied by the size of the blocks and the block size is needed because most blocks are size block max, but the last block is smaller. So we need to know the actual Block size. So often this will be block max. Great. Then we send a message here, then we await the next message from the peer.
00:54:08.295 - 00:55:39.747, Speaker A: And I guess we could do for all of these to really anyhow ensure like this. Then I suppose this can really just be piece, dot, block and it's really vec from this. Okay, I'll back from this. So the. This piece is basically the payload that we get back here from the peer. That payload is a vector of U8, but it's structured like there's a bit of header information and stuff. And so we ultimately want to get out just the block that holds the real data and then turn that into a vector.
00:55:39.747 - 00:56:26.385, Speaker A: Technically, we might be able to do this in a slightly more efficient way by allowing the. We could return like a thing that just ignores all the header bytes and then lets you iterate over the bytes that follow, just so we don't have to do the MEM copy. But I'm going to allow the MEM copy here because it's for a given block, so it's fairly small. I think this is probably okay. And it makes the interface a lot nicer. Okay, so a given peer we can now tell to download something and they will do. So I guess the other thing we need to decide here is around this interested and unchoke and I think.
00:56:26.385 - 00:56:59.125, Speaker A: All right. Right. So this is also something we have to think about, which is this bit field. So the peer tells us which pieces it has available and it might not have every piece. So I think. And then that's represented in the bit field here. Bit field.
00:56:59.125 - 00:57:40.335, Speaker A: So I think we actually want to keep track of that one. That's not right. All right, where is the torrent specification? I don't remember. The URL to it is this one. No, it's not 00, it's 03. All right. And then we'll also do this to make people happy.
00:57:40.335 - 00:58:34.525, Speaker A: So trackers, connections, peer messages, bit field. It's payload as a bit field. With each index the downloader has. With each index the downloader has sent set to 1 and the rest set to 0. Downloaders which don't have anything yet may skip the bit field message. First byte of the bitfield corresponds to indices 0 to 7, from high bit to low bit, the next one 8 to 15. Okay, so the bit field is really a.
00:58:34.525 - 00:59:53.465, Speaker A: We're going to have to structure this one a little bit. But the bit field that we get back from payload bitfield, payload like so why is my completion not working? Whoa. It's very unhappy about a bunch of things. Let's do a cargo update here and a cargo check and see if it gets happier. Whoa, Rust up update maybe too. Oh, right, There's a new rust version, isn't there? Let's see. Come on, Rostop.
00:59:53.465 - 01:01:07.465, Speaker A: So my thinking here was over in peer, that we're going to get this actual bit field. We're going to turn that into a type that lets us actually inspect the bit field in a less inconvenient way to figure out which pieces a peer has, so which one it's a candidate for downloading from and also whether it has a given piece. The two are sort of synonymous here, right? And then we can make use of that in download to basically for each piece, figure out which peers are candidates to download from. Let's now see if we get this to do something useful. Now, is it happy? It's happier download? Okay, it's not happy about this one. That's fine. But at least now I'm getting error messages, so that's a start.
01:01:07.465 - 01:01:51.245, Speaker A: Oh, this should be not context but a result. And then yes, I need to import this. Yes, I need to import this. Yes, I need to import this. And bit field we don't have yet. And bitfield payload is the one that I wanted to. Why does it not understand what type this is? Interesting.
01:01:51.245 - 01:02:46.257, Speaker A: Block max is stored in main. It should not be in main, it should be in peer. Okay, and this one here should say self stream and same here because it's this peers stream. Okay, so now there is a bit field crate. I don't know whether it supports this because it's a little bit of a weird mode. The payload here is a vector of U8s, right? Like the. If we look at the spec, the response or the contents of a bit field message is a bit field.
01:02:46.257 - 01:03:37.425, Speaker A: So each bit corresponds to one piece with each index that the downloader. So I assume the downloader here is the peer has the downloader has sent. I assume it means these are the. These are the pieces that I have. As in the peer that you're talking to says these are the ones that I have. The first byte of the bit field corresponds indices 0 to 7 from high bit to low bit respectively. Okay, so what that means is if we implement here on bitfield we could have a pubcreate FN has piece where the piece I is a usize and we turn a bool.
01:03:37.425 - 01:04:51.295, Speaker A: And what this is telling us is that we want the for piece I, right? We want the ith bit. So let byte is going to be piece I divided by 8 and let bit is going to be piece I modulo 8, right? So. So the byte is which of the chunks of 8 bytes and the bit is what's the remainder. When you do modulo 8, that's the bit within the byte. And the bit here is bit counting from high, right? Because the spec said indices zero to seven from high bit to low bit. And so what we want is, we want to. I guess we can just say let some byte is self payload get byte.
01:04:51.295 - 01:05:50.071, Speaker A: And it's certainly we certainly. Or that peer certainly doesn't have it if there's no such byte self. Oh, right. And then to get the bit, what we'll do is we'll do. We'll do byte ended with one to left shifted by bit. No, I want right shifted. So if we have a byte like 1, 2, 3, 4, 5, 6, 7, 8.
01:05:50.071 - 01:06:35.301, Speaker A: If we have a thing like this and we want to know whether the nth bit is set, then if it's the nth bit from the right, then it's 1 left shift n right, which is going to be. Let's say it's three. Then what we want is the third from the right, which would be one shifted left by three. So the number this would generate is this one. And if we end this with this, then what we end up with is in this case, one as in it has the thing because these two are both one. I'm lying. This is shifted left by three.
01:06:35.301 - 01:07:25.109, Speaker A: Now I'm confusing myself if I do themes. Just do Solarize dark. Why not? Why am I opening the playground when I have rust locally? Yeah, fine. Is it colon b1 left shifted by 3? Yeah, so 1 left shifted by 3 leaves 3 zeros behind. So it shifts 3 over right. So if for n equals to 3, it's going to end with 1 shifted over by 3. In this case that's 0, which means that we don't have the piece.
01:07:25.109 - 01:08:17.165, Speaker A: But in this case what we want is we want right shifted by one. And I think so there are a couple of ways to do this. One of them is 1.rotaterite bit plus 1. And so what rotate right does. Now let's take use rotate right shifts the bit to the right by the by a specified amount, wrapping the truncated bits to the beginning of the resulting integer. Right? So what this will do is it will rotate the.
01:08:17.165 - 01:09:06.363, Speaker A: So it'll take one which has only the rightmost bit set. In fact, we could make this instead be one if we wanted to avoid the plus one here, we could make this. We could make this be 1 left shift 7, but it's not actually that nice. So we're going to rotate right one. So one has the last bit set, right? If we rotate that by one, so the plus one bit, that means this is here. And then we rotated another N bits where that's the bit we're looking for. So if we're looking for bit zero, we will not rotate anymore.
01:09:06.363 - 01:09:52.815, Speaker A: And so the one will be in the right place to do the end if the bit is 2. If the bit is 1, then we want the first bit from the left, not the 0th, in which case we'll rotate one more time. We'll get the right one, right? So this is going to end up ending the right bit. At least I think it will. And then we're casting that to a bool. And the way this cast to a bool is going to work is if any of the bits are 1, then the resulting bool is true, right? And the only way the Resulting byte is 1 is if the one bit from our shifting here aligns with a one bit in the input, which is the pieces that we have within that byte. So this should tell us whether it has a given piece.
01:09:52.815 - 01:10:57.255, Speaker A: Similarly, we could also do this your size, right, which is tell me all of the pieces that you have. And so for this one, what we'll do is bit is piece. We can just do four. Piece I in. Yeah, so someone said in chat, why not just seven, right, shift by bit? Well, you could, but I actually think this one's easier to read. Like, I think this one's also right, but I think this one is easier to reason about. So that's why we have a couple of ways that we could do this.
01:10:57.255 - 01:12:25.717, Speaker A: I think what I want here is actually byte and bytei in self payload iter enumerate and. And then actually don't know whether that's nicer. So the piece I of the leftmost bit in this byte is going to be byte I times 8. And then we're going to mask is going to be1.rotaterite1. And again, this is probably just going to be optimized by the compiler to be equal to 7, right? And no to 128, right? Which. So the leftmost bit in a single byte being set. Unless I'm.
01:12:25.717 - 01:13:18.245, Speaker A: Now I'm confusing myself, but I think that's true. Right, so if I say 128 here, so that's 1, 2, 3, 4, 5, 6, 7, 8, right? So 128 is just the leftmost bit set which is what we want. Right? That's the leftmost bit of a byte. So we could write 128 here, but I actually think it's clearer to make it one rotate right one. As long as this is a U8 to be clear. And so then we're going to do. And here, to be clear, we could do this.
01:13:18.245 - 01:13:55.055, Speaker A: They are equivalent. And then what piece I is plus equals one. And in fact this could just be. This could just start at 0, in which case we don't need the byte die anymore, in which case we don't need the.it error. We can just do this. And so that's the impliterator done it.
01:13:55.055 - 01:14:29.433, Speaker A: This is where I really want generators. Right. Like this should be a generator and it is not. That's fine, I suppose. Fine. We'll write this as a damn iterator.iter. flatmap bytes and then we'll do 0 to 8.
01:14:29.433 - 01:15:16.695, Speaker A: Makes me so sad. 0 to 8 dot map. Oh, I wanted so bad. All right, enumerate flap map. Byte. Byte I. We could have a manual implementation of Iterator here, and it might actually be nicer, but it's fine.
01:15:16.695 - 01:16:30.799, Speaker A: So this means we move in the bit I. And now the piece I is going to be byte I times 8 + bit I. And the mask is going to be 1U8 rotate right by 1 + bit I. And to be consistent with the code above, let's just make these be all at least consistent within the same part of the file. Rotate right bit I. And then the result of this is going to be the byte ended with the mask, not bit one, bit I. Is there any way to make the magic digit 8 in Hass pieces? Oh, this one? Yeah, this U8 Bits.
01:16:30.799 - 01:16:54.745, Speaker A: Fine, I'll use U8 Bits. Fine, fine, fine, fine, fine. So the associated constant bits with a given integer value tells you how many bits are in that integer value. So I mean, yes, that. Sure. Now it doesn't say eight. I understand.
01:16:54.745 - 01:17:52.691, Speaker A: Okay, so we want to do this. And so now this is the kind of thing where I really want to test that that actually does the right thing. Bitfield has. So we're going to do bf is Bitfield payload is going to be a VEC of 0B 101010100101010101. And then I want to assert that it has. Right. Are all of these 1, 2, 3, 4? Yeah, 8 1, 2, 341 2, 3 4.
01:17:52.691 - 01:18:44.225, Speaker A: Yeah, great. So we want to assert that it has pieces zero that it does not have pieces one. We also want to assert that it has piece. It does not have piece seven. Right, because this would be P7. We also want to assert that it doesn't have piece eight, because this would be piece eight. And we also want to assert that it does have piece 15.
01:18:44.225 - 01:19:59.769, Speaker A: Okay, so that's this one. And then we can do the same for bit field iter and then I want to do VF dot pieces like so. And here's what I want to do with this one. I want to we in this case it's short enough that we could assert all the way through. So normally what I would do here, right, is I would write something like I would just do an assertion over the iterator that it alternates to something. But it's short enough here that I kind of just want to write them out. So we should expect to get some piece 01 and then let me.
01:19:59.769 - 01:20:33.037, Speaker A: Right, so this is byte 0, 1, 2, 3, 4, 5, 6, 7. So this is 7. What? Oh, damn it. This is number 0. This is number 7. Right. So number 7 should be 0 and then number 8 should also be 0 and then it should continue.
01:20:33.037 - 01:21:12.401, Speaker A: So this is 9, 10, 11, 12, 13, 14, 15. Let's see what that does. I checked God bolt and the optimizer gets rid of the modulo because rotate. Right. Doesn't actually care since the rotation is modulo 8 as well. Yeah, I generally just like assume that the compiler gets rid of a bunch of these and I would and therefore I would rather write it in a way that it's easier to read than optimize for. Than optimize for what the compiler might produce.
01:21:12.401 - 01:21:49.405, Speaker A: Like I just sort of assume that the compiler is smarter than I am. I cannot find function URL encode Interesting. What? Oh, right, forgot we had to do an ugly thing with URL and code use. Anyhow, context. That's fine. Wallace, does it want. It wants path.
01:21:49.405 - 01:22:27.095, Speaker A: That's fine, you can get path. What else we got read is I want to pass in that actual path self.info name use anyhow, context. This needs to await what else we got downloaded? I want to import that. This is an await. We're getting there. Can I cargo test now? Okay.
01:22:27.095 - 01:23:02.765, Speaker A: Not quite yet. No method context found for results because we need to use any how context. That's fine. All right. And I need these bits for this to be happy. This needs to do this. This needs to pull in sync and stream X.
01:23:02.765 - 01:23:41.293, Speaker A: Okay. This is in fact a function that we're going to need over here, which is from payload, which just self payload. So that constructor is easy. We're getting pretty close. Can I multiply U32 by usize? That's fine. Can't compare. All right, that's fine.
01:23:41.293 - 01:24:03.755, Speaker A: These can all be usize arguments. And I realize that these Maybe should be U64s because they're file file offsets and those are usually U64 rather than usize. So that if you were to compile this on a 32 bit platform, you'd actually get the right behavior. We can do that later. It's more. We already have U sizes a bunch of other places. And so I would do that just separately.
01:24:03.755 - 01:24:36.343, Speaker A: Has. I should just say has. Peace. Cannot add U32 to U8. That's fine. What? Oh. Cannot multiply U8 by U32.
01:24:36.343 - 01:26:14.835, Speaker A: Okay, thank you. Expected U8 found U32. Is that because what it's very confused about the types here. 32 as U32, I guess actually as US because PCI here is US expected bool, right? So this is going to be bool from expected U32 found usize by tier is a U8 and this is a U8. Right? So I'm pretty sure I thought bool implemented from U8. Is that not the case? Because if so, that's kind of silly. From.
01:26:14.835 - 01:26:47.639, Speaker A: Okay, I want the opposite set of implementations. I guess not, huh? All right, I guess we'll cast it has Bullshit. Fine. Not equal to zero. That's fair. Bit I is now a U size. Yes.
01:26:47.639 - 01:27:43.047, Speaker A: U32. That's fine. As U32 cannot. Yeah, yeah, I did do that tonight. See, here's what I want, okay? MPs I modulo u 32 bits as usize. And then I want that whole thing arguably as a U8, but it has to be a U32 because that's the argument that rotate. Right.
01:27:43.047 - 01:28:40.539, Speaker A: Takes. That's fine. Payload get blind. Actually, that's fine. So this one can just stay in USIZE land. Now this one's a bite I here. Why is that a reference to a U8? It's a move closure U8 U8, I guess.
01:28:40.539 - 01:29:35.281, Speaker A: Actually this is a U size because I think that's what enumerate produces. Oh, it's because I have these backwards. Glad I checked. So enumerate produces pairs of I and val, where I is the current index and val is the value returned. Glad I checked that. Cannot add U32 to usize. So byte I here as a usize, this as usize, which really means it could arguably be usize from usize and bit I here is U32.
01:29:35.281 - 01:30:31.845, Speaker A: That's fine. Okay, now can I test it? Oh, expected to be a closure that returns usize but returns U8. If byte mask not equal to 0 and in fact, if we want to be real ugly here we do, then. Nah, fine. It's because this needs to be a filter map. Because if the if the mask is not equal to zero, then we want to produce piece I. If it is equal to zero, then we want to produce none.
01:30:31.845 - 01:31:05.375, Speaker A: Hidden type captures lifetime that don't appear in the bounds. That's fine. Yeah, because this iterator actually consumes or continues to reference the payload until the iterator has been consumed. And yes, I know. I held a talk recently where I told everyone that this is wrong. It still works, so it's fine. Okay.
01:31:05.375 - 01:31:54.765, Speaker A: Mismatch types in download, that's fine. Downloaded bytes todo and files todo are almost at the point where we can run those tests and see if I got it wrong. How about now? Torrent cannot move out of self. That's fine. Same thing here. Great Lib don't care about main. All right, we're getting there.
01:31:54.765 - 01:32:21.335, Speaker A: We're getting there. So let's see this bit field. How's it doing? Iteration complaints at line 135. The first one. Good. That's always good. It gave a zero.
01:32:21.335 - 01:32:49.325, Speaker A: Should have given a one. Okay, so we fucked up something. Pieces. We iterate through the bytes left to right. We iterate through the bits left to right. That's because I'm stupid. The things that are yielded here are the ones that have a 1.
01:32:49.325 - 01:33:36.205, Speaker A: So the output here is not the bit, it is the index of the piece. So the pieces that have ones are pieces 0, 2, 4, 6, 8, no, 6, 9, 11, 13 and 15. And then we should get none. Sweet. Okay, so this bitfield thing is right. That makes me happy. And so now we should also be able to say here.
01:33:36.205 - 01:34:26.589, Speaker A: Anyhow, ensure that self.bitfield. has piece piece I. So if you now try to download a piece from peer that doesn't have that piece, we'll return an error. Beautiful. Okay, so that's the stuff we want to do with the pier. And there's one more thing which is around this. If we look back at our main, back to where we originally were, when we connect to a peer, we send it an interested and we send an unchoke.
01:34:26.589 - 01:35:09.421, Speaker A: So the question is, should we just do that when we first connect to the peer? Let's go. Look, downloaders generally download pieces in random Order, which is a reasonable good job of keeping them from having a strict subset or superset the pieces of any of their peers. Choking is done for several reasons. TCP congestion control behaves very poorly when sending over many connections at once. Also, choking lets each peer use a tit for tat ish algorithm to ensure they get a consistent download rate. The choking algorithm described below is the currently deployed one. It's very important that all new algorithms work well.
01:35:09.421 - 01:36:09.547, Speaker A: Both a network consisting entirely of themselves and a network consisting mostly of this one. Unchoking the four peers which has the best download rates from and are interested. Peers which have a better upload rate but aren't interested get unchoked. And if they become interested, the worst uploader gets choked. Okay, so this whole algorithm here about how you choose to choke. So the question then becomes, how do we want to represent this? I think what I want to do right now is. I see.
01:36:09.547 - 01:37:08.839, Speaker A: So interested. So what's the actual meaning of interested here? Connections contain two bits of state on either end, choked or not, and interested or not. Choking is a notification that no data will be sent until unchoking happens. The reasoning and common techniques behind choking are explained later. Data transfer takes place whenever one side is interested and the other side is not choking. Okay, so I think what this means is that we can always send unchoke, because what we're saying with unchoke is and this is going to be bad for us, but it's still okay for us to do it, which is if we unchoke, it means we are willing to send you things. That's what an unchoke does, which doesn't matter because we don't have seeding implemented at the moment.
01:37:08.839 - 01:37:32.215, Speaker A: So we will send an unchoke saying that we're. We're willing to send you things. Interested. We should only send if we actually want data. Transcript. One side is interested and the other side is not choking. Interested must be kept up to date at all times.
01:37:32.215 - 01:38:59.355, Speaker A: Whenever a downloader doesn't have something they currently would ask a peer for, if unchoked, they must expect lack of interest despite being choked. Okay, so it sounds like what we want to do here is on a given peer connection, if there's something that we want from that peer, if they're willing to give it to us, then we should mark ourselves as interested on that connection, which means we shouldn't mark ourselves interested unless we're willing to download something from them. Okay, I think. I think I know what I want to do here. I think I know What I want to do here, but I'm going to write the code slightly starting in the other end. So we're going to go back to download here. And what we want download to do is figure out which pieces to download next and then figure out how to get each such piece by marking all the peers that have that piece as we're interested and the moment they get an unchoke, then sort of set up the download from that peer.
01:38:59.355 - 01:40:29.919, Speaker A: Okay. It'll be clearer than code, I think. So this is in the all function, right? So this is assuming we're going to download everything, we get the peer info and what we will want to do is dig out all of the pieces and decide which piece to download next. And I think the way we want to decide that is we're going to keep a sort of need pieces and I think this is going to be a binary heap so that we can prioritize which pieces we try to download next. And initially what we're going to do is for piece in. And this is the logic in main and I guess. Do we already have a piece? No, we don't.
01:40:29.919 - 01:41:33.463, Speaker A: Great. So I want to go to Lib and I want to create a piece thing and a pub struct piece has a. It has a list of peers. And what are the peers indexed by? The peers are in. I think it's by their peer id. Yeah. So the peer list is just a, is the vector of addresses.
01:41:33.463 - 01:42:23.521, Speaker A: Right. So the peers. This is like the peers that have this piece and its I and its length. I know this should be U64. I'm ignoring that for now. And it's hashtag. And then I think what we'll want to do, we'll derive debug Partial eek Eek Ord.
01:42:23.521 - 01:42:58.411, Speaker A: Partial ord. No, actually I don't want to derive those. And then I want to implement partial ORD for peace. In fact, I want to implement ORD for piece. And the reason I want to do this is because I want us to. So we're going to keep a heap of which pieces we're going to download next. And we want to.
01:42:58.411 - 01:44:10.707, Speaker A: I think we want it so that you generally pick random pieces, but that you pick the pieces with the fewest number of peers first. And this is sort of a distributed systems thinking kind of thing where if few people have it, then you should add to the list of people who have it by downloading it yourself and then sharing it sooner because the fewer the peers, the higher the risk is for that piece to essentially go missing. So you should participate in the network and sort of do gooding here, in which case what we want, and I think what is binary heap? Binary heap is a max heap. So by default it picks the values, the sort. The next thing you get out of a heap, it's whichever value has the highest ordering, the greatest ordering. But when you derive partial or an ord, it orders the fields in this order, which is not actually what we want here. I think the order we want is self, peers.len
01:44:10.707 - 01:45:19.167, Speaker A: compare with other peers.len. then I want us to order by self. If there's the same number of peers, then I kind of want us to give a random ordering. But that's not a thing that Rust really likes for you to do, because if you order randomly, every time you get into this really weird situation where you might sort an array and it assumes that the sorting function is deterministic because it might compare the same element multiple times. So if you sort randomly, a bunch of algorithms are just not going to work anymore. So I almost wonder whether we want like a seed here, which is just going to be a random number. Let's say use 64, which we're going to use to ensure that we randomly select pieces if they have the same number of peers.
01:45:19.167 - 01:46:13.685, Speaker A: And this is basically to distribute load. If everyone chose to, let's say, order by number of peers and then by the hash. If every implementation did that, then everyone would choose to download the same hash next. And so you end up with this, like, contention in the network that is unnecessary. So I think what we want to do here is then self seed, self seed, compare other seed. And then, you know, we can compare all the other fields too. The, the remaining fields here basically aren't interesting anymore here because the seed is probably going to be different each time.
01:46:13.685 - 01:47:47.185, Speaker A: So we could do hash length, pierce, piece, pierce, it doesn't really matter. And then we can also implement partial or, which we can trivially implement by saying sum of self compare other. So anything that is or does trivially also partial ored by the same ordering function. Okay, so what we now want to do is something like implement piece pub create f a new piece I as usize. And I guess this is really going to take the torrent. No, it's going to take the. It's going to take a reference to the peer info info and a reference to the torrent, which is the tracker response, and it's going to return itself.
01:47:47.185 - 01:48:33.521, Speaker A: What is the difference between ord and partial or partialord is a partial ordering. And so with partialord you're allowed to say that some elements just cannot be compared to each other. Like neither is greater than the other. And ORD is a total ordering. So every element has a well defined ordering with respect to every other element. So for example, for numbers, they implement ORD because every number can be compared to every other number and it produces is definitely a greater than, less than or equal. A partial ordering is something like logical timestamps.
01:48:33.521 - 01:49:34.745, Speaker A: Like if I do a thing and then I do thing number two, then thing number two happened after thing number one. So thing number two in this, in some sense greater than thing number one. But if you and I do two things concurrently without talking to each other, then those two events time wise are not ordered relative to each other. Like your event is not greater than my event, the timestamp of your event is not greater than my event, and vice versa. Logical time as a very brief description of partial ordering versus total ordering. Okay, so the things we're going to have to pull out of here in order to construct one of these pieces is the piece hash. The piece size and the length here is T Length.
01:49:34.745 - 01:50:14.465, Speaker A: Oops, Slough. So piece I we have length is piecesize hash is piece hash. This doesn't need to be a reference. Seed is going to be a random number. And here we could use something like was fast rand? Is that the. Oops. Nope.
01:50:14.465 - 01:50:53.395, Speaker A: Fast rend I think it's called fastrend. No, that's not the one. Random sort by recent downloads. And I want. Maybe it is fast rend. I specifically want something that doesn't have a bunch of dependencies. Yeah, that's fine.
01:50:53.395 - 01:51:56.505, Speaker A: I thought there was another one too. That was like the one used for quick check. Yeah, but what is the quick check one? Doesn't really matter. I suppose that's fine. I'll take fastrand Cargo add fastrand. So seed is going to be fast rand random youth32u64 any range. And the peers.
01:51:56.505 - 01:53:10.245, Speaker A: Peers here is going to be T. No, it's going to be peers.peers.0.itermap no.iter.map. filter map in fact.numerate enumerate. Filter map peer I and peer and we're going to filter by whether the peer has piece piece I then sumpeer I bit fields. Oh, this actually needs to be.
01:53:10.245 - 01:54:16.305, Speaker A: Ah. As this is where this gets awkward is that we don't know which peers have which pieces until we start talking to them, which means we don't actually know, so it's hard for us to tell in advance how many peers have a given piece? Because the only way that we can know that is by connecting to them. And it might even change over time. Right. Peers might gain pieces as they themselves download things. So this raises an interesting question, which is peer list. So I think what we need to do is we need to pick a random set of peers that we initially connect to.
01:54:16.305 - 01:55:37.699, Speaker A: And so that's going to be something like peerinfo peers0.iter.take3. This is basically how many peers are we willing to connect to at once? Let's say five. Map. No, I think I actually want this to be a vecneer and then I want for peer in peer list dot push peer new of peer. I guess this is technically an adder, which might make our life a little easier.08 with context connect to peer Actually we can do even better than this, which is if let. Ok, we can even match on this because if a peer.
01:55:37.699 - 01:56:07.895, Speaker A: If we fail to connect to a peer, we don't actually want to exit the program. Right. Peer. And if we get an error then we could actually just like sort of fail to connect to peer. Peer adder. Yeah. And like this is realistically something where we would probably let.
01:56:07.895 - 01:57:29.371, Speaker A: We would probably let users indicate the setting. Right. So if peer list dot length is greater than or equal to 5 to do user config, then break import peer and we are also supposed to send in the info hash peer info info hash so that we can also do that here. And I think peer new probably only needs a reference to it. I guess not. That's fine. It can get it.
01:57:29.371 - 01:58:03.669, Speaker A: It's. This can get the actual address. So yeah, the problem with this is we're not actually connecting to these in parallel. All right. To do in parallel. In practice we can. I guess we can do this a little bit better because we were already in an async context.
01:58:03.669 - 01:58:52.665, Speaker A: So we could do peerinfo.peers. where it gets awkward with doing this concurrently is you don't know when you've had enough. So if you do this concurrently, I guess you might just drop the connection, which would be. Okay, that's fine. So here's what we'll do then. So I think in. Is it in Tokyo? There's a.
01:58:52.665 - 01:59:35.167, Speaker A: Where is this thing? It's in task join set. No, it's join set. Yes, you can stick a bunch of futures in there and they all get run. The thing here though is we want to limit the concurrency here so that we don't simultaneously try to connect to all of the hosts. And pick whichever first five to respond because that is probably going to get us banned in a bunch of places. Right. I don't know whether this has like a limit supported like max concurrency kind of thing.
01:59:35.167 - 02:00:25.955, Speaker A: I don't think it does. So we might actually have to use in futures util. There's a tool for this that has its own set of problems. But we can use futures unordered here, which not futures unordered. Sorry, where do we have it? Stream X. So if you have a stream which is arguably just an iterator, you can do dot where are you for each concurrent is not the one I want. I want buffer unordered an adapter for getting a buffered list of pending futures.
02:00:25.955 - 02:00:49.245, Speaker A: Oh actually I. Yeah. So the return stream will be a stream of each futures output. No more than N futures will be buffered at any point in time and less than N may also be buffered depending on the state of each future. And so this lets us do the basically what we want. And I did. I already have futures util here.
02:00:49.245 - 02:02:00.533, Speaker A: I do, yes. Okay. So in that case if I just pull in futures util stream stream X then now I should here be able to do iter and then we're going to have to do futures util stream iter to turn the iterator into a stream. And then we are going to map the peer adder into a peer new so it becomes a future. And then we're going to buffer unordered five user configurations. And then what I want here is let mute. So that's the.
02:02:00.533 - 02:02:47.025, Speaker A: That's the stream. And then while let some peer is peers.next awaits. I guess I could do copied here, but it's fine. So what this will do is we're creating a stream over all of the addresses for each one when it gets. When it gets pulled into the buffered unordered. So we construct a future for each one.
02:02:47.025 - 02:03:21.767, Speaker A: But constructing the future, if we go here, constructing the future does nothing because this constructs a TCP stream connect. We could do this. We could enforce that this is actually does nothing by doing this. So this is going to guarantee that this future does nothing until the first time it's pulled. And we say that at most five of these futures should be running at any given point in time. We can make that less too. Right.
02:03:21.767 - 02:03:41.079, Speaker A: So that we don't connect to too many more than we need. And then. But we can keep it five. That's fine. And then we're just going to read the. The outcome of the stream which is Going to be just whichever futures complete first, which is whichever peers we connect to first. And we match on that peers connection.
02:03:41.079 - 02:04:38.535, Speaker A: If we fail to connect to one, that's fine, we don't really care. And we could here also say let peer is equal to this. And we're going to return peer adder and peer like so so that we can give error messages about which peer we actually failed to connect to. And then we can do e to print out the actual error that we got. If we got a peer out of there that we successfully connected to, we add it to the list. If the list is long enough, then we break. And when we break here, we also drop the peers list of futures so that all of those connections are also just thrown away.
02:04:38.535 - 02:06:00.185, Speaker A: So now we have a peer list, and now that we have an actual peer list with open connections, then now we can use the piece thing to pass in the list of peers. So this will not actually be the tracker response. This will be a list of peers. And in fact, if we go to peer here, I think the this has piece thing is actually something that can be a function on the whole peer and not just on the bitfield subfield, which is not public. So if you have a peer, you can ask whether it has a given piece. Great. So now when we construct a piece, we can have it know how many peers have that.
02:06:00.185 - 02:06:47.093, Speaker A: And that can go here. Expected vecu size. Right. So this needs to collect. Excellent. So if we now go back to download, then now we can do need pieces extend of Actually, I guess, I guess really what we want to do now is do the whole same thing as we did in main, which is to figure out how many pieces there are. Actually, I guess we know how many pieces there are.
02:06:47.093 - 02:08:36.115, Speaker A: So for piece I in this, for each one, we're going to say piece is now going to be piece new of piece I reference to the T reference to Pierce this thing. Oh, peer list. I guess here we could also do peers as peer list. So many ways to spell peer peers and then need we could even do here if peace dot well, what's trickier too is that if something has no peers, then we don't have a way to download it. And the only way to download it is to connect to more peers, which is a little bit awkward. So we're going to want something here that's sort of in the background, maybe sort of randomly reaches out to new peers. Hmm.
02:08:36.115 - 02:10:30.737, Speaker A: But okay, so in theory we'll do need pieces dot push of piece. And then now that we've added all of these and what I was thinking here is that we kind of want something like no peers and if and I guess this is something we can do on piece here is something like pubcrate has. So we could do here. If piece peers is empty then no peers piece else need pieces push piece. So what we could do here is while we could stick this whole thing in a while loop or in fact it would have to be like this whole thing out here. We basically need something to make sure that we have at least one peer for every piece. But I'm going to skip over that for now because I want to get to something more complete and then we can refactor it to take into account that case.
02:10:30.737 - 02:11:50.735, Speaker A: So for now we're just going to assert that no peers is empty and this is obviously a giant to do and then what we'll do is while let some next piece is need pieces pop we will. So at this point we now need to figure out where we download each blob from or each block. Sorry. So it's going to be this bit piece dot a piece and peers is messing me up real bad. So I want. This is another helper that I want here which is length. It's going to tell me piece dot length like so.
02:11:50.735 - 02:12:40.035, Speaker A: Oh, where did we stick block max? It's in peer. Why is it in peer? Ah, I think this actually goes in library. That's what I think. So here we're going to import crate block max and then we can do the same thing in download. Block max comes from crate. Great. And the piece size.
02:12:40.035 - 02:13:26.697, Speaker A: Yeah we can track that in here. This is let piece size is piece length. So you know every piece consists of a bunch of blocks and here we have a list of all of the blocks and we also know all of the peers that we're. We could possibly iterate over here. Right. So let mute peers is going to be. See I don't need it to be mutable.
02:13:26.697 - 02:14:07.475, Speaker A: I just want to do peace.peers.iter so this is the peer I. Right. And what I want to grab out is a mutable reference to and it's not going to like this at all. What I really want to do right is peers of peer I. This is going to complain about multiple borrows. It doesn't yet because there are other errors.
02:14:07.475 - 02:15:57.005, Speaker A: But this is going to complain about the fact that I'm borrowing peers multiple times because it doesn't know that the the peer eyes are non overlapping. There are a couple of ways to deal with that. The easiest one I Think is actually for peace to hold a hash set of peers and you'll see why in a second. So if this holds a hash set of peers, hash set of this, what's it complaining about? Hash set Usize is not an iterator. I mean, I agree with that. What? Wait, what hash set does it not implement? I don't think hash set implements ord. Why does hash set not implement ordinary? Why can you not order hash sets? That just feels like an unnecessary restriction.
02:15:57.005 - 02:16:49.161, Speaker A: Can I order their iterators? I can. Okay, great. That's good enough for me. We're basically never going to get to that part of the comparison anyway. I guess it could be a B tree set instead of a hash set, but it's complaining about complaining a bunch of download. That's fine because now what we can do is instead say peers.it or mute which gives us a ref.
02:16:49.161 - 02:17:43.165, Speaker A: A mutable reference to each element. Enumerate dot filter map. So this has an I and then it has a mutable reference to the peer. And now we can do if Peace.Peers contains I then Peer.Collecter. really? Then some pure I. So what this is doing is the.
02:17:43.165 - 02:19:28.545, Speaker A: The iter mute on vectors knows that it's allowed to yield mutable references to all the elements separately because it knows that everything it yields is an independent element that it is allowed to give out mutable borrows of each element concurrently, or not concurrently, but rather it's okay to give out immutable reference to the first element and the second element both at the same time, which is effectively what the iterator ends up doing. And so then we can filter that iterator based on only the peer eyes that appear in the peer list. And the reason I wanted this to be hash set instead of a vector is because otherwise we would need to search the vector every time for the element. Whereas with a hash set we can just do contains. Oh, it's because iteration isn't defined. You're right, iteration is random for hash sets, which now that I think about it, might actually be the only randomness that we need. Right? Like that just means that we can really order here by that and then we don't need the seed because iteration order of hash sets is random of hash set to avoid deterministic contention.
02:19:28.545 - 02:20:45.365, Speaker A: So that way we no longer need the seed here, which means we no longer need Fast rand. Nice. I'll take it. Right, so now we have a list of the. We have a mutable reference to each of the peers that have this particular piece. And then what we want to do is we want to download all of the blocks and I want to map block I here. Great.
02:20:45.365 - 02:21:46.037, Speaker A: And then I want to map that again. I guess I can just map it once. So I kind of want. So we're trying to download all of the blocks and what we actually want to do is. Not quite this. What we actually want to do is make. This is where the un choking comes in.
02:21:46.037 - 02:22:53.729, Speaker A: We want all of the peers that have. That have this piece mark themselves as interested and request some subset of the block. But if a peer is choked, then we want another peer to take over that block instead. So it's like one way in which we could do this, right, is we pick a random peer like rand.rand choose or whatever of peers and then we just send the request to that peer and then we do all of these in parallel. But I don't think that's actually quite what we want to do. Instead we.
02:22:53.729 - 02:23:43.225, Speaker A: We kind of want these, these peer instances to cooperate, right? Because they need to keep track of who's responsible for getting which block. So in a sense it is like a work stealing pool of if some peer is trying to like basically we. We enqueue all of the blocks and then the peers just take. Whenever they get unchoked, they take the next block and they try to download it. I think I'm liking this. I think I'm liking this. So what we would do is we would create a work queue and a work queue in this case is really just a channel.
02:23:43.225 - 02:24:44.673, Speaker A: So let's do. Yeah, so we want an async channel here and I think we want. So we want a work stealing channel, which really means we want an MPMC channel, which. What channel do I want to use for this? I like Thing Buff, which I think gives you MPMC Thing Buff. Ah, but I think Thing Buff does not give you. Yeah, it doesn't give you an async version of this because the only there's a. There's an NPSC channel built on top of it.
02:24:44.673 - 02:25:35.695, Speaker A: But that's not quite what we want either because what I really want here is a Async MPMC channel. See what we get. Async channel. Well, but this is a small based one which I don't want for Tokyo Flume docs. Async. Yeah, he uses a sync API, which I don't really want to use. Canal.
02:25:35.695 - 02:26:58.647, Speaker A: All right, Higher is better. Canal Async MPMC Big. All right, sure, why not? Gotta start somewhere. What I actually want is a single producer one. Actually. No, I need a Multi producer. So the reason I'm hesitating here is because imagine that you have two peers and we have a channel where we send all of the block indices, like all the block eyes we send to a channel that's shared between these two peers.
02:26:58.647 - 02:28:10.375, Speaker A: Imagine one of the peers is really slow and the other one's really fast. So the first one, so they both initially grab a thing from the queue and they both sort of request that and then the fast one completes, takes another from the queue, completes, takes another one from the queue until eventually the fast one is sitting idle and the slow one is still sitting on that one block that initially took. What would be really nice is if there was a way for the fast one to steal the block from the slow one or alternatively for the slow one to time out and then basically deregister itself and stick the. And then stick the. Like if it times out, stick the block ID that it basically failed to get back onto the queue and then remove itself. As a receiver, that's what I think I want. In which case you need an NPMC because you need to be able to have a receiver send back to the others.
02:28:10.375 - 02:28:45.021, Speaker A: Is Tokyo Sync Broadcast good enough for this? I thought many values for many producers to many consumers. Each consumer will receive. Each value is the problem. So when you send one thing, it's received by everyone, which is not actually what I want. Right. I want. When you call receive only you get that one because you are responsible for downloading it.
02:28:45.021 - 02:29:08.365, Speaker A: So it's not quite the same. Oh, Canal is pre. It's very early version. I just want. I know there's also no, it's none of these. It's in crossbeam. There's like a work stealing cube, but it's not async.
02:29:08.365 - 02:30:06.295, Speaker A: All right, all right, Canal, see what you can do. So here's what I want. I want a TX and an RX or let's call it submit and tasks is Canal. I think it's. I think this can be bounded, actually bounded async because we know how many blocks there are. Great. And then here's what I want to do.
02:30:06.295 - 02:30:52.105, Speaker A: Join set here is going to be. So if you remember from the Tokyo docs, is a join set under task. Join set await completion of some of or all of the tasks in a set. The set is not ordered and the task will be returned in the order that they complete. Now we don't actually care about what they. The completion result for these. Instead.
02:30:52.105 - 02:33:39.755, Speaker A: Here's what I'm thinking, here's what I'm thinking How do I connect into. Okay, I create the set first so join set new. Why is this not giving me completions anymore? There we go for peer in peers and then I want to do something like participate and I'm going to give it submit and tasks and I want joinset spawn async move. In fact I don't think the move here is going to matter so I want join set dot spawn yeah, so I want to spawn all of the peers participating in this and then I want to for block in this. So I'm going to basically enqueue a job for every block submit dot send block I guess await and then this is what the receiver is going to do. So it's going to be something like 37 so on the peer side and I guess I can generate this from here. Apparently not.
02:33:39.755 - 02:35:48.905, Speaker A: Pubcrate async fn participate takes immutable reference to self it takes a submit which is a canal async sender of you size and a tasks which is in canal async receiver of usize and inside of there it's going to do something like I get while let some block is tasks.receive.await right. So it's going to continuously receive tasks that it's going to download from this channel and then it just constructs a request, sends that request on its own thing, waits for the response, pieces it together and then does something with the result. And what it does with the result I haven't quite decided yet. It might just be a vector of these full responses. Yeah, in fact, in fact I think I want another one which is finish and done. This is going to be a finish here which takes a piece.
02:35:48.905 - 02:37:51.625, Speaker A: Right. So the idea here is that if you actually get this then you send the. This is just used for assertions so that's fine. Then you send the piece over here and then I think what we'll do is probably this await. So here we should have a timeout and return block to submit if timed out here and then on the receiving end. So we're going to send out all the blocks and then we're going to have a loop here which is going to be a Tokyo select over joinset next await or joinset next and done next receive. I mean and this can actually be a Tokyo NPSC Tokyo Sync channel.
02:37:51.625 - 02:41:00.465, Speaker A: NPSC channel and so we can go up here and make that be a Tokyo sync MPSC sender. What is type of piece here? I'm confused. The thing that we get back from next here. Something something's L. Right. So this is going to need piece I and n blocks that's fine piece size okay it also needs the piece size that's fine okay some this is not important I want to get to the good stuff this is self stream and this is self stream and now what's the type of piece Is a message so message is what I want to send here and I suppose this can return anyhow results so if one of these fail like if a peer completely fails in the middle of down only blocks from it we want to eliminate it from the set of peers so that's fine if we get down here then okay great. So this one's now happy task receive returns a result of usize okay that's fine we don't currently use submit because of this to do but the interesting part here should be what do you mean you can't infer the type? Oh, peers here can be a doesn't really back is fine, doesn't really matter and this now needs piece I piecesize and end blocks piece I piece size and end blocks I guess piece that's fine.
02:41:00.465 - 02:46:04.355, Speaker A: Oh I I guess we actually need to show which piece this is so length and index which is self piece I okay so we're going to make all of the peers participate by running this loop Then we're going to send all of the blocks in as jobs and then we're going to observe both the done list and the join set so the reason we want to watch the join set is if a participant ends early it's either slow or failed and here it's you know, I guess this is like message then you know keep track of the bytes in message and where this now gets interesting is all blocks is going to be a VEC of 0u 8 of length piecesize and then if we again go back to our main right we have this code where we figure out the begin and the end so here we want to do this I guess piece is fine here and this is actually a crate peer piece just to be clear and so what we should now be able to do is we find the block of bytes in here and we should then be able to do all blocks sliced from p begin and onwards copy from slice piece block and then we can get rid of the asserts what does this type? BU8 cannot be indexed by range from what? Oh begin as U32 as you size next does not exist for join result what is it then? It's called join next and it's either it's an option result so if this is none Then that means there are no peers. If this means. If this is sum of okay, it means the peer gave up because it timed out and if it's error is the peer failed and should be removed later. Right, so these are the cases for this one. Receive just gives back an option. So that's perfect. And I guess really if we get none back from done if let some pieces piece then this else have received every piece or no peers left.
02:46:04.355 - 02:47:46.265, Speaker A: So let's see, once we've told everyone to participate then we should drop our finish and we also should drop our submit after we've done this to indicate that there's no more inputs of this kind. Any code following this expression is unreachable. Why? Oh, right. So if we get to this, let's break Technically we're going to need to do a little bit more than that. But at the end of this we should now end up with all of the blocks having been filled into this vector and so now we should be able to compare the SHA one. What's the stuff we need to implement to get that we need this and this should match the piece hash which I thought we got from. Right, so in P's we have the index and we also have the #ua20 and so we should at the end make sure this matches piece hash.
02:47:46.265 - 02:48:46.805, Speaker A: Great. All blocks does not need to be set up here. Cannot appears as mutable. Sure we can. Peers was mutably borrowed somewhere. Returning this value requires that peer is barred for static. Why? Oh, this is because.
02:48:46.805 - 02:50:46.549, Speaker A: Damn iterators. Okay, when you iterate over the elements of a vector, then in theory every element that you yield is independent, right? They are independent in the sense that they point to distinct elements in the vector. And it's okay for you to have a mutable reference to the first element and the second element at the same time because they're non overlapping, they're non aliased and in theory this should be fine for iterators too because the iterator should be able to yield elements that are tied to the lifetime of the vector rather than the lifetime of the iterator. But the iterator trait is not was stabilized long before generic associated types which means that if we now look for for vec slice mute so intermute has a mutable reference to the overall slice and it's going to be interesting. Actually iterator no it should yield elements into the vector. So why is it unhappy about this? Basically what I'm claiming here, right, is that if I have a let mute V is a vector that has a 0 and a 1 and then I do iterator is v.it or mute and then I do 0.
02:50:46.549 - 02:51:07.401, Speaker A: Is it.next.unwrap1 is it.next.unwrap. then I should be able to now, you know, do whatever I want here. Like for example, I should be able to do 0 is 1 and 1 is. Is 0. Just to use both of them. Yeah, and that's okay.
02:51:07.401 - 02:52:00.555, Speaker A: So why is this not okay? I wonder whether this requires that. It's static, that's why. So joinset requires that the future you pass in is static and participate takes a mutable reference to the peer, which we get from up here. And the mutable reference to peer is therefore required to be static in order to be passed to spawn for the future that gets passed to spawn to be static, which then requires peers or the borrows from peers to be static, which would require peers itself to be static, which is not. So that's what it's actually complaining about here. I think we can use a local set instead. So in Tokyo there's a.
02:52:00.555 - 02:53:24.905, Speaker A: There's a join set, but there's also a local set, a set of tasks which are executed on the same thread. Yeah, but does it require static though? That's what I want to know. It still requires static. So we either need to move the peer into the future so the participate future would consume the pier and then like return the pier at the end. Or we would need this to just kind of work. I thought there was a way to have one of these that's not static because really what we're doing here is just a join. But I can't use the actual join macro because that requires that you enumerate all the branches.
02:53:24.905 - 02:54:13.835, Speaker A: I basically want like a dynamic join. Right. Which is what I was hoping that join set would give me. But I think join set actually spawns the tasks, which is the problem, because the moment you spawn them, then they are. Then they do need to be static. And I thought local set allowed you to do this, but for some reason it doesn't require send. But it still requires static.
02:54:13.835 - 02:55:08.515, Speaker A: Yeah, I mean there is in futures util there is. Where are you? Is it under future? Is it under future join all? Which does not require static. And we're actually okay with this using futures unordered instead. Instead it just makes me sad is all. But fine. So this is going to be a futures util stream. Futures unordered.
02:55:08.515 - 02:55:46.187, Speaker A: Futures unordered. New participants install push and then participants next. Okay, things are happier now. That's Good. So submit here, clone tasks, clone and finish clone. That's easy. This should be done.
02:55:46.187 - 02:57:13.545, Speaker A: Yes. Sending the blocks, unwrap and drop tasks as opposed to all peers already exited, which actually means we could even do this up here. Expect bound is equal bound holds all these items, right? So we queue all the work, we make all the peers start their sort of work. Stealing collaborative journey. This is basically cooperative multitasking, right? And then we watch for things to finish. If we get a piece, then we're happy. If we've received every piece, then I support.
02:57:13.545 - 02:58:55.545, Speaker A: I suppose what we could do here too is mute bytes received is zero and then we could say bytes received plus equals piece block len. If we get here, we should assert equal bytes received with piecesize. And in fact. Okay, so we're in actually in a slightly awkward place here. We have to be a little bit careful around cancellation because let's say that all the pieces are done here. If all the pieces are done, then we're fine. The thing I'm concerned about is that we drop the future of a given participant while it is still active.
02:58:55.545 - 02:59:48.005, Speaker A: So, for example, let's imagine that I just had a bug here, so I broke here. The moment we get any piece, what will happen is that means that we're going to drop participants without letting all of those futures finish. If we drop participants, then that means that we're going to drop this entire async block, right? This is a future and we would drop that future mid execution, which means that we might drop it here, for instance. So we've sent a message, we haven't received the response. So imagine that we drop the future right here and then we go through another round and now we downloaded a different piece and we try to use the same peer. Well, it hasn't read this thing out yet. So when it starts, it's going to send another message to request something.
02:59:48.005 - 03:01:04.043, Speaker A: But then when it goes to read, it's going to read this, the message that it didn't get around to reading last time because it was canceled. So that's the thing we have to be careful about here. So really what we want to do is make sure that we always wait for all of the futures of all of the participants. And how do we want to do that? And we have to think about the same safety here around dropping the future that we get back from participants next. But I think that's okay because dropping the future from next does not drop the participant future. It just drops the future that looks for the next participant that's ready like Participants itself is not dropped because this. This basically holds on to a mutable reference to participants.
03:01:04.043 - 03:02:17.059, Speaker A: So that part is fine. So I think what we want to do here is if not done dot closed maybe. Oh, where's our canal docs? If I go here to async receiver, what do I have available to me Is terminated. Oh, right. This is actually a Tokyo channel NPC receiver. Wow. There is no is close.
03:02:17.059 - 03:02:48.133, Speaker A: That makes me sad. It's actually okay for us to break here though. We could just repeat this loop underneath. It's just. I would rather not do that if I could avoid it. No, there's a close method, but that's not what I want. I want is closed.
03:02:48.133 - 03:03:46.025, Speaker A: I want to check whether it's closed. I don't want to actively close it, but I think actually. So if we've received all of the done events, I think that has to mean that all of the participants are either peer. So one of these triggers that. Right. And if that means that if we get the end of this, either all of the participants are gone, right? So all of the send handles have been dropped, or there are still some peers that are active and just waiting for more work, which they'll never get. And if future is stuck here, then it's totally fine for us to cancel it because the connection is in a sort of clean state.
03:03:46.025 - 03:04:46.825, Speaker A: So I actually think it's okay to break here. This must mean that all peers have either exited or participations have either exited or are waiting for more work. In either case, particip, it is okay to drop all. To drop all the participant futures. Great. So breaking here is fine, in which case we're going to drop participants. If a peer gave up, then that's fine.
03:04:46.825 - 03:05:47.745, Speaker A: We don't actually need to do anything with that. In theory, we could imagine that, okay, this peer is probably so we shouldn't try it again ever again. But the fact that it's like it is no longer reading from the task queue, so we're kind of fine. The one thing to watch out for here is that we might be in this case. So this is really like if bytes received is equal to piecesize, then great, we got all the bytes, else all the peers quit on us. So we don't actually have to handle this case here because either there are still more peers, in which case they're going to continue to handle the traffic, or there are no more peers, in which case we'll still get into this case and we'll just get into the else case down here. Nothing to do except maybe Deploy prioritize this peer for later.
03:05:47.745 - 03:06:42.445, Speaker A: So like a to do. If we learn that there are no participants next that there are no participants left, this must mean we will. We are about to get none from done receive, so we'll handle it there. Right, because the transmitter for done is finish. Finish is cloned into every participant and then we drop our copy here. So when there are no more participants, that means there are no more send handles for finish, which means that done will return none. So there's nothing to do in this clause because it's the same as this clause and it's just racy which one we hit first.
03:06:42.445 - 03:07:52.875, Speaker A: And I guess this. We only need to think about this branch if this is participants is empty. Okay, so the last case is this like the pier failed. It already isn't participating in this block in this piece anymore. So this is more of an indicator that we shouldn't try this pier again and should remove it from the global peer list to do. And again, if this causes us to have no peers left for this piece, it'll be handled in this case anyway. So these are really more about like peers that we should now think about removing rather than we actually need to do something that's different from this branch.
03:07:52.875 - 03:08:27.675, Speaker A: Great. So this is the only break case. And so what we'll do here is if Bytes receives this, otherwise we can actually do. So there are two things we could do here. We can do the simple thing for now, which is just if we don't didn't get all the bytes because all the peers disconnected on us, we just give up. We just return an error. The other sort of.
03:08:27.675 - 03:09:26.425, Speaker A: Realistically what we would need to do right, is okay, we did connect to all of the peers. Even this is arguably a little overzealous because this should really be. Imagine all of the peers have a particular piece we still don't want to download it from. I guess we're already limiting how many peers we're connected to anyway, so I don't think we needed the take here. But what that means is if it turns out that none of the peers that we originally connected to are accessible to us anymore, none of them are able to give us this piece, then the only thing we can do is connect to more peers, which sort of happens outside of this. Right? It happens all the way up here. So we would need to grab more things into this in the first place.
03:09:26.425 - 03:10:02.031, Speaker A: And we could do that. I think we might actually need a sort of. I think we're going to need a sort of data structure outside of this that lets us continuously populate more. More peers. And the way we might have to do that is using maybe we could do this actually with the tower service crate and load balancing. I'll have to think about that one. But.
03:10:02.031 - 03:10:58.895, Speaker A: But ultimately like the. The recovering from this case is actually kind of complicated. It's like will need to connect to more peers and make sure that those. That those additional peers also have this piece and then download the pieces we didn't get from them. Which also means we don't want to redownload the parts that we have now successfully downloaded because it might be that like before we lost the last peer we downloaded all but one of the blocks. So we actually want to be a little bit smart about how we do that recovery. Yeah, we'll have to think about that.
03:10:58.895 - 03:12:44.205, Speaker A: So in this case I think what we'll do is bail here say no peers left to get piece piece I And the nice thing that we can do now, now that we have this loop I think we can expect here receiver should not go away while there are active peers us and missing pieces, missing blocks. This one is that here we can actually correctly deal with choking too. Because down here I suppose right we can. We can do what we kind of want to do is we want to send I suppose interested when we're asked to participate. And this was in previously in Maine. Right. So we're going to send an interested message.
03:12:44.205 - 03:13:45.061, Speaker A: And now the thing that we're going to need to keep track of is whether we're choked. It's going to be a Boolean. And so initially choked is true. So we can't expect to get one of those. So initially we're going to assume that we're choked. And initially we're not going to say that we're interested in anything. And then when we're asked to participate we're going to send okay, we're interested now and we actually need to be a little smart here which is something like loop.
03:13:45.061 - 03:14:46.733, Speaker A: This has to become a loop. We want if self choked. If we're choked then we need to wait for an unchoke message and I guess here we can match on unchoked tag. Then self choke is false and then we're allowed to keep going on. If it's anything else then this doesn't really help us. Like that means we're still choked. So we can't really send any other messages.
03:14:46.733 - 03:15:19.505, Speaker A: There are other messages here that you can imagine we have to handle. But. But unchoke is really the thing that we're waiting for. If we get anything else, I think we can just ignore it because we know not in a request and if the other side is interested in something, we're not going to send them anything anyway. So I think unchoke is really the only message we can get. We could look at the spec here so we can get. We could get a choke.
03:15:19.505 - 03:16:29.865, Speaker A: We can get an unchoke but we're in the case where we're already choked. So the so we shouldn't be getting another choke message. We can get a choke down here. So I guess this here we should really match on piece tag. And if the message tag is choke then then we should set self choked is true. We should do submit dot send the block right? So we should make someone else take this block instead because we're choked and then we will continue with this outer loop. If on the other hand we get message tag piece then we can.
03:16:29.865 - 03:16:57.805, Speaker A: Then we're fine, we fall through. And if we get anything else, I don't think we should expect anything else. Where's the right. So here let okay. Block. If we get anything else, we're going to break. So at the beginning of the loop we're going to make sure that we're not choked.
03:16:57.805 - 03:18:23.285, Speaker A: If we are choked, then we're going to wait until we are unchoked. And is there anything else we could get interested we don't care about not interested. We don't care about have so have have means peer should now be eligible for more pieces. So that's something that we, you know, might want to handle in the future. So this is like a to do update bit field and to do update a list of peers or add to list of peers for relevant piece. But it still doesn't let us break from this loop because we're still choked. Request we're just ignoring right? Not allowing requests for now piece we shouldn't get because we haven't requested anything and cancel we also shouldn't get because.
03:18:23.285 - 03:19:32.735, Speaker A: Because we're not allowing requests. But actually I think we might be able to get peace. I'll show you in a second. So the moment we break out of this loop, it means that we're no longer choked, which means that we can take a task off the queue. If there are no tasks on the queue, then we can break, right? It means there's no more work and then we do the whole thing to send the request and then what we're going to do is see what we get next. Like so if we get a chalk, if we get a choke, then we have to continue this which is going to be. Then we're going to continue task.
03:19:32.735 - 03:20:19.159, Speaker A: If we get a piece then we can break because we're happy and I think it's impossible for this to have gone away. We still have a receiver, so it's not possible for this to fail. If we get a piece, then we're good. What else can we get after sending a request? I don't think think we can get anything else because we know we're unchoked. I guess we can get the. We can still get have. So this is.
03:20:19.159 - 03:21:02.147, Speaker A: I guess we can do message tag interested Message tag not interested. Like these. We just ignore these. What I actually think I want here is something like pubcreate fn. Well, I'll leave that for now. So these ones can all happen down here as well. I guess I might as well do this right.
03:21:02.147 - 03:22:00.635, Speaker A: So mission tag unchoke should be anyhow bail. Peer sent unchoke while unchoked shouldn't happen. And bit field is sort of the same like peers sent bit field after handshake has been completed. So these are basically like violations of the state machine right from by the peer. And now the interesting part here is. Whoa. Okay, okay, okay.
03:22:00.635 - 03:22:39.059, Speaker A: Peace is. Is this possible? So can we get a. While we are choked, can we get a piece? And I assume that can't happen. Peer sent peace while choked. But what I wonder is imagine that you are currently. You're currently unchoked. Then you send a request and while you're sending the request, the other side unchokes you.
03:22:39.059 - 03:23:34.035, Speaker A: And so it receives the request after it's unchoked, but you, sorry, it chokes you. So you send the request before you realize you're choked. But the recipient receives the request while the choke is still on its way to you. So we then read here out of choke and so we decide to go back up and wait to be unchoked. But the request we sent was still going to the server. Is the server ever going to respond to that request? Like if it decides to unchoke us, can it now decide to send us that piece anyway? Yeah, there's something about the state machine that I don't quite like. Like I think it might need to be more not one at a time than it currently is.
03:23:34.035 - 03:24:12.695, Speaker A: Like I think this actually needs to be like. Like more truly a state machine because like it's a little weird, right? Imagine we get a piece that we asked for ages ago and we thought we were choked. So we thought it wasn't coming. Then if that request. If that peace now comes. I guess we could send it on the finished channel, but it. But we already yielded that block for someone else to be responsible for.
03:24:12.695 - 03:25:04.405, Speaker A: So we, we no longer really own sending that on finish. Yeah, something's not quite right here. Like we can, we can make it work, right? So we can say we can just ignore this piece. Piece that we no longer need slash are responsible for. And we can do the same down here. Wait, no, not download. I don't think we're going to need the download function anymore.
03:25:04.405 - 03:26:13.305, Speaker A: We want participate. So down here, if we get a piece here. So if Ps.index not equal to Ps I or piece begin is not equal to the piece we're waiting for, or those are actually the only two things that really matter. This can actually be an assert. So if either of those are true, then it's not the piece we were looking for. Otherwise it is the piece we're looking for and we can break.
03:26:13.305 - 03:26:45.137, Speaker A: Right. So if we happen to be getting some piece that we asked for in the past, we're just going to ignore it because it's not the one we needed. The reason I say it feels a little weird is because having this twice, for example, reads a little odd. And you could also imagine that you want to support requesting multiple blocks simultaneously. Maybe, but maybe that's also an optimization we don't care about. The fact that we have to duplicate have is a little weird, but. But maybe this is.
03:26:45.137 - 03:27:14.855, Speaker A: Okay, we'll see how it plays out. So if we now go back to download. Actually, we don't need to. I think we did that. So this now handles choking and unchoking gap gets the block, sends the. I guess piece here is really arguably misnamed. This should be message.
03:27:14.855 - 03:27:53.265, Speaker A: And it's a little misleading for the message tag here to be piece because it isn't a piece, it's a block. It's a piece of a piece. But fine. Okay, so now that we have this and we're ignoring those and that's fine, it shouldn't be a problem in this instance. And then we get all of this back. So we now have all the bytes. So bytes here is now going to be all blocks.
03:27:53.265 - 03:29:04.915, Speaker A: And files is just going to be. Oh wait, no, that's not right. So the, the all blocks here is all the blocks for this piece. And so this is where we're going to stick it all in memory for now. But obviously that's not actually what you will want to do is we'll do. Where's the place where we compute the length here. I thought we added that to to the tracker, did we not? I guess we didn't.
03:29:04.915 - 03:29:23.395, Speaker A: Sorry, I mean to torrent. No, we did. Okay. Yeah. So T dot length. So we just create a giant thing of that holds all the bytes of all the pieces. So clearly you would not actually do this.
03:29:23.395 - 03:30:09.075, Speaker A: Right. Like to do this is dumb. But what we can now do is when we get back whatever this piece is, we should be able to do all pieces index it by. Index it by where do we have the piece I. Right, so this is going to be piece.index multiply by the t.info.pl there and further.
03:30:09.075 - 03:31:48.135, Speaker A: Yeah and then we just copy from slice all blocks and in fact maybe the error case we do here is we do something like stick this piece back onto the need pieces heap. Right. So probably also stick this back onto the pieces heap. But after we've done all this and after there there's nothing left in need pieces then now bytes should be all pieces and files should be t dot info. What do we say this should be vec of file which is going to be a match on t.info.keys. right. Where single file.
03:31:48.135 - 03:33:12.665, Speaker A: Then this is going to be a vec of file. Otherwise it's just going to map to files length and the path is just going to be t.info. name great. And why can't I move out of this? I can't move out of this because let me move it as innovariant multifile which is behind a shared reference. Oh, it's because. It's because we're taking in a reference to the torrent is why. So this is going to have to be clone and this is files clone.
03:33:12.665 - 03:33:40.223, Speaker A: Great. And this is length. Yeah, fine. This is length. And now we don't need download piece. We don't need this bit in here. We don't need any of the the download method we wrote.
03:33:40.223 - 03:34:18.115, Speaker A: That can go away because it participate takes care of it and what do we get? Right, so now I think all the errors are in main. So if we get rid of these unused things, tidy up a little bit. Adder is never used, pieces is never used. That's fine. If we now go to main what I want to do for download. Oh right. Source lib.
03:34:18.115 - 03:35:28.465, Speaker A: That's fine. Just so that the old code keeps working. Nice. Okay, so this now builds with the code the way that we had it and I wonder, I wonder if this will just sort of work. I mean I realize this is we wrote a bunch of code that we haven't really tested, but at the same time most of it is very similar to the, to the like, it's sort of copy pasted from what we had before. So the main question is whether this scheduling logic actually does the right thing. So let's do git, add dot, hit commit, first attempt at multipeer file download.
03:35:28.465 - 03:36:17.961, Speaker A: And I just want to see like if we push it up and run the test suite, like does it just do the right thing? There's almost certainly a bug somewhere. Yeah. So someone in chat is pointing out that there's a different design here that is much more centralized. Right. So you have a, that has a sort of central location that knows about the state of every peer, the state of every piece. And then you have a sort of like you have a thing that's responsible for the connection of every peer. And rather than having each peer decide what it does, you just have the central thing.
03:36:17.961 - 03:37:00.899, Speaker A: Say you download this thing, you download this thing and sort of drive the whole thing. And then the peers just blindly do what they're supposed to do or what they're told to do rather. That's fine too. I actually don't think it would be that much nicer, but it could also be because I haven't built it that way, so it's hard to say. Let's see what it says for this last step. I'm curious. Build, build, build, build.
03:37:00.899 - 03:37:30.339, Speaker A: Thank you. Step 18. How many steps are there? I don't remember how many steps there were. What are we here? Step. I don't know what step this is. Step 24 somehow. How many steps are there? What is Codecrafters? Oh, it's this.
03:37:30.339 - 03:38:01.021, Speaker A: So this is the, from the previous video. This is the, the site that has like build your own X style challenges. And so I was doing their build your own BitTorrent challenge and it basically guides you through. Like if you were to build your own BitTorrent, here are the sort of a set of problems you would need to solve. The goal isn't so much to build something that's like a production ready version of X. Right. Like as you see from here, this is clearly not a product production ready version of a BitTorrent client.
03:38:01.021 - 03:38:27.595, Speaker A: But it does force you to think about some like relatively real problems. Go read the spec, implement some like actual real code. And I think this is a good way to learn in general. If you want to try it out, then there's a. Here you could do it through this thing. All right. Something failed.
03:38:27.595 - 03:39:30.215, Speaker A: What failed? Source slice length does not match destination Slice length at download line 223. No, 123. Okay, so we do actually need here to say that this is until piece dot block len, which I guess is really piece size. Wait, no, no, block size. And block size here is piece block len. And then down here we're probably gonna have to do the same thing. So this is basically copy from slice asserts that the slice you're copying from is the same length as the slice you're copying into.
03:39:30.215 - 03:40:29.065, Speaker A: So here, this would be piece size. Yeah, copy from slice is strict. I guess peer doesn't really need to hold its adder. The real reason I did that was so that a peer could reconnect if they lost their connection. Stage 11, I think it's stage 12 is the last one. Oh no, it is stage 11. Yeah, this feels an awful lot like it's just hanging.
03:40:29.065 - 03:41:16.885, Speaker A: So the question is where it's hanging. I forget whether I can I like get one of the torrents. Yeah, there's like a. This thing download. Well, something's doing something nice. Okay, we get no output. Great.
03:41:16.885 - 03:41:37.895, Speaker A: So let's hear. Let's do a little bit of debugging for our own sake. Start receive loop. See if it. Just see if it gets there. It does. Okay, this is participant finished.
03:41:37.895 - 03:42:27.515, Speaker A: And this is got piece. This is got pieces end. Now, if I remember correctly, there are only two pieces, so. Oh, I know what's going on. Okay, okay, okay. So this is actually if. If bytes received is peace size, then we're done here.
03:42:27.515 - 03:43:24.191, Speaker A: Have received every piece. This must mean exited or waited for more work in the case. Great. And then because every one of the participants is not keeping track of how much work there is, what we actually run into is every participant holds a submit handle to put tasks back in, which means that looking for a new task will never finish. Like they'll never get none from the new task queue. So therefore they'll always be stuck there. And every thread holds on to finish, which is the thing that lets you send blocks you finished downloading, which means that the.
03:43:24.191 - 03:44:22.315, Speaker A: We'll never get the none signal here from done unless all of the peers have failed. So this is. There are no peers left, so we can't progress. And in the else case here, this just means that there are more blocks left. Oh, less foo. That looks pretty promising, right? Actually exit when done. Now this is arguably a.
03:44:22.315 - 03:45:08.143, Speaker A: Or not just arguably. This is a simplified version, right? Because. Because in the codecrafters one, I think they assume that every peer has every piece. And so our logic and no peers ever fail. And that obviously makes it so that it's a lot easier to get things wrong in the error cases or the not everyone has everything cases and still pass the thing, right? All the tests ran successfully. Okay, this is pretty amazing actually, because again, remember we wrote all of the code here and didn't test any of it until the end. And what we had, we had one bug, right, which was this one.
03:45:08.143 - 03:46:02.447, Speaker A: I'm not going to count this one because this is just copy from Slice doing sanity checking. It was still correct, but we had one bug. Nice. That's really cool. Now, there are obviously things missing here, right? So for example, in the peerconnection case over in this world we're going to want to deal with things like timeouts, right? So if the stream on the other end ends up taking a really long time, we actually want to terminate, terminate that peer. And that's not something we currently have any handling for. So we'll add that here if dot next timeout error and return block to submit if next timed out.
03:46:02.447 - 03:46:49.765, Speaker A: So there is more work for us to do here. But I think this is most of the restructuring that I wanted to show, right? Like there's obviously more stuff to get this to production readiness, but hopefully you can see now just how different this structure is from how we started in. If you look at download piece, right, which we wrote last time, which is a very. Just imperative linear, top to bottom, do these steps in this order, which worked fine for doing the challenge. But once you start like thinking about how you actually want the system to operate, first of all you change the interface, but also you. You start changing it so that you can have this concurrency. You keep track of multiple pieces of state at the same time and that just makes it better to work with.
03:46:49.765 - 03:47:55.935, Speaker A: Oh, right. And then obviously another. Another improvement we would want to make here is, you know, this is dumb. Like you wouldn't keep all of the pieces here in memory in a linear sequence. Um, so at the very least use bytes. Bytes to avoid the single large allocation and having to mem copy into it. Really like bytes doesn't really even help you here, but bytes is actually probably what I would use down here because what bytes lets you do is it lets you have multiple vex or multiple sequences of bytes that are gathered separately and then it lets you just sort of stick them together and then you have one thing that references the other ones rather than having to copy them back and forth.
03:47:55.935 - 03:49:39.685, Speaker A: In practice, I don't know that it matters within a piece. So I'm Kind of tempted to just leave that one. It's not actually that dumb but for this, this is dumb because all the pieces for a given torrent may not fit in memory should probably write every piece to disk so that we can also seed also resume downloads and seed later on. And obviously this like if there are no peers that have the pieces, obviously also a big to do. There's more work we can do here on the seeding side. So if we look at peer right ideally up here, ideally peer should keep track of what pieces we have downloaded and references to the them so that we can respond to requests from the other side. Also choking the others, choking and unchoking the other side.
03:49:39.685 - 03:50:26.435, Speaker A: So there's obviously a bunch more stuff to do here and I'm not going to claim that this is now a production ready BitTorrent client, but hopefully. And the same thing with handling the halves here, there's like more dynamism that can be added, but hopefully this is a useful insight into how you would restructure this code. And as was pointed out in chat, like there are other ways to restructure this code. This is not the only way to do it. Rather than having each peer, for example, be somewhat smart about how to manage its connection, you can instead just have a central entity and then just do like IO parallelism. Like it just says it like all of the messages that come from any peer just go to a central point. That central point says this channel, send this message, this channel, send this message to you.
03:50:26.435 - 03:51:13.605, Speaker A: Keep track of the entire state machine in one thing and then it just uses the channels as sort of dumb IO channels. That's also a totally legitimate restructuring of this. Which one is better is hard for me to say because I think you learn which one is better from building with one of them and finding that it doesn't really work well or that the code ends up really messy with lots of interdependencies. We're already seeing a little bit of that here, right. Like for example, I think if you tried to fill out the code for have here, it actually be pretty annoying and it might have to tie into the code that's in the download loop. And so that. That's not going to be nice and that's an indication that maybe you do actually want the entire state machine to be encoded in one place.
03:51:13.605 - 03:52:02.065, Speaker A: Now that place is arguably download here, right? But yeah, so you could say the download should be that one entity and to make the peers here dumber rather than use a participate also totally valid and frankly could be better? I don't know. I haven't gone down that path, but at least we've gone over a lot of async tricks, a lot of channel stuff, a lot of hopefully more understanding of like the kind of state you need to keep track of and how to think of the state machine. I hope that was useful. I think that's where we're going to end it for today. Oh, you're reserving the disk space up front, of course. Yeah. This clearly a bunch more work that can happen here.
03:52:02.065 - 03:52:22.685, Speaker A: Not. Not at all claiming this is done. Hopefully that was useful. And have a great rest of your Friday or Saturday if you're elsewhere, or I guess, or Thursday for some of you. But I will see you later and have a good weekend. See you folks.

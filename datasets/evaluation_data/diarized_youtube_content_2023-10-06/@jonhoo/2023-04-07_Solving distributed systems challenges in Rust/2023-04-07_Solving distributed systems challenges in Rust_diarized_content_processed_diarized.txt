00:00:01.240 - 00:00:57.845, Speaker A: Hey folks, this time we're going to try something a little bit different. It'll be in sort of rust implementation stream. But this time we're not implementing an algorithm or some kind of useful crate or anything. Instead we're going to take on a set of basically programming challenges. So this particular set is one I was linked to not too long ago. And it's a set of distributed systems challenges that use a platform called Maelstrom that is basically a sort of distributed systems testing framework or exercise framework that can basically orchestrate message passing between nodes in a distributed system and emulate things like delayed messages or reordered messages or dropped messages, nodes coming and going, that kind of stuff. And you know, it's written by or it's written alongside the author of Jepsen.
00:00:57.845 - 00:01:56.895, Speaker A: And if you haven't looked at Jepsen, it's a really cool effort. It's basically they're doing correctness research for. Wow. My browser plugins are messing with the site, but they're doing correctness research for distributed systems. So they have this framework for exercising a lot of the interesting corner cases of distributed systems and they found like a bunch of bugs in real systems, like real distributed systems like Redis, Raft, Postgres, I think they did something with Etcd. So they're studying real systems and finding real distributed systems bugs. Now this is, I assume I haven't actually looked through all the exercises yet, but this is going to be a sort of let's build up an increasingly more sophisticated distributed system and run it through Maelstrom and see whether what we implemented is actually correct or what kind of additional mechanisms we might need to introduce in order to make it correct.
00:01:56.895 - 00:02:33.995, Speaker A: Now the. I'll link the website in chat so that you can, you can take a look. Now this one is, you know, the exercises that they give here or in the documentation for them is going to be in Google, because I assume that's what flyio uses or something. And I took a look at the Maelstrom repo and in the Maelstrom repo they have this. Why does it not. No, I want this. There we go.
00:02:33.995 - 00:03:24.769, Speaker A: In the Maelstrom repo, they have demo implementations of the node code. And when I say node, I mean node in a distributed systems, not like Node js, they have demo implementations of that, that node stuff In Ruby, Go, JavaScript, Java and Python. There isn't one in Rust as far as I can tell. So we're going to have to write a little bit of the sort of connecting code to get all this to work now, looking at it, let's see. I think it's send an echo challenge. Yeah. So Maelstrom basically requires that each node is just a binary and all the nodes are running the same binary and they receive JSON messages from standard in and send JSON messages to standard out.
00:03:24.769 - 00:04:20.046, Speaker A: And these messages are basically just like the stuff. These JSON objects that you send and receive sort of correspond to network messages. Like if we look at the protocol spec, which we're going to have to implement here. Yeah. So the messages are of the form, source, destination and body, where source is the sort of identifying string of the node that sent the message and the other one is an identifying string for the node that is the target of the message. And I assume these are going to be like, you could think of these like IP addresses, but because we're using a thing that essentially emulates a network here, they're going to be node names like N1, N2, N3, etc. The message bodies have the following reserved keys.
00:04:20.046 - 00:05:05.635, Speaker A: Message IDs should be unique. Each message has additional keys depending on what kind of message it is. I see. So these are fields that can be set on any message or sort of reserved keywords. And then you can set other stuff in the message too. They can be have any body structure you like. So we're going to basically have to implement this protocol, but it seems like a pretty straightforward protocol here that we're going to have to build on top of type error.
00:05:05.635 - 00:05:51.885, Speaker A: Interesting. Okay, so we'll have to think about exactly how we want to model this and how accurate we want to do it. I kind of want to just sort of get started with the real distributed systems part of things. Rather than spend too much time on implementing the protocol, we're going to have to do that just to get sort of set up. In fact, how about we just do the echo example here? So this is just like to see that it works like you get an echo message in from this orchestration system, Maelstrom, and your job is to send a message with the same body back to the client, but with a message type of echo. Okay, so I guess we're just going to start writing some code. I already grabbed Maelstrom.
00:05:51.885 - 00:06:37.807, Speaker A: Maelstrom. Maelstrom. So I have that over here. So once we want to test this, we can actually do that. Great. So let's do cargo new binary and what are we going to call it? What's a fun name for a distributed system that runs on top of Maelstrom? What is the center of a maelstrom called vortex is the proper term. Yeah.
00:06:37.807 - 00:06:55.255, Speaker A: But I want something that has to do with rust, ideally. But let's. Let's look at vortex here and see if there's a. Turbulence is pretty cool. Cool. Vorticity. Ooh, that's a cool word.
00:06:55.255 - 00:07:53.825, Speaker A: The Naruto Whirlpools. That's fantastic. Alternatively, I'm thinking like, ship, right? Like something that might navigate a whirlpool. Eddie is also cool. Moloch. It's a name of a huge ship in a story about the 13.5 lives of a blue bear.
00:07:53.825 - 00:08:20.535, Speaker A: Rasengan is fantastic. Yes. Let's do Rustangan, huh? Yeah. Yeah. Rustangun. Nice. Great.
00:08:20.535 - 00:08:57.925, Speaker A: I love this already. My girlfriend would be very proud. Okay, so Rasengan is a. I'm gonna call it a battle spell, even though that's not actually really what it is. From the anime Naruto where it. You create like a swirl of wind essentially in your palm of your hand. And so it's kind of like a whirlpool, but also it's rusting gun because we're doing it at rust.
00:08:57.925 - 00:09:39.735, Speaker A: Okay, so what are we going to need? Well, we're going to need. We're going to need serde, and we're going to need serdejson, and we're going to need those. Because the protocol here is. The protocol here is in JSON, we're going to define something like a struct message. These are going to be passed everywhere. So I'm tempted to make it short, but I'm not going to. And I'm probably going to make this generic, but we'll do that down the line.
00:09:39.735 - 00:10:05.925, Speaker A: So there's going to be source, there's going to be destination, which they call dest. But I want this to be actually called so that they're the same length. And I guess I will serded. Derive. Nope, nope. Derive. Serialize, Deserialize.
00:10:05.925 - 00:10:51.353, Speaker A: And I also here want probably debug and clone, which means I'm going to use serialize and deserialize. And I want body. Body is going to be one of these things. And so what is body? Body here is a. I actually think maybe this is a. Hmm. Let's look at this in a second.
00:10:51.353 - 00:11:57.215, Speaker A: So there's type, which we can't have, so because that's a reserved keyword. So we'll rename that to type, and we'll have it be. There are a couple of ways to get around this. Either you call it type or ty, or you call it Kind I'm going to go with ty because why not? It is mandatory and it's a string identifying the type of message that this is. It would be nice if that was an enum, but let's make it keep it simple. Then there is the id, which is called message ID in the protocol, a unique integer identifier. So this is going to be an option usize and there's in reply to which is option usize and then they say it can also be arbitrary other key value types.
00:11:57.215 - 00:12:48.985, Speaker A: So we have two options here. We could either do something like, you know, rest and say that is a hash map of string to like serde JSON value. So that's one option. The other option is to make this generic over B and then use like serde flatten rest B. I don't think we want to do this because it's tempting, but it requires that you know the type of the message ahead of time. Like at the time of deserialization, which we're not generally going to know because the type is going to. That type is going to depend on the type up here.
00:12:48.985 - 00:13:29.265, Speaker A: Now there's a. We could make this an enum actually and then say that it is internally tagged by the type here. That's also kind of tempting, although that means that we're going to have to explicitly list out all of the enum types. But that's a little. Actually I kind of like that. The only thing that's weird about it, maybe we do that actually. So maybe we do this and then we say I don't know if this works.
00:13:29.265 - 00:14:35.005, Speaker A: So here's what I want to do. I don't know whether sort to support this, but I want to do enum, I guess payload. And the payload is going to be. Sorry about the bright mode. There's no alternative for serd RS serde tag equals type. And then now in theory at least, we should be able to just explicitly enum out these and say the message types here are. So Echo is going to be one of them and this is going to be one of those serday rename.
00:14:35.005 - 00:15:02.319, Speaker A: There's like a serde. There we go. Rename all equals lowercase. And I think it's probably not even lowercase. I guess we'll see this soon. It's going to be echo underscore. Okay, so they're using Snake case.
00:15:02.319 - 00:15:53.325, Speaker A: So we're going to turn all enums into Snake cases for us. And then now we should be able to have these be types. So if we go back here for Echo, the field is going to be a field called echo, which is a string. Now the thing I don't know whether is supported is this business, which is I want to flatten in here. Payload. Payload, pay that load. I guess we'll see.
00:15:53.325 - 00:17:02.539, Speaker A: Right, so the flattened bit here is like the body has the type which is the tag, but it also has these fields which are shared across all the possible ENUM variants. And I don't know whether flatten works in this regard. We'll find out. All right, so let's see now let's just write the logic here for actually doing the deserialization of inputs. Like we're basically constructing the state machine driver here, right? So we're going to say STDIN is standard IOSTD in lock and we're going to do stdout. The idea here is that we really want the inner state machine to just deal with messages in and out and not have to deal with things like IO. So we'll say here now that actually I kind of want to make some of this a library.
00:17:02.539 - 00:17:52.705, Speaker A: We might do that down the line. So here we'll do. We want STD in to be a stream decrealizer. So in surday there is this thing called a deserializer. Nope, that's not what I want. I want the docs serdejson deserializer Deserializer so you can construct a deserializer. And what's neat about it is that it can be turned into an iterator if you know that there are going to be multiple things that you're going to deserialize.
00:17:52.705 - 00:18:50.135, Speaker A: So what we can do here is we do input is serdejson from reader standard in dot. I guess we can do question mark here. I don't love it, but it's fine. Result we'll probably do anyhow result here feels fine to bring in anyhow for this. So we do from reader question mark and then we do into iter just to make the compiler happy. And what is it complaining about here? It wants R and T. We're going to let it infer and T is going to be message.
00:18:50.135 - 00:20:14.179, Speaker A: What? Why? Oh, I actually do need to do deserializer promoter integer and now we don't need this. And we don't need this, but into iter is now the thing that gives message. Okay, so now we should be able to do like while let. Okay, input is inputs. Alternatively we can just do, I guess for input in inputs. And then the way that this deserialization works is that if you get an error during deserialization It'll it's still an iterator overall, but the items that it yields are results. And what would happen if there was a deserialization error is it would propagate up an error through the item that the iterator yields.
00:20:14.179 - 00:21:06.019, Speaker A: So that's why we sort of do this unwrap over here. I also want to use anyhow context to give some context to this thing which is going to be Maelstrom input could not be deserialized. Input from standard in cannot be deserialized. And then this is where we get to sort of the state machine. So we'll do something like, you know, struct echo service or I guess we could call it Echo. Echo Node, why not? And initially Echo Node is going to be nothing and on Echo Node we're going to have. This is a pretty common way to model state machines.
00:21:06.019 - 00:21:56.297, Speaker A: There are crates that let you write state machines too. But I'm going to assume that we don't need that, at least not quite yet. And we're going to do something like handle. It's going to get a mutable reference to the state of the node in the distributed system and it's going to get the input which is going to be message and the expectation is that this returns actually no. And then it's also going to get a mutable reference to. I think there's a stream serializer too. The idea here being that as the node is executing it might want to send messages as well.
00:21:56.297 - 00:22:28.257, Speaker A: Right. The seems pretty reasonable. That might be things like responses, but it can also be it triggers messages to other nodes. And so the sort of state step function here, let's call it step needs a way to send messages. Now arguably it actually also needs a way to wait for a message before it replies to the current message. So there's a tricky interleaving of things that can happen here. It's not clear we actually want to model it quite in the full state machine here.
00:22:28.257 - 00:23:15.465, Speaker A: We'll see how it turns out. So here what we'll want is a mute serdijason serializer over and it returns a anyhow result so that it has the ability to just fully error the Maelstrom protocol. New line separates the JSON object. So you don't need to use the fancy serdes thing for streams. That's true. But this gives a nice interface. Anyway, I don't.
00:23:15.465 - 00:23:42.565, Speaker A: I don't think this is all that much additional complexity. Really great. Yeah. So I don't know whether we're going to want to express this through a Step function. But for now this seems probably fine at the moment. Or actually we can just implement the logic right here. Because the logic they want is pretty straightforward, right? They want.
00:23:42.565 - 00:24:31.767, Speaker A: The reply is going to be a message and the message is going to have a source which is the input destination and it's going to have a destination that is the input source. It's going to have a body. That's going to be a body. And the ID of the response we're going to have to generate. So that's the one bit that's going to be in here for now is id. So we're going to do self ID and then we'll do self ID one down here. The ID is going to be sum.
00:24:31.767 - 00:25:13.145, Speaker A: It's in reply to the ID of the input here, id and the payload is going to be payload echo. It's not going to be echo, the payload is going to be an echo. Was the response they wanted. Okay, yeah. So here you see, they've built a library that does the reply mechanism for you. We haven't done that yet. And so we manually swap the source and destination here.
00:25:13.145 - 00:25:50.355, Speaker A: So this is going to be an echo, okay. And the echo is going to be echo, which we haven't extracted yet. So this is one of those. We're going to do a match on input. Actually we're going to do a match on input body, payload. This is going to be not. Okay, unexpected.
00:25:50.355 - 00:26:32.135, Speaker A: Actually, we're going to do nothing. If we receive an echo. Okay. Then we just do nothing. And if we get an echo, that's when we want to send this echo reply. And this is going to be in reply 2. I thought the ID was required.
00:26:32.135 - 00:27:35.695, Speaker A: Am I misremembering in the protocol? Only the type is required. Okay, so we generate one of these. Only if it had one of these. And so this reply, we're then going to do output. Oh, what's the way you use the serializer again? Right. I thought there was a output dot serialize. Can I use serialize any here Reply failed to serialize response to echo.
00:27:35.695 - 00:28:06.625, Speaker A: Oh, right. It's reply.seriorize and you give in the serializer. That's right. Great. So this is then going to do down here. I guess we're going to do a.
00:28:06.625 - 00:29:07.385, Speaker A: Let's construct this output channel as well. Serdejson serializer new standard out. And we're going to do state is echo node. So we have to construct this echo node. It starts at or it's the state for the echo node. It starts at zero and then we're going to do state step, give it the input and then this is going to be context node step function failed and we need to pass in the output serializer. There's obviously a lot more framework we could do here, but this is the basic motion of the system, right? You get messages in and those messages are going to cause other messages to be sent and you need to deal with those in as a result.
00:29:07.385 - 00:29:54.475, Speaker A: So I think now we have a binary that in theory does what they ask for. I'm sure there's going to be stuff that breaks here. Great. So if I now run cargo R. Great. It's running because it's just waiting for messages. And so if I now do this, except this, and the binary we're going to use is target debug resting on.
00:29:54.475 - 00:30:22.603, Speaker A: See what happens. Well, it's doing something. Oh, it crashed. Unknown variant init. Right. So it says this in somewhere. Initialization.
00:30:22.603 - 00:30:53.689, Speaker A: At the start of a test, Maelstrom issues a single INIT message to each node. Like so. The noid field indicates the ID of the node which is receiving this Message. The node IDs Fields list all nodes in the cluster, including the recipient. In response to the INIT message, each node must respond with a message of type init. Okay, great. So in other words, there are two more here, INIT and init.
00:30:53.689 - 00:32:19.775, Speaker A: Okay, this is one of those where it would be nice to split this enum between replies like responses, no messages, requests and responses, so that we don't have to list them together. But it doesn't really matter here, at least not at this stage. So node ID is going to be a string and also node ids, which is a vec of string. And in response we have to respond with a message type of init okay, which has no fields. Great. So now we should be able to say for initial, we don't actually care about any of the fields, but what we're going to do is respond with the required message, which is here INIT ok, and INIT ok. If we receive an INIT OK message that should never happen, we might receive an echo, ok? Because remember, if some node sends us an echo, then we're going to send it an echo, ok, back.
00:32:19.775 - 00:32:49.145, Speaker A: And so we might receive an echo, ok, back. The init ok, I assume goes to the Maelstrom servers. So if you saw up here somewhere. Yeah. So there are nodes n 1 and 2 and 3, etc. That are our nodes, and then there are the C nodes, which are the Maelstrom internal clients that sort of trigger these to be sent in the first place. So the init okay, our nodes should never receive because we never send one to one of ours.
00:32:49.145 - 00:33:40.255, Speaker A: So this is received init okay, message should never happen. And I guess here we can do. I want bail in here too. Great, let's try that. I need to build it, see what it does. What do you mean by split the enum have two unrelated enums? Or is there a way to specify the two enum types are somehow related? It was the former. I was thinking like split the enums but then have them sort of flatten into the same actual enum that gets used by serde and I think there is a way to do that, but I don't know.
00:33:40.255 - 00:34:51.034, Speaker A: Seems probably unnecessary to do expected node and 0 to respond to an INIT message but the node did not respond. That's interesting. It might be a matter of flushing here. Oh really? Can I not get at the underlying type? That's going to be annoying. I think the problem here is that standard out is buffered, so when we write out here we're not flushing stdout as well, which means that the message isn't actually getting out to the out to the server. It might be enough to just print a new line because I think this is a line buffered writer. The challenge is that in order to print a new line we need to get at the inner part of this.
00:34:51.034 - 00:35:32.685, Speaker A: This output stream which serializer doesn't let us. Right. All we can do here is we can unwrap it and then put it back together. But that feels feels unfortunate to have to do that. But it might just be what we have to do here. Actually I wonder if we could do this with pretty like if we made this a pretty serializer is going to print new lines for us. Oh, I need to do pretty.
00:35:32.685 - 00:36:17.215, Speaker A: The protocol itself also requires you print a new line because new line separated JSON objects. Makes sense. Wait, why is it. Oh, it's a pretty formatter. Fine, fine, fine. Where's the tick A here. This comes from serdejson Ser this.
00:36:17.215 - 00:36:55.281, Speaker A: Can you explain again, when would the node receive echo? Ok, so if one of our nodes sends an echo request to another one of our nodes, then that node is going to respond with an echo ok. To our node. So it's reasonable for us to receive an echo. Okay. In this particular case I don't think it would happen because I think the initial echo messages come from the C servers or the C nodes. Let's see if pretty safes is here. Did you mean to encode this Line as JSON.
00:36:55.281 - 00:37:28.905, Speaker A: Yeah. Okay, so it actually requires them to be one per line. Oh. Now there is technically a way to do this, which is a. And new line writer, where anything that gets written to it, it depends. A new line too. But I think the way we're going to do that then is to not construct the serializer here, which is a little sad, but it is what it is.
00:37:28.905 - 00:38:45.285, Speaker A: And then instead say this is going to get the standard out and we're going to do reply dot serialize. No, we're going to do serde JSON to writer output and reply and then we're going to do output dot write. All right, Trailing, See if it's happy about that. Right. And we need to do the same down here. And this should be standard out. Great.
00:38:45.285 - 00:39:50.255, Speaker A: No borrowed value output. Why does it not want to be helpful to me here? Do I really need to do a reborrow here? That's pretty stupid. Okay, so this is just saying when, when I do this, what happens is the mutable reference, the ownership of the mutable reference gets transferred to. To Writer, which means that I'm not allowed to use it anymore here. Whereas what I really want is just the mutable reference to be sort of reborrowed. Like I want a mutable referenced again to Writer, but I don't want that to mean that I no longer have it. So I do a reborrow here where I dereference and create a mutable reference, which I'm allowed to because I have a mutable reference.
00:39:50.255 - 00:40:48.447, Speaker A: And then at the end of this call, that is no longer mutably borrowed and so I can reuse it again up here. I think what I'll do is actually, once we get to the next challenge, what we'll do is we'll move some of the stuff into lib and then we'll have each binary just define the bits of the protocol that it uses. Why can't the step function return a message and have the surrounding code serialize it and print it? It could. The reason why I haven't done that is because in this particular exercise, it's just request response. But you can imagine that when a node receives a particular kind of message, it actually sends a bunch of messages. Like, for example, it might send a message to all nodes, in which case is not sufficient for it to return one message. Furthermore, it might be that when I receive a message, I have to send messages to like three hosts and wait for them to respond before I can respond to mine.
00:40:48.447 - 00:41:24.489, Speaker A: So that there actually has to be a Mechanism here for sending messages that is separate from returning from the function. Yeah, so that's the reason why it doesn't return a message. We can have it return a message for convenience, but that's sort of separate. So here we go. That seems promising. Everything looks good. Wow.
00:41:24.489 - 00:42:08.613, Speaker A: It's not so good at printing. Well, my terminal is not that good at printing Unicode symbols, it seems. Okay, so now we basically passed the first exercise, right? So we now have this working. We can look at Maelstrom Serve, too. So there's a mechanism in Maelstrom that lets you basically look at all the stuff that was sent. And so we can look at here, this execution of Echo, and we can look at all the messages that were sent. We can look at the latency for Echo, the rate, the throughput rate.
00:42:08.613 - 00:42:35.373, Speaker A: We could look at all the messages that were exchanged in between which nodes. So this is going to be handy for debugging and stuff later, but for this Echo server, it's not all that interesting. Okay, so now we have distributed system one. Done. Next is unique IDs. We need to implement a globally unique ID generation system that runs again. Maelstrom's unique IDs workload.
00:42:35.373 - 00:44:03.075, Speaker A: Your service should be totally available, meaning that it can continue to operate even in the face of network partitions. Okay, so here now comes the next question of do we want to tidy this up a little bit before we start generalizing? And I think we do. So I think what we're going to do here is lib RS and we're going to take all this stuff and move it over here, and we're going to say that the payload here is going to be. I wish there was a nice way to. I think the way that I want to do this, I want to see if this works. I want to see whether I can do this. Yeah, I was where that might not be the case.
00:44:03.075 - 00:44:46.305, Speaker A: So this means that the payload needs to be fully defined by the caller, which is a little unfortunate, but it's okay. So the payload here is going to be generic. And the reason it's okay to make the payload generic here is because the payload is entirely based on what node service you're implementing. I'll commit the code. All right, fine, fine. I'll commit the code first. That's fine.
00:44:46.305 - 00:45:38.535, Speaker A: Git add. Actually, I want to gitignore store as well, which is Maelstrom's thing. Gitignore the cargo files and source main. So the reason it's okay to make message generic over payload here. Remember I mentioned earlier that the problem with doing this is you need to know the generic type at the time of deserialization. Now if we do that to all of. If we say the payload here is all of the message types that are used by a given service, then we do know that at deserialization time, like the echo service knows that only echo messages should be exchanged in this particular messaging network.
00:45:38.535 - 00:47:01.631, Speaker A: So this should be okay, what we can do is say struct initiated just because we know what these fields are. So this is going to be pub, this is going to be pub, it's going to be pub, these fields are going to be pub. And this and this and this and same with the Node ID and the Node IDs. Now there are some things we could do here that are kind of interesting, which is we could. We could do something like have a. Like pub struct node that we implement on behalf of of the user basically which would have the ID management, for example the message ID management that is and would have mechanisms like reply. I kind of want to avoid doing that yet.
00:47:01.631 - 00:49:20.027, Speaker A: I want to build a second service to see what it is going to need first. The main loop here though I think is kind of tempting to expose. I think what we'll do is so we could have a pub trait here called something like node instead. And it is going to define the step function payload and we're going to say that in order to implement main and this main is maybe not it's like main loop and it is going to take a state and it's going to take. It's not going to take a payload and S needs to implement where S implements node payload and payload needs to implement deserialize the serializeowned. So that's going to be the main loop here and we're not using bail anymore, we're not using write. So now we have a main loop that echo can reuse and we can make changes here so that it doesn't use a step function for example.
00:49:20.027 - 00:50:50.757, Speaker A: But. But if we now go back to cargo toml what I want to do here is to say there is now a bin actually it doesn't. We don't even need to do this. We could do git move or actually we can do make their source bin and then we can git move source main to source bin echo.rs and then we can go over here and say this is going to use rustangon star so now 17 impulse no impul node for echo node node payload for echo. This can mostly stay the same and Our main is going to be just main loop and pass in this. So now we've split this up a little bit and at least in theory this if we now run Maelstrom again and instead of Rastangan, this is not going to now going to be Echo and hopefully this should still just work.
00:50:50.757 - 00:52:28.447, Speaker A: We haven't really changed anything. Will the INIT and Echo bit still be required to challenge 2? No, init I think will be required. INIT is a global setup step, but Echo is not. So now we have split out, split out shareable parts and so now we should be able to copy Echo to unique unique IDs and for unique IDs we need to support a generate message generate and we need to return a generate OK message with an ID, it's going to be. Oh, IDs may be of any type, strings, booleans, integers, floats, arrays. Okay, so realistically it's going to be a string. There are a bunch of ways to do this, right? So you could run a full like consensus algorithm to decide what ID to generate to ensure that like you could run Paxos basically to, for everyone in the network, like for consensus in the network to.
00:52:28.447 - 00:53:20.135, Speaker A: Or quorum really of the network to agree on what the next ID that should be generated is. And then it could actually be an integer. The other way to do this is you generate a unique string and you make it unique enough that there just aren't collisions. One is very easy, one is very slow and hard, but the very easy one is also more costly in terms of the IDs are going to be longer. There is also a somewhat higher risk of collisions, but that all depends on how you generate the IDs. But let's see if we can get by with the unique generation here. So this is going to be unique node, unique node.
00:53:20.135 - 00:54:05.143, Speaker A: It's going to. For the INIT message, we still have to respond for the generate message and then generate. Okay, we actually want this here as well. Or this is another one of those where I, I don't think our nodes will actually receive any of these because we're not sending any of the generate messages. But it doesn't seem like a problem if we get one. Okay, so if we're told to generate, we need to respond with a generate. Okay, which is going to need to have an id, which is really like ID is not really the right word here.
00:54:05.143 - 00:54:59.455, Speaker A: I actually want this to be guidance because it makes it a little clearer in our code that we don't have to refer to the ID everywhere. And so when we generate this back, we're going to have a guid. And now the question is, okay, how do we generate this guid? This is server response to generate. So that's the missing part here. And then this is going to be unique node. Okay, so how do we generate the guid? Well, there are a bunch of different ways. If you go look at something like the ULID crate UUID is sort of the standard way to do it.
00:54:59.455 - 00:55:58.987, Speaker A: The ULID is a little nicer because it's lexiographically sortable, which doesn't really matter most of the time, but it has the NICE property that the identifiers that you generate have the time field appear earlier in the struct. So if you sort them, they end up sorted by roughly the time they were generated. And the ulid, I wish they had an example of this in the docs, but it looks like this, where part of it is a sort of header, if you will. Part of it is a timestamp in milliseconds that gets turned into a string, and then part of it is the is like randomness at the end. Now the question is, is it random enough? Unclear. Yeah. So here, randomness bit.
00:55:58.987 - 00:56:53.517, Speaker A: So you see, it's a timestamp that's encoded using letters and then randomness. And so, at least in theory, we could use this. It is true that, like, this is not guaranteed to be globally unique, but it's close enough. Aren't we supposed to use the info and the INIT message to set the node id? No, let me do the ULID thing first and then I'll explain. So, ulid new tostring. So the question was, shouldn't we use the info in the INIT message to set the ID inside the struct? And the answer is no, that this ID is really the message id, not the node id. We could arguably have named it as such, but it's the ID that we assign to each outgoing message.
00:56:53.517 - 00:57:25.815, Speaker A: And the requirement from Maelstrom is that the message ID is locally unique. So it has to be unique for any node that's sent from this node. For any message that's sent from this node. It does not need to be globally unique. Think of it as a sequence number. And so this is something that we just have work locally for the node, and then we increment it. Every time we send a message, you're guaranteed that the message IDs are unique, so you could use those.
00:57:25.815 - 00:58:08.525, Speaker A: That's also true. We do know that the it's not Even the message IDs it's the combination of the node ID and the message ID is guaranteed to be globally unique. So that's the other thing we can do here. If we assume that the overall system never reuses a node identifier, then let me do this first so we can test it and then I agree with you, we could just do this much easier. But let's try this first. I just want to see that ULID actually passes. So this is going to be where is the.
00:58:08.525 - 00:59:06.475, Speaker A: And this is going to be Target debug unique IDs. Yeah, so here you can see all the unique IDs that are being generated. You see there's a bunch of randomness and you can see the timestamp at the beginning here keeps clocking up. And I would be surprised to learn that these weren't actually unique. The proposal that came in chat is a good one. Like what I just said was the message ID is guaranteed, or we need to guarantee that it is unique per message from a given node. So within a node you never generate the same ID twice.
00:59:06.475 - 01:00:08.785, Speaker A: And separately we know our own global node ID, right? N1, N2, N3, et cetera. And that combination necessarily has to be globally unique. And so when we respond to that message, right, this generated ID could just be the combination of our, our node ID and rMessage ID, because that combination is always guaranteed to be unique. So let's first see that this looks good. Okay, everything looks good. And then instead now of using ulid, we say this is going to be format self node and self ID and self node. We haven't stored yet, but we're going to say here node is going to be a string.
01:00:08.785 - 01:00:53.045, Speaker A: Now really, the state here should be constructed from init, if we wanted to make this a little bit more reasonable from init. So this is going to take an initial and it's going to return a self. It can return an anyhow result self. That's fine. So where self assized here is just saying that this method cannot be called with dynamic dispatch, which is fine. We're not expecting to use dynamic dispatch here anyway. And so now the state here is actually not going to be passed in.
01:00:53.045 - 01:02:00.345, Speaker A: Now the downside of this is, the downside of a constructor like this is that it gets pretty annoying to write code where you want to construct parts of the state in advance and then the rest of it when you get to frominit, because frominit is now in a trait definition or your impulse of the trait definition. And so it doesn't have access to any state that might have been set up previously. There is a way around this, which is to say that this is generic over some S. And you say that. So this would have to be S. And then you say here that N implements node of S and payload. And then you do like this is the INIT state, which is going to be S.
01:02:00.345 - 01:02:39.637, Speaker A: And when we construct it, we do let mute node is going to be node from init. But we can't use the step function for that. It gets a little annoying. All right, fine. Let's leave this the way it was. The thing I was about to say was constructing this node from init here you can then pass in the INIT state and then you would also pass in the data that you get from input. The place where this gets annoying is, first of all, you.
01:02:39.637 - 01:03:06.781, Speaker A: You can't use the step function because step function is called on a node and you haven't constructed the node yet. But you need to call the. You need to. Oh, actually, no, you don't. You can just get the input. We need to get at the input message, but in order to get to the input message, we need to deconstruct the message, which is generic over payload. And the INIT is inside of that payload.
01:03:06.781 - 01:04:42.605, Speaker A: But payload here is generic, so we don't know how to get at the INIT variant. This is one of the reasons why it would be nice to have payload be a sort of combination enum where we define some of the variants in the library and the remaining ones are defined by the caller through generics. But M. I guess one way we could do this is we could say extract initial and say here this has to return an init. So the node needs to tell us. Actually we could do this on payload. Now that I think about it, we could have a separate trait which is payload, and what that has to define is extract INIT message self.
01:04:42.605 - 01:05:49.125, Speaker A: And it has to return an initial and I guess we could say option and then we panic in our code when we know that it should be. And this is also going to require to be sized because it names self. Because now if we require that, I guess I'll make this P so that we don't have overloading here. So P has to implement payload. And so now we should be able to say, well, we know that the very first thing that's going to happen is INIT inputs next unwrap or expect. I guess, I suppose saying no INIT message received. I guess we could really say INIT message should always be present.
01:05:49.125 - 01:06:43.625, Speaker A: And then we can now say P extract init. There should be no self here. Extract INIT from that INIT message. So this is really the INIT message. So extract INIT and expect first message should be init and then we can call from INIT with that init and now we have a node. And now for all the remaining ones we can call the state machine. No next exists.
01:06:43.625 - 01:07:40.695, Speaker A: This also has to have a. This might fail deserialization. INIT message could not be deserialized. And this should be P and this from init we allowed to fail. Node initialization failed. And then I guess we don't actually need to pass that message on. We can send the INIT response here now too.
01:07:40.695 - 01:08:41.475, Speaker A: So the INIT okay, right. So that's the other thing that we want from payload is INIT okay, which should generate a payload should generate a self, I suppose. And this again is the reason we need these two is because we don't have insight into the ENUM variants of the payload and we need the INIT and INIT okay ones. And this is why I wish we could pull it out. So now what we should be able to do is INIT okay is P again, INIT okay. And we should now be able to construct a reply message. And we're going to have to increment the ID too.
01:08:41.475 - 01:10:29.585, Speaker A: That's pretty annoying, isn't it? This is actually going to take a self and we're going to pull out just the payload because the other fields we're going to want to use here, init, destination source, swap those. Right? Fine. This is the INIT message. So this is just us generating the INIT reply on behalf of the underlying node. Now this ID is going to be a little bit annoying because I guess we could just say these should always start from one and this is definitely going to come back to bite us, but we're going to do it anyway and say that the 0 is reserved for this init OK response init message body ID and this is the init gen init OK. And we're going to require here the PS payload and also serialize. Great.
01:10:29.585 - 01:11:46.395, Speaker A: And it doesn't like this because I cannot borrow inputs as mutable. That's fine. Okay, so to talk through what we just did. So we changed the main loop so that it will now also handle the input message by reading the first message from Stdin, parsing it as a message payload and payload here is a P, like it's a generic. Then we use the implementation of the payload trait on P to extract just the init information from the payload through the sort of variant inside of payload that the consumer of the library is using. And then we pass that initialization into the node initialization step, which gives us back an N, which is the node implementation that the user of the library is using. Then we generate the init okay, and there too we need to rely on the implementer of the payload trait to tell us what that variant is.
01:11:46.395 - 01:12:52.825, Speaker A: We write that out and then we do the normal operations. So now if we go back to Echo, for example, this should make it so that we can implement payload for payload. This is probably going to yell at me, right? This is going to be rusting on payload. And extractinit here is going to be oh, we can use let else let payload init. And now this, I guess can be rustangon. INIT equals input else return none. And then we can do sum.
01:12:52.825 - 01:13:38.211, Speaker A: And we could do this even nicer actually, I suppose we could do if let. I like the let else we could do this as an if let instead. And gen init okay, is going to be payload. So it's a pretty easy trait to implement. This is what the implementation is going to look like for basically every case. Oh, my chat did not catch up. Let's see, you can just set up the state on step when you receive the init.
01:13:38.211 - 01:14:10.381, Speaker A: Yeah. So the whole reason why I got into this business is for unique IDs. We want the Node ID to be a part of the state. But this field we only have access to once we receive the INIT message. And so if we wanted to set up the state before we get the INIT message, the node now has to be an option because we don't know whether or not it's been set yet. But in practice, the way the system works is we know we get the INIT message first. So in practice, nodes should never be none.
01:14:10.381 - 01:14:50.285, Speaker A: By the time we get to handling any message that's not initially. All of this setup is specifically to avoid that option. I don't know why my interview with Primogen is no longer on YouTube. That's weird. Does the node need to know about the INIT message at all? It could be handled by the message loop entirely. This is where it gets tricky, because in theory it could. In theory we could deserialize out without using the message type at first, or with using our own message type.
01:14:50.285 - 01:15:24.555, Speaker A: And in fact, that's not a bad idea. It's a little weird, but it is doable. So if we go to lib here, currently we construct this stream Deserializer and the type of the things it yields include this generic parameter. What we could do instead is first deserialize a single thing from Stdin where we use our own concrete enumerated type instead of P. That just holds in it. In fact, maybe that's the way we should do it. It's not a bad idea.
01:15:24.555 - 01:15:54.405, Speaker A: And then we construct this stream deserializer only after we've handled in it. I like that we can do that instead. Give me a second, I'll do that. I'm just catching up with chat. In case of restarting the node, you will generate the same id. It means the idea is not unique anymore. That is the downside here, that if nodes can be restarted and when they restart they have the same node id, then yes, it's a problem.
01:15:54.405 - 01:17:22.455, Speaker A: That's already a problem with the way that we generate IDs here though. So the assumption here in the system is that if a node were to restart, it gets assigned a new node id, it doesn't reuse its existing one. Okay, let's tidy this up some more. So instead of doing this, we're not going to construct inputs until down here. And instead what we're going to do is we're going to do INIT message is going to be serdejson from Reader standard in and then we're going to do INIT message this and this is now going to be a message and it's going to be an init. And now INIT doesn't even need to be pub. What we're instead going to have to do is do this INIT payload.
01:17:22.455 - 01:18:39.075, Speaker A: And now I don't actually even think we need INIT to be its own type. We could just have it be like this. We're not going to need the payload trait anymore. Oh, actually I think we do want INIT as its own type just so we can pass it to the constructor here. But we aren't going to need the payload trait. And instead what we're going to say is we don't need to implement serialize either. So what we're going to say is we're going to construct a message where the payload is INIT payload and then we're going to say and here we can do a left else let initiate payload INIT is equal to this else panic.
01:18:39.075 - 01:19:36.225, Speaker A: And this response now can be INIT payload init ok, and then down at this point now P no longer needs to include init because we've handled INIT previously. So this means we're deserializing using two different types. But I think that's fine here because for the first one we know it should be init. This now should indeed be pub, but it doesn't need to be serialized. Fine, great. And now if we go back to Echo, these can go away. This implementation of the trait can go away.
01:19:36.225 - 01:20:40.795, Speaker A: This doesn't need any state. So we can do from init of state and init which returns anyhow result self. And that's just going to be okay, it's just going to be one of those. And it doesn't use the state and it doesn't use init. And now this can't possibly receive an INIT message or an init. Okay, so it doesn't need to think about them. And main loop now is just going to be echo node and no initial state.
01:20:40.795 - 01:21:50.385, Speaker A: That does look a lot nicer. And if we go to unique IDs it should have the same property that we can get rid of the INIT bit here. The initial state that we care about is just going to is going to be empty. There's no context from the surrounding environment we want to bring in from INIT is going to take an init and it's going to return unique node where the ID is one. See, it almost bit us already and the node is init node or node id. There's no longer an INIT payload, there's no longer an initial OK variant main loop is going to be nothing followed by unique node nothing and no initial state. And I messed up my thing here and this is going to be always ok.
01:21:50.385 - 01:22:29.975, Speaker A: And we don't use state and we don't need bail. That is a lot nicer. Right, so now the way we got here, right, is that we want the unique ID generator to use the node ID and the message ID combined. And now it knows the node id. And notice there's no unwrap here. The node ID is always set because it's set as part of initial. We're still inverting the source destination node IDs in the response.
01:22:29.975 - 01:23:14.775, Speaker A: Inverting the source destination node IDs in the response. Yeah, I mean that's what we want to do, right? Because it's a response. Okay, so let's see if this builds. Let's see that echo still works too. That doesn't seem very promising. Well, we broke something. Expected node n 0 to respond to an INIT message, but the node did not respond.
01:23:14.775 - 01:24:21.575, Speaker A: What do you mean it did not respond? Why? Why didn't crash with anything as far as I Can tell. I guess we can do cargo R bin echo and just send in. That's fine. Show me one of these init messages so I can copy paste it. Oh, okay, fine. This is going to be Source is going to be. I don't know.
01:24:21.575 - 01:25:10.779, Speaker A: C1 destination is going to be N1 body is going to be this thing. Source is going to be C1DEST is going to be N1 body is going to be this. It doesn't print the response. That is certainly true. Oh, I know why it is. Because this from reader waits for stdin to be finished. It went for end of file, not for newlines.
01:25:10.779 - 01:26:42.835, Speaker A: So we're actually going to want to construct a stream deserializer here into iteration message init payload next expect no first no init message received. So the difference here is that when you use the stream deserializer, then it stops at. It checks whether it can deserialize at the end of new lines rather than just at the end of the file. It is true that we could like someone's made the point, I think Gal has made the point in chat here that since we know that the format is newline separated, we could do better here than the sort of guessing deserializer, which is what the stream deserializer here is because it doesn't know until it's parsed whether this new line is the termination of the object or just something in the middle of the adjacent object. So this one's a little bit more costly when we know that the format is actually stream based. So one way that we could do this instead is standard in. Is standard in lines.
01:26:42.835 - 01:27:19.065, Speaker A: Right? And then we could deserialize each line at the time instead. And maybe we should just do that. It's not a bad suggestion. So in that case, what we would do is standard in next expect and then we would do from. I forget what lines gives you. I think it's a. I think it gives you a stir.
01:27:19.065 - 01:28:37.285, Speaker A: And this would then be message init payload context because here fail to read from standard Fail to read init message from standard in. Consider borrowing here because this gives me a string. That's fine. So what we're doing here instead, we're splitting by lines and then we're just straight deserializing the entire string of a line, which we know is going to be exactly one message. Then we can do the same thing here or we can continue to use the deserializer. But let's do for line in STD in line is line context and I guess we can reuse most of the same context. Context here could not be read.
01:28:37.285 - 01:29:17.255, Speaker A: And then we do serdejson from string line. And this now is going to be message P and we don't need this mute. That's true. So the code difference is fairly minimal here and now it's going to yell at me if I do this. So I'm going to make it all one line. Yeah. And now we get the response straight away.
01:29:17.255 - 01:30:00.811, Speaker A: All right, let's see that echo still works. That looks promising. Great. Everything looks good. And if we now go to the unique IDs one make sure we build all the binaries, see what it does. That seems promising. I mean, it is generating exactly the string we wanted it to generate.
01:30:00.811 - 01:31:06.117, Speaker A: And those will be globally unique. Again, as someone pointed out, though, only assuming that node IDs are not reused when nodes restart. Amazing. Everything looks good. Okay. Actually, I want to move init logic into main into lib and then add solution to unique IDs challenge. Next challenge.
01:31:06.117 - 01:31:40.525, Speaker A: Please continue on to the broadcast challenge. Okay, single node broadcast. In this challenge, you'll need to implement a broadcast system that gossips messages between all nodes in the cluster. Gossiping is a common way to propagate information across a cluster when you don't need strong consistency guarantees. This challenge is broken up in multiple sections so that you can build out your system incrementally. First, we'll start with a single node broadcast system. That may sound like an oxymoron, but this lets us get our message handlers working correctly in isolation.
01:31:40.525 - 01:32:22.475, Speaker A: Before trying to share messages between nodes, your node will need to handle the broadcast workload, which has three RPS message types, broadcast, read, and topology. Okay, let's start encoding this. So we're going to say unique IDs into broadcast broadcast. That's fine. And this is going to be broadcast node and the payloads we'll get to in a second. So broadcast node, broadcast node. This can just be self.
01:32:22.475 - 01:32:53.821, Speaker A: Great. So there's no longer a generate, there is now a broadcast. There is a read and there is a topology. Okay. Your node will need to store the set of integer values that it sees from broadcast messages so that they can be returned later via the read message. Rpc, the GO library has two methods for sending messages. Send sends a fire and forget message and doesn't expect a response.
01:32:53.821 - 01:33:20.545, Speaker A: As such, it doesn't does not attach a message id. RPC sends a message and accepts a response handler. The message will be decorated with a message id so the handler can be invoked with the response messages received. Okay. So this is starting to look more like a sort of service. Like we actually want an abstraction where I can send a message and attach a closure to it. And that closure gets called when we get a response to that message.
01:33:20.545 - 01:34:04.067, Speaker A: Message, which is interesting. I mean, that requires a little bit more mechanism in our library if we actually want to support that kind of callback mechanism. Basically, there are two ways to handle systems like this. One of them is you have an interface for doing sending a request and attaching a response handler. The other is to say it's just a flat state machine. So when you send a message, you might record in the state machine that you've sent that message, and then you need to do something. But really you're just updating the state machine to now be in a state where it expects a response.
01:34:04.067 - 01:34:25.745, Speaker A: And then when the response comes in, it's just handled by your step function saying, well, I got this response. What do you want to do with it? And so there's no. There's no closure being called. You don't register at the time of sending the request what to do in the response. You just encode it as another step in your. In your state machine. And these both have merits.
01:34:25.745 - 01:34:48.927, Speaker A: They're a little bit of a different programming model. I want to try to see if we can stick with the state machine here, but we'll see if it gets too annoying. It might also be that we need to turn all of this async. We'll see a little bit how it pans out. It might not be necessary. This message requests that a value be broadcast out to all nodes in the cluster. The value is always an integer and is unique.
01:34:48.927 - 01:35:29.689, Speaker A: For each message from Maelstrom, your node will receive a message body that looks like this. Okay, so a broadcast has a message which is a usice. It should store the message value locally so it can be read later. In response, it should send an acknowledgement with the broadcast okay message. Okay, so there's a broadcast okay thing read. This message requested a node return all values that it has seen. Okay, so there's a read and then there is a read, okay? And the read doesn't actually include any data.
01:35:29.689 - 01:35:59.715, Speaker A: The read okay returns all the messages. The order of the returned values does not matter. Okay. It could be a set, I guess, given that we're guaranteed that the messages are unique. Topology. This message informs the node of who its neighboring nodes are. Maelstrom has multiple topologies available, and you can ignore this message and make your own topology.
01:35:59.715 - 01:36:40.985, Speaker A: From the list of nodes in the node IDs method all nodes can communicate with each other regardless of the topology passed in. Ooh, interesting. Okay. So topology informs us of the topology and it is a hash map from node to a vec of nodes. In response, you should return a topology. Okay, Topology. Okay.
01:36:40.985 - 01:37:26.247, Speaker A: All right. So I mean the setup for this is pretty straightforward. In fact, we don't. We might need the node id. We're going to need the message ID and then we're going to want a messages which is a vec of you size. And so initially messages is empty. When we get a broadcast with a message, then we're going to send a broadcast.
01:37:26.247 - 01:38:08.595, Speaker A: Okay. And here, you know, we could easily say we want to make it easier to construct something like this, right? So one of the ways to do that would be to say we have a. We had an associated method on message which is like prepare reply which does. Just does these bits in particular, inverts these. It sets the ID to one that's passed in if you have one and it sets in reply to as necessary. So let's, let's go ahead and do that. That seems like a potentially useful thing here in Oops.
01:38:08.595 - 01:39:11.075, Speaker A: In lib over on message impl message for any payload, this should be payload agnostic. There is now a reply which consumes the message. I want to say it consumes the message. It. Well, unclear whether that's what I want actually into reply is nicer. The ID is going to be an option to a mutable reference to a usize because we want to increment the ID whenever we prep this reply and I think that's all we want. We could say that like this also takes a closure that maps the payload.
01:39:11.075 - 01:39:50.417, Speaker A: But I don't think I want that here. And it returns to self. And what it does is exactly this. Now it doesn't actually need to construct a new self. Technically we could just set the fields instead. But I actually feel like this looks nicer. Ed Striff Fine.
01:39:50.417 - 01:41:24.641, Speaker A: ID map and the response payload. The question is whether it should leave the payload in place. I guess maybe it can just take the payload. But I think what I want here is I want it to return. What I'm thinking here is I kind of want to be able to take the old payload payload out and return it. Like I sort of want it to be a swap of the payload. And the way to do that would be something like actually, no, I think this is actually what I want.
01:41:24.641 - 01:41:56.635, Speaker A: I want to not take the payload in, set the same payload for the reply. And so now this is going to be. No, that's not what I want. I want bin broadcast. Are you drinking? You're a very loud drinker. The cat was drinking. She was very loud.
01:41:56.635 - 01:43:26.165, Speaker A: So when we get a broadcast here, we should be able to say input dot into reply and we should be able to say. So this is why that won't work. It's because we're already consuming the payload here. So I think what I want is. I guess in some sense what I want is like mem replace the payload with a payload that is going to be empty. But I kind of want what I replace it with to depend on what's in. There's a couple of ways we could go about this, right? Like we could say reply payload.
01:43:26.165 - 01:44:05.235, Speaker A: I don't want to do that either. The other way to do this is actually. Now here's what we do. We do let reply is input.into reply self and then we match on the reply payload. And then we say reply.body. payload is equal to this.
01:44:05.235 - 01:44:38.561, Speaker A: Boom. Beautiful. That's pretty nice. And then we have to do the same thing for read, although read doesn't take any arguments. And we have to do the same for topology. Checks the topology and we ignore anything that is broadcast. Okay, read.
01:44:38.561 - 01:44:48.235, Speaker A: Okay. And topology. Okay, and topology. Okay. So this. And we can just. They have the same handler.
01:44:48.235 - 01:45:33.333, Speaker A: Oops. Okay, so here what we want is self. Self messages push message. For this we want read. Okay, where messages is self.messages. clone and topology. I guess we're doing nothing with at the moment except responding with a topology.
01:45:33.333 - 01:45:54.735, Speaker A: Okay, message. And we can ignore this field for now. And we're not using the node at the moment. That's fine. I suspect we're going to start using it once. We need to know what our neighborhood is. Right? This is single node for now.
01:45:54.735 - 01:47:10.785, Speaker A: And so there's no need to know yourself or your neighborhood. But I think we're going to need it next. All right, let's see what we got here. So I want maelstrom and I want target debug broadcast. Why is the ID optional? ID is optional because for messages where you don't expect to get a reply, there's no need to put an ID on the message in the first place because there's no need for the other node to identify the message it is responding to. That said, usually in these systems, it's valuable to put an ID on messages regardless of whether you expect a reply, because it can help with things like idempotency. So the recipient, let's say you end up retrying a request, the recipient can tell whether a message is one that it's already seen by looking for two messages that have the same id.
01:47:10.785 - 01:48:38.665, Speaker A: So usually even for broadcast messages in a real distributed system, you would often assign them IDs regardless of whether or not you expect a response. Okay, that seems to have worked. So get diff. I guess actually we could also now go back and make these a little nicer. So let reply is input inter reply some mute self id and then we say here fly body payload is equal to this does make things a lot nicer, doesn't it? And I guess we'll do the same here. Reply reply body payload east equals this. Right? And this needs to be replied.
01:48:38.665 - 01:49:37.835, Speaker A: Beautiful. And I guess just as a sanity check, if we go back and run Echo, which should still do fine, why don't you use match all but list the other variants explicitly? Where? Oh, you mean here for the. Okay, so I don't love doing this because I want to know if there are variants that I've forgotten to list. Does that answer your question? I think that's what you're asking. So in theory I could do this and just say do nothing for those. But if I for example, added another payload variant, I want to compile error telling me I'm not handling that variant, which I wouldn't get if I had underscore there. Everything looks good.
01:49:37.835 - 01:49:53.955, Speaker A: You're probably right. I am. I don't need to increment it here because into reply does that for me. Totally correct. It doesn't matter. There's no requirement that they increment by one, but it is unnecessary. That is true.
01:49:53.955 - 01:50:43.315, Speaker A: Okay, let's do. Actually, what do I want to do here? Add message into reply helper oop. So this is solve. Okay, fine. Single node broadcast. Okay, bring multi node. Your node should propagate values it sees from broadcast messages to the other nodes in the cluster.
01:50:43.315 - 01:51:18.615, Speaker A: It can use the topology passed to your node in the topology message, or you can build your own topology. The simplest approach is to simply send a node's entire dataset on every message. However, this is not practical in a real world system. Instead, try to send data more efficiently as if you were building a real broadcast system. Values should propagate to all of the nodes within a few seconds. Okay, so the idea here is that every node in the system should know about every broadcast map message. And so what we're going to do is we're going to gossip them around.
01:51:18.615 - 01:52:09.235, Speaker A: If you're not familiar with gossip protocols, the basic premise of what we're setting up today is let's say we have three nodes, and let's say that a. An operation comes in here saying, Broadcast 34. What we want is for 34 to be known to this node and for 34 to be known to this node. And the question is, how do we get there? Like, what messages do we have to exchange in order for 34 to make their way over there? And one answer, of course, is that this node is going to. It knows about all the other nodes in the system. So it sends two messages, one to. Let's name these N1, N2, and N3.
01:52:09.235 - 01:52:49.735, Speaker A: It could send this message to every node in the system. The challenge with this is that it doesn't really scale well. Like, imagine you have lots and lots and lots of nodes. You really don't want a system in which every node sends a message to every other node anytime it gets broadcast. So instead there's this notion of a broadcast of gossip. The idea with gossip is that rather than every node sending a message to every other node, what you do is, let's see if I can make this. That's a little much.
01:52:49.735 - 01:53:24.945, Speaker A: So instead, the idea is that you take. I don't want that you take your node and you have every node have a topology that tells it about its neighborhood and the neighborhood you can define however you want. It could just be pick two random nodes. That's a valid neighborhood. The neighborhood could be the nodes that are closest to you in terms of network, like the ones you have direct network links to, for example. There are all sorts of valid ways to define a topology. But let's say that we.
01:53:24.945 - 01:53:47.475, Speaker A: This one. Ooh, that was a. That's very big. Let's make that smaller. Uh, let's say that the, the topology of this node is this and this and this. Now, note that topologies do not have to be symmetrical. Um, so it doesn't have to be the case just because n.
01:53:47.475 - 01:54:26.323, Speaker A: Let's say this is N6. It, it doesn't have to be the case of just because N6 is in and one topology that N1 is in N6's topology. It doesn't have to be symmetrical. And so instead it could be that N6's neighborhood is actually, you know, includes N2, for example. What happens though, is when you do gossip is that you send the message to everyone that you gossip to, but you don't send it to anyone else. They are going to gossip to their topology. So N6 might send it to this one.
01:54:26.323 - 01:55:24.255, Speaker A: So it might send it to A node that's already received it, but it might also send it outside of the previous set of the topology. And then this node is going to send it to here and here, maybe this node is going to send it to here and here, this node is going to send it to here and here. And as a result, that 34 that came in over here is actually going to end up propagating throughout the system. Right, because it's going to. This 34 is going to first go here, then it's going to go here, then it's going to go from there to here and to here, and from here to here, and from here to here to here. So this node is going to hear about it last, generally, if we assume all these hops are roughly the same latency, but they will all eventually hear about it. And of course this is, this is true for any set of topologies, as long as you always have at least one link from one node to another one through transitive closures.
01:55:24.255 - 01:56:13.975, Speaker A: And it should also be the case that no matter which message you send the broadcast to, the broadcast will eventually make it to every node. And so that's the basic essence of the gossip protocol is you regularly talk to all of the nodes in your topology to learn about messages that, or in this case, messages to learn about data that they have that you do not. So you can think of this more as a sync. So what I drew here was essentially a sort of limited broadcast. Like when I hear about a message, I immediately tell my neighborhood, you don't have to implement broadcast or you don't have to implement gossip that way. Instead, what you could say is you regularly gossip with the rest of your network. So, for example, N6 and N2, every now and again they're just going to talk together.
01:56:13.975 - 01:57:24.173, Speaker A: It doesn't have to be the case that they do it immediately when someone has a new value that might lead to a lot of messages. Instead, you say every 500 milliseconds, nodes are going to talk to their topology and do a sync. And a sync could be something like, hey, I have these values. Which values do you have? And so you do a two way sync rather than a one way sync, and you do it in a sort of batched fashion rather than do it in terms of single messages you send. And so when they sort of give this specification here, you'll note that they say values should propagate to all other nodes within a few seconds. And the reason why they say that, I presume, is because you might choose to do scheduled gossip but once you do scheduled gossip, you run into this weird problem where once you have many hops, the time it takes for the 34 here to reach the note all the way on the right can take a really long time. Right? So N1, let's say that it receives the broadcast message, and then its next gossip window with N6 isn't for 500 milliseconds because it just did it.
01:57:24.173 - 01:57:54.631, Speaker A: Okay, so it waits 500 milliseconds and then it gossips with N6. And N6 just gossiped with its network. So N6 is going to wait another 500 milliseconds before it gossips again. And then you have the same for N2. And that means that the time it's going to take for the value to get from 30, from N1 all the way to the node on the right, this one over here, right. Is going to be 500 plus, 500 plus 500 plus, like the link distances of each one. So the latency of doing the sync itself.
01:57:54.631 - 01:58:39.585, Speaker A: So suddenly now you're adding up to a bunch of seconds before the nodes at the edges of the graph actually have all the information necessary. You don't usually run into loops here, because again, this isn't actually forwarding. What you do with gossip is you exchange information with your neighbors about data that one has but the other does not. So it's not as though what's really going to happen is N6 and N2 every now and again are going to talk together and compare notes. But it's not a blind forwarding. Blind forwarding is where you run into trouble with loops, right, where I get the message, so I send it to you. I'm in your network, so you send it to me, and then I send it to you, and then you send it to me.
01:58:39.585 - 01:59:07.921, Speaker A: That's where you need, like TTLS or something like that. But in gossip protocol, that doesn't really happen. What happens is when I get a message, I contact you, and. Or at some point later I contact you and I say, I have these messages and it includes the one that I just got. And you say, oh, I don't have that one, Please send it to me. And then our sync is done. So there's no I don't take any action as a result of learning this new value, except I'm going to gossip in the future at some point too, and compare notes with my neighbors.
01:59:07.921 - 01:59:42.625, Speaker A: So there's not actually a forwarding in the way that you might think. And now there are a bunch of questions here. Like when you do the sync, how do you do it? In a minimal fashion. Right? So as they point out here, the simplest approach is to simply send a node's entire data set on every message. However, this is not practical under real world system. And in fact, even in a non real world system this gets problematic pretty quickly. So let's imagine that we have.
01:59:42.625 - 02:00:19.005, Speaker A: Let's imagine that we have just two nodes and there's all sorts of network that they have on either side. So they get new messages over time. And now let's say that this node over here has the messages 24, 36 and 48. This one has 12, 13 and 24. Now let's say that they have to do a sync. One of them decides that it's about time to do a gossip. And this node, let's call them A and B.
02:00:19.005 - 02:00:46.123, Speaker A: So A contacts B and says, hey, I want to do a sink. So it's sending a message. What does it include in that message? Well, it can include all of them. What am I doing? It can include all of the messages, right? So it could say 24, 36 and 48. And then B goes, okay, that's great. Let me tell you about the ones I have. I have 12, 13.
02:00:46.123 - 02:01:16.337, Speaker A: Or let me tell you about all of the ones that I have that are not the ones that you have. So it knows to eliminate 24 because it sees that A already knows 24. So let's say this is already an optimization, right? If we didn't have this optimization, it would say 12, 13, 24, 36, 48. Those are all of the messages that B have. But it can do at least this sort of obvious optimization of I'm not going to tell you back the things that you have told me. So it sends 12 and 13. Okay, that's pretty good.
02:01:16.337 - 02:01:44.719, Speaker A: Now imagine that, you know, let's again, let's assume that our time here is 500 milliseconds. So 500 milliseconds pass and then they decide to do another sync. Or at this point, let's say B initializes a sink. So it doesn't have to be 500 milliseconds. It's just another sync happens and this time B sends a message. What does B send? Well, there's no message for it to reply to. So it doesn't on paper know what A has.
02:01:44.719 - 02:02:50.695, Speaker A: So the only message it can send is 12, 13, 24, 36, 48. Those are all of the messages that B knows about. And then when A now responds, its response here is going to be, well, I don't know of any values that you don't have, because it sees all of these messages. So it is now in the same position as B was previously of being able to eliminate anything that it was already sent, but they just talk together. So there's no need for B to send any of these because it knows that A already has them, because it knows that A sent these here and it knows that it sent A these here, so there shouldn't be any need. And so as a result, you run into this weird situation where B could remember what it has synced with A in the past and just not send any of those either. So now B needs to remember not just which messages does it have, but also which messages does it know that A has.
02:02:50.695 - 02:03:46.379, Speaker A: And now we get into the sort of really wonky world of distributed systems. So you might say, well, B here knows that all of these messages here, that all of these numbers are known to A because A told it that it knows 24, 36 and 48, and b previously told a that it has 12 and 13, so all of these can be removed. B doesn't have to send anything. That's not true though, because in a distributed system, what if this whole message got lost? So A sent 24, 36 and 48 to B and B responds with 12 and 13, but A never gets that message. A doesn't know. It could, in theory detect that, oh, I never got a reply to this message and then sort of tell B again. Alternatively, it could just like go, maybe it didn't have anything to tell me, it's not going to send a message.
02:03:46.379 - 02:05:09.393, Speaker A: That's also fine. We don't even need acknowledgements here. The challenge is B can't assume that A knows 12 and 13 until it hears 12 and 13 from A. Right? And so therefore the only safe thing for B to send to A here is actually 24, 36 and 48 is the only thing to eliminate is these. It still has to send 12 and 13. The question then of course becomes, well, how will B ever realize that a now knows 12 and 13? Right? And the answer to that is, well, A, when it does the next sink to B, it's going to say, you know, naively, 12, 13, 24, 36, 48. The question is, what does it know that B knows? Well, it knows that it knows that B knows 12 and 13, so it doesn't need to send 12 and 13, but it doesn't know that B got this message.
02:05:09.393 - 02:05:48.139, Speaker A: It only knows that B got this message if it gets B's reply. So Whether it can eliminate these depends on whether it saw this. So there's an implication here between these two. It is the two generals problem, right? Like this is the problem of consensus is it is really hard to know whether someone else knows something if arbitrary messages can be dropped. And to be clear, there is no solution to this problem. There is no finite set of messages you can send that ensures that these two are in consent. If you allow for arbitrarily dropped messages, you cannot solve this problem.
02:05:48.139 - 02:06:31.327, Speaker A: Like there's a mathematical proof saying you cannot solve this with a finite number of messages. The moment we know the messages are received, you're fine, you know when you're done. Or if there are no drops, you know when you're done. The challenge is you don't know that there are no drops. So the question is, well, what do we do? And the answer is really, this is all an optimization, right? What we're doing here is saying we want it to be the case that if messages aren't dropped, then we're able to eliminate messages from the sync. That's all. And so it's okay for this to be imperfect.
02:06:31.327 - 02:07:04.655, Speaker A: It's okay for us to send some extra values if some messages happen to be dropped as long as the recipient has a way to detect that it already knows something. And in this case that's fine because the messages are all have unique IDs. All the messages in the system, like all the 12, 13, 24, 36, are guaranteed to be globally unique. And so as a result, we can just keep a set. And so when we hear things from a neighbor, we just add it to the set. And if it's already there, it doesn't matter. It's a set.
02:07:04.655 - 02:07:52.523, Speaker A: Okay, so how are we going to do this? Well, what we're going to want here is messages is going to be a hash set instead. And we're also going to need to keep some state about known. Let's see, Known. This is going to be a hash map from a node, a node identifier to the things that we know that they know. Right? So this is going to be the set of. I know that N1 knows these values. And the hope is that this makes things, this makes the gossip protocol be more efficient.
02:07:52.523 - 02:08:45.525, Speaker A: And the real question is going to be when can we add something to known? Okay. And one of the things that I suspect we're going to have to keep here is something like a message communicated. And I'll talk about what this means in a second. You'll see why we need this. A Little bit later. Okay, so messages here is going to be a hash set new known is going to be a hash map new. And in fact, in init here, there's the assumption that we know all of the node IDs.
02:08:45.525 - 02:09:37.177, Speaker A: That's not always true in distributed systems. Right? It could be that new nodes are going to be added and removed. And currently there's no support mechanism for that here. But we can actually do a little bit better here by saying we're going to do init node IDS into iter map into NID and hash set and sort of pre allocate the hash sets here, collect and then message communicated is going to be a hashmap new for now. Okay, so now let's get to this step. Function broadcast is going to be easy enough. We're just going to insert the message read is going to be fine.
02:09:37.177 - 02:10:12.595, Speaker A: We're just going to do self messages. Actually, I think a set gets printed as a vector. Let's just work under the assumption that it does. I think it gets encoded as a sequence for JSON. So let's keep it a hash set and if it ends up with the wrong encoding, that's fine. We'll fix that later. Okay, so the topology is going to tell us about what nodes we want to communicate with.
02:10:12.595 - 02:11:30.631, Speaker A: We know the total set of nodes, right? It's known to us by virtue of the INIT field here that tells us all the nodes in the network. But realistically, we want something like a neighborhood. And the neighborhood is going to be a vec of uses, no evac of strings which are going to be the nodes that we should gossip with. So when we get a topology, we're going to say self dot neighborhood is equal to topology. Remove ourself, unwrap or else no topology given for node. Right? So the topology here is basically a suggested topology of what our neighborhood should be from Maelstrom. If we weren't given one, we could pick randomly.
02:11:30.631 - 02:12:07.209, Speaker A: In this case, like we don't actually know the network topology. So we just pick some random subset of the nodes in the network of size, let's say two or three. The challenge with doing it randomly is you don't actually know that you end up with a connected graph. You could, if you pick randomly, end up in a state where purple. Let's say that these are the nodes in the system and let's say all of them choose their neighborhood randomly. But they all choose at least two nodes. Okay, so this one picks a neighborhood that's here.
02:12:07.209 - 02:12:50.823, Speaker A: So one picks this one, two Picks the same one, three picks the same one. I need one more node in the system for the problem to be apparent. Whereas these, this is four, this is five, and this is six, and four, five and six all pick this neighborhood. Well, now there's no way for the gossip to disseminate broadcasts from the left to the right or right to the left partition. This is what a network partition ends up being. In this case, it's really more of a node partition because the network, there are network links here. We're not just not using them.
02:12:50.823 - 02:13:45.095, Speaker A: And this is where you get into, like, there are solutions to this problem, such as the number of nodes that you choose is one more than half of the number of nodes. So if you required every neighborhood size to be of at least four, including yourself, so three additional nodes, then there must be an overlap here. Now, the overlap might only be in one direction, because depending on how we do sync. So if sync is just I send you my stuff and not a bidirectional sync, then you still end up with partitions here. But if it's a bidirectional sync, then one of, like the nodes in 4, 5, 6 have to include one more node, which means there's no way for you to end up with a partition, because there's always going to be overlap between the circles, because here there are six nodes. So if every partition contains four nodes, you can't partition the network. There's always going to be overlap.
02:13:45.095 - 02:14:22.201, Speaker A: So here you end up with two clusters. But if you change the rule for gossiping to be a broader topology, you don't have that problem. Now, I'm going to assume that the topology that we're given from Maelstrom is one that's guaranteed to be connected. If that's not the case, then we have to basically compute the topology ourselves in a smarter way. But let's assume that it is for now. Okay, so the neighborhood is going to tell us the topology. Read and broadcast are easy enough, but there's obviously the actual gossip part.
02:14:22.201 - 02:15:29.485, Speaker A: That's where we get into trouble next. And the question becomes, well, how are we going to do that? Oh, right, a neighborhood. And this is where our current model of a step function becomes a little weird, because the gossip isn't really a step function. There's no message that we receive that tells us to do a gossip. There are ways to model this, right? So you could start up a separate thread, and that thread generates input events every like 500 milliseconds that say, you should go gossip. Now that that's Totally a thing that can happen. The other way would be to make this main loop be know about the outer loop over Stdin and say that the outer loop is actually going to be a select over a timer and reading from stdin.
02:15:29.485 - 02:16:30.795, Speaker A: So this would be a sort of like you modify the input loop instead to say it knows how to select over multiple input sources. And for that you don't quite need async, but you're going to want to do it in async. Now this is where we can get into either the sort of go down the root of just write all this code in asynchronous style. The other way we could do it is that we could do this with essentially an actor system. So we said every and this is basically how we've modeled it now with a state machine is to say every node is an actor and it's not going to be internally concurrent at all. It's going to handle one event at a time and we're going to generate the inputs to that event and they're all going to be handled synchronously. I don't know which one I prefer here, actually, I think I want to avoid making this async for now.
02:16:30.795 - 02:17:32.533, Speaker A: And if we're going to avoid making this async, that means that the outer loop needs to have a way to inject additional input messages. And how do you do that? Well, in synchronous programming you don't have a lot of ways to do select. Like if you want to say I want to wait for whichever comes first of another network message or a timeout. You can do a read from standard in with a timeout. It's not super pretty and it's annoying to do it through libraries like serde, but it is possible. The other way you do it is you introduce a channel and then you clone the sender side of the channel and you give one clone to each thread and that thread is going to be blocking and doing the operation that you want to select over. This is going to be a little clearer if I demonstrate.
02:17:32.533 - 02:18:22.607, Speaker A: So rather than have this loop be for line in stdin, what we're going to do is we're going to do TXRX is standard sync NPSC channel. What is sync channel? Oh, it's with a bound. Do I want this to have a bound? I don't think I want this to have a bound for now. And did I get the sender order right? Yes. Okay, great. And then what we're going to do is for line in RX and Then we're going to do. Actually that's not what we're gonna do.
02:18:22.607 - 02:19:15.995, Speaker A: We're gonna do a thread spawn. So we're gonna have one clone of the sender for std. So this is going to be for input in rx. This is just receiving from the channel. We're going to do the step function. And then in this thread is where we're going to do the standard in work. That's probably not going to work because I'm lost locking standard in here.
02:19:15.995 - 02:19:59.335, Speaker A: That might become a little annoying, but it's going to loop over standard in. It's going to parse out the messages, and then it is going to instead of do the step, it's going to do STD in tux, send input. And if that fails, so if for example, the channel has been closed, then we want to return from this thread. Okay. And we now need P to be send. That is true. Because it's going to be sent along with the message.
02:19:59.335 - 02:20:59.335, Speaker A: Yeah, the mutex card can't be sent. That is true. That's a good question. What I'm worried about here is if I drop this and drop the standard in lock and take it again inside of this thread, we're going to get into a weird position of there might be buffered lines inside of lines. Question is whether that is true. Buff is self. What's self here? Standard in lock is just a lock over the inner one.
02:20:59.335 - 02:21:22.865, Speaker A: The buff reader is inside the mutex. Okay, great. That makes a lot of sense. So dropping this lines and dropping the lock is not going to mean that any buffered data from standard in is going to be dropped. That's the thing I wanted to check. So this means we can now do just reconstruct this in here. Drop STD in.
02:21:22.865 - 02:22:21.455, Speaker A: Oh, we're gonna have to drop all the standard ends. This is gonna be annoying. This is gonna be standard in lines and this is gonna be anyhow error. And P also has to be static. That's fine because it needs to live in a different thread. Oh, actually if this consumes self, then I don't need to worry about that. Great, that is even better.
02:22:21.455 - 02:23:29.615, Speaker A: Student lines. There we go. And once this channel closes and the node has nowhere else to go, I guess we can be nice and we can wait for this thread. So when you join a thread, the first unwrap or the first layer of result is if the thread panicked. Thread panicked. And then the second layer is whether it returned an error. Okay, so now we have this main loop.
02:23:29.615 - 02:24:37.925, Speaker A: Great. Now the reason why this Matters like, currently I haven't actually fixed the problem we were talking about, which is we want the ability to generate additional input events. And I think what we'll want here is actually the ability to say, hmm, it's going to be annoying, isn't it? Is I want to give away this TX handle to the node. So over here I actually want to construct this first. And when I initialize the node, I want to give it the TX handle, which lets it inject its own messages. And so now Insider from Init, for example, we could just choose to spawn a thread that generates messages or events every so and so often, like on a time SC schedule. And then those would end up being surfaced in this main read loop that calls node Step.
02:24:37.925 - 02:25:45.705, Speaker A: So this is now going to be just tx and then we go to node from Init that's now also going to be passed a sort of inject handle, which is going to be async MPSC sender. And the question becomes, what does it send? We could say it send messages of payload. It's a little misleading though, because the payload messages are source destination things, which is not actually what we generate here because there's no source or destination for a generated event. We could say that there should be. So you could imagine you want to generate an event for saying specifically you should now send a message to this node. But I don't think we want to represent it as message. Instead, I think what we want to do here is something like enum event.
02:25:45.705 - 02:26:48.345, Speaker A: And the event is either going to be be a message, in which case it's a message payload, or it's going to be a body, or it's just going to be a direct payload, which is payload. This isn't going to be serialized or deserialize. And what we'll do now is say that this is going to be an event. And we're going to say that step is going to take an event payload. So it may be an injected message, or it may be actually, let's call this injected, I guess. Or it may be an actual message like that we got from standard in or from the network. And so this is now going to be an event message here.
02:26:48.345 - 02:27:50.815, Speaker A: And so now we can differentiate between injected events or injected payloads and actual messages we got from the network. And now we're going to have to go fix Echo. It doesn't care about the sender. Sender of payload. Right, Event payload, which is then. Yeah, and the input here is an event payload. And we can actually here say let event message Input equals input, else bail.
02:27:50.815 - 02:28:47.945, Speaker A: Or this is really a panic got injected event when there's no event injection. And we should be able to do the same up here. So this is going to be an event. This is also going to be handed one of these, but it's not going to use it. And crucially for our broadcast, we will use it. So this TX business over here is in fact something we're going to use. We're going to say something like inject is going to be this.
02:28:47.945 - 02:29:35.975, Speaker A: What's going to be awkward about this is it's actually never going to exit because we're in the state. If you go back to look at the lib, we keep looping over our inputs for as long as there are messages in the channel or might be messages in the channel, which means that we keep going until all of the transmit handles have been closed. And one of the transmit handles is held by standard in and will be dropped when STDIN is closed. But the other transmit handle in the case of broadcast is held by the broadcast node. So it's held by this node right here, which we know still exists because we're holding onto it, because we're going to call it in the loop. And so this loop will never terminate for broadcast. So there's arguably a sort of.
02:29:35.975 - 02:30:49.615, Speaker A: When STDIN ends, we might actually want to send a message saying stdin ended. And we can do that down here by saying that there's a sort of. There's an additional event here which is end of file, and we don't actually care about that result. And so this now there's at least a way for the node to learn that it should exit. Great. And inject here is going to be tx, this is going to be event, and we're going to now match on input. And if it is a message, then we do what we were doing previously.
02:30:49.615 - 02:31:27.595, Speaker A: But if it is end of file, then we're going to do something different. And if it is injected, then we're also going to do something different and we'll figure out what this is. Now, currently we're using the same ENUM for injected events and for messages. And it might be that we want these to be different enums. It's not clear that you're always going to inject a payload. Might be a thing that we want to do. I haven't decided yet.
02:31:27.595 - 02:33:45.525, Speaker A: Almost certainly we're going to need to do that. Okay, so in that case, the question becomes how do we inject a message in the first place? What do we do? Oh, why Can't I mute topology? Well, what we're going to have to do here is when we construct from Init, we're actually going to start a new thread and this thread is just going to generate gossip events and we'll do something like it's going to be a loop, it's going to be a forever loop and it will do. Actually we can do a gossip TX is TX clone and in fact we don't even need to hold the injection in the node itself, I think because we're not going to inject anything except for through the separate thread. And this is. We're going to have to want to find a way to make this loop terminate when the node itself gets the end of file event. And we can do that with an atomic bool or something, but it's not super important right now. So this is just going to loop, it's going to do sleep and we're just going to sleep from millis 300 milliseconds and then it is going to TX send event injected gossip and if sending fails then it is going to break and duration needs to be imported.
02:33:45.525 - 02:35:04.695, Speaker A: So currently this has to be now a variant of the payload. And that sounds nice because it means that all of our payloads are gathered in one place. But the downside of it is a it now needs to be serialized and deserialized as well, which seems unfortunate, right? Like there's no actual requirement because it never gets serialized or deserialized. And the other reason this is unfortunate is because down here in our match, when we match on an event message input, we match on the payload in here we now also need to match on payload gossip, even though that can never come in as a message. And all this makes me think that we, we should actually have injected payload be a separate thing. And we can give it a default here just so that for things that don't need to inject payloads, they don't need to specify it. Forget whether you can set this in traits.
02:35:04.695 - 02:36:32.815, Speaker A: Yes you can. A lot of nice generics here. So it should now be the case that here found IP expected this. That's because then ah, this should be N. That's fine from init. Ah, this should be injected payload and injected payloads need to be sent and they need to be static actually do they. They need to be send because they need send instead because they're going over a channel, right? Like the injected payloads, even though they're not necessarily going over or across thread boundaries, they are going over a channel and the channel Requires that the types you send over there ascend.
02:36:32.815 - 02:37:48.715, Speaker A: Okay, great. So if we now go back to echo Echo shouldn't need to change because we have injected payload has a default value of the unit type but it will be needed here. And unique IDs similarly should only need to change because we use the turbofish down here. But broadcast now we can have it infer that too. But we're going to have a enum injected payload which is going to have gossip, nothing else. So this is now going to be an injected payload Gossip injected payload and this is going to have injected payload. And so now we should be able to hear match on payload and the only injected payload is gossip.
02:37:48.715 - 02:40:04.397, Speaker A: And we don't need to change anything about the the matching on message further down because we know that message will never include these. Okay, so what do we do when one of these gossips trigger? Well, at least in theory all we should need to do is for n in self neighborhood we really want to do something like a. Actually here's another helper we can have on message is this business where's our message helper Right here. Pubfn send reference to self and a W which is an implwriter or implwright I suppose. Like so, like so and like so where payload is zero device. There we go. And so now this over here we should be able just to reply send to output and this is going to be reply to broadcast.
02:40:04.397 - 02:41:22.205, Speaker A: So that's suddenly now a lot nicer. And this is reply to read and this is reply to topology. And I guess we could also do this serialize response message and this is write trailing new line. Right. So back to gossip. Now what we can do is for end in neighborhood we should be able to do message dot send to mute output gossip and we could here do with context gossip to N Question becomes how do we fill out the message? And the message is easy enough here, right? The source is self node, the destination is N. We're going to have to clone these which is a little sad, but it's fine.
02:41:22.205 - 02:42:15.515, Speaker A: The ID here is going to be self ID and so that means we're going to have to increment the id. Be nice if that wasn't as error prone. If we forgot this. It is not in reply to anything and the payload is going to be payload gossip. So actually this is a good idea. Good thing that we split up this event because we are going to want gossip and gossip okay messages and those messages are actually going to have the whole data, right? So remember we're exchanging which Messages we've seen. So this is seen and this is seen.
02:42:15.515 - 02:43:18.515, Speaker A: So these are messages that I have seen. These are messages that you have seen in the response. So what we're going to generate here is let's do the sort of stupid version first self messages clone, which is I'm going to just send everything that I have and what you're going to send me in response is everything that you have. And what's also interesting here about gossips is we don't actually need to have responses. Currently the way that we've set this up is that, you know, when we were drawing this was that when A and B gossip they do a sync like A sends a bunch of messages and and be response with something, but it doesn't actually need to be a reply. In fact, maybe we should just get rid of the response here because it's sufficient to just sort of fire and forget them. Which also means they don't even need IDs.
02:43:18.515 - 02:44:20.285, Speaker A: This can be none because no one needs to identify the response. If it gets dropped, it doesn't really matter. And so here we could probably prune out anything that we know that the other side has. And in fact we can write this right now. So we could do iter copied collect iter filter. I want to do that. After the copied filter N N knows is going to be self dot known of N filter only things that are not where not N knows.
02:44:20.285 - 02:45:10.025, Speaker A: We could do this better. We say known to N not known to N dot contains this is M for the message. So we're going to take all the messages that we know about and we're going to filter it out so that only the ones that are not known to N, only the ones that are not known to N are sent. And now the question is how are we going to update known to N And we can leave that for later. Like it's fine for it to always be empty for now. And just to check my logic here, it's always weird with Boolean operators. So known to N we're expecting that we're going to send all of the messages.
02:45:10.025 - 02:45:37.695, Speaker A: Let's double check that that's true. Known to N is empty. Therefore for any given message the filter closure here is going to return. So empty contains is false. This is going to turn to true. So the filter is going to return true and filter removes anything where it's false and therefore all messages will be sent. Great.
02:45:37.695 - 02:46:43.889, Speaker A: So whenever it's gossip time, we're going to send a message to everyone in our neighborhood telling them about all the messages that we have. And over here, when we get a message gossip scene, we're just going to do extend scene and we're not going to reply. So that's all we have to do. Whenever someone tells us about it, we just add it to the set that we have. So let's see if this works. And we might actually not need message communicated anymore. I was adding that because over in this space, right when I get a response from you, then I know that you have seen these, but that means that I need to remember those for when I see this response.
02:46:43.889 - 02:47:42.879, Speaker A: But if we're not doing responses, then this doesn't matter anymore and we'll see how well that works. Okay, so if I now run what's the message they want to use here? This maelstrom target debug broadcasts. Let's see if it all fails. Notice that it only prints here the. The gossips, only the messages that get exchanged between the. The. The Jepson like the.
02:47:42.879 - 02:48:16.781, Speaker A: The maelstrom clients and our clients and not what our nodes are telling each other. Tearing down. Everything looks good. I'm curious here to see what this actually looked like. So let's head over here to our local host business broadcast. Let's see the message history here. Okay, so that's only the Jeps and messages history.
02:48:16.781 - 02:48:47.595, Speaker A: Edna. I wanted to see if the. If our gossip messages showed up here, but it doesn't look like they did, which is interesting. Hmm. Broadcast messages are very fast. The reads are slower because they need to transfer data. That seems reasonable.
02:48:47.595 - 02:49:12.501, Speaker A: A bunch of topology messages. Ah, yeah. So here we see the gossip messages. Okay. So initially we sent all the topology got sent and we responded with topology. Okay. Then there was a broadcast, broadcast, broadcast, broadcast, broadcast.
02:49:12.501 - 02:49:43.945, Speaker A: And then you see all of our nodes started gossiping and you see the sort of seemingly weird interactions between them because they're just sending to basically random other nodes in the network. You see these gossip messages start to get pretty long. Right. Like down here, we're sending giant chunks and they just keep growing. And we should see that then if we look at the timeline. No, I don't want the timeline. I want the latency raw.
02:49:43.945 - 02:50:44.425, Speaker A: That's not really what I want either. There's sort of a view here that I'm looking for, which is the performance of. What I really want to see is like the delay between when a message is broadcast and when it's visible to all peers, which it doesn't look like it's recording here. This is the rate of broadcast. But I want like the Visibility delay, which doesn't seem to, it doesn't seem to surface here, which is too bad, because what we should see is when the gossip messages become longer, longer and longer, that means that the send between two nodes, the gossip between new nodes gets slower. And as a result it takes longer for any given message to propagate across the network. And as a result the propagation delay for messages is going to be longer.
02:50:44.425 - 02:51:53.525, Speaker A: So let's stop this one and say implement naive gossip. And so now let's see if we can do a little bit better. And actually this should be really easy. It's just when we receive a gossip message, then we know that the messages that the sender knows about include all of the ones that they sent us. If A told me about 3, then I know that A knows about 3 and I never need to send it 3 again. Get mute of this. Got gossip from unknown node.
02:51:53.525 - 02:52:46.795, Speaker A: And that's in theory all it takes for this to be smarter. So if we now run this, at what point will. Isn't that the broadcast rate? I think the broadcast rate is the rate at which the broadcast operation succeeds. And broadcast is a trivial operation because it doesn't trigger any work. We trigger all the work in gossip, so broadcast won't actually get slower. At what point will copied produce copies of values being iterated on? Will it copy those that end up filtered out? It depends whether you put dot copied before or after the filter. If you put it before the filter, then every value will be copied regardless of whether they match the filter, because the copy happens before the filter.
02:52:46.795 - 02:53:34.205, Speaker A: If you put the copied after the filter, then only the ones that aren't filtered out get copied. The reason I put it before is because filter operates on references to the items being iterated over. And so it just makes it more annoying to write. And in this case, the copy is basically free because the references are to numbers. So there's not a huge clone that succeeded. Let's go ahead and look at this and just verify that the gossip messages are in fact shorter. Now this broadcast messages, if we scroll down pretty far, so they're still kind of long.
02:53:34.205 - 02:56:01.385, Speaker A: I'm just trying to gauge whether they're getting shorter. Like, you know, we're pretty far down the tree here and you see this list of messages, for example, there aren't that many. Like it's not all the messages that have been sent up to this point. Like, let's go maybe to the end here, these are still pretty long. It's hard to tell whether this is because there are so many messages to exchange or whether it's because the logic isn't working. What we can do here is actually give ourselves a little bit more data and say, here, let notify of. This is a hash set.
02:56:01.385 - 02:56:49.015, Speaker A: I just want to print to see whether it's. Whether it ends up eliminating any. Because that's really what we're after here. Right. So there should be a store latest node logs and zero. Yeah. So it is only notifying of a subset of them.
02:56:49.015 - 02:57:38.915, Speaker A: Let's let it run for a little bit longer and see how much it reduces stable latencies in the results. EDN link has the time to propagate. All right, let's go look at that. I'll let this run first. The reason it's destination, not source is because this is after calling into reply, which swaps them. So if we go to the end here. Yeah, so it's definitely subsetting them.
02:57:38.915 - 02:59:10.275, Speaker A: Right. I guess the observation here is that you will only eliminate messages that that other node has told you about in the past, and they won't tell you about ones that you already have told them that you know. So this is the problem we had that we described in the over here. Right? Which is if I know that you know these values, I won't tell you that I know those values. So I think actually the thing we need to do here is we need to be a little bit smarter and we need to say, I think we want to add to notify of. Include a couple of extra messages to let them know that we know them. And so we're going to say notify of, extend self messages, enter dot copied.
02:59:10.275 - 03:00:15.607, Speaker A: Trying to decide how I want to. I kind of want to pick these randomly, but then I need actual randomness. Let's do partition already known and notify of. Whoa. Hash set. And then what I want here is extend with already known. But I only want some of them.
03:00:15.607 - 03:01:03.889, Speaker A: And the way that I'm going to pick only some of them. Yeah, exactly. If A tells B123, B will know that A knows 1, 2, 3 and will not tell A that it knows 1, 2, 3 and therefore A doesn't know that B knows them. Which is exactly the problem I'm trying to solve. And the way we're going to solve it is essentially with like more of this gossip idea sort of of. I'm also going to tell you a couple of extra ones, not too many, but just enough that over time you're going to learn more about the ones that I have. And so we're going to bring in Here random and Rand is version 08 now and what we're going to do is iterating a hash set could be seen as semi random.
03:01:03.889 - 03:01:57.715, Speaker A: The problem is it's. It's not actually random enough because we want it to be different every time we send messages to someone. And the hash set randomness only changes. It is random, but it only changes between iterations if the hash map gets resized, which doesn't happen that often. So I want RAND prelude. I don't care too much about the performance here dot filter and I don't actually care about the value and instead what I'm going to say is rand random. What is the.
03:01:57.715 - 03:04:06.415, Speaker A: I want this, I want an RNG and what I want is RNG gen bool But I forget what the returnable with probability p of being true 0.1. There's another argument here which is instead of this being a fixed percentage of the total number of things that are already known, it should actually be like we always send an extra 10. So what we'll do here is gen ratio and I want a gen ratio 10 out of already known dollar as ethnic and actually this shouldn't be 10. This should be 10 dot min. Oops. Because if there are fewer than 10 that are already known, I don't want this to fail. Okay, let's see how that does.
03:04:06.415 - 03:05:27.281, Speaker A: I assume it passes be weird if including additional things in the gossip made a difference. What I really want to see here is. Yeah, so now I see the gossip's at the end here. There's basically nothing to exchange. That's more like it. And so if I now go up and do serve, we go over here and we go back, back refresh this one and we go to messages then now the gossips as we go down should still stay pretty short. There's a point in the middle where there's a lot of gossips.
03:05:27.281 - 03:06:25.125, Speaker A: But if we go farther down like around here, like see here, these gossips even now they're far at the end, are relatively small. Some of them are longer but it's random. Right? Beautiful. Okay, and then someone said if you go to the results EDN stable latencies. Ah, worst stale. Okay, stats. What I really want is like a.
03:06:25.125 - 03:07:22.875, Speaker A: Yeah, I guess maybe it's just in text form. Stable Latency 861,771So the worst ones are like stable latencies. The 99th percentile of stable latencies is 771 for this one if we go to our first implementation, stable latencies was 800. So we didn't actually reduce it by that much. I'm not terribly surprised actually, because this, these executions are pretty small anyway. It only matters once the gossip gets very long. So the 99th percentile was about 800.
03:07:22.875 - 03:07:52.109, Speaker A: And then as we started to make our gossip smarter, it went down a little bit. When we made gossip, we made the gossip without the randomness, it went down to 777. And when we added the randomness, it went down to 771. So statistically irrelevant. Okay. Yeah, I think I'm happy with that. Interesting.
03:07:52.109 - 03:09:04.935, Speaker A: Okay, I think that's actually where I want to stop for today. So know that we know them. Let's make this a little bit more clear. And we don't actually need the notify here. If we tell N that we know, if we know that N knows M, we don't tell N that we know M. So N will send us M in for all eternity. So we include a couple of extra message, extra M's so they gradually know all the things that we know without sending lots of extra stuff each time.
03:09:04.935 - 03:09:58.205, Speaker A: And you could tune the 10 here, right? Like it doesn't have to be 10. You could say that we're willing to always include a sort of overhead of the message of at least 10%. So instead of 10, this could be notify of dot len as U32. It could be like, for example, whoa, that's not what I wanted to do. Like, like this is one way to do it, right? So say, oops, actually that's not what I want. I want. Well, that is what I want, but I just don't want it there.
03:09:58.205 - 03:10:37.105, Speaker A: Let additional cap is. I don't want the message size to grow by more than 10%. Right. So the message size is going to be basically the number of things we have to tell them about. And I'm saying 10% of that is as many of as many additional things I'm willing to tell them about. So this caps the. It doesn't hard cap it at 10, but it hard caps it as a ratio of how much I'm already telling them about.
03:10:37.105 - 03:11:29.855, Speaker A: And this is 10%. And we could of course do something like we could do this in floating point instead. I think it's fine. This way the rounding isn't really going to matter. We cap the number of extraneous Ms. We include to be at most 10% of the number of M's we have to include to avoid excessive overhead. Now I kind of want the print line back.
03:11:29.855 - 03:12:14.045, Speaker A: Ah, it's fine. It doesn't matter. And so the idea is like, you know, if, if you have to gossip 100 things to them, then you're going to send 10% of 100. So 10 extra bits. If you're telling them about five things, I guess now it's going to end up being zero. Huh? That's not great either. So maybe 10% is too low.
03:12:14.045 - 03:12:54.815, Speaker A: Let's go back here and look what messages. Show me the end. Some of them are still pretty short, so I think this is probably okay. You don't want the overhead to be a lot more than 10% anyway. So it still means that if you send 10, you're going to send one extra. Okay, I think I'm happy with that. Let's stop it there.
03:12:54.815 - 03:14:18.005, Speaker A: Make gossip. Make gossip smarter. Sweet. I think that's all I wanted to touch on today. There are more exercises if you go here. There's like fault tolerant broadcast, which actually I wonder just to see whether we already do this debug broadcast. Are we all already resilient to network partitions? So this is basically, it's going to make it so that certain nodes can't talk to each other for some period of time and to see whether it still works, see what it says.
03:14:18.005 - 03:14:37.577, Speaker A: Everything looks good. Okay, great. So the gossip protocol we have actually works even if there are network partitions. Right. If there's a permanent network partition, it won't work. But as long as there's some path, the values will eventually make it there as long as the topologies are updated so that you, you end up sort of bridging that gap. Nice.
03:14:37.577 - 03:15:06.635, Speaker A: So we actually do 3C as well. And there's going to be broadcast efficiency which we can, we can get to later. Are there any questions about what we've done so far before? I sort of end the stream here. Like, I think you could build on this and do the later challenges too. I just, I think this is a good place to end. I think we got to something pretty interesting. And I'll push this to GitHub too, so people can build on top of it.
03:15:06.635 - 03:15:33.353, Speaker A: No questions. Everyone thinks everything made perfect sense. It's amazing. All right, in that case, thank you all for showing up or for watching if you're sitting there at home afterwards. I hope this was useful. We'll see. I might do a part two of this with the later challenges.
03:15:33.353 - 03:15:49.225, Speaker A: Don't know yet. But this was fun so far at least. And you know, I like thinking about distributed systems problems. All right, have a good rest of your Friday or Saturday if you're on the in Australia. And such. And I'll see you all later. Bye, folks.

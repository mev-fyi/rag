00:00:11.200 - 00:01:12.810, Speaker A: Hi, I'm Tom from Geometry. As Michael said, I did get rugged overnight by Justin Drake and also by John Shabano. And I'm also I'm sorry, I'm in the middle of a giant ZK sandwich attack as well. So this is nothing to do with ZK and this is geometry really going off pieced a bit and it's some very some hazy guesswork about the economic end state and maybe even computational end state of the Ethereum machine. So the things that I want to cover today, and I'm going to do this in ten minutes, this has also had the scissors on it, so you can all go and enjoy the after event party. The things I want to cover really are some infrastructure design principles. They overlap with some basic macroeconomic principles and also how protocol builders can continue to be economically sustainable, which is going to be quite a difficult thing for people who are sort of building L two S now.
00:01:12.810 - 00:01:47.284, Speaker A: The business options that they have ahead of them and the opportunity for economic surplus are massive. But you just got to stay on top of it and I want to talk a bit about that too. So I'm going to give a quick kind of sanitized where are we in history right now account of Ethereum. And this kind of applies to all L two S. But particularly, I guess, Ethereum was sort of the first mover with these scaling problems suffered. First. There were some panic highlights, like all them, including Sharding state, rent MapReduce, lots of these things.
00:01:47.284 - 00:02:37.044, Speaker A: How on earth are we going to scale this thing? This gave rise, obviously, to the production of layer twos and they all scratched their heads and thought, well, whilst we're doing this, we have sort of mixed views on EVM and we have maybe some other machines that we're interested in trialing too, so let's try Cairo and Maiden and Risk Five and Noir. And then there's all these companies that are sort of tying the state, the Balkanized state of these things, back to these L two S so that they can sort of reason about things that are going on in other chains. And of course, there's also the ZK bridges as well, doing the same thing between L ones and L two S. So it's turned Ethereum into this massive virtual microchip factory. It's an accelerator. It's almost like a kind of it's hosting a load of startups. So maybe this means long run.
00:02:37.044 - 00:03:41.704, Speaker A: The layer one's job in this model, if it's the correct model, is something like mind your monetary stability, find cheap capital, validator capital, accumulate a lot of it, store things and check proofs. So as far as the infrastructure goes, what game should we be playing at each layer? We've got the layer one and we've got the layer two. The layer one, I argue, and I think John and other sort of experts sit on the fence on this, but I think it is playing a macro game and I don't think this is particularly controversial. It is after deep liquidity of the underlying asset and I'm going to explain with some correspondence to fixed income markets why actually this is quite important. It's after deep liquidity, price stability, wide dissemination, wide handling of the asset because this is going to affect its cost of operation. The layer two is playing a slightly different game in that it probably cannot get access to candidacy as a macro asset for the native asset. And so I think it is playing a slightly different game.
00:03:41.704 - 00:04:30.068, Speaker A: And I'll explain all this in the talk. So here's some possible layer one design principles in the sort of hierarchy I think they should be addressed in. Number one is just do enough by returning cash flow through some sort of burn mechanism to the layer one asset so that you manage its supply, you make it a sort of plausible part of the monetary furniture. Then the next thing to do is take any additional surplus and make the aggregate number of dollars maximally available for security capital for validators. And then three, aim for low APY on that validator capital. And you will probably and I will say I'll explain this a little later in the talk, but I think you will do best by that. A very good start is stabilize the layer one asset.
00:04:30.068 - 00:05:29.000, Speaker A: That's the first thing you can do. And then the second is sort of make the maximum number of dollars of cash flow available to attract lots of that capital. Layer one and in particular the EIP One Five nine debate was really interesting. I don't know how many people have sort of braved tim Roughgarden's 40 something page report on this, but aside from the analysis of the eventual design of one five nine, there was additionally some sort there was a sort of section towards the back with a load of other designs that might also have been looked at at the same time. One known rather grandly as the L smooth mechanism. Essentially take the feed that you're about to burn and don't burn it and send it on to the stream of the next sort of L, the validators of the next L blocks. And if L is sort of big then that means that the opportunity for collusion should remain relatively small.
00:05:29.000 - 00:06:53.888, Speaker A: So I don't want to dwell too much on that, but I think we're about to revisit or have a sort of recapitulation of a similar argument in the context of MOV. Now, I've tried to suggest the post from Justin overnight and John's excellent thread on this. And John's thread is far subtler and far more educated than mine than my analysis will be. But I'd like to actually run through what Justin sort of cites as the main motivations for going for a burn mechanism, which is this is kind of like the company buyback mechanism. You return the cash to the unstaked version of the token, not the staked version of the know. What are the reasons for doing this? Well, one interestingly is there's a concept of sort of reducing the validator count a little bit actually there's a very specific reason that this might be beneficial, which is to promote single snot finality there is a sort of sense that increasing staking apr or sort of keeping maintaining staking apr as a consequence. Well, I mean, really, I think markets, future markets, if there's a good primary function, there's a good ability to put money into its validator form and then remove that money, that should be a good primary mechanism to make sure that the market's view of what a rational staker ought to be compensated will be reflected in that eventual.
00:06:53.888 - 00:08:06.764, Speaker A: Apr APY, I should say there is an argument around economic sustainability. So this is obviously looking forward to Dank Sharding when we're going to have sort of severance of data, so not everyone will be storing all the data, but the data is going to be sort of somewhat sharded, then there could be some revenue losses from that. And this is about sort of looking forward towards compensating for that tax efficiency. I'm less sure that should be a concern of a layer one protocol so that's the kind of one of the ones I'd push back on there is an argument towards economic scarcity. There would have been more economic scarcity of ETH, a higher net burn as a consequence of burning MEB had this mechanism been in operation today. Again, I think sort of the deflationary asset, if that is ultimately the aim, is not necessarily the best way to promote an asset either as an expression of validator capital nor which is the really important point is can it support future fixed income assets which includes credit systems? There's also an argument around a triunit account of emetics. I think we'll sort of skip over those.
00:08:06.764 - 00:09:01.864, Speaker A: But anyway, that's the argument that's kind of been the succinct argument that he's put around the mev burn model rather than the mev smoothing model, which I think was first proposed maybe two years ago. So what about economic design at the layer two? So can the layer two get a piece of this macro candidacy? I think it's a lot harder. It doesn't have canonicality in its L one it's not actually sort of necessary to the creation of the layer two network that there should be a native asset. ETH is there as an expression for denomination, so it doesn't have canadacy as a macro asset quite the same way. There's not that sort of canonical role that it's granted. There's actually no binding equivalent to the board shareholder relationship or any sort of source of value capture, cash value capture we've seen historically that ensures that there is a constanturing of margin. It just kind of doesn't really exist.
00:09:01.864 - 00:09:44.716, Speaker A: So I think that needs to be thought about a bit. It's typically meted by gas. There is some history around telecom companies and as we saw some people were using telecom companies data to build Skype. Not that was necessary in the end of great success story but that certainly was an application that had the power to price discriminate between users. It could tell the difference between packets of data by definition in a way that the telecom couldn't. I suspect the layer two is closer to the telecom company at the moment, but Mev may be maybe an exception to that. The other thing is protocols need to freeze these midair reconstructions of the aircraft that are done sort of midair by protocols today.
00:09:44.716 - 00:10:58.180, Speaker A: They can still happen but they probably have to become more and more and more minimal and you need to leave innovation to where security concerns. So sort of data availability guarantees execution is being gradually loosened as you go up the layers of the infrastructure and that's where you can probably afford to experiment because you're probably not carrying the weight of business that is being carried ultimately by the layer one and layer two. There's also, I think a sort of sleepwalking sense for the community in which this stuff is incredibly hard to build. It's created, it's required a huge amount of accumulated genius and we've seen actually a lot of it on display today, a huge amount of accumulated genius to build these systems. But does that give us actually moral right of economic access to a return of the protocol layer? Big question. So the layer two, I think as much as anything it's a matter of sort of psychology and is the business and are these infrastructure businesses more widely prepared to just keep on looking for the trust residues that are left once they've done their amazing work? The ZKP sort of extinguishes a lot of the primitives of business economics that you're sort of used to trying to find in building some kind of business or service. But plenty is left.
00:10:58.180 - 00:11:37.036, Speaker A: Arguably the surface of utility actually widens and there are lots of businesses you can build on top of this. I've listed some examples here, just we all know about the wallet that sort of never goes away. Number three, the developer platform. That's a kind of trust relationship that does not actually imperil the user's right of priority, bear access to their asset. But there is a role for sort of threat detection and deployment migrations, migrations of user funds, migrations of smart contracts. That probably means that there is a long term value extraction opportunity there. And then number two is kind of weird.
00:11:37.036 - 00:12:43.796, Speaker A: I don't think people I'm calling this the virtual private computer but there are two of these novel VMs that support private state and this might be part of a route towards the final flourishing of our general migration to the cloud. So we've been gradually sort of walking off the edge of our physical hardware and our computers are really sort of not physically sort of present where we think they are. A lot of the compute and the storage is actually going off chain. This in some senses could be the final flourishing of that as you have a fully, fully validated Ephemeral computer that's running on something like a blockchain network. Of course, the difficulty with computational privacy can be well, and we heard this earlier, I can't remember who said it, but there's sort of essentially more Balkanization of state, it's more single player mode. And so sort of the questions then start to open, well, do we really need this in a sort of on chain or in an off chain environment more generally? I'd sort of ask infrastructure companies to keep on looking for the pair business. So keep hold of your companies, don't dissolve them.
00:12:43.796 - 00:13:16.320, Speaker A: You probably will need them. Obviously the end game for a lot of these protocols tends to be sort of wind up the company and the token goes out and then it's got to sort of find its own economic way in the world, seek the pair business. Lots of historic examples here. So the older one and the classic one, the one that all VCs like talking about is MongoDB Inc. But there's also next JS and Versailles. There's lots of kind of modern examples as well. The open source thing, the utility and then the trust residue, the thing you need to provide to the user and they come to depend on you and this opportunity for value extraction.
00:13:16.320 - 00:14:10.080, Speaker A: Okay, so I quickly want to return to a point I made about the macro asset and the stability of the asset and what the implications this has for validator capital. So a very basic theory of the rational staker is the validator return on investment is something like it's a fixed income instrument, something like fixed the fixed free rate, whatever that is, the slashing risk premium, which I think we all assume in the long run to be quite small. And then there's going to be some sort of FX risk premium. And you can see this in classical fixed income markets. These differences really do exist. Corporates who issue debt in different currencies and there are also even emerging market countries that will do kind of us denominated debt and sort of debt denominated in their own currency. And they often pay more for their own currency because it's less liquid, more volatile, less widely held.
00:14:10.080 - 00:15:00.828, Speaker A: So this could mean that the moment a layer two or any piece of infrastructure decides to accept validator capital in, let's say, ETH versus its own token, you could end up opening up a two speed validator capital system, one with a tighter ROI and the other with a wider ROI. And this could even give rise to sort of virtuous and vicious circles. So for example, the higher ROI instrument is the one that the protocol wants to deprioritize. The reason is it doesn't attract as much validator capital for the same mental security fee that's paid. And so that then becomes a less widely held asset, less liquid, it requires a higher premium, et cetera. And you can see the cycle go round and round. And on the flip side, you could end up with ETH becoming a more and more widely accepted expression of validator capital.
00:15:00.828 - 00:15:50.960, Speaker A: And it enjoys the converse phenomenon so quickly. Here's the example of an emerging market country. So Mexico for a long time and I think still does have some USD bonds outstanding and you saw this differential, you saw these extra premium. I'm not sure whether you can see it on that slide but basically I've added in extra premium, extra returns. So between the eight, what is that 7% bond and the eight and a half percent bond, the extra return, the extra amount that the rational lender, the rational owner of the bond needs to be compensated for holding the peso denominated asset versus the USD denominated asset. So here it's illustratively 150 bips. On the right hand side I've done an again illustrative example of what the layer two computation might be.
00:15:50.960 - 00:17:14.456, Speaker A: Now, the reason I've equilibrated the left and right hand sides of those types of I should say in the blue by the way, that's the capital balance and in the red is the sort of red and yellow is the income balance. So let's suppose that there is a really dramatic difference between the liquidity, the price stability of ETH and the L two asset. So we might see, I don't know, it could be a differential of 8% versus 3% return on the validator capital. Now, if we hold fixed and this is a big assumption, but if we hold fixed somewhat, the amount of fees that are available to the Lt stakers and you equilibrate those, you can sort of see that the result. Of some sort of efficient, rational staking market is you get 2.7 times whatever it is, the amount of staked ETH for the same amount of security fee and then for much higher efficiency for the level of security that you're providing to your users. So could I call this Jean Sharboneau a lot, this talk? I'm calling it Sharpeneau's return, which is this sort of ephemeral return that is due to the token holder, which is kind of if you're willing to be charitable.
00:17:14.456 - 00:17:49.924, Speaker A: And say this is sort of purchased knowingly and with the expectation of bearing the costs of bootstrapping the system. There's all this kind of proval work that needs to be subsidized. And so you kind of need this ephemeral return to sort of get the system going in the midterm. You then get the introduction, let's say, of ETH. And largely this might be because of competitive dynamics. Oh wow, I need to be cheaper for the same level of perceived security. Obviously there are lots of things that go into security but one of them is how many security dollars being posted against your L2 versus the other L two, because I don't want them going around saying they're more secure than I am.
00:17:49.924 - 00:18:10.376, Speaker A: So I have to now accept ETH. And so that's the moment. Then you get the two speed capital system and then you get that potentially sort of vicious circle in the L2 asset. So, again, this doesn't mean the L2 S cannot make money. They certainly can. And I'm going to go into how they can keep on to tracking value. Later on, I started to put together a value athletes.
00:18:10.376 - 00:18:36.768, Speaker A: I don't think we're going to get through any of this. So I'll just say sort of bottom right. So generally sort of sees, I think for us, sees more green than anything else. I'll just show you how this thing's constructed. So on the left you can see those sort of purple boxes, layer one, layer two, layer three. So layer the idea, the differences between these is layer one moves to layer two through execution scaling. Layer two moves to a layer three, let's say through data availability scaling.
00:18:36.768 - 00:19:50.120, Speaker A: Now, obviously, with Dank Sharding approaching, it's going to take a lot of Pudgy penguins to require possibly layer threes immediately, but at some point they will be very relevant. And then along the top you've got all of the sort of capital and service providers who might be engaged in the system. So from the kind of unstaked token on the left through to the capital provider proposer, and I put them essentially twice, one to sort of account for how big is the ultimate dollar market, and then the other is what is the ROI on the capital deployed into that market? You then got builders proof of farms, storage, and then you've got maybe the things that you won't have sort of, maybe looked at or thought about quite so much before are things like the virtual private computer, which I mentioned earlier. Where that's kind of the environment in which, let's suppose MIDN VM does not optimize for client side proofs. And then you've got some sort of remote computation for all of your private transactions. Well, in such a situation then there is a VPN like Role, perhaps even better for value extraction for the company that created the virtual machine in the very first place. They have that trust relationship with the user, developer, platforms, wallets.
00:19:50.120 - 00:21:02.820, Speaker A: I think we know the sorts of things we mean by something that has a kind of a trust relationship. Anyway, I think we'll try and make this public and then people hopefully criticize it and comment on it and over time we can maybe improve it, given time. I'm going to skip over this final thought. What are the crypto digital archaeologists going to find? Is the layer one EVM? Is it sort of not a wreck on the ocean bed, but is it sort of only relegated now to verifying proofs that's one possible endgame for that? Does Layer One mev actually become more like a wholesale market? And all the interesting mev travels down into the lower layers? Interested to sort of have some conversations with all the mev folks here afterwards to hear about that. Will layer twos with layer one defined DA be enough DA reduction following Danksharding to build, quote unquote, normal programs. And does the increasingly siloed execution environments of, say, Layer threes, layer Fours start to reduce mev opportunities? And to what extent? So, look, these are all just sort of questions. They're questions without answers.
00:21:02.820 - 00:21:06.790, Speaker A: And I think that's really the extent of the talk. Thanks very much.

00:00:07.280 - 00:00:33.804, Speaker A: Hi, everyone. I'm Cooper. I do product and strategy at Aztec Labs. I'm mostly here today just to share this QR code with you, I guess. So if there's one thing you do, you should scan this QR code, go to our research forum, and actually read the research that we did. I'm here today to talk about, like, kind of how we got to this research, why we care about it, why it's worth your time to pay attention as well. But if there's one thing you do, go check out our research forum.
00:00:33.804 - 00:01:07.926, Speaker A: Quick reminder, what Aztec is. It's a privacy first Zk zk rollup. This is a little bit of a tease, but eventually, perhaps, Aztec might be a universal layer for privacy on any chain, which could be interesting. Users generate client side zero knowledge proofs using Zack's latest proving system called honking. Um, we have fully programmable smart contracts and noir. Uh, and yeah, we have public private smart contract composability, uh, with a unique kind of account abstraction model. Uh, this is how we kind of got here in the design process.
00:01:07.926 - 00:01:35.964, Speaker A: I initially published an RFP of May of last year. Uh, I actually showed up to research day last year to present some of the initial ideas, which was quite cool. Uh, we decided on a protocol called for. Net, which stands for a fair election randomized on Ethereum trustlessly. It's a backronym. It's a terrible backronym, but it's basically a fair random leader election. Recently, in January, we basically decided to outsource proving to third party proving marketplaces in a protocol that we called sidecar.
00:01:35.964 - 00:02:01.364, Speaker A: And today I'm going to share some ideas about becoming a base roll up, which may or may not align with the for. Net roadmap. And, yeah, so last year I presented, it was actually the first talk I ever gave at Aztec. So thanks, MJ and John and everyone, for having me back. Cool to be with so many people I really admire. Yeah, last year I talked about a PBS federated proving network, which was quite cool. You could have a proving network, actually vote on which block becomes next.
00:02:01.364 - 00:02:30.924, Speaker A: You could actually have an SSLe using the whisk algorithm or a l two based auction. We ended up not using any of these, but that's what I presented on last year. And this is how the current design works. So you stake some tokens, potentially as tech tokens. On layer one, you have a random leader election. You have out of protocol PBS for block building, you have an out of protocol proof auction through something that we call Proverboost. Yeah, proving happens, you end up getting verification on l one once proving completes, and then the process repeats.
00:02:30.924 - 00:03:01.154, Speaker A: This is a very slow process, intentionally prioritizing safety over liveness. You basically wait till the last block is fully verified before proposing the next block, which guarantees that you can never have reorgs. At worst, you'd have a missed slot, but there would be no reorgs in the current design, and that's kind of important. A lot of the other designs I'll talk about can have pretty nasty reorgs. And. Yeah, so, quick shout out to Josh Bowen, Edamar and the Astria team, actually, for putting together a nice proposal for how this current for. Net design could outsource its blockbuilding to Astria.
00:03:01.154 - 00:03:30.492, Speaker A: Highly recommend scanning this QR code and reading it. I know Josh is speaking next, so appreciate their work here. And, yeah, so, yeah, we have these designs, right? They all have stake sequencer networks. You have actual people running aztec nodes. Why are we talking about based roll ups? The industry and, like, ecosystem interest in base roll ups has just skyrocketed, probably in the last year. So this was an idea originally articulated in 2018 with the original arbitrum white paper. The original roll up articulated was actually a base roll up.
00:03:30.492 - 00:04:14.454, Speaker A: It was like anyone can propose the next block into the state transition function. Kind of lost the plot somewhere with centralizing all the infrastructure in the next three, four, or five years. But then Justin Drake dropped a paper on ETH research, and then an anonymous person actually proposed it on the aztec research forum. I genuinely don't know who it is. And then in February, there's actually been a lot of revitalized interest in broadly ethereum shared sequencing and pre conformations, which are closely related to the base roll up research. And so this kind of superpower that gets unlocked, as Justin would say it, between shared sequencing based roll ups and pre conformations, is a really interesting design space that we're seeing a lot of roll ups, including aztec being super interested in. And, yeah, fast forward to March.
00:04:14.454 - 00:04:45.644, Speaker A: We published that research that I linked at the beginning called collaborative based roll ups, which actually is a potential endorsement for the model. We'll talk about why it might make sense for some, why it might not make sense for others that care more about privacy. This is just in Drake's definition. So a based roll up is one where the next l one proposer may, in collaboration with L1 searchers and builders, include the next block. It's pretty straightforward. It's the most basic design you could possibly come up with. And this is how simple it is.
00:04:45.644 - 00:05:00.436, Speaker A: This was the anonymous person's proposal in our research forum. Like the whole proposal fits in this one screenshot. It is a very simple architecture, very simple design. There's a decent chance that whoever submitted this is actually in this room. So shout out to you if you did this. We appreciate you. It's super simple.
00:05:00.436 - 00:05:38.164, Speaker A: You can see there's nothing going on here, but there is a problem. And so in public roll ups, we can just dump data somewhere and everyone can order those transactions. They can apply the state transition function, they can build ahead. They can propose the next block. Basically, in ZK rollups, specifically ones that use state diffs, you have to build ahead before proving happens. So you have to basically propose block sequentially on top of each other, knowing that they have to later be proven. And so if you're proposing a bunch of blocks on top of each other and block five doesn't get proven, any block built on top of block five might get reorged out of the network.
00:05:38.164 - 00:06:34.044, Speaker A: And so you can have really nasty problems if you actually allow building ahead. In ZK based roll ups, where people can propose blocks before the other ones are actually verified and finalized, generally, the whole idea is that people might publish the state diffs, but the actual transaction inputs to the state diffs might not be shared. So people know what the resulting state is, but they might not have all the relevant information to update application states to alert their users. You might be able to progress the chain, but it might not be practical to use for everyone. And so, yeah, basically, if state diffs are shared, but the actual transaction data that generated the state difs aren't shared, you can actually get some pretty nasty reorgs, because those blocks might not be able to eventually get proven. Generally, we propose that being collaborative can fix this, and I'll illustrate in a diagram how this will work. So you have like a privacy focused l two user, they're going to send a transaction plus a zero knowledge proof to.
00:06:34.044 - 00:06:51.840, Speaker A: In this case, it's an l one superbuilder, or validator. That's what they are called. When they start validating l two s, l three s. Whatever. This l one superbuilder validator is going to put this transaction in a block and then put that state diff into l one. It's going to say, thanks for the fees. Ethereum doesn't care.
00:06:51.840 - 00:07:24.204, Speaker A: Ethereum doesn't know. The next privacy focused l two user is like, my friend sent me funds, I want to use them. But you can see in the top section the original supervalidator didn't publish the transaction inputs, they just published the state diffs. And because of that, the next superbuilder validator doesn't know if that transaction data will eventually get revealed and be able to get proven. And so they can't build a head on that block. They basically don't know if they build a head on that block if they're going to get reorged. And then that would reorg their block as well.
00:07:24.204 - 00:08:16.284, Speaker A: So basically, this actually kind of a pretty simple model where this actually doesn't impact this user other than a perceived liveness failure. They would have to wait until that block that this first superbuilder validator proposed gets finalized in the chain before they get the rest of their data, and then they know that they're never going to get reorged. Um, so, uh, we proposed kind of this idea of a collaborative based roll up. So it's a base roll up where the inputs to the state transition function are always derivable from published data. Published data, very specifically in the term of like Da layers and the way Celestia uses it. Um, if the actual transaction data prior to the state difs being put on chain are made available or published somewhere, uh, then you can actually have a collaborative nature where, you know, even the state of pending blocks are able to be proven, uh, eventually. So it's a really interesting design.
00:08:16.284 - 00:08:52.795, Speaker A: Uh, and it basically just gets you to this. Like, it's a very subtle change. But in this case, like the l one superbuilder validator just has to publish the transactions to its DA layer of choice or to the protocol's DA layer of choice. And the next superbuilder validator actually knows that they have all of the data required, and they know that this block will eventually be proven. So they know that they can confidently propose a block and build a head on top of it. Yeah, this is one pretty naive, obvious example, but it articulates kind of the value of data publication. And so there's a bunch of ways that we think Aztec can make our block times go faster.
00:08:52.795 - 00:09:25.444, Speaker A: I know I'm kind of running over on time, so I'm going to wrap it up here soon. We could build an l two consensus network, right? We could take tendermin or whatever off the shelf, and you could basically try to attest to that transaction data being seen by a super majority of the network. And therefore, once that attestation comes in, they could propose the next block and know that it's not going to get reorged. You could do some type of, we call it private kernel proof aggregation. So you could, like, pre prove the private parts of Aztec's roll up and then put that on chain with the state diff. Kind of really hard to do fast. That could be a whole talk in itself, but it's a really cool idea if someone can figure it out.
00:09:25.444 - 00:10:14.294, Speaker A: The naive thing that I articulated on the previous slide is what we'd call Validia mode, where you just dump a bunch of data onto a da layer of your choice. Um, and it's like a real possibility this might be the most easy option, um, high celestia. Um, and then the other fourth option that we're considering and actually probably pursuing the most aggressively is what we would call, like an economic optimistic data availability solution, uh, where basically a proposer puts up a bond with their block proposal, saying that eventually this, uh, transaction data will be revealed before the proving window ends. Uh, so it's basically like a commitment to build ahead. And the person proposing the next block knows that there's like ten or $100,000 of additional reorgan insurance or something on top of the block. Most of these can be based or use a for net style staking set. They're not mutually exclusive.
00:10:14.294 - 00:10:47.082, Speaker A: It's like, do you want your own validator or not? And so at a high level, most of the designs end up looking kind of like this. You have a private mempool, you have a public mempool. It's going to an aztec builder. They go to infernet sequencer, they sign the block, it goes to the l one builder, it goes onto the chain, and then you have a proverboost auction for the rights to prove this block between all the proving marketplaces. In a base design, you could basically just collapse the l two builder and l one builder into a single entity. Otherwise, the designs look generally the same. Just merge those and.
00:10:47.082 - 00:11:10.834, Speaker A: Yeah. So, high level recap of our key findings. There's various flavors of base roll ups, there's vanilla based roll ups, there's all these other flavors here. We articulated collaborative based roll ups. Um, and so these are findings for all flavors of base roll ups, not just collaborative. Um, definitely simplifies your engineering complexity. Uh, simplifies protocol complexity, makes it easier to rationalize.
00:11:10.834 - 00:11:47.368, Speaker A: I think three in the pros section is really, really important. These pre conformation shared sequencing calls and whatnot are very valuable. Uh, it is the easiest and most clear path to fixing, uh, roll up fragmentation that aztec sees. Um, and so if there's a huge argument for becoming a base roll up, it is probably in the actual user and operator experience benefits that it brings. Um, it does reduce your sovereignty and increases your reliance on Ethereum's roadmap. Your roadmap just becomes Ethereum's roadmap, um, which is quite uncertain today. Um, and it could actually centralize not only your validator set, obviously, but Ethereum's validator set as well.
00:11:47.368 - 00:12:14.110, Speaker A: Uh, and it could increase reliance on re staking. Um, there's no historical precedent, really, so, like, I don't really know how the market will react. There's probably like a 40 IQ argument that networks with staked validator sets and high economic security are just worth more. And so it'll be interesting to see how the market tries to react to that. We have a related research. There's what we call the aztec simulation network. It's a Python based implementation and a CAD.
00:12:14.110 - 00:12:58.080, Speaker A: CAD framework basically implements the Frenet insidecar protocols that we talked about. It simulates one ethereum block at a time and runs thousands or hundreds of thousands of machine learning models against them to see what might possibly happen. It's quite cool. I'm surprised that there's no standard ethereum simulation out there that all the teams are taking off the shelf and kind of working with, iterating with, playing with, and fitting their l two based solutions on top of that simulation. So this could be a potentially interesting first work in that direction of standardizing simulation based efforts. We did a whole notebook specifically on l one, censorship. And so if you scan this QR code, you can read a write up report of how concerned Aztec is about l one, censorship, which is quite cool.
00:12:58.080 - 00:13:27.794, Speaker A: You can also check out the code. And yeah, Aztec is not currently a based roll up, but it might become one someday. It really is in the hands of its community. We really mean that. So if anyone feels strongly about it, I'd love to talk to you after this or join us on the research forum. And, yeah, the last thing I'll drop is that Aztec does have a new section in our documentation, which is the first draft of our protocol specifications. You guys are the right audience to actually care about and maybe provide feedback to them.
00:13:27.794 - 00:13:33.974, Speaker A: Highly recommend checking them out. And yeah, thank you all for your time. I really appreciate it.

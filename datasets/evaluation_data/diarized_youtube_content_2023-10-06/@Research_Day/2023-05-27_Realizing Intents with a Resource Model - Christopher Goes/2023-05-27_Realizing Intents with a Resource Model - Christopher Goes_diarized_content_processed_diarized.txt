00:00:09.990 - 00:00:30.434, Speaker A: Hello everyone. Thank you. For those of you who are not leaving to go take an early lunch. No, just kidding. I love you too. I'm Christopher, I work on Anoma and the talk is very opportunely timed, I guess what I'm talking about here, just to situate it a little bit, also public Safety Advisory. I wrote these slides at like five in the morning.
00:00:30.434 - 00:01:15.226, Speaker A: I was still kind of jet lags. They might not be pedagogically optimized if you like the talk, but you think the slides are confusing or you didn't like the talk because you thought the slides were confusing. In either case, feel free to come find me afterwards and complain about it. So I think it might be helpful just for this crowd here to situate anoma in relation to, say, a project like Suave. I guess we envision our role in a broader ecosystem as sort of doing things which are complementary, like doing things maybe which other people aren't doing based on what constraints we might have that are different. And in particular one thing which is different about anoma as compared to kind of projects in the Ethereum ecosystem is basically that we are willing to ditch backwards compatibility. As in that I've worked with Ethereum and I've worked with Cosmos.
00:01:15.226 - 00:01:57.626, Speaker A: And both of those systems are great and they're working in the real world and they have real users and those things are amazing. And I'm thrilled that people are building on those systems. On the other hand, I think those systems also embed a lot of design assumptions. And many of them are kind of old. Like they're design assumptions that were made based on our understanding of the world five years ago. And some of those assumptions, I think, have proved to be right and some of them, I think, have proved to be, if not wrong, at least kind of orthogonal to what has actually happened. So in that spirit, I'm going to explain a little bit about how taking this kind of intense anoma has been working on this intent centric idea, often phrased in kind of vague terms for a little while.
00:01:57.626 - 00:02:23.186, Speaker A: And now it's kind of permeated its way through all the layers of the protocol stack to what you might call a VM. And this talk is going to be about that. So to kind of relate it to the previous one, this is like a proposal for an intent language or so to speak. And I'm not what is an intent? That's a great question. Maybe intents are decided based on extensional equality. There's just no one true answer. I'm not going to try and give the one true holy answer to what is an intent.
00:02:23.186 - 00:02:47.706, Speaker A: This is kind of our answer to how can intents be represented? And it's an answer that we think satisfies design criteria that many of these projects may actually share. So we think it's interesting for this audience. So this talk was inspired by basically a tweet and a meme. I would like to give credit. So the Tweet. Thank you. Andrew Miller, who I haven't seen here, but maybe he will somehow see this later.
00:02:47.706 - 00:03:26.026, Speaker A: Intents and transactions aren't really let's fight. Well, I mean, if you squint really hard, intense transactions, there's like some data, you send it to the distributed system, like something happens. But I think that's like squinting slightly too hard, and I'll get into why oh, you can't see this. Well, anyway, this one thanks, Sheen from Flashbots for this meme. So I don't even know what this meme is called, but Vlad CT 43 37 crowd anoma, they have no idea tests or higher or commitments with extensive literature defining its semantics. Well, yes. No.
00:03:26.026 - 00:04:10.226, Speaker A: So, interestingly, the extensive literature is filled with what are called folk theorems I E, where people seem to all know something, but it took a while for someone to write it down. And I think intents are kind of in fact, they're kind of the same thing from the research literature also have this folk theorem property. You see stuff like account abstraction and these kind of user gas payment systems kind of approaching the concept of an intent, but in this domain specific way. So this talk is about a kind of general intent centric VM. And let me clarify a little bit what I mean by VM, because that word is used to refer to many things which I think are not really in the same category. So, a long time ago that people were building computers, and they wanted those computers to execute programs. And those computers had hardware constraints.
00:04:10.226 - 00:04:29.626, Speaker A: They had like a processing unit. They had some instructions that processing unit could execute. They had some kind of various levels of memory at different speed to sort of durability trade offs. They had registers in a stack. They had volatile memory, slightly less fast volatile, and they had non volatile storage. And they wanted to run programs. I mean, very reasonable.
00:04:29.626 - 00:04:43.614, Speaker A: This is like 1960. No one's thinking about mev. They wanted to execute programs sequentially. So if you go on the Wikipedia page, it's where I got it from. Not going to make up my own diagram. And look at von Neumann architectures. You'll see something like this diagram.
00:04:43.614 - 00:05:17.840, Speaker A: And basically the distinction between control and arithmetic logic units doesn't matter anymore. But the same kind know, there's a communication system between the CPU, it's executing instructions sequentially, and as a result, you kind of run through your programs, accessing memory, input output when you need to, right? So bonus credit to anyone who knows where this screenshot is from. But the EVM is in the grand von Neumann style, von Neumann VM. It has program counter. It has an instruction set. It has different kind of layers of memory and storage, and it goes through and it runs programs sequentially. Great.
00:05:17.840 - 00:06:01.002, Speaker A: And I am going to talk about a VM, which is designed to do something else. So it's not, like, not really competing with the EVM, but it is doing something which I think is perhaps more suitable to this Intent centric world. In particular. This VM is designed to match conditional commitments atomically, and commitments involve programs. So you might say, well, of course you just need something that will execute programs. Why don't you just use a von Neumann VM? And my answer is that, yes, you can do that. But it's, like, not quite the relevant problem because what you want to do in matching commitments is to execute several commitments atomically and in an intent centric world, as I'll kind of get to in more specificity later in the talk.
00:06:01.002 - 00:06:23.198, Speaker A: You care about whether the result of executing those intents or those commitments is satisfactory to all involved parties. Maybe you care a little bit less about the specific path of execution you took to get there. Right. So there's a slightly different design constraint. The EVM also includes a few other things which are, like, not exactly von Neumann things. It includes message passing between programs. It includes scheduling.
00:06:23.198 - 00:06:53.834, Speaker A: Those are relevant, I think, and I will get to them later. Sometimes something people bring up in sort of the broad discourse is like, Turing completeness. Well, if you want something, why don't you just emulate it on this Turing complete VM, which we already have. So bonus credit number two to anyone who knows where this is from. I think this is harder, actually, but you definitely are an OG if you recognize this quote, I'll tell you at the end of the talk. And my answer is, yes, you can emulate the thing which I'm talking about upon the EVM. I think that's great.
00:06:53.834 - 00:07:37.094, Speaker A: But the question I'm interested in is, like, what does the execution environment look like for intents? And how you kind of emulate that as a sort of interesting from a performance standpoint, but kind of separate question. Like, you could also emulate it on some other non EVM von Neumann machine, and nothing would change that much. So I want to go just to kind of go back a little bit into the research literature, just to add another answer to the question of what is an intent? This meme is my own. Unfortunately, you can't see the bottom, but it says intents are cybernetic commitments to the future human l synthesis, something like that. It doesn't matter, because I'm not going to talk about that. I'm mostly going to talk about the third thing. So what are intents? Intents are just transactions.
00:07:37.094 - 00:08:02.370, Speaker A: Intents are binding conditional commitments from 50 year old game theory. Right? So here's the 50 year old game theory. The first kind of folk theorem to be written down by Friedman in 1971 was this equilibrium for supergames and supergames. I'm I'm very sad that that term has kind of gone out of fashion. I think it's a more fun term than, like, repeated games. supergames. Who doesn't want to play the super game.
00:08:02.370 - 00:08:28.666, Speaker A: It's like the infinite supergame. Anyway, the result established in this paper was just that repeated interaction can result in any feasible individually rational payoff. And then a bunch of recent work, I'm just going to cite one. There are like 15 papers that talk probably more, I just haven't read them. But that talk about different variants of this idea is program equilibria. I think this paper is particularly clear, so I recommend it. And the idea of program equilibria is basically that you can achieve this same result.
00:08:28.666 - 00:09:23.258, Speaker A: You can get any feasible individually rational payoff. If you have users, instead of just taking actions themselves, use what are called commitment devices or use programs and commit themselves to a strategy. And because this provides like a credible guarantee of how users will act, then you could do stuff like this in the Prisoner's Dilemma if my program is the same as the other player's program, then cooperate. Else defect seems like very straightforward, right? So program equilibria, I think are what you might call the closest near term or relatively recent research basis for intents. And I think the research literature here at least like I'll talk in just a SEC about what I think we need to change. But it describes the problem pretty well from a mathematical perspective in terms of what we want to get out of these systems and why it's interesting. So from that perspective, I want to ask the kind of different direction of questions.
00:09:23.258 - 00:09:54.114, Speaker A: Forget blockchains, like whatever. What if we just wanted to center around commitments and then we want to settle them somewhere? You do need public knowledge to make it credible. Let's just say commitments are functions. We publish them to a blockchain and the blockchain calculates this equilibrium which is sort of individually rational and feasible. I argued that this runs into basically four challenges. So if you just try and take the research literature and implement it, I think you run into all of these challenges. Maybe there are three, not four.
00:09:54.114 - 00:10:10.810, Speaker A: It's not an exact mathematical characterization. Some of them are kind of related to each other and depend on the particular language. But I want to go over each of these in turn. The first is sort of termination. The second is function introspection. The third is this difference between nominal and structural identities. And the fourth is unclear information flow.
00:10:10.810 - 00:10:45.474, Speaker A: Right. Termination. Fixed point finding. So if you use the kind of most powerful representation in the research literature which gives you the best game theoretic results, you need to use higher order commitments, as in commitments which are dependent on other players commitments, and you want eventually your execution to terminate. Which basically means that you need to somehow, if your commitments are dependent on what the other players do and what the other players do, or dependent on what you're committing to do, that system runs forever unless someone short circuits somehow. And I've seen kind of two approaches in the research literature to short circuiting. One of them is to use randomness.
00:10:45.474 - 00:11:31.590, Speaker A: So if you have kind of a shared randomness beacon then you could say like oh well, 1% of the time I'll just cooperate, else I'll call the other function and that function will call me and I will call that other function until some randomness happens and then we'll both cooperate and then it will terminate. Right? So it gets you basically the same results modulus on epsilon. But I think this is like a more serious implementation problem than it might appear to be for two reasons. One, randomness. Although it's possible to get in these kind of distributed systems threshold BLS signatures or something, it adds an assumption which it seems like you maybe don't want unless you really absolutely need it. And there's this kind of annoying trade off that you have to now run for a lot of time until your randomness causes the system to terminate. And when your execution is replicated that seems like a very expensive thing to do.
00:11:31.590 - 00:12:10.658, Speaker A: Another way to do this is that you can add a separate payoff, basically bribe someone to make you terminate. And that also works but I think it sort of creates kind of unnecessary mev. So program equilibria and the reason I said these were kind of related is the program equilibria deals with this problem by checking, by reading the source code for the other guy's program. So if we go back so in the program equilibrium paper, they write the program like this. There's some very simple syntax but this is just the example. If my program equals the other player program, then do cooperate, else do defect. That's great.
00:12:10.658 - 00:13:14.898, Speaker A: The problem is that this equal sign is like open type theory research problem in the general case in particular, if you want to deal with sort of programmatic preferences which are going to encode complex things and you care about specific sort of structures of if you do this kind of thing, what does your counterpart do? You would need full dependent types. Like you basically need to prove arbitrary properties of these other functions to figure out what your fixed point is. So this seems very heavyweight. Of course there are dependently typed languages but ideally we wouldn't need to embed dependent types as a design requirement for our intent centric architecture. The third challenge is what I call I don't know if this is exactly the right term, but what I call nominal versus structural identity, which is that in these formalisms all of the players are known and they're numbered. So they're referred to each other like by index. And if you have a formalism, I think like the one from 2011 that uses commitment devices, these devices are referred to each other by index.
00:13:14.898 - 00:14:34.240, Speaker A: There's kind of a closed world model where you can say oh well, I care about what this specific player does and I know beforehand who all the players are. I don't think this matches what we need in the kind of typical distributed blockchain setting. In particular, we're dealing with this open world where we don't necessarily know, I mean we definitely don't know all the identities of the players. We don't want to know for privacy reasons and the set is like very large and anyway, so we typically don't care because we want to be able to find counterparties on the basis of structural identity, like what capabilities they have, where something like owning a token is a capability. Maybe we're actually trying to use these systems to avoid war and then we want credible attestations that this party can actually take some action in the external world, something like this. So we need to change the kind of basis of identity from this literature to include all actions that matter in our context. My sort of fourth 4th thing that I think we need to change is not precisely characterized, but typically these constructions from the research literature require or rely on this magic, logically centralized commitment to executing computer.
00:14:34.240 - 00:15:43.990, Speaker A: And it needs to take all these commitments and calculate the equilibrium somehow or run them all or do something fancy and then it needs to reach the output that state, right? This is fine, but unfortunately it requires this single logical point and it doesn't give you this kind of fine grained informational control. Like you might want to know things like oh, I have a bunch of these commitments and some of them are not codependent, so in fact I can deal with them separately. And this framework doesn't natively give you a way to check that. Okay, so now I'm going to talk about the kind of specific construction that we have in mind, which we call a resource logic. And the reason we ended up choosing this term is that there seem to be a bunch of similarities to kind of distributed linear logic. We care about no double spends in the blockchain context and we like the idea of modeling everything as resources. And there's a really basic kind of trick that resource logic uses to solve or address several of these concerns.
00:15:43.990 - 00:16:37.330, Speaker A: And that trick is to forget some information or to not care about some information. And that information is the path of execution. So in a typical kind of commitment scheme, you have like commitments, you sort of do one commitment, then you check the next commitment, then you check the next commitment. It's like executing small state transitions one at a time. And if you look at this in kind of a branching flow maybe depending on what player one does. If player one is the red arrow, you go to S One or S one prime, then depending on what player two does, you go to S two, S two prime A, S two prime B, et cetera, until you reach some final terminating state. And my argument is that we actually have this brilliant property which allows us to not need to do this, which is optimicity and we can get this by changing the type slightly.
00:16:37.330 - 00:17:45.478, Speaker A: So instead of having commitments be kind of higher order functions, we can instead just pretend that we already executed everything. We can say that commitments will take some final state including some specific strategies which are played by particular players and commitments will say yes, I'm okay with that, or no I'm not. So still they're issued by particular parties who have the ability to authorize particular actions. This is like a very high level view, but if we do this, then we can not care about the path. So a sort of way to bring this into a practical context is that the earlier talk talked a little bit about these different sort of intent centric vertical specialized systems like account abstraction or something like this. And one thing which these systems often differ in is like where the execution is specifically happening. So there's some, you know, still some ultimately some verification on chain but sometimes someone is executing to do a meta transaction, sometimes some searcher or some builder is executing the execution is happening somewhere.
00:17:45.478 - 00:18:45.600, Speaker A: And if we can architect our VM in a way which doesn't care about where the execution happens as long as the final result is in line with everyone's preferences and still satisfies the kind of state transition constraints of the system. Then we sort of generalize all of these cases, as in like, people can choose a specific topology for where the specific components of execution will happen at Runtime and all that. We need to check on the final blockchain that we've agreed to trust for sort of consensus and stake custody purposes is that everyone who took an action in this transaction is happy with the final outcome. So how do we encode this in Anomalo? We encode this in something that we call resources. And resources are a little bit like smart contracts but not quite. If you squint, you could also call them smart contracts. But that term has come to be associated with many things and some of those things resources are not.
00:18:45.600 - 00:19:32.586, Speaker A: In particular, resources do not encode imperative execution logic. So smart contracts typically encode like start at state one, do some computation, end at state two, right? Resources don't encode this. Instead, resources encode constraints. So in Enoma each resource has what we call a logic, where a logic is this kind of predicate function over partial transactions which I'll talk about in a second, maybe some arguments, prefix, suffix, quantity which is like if you have different tokens, it's just for the linear logic balance. So if you have different tokens, you might have one unit of a token, two units of a token. You want to encode fungibility into your base system because it gives you a lot of capabilities and some kind of arbitrary value. So if you want to squint and think about them as smart contracts.
00:19:32.586 - 00:20:22.638, Speaker A: The logic is the code and the value is like the state in the ethereum system. But we have this built in way to encode fungibility into the VM and resources don't specify any kind of execution logic. Oops okay, then the units of the system are kind of the closest thing to an intent how you might encode an intent, let's say, although it could also contain subsided information, is what we call a partial transaction. A partial transaction includes two sets of resources. It includes a set of resources which were consumed and a set of new resources which were created. And it includes some arbitrary extra data such as signatures. And the idea behind partial transactions is that we can have this kind of resource validity check at the partial transaction level.
00:20:22.638 - 00:21:01.050, Speaker A: So partial transaction may not be entirely balanced. So we might spend resources that we don't actually have or we might create resources that aren't yet consumed. But we can check if all of the predicates are satisfied just by mapping over them. Right? Then we can separate out what we call the balance check. So the balance check relies on maybe this kind of fungibility of resources question is not so important for the order of execution point. But you could think of there as being different denominations of resources. The denomination of a resource is calculated based on the logic prefix kind of the static data.
00:21:01.050 - 00:21:39.122, Speaker A: And then what we require in order to actually have a transaction be balanced is that there's no change. Basically, the sum of the sort of delta of all of the created resources, less the sum of the delta of all the consumed resources is zero. So this is the linear logic check if we think about the system in linear logic terms. Now, this has several nice properties. One is that partial transactions compose. So if you just take two partial transactions and they're valid and you join their created and consumed resources, you end up with another valid partial transaction. So the system is compositional.
00:21:39.122 - 00:22:10.026, Speaker A: Now, they might conflict with each other or something. This has nothing to do with ordering, but the partial transactions themselves compose. Also, a transaction, like a valid full transaction, is just a partial transaction that in fact happens to be balanced. So there's no sort of hard distinction between intents and transactions anymore. And when you create these partial transactions and compose them and append to them, you can do all of that execution kind of wherever you want. It just needs to end in this valid full transaction which you published to the blockchain. So you could take.
00:22:10.026 - 00:23:24.546, Speaker A: So, for example, if you think about the specific Prisoners Dilemma case, it's almost like you just pretend that you can do some execution which you actually can't do. So you pretend that you're the other player and you create a resource that says that your counterparty cooperates and you consume a resource that says that your counterparty cooperates and you create a resource that says that you cooperate, which you have the permissions to do. You don't have the permissions to create a resource that says that your counterparty cooperates, but you can consume one that says that your counterparty cooperates. Where then this balance check sort of defers the check of the validity of the whole thing to the transaction level instead of the partial transaction level. So symmetric partial transactions, if you create a partial transaction that says that you cooperate and consume a resource that says that your counterparty cooperates and your counterparty creates just the inverse, then these will balance because the denominations cancel out. If you use this for something like a token swap, then you just consume the tokens resource representing the tokens that you already have and want to pay. Create a resource of new tokens assigned to you and similarly symmetric partial transactions will balance maybe with some slack.
00:23:24.546 - 00:24:24.482, Speaker A: That's like an Mev question, which I think is very interesting but orthogonal to this VM design question. So I'm not going to talk about it. And I will argue that this model addresses these concerns with kind of faithfully translating this conditional commitment concept. In particular, it addresses this kind of like termination and introspection difficulty by just splitting computation from verification. So if we go back I think this slide is helpful if we go back to the kind of path in the configuration space of potential state changes that we can make. When you make a partial transaction, you can make some state changes which you don't even have the permission to do, like they're far down the line, right? But then you can send that partial transaction to someone else who could make the state changes which if the whole system were sequential, would have happened first. But they don't need to happen first anymore because we've made our VM agnostic to the actual ordering of computation.
00:24:24.482 - 00:25:46.838, Speaker A: All it needs to care about is that everything checks out okay. And verification. Then, to deal with nominal and structural identities, when we specify interactions on the basis of resources instead of on the basis of like this 1 may be simpler, like, Blockchains kind of already do this, but just to be comprehensive, resources already connote the ability to do something because they're owned. So inclusion of other players is explicit in this model, if you want to check that your counterparty cooperates, you just put that check right in the validity check of the partial transaction, right? You consume the resource that says that your counterparty cooperates and the whole transaction is only valid if your counterparty in fact sees this and creates the resource that says that they cooperate, then addressing Information Flow so this is a VM. It's not like a language for information flow, but because validity conditions are separate from the balance check, this helps a lot with building a kind of good substrate for information flow in particular, it means that you can make the proofs of validity separately and prior to checking the balance. So if I spend my tokens in a partial transaction and the whole thing is unbalanced, but I can go ahead and make the proof for that spend. I can hide the note where they came from.
00:25:46.838 - 00:26:35.410, Speaker A: I can send the partial transaction to you and you can see what constraints have to be satisfied in order to balance it without seeing the path of execution that allowed me to create that potential state in the first place. So the validity constraints are, so to speak, are forwarded, and they can kind of be satisfied at any point during execution as long as they're all satisfied at the end. Right. Okay. So the spicy take, which I did not offer a comprehensive mathematical defense of in this talk, but I haven't heard any good counterarguments yet, is that this research structure is kind of inevitable, I think. As in that what? You really want in order to generalize intents is to build a kind of VM or an execution environment which is agnostic to where execution happened. You don't want it to care about the path.
00:26:35.410 - 00:27:12.306, Speaker A: You only want it to care about the end result. You could still use the EVM to do execution. I think that's fine. But I think you would end up with something on top of this that will kind of do this sort of intent matching and that will end up splitting out the validity and balance checks in this way. Then I argue if you end up with this, then the EVM does things that maybe you don't need. Like in particular, it does this sequential message passing execution, which is fine, but I just don't think it solves the problem that matching conditional commitments wants to solve because it is path dependent and we don't care about the path. Cool.
00:27:12.306 - 00:28:07.730, Speaker A: So just the last part here kind of to touch upon the first talk in going towards a more privacy centric world, is how I think this resource model can act as a substrate for information flow control. So I want to first clarify what I don't mean by substrate for information flow control. There's this great paper called Viaduct by Ralph Recto, some others, Cornell, which I think is a good resource for people trying to think about information flow control in an MEB context, blockchain context. And that paper includes a language for information flow control. And this is not a language for information flow control. It's kind of like a runtime. So the way this paper VDAP structures things is that they have a high level source language that describes in a pretty declarative way information flow control policies like constraints on who is trusted, that they sort of b or not A, includes like integrity assumptions and information assumptions.
00:28:07.730 - 00:29:02.898, Speaker A: And maybe such language could include cryptographic assumptions that you're willing to make other kinds of constraints. Then that. Language is like compiled somehow into a bunch of instructions which are run using actual cryptographic primitives. The runtime execution engine is responsible for running the primitives in the correct sequence with real data. And this is what I think the resource model is kind of suitable for as and it could be part of at least with specific cryptographic primitives. This kind of runtime that executes partial transactions with real data and if it's constructed correctly, can enforce information flow control policies by calling the primitives in the right order, right? So this is not you could have many different higher level languages which compiled and run on something like this. But I think this system is helpful because it is very amenable to what I call the least powerful primitive.
00:29:02.898 - 00:30:24.170, Speaker A: The rule should be in quotes really, because it's not a rule, it's just a heuristic. But there's kind of this power ranking of cryptography primitives where you have very powerful primitives that do everything but are extremely slow and you have very fast primitives that do only one thing like hash functions or even slightly in the middle, zero knowledge proofs, but are much faster. And typically you want to architect your system so that you can use the least powerful primitive you need for the specific task you're trying to do under the specific information flow constraints that you have because it will make the thing more efficient and faster, just amenable to kind of replicated verification, the cases EKB, stuff like this. So an example of how you would kind of use this runtime, this resource logic runtime to provide the kind of information flow control people might want is let's say you wanted to do kind of solver selection. Let's say in this system you still have to reveal some information to the solvers in order for them to match your intents or for them to put together partial transactions. But maybe you care about which solvers you send those intents to, maybe you trust some, maybe they're your friends and in particular because we have this separation of validity from balance. Once you send, let's say you send your intent to a solver with the instruction like please find me a counterparty and don't forward it, don't reveal it to somebody else because we have the separation.
00:30:24.170 - 00:31:21.550, Speaker A: They can do that. And once they find you a counterparty, they can create another partial transaction which already kind of has because it has some execution and makes some proofs already, doesn't reveal any of your personal data anymore. Let's say they take like you have an A for B trade, and they take an A for B trade, a B for C trade and a C for D trade and make an A for D trade. And maybe under your information flow constraints, this is like a fine amount to reveal because it no longer reveals that not you and not even that there was an A for B trade in the first place. So because we have compositionality, we can get these kind of nice information flow control properties. Another example is batching or kind of like if you were to implement something like penumbra on the resource logic model, how would you do it? You would simply consume tokens to create in this case threshold encrypted resources which would be queued in some kind of batch, perhaps a per block batch. Those resources are threshold decrypted, next round, next block.
00:31:21.550 - 00:32:51.406, Speaker A: And they have logic such that their logic allows them to only be consumed in this batch. So basically the validators you still have to have the validators attest to what was actually included in the batch, right? They're providing data availability but the validators attest to what was included in the batch and the logic checks when all the resources are consumed that the fairness condition, say optimal arbitrage was satisfied. Another thing you might want to do is something like aggregate statistics. So in a kind of privacy first world where all of your transactions are private, sometimes you might want information flow control to decrypt like aggregates that still allow you to reason about aggregate properties of user interactions without de anonymizing specific users. For example, if you have a kind of private bridging system, often you might want to be able to reason about economic security which requires that you know how much of, say, some assets are secured by the proof of stake asset of some particular chain. And in order to do that in a world where the bridges are private, you need to decrypt like some aggregate amounts of assets, right? Let's say you have an information flow control policy that says that oh, this counter of how many assets are on this particular chain will be decrypted like every day or something like this, or even every ten blocks. Resources don't magically solve any of the cryptography problems for you, but they create this nice separation of different parts of state and different parts of logic and then you can enforce different information flow control policies on those different parts of state.
00:32:51.406 - 00:33:43.706, Speaker A: So that's why I think it's kind of like an amenable substrate, right? So kind of. In summary, the case for the resource model and why I think it might be interesting to you if you're thinking about intents and intent centric architectures is that resources package data and logic together very cleanly. They separate out execution so that you don't need to worry about execution paths, you can just worry about results. They make state inclusion very explicit. Instead of having implicit global state which is accessed in some pattern that you don't know, you access only state that you specifically need to validate for the purposes of your application. And yeah, no path dependence, which is also helpful for information flow control because once you know some variable x, you can compute like f of x for some other arbitrary functions, you also don't care about this path dependence. Conclusion of future directions.
00:33:43.706 - 00:34:05.938, Speaker A: Three points. If you only remember three points from this talk, make it these three. One intent centric VM design is not a von Neumann problem. We're trying to build something else. It's not competing. It's just like orthogonal. Two, speculative execution, or this kind of like executing things that you can't in fact authorize yourself but you want to happen as part of a transaction.
00:34:05.938 - 00:34:37.354, Speaker A: Plus, atomicity is a very powerful tool because users care about equilibrium. To hearken back to the previous talk, users care about the results. And if you kind of translate that philosophy into the design of the VM, users care about the final output state, they care about the game theoretic equilibrium. They don't care about the path it took to get there. In fact, you don't even need to compute the path it took to get there. In many cases, if you can just find some equilibrium that satisfies all of the constraints. And third kind of the spiciest, perhaps controversial take is that the resource model is probably inevitable.
00:34:37.354 - 00:35:10.326, Speaker A: You can call it something else you can change. There are some specific decisions about which variables encode different parts of static or dynamic data. You can change these decisions. But the kind of atomic execution of conditional commitments in the separation out of the execution path so that it can be determined at Runtime, I think, are things that any intense centric architecture is really going to want some open questions. I think there are also some on the website. Please find me if you're interested in these things. Better formal languages for information flow control, particularly amenable to conditional disclosure.
00:35:10.326 - 00:35:34.706, Speaker A: More suitable abstract intermediate representations for programs solver privacy improvements, maybe particularly using like Tees in combination with CKPS in efficient ways. I think it's interesting. Many more. You can find me at cwgos while Twitter lasts. Maybe go away soon. I'm also on Blue Sky, but I haven't posted there very much. But that's only because I'm lazy and I should or preferably even here.
00:35:34.706 - 00:35:35.120, Speaker A: Thank you.

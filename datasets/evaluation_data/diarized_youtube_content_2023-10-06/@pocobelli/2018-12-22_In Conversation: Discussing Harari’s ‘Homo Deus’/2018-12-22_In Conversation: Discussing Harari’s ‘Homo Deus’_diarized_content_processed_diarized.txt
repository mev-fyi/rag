00:00:00.360 - 00:00:11.830, Speaker A: Why do I have this face? Like, I don't want any face. No. Can I not have a face? Like, can I not have anything?
00:00:11.942 - 00:00:12.710, Speaker B: Maybe.
00:00:12.902 - 00:00:16.194, Speaker A: No, there's no, like, nothing option.
00:00:17.454 - 00:00:18.954, Speaker B: Maybe if you click on.
00:00:19.894 - 00:00:20.558, Speaker A: All right.
00:00:20.606 - 00:00:21.354, Speaker B: Okay.
00:00:22.094 - 00:00:23.270, Speaker A: Should I start now?
00:00:23.342 - 00:00:24.158, Speaker B: Yeah, just go.
00:00:24.246 - 00:00:25.674, Speaker A: This is so funny.
00:00:26.434 - 00:00:29.174, Speaker B: You lead the. You lead the.
00:00:30.234 - 00:00:32.574, Speaker A: I lead the live and you lead.
00:00:34.914 - 00:00:35.818, Speaker B: Hi, everyone.
00:00:35.986 - 00:00:39.174, Speaker A: Hello. But nobody's here right now yet.
00:00:39.914 - 00:00:40.402, Speaker B: Okay.
00:00:40.458 - 00:00:49.134, Speaker A: I think it will show up, but we can just, like, stream it doesn't matter. Hang on. We're telling more followers to join your video.
00:00:50.274 - 00:00:53.204, Speaker B: So how should we structure this thing? Think.
00:00:53.904 - 00:01:10.368, Speaker A: I don't know. But we can just do what we did last time and say hello. And then we said, we're going to talk about one view now. Hello. We're going to do a book reading on. What's the book on Harari's?
00:01:10.456 - 00:01:12.200, Speaker B: A book review, actually.
00:01:12.352 - 00:01:15.872, Speaker A: Book review on Harari's. What is that book?
00:01:15.968 - 00:01:17.144, Speaker B: Homo day hode.
00:01:17.264 - 00:01:21.484, Speaker A: So stay tuned. We're recording it right now while going live. Hello, mata.
00:01:21.844 - 00:01:22.704, Speaker B: Hi, everyone.
00:01:23.844 - 00:01:29.884, Speaker A: Oh, two people. Now, this is interesting. It's like my first life. Okay, let's start.
00:01:29.964 - 00:01:31.020, Speaker B: Yeah. Shall we begin?
00:01:31.172 - 00:01:46.436, Speaker A: Welcome to the in between show. This is our second show, our second time recording. And today we're gonna talk about Harari's homo deus. I have a, I hate that book. With a passion. And here's the guy, here's the guy.
00:01:46.460 - 00:01:47.844, Speaker B: That recommended it to her.
00:01:47.924 - 00:01:48.180, Speaker A: Yeah.
00:01:48.212 - 00:01:49.740, Speaker B: So I'm happy to.
00:01:49.932 - 00:01:54.944, Speaker A: Hello. Hello, everyone. Hello. Three people. Wave hello.
00:01:55.524 - 00:01:58.476, Speaker B: So, well, why don't you begin by telling us why?
00:01:58.660 - 00:01:59.228, Speaker A: Yes.
00:01:59.316 - 00:02:00.944, Speaker B: Why do you not like the book?
00:02:01.404 - 00:02:37.690, Speaker A: If I can just say one thing about the book, I think it's a book that I see as like a transhumanist book. But the problem with transhumanism and with this book in particular, Harari's homo deus, like, for people who just join us, it's a book that is, that has, like, an underlying tone of white supremacism, really. I think it's a book that sort of sees the future of humanity through the eyes of a really rich white.
00:02:37.802 - 00:02:40.074, Speaker B: Person, a privileged individual.
00:02:40.194 - 00:02:45.300, Speaker A: Privileged white person. I think that's just what the book is about.
00:02:45.492 - 00:02:46.732, Speaker B: Interesting. Okay.
00:02:46.828 - 00:03:01.304, Speaker A: Secretly, I mean, he's really into like, buddhism and all that kind of thing as well. But then I think, yeah, he's trying to get away from liberalism, like western liberalism. He's trying to do a proper critique, but that's that, actually. Yeah.
00:03:01.604 - 00:03:20.112, Speaker B: So you saw a critique. I mean, when I listened to the book and I listened to the audiobook same here. I sort of just felt like this was his best assessment of the situation. I didn't so much get a critique of the. But I mean, but I mean, I.
00:03:20.128 - 00:03:24.448, Speaker A: Suppose there's a liberalism or not a critique of what?
00:03:24.616 - 00:03:55.444, Speaker B: Of liberal. Like, I think there's an analysis. I mean, maybe it depends what you mean by critique, but I saw an analysis, an assessment of liberalism and, you know, the rise of the individual over, you know, and the power of the individual over time. And then what? And humanism and that leading to, say, techno humanism. So, yeah, I suppose one could say there's an inherent critique in there. But anyway, so, sure. Okay.
00:03:55.524 - 00:04:57.294, Speaker A: So that's my main problem with the book because I think it's a book that tries to prescribe a future for humanity where you will have an extension of humanity due to a lot of the technological advances which are happening right now and which will happen, hello, in the next 20 years or so because I'm from Shenzhen, as some of you might know. And Shenzhen is a place where you see a lot of the technological events when actually happening on the grassroots level. Whereas from that book, like from Harari's homo Deus, you don't actually have a feeling like this is one of his constant arguments as well. You don't have a feeling that the masses really understand what's going on with technology, and only the rich people and the scientists, the policies maker, are actually making decisions on technologies in the forest, industrial revolution. But that's actually not what I saw, personally saw and witnessed in Shenzhen.
00:04:58.994 - 00:05:40.908, Speaker B: So, yeah, yeah, I mean, I did get that sense out of the book that he sort of saw a divergence between the rich and the poor and that ultimately the rich will be able to, you know, he definitely is. I mean, he talks about going for dinner with, I think in his most recent book, the 21 lessons, he talks about going for dinner with Benjamin Netanyahu. So, yeah, so, I mean, I mean, and several other people. But nevertheless, he definitely, we could categorize him as in the elite. But I think the overall assessment, I feel, is fairly sober is what I would say, which is that the rich, the rich will be able to, they will be able to modify their kids.
00:05:40.996 - 00:05:43.704, Speaker A: Genetically and the poor will not be, you know.
00:05:44.354 - 00:06:01.410, Speaker B: Yeah, exactly. In this sort of economic class, divergence that we maybe currently experience will be, it will extend to, it'll extend to our biology is kind of, and so what's to disagree with there?
00:06:01.442 - 00:06:48.956, Speaker A: It seems pretty, but this is precisely what I'm questioning. Is there a way in which technology can advance us in a way that not only the rich will be able to benefit, benefit from it. I think this is my perspective. And that's why I'm like, you know, really critical of the book, because I think he talks about the poor and poverty in Harare's humiliation. But then he never really tries to use his imagination for the masses, for the grassroots, for the poor people. How? For instance, like, I went to a lab in charity, which is like, they have like several geniuses editing apps, and I went to three of them. And what I asked them, because I am interested in imagining how the masses can usurp or can take advantage of what I call the technological surplus of the fourth industrial revolution.
00:06:48.956 - 00:07:04.476, Speaker A: And what I would ask them would be, hey, you guys are doing gene editing. To what extent can gene editing become automatable? Like automation can happen to it so that it's not completely individualized? And that's what happened to our smartphones.
00:07:04.580 - 00:07:08.804, Speaker B: Because in a sense, you're saying that it'll become economically feasible.
00:07:08.884 - 00:07:11.164, Speaker A: Yeah. They're more accessible to everyone, right?
00:07:11.204 - 00:07:18.668, Speaker B: And that there will be. I mean, it's almost a capitalist argument that there will be an economic imperative to make this available to the masses, because you're gonna be able to sell.
00:07:18.716 - 00:07:55.238, Speaker A: A whole bunch more gene modification or services. If I'm like, poor person, I can't be like a Frankenstein. I. And you know, there, for instance, this is what happened to our phones as well. Like, poor people invent new ways of using Instagram, of like, posting content like we do right now. So there's a way in which it's so automatable, it's like some device that everyone can use, can own. And there's this Internet network where everyone can take advantage of, but they're not invented for the poor.
00:07:55.238 - 00:08:15.030, Speaker A: But then, now the masses can actually imagine new ways to use the Internet, to use smartphones. And I wonder if the same can happen to, for instance, other things, like, I mean, it's storing our memory, gene editing, you know, that kind of thing.
00:08:15.142 - 00:08:43.530, Speaker B: It's pretty staggering implications, if you do think of like, I mean, if the science gets so advanced, where in a sense, the so called poor, the masses, can, all of a sudden, I don't know if you're suggesting they can do their own gene editing or they can harness that technology and run with it. That's a pretty staggering thing to imagine. But I mean, 200 years from now, who's to say why they wouldn't be able to? But I don't know. Is that what you're sort of getting at.
00:08:43.602 - 00:09:04.134, Speaker A: Yeah, I'm getting at that. I'm also wanting to help people to imagine that. Whereas Haorawi's book, you don't see that he's talking about the elimination of poverty. Like, if you come from China, like myself, or if you go to even Noi Ken, like one of our friends said that to us, if you go to Noi Kern, poverty is there. Like, it's actual. It's real.
00:09:04.294 - 00:09:26.786, Speaker B: Yeah, but I think Harari's point is sort of, I would say it's like a small C conservative point. Fair enough. That it is that overall, these things like poverty and war, which were sort of seen as constant plagues of the human condition, that would never go away.
00:09:26.930 - 00:09:27.774, Speaker A: Sort of.
00:09:28.234 - 00:09:33.746, Speaker B: He argues at the start of this book that, in fact, they are being resolved and you're saying, well, go to.
00:09:33.770 - 00:09:36.346, Speaker A: Neukol, and then you find a whole bunch of people.
00:09:36.490 - 00:09:52.250, Speaker B: But I think in the larger perspective, you will see that, in fact, not nearly as many people are dying of starvation and that, you know, China, as he says, used to be synonymous with starvation.
00:09:52.322 - 00:11:10.492, Speaker A: Yeah, this is like. Yes, but this is what I'm trying to say. Like, for instance, let's say we agree that poverty is still real now today, right? This is what we agree on. But then, if you like, by writing that book, Harare's homo deus, if you join us lately, if you're writing that book, you're trying to imagine a world where poverty is already cured, right? This is like his starting point of that book. And then he's talking about how you can be happy in a world where there's no poverty and no everyone has a roof over their head and stuff like that, right? This is the starting point of this book. Hold on, continue issue that we're about to probably would be able to correct in the next ten to 15 or 20 years, like poverty, then what I'm asking right now is that, why wouldn't I, if I really actually care about the general masses and how the fourth industrial revolution with big data, AI, all of that is going to change the masses, the life of the masses and the interest of the masses, then I would go ahead and imagine ways in which poverty can be cured. Do you get what I mean? Like instead of talking about a post poverty world, which is actually already the white world that we're living in, I'm living in a post poverty.
00:11:10.492 - 00:11:16.916, Speaker A: Like, I'm poor. I'm widely poor in a way. Like, if I may say, I don't.
00:11:16.940 - 00:11:31.626, Speaker B: Know, again, like, look at middle America, the so called rust belt. I mean, there's a lot of poverty, Halloween, out of the middle class. Is it a cured thing? I'm not sure, but I think his general perspective, there's an interesting comment.
00:11:31.730 - 00:12:20.974, Speaker A: The rich only sure if they can earn more money or not need anything more. I agree. And this is actually the problem. It's like a constantly continuation of, you know, rich being able to earn more money and cure poverty within the rich people. But I think the real issue with the fourth industrial revolution, which is about, you know, all this thing, which is an extension of humanity, would be that how can the. What would happen to the masses? What would happen to somebody? Like, if, for instance, a scientist tells. If a scientist tells me gene editing or genomics will be completely part of only individualized healthcare, it can only be practiced in an individualized way.
00:12:21.094 - 00:12:21.862, Speaker B: Sure. Yeah.
00:12:21.918 - 00:13:06.298, Speaker A: Then this is a great, you know, this will affect the way this technology will be seen by the public, and it will also affect, you know, the general status of that technology. But we're not discussing that. And that is also not in that book, you know, in Harari's book. But this is what I'm interested in, you know, to what extent that not only rich people but poor people can afford that, if that's norm. And it's not just like gene editing, as in like, oh, changing the genome of us, but like, for instance, what happened to Iceland is that baby can actually be tested or like, embryos can be tested, parents can be tested for whether your embryo, whether your baby has down syndrome.
00:13:06.466 - 00:13:13.150, Speaker B: Right. Shocked to hear that. I was shocked to hear that, yeah. Because, I mean, it seems like Iceland would be one of the last places.
00:13:13.182 - 00:13:18.874, Speaker A: In a strange way, they will have the smartest people in America that would intervene.
00:13:19.814 - 00:13:30.914, Speaker B: And I assume they get rid of the down syndrome baby. Or, I mean, what, I guess that's the issue. Do they try and correct it or do they actually, do they eliminate. Right.
00:13:31.814 - 00:13:35.536, Speaker A: And would that be a part of healthcare for everyone, you know?
00:13:35.640 - 00:14:12.708, Speaker B: Right. And who gets those services now? Is that part of the public health care? It seems quite controversial. I'm sort of, again, surprised to hear that. But I mean, if that's the case, that's the case. So, yeah, I mean, as far as the whole is poverty and war being. I do agree with this general sense, though, that these things are being reduced and that in a sense, it's not an eternal plague of the human, you know, species that were always going to be at war. I mean, this is the argument that gets made by the historians oftentimes, and he's as a historian is saying, actually, in a sense, this is kind of his contribution.
00:14:12.708 - 00:14:19.500, Speaker B: He's like, actually, let me show you the argument for starvation and war being solved. And even death, I think, was the third one.
00:14:19.532 - 00:14:21.324, Speaker A: Yeah, yeah. He wants to solve death.
00:14:21.444 - 00:14:48.808, Speaker B: Well, I don't know if he wants to solve death. Like, again, I see it as this is his assessment of that people. He talked about Ray Kurzweil, in that chapter, in the first chapter of wanting to solve. I see. This is more of his assessment of the landscape than is, you know, his view, like his personal opinion. So, yeah, so anyway.
00:14:48.896 - 00:14:52.472, Speaker A: Yeah, yeah, that's my opinion. That's why I hate that book. When the past.
00:14:52.648 - 00:15:15.992, Speaker B: Yeah, so that's homo deus. You know, what I like about that book is I find it's smorgasbord of ideas. There's a ton of ideas that you can bounce off of. I think he's fairly contemporary and fairly informed. So it's a way into the conversation. And then in a sense, you can walk away with your own opinions. You can bounce off it.
00:15:15.992 - 00:15:24.340, Speaker B: I think it's a great book for that in terms of what is the conversation around AI and the future of humanity at this point. In a sense, it's hard to find.
00:15:24.372 - 00:15:56.576, Speaker A: A good synthesis conversation that's happening surrounding AI or like genomes, you know, with, like not having death and stuff. From the really, again, from the perspective of a rich person, though, like, because then, like, if you. If he actually wants to extend the discussion or his imagination to other people, it wouldn't have, like, it would be a completely different kind of discussion than the discussion that he has in the book or he evokes with that book.
00:15:56.640 - 00:16:29.742, Speaker B: I feel like, yeah, I think he largely leaves out. I mean, there's a lot of economics in there, but I think, yeah, it's not in a sense, there's no activism in his book. Like, there's no sort of. There's no attempt at this is how we're gonna solve the plight of the poor. I think it's more just a cold analysis of the situation and what people are trying to do and what are the implications of that. And I think part of the implications is that there's gonna be a whole other set of issues that are gonna come up, such as, what does it mean?
00:16:29.758 - 00:16:30.590, Speaker A: What an interesting comment.
00:16:30.622 - 00:16:32.038, Speaker B: Again, what does it mean to be happy?
00:16:32.126 - 00:16:49.690, Speaker A: For example, the only problem of our planet are people who care cannot be changed. Oh, that's funny. Thanks, Nick. Thanks, Nick. That's actually quite humor. Are we the people who can be changed or cannot be changed.
00:16:49.722 - 00:16:58.454, Speaker B: You think, well, you try. You want to embrace, you always want to be getting better. So yeah, I hope I'm a person that can change me too. And get better.
00:16:58.954 - 00:16:59.738, Speaker A: Me too.
00:16:59.866 - 00:17:06.144, Speaker B: So yeah. So do you have anything else to say on the book that we should, any takeaways?
00:17:06.684 - 00:17:22.164, Speaker A: When I was listening to it, when you recommended it to me, when I was listening to it on a ring bun, I had this thought in my head that I get really stuck with. The thought was that this guy and a lot of people were in the same train of thought as Harari.
00:17:22.284 - 00:17:22.980, Speaker B: Yeah.
00:17:23.132 - 00:17:40.036, Speaker A: He's willing, with this book, he's willing to extend humanity to robots. So it talks about, hey, human being have, if human beings don't have souls, why like what about robots? Robots also don't have souls. We can't tell the difference really between robots and human beings.
00:17:40.180 - 00:17:40.676, Speaker B: Right.
00:17:40.780 - 00:18:05.962, Speaker A: This is also like the whole vegan thing as well. I don't want to attack any vegans. But then, you know, what they're doing is that they're extending humanity to animals. And this guy extends, humanities, extends, extend humanity to robots. But the only people, the only thing, quote unquote thing that he does not extend humanity to is poor people or the general masses.
00:18:06.138 - 00:19:03.256, Speaker B: I don't, I mean, my impression, I would say he, he does make the argument and he does take a stand on the whole soul issue, that there is no soul and that ultimately the human organism, as he puts it, as like a biochemical algorithm. And that in a sense your emotions are some sort of algorithm, basically. And he does that actually quite convincingly, but, and then so he goes, and I think he simply poses the question, what is the difference then between a robot and a person? If we're simply algorithms and ones by biochemical one comes a different way where, and we're both, and neither have a soul. Where, where does that, where, where is the distinction? So yeah, I think, again, I find it all quite persuasive. I don't see so much the poor narrative, but I'm not looking for the poor.
00:19:03.360 - 00:19:03.720, Speaker A: Exactly.
00:19:03.752 - 00:19:04.184, Speaker B: Like what's.
00:19:04.224 - 00:19:05.768, Speaker A: Absolutely. So maybe this is all I'm saying.
00:19:05.816 - 00:19:12.664, Speaker B: And maybe that's your criticism. Yeah, okay. Which I think is, I think it's fair enough.
00:19:13.124 - 00:19:16.068, Speaker A: You know, I think, I don't know.
00:19:16.076 - 00:19:47.344, Speaker B: If that's necessarily his concern in a sense, the poor's plight in this situation, I think, but I think he does address it in the sense that there is going to be this divergence between the rich and the poor and that the rich are more likely to be able to edit their genes and make, you know, a quote unquote superior humor versus a poor person who can't afford to. And, you know, is this going to be extended to healthcare, public health care? Who knows, right? Maybe in Canada. I'm canadian.
00:19:48.124 - 00:19:49.464, Speaker A: Yeah, I'm chinese.
00:19:50.004 - 00:19:51.268, Speaker B: We're both in Berlin.
00:19:51.356 - 00:19:52.140, Speaker A: In Berlin.
00:19:52.292 - 00:19:53.424, Speaker B: Live from Berlin.
00:19:54.804 - 00:20:01.352, Speaker A: Okay. I guess this is the end of our life. Maybe we'll try to do more, like, book read and take art stuff, because.
00:20:01.508 - 00:20:10.440, Speaker B: Yeah, yeah. Thank you for your patience. This is our first attempt, so we're just sort of learning this situation. So thank you for. For watching and. And for your comments.
00:20:10.592 - 00:20:11.664, Speaker A: Yeah, thank you, Nick.
00:20:11.744 - 00:20:13.784, Speaker B: So hopefully see that again. All right, see you guys.
00:20:13.864 - 00:20:14.400, Speaker A: Ciao.
00:20:14.472 - 00:20:15.164, Speaker B: Bye.
00:20:18.304 - 00:20:23.624, Speaker A: And this is interesting. Do I have to end a little.

00:00:07.200 - 00:00:24.834, Speaker A: Hello, everyone, and welcome to a new episode of the Kiln restaking rendezvous. I'm Edgar Roth, protocol specialist at Kiln, the leading enterprise grade staking platform. And today we have Delhi, who's co founder at Automata, and we're going to be talking about the automata AV's Delhi. How are you doing today?
00:00:25.954 - 00:00:31.134, Speaker B: Hey, everyone. Yeah, hey, Edgar. This is Delhi and glad to be here. I'm good.
00:00:31.714 - 00:00:48.014, Speaker A: Great. Yeah. So to start this off, like, we would love to have, like your. If you just introduce yourself, like, what led you to work in automata and what let you more broadly to working in the, in the wonderful crypto space.
00:00:49.154 - 00:01:15.254, Speaker B: Sure, yeah. I mean, I actually started programming, learning programming at high school. I was doing a lot of, like, coding competitions. The first programming language I learned was Pascal. I'm not sure if everyone knows that. Then C, C, they eventually rust because many blockchain projects are using routes right now. So I also studied computer science at my university.
00:01:15.254 - 00:01:59.780, Speaker B: And then also I learned, like, how basically how some of the component works in the computing space, like how cpu works, how pre existing works, and how compiler works. Then after that, I moved to Singapore, doing my research at National University of Singapore, trying to learn what is the system security and network security. That's actually the moment I started learning about bitcoin. I read about this white paper and also etcetera as well. At that time, people call it word computers. I learned what is solidity and how it works. That's basically started the chapter for me.
00:01:59.780 - 00:02:20.534, Speaker B: And later I joined a blockchain company called Zilliqa, spent some time there as core developers and also as head of infra, trying to take care of thousands of nodes running across different clouds. Yeah. And then eventually I started automata and then doing like, study our story, basically. Yeah.
00:02:21.154 - 00:02:48.024, Speaker A: Great. Well, it's a perfect segue into my next question, which is like, what is the origin story of automata? Because you guys have been around for quite some time and you've been doing a lot of things, like, I just saw yesterday a presentation of you talking about me, minimization. So, yeah, I would love to have, like, the background story and like, what are the different projects that automata worked on and what led you to work on what you're doing today?
00:02:49.044 - 00:03:45.932, Speaker B: Right. I think I will start with the name itself. So, because most co founders were, like, coming from, comes from the computer science background. So, I mean, we choose this name is because it has, it carries all the meanings in, in the computer theory, because it essentially means kind of a abstract self acting machine that just executes a bunch of sequences deterministically. So it's very good representation of what blockchain is doing. So if you imagine that what blockchain does is it takes input, it takes state transition instrument instructions and then execute those things and eventually generate the output on chain. And each, even each of the blockchain node, like part of the consensus protocol they are doing, they're basically following the protocol and trying to reach consensus at end of the computation.
00:03:45.932 - 00:05:16.940, Speaker B: And even in today's context, like when people are talking about off chain computing, it's Oracle processor is also a type of automata because like it runs computations off chain, but it's deterministically executed and the result will be later, like committed back to blockchain so that everyone can verify it. So we actually started automata with a focus on building middlewares using tee or trusted computing, trusted execution environment. So the reason we use that is like back in the time that we are doing research in lab, we found out that this is much more efficient way or practical ways to improve the security in computing systems in general. We've been doing some research on securing some of the networks, securing some of the systems, but we haven't really time on doing this with blockchain. So that essentially made us wondering what we can do with CE in blockchain. And then at the very beginning of the project, I think we started looking at the MEV issue. We use CE to create a fair ordering mechanism so that all the swaps that goes to particular Dax can be ordered just in a fair manner.
00:05:16.940 - 00:06:20.154, Speaker B: So at that time we're thinking about maybe just to info like first in, first out, just kind of ordering based on the time that the transactions were seen by the node, basically. So that was kind of the beginning story and it really helped us to get tractions and get the fundings as well. Then moving on, we explored other spaces, like how we can secure privacy for maybe for governance. We also like look back into animate space when the story was switched from POS networks to appeal work network to a proof of state networks, like when Ethereum made the transition. Eventually we started thinking about how we can use to provide like more general computing. And I mean, coprocessor was a really good start. I mean, earlier last year we started looking at that.
00:06:20.154 - 00:07:07.084, Speaker B: We figured out there's multiple ways to achieve, achieve the security using co processors. We had one of the product like kicked off at that time, it's called wire PC. It's actually running entirely in te using its coprocess capability to process all the requests coming from users. We make sure that all the private information or the metadata information is filled out from the request. And eventually the providers will not just see, we will not get to see the user privacy, basically. So, yeah, then earlier this year, I actually started from late last year, we learned about Eigen Lear. We started thinking about what we can do with AV's.
00:07:07.084 - 00:07:33.564, Speaker B: And also that's the same time we've been in contact with some of the roll ups who are interested in multipur langley, multipurpose, essentially also the form of co processors that we are doing, trying to secure some of the compute that's running in rollups. So that's basically the entire journey right from the beginning to today.
00:07:33.644 - 00:08:09.424, Speaker A: Yeah, great, great. Very interesting. So, yeah, lots of things. But you were always very involved in using Te as a solution to the problems that you were finding. We could say, I guess that's really interesting. And yeah, can you talk a bit about like, what's the automata abs today? And what is that it tried to solve? And basically like, what are going to be the users of this Abs?
00:08:10.764 - 00:09:08.988, Speaker B: Yeah, so, I mean, the Abs we just launched is called like multi pro rate Abs. It essentially carries out all kinds of multiproving tasks that we think would be useful for some of the customers. So we're thinking about helping ZK roll ups as well as leaky coprocessors to mitigate some of the issues that could appear in their circuits. I mean, if you look at the way that vm or circuit based project work, it relies on correct implementations in those circuits, as well as the verification logic that run on chain. But chances are there will always be a bug in the circuit. I mean, we've seen that in the past in some of the projects. And good news is, all those issues were detected very early on, either by developers or by auditors, or even by white hat hackers.
00:09:08.988 - 00:09:58.574, Speaker B: But then the reality is moving on. There might be more that goes undetected. So we really need a security mechanism that can help the roll ups or help the leaky circuits to detect the issue. So the solution we have is based on a concept called multiprover, which was just coined by a term coined by Vitalik in 2022. So the mechanism of multiprovy essentially trying to check the same computations from like different provers or different implementations of provers. That's why we have the multi pill like, different implementations here. So we're taking the chemical implementations from the roll ups as the primary ones.
00:09:58.574 - 00:11:13.738, Speaker B: But in the meantime, we're creating a parallel independent implementations that's running in dE. And even in that category, there might be like many different flavors of Te that we can use. So currently we have Intel SJX based ones, but moving out, there will be AWS, nitro enclaves as well as like some new tes. For example, Intel TDX people have been exploring their implementations here as well. So I mean, with all this kind of diversified implementations, it's really difficult to miss a bug, because unless all of the implementations have flaws and attackers would be able to know them and also trying to explore at the same time, otherwise it essentially harden the entire system with enough security. And that's what we're doing with roll ups. And then the rhythm we bring this up to, to AV's to make it into AV's is it help us to kind of gather like a group of nodes, a group of operators that has enough diversity.
00:11:13.738 - 00:11:39.114, Speaker B: I mean, of course if you have different geolocations deployment, some of them will run on cloud, some of them will use your bare metal machines. And in terms of the TD flavors, maybe some of them have expertise in operating a particular type, while the others have other preferences. I mean, this is kind of a great way for us to further decentralize network and try to enhance the security.
00:11:40.774 - 00:11:57.114, Speaker A: Great. You mentioned previously CK rollups. Could you just remind our audience, like what are Zk rollups? How they differ from optimistic rollups, for example, and maybe give an example of how Zj rollup could use automata, multiple abs.
00:11:58.204 - 00:12:47.664, Speaker B: Sure. I mean, I think I will start from the roll up. Sorry. I mean, roll up is a mechanism to essentially skills the computations that were supposed to be done on Ethereum, but now, like, it will be done at the kind of L2, L2, word head off. So what goes back to the casing? So the scaling approach it takes is relying on a out of the ZK proof system. So because we found out that if you use some of the ZK proof system, you are able to achieve, you can call it compression or skating effect. So that massive computation that's done on layer one or other places natively can be actually compressed and eventually become a very small footprint.
00:12:47.664 - 00:13:48.132, Speaker B: Computation on L2, where you can just verify, verify the proof of the execution. And the entire system was relying on some of the leaky schemes out there. Many roll ups may use different type of leaky system, but the high level workflow are similar. Essentially the prover will take batch transactions on L2, those L2 blocks, put it into the circuits. I mean, the circuit has to be kind of design and also implemented beforehand. So the circuit will, the program will take the input and try to generate like a small footprint like computation with just enough data that can be like executed on layer one to verify. So once it's verified, the transactions that was included in the batch were considered finalized and the difference between they can base roller to like to optimize rollerblades.
00:13:48.132 - 00:15:07.498, Speaker B: The mechanism is so different because like in Zika roll up, you can just rely on, you can just trust the execution like this, for example, first HDR user circuit is implemented correctly, but then optimistic roll ups, you are relying on a optimistic mechanism, so you, so that the sequester will be putting a bound in the transactions. And later on, if the transactions are found to be faulty, it will be a challenging going on, challenging period going on. Then the price actors can be kind of rectified. I mean the wrong state can be rectified and eventually people will be happy about the final correct state. So this is essentially all the roll ups that up there. What we do with the roll up to do the multi program is we're trying to actually run same kind of repeated computations, are all the batches that submitted by the prover like l two sequencer node or proverb node. So what we do is we take the transactions from either l two full node, or waiting for the signal that those batch transaction has been submitted on layer one.
00:15:07.498 - 00:16:13.910, Speaker B: Once our provers see those kind of blocks or transactions, we'll be taking that, putting it into the te prover that we implemented, but hosted by other operators. Eventually the execution will be done by all the operators or by some subset of them. We will take the result and throw back the readout to layer one, so that now at layer one at the root contract for the roll up, you will get to see at least two proofs. One is coming from the kid provers, the other one is coming from our te prover. So then the layer one, I mean the roll up contract can just make a decision on how to deal with this to like proof result. Of course they can just, they can, they can, it can be a different, really different play out there. They can trust the primary one as like for example the decay proof, or just like treat the te proove as a secondary color implementations.
00:16:13.910 - 00:16:48.444, Speaker B: So if something different, what's happened like between these two, then something is wrong. Maybe something wrong is there in the table implementations or entity implementations. So that's actually the time that people should be to be alarmed and trying to figure out what should be the next step for the roll ups. So of course there will be other ways to do this. There'll be many different combinations or mix of te proove and decay proofs, but that's something we'll be exploring without the roll ups.
00:16:49.644 - 00:17:11.624, Speaker A: Great. And my follow up question is around like the economic security that is provided by Eigenaire, how do you plan to use this economic security? What are like the, basically, I guess my very basic question is when does stashing happens?
00:17:13.124 - 00:18:56.000, Speaker B: Yeah, I mean, I think our view of like economic security out there is really helpful because in our design, in this kind of de based computations, there's actually a lot of things that has been kind of hardened guaranteeing by using the hardware. For example, it's very difficult to see a node that goes in a different way because all the code, all the data that goes to those de is, is kind of guaranteed by the hardware because like it's not possible for those operators to alter the implementations or trying to inject some like outside data or inject some of the imputations into it. But then is there still a risk of like liveness issues? I mean, because those operators are still the ones that technically possess all the hardware, they could just power it off or restart it, or even like this network goes to the, like all the te nodes. So the economic security here would, is well positioned to help us to ensure that those nodes operators will try their best to ensure the uptime of the approvers team nodes. So that's exactly what we need. And in terms of the slashing, I mean because of this, because of some of the kind of objective claims that we can have from te, the slashing will be very much clear. Like if certain nodes indeed does something wrong, we will know.
00:18:56.000 - 00:19:45.814, Speaker B: And actually everyone will know because it will be a public records that can be checked like on chain. Everybody will know that maybe a particular node indeed submit something wrong. Or like if, like if the liveness condition is not met, we will be also like knowing that as well, because like it's clear that certain nodes didn't submit like enough work. From there we can just treat it as kind of a slash for condition. So I mean, basically all those situations out there will be, will be cut out objective. We can just do the slashing based on the kind of, the gathering of the result and then ensure that everyone is, I mean, the 41s is slashed correctly.
00:19:47.194 - 00:20:14.474, Speaker A: Gotcha. It's interesting that you said that most of the faults would be objective because we get, we recently introduced to the concept of intersubjective faults. And this is, I just wanted to ask a question if you think that you will still have, for example, the need to use Eigen security for intersubjective faults.
00:20:17.094 - 00:21:12.128, Speaker B: Yeah, actually, because just like I said, there's always a type of faults or misbehaviors that we couldn't really attribute properly, like using some kind of proofs or using some kind of evidence. Lightness is one of them. Other things might have, might include some of occlusions that could be done by some of the operators. I mean, this really goes undetected. But if there's enough kind of consensus or other settings between, like the global view, like, I mean on the global view of the, what each of the operators doing. So it might be possible to be, to be, to be detected. And in that case we might need like the interest objective by Eigen token to do, to deal with it.
00:21:12.128 - 00:21:23.544, Speaker B: Maybe we will go for some kind of forkings or like just kick off the, like the mechanism to make sure that the bad behavior will be punished.
00:21:25.084 - 00:21:36.224, Speaker A: Gotcha. And do you already have, I would say, an idea of the amount of security, of economic security you would need per dollar at stake?
00:21:38.524 - 00:22:35.008, Speaker B: I think a good measurement of the security that we might need is based on the assets or the value that we secure. So right now we're trying to secure the rollouts using the multi programmed cat in them. So that's really a good reference. For example, some of the rollout that we support is already reaching like 100 million of tv out over there. So I think that would be a really good start point for us as well. But of course, because we are, because the, if multiprobert goes wrong, what is effect? Essentially, it might not slash the, or punish the bad actors enough. So we probably don't need exact amount of the TVL to be the kind of security boundary.
00:22:35.008 - 00:22:53.594, Speaker B: It can be certain percentage less. For example, we probably just need to get like 20% or even 50% of the change tv out. So this is some factor that we're trying to measure and also consider it right now.
00:22:54.534 - 00:23:12.654, Speaker A: Gotcha. Yeah. Just last question on economic security. Have you already had some reasoning around like a preference towards like pooled security or attributed security, or is it something that you're not like necessarily concerned about?
00:23:14.594 - 00:24:28.904, Speaker B: I think as of now, we will just, I mean, we all start from the shared security, the pool security that IBN already provide. We also still just learn about, like more about the attributable security that they're offering. It's probably a good mechanism for us to just further increase or have a mechanism for us to work with each of the individual project out there, because this provides some preference that we can, or different ways that we can do with those partners. I saw that, just discussions about this. Do you think that this is interesting mechanism, uh, which is also interesting because uh, like if you're using a tv systems, uh, like if people are really confident about their setup, about their um, operating, uh, uh, like experience, it's possible that we can even enter this kind of like interest like scheme so that uh, like if things are correct, they will be rewarded properly. But like new things goes wrong, um, like those uh, the slashed like matter will be kind of redistributed to the victims. Gotcha.
00:24:30.244 - 00:25:02.374, Speaker A: Just want to talk a bit about your general timeline. So first and foremost, congrats on launching your AV's on Mainnet. And Ken is really, really happy to be supporting your AV's. Wanted to know if there were, if you could share what's next for automata's roadmap. I also heard that score will be the first team you'll be working with. Could you share maybe what's next for 2024 in terms of partnership work with other roll ups?
00:25:03.794 - 00:26:22.672, Speaker B: Yeah, I mean, as of now it's quite clear that we're working with Stroh and Linia. We help them to develop the multi krover system as well as each of the individual implementations for multiprover. And the next step for us after launching AV's is really kind of complete the entire system, because like you can look at the multiprover system, it relies, it has so many components, and so far we have the implementations of multiprooper. We had the AV's acting as a control plane to organize all the nodes and try to facilitate the tasks and as well as the payment for the execution as well. But then there's still some missing part out there, because for te, we have to do the attestation properly. It's also a fundamental mechanism for us to know that each other node running out there can be trusted. So I think it's quite clear that the next step for us is to have a testation layer either running as a roll up, or we'll be using some latency mechanism to try to scale it up so that we can run the verifications for the attestations much efficient, much more efficiently on chain.
00:26:22.672 - 00:27:25.714, Speaker B: And then those, all those evidence of attestation will be used as a mechanism to show that if some operators are really following the protocol. So, so we're probably gonna have a roll up going on as a, just as the attestation layer, so that we can gather all the attestations there. That's probably come up really soon. As for the other multipurpose integrations or in general t co processing integrations, we'll be working with some of the KVM projects trying to also like in a similar manner, trying to secure like the competition is down in the case circuit. And also we're actively looking at some of the AI computing space. We know that there has been discussions going on about confidential AI, which also uses this kind of te mechanism. There will be GPU's that's capable of doing attestations, doing confidential computer.
00:27:25.714 - 00:27:27.834, Speaker B: So that's also something we might consider.
00:27:29.934 - 00:28:19.854, Speaker A: Amazing. Sounds like there's going to be a lot of potential use case for this AV's. So great stuff. My follow up question is around the revenue model, basically for the AV's. As you know, this podcast is really for an audience of restakers. And number, the number one question that our risk taker asked us is how much shield am I going to get on Eigenaire? And so to understand that yield, it's really important to talk to the AV's teams. So my question to you is basically like, how are you going to incentivize economic security to secure your AP's?
00:28:21.474 - 00:29:48.684, Speaker B: Right? I think ultimately what we want to ensure that we will be having enough operator nodes running all kinds of de adventures and trying to collectively protect or support some of the partners or some of the AV's customer that uses the services. So the incentives for the operators, for the operation, as well as for the restricters who help with the pool security, of course coming from our token itself. So we'll be allocating enough amount of the token at the early stage, incentive to boost drive the network to make sure that all the operators and stakers were treated with nonsense rewards. And of course because we're directing, working with some of the roll ups, I mean we're trying to see if there's any possibility of roll up allocating a certain amount of tokens as also a security budget, because we are creating a security system for the roll ups. And this helps with enhance the overall security of the roll up. So it's kind of reasonable. I mean, we can literally go through some of the obvious mechanisms to maybe just get a ground or get the allocation going on for the operators and then of course for the restrictors as well.
00:29:48.684 - 00:29:52.960, Speaker B: So this is really something we'll be exploring in the next step.
00:29:53.032 - 00:30:30.624, Speaker A: So we just talked about the revenue aspect of the AV's. Now let's talk a bit about the costs, and it's a question, especially coming from Kian an operator is how heavy will the AV's become, especially when it starts basically working on all of these multiproval tasks? And can you talk a bit also about if you have an active set requirement and if that active set will evolve or if you are really aiming to be completely permissionless in the future?
00:30:31.984 - 00:31:40.004, Speaker B: Yeah, I mean, the short answer to your first question is it's actually considered very lightweight because the requirements of participating in the multipurpose is you literally just need to have te capable hardware and that's already generally available across different clouds. Or even you could just build up your own machines using some of the bare metal components. So I would say compared to running a ZK competition, running things in t is actually much cheaper. And it's fairly easy for us to build this kind of software that does the task as well. So then to answer your second question, the future strategy for the admission of the new operator node. We do want to fully decentralize and make it permissionless as long as the future has enough multiproved tasks to do. But right now we really have to coordinate it between the operating nodes as well as the workload that we've seen.
00:31:40.004 - 00:32:27.674, Speaker B: But technically speaking, it's possible to become fully permissionless data because all those tasks can really be just automated, like based on, based on the events that's happening on year one. So those bad transactions submitted by all the roll up nodes could be just treated as signal to start this kind of multiple tasks. And in the future the operators could just work together, like if each of them like individually see these kind of events happening, they will be just doing the multiprofing task and eventually some either to our aggregator or just to our chain.
00:32:28.814 - 00:33:09.554, Speaker A: Great, let's close this off by talking a bit about like the broader restaking markets. I would love to have like your vision as a builder, as someone that basically like was able to migrate basically what you were doing to Eigen layer. What is basically like your vision for the next 1818 months on Eigen layer. What do you think we will see in terms of exhaustive applications being built on top of Eigen layer and give us a bit your impressions on that piece.
00:33:10.704 - 00:34:43.906, Speaker B: Yeah, I think actually since our launch on the Eigen layer for the AV's, we also get a lot of questions from some fellow founders and friends asking about what could be done using Avenger. My answer to that is always like, you can literally build anything on top of it, because after understanding what the SDK is offering, understanding what the core contract that ekenay is offering, there's actually not many restrictions out there as to what you can build. You could build oracles, you could build co processors, you could also maybe embed some kind of protocols into NES, because essentially what it offers to you is just a bunch of operators with enough economic security. And on top of that, you could just find different ways to interface your protocols with some of the kind of elements out there or primitives out there. For example, you could model properly between your protocol with some of the operators out there. Or you could just model some of the security parameters with interface security parameters with economic security that you can get overall from the AV's or from each of the operators. So there's just too many possibilities out there.
00:34:43.906 - 00:35:14.464, Speaker B: And also what I foresee is we might really need more builders in the space to just create different mss and then collectively enjoy the full security from iconier. Because there's really a very high security guarantee out there. It should really be shared with more and more abs. And what was the second question? I think there's also a follow up just right before the first one.
00:35:15.444 - 00:36:00.474, Speaker A: Yeah, no, I think you answered all of the questions. I guess I also asked you what you thought would evolve in eigenvalue in the past 18 months. So, like as operators and risk takers, and probably also avss, we are expecting slashing to come on testnet and mainnet starts and also rewards and understand like how all of these will be, will be treated. I'm probably confident that you don't have like much more information on that than us operators do. But I think that definitely something that will help all of the ecosystem better understand the risk rewards of engaging in restaking.
00:36:01.934 - 00:36:37.114, Speaker B: Yeah, that's true, actually. I mean, payment and slashing is not an easy task. I mean, we have to do it properly where it touches someone's money, right? No matter. It's like the rewards coming from us to those restrictors and operators, or it's money that restricters has staked into the system. I mean, there, it's always tricky to divide properly in the first place. So, I mean, we really have to do a lot of experiments, do a lot of analysis to make sure that it's derived securely.
00:36:39.134 - 00:37:16.344, Speaker A: Great. And for my just closing question, I wanted to talk a bit about the competitors twine air, and not just the competitors on Ethereum, but also competitors using re hypothecating other types of economic security. What do you think about the competitor landscape for Eigenaire, do you think it's a winner takes all markets? Do you think there is room for competition from a builder's perspective? How do you see the different trade offs that are being made by different risk taking hubs?
00:37:17.704 - 00:38:12.904, Speaker B: Right. I think I'm also seeing some discussion out there, seeing like some new project trying to do rest taking or becoming a new hub. I mean, the competition is definitely something really healthy to have, I mean, in this space. Because if you make sure that each of the party out there doing their best to offer the tech as well as the other economic mechanism, as far as the trade offs, I'm still trying to learn what other protocols, I mean, other rethinking products are trying to do out there. I do notice a difference. Like some of the risky protocols are willing to allow any kind of USD 20 tokens to be kind of the bond or the stakes. I'm also trying to understand what's going to be the implication of that because not all the assets could be as safe, as ease as the staking assets.
00:38:12.904 - 00:38:39.304, Speaker B: So, but that's also create possibilities out there. So there might be like, I mean for some of the risk takers or users, they could have, they could have a practice on certain like high risk profile, I mean assets. So that might be like something that they really want. So yeah, I mean, in general, just trying to also learn what's going to happen in the next step.
00:38:40.904 - 00:39:00.480, Speaker A: Great. Well, thank you so much for this discussion. Delhi, I need just the opportunity to share anything you wanted to, if you had just any last words and maybe you can share how people can learn more about Autonata. Maybe follow you on Twitter, right?
00:39:00.552 - 00:39:33.374, Speaker B: I think, yeah, definitely, just give me a follow on Twitter. My handle is just daily go and then I mean, to all the rollout and they keep processors users out there, it's like you have, you need this kind of multi proving system. Just talk to us. We're able to also help you to deny the mechanism, also provide implementations running in De and eventually just connect it to the AV's so that we can have all the operators out there helping you guys on the security.
00:39:35.114 - 00:39:45.114, Speaker A: Perfect. Well, daddy, thank you so much for this conversation. It was surely great. And to the audience, we'll see you guys in the next one. Bye everyone.

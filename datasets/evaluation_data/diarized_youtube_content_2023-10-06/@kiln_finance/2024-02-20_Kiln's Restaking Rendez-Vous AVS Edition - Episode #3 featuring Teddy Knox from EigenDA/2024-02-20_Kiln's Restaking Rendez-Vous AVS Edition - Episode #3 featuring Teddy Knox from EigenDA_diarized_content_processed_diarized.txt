00:00:07.370 - 00:00:38.860, Speaker A: Hey there, and welcome to the latest episode of Kim Rendezvous Edition. I'm Edgard, protocol specialist at Kim, the leading enterprise grade staking platform. And today I am your host, Brendalone. I've also invited Sebastian Ranu, principal engineer focused on Ethereum research and development at kiln. And joining us today is Teddy Knobs, senior research engineer at Eigen Labs, to discuss the very exciting avs, which is Eigenda. Teddy, how are you today?
00:00:40.030 - 00:00:42.140, Speaker B: Doing well. Thanks for having me on.
00:00:42.750 - 00:00:59.150, Speaker A: It's our pleasure. I guess I'll start with our first question. Very simple. Can you just introduce yourself and your background and what led you to work on blockchain in crypto and joining Eigenlabs?
00:01:00.210 - 00:02:24.150, Speaker B: Yeah, sure. So I went to school and studied cs and knew I wanted to work in tech in some way. I'd been programming since I was in high school and kind of obsessed with the idea that technology could improve the world. It translates into economic growth, and everybody ends up richer and hopefully happier. And I worked in web two for a little while after college and saw that it didn't seem like this was translating into improvements in the quality of life for most people on the planet. And so the question was, well, what kind of work in tech would do that? And it was around 2017 that I discovered crypto and kind of fell in love with this idea that crypto could be this technology that empowered people with software rather than sort of serving as more of a utility that was centralized and kind of went from there. So I joined Steakfish back in 2020, which is another validator, and I, too, was a protocol specialist there for a little while, and then went to a startup called Duality in the cosmos ecosystem.
00:02:24.150 - 00:02:36.910, Speaker B: And I was there for about a year as the tech lead on their product, and then finally joined Eigen Labs about five months ago as a senior research engineer.
00:02:39.330 - 00:02:40.080, Speaker A: Great.
00:02:41.170 - 00:02:41.534, Speaker C: Yeah.
00:02:41.572 - 00:03:17.130, Speaker A: So you had, I think, a great background and a great way to see different ways to do blockchains and especially around the modularity in the cosmos ecosystem. That's great. Last week, we had amrit from Aslayer on, who already introduced the concept of roll ups. And I know it's going to be like a big, big topic in this avs series. Today we're going to be talking about data availability. Could you tell us what is data availability and what is a data availability layer?
00:03:18.430 - 00:04:11.920, Speaker B: Yeah, sure. So this one, until I went to work for Eigen Labs, this one confused me for a while. Data availability is the storage of transaction data for some temporary amount of time. Depends on the exact data availability layer. That you're using. But the general idea of data availability is that l two s need a place to l two s and l three s need a place to put transactions. So store transactions in usually a decentralized way in some way, although not necessarily so that the various other full nodes of the l two or l three network can see those transactions and also rederive the state route of the l two or l three.
00:04:11.920 - 00:04:34.260, Speaker B: I sort of touched on it a little bit, but decentralization is an important aspect of any kind of scalable l two or l three that's looking to provide the same kind of guarantees as a centralized l one. So that's the general idea, and that's what eigenda is doing.
00:04:35.430 - 00:04:42.854, Speaker A: Nice. Within this concept, what is Eigenda and.
00:04:42.892 - 00:05:31.430, Speaker B: What purpose does it serve? Sure. So I'll start with the sort of origin story of eigenda. Eigenda is the first avs on Eigen layer. And so everybody's heard of Eigen layer. Eigen layer is a restaking platform that lets people put their ethereum stake to more work. It provides the restakers with additional yield on their existing yield with their staked ethereum, but it also subjects them to additional slashing conditions. The idea is that with Eigen layer you can incentivize and secure services outside of just the ethereum validators.
00:05:31.430 - 00:06:33.690, Speaker B: And so Eigenda is one of the first abs on Eigen layer. This means that eigenda operators are secured by the restake from Eigen layer. And Eigenda's sort of core concept is that of allowing the user to own their relationship to DA. So what does this mean? This means that eigenda not only scales, it scales to. We've done tests that scale it all the way up to ten megabytes per second. But also Eigenda will let you stake potentially with a a dual quorum model, which means that you can use your own, your rollups token to define a quorum that's separate from the main default quorum based on the Ethereum restaked. And so you can define a second quorum which is sort of secured by your own token.
00:06:33.690 - 00:07:15.000, Speaker B: Eigenda also allows you to pay for your DA services in terms of your own native token. And Eigenda also allows you to reserve bandwidth so you can basically control these costs that otherwise would be very volatile when it comes to running a roll up. And so that's the general idea of eigenda. Eigenda is a set of operators that provide hyperscale level throughput to l two s and l three s, meaning da storage and doing so in a customized way that allows roll ups to bone that relationship.
00:07:16.170 - 00:07:39.600, Speaker A: Great. Okay, super clear. And have you already talked to specific roll ups? Can you talk about roll ups that you've already integrated with, or maybe roll up stacks that you've already integrated with and the future for integration? How many roll ups can we expect Eigen DA to support in the future?
00:07:41.170 - 00:08:33.014, Speaker B: Yeah, sure. Okay, so like I said, we did a speed test and found that Eigenda was capable of handling up to almost twelve megabytes per second of data on guerrelli. So within that throughput, which we're launching with and actually is subject to continue increasing post launch, we can support many, many roll ups. For example, EIP 48 44 opens up one to two megabytes of space per Ethereum block. And here we are talking about ten megabytes per second through Eigenda. So it changes the economics dramatically. We have a long list of launch partners for Eigenda.
00:08:33.014 - 00:09:30.542, Speaker B: We have cello layer. N alt layer is a roll up as a service platform, but also brings restaked roll ups. We have polymer bringing IBC to the Ethereum ecosystem. We have versatus, Nodekit, movement labs. And yeah, the list goes on. But we've found that there's a fair bit of excitement around Eigenda and the idea of scaling DA in a way that gives rollups control over what their integration looks like. And so, know that side, which is all these roll ups are interested in launching with Eigenda, there's the other side, which know what is Eigenda doing to make it easy for these roll ups to launch.
00:09:30.542 - 00:10:32.694, Speaker B: And so that's actually my day job at Eigen Labs, is integrating Eigenva with various roll up development kits, or rdks, as I'm calling them. And we currently support two rdks. That number is increasing every week. But we started with support for Opistack, which is the software that runs optimism, and that launched roughly a month and a half ago. And then we actually launched support for Arbitrum's orbit stack, which is a similar platform that lets developers launch l two S and l three s using the same software that powers Arbitrum one and Arbitrum Nova. And so we launched these two integrations in a sort of v zero model, where the integrations write to Eigenda. They read from Eigenda, but fraud proofs are not enabled yet.
00:10:32.694 - 00:11:17.880, Speaker B: So that's something that's coming before the main net launch in a couple of months. And then finally we have a long roadmap for adding further support for rdks. We have Polygon CDK currently under development, we have work on integrating with Rollkit, and then we have an interest in providing services to a variety of zk based rdks as well. So yeah, a lot of exciting progress on the Eigenda front. And the general goal is to launch, is to launch Eigenda with a vibrant community from day one.
00:11:19.210 - 00:11:35.820, Speaker C: So about a month ago, there was like a gray upgrade where blobs arrived with protodon sharding. And I guess the implementation of Iganda is strongly linked to this. How did you approach this upgrade and what didn't change for you?
00:11:37.390 - 00:12:42.298, Speaker B: Yeah, sure. So Protodank sharding and Eigenda operate relatively independently. So Protodank sharding is the idea of increasing the block size of Ethereum blocks to support what essentially serves the same role as call data in a DA capacity, but which this data actually cannot be executed on. And so this makes it so that the cost to Ethereum validators and operators is lower than if you had just increased the amount of call data that could be stored in each Ethereum block. It also introduces the sort of multidimensional fee market, which allows these two things to operate independently. So like I said before, this ends up being one to two megabytes per Ethereum block, which is roughly every 12 seconds. This increases the l two throughput, the secure full roll up l two throughput dramatically.
00:12:42.298 - 00:13:58.594, Speaker B: Right? Because I think the current general max of call data that could be written to Ethereum is roughly 200. So this is a good order of magnitude larger. That's great. And that's going to provide throughput to roll ups that already settle on Ethereum and are interested in scaling up from there and reducing their costs from there. Eigenda is aimed to supplement that additional throughput. And in general, our thesis is one of induced demand, which is essentially if we stop doing pricing and we stop passing on the cost of DA, or the congestion cost of DA, where there's a shortage of DA to the users, how many new users will come to crypto? How many new users will be thrilled to use an l two, where fees are so low that the sequencer basically doesn't charge for them somehow makes money another way, or doesn't, maybe. And I think if EIP 48 44 is successful, that's great.
00:13:58.594 - 00:14:03.580, Speaker B: Of course it will be. Eigenda is aimed to scaling beyond that.
00:14:06.260 - 00:14:28.570, Speaker A: Great. And I think in the Da space we've seen a lot of also newcomers you've seen, for example, like Celestia Avail. How do you thinknda compares to those new actors in the space? And how do you think Eigendier is different?
00:14:31.740 - 00:15:37.020, Speaker B: Sure. So I think a good place to start with Eigenda and how it compares is where the design came from for eigenda. The general idea of Eigenda was can we build a DA layer that is completely oriented around ethereum l two s and ethereum l three s? So start from there, right? So sovereign roll ups are all good and well, but this is aimed for roll ups that are bridging from Ethereum. And the main insight that we had when designing egg and DA was that we actually did not need to run any kind of consensus as part of supporting the DA goal. Because running consensus is actually relatively expensive. You need to be able to propagate blocks from a proposer to the rest of the validator set. You need to then collect all these signatures.
00:15:37.020 - 00:16:36.016, Speaker B: That whole process is this sort of almost n squared problem. And if you try to build anything scalable where there's an n squared problem involved, you're going to run into trouble. And so Eigenda saw this and well, you know, it looks like we might not actually need to run consensus to make this thing work. We already have Ethereum that can potentially provide us consensus in the same way it provides consensus for l two s and l three s. Can we build a DA network around that general principle? And the answer was yes. Eigenda is different in that its DA nodes are directly addressed by the sequencer or the eigenda disperser, which is essentially a sequencer component. And this basically allows eigenda to scale in a much more straightforward way.
00:16:36.016 - 00:17:37.990, Speaker B: Essentially, eigenda scales with the number of operators and the amount of stake that is staked with eigenda operators. And so we can expect a network that essentially does not tax you for greater throughput, doesn't have some kind of super linear relationship between throughput and cost to be generally a better DA solution for roll ups. Looking for that. So that's the main difference between Eigenda and various competitors. I think the other factor that Eigenda prides itself on is this idea that DA should not be a. It should not be this service that's so modular that it doesn't provide a tailored experience to roll up. So let's say you're launching a roll up that you need absolute security for.
00:17:37.990 - 00:18:57.752, Speaker B: Maybe it's dealing in very high value transactions. You're probably as a roll up administrator or sequencer, you're probably very much interested in paying for a higher level of security from eigenda to avoid data withholding attacks. Know, let's say maybe just like a much smaller payment processor. And so the Eigen DA approach to allowing you this security is to let you select when you're going to disperse a blob, when the sequencer is saying, hey, I have a batch of l two transactions I'd like to write. You let the sequencer decide as part of that. To what degree should this blob be replicated on the eigenva network, on the operator set of eigenda? And so what you're doing is you're selecting a quorum threshold, which is saying what percentage of stake has to have received this data in order for them to sign off on it, in order for the entire blob to be dispersed. And then there's this other aspect of it, which is the adversary threshold, which is what percentage of the stake needs to sort of go byzantine or be dishonest for the blob to be unavailable.
00:18:57.752 - 00:19:45.470, Speaker B: And so you can customize these two parameters as you wish, and end up with between two sequencers with different sets of parameters, very different distributions of their individual blobs according to the security needs that they have. And so that's just one example. I mentioned a few others, like dual quarantine and paying rewards in your own token, as well as reserve bandwidth. But these are sort of like examples of this approach we're trying to take to dA, which is going beyond just like, hey, we can store your data, and that's great, versus going and being a partner through the process and ensuring that the roll up sort of feels like they are receiving this experience that aligns with the goal of their product.
00:19:46.320 - 00:20:20.856, Speaker C: So if I understand correctly, sequencers will be able to define how they want their data to be stored geographically or according to different criteria that are available. How is it going to work on the operator side? Will operators have to go up front and say, like, hey, look, we are in this, I don't know, part of the world, or we can handle this amount of data? How, basically, will operators will be able to define their characteristics that can help eigenda decide how to distribute data? I'm not sure if my question was here.
00:20:20.958 - 00:21:11.464, Speaker B: That makes sense. Yeah. So to start, Ignda is not going to have any kind of geographic protocol level concerns. So sort of similar to how proof of stake works, where geography doesn't play into who's a proposer. Usually it's just the amount of stake and whatever random seed decided and becomes a proposer, it's that same strategy. But the general idea is that eigenda has a certain throughput at launch, which is mostly a product of the throughput of the KZG commitment proof generation. This is sort of the bottleneck in the process.
00:21:11.464 - 00:22:05.940, Speaker B: This is something that we can increase the speed on relatively quickly. You can accelerate this with gpus really easily. You can decentralize it and have all the sequencers be doing it, rather than a centralized component be doing it. And the throughput of the system is fixed, at least to start at ten megabytes per second. And the general idea is that the operators with the most wake are receiving the most bandwidth of that ten megabytes per second. So they are tasked with writing that data and storing it so that it can be later retrieved. And then from there the idea is, okay, as the network is established and as greater demand becomes available, then we can go and increase the throughput of the entire network.
00:22:05.940 - 00:22:28.770, Speaker B: And by doing that, the operators with the greatest amount of stake will essentially have greater responsibility for storing more data. But yeah, we don't see any kind of issue there. Operators don't necessarily need to be one machine. Theoretically, an operator could be a cluster of machines operated by a validator, and that can scale relatively well.
00:22:32.980 - 00:22:34.770, Speaker A: Amy says you had another question.
00:22:35.780 - 00:23:04.090, Speaker C: Yeah, it's more like stepping a bit back. So you are probably like the first gold standard avs around, and I guess you are discovering probably patterns to write avs in the right way, and sort of paving the way for future avses that are being developed in parallel. How do you think your work here is going to impact the ecosystem, let's say, when there are dozens of avs production rate?
00:23:06.220 - 00:23:34.610, Speaker B: Yeah, sure. So I think it needs to be done. We need to show the world that eigen layer can support Abs that really make an impact to the crypto ecosystem. I think that there's a bit of psychology involved there. For many people. They're not going to believe that it's possible until it's done. So that's one aspect of it.
00:23:34.610 - 00:24:31.750, Speaker B: I think in general we're seeing a lot of interest in Abs. For example, we have witness building, proof of location. Even espresso is building a DA layer using Eigen layer as an Abs. And we encourage that. And we see that this is the general thesis of eigen layer as a whole, which is that there's this huge pool of security that could be being applied to a variety of other tasks, and could essentially simplify the security model of a lot of these different existing abs that are not associated with eigen layer. So if Eigenda is successful, that will just sort of prove the thesis of eigen layer more and nice.
00:24:32.680 - 00:25:02.350, Speaker A: And how long was the process to build the avs? Did the process start right after you started working on eigen layer? And I guess this follow up question is, what are good guidelines to build an avs? We've seen some avias talk about avs minimalism. Is it a good path or is it just a bunch of different trade offs and everybody will have to adapt their own way?
00:25:06.760 - 00:26:31.550, Speaker B: Sure. So the general start over. So the general relationship between an abs and eigen layer is one of defining paths for rewards and paths for slashing. And so in some ways, it kind of has ensure some amount of similarity to an optimistic roll up, in the sense that an optimistic roll up, you have this proposer that's doing sending state routes to a bridge. And in certain conditions, that proposer can be slashed for providing an incorrect state route. At least that's how it works in arbitrum nitro. And so there's like a whole set of sort of logistics around exactly how do you validate these slashing conditions? And under what conditions does the slashing actually occur, as well as various logistics around how do you reward operators of a given abs? I guess the approach that any given AbS takes to implementing those two sets of concerns is going to differ widely by abs.
00:26:31.550 - 00:27:03.850, Speaker B: But for eigenda, we're sort of seeing that we're touching on a lot of different things. For example, we're considering doing proof of custody, which is ensuring that eigenda nodes are indeed storing data as long as they are supposed to, which is two weeks. And that would involve some amount of slashing conditions, as well as the standard rewards model, where an eigenda operator must get paid for doing the storage. So, yeah, it's going to differ by.
00:27:07.980 - 00:27:50.250, Speaker A: And yet, I think this is a good segue into the whole revenue model. This podcast is really tailored towards having a risk taker audience so that people more understand better what they will be securing and also the potential revenue that they'll be able to get. So I want to jump into this new category, which will be like, what can risk takers expect from identity in terms of revenue? What are the things that they can look at or they could hope will happen in the space for agenda to generate more revenue? Yeah, pretty much.
00:27:52.700 - 00:28:53.704, Speaker B: Sure. Okay, so the general idea is we want to remove this kind of like cap on supply of DA, because right now there is one, if you're building a roll up and you're intent on using some kind of decentralized DA service. Within the ethereum ecosystem, you are pretty much limited to either plain ethereum call data, which is 200 kb every 12 seconds, or EIP 48 44, which is one to two megabytes every 12 seconds. The demand for EA is elastic in that if the price of DA is too high, people are less interested in it. And also you can't increase the price to infinity. It's not like there's some kind of like ultra. Maybe you can right now, but you kind of can't.
00:28:53.704 - 00:30:21.864, Speaker B: Because at the end of the day, users of optimism and arbitrum are unwilling to pay fees that are too high. And so what this means is if the industry wants to not only scale blockchain to the next billion users, but if the industry also wants to turn DA into a profitable business, there just needs to be more supply, right? Like you can only make so much in rewards and fees if there's a limited amount of DA. So that's sort of one angle on it, is that the increase in supply of DA should basically translate into greater rewards for operators. The general goal is, can we move from this model? I mean, this is a separate idea, but can we move from this model where we're essentially doing congestion pricing, right? Like Ethereum, call data is priced according to how many other people want it. And this is good and bad for the same reason I just covered. But if we can move to a model that is generally, I would say better, which is let's let users pay for DA what they need in security. Essentially, cost of security is something that the user is interested in.
00:30:21.864 - 00:31:46.000, Speaker B: What I mean by that is, if DA is priced just according, let's imagine a world where DA is bountiful. There's gigabytes of DA per second available to users. That does not necessarily mean that the price of DA goes to zero, because of course, if the price of DA actually went to zero, how much security would the DA be providing? The important factor is how much security does the user need in performing the transaction that they wish to perform. And so as the DA industry matures and as external DA becomes an adopted paradigm, what we're going to see with Eigenda and with various other DA providers is one where the user is quantifying exactly how much security they need, and those fees end up in the hands of operators and restakers as a way of ensuring that there is sufficient security. So that's another big idea associated with cost. And what we can generally expect is stakers or restakers will be able to earn significant rewards on top of their existing Ethereum rewards.
00:31:48.180 - 00:32:03.850, Speaker A: Perfect. And so, as your stakers, are we expecting these roll ups to be paying in Ethereum in their own roll up token? What do you think? Do you think againdi will be able to impose a model?
00:32:07.100 - 00:33:33.670, Speaker B: You know, we don't want to impose any specific model. I think roll ups might be interested in paying an ethereum, but in general, we serve as sort of like a middleman in this marketplace between operators or not middleman, but sort of like allowing these two sides to meet. And the operators are going to require a certain amount of rewards long term in order to decide to run eigenda. And the question will be, okay, well, are the various users of eigenda, for example, like an l two with a sequencer dispersing blobs to Eigenda? Are they compensating these operators well enough for these operators to continue to run eigenda? And so that's sort of like a marketplace of the cost of eigenda or the cost of running an operator, where we are not going to impose any specific controls on exactly what token changes hands. So an l two could theoretically pay for their DA services and their own token. And that's if operators choose to accept it or on what terms, what exchange rate or whatever. So yeah, we want to basically not impose our own approach to that and let the market decide on that one.
00:33:36.550 - 00:33:54.140, Speaker A: And do you know how the market will be able to decide? Will there be some type of governance at the restaker operator level for them to decide what they want roll ups to be able or not be able to do?
00:33:56.270 - 00:34:51.580, Speaker B: Well, it's the same kind of governance that decides who is an operator in a proof of stake network, right? Like there's this process of voting with your feet, it's actually voting with your stake in this world. But yeah, the people with the most, the operators with the most stake end up becoming validators. And the same will be true of eigenda operators, right? Like if people choose to restake with these operators, then they become added to the eigenva operator set. And similarly, the operators also have a role to play in opting into that arrangement. So if they feel like they're not earning enough rewards from the various compensations they're getting from roll ups, then they're going to decide that this isn't worth it for them. So yeah, that's generally how the marketplace is going to work.
00:34:54.130 - 00:35:24.440, Speaker C: What do you think would be the role of operators from a security perspective? Will they be the ones, let's say, choosing and doing security reviews of the different avs around. Or is it going to be more organic? Like, I don't know. A bunch of stakers decide to tin for everything and they get slashed because, I don't know, it was not high quality abs or this kind of stuff. And with time we learn from our mistakes. How do you see this going on?
00:35:26.170 - 00:36:37.680, Speaker B: Well, I see operators as an important part of any ecosystem, whether that's an ABS ecosystem within eigen layer, or whether that's a challenger network for an l two or an l two validator ecosystem, or even full node ecosystem. So operators always have a role to play in not just sort of taking code and running it, but maybe developing alternative implementations of a protocol, doing their own audits, or at least checking on the claimed audits from protocol teams. I think operators are going to absolutely play a role in upgrades which obviously are not mandatory. Every upgrade generally will require buy in from the operator set. So protocol teams will need to sort of do a certain amount of persuasion and say, hey, this upgrade is a step in the right direction and everybody wins with this upgrade. So yeah, those are a few examples. I think operators are absolutely definitely part of the process.
00:36:38.690 - 00:36:44.270, Speaker C: Do you think there will be some sort of EAP process for Eigen layer or Eigen DN.
00:36:49.900 - 00:37:18.950, Speaker B: Eventually? Yeah, I mean, Eigen layer is built to be a protocol and not some kind of centralized decision making authority. And so I can definitely envision it happening in the future. I can't tell you with any certainty, I don't have any special knowledge of anything relating to that, but I would speculate and say yes. Sorry.
00:37:21.640 - 00:37:37.150, Speaker A: I guess my next question is, I think something that all of us want to know is when will risk takers will be able to start earning rewards securing eigenda. Do you have some timelines to share with us?
00:37:38.960 - 00:38:36.290, Speaker B: So Eigenda is going to mean that around April Q two is what we're claiming. We haven't set an official date yet, but that's the general goal, and we'll be launching with a very minimal set of features. And so the payment system will be launched with the main net version of InbA. And I think we can say that rewards will begin to come out around that time, but there may be specifics to the schedule which change that. So in general, the goal is we have not really crossed the finish line on the 1.0 release of Eigenva until not only is it launched on main net, but operators are earning rewards so that they're not just taking on debt running our service.
00:38:38.100 - 00:38:53.990, Speaker A: Nice. And do you already know maybe how many wallops will be supported via againda will get the help of againdf when I get launches? Do you have a number in mind? Maybe.
00:38:56.060 - 00:39:44.260, Speaker B: Well, so the total amount of Da demand is actually relatively low in the industry right now. You can look on various other DA providers, explorers, and see for yourself the amount of data that's being written to external DA. Our view is with ten megabytes per second, which is miles above any other DA external DA service, we have enough throughput to support essentially as many roll ups as want to use Eigenda. And so our current launch partner list has roughly ten names on it. And we're looking to increase that to the degree that roll ups are interested in Ida.
00:39:46.360 - 00:39:51.690, Speaker A: Great. Amex, do you maybe have for the question?
00:39:53.820 - 00:39:55.320, Speaker C: I'm afraid I don't.
00:39:59.120 - 00:40:34.150, Speaker A: I think that's perfect. At least on the kiln side. We've been very excited for the launch of Avs Mainnet and for Igenj specifically. I know you're not only in Eigenj, you're more broadly on Eigen Labs. Do you already know how many other avs you'll be launching at the same moment? Or is it going to be likenda and then few days after others? Or are we going to see four avs at once, for example?
00:40:36.520 - 00:41:32.260, Speaker B: I'm a bit closer to the Eigenda side, so I'm a little bit less knowledgeable about this side of the Eigen Labs business. The general goal is to launch with other, you know, Eigen layer launches. And there are several other abs that launch with it. That's about as much as I can give you, unfortunately. Yeah. I think the general goal is to bootstrap and kick start this ecosystem of operators, restakers and abs developers, these protocols. And the only way you do that is with getting all three of these elements in the room at the same time and sort of making it happen.
00:41:32.260 - 00:41:53.740, Speaker B: Because if you kind of launch and you don't have a bunch of pressure kind of synthesizing these three things, then the mixture won't ignite and won't actually start. And so yes, the complete goal is to launch and try and sort of get this whole flywheel spinning.
00:41:58.010 - 00:42:10.490, Speaker C: Talking a bit about testnets. So right now Eigenveau is only present in Guerreli. Do you think we move to Holesky and when because guerrilla is getting deprecated?
00:42:13.550 - 00:43:00.780, Speaker B: It's a great question. Yes. So we are going to be moving to Holski. We're going to probably wait it out until the bitter end on Guerley because we want to put all of our resources towards getting to mainnet. And so focusing on two testnets at the same time doesn't make sense. We've gotten a lot of requests to also support sepolia, which is something we want to do, although it's a little bit more costly because of the exact model of sepolia as like a proof of authority testnet versus the other testnets, which are sort of proof of stake. Testnets that more accurately reflect the true production environment, the main net.
00:43:00.780 - 00:43:04.122, Speaker B: But yeah, it's on our to do list.
00:43:04.256 - 00:43:20.510, Speaker C: So it's quite interesting that you mentioned sepoya because there is, well, no staking there. So would security be brought by some sort of wrapped sepoya token or how would you be able to restake without a staking mechanism?
00:43:21.970 - 00:43:44.120, Speaker B: Right, well, that's the problem. You hit the nail on the head. We would essentially be simulating some kind of staked token and then you would be able to use that. But obviously that would involve development towards a testnet. This is not something we want to be spending energy on, at least at this time in the company's life.
00:43:45.530 - 00:43:58.730, Speaker A: Perfect. Just being a bit conscious of time because we were a little over. Teddy, we're going to wrap this up. Where can we send the audience to find you and find more information on eigenda?
00:44:00.850 - 00:44:22.914, Speaker B: Sure. So my Twitter handle is Teddy Knox, and you can find more information about Eigenda on the Eigenda Docs website, which is Docs, Eigenlayer XYZ or on Twitter at. So thank you so much for having me on. This has been great.
00:44:23.112 - 00:44:33.110, Speaker A: Yeah, thank you so much Teddy, for joining us. It was great to talk to you and I hope that we'll be able to see you maybe in Denver. I don't know if you're joining.
00:44:34.250 - 00:44:46.680, Speaker B: I will, yes, I'm flying out early for the hacker house and hackathon that Eigen Labs is hosting. And then maybe I'll see some people skiing after.
00:44:47.610 - 00:44:59.280, Speaker A: Nice, that's a great program. Thank you so much, Teddy. And hoping to hear a lot more of againda in April. Thanks a lot.
00:45:00.290 - 00:45:02.730, Speaker B: Wonderful. Thank you, Edgar. Thank you, Sebastian.

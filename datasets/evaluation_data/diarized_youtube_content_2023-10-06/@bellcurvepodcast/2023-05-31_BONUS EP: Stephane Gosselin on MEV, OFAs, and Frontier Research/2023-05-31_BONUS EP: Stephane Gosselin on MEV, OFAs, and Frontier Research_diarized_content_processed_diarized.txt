00:00:00.090 - 00:00:27.478, Speaker A: Alright, everyone, welcome back to another episode of Bell Curve. Before we jump in, quick disclaimer. The views expressed by my co hosts today are their personal views, and they do not represent the views of any organization with which the co hosts are associated with. Nothing in the episode is construed or relied upon as financial, technical, tax, legal, or other advice. You know the deal. Now let's jump into the episode. Hey, everyone.
00:00:27.478 - 00:01:00.202, Speaker A: Before we get into it today, just want to give a quick shout out to this season sponsor, Rook. Close to a billion dollars worth of mev has been taken out of users'pockets, and that's just on Ethereum, and that number is only getting larger. Unfortunately, Rook thinks that it's time for a change and they've built a solution which is going to automatically redirect that mev back to where it belongs into the user's pocket. So you're going to be hearing all about them later in the show. I'm a huge fan of this team and what they're building, so stay tuned to find out. All right, everyone, welcome back to another episode of Bell Curve. This is a little bit of bonus content from the mev season.
00:01:00.202 - 00:01:18.510, Speaker A: Today. I am joined by Stefan Goslin today. He is the founder of Frontier Research, which is putting out some of the best research in mev in a past life. He was a founder at Flashbots and the chief architect over there. You might know him as the Ghost Step on Twitter. I think that's maybe the best intro I've ever done. So, Stefan, welcome.
00:01:18.510 - 00:01:19.574, Speaker A: Welcome to the show, man.
00:01:19.612 - 00:01:22.280, Speaker B: That was amazing. Wow. Can you do my intro all the time?
00:01:22.970 - 00:01:26.054, Speaker A: Yeah, absolutely. Just just buz me in. I'm happy to.
00:01:26.172 - 00:01:29.160, Speaker B: Maybe I'll save the silently clip and just send it to people.
00:01:29.690 - 00:01:58.062, Speaker A: I think that's a good idea. This will be a little side hustle for myself going forward, but we've got a lot of ground to cover today. I want to give you a little shout out here. Frontier puts out far and away the best content in terms of mev. Whenever a new piece drops, all of our analysts are always talking about it. Sets off some lively debate for at least a week. And I kind of want to use this as a chance to kind of go through some of the topics that you've outlined.
00:01:58.062 - 00:02:13.862, Speaker A: So maybe we can kind of start at a high level and talk about the transaction supply. Chain of mev and just how it stands today. How it's changed over the past year since you were at Flashbots and wherever you want to take it.
00:02:13.916 - 00:03:19.082, Speaker B: All right, yeah, let's do it. Well, first of all, thank you so much for having me on. I haven't done really media since I left Flashbots, and so I'm excited to sort of get back into the open and start talking about these ideas that I enjoy talking about a lot. So the mev supply chain or the transaction supply chain. I published initially this post. It was in April of last year around the time of the DevConnect conference in Amsterdam. We hosted, or I should say Flashbots hosted a conference there called Mev Day and I sort of opened the conference with a presentation that was know mev utopia or Dystopia? What is the future of this industry? And in this presentation I outline sort of these new sets of roles that I think are becoming very common in the vocabulary and the language that people use in blockchain protocols now and especially on ethereum by the time weren't very popular at all.
00:03:19.082 - 00:05:31.314, Speaker B: So the Mev supply chain I think a lot of people recognize now is there's users, they have intents, they communicate those intents to wallets or applications, those help them put them into transactions. Those transactions are put into some kind of transaction system whether it's an order flow auction, transaction pool, searchers, see these transactions and they augment them with their own transactions. Those make their way to block builders or sequencers those put them into blocks and then propose them to the validators and to the consensus of the system on which they operate. So the last year since I sort of published this article, I mean we've seen a lot of excitement and innovation happen at every layer of the supply chain which was really the goal of framing sort of blockchains in this way. I think for me it's also been sort of a personal journey like going from trying to sort of define the way that these systems work in a fairly simple and linear way. And one of the things that I had in there was the question of how will value flow? Is the value going to flow sort of towards the inside so towards the searchers and the block builders and they'll sort of aggregate a lot of the value or is the value going to sort of flow towards the outsides, towards users and validators? I think for me what I've sort of come to realize is that that was actually the wrong framing of the question. Like this question of the mev supply chain how is value going to be redistributed amongst the supply chain? Is it going to tend towards utopia or Dystopia was really sort of the wrong framing and the correct one is actually like what can we create using sort of this model of the industry? What is the additional value that this allows us to generate? And so it's sort of reframing it from a wealth redistribution which is sort of more zero sum.
00:05:31.314 - 00:06:22.502, Speaker B: And I would associate more with a lot of the questions that we have around mev to one of wealth creation which is actually like how do we deliver systems that are better for users, that allow us to generate sort of genuine value for the technology that is cryptocurrencies. And I would sort of frame that one more as transaction supply chains. So how are we sort of enabling these systems to settle the kinds of user activity that is most beneficial? So that's sort of my introduction of my journey and exploration of the supply chain over the last year. I would love to sort of dive into any of the components of it and see sort of where has the energy been and where they're going.
00:06:22.556 - 00:06:59.438, Speaker A: Yeah, let's dive into that concept a little bit. The first thought that I had when I was hearing you describe that is sort of this trend in MEB of returning mev to users, right, from the intents which we'll get into, that they sort of create and preferences that they want to express onto a chain. Right now the vast majority of that value flows all the way down the transaction supply chain to the validators. Right? Now there's this big trend of returning that to users. Is that kind of what you're talking about? Or expand on that concept a little bit of moving away from sort of this allocation mechanism to a wealth creation mechanism?
00:06:59.534 - 00:08:19.334, Speaker B: Yeah, exactly. So there's sort of some very simple mechanisms that we can think about that manipulate this value distribution, right? Like, oh, we're going to add in an order flow auction which allows us to sort of claw back. A lot of the fees are being paid through transactions to validators and instead send them back towards the user. So there's this whole area of research and I published an article about it. The design of order flow auctions. How do you design them in a way that's incentive compatible and sort of helps return value to the users? I think the other place where a lot of this discussion is happening is for uniswap LPs, right? Or you could say Dex design as a whole. How do we design better decentralized exchanges that don't leak as much value either from users swapping and being targets of information leakage through sort of sandwich attack or LPs being vulnerable to sort of slow price updates and uninformed liquidity provision which leads to LVR and sort of large arbitrage opportunities between the decentralized exchanges and centralized exchanges.
00:08:19.334 - 00:09:36.580, Speaker B: A lot of the conversation there again is how do we redistribute the value away from these arbitrage players who are bidding a lot on gas to be able to pay for the block space and more towards these liquidity providers? Maybe like a final one is the recent conversations around mev burn, right? How do we sort of redistribute value away from these large spikes that are sort of random to individual validators and more towards the network and sort of spread out the amount of that value? I think a lot of these conversations completely miss the point that we're trying to solve with all of these blockchains. We're trying to create systems not just that move money around between different actors, but rather are genuinely more useful and are going to be able to attract sort of the next billion users. And developing mechanisms that allow for those better user experiences isn't just about redistribution, it's much more about expressibility. And what can you actually do with this infrastructure? I really think that's where the limitations of our space is more so than any sort of protection or extraction or any other framing of it.
00:09:37.110 - 00:09:49.654, Speaker A: I would love to get your opinion on each of those things that you just mentioned sort of in reverse order. Love to just get your thoughts on mev burn and that sort of dichotomy between different stakeholders the way that I.
00:09:49.692 - 00:11:28.150, Speaker B: Think of mev burn and sort of value that it brings. Well, I think it fits within a fairly complicated question which is what is the future of proposal builder separation on Ethereum? What is the future of roll up adoption and sort of mev activity on layer one versus layer two? Mev burn is kind of, I think, a desirable property when you have a system like we have today where all the activity is on layer one, all the economic activity is on layer one. There's a significant amount of arbitrage and sandwiching activity that is highly contested. So you have high contention rates, or you could call it contention rates between at every block for having sort of a specific state update. And what that causes is basically all of those opportunities are being paid out to the validator through block builders and mevboost that's somewhat destabilizing to the consensus of the chain and also centralizing to the sort of distribution of the nodes. The reasons are that you have a strong incentive to pool your stake to be able to have the yield that comes from all this mev activity that is highly variable. Right? So my chance of getting 100 E block as a validator is very small because those don't come very often.
00:11:28.150 - 00:12:24.714, Speaker B: But I can have the same expected value if I join a validator pool that's able to spread it out exactly the same economics that we've seen on Proof of Work Ethereum and are sort of playing out here as well. Burning in this case sort of creates less of an incentive to join into larger pools because there isn't sort of this high variance value that you're missing out on as a solo staker. It also means that now this mev value is getting burned, which is great for ETH stakers, I should say ETH holders. There's some economics here that's sort of above my head and understanding I'm not going to LARP as knowing what the tokenomics of Ethereum are. But anyways, that's the argument as I understand it.
00:12:24.752 - 00:13:14.662, Speaker A: There's a great if you want to really nerd out on this and get super in the weeds on it. Justin Drake gave a good talk on this on mev economics which you can just look up on YouTube and sort of get his take on it. I also want to get your, before we move sort of up the stack, you mentioned sort of the future of roll ups on Ethereum and how mev's going to look up there. I want to get into that with you, but before we do, I want to talk about because yeah, you've written about sort of Dex microstructure, you've talked about order flow auctions and that's just pretty cool, interesting content. So maybe could you talk a little bit about sort of your thoughts on the evolution of Dex architecture and maybe touch on take something like Univ Three or something like that. What are the sort of leakage points of mev and how could we design DEXes in a way that will be better for users?
00:13:14.726 - 00:14:44.614, Speaker B: So this is an active area of research and exploration for say, I should give a shout out to my research collaborator here, Ankit, who's been doing a lot of the research on this particular vertical as well. He sort of helped classify a framing of mev which is called EV Ordering and EV Signal and it tries to sort of provide the basis for analyzing how a lot of these mev opportunities are being targeted in various different mechanisms. And so it's quite a useful framework for doing this kind of analysis. Now, in the case of Uniswap, the way that we would think about this and the value leakage is, let's say you have a user that sends a transaction through the transaction pool, through the mempool and they have sort of a slippage tolerance that allows them to get sandwiched. Well, EV Ordering says any bot operator, any searcher can basically take the transaction, sandwich it and extract some value internal only to the system that is uniswap. Another example of this would be sort of doing arbitrage between Uniswap and some other exchange on chain. So that's certainly one piece of the puzzle and where sort of the value comes from.
00:14:44.614 - 00:16:02.830, Speaker B: There's a second piece of the puzzle which is defined as EV signal, which is actually the value that comes from this activity happening within the environment of Ethereum, but also taking into consideration the sort of external state to Ethereum and its mempool. This looks at other transaction, it looks at the state of other chains, it looks at the state of centralized exchanges like binance. And so here you have a much more rich sort of field where you have arbitrage between these chains, you have arbitrage between the centralized exchanges and the decentralized exchange. And you can also measure as part of this sort of arbitrage between the LPs of Uniswap and Binance, which is the second biggest source of leakage for the protocol. It's what's sort of described when people talk about loss versus rebalancing. It's the same sort of value that's being exploited here. So to your question about how do we do better than Uniswap V Three? Well, to do better we need to solve those two things, those two leakage, the ordering that's based off the slippage and the leaked value through signal.
00:16:04.950 - 00:16:05.314, Speaker A: The.
00:16:05.352 - 00:17:32.426, Speaker B: Design space for here is still being explored. I think one of the insights that's quite clear is that it's really difficult to have price discovery on a system that is not very fast and has high fees. And so we're sort of in this situation now where the price discovery for a lot of these assets is on binance and this leaves all the LPs to be sort of targeted by toxic flow, basically Arbitrage traders that are more informed and are able to get those price updates reflected on chain. You could think of it as like a very inefficient decentralized oracle where you have a lot of LPs that just put money and constantly get bad execution and offer this service of having a price on chain to anyone else who wants to trade against it. There's been sort of a lot of innovation a layer up the stack on RFQ systems, right? So looking at, okay, well clearly the on chain price isn't the best one. It's a delayed price that can be up to 12 seconds stale depending on the situation. Is there an opportunity to actually use this price as the best bid and offer have it as sort of a backup price, but provide the opportunity for market makers to improve upon this price.
00:17:32.426 - 00:18:48.462, Speaker B: And that's essentially how a lot of these aggregators work today, right, so they'll say, okay, well we see that the current price of this swap on uniswap is X. Let's put it out there and if anyone can provide a quote that sort of beats this execution, then we will settle with them and provide some level of price improvements to the users. And so moving up outside of sort of the chain execution into this environment has some benefits. It does seem to provide better execution for users, but it also means that now it's sort of private market makers that have all of the liquidity and that's being kept off chain as opposed to being placed on chain. I think there's still a lot of innovation happening. The biggest question is, is it going to be sort of a decentralized exchange on layer one that's going to be the place where price discovery happens? Or is there some designs for exchanges on layer twos that will allow to actually have price discovery happen within the decentralized context and bring that liquidity back onto the chain and not necessarily have it out of the chain.
00:18:48.526 - 00:19:40.790, Speaker A: Yeah, I think the point that you make about basically LPs overpaying the Arbitragers is going to be a pretty interesting one in the coming years. In some sense that's sort of a political argument as know the other thing I would point listeners to as well is sort of FBA sort of designs for exchanges like sort of the cow swaps of the world where very similar to kind of an RFQ based system. There's sort of a baseline of execution that traders are willing to pay and then I forget there's I think solvers is the word for this particular actor. But they sort of go out into the world and figure out a way if they can execute at a cheaper price. And that surplus is actually measured for traders on the exchange. And we'll get into this later. But I think that's kind of one of the first experiments in terms of intents.
00:19:40.790 - 00:19:43.762, Speaker A: An exchange utilizing intents.
00:19:43.826 - 00:20:43.334, Speaker B: Yeah, I mean, there's so many interesting components that go into this. One of them is you don't necessarily need to only source liquidity from a single chain. Once you have this, the intent is to source liquidity from everywhere. I think one parallel that's not explored enough is actually how frequent batch auctions at the transaction layer are fairly equivalent to payment forwarder flow systems. They're doing very similar activity in terms of auctioning off the sort of ability to solve it or to settle a set of transactions. But it's looking at it from a different time perspective and there's some sort of auction theory around this that means that you might actually have sort of more collusion in a system that does frequent batch auctions than a system that does payment forward or flow. There's not by any means sort of a question that's fully settled, but that's one of the questions that we look at when we analyze these systems.
00:20:43.382 - 00:20:47.126, Speaker A: Why is that, Stefan? Why does that maybe lead to collusion?
00:20:47.318 - 00:20:54.320, Speaker B: So it all has to do with the type of mechanism that's used. So this is the same case.
00:20:56.370 - 00:20:56.734, Speaker A: For.
00:20:56.772 - 00:22:21.290, Speaker B: Order flow auctions that sort of auction off individual opportunities you have in the case of EV ordering or EV signal a fixed amount of opportunity but with some probabilistic payoff. So you're not actually sure if you're going to get the execution that you want. And so when you're providing a bid, you know that okay, the max that you can make is X, but you have some risk factor on your execution. And because it's a single winner auction, there's only the person that bids the most that actually gets settled and they always end up winning because they overpay for the opportunity that they have. The end result of this is that you have sort of an incentive for all the participants in this system to collude and underbid and say we will all bid with 20% discount to what our real preference is as a way to make sure that we don't lose money. One can argue it's not like a stable equilibrium and you'll have bidders that overbid, but the thing is that those bidders will eventually run out of money. And so if you have infrastructure that you can run and that your cost of capital is sort of within the range of the amount of opportunity that you capture, you can run sort of a discounted bidding profitably for a very long time.
00:22:21.360 - 00:23:17.302, Speaker A: Well, be interesting to explore honestly very interested in the FBA sort of design space and I think you know, which by the way stands for coincidence of Wants, which I didn't know until recently. It's a funny little thing. We also talked to Henry Davalenz this season and know is building Penumbra on Cosmos similar FBA sort of design with privacy in mind first, which is super cool. I want to transition here to your thoughts on order flow auctions, because you put together a great piece sort of exploring the design space there and you just started to say one of the highlighted two of the differences. Between payment for order flow and order flow auctions, which is sort of the time the time component and then basically the individual sort of transactions that's possible to do in an order flow auction. But maybe I'll just turn it over to you carte blanche here and can you sort of explain what the design space looks like if you had to categorize the different types of order flow auctions and maybe highlight how it differs from payment for order flow?
00:23:17.366 - 00:24:17.166, Speaker B: Sure. I think the top line takeaway for that piece is a lot of these systems try to solve two things at once. They try to solve for price discovery and for settlement sort of together. And it sort of confuses one thing for the other that ends up being expressed in a lot of challenges and how these auctions are constructed around trading off value. Like basically best price return for the user, best price, best execution for user and reliable inclusion. Based off of this insight, I sort of proposed that there's actually four different types of ofa designs and they can be sort of put on a four x four grid between if they're application specific. So only for sort.
00:24:17.166 - 00:25:14.410, Speaker B: Of a swap. Use case or generic for any transaction and if they settle based off of individual transactions or based off of a group of transactions. And we can put basically all the different designs of order flow auctions, whether it's an RFQ, sort of a Cal swap, a Pfoff model, sort of a Mev blocker style system, or more of a mev share type system. Inside of this two x two grid, each of them have their trade offs, each of them optimize for something slightly different. And I think crucially, I don't necessarily think that any of them solve the problem that users actually want to have solved, which is being able to trade in a venue that they're going to have high confidence is going to give them a good price and timely execution.
00:25:14.490 - 00:25:46.570, Speaker A: It's definitely an interesting debate that two x two matrix is, I think, a really good way of thinking about it. I'd be curious just because if you have thoughts between sort of generalized order flow auctions versus maybe more specific, like maybe in the future, like DAP run order flow auctions, if you imagine something like a uniswap trying to run their own order flow auction, you can certainly see the incentives for them to do something like that. And I would just be sort of curious how you would assess sort of the pros and cons of those two different approaches.
00:25:46.910 - 00:27:11.640, Speaker B: I am a strong believer in application specific order flow auctions. I think that's likely the way that you optimize for user experience. I think there's some arguments you can make that you can have a specialized order flow auction built on top of a generalized one. But I don't see a way to really do this that doesn't introduce a lot of trade offs. And so my intuition says that certainly the ultimate best user experience for users who want to do the use case of swapping or providing liquidity trading in some kind of way, which is one of the few proven use cases, I guess, of Ethereum today, those will end up in a specialized order flow auction model. I guess the separate question is like is there still demand and value added to long tail order flow auctions or generalized order flow auctions? Maybe. But I see them more as block space aggregation platforms and sort of discovery of contention on state access than I see them about returning value to the users or providing better price.
00:27:11.640 - 00:27:30.934, Speaker B: So I wouldn't see in those system it to be very successful to build an order flow auction that returns value to users. I do think that it's likely that those systems are more used to minimize the block space fees paid by individuals trying to interact with the chain.
00:27:30.982 - 00:28:24.142, Speaker A: So, speaking of fees, I would love to kind of get your thoughts on sort of moving up the stack to the roll up layer and how Mev works there today. I'd be curious right now, obviously not a secret, right, that all the roll ups use one centralized sequencer which has big implications for mev. And a lot of these roll ups today sort of view mev as a source of revenue for their roll up. Obviously this isn't sustainable. HASUs argued for something like PBS that exists on Ethereum main chain today in sort of the form of Mev boost. Eventually it's going to be enshrined, but something like that needs to exist on sort of layer two. I'd be curious just to get your sense of how you're thinking about roll ups these days and I would love to sort of get your kind of high level thoughts on how Mev is going to work up there.
00:28:24.276 - 00:28:28.490, Speaker B: You said every roll up except for one uses centralized sequencing.
00:28:28.650 - 00:28:31.626, Speaker A: No, all of them, I think all of them use centralized sequencers.
00:28:31.658 - 00:29:20.942, Speaker B: Yeah, I'm still not convinced that that's a bad thing. I don't think it's a done deal to say that actually first in, first out sequencers on a layer two are a bad thing. The argument that we often hear when this is mentioned is well then it creates a latency game and causes centralization around a specific region and therefore the roll up is susceptible to the censorship rules and regulatory rules of the region in which the sequencer is deployed. And I think that's true. But still the question is, is that actually bad? So let's explore this together because I think it's like a bit of a controversial or like this is a spicy take, my friend.
00:29:20.996 - 00:29:23.120, Speaker A: I'm very curious to see where you go with this.
00:29:25.030 - 00:30:31.590, Speaker B: This is something I've been trying to know. If people want to add me on Twitter and argue with it, I would love to. The statement goes like this so if you have a maximally decentralized Layer One, that probably means like a Layer One on which there is very little economic activity, it only settles data and there isn't sort of contention rates, right? There isn't this sort of demand for settling on a specific position. You only have congestion rates. That's sort of how Ethereum has been designed. When you start to think about economic activity, then you have all the issues that comes with mev and the latency gains that are sort of ensued. If you have an architecture where the Layer One is only settling sort of data blobs and there isn't contention, and you have all the activity inside of Layer Twos, it reduces the centralization pressure on the Layer One significantly.
00:30:31.590 - 00:31:37.242, Speaker B: Now, okay, how is it any better for the Layer Two s to sort of become centralized? Well, if you have some way to have cross chain messaging between these Layer Twos that is quote unquote censorship resistant, you have some way to push messages out from the Layer Two back into the Layer One, or maybe for it to be interpreted by some other spin up of that Layer Two somewhere else. You might be able to when I say interpreted by another Layer Two somewhere else, I mean like a fork of that Layer Two. Then you might be able to be completely okay with having a centralized roll up that's targeted by regulations because it remains censorship resistant. It remains, you could say noncustodial. There's still a way for individual participants in that roll up to exit their state and bridge it over to some other roll up in some other jurisdiction if there's enough demand to sort of bootstrap this other roll up.
00:31:37.296 - 00:32:31.978, Speaker A: It's an interesting premise. Let me see if I could poke at a little bit and see what you think there. So I hear what you're saying in that if there was maybe some sort of messaging system be that like an IBC or a shared sequencer or whatever, and there are sort of guarantees, right, that the state or the TVL or whatever that you end up locking on this roll up won't be necessarily disturbed. That said, if some sort of state intervention basically shut down that centralized sequencer, it would certainly be market disruption, right? And there would be like a period of time where we'd have to migrate the assets and everything down into main chain and back up onto. Another roll up. I don't know how seamless you see that process being not technical enough to have an opinion about it, but I would imagine it's relatively disruptive. I feel like if there's the threat of that hanging over these roll ups, then it will prevent TVL and activity from migrating up to the roll ups as much as they otherwise would.
00:32:31.978 - 00:32:37.438, Speaker A: If there's always kind of that threat of reorganization hanging over them, how would you respond to that?
00:32:37.524 - 00:33:45.330, Speaker B: Yeah, I think that's a valid argument. I think the other argument is like, well, if you have some way for state to be able to exit back to the layer one, if that does happen, then you have a lot of contention on the layer one, and so you have all the same centralization pressure on the layer one. I don't think by any means it's perfectly solved. I do think this does generate an argument for more fragmentation between layer twos, which I would consider to be a good thing. I think if there's a layer two that has all of the state on it, and there's like a single winner in the layer two world, that seems really bad for innovation. It seems really bad for robustness of this system. Whereas if you have multiple different layer twos with liquidity fragmented across all of them, yes, it does create some challenges on cross chain messaging and creates maybe perhaps worse, worse price execution and some framing of it through there being more arbitrage opportunities.
00:33:45.330 - 00:33:56.994, Speaker B: But I would treat that as a separate concern than one of, okay, how do we have a robust and scalable ecosystem around selling transactions?
00:33:57.122 - 00:34:32.980, Speaker A: Okay. It's actually a very interesting point. It makes me think of we're recording this on May 26. So Vitalik just came out with his piece, don't overload Ethereum's consensus, and he actually listed one of the explicit risks of relying on ethereum's social consensus on, let's say, one of the layer twos becomes really large. Don't count on the fact that if there's not some sort of catastrophic hack that we're going to roll back the chain, because then you get the sort of favoritism that you see in TradFi, right. Between, say, like, a large bulge bracket bank versus a small regional bank. And that doesn't seem necessarily fair.
00:34:32.980 - 00:34:55.100, Speaker A: I don't know if I have a good response to you, but I have to think about the fragmentation of the L two ecosystem because I had been kind of thinking about it within the context of the optimism super chain, right. And we'll figure communication out if that's IBC or shared sequencers. But I hadn't really thought about fragmentation actually being good for the robustness of the ecosystem. That's an interesting take.
00:34:55.630 - 00:35:53.930, Speaker B: I'll caveat all this by saying I'm by no means a layer two expert. I think I know one thing or two about how ethereum works by now. But layer two, I haven't built. One I haven't worked with closely with the team so I'm building one. So I'm sure that there's a bunch of content there and ideas that I'm just not exposed to. But it seems to me like, and this goes maybe into a bigger perspective on decentralization that I've sort of grown over time, which is you want the decentralized system to be as simple and dumb and uncontroversial as possible and for those rules to be sort of not changing very much if you want the system to remain decentralized. I mean, the concern is any system that is complex and requires sort of global consensus is likely always to lead to centralization and capture.
00:35:53.930 - 00:36:29.426, Speaker B: And this is not even just like an economic or mev argument, it's actually an argument on how humans coordinate and politics where anything that requires vast groups of people to agree to the same thing will devolve into political communication games and that will inherently cause the system to concentrate and centralize. Whereas if you have a system that doesn't require people to all agree on the same thing all the time, then you have a lot more fragmentation and diversity by proxy. Decentralization.
00:36:29.618 - 00:36:34.390, Speaker A: Yeah. Last question that I have for you on the centralized secret certs.
00:36:36.590 - 00:36:37.018, Speaker B: If you.
00:36:37.024 - 00:37:10.262, Speaker A: Look at how it's sort of played out with Arbitrum so far, which has taken a very different approach from optimism in terms of their MEB strategy, although optimism has changed as well. But if you look at Arbitrum, which was a sort of fair, they were the fair ordering sort of group, they've already changed the way they're doing it a little bit because they have the same problem that Solana has with just spam. So I'd be curious to get your takes on what you think about when you introduce something like FIFO or fair ordering or whatever it is. You end up getting a whole bunch of spam. Be curious what you think about that.
00:37:10.396 - 00:38:21.974, Speaker B: So the spam is a proxy for latency. So the question is not FIFO is the wrong approach, the question is more like how do you handle the fact that there's latency advantages. The TradFi solution to this is like you sell colocation spots around your matching engine and you can boot people off of their colocation spot and so therefore you don't have the same sort of incentive to spam or for them to try to DDoS you in some way or another. So I think that there's other approaches. If you're sort of committed to this idea that there's going to be a single roll up and a single sequencer and that it's going to be first in, first out. Certainly there's a lot of established ways that you can make sure that this server stays online and you can deal with all of the sort of economic side of it in a much more centralized way. So you just have to sort of commit to go down the centralization path if that's the design that is being targeted.
00:38:21.974 - 00:38:56.962, Speaker B: The alternative is to try to go down this sort of encryption path. Right, okay. I will continue to use a first in, first out system, but it's going to be encrypted and distributed across a bunch of different sequencers that are sort of all around the world. You still have latency game, they just become sort of at the edges of the encryption. So before the packet gets encrypted, who has access to that information? How is this sort of generating value and who can sort of capture that value? And then afterwards, where does the information becomes available first? And that's where you have, again, sort of the latency games emerge.
00:38:57.026 - 00:39:35.666, Speaker A: Yeah. Interesting. Before we move away from layer twos, I would love to just sort of get your thoughts on a big topic du jour is sort of this idea of shared sequencers for a whole bunch of different reasons. Part of it is the communication issue that you were alluding to before, but the other sort of honeypot that this opens up is cross domain mev, which has been a very sexy topic for a long time, although it's sort of yet to be realized aside from Stad. ARP. So be curious sort of what your thoughts are on eventually. Do we end up getting this very rich ecosystem of cross domain mev on the roll up space, or is that a little bit of a pipe dream for now?
00:39:35.688 - 00:39:40.662, Speaker B: So I still don't understand what is shared sequencing? Do you have a quick explanation for me?
00:39:40.716 - 00:40:12.026, Speaker A: Sure, I can explain it to you. Like you're five, because I'm also secretly five. But basically the idea is, I think about three different models, right, for how roll ups can sequence their transactions. There's one centralized sequencer which is super easy to understand. Then there would be a decentralized sequencer set. So multiple different sets of sequencers that only settle transactions or order transactions for one roll up. And then you can imagine a world where there's a set of sequencers that sequence transactions for multiple different roll ups.
00:40:12.026 - 00:40:15.978, Speaker A: And in theory, there you could guarantee something like atomic inclusion.
00:40:16.074 - 00:40:30.840, Speaker B: Okay, I think I see this very similarly. Maybe this is like the other take that I'm going to have on this, which is I think everyone is building the same thing and I don't know if everyone is building the same thing.
00:40:31.210 - 00:40:32.600, Speaker A: I agree with that.
00:40:33.210 - 00:41:44.030, Speaker B: So whether we call it shared sequencing, decentralized block building, oracles, all of these to me all have sort of the same flavor. They're all sort of trying to solve this problem that you have a lot of information, you have a lot of messages that are floating around into the world, and then you have some consensus system that asks you, hey, can you find some way to put all these messages together into my next update? And everyone is kind of trying to figure out, okay, how do we represent all this information that's out into the world into some reductionist view? Of what the state of this roll up this chain is and we're creating all kinds of games around this. Right? I sort of put this cryptic tweet out the other day that said it's all messages and solutions, bro. Just saying, okay, all of these things just end up being exactly the same thing. So, shared sequencing? Yes. I think that there's value to be able to do things on multiple chains at once. There's sort of this concept that I've been trying to push since 2020 of chain abstraction.
00:41:44.030 - 00:43:01.398, Speaker B: If we want the crypto ecosystem to become useful, if we want it to be used like AWS is used to be able to deploy application, not only users should not care about which chain that they're interacting with, but application developers should not even care about which chain that they're interacting with. This is just what's required. If we want to be able to enable the types of applications that are actually useful, we need to create an ecosystem where it really doesn't matter. At the end of the day, yes, you're going to have trade offs in these different execution environments, but it shouldn't be up to the developer to sort of know exactly how does an ethereum transaction format work. Does like the layer two have shared sequencer or not shared sequencer? They just want to be presented with sort of a set of features or an interface that they're able to connect to and automatically deploy to these systems. I do think that these shared sequencers or decentralized block builders, cross chain bridges are all in the same game of trying to build and provide those services. They're trying to say, okay, we have a good view of what each of these different execution environments are good for storing data.
00:43:01.398 - 00:43:37.746, Speaker B: Maybe it's more decentralized. Maybe it's good for storing value. Maybe it's like lower latency and they're trying to provide these services to applications that are trying to build on top of these different systems and expose them in a way that's the most intuitive and provides the best guarantees. So I think whoever is going to be able to provide these best sort of user guarantees is really what the shared sequencing should be all about and the mechanisms behind it for actually settling it. There's so many different ways to build these things and that's not clear to me where it's going to go.
00:43:37.848 - 00:44:20.458, Speaker A: I completely agree with you on the point about abstracting away a lot of the complexity for developers, and maybe that's a decent segue into something that is a very sexy topic within mev, which is account abstraction and how four three Seven is going to impact mev in general and sort of the creation of this new interop mem pool that intersects with intents as well. There's a lot of questions about what is an intent, what is not an intent. So can you kind of just delve headfirst here into this whole thorny topic and sort of explain what 4337 is, who are the new actors that it sort of introduces, and how is this going to impact mev?
00:44:20.554 - 00:45:28.866, Speaker B: The intense language, I think, is a really interesting one. I think it goes to the core of this question, which is we're not building systems that allow people to update the state on a global computer. We're not trying to provide these services, we're trying to fulfill user needs. And that's really how I started to use the language of intent in the concept of trying to provide better services to users. I think it's being now used as a way to sort of escape from the limitations of the Ethereum transaction format, saying, okay, it's very rigid to be able to say that this intent has to be programmed as I'm interfacing with this function on this contract. And it's like yielding x result when you have sort of a design space of interacting with multiple different chains. Unfortunately, I don't think that account abstraction today is really nudging us that much in that direction of being able to achieve intents.
00:45:28.866 - 00:46:33.834, Speaker B: And so I sort of have this quote which is four three seven is the future, but not really. So four through three seven is trying to develop this new mechanism that allows for account abstraction, that allows for signing, basically call data and have that call data be routed through some distributed peer to peer mem pool and be eventually included on chain. It introduces the concept of a user op, which is sort of a new message format. Again, it's all messages bro and it introduces a new entity which is a bundler. And again, it's all solutions bro. And so it tries to say, okay, with this new message format and this new solver format, we're going to be able to enable sort of account abstraction and unlock some latent value and build new kinds of applications. I think it's true.
00:46:33.834 - 00:47:35.918, Speaker B: It's correct in the way that escaping from the current format of how Ethereum fees work and sort of the requirement to have ETH in your account when you're submitting a transaction to the chain is going to unlock a lot of value. I'm not convinced though, that the standard itself, the 4337 standard, is going to be robust enough to be able to express all that intents have to offer. And I'll give a very simple example of this. So one of the limitations of 4337 is that you have to be constrained in the state that you're simulating against. So there's sort of this attempt and this assumption that you want to create these messages in a way that is Dos resistant. And the only way to do this is to fix the state that you're going to be simulating the transactions against. So you're saying here's a subset of the state on chain, this transaction is only valid if it only interfaces with this subset of the state.
00:47:35.918 - 00:48:18.998, Speaker B: And that's incredibly limiting from the perspective of expressing intents. Because my intent maybe isn't just about this limited state. Maybe it's about some other contract that's, like, outside of this state that might change. Or maybe it's based off of the state of some layer two or the state of finance as a chain. And none of those preferences can be expressed within a sort of four three seven user operation. So I think it's a step in the right direction. I think it's going to be adopted and I do expect sort of it to be the new way that users interface with Ethereum.
00:48:18.998 - 00:48:26.826, Speaker B: But it's not going to be the future and it's going to be superseded by some superior transaction formats.
00:48:27.018 - 00:50:17.518, Speaker A: The simplest way that I've heard how to describe intents is you're hard coding the output instead of hard coding the input. So what you just mentioned is 4337 doesn't perfectly allow that, right? But it definitely does solve some big problems, I think, that have been holding adoption back from Ethereum. So one, there is another entity that I think four three seven introduces, which is a paymaster, right? And one of the results of this new format of each wallet being a smart contract wallet instead of an end owned account is that you can actually have another entity pay on your behalf, right? So you could imagine a paymaster that adapt acting as a paymaster to subsidize gas fees for users, right? So you don't have that weird problem when users first open their MetaMask that they can't do anything because they don't have any ETH in there, which is a very difficult onboarding problem for new users. The other question that I have for you on that is what are the implications for mev? When you think about this so intense, it does something there but not quite everything that we would want from intents, but it does create kind of this what's being dubbed as an alternative mempool. And I would love to get your thoughts on who the bundlers of these user op transactions are ultimately going to be. Does this sort of I guess that they'll probably be builders or builder searchers and does this sort of raise the now you've got the Ethereum public mempool, you've got the user op mempool, you maybe in the future have application specific, basically application specific mempools if they implement some sort of RFQ type system. Just seems like now to be a successful builder searcher you have to draw on all of these different sources of order flow, right, to build the most efficient blocks.
00:50:17.518 - 00:50:25.758, Speaker A: So I guess my question to you here is what are the implications for mev and does this sort of raise the barrier to entry for builder searchers?
00:50:25.854 - 00:50:56.030, Speaker B: Does it raise the barriers to entry? I think one of the places where people go to when they hear this is exclusive order flow is sort of a danger and I used to believe so and then sort of stopped believing that that's the case. And the reason is that I don't genuinely think that block building is a profitable activity. And the argument is this way. So to be a block builder.
00:50:58.610 - 00:50:58.926, Speaker A: You.
00:50:58.948 - 00:52:34.714, Speaker B: Have to have two things like one, block space access and then two, enough trust to have order flow being be sent to you. And the only way that you can sort of bootstrap this is if you make no profit and spend all of your profit subsidizing either the block space or the order flow that you receive. And so block building I actually see as sort of a race to the bottom to maintain a certain position on the leaderboard to justify, hey, you can send your transaction flow to me. And I'm like providing all these different features, I have to sort of be willing to pay for that transaction flow that's being sent. And so as soon as there is sort of a mechanism for block builders to be able to pay for various different types of transaction flows, they are going to be in a race to zero to be able to sort of outbid other block builders for those transaction flows. And so under this framing, sort of block building actually becomes much more of like a public good, not dissimilarly to how relays on the MAV Booth context are being operated today. There just isn't like a natural way for these systems, I think, to capture value and they will be sort of competing in this closed game for being able to access barriers to entry.
00:52:34.714 - 00:53:08.262, Speaker B: I'm not sure, I think it may be that it creates some barriers to entry. There's like some integration cost to be able to support all the different transaction types. Maybe the barriers to entry here is actually that there isn't a good way to make a case that you can bootstrap like a new one of these things because it requires subsidizing and not everyone has infinite access to capital to be able to do this. So I'm not sure where that piece of it is going to go.
00:53:08.316 - 00:53:41.620, Speaker A: Yeah, you might be absolutely right. I guess you sort of answered my next question. But maybe just to poke at the builder question one more time, is there definitely have been builders that have made a lot of money, right, without naming any names, but sort of these shadowy, not super public builder searcher firms that have done quite well in recent years. So is your contention there that basically those profits are going to get armed away as more builders come into the space and yeah, it's sort of a race to zero in the same way that transaction fees are raised to zero in the brokerage world. Is that kind of the idea?
00:53:43.030 - 00:54:38.150, Speaker B: I don't think that trading activity is going to go away and like arbitrage opportunity, I think that's going to remain. I think the paradigm of you have to be a builder to be able to land your arbitrage transactions isn't a correct one, I think that actually neutral block builders are going to outcompete searcher builders because it's a position that actually requires more neutrality. And I think that the neutral block builders are going to compete basically on merging systems and who can subsidize the most the order flow that they receive from searchers. Yeah, and searchers will continue to sort of send to every block builder that they trust, so long as they can sort of believe that the block builder isn't also sort of using their flow and trading with it.
00:54:38.220 - 00:55:12.394, Speaker A: Super interesting. Yeah, I do think that neutrality, that point just clicked. That's super interesting. I would love to maybe we could before I want to give you the chance to talk to the audience about sort of leaving Flashbots and what you're doing at Frontier Research. But before we go, maybe we could close on this idea of latency as just really getting into the weeds of mev for these past couple of months. It seems like that's sort of the topic that folks are super interested in. And I kind of think about latency now in terms of two buckets.
00:55:12.394 - 00:56:16.606, Speaker A: There's sort of latency as a geographical centralization kind of risk for the health of the network. And we talked that a little bit about a bit about that on roll ups and you kind of have that contrasting against a strong user preference for fast confirmations. So that is kind of that bucket when you talk about latency. And then there's this idea of latency expanding time around the block so you have more time right now, I guess, as a builder or searcher to get more transaction order flow and therefore you can build more profitable blocks and shout out to your team. You guys wrote a great post on optimistic relays, which I think you really got deep into the weeds of how this works today. So I would just love to get your thoughts on latency whether or not you view it as this sort of inevitable force that's going to shape the network in good or bad ways. If you want to get into the technicalities of how optimistic relays work and unconditional payments from builders, I think that's a good nerd snipe.
00:56:16.606 - 00:56:22.722, Speaker A: I think the people would like to hear your thoughts on that, however you want to take it. Maybe we can just close on the subject of latency.
00:56:22.786 - 00:57:46.698, Speaker B: I sort of mentioned my thinking around mev supply chain and recalling it. The transaction supply chain evolved. My thinking about latency also evolved and the benefits and inevitability that's a hard word to say of latency in the systems that we design is sort of something that blockchain systems are going to struggle it's. I can make a I can, you know, take this from so many different directions. We can talk about sort of mevboost and how it came to be and how optimistic relays are sort of inevitable as the next steps in the progression towards enshrined PBS. We can also talk about how sort of latency means that for as long as there's economic activity on the layer one, even in an Enshrined PBS context, there's going to be centralization pressures due to the latency. And we can also talk about how in distributed systems that have global consensus because of general relativity, it's inevitable that we have these latency games that sort of emerge when you have information propagation across the network.
00:57:46.794 - 00:58:01.222, Speaker A: All right, let's start with optimistic relays because you wrote a great piece on this. So let's get sort of your thoughts on there and then maybe if we could segue into Mev Boost, why that was originally created and then talk about the roadmap for Enshrined PBS. Your thoughts there.
00:58:01.276 - 00:59:21.070, Speaker B: Optimistic Relays is sort of this new relay type that allows for the faster propagation of blocks from block builders to validators in the Mev Boost context. So the state of the art right now and when Mevboost launched was a block builder sends a block to a relay, the relay simulates it, validates that it's a correct block, and then forwards it over to the validators for inclusion in the chain. For the proposal and inclusion. Optimistic relays basically just say, well, instead of simulating the block, we can have a trusted relationship with the block builder where they're bonded for some amount of capital and we can optimistically just pass the block over to the validators for execution and we save. Call it 100 200 milliseconds on the simulation of the block inside of the relay. This means that you can incorporate 100 milliseconds to 200 milliseconds of additional value into the block. And by value here, I sort of mean it equivalent to information, right? Because time is money, as we are all taught.
00:59:21.070 - 01:00:11.342, Speaker B: And so in this additional 100 to 200 milliseconds, the block builder is able to sort of incorporate a lot of new information that's being propagated in the world about maybe the price of different assets on different chains and update the arbitrage trades that they're sort of including in their block, which means that the blocks that come from these optimistic relays land on chain and win sort of the block auction at the validator level. So this is like a very clear example of, okay, well, every millisecond you can incorporate additional value into sort of the proposal that is being made to the validators. And so there's going to be sort of a race for more efficient relay infrastructure to be able to carry these blocks over.
01:00:11.396 - 01:01:00.330, Speaker A: Interesting. So let's segue the discussion of optimistic relays because relays are not a permanent state of right there's. Eventually they're sort of a stop on the road into Enshrined PBS and I feel like that's a pretty good place to close. This week, Mike Neuter actually came out with sort of his updated thoughts on what the roadmap was going to look like and how we should all be thinking about that. I would love to get your thoughts on Enshrined PBS. What you think about the decision. Ethereum is very selective about what it actually decides to take into the protocol PBS was kind of one of those very select, you know, maybe if you could just weigh in on that and then how you see Ethereum consensus sort of changing with Enshrined PBS.
01:01:00.410 - 01:01:13.058, Speaker B: Okay, this is exciting. So I started looking at PBS in the summer of 2021. So I'm like two years into PBS research, I guess you could say.
01:01:13.144 - 01:01:17.720, Speaker A: I was just looking at it, I was like, It's 2023. That could be five years ago, I have no idea.
01:01:21.050 - 01:02:46.558, Speaker B: And it was all in the context of, okay, the merge is coming right now. Flashbots is sort of working on proof of work. Ethereum, what is the solution that we're going to bring to proof of stake Ethereum around mev? Is it going to be the same thing or is it going to be different? Had some discussions with the EF team with Vitalik around what does a better system look like? And that's where sort of initial designs and ideas around PBS came into play. Separating out the builder role from the proposer role. And the question at the time was, okay, do we wait until PBS enshrined PBS is ready before doing the merge, or do we proceed with some other solution at the merge that doesn't require consensus changes and therefore isn't going to delay the timeline of when the merge happens? And the decision at the end of the day was, okay, well, we don't think that we can convince protocol developers and development teams to delay the merge and to do the research that's required for PBS to be a thing. We think that there's just too much research there and so we need to find a solution for having out of Protocol PBS. And that's where I started designing Mev Boost.
01:02:46.558 - 01:03:45.026, Speaker B: And over the course of sort of the following year, sort of brought it to the market. Now there was some very conscious decision in the design of Mev Boost. One of the main goals with it, from my perspective, was to be able to put a clear price on the value of a block, which was not a thing that existed in the past. This concept of there being a public value of a block and say, this block is worth X did not exist because all you had before was a bunch of transactions being routed to a miner, a miner constructing that block. And it was sort of obscure how much value they were capturing out of it. And you had this issue where the mining pools would be able to capture some of the value and not distribute it back to their miners, so they would capture the Mev value and not distribute the rest of the value back to their miners. Mevboo sort of solved this by saying, okay, we have this block auction the value of.
01:03:45.026 - 01:04:44.310, Speaker B: The block is public and this allows us to have sort of transparent price discovery on block space value. It also sets us up nicely if sort of this continues and gets put into the protocol for being able to burn this value. So if you can have some consensus on what is the highest value of a block because you have this open price discovery, then you can sort of do whatever you want with the value of that block. That's sort of where the inception of why mev boost is good, why it's sort of a good precursor for entry PBS and for eventually mevburn sort of came from. I think there's still a few upgrades to sort of mev boost that are possible before we get to Enshrine PBS. One of them you mentioned a few time, which is unconditional bids. So this just means that now block builders have to sort of commit to a payment regardless of the validity of the block.
01:04:44.310 - 01:05:13.566, Speaker B: There's some technical difficulty to implement this outside of protocol. You need basically some oracle that's able to say after the fact if a block was valid or not. But certainly when it comes time to Enshrine PBS, that's sort of one of the main things. You no longer need to have an oracle or some external source of trust to validate a block. You just have sort of within the protocol, the Attestation committees be able to determine if a block was valid or not.
01:05:13.588 - 01:05:37.334, Speaker A: Kind of land the plane here on when we eventually so move past all of this and this is all put in protocol, how is it going to look different from today? Obviously we're not going to have relays. And then walk me through what are the big implications of this? Is this going to be like a huge boon for the network and really lead to a more decentralized sort of validator set or is there kind of another side or take to it?
01:05:37.372 - 01:06:36.330, Speaker B: One of the things I found most beautiful about the merge is that you completely changed everything from the RPC down and to application developers and to users. They didn't notice a thing, right? They just went from one transaction transacting with miners and mining pools in China to the next day transacting with stakers and staking. Pools are mostly concentrated in the US. And to their perspective they didn't have any UX difference. And that was just like crazy to even think that you could do that. I think Enshrined PBS is going to be pretty similar, right? So it maintains the role of block builders and all the features that sort of block builders can develop. It changes the role of the relays and sort of gets rid of the relays and allows block builders to interface directly with proposers.
01:06:36.330 - 01:07:05.618, Speaker B: The question is then, okay, well, what's the next step after that? Is Mevburn going to come around? I think that might have a bit more impact. So if mev burn does get shipped, then there should be less incentive for concentration of stake inside of staking pools. And so maybe you'll have sort of more of a noticeable difference there. But enshrined PBS on its own I don't think is going to have much noticeable difference to the way that the system works.
01:07:05.704 - 01:07:17.914, Speaker A: All right, Stefan, we could, I'm sure, go on for hours more here, but I want to give you a chance to talk a little bit about Frontier Research and what your plans are and what you're kind of doing over there.
01:07:17.952 - 01:09:02.566, Speaker B: Yeah, so I sort of opened up the conversation here by talking about going from thinking about mev supply chain to transaction supply chain. And Frontier Research is really sort of based off of this idea, an idea that thinking of sort of mev as a zero sum wealth redistribution problem is not the right framing. It causes teams to think much more in a closed mindset, like not wanting to share information and a lot less experimentation and innovation across the board and instead reframing things as sort of a positive wealth creation game and allows us to think more about, okay, how can this infrastructure, how can this supply chain be used to generate real value for the users and really prove that crypto and these systems that a lot of us have spent so much time building on have some true value to create for the world? And so it was based around this idea and wanting to explore these concepts a lot more. And so we have a few different initiatives. We have a publication that you kindly mentioned and said nice things about. And this publication is not just the content that we at Frontier Research create, but we invite any actor that's building on the transaction supply chain to submit articles for review. We basically provide editorial services.
01:09:02.566 - 01:10:27.190, Speaker B: We review it, and then we curate the content to make sure that the publication remains sort of a place with super useful mental models and high quality signals. And so, yeah, anyone who's interested in submitting articles for publication there, we'd love to hear from you. We're also offering sort of advisory services. So part of the vision is for this transaction supply chain to deliver value to the world, we need a lot of different teams building different things and really going out there and trying new things that you wouldn't have if you just have sort of a single approach or a single way to view this supply chain. And so we work with parties sort of across the entire industry to help them bring some of their products and ideas to market. And then the final initiative that we're sort of getting kickstarted is what we call Frontier Adventures. And maybe you could call it a bit of a play on Frontier Ventures, but it's Adventures because what we're looking to do here is really sort of target some of the components that are very core to this transaction supply chain and incubate and sort of build some experiments in house as well.
01:10:27.190 - 01:11:09.346, Speaker B: And so we've sort of started collaborating on a builder on a block builder there that's called the Faith Builder. And we're helping the team there sort of bring this to market and provide sort of some of the more interesting transaction types that I think are going to become really useful for providing these better user experiences. And then we're also looking at, okay, what does it look like to provide services at the messages layer, at the networking layer? We are considering sort of launching some additional efforts on that side.
01:11:09.448 - 01:11:41.482, Speaker A: Super interesting, man. Well, honestly, Stefan, this has been so great. I'm so glad we're able to do this. This was, like, just honestly, just filled with gems and we got to basically everything that I wanted to ask you about. So I don't know, guys, listeners of the podcast, I mean, you just heard from Stefan for the last hour and change, but I highly recommend that you go check out the site. I can link it in the show notes, but yeah, it's Frontier Research and I think the site is Frontier Tech. So definitely go check that out.
01:11:41.482 - 01:11:55.690, Speaker A: And yeah, man, I'll be super excited to see, particularly on the adventures. The ventures are adventurous, fun. I'm excited to see what you got cooking over there. So maybe we can do this again in six months or something like that and just see how things have progressed.
01:11:55.770 - 01:12:03.918, Speaker B: Amazing. Thank you so much, Mike. It was a pleasure to speak with you and yeah, I hope it was some interesting content for everyone.
01:12:04.004 - 01:12:05.940, Speaker A: Absolutely. It my friend. Be well.

00:00:00.090 - 00:00:28.626, Speaker A: Alright, everyone, welcome back to another episode of Bell Curve. Before we jump in, quick disclaimer. The views expressed by my co host today are their personal views and they do not represent the views of any organization with which the co hosts are associated with. Nothing in the episode is construed or relied upon as financial, technical, tax, legal, or other advice. You know the deal. Now let's jump into the episode. Welcome back to another episode of Bell Curve.
00:00:28.626 - 00:01:20.046, Speaker A: Today, Miles and I are going to be talking with Sriram Kanan, who's the founder of Eigen Layer. This is a really interesting episode, one of the interesting intersections of two very hot topics in crypto today, which is Liquid Staking and restaking. We're going to be diving deep into that intersection and we sort of cut this conversation into two different parts where we actually look at Eigen Layer of the protocol. We divided that talk as we sort of described Eigen Layer as a social coordination mechanism or a marketplace in between ethereum stakers and runners of middleware or other protocols that want to access that stake. So we talked about the supply side and the demand side of that market, which was a fascinating conversation. Then we talked about sort of this intersection in between Liquid Staking and restaking, more towards the end of the conversation and some of the very interesting dynamics in between, frankly, protocols like Lido and Eigen Layer. So this was a really fun one, Miles.
00:01:20.046 - 00:01:21.046, Speaker A: I can't wait to get into it.
00:01:21.068 - 00:01:31.730, Speaker B: Yeah, it'll be a blast. I think Eigen Layer is top of mind for a lot of people both in terms of excitement and potential concern. And so I think we want to dig into both sides and really excited.
00:01:31.810 - 00:01:41.290, Speaker A: Same budy. All right, let's jump right in. Welcome back to another episode of Bell Curve here. Excited to get into it today. Miles and I are joined by Sriram, the founder and CEO at Eigen Layer. Sriram, welcome to the show.
00:01:41.360 - 00:01:50.574, Speaker C: Pleasure to be here. Looking forward to go deep into Eigen layer restaking. Yeah, I've enjoyed listening to the Bell cover earlier, so it's a great pleasure to be here.
00:01:50.612 - 00:02:25.014, Speaker A: Thanks a lot. That means a lot coming from you. Well, we can just get right into it here. And I want to know we're going to start with sort of a brief overview of Eigen layer, but we're going to assume a little bit of knowledge here because we want to leave enough time to dive into some of the technical, extremely nerdy sort of questions that Miles and I have for you here. So I want to say if you're looking for kind of a higher level overview and you aren't as familiar with the concept of restaking and Eigen Layer, SHRIM did a great episode on Bankless. I would recommend that you go check that out. But for now, Sriram, maybe could you just start actually at that high level and maybe keep the explanation relatively concise.
00:02:25.014 - 00:02:33.626, Speaker A: Could you just give an overview of what eigen layer is and maybe explain the two sort of fundamental innovations of restaking and kind of creating an open marketplace for trust?
00:02:33.728 - 00:03:27.918, Speaker C: One way to think about it is if you ask what is a blockchain solution and what is not a blockchain solution? And you want to find like what is the key ingredient that makes something a crypto or a blockchain solution, you'd say probably that's decentralized trust. Take anything and then add decentralized trust to it. You'd call it a blockchain solution, you remove decentralized trust from it, you'd no longer call it a blockchain solution. So in some sense, the dividing line for what is a crypto or a blockchain solution is decentralized trust. So it is the raw material out of which the entire crypto economy is manufactured. And the first marketplace for decentralized trust was actually, in our view, Ethereum. The idea that, hey, I'm building this common platform, it's programmable, people can build arbitrary new applications or modules on top of it.
00:03:27.918 - 00:04:29.714, Speaker C: And when somebody is building an application at that time, Bitcoiner said, why would you think that people would come into the same platform? And the idea is because you're getting a common pool of decentralized trust and applications building on top of Ethereum, consume this decentralized trust and pay a certain fee. One way of thinking about this is Ethereum distills this decentralized trust into block space, uses its own consensus staking, and then there's a consensus protocol on top. There's an execution layer, the Ethereum virtual machine, there's a gas limit and then there's a certain amount of block. So block space is just the distilled form of decentralized trust that Ethereum is selling. And clearly we talk about block space as being one of the most important commodities in the crypto space. But you can ask, why not sell the raw material, decentralized trust itself, rather than the distilled product which is blockspace? So that's eigen layer. Eigen layer is a marketplace for raw decentralized trust.
00:04:29.714 - 00:04:58.700, Speaker C: What is the aspects of decentralized trust? What makes up decentralized trust in a proof of stake system staking, which is the amount of economics that underpins it. There's a sum amount of stake. That's number one. Number two, there is decentralization itself. Like, there are many nodes. Each of these nodes don't talk to each other or collude. And I think a combination of decentralization and the economics, the crypto economics together make up decentralized trust.
00:04:58.700 - 00:06:40.122, Speaker C: And what we observed is, while there is this marketplace of decentralized trust that Ethereum has already created, it is at the application layer and I can only consume it if I write a smart contract on top of this platform. But for many, many reasons, I may want to access more raw decentralized trust because my protocol imagine I'm building a data storage protocol like Filecoin, and I want a bunch of nodes as well as some bonded economics, somebody making a promise that they are not going to violate the covenants of the protocol. And to do this I had to go or the file coin guys had to go create a whole new network of nodes as well as a staking token of value. And you see this again and again and we ourselves, when we created earlier protocols we were forced to actually think about do we want to start a whole new layer, one with its own economics underpinning it. We decided to not do it. And I think over the many years I've been thinking about this question which is how do we enable any innovator to come in and build on top of a common framework for decentralized trust? And in our view Ethereum is the closest because of the wide availability of node validators the availability of stake itself as well as the alignment of the ethos of permissionless innovation which is I think the underpinning of Ethereum. And because of these several factors we think Ethereum is the natural source of decentralized trust on top of which one could build a very interesting economy or a marketplace of raw decentralized trust.
00:06:40.122 - 00:07:24.326, Speaker C: What Eigen layer does factually is it lets takers in Ethereum who already put in Ethereum you put 32 ETH and make a promise that you're going to continue to validate Ethereum blocks correctly. And if you do not then the protocol might remove a portion of your ETH. So the promise is credible because you're putting your money where your mouth is. You're not just saying that you're going to do it, you're actually committing to do it in a way that is if you violate the covenants you may lose your ETH. And so that is precisely the same thing we want to extend to other protocols. You put your ETH in the Ethereum protocol and then Eigen layer is a series of smart contracts on top of Ethereum. It's not a new chain.
00:07:24.326 - 00:08:14.022, Speaker C: It's not a new l one or anything. Just a system of smart contracts on Ethereum which allows Ethereum stakers to opt in to serve other systems. And to serve another system you'd have to be able to download and run software for this other system. Imagine you're running a different like a file coin like node. You need to have the node software for actually running and storing the data and so on and on. The Ethereum smart contracts you somehow have the ability to indicate to the Eigen layer smart contracts saying that hey, I'm going to go and validate these other chains because I promised that I'm going to go and validate these other chains or other protocols. Now if you don't do it you may lose your stake.
00:08:14.022 - 00:09:03.558, Speaker C: So that is the core promise that the staker is doing opting into new services. We call these Avs actively validated services. It's basically any protocol, I mean any protocol that needs end nodes to actually talk to each other and come to some kind of consensus that any kind of a protocol can be built as an actively validated service. So an actively validated service is being built. Somebody who wants to come up with a new actively validated service. What they do is they write a smart contract on Ethereum that can talk to the eigen layer contracts, which specifies who can register for my contract, what is the payment I'm going to make. If Miles is storing 1GB of data, I'm going to pay him one, eat whatever set of conditions that we want, and then we also specify what is the slashing conditions.
00:09:03.558 - 00:09:54.406, Speaker C: Or if you're claiming that you're storing a data relative to this hash, I may ask you randomly to reveal portions of the data on the Ethereum chain. And if you don't, then you may lose your ETH. So there is a set of conditions that you're opting into. So what this does is suddenly instead of working with the distilled product of decentralized trust, which is block space, you're working with the raw aspect of decentralized trust. And you can allow people to build arbitrary protocols on top. One analogy I think, which has helped root this conversation, is if you look at 1994 internet and you want to build new web applications, you have to build your own server stack, you have to build your own payment stack, you build your own identity stack, you have to build your own DB stack, and then build your application on top. That's roughly the scenario if you're a power user.
00:09:54.406 - 00:10:36.482, Speaker C: If you're not a power user, you could just use Geocites for hosting GeoCities for hosting your website. You could do that in 1994. In the same way today, if you are not a power user in the sense that you need access to much more programmability than what a smart contract on Ethereum offers, you have to say go take the Cosmos SDK and figure out how to customize it to whatever you want. But also you need to figure out your own staking economics. You have to figure out your own validator nodes, you have to figure out every single aspect of the service. You have to figure out for yourself instead. The crypto world that we envision is a world where it's very similar to 2023 web application development.
00:10:36.482 - 00:11:49.162, Speaker C: You have AWS, which is the cloud, on top of which there are a lot of SaaS services like OAuth for authorizations, stripe for payment, MongoDB for database, and then you just concatenate whichever applications, SaaS applications you want, and then you get your end user facing application. Now SaaS, the term SaaS looks very corporate ish, but really what it is, is open innovation. It allows any one person who can be hyper focused and specialized in creating a certain utility, rather than everybody needs to create a whole new world around themselves. And I think this is the history of the modern world is we all become more specialized in what we create and more general in what we consume. So we're just trying to create a reflection of that in the crypto world. And to us you can't run it on AWS if you want to call it a crypto solution because decentralized trust is at the heart of it. So you run it on the wide validator network and the economics surrounding ethereum eigen layer just makes it more programmable.
00:11:49.162 - 00:12:55.150, Speaker C: On top of which now you suddenly have very interesting services that can then be built on top. And one thing I want to just comment here is people think of the modular landscape and they think, oh, maybe there is data availability, maybe there's execution and something, three things that's not at all true. If you look at the number of SaaS solutions that are needed to run something in the web, two stack, there's thousands of thriving SaaS solutions and any given application integrates 15 SaaS solutions. This is on an average. And that's roughly what we envision to happen here in the crypto market as well. There is trusted execution environments, there is secure multiparty computation, there is secret sharing, there is data storage, there is data availability, there is oracles, there is bridges, there is proof of decentralization that we are working on, there is Guardian networks which can protect you against hacks, there is AI inference systems. The number of things that are SaaS solutions that can share common trust is unlimited.
00:12:55.150 - 00:13:09.622, Speaker C: So that's roughly just to lay out the vision for what we are building. Eigen layer, eigen in German for your own, your own layer, you can dream up whatever you want and build on top of it. So open innovation is our core value.
00:13:09.676 - 00:14:23.326, Speaker A: That was a really helpful explanation. And particularly I love that analogy of I almost imagine sort of a crude oil refining process where you have distillates that's a little bit upstream, right? But actually you're sort of moving up one level in the value chain to something that's more raw and that just enables so much more flexibility. I think that's very sort of high level analogy. I think to get a little bit more concrete, the other framework that I have for conceptualizing eigen layer is this two sided marketplace and we'll eventually bring in liquid staking later, but we've talked about these liquid staking protocols as two sided marketplaces as well, in between node operators and those who want to delegate their ethereum. I think the analogy to eigen layer would be actually a very similar construction, except on the supply side you have stakers and on the demand side you have these AVSS, these actively validated services. And I think it would be helpful for the remainder of this part of the discussion where we're getting into the nitty gritty of eigen layer to sort of break up a discussion between the supply side of that equation and the demand side. So Miles, I know you have a couple of different frameworks for how you sort of parse out the supply side and maybe I'll turn it over to you to kind of go through the operational model and then kind of the asset preferences and how you think about it.
00:14:23.326 - 00:14:49.490, Speaker A: Hey, everyone, we've got a great episode here, but before we do, I just wanted to give a quick shout out to Permissionless. This is the biggest and best conference in all of DFI. It's the one that we do with Bankless, who's a great partner for us. Last year we had almost 7000 people there in West Palm Beach. We are moving this year to Austin, Texas from September 11 through the 13th. And if you are a listener of Bell Curve any of these last five seasons, this conference is basically custom made for you. We're going to be talking about Liquid Staking, the theme of this season.
00:14:49.490 - 00:15:15.978, Speaker A: We've got a bunch of great panels on mev. If you listen to the App chain thesis, we've got a bunch of Cosmos folks out there in full force. We're talking about the converging architecture of Salana, the roll up space in ETH and Cosmos. So I would love to see all of you there and to reward you for being such great listeners. To Bell Curve, you get a special 30% off code. It's Bell Curve 30 that'll get you 30% off tickets. Click the link in the show notes and then head over to the permissionless site and make sure that you get your ticket today.
00:15:15.978 - 00:15:18.894, Speaker A: Again. That is Bell curve 30. Click the link in the show notes.
00:15:18.942 - 00:17:02.878, Speaker D: It struck me, just reading the white paper, how flexible the supply side setup can be, right? I think about this as in a couple of different dimensions of choices that you can make, right? So there is, first of all, which assets are being restaked, the actual capital being restaked. Is it just natively staked ETH? Is it LSTs? And if so, which LSTs? Or is it even LP positions right in something that looks more like superfluid staking, which we see on Osmosis? And then who are the actors actually running the hardware for the AVSS running these Eigen layer nodes? Are they ethereum validators that have chosen to also run some other node? Or are they specialized operators that maybe are better suited for something like an Oracle protocol? And then lastly, from the perspective of the staker, there are a bunch of different flavors. You can have a fully insourced version where you are a self staker of 32 ETH. You then elect to run additional hardware and put that 32 ETH at stake. You could be a self staker at the L1 layer, but then decide to delegate your 32 E to an operator, an Eigen layer operator. Or you could do the fully outsourced model, right, which seems to be the largest capital pool, which is I have already delegated my stake to a liquid staking protocol. And then I take my LSTs and I elect to go redelegate that stake to an Eigen layer operator.
00:17:03.054 - 00:17:04.242, Speaker B: And so is that fair?
00:17:04.296 - 00:17:13.350, Speaker D: And is that how you think about the three major buckets, I guess, of sort of models and the decisions that the supply side will have to make?
00:17:13.420 - 00:18:04.070, Speaker C: That's a really good overview. I think you maybe put it even better than I could. So that's awesome. We think of the supply side as at least comprised of two subsides, right? One side is the staker and the other side is the operator. And sometimes these two are the same people, sometimes they are not. And that covers the third thing that you talked about, which is delegation. So how do these two sides kind of interact with each other? And then downstream of this, there is a question whether after you've done all this, do you have a final liquid derivative on top of all of this or not? So that's the kind of wrapper for this relationship.
00:18:04.070 - 00:19:11.542, Speaker C: And all the actions that are being done could then be represented by a downstream token. So that is definitely the set of considerations on the supply side, the number one being what type of tokens to be allowed. Before I get into some of these things, I want to express the philosophy underneath this. The philosophy is protocols should minimize subjective decisions. This is how we think about it and the framework. So if protocols are not expressing subjective decisions, and there are definitely subjective decisions to be made, then who expresses these subjective decisions? And in our case, we want to be as close as possible to the ethereum staking layer. And in fact, our own ideal end game would be to become part of the ethereum staking layer itself, right? Basically, Eigen layer becomes the ethereum staking layer.
00:19:11.542 - 00:20:13.440, Speaker C: Eventually, whether through a protocol upgrade or an EIP or something, we don't really care. That's our kind of end game. So if you want to start from that and then ask how do you think about the subjective decisions that need to be made? Our principle, there is protocols, especially protocols as bare bone as the rest taking protocol, need to minimize decisions at its end, but allow those decisions to be made by services building on top by the consumers of this supply. Right? So that brings us to the other side. So do we allow A or B or C? That's not going to be the question that we will be facing. It's an initial shepherding process to get the platform started. We have whitelists and cautionary things, but eventually this is going to be a completely permissionless platform.
00:20:13.440 - 00:20:55.002, Speaker C: You can come and restake your ETH, you can restake your Steeth, you can restake your Steeth, ETH LP token, you can restake your Op token, you can restake your Starquare token. That's not our decision. So when a service creator comes, they can specify that, oh, I like CBE, or I don't like CBET, I like lidos teeth, or I don't like lidos teeth. I like the curve LP token. Or I don't like the curve LP Token. That's the granularity that is given to the AVSS. So our platform minimizes its own subjectivity.
00:20:55.002 - 00:22:05.018, Speaker C: So we are not going to be playing this role of deciding, oh, is this good or not good? It is up to the market to figure that out. So this comes from this framework of open innovation. Open innovation is best built on top of a credibly neutral layer. This is why we like Ethereum and this is why we want ourselves to be as similar as possible to Ethereum, even at one point dissolve into Ethereum itself. So if you look at that philosophy, which is that if we minimize these decisions, which of these are actually going to work and be used? Depends on the services understanding of the different risk profiles and exposing these information to be as transparent and clear as possible is the role of the associated services around the protocol. The protocol itself just gives the ability for people to express their visions and enter into contracts. Right? One way you can think Know Mike earlier laid out the marketplace viewpoint of Eigen layer.
00:22:05.018 - 00:23:00.818, Speaker C: You can also flip it and say know, eigen layer is a coordination mechanism for stakers node operators and innovators to come together and create a useful service. And all of this is serving somebody else, which is outside the definition of the marketplace, which is the ABS consumer, like an oracle consumer or a data availability consumer or storage consumer. Right? So it's a coordination mechanism. When you want multiple parties to coordinate, they're mutually distrusting. So how do you enable multiple distrusting parties to come and coordinate? That is really what the eigen layer marketplace is. And that's why we think a lot about this question. But to reiterate the supply side, initially we're starting with a small handful of tokens.
00:23:00.818 - 00:23:43.854, Speaker C: But eventually this will be completely permissionless, not only including ETH and downstream superfluid tokens, but completely different tokens like the optimism token or starquare or polygon or whatever. Because in some sense there is the other view in the Cosmos world of mesh security, which I think Cosmos and Ethereum always have a good back and forth. They originally had interchange security. We came up with Eigen layer. I think Eigen layer inspired mesh security and now mesh security. But if you look at mesh security, it's basically like I'm bringing the strength of many communities, many tokens together in order to give security. But the problem is adjudication.
00:23:43.854 - 00:24:17.102, Speaker C: It's not just economic pooling from different economic systems. It's also you have to go to each jurisdiction, you have to go to each chain and create a fraud proof or something to adjudicate whether you behave correctly or not in each of these systems. Eigen layer flips this viewpoint. It says we have a common adjudication but multiple economic systems. You can have the op, you can have the starquad, you can have the polygon. You can have the ETH all contributing economic security, but you have a common adjudication system. It's all in the same place.
00:24:17.102 - 00:24:37.842, Speaker C: You have a common understanding of risks and rewards. You have a common place in which all of these get adjudicated. It's just a much smoother experience when everything gets aggregated into that kind of a single point place. And to us, ethereum becomes the underwriting trust and adjudication layer.
00:24:37.906 - 00:25:32.614, Speaker D: I think that makes a lot of sense. And yeah, really, I like the approach on the supply side of just making the protocol as flexible as possible so that it's really the customers, the demand side that is going to shape what is used the most and what eventually becomes the go to model, essentially. And yeah, I think I'm glad you brought up mesh security. That's something that's near and dear to my heart with my seat working with Osmosis and I see tons of similarities here. I think one of the big differences is that mesh security is going to be built into the chain of these Cosmos chains as an SDK module. And that is something similar to that is kind of the end game that you just described in terms of getting this restaking infra built into the L1 itself. I just want to double click on that a little bit.
00:25:32.614 - 00:26:23.350, Speaker D: And something else you said where you said you wanted to get as close as possible to the L1 validators, right? Because I was thinking about that technically, eigen layer could exist without any interactions with stakers and validators of ethereum, right? It could be something more, I would say, further away from the metal of the protocol where you just have folks who have liquid ETH that are depositing into some contractual agreement, right? It doesn't have to be pre staked before that. And so I would love to just kind of understand maybe double click on that piece of getting as close as possible to the ethereum validator level. And really what Eigen layer would look like if this is restaking is built into the entrenched to the ethereum L One.
00:26:23.420 - 00:27:34.030, Speaker C: One way to explain this is to start with we said we're building a marketplace for decentralized trust. So a marketplace usually trades some kind of graded commodities. So we want to think about what are the types of decentralized trust, what are the elements of decentralized trust that Eigen layer is allowing to be traded? And imagine building the first potato commodities exchange, right? Like you have to figure out potatoes can be big or small, golden or different colors, red potatoes. You have to think about all of these things. You have to figure out for the first time, what is this object that you're dealing with, how do you grade it? How do you understand it? And I think that's the rough situation we are in. If you want to say that we are creating a marketplace for decentralized trust, we have to figure out what are the elements of decentralized trust. Each consumer of decentralized trust may want different aspects of this so they may only lean on different subsets of this model.
00:27:34.030 - 00:28:17.974, Speaker C: So I think as far as we've thought about, there are three elements of decentralized trust and that Eigen layer can offer. And these are somewhat distinct. The first one is the economics, the economic trust. I have $1 billion staked on a protocol and I know that if I violate some of the covenant of the protocol, I'm going to be able to slash or take away a majority of this 1 billion. That means it almost doesn't matter whether it's a single person, a single whale putting up a 1 billion or like millions of people putting up $1,000. There's no difference. The economic aspect of trust, just the economics.
00:28:17.974 - 00:29:14.730, Speaker C: It's how much money is promising. That the correctness of this particular statement. So that's the first aspect of decentralized trust in Eigenair is economics itself. The second aspect of decentralized trust in Eigen layer there are certain kinds of protocols which can live purely off of economic trust, right? Imagine I'm building a ZK verification system so you can of course write a ZK verifier in ethereum. It turns out to be expensive, right? It takes like a 1 million gas which is one 15th of a block for some of the protocols. That's why something like Starquare writes proofs to ethereum every 8 hours rather than every 8 seconds or 12 seconds, right? So it is expensive. So if it is expensive, could I somehow find a proxy for what I can do in between these 8 hours? Every 8 hours I go write it directly to ethereum.
00:29:14.730 - 00:29:57.290, Speaker C: Maybe in the middle. What I could do is I get somebody who promises with their $1 billion that okay, this proof is correct, and then just make a claim with the well known fact that if their claim is wrong when the 8 hours judgment day comes in, they may lose their 1 billion. And this may be good enough for me to go move a bunch of bold apes from starquare to ethereum because I know that 1 billion is at stake. So in this use case, I don't care if you have 10,000 validators or one validator. It doesn't matter. I know the promise is purely economic and my enforcement is purely economic. I don't care about anything else.
00:29:57.290 - 00:30:38.066, Speaker C: Number one, this is one aspect of decentralized trust which is purely economic, crypto economic trust. And the second aspect of decentralized trust is decentralization itself. Imagine I want to build a service which is not based on the amount of economics, but purely based on decentralization. Just to make it easy. What's an example? One simple example for this is I take a data. It's a secret sharing system. I have a secret and then I want the secret to be stored in the network.
00:30:38.066 - 00:31:45.994, Speaker C: But I don't want anybody to have access to. The secret until a certain time is passed. For example, what I would do is I take the secret, encode it into smaller pieces so that each node gets this smaller piece, right? And any majority of the nodes can come together and reveal the secret, but no one node gets any access to the secret. So this is a famous scheme in distributed systems called the shamir secret sharing. So you want to go and build this and you want to use decentralized trust for doing this. The key aspect of decentralized trust is this fault. The fault that you're trying to protect is that all these nodes come together and expose the data before the timeline is passed, right? Imagine I'm putting my medical information on top of the secret sharing and the assumption is that unless there is a disaster, please don't share this information because in the disaster I want this information to be public so that the registry of who needs what can be opened and then I can get my medicine.
00:31:45.994 - 00:32:29.414, Speaker C: Because at that point I don't care about my privacy, I care about my life. Simple example conditional secret sharing. And what you don't want is, in the normal mode, these guys all come together and reveal my secret and sell it to a pharma company so that I'm bombarded with ads that hey, why don't you buy this, I don't want that. And there's no way to slash these guys for this misbehavior because it is a non attributable fault. I don't know if those guys colluded and did this or I gave the secret or somebody else did it. So there's no way to attribute it for non attributable faults where you're relying on collusion resistance, you're relying on the fact that these guys are all not like meeting in the same room and exposing the data. You need decentralization.
00:32:29.414 - 00:33:13.340, Speaker C: This is the second aspect of decentralized trust, which is decentralization itself. And there are several services who live and thrive on purely decentralization. And I gave an example secret sharing. But there are other examples, censorship, resistance and so on, which rely on decentralization, not on economics. It doesn't matter in this case, it doesn't matter that I have a trillion dollars staked or a billion dollar staked, but it matters that I have thousand independent agents rather than one agent. Because even if you have a billion dollar staked and it's a one person, I'm going to reveal all the portions of the secret to that guy and secret sharing doesn't work. Okay? That's the second dimension of decentralized trust, which is decentralization itself.
00:33:13.340 - 00:33:45.362, Speaker C: The third one. So the first two dimensions of decentralized trust are economics and decentralization. They have really nothing to do with ethereum's validator set. Like you could basically I go and construct a huge my own validator set that's good, that could be decentralized. I could have my own new ETH or take bonds from the bond market. We have a friend who's working on onboarding bonds into the crypto space. You use the bonds as collateral and go and do something.
00:33:45.362 - 00:34:28.222, Speaker C: Okay? So this is something that you could do. So the first two things really don't have much to do with Ethereum but it has something to do with it, which I'll briefly highlight. The thing that it has to do with is shared security is better when sharing across multiple layers. So if Ethereum for its own purpose needs 10 billion security or 35 billion security as we see today, and Eigen layer for its own purpose needs another 35 billion security, it's much better to have 70 billion common security which secures both these systems. Everything is just better because it's going to be so much more difficult to attack the system. You need to attack any one of this. You need to get a majority of 70 billion rather than 35 billion.
00:34:28.222 - 00:35:24.340, Speaker C: Shared security is a superpower. So that's the reason that you might want even just the economics to be shared and the practical way it works out is the marginal cost once you're sharing into systems is just better. So that is the one reason you want to share. The reason you want to share the decentralized validator set is firstly, already Ethereum has a decentralized validator set. And secondly, it'll be even more awesome if as new services come on and demand decentralization that forces Ethereum itself to become more decentralized. You guys did a whole Mev podcast like a series and one of the things in the whole Mev discussion is we discuss a lot about how Mev does not become a force for centralization. That's one of the core topics that you come again and again to.
00:35:24.340 - 00:36:20.534, Speaker C: But what is the force to decentralize? There is zero force in the Ethereum protocol or any protocol to decentralize because the protocol cannot evaluate and value the thing that we say we are selling, which is decentralized trust. And decentralization is a core part of decentralized trust and there is no mechanism in the entire crypto space to value decentralization and to encourage and enhance and pay for it. What doesn't get paid for, doesn't get grown. That's why decentralization is a theology today. Like we are all talking about the religion of decentralization in some sense rather than the marketplace of decentralization. If decentralization has real value, why aren't we paying for it? Why is nobody actually discovering and paying the value for it? And Eigen layer with the second mode I want to build secret sharing on top. I want to build censorship resistance on top.
00:36:20.534 - 00:36:43.662, Speaker C: I want to build some other thing on top. Can actually for the first time start valuing putting a value on decentralization and by making it part of the Ethereum and sharing the validator set with Ethereum actually enables more decentralization not only in the Eigen layer level but also Ethereum itself, which is something that would be super cool if something like that works.
00:36:43.796 - 00:37:50.578, Speaker A: Sure, that's a really interesting point that was a constant theme of last season's mev episodes, which was what happens if the sort of design philosophy or the ideals that are informing the design of your system run counter to the economics of how the system ultimately wants to go? And I had never really thought of that from the standpoint of we're talking about either it's a coordination mechanism or marketplace. I would actually argue that a marketplace is a form of social coordination, but it actually provides an incentive in the positive direction where if there are a bunch of AVSS that want a more decentralized form of trust, then suddenly you have an incentive to actually go do that and create that. So maybe this is a good way to segue into the demand side here and would love to kind of tease out where you sort of see the early adoption from different actively validated services. But Miles, I know you've got some thoughts on kind of the nitty gritty again perspective of what would it look like if you were a middleware, maybe an oracle or something tee or something like that, and you actually wanted to onboard? So, Miles, can you kind of walk us through some of those more nitty gritty questions of what that user flow would look like?
00:37:50.664 - 00:39:32.962, Speaker D: Yeah, and I think you honestly have already teed me up very well for these questions because by answering some of the supply side questions around what you really care about, I think that gets to the demand side, right? Because those are the folks making these decisions. And so, yeah, I would love I've been thinking a lot about if I was, say, in the shoes of a shared sequencer network, what flavor of restaking would I want to resecure myself? And I think there's a lot of decisions to make, and I'd love to just kind of get your thoughts on the considerations around them. As I think about it, it's what assets do I want to be able to restake to my protocol? I think, do I care more about just enabling the largest amount of capital to come or do I care about actual decentralization component like you just described with the secret sharing piece? And then I think a big one that I would love to cover is do I go through this onboarding process to the Slashing Veto Council or do I basically plug in permissionlessly? And what are the costs of that, from my perspective? What are the benefits? Why does opting into something like that make restaking to my protocol more attractive to the supply side that you're trying to get to restake to your protocol? I think you've already teased out it a little bit, but I would love to just hear about the considerations that if you were in the shoes of, say, a bridge or a sequencer set, how you would be thinking about this and what are the major decisions that they will have to make.
00:39:33.096 - 00:40:50.298, Speaker C: Yeah, totally. Before I get into it, I think I was talking about the three trust models for Eigen layer, and I talked about two. One is economics, one is decentralization, and the third actually gets to a different class of use cases. And then I'll address the question about, like, when I'm building a new service, which modes of trust am I actually using? How do I think about which set of stake do I actually use? And then the question about how do I decide whether I want to participate in the veto committee or not? Okay, so the third model so the first model of trust was economics. The second model of trust was decentralization. The third model of trust is the fact that a restaker can be the same as the ethereum staker itself. And this goes to the mev thing that we were discussing, which is what if I want to make a credible commitment on how I'm going to do ordering as a block proposal? Let's say I want to say that I'm a block, proposer I restake, and then I want to build an mev solution on Eigen layer that might say that whenever I make a promise, when you send me an encrypted transaction, I'm going to send you a promise that I'm going to include this.
00:40:50.298 - 00:41:52.814, Speaker C: And if I don't include a decrypted version of your encrypted transaction, you can take me to court and then show that, hey, you promised me this at this block number. But actually in that block number, there's no decrypted version of this, so you will get slashed so you can start building. I gave a talk on mev and restaking, and this is basically the idea that suddenly you have superpowers in making credible commitments on altering rules using Eigen layer. This is neither related to the economics nor related to the decentralization. This is coming from the specific fact that the restakers, or at least if the restakers are the same as the ethereum stakers, then they can get into these kinds of commitments, that credible commitments on ordering is a whole family of solutions that you can start building on top of Eigen layer. And we have a 25 page paper coming up explaining what these different kinds of applications you can start building. Maybe since you asked me examples of services, I can give you some examples here.
00:41:52.814 - 00:42:27.366, Speaker C: I mentioned threshold encryption. I want to create an encryption, but it's not default in protocol, but maybe 30% of the stakers opt in. Then suddenly you have threshold encryption as a lane. That is possible because you send a transaction to this encrypted, which is encrypted to an address, which is controlled by a Keeper committee. And then as a block proposal, I can make a promise that I'm going to include it. And if I don't include it, after I send the promise, they give me the decrypted key. The committee gives me the decrypted key, and then I include the decrypted version.
00:42:27.366 - 00:43:18.582, Speaker C: So you can start building really insane things which are like protocol upgrades without having to actually go and do this. This is one example. Another example is I can do partial block auctions. I can tell you, Michael, that I'm selling the first 30% of the block to you, and I get a signature from you saying that I send a signature to you saying that, hey, here is what I'm going to include in the first 30% of the block. I tell Miles I'm going to use 70% of the block and sell it to him. You can start doing credible commitments at the block proposal level using this kind of an idea, using the restaking idea, which is a third trust model, really, which is the fact that the block proposal is identical to the Restaker. And another example which I'm actually quite excited about is event driven actions.
00:43:18.582 - 00:44:27.230, Speaker C: Event driven actions are, imagine you're building a stable coin or margin lending or some kind of a protocol, and one of the core causes of capital inefficiency in these systems is the over collateralization ratio. Like, how much over collateralization should I do and how much over collateralization should I do depends on the price volatility in the time to liquidation the price volatility of the asset relatively to what I'm lending in the time to liquidation. So if I can reduce the time to liquidation, I can actually get like much tighter systems. I don't need to over collateralize at 50%, I can overcollateralize at 5%. If only I can guarantee liquidations in one block. How do I guarantee liquidations in one block? If you had event driven actions event driven actions are if such an action happens, then do this. And if you already have a liquidation pool opted into a certain liquidation condition, and block proposes promising that every three blocks I'm going to actually trigger all the liquidations.
00:44:27.230 - 00:44:56.614, Speaker C: Because the inattributability problem that you have in a system like third party keeper system, like a gelato, does not exist when your block proposal is the one making this promise. So there's all kinds of rabbit holes to go through just in mev and restaking. But that's the third trust model of eigen layer is block proposal commitments. Okay, now I'll switch to answering if you want to make any comment on the restaking.
00:44:56.662 - 00:45:40.982, Speaker D: As you were talking, it reminded me a lot of what has just been implemented on the cosmos side in vote extensions, right, where you are asking your validator to set to do additional work in constructing every block. And I think it's very common to see like on the ethereum side, something similar come along, but less ingrained directly into the protocol, right. It's more of an opt in basis. But now I think I fully understand why the benefits of having the block proposer be the same as the Eigen layer operator right? Versus I think going into this conversation I was like specialized operators might end up being the kind of winning model but can totally see how that just increases the general health of the network.
00:45:41.046 - 00:47:43.578, Speaker C: Just to round this point out, one of the worries that people have when I talk about proposal commitments is hey, whole PBS was designed around proposals being dumb but now proposals are making commitments. But if you look at the mev literature you will see a lot of builder commitments. People talk about pre confirmation and this and that and how are you doing any of these things? How are builders making commitments? And even more fundamentally who is a builder? Like builder has no protocol role who's this random builder who's suddenly making commitments? The proposer has the monopoly the proposer is the one that we can control in protocol so in my view what should happen is the proposer should enter commitments and the builder should enforce it. I enter commitment on that I am opting into an event driven action as a proposer the proposer is the one that has agency that we are actually trying to decentralize. Sending all this to the builder is a terrible mistake because the builder should enforce it. Like the builder is the muscle, the heart and the brain the heart particularly is the proposer like if we move power out of the proposer, the point of decentralizing the proposer is a shara like what do you do with the proposals are decentralized but the builder has all the power so the proposer is the one who has to make promises and by keeping the proposers aligned with the decentralization and ethereum spirit and all this they will enter only commitments that actually are in the general health of the ETH that they are putting into the system and the builders keep the commitments. It doesn't mean suddenly the proposers have to work much harder the same ecosystem PBS can be generalized to then say the builders hold to all these other conditions the relays double check that they're holding to all these conditions and the proposer right now blindly signs up on a header it could continue to do it by trusting the relay to actually take care of its own goodwill.
00:47:43.578 - 00:48:33.150, Speaker C: So anyway, so that's just to round out what we think would be the right place is proposers have a protocol role, they should make commitments builders are just the execution muscle and they can keep those commitments that the proposers have entered into. This requires upgrading the MEB boost infrastructure to make it more general purpose. Right now there is the whole thing about intents on the other side, on the user side, and how to communicate the intents into the system. But what I'm talking about is proposal commitments, which is intense on the proposer side. Not just intents, it's commitments made from the proposer side that can then be kept at the builder side. So that's something that I'm actually quite excited about as a natural evolution of the mev space.
00:48:33.300 - 00:48:42.402, Speaker D: That's fascinating and is not necessarily what people think of when they think of restaking in terms of the early use cases. But I think it's absolutely see that.
00:48:42.456 - 00:49:11.786, Speaker C: Part of the reason we don't think of these use cases today or we are not building these use cases today is these use cases make sense only when there is a significant fraction of proposals restaked. If you have like 5% proposals restaked, that's good enough. It's $1 billion security for something. But 5% of block proposers do an action is not that interesting. But when 50% of the block proposers can do an action, that becomes suddenly very interesting.
00:49:11.888 - 00:49:44.870, Speaker A: Sure, I'm glad you brought that up. I actually wanted to ask you as well. If I had to ask you to sort know, pull out your crystal ball and try to get a sense in. Let's say five mean what percentage do you think of the Ethereum validator set? Ultimately ends up engaging in restaking and sort of what is the Ven diagram in between node operators on Eigen layer and ETH validators? I would guess the lion's share of node operators for Eigen layer ultimately are ETH validators. But I know that's not necessarily the case. So wanted to get a sense of what that overlap ends up looking like.
00:49:44.940 - 00:50:39.766, Speaker C: I think those are two different questions. One is like what fraction is restaking and the other one is whether the node validators are identical. We are building Eigen layer because we believe that restaking is just uniformly better for all stakers to participate in. That's why I'm saying this should become eventually just a part of Ethereum itself into the core protocol whether node operators of Ethereum should be identical to node operators of these auxiliary services. I don't think that there is. What we would see there is that there'll be a stratification of two kinds of services. One kind of services that require decentralization where it's better to share the same set of validators.
00:50:39.766 - 00:51:45.280, Speaker C: The interesting thing is you can get decentralization only when the service that you want the people to run is lightweight. So there are lightweight services that thrive on think. I don't remember Michael or Miles mentioned Oracle as a thing that might require professional validators. But I think Oracle is one of those use cases which don't require really professional validators because it's one of those things which is very lightweight, right? Querying a price feed of the Internet can be very lightweight but very trust sensitive. So it matters a lot more the trust matters a lot more than just raw performance in those cases. You would see that people develop, of course, lightweight Oracle adjuvants that you can actually add on to your node and run. In fact, Justin Drake had a proposal on an Oracle add on to Ethereum two years back and something like that could be very interesting.
00:51:45.280 - 00:52:53.422, Speaker C: On the other hand, but this could be a purely non slash service, right? Like just the decentralization you're getting a majority opinion from tens of thousands of stakers is already like a super useful oracle feed. On the other hand, there'll be services which require for example, I want to operate a bridge which makes the kind of promise I was talking about, which is verify a ZK state on one ZK roll up and then transmit that state to another roll up. Here I don't really need decentralization, I just need economics. And in these kinds of use cases it's much better to have single or like a few small central parties that you can either delegate to or they have their own stake. So what we'll see is basically a stratification into two kinds of services. One kind of services which are lightweight and require decentralization, another kind of services are heavyweight and can rely on economics. The bad case happens when you have heavyweight services that require decentralization and the fact is these two are just not compliant.
00:52:53.422 - 00:53:39.586, Speaker C: Like you can't have decentralization and a heavyweight service that just doesn't go together. So anyway, those will be weeded out as wrong or bad ideas. So the good ideas are things that are decentralized and lightweight that we believe every staker will run. Eigenda is one of them because the requirement to run Eigenda is 10% more than just running an ethnode that's bare minimum. So that's an example of a service that we think every staker can eventually run. The things that we think every staker will not run are the things that are going to then be delegated. So essentially you'll see a stratification of the market into lightweight things that require decentralization and people are willing to pay for it.
00:53:39.586 - 00:54:46.066, Speaker C: So that creates the active incentive for there to exist some number of decentralized nodes that actually do it in a decentralized way. And then the other services which are heavyweight and centralized. And one of the things people talk about the modular landscape and so on, I think trust itself is modular and inside any given service you can split it into aspects that need decentralization and aspects that can work on centralization and we need fundamental rethink of how protocols think of themselves. And this is something that we will be playing a lot of role in going forward. At least as researchers we've thought a lot about how to take a complex protocol and split the portions that require decentralization into the decentralized committee and the portions that require only economic trust into the economic committee. You can just modularize that. So for example, it'd be amazing if I can take a consensus protocol and just borrow censorship resistance from the decentralized committee and borrow economic security from the highly centralized committee.
00:54:46.066 - 00:54:52.170, Speaker C: So these are things that we expect would be super interesting going forward.
00:54:52.320 - 00:56:42.382, Speaker D: I think that's great and I honestly think you've covered the demand side really well in thinking about what sorts of models, without even trying, what sorts of models work are most attractive for different sorts of ABS, right? And so, yeah, I think that makes a lot of sense where something that's super heavy, like a bridge really just needs economic security or it's unrealistic to try to go through with that. And so I think one thing I'd maybe want to segue here too is the role of Eigen Layer and Eigen Layer's governance in, know, Restaking's, I guess growth and development and doing so in a safe way. And to me it seems that there's a lot of similarities to the early days of Lido where Lido had to make certain choices in the early days, such know, maintaining a whitelisted validator set that were necessary in order to basically get the market share. It has now mitigate the risk of centralized exchanges, dominating staking, et cetera, et cetera. And now their focus is very much so towards Ossification and Mitigating principal agent problems. I'd love to hear just a little bit how you're also thinking about the sequencing, both in terms of rolling out all of these different flavors rolling out maybe it's just existing node operator like ethereum L1 validators versus bringing in these specialized operators. And especially the role of the veto council in all of this because I think it's very interesting in that it's clearly necessary, I would call them training wheels, the veto council, but I could see challenges ahead in trying not to be subjective at all.
00:56:42.382 - 00:57:00.066, Speaker D: Right. Whereas the veto council has a few roles that could be viewed as very subjective, like which LSTs to onboard, right? Which ABS are allowed to have this backstop of a Slashing veto in case there's an unintended Slashing event.
00:57:00.168 - 00:57:02.386, Speaker B: So would love to just hear how.
00:57:02.408 - 00:57:06.978, Speaker D: You'Re thinking about rolling this out and the sequencing around it.
00:57:07.064 - 00:57:44.658, Speaker C: Yeah, no, this is a very important question. And when people think and talk about what are the risks that are associated with something like Eigen Layer, I think this becomes even more salient. So I just want to highlight some of the history here. So we talked about restaking. We came up with the concept of this like more than a year and a half back. And the easiest thing to do would have been basically to say we just accept one LST. You don't need to wait for doing all the things that we were doing.
00:57:44.658 - 00:58:18.394, Speaker C: Just say I accept one LST and then accept. And anybody can run a chain. It's actually the easiest thing to go and do. We did not do that. We had to design the complex Eigenpot system which allows native stakers to participate. And we don't launch till we actually have the Eigenpot system which allows anybody to participate as an equal. Not only that, the most important problem of restaking is that it is going to overload the validator set.
00:58:18.394 - 00:59:11.360, Speaker C: So this is my main issue with interchange security. You have the same set of validators and they have to opt into, let's say, our vision is there will be tens of thousands or millions of chains. So if that's the case, then every node has to validate 1000 chains, which set of nodes are going to be able to do it? What that will lead to is basically convergence into a very small validator set. That's what will happen. The solution to that has already been figured out in the ethereum community is to separate execution and DA and to let data availability scale. And that's what we did. We're actually building Eigen DA as the solution to the problem that we are creating, the problem of overloading the same validator set.
00:59:11.360 - 00:59:36.286, Speaker C: So the solution is that the data availability scales you can have more and more nodes and this data availability system is the only thing that exactly horizontally scales which means as you get more and more nodes the total available bandwidth on the system. Linearly increases. Exactly. Just you can take the number of nodes. Each node has a certain bandwidth. You multiply the two things together. That's the data availability bandwidth.
00:59:36.286 - 01:00:06.334, Speaker C: It's an exact linear scaling system. So you basically just get more and more nodes and more and more nodes means the system's better and better. Each node doesn't do all the work. And so Ignda is a key primitive in enabling shared security. Shad security without horizontal scaling is an absolute nightmare. So that's why we did not do what one could have very easily done last year. Take a single LST, take the Cosmos SDK, build an adapter to trust.
01:00:06.334 - 01:01:17.302, Speaker C: This validator set we waited for actually figuring out, because one of the things is we are thinking about the next decade, at least maybe the next 30 years for how this system has to evolve. And if you want to think about this, and we want to be a marketplace for decentralized trust, by building this restaking you can kill decentralization completely, then where is the marketplace? This would be like a small one year blip that shows up and like a cancer, it just kills everything that it built on top of. We are very aware of all these issues, that's why we actually did not launch and we are not launching without the data availability substrate. So our natural evolution of the space is that when we say there's thousands of chains, these are not really chains, these are thousands of roll ups and in the most general sense, thousands of applications that use modules that themselves are horizontally scaled on Eigen layer. That is the end game. The end game is you have horizontally scaled services like data. We built a data availability horizontally scaled service.
01:01:17.302 - 01:01:59.726, Speaker C: We have a paper coming up which solves horizontally scaled censorship resistance. We have papers coming up on how to build horizontally scaled oracles. So essentially we take each module, each thing that is needed in the space, figure out how to horizontally scale it, either us build it, other people build it as services on top of. This common trust system. Now we are talking now we are actually talking about a system where you can have more and more nodes join and as you get more and more services, each service, each node is doing only one end of the work. So you can actually have many more services running. So that's how we actually thread the needle.
01:01:59.726 - 01:02:50.654, Speaker C: It's a very tight needle and we have to take a cautious approach and answering your question about governance and sequencing. So this explains the sequencing till another story so far, so to say. But going forward there's much more harder decisions we would have to navigate and we are continuously engaging and seeking community inputs for all of these things because our ultimate understanding is nobody has all the answers. Innovation. We call this open innovation because I have felt many times from the outside look at a protocol and hey, I can do ABCD to the protocol and make it better, but I don't have a governance right to go and do it on that protocol. So permissionless innovation particularly enables this. Somebody comes and builds a data availability.
01:02:50.654 - 01:03:21.582, Speaker C: We build a data availability on Agile. Somebody will look at it and say hey, these guys missed ABCD. I want to build a better data availability on Agile. That is awesome, right? So that's the core primitive but sequencing going forward and particularly the Slashing Veto committee. So when you think about it, before I get into the Slashing Veto committee, I want to lay out the philosophical basis. So when I'm talking about open innovation and Chad security, what you want to prove, so one access is open innovation, other access is chat security. I want to get as much open innovation and as much chat security as possible.
01:03:21.582 - 01:03:52.040, Speaker C: That's the stated goal. And if you start with this goal, the problem that you want to avoid is open innovation should not create an externality on security. Like I stake and I stake into new things and then I stake into new things and then my money blows up. That's just a bad situation. So there's a trade off between open innovation and security. And just to make this more interesting, it is not unique to crypto that there is this trade off. You can think about nuclear power.
01:03:52.040 - 01:04:44.406, Speaker C: Do you want open innovation or do you want safety? You can think about AI, do you want open innovation or you want safety? This is a fundamental problem everywhere. It is not something super unique to what we're doing. But how do you thread this needle, right? It's naive to say I only want innovation, I don't want safety because then once the system becomes unsafe, you're going to allow zero innovation after that. So it's also naive to say I'm going to be so safe that I'm not going to allow any innovation because there's no growth in that system. So this is very careful trade off that one has to think consciously about and bring technology. One definition of technology is it breaks existing trade offs. One definition of technology or innovation is you think there is a trade off between A and B, but I can actually break it.
01:04:44.406 - 01:05:31.906, Speaker C: That's an example of I'll give you one example on how we can break this trade off in a limited context, okay? But broadly, you set this up like there's a trade off between over innovation and safety. And one way you usually solve this problem is have governance decide like some council or something, navigate this trade off. Because whenever there is a natural trade off which cannot be technologically solved, you need consciousness and human intelligence to navigate it. And that's part of the initial design, is to have the Slashing veto. So Slashing veto the initial design is there is going to be a Slashing veto, which onboard services. And whenever slashing happens, the veto can intervene and just veto the slashing. It cannot create new Slashing, but it can only veto the slashing.
01:05:31.906 - 01:06:32.590, Speaker C: So that's the role of the slashing veto. And it'll be filled with community members in the broader Ethereum roller middleware Eigen layer space. So that's the core idea. And already you'll get a hint of what kind of people will participate in this by looking at the participants in some of our community multifig. For example, is this a permanent feature or is this a temporary feature? That's the next question. And of all the things in the Eigen layer protocol design, this is the only place where there is subjectivity to decide who this committee is, right? And like I said, our stated goal is if you want to get rid of all subjectivity, for one, if we don't get rid of all subjectivity, there's no chance it'll go as a default part of Ethereum because Ethereum doesn't want to exert subjectivity. That's why a liquid staking protocol can never be a default part of Ethereum because it requires exerting unnecessary subjectivity to actually make that work.
01:06:32.590 - 01:07:25.336, Speaker C: How do we think about this number one eventual? So the first thing is, when I build a service, initially, the service goes through the slashing veto and the service ossifies. And once the service is belt tested and Ossified says, I don't need the slashing veto anymore, and goes on a completely permissionless layer. So we could even launch with a permissionless layer and a permission layer where the permission layer is controlled by is onboarded by the slashing veto, the permissionless layer. Anybody can launch anything on top of it. And the reason this is interesting is as a staker, you have to convince the staker that you have to opt in to a service which is raw. Like it doesn't have the protection of the slashing veto. So you have to go and tell the staker, hey, I'm moving off the Slashing veto.
01:07:25.336 - 01:08:06.004, Speaker C: Please come and serve me. And they'll be like, what are you talking about? If there's a service bug, I'm going to get slashed. And my position is open to random errors. And this essentially makes the information transparent on both the sides of what is actually the risk profile. So by allowing a set of stakers to trust both one or the other. So if a service goes through the Slashing veto, either the contract is right or the Slashing committee is right, you are protected. Whereas somebody natively opting in without the Slashing committee has to purely rely on software.
01:08:06.004 - 01:08:50.276, Speaker C: Correctness? And if your software is so correct, then maybe you can convince people that that is the right thing for you to do. So this is how we threaten the needle again, like have a slashing veto committee but also have a permissionless layer. Eventually we could say we don't have anything to do with the Slashing committee and there's not one Slashing veto committee, but there's a marketplace of slashing veto committees. Slashing veto committee is basically just a doubly trusted party. Like the relay role in PBS, in Ethereum, which is basically a doubly trusted role, which both the block proposal trusts and the block builder trusts. So you can make it intersubjective. So this is the philosophical solution.
01:08:50.276 - 01:09:21.116, Speaker C: Then I'll come to the technological solution. The thing that we see again and again as an academic, I worked on many different areas. The thing that I see is once you state the problem clearly, people are empowered to then go and come up with interesting solutions. The tension that I'm stating here is there's a tension between open innovation and safety. Once we stated it like this, we found this interesting solution. For example, let's say I want to run not one consensus protocol. There are many, many consensus protocol.
01:09:21.116 - 01:10:05.520, Speaker C: As an academic, we've written at least ten papers on consensus protocols. Each of them are like, oh, you do BFD like this, you do longest chain like this, you put them together, whatever. There are many, many ways to do it. And there are thousands of protocols out there and can we break the trade off between open innovation and safety for these thousands of consensus? Not any protocol bridges and this and that, but just consensus protocol where the goal is to agree on a history of altering and it turns out you can actually completely break the trade off by using technology. What do I mean by that? The only thing that you slash for in all of these consensus protocols is signing two blocks with the same block number. That's the slashing condition. So we just need to write one Slashing contract.
01:10:05.520 - 01:10:52.856, Speaker C: That slashing contract. But that is not enough still, because the slashing contract may be the same, but I download and run code bases provided by random people who are saying that they're running consensus protocols. And then in that code base, the code base double signs due to an error or due to malicious intent or whatever. So having the same Slashing contract is not sufficient to protect me as a staker from illegitimate Slashing. So what can I do? We can actually build something we call the antislasher. What is the antislasher? It keeps the keys required to sign on these consensus protocols in a separate container. And in that container it checks that when I sign once, I don't sign twice.
01:10:52.856 - 01:11:39.784, Speaker C: That's the thing that's checked. And we write it, somebody else writes it and then we keep it separate. Once you have the Slashing contract and the antislasher, now you suddenly have broken the trade off completely between open innovation and safety. I can degen into any new consensus protocol without knowing anything about what this box is because I know I'll never get slashed because the Slashing contract and the antislasher are palved. And this is a beautiful example of how once you state the problem clearly that this is what we're working towards is there is open innovation and safety. Actually, you can come up with technology breaks the trade off completely. In fact, it breaks it so beautifully that what you could do is even solve the principal agent problem in delegation.
01:11:39.784 - 01:12:30.156, Speaker C: What you could do is you could take the antislasher and put it into a trusted execution environment. And I said now suddenly it's transparent. If you delegate your stake to me and I restake into all of these consensus protocols, I'm still protected. You are still protected because you know that whenever I'm signing off, it's going through the trusted execution environment which is checking the antislasher. We're already working with a project called Cubist, which is implementing, starting to think through the protocol specification for this. So this is an example of the landscape that is there going forward, is there is a trade off between open innovation and safety. We can start with a permissioned committee which exerts human judgment, but then we don't like our role as stewards of who this committee should be.
01:12:30.156 - 01:12:53.828, Speaker C: We can make that committee itself inter subjective, which is just a doubly trusted party, a marketplace of intermediaries. And then maybe for a whole class of solutions, you don't need any of these committees, we just need better technology and we'll be working on it. We hope the community will be working with us on figuring out how to solve this trade off, not only for consensus protocols, but for every kind of protocol that you might want to build on top.
01:12:53.914 - 01:13:30.444, Speaker A: So the theme of the season obviously is liquid staking. And I want to get a sense of there's sort of this link in between what you're doing at Eigen Layer and some of the big liquid staking tokens like lido or rocket pool or something like that. And those were the two first liquid staking tokens that you onboarded into Eigen Layer. And in a lot of ways I can see this virtuous cycle in between the liquid staking issuers and something like Eigen Layer. I'm going to go out on a limbs. It's my personal perspective. It might end up playing out differently than this, that liquid staking continues to find product market fit on ethereum.
01:13:30.444 - 01:14:29.076, Speaker A: That becomes the dominant way that most folks end up staking. So if we return to that sort of operational model and spectrum of the different ways that people are going to interact with Eigen layer, I would go out on a limb and say mostly there will be some people that are actually sort of solo stakers and they actually work directly with their staked ETH. But I think a lot of folks are going to take their Steeth or their re or whatever it is and end up using that to restake on Eigen layer and that's good for your business or for Eigen layer, the protocol. I would be curious to see how you think about the strategic alliance between these liquid staking protocols and something like Eigen layer. And we've been using this word this season, Coopetition, if it can ever get a little bit competitive as well, maybe based on where you sit in sort of the user relationship, like how close you sit to the user. So I would love to just get your sort of that was a lot of words. I'd love to just get your high level on how you think about it.
01:14:29.178 - 01:15:11.570, Speaker C: Regarding the first part, is it going to be the case that liquid staking kind of dominates the market? I don't know. There are some reasons why liquid staking will dominate a portion of the market. There are reasons. There are institutions that want to stake that don't want to give up control, that don't want to pool. They have legal regulations, they want to have a node operator in their jurisdiction. There's all kinds of things going on. And as we start expanding the total market cap of ETH, we will see that the set of constraints that each staker operates in their delegation model will also be very different.
01:15:11.570 - 01:16:04.736, Speaker C: So I don't know whether it's as clear that there will be whether I think you can break down your question into whether there is a liquid staking is the dominant way people will interact and then whether there's a single liquid staking, which is the dominant way in which people interact. I don't know the answers to these questions. I think there is complex market dynamics in that. But we are very neutral to this fact. As a protocol, we have no horse in the race to whether a single protocol wins. Multiple protocols wins like we have no horse in the race, but we have some horses somewhere and one horse is that. Like I said, there are three aspects of the marketplace that we're creating.
01:16:04.736 - 01:17:13.240, Speaker C: There's economics, there is decentralization and then there is the exact alignment that it's basically the each staker that is also a node operator that's also restaking the first, the second one which is decentralization. Whether one liquid staking protocol wins or not, as long as we can ensure that there is a node operator set which is decentralized and not under anybody's control. I think that satisfies what we want out of the marketplace is basically there's enough set of nodes in this system that are highly decentralized. And I think that is a very important consideration for us. And I think that we hope and we're shepherding the space as much as we can to actually value this decentralization and pay a premium for decentralization. In fact, one of the first services building on Eigen layer is called Witness Chain. It's a project out of Princeton which is building a proof of decentralization or proof of location.
01:17:13.240 - 01:17:50.176, Speaker C: So you want to have nodes around the world. That's one type of decentralization. There's stake decentralization, but there's also node operator decentralization, geographic decentralization, if you can't measure it. One of the principles is if you can't measure it, you're not going to optimize and grow for it. Right? So we want a measurement oracle and if the measurement locus itself is centralized, that breaks the whole point of the system. So it's a beautiful protocol, which is the measurement is itself done by the decentralized nodes about other decentralized nodes. Even if a fraction of the nodes lie, you can still get the truth.
01:17:50.176 - 01:18:29.436, Speaker C: So that's an example of a service building on Eigen layer, which will be a very base layer service, because many other services can then recruit stakers based on that. So that's just highlighting the second point, which is decentralization. And as other protocols participate in the ethereum staking ecosystem, this is going to set up a healthy pressure to decentralize. That's number one. Number two, our goal, like I said, is to dissolve into the ethereum protocol. That would be the ideal output of restaking. And with that goal, we find zero competition with liquid staking.
01:18:29.436 - 01:19:07.150, Speaker C: Liquid staking protocols cannot dissolve into ethereum. And like I explained why I think that is possible for Eigen layer because the only subjectivity that we had to exert was the slashing veto. And you can make the slashing veto a marketplace of slashing vetoes. You can get rid of the slashing veto, you can do many things to basically potentially dissolve this protocol into ethereum. But liquid staking requires human judgment and management of the node operators. So liquid staking will always exist as a protocol on top of ethereum plus Eigen layer. That's our view.
01:19:07.150 - 01:20:13.868, Speaker C: In fact, what will absolutely happen is either these liquid staking protocols will integrate some of the Eigen layer services under the hood. For example, you stake in ethereum, you stake in Eigen layer and then say your liquid stake teeth now represents both of these together, or somebody else will take a Steeth, put it on Eigen layer and then do operations and then create a liquid derivative on top. I think this is going to happen. It's much more likely the farmer might happen because there are big protocols with enough power there and they'll say, so what will happen is the services with the most interesting rewards will get integrated under the hood of one of these bigger tokens. And this sets up lots of interesting things. Smaller tokens may be more risk tolerant, so they may take more risks and so on. So we don't know exactly how these dynamics will play out.
01:20:13.868 - 01:20:46.716, Speaker C: But we do think liquid staking is irreplaceable through eigen layer, so we have absolutely no intersection or interest in being a liquid staking protocol. Our thesis is very narrow. Our thesis is narrow in one sense, which is that we are here to promote open innovation. That's our thesis. That's why we're very happy if eigen layer and restaking becomes a default part of ethereum. We have many, many things we want to build. We want to enable other people to build.
01:20:46.716 - 01:21:52.700, Speaker C: So we have no dearth of this is our one idea and we have to hang by its corner. If it's part of ethereum and it's native, it's a superpower to us to go and build lots of other things that are complementary to what ethereum can serve today. So that's our own roadmap. So I don't know how the liquid staking protocols think because I can't speak for them, I can speak for Eigen layer. And our own view is we are very complementary in how we approach this problem. Our superpower is in actually figuring out what aspects of trust protocols need. How do you build enough interfaces for complex distributed systems to then be built on top of wagonlayer? Our superpower is in figuring out all of these things and we want to build a community which is filled with experts in protocol and distributed system design which is very different from what a liquid staking protocol has to be specialized in, which is in understanding and figuring out how to ensure that node operators hold to their frost and SLAs.
01:21:52.700 - 01:21:57.456, Speaker C: And these are completely different specialties in our view.
01:21:57.558 - 01:22:17.592, Speaker A: I want to close shrum by asking you a question, actually, about when I'm just sort of playing out into the future here. So obviously, ETH started as a proof of work protocol and for that reason its stake rate is much lower than some of the other protocol l ones that started as proof of stake. So you could look at something like.
01:22:17.646 - 01:22:18.600, Speaker B: Salana.
01:22:21.660 - 01:23:35.600, Speaker A: The expectation, right, purely for them just wanting to gather native staking yield would be that that stake rate increases over time. When you layer on something like liquid staking where you no longer need to separate, you can immediately get access to your stake and you don't have to sacrifice opportunity costs by participating in DeFi. You'd imagine that stake rate to go up when you layer on something like eigen layer, the ability to restake and you get even more capital efficiency, you would imagine the stake rate to go up even further. I think one consequence of that would be that the native stake rate that you get if you don't want to participate in liquid staking or restaking ultimately goes much lower. Right? Because the more people you have staking the rewards need to get dispersed over a whole bunch of different people and it's lower on a sort of per individual basis. I guess one of the things I'm reminded of here is to bring up again sort of this dichotomy between Ethereum and Cosmos is in Ethereum it's been an explicit design choice for Ethereum to remove complexity, especially from the validator set. Whereas in cosmos actually Sonny and Dave will often say what can your validators do for you? It's the exact opposite, opposite idea.
01:23:35.600 - 01:24:35.796, Speaker A: And what is interesting to me about what I hear you saying about Eigen layer is it's actually weirdly, a blending of these two ideas which is to say if the validators want to do additional services and they want to post some of their stake as collateral, they should be able to do those services. So knitting together this idea. I could see a situation in, say, five years from now where the native staking rewards just from ethereum. If you're not doing liquid staking or restaking are so low that basically everyone's either liquid staking or restaking. And then you have validators doing many of the services that Ethereum explicitly decided not to bring into the protocol before. The key difference being that they're opt in instead of like top down commanded. So I guess my question at the end of the day there though is is that a desired state? I suppose if you're like the Ethereum foundation and we're like, hey, we didn't want to bring this stuff into the protocol and now we find ourselves our validators doing all the stuff we didn't necessarily want to do.
01:24:35.796 - 01:24:37.760, Speaker A: How do you sort of answer that?
01:24:37.850 - 01:25:26.448, Speaker C: My only answer to this is are there services that want decentralization or not? Is there a market, what is the market value of decentralization? This is what we are going to find out in five years. We are going to find out. We are trying our best again to ensure that we take responsible steps so that we don't just go through the problem of path dependence. Like you start off in a highly centralized place and you know, you never have an incentive to decentralize. So we don't want to come and mess up the existing decentralization. But the core thing is the total amount of stake that will be decentralized depends on what is the additional yield I can get for being decentralized. That's it.
01:25:26.448 - 01:26:19.080, Speaker C: That's what is going to determine it. And the way we can smooth this out is by saying that hey, you remain decentralized and validate ethereum plus a few services but then delegate to somebody else for all these more complex services. So you are contributing to the decentralization premium for all these services. But for all the other things that are just like relying on your stake, if you have a trusted party just send it over to them. That's possible. But I think at the core of the space is the question of are people willing to pay for decentralized trust? If the answer is no, people don't want to pay for decentralized trust, no services will have enough economics to actually drive value into decentralized trust, then it might end up basically collapsing. But I don't think that that's the case.
01:26:19.080 - 01:27:14.660, Speaker C: We haven't figured out I think this is because we haven't figured out how to for example, I mentioned Shamir secret sharing. How do you do secret sharing without having a decentralized validator set? I don't know the answer to that. So there are fundamental tensions. And when people think about things like zero knowledge proofs and all that, I think there is still a huge space between a gap between what can be achieved through zero knowledge proofs and more complex secure multiparty systems so which need like multiple nodes and multiparty information dispersal. And one of the really nice examples of this is what Panambra is building in the cosmos ecosystem, henrietta Valens and his team. So that's a great example of what you cannot build without decentralization. And so there is a premium for decentralization.
01:27:14.660 - 01:28:03.640, Speaker C: That's our thesis. We are pushing very hard to figure out how to make sure that the cost of decentralization is not heavy. So what do I mean by that? Like for example, the core principle around Eigenda is the total cost required to download and store the data in a distributed network is N times more than the cost required to store and do it on a single node. And so if N is 10,000, the cost basis of the system is 10,000 x higher than like an Amazon. So how are you going to compete with that kind of a cost basis? So by building the system itself to be exactly horizontally scalable, in our system, the cost basis of downloading and storing data is exactly two times the cost of one node downloading and storing data independent of how many nodes exist. You can have a million nodes and still the cost basis is only two x. These are the innovations that actually transform.
01:28:03.640 - 01:29:02.056, Speaker C: Is the system going to decentralize or not? Is if the cost of decentralization is negligible and we're trying our best, we want the community to continue to try the best to actually ensure that because nobody's really going to pay for decentralization. That's the fact end users are not going to pay for decentralization because you look at Http and Https, https is more secure. People still prefer Http because the UX lag on Https till that was resolved, till the additional marginal cost of the secure Http is higher, people are not going to do it. That's the same thing our thesis we need to figure out. So the thing that instead of the decentralization theology, we need decentralization technology, which is systems that actually break the trade off the cost basis of decentralization, the latency basis of decentralization and all of this stuff. And I think that's what we would be most excited about.
01:29:02.158 - 01:29:38.180, Speaker A: True. Unfortunately, we've got to wrap it here, but this was just a fascinating conversation. I just want to say also, I really appreciate you as a founder here. I know you've gotten a little bit of pushback from the Ethereum Foundation, et cetera. You've done such a good job of educating the community about such sort of a new and interesting and complicated idea. And I just really admire how with such, well, intentions, you've taken a lot of these poking questions and you've just really embody, I think, a lot of the traits that I look for in founders with integrity. So just want to say I really appreciate all the education that you do and how well you take some of these more probing questions.
01:29:38.180 - 01:29:54.172, Speaker A: And I want to give folks if they want to find out more about you or Eigen Layer or, you know, if you're maybe in Avs and you're looking to find out more details about how they can start renting security from Eigen Layer or anything like that. I mean, what's the best way to find out more information?
01:29:54.306 - 01:30:59.404, Speaker C: The best place to look for information is our Twitter handle at eigen layer EIG and L-A-Y-E-R my own Twitter handle at Sriram Kanan, we also have for people trying to build new AVSS, we have a forum forum iconlayer XYZ. We have a Discord channel for Stakers and other people broadly in the community who want to engage with us on various questions. Yeah, if you are interested in building more open innovation in the crypto ecosystem and like our vision, please do send me a DM either to me or to the Eigenve. And if you want to join our team, if you want to be part of the community in any way, we're very much open for all of that. And I appreciate your comments, Michael, on some of these. I think, you know, it is easy to respond nicely when you know that the comments are well intentioned.
01:30:59.452 - 01:31:14.070, Speaker A: Sriram, thank you very much, my friend. Guys, I highly recommend that you go check out Eigen lair. And cheers. We'll have to do it again soon. All right, miles, I think you and I were prepared for a banger from Sriram, but at least met, if not exceeded the expectations. What a fun conversation with him that was.
01:31:14.760 - 01:31:40.088, Speaker B: Know, I think we covered so much ground and what we were really hoping to get out of it is, know, get into some discussion topics that maybe haven't been spoken about before with Sriram on other episodes that are very top of mind for a lot of people right now. And I think we accomplished that. Hopefully we'll let the listeners be the judge of that. But I came out feeling like great about this episode.
01:31:40.184 - 01:32:37.344, Speaker A: I want to get in and actually divide our. Recap into relatively the same way that we did the episode with SHRIM, which is maybe talk about some of the supply side portions of the Eigen layer marketplace or a social coordination mechanism, however you want to call it. And then maybe we can get into some of the demand side and then play around with that intersection of liquid staking and restaking that we only got to at the end there. So one of my takeaways here, I eventually want to segue this into this claim that he made, which I found very interesting about wanting to enshrine eigen layer in the Ethereum protocol. I'm starting to see these two natural tensions is actually kind of being very similar, actually, which is this sort of tension in between wanting to create a permissionless experience versus a good user experience. So this would be the app store and then this tension in between what does governance decide and what does the free market decide. And I think that messy gray area right now is a lot of the work that these protocols are going to have to do.
01:32:37.344 - 01:33:10.244, Speaker A: So Sriram had this very interesting line of reasoning early in the podcast where he was know, ultimately we want to enshrine eigen layer at the level of Ethereum and the users should really decide here, this should all come down to the users. That sounds good ideologically in practice. We know that this early crop of crypto users doesn't always make good decisions on a short or midterm timeline. And so how do you deal with that sort of adverse selection problem that a lot of these protocols have had to mitigate? I found myself wondering a lot about that tension.
01:33:10.292 - 01:34:45.780, Speaker B: Yeah, 100%. I mean, I think there's a clear analogy that you could draw between we talk about this concept of training wheels, right? And Lido's training wheels were to have a curated validator set in the early days and that at the expense of maybe being a little bit less permissionless, creates a better user experience, right, and allows Steeth holders to feel better about their validators not getting slashed and those losses being socialized across all the holders. And in the same way, eigen layer's slashing veto council is going to make Restakers feel a lot better about their decision to provide economic security to an Avs because they know if there is an unintended slashing event, they have a human backstop basically to veto that event and protect them. Right? And I think that as it relates to the free market and governance, you could see this apply in a lot of ways. We talked about on the Staking router episode, this concept of these different modules basically pulling out the decision of allocations from governance and letting a free fee market determine the allocation of deposits across stake. And I think that applies to eigen layer as well and it applies to Ethereum itself. What should Ethereum actually enshrine into the protocol? Because letting the free market dynamics kind of play out, can be very scary in the same way that I think beforehand this was something that they would have never considered.
01:34:45.780 - 01:35:21.332, Speaker B: But now that we actually see what happens when you let the free market determine a lot of these critical areas that are so close to the metal of ethereum I think Ethereum folks are coming around on this idea of maybe we should be a little bit more opinionated and maybe we should leverage this extraordinarily decentralized, validator set to do other things. And so I think that's why we wanted to have them on, because there are so many similarities between decisions at the L1 level, between decisions at the liquid staking governance level and now the restaking governance level.
01:35:21.386 - 01:36:30.936, Speaker A: Yeah, really well said, Miles. And you and I have the benefit of doing this recap post ECC and enshrining eigen layer was definitely a big conversation that was happening behind, but also, frankly, in front of closed doors as well. One point that I want to make actually this sort of tension in between what does governance do, what does the free market do? So hasu talked about creating sort of a free market mechanism for price discovery within the Lido protocol once the staking router actually is live, so once more modules get added. Same thing with Sriram, basically, instead of for validating, it's sort of slashing. And there's this tension between what does governance decide versus what does the free market do. The middle ground there actually is the token, the governance token of Lido or eventually Eigen layer once they release a token. And that actually opens up both Lido and Eigen layer to a bribe type model, which I hadn't really been thinking of before either of these two episodes where in the same way, where you have curve, right? And they have this sort of governance emission token which it has value because different Lpers want to buy up and sort of ve stake it and then direct liquidity into their different pools because there's a clear incentive to do that.
01:36:30.936 - 01:37:00.932, Speaker A: You could actually see a very similar mechanism for LDO or whatever the eigen layer token ends up being. Where if you're a very specific, like, let's say you're a large institutional staker and you want to direct your stake to a very curated set of validators, you could buy up a bunch of LDO token, you could set the fee parameter for that particular module and benefit from it that way. And I'm starting to see I hadn't really thought about this bribe model for these sorts of protocols, but clear incentive actually for that to happen.
01:37:00.986 - 01:38:26.848, Speaker B: Yeah, but I think that's also really scary too, right? I agree. I think that's why Eigen layer is opting for something that looks a little bit more similar to the optimism two house model early on, where they have not released any information. But if I had to guess, I think the speedo council is not going to be anything to do with Token governance. I think it's going to be purely reputation based and then maybe the token that has a different function, at least in the early days, and Lido is more directly uses its token for governance more directly. But that's almost like of a similar sort of proof of authority system, right? Because for optimism, if who is controlling, who runs the sequencers, you don't necessarily want that to be a bribe model either, right? Because that's how bad actors get in. And sometimes, yeah, reputation is more important or more effective than economic stake because you can be opinionated about who those folks are and vet them based off of how aligned their principles are with that of the protocol. And so, yeah, I think between complete, like taking governance out of the equation completely and letting it be a free market sort of function, or if you let it be controlled directly by Token governance, that's another option.
01:38:26.848 - 01:39:08.380, Speaker B: Or if you do this more kind of social governance approach or reputation based governance approach, I think each of them has their own trade offs, right? Because the reputational one, I think you can feel confident that they're going to make the right decisions, but it's not permissionless. Right? You're choosing people based off of their social standing in the community. I agree. And that's not perfect either, but I think it's really scary. The other two options are perhaps more permissionless, right, because anybody can buy the token and then use that for their power. Or if you let it completely to the free market, then you don't even need the token in the first place. But those can lead to scary outcomes.
01:39:08.380 - 01:39:25.190, Speaker B: I think we're seeing a lot more of these training wheels across the space broadly. Even in Cosmos, we've been discussing social slashing for certain types of activity that is not aligned with the principles of the protocol or could create a worse user experience.
01:39:27.720 - 01:39:32.500, Speaker A: I guess you're talking about dYdX there, but also Osmosis.
01:39:33.080 - 01:40:16.464, Speaker B: There was a proposal submitted to Osmosis and that kind of set the precedent. And Cosmos, as we talked about, loves leaning into governance, loves leaning into validator set. What can your validator set do for you? And sometimes the biggest superpower and it's also sometimes the biggest weakness, as we've seen with events like Atom 2.0. And so some of these ideas are migrating over to Ethereum. People are seeing a little bit more value in them. And I think that a lot of that's because they have been so unappinionated and scary things have happened. Fortunately, nothing catastrophic yet, but we're getting to the point where some of these projects are so close to the metal that it could be bad.
01:40:16.502 - 01:41:27.396, Speaker A: I agree. I actually think an enormous first of all, just again, we're going to get eventually to this to drive this point home. But so much of the Ethereum roadmap either comes from the Cosmos is directly inspired by them or ends up swinging back to the original sort of thought process and ethos of the Cosmos ecosystem. But an enormous amount of what's going on with these protocols, Lido and Eigen Layer and this debate around Enshrining really comes down to this fundamental debate which has been had for a long time in crypto, which is how should your validator set look? And on the one hand, you kind of have the Ethereum design philosophy and principle of there's actually a great talk at ECC of how to make your validator a cuck, but really it's just making them very commoditized and spread out and sort of dumb. And then there's this Cosmos ethos of what can your validator do for you? And honestly, I think are starting to see Ethereum swing a little bit back towards more towards that Cosmos ethos. Vitalik actually, he spoke a number of times at the conference, but he had a great talk on account abstraction. And the first sort of bullet that he made, I thought was very interesting was we're starting to see a swing back towards Enshrining.
01:41:27.396 - 01:42:15.352, Speaker A: And I think the reason why we're starting to see that is because Ethereum at one point said we don't want to do a lot of this stuff because we don't have to make weird decisions around who those validator sets are. Shared sequencers would be like, we want to outsource things like block production or delegation of stake and things like that. Now that some of those services have understandably found product market fit and they're going to have an enormous amount of say over the ethereum protocol, I think there are starting to be these voices that say, hey, actually maybe we can't. This is simply too critical of a function for this network to leave to an outsourced provider. And maybe we want to enshrine parts of this. So I actually thought it was fascinating to hear Sriram say this is the explicit goal of Eigen Layer to be Enshrined, and a lot of folks were talking about that, frankly, at ECC. So I'd be curious what you think about.
01:42:15.486 - 01:43:45.620, Speaker B: I mean, I think I was not in the room for these original conversations a couple of years ago, but I think my gut sense is that part of the momentum back towards Enshrinement is because of Ethereum's shift towards a more modular roadmap. And when so little is done at the base layer and so much activity is being pushed up to different layers of the stack, I think you end up with a situation where doesn't matter how decentralized your base layer, validator set. Is there's critical functions? Arguably as critical as block. Production happening higher in the stack that are being done by much more centralized, I guess. Systems or entities? Right? And so to me, it feels like maybe now that they've shifted the roadmap a little bit, they're seeing some of these scary things that they didn't really think about originally when there wasn't this idea of a modular stack and Ethereum shifting to being more of just a data availability layer more and more over the years. And now they're saying, okay, if something bad can happen higher in the stack that we've pushed out originally on purpose and that basically undermines everything that we've done really well at the base layer. In having hundreds of thousands of Validators, I think that that could lead them to say maybe we should do more at the base layer because we're putting too much trust in these higher levels of the stack.
01:43:45.620 - 01:43:53.368, Speaker B: So I could be wrong, but I think that this shift in roadmap towards something much more modular is also playing into this.
01:43:53.454 - 01:44:25.968, Speaker A: I think you're right. I think you're right, Miles. And I think it's too early to speculate on whether or not I wish Sriram the best. Frankly, I was really impressed with this discussion and how he treats how sensitively and how deeply he thinks about these issues. I can't speak to whether or not it's realistic for Eigen layer to get enshrined. It is interesting, though, to hear even from the Ethereum Foundation, other ideas that aren't exactly Eigen layer, but are different flavors of Eigen layer are starting to get talked about. That, again, exist on the spectrum of getting your validator to be very dumb versus wanting them to do a lot of things.
01:44:25.968 - 01:45:27.284, Speaker A: Another idea that I would point to, we talked about it very briefly in last season on Mev, but it again came up at this conference is this idea of PEPC. So PEPC is protocol enforced proposer commitments. This comes from Barnabay Manat, who is at the Ethereum Foundation. And it's this sort of framework for again, there's an enshrined component that exists on chain or within the Ethereum protocol rather, that allows proposers to make credible commitments in terms of block production, which if they are not honored ultimately by the proposer, will make the block invalid. So if you really think about what that is in terms of Eigen layer, it's actually a very similar thing, which is, okay, there's the very base state of a proposer gets like a block header and then kind of attests to that and publishes it to the chain. But if they also want to opt into these additional middleware solutions, like running a shared sequencer, for instance, or an oracle or something like that, they'll have the ability to do that if they restake their ETH. PEPC is sort of another flavor of that.
01:45:27.284 - 01:45:41.436, Speaker A: And frankly, I think you're going to start to hear this debate around commitments crop up quite a bit in the coming, let's say six to 18 months. And when you guys hear that word commitment, I want you to think about the spectrum of validators doing very little versus them doing a lot.
01:45:41.538 - 01:45:42.190, Speaker D: Right?
01:45:42.960 - 01:46:39.932, Speaker B: I don't know if Sriram actually mentioned it PEPC by name, but I asked him a question around. Do you see these Eigen layer operators being specialized separate parties than the L One validators? Or do you see the most Eigen layer operators being validators themselves? Right? Because there is this flavor of restaking where you can delegate your stake to a specialized operator and it doesn't have to be an L One validator. But he spoke a little bit about the benefits of why it's sometimes better for it to be the L One validator itself. And you can get into basically all these different coordination mechanisms. And that, I think, is one step before we get to PEPC, which is the validators at the base layer, the actual ones doing additional work on an opt in basis, but it's not yet built into the protocol. And then when I heard PEPC, I think it was Mike neuter's talk.
01:46:39.986 - 01:46:40.300, Speaker A: Right?
01:46:40.370 - 01:47:41.644, Speaker B: And it reminded me a ton of vote extensions in Cosmos, which has already been implemented or is very close, hopefully, which is a lot more manageable because it's only 150 validator, 200 validator set, and it's actually not opt in in Cosmos. So this is things like, along with just deciding coming to consensus on a block, it's also coming to consensus on a median Oracle price or the top of block auction winner. And I think that is very similar to Eigen layer today. But I think about what this could look like in its implementation. And Cosmos will be very opinionated about the jobs that they asked these validators to do. Additional jobs. But Ethereum's general purpose, right? There's no limit to the amount of additional jobs that could be valuable for different protocols at higher levels than the stack.
01:47:41.644 - 01:48:03.812, Speaker B: And so how do you enshrine this but also make it flexible enough to add new jobs, but not force people to do those jobs that don't do them? And how do you also make it agnostic to maybe the restaking or some sort of third party protocol that's facilitating this, even though it's built into the protocol?
01:48:03.876 - 01:48:04.200, Speaker A: Right?
01:48:04.270 - 01:48:29.890, Speaker B: Because if it's enshrined in the protocol, they're not going to say that Eigen layer just fades away, right? It will probably be somewhere eigen layer will be facilitating the user interactions with this or the supply side interactions with this, but you have to make it agnostic to the third parties that could enter this market instead of Eigen layer is a monopoly now for anything restaking. Very interesting.
01:48:30.260 - 01:49:15.624, Speaker A: I agree with you, Miles, and actually, we're talking about this as if it's some binary thing of enshrined versus not enshrined. And even once you decide to enshrine something, there are many different flavors. And what that spec ultimately looks like has an enormous impact on what the functionality is going to be. The Mike Neuter talk that you referenced, actually it was specifically about different specs for EPBs, which is enshrined PBS. And you went through these five different potential specs and flavors of it. And we could probably do a whole other podcast on that but it probably makes sense to move on here to the second part of our discussion, which is the more demand side of Eigen layer. And I eventually want to talk about this intersection in between the intersection between liquid staking and restaking.
01:49:15.624 - 01:50:06.560, Speaker A: So on the demand side, I think we got a bit of a better sense. But again, frankly, this gray area is a lot of what these protocols are going to be figuring out of. All right, if you're a middleware operator and you're sort of opting into using Eigen layer. So connecting to E validators, like, what are some of the decisions that you'll have to make? Again, some of this is being colored by actual conversation that I had at the conference this past week. But I walked away from a lot of those chats because my worry was on the demand side of this marketplace, we know there's going to be plenty of supply side people that want to earn additional yield and opt into running or Validate or whatever some of these additional services. The question is, is there going to be demand side? I actually think there is going to be plenty of demand as well. And one regret that I had of this conversation.
01:50:06.560 - 01:50:50.430, Speaker A: It was already so long, but I wanted to ask about Eigenda and why data availability was one of the first use cases and sort of walked away again from a lot of these conversations with, like, data availability and the load that this is going to put on. The average Ethereum node is going to be very high, which is, I think, the reason data availability eigenda is the original solution that they're kind of shipping here. So I think Eigenda is meant to solve some of the networking load that gets put on Ethereum validators here and we'll open it up and make it more economical for middleware operators to opt into this. And my actual sense is that there's going to be a strong amount of ABS demand for this.
01:50:51.120 - 01:52:18.356, Speaker B: I'm not worried about the amount of ABS demand that there's going to be. I'm more worried about how many Validators are actually going to be able to run additional hardware or maybe just compute profitably. And again, I sound like a broken record here, but a lot of the conversations that I had this past week, we were comparing restaking to say, replicated security in Cosmos. And the problem with replicated security right now is there's no shortage of demand for ICS. Lots of chains love this idea of having $2 billion of security from day one with a huge token holder base and all this liquidity that can be injected. But guess who doesn't actually like this idea anymore? The validators, because they're having to stand up new hardware, and the people that are voting on this have no skin in the game, right? And so when I was talking to a lot of teams that plan on becoming AVSS, I think that was one of my main questions is how do you lighten the load on the Validators, or do you go with a specialized operator to make this economics work on their side? I think the economics will work on the demand side, but if we just can draw a couple of lessons here, we already know what doesn't work, and that's making people stand up, doubling their costs for a fraction of the revenue, right? Yeah, a revenue share. But it's the same cost as running a full node.
01:52:18.356 - 01:52:30.092, Speaker B: Then you're just running a full node for a fraction of the revenue that you get with your l one Validator. And eventually these Validators are going to be sick of it. Right.
01:52:30.226 - 01:52:30.984, Speaker A: Overloaded.
01:52:31.032 - 01:52:47.270, Speaker B: Yeah. How can you make this as thin as possible for what you need to do in terms of the work they're doing while still getting what you want as an Avs? So I agree with you. There's going to be plenty of demand. I just think they need to be thoughtful about the way they do this.
01:52:48.840 - 01:53:06.360, Speaker A: That was actually one of my big I think the solution to that is multiple data availability. You know, Celestia is one, polygon avail is one. Obviously. Eigenda. Did you know? Espresso, actually. So they're a shared sequencer. Do you know they also have their own data availability solution?
01:53:08.220 - 01:53:10.744, Speaker B: No idea. But yeah, it's great.
01:53:10.782 - 01:53:16.140, Speaker A: I think you're going to start to see I think people understand that that's going to be a problem and they're already building towards solutions.
01:53:16.880 - 01:53:17.148, Speaker D: One.
01:53:17.154 - 01:54:29.772, Speaker A: One. Because I want to make sure we get at the intersection between why are we doing this episode on restaking in a liquid staking season outside of the similarities in between Eigen layer as a protocol and Lido, the reason why we're talking about this, the important detail about Eigen layer is that this is an opt in situation. So instead of EIPS being passed that, say, validators on ethereum now have to run an oracle, there is instead an opt in system where Validators, a certain subset of them can opt into running an oracle. Now that works with the current yield that Validators are open to generating. The reason where liquid staking and restaking combine, I think, is that the existence of protocols like Lido that offer liquid staking will drastically increase the ethereum stake rate, which is still relatively low compared to other proof of stake protocols. As the stake rate goes up, the staking yield that Validators earn goes down. So you could imagine a scenario where in the relatively near future, liquid staking doesn't earn you very much yield as the stake rate for ethereum creeps up.
01:54:29.772 - 01:54:54.920, Speaker A: I'm not smart enough to know what it's going to be, but it's much higher than it is now. And then there might be a situation where in order to profitably Validate, you also have to opt into some of these restaking services. So it's technically not an opt out situation, but to make it make economic sense. A lot of the validating base is going to have to start doing opting into some of these additional commitments. I think that's a challenge.
01:54:55.260 - 01:56:10.180, Speaker B: Right, and so where do we strike that right balance? I think between a stake rate where people are running validators profitably without having to restake right. And then if they do have to restake, at what point, how much revenue do they need to be earning from that in order to offset the additional cost they're taking on? And yeah, I think the other kind of intersection here is where we talk about whether it's the curated Lido set or the permissionless lido set or rocket pool set. All of these folks are going to, there's going to be a huge overlap obviously between the middleware operators and the validators. And so I think Eigen Layer looks at Lido and says if they wanted to build a competitor, they could because they have the relationships here already. They have all the capital from the stakers already, the delegated capital. And they could say they could just add a module right where they're all restaking. Or they could create just a fork of Iken layer and let it be more of an opt in basis for the stakers rather than dragging up the weighted average yield of the base LST.
01:56:10.180 - 01:56:50.240, Speaker B: And I just also think from our conversations with some Lido folks that's maybe a little bit less realistic for Lido specifically. But I could absolutely see some of the more, I guess, lower market share competitors doing that as a way to capture more market share and attract more stake because they can say hey, look at our APY as 1012 percent where the base rate for native staking is 4% and Lido is only 5% or 6%. Say. Right, so you could see some of the more aggressive upstarts start doing this as a way to attract capital through yield.
01:56:51.540 - 01:57:43.824, Speaker A: Yeah, I agree with that. And one thing I'm already thinking a little bit differently about, but frankly I can't really tell where I come out on it yet is I thought it was eventually going to be a big deal. Eigen layer and LiDAR are today very complementary. You could see them being competitive and the framework that I had for this was maybe you want to be closer to the consumer, right? In terms of if you're eigen layer you should be worried that Lido is very close to the consumer. People are going to liquid stake most likely before they restake, I think, and then a Lido could create their own competitor like you just mentioned. But it seems like what eigenlair's strategy or solution to that is instead of trying to compete directly, they're going to the very bottom of the value chain directly into the ethereum protocol itself and getting itself mean.
01:57:43.862 - 01:57:44.976, Speaker D: You could also look at it from.
01:57:44.998 - 01:58:22.592, Speaker B: The fact of know this is just another utility for a steth holder or for an ETH holder, right. In the same way that you go into the liquid staking protocol to stake originally, and then you can go to Ave or you can go to Curve right now, you can go to restake. And I think that they could just look at it like that and maybe be a little bit more hands off, if that makes sense. But, yeah, it's definitely different. But you just haven't seen Lido say, okay, we own the user relationship, so we should make an AMM, we should make a lending protocol. Fracs might have a different opinion. Right.
01:58:22.592 - 01:58:50.008, Speaker B: Obviously they're coming out from the opposite angle, but I view it more as it's kind of a horizontal expansion a little bit, or maybe it's vertical for restaking. But yeah, I just don't necessarily think it's so likely in the near term that the liquid staking protocols will be building competitors, or at least the dominant ones. But I could be wrong. We'll see.
01:58:50.094 - 01:59:41.816, Speaker A: Yeah, who knows? The big question is ultimately going to be especially if let's just imagine, Miles. There's a future state where a large percentage of ethereum validators are opting into receiving rewards from these other chains to the point where it's extremely normalized. And that's actually thought as part of the native yield of ethereum. Especially if Eigen layer ends up getting enshrined in that sort of world. How many more folks are comfortable with Steeth being a claim on a pool of mostly ETH plus a couple of L2s versus today? And I think that is the big question to ask yourself. And again, I just have to come back to this idea that we're speaking from this bear market where everyone's making aggressive amounts of sense and being far too reasonable, and we know that that's not how it really works over a period of time. Right? I mean, can't you imagine these sort of VC thought pieces where, oh, there's precedent for this.
01:59:41.816 - 02:00:08.112, Speaker A: It could be bond ETFs or it could be mutual funds where you hold and then Lido gets branded as more of an index than a one to one pegged asset and hey, that was what it really was supposed to be all the time anyway. You know what I mean? I just think it's at this current moment, it's hard to imagine Lido doing that. But I think in a world where an enormous percentage of the ETH validator set is also opting into these additional rewards, you could very easily make the argument that that's what Steve should be representing anyway.
02:00:08.246 - 02:00:44.732, Speaker B: Yeah, I think that's it could happen. It absolutely could happen. I don't know what that would look like. Maybe it's marketed as, hey, we're going to put buy pressure on ethereum because all these tokens that come in from L two S or from Cosmos chains are going to get converted back to steth and then we'll give it to you as a reward. But I think we didn't touch on this. But from the demand side, there is a worry there, right, where if you're paying out your native token as a reward to Ethereum stakers, they're probably going to dump it back more ETH. Right.
02:00:44.732 - 02:01:32.372, Speaker B: So that's kind of a trade off that we didn't talk about a lot on the demand side, but that's kind of maybe the only thing that's kind of going against them on that side. Yeah. And then I think there's going to be additional third party players that pop up to then re unlock this restaked capital. Right. Like Ion Protocol is a fascinating project that is basically a credit risk underwriting framework for restaked tokens based off of the validators that are operating that stake. And that will help you lend against your restaked positions based off of your individual risk profile. And so, yeah, I think there will be a big market that pops up on top of this and then eventual consolidation, potentially between these players.
02:01:32.436 - 02:01:47.820, Speaker A: All right, Miles, it's been a really fun one. And guys, I know these are long, but man, these has just been packed with information here. All right, partner, this has been a really fun one. See if back here next weekend.

00:00:00.200 - 00:00:19.318, Speaker A: Any arbitrary execution environment can be made to run on roll ups. And essentially what these roll ups are hungry for, right? Like on the base layer. Like what do they depend right now they almost all implemented on Ethereum, but what are they most hungry for is.
00:00:19.334 - 00:00:30.446, Speaker B: Data availability and avail is really coming in and really scaling that core data availability piece while allowing the flexibility for different L2s built on top of it.
00:00:30.518 - 00:00:42.830, Speaker A: Around 70% to 90% of roll up. The roll up cost today is on, you know, like primarily on exploring transaction data on Ethereum.
00:00:44.450 - 00:01:30.238, Speaker B: Well, Anjurag, thank you so much for joining me. Really appreciate your time today. Looking forward to the conversation and really what you're building at avail. I think the conversation has really centered, I mean predominantly, I would say this year around really the traction that L2s are ultimately getting, especially with the announcement of base. There's a lot of exciting news in the air and I think what you're building out of AEL ultimately helps accelerate that adoption. So really looking forward to diving deeper and one to the technology stack, but two, kind of how you're viewing the entity industry as a whole as well. There's also lots of various debates around integrated versus modular change which we can get into.
00:01:30.238 - 00:01:35.486, Speaker B: But again, super excited for you to be joining me on the podcast and looking forward to the conversation.
00:01:35.598 - 00:01:39.350, Speaker A: Yeah, thanks for having me and looking forward to the discussion.
00:01:39.470 - 00:02:18.640, Speaker B: Awesome. Well, maybe just I think in general probably people are relatively aware of avail and what you're ultimately building there. But I would like to maybe start out the conversation by diving a little bit deeper into the core problem that I feel like you are addressing, which is creating that unified data availability layer and really the role of data availability layers within blockchains. I think it would be a great foundation point for us and also the audience to really establish the role of data availability layers and the, what they play in blockchains and then we can build from there.
00:02:19.020 - 00:02:57.130, Speaker A: Yeah, no, I think that's a good start in general, to give some context. Right, like you mentioned base. But in general, the last two, three years we've seen the rise of roll ups in general. Right. Like, so if you look at an arbitrum optimism, this year's, you know, like ZK Polygon, ZKVM ZK Singh for example, stockware has been building roll up for quite some time. And then there is a lot of new teams that are building, you know, like non EVM robots as well. Right? Like, I mean, and both in the optimistic and validity proof category.
00:02:57.130 - 00:04:06.810, Speaker A: Right? Like, so some of these, like I mentioned a little bit for, you know, like Stacker is building a very specific kind of a stack, fluent, just, you know, like the new startup that just announced, for example, which is building a ZK wasm kind of environment. There are other startups like blockless, which is again offering a wasm kind of environment, risk zero, you know, like is building up like a RISC five kind of a ZKVM and brewer, for example. And so, I mean, what is really happening is that over the last two to three years, especially on Ethereum land, what is happening is this whole rise of roll ups, right? Like, and you see, you know, like arbitrum pretty big in terms of TVL and optimism, also not that far behind. And a lot of the newer roll ups also catching up. GK Singh, for example, GKVM also taking significant strides, for example. And so in general, what has been happening is this rise of roll ups. And so, you know, like when we, when I founded Matic or Polygon back in 2017, we were working on this.
00:04:06.810 - 00:04:48.084, Speaker A: We started off as a plasma solution on top of Ethereum, right? Like, and if you look at plasma, right, like it's an off chain execution and off chain data availability kind of solution. Of course, we never got to implementing plasma because it was unworkable. But I then finally we pivoted to rollups in general. So, I mean, rollups is a very particularly clever way of putting execution off chain. And so you can see that already happening on Ethereum roll ups. And it doesn't necessarily need to be EVM roll ups. It can be any environment.
00:04:48.084 - 00:05:32.248, Speaker A: It could be even the Solana virtual machine, for example. Or you know, like any, any arbitrary execution environment can be made to run on roll ups. And essentially what these roll ups are hungry for, right? Like on the Beijing, like what do they define? Like right now, they almost all implemented on Ethereum. But what are they most hungry for is data availability. And for now, these roll ups rely on Ethereum for data availability. And Ethereum never started off focusing on data availability. It was one of the first things, it was the first chain for general purpose computing.
00:05:32.248 - 00:06:46.120, Speaker A: And so in general, of course, it's become so big now, it's very difficult to change it pretty quickly. So it's taking its own sweet time, which should to kind of upgrade itself to a databuty layer. So you must have heard of proto dank sharding and dank sharding. And so those are all upgrades to data availability, right? Like how, how can we provide more scalable data availability on the base layer on Ethereum, for example, so that there can be more roll ups that can consume this, like with more da and less da cost, right? Like just for context, around 70% to 90% of roll up. The roll up cost today is on, you know, like primarily on storing transaction data on Ethereum, right? Like that is significant cost, of course, you know, like they're working on prototype charting, which should hopefully come up this year or maybe early next year, which will reduce cost by factor of like one by five, one by ten, it'll depend I. And so that will improve things. But essentially, you know, like they will have to implement bank sharding, which is take a few years.
00:06:46.120 - 00:07:32.180, Speaker A: But essentially what, what I want to kind of wrap this discussion in this is that roll ups are, you know, like particularly clever way of putting execution off chain right now. You know, like they depend on Ethereum for ta, for example. I mean, it's not necessarily that roll ups run, can run only on Ethereum. They can be run on any chain as such. That's why I give a talk at modular summit in Paris some few weeks apart, and I put out this slide saying every Bayes layer blockchain is going to be a d layer. So base layers is where DA will be optimized for and exhibition will be optimized for in the roll ups.
00:07:32.750 - 00:08:20.190, Speaker B: So that's, so maybe let me like break it apart a little bit or kind of re articulate kind of your core thoughts, and please correct me if I get anything wrong. Ultimately, in blockchains, there's two main components that go into scaling. One is the data availability layer and then the second one is compute. And that compute today can kind of either happen on the base chain that's kind of integrated with the data availability layer, or it can be separated and pushed to a L2 for an execution environment. And that lives out there. But the more that you kind of scale execution, the more hungry ultimately, or the more data that you actually need at the base layer to scale. So if you scale one, you also only kind of have to scale the other.
00:08:20.190 - 00:08:53.378, Speaker B: And what avail is ultimately doing? And kind of the modular roadmap is separating the compute from the data availability bandwidth and scaling. Ethereum's kind of taken a, I'd say, conservative path for data availability, just as it was the first blockchain. And as the roadmap has kind of evolved, so has ethereum. And avail is really coming in and really scaling that core data availability piece while allowing the flexibility for different L2s built on top of it.
00:08:53.474 - 00:10:02.100, Speaker A: Absolutely, absolutely. I agree. I mean, in general, I mean, I just, you know, like a response to, I think, one question you didn't ask directly, but let me answer that is, that is basically you can scale DA on any chain, right? Like, I mean, any, any business, you know, like da. What is it? Availability, right? Like, I mean, it's basically you have a set of transactions. You have to like order it in some manner and you have to keep it available so that, you know, like, I, it can be verified, you know, the execution can be verified against it. Right? Now you can do it on any post chain, right? Like any posture. It can happen on Ethereum, it can happen on Solana, you know, like, it can happen on any chain, right? Like, but essentially what we are doing at avail is basically a very different way of verifying it efficiently, right? We implement something called data availability sampling, which is this unique way for very resource constrained light ranks to verify the data availability component quickly and scalably.
00:10:02.100 - 00:11:12.150, Speaker A: You can do it on Ethereum today. You have to run a full node for that. You have to download all the blocks and do it in Solana today, you have to download all the blocks. And what the main difference is if you want this, like block sizes that keep da, like two big numbers, right? Like, I mean, it's basically a block size scaling debit, right? Which is very different from the execution plus ba, block size scaling debit like you in BA, because we specialize on that, right? Like we are able to scale block sizes pretty much, you know, like to a very large amount while still keeping the verifiability intact, right? Like, I mean, we have, we're starting off with the block time of like 20 seconds and light lines. We benchmark like sizes of 128 mb for the block size and light lines still are able to verify well within the bounds, right? Like, I mean, and we are able to scale more, right? Like that is very difficult to do in a chain that is, that has both execution and da. Of course, you know, like the trade, see, everything is a trade off, right? Like, I mean, I will not say.
00:11:12.990 - 00:12:53.616, Speaker B: Yeah, and to your point, I think data availability sampling is really novel and as you mentioned, by allowing less resource compute and also ultimately bandwidth as well, to verify the chains in kind of a, being able to verify the chain by having less resources, by having less bandwidth and getting almost similar assumptions and trusts to full nodes without actually having to run like a beefier full node and larger hardware is extremely novel. I'm very curious over the long term. I know Celestia was kind of one of the pioneers in this regard and more blockchains are kind of taking this data availability sampling approach because to your point, I think over the long term, it's going to be very hard to actually fight the physics of, like, you have to increase the bandwidth, you have to decrease the compute. And if that is true, you have to figure out ultimately how to keep the verifiability, the property that we really love and enjoy about blockchains to small resources. And that data availability sampling is a true unlock, I think, within the industry that allows us to do that. And it's amazing to hear that the avail team is also working on data availability sampling. One thing that you mentioned, though, is kind of around, I would say, the larger conversation of, like, integrated versus modular chains and the fact that your belief that all chains will really need kind of L2s down the line.
00:12:53.616 - 00:13:01.500, Speaker B: Can you maybe expand upon that? Because I think this is like a fierce debate that's kind of happening on Twitter and within our communities at the moment.
00:13:02.440 - 00:14:19.334, Speaker A: Yeah, I mean, so there, as I said, it's always, there are two sides to this debate and there are always trade offs. But I'll just come up with my viewpoint, essentially some of the discourse that I've seen on Twitter and on, you know, like, in general, right? Like, there's this notion that modular systems are not, like, are not integrated, you know, like, in general. So monolithic chain, for example. I mean, it's all tightly coupled, everything even. I mean, so the definition or the usage of the term modeler is, you know, like, taken a little bit of the, you know, like, liberty in some discussions. Like, I mean, so being modeler does not really always mean not integrated, right? Like, I mean, so, for example, I'll give an example, right? Like, so, like someone, a user who's running like a roll up or using a roll up on Ethereum, let's say arbitram, for example, or some other roll up, right? Like they don't really care about, you know, like the, how many modules are in this roll up that is working, right. Like, I mean, most users don't even care whether, you know, like this roll up turtles to Ethereum, for example.
00:14:19.334 - 00:15:47.020, Speaker A: You know, like, I mean, some roll ups don't even have working fraud proofs in production, for example. You know, like, so in general, so the experience of a user, right, like on, let's say, arbitrum or polygon, ZKVM is not very different from, let's say, a user on Ethereum. Ethereum or Solana, for example, right? I'm talking about the base execution layer right? Like, I mean, the way they send the transactions is, you know, like, let's say is almost the same. There might be on ramps, off ramps, you know, exchange connections, for example. I mean, there is a bridge from a roll up to Ethereum, but you know, like the bridge to Ethereum is, you know, like just like a bridge to another blockchain, right? Like, of course under the hood it is trust minimized and you know, all that, right? Like, but every blockchain, you know, like has that experience. So I mean, I think it's a little bit, you know, like intellectually not that honest to say that modular systems are not integrated in that sense or provide like a, you know, like incorrent user experience. In general, what modularity does is it basically focuses on component specialization, right? Like, now, once these mature enough, right? Like, I mean, we are still very much in the series of modularity in blockchain, right? Like, I mean, that data already sampling layers are just, just now getting into production.
00:15:47.020 - 00:16:30.370, Speaker A: For example, roll up technology is also just about getting, like, it's not, I mean, we have like an optimistic roll ups running for two, three years. But GK roll ups are pretty new, you know, like, and so. And all of these newer rollouts will take some time, right? So, and there's a lot of abstraction and middleware yet to be built in. Modular ecosystem. Right? Like, so it's not the right lens to directly compare what a monolithic blockchain can do with the state of the modular ecosystem today. Right? Like, I mean, it'll change in the next 612, 18 months in general. But I mean, yeah, hopefully that provides some context.
00:16:30.710 - 00:17:16.306, Speaker B: 100%. And I think honestly, a lot of the confusion ultimately lies in my belief around modular versus the integrated stack, and that one is more inherently scalable than the other. I think both of them, if given the same kind of data availability layer, whether it's integrated on the base layer or kind of separated via a L2, and have the same compute and the same data availability, ultimately they have the same scalability properties. And I think the fact people sometimes confuse that, oh, one ecosystem is inherently more scalable than the other, and that leads to a lot of confusion on the timeline.
00:17:16.458 - 00:18:06.426, Speaker A: Yeah, I mean, of course. So when I see some debates, right, see, debates are good. I mean, they help further the industry forward. But essentially, you know, like, the points of debate should also be pretty clear, right? Like, I mean, I think one, like, let's say, let's have this, let's say this critique that, you know, like, there's a lot of new infrastructure that app developments have to, app developers have to maintain. You know, when they do, let's say, app change on modular infra, right? Like, I mean, I mean, that's right. That's at the moment, right? Like, it's currently, you know, like, let's say it's a basic example, right? Like, the op stack is open source and, you know, like, base or Coinbase took the op stack and, you know, like, spun up a new roll up. And now they have to kind of maintain that.
00:18:06.426 - 00:18:58.452, Speaker A: All that, for example, for now. But but, you know, like, as we move six months, twelve months, you know, like, we already seen, like, roll up the service providers gaining prominence, for example. And there's a lot of abstraction that happens. See, the beauty of a roll up, especially, like, optimistic roll up, is it massively lowers the cost of spinning up a chain, right. In the sense that there is no validator bootstrapping to be done. In most cases, if it's, let's say, like, a volatility or ZK proven roll up, all you really need is one sequencer and one prover, right? Like, and even those that prover can be shared amongst multiple roll ups, right? Like, I mean, I'm not saying that you should totally run only single sequences roll ups. Of course, there it will be.
00:18:58.452 - 00:20:04.354, Speaker A: There will be some decentralization. I'm just saying that if you want to do a monolithic chain today, right, look at the cosmos ecosystem, right? Like, I mean, it takes immense effort to kind of, you know, like, bootstrap this validator set of hundred, for example, you have to set up a token. You have to enter the value. You know, there's a lot of validator bootstrapping cost, which has to be paid by someone. Nothing comes for free, right? Like, I mean, so, basically, the role of construction changes that dynamic in the sense that, you know, like, it borrows of the security of the base layer and you. The cost of spinning up that, uh, chain or roll up, that is pretty, uh, low. And that leads to potential, you know, like, a lot of potential for experimentation, right? Like, I mean, if you have, like, a monolithic, uh, l one, right? Like, I mean, let's say, let's see ethereum, for example, right? Like, it's very hard to make any changes to to ethereum, right? Like, I mean, let's say, you know, like, there's this, uh, op stack, I think, for.
00:20:04.354 - 00:21:01.428, Speaker A: Called op cliff, for example, which added a few pre compiles because, you know, like, I I mean, there are some other change that I didn't move you know, like some custom functionality, for example. I mean, so essentially what I'm trying to say is the base layer necessarily has to be, you know, like, it can't be changing all the time, right? Like, I mean, it needs to have some sort of classification over time. And so this, the role of construct is primarily this whole framework by which, you know, we can add arbitrary new experimentation things, right? Like, I mean, arbitrary vms, arbitrary authentication or access mechanisms or, you know, state models, whatever experimenting you want to do. If you want to do with a custom l one chain that's very. You can do it. It's just too expensive here, you know, like, it just doesn't cost much.
00:21:01.564 - 00:22:15.910, Speaker B: And that's, again, specifically because you have to spin up your own data availability layer within the cosmos or kind of like subnet ecosystem, and that is not shared. And it allows you to experiment with, as you mentioned, the different virtual machines kind of customize that stack and play around with kind of different compute, which I do think is interesting as well. I'm kind of partial to parallelization. I think it's going to definitely help kind of some of the scalability fronts, but perhaps a different conversation now. And I do think in general, the modular kind of versus integrated stack is still a little misunderstood, and that having these conversations definitely help kind of progress the industry and push it forward. They definitely play out on the timeline and it's a little bit hard to kind of parse apart theme. So I appreciate the long form content where we can go through them, but particularly maybe jumping back to what is kind of happening in the Ethereum land, particularly around base.
00:22:15.910 - 00:23:23.728, Speaker B: Ethereum today as a data availability layer is really not doing that much data, and that's partly by design, but also kind of limits some of the scalability fronts. As you mentioned early in the podcast, I believe it was like 80% to 90%. Ethereum's or of L2's costs is settling to Ethereum because it has little limited amount of data availability. Once EIP 4844 introduce and kind of doubles or triples the amount of bandwidth, approximately, that Ethereum will have. But I think over the long term, you'll still need to scale. You'll have dank sharding and then other ecosystems such as yourself and what you're building at avail that will really kind of maximize the throughput that you have at the base layer. Can you kind of talk about in the long term? Where do you kind of see the role of these data availability layers? Is it to kind of maximize the amount of throughput at the base layer is maybe 100 megabytes enough.
00:23:23.728 - 00:23:29.120, Speaker B: Do you need 1gb/second is it 10gb? 100? Like, where do you see it going? Term?
00:23:29.500 - 00:24:02.160, Speaker A: Yeah, I mean, so basically, of course, the function of the base DLA itself is to maximize da. I mean, the actual throughput will depend upon, you know, like how many, how much block space demand is there. Right. Like, I mean, and that all depends on, you know, like what kind of apps really get built and what kind of bandwidth is really required. Right. Like, but essentially the architecture that, you know, like we are optimizing for it a while, that kind of, you know, allows for, you know, like expansion of that. Right, like that DA throughput.
00:24:02.200 - 00:24:50.712, Speaker B: Right. Like in general, like it mirrors. Sorry to jump in. Do you think it mirrors the early days of the Internet? I often find this analogy a little bit overused, but I find it helpful and so I kind of always revert back to it. Where you had kind of 56k modems, you had a limited application set that you could ultimately build upon. Then broadband came, it unlocked a bigger sandbox for engineers, and then you gain got to fiber optics and then all of a sudden you could stream 4k gaming on someone else's computer in real time with very low latency. So in that kind of analogy, do you see blockchains playing similar in regards to their progress, where today kind of Ethereum's bandwidth and data availability is relatively limited, it will kind of expand to like broadband with full dank charting.
00:24:50.712 - 00:25:06.924, Speaker B: But then there will be other solutions such as Polygon, avail or avail apologies that will have really kind of that fiber optics connection where you're targeting hundreds of megabytes, gigabytes in the future that ultimately expand what engineers can build.
00:25:07.092 - 00:25:22.362, Speaker A: Well, absolutely. I mean, see, basically every kind of major computing evolution starts out like that. As you rightly said, we started with like 56 kb lines, you know, like on top of the telephone network for example and so on.
00:25:22.386 - 00:25:22.522, Speaker B: Right?
00:25:22.546 - 00:26:43.860, Speaker A: Like, I mean in general, you know, I like to use example in terms of mobile app evolution. Right? Like, I mean, so when the first mobile OS is where made really when the first one of phones came, right. Like, I mean, it was too early to envision some of these apps, like, I mean, let's say something like an Instagram or, you know, like something like an Uber for example, right? Like wasn't built in the first 1st few years, right. It took a lot of time for people to kind of, you know, like put that intuition together in the sense that, okay, I have now I have a camera that can go anywhere you know, like, why don't we use it to, you know, like, click photos, for example, and post it to our social circle, for example? Or we have now a gps, you know, like, on our, you know, device that we can carry on our phone. Why can't we apply to the problem of finding a cab, you know, like, so, I mean, I remember the first app that I made on one of the early mobile long back was, you know, like, was this, you know, like, can I take this paper form that I fill and you put it on the mobile so that, you know, like, so I don't have to fill paper forms. And then, you know, input into the desktop, for example. I mean, initially, you know, like, the kind of apps that get built are limited by the kind of infra that is available.
00:26:43.860 - 00:27:53.818, Speaker A: Right? Like, and as you go forward, right? Like, I mean, in India, for example, right? Like, for a long time, yeah. You know, Internet bandwidth wasn't that available to a lot of people. But there, this game, this player called Jio, you know, like, who kind of started giving data almost for free. Like, I mean, like a few dollars per month, for example, right? Like, and till that time, Indians, you know, India is a big country and they didn't have, you know, like, they used to spend their, you know, like, data bandwidth very judiciously. Right? Like on the only, like this took put cellular data off, for example, not to waste bandwidth and so on. Right? Like, I mean, but once Jio came in and gave this, you know, like, data almost for free, the you, the YouTube, you know, like, usage, you know, just grew exponentially over time. In general, the video and, you know, like, now it has come to a part where there is this whole content creation industry that has sprung and, you know, like, there's a lot of domestic consumption, for example and so on.
00:27:53.818 - 00:28:43.136, Speaker A: Right? Like, I mean, I. In general, what I'm trying to say is that, of course apps are influenced by infra. So with the kind of infra that early on is there, you will see apps that will fit to that infra. If we kind of expand that infra, we don't like that. The kind of apps that change and it brings. An interesting point is that's why I also been mentioning about experimentation with different execution environments, but also with how to access the blockchain. Like today, for example, you have these standard ways that has somehow become standard, but there is no reason why you cannot have roll ups doing very arbitrary access mechanisms.
00:28:43.136 - 00:30:05.168, Speaker A: You could have some roll ups doing a very gated API access token kind of an approach, for example, I mean, there's nothing to stop it doing it, right? Like, I mean, state models, for example, you don't have to conform to the EVM state model or the Solana state model, right? I mean, it can be arbitrary, right? Like, I mean, in normal web or mobile application development, what most developers start with, right? Like, is they write the data model first. Like, they will define the schema, database schema first, and then like, go and write the business logic, right? Like in current blockchain implementations, you know, like, what, what happens is there is a, there is a global state model that everyone has to adhere to. People have to tailor their data model to the global state model and then figure out ways and means to write and read and write to it, right? Like, and that's why you see all this complex. You know, I've written, you know, like at least couple of indexers, EVM indexes, you know, like, which are very painful, you know, kind of to write and maintain. For example, you have to run complicated, you know, like transaction, you know, like relay infra. You have to do, you know, like RPC, you have hosted RPC notes because no one can run a full node on their infra. So, I mean, see, everything is well and good, you know, like when we discuss about monolithic blockchains.
00:30:05.168 - 00:30:37.370, Speaker A: But you cannot deny the fact that application developers have to manage a lot of infrastructure, you know, like managing this global shared state model, right? Like, and it's not a very thing to do. I mean, and unless we move the needle or, you know, like reduce the friction for application developers by coming up with infra, that, you know, kind of helps them to do more experimentation faster, cheaper, we are going to end up with the same old apps being developed.
00:30:37.450 - 00:31:59.012, Speaker B: Yeah, I think, I mean, to your point, having kind of a preordained data model kind of inscribed into an execution environment definitely forces engineers to, is rather opinionated in kind of prescribing to engineers a type of way to build. I think there are some pros to that, just making kind of the social coordination between developers rather easy because you have a single unified interface of one data standard and everybody kind of complies to it versus kind of the modular approach where ultimately you do get much more flexibility. But with that flexibility can also come kind of the social coordination of trying to go from one data model to another and kind of comparing and contrasting some of the opinionated pieces with kind of prescribing the data model versus maybe a less unopinionated with different execution environments. But at that kind of comes the social coordination piece. So it is interesting. It's not necessarily a correct way. It's, again, just like how you kind of go and evaluate those different trade offs.
00:31:59.116 - 00:32:10.812, Speaker A: Yeah. No, so even if you look at the web, right, like, I mean, there are standards that, you know, like, apply to everyone, right? Like, let's say, you know, like the HTTP SSL standard or, you know, like, things like that.
00:32:10.836 - 00:32:10.972, Speaker B: Right?
00:32:10.996 - 00:32:24.244, Speaker A: Like, I mean, there's a, there's a standard way to do it, right? Like, but you know, like things like, you know, cross app messaging. Right? Like, I mean, rest, for example, right? Like web apps, mobile apps use rest.
00:32:24.292 - 00:32:24.476, Speaker B: Right?
00:32:24.508 - 00:32:35.926, Speaker A: Like, I mean, now, if you were to prescribe, like, a standard format for every app on the Internet to interact with other apps, it's going to be unnecessarily restrictive, for example.
00:32:35.958 - 00:32:36.102, Speaker B: Right?
00:32:36.126 - 00:32:41.102, Speaker A: Like, and that's why. So it's useful to see the evolution of, you know, like, how the web has developed.
00:32:41.126 - 00:32:41.238, Speaker B: Right?
00:32:41.254 - 00:33:27.512, Speaker A: Like, there are standards, you know, like, which most apps have to adhere to for some areas, but other areas where, you know, there's a lot more flexibility into how you define those interfaces. And I see the same thing happening here as well. I mean, now, the thing is, again, like, how restrictive do you make the standard interfaces? Right. Like, I mean, and what level do they need to be done? Right. Like, do they need to be done at the level of the state model that you need to do? You know, like, I don't, you know, like agree with that, for example. So in general, what I'm trying to say is there will be, it's not like modular is, you know, like Wild west, like, you know, everything. There's no standardization at all.
00:33:27.512 - 00:33:42.632, Speaker A: Right? Like, there will be standardization going forward, but there is enough room for flexibility that, you know, you can actually do the things that you need to do that I think that's, that's, that's roughly my thought on that.
00:33:42.776 - 00:34:23.396, Speaker B: So the standard is the true standardization, at least today, is the agreed upon data availability layer I, which kind of unifies the different execution environments on top. And then it's kind of your belief that over time, even though you may have different execution environments, different L2s, those will have standards across them that will allow them to communicate even though they are not necessarily equivalent or because they have that additional flexibility. Uh, they may not map one to one kind of the commution communication standards today, but over time they will.
00:34:23.548 - 00:35:27.580, Speaker A: Yeah. And actually, one thing we are missing also from this whole debate is also the rise of, you know, like, especially on the Zk or validity proven side recursive ZK proof. So recursive validity proofs, right? Like, and, you know, you know, we are working with a variety of teams not only on EVM ZKVM, but also on non EVM vms. Yeah, like Ris zero, for example, and others. And all, all of these great ZK teams are basically, you know, like they have recursion built into their proving system. Now, why am I mentioning this? Is because at some point in time, right? Like, I mean, of course these proving systems are able to do proof aggregation with proofs of the same proving system. And so, you know, like, what that practically means is if you have roll ups, you know, like, let's say ten different or 100 different roll ups working on risk zero, you are, you will be at some point in time be able to aggregate proofs from these roll ups.
00:35:27.580 - 00:36:16.766, Speaker A: And so essentially rolled up into this. And so you, you can have trust minimize messaging between these, right? Like, and so there's some sort of standard that will need to be applied. Now, I'm referring to, let's say, proofs from one proving system. But my hope is that in the next year or two, you will see the first instances of proof aggregation across two proving systems. Some of these, I mean, maybe it will be like the ones that are, you know, like similar in implementation. For example, you know, like, I've already seen code from like the maiden VM proof being verified under Cairo VM, for example. So things like that.
00:36:16.766 - 00:36:52.498, Speaker A: Right, like now, when that happens, right, like, you will, you will see some sort of, you know, like some standards emerging from that because the trust parameter itself is being solved. Because, I mean, of course we assume that all these EKVM systems have been audited and, you know, like run properly. But if that is, if that were reconsidered too, and if you're able to compose proofs, then, you know, like, that allows for a very rich variety of messaging. And then, you know, like, standards can be pretty quickly coordinated.
00:36:52.594 - 00:37:24.796, Speaker B: And so just to confirm, when you're kind of talking about the aggregations of different proofs, are you kind of talking about like a shared sequencer or that people will ultimately, excuse me, settle multiple different roll ups to a kind of individual or shared sequencer that allows kind of that aggregation of numerous different roll ups and then posting it, kind of doing the recursive proof and then that can be proved to somewhere else.
00:37:24.878 - 00:38:45.914, Speaker A: Yeah, I mean, you don't really need a shared sequencer to do that, essentially. See, that's, that's one of the benefits of you know, like roll up on, let's say something like, I mean, on avail or any other shared DLA, right? Like, I mean, the roll up data is already being posted to avail or the base layer, for example, right? Like, and so you have all the roll up data already being there, right? Like, and so now when you combine this DA, shared Da with, you know, like aggregated proofs from all these roll ups, right? Like, so what this shared DA gives you is access to availability of all the transactions, ordered set of transactions. And the proof really gives you the, like very verified, like, execution correctness. And so essentially, you know, like this construction, now you could have like a shared sequencer kind of a construction, but I mean, you can you do it without that as well? In fact, at a whale, we are building this middleware called Nexus on top of a whale, which, which, you know, like will provide proof aggregation as a service as well. And so that's why we are, you know, like working with a lot of these newer GK vms for that.
00:38:46.042 - 00:39:42.614, Speaker B: Interesting. And so maybe for the listeners just who are following along, we're kind of talking about the different execution environments when you separate in the modular stack. So you have the data availability layer, which avail is ultimately working on, trying to maximize the data availability bandwidth at avail specifically, which allows various types of roll ups, possibly hundreds or thousands in the future, those will create proofs and settle that to the data availability layer. And that is kind of, you can either have the kind of limitation being on the compute side or the bandwidth side, but both ultimately have to be scaled to increase the overall throughput of the ecosystem. Once it is on avail, then you kind of have the ability to aggregate these shared proofs because the data availability layer is the thing that's unifying all the different L2s, correct?
00:39:42.712 - 00:39:44.602, Speaker A: Yes, yes, you can say so.
00:39:44.706 - 00:40:22.504, Speaker B: Interesting. So in this world, I mean, maybe getting back to avail and what you're doing, you've stated that today, approximately blocks are every 20 seconds, you're doing two megabyte blocks. You've tested blocks up to 128 megabytes. Kind of, with that analogy of going from dial up broadband to fiber optics, do you kind of see a world where you will ever need to stop increasing kind of block size? Uh, or do you think kind of human demand is insatiable? Will humans always want more? Uh, always want it faster? Or at some point will it be good enough?
00:40:22.592 - 00:41:02.088, Speaker A: Yeah, I mean, uh, of course. I mean, uh, I would like to say that, you know, like we would have be happy to, you know, kind of scale this. The laws, laws of physics hold us back, right? Like, but we also have to come be practical in the sense that, I mean, the kind of apps or the bandwidth that is there, right, like that, that also needs to change a lot. So it's not only about increasing Da bandwidth, it's also about essentially helping build infra. And this is, this is why, this is why I refer to, you know, like, both Da and, you know, like these ZK vms. I mean, I have nothing against optimistic systems. They are also pretty good.
00:41:02.088 - 00:41:55.386, Speaker A: But the ZK validity proof system driven execution environments unlock a whole new, you know, like, developer developer experience or. And essentially. So I think one of the first goals is, you know, like, quickly finishes infra so that, you know, like, we can have more developers build more apps. So, I mean, I was talking to someone yesterday, and, you know, like, we're talking about these roll ups on top of chains. So I mentioned that, you know, like, right now, these seem like chains at some point in time, right? Like, these. These will be viewed as apps, right? Like, I mean, essentially, you know, like, you have some, you know, like, let's say this company called Stacker, for example, which is building a specific roll up, right? Like, which has. Doesn't even have a Vm.
00:41:55.386 - 00:42:52.248, Speaker A: It has the state transition function encoded in its execution, right? Like, I mean, that's what it runs, right? Like in general. And. And you can define the state model. And what I'm particularly bullish on is these more lightweight app chains with very custom state transition functions or very light vms, basically. And with custom state models. And essentially the end goal for that is to create the infra in such a way that the app chain orchestration itself is all abstracted away. And what the app developer really comes to this part is, you know, with their business logic and with their state model, which is what, let's say, monothe change with, let's say, on the EVM, for example, let's say Solana, for example, provide today at the moment, right? Like, what they provide is a hosted service, right? Like, I mean, validators run the nodes, for example.
00:42:52.248 - 00:43:42.616, Speaker A: But from the applicant developer point of view, it's a hosted service. You don't have to worry about who runs the validator, etcetera. And so what we want to really want to do is basically making, deploying these app chains as simple as deploying a smart contract on a monolithic chain, right? Like, and essentially, once, once we reach there, then, you know, like, basically, I think that will be the undraft where we will have lots of app devs, you know, kind of, uh, starting experimenting with all this new, new kind of, um, functionality that is available, right. Like, so I think one thing which we have been missing a lot in the blockchain industry is also how to. So what. What we as an industry, we are doing is, you know, like, we systems. And it's like a.
00:43:42.616 - 00:44:37.958, Speaker A: I mean, I don't want to say like a walled garden, but essentially, it's a new world, right? Like, and people have to come into this world to use it, right? Like, and there's no really very great interface between, let's say, like a mobile app or a web app sitting outside of this. You know, you have to buy, you have to buy tokens to get into blockchain, for example. And a lot of things going on. But at the heart of blockchain is, like, what. What does really provide you? Of course it provides a lot of things, but I think the most important thing it provides is, like, trustless compute, right? Like, or verifiable compute, right? Like, I mean, I. And you see a lot of industries out there, right? Like, basically, you know, things like escrow. I mean, I don't know if it's not, it might not be a very big problem in western countries, but in developed developing countries, very simple things like an escrow are a huge issue because the level of trust is pretty low.
00:44:37.958 - 00:45:06.110, Speaker A: And so there are escrow companies that are doing millions and billions of volume every day, and their stack is, they have a bank account that they have a license for, and they escrow the funds in the bank account and, you know, like, give it out when it is due. Think of it, escrow is a default in smart contracts. You know, like, the thing is, we haven't figured out a good way for people to access this functionality, for example.
00:45:06.150 - 00:45:06.302, Speaker B: Right?
00:45:06.326 - 00:45:25.820, Speaker A: Like, I mean, so, I mean, yeah, I mean, sorry to get into this long winded this thing, but, you know, like, in general, I would like to say, yes, we can scale this as much as we want, but there has to be a lot of improvements on how we get more app developers to enter this space 100%.
00:45:26.720 - 00:46:31.108, Speaker B: As we've kind of gone down the rabbit hole. Infrastructure does enable more interesting primitives, and I think as more interesting primitives get built will cause us to reflect and look at the infrastructure again. And we'll kind of do this over and over until we maybe forever. We'll see where we ultimately get to one kind of criticism or not criticism pushback that I hear often is that the modular ecosystem, or in terms of, by enabling one application per chain. You're kind of fragmenting or siloing that application to a specific instance or its own world where we're kind of recreating some of the gardens that currently exist. Instead of having a kind of shared state, you have a individual state. And that can be reflected across hundreds or thousands of individual applications if they each choose to build their own.
00:46:31.108 - 00:46:53.044, Speaker B: How would you kind of answer, or what kind of data points would you give to say, look, no, you should be making your applications in kind of their own siloed instance. And it's less about shared state, it's more about controlling the stack. That and the flexibility that the modular stack allows you to utilize.
00:46:53.172 - 00:47:03.622, Speaker A: Yeah, no, I think so. This debate is, you know, like mostly around synchronous composability and, you know, like asynchronous composability as I like to put it.
00:47:03.646 - 00:47:03.782, Speaker B: Right.
00:47:03.806 - 00:47:54.930, Speaker A: Like, I mean, in general, like if you look at like anything on the web or mobile or like in general in Internet infra out there, right? Like, I mean, you look at, let's say if you are buying something on Amazon, you know, when, when you kind of want to buy an item, right? Like, I mean, it sends a request asynchronously to a visa microservice. That kind of send gives you the payment page. For example, when you enter the payment, you know, like visa receives that data, then sends an asynchronous message to Amazon saying, you know, like, the payment has been made. And then, you know, like Amazon then basically sends a microservice call to its logistics provider, which then kind of starts shipping, for example.
00:47:54.970 - 00:47:55.122, Speaker B: Right?
00:47:55.146 - 00:49:11.076, Speaker A: Like, I mean, and all of this happens in a matter of seconds. Like, I mean, basically, I think there is a, there is a requirement for synchronous messaging because I think it's also that that opinion is biased in the way the blockchains have evolved. Right? Like, I mean, blockchains are evolved in this monolithic kind of an environment, right? Like Ethereum is a smart contract platform where you can host multiple apps and because they have this the way activity, you are able to message between contracts and similarly with other blockchains as well. But there is, if I, if you go back to the example that I gave, right, like, I mean, you are, you can treat the entire Internet as one big, whole computer and everyone synchronously talking to each other. But it, in reality, the Internet scale, because you can, you know, like create this different microservices which can, you know, like asynchronous talk to each other latency is not an issue at all. Right. Like, I mean, you hardly notice the microservice call being made to a visa, for example, from Amazon or, you know, like, I mean, it's pretty fast, right? Like, I mean, and that's what matters, right? Like, I mean, I.
00:49:11.076 - 00:49:47.010, Speaker A: And if we. In this whole thing about on blockchain, right? Like, of course, synchronous composability is important. It allows for, you know, like, let's say, especially in defi, for example, it has allowed for, I would say, innovation on top, right? Like, I mean, there's been apps being built on top of uniswap or, you know, like, so, so. But there's, it's. There of course, benefit to that. But I would say there is a lot of use cases that don't really need synchronous composability. I mean, asynchronous is fine for a lot of use cases.
00:49:47.010 - 00:50:48.786, Speaker A: And if we go to this modular action thesis and we see like a lot of these rollouts running and as I already said, with proof aggregation, for example, we should be able to quickly allow asynchronous messaging. And I would say that is fine for a lot of the use cases because it gives you a lot of flexibility on how you give access to users, how you handle users, so on state contention, etc, etcetera. So, I mean, again, right, like, I mean, there are. And in general. Right. I also want to address in the modular ecosystem, doesn't mean that each app roll up on top of, let's say, avail or any other modeler based layer is going to be an application specific chain. You can actually run an entire SVM Solana virtual machine roll up or an EVm roll up on top of teams that are trying to do that right now.
00:50:48.786 - 00:51:00.358, Speaker A: And so those who want that synchronous composability can use that roll up same way someone uses arbitrary polygons for now.
00:51:00.414 - 00:51:00.606, Speaker B: Right?
00:51:00.638 - 00:51:10.806, Speaker A: Like, and you know, like, if you want to message application another roll up, then you do I single. Right.
00:51:10.838 - 00:51:42.740, Speaker B: Like, I mean, so, yeah, yeah, no, it is interesting. And I think, like, as we've kind of talked throughout this podcast, a lot of it is just ultimately the trade offs that you decide to enable, uh, necessarily. Uh, there's lots of engineering choices that kind of go into these things, uh, versus the difference tax. And it's not, I always say you can't really remove these kind of issues. You can kind of just move them around per se. It's. Can't really eliminate them 100%.
00:51:42.740 - 00:52:18.804, Speaker B: Uh, I think what I've tried to focus on is kind of the core raw ingredients of blockchains, which, in my opinion are the. That data availability layer, which is bandwidth, and then on the execution side, which is compute. I think you can either do the sharded architecture or you can have a single unified data availability layer. You can do multiple different roll ups, or you can do a large machine that does the execution alone, but you still have to scale both bandwidth and compute. Those are the non negotiable items.
00:52:18.902 - 00:52:19.808, Speaker A: Absolutely.
00:52:19.984 - 00:53:05.808, Speaker B: So it is interesting, I think the industry is young, and I'm excited, quite frankly, about that. We are in our quote unquote dial up phase and we're graduating. We're going from dial up to broadband in terms of blockchains and the amount of data availability that blockchains are really going to lock specifically around what your team is building at avail granting and unlocking the true power of more data availability. And what that will allow engineers to ultimately build with different applications, I think is only yet to come. And I'm excited for that future.
00:53:05.904 - 00:53:30.104, Speaker A: Yeah, absolutely. We're also kind of been working on this since late 2020, and, you know, like, it's finally, everything is coming into play. And yeah, we are hoping to shift quickly, as quickly as get into production as quickly as possible. But I'm absolutely very bullish on what these can unlock for the ecosystem.
00:53:30.192 - 00:54:35.922, Speaker B: In terms of the broader ecosystem, there are various teams working on different data availability layers, whether that's Ethereum itself, whether that's Celestia, I guess you could call, maybe even Swe or Solana or Aptos, data availability as layers as well. Maybe slightly more opinionated in the data stack, but still scaling the data availability at the bandwidth. In terms of your arguments for why engineers should pick avail over these other ecosystems, could you maybe elaborate on that? Because I think now we're going from we were resource constraint to lots of teams have started to unlock these resources, and now it's really about, all right, I need engineers to build useful applications on my tech stack, and now they have more options than ever. What would your recruitment be to the engineers to have them build on? Like the Polygon or the avail stack?
00:54:36.116 - 00:55:18.818, Speaker A: Yeah, I mean, so basically avail and of course Celestia as well. I would say we are slightly different breed of players where, you know, I think our main customers in general are initially at least roll up developers. Right? Like, I mean, and so essentially the app developers, and they then interface with app developers in general. Right. Like, so. So we provide a service to roll ups, whether it be app specific roll ups, whether it be shared, you know, like roll ups for example. And that's what we focus on of course.
00:55:18.818 - 00:55:59.814, Speaker A: I mean there's a bunch of stuff that we are planning to do with the application developers. But for now our strategy is to kind of work with the providers, whether these be ethereum l two s teams for example, or the more newer sovereign roll up stack players for example. But essentially we kind of work with our partners to kind of interface with the application developers. And of course we help the roll up developers kind of refine the infrared that they want from us in general. We also collaborate with a lot of these teams to do the actual work.
00:55:59.862 - 00:56:00.022, Speaker B: Right.
00:56:00.046 - 00:57:12.100, Speaker A: Like I mean we are working with let's say the Madara team from Starkware to get avail into the Starquire stack for example. You're starting to work with a couple of other l two teams, the bigger ones for example, to get away into their stack. Essentially. Initially we like to answer your question, the application developer really doesn't need to know about the base layer. You know, like to take a decision, right? Like because most of their choices are defined by the roll up configuration, right? Like I mean so if someone is building an SVM roll up on top of avail, then most of the choices are already taken by the SVM roll up, right? Like the applicant developer just needs to deploy the Solana contract. Or let's say we are doing an EVM roll up or we are doing an app specific roll up, right? Like all these are opinion choices made by the roll up designer and essentially all of them depend upon avail. So we are more like a back end infra play more than the very applications play.
00:57:12.100 - 00:57:58.020, Speaker A: The one place where we want to get into front and center of the applicant developers of course, along with our partners is once ZK lightweight ZK app chain kind of construct really becomes mature. That is a few months away. And once that is there then you like this new kind of construction where, which hopefully makes the app chain construct. Like I mean just bring your business logic and state model and put it into this infra kind of construction. Right? Like I mean so there, we will focus more there. But for now, I mean we work very closely with our partners to do this. Does that make sense?
00:57:58.140 - 00:58:31.718, Speaker B: Yeah, no, definitely does. I think. Yeah, the roll up landscape is interesting. It's definitely unfolding quickly. You guys are obviously expanding the bandwidth side on the data availability layer. You're kind of, it's up to the L2s really to expand now the different execution environments and scale the compute side. And as both of those scale the data availability side, it allows for more scale on the compute side, and you could continue to scale together, allowing application engineers to build more interesting apps.
00:58:31.814 - 00:58:32.398, Speaker A: Yep.
00:58:32.534 - 00:59:15.590, Speaker B: In terms of, I mean, maybe kind of as we're wrapping it up, we kind of talked about just increasing raw block size and that really being one of the limitations to scaling overall data availability. We talked about avail going from two megabyte blocks to 128 megabyte blocks and that you also mentioned that you're doing 22nd block times. Do you see that? Block times, can it decrease over time, or do you have any future vision of trying to shrink those or even maybe possibly expand them? Any thoughts or considerations around playing with block times?
00:59:15.930 - 00:59:50.506, Speaker A: Yeah, I mean, so basically, when we think of like the block time for base layer, so what we. So basically it's again optimization, right? Like, I mean, what we want to optimize for at the base layer is, is, you know, one of the things is of course, you know, like some, some amount of, you know, like decentralization, really, we want decentralization at the base layer to be good. Right? Like, in that necessarily it's a wider set of validators. And that also means that, like, we need to kind of ensure there is enough time for validators to reach consensus finality, for example, and so on.
00:59:50.538 - 00:59:50.682, Speaker B: Right.
00:59:50.706 - 01:01:01.472, Speaker A: Like now it doesn't matter that much to users because, you know, like most, I mean, there are two types of roll ups that are possible. There's something called, there's something called, you know, like sequencer run roll ups. I mean, totally depends on who the sequencing and wherever I, and most implementations, for the purpose of practicality, are going to run sequences with second block times or maybe millisecond level block times or something like that, which provides primary, the primary part of the user experience for most users. Now, the block time on the base layer really lends itself to the actual finality, right? There's a soft final t element. There's a, you know, like a hard finality element. And so within that constraint, I think, you know, like a block time of 20 seconds is pretty great because, you know, like, the consensus that we use, like grant, for example, it is a hybrid ledger. And, you know, like, mostly, you know, like, it finally is achieved in two blocks.
01:01:01.472 - 01:01:45.478, Speaker A: Sometimes penalty might be delayed, but block, it's a hybrid lecture. So we have babe do the block production and grandpa do the block finality. And so block production always goes on. Finally, in most of the cases will be, you know, like pretty quick. In some cases, it might get delayed. Essentially what I'm trying to take from this is on the user side, you know, the soft is provided by the sequencer or set for example. And that is, you know, already, for example on all the robots that you see on Ethereum, it's mostly either a second, 2 seconds or in some cases milliseconds, right? Like so, so I.
01:01:45.478 - 01:02:06.862, Speaker A: We don't foresee bringing the block time down on the base layer because it's really not necessary. Also gives us the flexibility to increase more block size as well, more than what we have benchmark like 128 mb. We can go much farther than that as well.
01:02:06.966 - 01:02:28.558, Speaker B: So maybe, just so I can re articulate it once more, the soft finality provided by the sequencer will give the users enough confirmation, especially from the user experience, that the finality on the layer one or ultimately avail can have the longer block times because it's not directly affecting the user experience, in your opinion.
01:02:28.654 - 01:02:29.318, Speaker A: Yes.
01:02:29.494 - 01:02:30.062, Speaker B: Gotcha.
01:02:30.126 - 01:03:23.758, Speaker A: Cool. I mean and this also has to go in conjunction with, you know, like again. Right like I mean you, you also see this, all these ZK roll ups now coming up, right? Like. And finally like so there are two elements, right? Like there's a finality element, right I, so the proof generation, right? Like for, for a ZK roll up for example, right? Like so as, as soon as you have a proof generated, you know that the batch of transactions, the execution was correct, right? Like now you have to rely on the order of the transaction, the finalty of the order of the transactions that the dealer, you know like gives, for example. And so a combination of this, you know, like you can make enough configuration or structure changes and we can provide.
01:03:23.814 - 01:04:34.220, Speaker B: The best ux to users 100%. Maybe wrapping up the podcast. We've gone through a lot kind of talking about data availability's role within blockchains, how you ultimately need to scale the data bandwidth for at the data availability layer, which allows you to further scale the execution environments or the compute within different execution environments, how those are kind of intertwined. But once you scale both, you can ultimately allow engineers to build more interesting applications over time. And really the avail thesis is by creating these modular ecosystems, it allows developers the greater flexibility to really choose the thing specific to them and their applications. Maybe kind of wrapping up like looking towards like the end of the year or even 2024. Are there anything that you are specifically excited for that the avail team is ultimately working on or even outside of the Vail team? I know we've talked about zero knowledge and validium type roll ups.
01:04:34.220 - 01:04:40.296, Speaker B: Are there anything particular that maybe outside of those categories that you're looking forward to.
01:04:40.408 - 01:04:52.096, Speaker A: Absolutely. I think of course we are trying to get that shipped from within avail, but other teams might also be working on it.
01:04:52.128 - 01:04:52.272, Speaker B: Right?
01:04:52.296 - 01:06:20.752, Speaker A: Like, but of course there's a ton of other things that I've excited on, including vardiums and optimistic chains and l three chains and such. But one thing I'm pretty interested in is because we have this data already sampling unlock and what we are doing is coupling this DA verification like our lite lines can do data sampling and can do da verification. We are coupling that with a proof of validity proof verifier and embedding it into besides the light client. So that, and we are trying to put this in a user wallet. So we are already working with a couple of wallet teams to embed the lite client into the wallet but also the proof verifier. And so at some point in time we will have, hopefully soon we will have a wallet that has very cheap verifiation of data, efficient verification of data, but also, you know, like efficient verification of fit. And I think once we have that layer up and running, I think that will unlock, you know, like a bunch of use cases that, you know, like we are, we are excited on.
01:06:20.752 - 01:06:23.064, Speaker A: So that is one thing I'm certainly very excited on.
01:06:23.152 - 01:06:51.254, Speaker B: Amazing. Well, we'll wrap it there. Thank you so much for joining me. Really appreciate your time. Excited to hear you kind of share your vision for kind of the modular stack increasing the data availability that the entire ecosystem really has access to. I truly am aligned with you there that we need more bandwidth and we need more compute. We need to let engineers build, allow them to build more interesting applications.
01:06:51.254 - 01:07:02.550, Speaker B: And those raw ingredients of bandwidth compute are the things that we really need to solve for sure. Amazing. Well, thank you again, appreciate you coming on the podcast and wish you and the team all the best.

00:00:00.400 - 00:00:08.902, Speaker A: We need you tweeting more, Sam, this is super fascinating. Maybe I just been aloof, but this is super cool stuff.
00:00:09.006 - 00:00:48.058, Speaker B: And so even for the biggest wallets, it's like 30 million people. This isn't a large audience for an app by sort of conventional app builder standards. And so if you look at that and see, like, that's the ceiling for success in your CR's builder, you might be like, why am I going to build this platform? I'll build somewhere else where if I'm successful, there's sort of things can go truly viral and there's no upper bound. And during one of those quests, we hit a milestone where we process the most transactions that any blockchain has ever processed in a single day, 65 million. And so that made us feel really happy where it's like, hey, there's all these lab scalability numbers, and you can talk a lot about what kind of traffic you can push, but here it's something where it's like, hey, we hit 65 million. That's more than anyone's ever done. We didn't have the gas price go up.
00:00:48.058 - 00:00:55.030, Speaker B: We didn't have any increased latency or decreased quality of service. It's just the network working as it's intended to even in these early times.
00:00:58.020 - 00:01:23.520, Speaker A: Well, Sam, really excited to have you back on the podcast. We chatted a little bit over a year ago. I think it was even prior to your mainnet launch, and a lot has happened since then. So really excited to have you back on the podcast. Really deep dive some of the new things that SwE and Mist and labs have been working on. But excited to nerd out with you once again because it was truly one of my favorite podcasts that I've ever recorded.
00:01:24.430 - 00:01:38.090, Speaker B: Logan, appreciate the kind words and really great to be back on here with you. I really appreciate you having me. I can't believe it's been over a year. It feels both like it was yesterday and that it's been a thousand years. So, yeah, really excited to pick up the conversation and tell you what's been up with us recently.
00:01:38.510 - 00:01:53.050, Speaker A: Awesome. Well, it's been about six months since sue has officially launched on Mainnet. Could you maybe speak to kind of that go to market or not even go to market, but just launch and kind of your view on the progress since that six months?
00:01:53.440 - 00:02:29.426, Speaker B: Yeah, absolutely. So we went live on May 3. So we had the six month anniversary just a couple of days ago on November 3. And so launching was really exciting for us because when we came out of Facebook in late November or like in late 2021, we could have gone to market immediately with the sort of DM like tech. And we made the decision like, you know, we really want to rebuild this thing from the ground up with horizontal scalability in mind, with like this object orientation in mind, and it's going to be a longer path. We're going to do it. So we were very happy that we were able to get out the door and have the network up and stable and performing well.
00:02:29.426 - 00:03:05.550, Speaker B: So it's been going well for the first six months. We've had steady growth in active users. We've processed all the transactions, we've kept the network up. One of the achievements I was most proud of is we've been running some of these quests that are highlighting various, various themes or apps built on Swiss. We've had gaming focused ones. We've had a couple that are focused on defi just to let people see what's out there and to try stuff out. And during one of those quests, we hit a milestone where we process the most transactions that any blockchain has ever processed in a single day, 65 million.
00:03:05.550 - 00:03:33.144, Speaker B: That made us feel really happy where it's like, hey, there's all these lab scalability numbers and you can talk a lot about what traffic you can push, but here it's something where it's like, hey, we hit 65 million. That's more than anyone's ever done. We didn't have the gas price go up. We didn't have any increased latency or decreased quality of service. It's just the network working as it's intended to even in these early times. So the lots and lots more to do, and it takes a while to bootstrap an ecosystem and get everything going. But I think overall we felt quite positive about the first six months.
00:03:33.144 - 00:03:34.632, Speaker B: Seeing what people have built into seeing.
00:03:34.656 - 00:03:55.890, Speaker A: The network coming along, it is rather remarkable. I don't think that fact is propagated enough because that is no small feat. Combined with having transactions fee stay flat, that's very hard. So congrats to you and to the team. I think that needs to be propagated out into the world more widely.
00:03:56.830 - 00:04:15.850, Speaker B: Yeah, this is the not my triumph of the SWE foundation and the SWE core team and the whole community of validator operators who play no small role in making sure that everything stays smooth in these sorts of times either. So we're. It's a community shape, man. We're all quite happy about it, but, you know, we want to be doing that on a daily basis, not just doing it once.
00:04:15.890 - 00:05:15.240, Speaker A: So that that's what we're really looking forward to 100%. And it's really, I would say, a stepping stone along kind of the journey that we're really all trying to get to, which is ultimately Facebook or meta level scales on blockchains, hundreds of millions and billions of daily active users or daily active addresses. And I think that's just one step in that direction. So again, kudos. But maybe to kind of jumping off where we started last time, nerding out from the TAC, talking about how you guys did data propagation, the execution environment, I would love to just re pick up the conversation and start with some of the things that you have been working on under the hood, or the missing labs team since you guys launch, or even in the last year since we chatted, maybe starting with some of the stuff that you're doing around the ZK login. Because I think that is one of the hardest parts about onboarding people within crypto is just making sure that they can have a wallet. So we'd love to start there.
00:05:15.620 - 00:05:52.662, Speaker B: Yeah, absolutely. Let me start with a little bit of the sort of like background and motivation, and then we'll definitely get deep and nerd out on this bit because I think there's a lot to dig into there. But we, you know, when we decide what new technology to develop on top of suite or what new features to add, we're really thinking about growth. App enablement and product enablement and all is our primary focus in trying to decide what to do. One of the key things we ask about is, let's say a builder comes to SWE and they create some app and the app is really, really successful. What's the first thing that go wrong? The first thing you always hear about is the network can't handle the capacity, the gas prices go up or the network goes down. These sorts of things.
00:05:52.662 - 00:06:24.042, Speaker B: That problem we knew about from the start and have the whole architecture solved. But another one might be, well, everyone who uses the blockchain loves this app, but nobody else is going to try it because it's too hard to become a new blockchain user. We think there's a lot of large barriers to that. To be using a blockchain, typically you have to install this piece of wallet software. It's usually an odd plugin that requires chrome, super user privileges or whatever. It's a bit intimidating to install. Not the most user friendly, even if the teams do a very good job.
00:06:24.042 - 00:07:03.022, Speaker B: And then there's the barrier of, okay, I gotta go to an exchange and get some swe so I can pay for gas and send transactions. And so as a builder, you could build a really compelling experience. But then the ceiling on the success of your app is sort of, however many people have installed a wallet and so even on the bit for the biggest wallets, it's like 30 million people. This isn't a large audience for an app by the sort of conventional app builder standards. And so if you look at that and see that's the ceiling of your success in your service builder, you might be like, why am I going to build on this platform? I'll go build somewhere else. If I'm successful, things can go truly viral and there's no upper bound. One of the things we've really been focused on solving is how can we remove that install wallet barrier? And this isn't to say that wallets are going to die.
00:07:03.022 - 00:07:45.300, Speaker B: I think they have a use case and they'll still clearly be there. But I think you can enable a whole new class of use cases if you're able to eliminate the need to do that. What if someone built something cool using sui in the background and then I can send a link to my friend and then they can just try it out whether they have a wallet installed or own suite already or not. Zklogin, that's really what we were going for is how can we enable a web two login experience now? Starting to get into the tech a little bit. What zklogin lets you do is when you go to a login provider, it could be Google, it could be Apple, it could be twitch. For us, it's anyone who implements this openid connect standard in a certain way. You get back a cryptographic artifact called a JWT or JSON Web token.
00:07:45.300 - 00:08:32.830, Speaker B: The trick that we use is when you make this request, there's some metadata, some custom metadata that you can stuff into the JWT. And so we're like, well, what if we put a public key in there? And then, so you get back this JWT, the sign attestation that says, okay, I'm going to bind your email address to this public key. Now, you could submit this directly to the blockchain and then that would let you sort of log in with Google. But then like, okay, I've got my Google account linked to a blockchain address. I might not want that. So that's where the ZK part of this comes in, where what we do instead is we have a ZK circuit where it can produce a proof that says this person has authenticated with this address and they can sign for this address with this key pair and then they send both the proof and use the private key corresponding that public key to the blockchain to send transactions. But there's no linking back to the web two account.
00:08:32.830 - 00:08:59.610, Speaker B: That's the trick that we use. And then you can build these app experiences like we recently rolled out this Dksend thing where you go to a website and you can send links that have switched have nfts in them, people can click on them and claim them from their email. And that's the sort of thing zklogin enables. And there's a lot of derivative functionality of zklogin that you can do on top of that, but that's the big picture. So I'll pause here for a moment.
00:08:59.910 - 00:09:38.430, Speaker A: It's rather beautiful linking your email to the blockchain, but obviously not everybody wants their email linked on a blockchain. So making sure that you can encrypt that or encode that in some privacy aspect with the zero knowledge proof, it's very fascinating. I think maybe on the zero knowledge side one thing that historically has been a little bit of harder just because the technology is so new is running that transaction or that proof just created client side. And does that take a long time to generate.
00:09:39.090 - 00:10:15.722, Speaker B: Yeah, great question. Whenever you ask about zero knowledge, you should always ask about, yeah, where's the proofer, who's running it? How much does it cost? These are very important questions. So what we have there is the proof is fairly, the, the proof is fairly cheap to generate by these standards. I think it, you know, takes, it takes a couple of milliseconds. We have a back end service that it's like a validator, like anybody can stand up approver and run it, or I should say it's more like a full node actually. It's like that. You can pick up the binary, you can run a prover service for your application, or you can use an RPC provider who our RPC providers now are starting to be like hey, we'll run a full node for you, we'll also run a prover service if you want.
00:10:15.722 - 00:10:35.390, Speaker B: It's also in principle possible to do it on the front end side. It's a little bit expensive to do in the browser right now. I think it's five to 10 seconds that have to check the latest folks. So probably you'd want to use the backend service. But of course the crypto team is always looking at optimizing these circuits or using new libraries that are doing some of the key parts a bit faster.
00:10:36.250 - 00:11:13.570, Speaker A: That's amazing. I truly think that is one of the hardest parts. Just onboarding people within blockchain and getting them accustomed to web3 and just onboarding them seems to be the biggest challenge because you have to go to an exchange, you're on board to the exchange, move the money from there to your wallets, and then you can start interacting with applications and being able to obfuscate some of that steps, or at least go from skip the exchange part directly on chain. That is a massive leap forward in the entire onboarding experience.
00:11:14.630 - 00:11:51.604, Speaker B: Yeah, absolutely. That's one of the other things we've really been focusing on eliminating with a nice native feature. So we also have this sponsor transactions feature built in where ZK login solves the conventional SSO like login experience part. Sponsored transactions can solve the have to go to an exchange and get sweet part. So there, the recipe is a little bit less mind blowing than the ZK login setup, but it's that in a sweet transaction you declare what objects you're going to use. Some of those objects actually get used in the body or the meat of the transaction, if you will. And then some of them are one or more coins that are used to pay for gas.
00:11:51.604 - 00:12:45.778, Speaker B: And so the way the sponsored transactions feature works is that the owner of the gas coins doesn't have to be the same as the owner of the other objects. And so what this lets you do is like as a user, I write a transaction that's going to do something and then I can shop around for a sponsor that's going to do it for me. Or if I'm an app developer, like I run a sponsor service, like maybe it's an onboarding mechanism, I sponsor the transaction to create an account, or I sponsor but then make people pay afterward. Or maybe I sponsor everything and I collected money through a subscription or via some other vector just to hide that friction from folks. So there are these great services like tsunami and the sweet ecosystem that offer sponsorship for people or have nice APIs for app builders to use sponsored transactions and so they can make this part go away. There's also interesting things some folks have built that they call dynamic gas, where it's like sometimes maybe you want to pay for gas but not pay with the suite token. Well, the platform forces you to pay with sweat tokens.
00:12:45.778 - 00:13:14.160, Speaker B: But of course there are many pools on chain that let you swap SWE for stablecoins. They'll let you swap SWe for wrapped tokens from other chains. And so basically, they'll do a setup where at the current price, their transaction is going to give you a little bit of the coin that they want to pay with, and then they'll give you swe that they'll use to pay it. And then so effectively you get this experience of paying for SWE with stable coins, your in game token, or whatever you want. So these two features combined, I think we're really, really excited about in terms of taking away key frictions.
00:13:14.720 - 00:13:37.420, Speaker A: So maybe just rooted for the normies on the sponsored transactions. You're saying it's possible not to have like SWe or the native token within, say like that ZK Login wallet and another account has swe in it that will vote or allow that pay for that gas cost on the behalf of another wallet.
00:13:37.760 - 00:14:10.840, Speaker B: Yeah, that's exactly right. You'd never have to have it in that ZK login wallet. And we think this is what their future will look like. Most of the accounts on SWI or on other chains never have the native token in it because why would they need it? They're only having objects because they're playing a game where maybe they're trading DeFi with stable coins or they're doing something else. So you have swe only if your actual application, use case, or use case is provided, not just because you have to have it for pay for gas. Then there are these big sponsor entities that have big pools of SWE, and they can pay for everything on demand. And maybe you have a subscription with them that you swipe a credit card or doing some more conventional payment mechanism.
00:14:11.420 - 00:14:20.400, Speaker A: We need you tweeting more, Sam. This is super fascinating. Maybe I just been aloof, but this is super cool stuff.
00:14:21.340 - 00:14:59.072, Speaker B: Oh, well, thank you. Yeah, I mean, I think this is a feature that a lot of folks are picking up on other platforms as well, with different levels of native integration. Of course, like a kind of abstraction with this Paymaster feature is a way that folks are trying to do this in the ETH ecosystem. I think the key thing though is for us, this is a native feature. So it's really just as simple as add an extra signature on your transaction and not have to have this indirection of these other smart contracts. Or in some cases, like implementing the sponsored feature, contracts have to opt into supporting a sponsored transaction, and it looks a little bit different than it does to support a normal transaction. Whereas with this at the smart contract layer, you can't even tell whether transaction is sponsored or not.
00:14:59.072 - 00:15:01.300, Speaker B: It just looks the same as any other transaction.
00:15:02.240 - 00:15:22.240, Speaker A: Super fascinating. And then you said the second half of that, I forget there was ultimately the sponsoring half. And then you said you could also swap tokens in one transaction, say if you have USDC, so you could get some swe if you needed to, if you didn't have any swe in that account.
00:15:22.620 - 00:16:18.300, Speaker B: Yeah, so this is more of a service level feature that people are providing rather than an application primitive, but the setup might be like you're a user and you've got, maybe you're playing a game and you've got a token for their game. And maybe the semantics the game developer wants is that we want app developers to be able to pay for using our game with our token. Okay, well we're not going to modify Swe just to accommodate that one game to allow them paying the game tokens. But if this is a token, it's going to be traded on Dexs, on Deepbook, SWE's native order book and elsewhere. And so there might be a service provider out there who says, ok, you come to me with this transaction, I see this token, I see what the market price is on the order book. And so I'll put my suite on your transaction, I'll sponsor it, and then I'll make sure that that transaction contains a small transfer to my address of this game token. And then after I get it, I'll go and trade it out on the platform.
00:16:18.300 - 00:16:41.660, Speaker B: Or maybe the transaction itself just hits the order book directly and gets the suite and then pays back the sponsor. And so both of those setups can work, but allows the under the hood it looks to the or from above, it looks to the customer like they were paying with the game token. But under the hood you're just using this powerful blockchain primitive of swap one token type for another to hide this away.
00:16:42.210 - 00:17:46.900, Speaker A: That's beautiful. I really think. I mean, my personal belief is we kind of had like crypto anarchists, like with like early blockchain adoption, like the cypherpunks, we kind of evolved with the ability to do smart contracts but didn't really have that scalability component. And now we're kind of seeing the third generation blockchain platforms that have the smart contractability and scalability. And I think within that, a lot of the builders that I've been talking more recently are very ruthlessly pragmatic about like the engineering trade offs and really making sure that a lot of these things like the Mist and labs team is building, whether it's the ZK login or sponsored transactions, are abstracted as much as possible because I think we've tried to go like the Normie or like the web3 route, and it hasn't necessarily translated well to kind of the tens of millions or even hundreds of millions and billions of people that use the web. And as much as possible, we really do need to abstract those while keeping all the properties of decentralization and self sovereignty or owning your private keys. But just making that super easy.
00:17:47.480 - 00:18:18.268, Speaker B: Yeah. Oh, I completely agree. I mean, at its core, to me like web3 is about, is about building technology for collaboration. It's about building technology for enabling interoperability, for removing intermediaries. And you can still have all of those things without introducing these ux barriers that I think are really incidental rather than necessary. You don't necessarily have to know, you don't necessarily have to know your seed phrase to participate in web3. You can log in with Zklogin, and it's not like the web two provider can send transactions on your behalf.
00:18:18.268 - 00:18:40.580, Speaker B: They cannot in the way the ZK login works. And it's also not the case that you have to worry about losing your account. You can rely on the web two recovery mechanism for that. If you don't like that, then you can still access the chain with your UNC phrase with a conventional wallet. It's just about giving people more options to enable more use cases. Not being religious about one way to do things or the other.
00:18:41.040 - 00:19:30.440, Speaker A: 100%. And one thing that really struck me from our last podcast that really I kept with me was one of your comments around the golden standard for composability. Your idea was all these assets really live within one ecosystem. It was really breaking down the walls that these web two kind of companies provided and being able to natively touch assets. And I thought that was such a powerful statement, because if you break it down and really think about it, I think that is like the core essence for at least the engineers. You remove these individual databases and put everything together, and that's really what makes the web3 magic. I would love for you just to briefly expand it upon it because it really stuck with me from the last podcast.
00:19:31.300 - 00:20:16.204, Speaker B: Yeah, definitely. And I appreciate you saying that. I think a blockchain or platform like sweat, fundamentally it's a smart contract platform. And what are smart contracts for? Smart contracts let agents transfer and share objects. That's what this whole thing is about. And then an important corollary of this is that if you put barriers up to sharing or transferring, you're going to fragment the the state across several different layers or shards that become visible to the user or to the validators, then you're getting in the way of that core value proposition. Whereas if everything is in the same place, then you can freely interoperate, you can freely transfer, you can freely share, and none of that stuff gets in the way.
00:20:16.204 - 00:21:13.428, Speaker B: Really. We think of starting from this very simple thing and trying to not introduce any barriers at the technical level or at the accessibility level, and in fact introducing features that try to, to break those down as much as possible. And then in terms of the object part of that statement that goes a lot into our object centric design where it's really objects are front and center in smart contract programming and all the use cases. But you really want to have a representation of this that's super direct to the programmer, that's super direct in the read APIs, that's super direct to clients and wallets. Everyone has this common vocabulary. Instead of saying well yes conceptually you have this thing, but actually this is represented as an entry in a hash table somewhere and there are some bytes and if you want to use it you have to go decode it and do something or chase a pointer to another hash table. You want to look at it and be like ok, here's my characterobject and then hanging off of it or its shoes object and it's Pan's object and it's shirt object.
00:21:13.428 - 00:21:39.470, Speaker B: And when I call the API I just see the thing, I get the object and then everything gets hanging off of it. I can render in a coherent way instead of trying to be like oh, here's the protocol for having to understand that. So we, I mean that's the other big part of this is just like if, if this is the fundamental building block, the fundamental vocabulary, then like how do we expose it at the programmability level and then use that abstraction throughout the system instead of trying to hide it or translate it into different concepts.
00:21:40.130 - 00:22:55.916, Speaker A: And I think a lot of people still in my mind don't know that you're the inventor of move or kind of led those efforts at meta and now kind of took that team and the expertise over to miss and labs. I think it's ultimately, I would not be surprised if move became the predominant programming language and web3 across like all blockchains in a very short amount of time. And I would love to talk about all the new updates to move, but maybe just finishing out the topic on kind of like having everything logically centralized. I think one of the big debates that is currently going on and will continue to go on is to your point? Having everything kind of co located together where you can kind of like atomically touch these things, and I think it will kind of boil down to intervalidator sharding versus intra validator sharding. And that still is not a very well known topic. I think we kind of touched upon it a little bit in the last podcast, but I think as we continue to scale the industry, it's going to be a bigger topic. And honestly, I love the approach that miss and labs has taken.
00:22:55.916 - 00:23:01.960, Speaker A: So I'd love for you to just expand upon it a little bit more and then we'll jump into what you've been doing on move.
00:23:02.260 - 00:23:57.176, Speaker B: Yeah, I mean, so this topic is very much related to the so called like monolithic versus modular debate, where it's sort of like, you know, if, if you're going to scale, if you're going to scale a blockchain or smart contract system, like, you're probably going to have to have more than one machine. And then, so when you have new machines, like how do you, how do you allocate those? And so, like, there are two strategies. There's like one is where, okay, a validator can be one machine or it can be many, and then how it's set up and how it scales internally is opaque to the, opaque to clients, opaque to the rest of the network, opaque to the cost structure. It's just an internal implementation detail of the validator. If you take this approach, then scaling, then with the right blockchain architecture, like what we've tried to do with suite scaling out the throughput of the network and the storage and the processing capacity, it looks very much like a web. Two problem that the folks from the hyperscalers are familiar with. Like, okay, I have this database, it's a bunch of petabytes now, it's going to be more later.
00:23:57.176 - 00:24:59.676, Speaker B: How do I make that bigger? Allocate more machine. Allocate more machines inside, then the alternative approach is actually at the network layer. We're going to be aware of sharding as a concept that validators know about, the clients know about, that users are going to have to know about. And so when we want to allocate more capacity, we have to have a scheme for saying, okay, here's who runs that new machine, and here's what part of the state it stores, and then here's what state should migrate over from existing things or other stuff. And then it just becomes a lot more tightly coupled to the design of the blockchain and makes it sort of more complicated because you're exposing those details and you can't just change them without breaking the protocol. Our thinking about that has always been both of these approaches can work, but we think of from the developer perspective, from the user perspective, what's the experience that you want? I think the experience that you want is the whole state is just there. I can write code that can touch any part of the state and there's no barriers and there's no atomic swaps or cross chain movement or bridging or any of that stuff.
00:24:59.676 - 00:25:38.912, Speaker B: Just everything I want is right there at my fingertips. This is weather in a nutshell, putting all the valuable state in one place. Or it's that every time I'd like to do that, I have to move from one to the other, or I have to write the cross chain swap, or I have to use some library that deals with this. I don't think anyone thinks that the experience of having to go across these barriers is better. I think it's just more of a question of do you actually think you can get the first approach to scale? If you don't think that, maybe you have to acknowledge we'll give up on the ideal experience and compromise and do this thing that we think is going to work better. And so for us, we don't think that we have to compromise. And so we've taken the first approach.
00:25:38.912 - 00:25:43.848, Speaker B: But I think there are many interesting designs along both lines and why, I.
00:25:43.864 - 00:26:23.350, Speaker A: Guess Swe is kind of unique, one of the few blockchains that have really taken this approach. Do you think other blockchains did not have kind of the learning lessons that sue ultimately has came upon to build everything together and scale with additional compute that programmers do not have to program against it, instead of the more traditional sharding method? Why do you feel like earlier blockchains have taken that design where it seems, at least to me, fairly obvious, this is a better design if you can do it well.
00:26:23.430 - 00:27:03.932, Speaker B: I mean, it's an interesting question. I mean, if you asked me to speculate, I think my answer would be that it's. It was really about focusing about backward compatibility with the first entrance in the space, Ethereum and EVM. This is something that has a great developer community around it. This is something that has great use cases built on top of it. But once you have those design constraints in place and you have billions of dollars in assets in there, then it's very hard to move forward in a way that fundamentally changes the design while also preserving compatibility with all that stuff or doesn't shake things up too much so I think it's a, I think it's more due to a status quo bias, which is very reasonable. It's very hard to bootstrap an ecosystem from scratch, a developer ecosystem, it's hard to bootstrap an asset base, it's hard to bootstrap apps.
00:27:03.932 - 00:27:40.580, Speaker B: It's like, well, I think it really comes down to this values question of, well, is what's valuable, what's already there? And we can sort of accept the technical limitations of that in order to preserve 100% compatibility with it. Or are we willing to take the plunge and just do something completely from scratch? So I think it's more that than like a technical thinking or like, you know, wondering which approach is better. But you know, this is highly speculative. It's really hard to know. You know, for us coming from a tech perspective or like, you know, a lot of the mist and founders coming from a research background, we're always motivated by like, how do I do the right thing from, how do I do the right thing from scratch? And so that's the angle we took.
00:27:41.040 - 00:28:49.520, Speaker A: And I very much appreciate that approach. It's, it's refreshing when a lot of people kind of look to their early entrants and say like, nothing can be approved on that. And so I really appreciate kind the radical new design because I think that's honestly how we get the industry to scale. But maybe jumping back to move, you've thought a lot about move kind of sui shipped with move and I think it truly is a much better programming experience. I think Rus and some of these earlier languages, whether it's solidity, are a little bit more open per se, but with move it, I would say as much as possible tries to eliminate the developer errors in a very programmingly programmer friendly environment. And so I truly would not be surprised if move became the dominant programming languages within web3 in a couple years timeframe. Could you possibly expand upon some of the things that either have been updated in move or progress since you've really launched?
00:28:50.180 - 00:29:33.004, Speaker B: Yeah, absolutely. And I appreciate you outlining the goal of becoming the dominant language in web theory because that's really what we're going for. I'm the creator of move. I've been working on the language since 2018, and I think the language has come a really long way in terms of its beginnings in DM compared to where it is today. The way we start off with Diem is, but it was this supposed to be this global payment system, but also it was focused a lot on compliance. So it was focused a lot on putting walls in the way, on certain actions in transferring. I think in a fully open smart contract platform, you want transferring to be really easy, but in a compliant payment system, only certain people can receive certain types of assets.
00:29:33.004 - 00:30:00.522, Speaker B: Account creation has to be privileged. There are certain guardrails that got built in. A lot of the changes we've made to move are going beyond the original requirements of DM and thinking about how does this work in an open system? So to anchor, and I said this again, but I'll say it once more, because I think it's a useful thing to anchor on. What we think of is smart contracts are. The task of a smart contract is to transfer and share assets between. Transfer and share objects between. Sorry, I'll start with a good one.
00:30:00.522 - 00:30:27.486, Speaker B: So it'll work for the recording. We think the task of a smart contract platform is to enable transfer and sharing objects between agents. So let's break it down and really talk about each of those. That's the vocabulary of what smart contract programs are supposed be doing. So you better have really good abstractions and really good answers for all of those things. So for the transferring part and the original move, for each new type that you declare, you have to sort of hand roll the transferring program. It's not something you get for free.
00:30:27.486 - 00:30:52.980, Speaker B: And so in the experience of building suite, we're like, okay, we want so called polymorphic transfer. Let's make it so all objects are transferable. So that's great. Developers are no longer having to hand roll that. And then if you want to put restrictions on a transfer, there's a special way to do that. But by default, everything is just freely transferable. Then there's the sharing part where in sue, objects have owners, and this is also a change they made.
00:30:52.980 - 00:31:28.542, Speaker B: In the original conception of move, there's no notion of an object or having an owner, there's just types. And the logic you write defines what ownership means. When we think about it, we're actually these very clear modes of different objects. In the smart contract world, it's an asset that it's in my address and it belongs to me, and other people shouldn't be able to touch it in any way, or it's shared. It's a Dex, it's an auction, it's a game that multiple people can play just by having those different modes where it's single owner, no one else can touch it. It's just inherently secure. You can't get things wrong, or it's shared, and you have to say who's allowed to do what operations on it.
00:31:28.542 - 00:32:14.688, Speaker B: That really helps partition the space of things you want to do. With smart contracts, sharing also is a fundamental operation in move as we have it now, you take an object and you can share it, and then that means anyone can call its function so they better have access control, whereas when it's transferred, it's owned by something and so it can only be sent in a transaction that's touched by its owner. This also led us to develop this thing that we've called programmable transaction blocks. And so there's this big problem in smart contracts of like how do you compose existing code? I have function a and function b. Maybe they're not aware of each other. And now I'm a user and I want to atomically, in one transaction, call function a, get an asset from it and pass it to function b. Originally move, we did this with scripts.
00:32:14.688 - 00:32:52.926, Speaker B: Scripts is like, okay, you have a main and it calls, it calls function a gets the thing and pass it to function b. That doesn't sound so bad. But then you think about the actual client or front end experience of doing that. Is your typescript code going to write move source code for the script and then invoke the compiler and then put the result into a transaction? It's like, that sounds kind of scary. Most of the time writing new code, you're going to have it audited. You don't want to call a compiler from the front all these sorts of issues. And so the workaround is basically like every time you want to compose two things, you have to either do a script that you build on the front end or publish new smart contract code that's doing that composition and you really don't want that.
00:32:52.926 - 00:33:23.558, Speaker B: Like, you know, in a lot of cases you have this sort of ad hoc composition where someone is deciding very much on the fly. Like I want to do these two things together. We see this often in Defi with routers that I'm going to decide what pools I'm going to hit at the last second based on what the current price information is, and I don't know in advance what it's going to be. I'm going to do that on the front end. This programmable transaction block feature helps a lot with that. The way it works is basically in swe you don't send a transaction, you send a programmable transaction block where it has a set of inputs. You call a function, that function has outputs.
00:33:23.558 - 00:34:07.020, Speaker B: Then subsequent function calls can take as inputs both the output of previous function calls and the initial inputs. And so it's sort of like the set of Lego blocks you snaps, nicely typed Lego blocks that you snap together and can accomplish these complex things. And so you can finally accomplish this task of, I have these two things that don't know about each other. Neither author meant for them to compose, but I, as a user, can do that and build these things in the front end in a way that does it. So I think that was a huge, huge step forward for us. And we see in SWE, the number of transactions within a single program or transaction block is growing all the time as users figure out, hey, I can do more work in a single transaction, I can do more atomic operations, I can do more complex stuff. It's quite cool compared to science end and losing that anatomicity.
00:34:07.020 - 00:34:09.820, Speaker B: So I think, sorry, go ahead.
00:34:10.640 - 00:34:18.060, Speaker A: Can you maybe provide an example for some of the non technical people what type of transactions that ultimately enables.
00:34:19.080 - 00:35:00.915, Speaker B: Yeah, so the one example I like to use is something like, say I'm, say I'm playing, say I'm playing a game, don't get in copyright trouble, but it's a Nintendo game that has a Mario in it. And then I'm going to play this game and I'm going to win a trophy. And then when I win a trophy, I'm in a sort of game player hacker collective, and I want to put it in my shared trophy case. Now, from a smart contract perspective, now, from a smart contract perspective, the game doesn't want to know about your trophy collective, that sort of thing. Wherever trophies from, lots of games come from. And then also the trophy thing doesn't know about the game. It's like, hey, people can put these everywhere.
00:35:00.915 - 00:35:36.908, Speaker B: So there's not a logical place to publish the function that says go and do this. And so the way you do that with a programmable transaction block is you call the first function, that's like play game. It does its thing, it returns the trophy, which is an object, and then that object is just free to be passed into whatever function the user wants. And that next function is determined by the next move function that you put in the programmable transaction block. So you would call play game that returns a trophy, and then you would call publish trophy or add trophy or whatever. And then the next function takes a trophy's input and then touches the shared trophy case objects and puts it in there. That's a very simple one that just consists of two.
00:35:36.908 - 00:36:08.150, Speaker B: But then a lot of times you end up wanting to do many such actions. It also lets you do basic things like, I want to do a batch of 200 payments. And rather than implementing special logic for batch payments in the smart contract, I just do 200 single payments and it makes it much easier. So those are basically the types of things where it's like I have this nice paradigm of objects flowing like I call a function. Objects flow out of it, and then the client gets to decide what to do with them next. And the original programmer doesn't have to worry about all the possible different things someone might want to do with their objects.
00:36:08.650 - 00:36:19.240, Speaker A: Is this uniquely enabled by move or the object oriented programming that sue enables, or a combination of the both?
00:36:19.900 - 00:36:51.860, Speaker B: So this is uniquely enabled by move, the typed object output parts, at least if you're familiar with Solana and the paradigm where it's like you have a transaction and then you have instructions, definitely that enables some flavors of composition. Definitely you can do batches of multiple instructions. But I think a problem people have a lot is what did the previous instruction do and how do I make sure that the next instruction is using that thing and not using something else? So I think it's spiritually similar to that. But really this paradigm of having explicit input and output objects and then having them be typed so that, you know, they snap together just so, or that they don't at all.
00:36:52.480 - 00:36:55.580, Speaker A: Okay, makes sense. Interesting. Very cool.
00:36:56.280 - 00:37:32.290, Speaker B: Yeah, so this is sort of like along the lines of answering a question about what's going on in move. So I think those are like the fundamental sort of like platform features that have changed in move since the DM days. But then, you know, we're starting now to make a lot of improvements at the source language and tooling level as well. So along a very long request, a very long term request that we're finally getting around to is we're going to have enums and move. So that's great. That helps a lot with type evolution where it's like you have in the first version of a contract, you have a type with certain fields. Now you want to add a field or do some other things, now you can add that easily.
00:37:32.290 - 00:38:24.526, Speaker B: We're also having method style syntax or receiver style syntax, where right now you have to have the module name and then a colon before calling any functions that ends up making your code a lot longer. Now you can just say, you would say vector, colon, colon, pushback. Now you can say v dot pushback if v is a vector type, and then you're done. So that part is great. And then also better macros for letting you do things like complex looping and iteration, or just code reuse that you can't do with a simple function rewriting the one other feature I forgot to mention, this is more of a, this is more of a fundamental platform one than a smaller new language feature is this dynamic fields thing. The way we think of this is that when you declare a struct type, it has an f field that's U 64 and a g field that's a U 64. Whatever you want, that's the static type of your object.
00:38:24.526 - 00:39:12.588, Speaker B: But then it might be the case that you want to add some things on demand or add or move them on demand JavaScript, where it's like I have a hero and I want to add shoes or a boot to him. Like we talked about later, you don't want to implement that by having a bunch of fields that are like option of shoe, option of boot, option of every possible type that this thing might have. It's a lot more mix and match or happens after the fact than that. The way we implement that is that every object has an implicit hash table inside of it that you can stuff other objects into. This is the thing. And we call that implicit hash table a dynamic field because the hash table can be keyed by whatever, and then you can put things in there or take things out. And so this is how we implement big collections like hash tables or sets.
00:39:12.588 - 00:39:24.720, Speaker B: But that's also this really flexible feature with objects where you can sort of like dynamically add and remove, add and remove other objects or like other data to them. So I think that's the other big fundamental change that we've made since the, since the early days.
00:39:25.300 - 00:40:16.750, Speaker A: Maybe a higher level question, Sam. I think in terms of kind of general adoption, people started with like solidity or EVM, and then now have been experimenting say with SVM in your terms, or like, what do you think? All these like features, I think are necessary and we need these to scale. What is that like in your mind? First step that we need people to explore the sui ecosystem. Do you think kind of after listening to this podcast, like developers will be like, yes, I need this and just jump into the SWe ecosystem to try? I'm curious, like in your mind, the engineering mind, what would get you excited to try Swe or what do people not understand about Swe that they should try it?
00:40:17.450 - 00:40:54.788, Speaker B: Yeah, so I think there are a lot of answers to this and sort of depends on what you're looking for as a builder. But if I had to say one thing, and I think this is something we're seeing now, is the ZK login feature. We've seen an explosion in developer interest since we announced that, where it's like, hey, you want to provide this polished experience for your app, you want to have SSL login? Guess what, that's a native feature. Just call this prover API, copy this example code and you're off to the races. Now that you've got that problem solved, what do you want to build? And you don't just have to build this for the 10 million, 30 million nerds with wallets. You can build this for anybody. And then that's the real where you get.
00:40:54.788 - 00:41:23.060, Speaker B: It's like, oh, also I don't have to write this scary language. This looks a lot like something I'm used to. Ok, there's these nice objects with types, it looks a little bit like rust, it looks a little bit like JavaScript. When I get something wrong, I get a slap on the wrist in the compiler. So I think that's a huge entry for now. I mean, certainly we've had a lot of folks where they're curious about move and their tech forward and they want to try another smart contract language, but I think that's the most powerful lever, especially for developers outside of the conventional web3 space that we have right now.
00:41:23.760 - 00:41:45.676, Speaker A: Yeah, it makes a lot of sense, I think as much complexity that you can handle within the protocol that abstracts these key friction points and making those more frictionless on the developer side so that they can focus on being product engineers instead of protocol engineers is a major step forward.
00:41:45.868 - 00:42:21.246, Speaker B: 100%. Yeah, I think if you have to be a protocol engineer to build something like the security, the security imposters is never going to work. And I think that's one of the big problems with these existing smart contract languages is like, even though the folks who build things are so hardcore, like so security conscious and know so many details about the protocols, it's still not possible to write safe code. And that's not because they're bad devs, they're great devs. They're like the best the space is possibly going to hope for. But it's, you really need the sort of safe by default language and you need those abstractions that hide the details without getting you into security trouble or you're just not going to grow the developer, the population much beyond what it currently is.
00:42:21.438 - 00:42:33.486, Speaker A: 100%. I'm rooting for move because I think it will be much better for the entire industry. So I really appreciate what you've done there to create it. I truly think it's a big step.
00:42:33.518 - 00:42:40.050, Speaker B: Forward, lots of work to do. But yeah, we're happy with where it is, and it seems to be working out so far.
00:42:41.070 - 00:43:14.126, Speaker A: One thing that I think we also, that you've been working on behind the scenes, as well as some improvements on consensus. I think this has been a fascinating field where people go off and do a bunch of research and then bring it back into production, whether that's increasing throughput or reducing latency. I know the miss and labs team has been putting a lot of effort into this field as well. Can you talk about some of the advancements that miss and labs team has made in the consensus since you've kind of, since we talked about a year ago?
00:43:14.318 - 00:44:14.190, Speaker B: Absolutely. I'm really excited to talk about this, and I think I gave the same caveat last time, but I'll give it again, like this side is not my area of expertise. George, our chief scientist and the researchers and some of the engineering folks are really the brilliant minds here, but I'll try to summarize their work at a high level and definitely have one of them on if you want to go really, really consensus nerd deep. But at a high level, we have this new effort that's called misticetti. There's a research paper out that we can link, and the thing that Mista SETI is doing is if you look at Sweem and the way it is today, it's this merge of two different protocols. One of the protocols is Fastpay, or what was originally called Fastpay, that was trying to solve the problem of I want to do really, really low latency transactions and highly scalable transactions, but I'm willing to restrict the amount of programmability that I get to the subset of computations that don't require full consensus. So, you know, object transfers, NFT mints, you know, token transfers, this sort, this sort of thing.
00:44:14.190 - 00:44:16.330, Speaker B: And so the, that's one part.
00:44:16.370 - 00:44:18.306, Speaker A: Non contentious pieces of state.
00:44:18.498 - 00:44:32.464, Speaker B: Exactly. Things that don't require shared state. Things that don't require shared state is exactly the set of computations. This thing ends up being a lot broader than you think. I think we've seen that with sweep, but so that, that's one part of it. And so we have that today. We call this the consensus fast path.
00:44:32.464 - 00:44:54.632, Speaker B: You get 400 millisecond end latency. If you use it, it's great. Then the other part is we're going to have shared state. Obviously, this is a blockchain. There's going to be trades on Dexs, there'll be auctions, et cetera, et cetera. And so for that we had the work that the team has done on Narwhal. And so in the original suite, it's like, all right, let's smush these things together.
00:44:54.632 - 00:45:49.360, Speaker B: But they're two separate protocols, or figure out how to make them interactive. But the way in which we did that, sort of like gluing them together, or, sorry to say, more explicitly, the suite protocol views narwhal as a black box. But if you open up the black box of Narwal, there's a lot of things that look like what you're doing at Fastpay. Like, Fastpay is built around this primitive called consistent broadcast, where it's about send a bunch of stuff to folks, get an attestation, and make sure they're on the same page. There's a consistent broadcast step both in Fastpay and inside of narwhal once you get in there. But if you don't open up that narwhal black box, you don't see that there are these two different steps that can maybe be combined. So what mischaceti is trying to do at a really high level is like, okay, given that we want two different parts, we want a consensus engine, and then we want this fast path for certain computation types, how can we merge the consistent broadcast step and sort of make these things fit together as nicely as possible? So that's really what this long term effort has been doing.
00:45:49.360 - 00:46:33.594, Speaker B: A lot of the ways we had glued these together before meant that you got worse latency than what was theoretically possible for the full consensus case. But now we can get much, much better results. So, to put concrete numbers behind it, we get about 400, 500 milliseconds end latency for the single owner object transactions today, and about two for shared object transactions. After Mista SETI, we think we can get about 0.25 for the single owner and about one for the shared. Big, big increase in latency here, all while maintaining the throughput we have or actually getting more throughput with fewer resources. So it's a research prototype, but we're pretty excited about trying to take it to production in the next couple of months.
00:46:33.762 - 00:47:07.990, Speaker A: That's awesome. Very impressive. Maybe just to reiterate, today, there's two consensus algorithms. One for, I say, non contentious pieces of state where you have the fast path, uh, where you can skip the ordering step. And then for the contentious pieces of state, you have to have that ordering step. And this new algorithm, is it or consensus algorithm, is that combining these two individual consensus algorithms into one, or is it still separate? They're just both more optimized.
00:47:08.610 - 00:47:31.360, Speaker B: So it's still separate. But I think we thought of it like before. We thought of it as, okay, we have these very separate things. Like there's fastpay, and then there's narwhal, and then in the new conception by the research team, it's like, how do we have a consensus algorithm with a fastpath? And when you co design these things and let them use some of the. And let them use some of the same components and primitives, then you can really get a lot of efficiency gains, is the core of it.
00:47:31.740 - 00:47:34.884, Speaker A: Interesting. And is this still a dag architecture?
00:47:35.052 - 00:47:36.260, Speaker B: Yes, yes, absolutely.
00:47:36.300 - 00:47:44.650, Speaker A: Okay, interesting. And you said potentially be on mainnet, say, six months.
00:47:45.070 - 00:48:14.184, Speaker B: So I don't want to make any promises on that, because with this thing, it's like you've done the work. But the most important feature of the network is its stability and its security. So we're not going to rush this if there are any risks put forward. So I think what we're going to do is the team is working on a plan to incrementally add various bits of this, and then we'll see when the whole thing gets into production. And so I think six months is, like, definitely not a problem. That's a reasonable time scale for exploring this. But ultimately, like, for any of the.
00:48:14.184 - 00:48:20.700, Speaker B: Any of these tough transitions, you really gotta let the security and reliability determine how soon somebody gets in.
00:48:21.160 - 00:48:33.906, Speaker A: True. We. I think we've seen Solana kind of shoot itself in the foot a couple times with trying to rush something so slow. And SeTI, I think, wins the race totally.
00:48:33.938 - 00:48:46.578, Speaker B: I mean, I think if you look at the merge, I mean, well, that took a very long time, but the rollout was extremely seamless. And so I think if you can get the stability part and care taken in that process, while maybe being on a faster timeframe, that could be the best of both worlds.
00:48:46.754 - 00:49:36.040, Speaker A: Fully agree. One thing that ultimately got flagged with me, I was talking with Emin, the founder of Avalanche, and we were talking about dags versus kind of traditional leader based protocols, was around kind of like channel saturation, and potentially having two leaders ultimately communicate kind of maximal channel capacity at the same time. Have you seen that? Or do you ever anticipate channel interference by having two leaders simultaneously saturating the data, ultimately dropping, say, from like 2gb of channel, two liters simultaneously communicating 2gb or 1gb each, but the channel capacity is only 1gb, if that makes sense.
00:49:36.380 - 00:49:46.920, Speaker B: Yes, this is a disappointing answer, but I think this is below my level of abstraction. On our consensus and networking layer. George would be a fantastic person to go deep on this one.
00:49:47.980 - 00:50:13.450, Speaker A: I would love to have him on as well because this is one thing that I've been trying to figure out and people have been kind of flagging with me, but been nerding out on trying to learn more on consensus algorithms. But no, it sounds fascinating. I think being able to get latency down that low in a global network, you're saying a couple hundred milliseconds and then kind of for full ordering around a second is extremely impressive.
00:50:14.230 - 00:50:32.918, Speaker B: Yeah, we're really, I think, starting to push it up against the theoretical limits, whereas before we had the theoretical limits in the protocol, but we weren't approaching learn practice. And I think now we, now we can really have both. So, yeah, with the, with the caveat that we got to be cautious and rolling it on. I'm really, really excited to see this go for sure.
00:50:33.094 - 00:50:51.650, Speaker A: Are there anything, I would say, learning lessons since you've launched approximately six months ago, a little over six months ago to today, and just seeing how the network actually performs on Mainnet, or has kind of the testing and testnet really been like that core building block that nothing really surprised you?
00:50:52.830 - 00:51:43.474, Speaker B: Yeah, it's a great question. I mean, so certainly in coming up to launch, I think we focus, as one does, a lot, on the right path and the performance of the right path and the stability of ensuring that all of that stuff works. But then, of course, from the app perspective, it's great. If you send a transaction, it happens very quickly, but if that information doesn't get propagated quickly enough to full nodes, or if there are stability issues there, or if indexers lie behind, then it doesn't matter if all of these things are happening very quickly. So I think we underestimated. Well, obviously we knew that was important, but that you really have a lot more control in the right path because it's all within the realm of the validator software, which the core team works on, and we have great monitoring and analytics. Whereas in the read path, it could be any full node anywhere in the entire ecosystem that could be configured this way or that way, or be on this machine or that machine and could be having these problems.
00:51:43.474 - 00:52:20.870, Speaker B: I think at the beginning we had some rockiness in terms of just making sure that that part was as streamlined and as efficient and as easy to use as the other stuff. I think we're in a very good state there now, and with this big RPC 2.0 migration that we're making, things will be even better. But I think that's one thing where it's obvious in retrospect, and if the core isn't stable or if the right path isn't working well, then it doesn't matter if the reads work well or not. But I think definitely in the way we approach core engineering now, we have a lot more of a balance in terms of thinking about both sides of the equation rather than just focusing on the, the fun part, if you will, the reads.
00:52:20.990 - 00:52:32.770, Speaker A: I mean, it's one thing to optimize the writes, but you have to do the reads as well. That can be challenging, especially when you get up to the number of transactions that sui is trying to propagate.
00:52:35.310 - 00:53:01.276, Speaker B: Totally. A pet peeve of mine space with this is people use this time to finality metric, but then finality is not something that's observable by a client. This is a theoretical thing that happens inside of a validator and no one actually knows. But like, to a builder, time to finality doesn't really matter. It's like if it's high, you know, the end to end latency isn't going to be higher. But what you really care about is, as a builder is the end to end latency. So you got to be talking about that number too, and like optimizing those bits rather than just the finality bit.
00:53:01.276 - 00:53:05.400, Speaker B: So I think we already had that mindset, but it's really hard to carry that all the way through.
00:53:05.900 - 00:53:17.040, Speaker A: I really wish we could kind of unify standards across the industry. I've been trying to do a little bit, but anytime you try to make a standard, people yell at you. So it's, it's not very easy.
00:53:17.980 - 00:53:32.140, Speaker B: Yeah, yeah. Especially when people just want their low numbers, which is fair. We want to talk about how fast our protocols are, but yeah, we also need to talk about the numbers that make sense for builders. So it's a tough effort.
00:53:32.440 - 00:54:08.830, Speaker A: I think in the last podcast I also asked you in terms of scaling, or one of the things that you thought was going to be the most difficult in kind of reaching mass adoption, whether that was going to be different things on the consensus design, different things with the virtual machine, either the high throughput and the bandwidth requirements there, or ultimately storage. I believe you said storage. Would you kind of. Is that still kind of, you think the end state or the hardest thing to scale in these blockchains? Or if not, how is your view changed?
00:54:09.730 - 00:54:52.632, Speaker B: Yeah, so I'm trying to remember back to what I said. So for us, that hasn't been a significant challenge, and I think we don't expect it to be one going forward. It's more of a, let's call it a conventional engineering problem or web two engineering problem than many other parts of the stack. If I had to guess what I was saying then, or think about why this is challenging elsewhere is I think the storage paradigm used in a lot of other chains is really based on account based system. I have a merkle tree of accounts. Basically, the way I do authenticated reads is that there's some accounts that leaves, there's a transaction, it changes some of the accounts, then I have to bubble that up all the way back up to a Merkle route, and I basically can't authenticate anything you until I've got a numerical route. And then basically folks will place that process on the critical path of execution.
00:54:52.632 - 00:55:14.914, Speaker B: And then basically, okay, now your entire execution is bottlenecked and computing that numerical route. And so I think folks have gotten wise to that. And a lot of times, if that structure exists, it's moved outside. But even when that's moved outside, this sort of thing is somewhat hard to scale. It's usually an efficient Mercator computation. You fit the whole thing in memory, and that's why you can do it quickly. But all of a sudden I.
00:55:14.914 - 00:55:48.208, Speaker B: You want to have a merkle tree that's distributed across multiple machines. Now maybe every production of an artifact that requires authenticator reads is a distributed algorithm. This starts to be quite tricky because you have to scale that in addition to scaling the execution. With us, we've set up the storage in a way that we don't need a global merkle tree to serve authenticated reads. We don't have that bottleneck of propagating up and competing a new state route. I think if you're going with that architecture, which, you know, it's the way ETH started, so a lot of folks are reasonably doing it that way. Then I think it becomes very hard to scale storage.
00:55:48.208 - 00:55:59.100, Speaker B: But for us it's more like, well, allocate a new rocksDB instance and decide like, you know, which object IDs belong in this one and which object IDs belong in the existing one. It's a much easier problem.
00:56:00.400 - 00:56:03.060, Speaker A: So does the answer still storage.
00:56:04.760 - 00:56:06.380, Speaker B: For us or for the space?
00:56:07.280 - 00:56:11.998, Speaker A: I would say particularly missing a. Yeah, for us, particularly.
00:56:12.094 - 00:56:56.690, Speaker B: I mean, I think for us. And even though I just finished speaking about how much we're going to improve on latency, I still think just turning the crank as much as possible there and really getting to the theoretical limits in terms of the protocol design but then also doing the engineering to make sure you're right on those limits or as close as possible is really going to be the thing. Just because I think it's really, really hard to have a low latency. It's really, really hard to have low latency transactions in a globally distributed network with hundreds or thousands of validators. And I think every millisecond of latency that you can shave off maybe enables some new use case. There are certain trading strategies that work under certain latencies and not others. If you have latency that's too high.
00:56:56.690 - 00:57:34.886, Speaker B: There are some games like consumer experiences that are going to be less smooth or just won't work at all. I really think that's the, that's the problem that's never going to go away, and that you always get wins by getting better latency because you enable more use cases and smoother experiences. And it's really, really hard to get it and to keep it consistently because it's both a theoretical and an engineering problem. So I think if I had to say one thing, I would probably say that. And there's so much talk in the space about TPS and throughput, which is clearly very, very important and something that we've been very focused on at the beginning. But I think latency is the thing that affects every user every time they send a transaction that everyone touches and feels every day. Whereas the other thing is something that happens on the edge case of your system that you obviously have to be prepared for.
00:57:34.886 - 00:57:37.690, Speaker B: But it's more of an out there concern.
00:57:38.270 - 00:58:13.670, Speaker A: True. And it's kind of fascinating to me. I mean, going back to when I was in product, how much time and engineering effort would be used towards trying to shave off 100 milliseconds from a checkout experience. And the bounce rate if that latency was high, and people in web3 are not fine, but uh, seemingly okay with multiple second latency, at least initially. I don't think that is going to be really scaled to mainstream adoption.
00:58:14.090 - 00:58:30.150, Speaker B: No, that's a hard problem. So many of these other things, like requiring to install a wallet, like needing to go and get the native currency, it just limits what you can do. You can still do a lot within that closed off garden, but let's open it up and see what else we can do.
00:58:30.900 - 00:59:25.000, Speaker A: Very true. In terms of maybe wrapping it back up as we end the podcast, I think theres a lot of different people that are interested in the suite ecosystem, whether thats the builders or myself on the VC side or other people in the venture capital space looking to either learn more or have that initial spark in the community or application to jump into the suite ecosystem and really take a hard look. I know you kind of touched upon ZK login and I think honestly it's an amazing feature that is absolutely needed. But is there anything else that you would say look into or you're uniquely excited about in the suite ecosystem since you've launched?
00:59:25.660 - 01:00:15.592, Speaker B: Yeah, so I would say a great way to get an overview of the suite ecosystem or some things that are going on is like jump into quests. Like, you know, there are these quests that run, that highlight projects that are prominent projects that are going on this week ecosystem and have different themes. So it's a great way of sort of getting hands on, of like, okay, what have folks actually built? You know, what are the different experiences that are available? How do they compare? You know, sometimes there's a fun aspect of contests or gamification to it. So that's a nice way to get familiar with some of the top projects and sort of get the, get the experience of what it was like for a consumer or a user. And then from the tech focus lens, yeah, I think CK login is great to look at. Of course to take a look at move if you haven't, or if you haven't in a while. I think in addition to that we have really strong builder groups and we're working on technical communication, blog posts.
01:00:15.592 - 01:00:35.880, Speaker B: There's this Sweeney writers group that's really great for that. Our builders hang out in and also with discord that's very active. I think that too. If I want to know what's going on in ecosystem, there's the consumer angle. Then you want to know what are builders talking about and what's coming next. Also the suite developer forum. So I would try to hang out in as many of those places as possible to see what's coming down the pipe.
01:00:36.220 - 01:00:38.680, Speaker A: I see you're very active there, which is very cool.
01:00:39.860 - 01:00:58.450, Speaker B: I try. I think there's nothing more important for me to be doing than to encouraging builders on blocking them and helping them see what's possible. And of course I have to scale myself in doing that. And we have a great. There are great teams both on the sweat foundation side and the mist inside working on that. But I still really enjoy talking to builders whenever I can.
01:00:59.470 - 01:01:40.980, Speaker A: I think that's honestly the alpha within all web3 is just following the builders and these new zero to one primitives where you have something that was not possible before would definitely say SWE and move are both in that category. And that's why I'm so excited about both, is because I truly think it unlocks scalability and new types of applications that just weren't previously possible on kind of like the first entrance of blockchain architecture. So yeah, thank you for building Miss in building SWE and what you've been doing with move, because I truly think it's going to unlock some new stuff.
01:01:41.890 - 01:02:00.010, Speaker B: Thank you for the kind words. I mean, I love that framework. Like, if you have a primitive that's unlocking something fundamentally new and you have strong builders, that's exactly where exciting stuff is going to happen. And we think SwE is a great spot for that. But I think if you follow that around the web3 space, you're going to be right on the bleeding edge and you're not going to miss anything interesting, 100%.
01:02:00.090 - 01:02:27.360, Speaker A: Well, Sam, I really appreciate you coming on the podcast again, sharing all the updates that you've really been putting blood, sweat and tears and also the mist and labs team into making sure sweet unlocks those primitives and can scale when the time is right. And I think you guys are very much on that trajectory, highlighting that, even with doing the most transactions per second out of all blockchains. So again, thank you so much and appreciate all the words of wisdom.
01:02:28.260 - 01:02:34.600, Speaker B: Thanks a lot, Logan. Thanks for having me. It was a pleasure for me to be on, and I really appreciate what you're doing for the space. Love the podcast.
01:02:34.940 - 01:02:35.980, Speaker A: Thank you. Appreciate it.

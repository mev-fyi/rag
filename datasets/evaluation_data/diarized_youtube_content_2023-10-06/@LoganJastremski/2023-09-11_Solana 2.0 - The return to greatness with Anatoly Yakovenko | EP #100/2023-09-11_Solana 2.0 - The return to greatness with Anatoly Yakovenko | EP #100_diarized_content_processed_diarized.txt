00:00:00.480 - 00:00:38.826, Speaker A: These systems are slow, right? Like, you know, when you step back and you think about, well, like, there's no way to make this distributed, decentralized system as fast as Nasdaq and as fast as NYSE. Like, where does the value come from? Why would it ever be competitive? And you actually have to take a step back and try to think about what NYSE and Nasdaq do. They synchronize the world's information. I think a lot of people say they want to infinitely scale blockchains, and they think, they really do think infinity. And that's actually, I think, overestimating demand is as bad as underestimating it.
00:00:38.938 - 00:00:59.954, Speaker B: Solana's core approach is ultimately going back to the beginning, is optimize the network for increasing bandwidth over time, increasing compute with multi core performance over time. And then later on, if these novel network optimizations arise, like data availability, sampling, the network can ultimately add that core.
00:01:00.042 - 00:01:21.796, Speaker A: Value that we want to do is, like, going back to that, let's reduce latency, eliminate fees that are caused by bottlenecks, and, like, really get the fees to be as low as hardware. Because everything else is a tax, right? It's sand in the gears of global finance. It's a tax on every consumer. Like, if we eliminate all that, that's a lot of value that's created for the world.
00:01:21.868 - 00:01:57.496, Speaker B: Put the nail in the coffin. The design is really, the world has latency. It's a big place. You have to ultimately propagate that information to right now, historically, New York, ultimately, in Solana's end state, there will be multiple leaders today, kind of similar to, like, AWS. They kind of have geographically located data centers in different parts of the world. You can send your transaction to that closer leader, and by that time, hopefully, you'll already be in a block and that arbitrage will not exist. Effectively trying to create a more synchronized world system than you would.
00:01:57.496 - 00:02:38.696, Speaker B: If you just have to send all your information to one entity in new, that's basically it. Well, Toli, thank you so much. Round two. Honestly, the last podcast that we did, it was one of my favorites. Deep diving turbine, sea level, kind of talking about multiple leaders bandwidth. And it's been a year since we did the last podcast in person. And I wanted to touch upon some of the things that I feel like you tweet a lot about, but are still not either fully appreciated or you kind of get to insert them into some podcasts, but don't get a deep dive.
00:02:38.696 - 00:03:11.504, Speaker B: So I want to kind of center this around some of the more technical things that you talk about that I don't feel like are fully appreciated. The first one, I think, is the all to all synchronization you touch upon this, and specifically, I feel like the best podcast that you've done are, or I've seen you communicate around the modular summit. But maybe just to kick off this podcast, can we, like, deep dive all to all and sharding and zero knowledge proofs and l two s? And why specifically you focus on all to all communication?
00:03:11.552 - 00:03:48.112, Speaker A: Oh, for sure. This is kind of like the foundation of how I got started with Solana. So, like, I know there's like, this myth of Vitalik playing World of Warcraft and then having the rules change on him and him feeling rugged by the World of Warcraft team. And that's what inspired building trust, minimized computation. This idea that you have a computer that cannot be modified, that everyone knows the rules of. Well, prior to starting Solana, I was an engineer, worked most of my career qualcomm. I was also a hobbyist trader.
00:03:48.112 - 00:04:44.422, Speaker A: I wasn't any good, per se, but, like, I love the idea of, like, trying to parse a lot of data, build, like, algorithms and things like that. It forced me to learn about deep learning and all sorts of other analysis, and, like, kind of just worked well within my, like, kind of signal analysis brain. That's, I think, every embedded systems engineer and ends up working on some kind of signal analysis. So, like, it was fun, but what I noticed is whenever I thought I had an edge, my trades would arrive later than I expected, and then the information that I needed would take too long to sink. So it felt like there was something in this black box that was against me. So when I got the idea for Solana, just like, oh, I can build a really fast blockchain. What is it good for? My immediate thought was, these systems are really, really good for finance.
00:04:44.422 - 00:05:42.272, Speaker A: They have this guarantee that there's a way for me to submit data in a guaranteed way, and it takes at least a third of the network to block that, to start reordering data. And also being part of the network, I have a guarantee of receiving the data as well in a timely fashion. So again, these guarantees, you have to bound them within certain number of milliseconds and stuff like that. But if you architect the system correctly, it takes a very large number of the network to be collaborating in a corrupt way, for you to, like, receive the data later or for you to not be able to submit it in a timely fashion. And that was like, I thought was really really cool, because what we end up with is a system that is run by volunteers. It's effectively open hardware. It might be expensive, or to some people, or to me, like, 350 a bucks a month for a box somewhere is not expensive.
00:05:42.272 - 00:06:37.832, Speaker A: It's very affordable. Me, as a. As a hobbyist trader, I would have gladly paid for that. Like, when the cost, in comparison at, like, Nasdaq or NYSE are, like, tens of millions of dollars per year, right? So, like, this is effectively free for that use case. So, like, if my only cost is the hardware and I get these real time guarantees that I can submit, you know, and I have a guarantee in submitting that information, and I receive the data, it's a really, really awesome value creation for the world. And then the question becomes, well, these systems are slow. When you step back and you think about, well, there's no way to make this distributed, decentralized system as fast as Nasdaq and as fast as NYSE, where does the value come from? Why would it ever be competitive? And you actually have to take a step back and try to think about what NYSE and Nasdaq do.
00:06:37.832 - 00:07:01.152, Speaker A: They synchronize the world's information. There's kind of this, like, a bunch of data. It's kind of in this high entropy state. Nobody knows what the actual offer or on any given asset is around the world. And there's news events that constantly occur. And all this data rushes from around the world, right? From Singapore, from Japan, from everywhere. There's markets and people, like, do stuff.
00:07:01.152 - 00:07:40.556, Speaker A: It's rushing into a single location in New York, and it's all being ordered and synthesized as fast as possible. Well, like, the global information latency is actually the same. It still has to propagate. That news event has to go from Singapore all the way to New York before a trader can look at it and then compare. Does this news actually impact the market or not? So when you think about it from that, there's actually kind of this, like, minimum latency around the world for all the stuff to synchronize. And Solana can be as fast as that. So, like, in comparison, you're not going to get one millisecond kind of trading on Solana.
00:07:40.556 - 00:08:44.850, Speaker A: But what you're going to see is that a news event happens in Singapore, that in that market, somebody could, as soon as they see that news, submit a transaction to Solana, and it starts propagating and getting into a block producer immediately. As that news event goes all the way to NYSE, by the time a trader at the New York Stock Exchange sees that news event in Bloomberg. They're going to look at a price on Solana and a price at Nasdaq or NYSE. It's going to be exactly the same. And that means there's no arbitrage of real news value trading between this decentralized system run on open source software by a bunch of volunteers, and relatively cheap hardware, and something that's very expensive, very much kind of an insider's club to get into. That's really, really cool, right? It means we kind of, like, cracked open this, like, very, very hard problem and that thing, right. For that to function, it just sharding is just not a thing that would make it better.
00:08:44.850 - 00:09:20.472, Speaker A: It would actually create two different synchronized states that now have arbitrage between them. So actually, sharding doesn't help. Roll ups don't help. None of the stuff actually helps solve that problem. So this is why in our design and everything that we built, we always thought we have to figure out how we, like, crack open this idea of information synchronously or like, reducing enthalpy around the world, whatever you, however you want to think about it, and be competitive with NYSE and Nasdaq. And that just leaves these other technologies kind of off the table. Sharding is not going to help you.
00:09:20.472 - 00:09:47.900, Speaker A: Zero knowledge proves to really help. All this stuff becomes secondary priority. So this is how we've attacked a problem. And it turns out if you build a system for super high performance, all to all messaging, you actually get very, very good utilization of the hardware, and that's what drives the fees down. And this is something that's very counterintuitive to a lot of other builders in crypto.
00:09:48.990 - 00:10:37.690, Speaker B: I think that's a beautiful setup. There's a lot of things I want to dive into quite a bit. Maybe the first thing is, I think, the ability to actually add a box and actually plug into the network. As you mentioned historically, with NYSE or Nasdaq, they literally give everybody the same cable length, so no one has a slight edge. And please correct me, you're giving everybody the ability, or the Solana labs team has ultimately built the ability for anybody to connect a node to the network and effectively receive information almost in real time as everybody else in the network. And I think that is the big breakthrough. Allowing anybody with relatively cheap hardware, compared to kind of traditional standards, to gain access to that information.
00:10:38.310 - 00:11:07.940, Speaker A: Yeah, that's basically the idea. And I think, you know, my dream is that this becomes, like, the backbone of global finance in the distant future. Like, everything runs on Solana and, like, even Nasdaq and NYSE than run on top of Solana. That's going to take a lot of work. And. Yeah, but, like, 20 years is a short and long time. It's a short time in, like, human timeframes, but in computing timeframe, it's a thousand x in performance under every parameter.
00:11:08.030 - 00:12:07.650, Speaker B: Yeah. Maybe touching upon, like, going slightly deeper into, like, the entropy. And particularly around, as you mentioned, a news event happens in Singapore. It goes to New York, that is transmitted through some fiber optic cable around the world, ultimately ends up in New York, and that trade happens. And I think, as you mentioned, I mean, these decentralized systems, when you start to replicate different nodes, they're always, I mean, you're going to have some real time latency that you're just not going to be able to ultimately be one for one with a more centralized system. And so maybe can you double click a little bit further on kind of how you view these all to all communication channels and really, versus, like, a single entity running it and reducing the arbitrage by effectively already having that price in by the time it hits New York.
00:12:08.190 - 00:12:50.220, Speaker A: Yeah. So you have, like, in a system, like, traditional centralized system, you have an exchange in New York, and all the trades from all the brokers and all these uis, like, from fidelity, et cetera, they kind of go through a bunch of hops and end up at the exchange eventually. And news also gets aggregated as close to co located to these systems as possible. It also goes through kind of a web, but you kind of want to be like, you have your algorithms in a machine that's really close to the New York Stock Exchange, and you're feeding it news triggers after they've been processed to go, like, adjust whatever markets and algorithms people want to do. So for us to be competitive.
00:12:51.920 - 00:12:52.232, Speaker B: The.
00:12:52.256 - 00:13:31.562, Speaker A: Event, if it occurs in Singapore, there should be a short path to a block producer that's closest to Singapore that doesn't have to go all the way to New York and then back out around the world. And the way to achieve that is that Solana right now runs with a single leader per slot. So there's a single leader that's randomly selected globally. You can actually have ten liters or 20 or whatever, however many you want. We'll start with two first, but basically you have two block producers. So now you've cut your geographical latency on average by 50%. When you have four block producers, it's now 25%, you know, 25% distance and so forth.
00:13:31.562 - 00:13:57.386, Speaker A: So you can kind of like, it's almost like Starlink. I don't know if you've ever seen those maps of Starlink. There's right now one satellite that's spinning around the world, and the likelihood that you're next to it is pretty low. But you can keep doubling the number of those satellites to the point where there's basically, like, one millisecond or five millisecond path. And, like, as that number shrinks, the arbitrage that you can get between NySe and Solana shrinks and shrinks.
00:13:57.458 - 00:13:58.002, Speaker B: Interesting.
00:13:58.066 - 00:14:12.430, Speaker A: And I think that actually, there's going to be a flip much closer than, like, five to 10%, because you still have all of this latency of sending all this information to the New York Stock Exchange and processing it along the way.
00:14:12.890 - 00:14:56.852, Speaker B: So just to kind of, like, put the nail in the coffin, the design is really, ultimately, the world has latency. It's a big place. You have to ultimately propagate that information to right now. Historically, New York, ultimately, in Solana's end state, there will be multiple leaders today, kind of similar to, like, aws. They kind of have geographically located data centers in different parts of the world. You can send your transaction to that closer leader, and by that time, hopefully, you'll already be in the clock or in the block, and that arbitrage will not exist. Effectively trying to create a more synchronized world system than you would.
00:14:56.852 - 00:15:00.132, Speaker B: If you just have to send all your information to one entity in New.
00:15:00.156 - 00:15:30.276, Speaker A: York, that's basically it. And there's going to be a bit of slicing. So maybe it's 100 milliseconds or 150 milliseconds. That's the slice of the block. And within that block, you may have to have some prioritization and bid for it, but you're going to approach really, really closely to, like, the time value economically of that, prioritizing within that block for the world. And I think, I don't think you can get, like, cheaper than that.
00:15:30.348 - 00:15:30.788, Speaker B: Yeah.
00:15:30.884 - 00:16:36.322, Speaker A: And this is like, I think the really cool thing is that, like, the cost, you know, I think, of finance is like a, like a regressive tax. It doesn't itself create any value. Right? Like, every time you pay, like, do a transfer, and there's a few bits here, a few bits there, it's like people charging to move numbers around a computer, and, like, there's got to be some minimum price to it. And, like, I think the fastest synchronized global state machine that, like, lets you synchronize as much data as possible with the lowest latency it's going to have the lowest amount of tax on the world. So this is kind of like what we want to get to that, like, smallest time slice that we can have around the world for everyone to send their data to and have the minimum amount of priority that they're paying over time and, like, have that stuff resolved. And I think that's like, you know, the best financial rails for the world with the least amount of value extraction. It's the one that should win over the long term and, like, benefit the world the most, right? Like, within 100 years, you imagine, like, what does finance looks like? It has to run on something like this.
00:16:36.322 - 00:16:46.170, Speaker A: Like, it has to run on the cheapest, fastest rails possible. Otherwise we're kind of wasting GDP growth, we're wasting human resources.
00:16:47.470 - 00:17:28.688, Speaker B: It's a beautiful vision. I'm definitely looking forward to that. Kind of staying on the topic of the all to all communication. I think you talk a lot about weather charting, different architecture designs, L2s, whether fraud or validity proofs, zero knowledge proofs, those ultimately do not solve this kind of global synchronization problem. They ultimately isolate states. And I think maybe visualizing it's kind of going back to that New York model. You're sending all your data to a single entity that's in one part of the world.
00:17:28.688 - 00:17:38.780, Speaker B: Can you maybe just dive slightly deeper for the listeners and kind of compare and contrast why all to all should be focused on versus these different methods.
00:17:38.820 - 00:18:33.006, Speaker A: That, yeah, so the reason why you need all to all is because we want to guarantee that if you're a participant in the system, that you receive the information as fast as possible, too. And you can't guarantee this in every possible way. But what we can do is that because of how data is propagated to all the machines at the same time and they all collaborate, retransmitting it, it requires a certain percentage of the network to be malicious and try to withhold that information for that process to slow down. And that percentage is roughly like a third, you know, like one third of the network has to be byzantine. So, you know, in, in like BFT terms. So that means that we can have some guarantees, looking at the Nakamoto coefficient, that if there's enough participants that are all independent, it's very unlikely for all of them to be malicious. And then we can, if they are, we can detect that and slash them and do all sorts of stuff.
00:18:33.006 - 00:19:16.204, Speaker A: Kind of makes it robust from that point of view. And for that to work right for that time synchronization like speed to work you have to propagate the data to everyone. As soon as you shard that or start doing tricks like that to reduce the cost, the hardware resource cost, and the network to do that, you're effectively letting some part of the network get the data first. That means that they get to see the information first, and they can be the first to trade and kind of extract value from the system that way. And this is like what I really, really want to avoid, because I want to be the hobbyist. That's like, oh, I have a very clever algorithm. Ten years ago, I was messing around with deep learning.
00:19:16.204 - 00:19:36.380, Speaker A: Maybe I was first to do that. And there's no way I could have won even if I had an innovation, because I was just getting beaten on the physical access. Bye, all the big boys. So that's really, I think, like, the problem that I want to fix and make sure that it's impossible for the big guys to extract value that way.
00:19:36.460 - 00:20:00.224, Speaker B: Interesting. And to kind of double click on that. I mean, some people say you can have all, or you can have all to all within, like a single l two in terms of having like, going from a sequel sequencer to multiple sequencer. But the end state would look similar to Solana.
00:20:00.272 - 00:20:05.824, Speaker A: Yeah, but that's just saying that Solana could be an l two of Ethereum. If Ethereum has enough data available, I.
00:20:05.832 - 00:20:07.140, Speaker B: Wouldn'T be banned later.
00:20:08.520 - 00:20:19.060, Speaker A: And Ethereum could be an l two to Solana. The l two thing is just a bridge. That's all it is. People should stop thinking of it. Anything else but a bridge.
00:20:20.570 - 00:21:03.988, Speaker B: I do want to get up to Altoo's, but let me first, one thing that you also mentioned earlier on was kind of amortizing the costs of bandwidth to all nodes in the party. And I think this is actually really fascinating. And what you ultimately communicate is that, like, being able to get the transaction costs to facilitate this on chain trading or whatever it may be as close to bandwidth as possible. I think we'll kind of skip the, like, core bandwidth part, because we touched upon that in the last podcast. But can you touch upon, I mean, how you kind of amortize the costs of, like, the bandwidth to all nodes?
00:21:04.124 - 00:22:17.456, Speaker A: Yeah, so, like, the way that sharding and all these other systems work is that they basically say it's too hard to propagate a lot of bandwidth in any given system. So we're gonna limit the subcommittee to, let's say, 100 nodes or 200 nodes, and each one will maybe do like, one to two megabytes per second, and then they confirm and then send that data to the rest of the network and the beacon chain. Or like, there's effectively some design where there's a single thing called the beacon chain that coordinates a bunch of subcommittees that all sync data, and each subcommittee has limited bandwidth. So the problem there is that you have a small channel, right? Like with one or two megabytes of capacity. And the way that fee pricing works is that your fees should be effectively based on the remaining capacity in the channel. And it kind of can stay pretty low up until it hits 100%, and then it's going to spike in a very, to a very high amount. You can think of it almost like when the Suez Canal was blocked by a single ship, right? The cost to get goods through that canal became very, very high because there was very limited bandwidth.
00:22:17.456 - 00:22:58.610, Speaker A: Now. And if you had, if you had a bunch of, like, if the Suez canal was smaller and was like 100 small capacity channels, the problem would be even worse because you have one ship that could block the channel. For that channel, the price goes up and you kind of have to reroute to other channels. So ideally, you actually have a channel that is so big that it never hits a capacity limit because you've aggregated capacity across all your channels. And there's tricks to do that when you have a bunch of small capacity channels, but it becomes harder. You're kind of introducing delays and synchronization. And I kind of wrote this out in a tweet.
00:22:58.610 - 00:23:37.010, Speaker A: Like, imagine Solana was an Ethereum. L two, what would that look like? Solana at ten gigabits would require, like, 600 subcommittees on Ethereum. That means that for every Solana, every second, Solana is bidding on 600 subcommittees on Ethereum to include Solana data, different data, right? And, like, all 600 have to accept without reordering. And if there's a reorder, Solana then has to go and, like, make sure that block gets retried. And you probably see that happening once a second. So, like, yeah, go ahead.
00:23:37.470 - 00:24:02.200, Speaker B: I'm just going to try to. It makes sense to me. But I want to summarize it. I mean, today, I mean, the ultimate bottleneck in these blockchains is blocks, or how big the blocks can be. And because that blocks your data, you have to propagate the blocks to all the nodes in the network. Today, Ethereum has relatively small blocks. With 4844, they're introducing slightly more data.
00:24:02.200 - 00:24:37.270, Speaker B: And with these committees for dank sharding, it's going to be like 1.3 megabytes per second in Solanas, they're much bigger blocks. They're much faster. Fire dancer is working on a client that I think ten gigabit are a target, and 1.3 megabytes per second versus gigabytes is totally different. So as Anatoly was explaining, ultimately you're going to need 600 ish ethereum bandwidth channels to just be able to settle for Solana, ultimately making prices much more expensive. Correct.
00:24:37.890 - 00:24:53.400, Speaker A: You kind of like, think of it as like, there's capacity right in the network. Like, think of it as like, you know, Suez Canal, right? Shipping, if you have a lot of small channels, like, one big boat is going to clog up a single channel.
00:24:54.220 - 00:24:59.080, Speaker B: So you're clogging all the multiple channels because you're exceeding all the bandwidth for everyone.
00:24:59.620 - 00:25:37.190, Speaker A: And the pricing in that channel, for that specific channel is going to shoot up. And then you have to reroute to a cheaper channel, if you logically can, to build the systems that can reroute logically, that pushes complexity up to the top of the stack, and that will, that will delay finality, because now you have to deal with channels that could reorder potentially and things like that. You have to synchronize all of them, make sure all of them get synchronized. And that's more complex. Versus you have one giant Suez Canal that's so big that it never fills up. That means that you're never going to run an auction that runs out of space.
00:25:38.010 - 00:26:06.780, Speaker B: And can you talk about, I mean, so obviously to get more and more bandwidth, kind of the key places to do that is like data centers or they traditionally, historically have had the highest bandwidth and the lowest costs. I think latitude provides like sixty four cents per terabyte of egress, which is pretty crazy. Can you talk about just that? Raw data costs versus, like, home validators as well?
00:26:07.330 - 00:26:33.676, Speaker A: Yeah, so, like, basically bandwidth prices drop roughly like two to three years by 50%. And that's called the Nielsen's law. And there's a lot of pressure to do that simply because people want to do more FaceTime or more high video content. Now, like, more AR and VR content is coming online, and that's even more bandwidth intensive. And it's just kind of like never ending process. Right?
00:26:33.708 - 00:26:37.040, Speaker B: Like, does bandwidth also double as it drops? Like the.
00:26:37.380 - 00:26:56.292, Speaker A: So it takes a little longer. There's like a new standard every decade. The one gigabit standard is 23 years old at this point. It was defined in 99. The ten gigabit is ten years old, I think. So roughly every ten years at least a ten x. There's like a new standard that rolls out.
00:26:56.292 - 00:28:02.052, Speaker A: The next one that they're working on is a 400 gigabit standard. I think that's basically been defined as well, but this is something that just massive industry behind it. Trillions of dollars of infra spend and engineering and R and D, that's happening. Why is it cheaper to have these large nodes that can manage the system even though they're all talking to each other? It seems expensive is because of the kind of pricing that you see at a data centers, and that effectively translates into home pricing as well. Just maybe like an order like two to three x higher is that when you're charging like even a dollar per terabyte and you have 10,000 nodes, each one of those nodes has to transmit all the data that it receives out. So every node is doing ten gigabits or one gigabit worth of work. The price per byte is 10,000 times right times $1, divided by 1 tb, times the overhead that you have in a system like turbine, it's about four x.
00:28:02.052 - 00:28:09.396, Speaker A: It comes out to something like four times ten to the minus $8 per byte. So it's very, very cheap, which is.
00:28:09.428 - 00:28:11.236, Speaker B: Only slightly more than the pure egress.
00:28:11.308 - 00:28:20.610, Speaker A: Its egress itself, it's 10,000 times bigger. Well, like 40,000 times bigger than, like.
00:28:20.650 - 00:28:24.466, Speaker B: The cost for the system overall. But for the individual validator, for each.
00:28:24.498 - 00:28:47.574, Speaker A: Individual validator, they're paying just their ingress cost. But because there's 10,000 validators and there's, like, forex overhead, you can think of it to the user. This network is going to be 40,000 times more expensive than my normal connection sending it into AWS. And that sounds massively expensive, but when you actually run the numbers, it's four times ten to the minuse $8 per byte.
00:28:47.742 - 00:28:48.970, Speaker B: Bytes are very small.
00:28:49.430 - 00:29:34.408, Speaker A: Bytes are very, very cheap. A single transaction is roughly 256 bytes on Solana, maybe sometimes more expensive. But you can think of it as like, the costs per byte on Solana, right? Like, when you submit a message is very, very negligible. Ten to the minus eight, even times 1 kb, you're talking like zero, zero message. And that is much, much higher than if you had to pay that for every FaceTime call. If you had to pay that, that would be expensive because you're transmitting a lot of data peer to peer. But for something like a network that, like a decentralized peer to peer network for finance, it's very, very cheap.
00:29:34.408 - 00:30:10.262, Speaker A: It becomes a negligible cost to finance. And this to me is what finance should cost. It should cost the cost of the hardware, maybe with some multiple for all the hardware providers to make a decent revenue. But even with like a forex multiple on top of that, it's still effectively free. And subcommittees cannot achieve that because we're not seeing the same pricing coming out of subcommittees. Even though if you think about it, the numbers should actually work out better in their favorite because they have fewer nodes. So that multiple shouldn't be 10,000 times, it should be like 200 times.
00:30:10.262 - 00:31:00.460, Speaker A: Because they're limiting bandwidth to the point that those channels get saturated. They hit that inflection point where you start having to auction the bandwidth to the highest bidder. And that causes people to overbid, not based on the raw cost of the materials, but overbid based on the person's need to submit the data, like based on their economic cost. And that's a tax that's like, effectively, you're now taxing finance at a premium that's much, much larger than the hardware cost. And this is like why four years or three years, whatever, since Solana launched and we've seen L2s and all these other networks launched, they've not been able, like, none of them have been able to get their transaction costs anywhere near as close as Solana. And like, this is going to be true next year and this is going to be true the year after that.
00:31:00.920 - 00:31:40.460, Speaker B: There's so many things that we are going to dive into, I want to say quickly, just on the channel utilization, I mean, so all to all communication is brutal on votes or coming to a consensus. Probably one of the least efficient kind of consensus algorithms. Other blockchain architectures have come forward with different type of consensus designs. Probabilistic, whether a dag versus kind of single leader. Can you talk a little bit just about probabilistic architecture and maybe relate that back to channel utilization?
00:31:41.160 - 00:32:35.810, Speaker A: Yeah. So there's other approaches that people have tried, and you can think of it as like leaderless, and think of a network with a bunch of different nodes, like 1000 or 100 nodes, whatever, and each node has one gigabit worth of bandwidth. So each one can do one gigabit up and down. If you don't know, if you don't have a dedicated leader and the bandwidth isn't allocated to them, like to a dedicated channel, you can have two nodes at the same time because they can't all know exactly what everyone else is doing. Start submitting one gigabit worth of data at the same time. So now, because the rest of the network is all limited one gigabit up and down, at some point, somewhere, someone's going to see two gigabits worth of information in, and that's going to saturate them. And this is the point where that network is going to break, and then we'll have to propagate information back, saying, hey, I'm saturated.
00:32:35.810 - 00:33:12.262, Speaker A: I need you to back off. And you need to reconcile a difference and effectively deal with that collision. And that collision is effectively noise in the channel. If you think of the network as having one gigabit worth of bandwidth, as soon as it crosses that limit, that capacity limit, it's no longer able to transmit information globally. So it's in a noisy state. It's effectively like, you have way too much noise to signal, and you're not like Shannon's law applies there. You start dropping bits.
00:33:12.262 - 00:33:52.786, Speaker A: So very, very simple analogy, but very much like Shannon law very much applies here. And you can think of this in radio, same problem. The first radio protocols that people have built, one of the first was called aloha. You have a bunch of towers. They randomly transmit, and if there's a collision, they have to back off at some random interval. And there's more complicated algorithms decide how to back off, but they have to back off, because if two transmit at the same time, you overwhelm the channel with the amount of data that you're sending, and nobody can decode what bits are being transmitted. And that's exactly the same thing.
00:33:52.786 - 00:34:17.810, Speaker A: And there's a limit to how many concurrent transmitters can participate in that network. And that utilization of that channel drops at a pretty significant speed. It's almost exponential. I forgot what the number is. But as soon as you start crossing 100, 200 participants in those networks, you have a very, very fast drop off.
00:34:17.930 - 00:34:26.186, Speaker B: And just to re articulate, I mean, the main thing ultimately, is because, I mean, in Solana with proof of history, you have a dedicated leader that knows.
00:34:26.298 - 00:35:08.089, Speaker A: So, yeah, so, like the first, when people started building cellular networks, and they're dealing with many different transmitters, right? Their cellular network means every phone can transmit, and you're dealing with tens of thousands of subscribers per tower. You're going to have a lot of collisions. A lot of people are going to start transmitting at the same time. So the way that they've dealt with this is called time division, multiple access, where you have your frequency that you can divide, but then you also have your time slot. And you assign each phone a specific time slot. When they can transmit over a specific frequency channel. And because they're the only ones that can do that, they don't run into a collision and information can propagate through.
00:35:08.089 - 00:36:02.370, Speaker A: And this is something that's been done probably since the fifties, right? Like, if you look. But, like, it's a very, very old idea, a very old protocol, and it works, right. It actually prevents these collisions from happening, and that fundamentally passes more information through the. Through the system. So the idea with proof of history was, like, the reason why I started building Solana was that when I had the idea for proof of history, I had a very high level idea that there's a way to synchronize time in a permissionless way globally without having to dealing, without trying to build a clock synchronization protocol that's permissionless, that deals with adversarial people, submitting invalid timestamps and stuff like this. I don't know if it's possible to even do that, but it's hard. It's even hard to do that.
00:36:02.370 - 00:37:02.234, Speaker A: When you're dealing with in, like, a network, like Verizon, like, when just systems are not even malicious that just go out of whack from, like, you know, power failures or component failures and stuff like this. It's a big pain in the butt to build those systems. So it would have taken, like, as much work to build back clock synchronization protocols as it would have built to the entire network. So when I had the high level idea that, like, proof of history is, like, a way for us to clutch together, this way to force people to take a specific time slot without having to deal to build this protocol, that was like, okay, it's going to be much, much easier to build the rest of the network, and we can utilize all the bandwidth available to the nodes because there's no collisions, and the system can be very, very efficient. So that was kind of the kick that I had, like, oh, okay. I know I can build effectively something that's going to look like TDMA. We're not going to have any collisions between block producers.
00:37:02.234 - 00:37:04.630, Speaker A: And I think we can be very, very efficient.
00:37:05.770 - 00:37:46.454, Speaker B: It is fascinating. I mean, ultimately. So, I mean, to take a step back, there's kind of the leader or leader design that Solana architecture has chosen. There's different architectures that dags or leaderless designs. But in those leaderless designs, when you have multiple parties ultimately sending large transactions to the network, the network has to kind of come to a consensus. There's only a certain amount of channel capacity and bandwidth, and that causes the network to be, it has to back.
00:37:46.502 - 00:37:48.210, Speaker A: Off and deal with consensus.
00:37:49.190 - 00:37:50.406, Speaker B: It has to come to agreement.
00:37:50.438 - 00:38:12.338, Speaker A: Yeah. It has to deal with the fork that occurred. So in a very, very simple, the simplest protocol is bitcoin. Right? So the reason why bitcoin is ten mega ten minute blocks is because if you shrink the block time to 400 milliseconds, you're going to have two different block producers that solve the puzzle at the same time around the world before they saw each other's blocks, before they.
00:38:12.354 - 00:38:14.186, Speaker B: Come to a consensus with the rest of.
00:38:14.298 - 00:38:45.016, Speaker A: Before they know of each other. Right. So that block has to propagate from block producer a to block producer b. And b will switch, you know, it's fork, but that doesn't happen. So now you have two head pointers, two different forks that are proposed on the network, and those have to resolve. And that means that your amount of information that you're transmitting is dropped by 50%. So if two block producers solve the puzzle at the same time, you've now cut your channel capacity by 50%.
00:38:45.016 - 00:38:56.898, Speaker A: If three do, it's by a third, right? So you kind of have this like the lower the block time or the lower the difficulty. You have more concurrent forks that you have to deal with. The lower the actual effective channel capacity.
00:38:56.994 - 00:39:47.732, Speaker B: Interesting. So ultimately, I mean, when I talk with DAG consensus experts, they all kind of tout, whether it's like probabilistic or they're able to increase throughput by like a two x or a five x with like this leaderless design. And because they've chosen that DAG architecture because it is leaderless, ultimately, the more parties within that network that are trying to broadcast that will effectively at scale reduce the ability for bandwidth to be utilized to its full capacity, ultimately kind of making some of those benefits and consistency or whatever less performant than if you would have had a leader and kind of do proof of history.
00:39:47.876 - 00:40:27.774, Speaker A: Exactly. And it kind of like, it's counterintuitive. You know, every node on Solana submits a vote for every block. So you can think of it as like thousands of votes. So if you try to optimize that away, like Avalanche, I think, and Snowflake are really brilliant protocols that reduce the number of consensus messages in the network. So imagine we spent all our engineering time and we reduced the votes from 4000 to 400 /second that seems like a huge win, right? In capacity. In reality, what we should have been spending our time on is doubling our capacity, going from like 10,000 messages per second to 20,000.
00:40:27.774 - 00:41:25.700, Speaker A: Because that gain, right? Like just working in very, very, like old school optimizations, figuring out where we can use twice as many cores, looking at like flame graphs and like doing benchmarking, that gain gets us from extra capacity goes from 5000 to 15,000 versus we get like 5000 more. So we get, you simply just like get more out of like sitting on the exponential growth curve of hardware than you do out of anything else. And that doesn't mean that you can't apply those optimizations later or whatever. It's just that the way that hardware expands is just really, really fast. It's just two years may seem like a long amount of time, but it takes a long time to build the software. It takes a year to go and do these optimizations and prove them out and do all this work. And that's effectively like you're halfway into your hardware upgrade cycle.
00:41:25.700 - 00:41:53.500, Speaker A: It's just like not worth your time because as the hardware improves exponentially, that difference between 4000 messages per second or 400 messages per second gets smaller and smaller as it becomes a smaller and smaller chunk of your overall capacity and it just becomes irrelevant. Like, okay, we optimize this one little piece and it has like 5% difference on the remaining capacity. Like, who cares?
00:41:54.640 - 00:42:33.346, Speaker B: So today, a lot of different teams, because the all to all communication is pretty brutal, have really optimized consensus around lowering votes. But over the long term, with this all to all communication, by increasing bandwidth, you have more allocations for either increased decentralization or increased TPS for application engineers to build novel applications on the network. And Solana's whole point of view is, even though today the votes take up the majority of the bandwidth over the.
00:42:33.378 - 00:42:58.512, Speaker A: Network, they don't take up the majority of the capacity, they take up the majority of the current use, because there's just, there's constantly, there's a very large number of validators in Solana, right? It's half of Ethereum. Even though Solana does more application transactions than all of Ethereum and all its l two s combined, it's just still like 400 or something like that per second.
00:42:58.696 - 00:43:23.770, Speaker B: And eventually, when you increase more bandwidth, when you increase more compute, if nodes stay the same on the network, you would have increased capacity for transactions. And so instead of saying, today there's 5000 votes, we need to make that 500, you just increase the raw resources of bandwidth and compute, and the network has more.
00:43:25.430 - 00:43:35.694, Speaker A: Within two years, latitude is going to offer twice as many cores for $300, right? And the pricing is going to drop from sixty four cents per terabyte to thirty two cents per terabyte.
00:43:35.742 - 00:43:36.110, Speaker B: Yeah.
00:43:36.190 - 00:43:55.438, Speaker A: So, like, why, why bother working on this, like, kind of optimization that's very much a very small constant factor improvement when I'd rather have all the engineers figure out, how do we make sure that when the number of cores double that, we just naturally scale elastically to take advantage of them?
00:43:55.614 - 00:44:34.172, Speaker B: At what point in time do you think ultimately it's up to, I mean, going back to the alt all communication, one of the very interesting things of Solana was being able to contribute a node to the network. As you contribute more nodes to the network, the communication overhead does increase. Do you think at some point in time the network is going to have to choose, hey, we should stop node production at 10,000 or 20,000 just so we have more room for applications? Or is it just the fact that bandwidth and compute are going to continue to increase over time and you can just scale both?
00:44:34.296 - 00:44:57.076, Speaker A: I'd be really surprised if we run into that limit. I think it's possible, but you can definitely then just have, like, do the work. We haven't done this, but you can have two computers per validator. Fire dance is actually set up really well for this. So once fire dancers out, their design is very much scalable across many two.
00:44:57.108 - 00:45:00.680, Speaker B: Different machines, you can so, like, enter validation.
00:45:01.080 - 00:46:07.906, Speaker A: It's just like, we haven't done that work. It's just really, really unlikely to need it because you can get away with double two socket systems. Four socket systems are rare, and there's not as much benefit to them, but two socket systems are pretty easy. The thing is that when you look at crypto, bitcoin's peak market cap was, what, 2 trillion or something like that. There are about 12,000 computers securing that. My guess is that that's kind of like the upper bound of what you need to provide very, very 15 nines of guaranteed security across the world, that it's very virtually impossible to go and break all 12,000 systems and corrupt our state, because you only need one with the correct state to continue. So, like, at a certain point, just the amount of shared security that the system has created is so large that you're seeing very, very small marginal benefits going from 15,000 to 100,000 nodes.
00:46:07.906 - 00:46:43.960, Speaker A: So, like, yeah, it makes sense to me. So that's kind of like, once we hit that, like, Solana has massive product market fit, everyone's adding no's, it gets to like that 12,000 point. You probably don't need more block producers than that. It's very unlikely that people are going to want to even run a block producer because of services like Jito and things like that. Start aggregating block producer services and give you access to these high level features that are programmable. You see that just normally occurring in the markets.
00:46:44.780 - 00:47:22.110, Speaker B: I think in general it's a lot of confuses me, but there is a lot of misinformation or just lack of education. I think it's definitely, since we did the podcast last year, amazing in terms of like community and what kind of fighting the good fight and misinformation, but I mean, yeah, to your point, bitcoin had like approximately 12,000 full nodes. Ethereum has about half that, 6000 and Solanas right behind that with like it is very impressive just how many actual phone nodes there are kind of syncing all the state globally.
00:47:23.090 - 00:48:01.958, Speaker A: And like my belief is that it's very much product market fit driven, that's kind of the leading thing. And like the nodes spin up because people want to use the state and want to get access to the state. And like folks like Magic Eden, they want to have the best ux. So they want real time access to the state with as many guarantees as it can. So when somebody does a trade that NFT pops up as fast as possible in their UI and people have that like snappy feeling, right? Like all that stuff is really driven by like real businesses having demand on like I want this data as fast as possible. And to them the hardware costs are like negligible.
00:48:02.014 - 00:48:28.990, Speaker B: Like it is interesting. I mean, you look at like just like cost per cost. I mean, with Ethereum, it's not like Ethereum has ten x more than nodes just because they reduce cost by ten x. I mean, to your point, like if it is valuable to run a node, people find a way to run a node. It's not typically just cost for the sake of cost.
00:48:29.570 - 00:48:49.608, Speaker A: Yeah, you start really getting very little marginal benefit cutting the cost below that. And this is why a lot of Ethereum nodes run on like cloud and AWS. Because even though that basically like puts like AWS, Ethereum nodes pretty close to what it costs to run a Solana bare metal node, that's kind of funny.
00:48:49.624 - 00:48:50.608, Speaker B: Because egress is so expensive.
00:48:50.664 - 00:49:11.780, Speaker A: Because egress is so expensive and you're dealing with like cloud provider costs. Yeah, you're kind of like, okay, like it's at that marginal price where people would rather pay for the convenience of running stuff on cloud versus like figuring out with like the friction of running stuff bare metal. But like that's, those are like at that point micro optimizations.
00:49:11.940 - 00:49:49.654, Speaker B: Interesting. Maybe next topic that I kind of wanted to touch and I think we've kind of have on a high level, is really kind of, there's two schools of camp on scaling data availability. One is kind of increasing. I think everybody actually agrees that you have to increase throughput. It's just like do you do sharding on the data availability layer, do you do add some data availability sampling? Do you keep it all integrated? Do you do volitions? It's just kind of moving around. You can't eliminate it. I think everybody agrees that it has to be done.
00:49:49.654 - 00:50:11.170, Speaker B: But the two primary school camps, or at least schools of thought that I hear talked about frequently, is kind of the Solana approach and more so recently the Eigen layer approach. Can you kind of touch on maybe the differences between the two? And again like how Eigen layer is perhaps approaching it versus like the Solana camp.
00:50:13.550 - 00:50:18.526, Speaker A: Eigen layer, as in like the restaking approach to provide security for Ethereum.
00:50:18.598 - 00:50:38.330, Speaker B: Well, they're going to do data availability sampling. I've actually asked Sharama a lot post a paper. They haven't done it as of yet. They're going to, I think it's do like polynomial commitments for data chunks, but ultimately they don't reassemble those data chunks.
00:50:38.790 - 00:51:22.232, Speaker A: Can you, so all that stuff is fine. I think those are optimizations that just want to provide some security, whether like economic, through restaking to Ethereum or like through sampling. You have like guarantees that if you see these many samples and you're not eclipsed by an attacker that has like perfect network knowledge, that the data is probably available. So you can have like a like client that can confirm that specific data availability subcommittee hasn't withheld data. I think all those approaches increase the security of the system to some degree. The question is like for that real time trading use case, you need the data to propagate globally.
00:51:22.296 - 00:51:23.416, Speaker B: So it goes back to the Alt.
00:51:23.448 - 00:52:14.702, Speaker A: All, and that also provides the same guarantees. Now it may be cheaper to provide good enough security guarantees with these other approaches, but they don't satisfy this. I need this data in real time as fast as possible. I need it globally available to everyone that's a subscriber. Now you can like, if you have that like all to all subcommittee that's already built, you can add actually data availability sampling on top, and you can do all these other things for light clients that may want to just have better security guarantees on the network. But all those protocols, they're kind of doing what already happens just through informal side channels. If the majority of Solana nodes become corrupted and withhold data, all the other nodes, even if they're not staked, RPC nodes, etcetera, that see that data withheld, they're going to fall behind.
00:52:14.702 - 00:52:43.020, Speaker A: Their pager duty is going to go off. Those engineers are going to go online. They're going to talk through side channels that are very hard to block. You may be able to block things on the network layer, but you can't really block the social layer. There's just too many ways that people start communicating and flags are going to go off. Circle is going to freeze their mint and burns, binance is going to freeze deposits, et cetera. You're going to see these cascading effects, and that may take hours to resolve.
00:52:43.020 - 00:53:43.544, Speaker A: But that actually is what happens in these networks. This is why they're so robust, that it doesn't matter if you control 100% of the stake. That stake itself is a very small part of the network. All the other services that are running on top, that are monitoring the network constantly, all those other full nodes are effectively also part of the security of the system, and they provide really strong signals to users, whether the network is healthy or not. And, like, clients are really cool, because for some of the failures, you can automatically detect that the network is withholding data and trying to propose invalid blocks. And in a short amount of time span, that's reasonable to, like maybe a minute or something like that. A lite client has guarantees that they've probably sampled enough nodes and waited long enough that if there is a fault, that it had that time to propagate to that lite client, and those are all awesome and can be built on top of Solana, and there's work in the community, like tiny dancer to add those.
00:53:43.544 - 00:54:07.810, Speaker A: But fundamentally, those are optimizations over the kind of security that already happens, as any single full node can go and say, hey, holy shit, the network just finalized an invalid block. And here's the snapshot in the ledger, and it'll take five minutes for anybody to go download that and verify and see, oh, wow, something happened. We got to stop everything.
00:54:08.390 - 00:54:51.158, Speaker B: So Solano's core approach is ultimately going back to the beginning, is optimize the network for increasing bandwidth over time, increasing compute with multicore performance over time. And then later on, if these novel network optimizations arise, like data availability, sampling, the network can ultimately add that. And it's not necessarily unique. It doesn't totally provide performance benefits. It could provide kind of security benefits, but ultimately scaling the network with bandwidth, with computer and then later optimizing or adding in these optimizations can be done.
00:54:51.294 - 00:55:16.060, Speaker A: Yeah. Yep. Because the core value that we want to do is, like, going back to that, let's reduce latency, eliminate fees that are caused by bottlenecks, and, like, really get the fees to be as low as hardware. Because everything else is a tax, right? It's a, it's sand in the gears of global finance. It's a tax on every consumer. Like, if we eliminate all that, that's a lot of value that's created for the world.
00:55:16.760 - 00:55:57.054, Speaker B: Interesting, very interesting. Okay, well, moving on slightly, I feel like you've been turning up the dial in terms of l two s or bridges checkpointing. I think some of your tweets that have done fairly well really talk about fees. And I think when the l two conversation really begun, it was not just kind of moving execution from the base layer to an l two, it was also the fee reductions. Can you talk more in depth, specifically around the fees component of L2s versus having them all integrated in a chain like Solana?
00:55:57.222 - 00:56:25.384, Speaker A: So there's two things that cause fees. One is the channel. Like the overall capacity of the network drops. And this is kind of like there's a big ship that gets stuck in so s canal kind of problem. So like your, the amount of throughput that the network can do drops. And when you think about like L2s and where they help is that you have compute limits. You have a single thread on ethereum that's got to run through all the smart contracts.
00:56:25.384 - 00:57:10.104, Speaker A: And what l two s help is that they skip that part. There's no single thread that's limited by a certain amount of time and resources that can, that needs to execute all the smart contract calls. It just looks at the only thing that it'll two post is like, here's a chunk of data, a bunch of transactions that happen and maybe a state route, and all it's doing is recording on chain. And there's maybe a zero knowledge proof that comes in later that validates it, or an optimistic fraud proof that challenges it. But effectively all it does is post data. So that single thread in the ethereum, l one, that's got to look through all the smart contract calls, just says data's there next, that becomes a very, very fast operation. So you've increased the capacity of how many of these calls you can do there.
00:57:10.104 - 00:57:58.924, Speaker A: So that's no longer the bottleneck in NL two you then have, depending on the design, you have a sequencer, then you have batching that tries to batch all those, all those things have some amount of capacity that they can do. And if any one of these queues gets filled up, you effectively, like, the system is full, right? There's a ship that's stuck in the canal and people, the only way to get to the front of the queue is people are going to increase fees and bid to be first. And this means that you have now multiple use cases that all have some value to be first. They don't know about anyone else's bids, and they all rush in and maximize their bids. Just because now you're effective. Block throughput has dropped. You're only letting a very small amount of transactions through.
00:57:58.924 - 00:58:41.438, Speaker A: And like, there's way too much demand for that, for that amount of, like, capacity that you have in the, in the system. And that can happen, like, in any one of these queues. So as soon as one of these queues is saturated, fees go up. Everyone bids to be first or to be included in the queue as fast as possible. And that, that creates those like, kind of fee spikes. But even if all the queues had infinite capacity, the reason why fees may go up is because you still have economic value that's in the state. And like, you can think of that as like an NFT mint or a liquidation in a defi protocol, or like effectively an offer for something, hey, I'm selling x for y dollars.
00:58:41.438 - 00:59:25.302, Speaker A: Somebody sees that that's worth y plus one dollars, right? And everyone in the world, because this, a public chain, sees that that's worth y plus one dollars. So that means everyone's going to bid at least one extra dollar to be first to take that offer. And that kind of like, fee spike, you can't avoid. It's just that's kind of like a nature of the hotspot problem. You have a single chunk of state that has certain amount of economic value to the world. People should bid up to that economic value. And what you really, really want to have is a system that doesn't get saturated by everyone bidding to get access to that first, to be first for that particular state.
00:59:25.302 - 01:00:17.220, Speaker A: You want to allow that state to be resolved and then another piece of state to be resolved at the same time for a different price. And this is what we built with localized fee markets. And there's no reason why l two s can't do this. But then they kind of effectively have to start rebuilding a ton of the work that Solana has done. Okay, you got to have parallelism in the execution engine that figures out how do we asynchronously compute the state route, you have to then have isolation in the way transactions are submitted. They have to specify, each transaction has to specify which part of the state it's touching and how much it's bidding to be first, and all the queues that lead up to that, from the users being able to submit this data to the batching service, the stateroot computation, all this stuff needs to be able to manage this parallelism.
01:00:18.720 - 01:01:18.372, Speaker B: Let's dive into it. Breaking that apart, the first scenario where the sequential running those operations, very similar to the ethereum virtual machine design. Today there's no parallelism. Everything is operated one after another. If you have infinite resources with kind of like the l one and l two, the fees ultimately arise because of at some point during that kind of handoff of operation, a channel gets saturated that could lead to fee spikes, the second one being state contention. So in the ethereum virtual machine, because it is single threaded, you can't isolate specific contracts on the blockchain. You have the NFT mint that's going, you want to do a defi swap, but the NFT mint is making all the fees for everybody much higher.
01:01:18.372 - 01:01:31.130, Speaker B: And because it's not parallel, you can't isolate those specific points on the network. Once you enable parallelism, it doesn't necessarily enable.
01:01:31.830 - 01:02:10.930, Speaker A: So like, the block producers are economically incentivized to sort everything by priority and then take the highest 100 transactions or whatever it takes to fill up the block without looking at the state. They just care about like what's the highest price? And because they're kind of taking blindly off the top of the heap. If there's a mint and 1000 people bid $1 to be first in the mint, my liquidation has to outbid all the mints. My payment has to outbid all the mints and liquidations. Now you get into this gas war that quickly forces everything to be at its maximum economic price.
01:02:13.710 - 01:02:30.802, Speaker B: The kind of modular point of view, at least today, is kind of keep with ethereum virtual machine just for backwards compatibility, but have multiple L2s that can kind of, it still doesn't remove, like, right.
01:02:30.826 - 01:02:35.746, Speaker A: So you have to have a, you have to have an l two that only does payments.
01:02:35.858 - 01:02:36.290, Speaker B: Yeah.
01:02:36.370 - 01:03:23.650, Speaker A: And an l two that only does liquidations, right? Like, but even there you're kind of start. It's really hard to deal with it because as soon as you have two NFT mints or two liquidations for different markets that occur at the same time, you now have a gas floor that forces everyone to bid up to their main, the maximum amount of economic value that they can extract. And that's problematic. As soon as a system can do services more than two states at the same time that are independent of each other, you're going to run into this contention. So this is just a old school database hotspot problem, and the only way to deal with it is with isolation. You have to put each one of these states into their own isolated locks.
01:03:23.770 - 01:03:25.402, Speaker B: Which comes from parallelism.
01:03:25.586 - 01:03:38.266, Speaker A: Right. And they're kind of related. To implement parallelism, you have to implement isolation more or less. There's other ways to implement parallelism, but the way that Solana implemented parallelism is by implementing isolation.
01:03:38.378 - 01:03:38.962, Speaker B: Interesting.
01:03:39.026 - 01:03:39.346, Speaker A: Yeah.
01:03:39.418 - 01:04:02.380, Speaker B: And I mean, so, I mean, yeah, I. The single threaded EVM is ultimately trying to solve this by multiple different L2s, but ultimately you still run into a lot of the similar issues that existed on Ethereum, one with global fee markets instead of isolated fee markets, particularly because of this state contingent issue. And then once you add parallelism, you have.
01:04:02.680 - 01:04:10.280, Speaker A: Once you add isolation, you also add parallelism, because it's trivial to implement parallelism with isolation.
01:04:10.700 - 01:04:21.156, Speaker B: And so once you have isolation, it's kind of a question of why do you need multiple different execution environments and different L2s? And your whole point has always been, you should integrate them.
01:04:21.188 - 01:04:36.032, Speaker A: Yeah. If you integrate everything and you have one aggregated channel, you're aggregating all the capacity. So then that point where you hit 100% capacity and fee spike for everyone in this like asymmetry way is further and further away.
01:04:36.096 - 01:05:12.780, Speaker B: Yeah. Interesting. So I mean, one chatting point that I hear often is around modularity in terms of creating different virtual machines. And today it's so early, kind of, in all these life cycles of the ecosystems, we shouldn't be as opinionated on what the virtual machine is. We should allow the engineers to customize their virtual machines, whether it's single threaded, whether it's parallel, and give them that opportunity to experiment with that. What are your kind of general thoughts around?
01:05:13.360 - 01:06:07.174, Speaker A: Well, like, I think there's. You definitely want experimentation, especially at the front end language layer, at the back end machine layer. The way that I see it is like, is it good enough? Is if I. We can support multiple different front ends. And the way that I think that's been demonstrating that Solana as VM is good enough is that you have things like neon, which is literally EVM re implemented as a Solana smart contract that can run in the Solana runtime. You have Solang, which is a front end to the LLVM compiler that's used to generate Solana programs that's used as solidity. There's a project to implement move, and those are forcing us to update the runtime in ABI to be more expressive, to make it easier first to build these front ends and to make it easier for even Solana programs to interact between each other.
01:06:07.174 - 01:06:27.770, Speaker A: So like, those optimizations are not like they're very impactful. They have a lot of impact on developer experience and things like that. But they don't fundamentally change the kind of the high level runtime design where you have transactions that have to specify state that's isolated and then you do all the parallelism on top of that.
01:06:28.070 - 01:06:44.238, Speaker B: So more opinionatedness on the front end via the programming language gives developers more flexibility. But by having kind of the fastest, cheapest execution environment that's going to be able to solve like 99% of the use cases on the backend.
01:06:44.374 - 01:07:47.066, Speaker A: Yep. You know, like there's some reason to want to say like, hey, you guys are using Berkeley Packet filter and we want to use WASm, and some developers will want to go build WaSm stack. But that level of like differentiation is like, not, it's just very preference and subjective. It doesn't actually like like solve like a business economic problem where you're like, you as a user, you really don't care whether the backend is running WaSm or Berkeley packet filter. It's just so far differentiated, so far removed from the user and very much up to developers preferences. It's nice to be able to say, oh, we serve every possible bytecode and everything else, but it's not an optimization that's worth creating a much, much like sacrificing all the other features. We could actually add loaders that load different runtimes and stuff like that.
01:07:47.066 - 01:07:55.270, Speaker A: But that's going to increase the audit cost because now we have to audit WaSm stack and all this other thing, it just becomes a kitchen sink. I'd rather.
01:07:57.170 - 01:08:23.994, Speaker B: The other main discussion point that I often hear is the Internet is primarily asynchronous versus like synchronous, and that it would be difficult to, I guess, kind of scale past like ultimately the size of one node and that there should be different environments. Can you also kind of like touch upon that point of view?
01:08:24.082 - 01:09:21.064, Speaker A: There's, this is also, I think, I think a lot of people say they want to infinitely scale blockchains and they think, they really do think infinity. And that's actually, I think overestimating demand is as bad as underestimating it. Like Google serves, I think about 100,000 queries per second, like searches per second. There's just some fundamental limits to how much any service needs to provide. And if you, if like the Google engineers were told we need infinite number of searches, they would have wasted a lot of their time building something that is solving problems that they don't really have. When you know that you need to serve 100,000 steady state and a million peak, you can build the fastest possible system that fits within those bounds. And that means that you go from 200 millisecond response time to 50 millisecond response time.
01:09:21.064 - 01:09:49.412, Speaker A: And that is actually more valuable to the customers. So like, from my perspective, my guess, like we're at 400 user transactions per second, and that's more than Ethereum and all its l two s combined. I really, really doubt that within 20 years we're going to see like more than 100,000 transactions per second. Like the top 99.999 valuable transactions in the world are going to fit in the first 100,000 tp.
01:09:49.566 - 01:09:51.980, Speaker B: And those are like actual user transactions.
01:09:52.560 - 01:10:20.590, Speaker A: I just don't see it breaking past that. And to support that, we probably need ten XP capacities to a million TPs. And that fits in the ten gigabit network that's available in every data center today, available in a bunch of homes already. If we build a system that works really, really well within those bounds and as fast as possible, like I think it'll actually saturate all of the world's needs pretty wild.
01:10:22.330 - 01:10:48.240, Speaker B: It makes a lot of sense. Maybe just sticking on the kind of zkl two briefly and then going to asynchronous execution, because I'm fascinated by that as well. And just so it's very clear, it's kind of your point of view. These different l two s or different execution environments, they're not actually scaling solutions.
01:10:48.540 - 01:11:15.590, Speaker A: Because you scale in the sense that they remove the single threaded bottleneck that's in Ethereum, so the EVM itself and the layer one doesn't have to execute those. And it's kind of punting off the execution to these other environments. And it's almost like using a Unix fork to create threats. Like you create these other processes that can run independently of each other, but they're still syncing data to this one single threaded environment.
01:11:16.410 - 01:11:44.224, Speaker B: And so by kind of charting that execution, you're giving similar benefits as you would if you were just integrating that with multiple cores. But for a L2 specifically, I mean, I guess you can scale compute more, but it's ultimately still going to be bottlenecked by the data availability layer, because you have to ultimately come to consensus with the layer one.
01:11:44.312 - 01:11:50.780, Speaker A: Yep. You still have to submit your data to Ethereum. So you're as fast as Ethereum will allow you to submit your data.
01:11:51.160 - 01:12:00.690, Speaker B: So you're going back like you're always bottlenecked by the bandwidth. You can kind of move that to a volition or wherever else, but it can't be eliminated.
01:12:00.770 - 01:12:10.230, Speaker A: And that's going to be the volition breaks the security, guarantees that what people want out of L2. So you still have another thing.
01:12:11.090 - 01:12:25.676, Speaker B: Yeah, I agree. Interesting. Okay. I just want to make that super clear. Asynchronous execution. This is something that I see you tweeting about a lot, but I would love to learn more.
01:12:25.708 - 01:12:51.020, Speaker A: And I'm sure this is like an optimization that would allow Solana validators to skip executing all the user transactions and just vote on forks. So imagine the validators. The only thing that they process are votes. So they're only looking at votes. They're only computing the fork weight and picking the next fork. And that means that all the smart contracts don't get executed right away. They can, but they don't have to.
01:12:51.020 - 01:13:44.004, Speaker A: So that means some nodes that are like magic Eaton nodes that are serving user data, they're going to want to execute all the user transactions right away. And as soon as they know that the network has confirmed this block, they know that everyone else is going to compute the exact same result, because that sequence of events is finalized. And even if it's parallel, the actual execution is deterministic, even if it's parallel. So they can compute that state and serve it to the users right away. And they know it's confirmed, they know exactly what that state is going to be. So validators are not bottlenecked by the execution that the question there is like, what benefit does it provide? Well, it's really, really hard to have the runtime guarantee, the exact execution timing on every event. It's kind of very, kind of a course measurement.
01:13:44.004 - 01:14:33.618, Speaker A: So on average, we can actually do a pretty good job trying to get every block within 400 milliseconds. But there's sometimes spikes, and those spikes are bugs. You can think of them as bugs, and they're always getting fixed and always getting better. But what would be better is if the network just could allow execution to slow down a bit and then catch up. And that actually opens up execution to a really, really cool optimization. If you know, like, you have like a million transactions and you know exactly what they are, you can actually perfectly pre fetch all the state from disk and make sure that it's in memory before you actually hit the execution on it. So you never take any, any cache faults, you can load up all the transactions for the same program, unlike GPU's, if that's, if that's possible.
01:14:33.618 - 01:15:26.050, Speaker A: You can do all sorts of tricks for batch execution, execution and even in the zero knowledge singularity world where you need a million transactions to go sent to this magic massively parallel prover, you can then do that and just submit the ZK proof for the state. All this does is it lets validators still say ok, I can vote on this fork, I know what all the client transactions are, but I'm going to execute them sometime later. And they need to be able to agree to execute this all the state some way, like once an epoch, and that's roughly every two days, might shrink to be as fast as every 4 hours, but like kind of basically that over that one kind of giant chunk of time, go execute all the transactions at the same time.
01:15:26.390 - 01:15:39.582, Speaker B: And this ultimately, I mean, allows you to also deal with kind of like these like big batch spikes as well, that you can kind of like amortize the transaction execution over APOC.
01:15:39.646 - 01:16:30.170, Speaker A: The big benefit that I can see is that if once we want to add multiple leaders to the system, we run into a similar problem that any multi leader system does, is how do you split bandwidth? Like if you want to split it in a very coarse way, you give everyone 50%, you're probably going to underutilize the network. So what's kind of cool is that you can actually let those leaders to temporarily exceed their bandwidth. There's a spike and then you start lowering capacity to average it out over like a period of 30 minutes. So that would actually smooth out the capacity and probably give us much, much closer to full utilization with multiple liters without having this course. Like if you have two liters, each one gets 50%, if you have four, each one gets 25%. Can actually let him kind of spike up and down.
01:16:30.870 - 01:16:48.050, Speaker B: Interesting. It is fascinating. So I guess like is there any downside or like trade offs by like, instead of doing like the state transitions like almost in real time as they come to the block leader after they come to consensus.
01:16:48.870 - 01:17:23.350, Speaker A: Yeah, this is like a, this is one of those optimizations with no trade offs. It's great with no downsides. Nodes that need the data right away can provision themselves with more hardware to be able to do it in real time, but validators that are voting on forks really don't need to do that. And then can just run in this single batch optimized configuration and there's no trade offs. It's great. Except for the hard engineering that needs to be done to test this to make sure it's bulletproof.
01:17:23.430 - 01:17:34.530, Speaker B: Interesting. Well, I think, I mean, that was majority of things that I wanted to talk about. Any updates on Fire dancer, how that's, like, progressing?
01:17:35.470 - 01:17:58.322, Speaker A: Go look at their GitHub. Yeah, they're cranking out. Like, I'm hoping that by the end of, by breakpoint that there is a fire dancer Franken dancer client, which is running part fire dancer code, part Solana core code. I'm pretty sure they'll get there. Obviously, no guarantees. These are like, engineering timelines are like the worst things to predict.
01:17:58.346 - 01:17:59.306, Speaker B: How many story points is that?
01:17:59.338 - 01:18:24.000, Speaker A: Yeah, but go look at, like, yeah, we need prediction markets for engineering timelines, but go follow their GitHub. They're making really, really good progress. And, like, as soon as they have a runtime that can verify Solana ledger concurrently with Solana code, I will sleep twice as good at night, have multiple.
01:18:24.040 - 01:18:35.620, Speaker B: Different clients, and less worries about any downtime or issues. Awesome. Well, is there anything particular that you want to touch upon or share with the community?
01:18:36.720 - 01:19:16.754, Speaker A: There's a hackathon that's just been announced called Hyperdrive. I hope all the folks that listen to this podcast tell their friends about it and go, literally, these are like the best ways to get into the space. A lot of the founders that have raised real money, real seed funding, they did a hackathon. It was just their first one. It didn't work out, but it sparked an idea that they worked on for like three to four months and submitted in the second hackathon that was like, at that high quality level and uniqueness that got them funding before the hackathon was over. So this is a path for a lot of first time founders. If you're an engineer, if you're working at a FAANG and you're bored in.
01:19:16.762 - 01:19:19.670, Speaker B: The weekends, come to the dark side of crypto.
01:19:20.210 - 01:19:29.470, Speaker A: Go build a prototype for hyperdrive. It'll fail, but it'll give you everything that you need to go succeed the next time.
01:19:29.770 - 01:19:58.844, Speaker B: Amazing. Anatoly, thank you so much. Again, these are some of my most fond and fun conversations, kind of like nerding out on the different execution environments, how you propagate data. And I really just wanted to make this, like, super clear, dive into some of the things that you've been talking about on Twitter and give you a little bit more of a long form conversation to dive deeper into them. But truly, thank you and really appreciative of you and what you built here at Solana.
01:19:58.972 - 01:20:00.404, Speaker A: Awesome. Thank you for having me.
01:20:00.452 - 01:20:00.700, Speaker B: Thank you.

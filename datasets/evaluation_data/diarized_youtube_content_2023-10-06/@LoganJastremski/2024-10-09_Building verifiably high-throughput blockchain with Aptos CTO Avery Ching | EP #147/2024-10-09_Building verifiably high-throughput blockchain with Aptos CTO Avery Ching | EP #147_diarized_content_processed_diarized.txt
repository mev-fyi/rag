00:00:00.520 - 00:00:38.029, Speaker A: Unfortunately, in crypto, it's been a lot of it has been narrative versus performance. And so what we set out to do was really show that performance is really important, of course, with everybody else, but it has to be done in a way that can be well understood and reasoned about. And so I think, you know, last time we talked, we talked a little bit about the benchmarks we had done for PreviewNet, where we showed with a certain branch of our code and in a mainnet like setup, we could do 30,000 transactions per second. We could sustain 25,000 transactions per second over 24 hours. That's more than 2 billion transactions in a day. That's more than every single credit card network combined put together. MasterCard, Visa, and everyone else.
00:00:38.029 - 00:01:06.565, Speaker A: And so the point of that was to really show that this technology is ready for prime time. And that now you can actually have a world where you can imagine something like a payments rails of Visa or MasterCard working on top of Aptos and making that something that brings value to users that the current payment network cannot. Having that transact with instant finality, with immediate settlement, being able to transact across the world without boundaries or barriers. I mean, those kind of things, I think, are things I really, really value.
00:01:08.905 - 00:01:14.681, Speaker B: Avery, thank you so much for coming on the podcast. Really looking for aptos experience here in South Korea.
00:01:14.833 - 00:01:22.625, Speaker A: Thanks for coming out, Logan. We're very excited about this first aptos experience for us, and we got a lot of secrets to share.
00:01:22.705 - 00:01:51.065, Speaker B: Honestly, I'm looking forward to it. South Korea is a really unique place in the world. This is my second time. I came here for South Korea Blockchain week last year, and it's been fascinating and cool just to see different parts of the world and where blockchain will ultimately take you, but it's really a huge hub for blockchain. There's a lot of crypto people, users, speculators, within the Asian market.
00:01:51.685 - 00:02:15.735, Speaker A: Definitely. Korea has always been, ever since we started, kind of a very, very home away from home for us. A lot of folks are. A lot of investors actually are from South Korea, and we've also got a lot of our teammates from South Korea as well. So we're. We're super excited about being here again and having this be the location for our first aptos experience and also continue to meet with our partners that we've built along the way.
00:02:16.995 - 00:02:58.831, Speaker B: Maybe that's a great place to start. Part of the like partners, different things that you've learned for the last couple of years. This is our third podcast together. When we did Our first podcast in Palo Alto, that was testnet. We did one around the research that you guys published on really the amazing performance that aptos has really brought to light. But from the community side, from developers, from working with different partnerships. What have you guys learned from the last 24 months since kind of really being in the industry, being live and kind of seeing Aptos mainnet rollout.
00:02:58.983 - 00:03:38.415, Speaker A: It's always fun to think back on the early days, just kind of recapping a little bit. Back in 2022 is when we first got the team together. A lot of us coming from the Libra Diem project at Meta and trying to figure out how do we broaden that mission from just being payments Rails in a very different kind of platform and to something much more bigger in the world and a public utility for that. We were very happy to launch very quickly in 2022, in just eight months since our founding team formed in October and there was so much excitement. We had so many protocols launching live. It was obviously a great time for us. 2023 we saw the expansion of MOVE to a large degree.
00:03:38.415 - 00:04:29.819, Speaker A: There were hundreds of projects building out across many different verticals, but DeFi, social media, entertainment and gaming were some of the ones that really stood out to us. And a lot of that time was also spent building out infrastructure and tooling which we is very necessary for developers to onboard, especially with a new programming language like move. And so I think we spent a lot of our time also building up the infrastructure so the developers had a much easier time to get started and to play around. In 2024 things started to change a little bit. I'd say we kind of feel like we've been able to demonstrate now we're world class infrastructure that can do things that show that web3 is really ready for prime time. And I'm sure we'll get into that a little bit later. And with that shift in change, we now think it's a right opportunity for us to focus on a couple of core vertical, especially around the use cases of how do we accelerate the new economy.
00:04:29.819 - 00:04:46.575, Speaker A: And that is very broad. But talking about finance, advertising, marketing as well as Defi and focusing on those efforts in particular to bring value to customers around the world is going to be a big thing that we've started to set our minds towards and we're really excited about some of the new initiatives in that space.
00:04:46.875 - 00:06:06.105, Speaker B: Yeah, crypto is a funny place because as we were kind of talking with a little bit prior, the markets are very funny in crypto and I think obviously you and I are very aligned about building high performance infrastructure. I think really what's going to be required for I would say the asset class of crypto. And even for crypto to really hit mainstream adoption, you need performant infrastructure to actually unlock that so application engineers can focus on finding product market fit, not doing, removing lines of code for limiting gas costs. And I think it's been remarkable to see, I think even since we first chatted around how the industry is kind of moving towards the high throughput blockchains. What do you feel like the industry is kind of missing or misunderstands more broadly about either the aptos ecosystem, the technology, or just like it's kind of like underappreciating, so to speak?
00:06:06.765 - 00:06:41.193, Speaker A: That's a lot of good questions into one. I'll start with one thing which is the narrative around performance has always been clear. You and others have really pushed towards that and I think it is very essential that we have high performance infrastructure in able to support the 5 billion Internet customers around the world. That being said, a lot of people make promises. There's been a lot of talk about unlimited scalable, horizontally scalable systems. But just again, my background is I worked in high performance computing during my PhD. Nobody ever in that world ever talked about being unbounded horizontally scalable supercomputers.
00:06:41.193 - 00:07:31.439, Speaker A: Everyone knew there were limits to them and that's why we run benchmarks to test them. There's something called the Top 500 which lists the top 500 supercomputers in the world that run LINPOC benchmarks to see which one can perform the best. And then there are now benchmarks with respect to performance against power, which is also a very important consideration for these very power hungry machines. Unfortunately in crypto a lot of it has been narrative versus performance. And so what we set out to do was really show that performance is really important of course with everybody else, but it has to be done in a way that can be well understood and reasoned about. And so I think last time we talked we talked a little bit about the benchmarks we had done for pvnet where we showed with a certain branch of our code and in a mainnet like setup we could do 30,000 transactions per second, we could sustain 25,000 transactions per second over 24 hours. That's more than 2 billion transactions in a day.
00:07:31.439 - 00:08:18.945, Speaker A: That's more than every single credit card network combined put together. MasterCard, Visa and everyone else. And so the point of that was to really show that this technology is ready for prime time and that now you can actually have a world where you could imagine something like a payments rails of Visa or MasterCard working on top of Aptos and making that something that brings value to users that the current payment network cannot. Having that transact with instant finality, with immediate settlement, being able to transact across the world without boundaries or barriers. I mean those kind of things I think are things I really value. And it's really important to think about when it comes to the payment space. Talking about performance some more like, you know, we put out some earlier, some latency benchmarks and we started to talk about what we think about when it comes to user latency.
00:08:18.945 - 00:08:29.673, Speaker A: You know, when users enter a web page they don't think about what's the time it takes for the database part to load and then how much time does it take for the server to get back. My response to me, they're just thinking about when does my page load.
00:08:29.769 - 00:09:09.853, Speaker B: It's funny because prior to me doing crypto I was at Expedia Group and one of the big metrics was time to page actually loading because the bounce rate, even if it was like half a second later, would dramatically reduce the amount of money because people would just bounce. And I think people kind of forget the Web two best practices were not there by accident. Blockchains are new technology, but you don't throw out the entire bath, so to speak. And so it's, yeah, I think people dramatically underappreciate the end to end finality.
00:09:09.949 - 00:09:59.845, Speaker A: Exactly. And so that's definitely the metric we've been trying to push in the industry, which is like when you submit a transaction, when do you get a response that the transaction completed, what the results of the transaction are? And those transaction results can be learned by others as well. And so we put out, we actually did a comparison. We have an open source benchmark, we've added a bunch of networks to it, some others have contributed as well. And we maintain that dashboard that kind of shows what aptos can do in comparison to other networks where aptos is definitely the lowest latency. But also also more importantly that this latency at 7 to 800 milliseconds for user finality times in Asia means that as a webpage takes 2 1/2 seconds to load, your web 3 portion of it can be loaded in a fraction of that. That's really important to show that now you can integrate web3 into everyday Internet use cases on any kind of websites that exist.
00:09:59.845 - 00:10:48.628, Speaker A: So super excited about that piece as well. And I think the last point is going to Be really around. How do we think about how networks perform at scale? Because as we've seen with MeanPoint workloads or with other large workloads that hit a network, some of the networks sometimes run into either high latency, they fall over. And for the largest enterprises in the world to run their use cases on blockchain, that's a really huge risk and a consideration. When we talk to institutions, they always wondering what is your uptime and how does your system perform at load? And so being able to see recently with some ecosystem projects that launched on aptos, Aptos did really well. We were able to show that, I think it was, I think August 17, there were 326 million transactions that completed in a day on Mainnet. This is not in a test environment.
00:10:48.628 - 00:11:08.943, Speaker A: This is Mainnet. That's more than 3,700 transactions per second sustained over 24 hours. And during that time you could execute another transaction. You could send APT from U to me or you could send us an NFT between us. And the times would be reasonable at still like, you know, about about under two seconds. And so the network's very usable. We see massive throughput going on.
00:11:08.943 - 00:11:34.495, Speaker A: There's no change in failure rates, there's no change in gas fees. And I think this is kind of the first proof point in industry to show that you can do massive things on web 3 without high cost, without worrying about the infrastructure falling over. And I think when we look back at this time, we'll see that this is kind of the proof points are needed for those industries and for those enterprises to actually onboard the use cases into the space and see massive success.
00:11:35.435 - 00:12:28.065, Speaker B: I think the industry going back to one of your earlier points is very narrative driven. I think those are hard to refute, especially when you open the data, people can run the benchmarks themselves. What do you feel like today? The industry is very, so much focused on the Ethereum virtual machine. Ethereum. Now that's kind of been drawn into some question with kind of the layer 2 roadmap, some of the fragmentation that has ultimately existed. I kind of view these layer ones or blockchains almost as developer ecosystems, so to speak. What do you feel like is going to be the catalyst to get kind of some of the people in the EVM world to experiment with an aptos.
00:12:28.065 - 00:12:36.229, Speaker B: Is it the benchmarks? Is it more liquidity? Is it more users? What do you think is the big bottleneck today?
00:12:36.397 - 00:13:28.613, Speaker A: Yeah, great question about what's the draw from folks coming from EVM into aptos? And the good thing is We've actually had a couple of good case studies to see that. We've had good conversations with the AAVE team, who's who put out a governance proposal to deploy an aptos. And I think the things that they saw that were very exciting to them is as they build out a very robust DEFI infrastructure, what's the safety of those contracts? What are the cost models of those contracts? And Aptos having the lowest industry fees in payment is 5,000ths of a cent. You can do 20,000 payments for a dollar. That can actually drive much more traction and volume and also unlocks things that just aren't possible when the networks cost more. I can give you another example. When you have network defi aggregators which are kind of showing different paths and routes to kind of exchange things, your limits are the fees are quite expensive.
00:13:28.613 - 00:14:13.069, Speaker A: There's just limited paths you're going to go through and just limited options for you. But if you got very, very cheap routes and you have lots of plentiful options and you have different paths, you can actually construct very, very interesting optimizations for people. And we've seen that with things like Panora and Aptos, which can deliver upon those utilities to customers today. And so I'd say coming back to your point, like, what's the draw? It's going to be the safety aspect. Having the MOVE prover as well is a huge piece for AAVE that they're excited about. When you can formally verify the correctness and the properties of your code and not have to write a unit test for every single instance of like, am I losing money in this case? Am I losing money in this case? No, no, no, no. It's not possible to lose money because we formally verify that every single outcome here.
00:14:13.069 - 00:14:39.605, Speaker A: Just can't drop the money on the floor. That gives you a lot of confidence, especially when you want to change your code, because otherwise every change is like, oh my gosh, am I, you know, this is the day my company ends, Is this my dance? That confidence is very important for them. And so that performance, the cost, the safety aspects and then kind of the performance at scale, I think are the key factors that really draw people into the characteristics of aptos provides.
00:14:39.725 - 00:15:35.415, Speaker B: It's been amazing. I mean, I feel like for a while we're seeing hack after hack. It's not that smart people don't exist in the other ecosystems. It's really just maybe we don't have the correct tools. And I think the work that the aptos team has really done around MOVE has really focused on that safety aspect allowing engineers, again, it's taking all the things that like they have to think about today, which is lack of performance, the amount of money that teams spend on audits and trying to abstract some of that complexity as much as possible so that engineers can focus on applications. Because I think we really do need apps. I think to your point, we are at the point now where we have performant infrastructure.
00:15:35.415 - 00:15:42.295, Speaker B: We just need cool engineers to go build meaningful things. And those two continue to scale over time.
00:15:42.915 - 00:16:31.085, Speaker A: I think you've hit upon a very important point. I've worked with some amazing developers in my life, in my career, and not one of them writes bug vue code, myself included. I think it's unreasonable to expect anyone to write bug v code. Yet the space we work in in web3 expects that because any single bug might lead to loss of funds or loss of value and hurt a lot of consumers and customers. And so being able to produce a developer environment, it's not just about the language, it's about the tools around it. It's the move prover, it's linting roles, formatting rules, it's even AI to help you kind of discover like, yes, you can do this, but this is probably like why are you doing this? This is a very strange idea. Those things are very key and very important for us to build out infrastructure that we know is going to be supporting value transfer on the, on the Internet.
00:16:31.085 - 00:17:04.053, Speaker A: So I'd say that's a key piece. And it's not like you said, it's not about different camps and different developer communities having different qualities of developers. It's really the tooling and the language and what it can allow you to do and how we provide safety. At aptos, we take a very extreme view around safety. We have something that even running called paranoid mode, where we do the bytecode verifier checks even at runtime, just to make sure there's no accidents, there's no mistakes, and it does cost some performance. It's a trade off for sure. But that's a trade off we think is worthwhile making.
00:17:04.053 - 00:17:46.153, Speaker A: And we know it's impossible for any developer to write bug free code. And so our goal is to make it as hard as possible for that to happen. And then I think the other thing that's not that intuitive about is not just safety comes with cost, it comes with advantage because it's harder to do that. It's actually much easier for you to launch your application with confidence. You know that what you've done has been tested, formally verified you know that there's checks in place to make sure that some things just aren't possible to have happen in the space. And so as you get from ideation to production using Move, and especially what we've done with Move on aptos, it's just a best in class developer experience for you. And I think what we've seen from our developers is they continue to give us feedback about what we can improve and we make those improvements.
00:17:46.153 - 00:17:50.005, Speaker A: But they're very, very excited about the fact they can move so quickly in our space.
00:17:51.905 - 00:18:27.345, Speaker B: From testnet to mainnet to today. What are some applications that are you are excited about? Because I think with more performance ultimately unlocks new capabilities. And when you're constrained to 10100 tps per second, the types of applications that you can build are obviously much more limited in scope than when you can do 25 or 30,000 transactions per second. What are there any things that you would love to see get built or kind of call to actions within like the Aptos ecosystem?
00:18:27.505 - 00:19:18.767, Speaker A: Yeah, I think you raise up a great question. And in many ways our industry is nascent, right? We don't have a lot of those use cases yet today on Web3, but they're going to come for sure. And so we were excited about our partnerships with NBCUniversal to build out mass distribution for people around theme parks and other big visions they have. I can probably share all those right now. I think that's a great use of how we think about scale Also now we're in South Korea thinking about things like Lotte, which is the largest retailer in South Korea, and how they think about loyalty programs amongst their their myriad of stores and customers and even different kind of industries in the space. How do these companies that are very large conglomerates think about interoperability even within their own companies is a very interesting question. They may have tens of thousands of employees themselves and also many different types of customers that they need to be able to figure out.
00:19:18.767 - 00:20:06.689, Speaker A: How do they organize those customers across different products and understand their behavior across different products. That's where we think Web3 can help. So we're really excited about that. I mean even gaming continues to be a very interesting place for us where we see very large gaming partners in different parts of the world building on different types of ideas. Some of them going to be very simple games and very hyper casual games. We've seen idle RPGs such as the one from Supervillains who are really innovating the space and thinking about how do we make bloshing completely behind the seams and seamless and how does that kind of bring value and utility to customers at scale? All those things are very exciting. But I'd say going back to I think the new focus around finance and in the new economy, we believe there's a lot of interesting value cases there.
00:20:06.689 - 00:20:47.071, Speaker A: And Deepin I think is something that we want to touch on. Deepin infrastructure. One of the biggest parts of Deepin is how do you kind of reward people almost real time for what they're contributing to the network, Whether it's contributing their wireless services, their Internet, their machine power, their storage capability. I think being able to kind of compensate those folks in real time with high granularity, with low fees is something that we're really well suited for. And I think it kind of shows that Deepin can be done at scale. You think about some largest kind of pre depend networks, which is kind of peer to peer networks around file sharing. They reach the scale of tens of millions of consumers around the world.
00:20:47.071 - 00:21:17.685, Speaker A: Or even think about things like SETI Home, which also reaches a large audience. Adding the web3 elements to those kind of products I think is very straightforward. And the complicated part is, does it make sense from a product standpoint? Is this actually cost efficient? Is there a better way to do these things? And I think today with what aptos provides in terms of the scale, the cost, the latency, and as we'll start to build in this space, even the confidentiality aspects, even more will be just a new paradigm and new utility for people to actually construct new applications upon.
00:21:18.725 - 00:21:48.225, Speaker B: One of the interesting parts of the industry is we often expect something to happen. But how engineers build and users build ultimately takes like a left turn. Meme coins have been super popular in 2024 and 2021 it was largely around NFTs. Has there anything that has kind of like surprised you in terms of things that happen that have kind of caught you off guard?
00:21:49.025 - 00:22:30.899, Speaker A: A lot of things have surprised me for sure. I don't know where we want to start with that one, but I think the thing that we really picked up notice on these days is just really trying to meet different types of users and developers. Users and developers are two distinctive use cases and making sure that we are doing our best to support developers and not just in the technical side. This is full stack support. How do we help them with thinking about marketing their product? How do we think about the legal aspects and compliance? How do we think about tokenomics and getting them accelerated essentially. So again, going back to the way we think about things, how to accelerate the new economy. A lot of that was also accelerating our ecosystem that are non technical aspects.
00:22:30.899 - 00:23:18.865, Speaker A: And so get them all the way from ideation to launch and beyond is something that we're really, really focused on and I think really excited about the efforts in that space and the amazing products that are coming out of it, and especially building differentiated things. I think the other thing that surprised us a bit, and I think we're still kind of working through, is just also how long it takes to build infrastructure. It's not easy to build a new infrastructure layer for Web3, and it took a little bit longer than we thought we would. But I think like you said, we're kind of finally now at that place where we've demonstrated industry leading capabilities. We've shown not just industry leading capabilities, but that this is a technology that is viable for the largest Internet products in the world. And that's a great proof point. But now it's time to start really focusing on the use cases of that technology.
00:23:18.865 - 00:23:23.385, Speaker A: And we really want to get the open finance ecosystem started in this space.
00:23:24.205 - 00:23:33.205, Speaker B: Do you think it took slightly longer from the actual software engineering side or the community side? What specifically took longer?
00:23:33.365 - 00:24:00.889, Speaker A: Because a lot of people just think of the blockchain as the infrastructure you need. No, it's not just the blockchain. So you need RPC services, you need indexing services. Because the data you have on the blockchain is not organized the way that people need it. Right. If you're building an NFT marketplace, it's not viable for you to go ahead and scan all the objects out there in the world and try to figure out which ones changed recently. So reorganizing the data in a way that is best suited for each product use case and each, I call them customers, but the developers are our customers.
00:24:00.889 - 00:24:36.347, Speaker A: Right. So each developer is a really important thing for us to consider. And so our indexing services support hundreds of ecosystem projects today. And that's something we probably didn't know from the very beginning. And also I think thinking about the development process also as a product, I think is something that we've really embraced. We spent a lot of time on developer documentation, on tutorials, on tooling, and every new feature we launch, whether it's the innovative stuff we've done in randomness to the keyless technologies we built, they all need to come with developer guides, they have tutorials. We have to work closely with ecosystem products to help them onboard and integrate.
00:24:36.347 - 00:24:54.411, Speaker A: And when they do onboard integrate, the results are just amazing. The product launch is so Much more successful. And we've seen that with Keyless, we've seen that with our randomness events. We had a randomness hackathon just around that. And so the closer we can launch with the community, I think is kind of the broad lesson here that we really embrace going forward and maybe jumping.
00:24:54.443 - 00:25:41.785, Speaker B: Off that we're here in Korea at Aptos Experience's first kind of global event. What would you, what do you want to kind of see come out of this vent? Is it kind of like a selling point for the entire Aptos community to rally a pound? You guys have done kind of some hacker houses. What's the goal? To get like community more involved, get more engineers, get funds, excited about what's going on because it can be reflexive and to the upside and downside and I think really bringing people together in person, there's some things that you just, you just can't recreate on Twitter and so really excited about aptos first event and seeing what you guys ultimately announce.
00:25:42.085 - 00:26:22.051, Speaker A: Yeah, for Aptos Experience, our goals are, I think a little interesting. We really want people to, I mean, it's called experience for a reason. We want people to touch and feel what the products are being built in the space, what the infrastructure can do, what the teams are like and who everybody is. We want it to be very different in that perspective from like a traditional conference where it's. There's some talks given, there's some swag given here. We want you to be a part of it. And the outcome for us should be that the community should be feeling much more excited about, I think just knowing each other, knowing what each other is doing, and also getting a touch and feel for that technology.
00:26:22.051 - 00:27:07.147, Speaker A: That has been elusive for a long time in our industry. We haven't had a lot of really great success stories when it comes to long term product market value and kind of seeing where we are today, seeing the potential of what we'll do and we have a bunch of exciting experiences there. I guess we can talk about since we're not, since we're talking about the podcast afterwards. I mean, I think that's the thing that we want to take away and we want our community to also be. We also have a lot of surprises to reveal around our consensus protocols around the next generation of block stm, around what Move two is going to do. MOVE two is going to be a whole new developer experience that we think is just totally customized for, for Web3. And we have some product releases around Optos Build, which is a new infrastructure for how do you perform this one stop, shop for people to focus.
00:27:07.147 - 00:27:58.497, Speaker A: Like, companies don't really want to focus on their Web three elements. They want to focus on what their product is shipping. So if you have a company like Toymakers, which is trying to build out digital goods where you can match your physical item with a virtualized economy and have that relationship between customers and clients, they don't want to think about the wealthy elements. They just want to have easy tooling to go ahead and mint a ton of NFTs and have them link to their products, monitor the usage of their website traffic against our indexer backends, and then kind of figure out how do I optimize for that use case but not have to think about, do I need to write this move smart contract? What are the safety elements of it? Do I need to get automated? All that fun stuff. So as much as we can to make that as easy as possible for developers and builders, we're really excited about making everything much easier in web 3.
00:27:58.601 - 00:28:03.417, Speaker B: Yeah, make application engineers focus on application skin.
00:28:03.521 - 00:28:05.005, Speaker A: That's right. That's right.
00:28:07.385 - 00:28:59.427, Speaker B: Maybe diving deeper into some of the technical aspects, given the CTO you mentioned, move to a new execution environment, even a lot of the work that you're doing around consensus. We talked a while ago and one thing that really stuck out to me that you mentioned on the consensus side is you can speed up consensus, but fundamentally, if you make the actual consensus algorithm better, that is just fundamentally much more performant. And it was really something that I kind of took away and I was like, it's hard to argue with that. That's true. I would love for you to maybe dive a little bit deeper into some of the technical aspects on the consensus side that we're doing. And maybe after that we can just kind of go through the line of some of the new things that you guys are going to be announcing.
00:28:59.451 - 00:29:23.999, Speaker A: Absolutely. We're really excited. Like this year, the last, this 2024, we've shipped so many improvements in infrastructure, like, it's hard to keep track, honestly. But in consensus, one of the key things we ship was something called order votes. And that allowed us to get to this theoretical best possible latency of three network hops before you have agreement on blocks. And I think one thing you called out there earlier was consensus latency is not user latency. So it's something really important for people to focus on.
00:29:23.999 - 00:30:00.935, Speaker A: It's just one aspect of the latency of blockchain finality. But being able to get there was a huge milestone. There's very few protocols that reached there. And I think we've done it in a way where we've to also provide all the other guarantees of our consensus protocol, the leader election pieces of it, the ability for us to also support things like on chain randomness with every single transaction going out there and many others that just aren't possible. So I think we're pretty happy about that piece, to be very honest with you. And we're announcing our next generation consensus protocol at aptos Experience, so you would have heard of it by now. It's called Raptor.
00:30:00.935 - 00:30:59.825, Speaker A: And that's going to be a very iterative step to kind of merge what we're doing with our three step consensus with very, very high throughput and super excited about that piece. But the longer story that I want to share is that as consensus is just a part of that blockchain finality time, we're going to be doing our best to push the entire finality time of the blockchain down the consensus latency as best as possible. And that's going to be really exciting because that allows us to get where we are today at about 700 to 800 milliseconds of user finality end time to hopefully around 500 or 600 milliseconds. And that's pretty incredible. The other piece that is going to be very exciting in this technology stack is something called block STM v2. One thing we've seen about block STM is that you think about the evolution from sequential execution to static parallelism to dynamic parallelism. We've seen this as kind of a very clear trend in industry that we talked about from the very launch of the Optos infrastructure.
00:30:59.825 - 00:31:42.233, Speaker A: Just for those to recap, sequential execution is things like the EVM which is single threaded in nature. We have static parallelism, which SWE and Solana do, and we have dynamic parallelism. And the difference between static and dynamic is that dynamic parallelism allows the system to adapt at runtime to anything that would actually help it paralyze. Additionally, on top of that we do things like we have aggregators which allow us to have global counters that are parallelizable. That's only possible in aptos. So if you want to build a prediction market and you want to have very effective voting, everyone is still touching the same votes over and over. You have millions of people voting on the same kind of elections and most networks that would serialize all the transactions and make it very, very slow.
00:31:42.233 - 00:32:11.447, Speaker A: But Naptos is parallelizable and very low feed. So that's something that we find Also very, very exciting. So the dynamic parallelism is a very important piece. And what we've seen also is that people have been adopting this technology stack and also the ideas in different networks. So we've seen Polygon, we've seen sei, Mona taking some ideas as well. We've seen movement and others, starkware most recently, all adopting kind of the ideas that block STM and dynamic parallelism is the right way to go in industry. And we're excited about that.
00:32:11.447 - 00:32:29.141, Speaker A: I think it shows, you know, a little bit of a maturation of the space. And for block of SDM V2, we're going to be able to take the ideas and say, like, look, they work really well in a 16 core environment today. But that's not where hardware is going. Hardware is going to be 32 cores, 64 cores, 256 cores. This is commodity hardware. Harbor doesn't advances. Right.
00:32:29.141 - 00:33:15.195, Speaker A: So the way Moore's law has been going up in the last couple of years has not been through transistors getting smaller and smaller, it's been through increasing the cores on a machine going forward. And so as we follow that trend, we're going to make sure we scale block STM to massive, massive limits. And that is going to unlock a lot of potential. The other difference between static and dynamic parallelism is that static, you know, upfront every kind of dependency out there and then you use it to schedule, but you don't understand the interplay between those dependencies. And so if you have an order book with a tree, you might just lock the whole tree and make everything serialized. Whereas in dynamic parallelism, if you only update some pieces of the tree, you can actually do that in parallel, which is really, really neat. Now in dynamic parallelism, the other cool thing is we can take hints in the transaction to say, I'm probably going to touch these pieces of data, I'm only going to read this data and write that data.
00:33:15.195 - 00:33:28.255, Speaker A: You can leverage those hints in scheduling as well. And so you can get all those benefits of static parallelism plus denying parallelism hints. And that's the direction we're headed towards. And we think that that's the ultimate kind of parallelism engine that exists in web 3.
00:33:29.315 - 00:33:43.979, Speaker B: Lots to touch upon. Maybe to start with the consensus, maybe in a little bit more Layman Terms, obviously, 500, 600 milliseconds is remarkable. Three hops almost bound by speed of light.
00:33:44.147 - 00:33:52.575, Speaker A: Yeah, I mean, I'll just say like on that point, you know, any two points across the world, if you actually have a decentralized network, it's about 200 to 300 milliseconds. So you can't go any faster than that. Sorry.
00:33:53.075 - 00:34:10.955, Speaker B: We got to figure out how to make speed of light faster. But what is a good way for non technical people to kind of compare and contrast what other consistencies, algorithms are doing, doing or kind of other best practices out there.
00:34:12.415 - 00:34:50.567, Speaker A: So I mean if you think about, you know, I think Bitcoin's finality time is like an hour. Ethereum is like you know, 10, 12, 15 minutes, something like that. I mean that's kind of like the example of different consensus protocols or different finality times, different latency times. Really pushing that to limit allows use cases just aren't possible. So if you think about the payments use case again, you know, if you want to have real time payments, streaming payments, autonomous payments, you need to have them very low latency. I think as we think about an AI LED future where you have AI robots interacting on our behalf to execute things. So let's think of an example.
00:34:50.567 - 00:35:32.455, Speaker A: I might have a portfolio on aptos and I want to maintain a certain percentage allocated towards different assets and have those automatically rebalance on my behalf. Maybe I want to do the second level granularity, or maybe I have an AMM pool that needs to be rebalanced frequently so it doesn't run out of funds and get liquidated. That kind of operation also needs to be very, very quick. So that finale time is really important to enabling use cases that just aren't possible or like it makes the use case very intractable going forward. And what we're also starting to do is think about how do we support those kind of autonomous agents working on aptos, which we think is actually really a really important differentiator going forward in the future.
00:35:32.755 - 00:36:21.225, Speaker B: Yeah, I'm very interested to see where blockchain AI intersects. Definitely early. There's a lot of excitement, I would definitely even say from the venture space. But I think the excitement is generally warranted in the long term. Short term there's a lot of experiments that will play out. But maybe on the block STM standpoint there's a lot of great things that you called out I think really around the optionality to kind of dynamically run it. But if you want to express your explicit intent to touch contracts, you can do that as well.
00:36:21.225 - 00:36:24.645, Speaker B: Kind of the best of both worlds.
00:36:24.765 - 00:36:52.415, Speaker A: Exactly. And so it's really about just giving the scheduler more information to do the best thing possible and parallelize and make it as much concurrency as possible. And so you can imagine A world like this is the thing about dynamic parallelism. It has to do. Also, I think the two key things of dynamic parallelism are going to be block STM as well as our pipeline infrastructure as well. The pipeline allows you to do two different things that are interesting. So once you have consensus on kind of this ordered set of blocks, it doesn't mean the transaction has been executed or it's been even accepted into the blockchain.
00:36:52.415 - 00:37:32.645, Speaker A: It just kind of means that there is some order now. Now, after the fact of that, you can then do this parallel execution engine and you can do dynamic parallelism to go ahead and reorganize those transactions in a way that's best suited for whatever goal you like or a set of goals. So let's give an example. One of the goals of the transaction ordering is going to be how do you kind of maintain the ordering of gas fees? Right? So transactions that pay more should kind of be prioritized. But you also don't want to have a completely serialized system in that case, right? Like, just because you pay more doesn't mean you want to actually have them execute one by one after that. So you also want to have a goal of how do you kind of make sure the resource usage on the machines is well utilized. And so you can actually start to use block ASTM to kind of manage between these two different goals.
00:37:32.645 - 00:38:14.717, Speaker A: And so some of the problems we see around fee markets, for example, right? So you have a situation. We have shared state today you have a very hot object that you want to access. And because a lot of transactions are accessing the hot object, it slows down everybody in the whole system. Now, in the world of dynamic parallelism with aptos, you can actually take those hot transactions and you can kind of feed in parallelizable transactions into the same kind of time of scheduling. And so while those hot transactions are kind of still sequentialized, you have all these other transactions that are filling the rest of the cores in the system. And you get a lot of parallelism out of that. And that's only because you have this very dynamic scheduler that allows you a lot of interplay and freedom around how that works.
00:38:14.717 - 00:38:34.065, Speaker A: You can also think about tuning and maybe not scheduling so many of those transactions at the same time. You can change. Like, if I don't want to have them in the same block, I can push on with the future blocks or I can cancel them. And so there's just a lot you can do when you have dynamic parallelism in the infrastructure. And again, the possibilities are kind of limitless. And I think this is the only way. The direction the industry must go.
00:38:34.365 - 00:39:10.245, Speaker B: The pushback or the alternative version that I hear from the strict parallelism camp is that if you do not determine the addresses that you're going to touch up front, there could be potentially much higher gas fees that are incurred by the user. Because if it is a hot or a contentious piece of state, you're only learning that kind of after the fact and then not able allocate the correct amount to get your transaction to land.
00:39:11.545 - 00:39:49.905, Speaker A: That's one possible way of solving the problem. The core problem is that you don't want to end up in a situation where those hot transactions are blocking everybody else. And as I kind of mentioned, there's different ways to go about it. One way is to actually just let those hot transactions continue at low gas fees, but don't schedule so many of them and then let a whole bunch of other ones that aren't blocking each other kind of go at the same time. So if I kind of had this, visualize this because of an example of like you have a 10 lane freeway or 16 lane freeway, let's say 16 cores. And two of those cores are blocked on a bunch of hot transactions, for example. And the other 14 lanes, instead of having them blocked, we just kind of feed in all the other cars that can go at the same time.
00:39:49.905 - 00:40:05.585, Speaker A: And so that produces a very nice. And then so those two lanes, they want to start having gas fees between them and start prioritizing, they can do that. But the other 14 lanes are free to go. And you just have to kind of figure out that mix of like how much contention do you want to support? How many contended transactions you kind of want to support in the system versus how much paralyzed transactions you want.
00:40:05.955 - 00:40:12.215, Speaker B: And in the strict parallel world, if those two.
00:40:12.595 - 00:40:20.643, Speaker A: Yes. In the stack plasm, you can also do that. But what you can't do is necessarily prune out those transactions. Like prune out cars in those two congested lanes as easily.
00:40:20.739 - 00:40:25.947, Speaker B: Okay, I see. To kind of do those throughout transactions.
00:40:26.011 - 00:40:26.451, Speaker A: Exactly.
00:40:26.483 - 00:40:27.139, Speaker B: Gas cost law.
00:40:27.187 - 00:40:30.171, Speaker A: Exactly. So you can kind of. Yeah. Those kind of dynamic optimizations.
00:40:30.243 - 00:40:30.867, Speaker B: Interesting.
00:40:30.971 - 00:40:35.611, Speaker A: Require dynamic runtime knowledge. Right. That's something. I think that's really neat.
00:40:35.713 - 00:41:02.797, Speaker B: Nice. No, it's super interesting. I think I've heard a lot of engineers express frustration with strict parallelism because it can be quite annoying from the engineering side. And I think the blended approach of dynamic parallelism with the ability to also express, hey, I'm most likely going to touch this as a Nice format.
00:41:02.901 - 00:41:34.517, Speaker A: It is, it is. And just thinking about the static thing again, like you have, you know, you probably programmed before, right. Logan, just imagine you have like a very simple case statement. If this based on this data, you know, I'm going to do X, Y or Z, you have to kind of specify all those as possible outputs. And now you've sequentialized something which is, you know, if you have 90% chance, it's only going to do one of those options. You sequentialize all those transactions anyway just because of that, unfortunately. So we like those hints as a way to help with the scheduling, but not as the ultimate decider of how we schedule.
00:41:34.621 - 00:42:00.553, Speaker B: Nice. Super excited. I think again, it has been really remarkable. Just the majority of the industry moving that way. Monad say movement, I've heard that cohesiveness really helps kind of explicitly within MOVE has helped Block STM really flourish across the variety of ecosystems.
00:42:00.729 - 00:42:35.113, Speaker A: Yeah. I think one thing that does help also is just people that use the MOVE on aptos that kind of get blockist in for free if they want it. And so we've seen a lot of partners that are starting to, you know, that want to use Move leveraging our stack and that's fantastic. So we've seen Initia use it, we've seen Roosh use it, we've seen Movement use it and others that are still not to be released networks leveraging that tech stack as well. And so sometimes you get MOVE on aptos and sometimes you get Block STM with Move on aptos and sometimes you get that plus also consensus protocols from aptos and we're happy to see the industry moving this direction.
00:42:35.209 - 00:42:44.965, Speaker B: Yeah. So the other items that I believe you mentioned were around Move two and then also the execution environment.
00:42:45.265 - 00:43:03.581, Speaker A: Yeah. So Move two I think is we're really excited about. And so as we talked about earlier, MOVE has been really focused on safety from day one. That was the core thing. It was not about functionality, about ease of having all, all things. You're used to normal programming languages. Just about how do you kind of make sure you build something at its core is really safe.
00:43:03.581 - 00:43:56.637, Speaker A: And so having the bytecode verifier, the MOVE prover, the concept of resources and things like that have been really important for it. But as we start to think about the future of move, I think there are two directions we're pushing it. One is definitely having more features for it. And so we've added things like randomness, we've added things like move objects a while back, we're adding new features around enums and Syntactical sugar that Wolfgang talked about during ae. All those things are great and they help programmers to be more productive and efficient. The other thing we're thinking about though is performance and how do we get MOVE to be as performant as every other VM out there and so redesign the VM to be everything from modern day vm, thinking about modern day caches, how do we do optimizations at the vm, layer around tail recursion and others. Very important.
00:43:56.637 - 00:44:38.419, Speaker A: So trying to get improvement out of move, which we think is possible, so it can actually be not only just safe, but also extremely performant and also extremely productive for developers. And having all the tools, the language to be there, I think are really important. And then also now that we have such great documentation tutorials and building out things that are kind of the equivalent of hard hat for movement, we think that that's going to provide a very compelling story for anyone coming into the Web3 space to think about. If I'm building from scratch, what's going to be the best place for me to get started? How am I going to get my application in production as quickly as possible with all the safety guarantees, performance guarantees and everything else that comes with it? It's going to be hard to resist.
00:44:38.547 - 00:44:54.505, Speaker B: Yeah. And so that approximate 10x improvement in execution, how is that either reflected in terms of of performance within the stack or even to the engineers that will ultimately build products?
00:44:54.625 - 00:45:26.705, Speaker A: I think it's going to have a very interesting impact. And the reason why is because execution is only part of latency. There's also the loading, the data loading, the modules that are necessary for execution. There is the consensus portion. There's also networking pieces. So execution is important, but it's only one kind of piece of the entire puzzle when it comes to latency aspect and the parallelism aspect. But that being said, I think the 10x improvement is going to hopefully at least, at the very least save a lot of CPU time on the machines and maybe allow us to do a lot more with a single machine going forward.
00:45:26.705 - 00:46:04.477, Speaker A: We have plans of how do you think about going to multi machine and kind of sharding across machines. We've already got a storage sharding implementation that we kind of talked about through last December 1st in the industry where we allow us to store to multiple RocksDB instances and that allows you to store to multiple RocksDB instances as well as different backends storage devices as well, which can allow you to scale out that performance. So I think comfortably, I could say probably at least a 2 to 3x in overall kind of throughput of the system. If we do it really, really well and we kind of also solve some other bottlenecks that are out there and that'll be huge. Obviously.
00:46:04.621 - 00:46:15.025, Speaker B: I can't remember the last time we chat, but I thought I asked you what you believe. The kind of like final bottleneck. Was it storage?
00:46:15.365 - 00:46:18.325, Speaker A: Yes, I think the final bottleneck will be storage eventually over time.
00:46:18.485 - 00:46:38.881, Speaker B: Cool. Amazing. And then the last thing that we haven't touched upon was what was the last technical aspect. So we talked about the virtual machine, Move two. Actually it was the virtual machine, but that was in combination with Move.
00:46:39.053 - 00:46:40.201, Speaker A: That's right. Gotcha.
00:46:40.313 - 00:47:02.725, Speaker B: Cool. Awesome updates. I think it's very exciting. I think the industry in my opinion and it has to move this direction. And now that you guys have published your results, those are open. End to end. Latency is coming down.
00:47:02.725 - 00:47:45.073, Speaker B: It's the virtual machine is kind of getting more refined. The programming language is continuing to be upgraded. That security aspect is really first and foremost. I'm excited to see what application engineers continue to build because I am very much looking forward to scale and applications that ultimately people will pay for or even if they don't pay for that affect a large amount of people. Because I think at the end of the day, the technology is so cool. We just need it in a large number of people's hands and building useful things.
00:47:45.209 - 00:48:20.979, Speaker A: Absolutely. And it comes back down to, I think our thought about the new economy, essentially accelerating the new economy. And for us that means really diving deep into the finance space, the payment space, remittance space, thinking about how new forms of advertising and loyalty take play in the market. And we have a lot of partners we're working with to kind of prove out use cases around that. And it's going to require new technology as well. Confidential token transfer is important and doing that at high performance, no one's done that yet. We've already got some great stuff there and we want to even push that area much further from where we are now.
00:48:20.979 - 00:48:37.919, Speaker A: So I think you're absolutely right. The infrastructure is ready. We've proven that at this point. And we've got to focus now on the upper layers of the stack and help builders achieve incredible, incredible new use cases and possibilities at scale with technology.
00:48:38.087 - 00:48:44.655, Speaker B: Yeah, I'm very much looking forward to it. Can I ask you spicy questions?
00:48:44.735 - 00:48:45.555, Speaker A: Let's do it.
00:48:47.055 - 00:49:09.321, Speaker B: I think maybe going back to the EVM and L2 ecosystem, there's been now more open discussions within the community about maybe they should have integrated execution. What are Your thoughts generally around L2s, their pros and cons, to kind of these blockchain ecosystems?
00:49:09.513 - 00:49:30.371, Speaker A: I'm not a max in that space, so I'll just say I think L2 is an interesting way to kind of shard out the computation. Right. I think a lot of people have taken that approach. It is the simplest approach to take. But I think that the usability aspect and trade off that comes with it is just the cost is too high. And I know we can do it at the layer one there. I mean we've proven that with aptos we can go a lot further in this space.
00:49:30.371 - 00:49:38.675, Speaker A: We can build an infrastructure that doesn't have to compromise in the usability aspects, but still supports the scalability that's needed for all Internet customers out there.
00:49:38.755 - 00:49:44.563, Speaker B: And the engineering trade off there is just you'll have slightly higher hardware requirements at the layer one.
00:49:44.619 - 00:49:45.159, Speaker A: That's right. Right.
00:49:45.207 - 00:50:28.677, Speaker B: Yeah. I think what I always like having the engineering chats because at the end of the day, kind of as you were talking with high performance computing, you have to be realistic. Nothing is unbounded and there is no free cake. And I think the engineers are always very direct or what I appreciate is that there is a trade off and it's just talking about, hey, if you want to optimize for low hardware requirements, go for it. We're making a differentiated trade off. And at the end of the day the market should probably, or the engineers that build on these ecosystems will probably decide, yeah, and I think the trade.
00:50:28.701 - 00:50:42.785, Speaker A: Off is clear for us. We're trading off, we're prioritizing user experience top first and foremost. And user experience to us is what's your latency, what applications can be supported, what's the cost? And all those things should be the best in class. And they are an aptos.
00:50:43.195 - 00:51:26.235, Speaker B: What? And maybe continuing on the L2 standpoint, it's kind of interesting because majority of those L2s today are kind of multi sigs. There's debates whether maybe backing up. Decentralization I think obviously is important. You get a lot of the aspects that we like, kind of the self sovereignty, being able to sign with your private key. But the industry hasn't really determined what is sufficient decentralization yet. Some think a single sequencer with an L2 is decentralized enough. Some think it's 10 nodes, 100 nodes, 1,000, 10,000.
00:51:26.235 - 00:51:30.195, Speaker B: Where do you see this spectrum playing out?
00:51:30.695 - 00:51:41.397, Speaker A: There are no right answers as you mentioned, but I think where we are we're pretty happy with. And so I think our Nakamoto coefficient is around the highest, if not the highest, around kind of major L1s.
00:51:41.421 - 00:51:41.981, Speaker B: That's pretty impressive.
00:51:42.013 - 00:52:07.915, Speaker A: I think 23 is our last number. I'll have to double check that. And we think of the liveness coefficient as being pretty high as well. And those are the metrics that we think about when it comes to security of the network. What is the safety and liveness properties of our system? And if I compare it to a multisig, if the multisig was 19 people who had equally vested interests in the survival of the network, maybe it's secure as what we do. But I don't think that's the case in most cases. Right.
00:52:07.915 - 00:52:32.829, Speaker A: And so that's the trade off. I would, I would kind of call out and we believe in, you know, consensus properties of a network. That's, that's what we think about from the decentralization aspect. It's got to be metrics driven. It's got to be thoughtful in terms of, you know, what are the safety, what can happen, what can go wrong. Right. So the ones that are harder to judge are things like, you know, what's the network risk to political and geo instability? Right.
00:52:32.829 - 00:53:14.385, Speaker A: How many countries is required for machines to be across, how many data centers? You know, if most machines are running AWS or gcp, is that a problem? Right. And so we want to make sure in those cases, at the very least, ideally one, there's no single point of failure. It's also important to kind of be realistic here and understand there will be some single points of failure. You know, we're not going to have probably 10 different chip vendors out there. We're not going to have too many different kinds of OSes. You know, Linux is great. Do we want to have a Windows implementation? You know, you know, do I want to have 10 different memory manufacturers at some point? Again, like there's, there's definitely centralization points and what are kind of the reasonable centralization points that make that, you know, that can operate in this space.
00:53:14.545 - 00:53:32.529, Speaker B: I always kind of thought this was a little funny because as you highlighted, there are always going to be points of, that could be potential bottlenecks. And even with you look at like the fiber, fiber optic cables that are laid across the oceans, there's not that many.
00:53:32.577 - 00:53:33.801, Speaker A: There's only a couple. Yeah.
00:53:33.953 - 00:53:55.973, Speaker B: And so as much as we want, I would say 10,000 or 100,000 nodes, really, there's only a couple major fiber optic cables that are going to transmit that data across the different oceans to make it a truly global decentralized network. Maybe with Starlink it throws a wrench in there, but not tbd.
00:53:56.109 - 00:54:12.515, Speaker A: Yeah. And we're just being practical here. Right. I think again, focusing on the user experience is the most key thing for us. And then thinking about what are the safety and security properties you want to see in the network and how does the network incentivize those kind of properties to be existing in practice?
00:54:12.635 - 00:54:25.175, Speaker B: Yeah. What is your strongest held engineering belief that you believe true, that others believe to be false? Kind of within blockchain landscape.
00:54:31.605 - 00:55:34.175, Speaker A: Oh, that's a good one, I think actually. Well, I'll start with the easiest one I think for me, which is, I think building everything together as a single stack is really, really important as a go to market plan. Like over time things may change, but having a single stack where you test, you develop and you're able to test holistically and then develop in tandem is really, really important. And I think this is something I've kind of learned throughout my experience as an engineer, as a researcher, and then in different roles I've had in the past. Because when you build in silos and you kind of build out your own individual thing, you almost always get the interfaces wrong, you get the requirements wrong, and then testability becomes a nightmare because you have to kind of exponentially down test all possible combinations of different software in that stack. It is much simpler to have a single stack that is kind of of well tested at its core in its practice, as opposed to kind of mixing and matching as many different pieces as possible. It's not that you're not going to do that, but definitely starting that way is going to be the best path to kind of quick success.
00:55:34.515 - 00:55:41.315, Speaker B: Start integrated and then potentially modularize over time if better pieces come about.
00:55:41.395 - 00:55:41.923, Speaker A: Exactly.
00:55:42.019 - 00:55:48.695, Speaker B: Makes sense. I think again, very logical answer. That would seem like best practices and web too.
00:55:49.035 - 00:56:12.891, Speaker A: Yeah, yeah. I think also. But some of that is something I think that is also learned over time. Like just learning that almost every time you start with the APIs, you get them wrong from the very beginning. And so that's why it's important to kind of make sure you're not, you're iterating over that you have an idea, we start to iterate, we start to build out use cases and building towards those use cases. Then we learned APIs, we learned out what people need. So always building with an API with a use case in mind is really, really important for this space.
00:56:12.891 - 00:56:14.299, Speaker A: But not just this space, just kind.
00:56:14.307 - 00:56:17.347, Speaker B: Of all engineering practices start from the product, not the engineering.
00:56:17.451 - 00:56:21.351, Speaker A: Right, right. It's Very, very hard to get the AP and you don't know the product you're building.
00:56:21.423 - 00:56:44.915, Speaker B: That's true. Maybe Final question. I guess a lot of things have kind of changed or maybe not changed within the last 24 months. What are you generally looking forward to through the rest of 2024? What are you excited about going into 2025?
00:56:46.185 - 00:57:37.377, Speaker A: I think I'm excited about so much. Like if I had to boil it down though, I'd say move to as a developer platform being kind of that what we feel is almost the very getting very close to asymptotic perfectness in how do we think about Web3 development and how we get closer and closer to that asymptotic perfection. We're getting better on that slope for sure. And so that is really, really exciting. The other thing of course exciting is just to see that now we've got massive scale and we're not going to let our foot off the brake and we're going to go ahead and see how far we can get in this space with the new improvements in consensus and on block STM V2. The third thing though, and then probably the most important thing is that use case driven development now. So thinking really really hard about with stables at Optos, with usdt, with hksa, with others coming on board, how do we best take advantage of that technology and then building across the entire stack.
00:57:37.377 - 00:57:56.633, Speaker A: So thinking about how does combination of tokens fit in there, how does the lower level infrastructure support things like how do we get best tick to trade execution in a blockchain on a decentralized network, really, really focus on those use cases then driving them to crazy new possibilities is something that gets me super excited about the space.
00:57:56.769 - 00:58:19.393, Speaker B: Totally agreed. Maybe briefly you mentioned kind of going from 16 to 32, 64 et cetera, et cetera. Do you think over time as just networking and higher core count increases, you go from 256 to 512 1,000 and just keep adding more cores.
00:58:19.449 - 00:58:47.615, Speaker A: It's definitely possible. Our goal here is not to necessarily run the most powerful hardware out there, but I think what's commodity enough so that we can have that decentralization we talked about. We don't want to be in only one data center that only has one piece of hardware. We want to make sure that that's supported across multiple data centers and ideally people can even run them them maybe at home with really good networking capabilities. But if we don't see the kind of Moore's law increasing fast enough, that's when we feel like, we'll go to multiple machines.
00:58:48.235 - 00:58:52.375, Speaker B: Do you think we'll ever go to ASX or FPGAs?
00:58:53.115 - 00:59:36.155, Speaker A: It's possible, right? I think especially in the cryptography space, as you see lots of new, interesting, I don't know, like quantum resistant cryptography being developed or fhe or other kind of things that are very exciting, I think those things are real possibilities. I think the key, again, now, the challenge in this space becomes if we want to see those possibilities taking shape, does that mean these are, again, specialized data centers? Are these specialized hardware? Ideally, it's commodity hardware that's available to everyone so we can continue to run in a decentralized platform. That's, I think, still something that we really want to build. I mean, our Optos is supposed to be the best kind of public utility for everyone out there, and we want to make sure that remains that way.
00:59:36.275 - 01:00:14.021, Speaker B: Well, then I guess we'll just wrap it up there, Avery. But I really appreciate you coming on the podcast. Thank you so much for the invitation out to Korea. Really looking forward to Aptos experience and the continued growth of the ecosystem, because, again, I think it's so directionally cracked that it's just a matter of time before it works. And as much as crazy as the industry is staying sane, continuing to iterate and making the product experience better will pay dividends. And so, again, really appreciate everything that you're doing to push forward the space.
01:00:14.133 - 01:00:30.189, Speaker A: It's definitely our pleasure to have to get to work with you again. Logan, you've been a true champion in the space, and we definitely appreciate everything you do to push for that. The need. There's a huge need for high performance blockchains, for the applications that we built on that, and for the 5 billion Internet users out there. So thank you for that.
01:00:30.277 - 01:00:31.125, Speaker B: Awesome. Thanks, Avery.

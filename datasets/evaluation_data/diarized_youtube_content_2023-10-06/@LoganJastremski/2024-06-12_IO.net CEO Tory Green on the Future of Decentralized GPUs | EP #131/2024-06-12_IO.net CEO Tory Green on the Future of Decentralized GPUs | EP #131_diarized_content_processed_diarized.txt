00:00:00.320 - 00:00:46.578, Speaker A: Take away the fact that we are building for the long term. As I said earlier, like, sure, we're going to launch a token, sure, we're a crypto company, but our goal is not to be a crypto company. Our goal is to take on AWS, GCP, Azure. I would advise everyone to like really get in there and learn about the product, read the documentation, read Ahmad's updates, use the product, get in the discord. Now, unfortunately, you go on the discord and the telegram and yes, 90% of people are asking win token, which is unfortunate, but it's just the world we live in. But like, you know, move past that. Like think five to ten years down the road.
00:00:46.578 - 00:00:51.018, Speaker A: Like actually get in there and try it and see what we do. Cause that's what we're all in this for.
00:00:51.114 - 00:01:09.414, Speaker B: This podcast was recorded May 20. This was before the changes of Tory becoming the CEO of Ionet and Ahmad stepping down. Please enjoy. Tory, thank you so much for joining me, the co founder and COO of Ionet. Thank you very much.
00:01:09.582 - 00:01:13.290, Speaker A: Thank you so much, Logan. It's definitely an honor to be on the pod.
00:01:13.590 - 00:01:27.210, Speaker B: Yeah. And thank you. I think we met your either first or second day of joining Ionet, which was a crazy time. And so it's amazing to see how much progress you guys have really made since then.
00:01:27.700 - 00:01:28.372, Speaker A: Well, thank you.
00:01:28.396 - 00:01:28.572, Speaker B: Yeah.
00:01:28.596 - 00:01:33.508, Speaker A: And I do remember our first call. It seems like years ago, but it was actually only like eight, nine months ago.
00:01:33.684 - 00:01:47.880, Speaker B: Yeah. Amazing how time flies. I would love to maybe like start the podcast, though, with a brief intro to your into yourself, how you got involved within the ionet team and then we can kind of kick it off from there.
00:01:48.260 - 00:02:25.460, Speaker A: Sure. So, you know, I've had a couple different careers. Started off mostly corporate, did investment banking and then corporate strategy and then private equity. And then the second half of my career, I shifted more to sort of like tech Web 2.0, was a co founder of a digital publisher and then was a vc for seven or eight years. And during that time I actually started off as more of an investing partner and then migrated to be more of an operating partner. So basically doing sales, marketing, finance, operations, strategy for port codes.
00:02:25.460 - 00:03:16.178, Speaker A: One of my last jobs was actually as coo of machine learning, fintech. And during that time I really got to understand some of the different nuances about AI, about the landscape, and especially some of the challenges facing the landscape at the same time. I had been personally into crypto pretty heavily since 2016, did a lot of writing about it, did a lot of blogging about it, and was always kind of looking for a reason to jump into crypto. But the problem I found was most protocols just basically seemed like, effectively, I'd say, like, problems looking for solutions. And this is especially true in deepen. I mean, there's a lot of great DPN ideas out there, but I didn't feel like any of them really solving heroin fire problems. And that's when I actually ran across Ionet.
00:03:16.178 - 00:04:00.240, Speaker A: And before that, I'd been combining a little bit of my knowledge with AI, with my knowledge of crypto. And this idea of a deep end for GPU's came to me. I was like, wow, this would be a great idea given that compute is becoming the most scarce asset in the world. There's huge shortage of GPU's, and there's all these unutilized sources. I actually started looking into the landscape a bit about this, and I ran across Ionet, met Ahmad, and was instantly very, very impressed with him. And I think partially because I've been a vc for so many years, I kind of have pretty good pattern matching when it comes to founders. And so a couple of the things that I saw that I really liked in him are, number one, he's just, you know, he has this extraordinary vision for where he wants, like, our product to go.
00:04:00.240 - 00:04:26.248, Speaker A: Number two, he's like, I mean, forget a ten x engineer, he's like a thousand x engineer. And number three, he has just the most insane sense of urgency that I've ever seen. And so I was like, you know, this is the product, and this is the guy I want to work with. And so I actually started working with him for a couple weeks. You know, we hit it off very, very well. And then I said, you know what? This is the time quit my job and joined Ionet. This was about August when I met.
00:04:26.264 - 00:05:17.206, Speaker B: You for the first time, maybe to dive into some of the specifics. I think we've all seen the historic rise in GPU demand, and the capacity has really not kept up. And I think it's either largely gone into the hands of their traditional large web, two companies, the Facebooks or the metas, the Googles, the Teslas of the world. On the flip side of that, though, you have this weird phenomena where you have these home GPU's and home computing, primarily in gaming computers. Can you talk about the inspiration for ionet to potentially be the connective tissue between these or tapping into the unutilized resources, as you mentioned?
00:05:17.358 - 00:05:30.650, Speaker A: Sure. And underutilized. It's more than. It's more than consumer GPU's. And just to give you sort of the landscape like, as you said. Yes, our thesis is pretty simple. GPU's are the most important resource in the world.
00:05:30.650 - 00:06:06.780, Speaker A: They're basically even China literally imported more chips than oil last year. So this idea that GPU's are the new oil and they're so important because they're used to train, optimize and distribute AI models. And so I think the complexity of AI model is doubling every 3.4 months. So the demand for these things is huge. And as you said, there's just really not enough supply in the cloud. Yeah, you have aws, you have Azure, you have GCP, but the demand is two to three times greater than the supply.
00:06:06.780 - 00:06:28.740, Speaker A: There are however, all these underutilized sources that people aren't tapping into. You mentioned a big one, consumer GPU's. Yes, like 90% of the GPU's out there are consumer. They're really not being tapped into. But there's also other major sources. Idle crypto mining farms are a big one. And there's a lot of underutilized data centers.
00:06:28.740 - 00:06:54.640, Speaker A: I think the average data center runs at twelve to 18% utilization. And a lot of these data centers have a. So they have some of the best cards. And basically what we're doing is we're effectively serving as like an Airbnb for GPU compute. So we're tapping into all these unutilized sources and that allows us to provide nearly unlimited computing power to machine learning engineers at up to 90% cheaper than AWS, GCP and Azure.
00:06:55.660 - 00:07:36.540, Speaker B: So within those specific computes, I mean kind of you have the cloud clusters that are run by the big tech companies, but then you also have kind of the bare metal compute, which are data centers operating specifically for whatever software that you want to throw on them. And then you have the home compute. Does ionet specifically have a preference towards a particular type of compute? Or is it more about aggregating compute holistically and enabling a marketplace for that?
00:07:37.220 - 00:08:44.278, Speaker A: Well, let me sort of step back in a second, because this is what is difficult for a lot of people to understand about ionet. And you mentioned the clustering, and I think it's sort of helpful for people to know what that is, because quite honestly, this is something, and I've been around AI for years and I wasn't aware of this, but clustering at a high level is taking multiple gpu's to work as a single powerful supercomputer. Everyone doing AI uses clusters. Without clusters, it would have taken ten years to train GPT-3 so it's like Uber's using clusters, OpenAI is using clusters, Instacart's using clusters, everyone's using. Now, it's very easy to create a cluster from a when all your gpu's are co located. So right now, like everyone, if you go to GCP, you go to Azure, you go to AWS, you can basically spin up a cluster. Where the problem is in the market is until ionet, no one has really found a way to create clusters from different geographic locations.
00:08:44.278 - 00:09:33.560, Speaker A: And so because of that, while the sort of like Airbnb for GPU's is a great idea, it hadn't actually worked previously, right? Because if you go to most of our competitors, what you get is you get a single instance, you get one to eight gpu's, which you're not going to really use that unless you're a hobbyist. Our secret sauce is the ability to cluster across multiple locations. And we can really do it on any type of hardware you want. We can cluster a 100s, we can cluster h 100s, we can cluster 3090s, we can cluster m three chips. So whatever the consumer wants. But the key is that we can actually leverage all of these other sources, and that's why a lot of our suppliers are actually other dpins. So Filecoin is a supplier, aether's a supplier, render's a supplier, Nosana's a supplier, Gaiman's a supplier.
00:09:33.560 - 00:09:48.740, Speaker A: I think Nosana is. Forgive me if I confuse our pipeline with what we've announced, but a lot of these, a lot of these sort of, I don't want to call them bare metal, but a lot of these Airbnb for GPU's are actually feeding into us.
00:09:49.370 - 00:10:39.924, Speaker B: So what's the secret sauce with like, either being able to cluster the GPU's, because I think that is a huge unlock. I mean, as you mentioned, the like, NV Nvidia link was really kind of that secret sauce that allowed you to scale these huge clusters acting as a single compute. But the kind of decentralized nature of blockchains can kind of throw a little bit of a wrench in that just because you can be in New York and Miami or San Francisco and Dubai, and those get a little bit harder to cluster from a latency and bandwidth standpoint. So can you talk about, like, specifically how I od does the clustering? Is it like by geographic region? Is it just the software? What's the secret sauce under the hood?
00:10:40.052 - 00:11:24.974, Speaker A: Sure. So, and forgive me here, because I'm not technical, but you know, I'll give you sort of some of the background about how we started. So Ahmad, he had his own AI quant trading fund, and he was spending, you know, hundreds of thousands a month on GPU compute. And he had some friends come to him and say, hey, we have idle crypto mining farms, you know, would you like to use our GPU's? And he said, sure. But what he realized was they were in different locations. And the preferred framework for machine learning that he used, called Ray, could not aggregate across different locations. And so, like, you know, like a lot of crazy entrepreneurs, he basically was like, okay, so he forked or a rewrote it and basically figured out a way to make ray work in different geographic locations.
00:11:24.974 - 00:12:06.970, Speaker A: And then once he did that, he basically realized that, wow, you know, I have, I have something much bigger. And so that became ionet in terms of the technical details of how it works. Like I said, I'm not an engineer, but at a very high level. What the system does is it's a fork of raydhennae, and so it uses ray in different locations, but it's basically designed to minimize latency as much as possible. And it does that by first, it will go and try to find co located GPU's. So it will try to fill as much of your order from co located. If it can't do that, it will reach out and it will find what is the next best option that could be geographically.
00:12:06.970 - 00:13:01.138, Speaker A: So maybe there's another data center that's very close that can reduce latency, or it could also be in bandwidth speed, may have a third data center that's farther, but has higher upload download speed. And so it would use that. And so what that is doing is it's trying to minimize latency. Now, when it comes to the latency question, because one of the big questions we get is, okay, well, isn't it always slower to do this in a decentralized manner? And I would say if you hold everything else equal, then yes, it is slower. But the truth is that things are rarely equal in real life. And so when you think about our platform, I think the first thing to think about is think about us more as like a priceline or a kayak. Right? Let's say you want super high performance, super high speed.
00:13:01.138 - 00:13:45.928, Speaker A: Well, we can get you 150 a 100s connected with nvlinkhead really close to you. So we can basically deliver the same or even better latency than you can get from AWS, GCP, or azure. I don't know how much of a discount you're going to get. Maybe in some cases you pay more, but it's more about choice. Just like on Priceline, you can fly spirit or you can fly emirates first class. Now, if you just really want to save money, sure, maybe you have fully decentralized GPU's using three thousand ninety s, and you can get off to maybe 90% off, but you're going to be a little slower. Now, the next thing is going back to the.
00:13:45.928 - 00:14:24.000, Speaker A: When I say, like all else being equal, distance is obviously one thing that affects latency, but so is upload download speed. And I believe that 40% to 60% of our data centers have faster bandwidth speeds than lambda labs. And so you may actually get better performance in a decentralized cluster if you have data centers with higher upload download speeds. And finally, a lot of what we're talking about is more for training. What we do is a lot of inferencing. And we've actually found that for inferencing, a decentralized network can even work better. I'll give you a simple explanation of this.
00:14:24.000 - 00:14:58.100, Speaker A: Let's say that you have an app that's like a stable diffusion clone, and you have a user that is sitting in Vietnam, and they say, I want to, I want to generate a picture of a dog wearing a hat. Well, if you're using a centralized data center in Texas, that's got to ping all the way from Vietnam to Texas and back again. But with a decentralized network, you can actually say like, well, hey, we've got a couple GPU's sitting down in Singapore, let's just ping them, and you can actually be faster. And so in that way, we're kind of building what I would best describe as a CDN for inferencing.
00:14:59.560 - 00:16:09.480, Speaker B: Yeah, it's very interesting. There's a lot of different nuance from the technical aspect of making these things work, but I think you, on a high level, touched upon the very important ones. And I think maybe even leaning into some of the unfair aspects of how you'll be able to provide some of this compute, potentially at a cheaper cost. Because historically this was idle or non existent compute that was not accessible, or to your point earlier, was potentially sitting idle in a data center not being used. But those resources are there, and as much as possible, you really want these extremely valuable resources as they've come. I think Sam Altman said, compute and energy are probably going to become the most scarce commodities in the next couple decades of being utilized as much as possible to their full potential. Can you touch upon, just like the pricing and really what you guys envision for long term, what Ioanet will enable.
00:16:10.260 - 00:16:32.850, Speaker A: Yeah, so, and I'm actually looking at our explorer right now, and I would actually highly, highly recommend anyone who's interested. We just updated our platform. We released cloud 2.0. It's got a much better UI. All of our pricing is very, very transparent. And I'll just give you some examples. Right now we have 40 gigabyte a an hour.
00:16:32.850 - 00:17:28.220, Speaker A: Let's see here. If I can scroll down 80 gigabits at 150 an hour. I thought, and don't quote me on this, I thought we had either a 100s or h for a little while. But in short, we have a huge supply of enterprise chips and they're quite frankly, the lowest market, they're the lowest rates in the market right now. And that's where I think we're going to go. In the short term, our goal is to disrupt AWS, GCP and Azure, because by using a decentralized network, we can offer faster access, lower prices and just an overall better experience compared to them. And as we continue to grow, obviously this advantage will continue to get deeper and deeper.
00:17:28.220 - 00:18:06.240, Speaker A: In the long term, who knows? There's a lot of options that we can do with this. One option is once we've built the compute layer, we could potentially build a storage layer on top of that where people could store models. And then on top of that, we can maybe build an SDK so people could make their own apps, and we could have an app store for AI apps. And we've actually already kind of built this in an app that we're dog fooding. It's called BC eight. So that's Bravocharlie Eight AI, and we created this ourselves. But basically it's the first fully decentralized AI app.
00:18:06.240 - 00:18:53.024, Speaker A: You can go on there, you can generate an image, and every compute, every, every GPU that it's made on is decentralized. And every part of that transaction is recorded on chain. So it shows, you know, there are all these micropayments. So it may be like a one, you know, 1000th of a cent to the app creator, 1000th of a cent to the model creator, you know, two thousandths of a cent to the compute provider, and then 1000th of a cent to ionet. And so that's, that's potentially one option where we sort of build vertically. The other option which we've toyed with is we now have like 20 to 30. We have close to 100,000 verified GPU's on our network and 30,000 or so that are active, and a lot of these are enterprise grade cards.
00:18:53.024 - 00:19:11.060, Speaker A: And so when we think about that, it's like, well, wow, we could, in theory, use this to build basically the most powerful l one in the world, maybe go down that path of like an l one for AI. And that's not something we've solidified on, but we definitely do have the resources for that, and that's something we're looking to in the future.
00:19:12.920 - 00:20:10.040, Speaker B: Yeah, there are a lot of options in terms of the specific amount or specific compute. You mentioned a lot of enterprise GPU's. Are those the main things that you think are going to be targeted for the network, or is the network pretty agnostic to just general parts of computer? Either, like six months, twelve months, 18 months down the line? Do you think the network consists, majority of people that have a 3080, a 4080, 4090, or an m one, m two, m three, they're trying to earn extra dollar a day on providing their idle compute capacity and would do that to the ionet of the world? Or do you think majority of the compute that's onboarded is going to come from the idle data centers that just need to make sure that their machines are running constantly?
00:20:10.940 - 00:20:32.280, Speaker A: So the network is definitely agnostic. But we're not. The Devco is not. And that's the thing. The Devco is running a business. And one of the reasons that I joined Ionet is I do have, this is my fourth time as a COo. And, you know, I do have a lot of experience sort of building inside sales teams.
00:20:32.280 - 00:21:19.352, Speaker A: And so, you know, on the Devco level, obviously, part of our job is to get as much supply and demand for the network. And there's a lot of different angles that we could have gone with this, right? We could have gone, we could have gone pure consumer. We could have gone to big tech, we could have gone to enterprise AI divisions. But where we found the biggest consumer need was in seed to series a startup. A lot of these guys are spending like $700,000 a month. And I think Andreessen did a, did a study that showed like 80% of a startups VC funds go to go to compute. And so imagine you're running.
00:21:19.352 - 00:22:01.026, Speaker A: Yeah, imagine you're running like a CTA startup, and you're spending everything on compute. And so these guys have this like amazing heroin fire problem, and they just need cheaper compute. And when you need cheaper compute, you know, it's like they're less concerned about security. They're less concerned about a lot of things. And so, you know, being a pretty disciplined operator, I was like, all right, like our sales team is going to focus on these guys and what do these guys need? These guys need a. So most of our sales motion is focused on sort of building that moat around early stage generated AI startups. And so most of our supply motion subsequently is focused on getting enterprise GPU use as well.
00:22:01.026 - 00:22:51.010, Speaker A: Now that said, once we sort of get past our beachhead market, who knows, right? Once we develop proof of concept, it's going to be a lot easier for us to serve big tech companies once we start. One thing we have in process is we're getting a lot of our GPU's SoC two certified. So once we do that, it'll be a lot easier for us to go to someone like a JP Morgan or a procter and gamble and be like, hey, let's work together. To the extent that we do get more consumer cards, we can start having a sales motion that caters to that. Who knows? Potentially we get enough GPU's. I mean, we could be the preferred provider to build chat, GPT six, or whatever. So I think in the short term we do have a goal where we're going, but the network itself is agnostic and so we will be very responsive to the market.
00:22:51.010 - 00:22:56.770, Speaker A: And so if we see a lot of a certain type of supply, come on, we're obviously going to cater to those as well.
00:22:57.630 - 00:24:05.910, Speaker B: Yeah, it makes a lot of sense, and I appreciate the pragmaticism as a strategic operator. I think though more holistically, it's been, we've seen a lot of these decentralized physical infrastructure networks focus a lot on bootstrapping that supply side. And historically, tokens and that incentive, either points or through the token, have done a really good job of bootstrapping the supply side, but the demand has historically been a little bit more of a challenge. I think Ionet, and kind of the AI crypto industry or intersection is really in a unique spot because it's a clear demand that's needed in the world. And if you can aggregate the supply side, the demand side should be, I won't say simple, but at least, you know, there is a customer base out there. Can you talk about that sales pipeline in a little bit more detail and kind of how you envision bootstrapping the demand side of ionet?
00:24:06.650 - 00:24:52.982, Speaker A: Sure. Right now it is primarily we're building an inside sales team. So we're basically going to startups 101 and we're saying like, we have a list of, I think, 500 plus startups that represents like an ACV of $1.8 billion. And we're basically going to these one by one, and we're signing Lois, we're signing partnerships. As we said, one of the main reasons I came here was because unlike a lot of deep ins of the past, there really is a hair on fire problem. And so it's not the quickest process, but building, because a lot of these guys, everyone's going to come on skeptical whenever you say, hey, we can offer 70% off AWS.
00:24:52.982 - 00:25:34.988, Speaker A: People are like, yeah, but can you really? Or does it work or is it going to have too much downtime? And so a lot of these guys like some test with us for weeks, some test with us for a couple months. And so we have this pretty fat pipeline of people that are in testing and they're starting to roll into actual gmv. And we have a decently healthy gmv. So far we're over a million. But we have many, many more startups in the pipeline that are moving down right now. I think this is our primary focus to sort of ramp these on. But as I said, we're also going to experiment with more, maybe for smaller customers, more of a marketing driven approach where we advertise people to come on and use the platform more self service.
00:25:34.988 - 00:25:42.630, Speaker A: Because a lot of the larger players, even though our platform is self service, they need varying degrees of handholding to get what they really need.
00:25:43.490 - 00:26:03.030, Speaker B: What do you feel like is going to be like the most challenging aspect, so to speak, of bootstrapping this entire thing? Is it going to be getting more compute on the network or is it going to be making sure that the GPU's are utilized, the tech stack? I'm curious, from your perspective being there.
00:26:04.010 - 00:26:29.820, Speaker A: I think it's more complicated than that. I think it's a bit of a, like, almost like a cat and mouse game, right? I. We know everyone wants a so very high demand. That's nothing to worry about. So we've got to get a lot of Enterprise GPU's. We build up our stack of Enterprise GPU's, and then we get more demand for Enterprise GPU's. But anytime you go up the supply curve, it's going to be harder and harder to find enterprise GPU's.
00:26:29.820 - 00:27:28.230, Speaker A: We may say, all right, is there a point where I think for a while, we've been very successful in finding enterprise GPU's and growing our GPU's supply? Like I said, I think right now we have 100,000 overall GPU's 30,000 that are fully available for clustering. So we think that there's some Runway on this, but there will become a point where it's like, all right, we've started to really saturate the enterprise GPU, and so maybe we have a bunch of consumer cards. How can we find uses for that? So it's always going to be finding one type of demand, finding one type of supply, finding another type of supply, finding another type of demand, and growing that until, I think. I think until the network reaches basically a tipping point where just everyone knows that this is the place for GPU's. And then things just run away because then you have suppliers coming on organically, you have demand coming organically, and you sort of leverage that first mover advantage into a long term mode.
00:27:29.730 - 00:28:00.358, Speaker B: Yeah, it's true. To be known as kind of like the predominant GPU marketplace, either similar to, like, a Google or an Azure would really put you guys at a strong footing compared to everybody else. And to me, the interesting thing kind of about these deep end networks is I feel like they're potentially the most clear product market fit if you can get that flywheel going.
00:28:00.524 - 00:28:31.840, Speaker A: Yeah. And the truth is, we are a crypto company, but we don't see ourselves as a crypto company. We don't get caught up in the day to day of different deep end providers and what they're doing. I mean, we're a competitor to AWS, GCP, Azure, plain and simple. We have much, much bigger goals than crypto. It's just that crypto, obviously, you cannot do what we're doing without crypto, so we need it as a tool. But ultimately, we see ourselves as a competitor to big tech.
00:28:33.300 - 00:29:02.998, Speaker B: As of today, the last maybe couple weeks or months have there's been a certain individual kind of highlighting some things and maybe some confusion either on the ionet side or the community side. What do you feel like has been, like, the biggest misunderstanding or learning lessons from, like, the last couple of weeks and some of the noise from the community that the team has kind of heard?
00:29:03.174 - 00:29:43.184, Speaker A: Sure. I think the biggest thing that, I mean, quite frankly, we messed up. We got civil attacked, and, you know, none of us saw it coming. You know, our GPU's started, like, going up pretty quick, and we were like, oh, this is great. You know, like, we have the airdrop program, we're getting the word out there more. And it was pretty steady, and it was kind of like, you know, all right, like things are going up. And then it finally got to a point where I think it went from like 600,000 to a million, like overnight.
00:29:43.184 - 00:30:14.398, Speaker A: And that's when all the alarm bells started going off. We're like, wait a minute, like something, something is off. And so that's when the team went in. They dug deep, and we basically figured out that were being civil attacked. And that was tough for us because the market started to notice that as well. And, you know, we were, quite frankly, caught in a really tough spot that we, you know, we just had. It was something that, like, we never really thought, we never really thought about.
00:30:14.398 - 00:30:46.560, Speaker A: Right. And I guess when you become such a high flying product, you become a honey pot. But once we once, yeah, once we figured it out, we basically started to, we completely changed our explorer. We started to divide GPU's into a number which we now call unverified, which is basically anyone who is claiming to be a GPU, and then verified. We have this process which is a proof of work process we run GPU's. The simple way to explain it is we basically run them for a couple minutes to figure out if they're real. And then we have a third category, which is active GPU.
00:30:46.560 - 00:31:14.390, Speaker A: Just because a GPU has verified is real at one point in the network doesn't mean that it's actively be providing. And so our initial response to this was, all right, the number one thing we have to do is we have to provide as much transparency as humanly possible because we did get attacked. But let's be honest, like, that's our fault. Our security wasn't good enough, and so we were very open about, you know, we move fast and break things. The security wasn't great. We got attacked. We didn't expect it.
00:31:14.390 - 00:31:58.720, Speaker A: And so now we are going to be as transparent as humanly possible going forward. And I think the tech team has done a really fantastic job at that. Ahmad has just been out tweeting on exactly what's going on. As I mentioned, we've changed the explorer. We're updating our proof of work logs every 6 hours so any engineer can get in there and test it. And we've really started to see the sentiment turn around. I think people, you know, whereas we went from, like, a lot of people thinking, okay, well, is Ionet some kind of scam project? To a lot of people saying, like, all right, you know, these guys made a mistake, they got attacked, but they are really changing their ways and they're being more transparent, and I think that's garnering a lot of respect for people, which is very important to the community.
00:31:59.620 - 00:32:15.280, Speaker B: 100%, I guess, from, like, the civil attack was the biggest learning lesson there. Just adding in that proof of work component to essentially verify that this compute is legitimate, as it says.
00:32:16.550 - 00:32:55.632, Speaker A: I think so. I think that was probably the biggest learning lesson after. But I also think, you know, just, like, fully being transparent at all times with the community, letting them know what we're doing, getting ahead of things. Like, we've released. We've released bug lists, so people know what our different problems are. And just basically, we're like, all right, you know, it's not like we were ever being untransparent, but transparency is really something you have to work at. And so just deciding as a team that we're going to sort of fail in public effectively, you know, we're going to show our work.
00:32:55.632 - 00:32:57.900, Speaker A: I think that was the biggest learning lesson.
00:32:58.600 - 00:33:46.840, Speaker B: I. It was definitely the talk of the Twitter universe for quite some time. And I think being more transparent is always good, and highlighting some of the key learning lessons, fixing the bugs and moving forward. I think bugs, to me, are always kind of a part of the process in terms of engineering. And as long as the core code in my mind is sound, then you'll ship bugs. And the goal is to minimize those, but making sure that the underlying software is not, like, fatally flawed. For example, in 2022, Solana had lots of downtimes and issues.
00:33:46.840 - 00:34:13.850, Speaker B: Everybody would come ask me, and they're like, Logan, why is Solana going down? I'm like, look, unfortunately, it's just part of software engineering. When you're part of a tech company, as you know, Tory, for a long time, bugs unfortunately happen. I think it's the response of the team, how you deal with those. And to your point, kind of being that open and transparent, that ultimately continues to build trust with the communities over time.
00:34:14.350 - 00:34:38.216, Speaker A: Well, and what few people understand, and I've been at VC for a really long time, few people truly understand the concept of disruption. Disruption is a very specific thing. And the example I always use is. And actually, I would argue that disruptive technologies are always. They always begin worse. The perfect example of this is the telephone. When at and t created the telephone, it was pretty crappy.
00:34:38.216 - 00:35:07.408, Speaker A: It could only go, like, a few hundred feet. And so the telegraph was much, much better because it could go across the country. But there was one thing that the telephone could do that the telegraph couldn't. It could provide instantaneous voice communication. And so as the bugs in the telephone worked out, it eventually was able to go the same distance and sort of overcome the telegraph. I think that's what we're seeing in crypto. And so when people talk about like, oh, Solana has too many outages, like, this is normal growing pains.
00:35:07.408 - 00:35:42.668, Speaker A: And I think it's the same thing with us. Like you said, we're bound to have bugs, we're bound to have things we're working on. And so I think the best way to address it is transparency. And I think with the transparency, what we're also trying to do is let's turn this into a positive. Let's set a new standard. We now have proof of work, so we're going to throw the gauntlet down and say, all right, other deep end projects, what are you doing to verify your GPU's? That's the level we want to get at, because we can verify beyond a shadow of a doubt that the numbers on our explorers are correct. So let's start digging into other networks, other deep ends.
00:35:42.668 - 00:35:46.600, Speaker A: When they're claiming they have so many GPU's, well, how are they verifying theirs?
00:35:48.100 - 00:36:03.930, Speaker B: Yeah, I've been pushing this for the layer one blockchains for a long time to try to standardize metrics across the industry. I don't know if we're getting closer to that or not, but any standardization I would love to see happen.
00:36:04.060 - 00:36:07.050, Speaker A: Yeah, no, I agree. I agree.
00:36:10.190 - 00:36:51.610, Speaker B: Maybe looking forward a little bit. So the team has really rapidly built out the core product set. Being able to enable either these idle compute or compute that is not being used in kind of homes or apartments to be brought online. You're building out the sales pipeline to onboard the demand side. Kind of ran into a couple bugs, snags on the community side. Those are being addressed. What do you really see as the path forward in the next couple months for the Ionet team or what is the team really heads down on today?
00:36:54.230 - 00:37:45.932, Speaker A: I think it's just continuing to build. Obviously, we have our tge coming up soon. We're finalizing a date now, but it's really just continuing to build on all fronts, continuing to build the demand side, continuing to build the supply side, continuing to make sure the product works better, and that we address any concerns. We take out any bugs. And continuing to build our community, I think that's for the foreseeable future. For the next three to four months, it's just build, build. And then I think as we progress longer, once we're in a comfortable spot there, we will sit down and we'll think, okay, where do we want to go next? Do we want to sort of vertically integrate this product more? Do we just want to keep growing here, get a million or more gpu's on there.
00:37:45.932 - 00:37:58.740, Speaker A: Do we want to transition into an l one? I don't think we've answered that question quite yet, but I do know in the near future, it's pretty much all hands on deck to make sure that we are delivering the product and making our customers happy.
00:37:59.880 - 00:38:36.380, Speaker B: Yeah, I love it. I think in crypto, remarkably, it's rare, I think, to focus on the product. Unfortunately, if the product is loved and people rave about your product, kind of everything else in my mind naturally falls, falls in place. During my time at Tesla, famously, they did no marketing. And I think it was because the engineers spent so much time on trying to make such a unique product experience and a product that was that much better that it kind of sold itself.
00:38:37.120 - 00:39:03.000, Speaker A: And I think the easy thing about us is, I would say to anyone who has read the FuD and has concerns, who has doubts, go on the network and use it, right? It's like, it works, period. And so, like, you know, if we're lying, it wouldn't work, but go in there and use it and like, that should. I think that should solve the problem because that's what we spend all our time working on, is the product.
00:39:03.620 - 00:39:58.470, Speaker B: Build a cluster. Build a cluster. Cool. Well, maybe wrapping up, what are the, like, top things someone watching or listening to this podcast, they kind of understand high level what ionet is trying to do. Aggregate these idle gpu, either units or clusters around the world, enable them to be used hopefully to more of 100% uptime or utilization rate and enabling kind of these new Google cloud or azure compute clusters and geographically disperse. But if they were to nail down on a couple things, what would you want them to take away from? Like the ionet podcasts and what you guys are really building towards?
00:40:01.210 - 00:40:42.964, Speaker A: I would say take away the fact that we are building for the long term. As I said earlier, sure, we're going to launch a token, sure, we're a crypto company, but our goal is not to be a crypto company. Our goal is to take on AWS, GCP Azure. That's really where we're going. So I think that's point number one to get out of all this day to day. You know, honestly, it's like children fighting on Twitter. And it's, you know, I've sort of stepped away from Twitter for that.
00:40:42.964 - 00:41:22.282, Speaker A: But like 1d pen versus another DPN, it's silly, right? Like we're all in this to disrupt big tech. I don't know why people are taking shots at each other. That's, that's just my opinion. And I think the team isn't really that concerned about it either. Like, we have a much, much bigger goal. And I think number two is to, I would advise everyone to, like, really get in there and learn about the product, read the documentation, read Ahmad's updates, use the product, get in the discord. Now, unfortunately, you go on the discord and the telegram and yes, 90% of people are asking win token, which is unfortunate, but it's just the world we live in.
00:41:22.282 - 00:41:31.070, Speaker A: But move past that, think five to ten years down the road, actually get in there and try it and see what we do because that's what we're all in this for.
00:41:32.260 - 00:41:58.036, Speaker B: Amazing. Well, we'll end it on that. Tory, thank you so much for coming on. Really wish you and the Ionet team all the success and look forward to see what you guys are building. I think every team kind of hit will ultimately encounter snafus, bugs, issues. It's how the team responds and moves forward from that and excited to see what you guys continue to do because you're really pushing forward on the industry. So thank you again.
00:41:58.228 - 00:41:59.220, Speaker A: Absolutely. Thank you, sir.

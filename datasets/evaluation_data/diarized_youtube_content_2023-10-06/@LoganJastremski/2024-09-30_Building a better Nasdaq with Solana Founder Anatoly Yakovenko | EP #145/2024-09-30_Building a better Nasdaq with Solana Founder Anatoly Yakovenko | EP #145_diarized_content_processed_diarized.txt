00:00:00.360 - 00:00:44.365, Speaker A: Silly tagline blockchain at Nasdaq speed, it's the North Star. Because it's possible, I guess in a way, as an engineer, you sometimes get like, I can build this really cool thing. I think if it exists, it would be a better product and it would reduce latency and friction and finance. And that means better pricing for customers and better prices always win. So I think not only is it inevitable because it's possible, I think it's inevitable because it's better. And even if the matching engine at Nasdaq, no matter how fast it is, it could be nanoseconds or milliseconds. The data around the world that somebody would trade on still has to go travel around the world to whatever that data center is, wherever all those trading systems are that can process that news.
00:00:44.365 - 00:01:27.567, Speaker A: What matters is not the matching engine speed. What matters is when that trade is tagged and ordered. So if we're sitting in Singapore and there's a Solana Block producer, and I think you can even simplify to just, there's a timestamp in Singapore that the network counts as somebody that can give you a good clock. When you make the trade in Singapore, you can send that message to the local block producer that's right here. And that distance is going to be miles and it's going to be very, very fast. The speed of lighter fiber. So by the time the news goes to New York, there's already a Solana Block producer that transmitted that transaction.
00:01:27.567 - 00:02:17.625, Speaker A: So that NASDAQ trader cannot arbitrage the price from Solana to New York. It means that Solana is as good at price discovery as NASDAQ or nyse, even though those things have very, very fast matching engines, right? Like, this is like the coolest, weirdest, eureka moment that I had is that we don't need to beat them on what they're good at. We can actually build a totally different product without sacrificing the permissionlessness, the openness of these networks. It's still random hobbyist that sets up this box if they wanted to in Singapore, one in New York on open source hardware, open protocols. And that's a very, very cool thing, right? It's transparent and open, run by anyone, run by volunteers. And it's better than nasdaq.
00:02:19.215 - 00:02:35.195, Speaker B: Tolle, thank you again for coming on the podcast. Always enjoy having you on. We're at your fourth break point, the community's fourth break point. How are you feeling about this break point versus 1, 2 and 3. Each have had high highs, low lows, and all the emotions in between.
00:02:37.855 - 00:03:14.165, Speaker A: It'S been. Each one has been like, I think, a milestone and kind of like a snapshot of the ecosystem at that time. And the low, lows were low. And I think this one is definitely the best by far. It's the biggest one, the largest set of companies and builders and devs across every possible spectrum of verticals and crypto you can think of. Like, the game conference is packed with games, and I talked to the founders and they're have revenues, they're profitable.
00:03:14.465 - 00:03:16.405, Speaker B: That's a crazy word in crypto.
00:03:17.025 - 00:03:34.849, Speaker A: Yeah. They built real companies with sustainable growth and stuff. It's really, really cool to see and to see that happening. So I am very excited that this conference almost looks normal as a normal tech conference.
00:03:35.017 - 00:04:16.873, Speaker B: It is remarkable. I think it's a testament, I would say, to the Solana community. And as you mentioned post 2022 break point, we're kind of all excited. And then different things happened in the world that were kind of outside the control of the community, which were hard on everybody. And 2023, I felt like, was a time that the community was just like, we're in it together, we're grinding. And every break point, to me, kind of just seems like celebration of the community and the engineers that grind throughout the year and one time together to showcase all their work. So, yeah, it's been fun.
00:04:16.873 - 00:04:33.285, Speaker B: But I think as much as I like to nerd out with you, and I'm sure we will throughout this podcast, I want to continue to harp on, I think if we continue to do more podcasts in the future, this global NASDAQ blockchain. And you've said this from day one.
00:04:34.305 - 00:04:38.247, Speaker A: Silly tagline, blockchain at nasdaq's blockchain at NASDAQ speed.
00:04:38.391 - 00:04:59.235, Speaker B: And I feel like either people don't think it's possible or think it's like a funny tagline, but I've talked to you multiple times now, and I know you believe it's a reality and actually possible from an engineering standpoint. And so I would love to just again, kick off the conversation with, why is that the North Star and how is that possible?
00:05:01.255 - 00:05:38.477, Speaker A: So it's the North Star because it's possible. I guess, in a way, as an engineer, you sometimes get like, I can build this really cool thing and you start working on it. And Linux was at North Star. It was a hobbyist project, but it had this like, oh, yeah, everything that Microsoft is doing, or sun and built these very expensive Unix systems. We can do it for free just by coding in the weekend. And the why wasn't as important as getting people excited to go work on it as an open source technology. So there's a lot of this is my personality and my kind of gut feeling.
00:05:38.477 - 00:06:21.219, Speaker A: A lot of what's driving me is just the fact that it's possible and it's cool. But I think I'm probably biased, right, in trying to rationalize these things. I think if it exists, it would be a better product and it would reduce latency and friction and finance. And that means better pricing for customers and better prices always win. So I think not only is it inevitable because it's possible, I think it's inevitable because it's better. And Linux became inevitable because it's better later in later stages of its development. So my hope and belief is that the same thing will happen with crypto, but also with this idea of blockchain and SDEX speed with Solana specifically.
00:06:21.219 - 00:06:33.285, Speaker A: And I'm excited to keep pushing it, keep working with all the developers and core dev teams and folks and try to keep nudging them in that direction and not North Star.
00:06:33.625 - 00:07:34.337, Speaker B: So one thing that I've also been trying to say more frequently, which I think is kind of like overarching break point, is better products, not better crypto products, just meaning like blockchains are great tools, but at the end of the day you still need to make better products to actually have convince people to use these really cool technologies. And I think to that point, the traditional finance system has historically been at least for New York located in Jersey, or New York for the data center where they actually do trading. All those trading participants are generally given the same fiber optic cable or same cable link. So they don't have any information advantage. And I think this was also emblematic of the two coffees and a beer and your kind of origin story. But I would perhaps love to start there and why those like same cable links are so important and how Solana can kind of insert itself in that wedge.
00:07:34.481 - 00:08:05.195, Speaker A: Yeah, so this is like information asymmetry. You can think of it that way or most people maybe that are not traders. Flashbots would be an example of this, but not quite exactly that. But like think of it as at least me as like more of a physics nerd. I think of it as a light cone. There is information travels at speed of light, speed of light through fiber. 70% is normal speed of light, but it's still pretty fast.
00:08:05.195 - 00:08:49.311, Speaker A: And even if the matching engine at Nasdaq, no matter how fast it is, it could be nanoseconds or milliseconds the data around the world that somebody would trade on still has to go travel around the world to whatever that data center is, wherever all those trading systems are, the, that can process that news. And it's very practical news. We're sitting here in Singapore. You could see a cargo ship full of iPhones sink in front of the harbor and that would be bad and catastrophic. And that information would impact Apple stock. But it still has to go travel speed of light through fiber to New York before it's traded on, because that's where that market is and that's where the matching happens. And that's a centralized system.
00:08:49.311 - 00:10:10.165, Speaker A: And even if we build L2s that have decentralized settlement guarantees and all these other things, if they have a single sequencer, a single box, whether it's in New York or wherever else, those systems also have that kind of information asymmetry where the people near that box receive all the data from around the world and they get to insert their messages and stuff like that. So the goal that we're trying to do is how do we, how do we beat those systems? How do we beat nasdaq? And if you're building a global, open, permissionless network, you don't have control over people deploy boxes, and you want them to deploy them globally. See, we don't want them all in New Jersey. So can we even build a product? Is it even possible? And the kind of eureka moment that I had is that what matters is not the matching engine speed. What matters is when that trade is tagged and ordered. So if we're sitting in Singapore and there's a Solana block producer, I think you can even simplify to just there's a time stamper in Singapore that the network counts as somebody that can give you a good clock. When you make the trade in Singapore, you can send that message to the local block producer that's right here.
00:10:10.165 - 00:10:51.435, Speaker A: And that distance is going to be miles and it's going to be very, very fast to speed away through fiber. So by the time the news goes to New York, there's already a Solana block producer that transmitted that transaction. So that NASDAQ trader cannot arbitrage the price from Solana to New York. It means that Solana is as good at price discovery as NASDAQ or nyse. Even though those things have very, very fast matching engines. Right? Like, this is like the coolest, weirdest eureka moment that I had is that we don't need to beat them on what they're good at. We can actually build a Totally different product without sacrificing the permissionlessness, the openness of these networks.
00:10:51.435 - 00:11:10.095, Speaker A: It's still random hobbyist that sets up this box if they wanted to in Singapore, one in New York on open source hardware, open protocols. And that's a very, very cool thing, right? It's transparent and open, run by anyone, run by volunteers. And it's better than nasdaq.
00:11:10.675 - 00:11:45.353, Speaker B: For me personally, it took a while to just speaking with you to kind of understand how this was possible. And when I like the dots finally clicked in my head, I was like, holy shit, this, this is a better product. And I think for the people perhaps as like traditional market makers. What would you say to them as. Because one thing that you mentioned was around the matching speed, you can't ultimately compete on the matching speed because it is global. There are real world latencies. We can't overcome physics.
00:11:45.353 - 00:11:48.353, Speaker B: But you can actually order things based by time.
00:11:48.409 - 00:12:23.255, Speaker A: Yeah. And the weird thing is that if you try to centralize and put all these boxes inside New Jersey, you actually sacrifice the product. I've moved all the, all the block producers to one spot in the world. And yeah, you can have very fast blocks there. You can beat NASDAQ and matching if you build everything in FPGAs or whatever, but you've limited your light cone to just that area. So we want to build this other system that is has the slow matching engine. So we could have something different that could potentially be competitive with these other platforms.
00:12:23.255 - 00:13:14.023, Speaker A: And the market makers, when they're dealing with something like nasdaq, they are paying a price effectively. Even there's financial costs just to be in that data center and stuff like that. Even if you could kind of make that more open and permissionless, when you look at the data of those systems, for every order there's like 20 cancel messages. So there's a lot of message activity. This is just kind of from a network protocol layer that is wasteful, right? There's kind of, we would call it spam, but it's wasteful. The difference in blockchains is that because they're permissionless and we can't have these guarantees that you as a market maker, you will not Send more than 100 messages per block or something like that. These messages are financialized.
00:13:14.023 - 00:13:39.155, Speaker A: So you pay a priority fee to outbid somebody with your cancel that wants to take your order or offer. So that minimizes number of messages. The market makers have to then run algorithms that decide what's the priority. How much is this cancel message worth to me? How much is this offer worth to me if there's a race in New York to cancel it and these systems will be resolved financially right within that 100 millisecond slot. And that's different.
00:13:39.935 - 00:14:07.437, Speaker B: But yeah, I guess to that point, since it's not one to one with kind of the existing financial system, I guess kind of the pitch to this new better financial system is it will not map one to one, it will be slightly different. And over time you're going to have to either rewrite your algorithms or rewrite kind of your trading system so that you can participate in this better price discovery engine.
00:14:07.581 - 00:14:42.797, Speaker A: Correct. And the hope is that because it's open and permissionless, it kind of becomes the easy defaults. Right. Like Linux became the easy thing to use because, well, it's open, I already know my buddies are using it and engineers kind of start using these systems. And the hope is that that could happen in finance because I think kind of things do roll downhill in technology. Like once something becomes ubiquitous and open, there's no cost to go try it. People kind of start organically using it if it's a better product or at least equivalent.
00:14:42.797 - 00:15:23.955, Speaker A: So that's the dream. I think it's possible. And I think honestly, if you think about science fiction, 50 years from now, in the crazy post singularity future, there's still going to be finance. I envision it as one giant chunk of silicon that's globally synchronized as fast as physics allow. Maybe at that point in time we have neutrinos that are sending these bits through the center of the earth to cut one distance and go the full speed of light. We're far from there. But that end state is one giant atomic single state machine that synchronizes fast as physics allow.
00:15:23.955 - 00:15:33.271, Speaker A: So we have an opportunity right now to accelerate that and build it. And I think that's just like what else would I be working on? It's the coolest thing.
00:15:33.383 - 00:15:43.839, Speaker B: And I think one of the things that I appreciate most about you is you've been saying this really from day one. It was your unique idea that kind of sparked this entire thing.
00:15:44.007 - 00:15:49.835, Speaker A: Yeah, those two coffees and a beer did not sit with me and I was literally like manic for four days, I think.
00:15:50.175 - 00:16:16.675, Speaker B: So one of the things that you mentioned kind of in the design is single leader Systems and also L2s. I kind of think of L2s and their logical end state almost resembling kind of the New York Stock Exchange where you have one beefy box, you have all that information sinking into there. So you. I feel like well end up in a similar game where you're playing the latency game to co locate next to that box to have better information.
00:16:16.795 - 00:16:39.665, Speaker A: Correct. And those systems will exist. And it's not like NASDAQ or NYSE will ever go away just like Microsoft and Unix never went away. But the goal is for this open platform that is as good as price discovery as the best version of a centralized system. The goal is for that thing to exist and to grow and to outgrow everyone else.
00:16:40.325 - 00:17:14.825, Speaker B: So today there are many multileader systems. I think even in Solana's white paper it was I think the first to mention multi leader. It was kind of snuck in there but it was there. There's kind of been a resurgence within the Ethereum community that Max has really been pushing that I think has been excellent dialogue around multi leader systems. Can you talk about today obviously Solana as a single leader system? The goal is to be multi leader long term. Can you talk about why the multi leader system is important?
00:17:14.985 - 00:17:41.011, Speaker A: So this is to make sure that there's a block producer in Singapore and New York and Amsterdam or else markets could exist and it would be nice to kind of. I wish we like there were, you know we might eventually get to designs that are stable like this but it's hard to build one where the network and the algorithms are aware of the geography and can actually pin. There's always a leader in Singapore, there's.
00:17:41.043 - 00:17:44.443, Speaker B: Always a leader kind of like AWS versus awes.
00:17:44.579 - 00:19:11.187, Speaker A: It's possible, I think we can actually get there with some stake based voting to figure out the topology and then pick whatever the random rotation is to always make sure there's spread across the topologies. I think we can actually get pretty good at pretty, pretty close to the right answer there. But the goal is to have as many concurrent leaders that are stable and performant and don't overly waste bandwidth and at the same time provide wide coverage around the world. And from Max's point of view why he ended up at this solution is that the monopoly that a single leader has during that slot auction can be very perverse and could create these incentives for defi to basically not work at its final end if the that single, you know the example that he has if you have like an auction for the Mona Lisa, the block producer wants the Mona Lisa. They block all the bids that are coming in to bid for the Mona Lisa and Instead, submit their $0.01 bid and buy the Mona Lisa for a price much, much lower than what it should cost. And as soon as you have Two block producers that are competing there, that block producer knows that the other block producer will outbid them, maybe 2 cents.
00:19:11.187 - 00:19:35.511, Speaker A: And then rationally in the game, theoretical way, they will bid whatever their actual value is. And then there's no incentive to censor anyone else's bid. Right. If their bid has to be competitive with another unknown, right. Potentially anonymous and fair bid, there's no reason to block other bidders. Right? Because you're not going to get a better price. That's really, really.
00:19:35.511 - 00:20:08.415, Speaker A: The important thing is that you should read his papers. He's a much better researcher than me. A lot of the stuff kind of to me is empirically discovered just through engineering. And my gut level intuition is that whenever you have markets, a single honest provider in that market can actually change the equilibrium and force everyone else to adjust and be at least as good as that one single honest offer. The more concurrent leaders we have, the more likely we are that there is a single honest offer in the market at any given time.
00:20:08.875 - 00:20:40.395, Speaker B: I think you were fairly early on to say that at scale, L2s would not have cheaper fees on contentious pieces of state. At the time. When you said that a couple years ago, I think that was relatively, relatively controversial. But today with multi leaders, do you feel like any single leader system long term is not going to be as relevant to multi leaders? Or is there any predictions on just like how multileaders will continue to perhaps be adopted or propagated throughout the blockchain community?
00:20:41.575 - 00:21:25.335, Speaker A: I mean like you could actually build single. There's still uses for single leader systems because you do have markets that are very geographically dense and close and don't care about the rest of the world. Although everything is so connected now, that becomes less and less true every year and the benefits kind of become marginally not important. So I don't think those designs are going to go away. People are going to continue launching more centralized sequencers, whether they're L2s or alternative L1s or whatever. And that's fine. That's just par for the course, right? Competition creates excellence.
00:21:25.335 - 00:21:57.415, Speaker A: I don't think they can offer better prices or ultimately better spreads or post impact price or however you want to measure the effectiveness of price discovery in those systems. Because again, you're dealing with speed of light through fiber and the opportunity to go extract informational asymmetry in those places. And all of the stuff competing ends up at the same place or at least no better than a decentralized multileader one.
00:21:57.495 - 00:22:22.291, Speaker B: To me, this is the holy grail because you get the full Huge quorum set, multiple validators. If people want to run a box, they can. They receive that pricing information almost in real time as everybody else. So no one's excluded from that. And it doesn't have to. You don't have to play necessarily the latency games and co locate to a single sequencer, which is kind of the best of all worlds.
00:22:22.443 - 00:22:36.895, Speaker A: Like that actually is worse to co locate. That's the cool part. And if that's a better product, and that actually depends on decentralization, then decentralization will survive.
00:22:37.355 - 00:22:38.835, Speaker B: Truly found its product market fit.
00:22:38.875 - 00:22:39.795, Speaker A: Yeah, exactly.
00:22:39.955 - 00:23:12.065, Speaker B: That's amazing. Yep. I think we've done numerous podcasts now and I think we've always kind of touched upon Fire Dancer. Fire Dancer, obviously a really exciting project for the Solana ecosystem. Kevin Bowers gave some super exciting announcements here at Singapore. I think Frankendancer is actually live in production on mainnet and the full Fire Dancer client end to end, is on testnet. Yeah, can you talk about some of the Fire Dancer project? Congratulations.
00:23:12.385 - 00:23:58.919, Speaker A: When people ask me what are you worried about, it's still the same thing. Since we started as a bad bug in the code and the probability of 2 really really good teams that are trying really, really hard not to have any bad bugs, to have the exact same bad bug in both implementations is very low. So as soon as Fire Dancer is out on mainnet and more than 33% of the stake either runs both nodes or different nodes than the majority, then we get into this environment where the bad bugs becomes a liveness failure. Those are terrible. They suck. Businesses are impacted and we never want to have them and hopefully never will. But that is not catastrophic to the state or to the rest of the network.
00:23:58.919 - 00:25:00.551, Speaker A: And in my view that's when I'll stop calling it beta. Because we have reduce the bus factor on the whole ecosystem with two implementations and the third implementation becomes much, much easier once you have two, there's already three and four already in the works. I think making good progress. But yeah, but beyond that, when we talked to the Fire Dancer team and I was pitching them this multiple concurrent vision of like we're going to beat NASDAQ thing, were they skeptical? They were, but they were excited. And what we asked them is that not just build a second implementation because that's boring. Like we were able to get improve the Anza implementation early on at 1 gigabit bandwidths at the Google kind of network in their data centers so it would saturate their switch. It was about actually 800 megabits but equal, you know, close enough to 1 gigabit.
00:25:00.551 - 00:26:03.333, Speaker A: And there's screenshots we have still from Grafana of like 300,000 TPS sustained on that switch, fully saturates that entire zone. At Google, we would deploy like as many boxes as we could and they would yell at us, what are you guys doing? We'd have to like convince them that let us run this test. And to them, that is one gigabit. Google networks are very, very slow and have terrible latency and bad switching times. And from there they have them and actually other competitors from Jump have already built high performance, low latency networks around the world. And they can actually demonstrate Fire Dancer saturating much larger bandwidth, much more than 1 gigabit globally, which we couldn't do because we would run literally in one zone. And Google to show that the code and the protocol doesn't suck, they can actually show that you can actually have this hardware deployed globally.
00:26:03.333 - 00:26:33.481, Speaker A: And this is what the coolest part of the Fire Dancer demo was. They took Frankendancer, so brand new networking code, which has ripped out all my old networking bugs and hopefully didn't add their own. But they built a very, very optimized networking stack. Exact same implementation of the same protocol. So still Solana. And on their overlay, like their really high performance, low latency overlay, globally 100 nodes, they hit a million TPS, which is awesome.
00:26:33.553 - 00:26:34.185, Speaker B: That's crazy.
00:26:34.265 - 00:27:45.315, Speaker A: That is crazy, right? Like, that is more TPS than I can imagine we need for the foreseeable future. But if we have it, well, a whole bunch of use cases that no one ever thought of, will they spring up and will we see people do stuff that no one expected? I'm excited for that. There's a lot of work to go make that main nut because there's still. If you were at Breakpoint and you went to a bunch of core dev sessions, there's still a bunch of work on SVM and controlling control flow and limits on memory and PCI bandwidth and all this other stuff that makes it like, when people are like, why, why are your benchmarks like 30, 40,000 tps on. When you go on Discord and you look at the bot, why are those so high? Why is Mainet only like a thousand tps? Well, because when we benchmark, it's like intel looking at their smallest feature in their chip and saying it's 3 nanometers. That's an important milestone because that is the smallest atoms you can move. But there's a bunch of components that are much Bigger.
00:27:45.315 - 00:28:27.117, Speaker A: There's a bunch of transactions that are much bigger, that take many more resources, use much, much more memory, and hit a whole bunch of different other watermarks. So increasing the raw TPS is a really, really good benchmark that shows that this is all possible with enough hardware. Like, if we have enough memory bandwidth, if we have enough compute cores, we can actually, like, saturate a million tps. And why it's important to focus on the network part is because that's the hardest part to increase. So. Right. Does that make sense? That is the most constrained feature of any of these systems, is the network stack, is how much block data can you just propagate.
00:28:27.301 - 00:28:30.261, Speaker B: And to that point, I think it would perhaps.
00:28:30.373 - 00:28:55.585, Speaker A: I mean, so, like, while it's still a lot of work to get SVM to handle more memory throughput and all this other stuff, it is downhill work that you can do with just systems engineers and more hardware. It's like it's a kind of like, not. It's not a computer science question anymore. It's like you can hire a bunch of L5 engineers and they'll get it done.
00:28:56.005 - 00:29:35.451, Speaker B: So I want to walk through the people that are maybe just watching this podcast for the first time on kind of that increasing throughput. As you mentioned, that is the hardest part of the stack today. Most of the blockchains are only doing a few kilobytes per second. Perhaps some of them are actually doing low megabytes of throughput, but we still haven't gotten to gigabytes. And I think for me, one thing that I've always appreciated about Solana was kind of the simplistic vision almost. And, hey, if we reach system capacity, we double the throughput capacity. We add more cores to support that capacity.
00:29:35.451 - 00:29:49.059, Speaker B: Can you talk about kind of where we are today? Even perhaps some of the recent issues with, like, DDOSes or the networking stack getting us from kilobytes to megabytes and then ultimately multiple gigabytes.
00:29:49.147 - 00:30:16.277, Speaker A: Yeah. So you can think of it as like, there's a whole bunch of resources that you're spending anytime you do something in the network, and it's hard to meter all of them. So you have like, just cycles, compute cycles that the core, a single core, can take. And if you take too many cycles, then the network can. Or the system can handle per second in any given node, that node gets overwhelmed. That means all the nodes get overwhelmed and the network falls over. If you take.
00:30:16.277 - 00:31:16.987, Speaker A: If you send so much data that you cannot transmit out in a block because you have to create so many more erasure codes and sign more signatures and send more packets. You could either saturate the cores there because of signatures or the IO ops on the network card. There's a whole bunch of weird little queues and spots with capacity. And if you hit anyone the limit on any one of those queues, everything backs up. And when that stuff backs up, the engineering problem is how do we create feedback loops that can shed load intelligently by only keeping the highest priority transactions and dropping the lowest priority ones. And that's difficult to do because these queues are in very, very odd spots across systems and further downstream from the place where you actually schedule and can do prioritization. So a whole bunch of work, it's like billing and metering.
00:31:16.987 - 00:32:00.011, Speaker A: It's not like computer science work at all. On paper. All this stuff was solved 30 years ago or whatever. It's just literally like doing the debugging and the metering and the measuring and making sure that stuff is robust. So a lot of denial of service attacks that end up looking like aliveness are not even like adversarial like malicious people trying to do a denial of service. It's just somebody accidentally at a customer or infra provider said hey, if we send this message 10 times to 10 different boxes we get through faster. Then everybody does it and you have 10 times reload and then some queue gets overwhelmed and everything folds over.
00:32:00.011 - 00:32:41.265, Speaker A: And like you got to find that queue, find that mispriced or misprioritization somewhere, fix it. And then the customer should never see hey, if I spam the network my data gets through faster. What they should always see is if I increase my fees above somebody else than I get ahead of them. If we can make that work, it's very simple conceptually, but we can get rid of all the bugs, we're done. There's no more liveness issues, there's no more denial of service. Bumping the fee gets you lower latency, you're done. So those are the hard day to day problems and they're more very implementation specific, very low level engineering stuff.
00:32:41.425 - 00:32:56.933, Speaker B: Then once you fix those bugs then it's going back to the point where you can start increasing those limitations. So it actually increases the overall throughput of the system. You go from megabytes to gigabytes, which is like 1000x difference in networking stack.
00:32:57.029 - 00:33:43.001, Speaker A: So somewhere in that kind of thing is the smallest queue, that's the most constrained one. And then somebody has to go buy more hardware to where you either have two queues or it's more capacity and then everything gets faster and faster. And a lot of that stuff happens without even our control because data centers and operators, they cannot use older hardware because it gets just thrown out. Like the boxes at Terraswitch or whatever are at most maybe four years old. So naturally, just without even us doing anything, hardware gets faster and we have to test and make sure that the limits can increase. By we, I mean not me anymore. It's Anza and Firedancer and Jiro and all those other guys.
00:33:43.153 - 00:33:46.283, Speaker B: Maybe on the topics of like L2s.
00:33:46.411 - 00:34:22.688, Speaker A: Versus versus these problems exist in L2s. Like the exact same debugging. This is why base cannot just flip on a million giga gas because there's weird cues and saturation that would happen in evm and if they had saturation that created so much data that could not be Synced to the L1 reliably. The settlement guarantees, finality guarantees, all that stuff breaks and the product effectively has the same liveness failure. So these are hard problems and they're no easier on Solana or no harder.
00:34:22.856 - 00:34:46.195, Speaker B: Some of the not pushback but some of the talking points that I've had more recently is they're like oh Logan, Solana has network extensions or people are building L2s on Solana. What is your point of view on some of the teams kind of adding either more compute or why are they doing these things in your mind?
00:34:47.055 - 00:35:05.087, Speaker A: So there is. You can kind of think of it as like pith is a really good example. Pithnet does 1 to 2000 TPS. The price that that network wants to pay for those transactions is the price of like a database entry. They do not. They don't. They don't.
00:35:05.087 - 00:35:13.159, Speaker A: That network is a data provider. They don't value those transactions at the economic opportunity cost of the state of the network.
00:35:13.287 - 00:35:14.479, Speaker B: The shared state of the network.
00:35:14.527 - 00:35:58.215, Speaker A: Yeah, so they don't care about the shared state. They just want to go record these things because they have a bunch of providers that are submitting data somewhere and this is a reliable open database. So from their perspective this is more like Zookeeper run Postgres makes sense, but it's open and permissionless and decentralized and the other features that they get out of the L1 actually make their product better and stuff. But like that data does not depend on the rest of the state. So they just want to pay raw bandwidth costs there and eventually there is no reason why an L1 that has markets and all this other stuff couldn't also provide that. It just takes time to go increase everything.
00:35:59.115 - 00:36:12.067, Speaker B: So long term, do you believe as networking bugs and general optimizations with the stack continue to get ironed out, we'll kind of see less of these network extensions or perhaps L2s.
00:36:12.131 - 00:36:27.935, Speaker A: There should be no if that magical world of a single slab of memory synchronized at the speed of light exists, there's no rational reason not to use it for something like bit. But right now the implementation is very far from.
00:36:30.115 - 00:36:40.349, Speaker B: Perhaps with our time left. Fire Dancer also mentioned some unique things on the networking stack. I think Mert was kind of commenting around building a new Internet.
00:36:40.397 - 00:36:40.893, Speaker A: Yeah.
00:36:41.029 - 00:36:46.145, Speaker B: What was your comments takeaways from this announcement or what was the announcement?
00:36:46.925 - 00:37:12.681, Speaker A: So when you watch like a movie or livestream or and stuff like that, a lot of this data is not live. It is live, but it's like 15 seconds behind. It's because it gets buffered all along the content providers and stuff like that. So they can give you a reliable thing with no stops or jitter because they have a 15 second window and they can kind of come back and forth and move back and forth.
00:37:12.793 - 00:37:17.985, Speaker B: Kind of why your YouTube always bar moves a little bit faster than the video you're watching.
00:37:18.145 - 00:38:05.393, Speaker A: Exactly, exactly. So that kind of preload window gives you that nice user experience of never having to stop in the middle of a video and wait for it. The problem is that that works great on the Internet. The Internet is really kind of built for that. But finance really, really needs those bits as soon as possible. So a lot of these companies that operate in global finance, they've talked to the data center providers and the fiber operators and whatever and they've built switching systems to make sure that there is no buffering and information gets sent as fast with very reliable latency guarantees. So they have built a new Internet, but it is obviously more expensive, right, than the buffered one.
00:38:05.393 - 00:38:42.921, Speaker A: And it is not designed for video, but it's designed for other things for finance and things like that. But it happens to also be really, really good for propagating blocks. So consensus can work really quickly with low jitter and things can vote very quickly. And it is really, really cool. It is when people think about it and they're going to ask themselves, is this centralized? It is as centralized as a normal Internet. The links and the boxes and the switches are owned by a bunch of randos around the world. And you still have to go and make sure and detect partitions.
00:38:42.921 - 00:39:11.059, Speaker A: All the same work has to be done. It's one set of randos that are optimizing for latency. The other set are optimizing for throughput, but they're just different people running these boxes around the world. It is as decentralized as a normal Internet. It is smaller, there's fewer of them. But from a design perspective, nothing in the protocol really changes and you can still do the exact same double spend detection and everything else.
00:39:11.227 - 00:39:45.871, Speaker B: The funny thing to me is the industry loves to talk about decentralization very much, but at the end of the day, you're actually limited by bandwidth in the communication channels between all these nodes. And when you look at the geographic, kind of like fiber optic lines between different continents, you see like there's actually not that many fiber optic lines, maybe like less than 30, going across different oceans. And those are the true kind of like final bosses of all these distributed networking systems, because you're actually propagating bytes or blocks from one continent to another.
00:39:45.983 - 00:40:21.663, Speaker A: So yeah, so we cannot prevent those partitions. So like, you cannot. It's really impossible for us to build a network that can always maintain 1 million TPS no matter which fiber optic cables get cut. Right. That's not physically possible because you have to, you need them to send that much throughput. But you can always detect that, because the amount of information you need to detect a double spend is just two conflicting signatures. And that's a very small amount of data that you could literally send over shortwave radio bouncing through the ionosphere if you wanted to.
00:40:21.663 - 00:40:42.535, Speaker A: Like there's so many other paths for information, for small bits, chunks of information to propagate around the world that I think in the day and age that we live in, we live in a world where you cannot reliably partition the Internet for small messages. And that's enough for us to make the system look like it can never double spend.
00:40:43.115 - 00:41:06.075, Speaker B: I hope we've hammered home on this podcast again, just like this, global distributed NASDAQ at the speed of light. Because you've mentioned it from day one. I think every podcast you've mentioned, and it's taken me a while to really learn what that means, but I think it ultimately boils down to actually building a better product, which is the super exciting thing.
00:41:06.155 - 00:41:36.621, Speaker A: Yeah, it means if it, if it's a better product, it'll survive. And this was. It took Linux a long time to go from an idea that people were hacking in for fun on their weekend to people trying a bajillion different startups that all failed to. This is a better product and it's now part of every major company in the world. That's the dream for any Open source project is to go through all three stages. I'm excited that it's possible. So we're not there yet, but I think the path is there.
00:41:36.803 - 00:42:02.365, Speaker B: So where are we on that path? We have Fire Dancer. We have some kinks that are still getting worked out. How long do you think it's going to be for us to actually make that global price discovery multiliter, multi gigabit future reality. I know it's always like asking engineers how long does it take to baby. And if you have nine engineers it's not one month instead of yeah, yeah.
00:42:05.145 - 00:42:40.495, Speaker A: The shortest steps. If you could just never write bugs or if debugging is incredibly fast. There's kind of three things that you need to build. I think Async execution is the next big feature that both clients are really excited to build that unblocks a whole bunch of those queues. We make them not blockers during block propagation. So those queues can kind of be processed later. That's really, really important.
00:42:40.495 - 00:43:35.145, Speaker A: And once you have Async I think it could be like three months after that you could get testnet the big unknown. And this is what I was talking to with Max is if we're lucky then we can make the system stable by using a bit more hardware, by generating more erasure codes and more signatures and sending more bandwidth out and statistically having very consistent delivery of data in presence of partitions and adversarial nodes. If we're lucky all it takes is bandwidth because that's. It's a simple problem. It's just maybe hardware is more expensive or whatever. If we're unlucky then we have to figure out how to manage the risk there such that it's very hard for an industrial participant like and they called epsilon stake like the smallest possible stake. They can participate in the network.
00:43:35.145 - 00:43:59.579, Speaker A: How much performance segregation can they cause? If it's. If all we need is more erasure codes then we're blessed because we can always get more of those. If we have to do crypto economic like hacks there to make the system more robust that'll take a while to build and debug and I hope we get lucky. My gut feeling is that we will based on turbine performance, but we'll see.
00:43:59.707 - 00:44:18.223, Speaker B: Perfect. Well, perhaps we can wrap it up there. We're at the fourth break point again. The vibes are electric. People are focused on products and I think the reason why I wanted to have this conversation was just really continuing to underscore what Solana's North Star is which has always been NASDAQ at the speed of light.
00:44:18.319 - 00:44:27.231, Speaker A: The coolest thing about this Breakpoint is that there's founders that are profitable, that have built business very bullish. And that's. That's been amazing to see.
00:44:27.343 - 00:44:41.095, Speaker B: Awesome. Well, thank you again, Toli. Really appreciate you and the entire Solana community for always making these wonderful events happen. It's fun for the entire community, and I'm sure everybody will enjoy this podcast, so thank you again.
00:44:41.215 - 00:44:42.415, Speaker A: Awesome. Thank you, thank you.

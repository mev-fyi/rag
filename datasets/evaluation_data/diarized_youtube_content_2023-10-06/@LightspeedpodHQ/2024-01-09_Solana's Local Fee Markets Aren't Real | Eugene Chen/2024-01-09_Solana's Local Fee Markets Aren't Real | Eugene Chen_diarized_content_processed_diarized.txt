00:00:00.090 - 00:00:24.670, Speaker A: I think it's incredibly important for application developers to understand the infra. I think there's some potential future world where all of the infra is actually perfect and you can have these like mental abstractions. None of the blockchains are there. None of the blockchains are even close to there. Solana is definitely not there yet. And I think it's really important for application developers to understand how the chain works so you can build better applications that serve the users better.
00:00:24.740 - 00:00:45.698, Speaker B: Is episode is brought to you by Access protocol. Access protocol is the best way to get access to premium crypto content without the ads, without the annoying subscriptions that are impossible to cancel. It's crypto native. It's here today. Go check them out. What's up everybody? Welcome to another episode of Lightspeed. Today we're joined by Eugene from Ellipsis Labs.
00:00:45.698 - 00:00:47.286, Speaker B: Eugene, welcome to the show.
00:00:47.468 - 00:00:48.920, Speaker A: Thanks for having me guys.
00:00:49.370 - 00:01:22.934, Speaker B: Pumped to have on. Eugene, I'm not going to lie, I think you are one of the smartest people in the Solana ecosystem, so I'm pumped to have you on and there's a lot we could talk about. But thing that I really want to focus on, at least the beginning of this podcast, is your post that you put out about two weeks ago. You tweeted it and the title was Solana local fee markets are not real. So I want to get to that because it's a bit controversial and I think a good place to start would just be describing how transactions work on Solana. So like as I as a user go to Jupiter, what happens between the time when I click submit a transaction and when it actually comes back on the UI and it says confirmed for.
00:01:22.972 - 00:02:19.450, Speaker A: Sure we can start there. Honestly, Mert might be a better person to answer this question than me, so feel free to jump in anytime. But as I understand it, Jupyter creates a transaction that goes to your phantom wallet to get signed when the user hits approve transaction that goes off to Phantom's RPC? In theory, it could be any RPC which forwards the transaction onto a validator, which then forwards a transaction to the leader. So the leader is whoever is currently elected in the proof of stake system to build the current block. And then there's a bunch of complexity inside the validator itself, inside the leader itself. But essentially there's first this network layer, the quick layer that transactions go through, and there's some throttling that happens there. So if your transaction gets dropped, this is one place where it can get dropped.
00:02:19.450 - 00:02:57.102, Speaker A: After it makes it through, there it goes. Into the scheduler, or internally, it's called the banking stage. But think of this as like the block builder, the thing that takes transactions, orders them into a block, executes them, and then forwards them on to the rest of the network. And so the transaction gets queued for execution. And there's a lot of complexity here because the queuing is multithreaded. And so there's another source of jitter here. And essentially you have multiple threads that are executing these transactions as they come in, scheduling and executing.
00:02:57.102 - 00:03:34.910, Speaker A: And a transaction can get blocked if it is trying to access some state that another executing thread is currently using. So Solana has state access lists which built into the transactions themselves. So at the time of transaction creation, the transaction specifies exactly which pieces of state it needs to read from and which pieces of state it needs to write from. And this allows for this parallel execution. It also allows for parallel fee markets, but those aren't really quite implemented yet in Solana.
00:03:36.530 - 00:03:53.586, Speaker B: Yeah, that was really helpful. So I have a few questions for me, but also the audience. So, one, you said it's multithreaded, which essentially means you can do, like parallelization. Correct. From what I understand, there's like four threads. And how you can think about it, at least easier for me, is thinking about lanes, like lanes of traffic. And you have four lanes.
00:03:53.618 - 00:03:53.766, Speaker A: Right.
00:03:53.788 - 00:04:01.226, Speaker B: And that's like four threads. One question I just have at a high level is, why is it four threads, like computers, have multiple CPUs, why is it limited to four?
00:04:01.328 - 00:04:01.546, Speaker A: Yeah.
00:04:01.568 - 00:04:03.050, Speaker B: How did that number get picked?
00:04:04.270 - 00:05:05.034, Speaker A: That's probably a better question for Solana labs, but I think my mental model for how a lot of the constants on Solana work today is some engineer roughly arbitrarily picked it a couple of years ago. And these numbers haven't really been revisited. They've worked okay up until today. If you wanted to have far more threads, there's some trade offs you'll have to take into account. One, you might have a little bit more contention for these accounts that are getting locked, so that you have a little bit more overhead managing this locking system, which is single threaded, because you have a single locks manager, and then you might also impose a higher requirement on the validators themselves. So higher hardware requirement, where instead of having needing four cores for execution, you might need more cores there. So there's four threads for, let's call them user transactions.
00:05:05.034 - 00:05:17.154, Speaker A: And there's also two separate threads for vote transactions, which are regular transactions in Solana. So technically there's six threads. But, yeah, for regular user transactions, there's four.
00:05:17.272 - 00:05:56.142, Speaker C: To maybe talk a bit more about how those numbers are picked. They are kind of arbitrary, right? Basically, there's 48 million compute units available. And that was picked because it was determined that that's kind of how much the machine can process to arrive at 400 millisecond block times. And so it's more like an empirical way of getting the number instead of doing some complex math to arrive at the right number, which we can talk about why Salana does that, versus Ethereum maybe, which is on the other side of the spectrum there.
00:05:56.196 - 00:06:25.800, Speaker B: So you're talking about one block has 48 million compute units. An account can have up to 12 million compute units in that block. And that is what really is supposed to allow for local fee markets. And an example that people often use of this is if you have an NFT mint, that's not going to raise up the prices across the board for, say, another Defi transaction. And that's something that would happen in Ethereum. You were saying, though, that that type of local fee markets doesn't really exist yet. What is the reason for that? What is preventing those local fee markets from actually working today?
00:06:26.170 - 00:07:06.766, Speaker A: Sure. So they kind of work, they work in this probabilistic sense. And first we have to get to this difference in block building between Solana and Ethereum. So on Ethereum, you have these blocks that are at a very high level, comprised of these user transactions that have gone to the mempool. And then you can imagine the most naive greedy block building algorithm is you sort the transactions in the mempool by gas, and then if there's too many transactions in there to fill up a block, then you just take the highest paying transactions. So you can imagine for 11.9 seconds of the block, these transactions are entering the mempool.
00:07:06.766 - 00:08:01.110, Speaker A: And in the last 100 milliseconds, the block is built in this greedy way by the block builder. On Salana, it works quite differently where the blocks are actually built continuously. So as transactions are coming in before the 400 milliseconds of the slot are up, the leader is building and executing the block on the fly. And so there's a lot of places where you don't get these guarantees. So, for example, on Ethereum, if I send in a transaction at the very end of the block that has a very high gas price set, I'm very likely to get into the block if the block builder is being greedy. And this is not necessarily the case on Salana. So, for example, if the block has already reached its 48 million cus, and then I try to add something to the end of the block that pays a ton to the validator.
00:08:01.110 - 00:08:55.810, Speaker A: I'm still not going to get in because the block is already built and I'm just going to make it into the next block instead. So you have this continuous block building, which means you'll lose some of the guarantees from discrete block building. I think there's just a ton of benefits you get from continuous block building where you can get really fast pre confirmations to the users that are not limited by the block time itself. I think that's one common misconception people have about Solana, where they think the fast pre confirmations come from short block times. And the short block times do help because you get to confirmed in finalization a little bit quicker, but it's really the fact that you have continuous block building. So in theory you can have a pre confirmation that is as fast as one round trip between the client and the leader. Then when it comes to local fee marks, you have to go a little bit more into the implementation of the block builder.
00:08:55.810 - 00:09:30.754, Speaker A: And just real quick. None of this is actually enshrined in consensus in the same way that an Ethereum block builder or Ethereum validator can propose any valid block. There is no rule of consensus that says the blocks must contain the highest paying transactions. That's just an incentive that the block builder or the validator has. And this is also true on Solana. So as these transactions are coming in, they're getting queued, and there's a single priority fee that can be set on the transaction. And you can roughly imagine the way these blocks are getting built.
00:09:30.754 - 00:10:41.626, Speaker A: So we have these queues, pretend there's like four queues for the four lanes of traffic. The four executing threads and transactions get scheduled to get executed, and then sometimes they get blocked and they can't get executed and they go back into the queue. So one way that you can implement this queuing mechanism with a priority fee is sorting the queues by priority fee. Here you would have like a priority queue of transactions that's keyed by the priority fee set. And so if you set a higher priority fee, you are more likely to get in. But it is still possible that if I send a transaction at the same time as you, that is accessing the same accounts and I set a higher priority fee, you might still get in first because you might end up going into a better lane just by pure chance. And it's also possible that even if my transaction is seen first at the time, mine is going to get executed it's blocked by this locking mechanism, and then it has to get re queued, and then maybe yours is coming in right after that, and by that time, the lock has been cleared and so yours can go in first, the canonical example, you have some hot NFT mint happening, right? You have a hot NFT mint happening.
00:10:41.626 - 00:11:55.246, Speaker A: And the behavior you want is if there's way more than 12 million cus per block of demand to access that state, the price you need to get in, the priority fee you need to get in is going to be higher than for some other uncontested state. And this is true in some probabilistic sense, because you're more likely to get blocked trying to access this high contention state, but you still have this global block limit, and then there's no real notion of a market, right? These things are all in this. I don't want to call it an auction, but it's kind of like a first price greedy mechanism. And the user, when they're sending the transaction, they have no idea what priority fee to set to get in. And this is really not an issue when blocks are not contested, right? When the blocks are not full. And so this is sort of the regime that Solana has, the market regime that Solana has been in for more than a year, probably two years or so, where blocks are just like, generally not full. And then with the recent spike in activity in the last couple of months, we've seen blocks that are full, we've seen accounts getting saturated by the per block, 12 million cu limit.
00:11:55.246 - 00:13:08.230, Speaker A: And now we see some of the downsides of this priority mechanism, where, because you have this first price mechanism, it's very difficult to know up front when you're sending the transaction, what is the priority fee I need to set to get in? And this is a lot of inefficiencies here, where you have this incentive to spam because of the jitter, and then you might be overpaying in terms of your priority to get in what you really want to enable. And this is like what most users actually want, right? Especially when the fees are somewhere between one 100th of a cent and maybe a few cents, or even like ten cents. The user really just wants to say like, hey, get my transaction in as fast as possible and just pay whatever the market gas is. And there's no mechanism for that on Solana today, whereas with some sort of controller mechanism that will tell you in consensus in protocol, hey, here's what we think the fee you need to set to get in is. In fact, it might be like minimum fee enforced by consensus that says if you don't pay at least this much, you're definitely not going to get in. And then that number can modulate depending on what the demand is. That actually provides for a significantly better user experience.
00:13:08.230 - 00:13:33.120, Speaker A: So today on Solana, when the blocks are full, we're seeing all the natural things you would expect to see from this first price mechanism where all these protocols and all these users and all these bots are seeing, oh, my, transactions are not getting in, the users are unhappy, and so everyone is just like, jacking up the priority fees kind of indiscriminately in this highly uncoordinated way, very empirical way, and that leads to a lot of inefficiency in the system.
00:13:34.290 - 00:14:00.374, Speaker B: Yeah. And in Ethereum, we've seen VIP 1559, right, which is that inconsensus base fee that will go up as you have more, as the blocks more saturated over time, and then, you know, it's more predictable to get the next transaction in. I actually, over the last few weeks, when Slana and just the ecosystem was kind of skyrocketing with attention, my Jupyter transactions were getting dropped. I don't know if that was related to slippage or are blocks at this point actually getting full enough where we're already having this problem, where the fees are moving fast?
00:14:00.412 - 00:14:04.170, Speaker C: Did they show up on your wallet? No failed transactions?
00:14:04.590 - 00:14:08.154, Speaker B: That's a good question. Maybe some of them. I just know I had to.
00:14:08.272 - 00:14:51.066, Speaker A: There's a bunch of ways your Jupyter transaction will fail to get in. So I think what Merd is getting at is if you see a failed transaction land, that probably means your slippage was not set high enough. So, like, the market moved away from your trade before you were able to get into the block, but your transaction was still scheduled and executed and landed on the blockchain. And there's two main other ways your transaction is not going to get in. And these are just very difficult to observe from the outside. You don't really know where your transaction failed. One of them could be at the priority fee level, where because the block is contested, or the account you're trying to touch is contested, and your priority fee was too low, you were never able to get in.
00:14:51.066 - 00:15:12.080, Speaker A: So that means your transaction made it to the block builder, it made it to the scheduler, but it was never scheduled and included for execution because you were just like, never at the top of the queue. And then another way your transaction can fail to get in is getting throttled at the network layer at the quick layer, and it's just impossible to tell from the outside which of those is happening.
00:15:12.690 - 00:15:18.930, Speaker B: That makes sense, I guess, at a high level. What are the basic ways to fix some of this going forward for Solana?
00:15:19.270 - 00:16:00.238, Speaker A: Yeah, so the network layer, I believe is the actual layer where most of the transactions are getting dropped today. This is from my conversations with RPC providers and some of the Solana core team, and that I have very little visibility into. I wouldn't say I have any good ideas on how to address that. That's like this very general rate limiting problem, which is pretty tough. There is some economic incentives you can throw in there, but at the end of the day, that really is more of an engineering problem. And then on the scheduler layer itself and the fee mechanism itself, setting a floor price on the priority fee I think will just help a ton. And so there's a lot of ways you can do this.
00:16:00.238 - 00:16:52.030, Speaker A: I think in my mind there's three changes we can make that are pretty much purely additive. There's just not that much downside in terms of just really helping us improve the user experience on Solana, really getting back to the fast inclusion and fast confirmation that users love. So first is on the base fee when all the blocks are full in the last few days, just like all the blocks, not all, but the vast majority of the blocks are full or very close to full. This suggests that the base fee itself is too low. And here you just need some sort of escalator mechanism. On the base fee itself today it's set to constant 5000 lamp ports per signature, let's call it three hundredths of a cent per transaction. And this is just like much lower than the market clearing price today.
00:16:52.030 - 00:17:56.882, Speaker A: And so you have this first price behavior with the priority fee, which again is this like probabilistic thing. So one easy thing we can do here is if you see many of the recent blocks are full, you jack up the base fee until the blocks are no longer full. So you have some sort of target utilization as well as a max utilization. This actually looks very similar to EIP 1559, but we don't even need to think of it as related to what Ethereum has done. It's just like a basic controller mechanism where you have a limited resource and when there's too much demand for the resource at the current price to include everybody, what you need to do is increase the price until you hit the market clearing price. The second thing we need to do is instead of making the fee paid, the base fee paid constant per transaction or constant per signature, it really ought to depend on the amount of compute that the transaction uses. So today, Salana transaction can use up to 1.4
00:17:56.882 - 00:18:51.426, Speaker A: million compute units. And if you use 1.4 million compute units, your base fee is exactly the same as a transaction that only uses 10,000 compute units, even though the larger transaction is more expensive to the network, consumes more of the resources. So the base fee just really needs to have some component that is linear in the number of cus used or compute units requested. I think that's pretty much a no brainer as well. And then the more controversial piece is, how do we actually price these write locks? How do we actually price the contested state? And here I think, again, we can just implement a pretty simple controller mechanism where instead of having like a global base fee, or just a global base fee and a global priority fee, you have a global base fee. So this is the controller that is going to make sure that when the blocks are all full, we're going to jack up that fee.
00:18:51.426 - 00:19:47.362, Speaker A: And then when the usage goes down, then we can lower the fee. Again, you also have a mechanism like that on each account. So if the Phoenix sole USDC market is hitting its 12 million cu cap very frequently, we should just increase the price that's required to access this market with a similar controller mechanism. And there's a lot of details here, right, that we're hand waving away, like what is the shape of the controller mechanism? How do you communicate these price changes back to the users or back to the developers? But those are all pretty tractable problems. They're more engineering problems. Figuring out what is the right controller mechanism, how fast do you want to increase the prices? Maybe that actually depends on what type of account it is and what you expect the shape of the demand to look like. But these things are all really to improve the UX where we have this constraining resource.
00:19:47.362 - 00:20:28.630, Speaker A: Right block space is not unlimited, even though on Solana it's kind of felt like it's unlimited for a long time. In this current market we see, okay, it's not actually infinite. And the way you're able to include the most valuable transactions, as determined by the users who are sending them, is to increase the price and then decrease the price when your resources are no longer overutilized. So there's a lot of theory in controller design, but at a very high level, you just want to have some sort of mechanism in place where if the demand exceeds the supply, you increase the price. It's really not too complicated.
00:20:29.770 - 00:20:57.280, Speaker C: Yeah, well put. There's a lot of economic back pressure work that needs to go live. Another issue that I might add is that, and this is being fixed with 1.17, or at least an attempt at a fix, is that the compute units aren't actually estimated that accurately. Right. It's kind of an arbitrary unit, what compute unit means. And so that's something to keep in mind.
00:20:58.130 - 00:21:10.660, Speaker B: And then on that merck, can you explain, why does that matter? How does that actually function? So when a transaction is submitted, it has estimated compute units. Correct. If that's way off from what's actually used, why is that important?
00:21:11.910 - 00:21:16.338, Speaker C: Well, it's just like you're just misappropriating resources in a sense.
00:21:16.424 - 00:21:16.818, Speaker A: Right?
00:21:16.904 - 00:22:17.078, Speaker C: A compute unit is just a resource, and if you don't estimate it properly, that you're not making the best possible use of the resources. That's just the simplest way to think about it in my. So, okay, so I want to recap what Eugene said, and then maybe I'll tackle the very first part, which was most of the dropping of transactions, let's say, happens at the network layer, which is to say that, so basically what happens is you have a transaction and then it keeps being forwarded. And then after some time, the block hash that you have is invalid because it expires as a result. You just don't make it in. Pretty sure what's now going to happen is labs has a new thing for chapping unstaked connections. So public connections, which is to say that you'll need an RPC with staked connections to actually make your, or prioritize your transaction properly or extend it.
00:22:17.078 - 00:22:58.358, Speaker C: Because previously I think that mechanism was buggy such that the number of public connections that you have wasn't being throttled properly. And so the people with staked connections were getting, were not making it in as much as they should be. And so that's being fixed. So that's actually like the quick stuff that went live. It's just not perfectly implemented right now, which is often the case. And so that's number one. And then, so, Eugene, just to recap what you said, one is dynamic base fees in a sense, and then two is going to be, or the last thing you said was basically like adding some sort of economic consideration for adding write locks to an account.
00:22:58.358 - 00:23:08.540, Speaker C: Right. Because that's actually kind of like a vector right now that I'm not sure. Maybe we'll talk about. And then the second thing you said was.
00:23:11.150 - 00:23:14.342, Speaker A: Having the base fee depend on cus used or cu.
00:23:14.406 - 00:23:25.534, Speaker C: Yes, because right now it's priced on signatures, which is a very naive way, let's say, of doing it, or optimistic because they should be a bit more granular in how you price them.
00:23:25.572 - 00:23:49.320, Speaker A: Okay. Yeah. The existing fee model basically assumes this world where blocks tend to not be full. And so maybe you don't really need to incentivize lower Cu usage. But now we're in a market regime where that's not the case and a little bit more like deliberate pricing is important.
00:23:50.330 - 00:23:54.582, Speaker C: Did you see the scheduler fixes coming in 1.18 by any chance?
00:23:54.716 - 00:24:25.098, Speaker A: I haven't looked at them in detail. I think there is a lot of work that needs to be done on the scheduler, and it sounds like there's good people working on it. So that will at least reduce the amount of jitter in the scheduler. The example I was talking about before, where if we both send the same transaction, it's unclear who's going to get in first, even if one of us is paying a higher priority fee. And so that should be good for reducing spam for sure. Because right now, if you're trying to get included early, there is this massive incentive to spam.
00:24:25.194 - 00:24:39.400, Speaker B: One thing I'd add on the transactions, and the spam is. Eugene, you quoted in that article that at least as of January 2023, I think it's 53% of transactions that land in a block are failed transactions. And is that just because spam is essentially dominating the block space right now?
00:24:39.770 - 00:25:17.314, Speaker A: Yes. And so again, this is from January 2023. This is a number that was pulled by the Jito team when they were looking at what is actually happening on chain and why are there so many failed transactions. And yeah, most of them are spammed arbitrage transactions and spammed liquidation transactions. And because the fees are so low, it's actually a good strategy to spam from the arbitrager's perspective, where you want to get in really fast. And so the best way to do that is just send your transaction many times. And even if you send your transaction 100 times and one of them succeeds, 99 of them land and fail, and you still pay the fee for those 99.
00:25:17.314 - 00:25:53.430, Speaker A: It's still profitable in expectation. But of course, this is kind of a poor use of the block space. And what we would like to see is something where in the ideal world, you would have one of these transactions land, and it pays a pretty high amount, and then you don't waste like 99% of the block space on these failed transactions. What the searcher is trying to express is like, I'm willing to pay, say, up to a dollar to land this transaction that is worth a dollar 50 to me. And instead the only thing they're allowed to do, or the way they express this preference is by sending 100 transactions that are worth $0.01 apiece.
00:25:53.590 - 00:26:02.350, Speaker B: Yeah. And the priority fees are supposed to fix that. Right. But because of the jitter, because the schedule are not being optimized, it doesn't always matter right now because latency is still such a big deal.
00:26:02.500 - 00:26:02.862, Speaker C: Yes.
00:26:02.916 - 00:26:18.600, Speaker A: What's going to be a feature of a system that has continuous block building where getting in first is super important? It's going to be more important than your pricing. The alternative approach here is sort of what Jito has done, which is moving more from this continuous block building world to a discrete block building world.
00:26:20.090 - 00:26:58.900, Speaker B: My last question on this whole fee topic is just what do you think about? I've seen Anatoli talk about this a bit, and how do you come up with the right base fee that doesn't push out certain types of transactions? Because you have defi competing against payments, competing against different industries. And the thing is, if you push up the base fee too high, it might get rid of spam, but could also push out these other use cases. So I'm just curious how you think about that, because from a lizard brain level, when I think of, oh, there's local fee markets, there's 48 million compute units and there's four threads. Well, if you have four accounts getting fired at the same time, then those local fee markets go away and then you're going to have these payment transactions be priced out. So what do you think about that?
00:26:59.750 - 00:28:05.090, Speaker A: So that's more of a global fee problem than a local fee problem. And at the end of the day, it really is just going to depend on how much economic incentive is there for these payment transactions versus for these other transactions that I think we're implicitly valuing, not as valuable as the other transactions to the network. I would push back on that assumption a little bit, where if people are willing to pay for these 48 million cus and they're willing to pay some astronomical amount, the network should be including those, and not including a transaction where the sender has expressed a much lower propensity to pay. Otherwise, you end up taking on these pretty opinionated assumptions about the value of transactions. And it's kind of unclear how you can do that in a neutral way. And at the end of the day, again, you still have this finite supply of block space. And if the market clearing price is very high, the whole point of increasing the fee is to price out some the lower value transactions.
00:28:05.090 - 00:29:04.806, Speaker A: And today it looks like those lower value transactions are going to be these failed arbitrage transactions that really no one wants them to land. They just happen to land and they happen to get sent as a byproduct of this inefficient fee mechanism and inefficient scheduler. But at the end of the day, if there's so much demand for the block space at a given price, you're going to end up in this world where if you keep the base fee low, you're just going to have these payment transactions not get in, or they get in with some probability that's pretty low. And I think that's just a significantly worse ux than, hey, when things are really congested. Yeah, you have to pay like five cents to get your transaction in. You have to pay ten cents to get your transaction in. You can wait and hope that the price goes down later, but I think that's a significantly better ux than what we have today, which is you're bidding this arbitrary priority fee.
00:29:04.806 - 00:29:12.582, Speaker A: You don't really know what it means, you don't really know how to set it. And in fact, it has no actual economic meaning. It's really an implementation detail of how the scheduler works today.
00:29:12.736 - 00:29:53.754, Speaker C: One thing I'll say before moving on karate is like the four threads thing again, just want to highlight that's arbitrary. I think the design goal here is essentially get the software in such a state that all you need to do to improve performance is add more course, right? And that's a long way or a long path to get there. Obviously, Eugene's pointing out some very valid implementation details and maybe even some actual strategy details as well that need to be reworked. But once those, let's say, hypothetically get solved, then if you're in a state where you can just keep adding more cores, that's kind of like what Tolley's vision is.
00:29:53.872 - 00:30:11.310, Speaker B: Quick break to tell you about access protocol. The easiest and best way to stay up to date on what's happening in crypto by following your favorite publishers. And you can do all of it without a subscription, without having to worry about ads. And we all know subscriptions. How many do you have? 1020. Can you cancel it? It's all a mess. Well, access protocol solves this, and they do it in a crypto native way.
00:30:11.310 - 00:30:39.750, Speaker B: They have over 60 publishers that include Coin Gecko, the block crypto slate, and a whole long list of independent creators. So how it works is you find your favorite publishers and you stake the ACS token. That's the access token. And once you stake, you have access to all that creators content without the hassle of ads or subscriptions that you can't cancel. You don't know how many you have. Access protocol already has over 225,000 users that are finding new creators that are reading content and even receiving NFTs from these creators. Because one of the cool things with Access protocol is that these publishers, they can know who their subscribers are.
00:30:39.750 - 00:30:58.286, Speaker B: They can make it where okay, maybe we'll do an in person event, or maybe we'll do an NFT drop and we'll do it only to our most loyal stakers, aka readers. Early tough 24. They're even releasing V two crypto native. It's on Salana and it's an awesome product. Put a link in the show notes to the hub. It's the easiest way to get started, so go check them out today. Quick break to tell you about an upcoming event I promise you don't want to miss.
00:30:58.286 - 00:31:25.986, Speaker B: It's Blockwork's biggest and best institutional conference called Das London. It's a two day event happening in London this March where we're going to have over 700 institutions, 130 speakers, and a couple of thousand of us all under one roof. Crypto is in a position for the first time to actually onboard these institutions, and they're showing up. We have companies from Blackrock to visa and launching real products in the space. We have the real world asset narrative taking off. We have things like payments that have been exponentially growing, and then we have things like deepen happening in the Solana ecosystem. There's a ton of capital right now in this institutional space that's going to be coming on chain.
00:31:25.986 - 00:31:46.926, Speaker B: It's going to completely change the industry. Whether you are an institution or you're a retail user, or you just want to learn more about what's going on in the space, this conference is for you. You're going to be able to meet some of the best and smartest people in the space. The speaker lineup is absolutely incredible, and you'll get to hang out with me. But the best part is you actually get 10% off your ticket if you use light speed. Ten, when checking out, I put a link in the show notes. I recommend buying this today because one, you'll forget about it.
00:31:46.926 - 00:31:52.174, Speaker B: Two, these ticket prices go up every single month. So anyways, I hope to see you there. Now let's get back to the show.
00:31:52.212 - 00:32:27.580, Speaker C: You briefly mentioned searchers, and then you also briefly describe Jito and how they kind of get around this idea of continuous block propagation by holding these mini auctions, or for people, because we haven't actually covered MeV on the show before. So for our listeners who aren't going to be sophisticated traders, could you briefly describe what MeV is, how it differs on Solana from Ethereum, and just how it works in general? Explain like I'm five.
00:32:29.890 - 00:33:30.718, Speaker A: I can try to explain it to you like you're 20. So MeV, at a very high level refers to how much value and the types of value that can be extracted by whoever has this monopoly power of organizing the block. So that's the leader of the block for both Ethereum and Solana. So you can run this default native block building algorithm, which on Ethereum would be you order all of the transactions of the mempool by gas, and then order in descending order, and then place them into the block until your block is full. And that roughly will maximize the value for the validator. And on Solana, the way the native block builder works is via the scheduler mechanism that we've talked about. But you can imagine if you have some infinitely intelligent, infinite computational power validator, there's a lot of other ways they can make money as well.
00:33:30.718 - 00:34:33.650, Speaker A: For example, you see all of these trades that are made, some of them are like very profitable trades, and the validator could be inserting them themselves. At the top of the block, there's this arbitrage opportunity. They're going to take it. And so today, the way these are extracted is not actually by the validators themselves, or very rarely by the validators themselves. It's by these external entities called searchers, who are searching for these mev opportunities, these profitable trades, and then trying to land them on chain before the opportunity goes away. So Ethereum has this notion of independent block builders and independent searchers as well, although there is some searcher builder integration. And so instead of the leader having to run the block building algorithm on their own and make modifications to that on their own, that's delegated out to these third parties and so on Ethereum, there's like three to five dominant blockbuilding entities that like 95% of the network delegates the block building responsibility to through the system called Meb Boost.
00:34:33.650 - 00:35:23.518, Speaker A: That's totally out of protocol on Salana. These searchers are just like sending transactions to the network on blocks that are not run by jeto validators. They're just sent the normal way. And then the only way you can try to get your transaction prioritized as a searcher, you might really care about, for example, landing this profitable arbitrage before anyone else can get to it. So you want to be really fast, and you might want to bid a little bit higher on your priority fee to get included. But there's no explicit mechanism for, hey, I'm willing to pay up to one dollars to get my profitable transaction in and don't include my failed transactions if I don't get there first. And the reason a mechanism like this would be good is one you reduce the amount of spam that lands on chain.
00:35:23.518 - 00:35:56.160, Speaker A: So that's like this sort of wasted block space. I think most of us can agree, even the people who are sending the failed transactions would agree. They would prefer all else equal, that these transactions do not land on chain. You just want the successful ones to land on chain. And then it also prevents this vector of validator centralization. Now, I think it's highly unclear how important this really is on Solana today. It's actually very unimportant, in my opinion, because the inflationary awards to validators are significantly higher than the amount of MeV that's available.
00:35:56.160 - 00:36:55.706, Speaker A: And the worry here, though, is you have the centralizing force where the most sophisticated validators can extract more value. They'll be able to attract more stake because they can offer higher staking rewards. And so in theory, you have this economic pressure that centralizes the validator set via staking incentives. But that incentive is quite small on Solana today. And I think far more important to Solana is reducing the amount of spam that lands on chain. So the way Jito does this is they just implement this auction mechanism where they say, instead of whoever is fastest makes it on first, they have these 200 millisecond discrete auctions that are happening during the jeto slots, which today is about 40% of all of the slots. And there they call it a tipping mechanism, where you basically send a tip to the validator to include you first and then your failed tip.
00:36:55.706 - 00:36:58.850, Speaker A: So if you lost the auction, your transaction does not make it on chain.
00:37:00.390 - 00:37:22.346, Speaker B: And when you talk about that, it gets into value accrual, or at least how some people would talk about it, right? Because right now, maybe as a searcher or someone that wants to get their transaction on chain and arbitrator, they use latency as the main means to express their preference. Whereas this hopefully moves some of that to actually, you pay to play, essentially, and that payment can go to the validator, who then goes to the stakers in an ethereum land. They often say that Mev is like.
00:37:22.368 - 00:37:23.782, Speaker A: The value accrual of ETH.
00:37:23.926 - 00:37:41.680, Speaker B: So that is something that could move towards slan in some ways, or at least help with validators being profitable. Have you had any thought on just how applications can accrue any of that value themselves? All of the tips for this hot state goes to the validators and to the stakers, but not to the individual apps themselves. Do you think there's anything that we can do there or that you've seen?
00:37:42.950 - 00:39:35.358, Speaker A: Yeah, so there are definitely things that can be done here. I would say they're generally quite opinionated, and the main opinion that is going to get expressed here is on the sovereignty of the block space. So who owns the block space that is contested, and who receives the economic benefits of owning this contested block space? So you could imagine some mechanism where we've implemented these dynamic fees per account, and then instead of the fee going to the validator or going to the network, it goes to the application. You might create some perverse incentives here, where now, instead of trying to minimize MeV, which is not always, but often ends up being negative to the users of the network or the users of the application, now, you might want to be maximizing it, but any proposal like this is going to be really opinionated on the specific question of who owns the block space and who deserves the economic proceeds that come from controlling this limited resource. I think in general applications, there's a lot of work applications can do to reduce the amount of MeV that they expose. For example, avean compound came out with this pool based lending mechanism, where you have external liquidators come in and before the position goes underwater for the protocol, you give them some incentive to unwind the trade on behalf of the user to prevent the protocol from losing money from bad debt. And the initial mechanism that they used was sort of giving this flat fee to the liquidator, something like 5% or 2% of the notional value of the loan, and right at the point where the loan goes underwater.
00:39:35.358 - 00:40:09.406, Speaker A: So you end up with this very spiky Mev opportunity where there's no Mev. No mev, no mev. And then all of a sudden, when the price crosses some threshold, now there's this discrete change in the amount of value that's extractable. Then we saw Euler finance come around with their lending protocol, which actually very similar to AaVE, except they have a dynamic fee associated with the liquidations. And this means, like, the more underwater a position is, the more incentive you give the liquidators. But that incentive starts very small. So now you're really one.
00:40:09.406 - 00:41:10.366, Speaker A: You're rewarding skill, where instead of anyone with half a brain being able to execute this liquidation opportunity, and then it becoming who's going to be fastest or who's going to be able to pay the most. And remember, this value is not going back to the protocol. This value is going to the liquidators, or in the end state, actually going to the validators. You can actually internalize a lot of that by hosting this thing that looks like a reverse dutch auction, where as a position goes more and more underwater, the bounty for the liquidation goes up. But it starts very small. And this in general should reduce the liquidation bonuses that are paid, and you end up in a regime where the validators or the network receives a lot less of this value and more of it is kept by the protocol itself. And so there's a bunch of application specific things that application developers can do to reduce the amount of leakage to MEV.
00:41:10.366 - 00:41:47.486, Speaker A: I think this really hasn't been studied very much on the Solana side, because the MEV marketplaces are just much less mature and the total amount of MEV is just a lot lower. But we should expect some of this to change. It also depends on the users caring about this. Right. Like, usually if a user has, like, a loan that is going underwater, it would have been really beneficial for them to just unwind it themselves, rather than paying this liquidation bonus to the network or to the liquidator. And in practice, we see users are just not particularly sensitive to this type of thing, even if they are economically harmed by it. Yeah.
00:41:47.508 - 00:42:28.860, Speaker C: So I have two follow up questions here. One is going to be just, you just mentioned the users here, and I have seen some funny tweets recently. So this guy hge posted, every time you swap on Solana, you are getting attacked by bots stealing money from you, and it is shitcoin season. And basically what ends up happening is you launch token, the bots snipe it, the liquidity, and then the prices get a little weird for the users, let's say. What do you think about that? What would you like to see more from the ecosystem so that we're more mature about that stuff going forward?
00:42:30.610 - 00:43:15.418, Speaker A: So I don't know if I'd agree with that exact wording, but I would say, like, yeah, there are opportunistic bots that profit immensely from this shitcoin activity. There's a couple main ways in which they do it. Let's throw out the sniping for now and just focus on the user transactions themselves. So I'm some user. I go to Jupiter, I see there's a price for the shitcoin I want to buy, and then I go click trade. There's a few ways I can get wrecked here or lose out on some economic opportunity or get, like, a worse fill. The first is sandwich attacks, which roughly means I set my slippage to 10%.
00:43:15.418 - 00:43:59.510, Speaker A: What I was really trying to say is just, I want to market buy this thing. I just want to pay the fair market price at the time my transaction gets included. And then the only way I can express that is by setting a high slippage tolerance. So if the market moved, like, 2% away, I'm still going to get in, but I'm just going to get a 2% worse price. And what a sandwich attack does is if they see your transaction and they're able to land a transaction in front of it, as well as a transaction behind it, they can actually force you to get the worst price that you set. So even if the market price was 2% worse than what you saw in Jupyter, and you set your slippage to 10%, the bot is going to push the price to the point where you actually get this worst fill possible. You get this 10% worst fill, and they're going to make this profit on top of that.
00:43:59.510 - 00:44:25.410, Speaker A: So that's pretty toxic to the users themselves. Previously, we did not see this on Solana for two reasons. One of them is just, again, the bounty was not high enough for people to set this up. And two, because Solana has no mempool, you can't see these transactions, or only the validator themselves can see it. So if the validator wanted to do the sandwiching, they could have done it. They could have done it this whole time. Now, there is some notion of mempool exposure through Jito.
00:44:25.410 - 00:45:24.500, Speaker A: So there's a lot of this probabilistic sandwiching that we're seeing on chain today, which is basically forcing users to get worse fills than they would otherwise. And then the other way in which the user can get wrecked is through back running. Usually this is more an artifact of poor routing or the routing being set at the time you send the transaction, and then there's some delay between then and when your transaction gets in and may no longer be the optimal route. And so after your transaction lands, let's say there's like three pools for the same shitcoin, but your transaction is specified a single pool. After you make this trade, the back running bots, the arbitrage bots will come in, they will sort of equalize the prices among all the different pools that have the shitcoin, they'll make some profit from that. And in theory, that could have gone to the user in form of better execution on the trade, or they could have executed across all the pools at exactly the right amounts to keep those prices in line while taking on the position they want to take.
00:45:25.910 - 00:45:54.830, Speaker C: Well put. Okay, so the second question I'm going to ask, and this is just a tweet I'm going to read, is from Tolle, and he says, and I want to see if you agree or disagree with this. My theory on MEB is that all the efforts to correct it will result in worse information latency. So a discrete batch auction of 10 seconds will end up with a worse price than the average price of 100 millisecond blocks, but the MEV will be unevenly distributed in the latter.
00:45:56.530 - 00:47:23.340, Speaker A: Yeah, I pretty much agree with this, and I think this goes to a fundamental philosophical difference between the Ethereum world and the Solana world, where the Ethereum world has been so focused, or the MeV side of Ethereum has been so focused on democratizing the opportunity, as they say, which is sort of equivalent to maximizing how much the users get screwed, and then making sure that that profit from screwing the users is distributed as evenly as possible in a way that doesn't affect the validator incentives or it doesn't create validator centralization. There's a few problems with that. One, you clearly make the user experience a lot worse. It's also bad for the applications because they just continuously leak value away from their system to the base layer. And if you optimize for speed, like with continuous block building versus discrete block building, yeah, you are going to have these returns really accrue to whoever is going to be able to be the fastest, but the user transactions will get in more quickly. And as long as there aren't too many other negative externalities, like again today we see so much spam landing on chain, which is a negative externality. And if we worry a little bit less about this theoretical validator centralization, or centralization of stake to the highest performing validators, I think a lot less of an issue.
00:47:23.340 - 00:47:59.590, Speaker A: And even on the Ethereum side, where we've been pretty worried about this theoretical validator decentralization, I think that was probably just a lot worse. In the proof of work world, where the mining pool with slightly better unit economics actually can just mine a lot more. And in the proof of stake world we've seen, the stake is not actually that sensitive. To the API. Certainly if my validator is getting 4% and yours is getting like 4.1%, we haven't seen things like massive amounts of stake moving from my validator to your validator. But it is possible.
00:47:59.590 - 00:48:40.898, Speaker A: Maybe in the long run that does happen. We just don't really see too much evidence of it today. And we see even like Coinbase, staking has more than 10% of the Ethereum stake today, and they're charging like a 25% commission on all the staking rewards. Clearly, the people who are delegating there are not delegating because they think Coinbase is going to give them the best API. There's something else that they're optimizing for too, which could be really trusting who you're delegating to. There could be like legal and compliance reasons. It is possible to focus too much on the democratization and then neglect other parts of the system because of it.
00:48:40.984 - 00:49:15.454, Speaker C: Okay, so completely shifting topics here. I didn't want to finish this episode without bringing this up at least once. I want to talk about risk. Right? So the other, I guess, month at this point, there was an incident with the MSOL price really taking a pretty big dive. And then Solan came out and said, well, actually we use the native asset for the native asset oracle. And then some people were like, wait, what? What did you think about that? And what do you think about the way we've managed risk in Solana defi so far?
00:49:15.492 - 00:50:31.510, Speaker A: In general, I think protocols that are hard coding asset prices are taking on a particular type of downside risk that might not be getting communicated to the users. It's kind of the same as hard coding USDC to one or USDT to one, or some stake derivative to whatever the protocol thinks is the fair value, rather than really focusing on protocol solvency and using the market prices to dictate that. So there's definitely some downsides of the latter approach, which is what we see more on the Ethereum world, where you do create, potentially an incentive to attack the markets, to manipulate the markets, to create liquidations. But then you end up with this. If you are hard coding, say like MSOL equals 1.1 sol or whatever, in the case where MSOL gets exploited and the actual fair value of MSOL goes to zero, your whole protocol basically gets drained. Or you get drained to some degree, and then maybe you have some other ways to pause the protocol, but at the end of the day, you're probably still screwed.
00:50:31.510 - 00:51:17.962, Speaker A: I think the risk discourse is pretty healthy. I wish it was a little bit more constructive rather than so antagonistic, because there's a lot of real questions there that I think deserve a better discussion. And also a lot of these leveraged protocols are derivatives of protocols that we see on Ethereum. And most of the Ethereum protocols have sort of taken the same stance around, like, we're just going to use the oracle price, we're going to use the market price. And it's not obvious that this is what you should be doing all of the time, but at least the discourse that we've seen in public has been very far from constructive.
00:51:18.046 - 00:51:30.374, Speaker B: That makes know you're an application builder, but you know a whole lot about MeV and how these transactions work on Solana. So you work at Phoenix, but you also write research at Umbra or Umbra. Is that the right way to say it?
00:51:30.412 - 00:51:30.806, Speaker A: That's right.
00:51:30.828 - 00:51:50.382, Speaker B: Umbra. Umbra. I want to get into what you're doing over there, but one thing that I hear about application developers on Solana is you don't have to worry about the infrastructure, you just worry about your app because everything scales. But you even write research about how Solana works and how these fee markets, et cetera. So you're like, you're getting really deep into it. Is that just out of interest, or is that because it's so important to something like Phoenix that you're working on?
00:51:50.516 - 00:52:32.640, Speaker A: I think it's incredibly important for application developers to understand the infra. I think there's some potential future world where all of the infra is actually perfect and you can have these mental abstractions where you don't need to actually dive any deeper into the infra. None of the blockchains are there. None of the blockchains are even close to there. Solana is definitely not there yet. And I think it's really important for application developers to understand how the chain works so you can build better applications that serve the users. So, you know, I myself come more from the Ethereum world before we started the company and went full time into Solana about one and a half years ago.
00:52:32.640 - 00:54:14.780, Speaker A: And what we saw here was a very refreshing focus on pragmatic engineering on the Solana side and a little bit less interest in some of the incentives and very high level economic design that is so prevalent in Ethereum. And over this last year spent a lot of time continuing to talk with people on the Ethereum side, many of whom have been interested in Solana because Solana has some very different approaches than Ethereum has taken to some similar problems, and it's just impossible for them to understand how Solana works, even at a high level. So the top goal for umber research is first and foremost to explain how Solana works in a way such that other motivated researchers who have no understanding, no background knowledge of how Solana works can come in if they're interested and be able to meaningfully contribute to Solana. So I think a lot of this reference material has been super valuable in terms of onboarding ethereum researchers onto the Solana side, and then with sharing some of these approaches, I think both Solana and Ethereum and all of the other blockchain ecosystems can learn together. And I think on the Solana side, we've been able to bring in some of the better ideas from the Ethereum world and vice versa. And we see just like a lot more collaboration between the two blockchains today.
00:54:15.230 - 00:54:47.480, Speaker B: Yeah, I think it's really important you hear John Charboneau talk about that as well. And the reason why you chose Ethereum is really like the documentation and the research, it was so interesting and also you could grasp what's going on. I know sometimes in Solana it's like, where was that post? It was in some discord, right? And it's like extremely hard to find. So I think it's really important. I'm curious. We've seen the price of Seoul go up exponentially almost over the last year. Have you seen the interest in developers and kind of conversation around how Solana is, know what changes need to be made? Have you also seen that exponentially change over the last year? Or is that a little bit slower than the price movement itself?
00:54:48.650 - 00:55:17.682, Speaker A: I think it's a little bit slower. It's definitely trailing the price, but it's there for sure. It is kind of funny. The technology has suddenly become like five times more interesting to everybody on the venture side, the investing side, and the research side. But the attention is definitely good, and there's a ton of work to do on Solana. And the more competent, well meaning people who are trying to contribute there, the better it is for Solana as a whole.
00:55:17.816 - 00:55:28.600, Speaker B: Definitely. Before we close, I want you to talk about Ellipsis Labs a little bit and what you're working on with Phoenix. Maybe describe what Phoenix is. And also, is that the only project you're working on? Is that the only thing you're planning to do in the future?
00:55:29.050 - 00:56:25.718, Speaker A: Yeah. So at a high level, the mission for Ellipsis Labs is to build better DeFi products, to build the backbone of a financial system that is decentralized and gives users all the benefits of decentralization while delivering superior products as well. And so when we started the company, we saw this gap in the market where Serum had existed for quite a while. Serum is like this OG limit order book implementation on Solana. I would say it was probably the first product on Solana that we could really categorize as only possible on Solana, where the fees and the block times make it possible for active liquidity to participate on chain fully on chain. And it was just a project that had been kind of neglected for a while. It was under the Alameda FTX consortium, and there just wasn't very much love put into it.
00:56:25.718 - 00:57:29.938, Speaker A: We identified a bunch of architectural changes as well as product changes to build a new limit order book from scratch. That takes all the learnings we've had on Solana over the last three, four years and just builds a much more modern version of it. And one thing we see with a lot of the other liquidity primitives on chain is they are just like, not sustainable, or they have this very fundamental trade off between quality of liquidity and sustainability. Because, yeah, these xy equals k or other amm type designs suffer from having the liquidity profiles being so constrained. Whereas with active liquidity, where you let these professional market makers really just place the liquidity where they want to and foster this competition between liquidity providers to provide better prices to users. That's worked very well in tradfi, and we see it as like a step function improvement over what exists in DFI today. And that really is only possible on high throughput, low fee blockchains like Salana.
00:57:29.938 - 00:58:15.290, Speaker A: So the product is called Phoenix. The protocol is called Phoenix. Today, we're around the number, somewhere in the top ten dexes by trading volume across all blockchains. Awesome. The most important thing that we care about is the liquidity being profitable and the liquidity being uninsentivized. So we don't offer anything like, hey, retail, come put your money in here, and you're going to get 100% APY with a bunch of asterisks on top. The liquidity is primarily provided by professional liquidity providers who care very much about being profitable and sustainable, which is super important for building a lasting financial ecosystem.
00:58:16.190 - 00:58:25.278, Speaker B: Yeah. So when you say that, does that mean you wouldn't offer liquidity on meme coins, likely just because of the giant volatility? Or are there market makers out there actually supporting that?
00:58:25.444 - 00:59:18.190, Speaker A: So there are some meme coins where market makers profitably provide. In fact, it's probably far more profitable for them to provide on those meme coins than on a coin like Sol USDC, just because the spreads are so much wider, that reflects the volatility. But I think the biggest trade off between this active liquidity model and a passive liquidity model is there is a lot of upfront work that goes in for a single market maker to be able to participate. And so if the volume on a particular meme coin or whatever is just not going to make it worth it for them, then the Amm pool is going to outcompete because you can have these retail guys come in and just like one click deposit liquidity. And I think there is a lot of value in that as well.
00:59:18.340 - 00:59:43.800, Speaker B: Yeah, I'm not saying this is good for the liquidity providers, but is it also maybe true to say with amms and heavy TvL protocols that that liquidity is probably stickier? And so that if you did have a big market disruption, for example, and someone needed to mass sell, like this person that mass sold and sold the other day, that liquidity might still be there for someone to actually exit, whereas I'm assuming maybe on something like Phoenix, those market makers might just pull out.
00:59:44.330 - 00:59:53.654, Speaker A: Yes, but in practice, actually what happens is these AMs are making these very unprofitable trades during those times on behalf of the liquidity provider.
00:59:53.702 - 00:59:54.300, Speaker B: Yeah.
00:59:56.190 - 00:59:56.938, Speaker A: Exactly.
00:59:57.104 - 01:00:14.046, Speaker B: Yeah, that makes sense. One thing you mentioned is you're not offering like 100% APIs to retail investors, or I shouldn't say investors here, LPs. You also don't have points at the moment, and you've had a few fun statements out there about points. You're seeing point systems throughout Salana. Yeah. What do you think about points?
01:00:14.228 - 01:00:59.418, Speaker A: So I think incentives in general can be very powerful bootstrapping mechanisms, whether it's like points or tokens or something else. But again, we have this core product thesis that active liquidity can outcompete passive liquidity. And the only way that we are able to be confident in this thesis is by not having incentives. So we've seen with many of these other dexes, whether they're amms or order books, that offer very, very heavy incentives. You don't actually know if you have product market fit. And so the whole point of incentives is usually to bootstrap these two sided markets, right, where the liquidity supply and the liquidity demand need to be there at the same time. And the way you do that is via these incentives to cross this activation energy threshold.
01:00:59.418 - 01:01:45.294, Speaker A: And then slowly you need to wean off the incentives. And for many of these defi protocols that focus a lot on incentives. They've noticed like, oh, as you try to wean off the incentives or as your token goes down because you're providing so much incentive in the form of the token, the liquidity also goes away, the usage goes away, and so you don't actually know if you have product market fit until you remove the incentives. And some of these Defi teams spend seven, eight, nine figures in incentives without even knowing the product market fit. So I think that's not a really good way to spend money and also not a good way to validate the product thesis. But I think in general, incentives are a very powerful tool.
01:01:45.492 - 01:01:45.854, Speaker B: Yeah.
01:01:45.892 - 01:01:47.498, Speaker A: Just need to be used appropriately.
01:01:47.674 - 01:02:06.150, Speaker B: Well put. Two final questions. One is just at a high level, and this is probably hard to answer. How do you see Solana? Do you see it as a consumer chain, a defi chain, an FT chain, or do you think it support all those things? And then the question after that, to close this off is just any advice you'd have for a Solana builder or someone looking to come build on Solana.
01:02:08.170 - 01:02:58.600, Speaker A: Sure. So I view Solana as a general purpose blockchain. It's unclear if a single blockchain will capture all of the use cases. It's possible that different architectures will make sense for different types of applications, and it's also not clear how much benefit there is to everything being on the same state machine. So it seems pretty clear to me that it's going to be important for all of DeFi, or a big portion of DeFi to be on the same chain. So you have composability between lending protocols and trading protocols and these staking derivatives and whatnot. It's not as obvious that that all needs to happen in the same place as NFTs or gaming or whatever other applications might come to the blockchain in the future.
01:02:58.600 - 01:03:56.002, Speaker A: So I think the answer to that question really just depends on what is the demand for composability, as well as how good the cross chain infrastructure can get. Haven't seen too many great designs on the crosschain side. There's a lot of the roll up teams on Ethereum working on these types of problems, but yeah, nothing really seems too promising in that direction right now. And then, in terms of advice to other Solana developers, I think the most important thing is to ask questions. Solana, really, from the outside, looks like this pretty insular community on the developer side. But what we found is that people are actually very open to answering questions, talking about the pieces that are less documented in the system. This goes across every layer of the stack.
01:03:56.002 - 01:04:34.162, Speaker A: So the Solana core team is really good at engaging with application developers. The RPC teams who understand the infrastructure very well, are also really great about engaging with developers. And we've also had a lot of good results just talking with other application. Yeah, I think just being willing to reach out is really important. Understand that a lot of pieces of the system are just, like, not documented super well. Solana is still a work in progress, and the answers are out there, but you might be able to get answers faster by talking to people rather than by reading the. Yeah, yeah.
01:04:34.216 - 01:04:35.038, Speaker B: Very good advice.
01:04:35.134 - 01:04:35.346, Speaker A: Yeah.
01:04:35.368 - 01:04:59.590, Speaker B: I think the interoperability is going to be a huge question mark for the next year. I think fees on Solana is going to be really big and just how it handles scale. Obviously, what is really enjoyable about salon is it's already focused on this, and that's like one of its sole focus. And I do think as the SVM gets extended, hopefully there's more experiments that you might see, similar to like, l two s can experiment maybe with certain fee markets that Ethereum can't. So he's made. Eugene, thanks so much for coming on, everybody.
01:04:59.660 - 01:05:00.666, Speaker A: Go check out ellipsis.
01:05:00.698 - 01:05:06.670, Speaker B: Check out Phoenix. Thanks for coming on, man. Like I said, you really are, I think, one of the brightest people in the space. And salon is super lucky to have you.
01:05:06.820 - 01:05:07.914, Speaker A: Thanks for having me, Garrett.
01:05:07.962 - 01:05:19.774, Speaker B: All right, I've got a little ending note here. First, thank you so much for listening. The full episode. If you really liked it, hit subscribe. But secondly, make sure you sign up for dash. This is Blockwork's biggest institutional conference happening in London in March. I've included a link in the show notes and also discount code.
01:05:19.774 - 01:05:25.970, Speaker B: Get 10% off. Make sure to use lightspeed ten when you sign up. All right, I'll see you there. And I'll see you next time on Lightspeed.

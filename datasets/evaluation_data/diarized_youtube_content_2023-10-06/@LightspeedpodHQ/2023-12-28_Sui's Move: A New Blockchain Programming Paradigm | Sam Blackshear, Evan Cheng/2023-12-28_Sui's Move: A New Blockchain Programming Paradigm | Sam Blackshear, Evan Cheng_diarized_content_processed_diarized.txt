00:00:00.000 - 00:00:23.454, Speaker A: Why would it be possible for people to have, like, okay, this is an idea of how I can incorporate some crypto powered element to my product. I think that's the thing. The space has really been lacking. To try anything, you have to have so much conviction. Like, there's this new technology. Maybe I don't even really understand it, but I'm going to pivot to being a blockchain game or a tokenized asset, rather than like, this is just one part of the development stack or one piece of utility that I can bring in. And I think great things get built, especially with new technology.
00:00:23.454 - 00:00:29.378, Speaker A: Not someone knowing this is exactly what this is good for, but by trying a thousand things and seeing what sticks and what doesn't.
00:00:29.474 - 00:00:46.060, Speaker B: This episode is brought to you by Das London blockworks number one institutional crypto conference, where all the top institutions and people in crypto are going to be this march in London, what's becoming maybe the crypto hub of the world. Have a link in the show notes where you can learn more and also discount code that will get you 20% off. So click the link, find out more, and I'll see you there.
00:00:50.910 - 00:00:51.770, Speaker A: What's up, everybody?
00:00:51.840 - 00:00:57.962, Speaker C: Welcome to another episode of Lightspeed. Today we're joined by Sam and Evan from Mist and Labs, who are the creators of sui the l one blockchain.
00:00:58.026 - 00:00:59.440, Speaker A: Guys, welcome to the show.
00:01:00.530 - 00:01:01.760, Speaker D: Great to be here.
00:01:03.010 - 00:01:04.670, Speaker C: Yeah, pumped to have you on.
00:01:04.820 - 00:01:05.194, Speaker A: Sam.
00:01:05.242 - 00:01:30.646, Speaker C: I was doing some creeping to get ready for this episode, and I wanted your LinkedIn to see when you started Suey. And I saw that that was in November 2021, which is the absolute peak of the last bull market. So from, like, an outsider's perspective, I could see why two people had come together and start a new blockchain in l one at the hype. But I don't think you did it just because you saw that the market was pumping and it was an opportunity to start in l one. So I'm curious, what is kind of the history there? What is the gap that you saw in the market and why you want to start Suey? Yeah, absolutely.
00:01:30.748 - 00:02:29.994, Speaker A: I mean, so for us, right, it didn't have anything to do with the bull market. Both Ed and I and myself were on the Libra team at Facebook. So we were both on the team since 2018 and working on this Facebook, a project of trying to build global blockchain powered compliant payments network. And so our roles there was, I was the creator of the move language, the lead on the designing move, implementing move integrating into the Libra blockchain, and Evan led a research team that I was on and several other folks were on. So in what we were doing, we did a lot of the design implementation behind then, you know, as the engineering on Libra was basically done. We were doing a lot of work and looking at limitations we discovered in the process of building Libra in the first place. How do we scale Libra beyond a single box? How do we lower the latency of Libra? How do we do more advanced, smart contract programming than the sort of restrictive stuff that we were going to allow in Libra? And so we basically had this entire playbook for the next generation version of Know Narwhal consensus, a more advanced version of Move, a lot of cryptographic permanents that weren't included in Libra.
00:02:29.994 - 00:02:54.190, Speaker A: At the same time, Libra itself was stalling. There were a lot of reasons that it wasn't able to get out the door. None of them had anything to do with the tech. And we had a lot of false starts on that. And so at that point, in 2021, we were sort of like, well, seems like we have a lot of conviction and Libra, we'd like to see it go out, but it seems like that's never going to happen. We have the technical playbook for the next generation version of this. We see that a lot of folks need what we would like to build.
00:02:54.190 - 00:02:55.390, Speaker A: Let's give it a shot.
00:02:55.690 - 00:03:14.220, Speaker D: Me. For me, the writing has been on the wall for a while. This is not where my destiny was. Right. I was very excited to be leading research for the Libra project. But if you look at my background, I was building developer platforms. I'm building products.
00:03:14.220 - 00:03:42.482, Speaker D: I'm a PhD dropout. I never published papers. Research was not my thing. I always wanted to do something bigger than what Libra was. And so it's been back in my head for a while. How do we take something from building a blockchain to an actual developer platform for products? And what does product folks need? The timing was just. Opportunity was a good opportunity.
00:03:42.616 - 00:03:42.914, Speaker A: Right?
00:03:42.952 - 00:03:57.320, Speaker D: And as Libra was starting to wind down that it was a good time for me to come out and do my own thing. I don't even remember it was full market or not. It's two years. It's a long. Yeah.
00:03:58.670 - 00:04:38.610, Speaker E: So, Sam, you just nonchalantly mentioned you created move, but that actually reminds me, I think I tweeted something like, list all the programming languages you've learned in order, and I believe, Evan, you replied to it. This was a while ago, and you said you listed a few languages that you helped create, and I was like, okay, that's a pretty big. So I am curious. Was it like a Brandon icke in Javascript kind of story where you guys created this thing in a sprint? Or was it like a very long and arduous process where you were very careful with the design choices? What was the story of the language itself and how you wrote it?
00:04:38.760 - 00:05:03.930, Speaker A: Yeah, great question. So it's somewhere in between. When I joined the, you know, at the beginning, the Facebook was sort of pulling in experts from various areas. There's a distributed systems expert, there was a databases expert, there's a cryptography expert, and I was sort of the languages expert. And the mandate wasn't create a new programming language, it was, hey, Libra is going to be the smart contracts platform. You have sort of carb launch. Like take a look what's out there.
00:05:03.930 - 00:05:54.090, Speaker A: You can take EVM and solidity as is. You can try to build tooling around it to make it better. Maybe you build a new source language for the EVM that's better. Maybe you repurpose Waslam, maybe you repurpose the JVM or some other existing bytecode and build a language around it. Or maybe you build something from scratch. So basically I spent a couple of months really carefully studying solidity and EVM and just trying to see, know, what are these smart contract things? What are developers trying to do? What's the limits of what kind of programs are they trying to write? How is it like conventional programming? How is it different? Where are the places where the language is getting in their way, and where's the places where the language is helping them? And so from that exploration, we looked at all the different paths that I described in depth. What we ended up thinking is like, look, the smart contracts thing, it's a, these languages are a lot more like a DSL than like a general purpose program language.
00:05:54.090 - 00:06:37.066, Speaker A: They only do a couple of things. You're going to create objects, you're going to transfer and share them, you're going to do access control checks, and you're not going to do so much more. You're not going to be writing a compiler, you're not going to be writing an operating system, you're not doing file I o. You really want your core abstractions to be focused around these smart contract programming tasks, and then you want those abstractions to be safe and you want everything else to work outward from that. And so when we looked at achieving that goal by trying to bolt stuff on top of the evamron solidity, or on trying to take a general purpose bytecode like wasm, and trying to make it into something that wasn't designed for. What we ended up thinking is, look, we're very early in this whole smart contracts and crypto thing. Let's just design something from scratch that has exactly the properties we want.
00:06:37.066 - 00:07:04.974, Speaker A: And so with move, we started with the bytecode. We worked on having the verifier that checked all these things we wanted, memory safety, type safety, resource safety, having this concept of objects or assets that you just pass back and forth between functions in a very ergonomic way. And then the story sort of evolved from there. So that's how it went. Of course, we learned a lot by actually implementing lots of example code for Libra and rewriting solidity code and move and saying, one is a nicer, one is a less nice. And that's continued for five years. Now.
00:07:05.032 - 00:07:39.258, Speaker E: That makes. So we'll get to how Swee works. And I do have some pretty specific questions around the concurrency and the SCM stuff, and also about atomic composability. But I am curious, actually, you guys created a new language which is, as you said, maybe more similar to DSL. Anyways, in the context of smart contracts, I think my concern personally has never been really maybe the tech of sui, but more so maybe the go to market for capturing new developers.
00:07:39.434 - 00:07:39.774, Speaker A: Right?
00:07:39.812 - 00:07:50.980, Speaker E: So I'm curious that at mist and labs, how do you guys think about the go to market for getting developers, getting them to use this and entrenching them, or just cultivating this ecosystem of move?
00:07:51.350 - 00:08:16.866, Speaker A: Yeah. So I think the biggest thing we think about in developer acquisition is what's the prize for a developer? If I build something compelling, how many people are going to use it? What's my total addressable market as a developer? If you look across crypto today, the number I anchor this on is wallet installs. Like, there's maybe 60 million wallet installs across all of crypto. This isn't just salon or just ethereum. This is everything. And so if you build something and it's really, really great, that's the maximum number of people are going to use it. 60 million copy.
00:08:16.866 - 00:08:47.522, Speaker A: Maybe some people will install a wallet just to use your app. I think typically that's not the case. Like, we all know the UX hurdles in terms of key management, in terms of installing this weird browser plugin, in terms of logged in with a loss, these are all pretty great. And so we think about, okay, and then the other hurdle, of course, is that you're sending transactions on a blockchain. You have to pay for those transactions with the native token. And so how are you going to get those tokens? You go to coinbase, you go to your favorite exchange, you're scanning your passport, you're waiting, you're doing whatever you have to do. So these are just immense barriers to building anything.
00:08:47.522 - 00:09:37.706, Speaker A: And so what we think about is, okay, of course you got to have scalability, you got the good developer experience, you got to have security. But really the thing you need the most is you need a motivation for someone to build something because they're going to reach a large audience, because they can have an app that can go truly viral. And so that's really what we think about with suite and our developer acquisition strategy is how can we turn these problems into technical problems and then build features into the platform that can get rid of some of these. So I think our flagship in terms of this is ZK login, or the ZK stands for zero knowledge, which is a way that it's a native authentication suite, has cryptographic agility. So you can sign transactions with all sorts of different key types. And one key type is ZK login, where you can send transactions from a Google account, from a Facebook account, from an Apple account. We support a variety of different login providers.
00:09:37.706 - 00:10:27.958, Speaker A: And you can do that. You can have a self custodial experience where there's no key, that you're just bootstrapping the existing web, two, login into something that you can send transactions, you can sign transactions, you can build apps, all without having to install a wallet or having to deal with that. And then we couple that with sponsored transactions, which is a feature where someone else can pay for the gas. So you can use more traditional revenue models like ads pay for the gas, or maybe the app sort of comp sets the user as part of their strategy. And so these are two specific examples. But that's basically how we think about it, is how do we make the audience that a developer can build for larger, and then how do we do all the things we need to do at a technical level to make that possible? And there's many, many other things in terms of the experience of using move, the experience of using rpcs and these other finer points. That's sort of the big picture we think, that we're doing differently than others.
00:10:28.124 - 00:10:53.422, Speaker C: When you're talking to developers and you want them to come build on your ecosystem, are you largely talking to people that are in web two, or are you talking to developers that are already into crypto? And I think as part of that you developed move a couple of years ago, at least just from the little research I saw. It's not something that's like widely used outside of crypto right now. Like Aptos also uses it, whereas Solana has something like Rust, which I think can be more difficult to actually program, but at the same time it's used by developers kind of outside of crypto in itself.
00:10:53.476 - 00:10:54.846, Speaker A: So I'm just curious, what is your.
00:10:54.868 - 00:10:58.270, Speaker C: Pitch to get users in to start working on suite?
00:11:00.690 - 00:11:30.182, Speaker D: It depends on the audience, right? I mean, when you think about building up a developer platform, there's definitely a large group of web suite developer that when we pitch to them, we tend to talk about the merits of the language, but also the platform as a whole. This is perhaps something that's a little bit of a misunderstanding in the general blockchain industry, that you don't take a blockchain and add a language on top of it, then you're equivalent. The whole system has to be designed cohesively.
00:11:30.246 - 00:11:30.570, Speaker A: Right?
00:11:30.640 - 00:11:36.362, Speaker D: Leverage each sort of design feature and the philosophy of everything else.
00:11:36.416 - 00:11:36.634, Speaker A: Right?
00:11:36.672 - 00:13:09.160, Speaker D: This is why the experience of developing on suite is very different, say, than Aptus, even though it's both move based chance, right? So for sort of like the bottom up strategy in terms of growing developers web, three native developers focus on the pain points, right? Is kind of the experience of the language or the APIs and all that, are they fine, right? And although the overall chain experience or is it more about security concerns or gas or scalability, any of that sort of thing. But we also talk to a lot of larger product builder, I wouldn't say they have much of opinions about Webstream. Typically they just want to solve problems, right? So for us, when we talk to these partners in these larger development shops or companies, enterprises, it's understanding what problem they're trying to solve and provide them with solutions. Frankly, if you think about how large scale applications are developed, they don't necessarily exactly using a particular language. It's typically building on a lot of different solutions already available on the market, right. There is a very few company, they have the capacity, the ability to go out and sort of build a stack on the bottom up. So it really depends on who we're talking to and the approach can be quite different.
00:13:10.250 - 00:13:31.038, Speaker A: And to touch on the question you asked about rust specifically, this particular thing is somewhat of a pet peeve of mine, because I think folks say like, oh, if I just use Javascript in my blockchain or use rust in my blockchain, then instantly I get the entire developer communities of those languages when that's not the case. Let's take rust, for example. I'm not picking on rust. It's a great language. I code in it all the time. That's what move is implemented in. That's what Sui is implemented in.
00:13:31.038 - 00:13:41.246, Speaker A: Long before Libra. We're talking about smart contracts. The fundamental thing you're doing is creating assets. Okay? Rust doesn't have a built in notion of an asset. You're transferring them. There's no built in notion of transferring. You have accounts.
00:13:41.246 - 00:14:09.698, Speaker A: There's no built in notion of that either. And so these fundamental things that you're doing, they all have to be added on in terms of libraries. And although the language itself is familiar and the IDE is familiar, the build system is familiar. These sorts of things like the programming experience and the core abstractions have to be bolted on with libraries. And there are certain corners of the language that you're not allowed to go into if you're writing smart contracts, but you could if you were writing normal rust. So I think these things help to an extent. I think it makes it a little bit easier to get started because you don't start off by, say, installing a vs.
00:14:09.698 - 00:14:22.670, Speaker A: Code in for some unfamiliar language. But I think in the long term, really focusing around the task at hand, which is very different than what conventional languages are trying to do, does actually provide a big benefit for developers and for writing things that are simple and secure.
00:14:24.130 - 00:14:25.520, Speaker D: Yeah, good point.
00:14:26.850 - 00:14:34.290, Speaker E: I do have some thoughts on that, but in the interest of time, because I have so many questions, I'll just kind of keep firing away. So I want to do a quick crash course.
00:14:34.360 - 00:14:34.594, Speaker A: Right.
00:14:34.632 - 00:15:18.686, Speaker E: Because we have a lot of investors and developers and founders, primarily probably from Solana, but also maybe from Ethereum. And I want you guys to explain how to think about suite in terms of a mental model. And the way I'll frame that is like everybody knows the EVM single threaded runtime. They strongly believe in lower hardware requirements. And then maybe you're going to scale via l two s and dang sharding with the DA, but then maybe Alt DA is going forward. And then we have Salana, where everything is done in an integrated way using the SVM, more parallelization, and then there's sui. So maybe with that framework in mind, can you explain how Sui first achieves performance and scalability?
00:15:18.798 - 00:16:06.610, Speaker D: In a lot of way, I think this whole blockchain space, there's too much focus on all the complexity of the underlying technology. This is the only time when you're thinking about using technology. You have to be very keenly aware of the different scaling strategy. Or you're asking product builder to say, well, you probably have to use different components best suits your needs. You can have to think about. You have to think about a sequencer, you have to think about a sediment layer and all that sort of thing. This is in a lot of ways nuts, right? So from the high level, what we want people to think about when they think about three years, it's a platform where a lot of these things that you are concerned about, which other blockchain are just table stake.
00:16:06.610 - 00:16:20.100, Speaker D: You don't really think about scaling, you don't think about performance, you don't think about gas stability. They just work. Then the focus on how can we enable to solve problems, Sam, that you can talk to the rest.
00:16:21.670 - 00:16:51.758, Speaker A: Yeah, sure thing. I mean, so on first position with respect to the platforms that you mentioned and then maybe sort of tell the story more from the ground up. Swee is a smart contract platform powered by move. It's designed around the goals of ultra low latency and horizontal scalability. The thing it's doing differently, I'd say, from most other platforms is that we're starting from a data model that's oriented around objects instead of around accounts. Let's look at Solana or Ethereum. And there are different metaways, but in the data model they're similar.
00:16:51.758 - 00:17:25.558, Speaker A: Everything is based on accounts, right? You have an account and if you have coins, if you have nfts, the way you represent ownership is there's a large hash table. In this hash table there are keys that are addresses. And the values in the hash table are integer values that represent balances. Or they're bytes that represent NFT or whatever thing it is that you're talking about. When you send a transaction, it has an owner. That owner, usually the code is written in such a way that that owner is only allowed to do certain things. But they're entering the hash table.
00:17:25.558 - 00:17:43.402, Speaker A: Maybe they can only deduct from the balance of theirs so they can increment the balance of anyone else's. These sorts of things. That's the basic sort of like data and programming model in suite. The global storage looks different. It's a set of objects. These objects have global unique ids. You can think of it a map from object id to object bytes.
00:17:43.402 - 00:18:20.060, Speaker A: And then in the object bytes there's some native metadata. So the native metadata includes an owner field. So the owner could be an address, it could be the id of another object, or it could be immutable, which is how you represent smart contracts, or it can be shared, which means there's an object that's not owned by anybody, anyone's allowed to touch it. And this is how you represent something like a dex or an auction or any of these things where you allow multiple folks to touch at the same time. So that's the basic different view of the data model. Like oriented run accounts represent ownership of the hash table versus this pool of objects. You have ownership metadata that's embedded within the object itself.
00:18:20.430 - 00:18:34.110, Speaker E: Just maybe zoom out to a fourth year university student or some sort of vc level understanding of how does we get, or how does it get its performance. That's different from Solana and the EVM.
00:18:34.530 - 00:19:13.034, Speaker A: Yeah. So let's break performance down into two. One is, one is about latency. And this is, I think the thing is something that we're focused on maybe more than others, where we think having really low latency is what you have to have if you're going to enable a lot of use cases, something like games, that's very latency sensitive. If you're doing payments or anything with transacting in real life, you care a lot about latency. So we think a lot about how can you take latency and push it to theoretical limits. And so the main thing that we do there that's different is that in other systems, in the EVM and in Solana, what happens is you get a bunch of transactions, you have a consensus process that creates a total order among the transactions, and then you execute them.
00:19:13.034 - 00:19:51.554, Speaker A: And the execution part in, say in Solana is parallel. In the EVM, it's sequential, or in these new parallel evms, it's sequential. But there's always this bottleneck of, like you do the ordering first. And so in suite, what we observed is, look, when you look at computations, some of them require ordering beforehand and some of them don't. And especially in particular things like object transfers or payments, they actually don't require full consensus. You can get away with a weaker systems primitive, called byzantine consistent broadcast. And so in suite, we have consensus, of course, but we also have a consensus fast path where you can execute transactions using this byzantine, consistent broadcast system without going through full consensus.
00:19:51.554 - 00:20:14.980, Speaker A: And that ends up being a lot lower latency because global consensus among hundreds or thousands of validators is going to have an overhead that you can't get around. So what that lets us do is that we can have some transactions like payments or transfers that have end latency of 480 milliseconds, which is just a lot better than you're going to do if you have to go through full consensus and then for consensus, we have all the bells and whistles to make that fast as well.
00:20:15.830 - 00:20:20.558, Speaker E: What are the finality guarantees for that? Does that always finalize?
00:20:20.734 - 00:20:21.460, Speaker A: Yes.
00:20:22.550 - 00:20:25.202, Speaker E: Okay, that makes sense.
00:20:25.256 - 00:20:33.494, Speaker A: Optimistic finality in 25 milliseconds and you get finality in 400 milliseconds and you get end to end latency in 480. Okay, cool.
00:20:33.532 - 00:20:37.334, Speaker E: So that's the first vector we're looking at for scalability. And what was the other one?
00:20:37.452 - 00:21:02.574, Speaker A: Yeah, so that's the low latency story. And then of course, then we're going to talk about throughput. We won't be able to process a lot of transactions. This is like the most popular topic in the space since 2017 or 2018. And so our story there is a couple of things. So I'd say it's most similar to Salana, and that in the data model you have transactions, and a transaction says, here's the objects I'm going to operate on. I'd like to take this object as input because I'm going to transfer it.
00:21:02.574 - 00:21:43.354, Speaker A: I'd like to take this auction as input because I'm going to list something for sale. I'm going to try to buy something that's there and these sorts of things. And so the transaction can only touch the objects that are inputs. And so what that lets us do is it makes it very easy to do parallel execution, much like Solana with input accounts, you know exactly what's going to be touched. You can have a scheduler that farms out tasks to the appropriate cores, to the appropriate machines, wherever you need to, and you turn and execute through things in parallel. In addition to that, there's the feedback loop into the incentive mechanism. One of my pet peeves about parallel execution is that people are like, I had parallel execution and now I'm done.
00:21:43.354 - 00:22:27.034, Speaker A: Everyone's just going to give me a parallel workload. Right. But of course what you need is you need some way in your gas pricing or your incentive system that if you're going to create sequential contention on the same piece of shared state or like hotspots a lot of folks like to talk about, then that should cost more and it should also not affect the quality of service for other transactions. So for us it's very easy to do that because we know the objects inputs that are coming in. We can set up the gas pricing scheme such that gas price goes up on hot objects and stays the same on other objects. And then so folks are incentivized to send transactions that won't create contention or write code. That's not going to create sequential contention because it'll run faster and the prices will stay lower as well.
00:22:27.072 - 00:22:35.034, Speaker D: Perhaps it's also worth talking about the storage scalability story, because it's very different from any other blockchains out there.
00:22:35.152 - 00:22:53.838, Speaker A: Yeah, sure. So that's a third access worth mentioning. So I talked about latency, I talked about throughput, and there was one other thing I want to mention on throughput before I go on to storage, which is that. Okay, yeah. So parallel execution is a big part of this. This means you can execute a lot of transactions at once. You have the incentive system to make sure you get a parallel workload.
00:22:53.838 - 00:23:38.100, Speaker A: And then importantly, we don't want this to only be possible on a single box. We don't want our throughput to be limited by the largest machine that we can buy or ask our validators to buy if we need to. We want to be able to farm execution out to different workers. We want to be able to store objects across different workers. We want to be able to scale elastically up and add machines because there's a spike of transactions coming in, roll them down once traffic returns to normal, and all these sorts of things. And so the object data model is how we're able to do this. Because you have the native ownership information, because you have types inside the objects, you can shard by owner address, you can shard by type, you can shard by objects that are frequently used together.
00:23:38.100 - 00:24:30.274, Speaker A: This is all under the hood, like not part of the protocol. So you can change the scheme you use if the workload you're looking at shifts over time. And so, as Evan was mentioning, we care about this for throughput because we want to be able to get more throughput by adding more workers. We also want to be able to scale storage by adding more disks and not having that affect the throughput of the protocol or affect the latency, because we're always having to compute a checkpoint over some global state. And so the way the object and transaction data model works, we serve authenticated reads by looking at, by committing to the results of a transaction and then looking the validator signatures on a transaction and showing the reads off of that, rather than saying, oh, here's a big global merkle tree of accounts, and do your read off of. Okay, okay.
00:24:30.312 - 00:24:41.174, Speaker E: I have a few follow ups, but I'll try to maybe skip some for the sake of Garrett. For the first part, I'm curious when you say, because latency is one thing you're optimizing for.
00:24:41.212 - 00:24:41.558, Speaker D: Right.
00:24:41.644 - 00:24:56.490, Speaker E: How does that just excuse my ignorance? But as you keep adding more machines, what is the relationship between the validator set size and overall network latency?
00:24:57.150 - 00:25:21.780, Speaker A: Yeah. So for this fast path, there's not a strong relationship, because I didn't go into the details of how this byzantine, consistent broadcast process works. But the way it works is that I have a transaction, say it's a payment for me to Evan that I'd like to send. So what I do as a user is I broadcast that transaction in parallel to all validators, a quorum of validators. It doesn't matter. It has to be at least a quorum. Each validator looks at that transaction, checks that.
00:25:21.780 - 00:25:46.614, Speaker A: This is signed by me. I have sufficient balance all these sort of pre transaction checks, and they signed it and send it back to me. And then these are BLS signatures. I aggregate these signatures into an artifact we call a certificate. And then that certificate goes back to one or more validators, and that's what actually gets executed. So this question of what happens when you add more validators. Well, the user is broadcasting to the validators in parallel.
00:25:46.614 - 00:26:00.842, Speaker A: So if you're broadcasting to 100, 100, and 5500, 1000, it doesn't matter. The only part of the equation that changes is the BLS signature aggregation and the BLS signature checking. And that basically increases linearly with the number of validators.
00:26:00.906 - 00:26:04.130, Speaker E: And that's for both paths, not just the fast path?
00:26:04.870 - 00:26:15.970, Speaker A: No, that's just for the fast path. For the other path, we're using narwhal consensus, the relationship of its speed with respect to the number of validators.
00:26:16.470 - 00:26:33.740, Speaker E: Okay, it was same, and you mentioned something interesting there about horizontally scaling, but like elastically spinning up workers. Can you maybe explain a bit more how that would work? I'm guessing you're spinning up more workers per machine. You're not spinning up new machines, right?
00:26:34.270 - 00:27:10.982, Speaker A: No, you can spin up new machines. And to be clear on this part too, this is the long term roadmap that we've had come up with the architecture such that this will eventually be possible. Sweet and mainet today runs on a single block architecture. Of course, we leverage all the cores on the machine, but we think of a worker as a core rather than a logical machine. There's a lot of engineering work that needs to be done to get to this point where you actually farm out tasks to new machines. But I do mean like a new worker machine, where you're like, hey, there's this worker that has all of the objects of this coin type. And so when transactions come in.
00:27:10.982 - 00:27:36.098, Speaker A: If they're touching this coin type, I send them to this worker. This worker is handling all the things that are NFT types. And then if they come in, I send transactions to this worker. And then you try to set up the starting seam, of course, such that you can have all the reads and all the writes you need to do on the same machine instead of having to go across. And your scalability, or, sorry, your throughput, depends on how successful you are in doing that isolation.
00:27:36.214 - 00:27:49.406, Speaker B: Quick break to tell you about an upcoming event, I promise you don't want to miss. It's blockwork's biggest and best institutional conference, called Das London. It's a two day event happening in London this March, where we're going to have over 700 institutions, 130 speakers, and a couple thousand of us all under one roof.
00:27:49.508 - 00:27:50.958, Speaker C: Crypto is in a position for the.
00:27:50.964 - 00:28:16.310, Speaker B: First time to actually onboard these institutions, and they're showing up. We have companies from Blackrock to visa launching real products in the space. We have the real world asset narrative taking off. We have things like payments that have been exponentially growing, and then we have things like deepen happening in the Solana ecosystem. There's a ton of capital right now in this institutional space that's going to be coming on chain. It's going to completely change the industry, whether you are an institution or you're a retail user, or you just want to learn more about what's going on in the space, this conference is for you. You're going to be able to meet some of the best and smartest people in the space.
00:28:16.310 - 00:28:32.238, Speaker B: The speaker lineup is absolutely incredible, and you'll get to hang out with me. But the best part, you actually get 20% off your ticket if you use light speed 20 when checking out. That's light speed 20. I put a link in the show notes. I recommend buying this today because, one, you'll forget about it. Two, these ticket prices go up every single month. So anyways, I hope to see you there.
00:28:32.238 - 00:28:33.534, Speaker B: Now, let's get back to the show.
00:28:33.572 - 00:29:10.970, Speaker C: Had a question on the validators. Sam, I know this can change over time, and me and mer definitely aren't under the belief that you should be able to run a full node on your phone or on a laptop, necessarily, or a basic laptop. But I am curious, just what are the validator requirements from a high level, even, like the cost per month? So when we talk about Salana, it's often around $300. I think you can do $300 to $350. And I know if you want to validate in the set, I think you need 30 million a suite, which is like $17.4 million today to join that validating set. So I'm just curious how you think about requirements and also just what's the ultimate node validator set that you want? Because I think right now you have around 100 validators.
00:29:11.390 - 00:29:57.878, Speaker A: Yes, I think the comparable numbers there is costs about $750 a month to operate a validator. And you need 20 million sui. And so with these 20 million sui at this point is a high barrier to entry with these things. It's not that everyone has like 20 million suite of their own funds. When you launch these new networks, you have the Swee foundation, they have a staking program where it's like folks apply to receive stake from the Sweet foundation. And then the Sweet foundation makes choices based on know, we want good geographical distribution, we want good data center distribution, we want to make sure that we're not too much dependent on one kind of cloud provider operating system and all of these sorts of things. And so this is something where over time, you prove that distribution.
00:29:57.878 - 00:30:55.434, Speaker A: The people get their own funds, they start up new validators, they compete with the existing validators. The other ones go out. New folks apply in this program because they perform better stake, it shifted around and then the validator set grows. There's a lot of talk about validator set, and validator set size is like, this is the ultimate metric for decentralization, or you have to reach this level or it's not going to count. We're pretty pragmatic about this. We think the metric that matters the most is basically how much does it cost as a user to replicate that the transactions that are touching your state are actually doing what you want to do. And our story on that is leveraging this object data model to do something that we call sparse nodes, where it's like you can validate just the transactions that are touching your objects or touching your state, and you can download and run these very efficiently without having to pay the cost of running a full, full node or running a full validator.
00:30:55.434 - 00:31:31.210, Speaker A: And we think, especially as you get to the point where the validators are processing thousands or tens of thousands or hundreds of thousands of transactions a second at a very regular rate, it's just not going to be feasible at all for a normal user to do anything except for tracking the changes to their objects. So really that's, I think the thing that we're going to care about the most, that you can do the audit trail for what you do. And collectively, if everyone is doing that, then you have the verified view what's going on, and you make sure that validators aren't diverging from the protocol or doing things that they're not supposed to do.
00:31:31.280 - 00:31:54.846, Speaker C: One thing I am curious about on the parallel execution is how you think about optimistic versus pessimistic parallel execution. I believe aptos is optimistic. And then we have monad, who's doing optimistic, and I've heard arguments from them that it actually is highly efficient to do so in the sense that even if everything ends up being sequential, it's not much of a hit at all and it makes it a lot easier for the developers. So I'm curious how you think about that.
00:31:55.028 - 00:32:33.786, Speaker A: Yeah, it's a great question. So it's not an either or in either Solana or in Sui, where you have static information that helps you parallelize, that doesn't preclude you from also using dynamic techniques after the fact. More static information can only be a good thing. We are not doing anything particularly advanced today because the static techniques work very well. But if we wanted to stack dynamic conflict detection on top of that and execute things in parallel, even when the static information tells us they might conflict and do the rollback, that's something we can do as well. So my feeling on this is that every system is eventually going to have static information. For this reason I sort of alluded to earlier, and that it's not enough to just have parallel execution.
00:32:33.786 - 00:33:12.854, Speaker A: You have to have incentives for folks to be providing you a parallelizable workload. And if you find out that a conflict happens at runtime because you have an optimistic technique and you detect that, oh, this is actually creating a conflict, it's too late to charge that transaction a higher gas price or to otherwise punish them for, that's going to be changing the semantics. If you want to do that, you have to be able to detect contention at the static layer by looking at, hey, there's too many Solana transactions touching this account. There's a hotspot. There's too many sweet transactions touching this object. There's a hotspot. And then deprioritize it in the transaction processing queue, require a higher gas price, kick it out if there's a limit of transactions that are touching the same object or that sort of thing.
00:33:12.854 - 00:33:28.702, Speaker A: So I think that's my high level view, is that there's a lot of like, oh, build it and they will come. We build a parallel execution engine that someone's going to give us a parallel workload. But I think you really, really have to work that into the incentives layer, otherwise there's no guarantee that's actually going to happen. And the static view is key to doing that.
00:33:28.756 - 00:33:29.918, Speaker C: State growth is a big part of.
00:33:29.924 - 00:33:30.862, Speaker A: This as well, right?
00:33:30.916 - 00:33:42.260, Speaker C: Like you can have parallel execution, but right now, the reason why the AVM is so slow and has such low tbs is largely to prevent state growth. So I'm just curious how you think about that right now to prevent that happening in the future.
00:33:42.790 - 00:34:21.742, Speaker A: Yeah, absolutely. So we actually want state growth. What you don't want is state growth combined with a need to build an authenticated view of all the state in the system. And so we talked earlier about the object data model and how that avoids the need to have a giant merkel tree with all the objects at the root or all of the accounts at the root. What you want instead is you want to use conventional databases. And so when you need to do more storage, you provision more disks or you get a machine with bigger hardware. And that's the overhead of state growth is just the size of your validator set times the number of bytes instead of some much larger equation that factors in the superstructure of a merkle tree or some other global authenticated data structure that you have to build on top of that.
00:34:21.742 - 00:34:49.186, Speaker A: So we don't mind state growth. Our storage is very cheap. I think it's actually 100 x cheaper than Salana. Now, salona folks are going to say things about NFT compression and how that's the way to get cheaper storage, which, fair enough, that's a discussion that we can have as well. We're very comfortable with state growth because we tried to design things such that the storage is cheap in the real world and what to. And we can leverage that as much as possible, minus the duplication evaluator set forces. Gotcha.
00:34:49.298 - 00:34:51.320, Speaker C: I was just going to say, you're going to have to respond to that.
00:34:51.850 - 00:34:58.630, Speaker E: I am kind of tangentially, I am curious on maybe your long term view on archival storage.
00:34:58.790 - 00:34:59.500, Speaker D: Right.
00:35:00.590 - 00:35:26.450, Speaker E: Okay. So the way Solana works, for example, is you have state in the validators, current state, but then the ledger necessarily doesn't have to be on the state. In fact, there's no point. The point is you're having consensus on state n to n plus one, and then with compression, maybe you link those two with a merkle tree. How do you guys like, let's say you, I don't know, gets like a trillion transactions in some x years. Where's that data stored? How are you going to store it in archive?
00:35:26.790 - 00:36:07.570, Speaker A: Yeah, it's very much the same story as Solana, where we keep the account database, or the object database, in our case, on the nodes, and you need that information there because any transaction might come in and want to touch it. But of course, for transactions, that log is ever growing, so you need some form of state pruning. There's no dependency on transaction processing to have the historical log. We had it to make it easier to sync full nodes to the last month or so transactions or whatever we set that printing window to. And then there's archival nodes that are run by suite foundation, that are run by Nissan, that are run by the community who are tasked with having that storage around. I think Solana is one of the first to encounter this problem, has come up with a variety of solutions every time. Like, at first it was just in Google.
00:36:07.570 - 00:36:22.738, Speaker A: I think now it's in our weave, maybe in other places. I think you got transaction history and make sure that it can't be destroyed. And I think we'll be very much following in the footsteps of making sure that this is available for someone who wants to do historical audits or analytics. But it's not something that burdens the validators.
00:36:22.914 - 00:36:46.542, Speaker E: Yeah, one thing I'm interested in is one of the problems is, let's say you take some transaction that happened, I don't know, at time t equals five, and then how do you guarantee that it was actually a part of the ledger? How do you guarantee that it wasn't tampered with? Do you have any cryptographic solutions for that right now or. Not yet?
00:36:46.676 - 00:37:13.510, Speaker A: Yeah, exactly. We do. So we have a system of checkpoints, which it's similar to a block. It's not exactly the same as a block because it's formed asynchronously, but there's a sequence of checkpoint, like, basically the history of sweep for auditing purposes is checkpoints, each of which commits to the previous checkpoint. And then we have a notion of epoch. An epoch happens 24 hours. And then there's a summary of epoch where you can say, show me all the checkpoints that are included in this epoch.
00:37:13.510 - 00:37:54.050, Speaker A: Each of those commits to each other, and then the epoch summary commits to all the checkpoints that are in there. And then, of course, each checkpoint commits to the transactions that were included in it and their order. And so if you're auditing it, you can always. And then the other component on this is these are signed by the validator set. You have to reflect the validator set changes and stake weight changes. And so if you're trying to look at some old data if you want to be in the most paranoid mode, you start from Genesis, you walk through all the validator set changes until you get to the data that you care about. You check those signatures around there, you grab the epoch summary, you grab the checkpoint, and eventually you get the transaction that's in the checkpoint that you can replay or otherwise inspect.
00:37:54.710 - 00:38:13.418, Speaker E: Okay, this one's not related to storage, but I am just personally curious based on kind of, because you guys have obviously seen a lot of prod traffic, right? Like, this isn't theoretical. What percentage or maybe ratio of transactions currently take the fast path versus not 19%?
00:38:13.504 - 00:38:14.810, Speaker A: Take the fast path.
00:38:15.390 - 00:38:16.390, Speaker E: Take the fast path.
00:38:16.470 - 00:38:16.906, Speaker A: Okay.
00:38:17.008 - 00:38:28.154, Speaker C: And Sam, on that fast path, is that essentially like, if I wanted to send USDC to Mert, that's definitely going to be fast path. But if I'm going to interact with, say, uniswap contract, if I'm on Ethereum, that would not, because you're interacting with a pool and smart contracts.
00:38:28.282 - 00:39:03.066, Speaker A: Uniswap would not be. Yeah, I mean, basically, the way you can think of it is like anytime where there's transactions from multiple parties that are hitting something and there has to be a winner or a loser, then you're going to have to use a shared object. So a uniswap swap is one version of that. There are some Defi builders who are building DeFi products that take advantage of the fast path. And there, the idea is more like there's an operator, and it's sort of like a crank in these other Defi systems where you trust the operator for liveness to keep processing the transactions that come in, but you don't trust them for integrity. Like, they can't steal the funds, and then you can do defi. That's taking the fastpath into account.
00:39:03.066 - 00:39:08.618, Speaker A: But in general, if you're building classic Uniswap style dexes or order books or anything else, and that's going to use.
00:39:08.624 - 00:39:49.106, Speaker C: A shared object, that right there sounds a lot like code. They have a form of a layer two that's on Salana, and they do the same thing for liveness. I do want to touch on one more thing, maybe before talking a little bit more about just building a community, which is the security aspect of move, because there have been a lot of hacks over the last couple of years, billions of dollars. And Stephen Goldfeather from arbitrum, he's like, yeah, there's a lot of hacks that are happening over here in Ethereum, but that's not truly just because of the EVM. It's not happening on your chain because it's obscurity through unpopularity. You made a comparison to Apple and Microsoft, whereas everyone was like back this is say, ten years ago or 20 years ago. People are saying that there was no hacks on Apple computers.
00:39:49.106 - 00:40:00.922, Speaker C: And the reason for that, at least at the time, was largely because all the hackers were just going to windows because they had the majority of the market share and they hadn't set up their systems to actually attack Apple at that time. So I'm curious how you think about that and the security that provides.
00:40:01.066 - 00:40:32.982, Speaker A: Yeah, I mean, I think if someone asks you why is your smart contract language more secure? And you say, because there have been no hacks in it yet, that's a very weak argument. There's no smart contract language in the world that's going to stop programmers from writing unsafe code no matter what protections are built in. People are going to find a way to make mistakes like that. That's just not something that can happen. Your arguments have to be based on foundations and they have to be based on pure problems with existing languages that my language or my platform can just take off the table, period, for developers. And so for move, some of those things are like reentercy. This thing is the scourge of Ethereum that's caused many, many problems.
00:40:32.982 - 00:41:12.946, Speaker A: Like we saw just last week with NFT trader going back to the Dow attack, many of these things, reentrancy or more generally like dynamic dispatch. Like this is a blank check in your program for, and of course you can safely around that, but it's very hard to do it. Then there's things like ownership and permission checks in smart contract languages other than move, you have to run this stuff manually. When you have native ownership, the runtime is checking ownership score you can't check. And so that takes a lot of things off the table, similar things. And this is some Solana specific lesson. Ethereum object serialization data is coming in.
00:41:12.946 - 00:41:36.970, Speaker A: You have to make sure you serialize correct object type, whereas like when you have typed objects, that's taken care of for you. And so that's really the way we think. I'm very proud of that. We haven't had any attacks on suite, any hacks on suite. I hope that will continue for as long as possible. But pragmatically, things always happen eventually. I think the argument for why is this better? Has to be about, here's from a theoretical perspective, why we've designed it not to have problems that exist elsewhere.
00:41:37.630 - 00:42:12.680, Speaker C: There's a thing on Salana called Runtime V two. That's going to launch, I believe, in 2024, and it's going to bring move to Salana. And I know some other ecosystems are looking to add move as well. Can you maybe explain from your perspective on how that might be different than what's on sui right now? And mert, you might have something to add there. And as part of that, as a non techie, you often hear how even arbitram is trying to add different languages that you can use with stylus, for example. How does a compiler, are there more risks that are coming into that? Because you're saying that move can provide all these security guarantees, but then does adding a compiler kind of remove those?
00:42:13.290 - 00:42:59.394, Speaker A: So here's the way I would think of it, where I think the key value proposition of move is that you have this notion of typed objects and that the type safety doesn't just apply to your program and the objects that you declare. It also applies to objects that flow into your program or to your objects when they flow into untrusted code. And so really, not all of the value of move, but a significant amount of the value for move comes from the fact that the protections don't just apply to you, they apply to code you interact with, and they apply to the bad guys as well. And so if you integrate move onto Solana, of course you're still going to have the old account based system. You're going to have to have a story for interrog between move and Solana programs, and you're not going to be able to run the move verifier. That's ensuring all these nice things that let objects flow across those boundaries on the Solana programs. And maybe you'll be able to do it between move programs.
00:42:59.394 - 00:43:39.090, Speaker A: Sort of depends on the details of whether you declare move by code directly or whether you're compiling it into EDPF or however that's going to work. So I think there'll be parts of it that are nice, but I think anchor is also very nice compared to, say, rust, and then it interoperates better with, say, non anchor written salon program. So I think love to see move going to Solana. I'd love to see it going into many of these other systems. But I think if you're going to use move, you really want all the smart contracts in your system to be using move. So you can get those benefits of running the verifier and all of them and getting those strong assumptions on all of your code and all of your objects.
00:43:40.470 - 00:44:27.502, Speaker D: I'll give you a high level example back in the day, this is very early days in tech. You could write object oriented code in c. You can build all these abstractions. See it. I look like I use void pointer casting. And I know all this pain kind of you have to go through, but why would you more likely to make all kinds of mistakes if you try to roll up all these nice abstractions to make your life easier and better? When in the Swee move case, all these enforcements are building into runtime, you don't have this problem. We're excited to see move being kind of adopted by Solana and many other platforms.
00:44:27.502 - 00:44:48.760, Speaker D: But it's more than just a language. It's everything around. It's your data model, it's your kind of a tooling. Upstreams and downstream, the whole system has come together. So just having a blockchain and attaching a different language to it doesn't really. You don't necessarily sort of replicate the same stack. You don't get all the benefits.
00:44:52.190 - 00:45:34.406, Speaker E: Yeah, I definitely agree with that. Before I talk about modularity and atomic composability, which Sam commented on a few weeks ago, I do have a question about security, but not on the smart contract side. But maybe as the holistic distributor system, there's some that believe economic security is kind of like the end all, be all. And then there's folks like Anatoly who's like, not really, that's kind of a. And you know, I don't want to talk about the price of the token in any speculative way, but I am curious how you think about economic security and just holistic security network and what the role of the token is or how others should think about it.
00:45:34.588 - 00:46:01.642, Speaker A: Yeah, I mean, I think we're probably broadly aligned with NFL's points on this. So suite is proof of stake. We use stake weighted voting. And basically we think of the economic security as how much stake would you have to acquire in order to cause undesired outcomes in the system. Because we're starting from scratch. We do what all new systems do, like their stake subsidies to make sure that there's sufficient stake on day one. So that number isn't like in the thousands or millions.
00:46:01.642 - 00:46:38.122, Speaker A: And so I think there's something like 8 billion sue is staked right now. That's pretty good economic security, given that the total supply of sue is around 10 billion or something. But basically, I think there's a good enough threshold here. And I think basically, I haven't seen a lot of cases where blockchains have been attacked via the economic security angle, and especially not early on. I think it's something where it's like, there are many, many security problems with blockchains. This isn't the biggest one. I think this really starts to become a problem when I think at the point where one starts to worry about this, where someone with the resources to perform an economic security attack wants to do it.
00:46:38.122 - 00:46:51.680, Speaker A: It's also the case that your ecosystem has probably grown enough that that attack is becoming more and more expensive. So it's something that, of course, we have to worry about and keep an eye on and deal with things like stake subsidies. But I think we're in a pretty good position there.
00:46:52.290 - 00:47:42.430, Speaker D: Yeah, I'll say right now, if you look at, there is not enough mission critical applications running on blockchains today. If you imagine financial institutions and or governments start using public blockchains for any of the functions, and that completely changed the dynamics, completely changed the equation. Right now, kind of a bad player kind of actors can attack, would attack a blockchain, not necessarily for financial benefits, for their own financial benefit, just to disrupt kind of a government or financial institutions. So I think this is only one sort of factor of the very complex kind of equation.
00:47:42.850 - 00:48:15.386, Speaker A: I guess the one other thing, I might add is that I feel like economic security attacks are a little bit like the sort of wrench attack or these sorts of things where it's like, one could do it like, a state actor could buy up $8 billion worth of sweet and cause a problem. But at the end of the day, social consensus is the ultimate protection. It'll hurt the network's reputation if they've done that and done something unexpected. But what will happen is the network is people aren't going to just say, oh, well, that's what happened. I'm done with it from a point before this happened and move on. Now, that would be bad for the reputation of the network. No one wants it to happen.
00:48:15.386 - 00:48:24.750, Speaker A: But I think the fact that this is doing something like that isn't forever is a big reason why folks never try or rarely try to mount ionic security attacks.
00:48:26.130 - 00:48:26.590, Speaker D: Yeah.
00:48:26.660 - 00:48:34.500, Speaker E: So, Evan, you mentioned reality, which is that there aren't that many mission critical apps in crypto right now.
00:48:35.430 - 00:48:36.658, Speaker D: I'm going to kind of use a.
00:48:36.664 - 00:49:09.498, Speaker E: Weird segue here, but a few weeks ago, Ryan from bankless, I believe, and correct me if I'm wrong on that, Garrett said something about the crypto's future being like different kind of roll ups in the similar way that there's, like, a new website for everything. And then you replied and you were like, actually, I think atomic composability is something that's quite critical to blockchains. Can you describe to people who are unfamiliar with those concepts why atomic composability is important and why you believe in it?
00:49:09.664 - 00:49:52.694, Speaker A: Yeah, absolutely. I think of the utility of a smart contract program, of a smart contract platform as this really simple equation. It's like the number of valuable assets you have on the platform times the amount of programmability you have in those assets. And I think the atomic composability aspect is a really key part of the programmability because let's say everything is on the same platform. As a developer, I can write code that accesses all the assets, all the building blocks out there. As a user I can have applications that are using any of those and I don't have to be aware of any of the implementation details of where those assets live, or if I have different latencies for interacting for one asset versus another, different security models. That's the vision of Suia, that's the vision of Solana, that was the vision of the original ethereum.
00:49:52.694 - 00:50:25.762, Speaker A: Like put everything valuable in one place, provide a programming model where you can atomically access all of it and don't put any barriers in place. Whereas now I think there's a different view where it's like, okay, actually it's okay to fragment this state, it's okay to spread it across multiple l, two s, it's okay to spread across multiple subchains, however you'd like to call it. And then yes, this creates UX issues. We'll fix it after the fact. We'll hide it under the hood. We'll add user experiences on top of that. We'll launch on just one, we'll launch on just one chain and pull things across, whatever.
00:50:25.762 - 00:50:49.900, Speaker A: I think I'm a technical optimist. I think all these problems can be solved. I'm not going to say that it's impossible, but I think the main thing is, what I would really like is I would like someone. Let's acknowledge that this is a compromise. The ideal thing to do is to put everything in one place and make that scale and make that be decentralized and make that have all the other characteristics we want, rather than cause the fragmentation and try to fix it after the fact. So that's really what I was getting at in that post.
00:50:52.270 - 00:51:05.466, Speaker C: I was just going to add, I was trying to play around on cosmos today to make a trade or two. And my God, it was terrible. They're going to fix it. But I had to reach out to our research chat. I'm like, I think my USDC is just stranded here. But it's really just Kepler. And moving between chains was so confusing.
00:51:05.466 - 00:51:12.990, Speaker C: And I know, like you said, that'll eventually get abstracted. It's just that's going to take some time as you have a new user. Like, I've been in crypto now for a while. It's going to deter everyone away.
00:51:13.060 - 00:51:13.566, Speaker A: And that's really.
00:51:13.588 - 00:51:22.486, Speaker C: You see, Solana right now with meme, coins are absolutely exploding. And that's when it's just so easy. Like, you bridge once or you come straight from a sax into there and that's all you have to do, I.
00:51:22.508 - 00:51:38.140, Speaker E: Would say, just to play defense on the EVM side, because this is just what would happen on Twitter. So let's assume that same. Your model of the world is correct. Do you think a single l one can actually handle that?
00:51:39.550 - 00:52:18.360, Speaker A: We wouldn't be doing things the way we were if we didn't think so. I think a lot of it depends on. Okay, I think it's a bit of a chicken and egg problem, right? I think if an L one can continue to scale and fit everything on the same layer and provide this experience, that's going to really expand the use cases that are possible, that's really going to grow the user base, that's going to make this thing real. And I think if there's a fundamental bottleneck somewhere where, well, you have to start fragmenting state and degrading user experience and increasing latency at some point, then so be it. We'll go down that route. But I think how big and important that can be really depends on how much we can push on the technical limits. And then I think.
00:52:22.810 - 00:52:23.222, Speaker C: Maybe.
00:52:23.276 - 00:52:35.760, Speaker A: I think this is maybe one of your points. It's never a bad thing to have more throughput, to have more scalability at the base layer. And then if you run into a bottleneck there, look, sure, do the fragmentation, do the bridging, figure out what you need to do. But that's basically my view on this.
00:52:38.290 - 00:53:30.138, Speaker E: I personally agree with that, of course. But again, I'm going to play the other side here, just to make it interesting. So let's assume the validators are whatever, adding more cores, making the machines slightly stronger, you've optimized for the software inefficiencies. Some people will say, okay, well, now you made the network inaccessible to run notes for, in a sense, and maybe that's kind of a centralizing factor and maybe they don't care about the word sufficiently decentralized. That's not how they think. How do you think about that? Like the relationship of validator requirements, and maybe to piggyback off of that as well. A very common critique of Solana is the validators that are actually running this hardware not necessarily being profitable in all cases.
00:53:30.138 - 00:53:34.030, Speaker E: How does suite maybe think about that in sustainability long term?
00:53:34.370 - 00:54:06.902, Speaker A: Yeah, I mean, I think there are maybe two different questions. That's just like, yeah, how do you deal with someone saying, I'm not comfortable with these higher hardware requirements, or I don't want there to be too much gatekeeping in running a node? So I think on that, there's some of the salona thesis. More hardware gets cheaper, storage gets cheaper, computers become more capable at the same price. Whether that happens at the same pace as blockchain demand changes, well, that's a different question. But that's something where you've always got a force working in your favor to mediate this. I think the other thing is that computers aren't magic. They're very fast, they're very powerful.
00:54:06.902 - 00:54:52.114, Speaker A: But you can't prop like, if you're going to any business that's doing a sort of consumer grade volume of transactions, consumer grade amount of usage, you need a lot of hardware. There's just no getting around that. That's how things work. And so I think there's a question there of is it more valuable to build something that's going to be able to have that kind of user base or have that consumer grade experience, or is it more valuable to have the lower barrier to eventually for nodes? I think that's something that each community has to sort of decide on its own. I think right now we're lucky because we're in a place where we can have both. But I think maybe in the future you get to the point where it's like, well, it costs 750 a month, maybe 2000 a month is too much, or 10,000 is too much. And it's like we actually want to throttle back.
00:54:52.114 - 00:55:05.006, Speaker A: We don't care that it's going to limit some use cases because we think that's too important. But I wouldn't personally have any priors on that. I think there's a wide open space. Evan, I don't know what you're looking at.
00:55:05.028 - 00:56:00.062, Speaker D: The Ethereum class, right? I mean, the trade off, is it worth it? Yes, anybody can run a no. But the experience for the users as same, say, the consumer kind of application, it's just impossible. And even for something as simple as staking for the newer chains staking for proof of stake network like suite, like Solana's rosary. Painless. For Ethereum, it's not a painless experience, right? And this is create another sort of factor for vehicle, for centralization, right? There's a lot of argument in that space. It's like, is the lido, this kind of services considered centralization, do they count it as a single validator or they count as tens or hundreds of validator? What's the true Nakamoto ratio? Is it truly decentralized? What's more decentralized, right. It's about trade off.
00:56:00.062 - 00:56:42.746, Speaker D: And we believe you're trading off the kind of experience you can build, kind of product experience and build. And that's their terrible trade off. Right. And then one can argue, well, I mean, Ethereum, the EVM community has been going for a number of years. There's very few that we can name that's approachable by consumers. And if that's not the goal we're going towards too, then ultimately you're just basically limiting yourself and what you can possibly the kind of value you can achieve. So I think that's kind of important to consider, not be kind of very maxi about it.
00:56:42.746 - 00:56:49.760, Speaker D: Decentralized just means anybody needs to run their notes, right? I mean, that's just not reality. Nobody does.
00:56:50.690 - 00:57:23.286, Speaker A: And Mur, I think your second question was about this critique in Solana of like, oh, it costs more to run a node than you make from, say, income directly from staking rewards or from transaction fees as a node. So for us, I think that's a question people ask too. But then I think there's a lot of other things to factor that equation. There's Mav, which is income for running a node. Hard to quantify this or see how much is extracted, but that's one way that things can be offset in a lot of cases. And of course, you know this, nodes also run RPC providers. The fact that you run a node, you get access to faster reads.
00:57:23.286 - 00:57:47.966, Speaker A: And so that's their business model. In other cases, there's reasons to run a node because you're a monitor, you have some security reason of doing it. So I think, I don't know if the long term plan is everyone has to break even just on fees. Hopefully that'll be the case. But I think in many cases there are other reasons to run a node that feeds some side business that you have and that just increases your investment in the ecosystem as well. So that's also a good thing. Yeah.
00:57:47.988 - 00:58:10.620, Speaker C: On Mert's question earlier about do you think that one chain could essentially handle everything in the future? I think even if that was the case, similar how we have different countries, people are just going to have different communities and they're going to be on different chains at the end of the day. So there's plenty of room there. I am curious, though, almost every product company, et cetera, needs a beachhead. Is there any industry when you're pitching developers that you're looking maybe to help come to suite first to really kick everything off?
00:58:12.990 - 00:58:56.098, Speaker D: I think gaming is particularly interesting because gaming industry always kind of experiment with their business model. We experiment with tech, right. So naturally they are one of the ones that we're spending a lot of time with because they are willing and they're very eager to try new things. But ultimately, when you think about what blockchains are good for, it's about assets. It's about what you can do with assets, which is core for every kind of commerce product. And commerce touches everything. It's hard to find commerce.
00:58:56.098 - 00:59:18.986, Speaker D: Any kind of consumer product doesn't have a commerce element to it. So that's the ultimate goal. Right? And that's actually a really good match. And commerce can be as simple as payment or can be exchange of assets. Value can be staking. As I said, it's an example of kind of commerce activity. You basically are lending out your asset for yields.
00:59:18.986 - 00:59:40.690, Speaker D: So gaming is really sort of the gateway dropped, so to speak. The first example of kind of consumer application we believe will become. We introduce to the general public what web three is about. But we're definitely not kind of limiting our focus on just gaming.
00:59:40.770 - 00:59:56.746, Speaker E: Let's say I'm a developer and I've already built something on salon and I'm looking to expand or something. How do I pick between suite and aptos? Because it actually does seem to be like some general confusion around. Exactly.
00:59:56.928 - 00:59:57.274, Speaker A: Okay.
00:59:57.312 - 01:00:01.610, Speaker E: I mean, they both use move, right? It's like, is that what are the main differentiators?
01:00:02.270 - 01:00:23.730, Speaker A: Yeah. So I think I would go back to what I was mentioning earlier, where our focus is on how do we let developers reach the broadest possible audience. So if you build on suite, you're going to have ZK login. That means your users don't need to have a wallet installed in order to try out your app. You're going to have sponsored transactions. That means that you can have these different models for monetized transactions. That doesn't require folks to acquire tokens.
01:00:23.730 - 01:01:00.350, Speaker A: If you're someone who's going to be issuing an asset or creating an asset, this is something that a lot of folks are doing. We have standards like kiosk that let you have ironclack royalty enforcement and that work for any objects. They don't restrict the structured nfts you can have. We have closed loop tokens which lets you issue a coin that you can put more control on than a normal coin, like for a loyalty program. Maybe you don't want the coin to be traded, you want to restrict the smart contract so it can be used in and all these sorts of things. So I think that's the high level answer I'd give. I think there's a lot of differences about the developer experience and the way we're using move versus the way that those folks are using move.
01:01:00.350 - 01:01:05.470, Speaker A: But I would focus on the higher order bits or do a much longer podcast.
01:01:06.470 - 01:01:39.066, Speaker D: I may get in trouble for this, right? But it's already happened. Just look at what's happening three after seven months versus other chains after seven months. Right. I think the answer is very clear. Who are capturing the imagination of developers? The numbers speak for themselves. I think this is part of it is building the community, the momentum. And developers want to go to chains that actually have the momentum that everybody's building on suite and they're building new kind of experience.
01:01:39.066 - 01:01:58.034, Speaker D: If you look at just recently, maybe a small thing, maybe it's not for everybody to pay attention. Our repo racing the NFT mint, right? 100,000 mint. None then have to attach a wallet to be able to mint. Anybody with a Gmail account can do this.
01:01:58.072 - 01:01:58.322, Speaker A: Right?
01:01:58.376 - 01:02:21.500, Speaker D: This is open up a new venue and developer come in and this is already happening. So to answer your question, we don't really talk about app versus suite for that reason. We point to the product experience, our partners able to ship. And that's how in my opinion, in a lot of way winning the battle right now.
01:02:21.870 - 01:02:45.762, Speaker C: Yeah, Sam, on that list of features that you had, I know those things exist to some level on Solana and on Ethereum. But is the largest difference that Sui enshrines some of these features which would make it easier on developer. And just on that, how do you feel on this whole enshrined roadmap where you bring more and more features into the protocol which might standardize things and also make it easier for developers versus kind of what Ethereum is doing and just allowing that more of a free market?
01:02:45.816 - 01:03:09.474, Speaker A: We'll see what people mean. I think the entraining is super important for the same reason that any standard is important. Sure, you might have, what, three author things that superficially look similar to what Zkloggin is doing. But the difference there is you got to go trust some centralized service provider, you got to sign up, you got to pay a monthly fee. Whereas on suite like ZK login, it's a native feature. You go use it, you're not paying anybody. It's secure, it's baked in the protocol.
01:03:09.474 - 01:03:41.266, Speaker A: There's no centralized services, there's no third party things at all except for the web, two providers and that just fits in there. Same with something like sponsored transactions versus say the way this works in ETH. Sure there's like a standard for you can have someone else pay for gas, but this is something where it's not supported everywhere. Like each smart contract has to opt in to be able to like oh, I support sponsored, I support this and here's what I do. In the code path where you're paying for the gas yourself versus someone else is paying for it where here it's in the transaction data model. Everyone use it by default. There's not even a distinction where smart contract knows that this was sponsored or not.
01:03:41.266 - 01:03:58.120, Speaker A: It just looks the same. So I think these things do matter. I mean I think obviously there's a boundary and you can't enshrine everything, but I think there are a lot of features that are really critical for product builders that you really do want to give that treatment to because otherwise you'll have a lot of competition for something that should really just be part of the platform.
01:03:58.490 - 01:04:08.570, Speaker C: Yeah, I would just add that you see that in Ethereum that a lot of features that might be either enshrined or built on chain and Solana and something like Sui are pushed off chain just because those gas fees are so high and inefficient.
01:04:08.910 - 01:04:50.394, Speaker D: That as well, or worse, sometimes it's just very difficult, if not impossible to do just for NFT royalty payment. Something is basic in a lot of enforce. You need to have software to enforce the rules of secondary royalties and you can't even do that. I think in the EVM world there's a lot of tries to come up with new standard to adopt this. But guess what, people are still following the old standard because it's easy. Everybody's opting already as opposed to the new standard. You kind of have to get everybody to agree, right.
01:04:50.394 - 01:05:03.358, Speaker D: The social consensus is far harder so you don't actually have the adoption paths. So this becomes one of those things that just sort of feel like the community just kind of keep up.
01:05:03.524 - 01:05:09.678, Speaker E: Last question for me is going to be more philosophical and it's going to.
01:05:09.684 - 01:05:11.726, Speaker D: Be, what do you hope to see.
01:05:11.748 - 01:05:13.958, Speaker E: In the next five years in crypto?
01:05:14.154 - 01:05:14.946, Speaker D: Right.
01:05:15.128 - 01:05:22.914, Speaker E: If there's some levers you could pull to change the trajectory or maybe this velocity of the network, what would those.
01:05:22.952 - 01:06:09.390, Speaker D: Be at a very high level? I hope in five years there are billions of people. They are indirectly benefiting from the technology we're building, blockchains and crypto, whatever you want to call it, web three. It doesn't make sense for the general public to even be aware what blockchain network they're using these current generation products, just not for consumers. So in five years, I hope that's the case. Yes. Those of us work in the industry that we continue to care a lot about this. New models, new kinds of product that actually are built from the ground up, sort of intrinsically only possible on blockchains.
01:06:09.390 - 01:06:53.246, Speaker D: And they're unique, they're exciting. D five is super exciting. And I think there's going to be many these example over the next 510 and whatever number of years, but there's going to be a lot of vast majority of consumers just simply would not care. But I hope we can benefit a very substantial number of them, hopefully in the hundreds of millions, in the billions. And I think five years is infinity. Right. In technology's terms, we're at a point we cannot really kind of fall back on the excuse.
01:06:53.246 - 01:07:32.080, Speaker D: We're still early. And I think this is a time. This next five years, in my opinion, is pivotal. Whether decentralized technology as a whole, not just blockchain, actually makes it, or this becomes another thing that we're not really ready for, that shift back towards decentralization. We shift a few times, right. Internet start out decentralized because convenience and all that and trust issue, we moved to a very centralized period. Now we are in the process of moving back towards the middle.
01:07:32.080 - 01:07:39.182, Speaker D: If we're not successful in the next five years, perhaps it's going to be a long time before that actually happens.
01:07:39.316 - 01:07:59.666, Speaker A: I think for me, my ambitions are really simple. It's like I just want a proper product iteration and experimentation cycle. I want it to be possible for people to have like, okay, this is an idea of how I can incorporate some crypto powered element to my product. I can try it out. If it has value, great, I'm going to keep it. If not, I'll iterate on it and maybe eventually throw it out. I think that's the thing.
01:07:59.666 - 01:08:32.080, Speaker A: The space has really been lacking where it's like to try anything, you have to have so much conviction. Here's this new technology, maybe I don't even really understand it, but I'm going to pivot to being a blockchain game or a tokenized asset or this sort of thing, rather than like, this is just one part of the development stack or one piece of utility that I can bring in and try it if it doesn't. And I think great things get built usually not by someone known, especially with new technology, not someone knowing like this is exactly what this is good for, but by trying 1000 things and seeing what sticks and what doesn't. And so I think if we're not seeing that by the end of the next five years, I won't be very happy. But if we have that, I think there's going to be a lot of interesting.
01:08:32.770 - 01:08:54.502, Speaker D: It's too much focus on capturing value, not enough value created. We really need to see a balance. I mean, absolutely, we're in it to do this. Everybody who build great products and great technology, they should be rewarded, but that should be rewarded because it created a lot of value for the world. That's what we want to see.
01:08:54.556 - 01:09:09.560, Speaker C: Yeah, there's a lot of tribalism in the space that doesn't really need to exist. And that's one reason why we wanted to have you guys on, because you're like pushing the innovation forward. You're doing a lot with move which is new to the crypto ecosystem. We think it's really cool and I think anybody doing that, we want to encourage it. So this is a super fun conversation. And guys, thanks for coming on.
01:09:10.450 - 01:09:13.226, Speaker A: Merton, Garrett, thanks so much. It was our pleasure.
01:09:13.418 - 01:09:14.640, Speaker D: Yeah, thank you.
01:09:15.650 - 01:09:16.110, Speaker A: Definitely.
01:09:16.180 - 01:09:17.118, Speaker C: We'll see you next time.
01:09:17.204 - 01:09:22.250, Speaker B: All right, I've got a little ending note here. First, thank you so much for listening the full episode. If you really liked it, hit subscribe.
01:09:22.330 - 01:09:23.994, Speaker C: But secondly, make sure you sign up for Dash.
01:09:24.042 - 01:09:34.998, Speaker B: This is blockwork's biggest institutional conference happening in London in March. I've included a link in the show notes and also discount code. Get 20% off. Make sure to use Lightspeed 20 when you sign up. All right, I'll see you there. And I'll see you next time on light.
01:09:35.044 - 01:09:35.220, Speaker D: To be.

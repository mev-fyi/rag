00:00:00.090 - 00:00:27.206, Speaker A: Fire dancer is running on eight cores, I think, in, like, 16 gigs of RAM. So the hardware requirements that you see on Salana could be much, much lower. What that tells me is not that we should lower the hardware requirements, is that we should figure out if there's bugs in the labs client that we haven't fixed yet and double the capacity of the network if we can quadruple the compute units per block right now, and the network is fine. It's like free growth. Like, why wouldn't we do it?
00:00:27.228 - 00:00:47.746, Speaker B: This episode is brought to you by access protocol. Access protocol is the best way to get access to premium crypto content without the ads, without the annoying subscriptions that are impossible to cancel. It's crypto native. It's here today. Go check them out. What's up, everybody? Welcome to another episode of Lightspeed. Today we are joined by Anatoly.
00:00:47.746 - 00:00:50.334, Speaker B: He is back on the pod. Anatoli, welcome to the show.
00:00:50.492 - 00:00:51.870, Speaker A: Thanks for having me.
00:00:52.020 - 00:01:16.280, Speaker B: Yeah, always pumped to have you on. I think we'd have you on every week. I know we have a lot to talk about. Mert actually messaged me and said he's going to hog this podcast, so if I don't say anything for the rest of the show, please understand. But, Anatoly, I do have one question. I want to get in here before we go any further. And that's the saga two or chapter two? And I want to talk about that because it was an announcement that came out last week, but it wasn't long ago, probably just four weeks ago, that you were on another podcast talking about how the saga wasn't really selling that well.
00:01:16.280 - 00:01:32.474, Speaker B: You're like, you know, it's been a great learning experience, but I don't know where this is going to go next. It wasn't selling like hotcakes. The next thing you know, Salana narrative kind of takes off. You have these airdrops, you have bonk, absolutely explode. And now you've sold out 20,000 units. I just want to know, what was that experience like? What's been the most exciting for you?
00:01:32.512 - 00:02:27.222, Speaker A: It was weird. So the thesis is the same. We kind of have this belief that crypto is like new user, new kind of user generated content. It's digital content that you can transfer and own. So it kind of inherits more rights from the creator because you can force a limited supply and transfer rights and stuff like that into the contracts and make it kind of more interesting for creators. That doesn't really work with the App Stores because their models are built around this idea that the developer owns all the content and the developer is price insensitive to how much the App Store can kind of levy them. So like a user that's buying a movie through iTunes or whatever, they don't care if Apple gets 30% of that revenue.
00:02:27.222 - 00:03:34.842, Speaker A: Amazon doesn't really. I mean, they care that they don't get that revenue, but it doesn't increase the costs to them to add that extra user, right? There's no additional cost to enable users on iOS versus Android. It's not like you're shipping physical hardware and all of a sudden Apple's tax puts you below profitability for the cost of the physical device, right? For the Apple or whatever you grew, you can't tax physical objects the same way, but with user generated content. If I own this monkey MBS skeleton king and I list it for $100,000 in magic Eden, magic Eden doesn't own it. So they can't eat the 30% cost and give it to Apple, right? They have to list it for 30% more in their iOS app if they have NFT sales enabled and the user is going to be like, what the f? This thing is worth 100K, why am I paying 130 in iOS? This is why there is no mobile native NFT marketplace. It just seems like, why don't we have those, right? That's why. So there's this kind of weird problem.
00:03:34.842 - 00:04:08.540, Speaker A: And obviously these kind of weird problems usually are an opportunity. I don't know how big it is, I don't know what's the likelihood of us succeeding. But basically developers that hate that tax need some outlet and there's an opportunity for us to get all the NFT and meme people into the same distribution channel. And those are the spendiest Internet users in the world. And mobile gaming is like 100 billion a year industry. Apple takes 30% of it. That's crazy, right? For nothing.
00:04:08.540 - 00:04:46.680, Speaker A: If there is a distribution channel with the exact same users that are generating most of your revenues. Because mobile gaming is just like also very power law heavy revenue stream. 5% of the users generate like 90% of the revenue. If all of a sudden those users are also NFT traders, you can deploy games to them in a mobile environment, get all the same features, get all that Ux, get inapp purchases, all of that stuff. But without the 30% tax, that could be that tipping point. But it's hard to get there. We need to first get a big enough set of people all in the same platform, all actively doing stuff.
00:04:46.680 - 00:05:10.942, Speaker A: And Solana Mobile is not like a content creator. We don't know how to make games. We don't know how to make even NFDs. We tried to make nfts. Those were kind of mediocre, but we know how to make hardware, we know how to make systems. So if we build this phone and we get ecosystem devs to go build experiences, airdrops, whatever, that could get the flywheel going. We'll see, though.
00:05:10.942 - 00:05:43.020, Speaker A: There's like a lot of ways it could fail. But, yeah, it was a weird moment for it to be kind of like in cockroach mode, like basically waiting and seeing to overselling out all our remaining inventory. And people wrote, like, bots that were submitting orders. This is like an NFT mint. They hacked Shopify and would submit orders no matter what price we set them to. We set the price to like $100,000 a phone, and they would still submit them. It's crazy.
00:05:43.020 - 00:06:13.858, Speaker A: We had to cancel all those and stuff. There was no way to stop people from buying it after we ran out because of the way that these. My God, man, the inventory systems of the world are like the worst databases ever built. So, yeah, it was a really strange experience, and that validated the theory a little bit. You're like, okay, there was an airdrop. It was built by an ecosystem dev. There was like a unique experience with the phone.
00:06:13.858 - 00:06:50.334, Speaker A: People are getting it. Is this scalable? So then we did the preorder, and that sold like 30,000 in 30 hours. And that's pretty big even for a CES. Kind of like rip that rabbit thing that was super hot in CES, sold 10,000 in one day. So you get signal, but it's still not clear whether we can build an ecosystem of users that are going to be mobile consumers. The tipping point for me is going to be when Epic ships a game for the saga DAP store. Even if it's not a crypto game.
00:06:50.334 - 00:07:02.740, Speaker A: I don't even care if it has any crypto features or not. If Epic recognizes that this is a distribution channel for them and they ship a game to it, then I know that we got there.
00:07:05.210 - 00:07:13.720, Speaker C: Because obviously you guys launched a saga before this. What are some tactics that you'll do differently this time? What have you learned? What's going to be different?
00:07:15.050 - 00:07:46.386, Speaker A: Oh, man. Like the price point. I think a lot of people balked at the $1,000 device price point, so we're really trying to get it down to 450. By the way, these are not profitable price points. Hardware has, like, initialization costs. You have to do the R and D and the certification in a bunch of different markets. And you have to have a minimum order, and those become profitable at like 250,000 plus.
00:07:46.386 - 00:08:13.254, Speaker A: If you can sell that many units, you can eke out a profit. But the margins are, like, razor thin. Like, it sucks. And these big companies like Google, Samsung, Apple, they have all that stuff optimized away, right, because of scale. So the initialization costs for them are pretty low. Plus they can literally take their App Store fees and subsidize the device, right? Like, if they wanted. So it's hard for us to compete.
00:08:13.254 - 00:09:11.262, Speaker A: So we have to build a device basically for cost and try to build it as fast as we can so we can capture a moment and get it out and then get ecosystem devs to be excited, ship stuff, and hopefully something catches fire. And if it does, and people are like, why are these sold out? I want another device. That means then we maybe go do round three, right? But there's a bunch of ways all this stuff can fail. I don't know why I'm doing this, but it's just like, the fee is just too big. 20, 30% is insane, right? We're talking about crypto disrupting banks, and they charge bips. They charge hundreds of a percent, right? And that is a massive, total addressable market, right? Like, finance is like 20 trillion a year, but it's pretty efficient. Apple and Google church, 20% to 30%.
00:09:11.262 - 00:09:41.560, Speaker A: It's insane on digital content. So if crypto is a disruptor of digital value transfer, this seems like a huge opportunity. And then if that could be a driver to build a phone company, that's massive, right? Like, if somehow we manage to get to million units sold or whatever per year, that's a home run. That's a really big technology company and can drive massive change across the industry and do a bunch of stuff.
00:09:42.250 - 00:09:49.206, Speaker C: Yeah, that's very well put. I found it funny when people were commenting about the cash grab aspects, and I was like, I don't think you.
00:09:49.228 - 00:09:50.550, Speaker B: Guys have ever built hardware.
00:09:53.530 - 00:09:59.902, Speaker A: Anyone that could think they could make this a profitable enterprise, I'll hire you right away.
00:10:00.076 - 00:10:23.070, Speaker B: Quick break to tell you about access protocol, the easiest and best way to stay up to date on what's happening in crypto by following your favorite publishers. And you can do all of it without a subscription, without having to worry about ads. And we all know subscriptions. How many do you have? 1020. Can you cancel it? It's all a mess. Well, access protocol solves this, and they do it in a crypto native way. They have over 60 publishers that include Coin Gecko, the block, crypto, slate, and a whole long list of independent creators.
00:10:23.070 - 00:10:54.702, Speaker B: So how it works is you find your favorite publishers and you stake the ACS token, that's the access token. And once you stake, you have access to all that creator's content without the hassle of ads or subscriptions that you can't cancel. You don't know how many you have. Access protocol already has over 225,000 users that are finding new creators that are reading content and even receiving NFTs from these creators. Because one of the cool things with access protocol is that these publishers, they can know who their subscribers are. They can make it where okay, maybe we'll do an in person event, or maybe we'll do an NFT drop and we'll do it only to our most loyal stakers, aka readers. Really tells 24 they're even releasing V two.
00:10:54.702 - 00:11:19.462, Speaker B: It's crypto native, it's from Salana, and it's an awesome product. But a link in the show notes to the hub. It's the easiest way to get started, so go check them out today. Quick break to tell you about an upcoming event I promise you don't want to miss. It's Blockwork's biggest and best institutional conference called Das London. It's a two day event happening in London this March where we're going to have over 700 institutions, 130 speakers, and a couple of thousand of us all under one roof. You crypto is in a position for the first time to actually onboard these institutions, and they're showing up.
00:11:19.462 - 00:11:42.110, Speaker B: We have companies from BlackRock to visa launching real products in the space. We have the real world asset narrative taking off. We have things like payments that have been exponentially growing, and then we have things like deepen happening in the Solana ecosystem. There's a ton of capital right now in this institutional space that's going to be coming on chain. It's going to completely change the industry. Whether you are an institution or you're a retail user, or you just want to learn more about what's going on in the space, this conference is for you. You're going to be to meet some of the best and smartest people in the space.
00:11:42.110 - 00:11:58.590, Speaker B: The speaker lineup is absolutely incredible, and you'll get to hang out with me. But the best part is you actually get 10% off your ticket if you use light speed. Ten, when checking out, I'll put a link in the show notes. I recommend buying this today because one, you'll forget about it. Two, these ticket prices go up every single month. So anyways, I hope to see you there. Now let's get back to the show.
00:11:58.660 - 00:12:24.234, Speaker C: Okay, so that's the phone. Now, what I want to talk about is a year and a half or two years ago, we would talk a lot about one of the up coming changes to the network to make it better. I think now it's in a much better place. During heavy, heavy spam or congestion events, the chain holds up, obviously can be better. And now that's what we're working on. So I guess first I want to start with assessing the current state of the chain. Right.
00:12:24.234 - 00:12:50.340, Speaker C: So currently there's some implementation details not particularly robust, let's say, on the scheduler. There's some jitter on the network. Some sends don't get finalized because maybe their public connections are not staked. There's a lot of random things like that. So can you maybe just what's on your mind about the current state of the network and what are some of the biggest problems present right now?
00:12:51.350 - 00:13:58.806, Speaker A: Yeah, there's a bunch of stuff that happens in that lifetime of a transaction before it hits a block producer. And the way that this is solved in other networks is using a mempool. And generally what a mempool is, is that you submit your transactions over gossip to a bunch of nodes, and they simulate them and evaluate them for value, like, how much is this thing worth? And then when I ask other nodes, hey, give me your most valuable transactions, I get kind of the top of the heap, and it kind of spreads around. It's very robust, very censorship resistant, because if you can get a high paying transaction to one node that has like six or seven peers, all of a sudden it gets to the top of the heap, across the entire network. And the next block producer, no matter who they are, even if they're randomly selected through proof of work, sees it and includes them in the block. And that's a very robust kind of censorship resistant guarantee, but it's very slow. And that slowness means that it takes a while for transactions to propagate.
00:13:58.806 - 00:14:48.438, Speaker A: And even if you increase TPS and block times and all this stuff, that extra lag is really felt by the users. And it also creates an environment where you're pricing access to the block in a one dimensional way to where if you have a liquidation and some other event all happening at the same time, they all want to get to the top of the block because they want to be in the next block. So as this information is propagating, I want to be first. Whoever's asking for. Give me your best transactions. I want this liquidation. I want to make sure that they include me, right? And that forces that competition for the top of the heap, and that creates kind of a single priority queue for everything and really causes gas fees to spike and stuff like that.
00:14:48.438 - 00:15:43.110, Speaker A: So we tried to innovate there. And the way that Solana works is that you can actually submit transactions directly to the leader, and if not the leader to a stake node, or you can partner with a stake node or something like that, then the leader gets kind of a funnel from the world. And this funnel is pretty big, like during an NFT mint, people will submit like a million packets per second because they are really trying to be first. And the fact that people try to submit more packets per second to be first in a block, that's the bug, if you have to understand. That's the inefficiency of our design. And this is kind of what we're fighting. The memple folks are fighting speed and this gas war for being top of the queue.
00:15:43.110 - 00:16:38.780, Speaker A: And we have a different problem. There's no perfect solution, otherwise it'd be out already, right? So you kind of pick your battles. So because we really care about latency and we have this multidimensionality to how we want fees to be priced, we have this different system. So with Qos, the leader actually caps the amount of traffic they receive. And I think right now it's at about 100,000 packets per second, which seems crazy, right? Like, why do you need to receive 100,000 transactions per second? If you only see, like, I'm looking at salon FM right now, it's like 800 actual user transactions land. Why do you need to see 100,000? Well, because we want to avoid this kind of top of the queue problem. So the way that Salana runtime works is if you include transactions in a block, they all take a write lock to an account.
00:16:38.780 - 00:17:20.586, Speaker A: And it's just like in a database, it's a write lock on memory, and you can only have so much compute. That's right, locking a specific location, because that limits single threaded speed. So you can only have a block last 400 milliseconds. So we can roughly estimate how much compute can lock any particular account. So when that happens, the right lock that gets saturated, you can no longer add any more transactions to the block, but you can include others. So why you need to see 100,000 transactions at the same time is because you're trying to grab as many buckets of high priority transactions as you can. So not just one.
00:17:20.586 - 00:18:20.486, Speaker A: So every stake node that is receiving public transactions is sorting them by these account buckets, and then is forwarding the top transactions from every bucket to the leader. And then the leader is receiving this kind of mixture of a bunch of different stuff from every stake node and then also merging it into buckets. So that kind of like merge sort, to me, it reminds me of merge sort. If you ever remember that algorithm in computer science, you're doing this merge sort operation at the leader. So you need to see a very wide kind of snapshot of what everyone believes are the highest paying accounts for different resources on the network. So that's how it works. And the challenge there is that if you have to process 100,000 transactions, you have to check for duplicates, you got to check that they're valid, you got to do signature verification, you got to check that they can pay the fee.
00:18:20.486 - 00:19:16.846, Speaker A: And all this kind of creates delays. So even if you have, like a super highly prioritized transaction, you're willing to pay to be first in the block. For the scheduler to figure out that you should be first in the block, that transaction has to go to the leader through this pipeline, then to the scheduler, then to the top of the queue. And if that delay is so long that the block is over, you just don't get prioritized. You get put in the next block. And this is why you see, even without some of the idiosynchronousies from the way that the scheduler works, because it's multithreaded, this is why you see kind of this weird behavior where I'm paying a high priority fee, but I see other transactions that have paid a lower fee ahead of me in the block or maybe in the previous block. So making that pipeline as tight and as fast as possible is a lot of implementation work.
00:19:16.846 - 00:20:06.782, Speaker A: And I think what needs to happen, and this is kind of like the big discussion in the SImdi forums, is that you actually need to put some economic back pressure on saturated accounts. And this is like, you can think of it as 1559 but for write locks. So not for a block, but for a single account that's receiving a whole pile of transactions. If that thing is constantly being saturated, start increasing the write lock fee, and at some point, the fee is going to be so high that users are just not willing to pay that fee to sign it. And that means that you now have fewer transactions in that pipeline. When you're dealing with 10,000 packets per second, it's much faster to sort and prioritize them than when you're dealing with 100,000 packets per second. So prioritization is going to be more effective, stuff like that.
00:20:06.836 - 00:20:51.610, Speaker C: So that was quite a bit. If I were to just sum this up for maybe non technical people. Basically, on other blockchains there's a mempool, which means there's block building is kind of discreet, whereas on Solana it's kind of continuous in a sense. And that causes problems because people have direct access to the leader and you need to figure out how to control that access, but in an economical way, such that they still get maximize some sort of economic value. And they don't just get spammed, which is what used to happen and cause some problems back in the day. Okay, so I have like three questions as follow ups here. First, what do you think about how Jeeto approaches this? Because they obviously make this process discreet.
00:20:51.610 - 00:20:57.040, Speaker C: They've seen a lot of success with it based on the numbers I've seen. So what are your high level thoughts on that?
00:20:57.570 - 00:21:48.560, Speaker A: Yeah, it's funny. They built a mempool on a system that was built without, and it'd be cool for it to generalize to user transactions, and I hope they try to do that too. And if we can see an improvement there, that'd be awesome. But they're particularly optimized for creating bundles and searchers for Defi. I'm a huge fan of what they're doing, and I think it's really important that they continue working on the MEV problem because I think kind of like both the feature and the bug of all of these systems is MeV. I think it's like, probably the most important feature is that they can capture value from MEV, and probably the most glaring bug that's possible. So we'll see how it all plays out.
00:21:48.560 - 00:22:38.990, Speaker A: The question I have is that can it scale to a large enough throughput to where we can handle it at high TPS? If it only works for searchers to submit infrequent bundles to snipe those things, and you're talking like tens of bundles per second, but not 50,000 TPs, then it will serve its purpose, right? Because I think the traffic from that activity is going to be pretty low, but super high value. But we need a system for payments, for gaming, for everything else. So probably the hybrid approach is the way to go. I think what's funny is that flashbots on Ethereum looks more like Gulfstream, which is Solana's transaction forwarding system. And yeah, Jito Solana looks more like the mempool.
00:22:41.250 - 00:23:03.526, Speaker C: Okay. And then my second question is with regards to the scheduler. There are a few changes and we basically never cover this as an ecosystem in Salana. But I want to talk quickly about. So 1.17 is basically, I think most people are, at least half are running it now, and then 1.18 is coming out.
00:23:03.526 - 00:23:07.800, Speaker C: Can you briefly talk about the changes in 17 and 18 that people should care about?
00:23:08.350 - 00:24:27.460, Speaker A: Yeah. So the big pain in our side with the scheduler is that block producers right now, they execute the transactions as well as schedule them. So kind of trying to do this optimization where if I'm a block producer and I schedule the block, I also execute it so I can vote on it right away all in one machine. The problem with that is that you want multithreaded execution during block build for that later stage, but scheduling, you actually really want single thread to go find all the hyper transactions and pack them exactly in that order. But we have four threads that do this execution because of this kind of original coupling. So until that we have what we were calling bankless leaders, until we have full separation of block producers from actual execution, you're going to have this weird thing where you have four threads trying to pack the blocks, and that means that the order is going to have some jitters simply because of the multithreaded nature of execution there. So Andrew's done a bunch of work to reduce that and make that jitter a lot less kind of.
00:24:27.460 - 00:24:32.900, Speaker A: I guess the worst case is to be a lot less bad.
00:24:34.390 - 00:24:41.160, Speaker B: One quick follow up on that, bankless leaders, is that the same thing as PBS proposer builder separation or what's the difference there?
00:24:43.930 - 00:25:15.330, Speaker A: I don't know enough about the latest design in PBS, I think probably not. I think a lot of what the PBS stuff involves with is the economics around being selected as a block producer, like posting a burn or something like that. I think this is just Solana moving towards a more asynchronous model for execution, really separating the work of executing things from ordering and consensus and finality.
00:25:17.590 - 00:25:42.570, Speaker C: And so my third question is, so you just mentioned the economic back pressure stuff, which is you guys with Tao wrote a SimDi on it. It was well received by some people, maybe not so well received by other people. So I'm curious, what do you think of the feedback so far? And I'm also curious after that, what you think about dynamic base fees?
00:25:43.710 - 00:26:16.258, Speaker A: So that's the same thing. The write lock fees are basically dynamic base fees. Why do you make them dynamic on? And the right answer is load, right? So if the load is high, you increase the fee. If the load is low, you decrease them. And this is an attempt to do that, just not at block level. And why it's important to try the right lock fees first is because if you start increasing global fees, that'll work. Eventually people will stop signing transactions and load will drop.
00:26:16.258 - 00:27:19.334, Speaker A: But then you're indiscriminately punishing all the users. Write lock fees are very targeted to the saturated use case, and that one I think would work better without creating high fees for all the users. I think you should see the base fee go up effectively in isolation for a specific set of accounts that are like the source of 99% of the load across all the stages. The reason why you need this economic back pressure, and I used to be in the camp where, no, we can just optimize the software to where you don't need it, is because the hardware that the network is deployed on is just really different. It's heterogeneous. There's a bunch of different operators, different systems. AWS has the worst hardware sometimes, and a lot of people need to use the network with different needs and requirements.
00:27:19.334 - 00:28:09.506, Speaker A: Like coinbase uses AWs and AWs sucks. But it would be really shitty if Solana required such high end hardware that was so unique that Coinbase could not run it in AWS. That would be, I think, bad for the network if the number of places where salon validators could be deployed was very small. Not even if the cost is high. But it's just like operationally, people expect that I have code, I can run it on AWS or Azure GCE, and they have different hardware constraints. Even if it's absurdly like ten times more expensive than terra switch or latitude, you still need to support those deployments. So you have a wide range of hardware and a block like compute.
00:28:09.506 - 00:29:02.380, Speaker A: Limits are a very crude estimate because they measure bandwidth limits and memory and cache misses and a whole bunch of stuff. And we try to all stuff it into this one single number. If we didn't, it'd just be really tough to put any limits on execution at all, because again, all of these systems are going to have different benchmarks, and sometimes pretty wide ranging benchmarks. So if you over provision them, you say, okay, we limit everything to a single core like Ethereum. You have a very slow system that can run reliably across a wide range of hardware, but you basically have limited the amount of resources it can use to such a small amount that it's guaranteed to be available everywhere. That sucks. Right.
00:29:02.380 - 00:29:40.070, Speaker A: And even they don't want to do that. So they have economic back pressure. So that's kind of like the goal of it is that we want to be able to set the limits for throughput pretty high to where the network can sustainably run it and effectively have burst capacity. But if somebody's constantly using it at the red line, you got to start forcing them to back off to kind of the baseline. And that, to me, is kind of like the right approach. Right. You have slack capacity to where if you have a burst of activity for five minutes, the price isn't going to change much.
00:29:40.070 - 00:29:55.130, Speaker A: But if you are, like, for hours on end, it's running at the limit, the price should start increasing to the point where people back off. Right. That's kind of like how these systems are best designed, in my opinion.
00:29:56.030 - 00:30:19.810, Speaker C: On a kind of a related note, I have two follow ups to that. So, Jeff from jump today, actually, when I said, what should I ask? Totally, he said something related, which is what steps are being taken towards slashing poorly performing validators? Are there in progress features or Simdis to address this? I'm tired of potato validator operators causing stress of the network without penalties. Chaps, when slashing.
00:30:20.550 - 00:30:41.946, Speaker A: Well, slashing for performance is really hard. That basically needs to be the people that are staking with those validators need to move their stake. They need to care that they're, like, hurting the network. The cost of moving stake is very negligible. So I think what we need to do is identify the validators that are bad. Get them to move. Get the stake to move.
00:30:41.946 - 00:30:52.380, Speaker A: I think a lot of those are unfortunately, like, foundation validators from the delegation program, and they're already taking steps to start kicking the potatoes off.
00:30:56.350 - 00:30:57.606, Speaker C: Gary, did you have some?
00:30:57.728 - 00:31:17.990, Speaker B: Yeah, I've got a question that we've touched on. But, Anatolia, I know one of the main goals here is you don't want to price out certain use cases. Right? Like, you don't want DeFi to price out payments. Because as a developer, I'm thinking, like, where to launch, go to Solana. But then you're like, okay, well, if all this activity goes there, maybe it's going to push up these base fees where my payments don't actually make sense there. So can you talk about, like, there's local fee?
00:31:20.010 - 00:32:10.310, Speaker A: So. So because of how Solana runtime works, developers go through this painful process of figuring out when they create a transaction which accounts are writable and which are readable. And that actually allows us to create localized fee markets because there's a limit to how many writes you can do per account. When that limit is saturated, you go to the next account. So prioritization should pick the highest priority paying transactions to first into that writable account. So if you have a use case that doesn't touch any of the hot defi markets, you don't care how hot those markets get, because the fees there are not going to touch your game or your payments use case unless the entire block is saturated. And if the block is saturated, this is when we need the validators to basically double the capacity of the number of parallel things they can do.
00:32:10.310 - 00:33:12.010, Speaker A: Like the number of hotspots that the network can handle should double every two years. Because Moore's law is on our side and this is great, we want as many hotspots to all concurrently occur at salon. So the question is, with the exponential write lock fees, what it's trying to address are the externalities outside of just priority fee pricing that are occurring from these hotspots. And this is because we don't have a mem pool, because we want this really fast environment for transactions to submit. Folks that are spamming the hot accounts are saturating those other pipelines, they're submitting 90,000 transactions, 99% of which get dropped because that account gets saturated. So we need to increase the fee to access that account to the point where they don't sign and submit. And all of a sudden that externality goes away, right? You're not negatively impacting a game that's also trying to submit a transaction into the scheduler.
00:33:12.010 - 00:33:46.610, Speaker A: Amongst with like, that's one problem. The other problem is just having replay constantly be hit with highly saturated accounts kind of creates this sequential dependency of single threaded execution, which sucks. So increasing the fees there will break it up too. So stuff like that I think is like all important fixes that we can do in the runtime to really make the system more robust to burst activity and wide range of activity without creating negative externalities that hurt other use cases.
00:33:47.830 - 00:33:57.640, Speaker C: Okay, I want to notch out like three or four more very high level and completely unrelated topics. So get ready. First I want to start with.
00:34:00.590 - 00:34:00.906, Speaker A: Mean.
00:34:00.928 - 00:34:21.518, Speaker C: I get reply guide about this all the time. Hey, how come Solano doesn't have this formal document outlining how consensus works in all cases mathematically? And then basically I think your response is something like, well, does Linux have this? Or something along those lines? So can you maybe think about, or talk about how you think about this and how we should think about it?
00:34:21.684 - 00:35:02.140, Speaker A: I mean, it'd be awesome if anyone's like a researcher at a university and wants to do this kind of research. It's probably the best place to do it because a bunch of engineers are going to be the ones that do stuff that's unexpected for academics anyways. So, yeah, go do research in Solana, consensus. Find a bug and submit it, and we'll fix it. Basically. I think culturally, the engineering team from Salana was like, 15 to 20 years out of college, so we just don't even know how to write those papers anymore. We know how to build those systems, but it's just not.
00:35:02.140 - 00:35:55.486, Speaker A: In my career, I've had one event where I had to rip out a formally verified kernel and put in, like, a custom system because of performance. It's just not something that often comes up in commercial implementations. Is this thing formally verified? No. CTO at a big tech company has really cared about that. So it's a thing that is important for a group of developers that are trying to build something from scratch, and they need to understand the parameters and kind of get going, but it starts losing its effectiveness once you're live, right, and you know the parameters of the system, you know how it responds to actual events and stuff. So there's just differences there. And from my perspective, I'd be happy for that to be for a team of researchers to go formally verify that.
00:35:55.486 - 00:36:29.962, Speaker A: I think the foundation is looking for folks to give grants to do that, but all the code is open source. You can go validate it. You can run attack vectors, we stress test it. There's a bounty for liveness, there's a bounty for safety. We go through every permutation of attack vectors we can think of, and I don't even know if other protocols do this, but at the end of the day, the white paper isn't going to save you. It's the work that you do to validate your assumptions and make sure that nothing goes wrong. That's what's going to save you.
00:36:29.962 - 00:36:40.540, Speaker A: We do that to the health, and if that's something that you want to work on, the folks at labs are hiring for that as well.
00:36:41.710 - 00:37:02.660, Speaker C: I want to now move to clients. And obviously, before we touch on fire dancer, I want to ask your thoughts on the recent events on Ethereum and kind of how there was a bug in one of the clients and how that sparked some discussions around inactivity leaks and liveness over safety, et cetera, et cetera. So what are your high level thoughts there?
00:37:04.070 - 00:37:51.550, Speaker A: Yeah, the hardest part to kind of validate, I would say, is liveness, not safety. So you can think of it from the perspective that these systems are designed with the assumption that the network actually goes rogue. Like circle. When they deploy a node on Solana, they have dollars that will automatically wire out if you send them like a transaction, right? So they have literal money on the line, right? And they don't trust the rest of the network. They don't care what the economic security of the network is, because they have no clue if that's real or not, it's just a number in a computer. They have no idea who controls these other systems, so they don't trust. The only thing that they trust is their own node.
00:37:51.550 - 00:39:04.186, Speaker A: When it processes an event, they have their own ledger, and that's a source of truth. And if that source of truth becomes inconsistent with the rest of the network, they halt, they don't process any more transactions. Everything basically stops. So from a perspective of an operator like circle, they internally do the work with a single node to have strong safety guarantees for the state that they care about. Does that make sense? And usually that's what it means to run a full node. So everyone that's participating in the network, you only trust your own full node, you assume the rest of the network is corrupt and it keeps going by a miracle, right? Like if I don't trust anyone else, how does it keep making blocks? Well, what consensus provides are like liveness guarantees that if there are forks or partitions and stuff like that, that all the nodes that are participating in the protocol can resolve those and make the same choice consistently as they receive information out of order and messages out of order, and continue and move forward. And while they're doing that, they're not accepting any new confirmations, they're just kind of accepting information.
00:39:04.186 - 00:39:55.862, Speaker A: And then they see that the rest of the network also said they're moving forward, and then they move forward. And this is kind of that process how it works. And if you have bugs in a single client, you could get stuck, messages could get dropped that shouldn't been dropped. They could arrive out of order and put the state machine in a weird spot. And if you have, in theory, four clients, the probability of all of them having the same bug is pretty low. And if they're evenly distributed by stake, each one is 25%, and one of the clients gets stuck, the other 75 continue going, because typically the threshold for moving forward is 66% or two thirds. Right? So the network is safe from the soundness of I own my own node and I can run it and I can guarantee the state that it creates and it's live from the soundness.
00:39:55.862 - 00:40:43.466, Speaker A: Like if I communicate with all these other machines, I can move forward. And that moving forward consistently is what creates that liveness. So if you have multiple clients, you have improvements there. But there's also risk simply because four teams, spec, right? A single spec, four teams is going to be four different interpretations. So it's very likely that there are bugs, that are inconsistencies that could be triggered that causes one of the clients to lose. In Ethereum, unfortunately, I think people trust guests so much and there's a penalty for being, having a client that's not working that they don't want to evenly distribute the stakes. You end up with a situation where you have like 85% of the stake, right.
00:40:43.466 - 00:41:08.690, Speaker A: Or something like that, is using a single client. So you lose that benefit of if there's like an actual implementation bug that impacts state that the network would halt. So this is kind of like the trade offs that you make. I think with livelist leaks and things like that, I don't think Solana would ever have a liveness leak. Yeah, inactivity.
00:41:11.830 - 00:41:29.580, Speaker C: So right before I get to fire, to answer, maybe on kind of a related topic, although not directly, are the concept of vote transactions. Right. And a very common misconception is, okay, Solana has vote transactions to artificially inflate TPS. Can you just give me a sound bite and tackle that?
00:41:31.230 - 00:42:22.682, Speaker A: Solana's runtime is so fast that it can handle consensus messages as transactions. It's the opposite. The whole point, there was this huge belief that you could not scale a layer one with traditional all to all BFT implementation beyond like 100 nodes. Like tendermint was the limit. And that statement did not make any sense, because if you can scale the runtime to have 50,000 TPS, no one questioned that. Why can't some of those transactions be votes for 25,000 systems, right. Obviously, it should have been just a very simple.
00:42:22.682 - 00:43:24.800, Speaker A: It's like a contradiction to say that you can't scale the network to beyond 100 nodes, but you can scale the TPS to 50,000 nodes, unless you're optimizing the wrong thing. Right? So from my point of view, the fact that we can quickly replicate very large number of throughput is not limited by node count. That's kind of what salon approved. So it doesn't matter how big the network gets then. If every node votes, it's just a transaction. Who cares? Who cares if they're submitting one transaction per block? Because the whole point of scaling to tens of thousands or hundreds of thousands of TPS, that nodes voting is an insignificant load in the network. So this is kind of like, it's a dumb thing to argue about because the systems that can't do this are the poorly designed ones that somehow scale TPS without the ability to actually utilize it for consensus or for anything else.
00:43:25.730 - 00:43:36.606, Speaker C: Yeah, and the node count thing is interesting because some people will look at these newer l ones and be like, oh, they're like as fast as Salana. And it's like, okay, well, they have like 39 validators.
00:43:36.718 - 00:43:49.438, Speaker A: Okay. Yeah. So run salona with 39 nodes like pith does, and you can see it's much, much faster. You can set block times to 200 milliseconds in that environment. And so is it fair to say.
00:43:49.464 - 00:43:53.686, Speaker B: As well that all these new chains are going to have these scheduler issues that salon is going through?
00:43:53.868 - 00:44:15.950, Speaker A: They just don't have the activity. Well, it depends if they try to manage multiple resource pricing. So if you actually want localized fee markets, you're going to run into this because it's like a knapsack problem. It's like a multidimensional packing problem. There's no good solution for them. There's only heuristics.
00:44:17.090 - 00:44:41.110, Speaker C: Yeah. And then. So on the topic of node count, actually, let's talk about your endgame block. I don't want to say blog post, Google Doc, and it says the ideal end state is something like 200 milliseconds with over 10,000 nodes. 10,000 is kind of arbitrary, I think you said you want some midwestern bank manager to just feel comfortable arbitrarily. What is that end game about? Why do you want that?
00:44:41.260 - 00:45:14.786, Speaker A: Well, bitcoin has like about 12,000 nodes, and it hit like multi trillion valuation. So to me that shows that that node count is sufficient to handle very large value, very large amount of value. Right. I don't think bitcoin would have hit that valuation if it had like 39 nodes. Yeah. Not as a permissionless cryptocurrency, maybe as like a bank that is running in permission mode or something like that. That could be interesting.
00:45:14.786 - 00:45:21.940, Speaker A: But, yeah, as an open permissionless cryptocurrency, I think it has to kind of get over that 10,000 number.
00:45:26.070 - 00:45:35.634, Speaker C: Can you talk a bit more about that end game? You imagine this world with 200 millisecond block times. Obviously, maybe the qualitative statement that you go with is syncing information global.
00:45:35.682 - 00:46:10.740, Speaker A: Yeah. The big pain in the butt for us is that these are different systems. We don't own them. Some are in AWS some are in bare metal servers and terra switch, and they have variable execution time. So shrinking the block time from 400 milliseconds to like 120 would be my goal is hard because the execution has to happen at the same time as block propagation. So all this stuff is happening right now all synchronously. As the block is propagated, it's executed, and nodes vote as fast as possible.
00:46:10.740 - 00:46:58.498, Speaker A: And the variability in execution time prevents us from shrinking block times. So what I want is asynchronous execution. Like really, the quorum doesn't even need to know anything about the state. The only thing that it cares about is who is in the quorum and what's the next quorum. And that could be like, anybody can post that over gossip and say, look, everyone, all the full notes did all the execution of all the stakeway changes and all the LSDs and whatever, and this is the next quorum. And if nobody challenges that for an epoch, then that's what happens. You don't actually need the consensus nodes or the block producers to execute any other state.
00:46:58.498 - 00:47:42.510, Speaker A: And it's kind of a weird thing to think about. It means that the network is kind of running blind, but circle is not. They have a full node, they're fully executing all the transactions, and they observe that the quorum is synchronized with their full node, and if it ever becomes desynchronized, they halt. Right? Their money is safe in the bank, their state is safe because they run a full node. They don't care if the rest of the network is corrupted. This is kind of like, I think the cool thing to think about is that security of the network doesn't come from the network itself. It's coming from every individual node running a secure system that they can verify as a good connection and is processing all the transactions.
00:47:42.510 - 00:47:58.200, Speaker A: So that's cool, right? It means every individual person can fully secure their own setup. They don't depend on anyone else. And this communication protocol just kind of keeps them all in sync, if not for the grace of God, just keeps running.
00:48:00.330 - 00:48:19.210, Speaker C: So with that grounding, which is like what matters for security is kind of the nodes, the full nodes. Then there's people who will say, well, what about economic security? What are you going to do? Basically price talks. And then you generally tend to think or say at least that economic security.
00:48:19.280 - 00:48:20.410, Speaker A: Is kind of a meme.
00:48:21.630 - 00:48:28.446, Speaker C: Probably the worst you can do is some temporary liveness failure at a very high cost. What are your overall thoughts on that?
00:48:28.628 - 00:49:28.500, Speaker A: Yeah, this is like, I think economic security is a hangover from proof of work. I think people look at proof of work and the cost to create heaviest fork. And that does make sense in bitcoin. But even there, all the operators would reject a rollback deeper than six blocks at this point, like finance Coinbase 100% would, and their systems would halt. And they would be like trying to figure out what the F is happening. So that would be localized liveness failures that are up to the operator, right? And they would stop confirmations from bitcoin if they saw a fork that caused a six blocks rollback, because their assumption is that within six blocks, this is final. So yeah, you can say that academically, Bitcoin didn't halt at that moment, but everyone that relies on it as a communications protocol stopped accepting messages from it as final.
00:49:28.500 - 00:50:30.626, Speaker A: That is equivalent to a halt from any kind of operational point of view. And similarly on Solana Circle, right, when they run their full node, hopefully when fire dancers out, they'll actually run both fire dancer and labs client. If they ever disagree, they halt. They could also run many different nodes, like M of them, which is going to guarantee that if the quorum is ever taken over, like completely hostile, and tries to partition the network and create two confirmations of two different forks. If circle runs ten different nodes anonymously, the quorum doesn't know which ones are in which partition. And the more nodes circle runs and has guarantees and communication, right? So its nodes, it has controller and can guarantee that they're not partitioned. The harder it is for an attacking quorum to create that double headed signed fork, right? As soon as both headers are detected, everyone halts.
00:50:30.626 - 00:51:11.262, Speaker A: All the honest nodes halt because they see that there's now two confirmed blocks with more than two thirds. That's an invalid state. All the honest operators that have a path between them write a minimum spanning tree between them. See both of those headers, they halt, effectively same thing as a long range attack. And the quorum can keep trying to create these two blocks, but they don't matter anymore, because effectively everyone that matters halted the network. It's just the malicious quorum is still running. And those nodes that halt it could actually restart from the last point that they've all confirmed and they have all the signatures to validate that and create a new quorum.
00:51:11.262 - 00:51:48.186, Speaker A: Slash the old one. So they can't just get staked back and try this attack again and continue. And there would be a thing, right? There'd be people on discord, somebody would say Solana's attacked and crypto Twitter, but actually would be what is supposed to happen, right? I want all the high end operators to run multiple machines. I want all of them to have guarantees that their machines are well connected. That means that they should never partition. That means they halt if they ever detect multiple headers, stuff like this. And that means that security of any given setup is in the hands of each individual operator.
00:51:48.186 - 00:52:26.374, Speaker A: And that's a really strong security assumption. It means it's only up to me to secure my own setup. I don't care about anyone else. There's no majority control, right? There's no honest majority dependency whatsoever. And that's a very scalable system. That is really important, because I think these systems have to be kind of like convincing risk wise to every individual operator individually, like that Midwestern bank. If we wanted to become a fully on chain bank, their CTO has to be like, okay, if I run these boxes and the setup and we keep it secure, we're safe.
00:52:26.374 - 00:53:06.150, Speaker A: And I can tell them, yes, your system will halt as soon as it detects an anomaly, and you will not accept any invalid confirmations, and you're not going to wire out any dollars that belong to your clients. And they can be like, okay, I get it, right. Those security guarantees are what's necessary for finance, probably not necessary for gaming and loot boxes. But I believe crypto's ambitions are much, much harder. And this is why it doesn't depend how much stake is there, what the value of it is on binance. All that stuff is irrelevant. What matters is the setup, the operational security of that particular instance.
00:53:09.050 - 00:53:40.180, Speaker C: I'm just never going to get the fired answer at this point. But that also brings up maybe something else related, which is to say that. So you're basically saying there's clearly an incentive for these people or the companies to run nodes for just their business security purposes, which then you probably know what the next question is going to be. There's a lot of criticism about value of profitability on Solana and inflation and whatnot. Can you just give your high level thoughts on that and what you think people get wrong about that?
00:53:41.590 - 00:54:34.658, Speaker A: Mean, like, I think the biggest criticism is that Solana inflation is too high and that somehow that's a cost to the mathematically. Like, if you look at the network, inflation is moving value between unstaked users and staked users, and that is a cost to unstaked users. But if everyone is equally staked, I think the staking percentage right now is 70%. If everyone is exactly 70% staked and 70% unstaked, no individual person is being diluted because it's literally just moving from one bucket to the another one that they own. It's not a cost unless you know the exact distribution and who the users are. So you can say it's a cost to those specific users, but it's a gain to the other users. And kind of the open market kind of evens that out.
00:54:34.658 - 00:55:11.582, Speaker A: But the network itself has a cost. It's the hardware and the operational overhead to run all the systems. And ideally, that cost is borne by businesses that have some random reason to run it. Like circle. They issue dollars on Solana, they run their setup. They don't care about validator profitability because they have a business on top of that that is so profitable that the cost of the setup is irrelevant. Similarly to tensor, to magic, Eden, whatever, right? I don't know how many RPC nodes you guys run, but you have a business that makes money off Solana state that has nothing to do with validator profitability, and that's great.
00:55:11.582 - 00:56:18.082, Speaker A: And any one of those nodes can provide the security necessary to detect a double spend or an invalid state transition by a fully corrupted quorum, and we can halt and restart the network. So security comes from that. The costs are borne by the machines and the operational overhead. And the gains to the network, from a black box perspective, is anytime somebody pays for block inclusion, that is money going into the network. Because if I have some steak and somebody literally gives me, like, potatoes as a side bribe, they bring me potatoes to get their transactions into a block, I can take those potatoes, sell them, get more stake, and now earn more potatoes, because now I have more block space. It doesn't matter how those fees arrive to the validator, whether they're priority fees, whether it's MeV, whether it's like, literally my neighbor giving me a sack of potatoes for a transaction makes no difference. Those are all real world inputs that are driving value creation.
00:56:18.082 - 00:57:21.980, Speaker A: And if you just look at priority fees alone, I think it's like, run rate right now is like 100 mill a year, which is five times more than the cost of the physical hardware. So from a network perspective, like, if you took the cost of the boxes and the priority fees just from that alone, it's already making more money than the cost of the boxes. So in that sense, it's sustainable. Inflation is a nice way to dampen that, because validators do get paid from inflation and priority fees. If they become high enough, validators will start rebating their stakers to grow more stake. So kind of like the bucket of earnings for a validator, whether it's coming from priority fees or inflation, is the same way they will go and try to get more stake to earn more profit. Again, doesn't matter if it's priority fees, if it's inflation, where the profit comes from, more potatoes, they're incentivized to get more stake at whatever costs, and that could be through rebates or whatever.
00:57:21.980 - 00:58:01.314, Speaker A: So that kind of becomes a wash. But having inflation, I think, dampens the ups and downs of bull and bus cycles. So, yeah, I think last year at its lowest point, I think all the fees included were not adding up to the cost of the hardware is about half. So you have to say that the network as a whole is running, and potentially running in the negative. You don't know what other incentive mechanisms like potatoes or MeV were having an effect, but just from priority fees, those were not covering the cost of the hardware. But in that moment, inflation is subsidizing that. Now it's the opposite.
00:58:01.314 - 00:58:25.840, Speaker A: Right now, priority fees are so high that it's more than enough from a sustainability perspective. You have to look, from my belief is you look at holistically, what are all the work inputs, external work inputs going into the black box, and what are all the external costs that the black box is paying for? Okay.
00:58:26.530 - 00:58:29.870, Speaker C: Guarantee there's a potato coin after this episode.
00:58:32.210 - 00:58:59.980, Speaker B: I've got one question, validators Anatolia. I want to know what you think the value is of diet and light clients and all this because Celestia and data availability layers is kind of taking off. And I know you said DAs data availability sampling is going to be a feature eventually, probably on every chain that they should have. So, yeah, how do you think about diet clients? And let's just say you're an SBM roll up in that future. Is there a reason for that roll up, for example, to put their DA on Solana versus something like Celestia. How do you think about that?
00:59:00.910 - 00:59:54.534, Speaker A: So, I think all execution environments are competing, because I think the only way that these systems make money is through selling block space. And that's an execution thing. If you're selling data, you're selling a commodity resource, and the pricing in that data is going to approach the cost of the hardware. The reason why these systems could be economically lucrative is because you're not selling data anymore. You're not selling bandwidth or like a resource, you're selling specific content. People care about block inclusion because there's a specific NFT, mint or market that has an economic value for me to access. And I'm willing to give you potatoes to be first, right? And if you move that hotspot to another layer, all the value that's captured from that content is moved to the other layer.
00:59:54.534 - 01:00:45.754, Speaker A: And now you're just selling data and bandwidth. It's a very kind of like commoditized thing. I can't imagine it being worth more than like two, three x the bandwidth, because from an application layer that is generating all the value, why wouldn't they just find the cheapest one? And you can say that, oh, security is different, but marketing is not. You end up with a situation where a L2 on Ethereum will know, blinking will say we're using celestia data availability or Eigen layer whatever, and you're like, that's not the same security as Ethereum. It's not a L2. And it's only like me and Duncrat or whatever, some poor Ethereum researcher that cares about this. If it's still marketed as a L2, it's a L2.
01:00:45.754 - 01:01:33.770, Speaker A: And then it doesn't matter what DA layer it uses. So my view is that the big opportunity is having a single giant execution layer that can handle as many concurrent hotspots as possible. It doesn't matter if it's write lock fees that are getting burned or it's priority fees that the validators are getting or like a MEV side tip. None of that matters as long as it's external input that's going into the network and you maximize that external input by having as many hotspots because those are content dependent, they're not data or it's not a resource anymore. So to me I think people can build L2s. They probably will. I don't think they're going to be any cheaper.
01:01:33.770 - 01:02:33.498, Speaker A: You can't solve the hotspot problem with L2s, right? Like database hotspot, the only solution is isolation, and Solana already does that. So I don't think you'll see like an improvement. There are some places where you can get an improvement and I think it's like, but you don't need like a full L2 there. You can actually do something like Zero X where you had a mem pool with transactions that could be matched. So you can run a very ephemeral order book that has super fast matching in a single system and only the matches get submitted to the network. Stuff like this. Still, this is moving the execution of prioritization into that layer above, right? It's no longer happening on the native layer, so value capture, most of it is going to happen in that environment where that box is running, I think could benefit users, but you lose composability.
01:02:33.498 - 01:03:06.790, Speaker A: You can't have Jupyter route atomically into that asynchronous box, which may or may not execute at the same time as other transactions. And this is, I think, the big advantage of trying to put it all in one system. So you have composability, which creates network effects, which creates usage and liquidity, and all this stuff aggregates. You can move stuff out and you'll lose some of that, and you may capture more of your own value, but you lose the composition. So that kind of tension is always going to exist.
01:03:08.350 - 01:03:11.114, Speaker C: Yeah, I disagree. I think we need more l three.
01:03:11.152 - 01:03:11.740, Speaker A: S.
01:03:15.950 - 01:03:35.070, Speaker C: Okay, I want to cover two final topics. Quick fire dancer and token extensions. So, obviously, everybody knows fire dancer, but based on my conversations that I've had, people are pretty, there's such wildly volatile expectations, like, somebody thinks it's going to be a million TPS, somebody thinks it's going to loudages.
01:03:36.310 - 01:04:07.354, Speaker A: I bet you could take 39 fired answer systems that are optimized to the hilt and get them to do a million TPS user like TPS. Yeah, but this would be like a very specific deployment. Like, you put them all in the same terra switch, or maybe even just, you find the bare metal data centers that have the best network connectivity, and you have peak optimized systems. If you have like 40 of them, I bet you can handle it.
01:04:07.472 - 01:04:16.510, Speaker C: Wait, so why wouldn't somebody just come from Silicon Valley, take code, run a fork, and raise like $2 billion?
01:04:16.660 - 01:04:58.140, Speaker A: I don't think. Well, the problem is that the cost to do that by forking the code means that you don't have a competitive advantage, and you're creating supply where there isn't demand, and you're sacrificing, know, the neutral base layer, all that stuff that Ethereum folks care about. We also care about that. And you now created your own thing, and then you have to go get all these other systems to connect to it, and all they have access to is AWS. And as soon as they connect, they can't do a million, like, and a bunch of stuff ends up being a job, and all of a sudden you're like, why did I ever do this?
01:05:00.850 - 01:05:04.910, Speaker C: Okay, what are you expecting to come out of fire Dancer for the first release?
01:05:07.170 - 01:06:00.122, Speaker A: A working implementation that is compatible with what's running on main net. So we can then start pushing for 50 50 split of stake running fire dancer and labs. And this would mean that there could potentially be an outage when they disagree. But this would be an important outage, because it shows that we care about safety over liveness, and we'll fix those bugs, and then we'll never have those outages again unless there's a catastrophic bug. And we'll all be thankful when that 50 50 split halts the network and catches that catastrophic bug. And that would be like, I think, really important. But if fire Dancer is running on their latest demo, like, the code that they published for processing the ledger, they ran it in eight cores, I think, and, like, 16 gigs of RAM.
01:06:00.122 - 01:07:14.870, Speaker A: So the hardware requirements for the current load that you see on Salana actually could be much, much lower. What that tells me is not that we should lower the hardware requirements, is that we should figure out if there's bugs in the labs client that we haven't fixed yet, performance bugs, and double the capacity of the network. Like, let's start increasing block space aggressively, let's host more hotspots. Let's just grow the network within. If this is free, right? If we can quadruple the compute units per block right now and the network is fine, it's like free growth. Like, why wouldn't we do it? And if fire dancer has shown that you can get twice as much than that on 32 cores than labs can, labs fixes those bugs, we double it again, right? We should just kind of use fire dancer as the horizon, like, what labs needs to do to fix to get to that point. And it's much, much easier once you see what they fix, what analysis they've done, they've identified which specific bottlenecks they were able to unblock, and that's what's kind of already happening, right? Like, 117 compute.
01:07:14.870 - 01:07:49.938, Speaker A: The CPU utilization is like, I think one fourth of what it was for 116. I don't know, we'll see. Right? But I think it would be awesome if we can basically start increasing block space in the network. Even given the current hardware deployment, we don't need a million TPS, but we need to keep doubling it every two years. I think that's really important, that the network is constantly growing capacity, and it.
01:07:50.024 - 01:07:59.682, Speaker C: Probably makes much more sense to increase that space once there's economic incentives stopping bots from filling it up and just getting all the empties.
01:07:59.746 - 01:07:59.974, Speaker A: Yeah.
01:08:00.012 - 01:08:03.590, Speaker C: Okay, let's completely shift.
01:08:05.290 - 01:08:40.566, Speaker A: That's kind of like the fun challenge right now is if we see that if we increase the throughput of Gulf Stream to 200,000 packets per second, it doesn't change anything because the spam is just filling up. So you have to do the work and figure out how to isolate the negative externalities of spamming hotspots to where you can then increase capacity and actually does create abundance of capacity. So then more hotspots could accumulate Antolia.
01:08:40.618 - 01:08:42.050, Speaker B: Over everything we talked about today.
01:08:42.120 - 01:08:43.102, Speaker A: What is your priority?
01:08:43.166 - 01:08:44.740, Speaker B: Just from like one, two, and.
01:08:47.030 - 01:09:27.338, Speaker A: Probably funny enough, it's writing docs which then become articles that I publish and getting alignment. Like, I feel like I'm finally like an L eight engineer back to my senior staff position, except instead of a big company or I have to go talk to a bunch of teams. It's random teams in the ecosystem that hate the design idea or don't understand it and then they got to like, no, look, it actually does solve your problem and make sure lab, cedo, mango, fire dancer guys are all aligned on getting stuff out the door. Yes.
01:09:27.444 - 01:09:29.220, Speaker C: So got to write more.
01:09:29.670 - 01:10:01.120, Speaker A: Yeah, well, it's funny, the main difference doing this in open source versus a big company, this process happens in every big code base. What's really nice in open source is that it happens mostly in GitHub and there's no meetings. Like you post a doc, people comment on it, they shit on it, you kind of fight it over, and all the discussions happen in the open and it's not like a massive meeting schedule that you have to deal with.
01:10:02.530 - 01:10:37.910, Speaker C: Okay, final question. Completely different really, in terms of what we've talked about. But I want to talk about token extensions, so formally called Token 22. That's obviously something that, let's say Salana foundation is really focused on and a lot of other teams. Jupiter actually released a new NFT standard today with bridge split. And there's a lot of things that opens up like confidential transfers, new metadata, different programmability. What do you think about token extensions? Why should people care about them in terms of developers but also businesses?
01:10:38.910 - 01:11:51.642, Speaker A: I think a weird side effect of how Solana runtime works is that instead of defining interfaces and then a bunch of implementations, people coalesce around an implementation that kind of defines a set of protocols and business practices. What's really nice about that is that you have a single well known implementation that everyone has verified and has gotten stress tested and gets robust behaviors that you can plug into a whole bunch of other things that you can build on top. There's a negative side to that. It means that it's hard for a newcomer to go build Token 2024, right, or their own version of a token where if you're an ethereum, you can just do that and be ERC 20 compatible. But the ugly side of interfaces is that interfaces are leaky. They're never perfect abstractions, and in those leaky environments, the implementations will introduce attack vectors. And this is why it's very hard for DFI protocols to arbitrarily add every random ERC 20 interface implementation.
01:11:51.642 - 01:13:11.480, Speaker A: They have to be very careful about how pools and all this other stuff are designed, and very specific about which things they enable. So you have to be on your guard always about what works. But in Salana, once you build like a DFI implementation that works on top of Token 22, you can just let all of them be instantiated, because it's the same implementation. You have guarantees about what happens when you do a transfer. Like it's not going to yoink state from some random place, or do the transfer in reverse, or whatever you can do, right? This is like it's worked well for SBL tokens and compression and NFTs. We've basically been able to roll one implementation out that gets scaled really quickly across a whole bunch of applications that are user facing, and there's minimum kind of like risk, and wallets have kind of minimum risks, so we'll see if that happens. With Token 22, it's trying to kind of tackle a bigger range of problems involving like for merchants, if you want to hide how much payment flow you're getting through your sales through crypto, you can actually encrypt all those payments, stuff like this.
01:13:11.480 - 01:13:39.742, Speaker A: And it does it in a single standard way, so you can just go enable them. And you have tools and everything else. You don't have to write any smart contracts to do this. You don't have to redeploy your own version of a token. So we'll see what people do with this. Some of the cool things are like token 22s can be, or token extensions that can be fully compressed so the mint can be cleaned up. So now we should be able to leverage compression for tokens.
01:13:39.742 - 01:13:44.660, Speaker A: And all we're waiting for is, I think, RPC providers to support this.
01:13:46.550 - 01:14:01.046, Speaker B: I've got two of my own selfish questions before we these will be quick. One, Antelia, I think you saw you retweeted it. I'm joining the squads team soon. I'm just curious, you've tweeted out a few ideas. What would you like to see out of squads?
01:14:01.078 - 01:14:52.234, Speaker A: What's a feature you'd like to see? What I would love to see is a how to set up squads with like two or three multisig using three different hardware vendors. And then for those hardware vendors, to just support squads natively. Like, what would it take to have Ledger, Keystone and treasure to support squad signing in that context? Because to me that's the perfect cold storage setup. You have triple redundancy across hardware implementations. Like if there's a bug, God forbid, in ledger or something, it's not going to brick or steal your multisig because you're dependent on two or three of those succeeding. So that would be awesome. I think that should be the cold storage set up for everyone is like two or three multi sig, three different hardware vendors formally verified code.
01:14:52.234 - 01:15:17.998, Speaker A: It's perfect. Other stuff I think is like the fuse wallet I think is awesome. And I'd love to see whatever we can do to get it supported across the ecosystem. So we have account abstracted wallet that users can use. Because I think there's a lot of security benefits to that approach. Definitely.
01:15:18.084 - 01:15:34.690, Speaker B: Yeah, I haven't used it yet, but I used argent back in the day on Ethereum, which I thought was really cool because for the first time you had social recovery as well, which was just awesome compared to having a seed phrase like blew my mind at the time. Problem is, on ethereum the transactions are so expensive that I never wanted to use account abstraction. Right, because they even added to the fees. But that's not the case in Solana.
01:15:34.770 - 01:15:36.360, Speaker A: All right, final question.
01:15:36.730 - 01:15:47.050, Speaker B: Solana is known for everyone in it and the ecosystem being jacked. You've focused on your fitness over the last year. You've become swolley. What is just like something you've learned over last year? What's your takeaway?
01:15:48.430 - 01:16:24.662, Speaker A: I've always been focused on my fitness. Until I started salon, I was an Iron man before this, I wasn't fast. I was doing Iron man so I could play underwater hockey. That was like my thing. I was pretty obsessed with that sport. So after starting, I like basically stopped running and had kids. And then I started running again and my knee started getting swollen and I was like, okay, so running is not for me anymore, which sucks because that was my kind of go to stress reliever and I started getting horrible back pain and whatever.
01:16:24.662 - 01:17:07.750, Speaker A: My instinct was that I think my muscles are just like getting. They were fit because I was an Iron man. So it's not like I totally became feeble, but they were out of balance because I think some of the things that were strong from doing all the cardio were still pretty strong, but all the sitting and not working out I think had impact on all the other side supporting muscles. So my instinct was go lift weights and basically started doing that and back pain went away. So I've been doing it, I think for two years almost now. It's great. Now my stress relief is instead of going running, I try to lift a heavy object off the ground.
01:17:08.970 - 01:17:11.218, Speaker B: Yeah, deadlifts you and marinate a competition.
01:17:11.394 - 01:17:43.940, Speaker A: It's much harder. It's a very focusing activity because it's not so much about raw strength. A lot of it is form. And that means a lot of mental focus has to be totally focused on what you're doing. And that's a lot of meditation. It's just being kind of forcing your mind to only focus intentionally on the thing that you want to focus on. So having that exercise and like, okay, I'm going to do this big lift if I have to get it perfect.
01:17:43.940 - 01:18:13.494, Speaker A: My mind can't wander and start thinking about localized fee markets or whatever. I have to force myself to think about a thing. Having that muscle, to be able to force yourself to think about something is what you need to be a good startup founder. You need to be able to like, I need to think about this problem right now. It's an important problem to solve. I can't go do what I want to do. I have to actually be intentional.
01:18:13.494 - 01:18:16.860, Speaker A: So I'm getting that out of it. So it's pretty good.
01:18:17.470 - 01:18:27.520, Speaker C: Okay. Other than practicing perfect deadlift form, what is the one piece of advice you'd give to Solana startup founders for the year?
01:18:32.050 - 01:19:23.920, Speaker A: Paul Graham's essays are really good and Peter Thiel's books are pretty good. It's just all about focus, like having vision and focus and surviving long enough until the market kind of reflects that and obviously luck that it reflects it at all. Right? You could be wrong about your assumptions or something like that, but generally smart people that get really passionate about something have thought it through long enough to where the idea is probably right. Timing could be wrong, and then you have to kind of keep at it and survive long enough to where the timing is right. I would say, yeah. If you want to talk to me about startup advice, how to hire and things like that, how to scale, I've got a lot of lessons learned from that that I'm happy to share with anyone. You've seen me post about them on Twitter too.
01:19:25.170 - 01:19:39.634, Speaker B: Amazing. Totally. Thanks for coming back on. Solana is super lucky to have you. I mean, you're the only reason you're here in the first place, but it's been six months since you've come on and a lot has changed. So I'm excited to see in the next six months where Solana is at, but thanks again.
01:19:39.672 - 01:19:42.054, Speaker A: It's been a lot of fun, for sure.
01:19:42.252 - 01:19:56.214, Speaker B: All right, I've got a little ending note here. First, thank you so much for listening the full episode. If you really liked it, hit subscribe. But secondly, make sure you sign up for Dash. This is blockwork's biggest institutional conference, happening in London in March. I've included a link in the show notes and also discount code. Get 10% off.
01:19:56.214 - 01:20:01.530, Speaker B: Make sure to use lightspeed ten when you sign up. All right, I'll see you there and I'll see you next time on Lightspeed.

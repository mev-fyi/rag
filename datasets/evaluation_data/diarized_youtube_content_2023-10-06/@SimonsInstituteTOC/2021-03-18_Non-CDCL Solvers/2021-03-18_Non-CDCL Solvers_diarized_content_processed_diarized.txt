00:00:00.920 - 00:00:21.158, Speaker A: Before we start with today's session, I'm Moshevadi. I will be chairing the session today and if you have not seen yet the news, and that's lobby and Aviv Gerson won the just was announced they won the Abel Prize for bridging theoretical computer science and mathematics.
00:00:21.246 - 00:00:22.274, Speaker B: So this is.
00:00:24.614 - 00:00:56.764, Speaker A: Thank you. Thank you for correcting me. I started with the first name and my brain went somewhere else. Thank you. So this is first of all, amazing recognition for the work of two luminaries in our field and also an amazing recognition by the mathematical community. The theoretical computer science is one of the have been outstanding accomplishment of mathematics in the past 50 years. So today we're going to talk about non CDCL solvers.
00:00:56.764 - 00:01:48.584, Speaker A: This is the theme of the session today. So CDCL solver has been another amazing accomplishment of the past 25 years. I call it the SAT revolution. But I've been on the record that as much as the CDCL have been successful, there is a bit of monoculture in the SAT community and we need to look at other, other type of solvers. And that's what today three speakers will tell us about three different type of solvers. And the first talk is by Maran Hewlett, who is talking about such solvers, but non CDCL, focusing on smart versus fast, or as some people call it, a Brennan versus the speed demon. Go for it, Marjan.
00:01:49.244 - 00:02:29.004, Speaker C: Thank you. I'm excited to talk with you about look ahead solvers. Lookahad was actually the topic of my PhD thesis and it is something completely different than CDCL. Although it's not as powerful as CDCL on the industrial instances, it has quite some also applications and some interesting reasoning. And I gladly want to kind of go over some of these cool techniques with you. This talk will focus on four parts. First, I have a kind of a rather large introduction on SatPat, focusing on Lookahad.
00:02:29.004 - 00:03:40.384, Speaker C: And I think the most cool thing I think of Lookahad is actually the so called local learning aspect. And frequently when I see other papers now about Lookahad, they kind of ignore this aspect. There's lots of cool local learning that one can do. And I kind of want to kind of go over a handful of these techniques and at the end of this talk I want to kind of show how look ahead can be used for very hard and challenging problems in combination with CDCL, which is known as cube and conquer. Moshe already mentioned this and I guess most of the audience is very aware about this Sat revolution, the enormous breakthrough that we had in the last 20 years. When solving sat up till the mid nineties, we were only able to solve formulas with up to, say, thousands of variables and thousands of clauses. And today we can solve many problems arising from industry with millions of variables and millions of clauses.
00:03:40.384 - 00:04:23.850, Speaker C: If you kind of look back to the early SOT research, say the first 40 years of SOT research. So from the late fifties till the late nineties, it was all based on DPL. And let me kind of, because this is actually also one thing that Moshe taught me. If you want to build an algorithm, you have to kind of decide whether you want to focus on being smart or being fast. And typically you cannot do both because the data structures don't allow you. If you want to do something very smart, you need very detailed data structures, and that prevents you from being fast. Once it comes to satisfiability, you also actually have a second choice.
00:04:23.850 - 00:05:24.164, Speaker C: You also have to decide whether you want to focus on finding a solution or trying to prove whether no solution exists. And if you kind of summarize to, say, the first 40 years, so the late fifties to the late nineties in sod solving, then almost all approaches were focused trying to be smart and trying to find a solution. And I think the main breakthrough actually came when the people decided, okay, let's try to be fast and try to find, to review the formula. And actually a satisfying assignment is just a counterexample that no such refutation exists. But there actually has been a lot of cool work in those 40 years and also later that are really worth exploring and also have their own applications. And so this is most of the group to actually look ahead. And I will talk about this now.
00:05:24.164 - 00:06:34.484, Speaker C: So, first, very short, what is lookahead? Lookahead. What it tries to do is it tries to make a binary search tree of the search space, and it tries to make the tree as small as possible. How does this work? In each node of the search tree, you pick a variable and then you split it into two nodes, one where the variable is assigned to true and the other one where it's assigned to false. Picking the right variable for the split is very important and can reduce the search stream, sometimes by orders of magnitude. This approach with the right heuristics is very effective on a broad range of problems, although all of them tend to be relatively small, say, up to thousands of variables and thousands of clauses, its main weakness, because the heuristics are very effective. However, they are also expensive. And if you deal with variables over formulas, with, say, a million variables, this is completely impossible, because these things are just too expensive.
00:06:34.484 - 00:07:23.384, Speaker C: CDCL, most of you probably know at least the basics of it. It is not trying to be smart as look ahead, picking the right decision all the time, but it tries to be fast. And so what it does, it does very cheap heuristics to pick a variable and then assigns it. Simplify. Again, a simple decision and only the reasoning starts to really kick in once you hit the conflict. This conflict is turned into a clause which is added to your database and we continue. This has been very effective on large problems, which I call easy, because sometimes the runtime of the CDCL solver is linear, even in case for unsatisfiable ones.
00:07:23.384 - 00:08:07.626, Speaker C: This is only possible if these problems are easy. So there are short proofs for these formulas and CDCl really knows how to quickly find them. One of the main weaknesses of CDCL is that it's very hard to paralyze. But I will actually, at the end of this talk, talk about how we can combine lookahead and CDCL for some effective parallelism. Something I briefly want to touch is local search. Local search is another solving paradigm which is quite effective on a range of problems. It starts with a full assignment, and then it starts flipping the true values of some variables until satisfying assignments is found.
00:08:07.626 - 00:09:35.584, Speaker C: Some problems that take years with both CDCL or lookahead or their combination, can be solved, sometimes in seconds with local search. Local search has the same as property as CDCL. All the data structures are really focused on trying to do things fast. So although most of the people that heard about SATA are aware of these extremely important progress on industrial instances, but also in the last couple of years, there have been a lot of progress in solving long standing open MAF problems using a combination of lookahead and CDCL. And without this combination, it would be impossible to solve these problems efficiently. Now let's go a little bit more into detail how Lookahad works. So Lookahad is based on it builds a DPL tree, which dates back to the early sixties, and I already mentioned it, it builds a binary search tree, and in each node of the search of the tree you pick a variable which ideally splits the space into two much easier subprumps.
00:09:35.584 - 00:10:37.344, Speaker C: And at each step of the recursion you first simplify the formula. With unit propagation you can also do some additional stuff, and then you do a split. And this you repeat. There are two important heuristics here. The first one is which variable do we pick at each node in the tree? And the second one is which of the two branches are we going to explore? First, if the formula is satisfiable and you pick the right one, you will just straight walk to a solution. So it can be very beneficial to spend some time to figure out which branch might be the more satisfiable. And although I won't talk about it in this talk because it's only 30 minutes, but you can do all some interesting ways to jump through the search space or through the tree to find a solution fast using lookerhead techniques.
00:10:37.344 - 00:11:29.234, Speaker C: A very simple example. So on the slide there is a formula with five clauses. If you would pick in this example x three as your first decision, then you have a small three with only two leaf nodes. However, if you for example pick variable x two, then the number of leave nodes doubles and so on. This small example, you see that just picking the wrong variable doubles the size. In practice for hard problems is it's picking the wrong variables can actually result in trees that are orders of magnitude larger compared to picking the right ones. So it's very important to pick the right variables for the split.
00:11:29.234 - 00:12:11.970, Speaker C: I already used the word look ahead now several times and most of you probably don't know exactly what it is. So let me be very brief to give first a high level thing here. The look ahead sorts over is a DPL where lookahads are used to pick the decision variable. And what is a lookahead? A lookahead is you pick a variable, assign it to a true value and then simplify it as much as possible. This is typically only done by unit propagation. And then you do two important things. The first thing is you measure the reduction.
00:12:11.970 - 00:12:48.842, Speaker C: And there are many ways to measure the reduction. For example, you can measure the reduction of the size of the formula. You can the reduction in the number of variables. I will briefly talk about this more on some later slides. And then what you can also do, and what I figured out in the last decade is that possibly the most important thing, what you can need to do afterwards is to learn as much as possible. And the learning that is here is completely different than CDCL. And this is what I call local learning.
00:12:48.842 - 00:13:23.518, Speaker C: And most of the middle part of this talk will be on local learning techniques. Once you've finished the local learning, then you backtrack and you do a look ahead for another variable. So this is the high level steps of lookahead. Now let's look at an example. So on the bottom of the slide you see a formula f learning. And I will use this formula throughout the remainder of this talk. And how does a look ahead work.
00:13:23.518 - 00:14:02.464, Speaker C: So we start by picking a variable in a truth assignment, for example, x two and false. And so we assign x two to false. And what you see now here is that this clause becomes units. All the literals except for one are falsified. And so you are forced to make x one false. This in turn makes this a unit clause and therefore forces x six to be false as well. And now this clause becomes unit, forcing x three to be true.
00:14:02.464 - 00:14:49.538, Speaker C: Afterwards, there's no simplifications possible anymore. And so that part of the look hat is over. But now we need to do the next step, which is measure the reduction. So on the next slide, I will show you this, and then we will talk a lot about learn if possible. Now, so this is exactly the same formula and the assignment of the look ahead on the prior slide. And now the question is, how are we going to do the measurements? So one way is, for example, is to count the number of satisfied clauses. In this case, we have eight clauses and seven of them are satisfied.
00:14:49.538 - 00:15:25.774, Speaker C: So there's a lot of reduction if you use that metric. You can also look at the number of implied variables. In this case, this is three of them. The number of satisfied clauses tends to be a very bad metric. The number of implied variables is quite a bit better. But the best method typically in practice, is to count and actually weigh the number of new clauses. And new are the clauses that are reduced but not satisfied.
00:15:25.774 - 00:16:23.494, Speaker C: In this example, this is only the clause x four, x five or x six. This one has been reduced from a ternary clause to a binary clause. And what you do in lookahead typically is you count the number of reduced clauses and then make the shorter clauses more important. And actually you also put a lot of weights in there and the weights you can maybe view as what is the probability that the random assignments would satisfy the reduced clauses. And this heuristic is now used in most of the state of the art solvers. Do some weighing of the reduced clauses. So now we have all aspects of the look hat architecture, which is on the top, we built our DPL tree.
00:16:23.494 - 00:17:09.844, Speaker C: And in each node, before kind of deciding which is the decision variable, we look at the simplified formula. And then we do look ahead on all the variables or subset of the variables. And a look ahead is we assign it to a true value, simplify the formula and do some measurements. So for example, the numbers over here show, for example, the reduced, not satisfied clauses. And these are the heuristic values. And then we need to combine them because you pick a variable and not a literal. And the best practice is actually to just multiply these numbers, and the highest multiplication is the one that you pick.
00:17:09.844 - 00:18:12.500, Speaker C: But notice here is that if you do a look ahead, sometimes the look ahead can result in a conflict. So if we assign x three to false, it can result in a conflict, which means that all satisfying assignments must have x free to true. And this is actually the kind of easiest way of local learning. And local learning is very important to pick the right decision. And so, although we can compute these values in the first kind of iteration over all the variables, it is very important to first do a lot of local learning, which improves the accuracy of the heuristic, which in turn makes a tree much smaller. Okay, now let me focus on the local learning. So we all so what CDCL is doing is it hits a conflict and adds a clause to the formula.
00:18:12.500 - 00:19:06.108, Speaker C: And this clause is logically implied by the formula. Lookahead is not doing any of this kind of global learning. The clauses that are added are only valid for that node of the search and OLED. And so what we're going to do is we're only going to learn clauses, typically units and binary clauses that are valid for that node and everything below it. And because they're only valid at this point in the search, it means that as soon as we backtrack, we have to remove them all. And this also makes the data structures much more complicated, because you need to do a lot of accounting which clauses are valid where. Let me first talk about the easiest part, and we already talked about it, which is the filled literals.
00:19:06.108 - 00:20:06.172, Speaker C: So we do a look ahead on l was true. If it results in a conflict, then we know that l has to be false in all satisfying assignments. If both the look ahead on l and the look ahead on not l are field literals, then we actually found a dead end situation, and that node is, and we need to backtrack. This notion of field literal can also be generalized to this so called double look ahead. And double look ahead is we actually pick two variables and two true values, and then do unit propagation and see whether they result in a conflict. For example, our learning formula, we assign x four to false, x six to true, and then by unit propagation, x one has to be true, x two has to be true, x three has to be true. And then we have our falsified clause.
00:20:06.172 - 00:21:02.144, Speaker C: And this means that we can learn the clause x four or not x six. This double look ahead is very, can be extremely effective on some problems. But notice that this is very expensive, right? Because we need to pick two variables. So the complexity of doing it for all possible assignments for two ones is cubic, because also the unit propagation can be linear in the number of variables. So it can be very expensive. But for some problems it is very effective, but for others, it's extremely costly. So, Jakob, let me do the.
00:21:02.144 - 00:21:38.914, Speaker C: What is the question? It's obvious why we cannot learn properly a globally valid clause. Yeah. So Jakob mentioned that, of course, the locally learned clauses, we could add them as globally ones by putting the prefix in there. But at least in practice. So Oliver implemented this in his solver, the okay solver. But in practice, this is not very effective. So the clause is typically because you pick the right decisions, that they are no longer valid elsewhere.
00:21:38.914 - 00:23:15.504, Speaker C: Now let's talk about another local learning technique, which is called hyperbinary resolution. We have a variable x prime that occurs in many binary clauses, and it occurs there with the literals not x one to not x n. And we also have a long clause, x or x one to xn. If you're going to look what happens with unit propagation, that if we make x prime false, then the unit clauses all propagate x one to false, x two to false, xn to false, and afterwards the long clause becomes unit, because all the literals x one to xn become false, which forces x to be true. So if we have this situation, then we observe that not x prime implies x, and this happens by unit propagation. But the interesting thing to notice here is that if we make x false, then just the long clause would reduce to a clause just one shorter, and there's no unit propagation. And so what hyperbaric resolution does is it picks all these binary clauses and the long clause, and by resolution merges it into a single step into a binary clause x or x prime.
00:23:15.504 - 00:24:38.990, Speaker C: And after adding this binary clause, we have x not x implies x prime, and we're actually going to find these hyperbinar resolvents using unit propagation. So we do unit propagation. So we start with x two, and then we have the unit x one comes from this binary clause, x six comes from this binary clause, and x three comes from that binary clause. And for all of the ones that are not implied by an x two binary clause, we can add a hyperbinary resolvent, this one or this one. And the latter one is the most effective one because this one is due to a binary clause, but this one is due to a ternary clause and would improve the unit propagation during future look aheads. Now, another technique is called necessary assignments. So we do a look ahead on x is x is true, x one is true, which would imply x two, x three, and x four to true.
00:24:38.990 - 00:25:22.370, Speaker C: And now we do another look ahead with x one to false, which would imply by unit propagation, x six is false and x three is true. Notice that in both cases, x three is forced to true. So either we assign x one to true, or if we assign x one to false, we both have x three is true. So therefore x three has to be true in all assignments. Satisfying assignments. In case we do hyperbinar resolvements, we also would find that x three to false would be filled literal. But if we don't do this, actually we wouldn't find this.
00:25:22.370 - 00:26:03.740, Speaker C: But doing necessary assignments is actually a way to find this much more quickly. Another technique is altar keys and altar keys. This is a bit more exotic. An altar key is an assignment that satisfies all the clauses that are taxed by it. Example is the pure literal, which there's no complement of it. So if you assign the periodical to true, then only clauses get satisfied. Also, satisfying assignment is an altar key because all the clauses are satisfied so clearly.
00:26:03.740 - 00:26:39.278, Speaker C: Also all the clauses that are touched are satisfied. Interesting. Altar keys are the ones actually in between pure literals and satisfying assignments. And the nice thing that you can do is if you find an altar key, all the clauses that are touched by the altar key you can take out. And the resulting formula is satisfiability equivalent to the original one. Then there's also this notion of the one alter key, and a one alter key is all clauses except for one are satisfied. So there's one clause that is reduced but not satisfied.
00:26:39.278 - 00:27:34.382, Speaker C: All the other ones are satisfied. Now we do, for example, a look ahead on x one, which results in the assignment that x two, x three, x four are also assigned to true. Notice that all the clauses that are touched by the assignment have satisfied literals, a green literal, and therefore the formula is satisfiability equivalent to x five or not x six. And this technique can also help to reduce the computational cost on unsatisfiable instances. A little small side note here is that lookahads can quickly solve two sot formulas by simply doing only lookaheads. You never have to branch. Either a lookahead results in an alter key, or.
00:27:34.382 - 00:28:25.194, Speaker C: And then you can force the literal to be true, or look ahead results in a field literal, and you can assign it to false. And yes, let me, because I'm kind of a bit short on time. So let me first finish the talk, and then we can talk about a bit more about the, the aspects here that we go beyond resolution. Another cool thing here, and this is actually much more effective than alter keys because alter keys are kind of rare. The one alter key learning. So now we assign x true to true to false. Sorry, this implies x one to false, x six to false, and x free to true.
00:28:25.194 - 00:29:31.288, Speaker C: Now we have a one autochey notice that this clause is the only clause that has been reduced but not satisfied. Now the question is, how can we do any learning here? Because if we had an auto key, we could just take all the clauses out. But what can we do here? The observation here is that if x four would have been true, then the assignment x two false would have been an alter key, because x is four would have taken this clause out. And therefore, if you would assign x two to false, this would have been an alter key. And the same holds for x five. If x five would have been true, then x two to false would have been an alter key. And as a consequence, you can learn the binary clauses, the one autarky clauses, not x two or not x four, or not x two or not x five.
00:29:31.288 - 00:30:15.994, Speaker C: So x four implies not x two and x five implies not x two. And the one alter keys actually happen very frequently. So while the altar keys hardly happen, one altercies frequently happen. And you can do this locally. So this rounds up the local learning aspect of this talk. So it is very important to look at hat solvers, because the local learning really also improves the accuracy of the heuristics and thereby making the tree smaller. And some of these techniques are also used in, in CDCL solvers for preprocessing and in processing.
00:30:15.994 - 00:31:24.028, Speaker C: Now let me briefly remark some remarks about Kubernka. So although lookahead is not effective on large formulas, because things are expensive, you can actually use lookahead in combination with CDCL to solve very hard formulas. This is what we call cube and conquer. And what does Kubernetes conquer do? It builds the DPL tree to some level. And then for all the leaf nodes in the DPL tree at some cutoff level, we are going to call a CDCl solver. And so we have split our formula f into n different subformulas, the leaf nodes at some cut in the DPL tree, and then we solve them effectively using CDCL and for several problems. So I've been showing this on some mathematical problems, but also some industrial problems.
00:31:24.028 - 00:32:19.268, Speaker C: We can have linear time speed ups even with thousands of cores. And for example, this technique has also been recently integrated in the SMT solver c three. I won't have time to go into detail here, but let me briefly explain what I think is going on, because kubernetes we frequently witnessed super linear time speed ups. How is this possible? How? I see lookahead. So lookahead is really good in able. If so, if there's a global argument why the formula is unsatisfiable, then you need to make a good global split. At some point, after doing enough splits, the formula there becomes some local arguments why the formulas are unsatisfied.
00:32:19.268 - 00:33:22.710, Speaker C: In case there's a local argument why the formulas are unsatisfiable, you shouldn't do a global split because then the argument will be there in both of the branches. And so what you need to do in order to get cube and conquer effective is you split until a short refutation exists, or at least heuristically, you expect it to be there. And then you call the CDCL solver and the CDCL solver will find you the local conflicts quickly. And so the plot shows kind of that you get this speed up more and more when increases. But at some point for this problem, the splitting cost becomes so expensive that the splitting is more expensive than the total CDCL cost. Now to conclude. So I presented some aspects of the look ahead architecture.
00:33:22.710 - 00:34:15.094, Speaker C: Lookahad tries to be smart instead of trying to be fast, and it tries to be smart both by picking the right variable. And an aspect that I really didn't talk about much is it tries to be smart by picking the right branch. This is very effective on small and hard formulas and also can be used very effectively for some heart problems in combination with CDCL. So it's important that we have these effective splits. And a very important aspect of this is the local learning, which I discussed. Something I didn't have time to discuss is that you really need to kind of massage your data structures in order to do this all efficiently. But this is one of the key things to make lookahead effective in practice.
00:34:15.094 - 00:34:22.214, Speaker C: Okay, that concludes my talk. I see lots of questions. Morshe, how are we going to do this?
00:34:25.234 - 00:34:26.426, Speaker D: I'll pick the last one.
00:34:26.450 - 00:34:36.113, Speaker A: Karem, what would you like to say or comment or ask? Sure.
00:34:36.933 - 00:35:03.934, Speaker E: My question was, it looks like, I mean, look ahead was done in earlier solvers. I forget the name of the solver, but this guy from Sweden. So there is BFS and there is DF's cuban conquer does bfs followed by depth first search, which is CDC health. Can you view this as just one point on the spectrum of how to combine depth first versus breadth first and learning in these most different styles.
00:35:09.394 - 00:35:14.530, Speaker C: What do you mean? There's just one aspect or because there's many other ways of doing this, you mean?
00:35:14.562 - 00:35:37.284, Speaker E: Yeah, I'm saying instead of just doing, like in cuban conquer, you do look ahead and then CDCL. What if you do a little bit of look ahead, do a little bit of CDCL and then stop CDCL and do more look ahead and then do CDC dot cities and so on. So you, you interleave breadth first and depth first, depending on what you're learning and what's happening in the search space.
00:35:37.944 - 00:35:40.080, Speaker C: Yeah. So we have a paper.
00:35:40.192 - 00:36:04.584, Speaker A: Let me, Marian, let me maybe augment the question. Suppose that we look at this, the cuban conquer and look ahead. It's just another kind of set of, we have arsenal of heuristics, and we decide dynamically to use them as appropriate rather than make a decision up front. Are we going to use CDCL or we are going to do look ahead?
00:36:05.804 - 00:37:18.128, Speaker C: Yeah. So, actually, I had a paper, I think, quite some years ago with a student in Delft, which we called concurrent cuban conqueror, where we had CDCL solver always running in parallel with the lookahead. So we, in every note, we let the CDCL solver run on the same problem, and the look ahead solver tries to figure out the best split and the first one that actually finishes kind of returns. And that was reasonably effective, although it didn't give a major improvement. And also, Armin has an implementation in tringerling where also this combination is trying to do it as effective as possible in practice. And Tringerling has been quite effective in several of the SAT competitions. Tringling splits the search space using look ahead, but then runs the subproblems using CDCL.
00:37:18.128 - 00:37:30.804, Speaker C: If that. If they cannot be solved within a certain time limit, all of them are split again, and this is repeated. So this is actually what you kind of suggested is what happens in the software trimming.
00:37:32.144 - 00:38:14.056, Speaker E: So it's been done. I mean, I'm just curious. I'm intrigued by the fact that, you know, you can learn in a local context something that might be extremely helpful in, you know, you know, either proving unsat or finding a sat. And the indications of what is happening in that part of the search space could actually inform whether you want to do further look ahead or further, you know, CDCL again, you know, what you said at the beginning, which is smart, not fast. You know, forget about, you know, being fast now, but, you know, that seems to be unexplored, yet, you know, exactly where you want to do this switch from one way of doing things to the other way.
00:38:14.200 - 00:38:43.604, Speaker C: Yeah. But to some extent, you can also see the in processing also as a bit of this. Right. In processing does field literal detection and other things that you might do in a look ahead solver. And so you might kind of incorporate lots of these look ahead techniques actually in an in processing phase of the CDCL solver. So you don't do any of the splitting, but you only take the local learning part, which in my experience is one of the most effective things also of look ahead techniques.
00:38:44.264 - 00:38:46.084, Speaker A: Oliver would like to make a comment.
00:38:47.904 - 00:39:28.502, Speaker B: So on this question of making it dynamic. So I think that's extremely important. And I believe that the look ahead solvers currently should have a better chance of getting a good theoretical handle on it because it's inherently simpler. You have all these processes related to tree growth and the solver measures anyway, a lot of data which is underutilized, yet all of that look aheads and so on. There's a lot of data which I believe, and I'm working on that. We could make much more progress with that. And then definitely.
00:39:28.502 - 00:40:04.894, Speaker B: So this interleaving of these different techniques. So kind of the look ahead, perhaps more at the planning. As Marine perhaps said, the look ahead has more, the planning oversight is less good, possibly with solving the problem, but it has a better statistical overview and this kind of combination. As also caring said, in the future, I believe there's a good chance because the look ahead heuristics we understand somewhat better, I think quite a bit better than the CDCL heuristics.
00:40:06.834 - 00:40:37.864, Speaker A: I'm going to use dynamic heuristic here. Houston is just being hit by a thunderstorm and I'm concerned a little bit about loss of power. So I'm going to ask Zhi where to go next rather than Jacob, as originally planned. And number two, if I disappear or if Gwe, if I disappear, I'll ask Albert to replace me as chairman. And let's go with Ga before we lose power here. So thank you, Maran.
00:40:38.244 - 00:40:39.252, Speaker F: Please stop sharing.
00:40:39.308 - 00:40:40.508, Speaker A: Please stop sharing.
00:40:40.676 - 00:40:41.556, Speaker C: Stop sharing.
00:40:41.620 - 00:40:43.604, Speaker A: Yeah, and we.
00:40:43.724 - 00:40:48.828, Speaker C: I will comment on the questions via email or in the.
00:40:48.956 - 00:41:12.212, Speaker A: Yeah, and let's go with Ga next. I'm sorry, Jacob, I'm just, we had a little experience with loss of powers. We are less trustful to now of the, of the power system here. Yes, go ahead, Zhiyun.
00:41:12.228 - 00:42:02.114, Speaker F: Thank you, moshe, for the introduction. Hello, everyone. My name is Zhu Ye Zhang and it's really my great pleasure to speak here at Simon's institute. Today I'm going to tell you about our work on a continuous local search approach for hybrid solving, and this is a joint work with anatalsocrylides, anshumari, srivastava and Mousehivardi. So when we are talking about set solving, what are we really referring to? I guess in most cases we mean CNF solving. Of course, CNF is the most prevalent and successful format in set community, but there are also other very important and useful non SYnf Boolean constraints which are much less studied in this community. In graph theory there are a lot of examples.
00:42:02.114 - 00:42:56.424, Speaker F: For instance, for vertex towering, it's more convenient to represent this problem by either cardinality constraints or pseudo boolean constraints. Another example is the hypergraph two coloring, where not all equal constraint is the most natural representation. Well, in cryptography actual constraints play important roles for composing protocols like SHA one, and I'm sure that you can list other applications to demonstrate the importance of non synf boolean constraints. So what have people done for handling non CNF constraints? There are two main lines of research. The first one is encoding. Encodings have been discussed in previous workshops, but here I want to make the list. Some limitations of encodings.
00:42:56.424 - 00:43:53.642, Speaker F: First is about size. Here is the histogram about the blow up of number of variables and classes. If we just want to encode a coordinator constraint with 250 variables, you can see the blow up here, and it is no doubt bringing a heavy burden to the sep solver and slow them down. Besides the size, encodings can vary a lot by other aspects like Arc consistency and the solution density. So usually different servers prefer different encodings. And the takeaway message here is that just because encoding is found for type of constraint doesn't mean it is server friendly. Well, the second aspect for handling non CNF constraint is to use extensions of CDCL based set servers.
00:43:53.642 - 00:44:47.284, Speaker F: There are a bunch of tools developed in this area, but we want to make the point here that they need to design algorithms for each specific type of constraints, while a uniform way for handling different types of constraint is still lacking. So both of those lines of research kind of rely on CDCL servers. With CDCL servers relies heavily on the property of seeing that format. So we are thinking about can we use a more general approach, namely local search. So local search. In local search, usually they objective function is defined by the number of constraints of formula satisfied by some assignments. There are many, many classical algorithms in this area.
00:44:47.284 - 00:45:48.128, Speaker F: GSAT is one of them where you start from a random initial point and you just keep flipping the variables with the best value until you reach a solution. Local search gives us interesting theoretical results, and in practice it was shown to be effective on hard, random and crafted instances as well as mat set instances. So we want to ask, can we use discrete load research for non CNF solving? Let's see what happens. So remember that discrete research also relies on some properties of CNF, which is an unsatisfied clause can always be fixed by flipping just one variable. But does this property also hold if we want to solve non synapse constraints? Probably not. Let's see the following example. Here we have a coordinative constraint with four variables.
00:45:48.128 - 00:46:44.706, Speaker F: And suppose we start from this all false assignment. Now it is unsatisfied and we will try to flip one variable, let's say the first one, to make this new x. Now there are two things to notice. The first one is that the constraint is still on set. The second thing is that, and the even worse thing is that if we just use the way we define the discrete objective function in synapse solving, we will see no change to the discrete objective, although we think that we are making some progress because we are closer to satisfying this coordinated constraint. So that indicates some problems with using discrete objective for non CNF solving. The first one is that discrete local search is limited to flip a single bit per iteration.
00:46:44.706 - 00:47:59.940, Speaker F: Second, discrete objective function fails to capture the progress towards satisfying a non CF constraint. So maybe stay in discrete domain is not enough and here is what we are planning to solve those problems. As for discrete objective fails to capture progress, we plan to design a continuous fitness function to measure the progress. Since district load search is limited to flip a single bit per iteration, we are thinking of just search inside of the box and do continuous research so that we are kind of flipping more than one bit simultaneously. Maybe we'll just flip each bit slightly, but we can manipulate a subset of bits instead of just one. So I think it's a good point to wrap up a little bit and show you some really good work on continuous approaches for set solving, which is not a new thing because people have developed both convex realizations and non convex polynomial representations for set solving. For the last part, we do have LP relaxation and SDP relaxation.
00:47:59.940 - 00:49:12.704, Speaker F: Those relaxations gives us good theoretical guarantees, but they usually fail to give high quality solutions in practice. While on the right, the CMF formula is usually transformed into a sum of product polynomial, but in the previous literature they failed to give sufficient theoretical analysis about this transformation. And also note that this transform only applies on CNF format. While we want to solve non CNF constraints as well. One point that both of those directions are missing is the success of gradient based techniques achieved in machine learning, and we believe that those advantages and new techniques are not fully leveraged in the SAT community. So we want to explore the potential of continuous local search. So here I will just show you the overall workflow of our framework, and the goal is to design an effective framework that handles different types of constraints uniformly we are giving.
00:49:12.704 - 00:50:04.984, Speaker F: So our input is hybrid boolean formula and we can do some kind of transform which I will describe later to generate a multilinear polynomial. Then we will be able to do continuous optimization based on some gradients approaches. We may end up converting to global maximum local maximum or set a point, but no matter which point we convert to, we can always discriminate it to check if it is a solution or not. If not, we just go back and do random restart. In the rest of this talk I will be decomposing this framework into different pieces and show you how each component actually works. The first and the most important part of our framework is how we define this continuous fitness function. Let's go for it.
00:50:04.984 - 00:51:00.604, Speaker F: Remember that the discrete objective function is just the number of satisfied constraints. As we discussed before, this function is kind of too discrete, so that it fails to capture some small progress towards satisfying noncnaf constraints. So, can we define a real value fitness function for the Boolean formula? Usually one of the ways people do it is to define a real value function by probability space. Here is how we do it. We want to define a fitness real value function for all the real vector which are constrained in the boolean bots from minus one to one. So we can define a probability space based on the real vector a. The probability space will be applied on all the Boolean vectors.
00:51:00.604 - 00:52:20.094, Speaker F: So here is how we do it. Each coordinate of the Boolean vector will be independent from each other and the value of xi will be only decided will be only related with the value of AI. So roughly speaking, if AI is positive, then xi has a greater chance of being one if sampled from the probability space sa and if AI is negative, then vice versa. Here is an example. A is a vector and here is a table probability table showing how what's the probability of each variable taking some specific value, and we can sample a Boolean vector from this table. So after we get this probability space, one of the way that we can define our real vector real value function is to use a probability that the formula is true under this probability space. So this looks good, but unfortunately this probability is sharp pre complete to evaluate because it reduces to the model counting problem.
00:52:20.094 - 00:53:40.304, Speaker F: But we can step back and compute something easier, which is the expectation of the original objective function under this probability space. So what happens if we choose this representation? Now, the capital f. The fitness function measures how many constraints are satisfied in expectation under the probability space, and we can next try to maximize this fitness function with respect to a, which is constrained in the Boolean box where a is a real vector. So generally speaking, this real value fitness function gives us a way to measure how good a real vector is. While we're doing search, the next question to ask is how to evaluate this fitness function. A naive approach takes exponential time, of course, but it turns out that this fitness fitness function can be evaluated in polynomial time by the so called wash Fourier expansions, which I will describe in the next slide. The wash floor expansion is the main theoretical technique we are using in our framework.
00:53:40.304 - 00:54:48.524, Speaker F: While Ryan has written a remarkable textbook on this topic, I will just give a brief introduction. It is basically a technique which transforms Boolean functions to multilinear polynomials. For example, if the formula is x and y, then I will claim that this polynomial is the four expansion. The reason is if you evaluate this polynomial on all the four possible discrete assignments, you will see that the Boolean function and the polynomial agree with each other. And this phenomenon is generally in the sense that every single Boolean constraint has a unique representation, a multilinear polynomial that agree with the constraint on all the Boolean assignments. But what happens on the real vectors? The polynomial itself does not prevent us from evaluating it on real vectors. If we do so, we may generate a surface in high dimensional space, which is useful in our framework.
00:54:48.524 - 00:56:04.344, Speaker F: So how does it help us to evaluate our objective function? Recall that we define our real domain fitness function by the expectation. So by the linearity of expectation, we can expand this representation to the sum of probability that each constraint is true under the space that we defined by a the real vector. One of the contributions we made is that this probability can be computed exactly by evaluating the Fourier expansion if we just use the same real vector a on both sides of the equation. So now we are able to rewrite our fitness function by the sum of Fourier expansions of each constraint. Here is an example. Now phi has two different constraints, and we can transform them both into their corresponding Fourier polynomials and add them up to get our polynomial representation of fitness function. So we will be able to evaluate it.
00:56:04.344 - 00:56:52.092, Speaker F: So here finish our first part. And the second part is about versatility. So since we are motivated by handling noncf constraints. And so we will see how we do it. Recall that our fitness function is defined can be rewritten as the sum of four expansions. So if we have a new type of constraint, and we know they closed form for expansions of that constraint, then we are good. But for what type of constraint can we do it? Fortunately, many types of interesting constraints have their closed form for expansions from axor to cardiovascular constraints to not or equal constraints.
00:56:52.092 - 00:58:20.264, Speaker F: And including CNF clauses, we further proved that for all symmetric constraints, we have their closed form for expansions. So here comes to the last part, and I believe that in this part a lot of questions can be raised. For example, can we say anything about global maximum center points, or local maximum? Or how fast is the convergence? Or after we discredit the convergent point, what is the quality of this assignment? So let's answer these questions regarding convergence and rounding. The first thing I want to tell you here is about global and local Matthema another contribution we made is to prove global matma are all preserved in robots. So if we what do I mean by that? Let's first consider the scenario in discrete local research. In discrete load search, phi is satisfiable if and only if the maximum of the discrete objective value is the number of constraints. This is easy to see, and what we have proven is that this theorem also holds in the continuous space.
00:58:20.264 - 00:59:08.804, Speaker F: So here I need to replace the discrete objective value to our fitness function, which is real value. And I need now the maximum operator is applied on all the possible real vectors in the box constraint, and the maximum of the fitness function is still the number of constraints. So that means the fitness function is well behaved inside of the tube and it won't exist. Exit the number of constraints. We cannot end up finding some global maximum inside of the tube. So it's not always realistic to convert to a global maximum. So we have to consider the case where we go to a local maximum.
00:59:08.804 - 01:00:16.236, Speaker F: Can we say anything about local masma? To answer this question, we need to study the geometry of multilinear polynomials. Multilinear polynomials are globally non convex and non concave, which is not useful for optimization. But locally multilinear polynomials are always convex along some directions, while concave on some other directions. So as a result, neither of this ball shaped local minimum nor this local maximum can appear on the surface of multilinear polynomials. The only place which may trap our search is such a saddle shape. But saddle shape is not the worst thing in search because we have a great chance of escaping from it. Formally speaking, if we do not apply our robots constraints on every point, there will always be a direction where we can increase the value, the polynomial value.
01:00:16.236 - 01:00:58.830, Speaker F: But if we impose our bots constraint, then this escaping direction may be towards a boundary. So we may still encounter local maximum along the boundary. Or in other words, local maxima should be on the boundary. So this kind of reveals the discrete nature of our framework, despite of its continuous appearance. So we formalize our intuition by proving that all local matma are almost discrete assignments. So what do I mean by almost discrete? Let's say an example. Now phi is x or y.
01:00:58.830 - 01:01:52.364, Speaker F: Logically speaking, if one of x or y takes value two, then no matter what value the other variable takes, phi should always be true. This also holds in the polynomial world. So now f is the corresponding polynomial. And we can see on the plot that on the blue point, at the blue point we can, we can move the blue points along the axis without changing the polynomial value. So that means we can round the fractional coordinates which does not matter at some specific point. So those points are so called almost discrete. Because if we just reach this point, I think we should stop search and maybe do random restart, because continue searching is not useful at all.
01:01:52.364 - 01:03:22.756, Speaker F: What we proved is that you can start from a fractional point at the beginning, but if you are able to converge to a local maximum, then you will finally end up with the following point where most of the coordinates are discrete, which means they are either plus one or minus one, while a small set of variables are fractional. But we don't care about those variables because changing the values of those variables does not affect the value of the fitness function. In other words, for a local maximum, rounding preserves the objective value. So this somehow gives us some guarantees about the solution quality of local maximum, because runding now does not harm, which is different from the case in both LP and SDP relaxation. Well, rounding t cost loss to the objective. In other words, local maxima are meaningful and they do provide good quality solutions for some more relaxed problem like mat set. I also want to answer the question about how fast can we converge? First of all, I want to emphasize that our framework does not limit anything about which optimizer you should use.
01:03:22.756 - 01:04:32.664, Speaker F: So you can use any optimizer as long as it solves the constraint polynomial optimization problem. But here we will focus on the projected gradient ascent approach. For those who are not familiar with it, it is just general gradient ascent, but projecting the outlier back to the bott's region by finding the nearest point. Sometimes when it happens, the projected gradient will be different than the original gradient. A point is called a critical point if the projected gradient at that point is absolute small. And one of our theorem is that if our framework uses projected gradient descent, then it will always converge to a critical point in polynomial steps. But what does a critical point look like? In most real life cases, critical points are just local maxima which we prove that they have good quality.
01:04:32.664 - 01:05:25.444, Speaker F: But theoretically speaking, a critical point can still be a saddle point. So you can see a gap here. On one hand we prove that local maxima are meaningful, but on the other hand we can only prove that we will converge to a critical point. The reason this step exists is because of a saddle point is a critical point that is not a locomotive optima like this one. Although in real life cases SATA point rarely exists, but in some crafted instances they can appear. For example, those are the gradient plots for absorb constraints. You can see that just at the middle of the boolean bots, saddle point exists where the gradient vanishes.
01:05:25.444 - 01:06:22.804, Speaker F: But practically we observed that our framework seldom converts to such starter points. So an open question we raise here is to prove that our framework does not convert to the start of points with high probability. So till here I think the framework has been introduced. So in this slide I want to tell you some improvements that were made on this framework. In our newest paper where we use a new representation of boolean constraints called binary decision diagram. We use BDD to handle coefficient bounded pseudo boolean constraints. Since the efficiency of computing the gradient is very important for continuous local search, we accelerated the gradient computation by BDD significantly.
01:06:22.804 - 01:07:33.982, Speaker F: Also, we are aware of the fact that inside community converting to a global maximum is much more important than just having a local maximum. So we also used adaptive constraint weighting borrowed from discrete research to get better global convergence. So if you are interested in any topics of those, I encourage you to refer to our newest paper. So it's time to show you some experimental results. The highlight of our framework is its performance on some small size plain madsat computation, where our approach gives the best solution for most cases compared with other mat set solvers. While we also tested our tool on on some real hybrid boolean formulas containing xor and pseudo boolean constraints. Well, we observed that our server is better than discrete load research servers, but it cannot match the performance of state of the art CDCL server or pseudo boolean servers.
01:07:33.982 - 01:08:26.294, Speaker F: Yet. Of course the state of the art servers are well engineered and usually the continuous operation is much more expensive than its discrete counterparts. So we believe that those results already show some great potential of this framework. On large industrial instances, the cost for differentiation is really too expensive, so we need to work on that. All right. In summary, we are motivated by handling constraints that beyond CNF, we want to explore the potential of continuous methods in set and set solving. Our framework exhibits nice theoretical results as well as interesting open questions as a continuous based approach.
01:08:26.294 - 01:09:34.484, Speaker F: In practice, our server can act as a complement to existing solvers. Since the framework can be decomposed into parts, it should benefit from the improvement from each area. For example, tracked both structures of boolean constraints and the techniques in continuous optimization. As for challenges and the future directions, first of all, the fourth gradient is really expensive on industrial benchmarks, so we want to compute imprecise gradients. Second, we also want to learn from discrete research to combine that with our framework to design a solver with better performance. Third, since the neural symbolic approach is really popular now, our solver exhibits good potential of being as a layer of neural network, as a differentiable optimizer. Also, we want to visualize the real value fitness function to see if we can find any insights of different logical formulas.
01:09:34.484 - 01:09:53.484, Speaker F: We also want to connect our algorithm with some well known message passing algorithms like survey propagation, and we will dig more into this. With that, I would like to conclude my talk. Thanks for listening and I'm happy to take questions.
01:09:58.484 - 01:10:04.716, Speaker A: Thank you Zhiy, for a very nice talk. Looks like Jacob has a question, I think.
01:10:04.860 - 01:10:11.344, Speaker F: Yes, please. You mean in chat.
01:10:13.724 - 01:10:18.460, Speaker G: Do I get it right that this is an incomplete method that is good at finding solutions?
01:10:18.612 - 01:10:21.380, Speaker F: It is complete, yeah.
01:10:21.452 - 01:10:35.734, Speaker G: And so did you considering like combining it with some complete method that could do like the unsatisfiability part and maybe you would do the search part or this is on the list of things to do or it doesn't work or.
01:10:36.754 - 01:11:02.694, Speaker F: Yeah, so if you mean by proving unsatisfiability by other completely different methods, yes, of course we can do that. But if you mean proving unsatisfiability by algebraic approach like groups and basis like other approaches, then we think people have done that before, but they fail to scale well. So we haven't done that yet.
01:11:04.794 - 01:11:18.058, Speaker A: But there is, Jacob, there is interesting insight, for example how you look at resolution from this algebraic perspective. So it turns out the resolution here translates to linear operations, right? Gua?
01:11:18.146 - 01:11:19.614, Speaker F: Yes, exactly.
01:11:21.424 - 01:11:25.288, Speaker A: So there is a potential to do to add, for example, kind of inferencing.
01:11:25.456 - 01:11:32.604, Speaker F: Yes, so there is a potential, but it's hard to see how they can be as efficient as resolution currently.
01:11:36.384 - 01:11:37.964, Speaker A: Other questions or comments?
01:11:40.184 - 01:11:41.632, Speaker B: Yeah, I would have a question.
01:11:41.688 - 01:12:05.866, Speaker H: So, like, would it not also make sense to have an imprecise encoding into BDD? So similar like what the hooker and other colleagues from CMU are doing for optimization, like dropping those sort of high degree monomials you have in your four year, because you're only saying here on this conclusion slide sort of imprecise gradient, but you could also do an imprecise, imprecise encoding.
01:12:06.010 - 01:12:32.150, Speaker F: Exactly. So I think using an exact representation of the polynomials corresponds to cut off some nodes of the corresponding BDD. So they are basically the same. It's just a spectrum method with keeping the major component. Okay, I have a quick question.
01:12:32.302 - 01:12:33.274, Speaker A: Yes, Oliver.
01:12:34.334 - 01:13:05.914, Speaker B: So, in the first part, for the basis depending, so you define that expansion expectation depending on that variable a. And then in the second part, as I understand it, you optimize over that a. Now, that expectation looked, did not fully grasp it, but it looked natural to me. But are there alternatives to that, or do you think that's it? So that's the natural choice to that basic definition from the first part.
01:13:07.274 - 01:13:20.426, Speaker F: Well, so is a question about whether we can do better than defining a fitness function based on expectation. Can we use alternative definitions?
01:13:20.610 - 01:13:21.426, Speaker G: Yes.
01:13:21.610 - 01:13:25.378, Speaker F: Yes. So, do you have any comments, Moshe?
01:13:25.466 - 01:13:28.254, Speaker A: No. Maybe even change the probability distribution?
01:13:28.714 - 01:13:54.536, Speaker F: Yes, yes. Those are all promising directions, but we did try several different representations, but the expectation is the most suitable one because it is multilinear, which means it is somehow smooth and. Yeah. So it's a balance between easily computable. Is it computable and precise. Thank you.
01:13:54.680 - 01:14:06.774, Speaker A: So, last question. I'll read the questions from Embry, which is, did we consider to doing parallel search starting from multiple points and then using perhaps the power of GPU's?
01:14:07.114 - 01:14:39.914, Speaker F: Yes, that is definitely a promising direction because our framework exhibits a good potential of that. So, yeah, I believe that the performance of our framework depends on how many trials you're doing, and if we can manage to parallelize it on GPU's, it would be very nice, but since the search contains some logical steps, it's not clear how to do it at this moment.
01:14:42.774 - 01:14:46.254, Speaker A: Okay, well, thank you. Thank you, Ziy, for the presentation.
01:14:46.334 - 01:14:46.574, Speaker F: Thanks.
01:14:46.614 - 01:15:06.796, Speaker A: Thanks for all the questions, and thank Jacob for his patience. And now we are going to switch to Jacob, and the storm has subsided, so I'm more optimistic that we'll be able to finish it. Jacob, would you like to share your slides?
01:15:06.940 - 01:15:10.220, Speaker G: I'm doing my best. Let's see. Do they show up now?
01:15:10.332 - 01:15:11.024, Speaker F: Yep.
01:15:13.724 - 01:15:14.624, Speaker G: Okay.
01:15:15.404 - 01:15:16.304, Speaker A: Okay.
01:15:17.404 - 01:15:18.020, Speaker C: Yes.
01:15:18.132 - 01:15:50.574, Speaker G: Okay. So. Right. Thanks for staying for the final talk. So, I'm Jacob Nordstrom, the University of Copenhagen, Lund University, and I'm going to talk about pseudo Boolean solving as something sitting right in between Sat solving and integer linear programming. So what is pseudo Boolean solving? Maybe the first question, apart from being a cool name. Well, as a theoretician I would call this is just a function over the Boolean hypercube.
01:15:50.574 - 01:16:56.008, Speaker G: Um, and, um, they have, they're well studied in operations research, in interlinear programming. So we are going to be interested in, um, when the pseudo boolean functions are linear functions, and that is enough to express a lot of if you think of your favorite np complete problems, then chances are actually that it can be expressed in linear pseudo Boolean form. And I should say right away that what you'll get now is like a condensed version of, mostly a condensed version of what I did during the summer's bootcamp. So you can view this as a teaser for going to that tutorial and listening to more of the details there. But I'll add some new twists, I guess, especially towards the end, just to convince you that you should stay anyway. So why do we want to do sudo boolean constraints? So, one reason is that it's a much richer format than the CNF format that sat solvers use. I mean, just to say, out of six variables, you want to say that three are true.
01:16:56.008 - 01:18:04.344, Speaker G: That's just one cardinality constraint, as you know, opposed to this mouthful of clauses where it's even hard to see that I didn't do a bug somewhere. I think in earlier versions of these slides I even had bugs and I didn't even see them. And in addition, once you move over to sudo boolean constraints, it turns out that you actually have stronger methods of reasoning than the resolution method that underlies CDCL. Um, and, but, but the bonus is that you're still close enough to sat to look at all the cool ideas that have, uh, appeared in sat solving, and you could try to port them to the pseudo boolean setting. Plus, since you have a zero one integer linear program, and there are lots of interesting ideas in, in the mixed integer linear programming community, you can try to, to take ideas from there as well. Okay, so just to make clear we're on the same page, so suitable. And constraints then will be linear constraints for the rest of this talk where I have integer coefficients, an integer constant term literals, that's just variables or negated variables that take values, true or false.
01:18:04.344 - 01:19:11.468, Speaker G: So one or zero. And in general, like in a suitable Boolean constraint, you could have any way of comparing them, but we will focus on it won't be too important for the talk, but it's like kind of nice when you describe the how you reason with pseudo boolean constraints, and when you implement algorithms to use what's called normalized form, where all of these coefficients and the constant term, they're non negative integers. And the reason that you can do this without loss of generality is that if you have a negative coefficient for xi, you just switch to not xi instead. And in this normalized setting, the constant term is known as the degree or the degree of falsity. Okay, so just to make sure, again, continue our discussion to make sure we're on the same page. So if you have a clauses in CNF, those are just special cases of pseudo Boolean constraints, because you just sum up the literals and want at least one of them to be true. And then we saw that cardinality constraints is an example of a more general class of constraints.
01:19:11.468 - 01:20:16.904, Speaker G: And then you can go wild and have arbitrary coefficients like this constraint, which is like a general pseudo Boolean constraint. And another thing that is nice with sudo Boolean constraints is that you can express a lot of things staying inside this formalism. For instance, sometimes it's useful to have a variable encode the truth value of a constraint, say that I want z to be true precisely when this constraint holds. So the nice thing is that this also I can write as a pair of pseudo Boolean constraints. And I won't go too much into the details, but you can see that just the first line is the easiest one to see here, that this says that if z is true, this forces, indeed forces this constraint to be true. And then if you look at the second line and you think a bit more, then you realize that z, false, will actually force this constraint to be false. So Sudo Boolean constraints are expressive and nice to work with, and what? So the input that we have are then sudo Boolean formulas, just conjunctions of such constraints.
01:20:16.904 - 01:21:06.984, Speaker G: And then we have two problems that I want to discuss with you. And one is just the satisfiability problem, but ported to Sudo Boolean to a pseudo Boolean setting. So this is pseudo Boolean solving. You get a collection of pseudo Boolean constraints and you want to know whether they are satisfiable or whether they're feasible. But another bonus with going to pseudo Boolean form is that you can express optimization problems in a nice and natural way. So you can also have some linear combination of literals weighted by some coefficients wi and that you want to minimize, say without loss of generality. So then the problem becomes that you want to find a satisfying assignment to f and among all such assignments you want to minimize the objective.
01:21:06.984 - 01:22:18.726, Speaker G: So that's the setting, that's the problem that we want to understand. And so what I'm going to tell you a little bit about is how you can do this by using so called sudo Boolean solvers. And I'll then also try to discuss how you can borrow ideas from the SAT side, in particular from Max sat solving and also from mixed integer linear programming. And this is again going to be like more of a brief overview talk or a sales pitch that I think this is something that might be interesting to look more into. And so I'll try to give you some pointers and there are some, some literature references on the slides and they are all available at the end of the slides, which I assume might be somewhere on the Simon's web page later. Or if not, then they will be on my web pages. Okay, so what do you do if you get a sudo Boolean formula? Well, one thing that you can do, since you know and love conflict driven clause running solvers, you just rewrite your sudo boolean constraints to conjunct in normal form and run your favorite SAT solver.
01:22:18.726 - 01:23:16.104, Speaker G: This is one thing you can do. Another approach, which is the one that I've been working more on, is in one sense you want to stay with conflict driven closed learning, but you port your input from Sudo Boolean to CNF. I want to go in the other direction. Mostly I want to stay with the Sudo Boolean format and I want to portray CDCL to a sudo Boolean setting. And in particular, I think there are two solvers that are being actively developed that I know of that are following this approach. And this is sat for J by the team in France and then rounding SaT, which is being developed by our group. So okay, how do you do it? How does CDCL based Sudo Boolean solving work? Well, it's being used because it turns out that it's often a very competitive approach.
01:23:16.104 - 01:24:13.984, Speaker G: And sadly, I have to say from the point of view of so called native sudo Boolean solving, the CDCL based approaches sometimes just beat the crap out of us. And it's interesting to understand why, and I don't fully understand why. So that's an interesting research question. But you can, I mean, it can be noted that when you rewrite the sudo boolean formula to CNF, then you're introducing extension variables. And these extension variables, they mean interesting things and they, so they give you a lot of extra power. And that means that if you have a disjunction over such extension variables, then actually that encodes some kind of polytope if you look at the original problem. So in some sense that we don't really understand it, it gives you a way of doing fairly powerful reasoning just because the variables mean things that you couldn't speak about before in a sudo boolean solver because there was no variable for this thing.
01:24:13.984 - 01:25:23.224, Speaker G: However, in order for this to work, you really want your formula to be encoded in a nice way. So for instance, if I'm evil and I try to permute the variables and the constraints so that they come in a not so natural order, then it seems that the CDCL based approaches take a huge hit in performance. And also for some problems, like say, if you're working on pigeonhole principle formulas, you just have the basic fact that no encoding into CNF can compensate for the fact that CDCL based reasoning is exponentially weaker than pseudo Boolean reasoning for such formulas. And this you can also see sometimes. But there are, I think, a lot of interesting problems. One interesting problem is when you're doing the rewriting, how do you rewrite to CNF in the best possible way? There is a lot of research on this, a lot of different encodings. I don't think we really understand from a rigorous point of view which encodings are good or bad.
01:25:23.224 - 01:26:50.064, Speaker G: Another interesting question is how would you, I'd like to understand better how the CDCL based approaches compare to the cutting planes based approaches that I'm going to discuss briefly next. In particular, they seem to be somewhat complementary, and it would be nice to, well, on the one hand, to theoretically understand what's going on. For instance, could we somehow pin down how helpful these new auxiliary variables are? This I don't understand. And also, I mean, if, if the CDCL based approach is sometimes good, and the cutting planes based approach is sometimes good, then why don't we try to build a solver that somehow tries to do both and get the best of both worlds? I think this would be a nice thing to do. Okay, so moving on to Sudo Boolean conflict driven search. So this is now when I want to keep my input in Sudo Boolean form, but I want to do like the conflict driven search and learning, because I've seen how good that is in sat solving. So do the same thing as in CDCL, but using cutting planes instead of the resolution proof system and operating on pseudo boolean constraints rather than clauses.
01:26:50.064 - 01:27:46.774, Speaker G: So what do I mean by the same thing? Well, we would have the same setup where there is this cycle of assigning, deciding on variables and then making obvious propagations. So you have a decision propagation cycle, and there's a natural way of generalizing what it means for a sudo Boolean constraint to propagate. And right, if a pseudo Boolean constraints will be violated unless I set x to true, then that means that this pseudo Boolean constraint propagate x to true. So I do this decision propagation cycle until I hit the conflict, which is a violated constraint. And then what I want to do is I want to look at all of my propagations that I've made that led to this conflict. I want to look at these constraints and then I want to do conflict analysis and learn a new constraint. But this constraint is going to be pseudoboolean and I'm going to have to use some other form of reasoning than a resolution to do it.
01:27:46.774 - 01:28:23.194, Speaker G: And the reasoning that we're going to use is cutting planes. So cutting planes like traditional cutting planes is this so that we know that all literals are non negative and then we know that we can take positive linear combinations. So Ca and Cb are positive numbers here. And then you have this division rule which just says that. And here I'm using that the constraint is written in normalized form, that all of these coefficients are positive. Then I can just divide by a c and roundup everywhere. So this is like how cutting planes is presented in the proof complexity literature.
01:28:23.194 - 01:28:52.798, Speaker G: Going back to cook et al. But then if you're doing solving, you also want to use the saturation rule. And maybe saturation is easier to see by an example. Also division by an example. So suppose I have this constraint x plus two, y plus four z greater or equal three. Then if I divide by two and round up everywhere, then I get x plus y plus two z greater or equal to. So this is what division does, what saturation does, it says.
01:28:52.798 - 01:29:39.702, Speaker G: Well, I mean if this constraint is satisfied, then having the coefficient four here is clearly overdoing it. Actually three is enough. So if this constraint x plus two y plus four z greater equals three holds, then the same constraint with three z instead also holds. Both of these rules, importantly are using that we know that the variables are integers. So this is like the rest of the rules. This is just linear programming basically. But here you have the boolean rules, and it's nice to have boolean rules if we're going to solve boolean problems, but doing the same thing, but just with suitable boolean constraint that's opening a can of worms.
01:29:39.702 - 01:30:36.074, Speaker G: And I think this is like an area where we could really use more research. The first annoying problem is that if you take this fancy pseudo Boolean solver, but you feed it a CNF formula in the proper pseudo boolean encoding, then everything just collapses to CDCL but with very, very expensive data structures. And this is a major weakness as I see it, something that has been proposed is to try to rewrite your input and see if it could be rewritten to, for instance, cardinality constraints in a better way. And this has been implemented, but it's not actually yet good enough to be used in practice. So, so you really, so one thing, if you, if you're going to use a pseudo boolean solver, you have to pay attention to your encoding. Like don't use the CNF encoding. If your problem is really a CNF problem, then you probably shouldn't be using a sudo boolean solver.
01:30:36.074 - 01:31:12.346, Speaker G: Another problem is that even if you get a nice encoding, we do have examples of where you have zero one integer linear programs where even the linear relaxation is infeasible. So you don't need any boolean reasoning to decide that there is no solution. I mean, just, just linear programming is enough. And this should be very easy for cutting planes reasoning. And still solvers take forever. This is another very annoying fact. A third area of possible improvement is that preprocessing is something that is very important in sat solving.
01:31:12.346 - 01:31:56.820, Speaker G: It's also being used in interlinear programming. But so far the pseudo boolean solvers don't really have it. And this is probably another source of possible improvement. So these are like, I guess saying that I believe there is quite a, a bit of low hanging fruit where you can take insights from either sat solving or interlinear programming. And if you just implement it, then probably sudo Boolean solvers would become much better. Another interesting question is that it turns out that when you're doing this conflict analysis on pseudo Boolean constraints, then many degrees of freedom arise. And again, going into details would be take a lot of time.
01:31:56.820 - 01:32:58.728, Speaker G: So I have to refer you to the tutorial, but there are a lot of like scenarios that a lot of choices that you just didn't have before in CDCL, but with suitable Boolean constraints you do. For instance, I mean in CDCL you're going to do your conflict analysis with resolution period. But in a suitable Boolean setting you could use maybe division, maybe saturation maybe combining them, maybe doing something else. You can massage your pseudo boolean constraints and simplify them in different ways. When you finally decide to learn a constraint, it can be asserting at several different levels. So how far should you back jump? Another thing is, since the coefficients are integers, what kind of precision do you want? Do you want to stay in fixed precision and round when you're overflowing? Do you want to be in arbitrary precision? And just such a basic question of what is a good learned constraint? What is a strong constraint for a clause? This is in some sense obvious. The fewer literals you have in a clause, the stronger it is.
01:32:58.728 - 01:34:17.458, Speaker G: But for a pseudo Boolean constraint, it's like at least two dimensional. On the one hand you have how many variables it involves, but the question is also how the coefficients relate to the degree of falsity. And so you could be in a scenario where you can learn several incomparable constraints, and we don't have a good sense of which one is the best one. And there are also interesting theoretical questions about understanding different subsystem of cutting planes. For instance, how does cutting planes with division compare to cutting planes using saturation? Lots of room for improving our understanding there. But still, I mean, these solvers do work well in the sense that there are a lot of if you have a decision problem, and if it's natural to encode in pseudoboolean form, then we do have lots of examples where pseudo boolean solvers are clearly stronger than CDCL solvers, not just pigeonhole principle formulas would be like the obvious toy example, but also lots of other examples. Going further, from decision problems to optimization problems, we can borrow ideas from Max sat.
01:34:17.458 - 01:35:05.944, Speaker G: So one obvious way to do optimization is just linear search. So you run your solver and you want to minimize this objective function, say sum of wi li for literature. Just run the solver, find a solution, and then you add a constraint saying now I want something better, I want something smaller than what you found, and run the solver again and keep going until the formula is unsatisfiable, at which point you know you found an optimal solution. This is like simple, but it works reasonably well. In particular, you can often get a decent solution quickly, which might be interesting in applied scenarios where you actually not interested in solving to optimality. But maybe you have limited time and you want some decent solution quickly. And linear search can be good.
01:35:05.944 - 01:36:01.194, Speaker G: But of course the downside is that you don't know how good your solution is, because you have no idea of what the matching lower bound might be another interesting idea, also from Maxat, is like the dual is to do core guided search. So now you say, ok, here's my objective, let's be optimistic. The best possible scenario here would be that it's possible to set all literals to zero, that we give the minimum zero. I'm assuming again here that all the WI's are non negative, so I'll just assume this. I'll run my solver with assumptions. So pre made decisions for setting the whole objective function to zero, and now one or two things can happen. Either this works out and then I've clearly found the optimal solution, or it doesn't, and then I learn the reason why that, you know, maybe some collection of these literals, at least a of them, have to be true.
01:36:01.194 - 01:37:22.094, Speaker G: And then I can use this to update my estimate of what the best possible solution is. And I can actually also rewrite the objective function by introducing new variables and run from the top again and keep going until I find an optimal solution, which will be when my, when in my rewritten objective function, I can set everything to zero, then I know I have the optimal value, and then I have sort of computed how much I changed my objective during this rewriting. So this means that I work with lower bounds, and it can, turns out that it can be helpful to get good lower bounds, because this helps to cut off the search space. You know, it cuts off places where there's no reason to go. The downside is obviously that you don't find a solution until you have the optimal solution, and you don't know for that reason, you don't know how good your lower bound is. So then what if we try to combine linear search and core guided search? Wouldn't that be nice? And it turns out that yes, it would be. And the nice thing compared to Maxat is that this is much, much cleaner and simpler to do in a Sudo boolean setting.
01:37:22.094 - 01:38:19.194, Speaker G: So this is something that we did and had in AAA just a few weeks ago. So here for comparison, here are two good sudo boolean solvers, sats, four J, and then the CDCL based solver naps. And here are different versions, different combinations of sudo Boolean solving with core guided search and linear search interleaved. And if you compare, like these rows and the rows down here, you can see that there are overall, like, significant improvements. Sadly, however, we're not beating the academic MIP solver skip. I'll get back to that in a minute. So what's up with MIP solvers? So, MIP solvers actually solve a much more general problem.
01:38:19.194 - 01:39:18.534, Speaker G: So then you have, some of the variables will be integral and not necessarily Boolean, and other variables will be real valued, except as a special case. If you don't have any real valued variables, then you have an integer linear program. And if in addition all of these variables are bounded between zero and one, then you have a zero one integer linear program, which is just another name for the pseudo boolean formulas that we started with. And if you want to do pseudoboolean solving, then you just do you give a vacuous objective function. But it turns out that MIP solvers are not so good for decision problems. They somehow, they really use the objective function heavily to guide the search. So we actually have, it's not so hard to find decision problems where sudo Boolean solvers will beat MIP solvers, but finding optimization problems where sudo boolean solvers are better, that is not so easy.
01:39:18.534 - 01:40:09.854, Speaker G: So what MIP solvers do is, again, they have, as I already said, they have preprocessing, which is important. And then they work by not trying to find boolean solutions, but instead they relax the problem, solve linear programming relaxations, and then try to use that to store information about how good or bad the solution can be. And then they use something that's called branch and bound, and they also derive new integer linear inequalities that rule out solutions to the relaxation that are not integral. And this is something that's called branch and cut. And then you combine this with lots and lots of heuristics.
01:40:10.354 - 01:40:10.890, Speaker F: Okay?
01:40:10.962 - 01:40:55.104, Speaker G: So if you compare to sudo Boolean solvers, pseudoboolean solvers have really good conflict analysis. But as I already mentioned, they are not great. Even on some problems where the LP relaxation is infeasible, they still run forever. This is a scenario where MIP solvers would terminate immediately, because they solve just in the very first root node. They solve the LP relaxation, they see that it's infeasible, they terminate immediately. Okay, so mixed integer linear programming solvers have powerful search. They use the LP relaxations, they have lots of different ways of adding constraints, but when you show infeasibility, then they basically just backtrack.
01:40:55.104 - 01:41:41.074, Speaker G: So this suggests that why don't we try to get the best of both worlds. We use the powerful search of MIP and then the sophisticated conflict analysis of sudo boolean solvers. Okay, this sounds great. It's easier said than done, but we have done this. So what we did, we took our solver roundingsat and integrated it with the LP solver soplex from this MIP solver skip, and then you can add different bells and whistles. You can also take these gomory cuts that are computed to rule out LP relaxation solutions. You can also ask the sudo boolean solver to share the constraints that it learns during conflict analysis to send them to the LP solver.
01:41:41.074 - 01:42:49.544, Speaker G: And when we run this on knapsack problems, then we see that all of these techniques here is the base rounding set, and all of these techniques really make the solver significantly better, although we're still not beating SCip. But in fairness, it should be said also that MIP solvers have a lot of special purpose methods to detect and solve knapsack constraints with, for instance, dynamic programming. And we don't do that, we're just running our standard conflict driven search here. Let's compare to some other benchmarks. So if we look at the sudo boolean competition benchmarks, decision and optimization instances, and some Miplib instances, again, decision and optimization problems, then, well, I guess we don't get the performance that we were hoping for. But at least the hybrid solver is always second best. So like, if you had to pick one solver, then you shouldn't pick the pseudo boolean solver, you shouldn't pick the MIP solver, you should pick our hybrid because it's always like reasonably good.
01:42:49.544 - 01:44:06.964, Speaker G: Although it would have been nicer if it, I mean, clearly you could also make the argument that if you care about optimization, then still it seems like MIP solvers are winning. So, but this is, I think it's before we conclude from this that sudo Boolean solvers are hopeless, it should be noted that there's been tons and tons of manures invested in coding up fine tuning MIP solvers. There are huge industrial solvers, and pseudo Boolean solving is really, in comparison, not at all that well explored. So I would argue that the fact that you can get this good results with so limited effort, to me this shows that I think pseudo Boolean solvers is something we should look more deeply into. And there are lots of interesting problems one could look at how to interact between the linear programming solver and the PB solver, how to make the pseudo boolean solver use information from the LP relaxations, for instance, that we don't do. I already mentioned that. Why don't we use preprocessing? In particular, we could take the MIP presolving techniques that work in a pseudo boolean setting and tag them on.
01:44:06.964 - 01:44:57.882, Speaker G: So this is you have to be a little bit careful because some mips solving techniques will change zero one integer linear programming problems into other types of problems. But it should be possible to deal with this. Another interesting fact is that you have a wide, like a rich library of different cut rules that you could in principle plug into Sudo Boolean conflict analysis and see if something better pops out. This is something that I really would like to do. And now this is like, ends where I was in my tutorial, and after the tutorial during the boot camp, I basically got questions saying that, nice. But, you know, why would any sane person actually do pseudo Boolean solving? So then I realized that I was maybe underselling a little bit. So I want, you know, for fairness sake, I want to balance the picture and say that there are in fact applications where already sudo Boolean solvers are outperforming even commercial mip solvers.
01:44:57.882 - 01:45:56.564, Speaker G: You just take a standard pseudo Boolean solver off the shelf and for instance, for problems like arithmetic circuit verification, it turns out that pseudo Boolean solvers are state of the art. Some people in Glasgow matching, doing some kind of matching problems for children with adopted families, apparently they take the same problems and they run our solver instead. It's order of magnitude better than the MIP solvers. They used another nice application area, which might be interesting for people who work on this, neural networks, in particular, binarized neural networks. The issue with those is you get a lot of reified constraints for the activation functions, and those are really, they're really killing MIP solvers, because when you relax them, they get very uninformative. But pseudo Boolean solvers deal really nicely with these reified constraints. So again, we see like, just off the shelf order magnitude performance and improvement compared to MIP.
01:45:56.564 - 01:46:59.050, Speaker G: Okay, so this concludes my sales pitch. So I guess what I wanted to say is, sudo Boolean optimization is it's an expressive and powerful framework, but it's close enough to sat that you can use all your favorite ideas from SAT. You can use ideas from Max Sat in some sense. It can be argued that Max Sat and Sudo Boolean optimization are just two different ways of describing the same problem. I believe that we're very far from exploiting the full power of cutting planes, which is exponentially stronger than what the reasoning that we're using on the SAT side. And I also do believe that we could use a lot of the insights from the mixed integer linear programming literature. And there are certainly, I mean, we're not where we would like to be in terms of performance, because of course we would like to beat the competition, all of them, including the MIP solvers, and we don't.
01:46:59.050 - 01:47:32.246, Speaker G: There are a lot of interesting challenges for how to design the algorithms. Also, efficient implementation is a huge challenge. Like a question like how to propagate sudo Boolean constraints is much more costly than propagating clauses. And this is really slowing down solvers. Also, different reasoning methods. We just don't understand them as well as we understand the resolution proof system underlying CDCL. But we already know that there are applications where off the shelf cutting planes based solvers are beating the competition.
01:47:32.246 - 01:47:47.814, Speaker G: So if you're looking at, for instance, binarized neural networks or something, maybe you should take a look at a sudo boolean solver and see if it can do something, anything for you. So that's it.
01:47:49.114 - 01:48:39.864, Speaker D: Thank you, Jacob. So I'll take the first question. So for resolution is a perfect fit for CDCL, because we know that if you have a set of clauses, you want to eliminate a variable, then you need to, what you do is exactly resolution. So resolution is equivalent to quantifier elimination or variable elimination. What is the corresponding statement? If I have a bunch of pseudo Boolean constraints, I want to do variable elimination. Do we have the same kind of a theorem that will give us the same result that do we have an algorithm does give us an algorithm to eliminate variables, cutting planes, saturations, division and saturation.
01:48:44.484 - 01:48:48.864, Speaker G: I'm not sure. I mean, is my question clear?
01:48:50.884 - 01:49:13.694, Speaker D: I have a set of pseudo Boolean constraints and I want to eliminate a variable and get the exist x such that a set of suitable I want, can I represent it, for example, by set of pseudo Boolean constraints, even is the projection pseudoblion? I suppose so, but I've never seen the theorem that would state what exactly is the projection operation?
01:49:14.874 - 01:49:39.196, Speaker G: I mean, I think the answer is yes, but I'm not sure. It's very interesting. Like, I mean, it's definitely a complete method, right? So you can, you can like eliminate in something I think you could do like the analog of Davis Putnam resolution, but I haven't thought about it in that way, and I don't know, I'm afraid I might not have a good answer. I mean, maybe someone from the audience would have a good answer.
01:49:39.380 - 01:49:58.392, Speaker D: So this is a theoretical result because it's important, because it tells us that the right thing indeed to do when you have a conflict is to generate the conflict clause and it is the resolution. So it gives us also a tight connection between what CDCL does. And, you know, we have a theorem that connects directly to proof complexity.
01:49:58.448 - 01:49:58.736, Speaker G: Okay.
01:49:58.760 - 01:50:17.484, Speaker D: We said it generates basically if you have CDCL plus restar that gives you, and it fails. The resolution proof is going to be of linear, of size, linear, or same size essentially as the search tree. Do we have the same kind of theoretical foundations here?
01:50:18.304 - 01:51:01.344, Speaker G: To some extent, yes, to some extent. I mean, it's definitely the case that if you look at what the pseudobulin solars are doing, they will spit out cutting planes proofs in exactly the same way as a CDCL solver produces a resolution proof. And this is a complete method. So one big difference is that for CDCL, we have the theoretical result saying that assuming that your heuristics are somehow magically optimal, then conflict driven clause learning with restarts is never more than polynomially worse than resolution. So CDCL searches efficiently for resolution proofs. This is false. In a sudo boolean setting, we are not searching efficiently for coming planes proofs.
01:51:02.244 - 01:51:11.464, Speaker D: Okay, that's important insight. Thank you. Other questions? Are there any questions on the charts? Let me check the chat.
01:51:14.044 - 01:51:15.224, Speaker H: Yeah, I have one.
01:51:15.604 - 01:51:16.418, Speaker G: Yeah.
01:51:16.596 - 01:51:42.238, Speaker H: So this mip, you see, it looks to me like. Look ahead, right? Like the thing what Marine was explaining. You spend lots of time and every search node and the, of course, your PB solver does the opposite. It's more like city cells. So the obvious question is, of course, like, just do what we did right with this cube and conquer. But for PB. And related to that, are there incremental PB solvers? Because this is something where we need to.
01:51:42.238 - 01:51:43.954, Speaker H: What is cubing? Conquer, actually?
01:51:46.654 - 01:52:34.226, Speaker G: You mean increment? I think that the answer is that all that needs to be done in that setting could be done, but maybe it isn't as well developed in the sense of having a standard library or API for how to do this. And this is probably something that we should do. Yeah. I think it's interesting to note, like, the parallels with moraine stock. I was, as I was listening to it, it's very similar in philosophy, but it's slightly different in the. So one thing that, I mean, also, MIP soloists would have this kind of thing where they probe variables and collect statistics. I think they call this strong branching, except that they actually consider this to be too expensive, I think.
01:52:34.226 - 01:53:39.534, Speaker G: So they do this strong branching at the start, but then when you've been running for a while, they collect statistics of how, how this branching worked out. And based on this, they make estimates of what's going to happen in the future. And this is something that they call pseudo costs. So this is like an interesting question, whether you would do look ahead solving and not do full probing, but sort of do intelligent guesses based on how things have been performing previously. That would be porting MIP techniques into look ahead, but I don't know how expensive the look ahead step is. And then another thing that is nice. I mean, I think there's a lot of questions to explore at the interface of pseudo Boolean solving and MIP solving, but the fact that you can, when you find a solution, but it's like you relax the problem, you find a rational solution that you can add a new cut, which is a sound constraint that cuts away this rational solution and so tightens your polytope.
01:53:39.534 - 01:54:22.514, Speaker G: This is important. And this, we see that, as I showed in some of the experiments, this can really improve performance. Another thing that can improve performance is when we're somewhere in the middle of the search and we're asking the LP solver. So the sudo Boolean solver cannot see the contradiction, but the residual LP is already infeasible. In that case, a MIP solver can help us by seeing a, that it is infeasible, and B, by Farkas Lemma, it returns a conflict constraint so that we can, like, you know, fast forward the conflict analysis. And this turns out to be, these constraints are apparently like super useful. But it's an interesting question.
01:54:22.514 - 01:54:24.076, Speaker G: Yeah, I don't.
01:54:24.260 - 01:54:31.084, Speaker H: Your experiments look like you would import like a MIP technology into PB solver. Right. But this tubing conquer turns it around.
01:54:31.164 - 01:54:31.380, Speaker C: Right.
01:54:31.412 - 01:54:37.468, Speaker H: So you would use a PB approach and then one point switch to BB. That's what I'm asking.
01:54:37.636 - 01:55:27.524, Speaker G: Yeah, that, that's I. Yeah, that's interesting. I think so. One problem has been to explain how suitable in conflict analysis works and the fact that it is exponentially more powerful. This is somehow a message that is hard to get across, but I think it's slowly sinking in and that it's more like, I think there are people on the MIP side that would like to do sudo boolean conflict analysis, but the question is whether it will happen. Because there's, you know, I mean, there's so many interesting questions to pursue, but yeah, that's definitely like taking, what we have done is like, the PB solver is clearly the master and the LP solver is the slave. You could turn this relationship around and let the conflict analysis be the slave.
01:55:27.524 - 01:55:31.244, Speaker G: Yeah, this is definitely something that I'd like to do.
01:55:32.224 - 01:55:33.804, Speaker D: Mikael, do you have a question?
01:55:40.184 - 01:56:31.034, Speaker G: So there's this. Is this approach similar to Sat modulo integer linear arithmetic in the SMT setting? Yes and no. I think it's stronger in the sense that since we're operating on the linear constraint, I think in an SMT setting, you would be restricted to deriving facts that you can express in the variables that you have. You have variables that mean certain things and you can derive facts about those. But now, when we are massaging, our linear constraints will generate tons and tons of new linear constraints. So, like, in an SMT setting, this would correspond to, I guess, you know, generating a lot of extension variables, which I don't think the SMT solvers do. So in that sense, I think it's slightly orthogonal.
01:56:33.094 - 01:56:34.714, Speaker D: Thomas, do you have a question?
01:56:41.874 - 01:57:38.920, Speaker G: If someone decides to encode a given pseudo boolean formula into CNF, is there any known worst case upper bounds? Regarding spa, there are lots of results on how to do this. Yeah, I mean, you can do it efficiently. There are two parameters that you trade off, the encoding size and the propagation strength. And this has, I mean, there's a, this is a research area. And in the tutorial, I have, like some, some references for this, but there's still room for, like, the theoretical results don't perfectly match what people actually use in practice, and there's probably room for improvement. Any last question Sibylla asks regarding back jumping, would chronological backtracking similar to chronological CDCL works not jump to any asserting level? In some sense, yes. So we don't know in sudo Boolean solvers that we're back jumping to the right level.
01:57:38.920 - 01:57:56.364, Speaker G: So in some sense, all the extra hacks needed to make CDCL work in a chronological setting. In some sense, I would argue most of them are already there in a pseudo Boolean setting, because we already need to deal with these problems. If that's an answer to the question.
01:57:57.964 - 01:58:01.100, Speaker D: Okay, we got all the questions answered. Thank you, Jacob.
01:58:01.132 - 01:58:02.508, Speaker F: I think we had a great session.
01:58:02.556 - 01:58:21.584, Speaker D: On three different approaches to non CDC and solving. So I will close the session. And we didn't even lose power. Some of them must have optimized the power appropriately. So close the session, we'll see you all. Let's thank all the speakers, and we'll see you all next week. Bye bye.
01:58:21.584 - 01:58:22.744, Speaker D: It.

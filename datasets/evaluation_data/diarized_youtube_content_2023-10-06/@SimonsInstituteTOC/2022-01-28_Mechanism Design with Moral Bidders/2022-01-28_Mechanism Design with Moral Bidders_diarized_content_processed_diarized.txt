00:00:00.880 - 00:00:45.356, Speaker A: This is a joint work with Shahad Obczynski, and I'm going to tell you today about mechanism design with mold builders. Many of the works in growth mix mechanism design look for truthful mechanisms. These are mechanisms in which we incentivize the bidders to report the true valuations. The underlying assumption here is that if we don't incentivize the bidders to report the true valuations, then whenever they can profit from lying, they are going to lie. But is it really the case? Research from behavioral economics suggest that it's not necessarily the situation in a very cool experiment, Fischer bar informing asked participants to roll six tied dice in a cup and report the result. The payoff of the participants was determined as a function of the number that they reported. So the higher the number, the higher the payoff.
00:00:45.356 - 00:01:40.250, Speaker A: Now only the participants saw the number that they rolled. So in principle they could always report six and collect the maximum payoff. What's nice about this experiment is that even though we cannot tell if a certain individual lied or not on the aggregate, we can't tell how much the distribution of reported values is different than the distribution of values we expect to get from a fair die. This experiment was done many, many times, different populations, different abbreviations, and in 2019, Abel et al published a meta analysis including Nike papers and there is the following conclusion. Participants only collect about 25% of the potential gains from lying, so they don't say six all the time. The following graph is taken from a website accompanying this meta analysis and this includes all data from experiments that were ran in Israel. So different colors correspond to different experiments.
00:01:40.250 - 00:02:37.820, Speaker A: On the x axis we have the value reported on the y axis, the percentage of people reporting it, and the dashed line is the line of one six. So what we expect to see if people report truthfully, and it's pretty clear here that one and two are underreported, while four, five and six are overreported, and especially five is overreported, so people do not lie to the full extent. A couple of explanations that could explain this phenomenon are first, that there is some cognitive cost for lying and second, this idea of social identity. So this means that we care about our perception by others, even strangers, and by our own self perception, and to keep our social identity in line with our moral standards. Then we will try to refrain from lying as much as possible. Another experiment about lying, which is more related to the setting we are interested in, was run by Uruguay in zero five. In this experiment there are two participants.
00:02:37.820 - 00:03:07.732, Speaker A: One plays the role of the sender and the other plays the role of the receiver. Now, the receiver needs to choose one of two alternatives, either a or b. And only the sender knows the payoff for each alternative. So for example here for alternative a, the sender will get five and the receiver will get six. And for alternative b, sender will get six and receiver will get five. Now, based on this information, the sender chooses which message to send. So she can either choose to send a message.
00:03:07.732 - 00:03:38.746, Speaker A: Option b will earn you more money than option a or the opposite message. And now the receiver makes a choice and the paper is realized according to the chosen alternative. Now, 80% of the sellers actually believe that the recommendations will be followed in all treatments. The option that gives more money to the receiver is option a. So when the seller recommends option a, this is telling the truth. And when the sender recommends option b, this is lying. In this experiment, they did three treatments.
00:03:38.746 - 00:04:16.314, Speaker A: So here are the different alternatives in the three treatments. In the first alternative, which is the one we just considered, then 36% of descenders lied. So they recommended option b. And this is a fairly symmetric treatment in which there's not too much to gain by lying. The second treatment, only 17% lied. So now again, the sender has relatively not so much to gain by lying, but the receiver can lose a lot, so just 17% lied. And in the last alternative, when there is a lot to gain from lying, 52% lied.
00:04:16.314 - 00:05:01.024, Speaker A: And what we conclude for this? That when the benefit from lying is smaller than the receivers loss, then senders tend to lie less. From the experiments we presented and other related experiments, we can conclude two behavioral assumptions. First of all, individuals have a preference for tooth telling. We can see this in the first experiment where people do not lie to the full possible extent. Second, individuals care about the damages to others. So in the second experiment, when the damage to others was high, people refrain much more from lying. In this paper, we refer to people obeying these two assumptions as moral bidders and define mechanisms in which they will report their two valuations.
00:05:01.024 - 00:05:44.864, Speaker A: The channel here is that a player will only lie if his profit from lying is larger than alpha times the sum of losses of the other players. And alpha here is a parameter between zero and one, capturing the extent of, say, morality of the bidder. Let me tell you about our mechanism a bit more formally. So, the setting we consider is a single item. There is one item that we need to allocate to one of the players, or we could choose not to allocate it at all. We consider deterministic mechanisms that are both individually rational, so the payoff of the beaters has to be non negative and no positive transfers. The mechanisms cannot pay the bills.
00:05:44.864 - 00:06:42.924, Speaker A: Now formally, a mechanism is a pair of f, and a location function gets the player value for the items and returns the identity of the player that the item will be allocated. Or it can choose not to allocate the item at all. And a payment function returns each player the payment that it should pay. So a mechanism is alpha model. If in every instance, v one through v one vn, v one through vn, for every player I and v I, such that player I can increase his profit by lying, so pocketing a different value, v prime I, his profit from lying has to be at most alpha times the sum of losses of the others from the lie. So let me walk you through the notation here. This is the profit of player I, that its true value is vi for reporting a different value, v prime I.
00:06:42.924 - 00:07:39.352, Speaker A: So this difference is the profit from lying, and we want this to be less than alpha times the losses of the other players. A couple of things to note about our mechanisms. So first, a twofold mechanism is zero model. So if you put zero here, this would mean that the profit from n, any lie, has to be less than or equal to zero, so the player cannot profit from lying. Second, the assumption for preference for truth telling appears here in that the bidders measure gains and losses with respect to truth stunning, which is considered the default options here. It is important to note that our bidders are not altruistic. They do care about maximizing their own payoff only when the bidders need to decide whether to lie or not in order to increase their payoff.
00:07:39.352 - 00:08:26.984, Speaker A: They compare the benefit from lying versus the damages that they will inflict upon others. This behavioral assumption fits better situations in which the beaters know each other. Think, for example, about an academic department that needs to decide who will get some expensive piece of equipment. So for example a microscope. Then probably people will have harder time lying and saying that they have a high value for this equipment when they know that other people need them more than they do. I want to demonstrate how moral mechanisms work using two examples. First, we will see that moral mechanisms can be used to implement the same allocation function as a total mechanism, but with different payment functions.
00:08:26.984 - 00:09:29.654, Speaker A: So here we consider the natural mechanism that allocates the item to the player with the highest value, and a tousl mechanism can only implement this allocation function by charging the highest value below the critical price, which is the second highest value. Mall mechanisms, on the other hand, have much more flexibility. And we can see that the mall mechanism can, for example, charge the highest players the highest value of player half of the second highest value. So we will show that this mechanism is one moral. So let me just remind you what we need to show for one more mechanism. We need to show that the profit of each player of a player for line, if this is positive, is at most the sum of losses of the other players from the line. Okay? So let's use vk to denote the value of the player with the maximal value, and vj denote the player the value of the player with the second highest value.
00:09:29.654 - 00:10:17.154, Speaker A: It is easy to see that player k cannot lie to increase its profit, since the value that it reports doesn't affect his profit and he is already winning. A player that can affect his profit is some player I that may be able to increase his profit by reporting VK plus Epsilon. By doing so, this player will become the highest value player. Okay, now let's see if in a more mechanism, the player I could do this. So what we require is that the profit of player I from this lie, which is this. Okay, so if player I would support vk plus one, you will get the item for a value of vi, and the second highest value will be vk. So this would be his payment.
00:10:17.154 - 00:11:06.404, Speaker A: And we require this to be less than equal. Then the profit that player k had for getting the item which is vk minus vj over two. And this inequality indeed holds, since vk is the highest value. So this mechanism is one moral mechanism. The second example we will see demonstrates that moral mechanisms can implement allocation functions that cannot be implemented by tools for mechanisms. In particular, we observe that the allocation function of a moral mechanism doesn't have to be monotone. Recall that the monotone location function is one in which if player I won the item when reporting vi, he will also win it by reporting any value greater than vi.
00:11:06.404 - 00:11:54.884, Speaker A: And the famous characterization tells us that when we allocate a single item, then we can only implement monoton allocation functions by a truthful mechanism. Okay, so what we will see now is a non monotone allocation function that can be implemented by a one over mechanism. So the allocation function is given by the following picture. So here, this is the value of player one, and these are the values of pL2. The green area, the gray areas, are areas in which we don't allocate the item at all. So when v two is less than one, 10th and v one is less than one, we don't allocate the item at all. Blue area, we allocate the item to player one.
00:11:54.884 - 00:12:23.734, Speaker A: And in this case, we charge player one one. And then we allocate the item to pL2 and charge zero. So we allocate the item to pL2 only in the case that v one equals eleven over ten. Now this is obviously. This allocation function is obviously non monotone. Since if we are here. Sorry, if we are here, yeah, and player one increases his value to eleven over ten.
00:12:23.734 - 00:13:05.834, Speaker A: Then suddenly he doesn't get the item anymore. Okay, so let's see why this mechanism is one model. First of all, if we are in the gray area or blue area, then it's relatively easy to see that player one cannot gain anything by lying. So if we are in the blue area, then player one is already getting the item and his price is one. So misreporting its value wouldn't change that. If we are in the gray area, then player one here could misreport his value for something greater than one. But, and since the payment is one, his payoff would be negative.
00:13:05.834 - 00:13:39.572, Speaker A: The more interesting part is here. When pL2 is allocated so v one equals 1110, we distinguish between two cases. So either v two is less than 110. So we are here. And in this case, player one doesn't want to misreport its value, since by doing so, it will only get the item to be not allocated to anyone at all. So doesn't gain anything from that. If we are in this area, then this is slightly more complicated.
00:13:39.572 - 00:14:15.814, Speaker A: And now we need to compare the profits of player one from misreporting getting to this region versus the loss of pL2. So if player one will misreport its value, his profit will be 110s. Okay, so his value for the item will be 1110 and the payment is one. So this is his profit. This was his profit for telling the truth. And we require this to be less than v two minus zero. Now, since we are in the region where v two is greater than one over ten, then this inequality indeed holds.
00:14:15.814 - 00:15:07.744, Speaker A: And a player that is 1 mol wouldn't misreport his value in this case. So the mechanism we just presented, in which the location function is non monotone, is a one model mechanism. The examples we've just seen demonstrates that model mechanisms extend both the set of bedded allocation and the parent functions supporting them. So my question is whether an auctioneer that only cares about maximizing its own revenue can take advantage of the morality of the bidders in order to increase its revenue. And the answer is that it depends. Let's first see if the auctioneer can increase his revenue by using a different payment function for an allocation function that is also implementable by a TOSL mechanism. The following proposition tells us that it's not the case.
00:15:07.744 - 00:15:54.084, Speaker A: So consider the tosal mechanism m and an alpha molar mechanism m both implementing the same function f. Then we claim that p prime, the price for the alpha moral mechanism is at most p the price, the payment for the total mechanism. And let me give you the gist of the proof. So first of all, we observe that every alpha moral mechanism is payment independent. This means that the price of the winning player doesn't depend on its value. Now let's assume towards contradiction that the price that player I pays in the alpha mall mechanism is greater than the price it pays in the truthful mechanism. This is the price that player I pay when he wins.
00:15:54.084 - 00:16:54.154, Speaker A: Now in the truthful mechanism, we know that the price that the player pays is its critical value. And in the truthful mechanism we also know that we can only implement monotone functions. So this means that player I would win the item in all of these regions. Now, since both mechanisms implement the same function, this means that if I's value is someplace here, then in the alpha model mechanism he will win the atom, but it's going to pay something much greater than his value. So his payoff would be negative, in contradiction to the fact that the mechanism should be individually rational. So we conclude that the auctioneer can not increase its revenue by implementing a function that also implementable by a truthful mechanism. This implies that the only possible benefit of more mechanisms in terms of revenue is when implementing new allocation functions.
00:16:54.154 - 00:18:07.014, Speaker A: Recall that when considering the question of revenue maximization, we assume that the values of the bidders are drawn from distributions that are unknown to the auctioneer. Our results demonstrate that when the player's values are drawn IAD, the auctioneer cannot exploit the beta's morality. However, when the valuations are drawn from a quality distribution, there are cases in which the auctioneer can exploit the morality of the bidders to increase its revenue. More formally, for independent valuations, we show that when the best valuations are drawn IAD from a standard distribution f I will tell you what we mean by standard in the next slide then. For any alpha mole mechanism m, there exists a truthful mechanism and prime that extract at least as much revenue. For quality distributions, we observe that there exists a two player coordinated distribution for which an alpha model mechanism can expect a higher revenue than any truthful mechanism. I will prove that when the betas variations are low on IAD, the revenue of model mechanism cannot be higher than the revenue of total mechanism holds when the distributions are standard.
00:18:07.014 - 00:19:02.414, Speaker A: Standard distributions include uniform distributions and exponential distributions. Formally, these are distributions such that for every value vj greater than vi in the support we have that Fvj is a syst FvI over one plus Fvi. Now, a natural approach for proving such a theorem would be building on myosome characterization of optimal options. Myerson characterized the parent function in terms of the allocation function. Given the characterization, Myerson poof completely ignores the parent function and continues to find the allocation function that maximizes the revenue. This approach inherently fails through molar mechanisms, since we observe that the allocation function of one more mechanism is almost unconstrained. Thus, we need to develop all the machinery required for proving the theorem from scratch, which makes our proof quite complex.
00:19:02.414 - 00:19:56.774, Speaker A: Our proof techniques provide an alternative proof to Myersome characterization of optimal auctions when the values are drawn from independent regular distributions. So we show that the mechanism has to be second price auction with virtual valuations and reserve price. Let me summarize. Our wolf joins the going literature on Google game theory, incorporating behavioral assumptions into well studied settings. Here we developed and analyzed mechanisms for mole builders. Our main result is a constructive proof showing that for standard distributions and values drawn IID mole mechanisms cannot extract more revenue than truthful ones. What's nice about our proof is that as a byproduct, we obtain an alternative proof for Myerson characterization, one that gradually exposes the mechanism for coordinated distributions.
00:19:56.774 - 00:20:37.034, Speaker A: We show that model mechanisms sometimes do extract more revenue and may extract up to twice the revenue of torso ones. Let me mention some open questions. So first of all, it will be great to try to apply our techniques to get a characterization of tofu mechanisms beyond our regular distributions. Also here we focused on the setting of selling a single item. Can we apply more mechanisms to more general settings like combinatorial auctions and more generally? I think that studying other sessions to truthfulness, for example, as a way to circumvent some of the impossibility results in the field could be quite fruitful and developed.

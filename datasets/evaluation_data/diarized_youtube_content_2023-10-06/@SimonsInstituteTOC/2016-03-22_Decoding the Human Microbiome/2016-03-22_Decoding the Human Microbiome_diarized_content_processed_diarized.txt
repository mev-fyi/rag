00:00:02.880 - 00:00:56.222, Speaker A: Thanks so much. It's great to be here to talk about the human microbiome today. Since we have people from a variety of backgrounds, I'm going to start with some introductory information. I also ask that you feel free to interrupt or ask a question during the talk if I'm losing you, because this is complicated stuff, at least from the biological perspective. So we're going to be speaking, speaking about the collection of thousands of different types of microbes, bacteria, archaea, fungi, viruses, that collectively are called the human microbiome. They live in and on our bodies, and about half of the cells in your body come from bacteria, and they're of all different types and have different genomes. Hence their genes outnumber the genes encoded in your human genome by about 100 to one.
00:00:56.222 - 00:02:03.674, Speaker A: And these are not passive bystanders. We know about pathogens, we know that, we're aware of our microbiome when we're sick, but it's also an integral part of our normal biology and health. The microbial cells are integrated with the human. Cells in our organs are secreting, molecules are signaling, are communicating with our cells and with our genetic material, really make us who we are. And yet, not too long ago, everyone, just essentially, including myself, were very focused on the human genome and understanding how it dictated our health, how it encoded disease. But it would be negligent to not consider these other genomes in our bodies, because a lot of the answer to these questions, I would posit, lie in these other genomes that we've had ignored up till now. So why were they ignored up till now? Well, we didn't have a good way to measure them, and that's because the vast majority of these organisms cannot be isolated from the human body and studied in the laboratory by classical microbiological techniques.
00:02:03.674 - 00:02:46.710, Speaker A: However, genomic sequencing gives us a way to footprint or measure what's there by looking at its biomolecules and reading out its sequences. And if we can decode that information, we might understand who's there and what they're doing. This isn't totally new to do this. For over three decades, we've had an approach to go in and target a single gene that's present in every microbial cell. And in particular, the 16s ribosomal rna is a good marker in bacteria and archaea, and it's a gene. We can sequence a little piece of it, target and sequence it. And those pieces are different between, between different species of microbes.
00:02:46.710 - 00:03:55.322, Speaker A: And so by looking at the sequences that we obtain that I'm indicating here by these blue lines and looking at sequence variations in them compared to a reference database, we can make an inference about what organisms are present. But there are some biases and certainly some limitations to this approach, one of which is it doesn't tell us anything about the rest of the genome of these organisms, and its resolution is good to about the genus and maybe the species. But as I'm going to argue today, a lot of the important variation in the human microbiome is at a subspecies level. We have a more recent technique that's just come on the scenes in the last decade to sequence all of the DNA in a sample without this PCR step called shotgun metagenomic sequencing. And I'm showing here a simple microbiome with just two genomes in it, organism and a green organism. And the result of the experiment is, again, little sequencing reads that I'm denoting in blue here, and they're a random sample from across the genomes of the different organisms here. And I'm showing less of them aligned here to the yellow genome because perhaps this is less abundant.
00:03:55.322 - 00:04:27.918, Speaker A: So if I sequence a certain amount, I see more sequences from the pink genome. What's challenging about analyzing this data is that all we get are the blue sequences. We don't know which genome they came from, and there aren't two. There could be thousands in the sample, and we don't know the relative amounts of each one. And so we just have this pool of sequencing reads, and we need to deconvolute it. That's the problem that we work on. So the data is big, and I'm not going to talk too much about algorithms today.
00:04:27.918 - 00:05:09.304, Speaker A: I'm going to talk more about statistics. But there are a lot of major algorithmic challenges in this field that I love to discuss with folks. We have a great need for people thinking about how to handle big data in the field. Essentially, we're using the tools from human genetics and genomics, and the data sets are orders of magnitude bigger and more complicated because they're these complex mixtures. So we're hobbling along. But I spend a lot of time actually thinking about hardware and the network and things like this that we had solved pretty well in human genomics, but they just break completely with these data sets. This is example of the top of a file that we might look at where the sequences are, say, 100 letters long.
00:05:09.304 - 00:06:02.864, Speaker A: I'm not showing all 100 letters there, obviously. And one of these files, which would be the sequences obtained, say, from your saliva after you spat in a test tube for me, would have about 50 million, for example, of these 100 face bear long sequences, these sequences of aces, t's and genes. So that's the data. And I don't know which one comes from which organism or from which gene in those organisms. And the questions, the basic descriptive statistics I would like is I'd like to know which organisms are present and how much of each one. And I'd also like to know what genes are there and how much of each one. So are they not just what kind of microbes do I have, but do they have enzymes to do a particular reaction? Are they secreting a protein that's going to dampen my immune response or elevate it? And so these are the basic quantities that we've been trying to estimate from this data.
00:06:02.864 - 00:06:33.692, Speaker A: Any questions up till there? Because everything follows from this. Okay, awesome. Hopefully you're on board. So here's what's happened in this field. We had no data and until about 2010, and then this experiment started happening. And not surprisingly, people have been doing a lot of experiments. And so we now in public databases, and this is just the SRA, there's some data in Europe that's not in the SRA and vice versa.
00:06:33.692 - 00:07:23.044, Speaker A: But this is one of the major databases, has about 120 terabytes of this data, and it's growing all the time. And the my lab spends a lot of time mining this publicly available data. And quite a few studies have been done in different countries and with individuals who are healthy as well as with various diseases. Most of these have been in Europe and North America. There's been a big cohort study in China, and more recently a couple of studies in individuals in living non industrialized lifestyles, either hunter gatherers or agriculturalists in Africa and Peru. And there's more of this kind of data, as well as these guys, non human primates coming down the pipe. So we will have comparative data, but a lot of it's been case, as in human genetics.
00:07:23.044 - 00:08:37.814, Speaker A: A lot of the field got launched with sort of case control studies of diseases in North America and Europe. So I'm going to show you three troubling results, and that'll be the motivation for what we're going to talk about today. Here's the first one. We got ahold of a bunch of these publicly available datasets, and we did a meta analysis where we asked whether this result that Ruth Le published showing that obese individuals had more of this particular phylum of bacteria called firmicutes than lean individuals in the same cohort of college students. We wanted to see how that held out across other publicly available data. And disturbingly, there was no consistent association with obesity, so the result didn't replicate, including, maybe in some of the studies, a trend in the opposite direction. But what I actually want to focus on today is what I found more shocking, which was that this biomarker, the amount of this particular bacteria, differed from about 80% on average, and this study to about 20%, on average, of the sequencing library in this other study.
00:08:37.814 - 00:09:25.484, Speaker A: So is that real biology? Do people differ that much in the amount of this particular bacterium consistently between different studies? So this is the human microbiome project. Those are adults living in St. Louis and in San Antonio. These were college students. Is that real biology? Is that an experimental artifact? Is it something about how the data was processed before I got to it and analyzed it together? What's going on? That's pretty striking, that this heavily touted biomarker would be that different across studies. Why? Okay, so that's the first thing. The second thing is, from the human microbiome project in which we were involved, where about 300 adults, healthy adults, have their microbiome sequenced.
00:09:25.484 - 00:09:43.504, Speaker A: And here's the same taxonomic variability. So some people, this yellow, I believe either yellow or the green is. I think the green is the firmicutes. So these guys have almost 80%, and these people here have 20%. So, again, we see huge variability. So maybe that's real. Now, this is within one study, so maybe that's real biology.
00:09:43.504 - 00:10:22.114, Speaker A: Maybe not. And strikingly, though, despite having totally different phyla, I mean, these are very, very evolutionarily distant types of bacteria dominating the yellows versus the greens and these two microbiomes. So each column here is a person, and the colors represent. These are stacked bar charts, and each column is a person, and each color is a type of phylum of bacteria. So despite this huge difference, when we looked at biological pathways, they were totally stable. So does that mean that it doesn't matter what you have, they're all doing the same thing anyway. They're all doing the exact same functions.
00:10:22.114 - 00:10:56.082, Speaker A: And that was sort of the hand wavy argument that was made in the paper, and I didn't by it. That didn't make sense to me. Yeah, yeah. So instead of metagenomes, if you just look in genomes, and so that reveals part of the problem. So jumping ahead a little bit. Part of the problem is these are very coarse descriptions and things like central carbon metabolism. Every organism has them, and so those, even in genomes, are constant.
00:10:56.082 - 00:11:32.476, Speaker A: And so that's part of the problem, this sort of looks more stable than it really is because of the resolution at which things were measured. And that also becomes apparent when you do the experiment that you described. But it doesn't explain everything. So that's part of it. So the question was, is there really functional stability or not, or is this some artifact of the experiment, or of how we analyze the data? And I've just revealed that it was partly an artifact of how we analyzed the data. But there's some other things going on, too. Despite this stability, we did ask if there were any microbial genes that associated with diseases.
00:11:32.476 - 00:12:15.564, Speaker A: So we looked in these case control studies. Here's an example of one where there were individuals with Crohn's disease and healthy individuals. Here there's a column for each person in the study. These are microbial genes, and the color is how much there is. And if we test statistically for differentially abundant genes, ones that are higher or lower in disease than expected, we get some housekeeping genes, the ribosome tRNA, charging central carbon metabolism. These are things that should not be varying. So despite the stability I showed on the previous slide, when you look for the most variable things with the sort of standard tools in the field, they're actually things that we know shouldn't be varying, pointing that there's actually a problem.
00:12:15.564 - 00:12:53.054, Speaker A: And luckily, actually, the solution is sitting here, too. And that's what I'm going to tell you about in a minute. So we've identified a bunch of the reasons why we might get these confusing results from data. A bunch of them have to do with the experiment. These things induce bias, essentially, and cause data to not be comparable across studies or even within study. If the data data were handled differently or generated differently, there's actually a bunch of bias induced by how you quality control the data. When we quality control to remove duplicate reads or bad quality data, we think we're doing a good thing.
00:12:53.054 - 00:13:17.830, Speaker A: But sometimes we actually induce bias there. And then how we actually estimate how much there is of a taxon or of a gene family is really important. So, three different sources of bias. Some of these have been documented in the literature already. Some were known from rna sequencing. For example, the GC bias of reads. You know that the probability of sequencing a read isn't uniform.
00:13:17.830 - 00:13:50.110, Speaker A: It depends on the GC content. So some of these were known. Some of these are things we helped to unearth. But the question is, are they important? So a bias can exist, but if it doesn't have an effect, that's on the scale of the biological variation in the. The data. I mean, it's good to know about, but it wouldn't explain a 20% versus 80% firmicutes in the data set. So are they really, are these biases on that scale or not? And if they are, can they be corrected? So, the experimental biases are actually relatively small.
00:13:50.110 - 00:14:31.638, Speaker A: They're on the order of the bias you would see just from resampling the same person twice. Biological signals tends to swallow these things. So even though there is a DNA extraction bias that preferentially with one of the kits, preferentially amplifies the firmicutes relative to other phyla, it doesn't explain a 20 versus 80% difference. So, the argument we have there is that you should just keep track of these things and you can model them in the downstream statistics and correct for them. The quality control also induces some small biases. And, in fact, since it's very computationally intensive, we're advocating. Maybe you skip this, actually.
00:14:31.638 - 00:15:12.690, Speaker A: I mean, it doesn't necessarily do much harm, but it doesn't do much good either, and it takes up a lot of juice on the computer. So this is sort of also good to know that it's not a mandatory step, interestingly. But what I'm going to focus on is the quantification. So, before doing that, I want to mention, this may sound like a really bad news talk. I'm saying all these things that are wrong in the field, and, in fact, we have published results sort of debunking some of the major papers in the field. But I don't only have bad news today. So, in getting really down in the trenches and understanding what's going on with this data and identifying these error sources, we've also found some opportunities.
00:15:12.690 - 00:15:48.574, Speaker A: So I hope that the talk also has a positive message. So, there's a lot of work. To identify error. We create new tools, computational tools, for this data, which we implement in open source software. We correct our inferences, and we feel like we're getting closer to the truth of what's going on with this data. But in making these tools, we've also been able to ask questions of the data that weren't possible to ask previously. So I have a few examples of that, which I think are sort of the silver lining of this line of research that I actually never intended to spend six or seven years working on.
00:15:48.574 - 00:16:45.040, Speaker A: But we absolutely had to solve these quantification problems before we could do the fun stuff with this data. Okay, a little bit more. So, I'm going to talk about quantification and estimating how much there is of a particular microbe or a particular microbial gene, and why that's really hard with this data. To start that conversation, I want to explain a little more clearly how we go from the data that I showed you, these hundred base pair sequences that are a mixture of random pieces of different genomes, to a summary statistic. So there are a number of different approaches, and they generally do some sort of a homology search of your metagenome. So these are the sequences. Compare them either to a database with lots of sequences, essentially everything that's ever been sequenced before, or to a database of models of what gene families look like.
00:16:45.040 - 00:17:31.838, Speaker A: The models allow you to detect more distant homology. These are things, for example, profile hidden Markov models that describe how a protein family evolves and therefore allow you to detect sequences that look like they come from the family, even if they aren't close enough to any given example from that family you've ever seen before. This is very important because the vast majority of the microbes in one of these samples, even in a person in North America or Europe, have very little homology to anything that we've ever sequenced. There's a ton of dark matter out there still. So these models can be very helpful. But you can also do just an individual sequence comparison. And the, this actually, for short reads, performs better in some situations than this.
00:17:31.838 - 00:18:10.860, Speaker A: So we had a paper talking about when to do which of the different types of search. I'm not going to focus on that today. The output is the number of sequencing reads, the number of these pieces of DNA that match a given gene or a given microbe to a count. So that's the basic data. And it could be one or two or it could be a very big number. Yeah, we do a translated search because of distant homology being really important. The DNA won't match at all a lot of the times, but if you translate the read, you don't know what frame to translate in.
00:18:10.860 - 00:19:01.154, Speaker A: And so there are metagenomic gene finders that essentially consider all six frames and make the most likely ORF out of your sequence. Sequence. Yeah, you can do a DNA search. It's not very powerful. So you get a count. And the question is, is that count comparable across studies and is failure for it to be comparable? Is that going to explain some of the confounding looking results that I showed at the beginning? So how do you compare it even across two genes in the same sample or a microbes? And that's an issue as anyone who's worked on rna seq knows you need to take the counts of reads that map to a gene, and you need to normalize by the length of the gene, right? For example, like a RPKM measurement. And because if it's longer, you expect more reads just by chance.
00:19:01.154 - 00:19:33.708, Speaker A: And some of these genomes are much bigger or smaller than others. So that's a real factor here. And the problem is we don't know their lengths. Those are unknown here. Whereas in transcriptomics on, say, the human or mouse genome, we pretty, pretty much, at least have a much better idea of the lengths. So you want to divide by the length, but you're not sure what that is. And more importantly, are these counts comparable across samples? So here's the standard approach, and then I'm going to explain what the problems are with it.
00:19:33.708 - 00:20:11.880, Speaker A: The standard approach is to take that count. And if you want to compare two microbes or two genes, you would divide by the length if you knew it, and maybe you can estimate it from data that you have seen before. So you take a stab at estimating it. To compare across samples, you need to think about how much you sequenced. One could be sequenced more than another. We know that also from human genomics that you would normalize by your library size by the. If you sequence twice as much, of course you expect twice as many reads to hit the gene, so you want to get a proportion, and this is called relative abundance in the metagenomics literature.
00:20:11.880 - 00:20:59.472, Speaker A: That's the typical thing to do. The problem here, that happens a little bit in human genomics, but not so much, is that the majority of the sequences will not match anything in the database. So we have this huge pile of unmapped reads, and they are a mixture of actual microbial genes that should have mapped. But our database is just insufficient because most of the things there have never been seen before or too distantly related to something we've seen before. But there's also things that I'll just lump together and call contamination in the human microbiome, that's you sequence different amounts of host DNA in certain samples than others. There are laboratory reagents that get into the sequencing library. There's a bunch of other DNA that gets in there that isn't a microbe and shouldn't be considered sort of an unknown category.
00:20:59.472 - 00:21:52.334, Speaker A: So you have a mixture in your unmapped bin of things that are knowable, but you just don't know, and things that shouldn't be in a metagenomic analysis, and we don't know which are which so that unknown category is problematic. And therefore, the statistic that everyone uses, relative abundance, or the percent of classified reads. So I have a count of reads to every gene I normalize by some guess about its length, and then I want to divide by the library size, and then it should be comparable across samples. But the problem is, for little microbes swimming around here, I have different amounts of gray ones in different samples. And for genes, if I cut open these microbes and dump out their genes, then there's some genes that are unknown or unannotated as well, a lot. And gray here is shown as about four tenths of the microbes of the genes. It can be much higher than that.
00:21:52.334 - 00:22:34.788, Speaker A: But along with that, there's also the contamination. And what happens then is, if I calculate relative abundance and I don't include the gray category, all the relative abundance is a compositional statistic. It's, by definition, the relative abundance is sum to one. And so it jacks up, as you would expect, the relative abundance of all the microbes. And therefore, people have tried to correct for that by making a category of all the unmapped reads and calling that gray thing a microbe, essentially. And that might be more than 50% of the reads. But if you include it, you at least aren't biasing these other estimates.
00:22:34.788 - 00:23:27.612, Speaker A: Hopefully, that would pull away the reads that would be increasing the relative abundances unnaturally here. The problem is, if this gray thing also contains hosts reads or laboratory contamination or things that aren't microbes, then you're actually pushing down the relative abundances of everything. And this can induce a bias on the scale of something looking like 20% versus 80% of your library quite easily. So, as the amount of novel things increases, the bias increases to pretty astronomical levels. And so we think that these numbers, these estimates that are commonly used, are just not comparable across samples at all. They may be pretty comparable for two genes in the same sample, but a cross sample is not comparable. There is a great solution, and it is that there are individual genes that every cell has.
00:23:27.612 - 00:24:11.324, Speaker A: I already alluded to 16s, which was targeted and sequenced for many decades, that we and our colleagues have identified several hundred genes that are present in every bacterial genome. They're present and in exactly one copy in every bacterial genome. So there are built in controls that shouldn't be biased. And so what we can do is to try to figure out what's going on at a taxonomic level by using only these genes. So if I just want to know how much of each bacterium I have, I won't use the whole library. I will use only reads that map to this set of taxonomically informative genes. And that is a fixed target size, and we don't have to worry about, therefore, this bar anymore.
00:24:11.324 - 00:24:41.784, Speaker A: We have a measurement that's comparable across samples. So that's the solution for taxa, but it doesn't solve quantifying the amount of a gene, because I'm not using most of the data. Most genes aren't in this set, and these certainly aren't the biologically interesting genes. I have to go back to the rest of the data to solve this problem. So, as the databases get better and more, there's less and less gray in the database. I think that a similar approach might be useful here. Right now, I don't think that's possible.
00:24:41.784 - 00:25:22.904, Speaker A: What we're advocating for is a different statistic that I actually think is more biologically meaningful, which is to try to calculate for a gene the average copy number per cell. So the thought experiment is, if I went in and I randomly sampled a cell, how many copies of the gene would be in there? So half would mean that about half the cells in. In the community have one copy. So I pull one. There's a 50% chance that it has it, or a two would be that compared to one of these universal single copy genes, there's usually two of them. So if the red with the single copy gene, blue, would have a copy number of two. And so we'd like to try to estimate the average genomic copy number.
00:25:22.904 - 00:26:12.654, Speaker A: But as I told you, we don't know which reads come from each organism. So if you're following me, you're now probably thinking, how the heck did she figure out the copy number per cell? Because she has no idea which reads come from which cell. They're all mixed together. How would you deconvolute this? So the reason I want to deconvolute it, or another sort of way of showing the argument I just made, is here, red is this red gene and blue is this blue gene. In this example here, they're equal copy number per cell, and their relative abundances are 50%. If nothing is unmeasured, if I measure everything and their average genomic copy number is one, but here in these cells, red is still one copy number. Blue is two, so there's twice as many, and I get that here.
00:26:12.654 - 00:26:50.724, Speaker A: But the red is only 25% of the reads because there's a green gene in these organisms as well. And so the relative amount of red versus blue depends on green being there. This other gene, the relative abundance shouldn't be changing. I want some quantification that doesn't depend on whether the organism also happens to carry some additional genes or not. I want a measurement that would be comparable and that this average genomic copy number is comparable. Every cell in this example has one, one copy of the red gene. And you can see that red is constant.
00:26:50.724 - 00:27:46.504, Speaker A: It doesn't change when I add two green genes or I increase the amount of the blue genes. So that's why we think this would be a nice statistic. The question is, how the heck do you estimate it? How would you estimate this from this pool of data? The answer was actually in my problem at the beginning of the talk, which was when I tested for differentially abundant genes. I found the ribosome and all these other housekeeping going up and down between samples when I know they shouldn't, because I know every cell has exactly one copy of each of these ribosomal proteins. So those are built in controls that are in every cell that shouldn't be changing. And when I found them changing, I knew I had a problem with quantification. And so, can I fix that problem by looking at how these built in controls basically are varying across samples? And we had this idea at the same time as some folks at Elhanan Borenstein's lab.
00:27:46.504 - 00:28:33.210, Speaker A: And luckily, Elhanan and I met when I gave a talk, and we were preparing our papers in parallel, and they came out last year and they essentially do the exact same thing. So this is one of these great examples where there was an obvious solution and it encouraged us that we had converged on it at the same time that they did. The idea is that there are some genes, there are a few hundred, and we actually winnowed it down to 30, that are the best examples of genes that are in every single cell at exactly one copy. And we determine that from looking at genomes. So we need to continually update this list. As more genomes are sequenced, we may decide one of these 30 isn't so good anymore, or we find another one that's better. But we have a set of genes that should be at one copy number.
00:28:33.210 - 00:29:18.864, Speaker A: So if in a sample I see a lot of reads mapping, then I know that I've got higher coverage of all the genes in that sample. And if I see few reads in a given sample mapping to these single copy, then I know, on average, I have low coverage in that sample. And I can use the reads mapping to these built in controls to normalize. And it turns out what these genes are doing is providing an estimator of the average genome size. So I said that the relative abundance of red goes up and down depending on how many of the green genes I have. As the genomes get bigger, then the amount of reads would be lower just by chance. And so part of our calculation is to look at Rij, which is the amount of reads mapping to a given one of these universal genes.
00:29:18.864 - 00:30:06.328, Speaker A: We, through simulations using genomes, figure out the relationship between that and the actual size of the genomes, which is this constant c that we estimate by simulation. And that's there because they aren't exactly universal or exactly single copy. And then we weight the genes because all 30 don't perform equally well. And we get this estimator of average genome size, which is just about, you can think of it as an indirect measurement of the coverage that I would have of any genome in the sample. And then I can get a statistic, an estimator for the we call RPKG. You can think of it as the copy number per cell that uses these genome equivalents. So that solved the gene quantification problem.
00:30:06.328 - 00:30:43.804, Speaker A: It doesn't give us a relative abundance statistic, but it gives us a statistic that is numeric and comparable across samples and not affected by the unmapped reads, at least not as much. There's a little bias there. So I want to summarize this first part of the talk and tell you our recommendations, essentially for this field. And we have a review coming out describing this in more detail that I'd be happy to share. So keep track of data. There's a lot of sequencing data, as I mentioned, in public repositories. Unfortunately, a lot of the sources of bias have not been tracked, and when they're not, then it's impossible to correct for them in downstream analyses.
00:30:43.804 - 00:31:26.262, Speaker A: So we're making an appeal, appeal for better tracking of data. And I'm actually headed out tonight on a flight to an international meeting where we're trying to get these data standards. Just like any new technology, this field is having to figure out what its sort of minimal data standards are. We need to think about a biologically meaningful parameter. And I would argue that the average genomic copy number is a better measure than relative abundance for genes. Avoid statistics based on the percent reads, which is 90% of the software out there is doing this. And if you're going to do comparisons, of course, process raw data yourself from scratch, because any of the analysis choices made in different studies can definitely introduce bias.
00:31:26.262 - 00:33:07.764, Speaker A: And surprisingly, we recommend for minimal, if any quality control on the data that the bias it induces basically offsets the gain in the quality of the read. So with this advice in hand, we've now analyzed all that publicly available data that I mentioned from twelve different studies in eight countries. About 2000 metagenomes have been sequenced by anybody up till now. And Steve and Nefak, a great student in my lab, has made this web server called meta query, where any of these results can be publicly queried by anybody with their precomputed. And this really democratizes this sort of analysis approach that I'm describing, because anybody working on a particular gene or pathway or microbe can search and find how abundant across people in different parts of the world with different diseases or healthy or other traits, how much of my gene or my pathway or my microbe do they have? And is there an association that I might want to know about? So now, in the remaining few moments, I just want to show you some of the biological, the fun biological results that we've gleaned from this massive meta analysis. So the first one, I think is amazing, and that is that if you take a micro black bacteroides vulgatus, which is probably in all of our guts right now, it has 16 sequence genomes. And each row of this heat map is a person where we've used the reads to quantify the amount of every gene in the genome.
00:33:07.764 - 00:34:00.624, Speaker A: So the columns are the genes in the Vulgatus genome. The color of this bar is where in the world did that person come from? These are just 205 samples here that are mostly from North America and Europe and China. You can see where blue means the gene is present. Present. There's a core part of the genome where everybody's vulgatus has those genes, but the vast majority of the genome is not present in all of these healthy individuals, human microbiomes, their bacteroides vulgatus does not have that gene, as shown by white here. And the average sharing of genes in the strains present in two of these people is, varies from about ten to 50% on this particular analysis. So your bacteroides vulgatus and mine could have 50% of the genes different or more.
00:34:00.624 - 00:34:39.884, Speaker A: And they aren't random genes. A lot of them are very important, for example, in how this microbe metabolizes your diet. Yeah, no, this is metagenome. So I kind of nuanced this. But we've now, like, taken the metagenomic library and deconvoluted it down to the strain level. Gene presence absence for all the prevalent microbes in the human microbiome. Yeah, right.
00:34:39.884 - 00:35:18.924, Speaker A: So we take the 16 genomes that have been sequenced. So you need some whole genomes, and then we ask if there's support in the metagenome for each of the genes in the reference genome to be present. What the method doesn't do is tell you about genes that are in the metagenome, but not in the reference genome. There's another tool called constrains that Eric Allm and colleagues were on that tries to find strains that. And it doesn't exactly do this, but you can kind of tweak it to find the genes that are in your metagenome, but not in the reference. This is back to the reference. So this is an underestimate of the diversity.
00:35:18.924 - 00:36:08.352, Speaker A: And then on top of that, even these core genes have, obviously, mutations in them. So we've quantified every single nucleotide polymorphism in each of these people's metagenomes, and some of them are damaging to the proteins. And I have a postdoc, Nandita Garud, who recently joined, who's looking for signatures of selection in those genes. The next thing that we did was to ask then, for which genes vary the most across different hosts, because you can see there's huge variability. And this should not come as any surprise to the folks who've worked with rna seq. And maybe you were thinking about this when I said that the ribosome was one of the genes that was associated with, associated with Crohn's disease. When you sample sequencing reads, it's a Poisson like or a negative binomial like process where the mean depend, the variance depends on the mean.
00:36:08.352 - 00:36:55.464, Speaker A: And so if I'm going to test, to design a statistical test for the most variable gene families, I need to realize that those are going to be the most abundant ones if I don't consider this mean variance relationship. But that's easy to model. So we designed a test statistic that has a gene specific mean, a study effect, because we want to integrate data across different studies. And even after the best normalization, there might be batch effects in the data. So that's what these are. And then we look at the residual variance that's not explained by the model. So in any individual person's subject s's microbiome, the amount of gene g, the variance not explained as epsilon, and we just take the variance of the residuals from this linear model, and that's our test statistic.
00:36:55.464 - 00:37:19.878, Speaker A: To get a null distribution, we use the negative binomial, which considers this mean variance relationship. So we're essentially testing for genes that are off the line here. So not that are high variance per se, but are higher variance than you would expect given their mean. And that's what this is. So these are the study effects. These are three studies. And you can see there are differences in the mean level of gene genes across study.
00:37:19.878 - 00:38:05.686, Speaker A: These are just batch effects or maybe biological differences between these different people in these different studies. These are the residuals after fitting the model. And we're asking, is there more variance for one gene family compared to another gene family? So this one has low variance, this one has higher variance. And so we've moved from this picture to one where there's the mean variance relationship is adjusted for. It also adjusts for the phylogenetic device of the gene family, because things that are widely spread also tend to be higher variants. And so what happens is something like the ribosome was one of our most variable gene families. After correction, it's no longer, whereas like this biosynthesis pathway was low and it actually increases after correcting for the mean variance relationship.
00:38:05.686 - 00:38:34.082, Speaker A: So this was a low abundant gene that we weren't able to detect that it was actually more variable than we realized. And then this example of type two secretion was changed a little bit by the normalization, but not a lot. So it's not a linear change on everybody. The different gene families are affected differently depending on where they lie on this mean variance relationship. And we think it gives a more biologically meaningful description of variability. We analyze all the genes in all the publicly available data. And these are different pathways.
00:38:34.082 - 00:39:03.194, Speaker A: This gets back to the functional stability question. There are pathways that are very stable, as I'm showing in blue, across different individuals. And these are stacked bar plots of the genes in a given pathway. But even some of these quite stable pathways have parts of the pathway that are variable across hosts. And they aren't just sort of random picks from the pathway diagram. They tend to be particular branches or up at the top or down at the bottom of the pathway. They have biological meaning.
00:39:03.194 - 00:39:43.374, Speaker A: And then there are some very variables, gene families like, for example, methane metabolism. Now we have a quantity we can compare across individuals. And at this level we found associations with phenotypes that were much more meaningful than when we looked at species. So we found almost in the human microbiome project, we looked at every gene family, every pathway, every species, every genus, every taxonomic and functional group that we had quantified and found almost. And there were about three medical record phenotypes on each patient. And we found basically no statistically significant associations with anything. But I think it was a resolution problem.
00:39:43.374 - 00:40:38.634, Speaker A: Once we drill down to strain level in genes, we are finding many associations with host traits. So here's an example in this vulgatus genome that I talked about before where there's a lot of difference between your strains and my strains. This is an operon, a pathway that's encoded by a set of side by side genes in the vulgatus genome that is absent in individuals with higher body mass index, so it's associated with obesity. And here's another pathway in the same genome that's actually associated with lower body mass index, so those associated with being a lean individual. And so our meta query server allows you to look up any of these genes or pathways and find the differences. I thought this was really interesting as we looked in the publicly available data. As I alluded to earlier, they're now individuals from eight different countries, twelve different studies who've had this shotgun experiment done on them.
00:40:38.634 - 00:41:13.920, Speaker A: There are not so many from the southern hemisphere, but we found some really interesting structure. So this is a Google map and I'm showing where the sampling locations were with the red dots. This is the phylogenetic tree of this particular bacterium, eubacterium rectale, built from the strain level data of the ractali in each of these people. So the leaves of the tree are hosts, these are the people whose microbiome were sequenced. The color is what continent the host came from. What you can see is there's a lot of structure for this particular bacterium in the strains. There's a clade here with all the chinese individuals.
00:41:13.920 - 00:41:53.984, Speaker A: The strains in China are different than the strains in other parts of the world. The strains in the southern hemisphere in red and purple tend to be different, and there's essentially two main groups and some subgroups present in Europe and North America, but they're mixed. Like this clade right here is shared between North America and Europe. So this bug gets around, but it doesn't get everywhere because you can see that where people live really has a relationship with the strain that they have. In contrast, this other bacterium, vectoroides uniformis, has a star like phylogeny. It doesn't matter where you are in the world, you could have a strain right now in your body. That's the closest person's strain in the whole world is in China.
00:41:53.984 - 00:42:38.102, Speaker A: And it was not found, however, in the individuals in Peru and Tanzania. So this thing gets around, but only in the industrialized countries. Diet, location, access to medical care, antibiotics, other things are confounded. Here, all of those variables. So we don't know if this is geographic structure, if this is selection based on, say, having taken antibiotics, if it's to do a diet or lifestyle. And that's what we're drilling down to try to figure out. Now, I'm very interested in testing a hypothesis called the hygiene hypothesis, that talks about microbes that are predictable, present in our ancestors, and have been lost in individuals in North America and Europe.
00:42:38.102 - 00:43:22.394, Speaker A: So the opposite of the pattern that I just showed you. And the idea is that we co evolve with many microbes, we've eliminated most of them, and that this might at least partially explain the rise of autoimmune diseases in industrialized countries. We are seeing strong support so far for this hypothesis and our analyses. This is a grad student that I worked with that's in, in South Africa, collecting data from Khoisan hunter gatherers who live a traditional lifestyle, don't have access to dental or medical care. And the majority of the microbes that we found in their oral microbiome were not found. A lot of them were not found in North Americans, and then in the publicly available data here from different countries. These are the percent of the.
00:43:22.394 - 00:43:49.006, Speaker A: This is an estimate of the percent of your microbiome. That's from a speed that's unknown. And you can see, even for most of us, that's around 50%. But if you're one of these individuals living a hunter gatherer lifestyle in Peru, it's much higher. So there is a lot of unknowns, and that's not surprising. Most of the sequences in the database came from an individual from one of these countries. So there's a huge bias in the reference data, and there's a lot of unknown in all of us.
00:43:49.006 - 00:44:49.556, Speaker A: But it looks like these individuals may have lost more of that component and that may be related to autoimmune disease. That's the hypothesis. The last thing I want to show you is that we're not only looking in the human body, we're thinking about the environment, the built environment, the air conditioners, the things in our homes, the soil outside that's putting particulate matter into the air, the plants that have fungi growing on them, that are aerosoling into the air we breathe, and thinking about the distributions of microbes in the natural world, because that affects our health. And for something like the bacteroides uniformis that seems to get around everywhere, the natural world might actually be the source of our microbiome rather than another human. And indeed, we've found a lot of antibiotic resistance genes, for example, seem to come from soil. So Josh Ledoux, who's a postdoc in my lab, has an ecology background, and he's. He does something called niche modeling, where you essentially try to predict where microbes, what the natural distributions of microbes are.
00:44:49.556 - 00:45:42.358, Speaker A: He used it in a kind of fun project to reconstruct what the midwestern United States looked like in terms of microbial, taxonomic, and functional diversity prior to agriculture. So before we wiped out all the tall grass prairie and put in corn and soybeans, what microbes were there. So this is reconstructing an extended ecosystem, but the health relevant application is actually projecting to the future. So these are his maps of the United States. Red means an increase in the amount of these pathogenic fungal allergens, and he can predict, with climate change, increases in some of these very populous states, including California, in particular, fungal allergens as we move into a hotter world. And so I think this is a really interesting application of the method that I just showed. Okay, so to wrap up, we are just scratching the surface.
00:45:42.358 - 00:46:24.334, Speaker A: There's a ridiculous amount of data, and I think a lot of unsolved algorithmic and statistical problems. But I think we're starting to get a handle on understanding the variety that's out there. We've revealed cryptic variation that was completely missed a couple years ago in analyses by being able to drill down to the strain in the species level and revealed this complex ecosystem. And I think this is very exciting, not just from a basic science perspective, but the microbiome. And I didn't show this data today, but the microbiome is very malleable. You might guess that from that map with the star like phylogeny, that some of these microbes can change quite quickly. My strains could be different tomorrow after I get on an airplane or eat a different diet.
00:46:24.334 - 00:47:01.564, Speaker A: That makes the research more complicated. Moving target. Unlike the human genome, which is pretty stable. Modulo cancer. But it's really exciting from a therapeutic perspective, because if it's something we can manipulate, and if it really plays a causal role in our biology and in disease, then it could really change healthcare in the future. So I'm exercising a lot of caution, and our lab has been a bit obnoxious in pointing out all the problems in the field at the moment. But I actually generally feel like there's a lot of hope and that we're just starting to get the tools that we can leverage this data for good in the coming years.
00:47:01.564 - 00:48:01.226, Speaker A: I'd like to thank the folks who did the work, in particular, a great student, Stephen Naefoc, led a lot of the work that I showed, and I also showed results from Josh and Patrick. I alluded to Nindida, who does the population genetics, and Svetlana is working on the hygiene hypothesis and inflammatory bowel disease. So thanks very much, and I'm happy to take questions. Yeah. In every genome, there's about 30,000 bacterial genomes that have been sequenced, and they all have exactly one copy, believe it or not. It's sort of shocking, but there are 30 such genes. 30,000 bacteria have been sequenced so far.
00:48:01.226 - 00:48:29.694, Speaker A: We need to update the list once we have 100,000 genomes to make sure that that's still true. But right now, they appear to be single copy. And the weights that I had were in there empirically to sort of adjust for the fact that in what's out there, they probably aren't perfectly single copy. And we found in simulations that some of them are more reliably single copy than others. So maybe it's like 99.9% of the time, there's exactly one copy, but sometimes there's two. Yeah.
00:48:29.694 - 00:49:27.704, Speaker A: Certain parts of the microbiome are really stable. So your lifetime. So, like anyone who's taken antibiotics ever that has a signature, I can do an unsupervised clustering and find the people who've taken antibiotics versus not, essentially, for a long time. You carry a signature of whether you were born vaginally or by a cesarean birth, whether you were breastfed or bottle fed. Various things that happen. On the other hand, if you go from eating a vegan diet and you eat nothing but meat for 24 hours, the majority of the microbiome changes. So there's a minority component that's very stable and tracks these sort of major disturbances and colonization events throughout your lifetime.
00:49:27.704 - 00:50:15.534, Speaker A: But a lot of it is dynamic. The difference between two people and you, your own microbiome a few years later is about the same. The what? Yeah, it's really important. So in the analyses I was showing, I was using, like, one data point from an individual to do those and then sort of checking if things hold in the other sample. But you need to. You can't sort of throw in two samples on the same person. Yeah, yeah, the methods.
00:50:15.534 - 00:50:33.310, Speaker A: Oh, yeah. So they used a little more than 30. They didn't winnow it down as much, and then they used machine learning to kind of weight the them a bit, in a bit fancier way. And so we. They. The methods are identical, essentially, and actually, we're using their tool a little bit sometimes in my lab, because there's certain things about. It works better.
00:50:33.310 - 00:50:53.634, Speaker A: So you know that. Yeah, it's. They're very equivalent, but they took sort of different approaches. We curated more and modeled less, and they kind of did more machine learning. They did more of a black box. They also tried to account for gc content of the genes, because they're sort of, you know, based on gc content, you get more or less reads. I'm not sure that made a big difference.
00:50:53.634 - 00:51:29.798, Speaker A: When you sort of turn off that feature, it doesn't change the performance too much. But they put that in there. Yeah. So I didn't give a definitive answer, did I? I think it's mostly batch effects. Yeah. So we've tried to go back and analyze it, counting using the methods I described. Most of those studies didn't share their raw data.
00:51:29.798 - 00:52:10.114, Speaker A: They had already processed it enough that we were unable to totally remove the batch effects. So I didn't come back and show you, like, here's the answer, because, actually, that's a problem. Yeah. Yeah. But I believe it's, like, there may be some biological differences, but I think it's mostly bathsheba. Yes. Yeah.
00:52:10.114 - 00:52:59.986, Speaker A: Great question. So, how useful will long reads be? So long reads are really helpful if you want to do assembly. So, everything I described was essentially assembly free. I think there's a lot of value in doing assembly. I think it's been incredibly error prone up until now. The long reads will help, but what I didn't emphasize, but I'll go back to is our gene catalog. So, we have a catalog of 10 million genes that we're using, and these include this IGC integrated gene catalog that Pier Bork's group put together by doing gene level assemblies, including some longer reads of specifically human microbiome samples.
00:52:59.986 - 00:53:56.978, Speaker A: So, not like, bacteria from the ocean and all these things. This is, like, what genes did we find in the human microbiome? This gene catalog is incredibly useful. So I think the big application for the long reads is to improve the reference databases. And then you can short read sequence the samples for a large part, but in less complicated communities with only, like, 20 different types of bacteria or something, then you may. You know, it might be a good idea to assemble whole genomes, because, of course, there's interesting questions you can ask once you have the whole genome assembled about whether genes are, you know, evolving together or things like this. So what would I do? So, we're sequencing some non human primates right now, and we're doing mostly shotgun, but we're doing a little bit of long reads to try to get the gene catalog, because I showed you that people from Tanzania and Peru, hardly any of their genes were in the database. Well, it's worse for chimpanzees or baboons.
00:53:56.978 - 00:54:29.950, Speaker A: There's almost nothing in the database. So we're doing some long reads to make a gene catalog. I think the answer is that both will be useful if you had a fixed amount of money. I think it depends on your scientific goals. But I feel strongly the long reads help assembly, and the assembly is helpful for the gene catalog. Yeah. So it depends a lot on this database.
00:54:29.950 - 00:55:08.744, Speaker A: So we also study the microbes in the ocean and the data, the. It's just less well known what's there. The database is sparser, and so there like 10% or something might map to anything in a database. In the human microbiome, with this good gene catalog, we're getting like 70, 80% mapping now, whereas it was like 20 or 40 a couple years ago. So that's part of why I'm advocating for these gene catalogs. It makes a really big difference to have a good database. Thank you, guys.
00:55:08.744 - 00:55:23.004, Speaker A: Hey. Yeah.

00:00:00.720 - 00:01:11.456, Speaker A: All right, so welcome to part two. Again, I'm talking about multidimensional and nonlinear mechanism design. Today, the main goal is to focus on solving the single agent problems. However, I did not finish one of my agenda items from yesterday, so I'm going to start by finishing that agenda item. To remind you, we were looking at multi to single agent reductions, and we had given a reduction under an assumption of revenue linearity, which was basically saying, if you want to think about an auction, given an allocation rule, which is a complicated function governing the probability that types are served as a function of how strong they are, that auction will always look like a convex combination of very simple mechanisms that are the optimal mechanisms if you're just going to consider an ex ante constraint on the probability service. So, in other words, these complicated mechanisms look like convex combinations of very simple mechanisms, and so their revenue is going to be the convex combination of the revenue of the simple mechanisms. And that's exactly what revenue linearity is saying is.
00:01:11.456 - 00:02:12.964, Speaker A: The revenue is a convex combination of revenue of things that come from convex combinations. Okay? So the focus of today is going to be looking at how to solve mechanism design problems, reducing the multiplayer problem to single player problems. When you don't have this nice revenue linearity property. Meaning if I give you some allocation rule and you want to find the optimal mechanism for that, it will not look like a combination of simple mechanisms that come from these exon depricing problems. Okay, um, so this single agent problem, as I said, it will have a constraint on the entire allocation rule. Uh, to build multiplayer mechanisms from single player mechanisms, we're gonna look at, uh, a method of stochastic weight optimization and see how that allows us to resolve, uh, the. The multiplayer problem.
00:02:12.964 - 00:02:26.158, Speaker A: Um, there'll be no assumptions, and so it'll handle general multidimensional preferences and also general risk aversion or budgets question. Yeah.
00:02:26.246 - 00:02:33.154, Speaker B: So on the easy setting is what's fundamental? Revenue linearity or more the orderability property. Do you think.
00:02:36.294 - 00:03:11.582, Speaker A: So? Revenue linearity implies orderability. Revenue linearity implies orderability. Okay. And the converse is not true, but sort of in a pathological way, so I wouldn't worry about it so much. So I don't think that distinction is very interesting. I would think of them as the same. I want to clear up some questions that I got last time from people after the talk to get us all on the same page.
00:03:11.582 - 00:03:47.734, Speaker A: Okay, so one question is, how do you prove revenue linearity? I have a setting. I'm wondering if it's revenue linear. How do I prove it and I'll give you two answers. One answer is if there's a payment identity, meaning I can tell you the revenue of any mechanism just by looking at its allocation rule. Then it's revenue linear. It has to be, because one way to construct the mechanism of that allocation rule is combination of other mechanisms. And so the only way to do it is the way that it has that same revenue.
00:03:49.354 - 00:03:59.670, Speaker B: Right. Jason, in one good auction case, dependent identity is easy. In these other cases, my guess is.
00:03:59.702 - 00:04:02.754, Speaker A: This is a, I have b on a.
00:04:03.694 - 00:04:13.078, Speaker B: It might take some work to establish, like in a multi attribute, multi. Good thing if you're an identity, you end up doing lots of work to prove it.
00:04:13.126 - 00:04:56.448, Speaker A: I would suspect that's correct. And in the single player question, the so that's correct. And so, which is why I'm going to give you another way to prove revenue linearity. And before doing that, though, I want to point out single dimensional linear preferences have a payment identity. We know that multidimensional preferences do not have a payment identity and even the cases that were revenue linear don't have a payment identity. So I just want to draw you a picture to remind you. We saw, let's see this mechanism which sold with probability one, two.
00:04:56.448 - 00:05:21.254, Speaker A: And so it has an allocation rule that looks like this. And this was, what was it? I forgot what this was. Square root of one half. Good, thanks. So this was the allocation rule y of q. And this was the allocation in type space where this is t t one and this is t two. And you get item one here and item two here.
00:05:21.254 - 00:05:48.404, Speaker A: Okay. We saw another mechanism that had allocation rule, the same allocation rule. And that was, for instance, just cell item one. Right. And that has the exact same allocation rule. If you do this, you get a revenue of square root one half, which is bigger than if you do this, which is a revenue of one half. Same allocation rule, different revenues, no payment identity.
00:05:48.404 - 00:06:13.664, Speaker A: Four, when I write things in terms of these allocation rules. Okay. The other approach is the existence of virtual values. Okay, so what are virtual values? I'm going to get to this much more in the later part of the talk today. This might be a little bit basic.
00:06:13.704 - 00:06:14.912, Speaker B: But is the reason that you don't.
00:06:14.928 - 00:06:46.504, Speaker A: Have a payment identity for multidimensional types? Basically because you're squashing the dimensions down to one dimension for your allocation rule. So you're sort of losing. Yes. And you could define a payment identity in terms of these pictures and then they do have one. If I give you a picture here and I tell you another mechanism has the same picture here in terms of who wins, it has the same revenue. So in terms of these pictures, they have the same revenue, but for composing multiplayer mechanisms from single player mechanisms. This is what I care about.
00:06:46.504 - 00:07:49.054, Speaker A: This stuff doesn't really matter so much, and I need to pay my identity here in order to have this buildup. So why do virtual values tell me that it's revenue linear? So, remember, and we'll get into this in more detail for those of you who know what virtual values are, virtual values. Let me write revenue as the expectation of a virtual value times the probability of service, which is fundamentally a linear. That's linear. So, having written things as a virtual value, I've just written down that the revenue must be linear. Okay? And so we'll talk about more of that later when we develop virtual values for this setting, whereby we'll be able to confirm that this is revenue linear. Okay, good.
00:07:49.054 - 00:08:33.624, Speaker A: So I have another great question about the awful mechanism for the uniform zero one squared, which I talked about, which was basically, you always sell the guy his favorite item, and it essentially looks like uniform prices like this. So basically, this, or convex combinations of these are what optimal mechanisms look like. Okay, another great question, which was, well, this just looks like you're collapsing the multi dimensional type space into a single dimension, which is the agent's value for his favorite object. The answer is yes. And in fact, for the uniform zero one squared case, this is optimal. It's optimal to collapse types to a single dimensional type. It is not generally optimal to do that.
00:08:33.624 - 00:09:25.828, Speaker A: And so the task is to understand when it's generally optimal to collapse the type space to a single dimensional type. Okay? And that's, again, what's going to happen later today, okay? Yes, that's what we did, or what will have to have happened, and we'll prove it today. Okay, the. Before I go into this more complex reduction to get multiplayer mechanisms from single player mechanisms, I want to talk. It's going to be complicated, and you're going to wish we didn't live in that world. Okay? And so I want to tell you that you can approximately not live in that world. In other words, if you're happy to give up a little bit of the optimal revenue, you can stay in the re.
00:09:25.828 - 00:10:22.864, Speaker A: You can basically pretend it was revenue linear and use the marginal revenue mechanism we talked about the other day, and things will be okay. Okay? So I want to tell you how to get approximately ex ante reduction without revenue linearity. And so here's the idea. A marginal revenue based mechanism is one that always looks to every agent like it's a convex combination of the ex ante optimal mechanisms. Okay? So you're not doing funnier things than just convex combining these mechanisms. So even though it would be optimal to do something better for some allocation rule, I'm just going to do the simple thing and take the convex combination of them, okay? And the challenge in understanding how well a marginal revenue mechanism does compared to the optimal mechanism is that the optimal one is not marginal revenue based. It does some complicated thing that's not doing marginal revenue.
00:10:22.864 - 00:11:10.396, Speaker A: So here's the idea. Let's relax the ex post feasibility constraints. So think of this as we had one item to sell. Let's relax the fact we have one item to sell, to sell one item in expectation, so relaxed, expose feasibility to hold ex ante or an expectation. If you do that, then the constraint that one agent poses on the other agents is, well, if he gets it with some ex ante probability, that means you can't give the other agent with that ex ante probability. So that poses an ex anti constraint on the other agent, not an interim constraint. Okay, so the optimal solution to the ex anti relaxation is actually marginal revenue based.
00:11:10.396 - 00:12:09.944, Speaker A: It's going to be only using ex anti pricings in its solution. Every single dimensional linear agent mechanism is marginal revenue based. And that falls because of the payment identity. Because every mechanism revenue comes from the payment identity. They're all marginal revenue based. Okay, what does that mean? That means any approximation result that you prove for single dimensional agents against the ex ante upper bound, the ex anti relaxation will automatically extend to general agents using the, the martial revenue based approach. And it's just, if you use the building blocks of single dimensional agents, and you prove a theorem where the upper bound also uses the building blocks of single dimensional agents, then everything just comes for free.
00:12:09.944 - 00:13:29.442, Speaker A: Okay, so let's suppose you wanted approximations to get arbitrarily close to optimal. If you had a large number of items, like k items, then the ex ante feasibility constraint is very, very close to the ex post feasibility constraint, and your approximation factor goes to one. Okay, that's one answer to your question. I don't have a better understanding of what this benchmark, the ex ante relaxation means, whether it has an economic interpretation. But it's sort of, it's one of those things that would be sort of vacuous in large markets, like it would always be true in large markets, because law of large numbers told age and preferences don't matter because they are coming from a continuum now. And so it would just be true. Okay, so, for instance, the posted pricing or anonymous pricing approximation results that were proven for single dimensional settings automatically extended these settings.
00:13:29.442 - 00:14:29.734, Speaker A: And these were two of the things I nailed out for you in the first slide of the first talk, saying these are the examples of where we get approximation. Okay? So I now want to talk about what I call the interim reduction, or the reduction without revenue linearity, okay? And this reduction comes from a joint paper with sayyid, alai, hufu, nima and azarat. And Seyyid, as I said before, is around. Hufu is going to be here for the semester also, and NeMA is also here for the semester. So if you think this stuff is important and you want to learn more about it, you can talk to any of these guys. You're going to be here all term. Okay? It's very closely related to some recent work by Kai Daskalakis and Weinberg, and it builds upon a lot of the classical auction theory, especially the auction theory for nonlinear preferences like budgets or risk aversion.
00:14:29.734 - 00:15:50.524, Speaker A: And remember, my working example for this interim production was the case of a public budget. There was a reason for that because that's what these original works were talking about. And one of the interesting things about what we did in this paper was he said that the stuff that these tools are using to solve the nonlinear case can also solve multidimensional cases using this framework of the multiplayer single player reduction. Okay, so what's my approach? So I'm going to call a profile of interim allocation constraints, y hat, where this is really just n functions, one for each player, which is the allocation constraint for that player. I'm going to call that profile interim feasible. If there exists some x post allocation rule, which I'm going to denote, y hat Ep, which is actually a function from quantile profiles, so all the types of the players to a feasible outcome, and so X is just some subset of all outcomes that's feasible. This can be anything you want.
00:15:50.524 - 00:16:04.374, Speaker A: Okay, I want you to think for this talk of single item settings. So this is anything that sums to at most one. Okay, just think single item settings when you think feasible here.
00:16:05.114 - 00:16:08.294, Speaker B: So at this point you have an implosion compatibility.
00:16:09.314 - 00:16:53.444, Speaker A: Nope. And in fact, interim feasibility will not consider incentive compatibility at all. The next slide will make it really clear what I'm talking about. Okay, great question. Okay, so what do I mean by this ex post allocation rule induces these interim allocation profiles? It means I can get each profile by taking the expectation of the allocation rule for a quantile profile drawn from the distribution of quantiles, which is always iid uniform zero one. Okay, so I just calculate this, I get allocation rules. This is what it means to be interim feasible.
00:16:53.444 - 00:17:47.154, Speaker A: Okay, here's the theorem. The optimal revenue is given by the following program. I maximize over allocation constraints, profiles of allocation constraints, so one for each player. The optimal revenue I can get from that allocation constraint. Remember, Rev is a revenue operator, takes this constraint and gives you the best revenue of every single player mechanism with that constraint subject to this profile, y hat being interim feasible, meaning there exists some other mechanism that doesn't have to be incentive compatible, but is feasible. Okay, so I'd like to understand what optimizing this program means. Well, first I want to get proof that it's optimal, that this theorem is correct.
00:17:47.154 - 00:17:54.074, Speaker A: Okay? So I'm going to give you intuition for the proof, okay? And then I want to understand what this whole approach is going to mean.
00:17:54.154 - 00:18:18.514, Speaker B: You want to state the background assumptions before you explain. Give us the proof sketch. I mean, what you're basically saying in this theorem is it's okay to throw away capacity. And so this some kind of monotonicity and free disposal things are running around. There's something about objective function, and is it just for auctions? I mean, what class of economic environments is this going for?
00:18:21.854 - 00:18:55.306, Speaker A: I'm in the settings that were examples of which were given last time. So I've got independent private values. Okay, so independence is going to be important here. And I'm, that's basically it. So think independent private value auction settings. Don't think necessarily quasi linear, don't think single dimensional. Could be generally.
00:18:55.306 - 00:19:47.174, Speaker A: Okay, so I'm going to tell you, give you the approach for this theorem from which any of you could just complete the dots and finish the theorem. I'm going to then tell you how to understand this constraint, which is kind of a strange constraint because it has a for all in it, for all mechanism. I mean, it exists a mechanism quantified there. I'm then going to tell you how you can restrict attention to a small class of ex post mechanisms, which is all you have to look at, and they're kind of simple. And so that's a sort of a nice characterization of what these things might look like. And then I'm going to talk very briefly about optimization subject interim feasibility. Okay, so why is this program correct? So first off, this program obviously upper bounds revenue.
00:19:47.174 - 00:20:23.100, Speaker A: Why? Well, any OpTL mechanism has to produce allocation rules that are interim feasible. And also for those allocation rules, it's doing this already, like these are just the mechanism it's producing. Right. So the optimal mechanism is a valid solution to this program. Okay, good. So I want to show the opposite, that the alpha mechanism that is achieved by this program. And notice there's a disconnection between mechanisms that do this and mechanisms that do this.
00:20:23.100 - 00:21:22.364, Speaker A: Right. Because this is what I wanted to solve independently for each player. And this is sort of any ex post feasible thing that had no incentive constraints at all. And so here's the theorem for any x post feasible, but not necessarily incentive compatible allocation rule. So this y hat xp and any profile of incentive compatible but not necessarily x post feasible mechanisms, y. If the x post mechanism induces a profile of constraints y hat and each yi is feasible for the y I hat, okay. Then you can come up with a combined mechanism which has the feasibility of the ex post mechanism and the incentive properties of the interim mechanisms.
00:21:22.364 - 00:22:33.958, Speaker A: Okay? And the main difficulty here is y might not be equal to y hat, y, I might not be equal to y I hatch. That's the main difficulty. And if you recall how I defined the interim pricing problem before, I said, you need to come up with some sigma through which you can map quantiles to put into y hat to get y. And by that definition of the pricing problem, it's exactly, oh, you have some oracle for y hat. How do I turn an oracle for y hat into a mechanism that actually allocates to my agent with allocation for y? And that's what a solution to the single agent problem was doing by that definition. Okay, so basically, by that definition it follows, which is saying that the definition of interim pricings that I gave before was the right definition of interim pricings. Okay? So I want to turn to my next objective again.
00:22:33.958 - 00:23:02.474, Speaker A: Here was my outline. I want to understand interim feasibility. I want to characterize Expo's feasible mechanisms and optimize subject interim feasibility. So I want to turn to my next objective, which is understanding interim feasible allocation profiles. So I want you to think you have a single item for sale, okay? So ex post, you better not allocate more than one item. And I want you to think about these two interim allocation rules. One always allocates to the player with probably one two.
00:23:02.474 - 00:23:53.134, Speaker A: The top one half measure of quantiles, it allocates with certainty. And the bottom one half measure of quantiles, it doesn't allocate at all. Okay, so these both have ex ante allocation probability, one half. So my question for you is, which of these three profiles of interim allocations for a two player, one item setting are interim feasible for which of these do there exist an ex post mechanism that induces these allocation rules? A and b. Good. So a is just a lottery, right? I flip a coin, give it to one, give it to two. That exactly has these allocation rules for both players.
00:23:53.134 - 00:24:23.864, Speaker A: Good. B is just a dictator mechanism. Or I offer player one a price of that he buys with probably one half. If he said no, give it to pL2. Player one buys it probably one two. So pL2 gets it with probably one two, which is this allocation rule C. I'll call a double dictator because I'm giving both the people the right to buy the thing if they're in the high half quantiles.
00:24:23.864 - 00:25:19.804, Speaker A: But this can't be feasible because what if they both say, yes, I only have one item, I'm in trouble? And here's the main idea for C. What is the probability that one of the guys is high? What's one minus the probability that neither are high? Neither are high with probability one, two squared, which is a quarter. So one is high with probability three, four. What is the expected probability that I need to allocate to a high type if both players have this allocation rule? Okay, but what's the probability that I allocate to a high type with player one? It's one half, right? Well, it's the same for the other guy. Linear expectation says it's one. So the expected number of items I have to allocate to high types is one. But the chance that I have a high guy showing up is only three quarters.
00:25:19.804 - 00:26:01.496, Speaker A: How could I possibly allocate more items than the guys more frequently than the guys show up? So that's a violation of interim feasibility. Okay, so I now want to look at symmetric cases. So the cases where the players are IID from some distribution, they could have complicated budgets or risk aversion. They just want to look at symmetric cases and understand interim feasibility in symmetric cases. Okay, so let's have our example, though. The one we've been talking about last time, which is two agents iid from the distribution and common budget f. Okay? And here's a fact I want to use.
00:26:01.496 - 00:26:51.524, Speaker A: If I'm trying to optimize some symmetric convex program, which the program I'm trying to optimize was, then there's always a symmetric optimal solution. So I can restrict my attention only to symmetric solutions that are interim feasible. And that's going to make my life really easy. Okay? And one of the reasons why I want to focus on this, because if you look in the literature in the eighties and nineties, in economic auction theory, you'll find a lot of solutions to nonlinear cases that take strong advantage of the symmetry assumption. And basically using this property that I'm going to describe right here. Okay, so here's the lemma, the x post mechanism I need to think about. There's only one.
00:26:51.524 - 00:27:25.844, Speaker A: It is the highest quantile wins mechanism. So in other words, I take a profile of quantiles and I serve the player, the one that has the strongest quantile, which is actually the lowest quantile because quantiles go, strong is low, weak is high. Okay, so the strongest quantile wins is the optimal x plus feasible allocation constraint. For my program. It's obviously interim feasible. It's interim feasible because I've defined it with an ex post mechanism. So it induces some allocation rule.
00:27:25.844 - 00:27:49.524, Speaker A: Good. So I'm going to prove this. So what am I saying? I'm saying there are no other symmetric allocation rules that are interim feasible that are better than this allocation rule in terms of revenue. And to do that.
00:27:53.044 - 00:28:13.944, Speaker B: Jason, I'm sorry, a little something that defines the quantile optical mechanism or the allocation rule. Right, we took an allocation rule and so now who the strongest quantile is depends on the allocation rules. So when you say smartest quantile wins, you smart contract wins with respect to allocation rule a is.
00:28:14.764 - 00:28:32.364, Speaker A: Yeah. So I want to remind you that once I've done this, I'm just going to talk in terms of quantiles from the distribution to talk about feasibility. So I no longer have types. Later I'm going to have to. The single player problem has to actually turn types into quantiles for me.
00:28:33.184 - 00:28:39.008, Speaker B: We talked about the strongest quantile. You mean first fix this. You fix some ordinary quantiles at some point somewhere.
00:28:39.096 - 00:28:47.216, Speaker A: So quantiles are defined to be ordered where the lowest one is strongest and the like zero is strongest one is.
00:28:47.240 - 00:28:50.872, Speaker B: Weakest before we decide how we order the quantum.
00:28:50.928 - 00:29:03.204, Speaker A: When I have a mechanism for types, I can now tell you what the quantile type is based on the ordering that that mech is meducines on types.
00:29:12.164 - 00:29:21.024, Speaker B: I'm obviously wrong, but if it's nagging feeling, it's circular because we use probability of winning to define strength. So I've lost some step of the definitions.
00:29:25.684 - 00:29:57.424, Speaker A: So I'm separating the problem of coming up with an optimal mechanism for these players into two steps. One is come up with good allocation rules. Allocation rules are just monotone allocations from quantile to probably a winning. In this step, quantiles are just whoever ends up being from the mechanism that solved. Once I have these allocation constraints. I then have to solve that single player problem that's going to tell me how to map types to quantiles. Okay.
00:29:59.684 - 00:30:16.444, Speaker B: I hear you. That I'm not trying to send. That's a definition of pontoo, who's stronger than which. And that's what I'm trying to ask about. But you should go on.
00:30:23.424 - 00:31:19.704, Speaker A: No, that's your thing. There will be a matic, protects the quantum. The point is, I am trying to understand what this constraint means. This constraint comes from this definition, which has nothing to do with types, nothing to do with incentives, nothing to do with types, nothing. Okay, so I'm just trying to understand this definition. Okay, so for n equals two players with quantiles drawn uniformly from zero one, what does strongest quantile. What is the allocation constraint? The interim allocation constraint that strongest quantile wins induces.
00:31:19.704 - 00:32:04.404, Speaker A: It's just the probability you win is one minus q. If you're a quantal q, you win the probability one minus q, because if your q equals zero, you win probability one. It's just a line. That's the fraction of people who are stronger than you from that distribution. So, in order to prove this lemma, I'm going to show that any symmetric feasible allocation rules, y, are also feasible for y hat. And therefore, because when I optimize revenue in my program for y hat, I'm allowed to choose something worse, something that was feasible for y hat. I might as well just start with y hat in the first place.
00:32:04.404 - 00:32:47.844, Speaker A: So I'm going to prove this by contradiction. So, suppose y is infeasible for y hat. So let's remember what feasibility means. Remember that feasibility was in terms of the cumulative allocation rules, right? We said y was feasible. If for every quantile ex anti constraint, the cumulative probability allocated below that is less than that given by the allocation constraint. So this just says, suppose it's infeasible, which means there exists some point where it's bigger.
00:32:49.744 - 00:32:51.936, Speaker B: Two very different notions of feasibility for the grand.
00:32:51.960 - 00:33:56.738, Speaker A: I'm assuming that's correct. So I have an allocation rule being feasible for an allocation constraint, and I have interim feasibility, which is, are they feasible for the ex post region? Exactly. And so, and when you think about optimizing things with a reduction that has two parts, right? So you have this optimizing over single player problems and then optimizing single player problems. There's this optimization has to have some feasibility property, but then when it sort of makes calls to the single player problem, it's got to also satisfy some feasibility property. So this is the sort of internal feasibility property. Okay, so what is the probability that player I has a type that's stronger than q hat? Just q hat, because quantiles are always uniform. Okay, so what is the probability that one of the players, one of these two players, is a high type stronger than q hat? Well, it's one minus the probability that neither are.
00:33:56.738 - 00:34:33.074, Speaker A: So it's the this, which is that. Okay, but how often do we allocate to one of these guys? Well, the probability we allocate to a type stronger than q hat by this allocation rule. Consider player one was probably allocate to him, right? That's just this integral of the allocation constraint. So this integrating this allocation constraint, one minus q, I get this integral. Okay. Okay. I have two players.
00:34:33.074 - 00:35:22.334, Speaker A: Both have to be allocated with probability, at least q hat. So this is the probability I have to allocate one of these guys if they're a high type, and this is the probability there exists a guy, and these are equal. And that better be the case, because remember, y hat was feasible, so y hat is all good. We look at the probability, these guys show up, we look at the probability we allocate. They're equal. But for the contradiction, we assumed that y was bigger than y hat at this q hat, which means when I write this down, I'm going to get a violation of feasibility. I need to serve these guys with more probability than they show up.
00:35:22.334 - 00:36:33.866, Speaker A: Okay, so any y, any little y with cumulative allocation rule, at some point which is bigger than y hat, meaning it's infeasible for y, just can't be allocated. Okay, I want to point out again that if I'm trying to solve this interim program and then try to solve these single player problems, the interim program is always solved by the same solution. The y hats are always highest quantile wins for a single item auction, which means I'm free to only consider the single player problem and just solve it. I don't have to do some complicated optimization of allocation profiles and then optimize a single player problem. I only have to optimize a single player problem. So in other words, that optimization, there's a sort of unique solution to the allocation constraints, which is kind of amazing and super helpful, and which is a large number of papers in the eighties and nineties used this property implicitly, not stating it this way. Yeah.
00:36:33.866 - 00:36:57.842, Speaker A: So your optimization problem had a sum of revenue is one for this period. So what is the revenue as a function of the quantile? What is that function? I don't understand your question, but I'm going to right now map this onto the public budget case where I think you might answer your question. So maybe could you ask that question again in a second? If you don't know the answer, tell.
00:36:57.858 - 00:37:12.668, Speaker B: Me if I understand. It seems like the whole power of doing this change of variables representation in quantile space is it allows you to view the optimal mechanism as identical even as you vary the single agent preferences. So it pushes the sort of preference dependence part just in the single agent problem.
00:37:12.756 - 00:37:51.354, Speaker A: Yep, yep. Okay. So as I was saying, the strongest quantile wins allocation constraints independent of single agent problem. It's always the best one to use in a symmetric environment. So how do we think about that? Let's look at the public budget example. And in the previous talk I said, given an allocation constraint of y hat equals one minus q, what is the optimal single agent mechanism? And I drew do I have it here? I do have it here. Great.
00:37:51.354 - 00:38:33.594, Speaker A: So I took this allocation constraint, I said what was the apple C mechanism? And I said what does it do? Well, it irons the top, it's greedy on some tiny interval, and then it reserve prices the bottom. Ok, so what is the mapping from types to quantiles that I want to use here? Well, the single player mechanism is going to say all these top guys get the exact same random quantileness interval. It doesn't matter. These guys get quantile sort of equal to their type relative to the distribution. And these guys actually doesn't matter either because they all get price at zero. They get rejected. So the single player problem will resolve how to map types to quantiles so that the right thing happens.
00:38:33.594 - 00:39:06.274, Speaker A: And I get this curve. As I said before, almost all positive results in literature for nonlinear mechanisms. So budgets, risk aversion are using this factory that the allocation rule I need at the beginning is just the strongest quantile wins allocation rule. Actually, you said almost all. Can you give us some examples? No, I said almost just to cover my bases.
00:39:08.654 - 00:39:25.066, Speaker B: Basically, almost all the literature is only a symmetric case. So in the nice case of out budget constraints, it's a little work in asymmetric auctions. But since there's almost no work in asymmetric auctions at all, then intersect that with budget constraints or anything, he's going.
00:39:25.090 - 00:40:17.634, Speaker A: To give me an interesting. No, I said almost because I knew I have some economists in the audience who might point out the one paper that didn't do this that I didn't notice. So that's why I'm almost here. Okay, so I want to think about the asymmetric case and this, you know, the study that the economist did of budgets and risk aversion actually prompted border to characterize this interim feasibility constraint more generally than the symmetric case. Okay. And the, the characterization is actually literally saying the exact same thing we said before in our proof. We said, except now I'm going to allow you to put different ex ante constraints on each type.
00:40:17.634 - 00:40:52.624, Speaker A: So suppose player one is in the strongest half, the pL2 is in the strongest quarter, and the strongest three is the player three is in the strongest third. So if you have a quantile constraint on each player, so each player's on the top Q hat of their quantile, then this is the total you have to allocate to those players in expectation. This is the probability that one of them shows up. One or more of them shows up. So it better be that you don't allocate to them more than one of them shows up. So one direction. This is obvious.
00:40:52.624 - 00:41:21.284, Speaker A: And the great thing that border did was he proved that it was an if and only if. In fact, it's a necessary and sufficient condition. Okay, I want to show you a very simple proof of this based on the min flow max cut theorem and network flow, which will seem familiar to a lot of you. Okay, so this is a network flow graph I'm going to make. So I have a start and a source and a sink. Okay. And I'm going to put types in this graph as follows.
00:41:21.284 - 00:41:42.724, Speaker A: Okay, so this column is profiles of quantiles. Imagine I've discretized quantiles, so they're profiles of quantile. I can discreetly write this down now. So profiles of quantiles. And here I'm going to do two cases where I have high and low. Okay? And high is going to be probably half, and low is going to be probably half. So I've discretized space by having high types and low types only.
00:41:42.724 - 00:42:06.264, Speaker A: Okay. So I have two agents in this example, and each can have a low type or a high type. So I have four profiles of quantiles, four quantile profiles possible. Here I put every possible type of every agent. Okay, so player one could be low, two could be low. PL2 could be high. Player one could be high.
00:42:06.264 - 00:42:44.858, Speaker A: Okay, and in this graph, I can interpret the flow that's going to happen from the start to these quantile profiles as probability. Okay, so these are all equally likely. So this is going to be actually a quarter on each of these. And then I can interpret how the flow goes out of a node here as who wins the object. Okay, so here when I got low high here, the high type won the object and the low type didn't. So the flow went this way. Okay.
00:42:44.858 - 00:43:28.324, Speaker A: And then I can interpret the flow here as what was the interim probability that type got anything because this is going to collect all of the things that it gets. Okay, so now I want to, so that's how I can take any mechanism I had and write it down here. I just say what is the flow? Where's it putting? It places, sum it up and send it from s to t. So any mechanism I can put as a flow in this graph. Okay, I want to note that this vertex is connected to two vertices over here, one for, or in general it's going to be connected to n vertices, one for the type of each person in the profile. Okay, so it gets an l one and an h two. Good.
00:43:28.324 - 00:44:01.912, Speaker A: So I'm going to add, I want to use the max flow min cut theorem. So I'm going to add capacities to this graph. The capacities on these edges are just the probabilities of getting there. The capacities out of these edges are just the same as the capacity incoming. So in other words, you can put the total, if your feasibility was one, you could put that total one out on any of these edges. So if you got, sorry, if your incoming flow was the probability of this, you can put that total probability anywhere else. So I just put that flow here.
00:44:01.912 - 00:44:45.792, Speaker A: That flow also goes there. Okay. And then the flow I'm going to put here on this edge is the flow that I want from the interim allocation rule that I want to see if it's feasible. Okay? So that is this interim allocation probability of that thing. Now I'm just asking, does there exist a mechanism that saturates all these edges? Is the maximum flow cut going to be this cut of just cutting b? Okay. Or is there something else here? And so this picture happens to be, I've done this for the dictator mechanism, which I showed you before. So player one, if they're high, they get it.
00:44:45.792 - 00:45:03.864, Speaker A: Otherwise pL2 gets it. That was a feasible mechanism. It has this allocation rule. Player one, if they're high, always gets it. PL2, this is pL2's low and high. They give it probably a half each. And player one, if his load never gets it.
00:45:03.864 - 00:45:56.332, Speaker A: Here is the double dictator mechanism, okay? Where what I've done is, I've drawn here, these edges are the capacities now, not flows. These are the capacities that you have to put on the edges for the double dictator mechanism. Okay? So double dictator serves both high one and high two with certainty, if they show up, and it shows neither of them, if they, the low types don't get served right of the double dictator. And so then you say, well, is min flow equal to max cut? And in fact, no, this has two edges going across it. These are one and one which is two. And here I had only three edges of capacity, a quarter each crossing them. Sorry, these were a half each.
00:45:56.332 - 00:46:55.000, Speaker A: So it was total one. And these were a quarter each. So I have three quarters crossing this cut and one crossing this cut. And so min flow is not equal max cut. Okay, so in the paper we have on this, we generalize this border condition to matroids, where the generalization is that you write the expected rank of the matriarch. Basically, if you randomly draw quantiles according to the probabilities of the quantile profile. I want to point out of interest to some people here that in 2005, in particular, Amos and Nicole and some others were studying de randomization of auctions, and we came up with basically the exact same flow graph construction to turn randomized auctions into deterministic auctions.
00:46:55.000 - 00:47:51.674, Speaker A: In other words, we wanted to take an auction where here we might split the flow. Right? Instead, you want to come up with an integral version of the flow where it only goes to one place, very similar construction in that paper. Okay, the next thing on my list. So I've shown you the characterization of interim feasibility, the theorem that you can then say, well, what kind of ex post mechanisms do you have to look at to be able to implement all interim feasible mechanisms? And the answer is stochastic weighted optimizers. A stochastic weight optimizer. The following. You take any function you want that randomly maps types to weights, and then you maximize the weighted sum of types subject to feasibility.
00:47:51.674 - 00:48:32.484, Speaker A: So this will give you everything. I'm going to skip my discussion of this. I think Kostas will talk about it briefly. And I'm going to skip my discussion of this also, because I want to talk about the next part of my talk. I'm happy to talk about this construction before, in particular, actually, I think I want to show you this picture. This is a picture, a pictorial representation of ex post versus interim feasibility. So this is ex post feasibility.
00:48:32.484 - 00:48:49.214, Speaker A: If these types show up, you can only serve them. You can't serve this guy didn't show up. And then you have this feasibility constraint. Okay? If this guy didn't show up, you can't serve them. So you can only serve some such types do show up. And now if you look at what interim feasibility means, it's some combination of these polytopes. It looks like this, in fact.
00:48:49.214 - 00:49:40.584, Speaker A: I don't want to go into more detail, but I can explain this picture to you offline if you want to see more of it. Okay, I was going to talk about public budgets, but I also don't have time, so I want to talk about this unit demand single agent problem. Okay, so again, the example you should have in your mind here is uniform zero one squared. I don't want to prove the thing that I said I was going to prove at the very beginning of this talk, which is that projecting this multidimensional type to a single dimension is optimal. Okay, this comes from a paper joint with Nima Hagpana, who's here for the semester, and this is something that he's been working on since 2011. And, you know, it takes you a while to get the right answer, and it's the right answer now. I'm quite happy with it.
00:49:40.584 - 00:50:26.254, Speaker A: It's very closely related to a bunch of recent interests in computer science, in solving multiplayer problems in bayesian settings. And so here are some papers. And it's also very closely related to some classic work, in particular most reliant on Armstrong and Rocher and Chennai. Okay, so what were my unit demand preferences? Again, if you had m items, you can have an allocation, which is the simplex. So it's a probability. You get each item, okay, with the sum of probabilities at most one. And a payment players have private types indexing how much they like each item, and the type space I'll denote by capital t, which I'll just restrict to zero one arbitrarily.
00:50:26.254 - 00:50:55.634, Speaker A: Okay, the utility is the dot product of type and allocation minus the payment. Okay, I'm going to draw types from a distribution with density function little f. So think of two examples which we'll be talking about today. One is the single dimensional case, which we know and love. M equals one. Okay. The other is my two dimensional case where let's think about the uniform zero one case.
00:50:55.634 - 00:51:18.574, Speaker A: Yeah, it does look like additive, but if I had this constraint that can only serve one of the items, it's the same as unit demand. This constraint says you can only get at most one of the items. We're allocating one thing to you, right? Because the allocation is the probability simplex on which item you get.
00:51:19.034 - 00:51:21.770, Speaker B: Yeah, x.
00:51:21.802 - 00:52:26.964, Speaker A: Could you have say, that's the point? So the point is, once I've constrained allocation to only give you one thing, then someone with additive preferences over things is the same as someone with unit demand preferences over things because they can only get one thing anyway, so that unit demand constraint's not binding. That was Nikhil's question for anyone else. Don't worry about that. I'm going to, for all of this talk, constrain myself to item symmetric distributions like this, okay? In an item symmetric distribution, the optimal solution is always symmetric. Therefore I can restrict myself to solving it only on the portion of the type space where the t one is bigger. The type for the item one is bigger than the type for every other item. Okay? So for the unit demand problem, I'm restricting type space to this part, okay? And if it was item spectrum distribution, if I solved the problem here, then I can just put that together with the symmetric opposite and I get the general solution.
00:52:26.964 - 00:53:50.024, Speaker A: This is just as a notational convenience for me right now, because I just want to just always refer to one as being the highest type type, the favorite item type. So there are multiple bidders. No, again, I'm solving the single agent problem, okay? And the stuff I talked about yesterday for solving the single agent problem for revenue players will solve the multiplayer problem, okay? So I want to consider some motivation for the result I'm going to give. So I'm going to tell you that under some large family of distributions, we can collapse the multidimensional preference for different colors of this car to a single dimensional preference the guy has for his favorite color car. Ok? So what's the intuition? So if you were thinking about price discrimination, you think, huh, I have this car, I could paint it red or blue. Maybe I can get more money by discriminating because players have different values, different colors. And the idea of price discrimination is that price discrimination can improve revenue if high value agents are more sensitive to the different outcomes you're producing, in this case colors than low value agents.
00:53:50.024 - 00:54:26.962, Speaker A: So they're willing to pay a premium to specify exactly what they want. And the low guys, you can give them maybe a random thing. So you would offer a high price to choose your color and a low price for random color. This is what you would want to do if high types were more sensitive to color than low types. So today I'm going to try to understand the situations when that's not true. There's no mileage from price discrimination. In other words, I want to understand what this condition, which I've written informally here, high values are less sensitive to color, what that means.
00:54:26.962 - 00:55:17.494, Speaker A: And so I'm going to give you a mathematical statement for this actually shortly. This means the intuition is then price unhelpful is going to be without loss to project this multidimensional type into a single dimensional type. And having done so, your awful mechanism is just a single dimensional theory. Okay? So you could either use this, the reduction I gave you yesterday for ex ante pricing, or you could just say, well, we know how to solve a single mutual problem. Let's just do it. So you write the single munch on virtual values and you solve it and you're done. So I want to tell you what this high valued agents are less sensitive to color means, okay? And so I want to look at the distribution.
00:55:17.494 - 00:56:17.370, Speaker A: So remember, t one is your value for your favorite item. So I want to look at the distribution of your value, the ratio of value for your favorite item, and second highest item condition on your value for your favorite item. Okay? So if I tell you your favorite item, there's a distribution that tells you what your second favorite item is drawn from, ok? What's the conditional distribution of the ratio to your favorite item? That's the object I'm talking about here. And then if I think about this distribution and change your value for the favorite item, that distribution changes, you change this, right? So if this is ordered by first order stochastic dominance, then high valued agents are less sensitive to color than low valued agents. You never want to price discriminate. I want to draw a picture. Okay, so high value agents are less sensitive.
00:56:17.370 - 00:57:27.358, Speaker A: So if you think about density, the, in other words, let's draw this picture. So say this is probably, I'm going to look at, one way to get a handle on this is, let's ask for any type t. What's the probability that your second value is less than half your first value? The intuition here is that densities are getting higher, like this way, okay. So your mass is getting pushed upward. Okay, I want to do a warm up, which is this. In fact, I'm going to completely solve the uniform zero one case before I show how to generalize this to more dimensions. Okay? And that approach comes from Armstrong, which says, let's just look at the problem condition to raise coming out of the origin.
00:57:27.358 - 00:58:29.184, Speaker A: So we condition on the types lying on some ray out of the origin, solve the problem optimally on that type space, the conditional type space, and then hope that the conditions are consistent. Listen at the conditional distribution of your favorite item to be f max, okay? And you can figure out what that is. So again, I said I want a condition on the ratio between the two types and assume that the seller knows what this ratio is. So the seller knows the types lie on this space. Now, I want to solve that multidimensional optimal mechanism problem, okay? I want to note that, okay, if I tell you that, then I might care about what your distribution of t one is. Well, that's just the same as the distribution of f max. So, conditioned on this knowledge of theta, you have the same distribution f max, for your favorite item.
00:58:29.184 - 00:59:31.964, Speaker A: Okay, the following two problems are the same problem. This stochastic, this probabilistic problem where your value is t one and I can allocate with probably one, or I could allocate it with probably theta or zero, sorry, the following stochastic problem, or this two item problem where your value is t one for item one and your value is always theta t one for item two. In other words, item two is the exact same thing as item one with some probability. Okay? So these two problems are identical, and we know how to solve this problem. If I have a single item and your value is t one, and you can allocate with a certainty, with some probability or zero, then we know you never want to allocate with probability zero probability theta with always certain t or zero. Why? You want to maximize virtual surplus. So you want to serve the types always that have positive virtual value, and serve them never if they have negative virtual value, which corresponds to posting the price that inverse, the virtual value function, which for this distribution is square root one three.
00:59:31.964 - 01:00:00.740, Speaker A: Okay, this is actually a combination of a bunch of results in the literature referred to as no haggling. You don't want to post probabilities. Okay, so these two problems are isomorphic. And then I want to note that I told the seller theta and said, use this knowledge of the guy's type. I'm telling you to design an optimal mechanism. The guy did. It didn't depend on theta, which means the same mechanism is often without knowledge of theta.
01:00:00.740 - 01:00:39.504, Speaker A: So if for theta, I want to post this price, that means for every array out of the origin, I want to post this price. So now I've solved the problem in this half. We have the symmetric solution in the top half, which is this. And so now we see we post a price square at one third. That is the fastest argument of a multidimensional optimal mechanism that I know of. Okay, there are two challenges to generalizing this to general types. And one is if you want to generalize the general types, you need to consider paths that are not raised out of the origin.
01:00:39.504 - 01:01:09.828, Speaker A: Now, the problem is there are a lot of paths out of the origin that you could potentially choose from the COVID type space. Which path do you choose? So that selection problem has prevented a lot of multidimensional mechanism from proceeding. We're going to give a solution to resolving that problem. Yeah. So here we're looking at rays out of the origin. We're looking at conditioning on types with this theta, which is just a line out of the origin. So you can imagine conditioning on some other path.
01:01:09.828 - 01:01:40.280, Speaker A: Right. What would be the path you'd want to condition on? One way to think about that is no matter what you condition, the distribution stays the same. That's another way to think about that. Okay. But then you have to solve the mechanism line on, not a straight line. Okay. And if you're solving a condition on a sum path, right, I don't have the simple property that your value for the other item is just a linear fraction value.
01:01:40.280 - 01:01:59.624, Speaker A: For the first time, it's only on rays. So the simple solution we had here is not going to apply the general paths. So we have to address two things. The most important one is the first one. I want to focus on that. Yeah. Okay.
01:01:59.624 - 01:02:51.276, Speaker A: So I want you to remember that when you're optimizing revenue, there isn't a point wise optimization. There's not some mechanism that for every input gives you the best revenue possible on that input. Okay? So you have to maximize revenue expectation for the distribution of types. Okay, so I want to give you the following definition, and I want to explain it to you and this definition, I want you to think analogously to Tim's definition of smoothness. This is a definition that if I can get it to do interesting things, then it's an interesting definition. So I'm going to call a function which is, we'll call a candidate virtual value function, which maps types to real numbers. So it's going to be a multidimensional virtual value if it is one, the following.
01:02:51.276 - 01:03:56.354, Speaker A: So it's an amortization of revenue if virtual surplus is equal to revenue in expectation, meaning expected virtual surplus equals expected payment. Okay, for any IC IR mechanism you choose, it always amortizes revenue. Okay, I'm going to call this function incentive compatible if the virtual surplus maximizer, meaning the x where you always choose to give the player the thing that maximizes his virtual value function if that x is incentive compatible. Meaning what does mean for x to be incentive compatible? There exists a p such that xp is ic. Right? I'm going to call it a virtual value. If both a and b hold meaning for all mechanisms, this thing will account for revenue. And if I optimize this function point wise, the result I get is incentive compatible.
01:03:56.354 - 01:04:28.094, Speaker A: And here's the simple proposition that you can have. If this definition is true, if a virtual value exists, then the virtual value surplus maximizer is optimal. And that proof is simple. So let x be the virtual surplus maximizer. We know that its revenue is equal to its virtual surplus. It maximizes virtual surplus amongst all methods. So it's better than any other x, and that x is equal to the revenue of the other mechanism.
01:04:28.094 - 01:05:25.188, Speaker A: Okay? And the great thing about this is we took this challenge where there was no pointwise optimal mechanism for revenue. And if you can find a virtual surplus, a virtual value function, then you get point wise optimization you can solve. Okay, so again, analogous to smoothness, the really nice thing about smoothness is you can analyze sort of a point argument about some input, and it holds for like distributions over stuff and all this other stuff that you don't want to analyze. So it's actually serving a very similar purpose to that definition. Okay, so I'm going to skip the single dimensional linear discussion. Talk about m equals two. Okay, so here is in one slide how you need to think about multidimensional mechanzine defined virtual value functions.
01:05:25.188 - 01:06:15.700, Speaker A: So Rocher characterized any incentive file mechanism as inducing a utility function that was convex. And you can always pinpoint the allocation rule of that mechanism as the gradient of the utility function. Okay? Then in a later paper, he showed you how you can view this to come up with a amortization of revenue. Okay? You just write revenue as surplus minus utility, surplus minus utility, and then you integrate by parcel on pass to write this utility in terms of gradients of utility, okay? And then if you do that right, you can factor out the gradient utility and just get a payment in terms of allocation. Again, for two dimensions, there's a degree of freedom in picking paths. For one dimension, there's no degree of freedom. You have to walk past downward.
01:06:15.700 - 01:07:32.300, Speaker A: For two dimensions, there's a degree of freedom, okay? And so that degree of freedom is going to give you a lot of possible amortizations. And most of them, all except for one, are not going to be in sine and compatible. And only maybe one, all except for maybe one, are not going to be inside and compatible. So how do you find the right one? And so the main idea from this paper with Nima, which lets you find multimental virtual values, is an idea for reverse engineering virtual values. In other words, I want to reduce this degree of freedom I have, okay? So I'm going to guess the form of the optimal mechanism and use that guess to reduce the degree of freedom from choosing paths. So if I'll call a mechanism a favorite projection, as I said before, if it always allocates as if it projects first and then runs the mechanism first, the favorite item projection, okay, if a favorite item projection is optimal, then it better be your multidimensional virtual value for your favorite item is equal to the virtual value of the favorite item projection. So now one of my virtual values in my two dimensional virtual value is known.
01:07:32.300 - 01:08:19.724, Speaker A: It's the favorite item virtual value. I can use that virtual value and the differential equation I get from this integration by parts to solve for the other one. Now, I've identified one virtual value function, and all I have to do is identify sufficient conditions that my initial guess is correct. So I need to guess that maximizing virtual surplus indeed gives me this projection. Okay? Which means if the virtual value is positive for the favorite item, it better be bigger than your virtual value for your other item. That virtual value for your other item comes out of the differential equations I get by starting here and going through the differential equations from Rocher. And if they're both, if the favorite item is negative, it better both be negative.
01:08:19.724 - 01:09:06.264, Speaker A: So I don't allocate it all. Hey, if that's true, it's optimal. And then the conditions I gave on the previous, in the first slide are exactly the conditions you need to check out that this is true. Okay, so to conclude, I've shown you a lot of aspects in which multidimensional and non linear mechanism theory can mirror what we understand and work with in the single dimensional space. There's a lot of value in taking that perspective, in part because a lot of results will automatically extend. And there's a lot known about that, the tools you work with in those settings. So, in particular, I gave you a couple multi single agent reductions.
01:09:06.264 - 01:09:50.133, Speaker A: We talked about marginal revenue, which is a very useful economic intuition about how optimal auctions work. And I showed you how to derive multidimensional virtual values, which is the workhorse of all of single dimensional auction theory. And there have been lots of extensions using virtual values. And the hope we have for this theory of virtual values we developed for multidimensional settings is, one, you'll be able to use virtual values for more kinds of problems than just showing the favorite item projection is optimal. And two, that these virtual values, these kind of virtualize, will similarly enable a theory for multimedia preferences like we've had for single dimensional preferences. All right, thank you.

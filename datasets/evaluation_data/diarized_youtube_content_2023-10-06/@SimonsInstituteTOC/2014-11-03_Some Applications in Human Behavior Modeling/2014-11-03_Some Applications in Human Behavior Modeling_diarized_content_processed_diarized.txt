00:00:00.760 - 00:00:29.006, Speaker A: Thank you. Okay, so since this is a workshop, I think I'm going to do a slightly different talk. Instead of tell you what I know about, I'm going to tell you what I do not know. Now, just to say, this is not a waste of your time, I hope. What happens is the audience would jump up and say, hey, that's a trivial problem. Or some of you hopefully will think it's an interesting problem, at least. So I'm going to present to two applications to you.
00:00:29.006 - 00:01:40.124, Speaker A: The first one is called verbal fluency. So, I work with psychologists, and a verbal fluency task is when a psychologist would ask a human participant to say as many animal words, for example, as possible, without repeating in 1 minute. So give it some thought in your head, like, pretend you're going to do this task. Okay, so what kind of lists do humans produce? Turns out here's a random example of six different participants, the list they produced in 1 minute. So there are several things, right? One is like they took typically start from familiar animals, and this is somehow a semantic run. By that, I mean, there seems to be sequences, subsequences in there where people tend to think about the same kind of animals, at least. So this hints at some markovian behavior.
00:01:40.124 - 00:02:14.184, Speaker A: And the question is, how do you model this type of data? So the psychologists think of this type of problem as one where we retrieve words from memory. In this case, here's one picture of what might be going on. Now, this is way too small, but this is an abstract space of animals. And forget about colors. They don't mean too much. But let me zoom in a bit. Okay, so that's a small portion of the graph.
00:02:14.184 - 00:03:24.562, Speaker A: The idea is somehow this is an embedding of different animals, and things that's closer are semantically related. Okay, now let's consider one specific model to think about this problem. So what if I say that? Let's treat this as if it's a random walk, where I have potentially a graph with vertex set v, and those are just n different animal words in English. Furthermore, let's assume there is some unknown transition matrix p, which typically should be dense. We believe people can think of any other animal after one animal. All right? And then, interestingly, because the participants are instructed to not repeat when they generate the animal lists, we assume the following generative story. It's like here's this random walk.
00:03:24.562 - 00:04:24.522, Speaker A: The participant is just doing a standard random walk and let x one, x two be the actual random walk sequence. However, we do not observe that sequence. Instead, we only see a sensory version where an animal shows up only when the first time it is visited. So let's think of, for example, let's say I have a very special graph and therefore standard transition matrix. Let's say that's my graph, it's a star graph. Then they call this node 12345 up to, say n here. Okay, my x one, x two.
00:04:24.522 - 00:05:13.132, Speaker A: That walk could be, let's say I started from two and I walk to one. Then I may come back to two again, back to 13151, etcetera. Okay, we do not see that. Okay. Instead, all we see is 2135 and so on. So that's our a sequence. Now, it's easy to see that if we, the random walk covers the whole graph, you will have n observations here, and it's just going to be a permutation of your n items.
00:05:13.132 - 00:06:10.642, Speaker A: Okay, so that's all you see in one list random tree. Yes. Okay, so what do we want to do? We want to estimate the transition matrix from such lists. So here's your problem, right? Let's say you have m different participants, and let's assume, conveniently, that all humans share the same graph and transition matrix their head. So you have m lists and you want to estimate the transition matrix from it. So how do we do that? Well, the difficulty, as anyone can imagine, is like this conditional probability. We already know k different animals.
00:06:10.642 - 00:06:37.990, Speaker A: And what is the probability of hitting some new animal? That is a hidden sequence. The reason being, let me say that this is k from one two to kk equals two here. And we're trying to decide what is the chance that the animal number three shows up. Right. If you only observe. Sorry. After this point, you don't know what's the actual walk.
00:06:37.990 - 00:07:25.074, Speaker A: It could be two one and two one repeating any number of times and jumping to three. Right. So you have essentially infinite number of hidden sequences that you need to integrate over. And that is difficult to do if you just do it straightforwardly. But here's a different idea, an algorithm that one can think about the problem. What if we say that. Let's call this a big step, an observed step from the cave animal to the cave plus one's animal.
00:07:25.074 - 00:08:20.334, Speaker A: Now, we can model this, just this particular step from k to k plus one as an absorbing random walk of its own. So the idea would be you have your original graph, but whenever you visit an animal, you mark it. So let's say that's my situation at right here when k is two. Okay? Now I need to worry about the probability of my next destination. What's my k one animal. I'm going to turn this graph at this moment into an absorbing random walk where the nodes I have visited are non absorbing and all the unvisited nodes are absorbing nodes. So these guys would not be absorbing.
00:08:20.334 - 00:09:07.850, Speaker A: And I'm going to start my random walk at the case node. In this case one, I will try to compute what's the probability that I get absorbed in any one of those absorbing states. So you can do this as follows. So think of the original transition matrix p n by n. Now let's reorder the nodes such that a one to ak the nodes you have visited. You're going to put them first and then the remaining are the nodes you have not visited. Okay? So first reorder p and then turn it into an absorbing random walk.
00:09:07.850 - 00:09:57.656, Speaker A: By just, you know, diagonalize this part and set this to zero so you get this absorbing matrix. Then it is known that the, if you take the fundamental matrix of this absorbing random walk, I just compute that smaller matrix. The inverse Nij is going to be the expected number of visits to j before absorption. If you start from I, okay, so that's well known. And then you just take one more step. You say that that's the chance that if I start from I, what's the number of times I'm going to visit J? If you further, right, multiply this with the r matrix. That gives you the probability of you being absorbed in any one of the absorbing state.
00:09:57.656 - 00:10:42.604, Speaker A: Okay? So that's the chance you will hit a new word. So you can compute this probability in that way. But keep in mind that here you turned it into a specific absorbing Reynolds. Okay? Then you can put everything together by just multiplying this probability. That's going to get you your log likelihood. The difficulty here is, since my k is changing, k is increasing every time you get a slightly different absorbing random walk. Okay? But you do this altogether, that at least gives you a log likelihood.
00:10:42.604 - 00:11:28.978, Speaker A: And now estimating the original transition matrix p becomes a problem. If you have a likelihood. Let's just try maximum likelihood. Turns out this is not convex, but we just did gradient method on that just to have an estimate of p. So let me show you some empirical result on like how this way of estimating the transition matrix worked. I'm going to show you three estimators beside the one I just mentioned. Let me present this p of rw random walk.
00:11:28.978 - 00:12:11.704, Speaker A: It's just the standard like maximum likelihood estimator on a random walk. If you pretend the a sequence you observe like just come from a standard non censored random walk. That's going to be wrong, right? Because it's going to say, yeah, here there's a transition from, say from three to five, which is actually not the case in the star graph. Okay, so we know that's wrong, but that's so easy to implement. So we did it nonetheless. Another estimator is to only take the first two items in each list. And if you think about that in this story, that one is actually okay.
00:12:11.704 - 00:13:04.814, Speaker A: It's going to be unbiased and so on. So that's an okay one, but you're throwing away a lot of information afterwards. Okay, so I'm going to show you these three estimators on a different, a bunch of different toy examples. So I have this graph with n equals 25, 25 nodes. What I'm showing you on the x axis is m, the number of lists available to each estimator. So it starts from like ten lists all the way to maybe 600 lists. These lists are generated from this story on the y axis.
00:13:04.814 - 00:14:11.504, Speaker A: It's just the square difference between your estimated quantity and the true transition matrix. Okay, so the red one is our estimator and it goes down. Now, it's interesting to see that the render walk one, as you would expect, is doing really poorly for this star graph, as expected, because it's mixing a lot of these types of transitions. The first two, we believe it should just go down eventually, but because it's throwing away a lot of information, it's not doing as good here. Although initially, somehow it's better. Let's on a star graph, this is on the 2d grid. Again, undirected unweighted graph transition is the standard one over degree.
00:14:11.504 - 00:15:43.804, Speaker A: This time we see that in the beginning when you don't have a lot of data, actually using the wrong estimator isn't too bad, but eventually it gets stuck there while the other two estimators are going down, a random graph behaves somewhat similarly. I think this one is interesting. If you have a ring graph instead, it turns out the wrong estimator was doing quite well in the beginning for a lot longer. And the reason intuitively is because if you have this ring graph and you're doing this type of censored output, what happens is intuitively you have a situation that after a while you sort of COVID an arc of the graph and you are running back and forth. If you are here, let's say this is k, the chance that you are going to hit a new node. You are going to hit a new node either here or here, but that probability is much smaller. It's one over.
00:15:43.804 - 00:16:15.894, Speaker A: The expectation is one over the length of the arc you already have. It's one over k. So in this case, actually just a naive estimate is getting it almost right. Right. Okay, so we have some evidence that this estimator, sort of the red one, seems to be working. But here comes the questions which we don't know anything about. Like we don't know if this estimator is consistent or not.
00:16:15.894 - 00:17:03.292, Speaker A: And if it is, we also don't have any rate on it. Okay, so that's application number one. Be happy to hear if you have thoughts on how to think about this type of estimate. Okay, let me move on to the second application. Second application is what I call machine teaching. And this is something that if you're familiar with machine learning, it takes a while to get used to. So let me start with a very simple example of learning.
00:17:03.292 - 00:17:38.193, Speaker A: So we're not talking about teaching yet, we're just talking about machine learning. So what I want to do here is I have a one dimensional feature space, so x is in one dimension. Let's say this is between zero and one. You just have this interval and there is a threshold function, unknown threshold function, that you try to estimate. So here's the assumption. There is going to be a theta star between zero and one such that to the left of it we have this y function which is minus one. Otherwise it's plus one.
00:17:38.193 - 00:18:29.134, Speaker A: Okay, you receive training data in the form of an id random sample. Okay, so let's assume x is uniform. So you just get a bunch of uniform points, let's say n samples whose corresponding y is noiseless and just come from this distribution. As a learner, you have your hypothesis space being, you know, the collection of possible thresholds. So you know it, this form, you just don't know where theta star is. Okay, so that's your problem, right? The question to ask in machine learning is of the following form. If I give you n training examples, how do you quantify like what is your estimator and how do you quantify the risk of your estimator? So let's think about it.
00:18:29.134 - 00:19:44.194, Speaker A: If I have four training examples like that, then one potential estimator or way to or learning algorithm is to do the following. I'm just going to find the interval which is containing the innermost black and white points, and I'm just going to put my estimated decision boundary in the middle. Okay, that's just me. Now, the interesting question is, how is this estimator going to work if your future data is also true id from the same distribution. It's easy to see that, like, I'm being really hand wavy here, but if you have NID examples, roughly speaking, the length of this interval is going to be one over n, and your estimator is in the middle of that. So you are going to be off to the true estimator by a quantity, roughly speaking, not bigger than one over n. So your error is going to be one over n.
00:19:44.194 - 00:20:31.820, Speaker A: You're getting x and y, or just y. In this case, you get both x and y during training. Yes. In other words, if you want a future error rate of less than epsilon, you need order one over epsilon training examples with high probability. Okay, so that's standard machine learning. Now, I'm going to contrast this with another type of learning that we often do in practice, which is called active learning. We said in active learning, the learner has the ability to ask queries.
00:20:31.820 - 00:20:59.128, Speaker A: So initially there is no IID sampled data. Right. The learner is going to say, I know the space is between zero and one. I have the ability to pick any point x and ask an oracle who knows the truth for its label at x. So that's all I can do. But I am going to ask one query at a time. Then I would create an estimator, maybe.
00:20:59.128 - 00:21:51.494, Speaker A: But in the next iteration, I will pick a different query to ask and so on. Okay, if you think about our specific problems, the best strategy for the active learner is essentially binary search. You're supposed to ask the label of a point in the middle. If it's white in our case here, then what we know is this side of the interval cannot contain the decision boundary. So you cut out half of the hypothesis space, but your decision boundary can be anywhere here. So the next query you ask is going to be the midpoint here in this interval and so on and so forth. Right? So by doing so, this is exactly binary search in the interval.
00:21:51.494 - 00:22:21.964, Speaker A: Okay, so let's ask the same question. If I want my final classifier to have an error at most epsilon, how many queries do I need to ask? This is not hard to see that you are much better off. Oops, sorry. It's exponentially smaller. Right? You, you just need this number of queries. Okay? So that's good. Active learning.
00:22:21.964 - 00:22:46.020, Speaker A: People like it. Okay. The reason I'm introducing these two learning paradigms is because I want to introduce a third one. A third one is, strictly speaking, not machine learning. Instead, it's machine teaching. So let me say what that means. So let's assume that, yeah, we have a learner that.
00:22:46.020 - 00:23:42.760, Speaker A: Think of that supportive active machine will just find the midpoint in your training set between the innermost pair of different label points. Now, let's say I'm the teacher. I'm not the learner. I'm the teacher. I know what theta star is, okay? And I want to design the smallest training set. Training set means xy pairs, okay? Such that when I give my training set to that specific learner, it's going to learn decision boundary very close to theta star. The question is, how do I design such a training set? So, for this problem, just 1d threshold function, right? And let's assume the learner is the supportive academy machine type of learner.
00:23:42.760 - 00:24:18.018, Speaker A: It's clear that one way that that you can teach is by using a training set like this. Just place two training examples right next to the decision boundary, but on a different side of it. And let's say they're epsilon apart. Okay? So clearly we were able to get that learner to a decision boundary. Well, that's epsilon. Good. But you only need two examples, right? It doesn't depend on n or epsilon.
00:24:18.018 - 00:24:46.716, Speaker A: Now, okay. The reason we just need two examples is because this is a different setting. We're no longer doing learning. Okay? We know what the target is and we don't need to explore at all. Okay? Okay. So that's okay. I hope everybody agree with me.
00:24:46.716 - 00:25:08.222, Speaker A: That's one example like that. Let me ask you a different question. Okay, so, audience participation. Let's say we have a different problem. This time. It's not classification. Instead, it's that density estimation we have called a learner.
00:25:08.222 - 00:25:52.620, Speaker A: But this learner takes a point cloud ying RD, and it's just trying to estimate a gaussian distribution from it. The estimator inside the learner is fairly straightforward. It's just your standard sample mean sample covariance. Okay, so let's assume you have this learner. But let me ask the teaching question again. Suppose I'm a teacher and I want to convey to this learner a particular gaussian distribution in RD. So with mu star and sigma star, all I can do is to somehow pick a bunch of points and give it to the learner.
00:25:52.620 - 00:26:02.764, Speaker A: I know the learner is going to do this. If I want to use as few points as possible, how should I do it?
00:26:03.584 - 00:26:10.768, Speaker B: So you're learning the moments, you're not learning the normal. Right. The fact that it's normal doesn't have anything to do with your problem.
00:26:10.856 - 00:26:23.174, Speaker A: It's the, it's the assumption it's the assumption of the learner. The learner is just going to say. Right, okay, sorry. Yeah. The learner is going to first say it's going to learn a gaussian distance distribution. Okay?
00:26:23.214 - 00:26:30.438, Speaker B: That's the motivation for that particular learner. Then you're not going to choose the point, anything to do with the normal distribution.
00:26:30.486 - 00:27:36.454, Speaker A: Just choose them. Correct. The assumption here is that learner is hard coded to only learn content distributions. Any suggestions? So for example, let's consider 1D equals one, right? So let's say I have this mu star here and I have some particular sigma star. How many training examples do I need for this type of thing? If I sample from this distribution and I just saturate the learner with infinite examples, the learner is going to learn this eventually. But since we are the teacher, we have the freedom to design to choose those points. We can do much better.
00:27:36.454 - 00:28:15.234, Speaker A: In fact, for this case, convince yourself that. Yeah, I mean, just again, two points would be fine. So two points for 1D. What about, say, a 2d gaussian, something like that. So let's say that's my target minus intuition. The trouble is, what's the algorithm? Right? The algorithm is right there. Yeah, that's the algorithm.
00:28:15.234 - 00:28:32.304, Speaker A: It could be the case that the third digit tells you something and the fourth digit tells you something else. I mean, the algorithm is right here. That's the learner's algorithm. That's just like sample. But that wasn't the case in the other example. It was not the case. I didn't specify it clearly.
00:28:32.304 - 00:29:14.694, Speaker A: It was. There was a learner assumption there. It's the take 1d examples, find the midpoint. So in this case, you can show that, in fact, in general, you just need d one points. Just put them like a tetrahedron type of configuration. And that particular learner, you can teach it with d plus one example. So let me see, what are we doing here? We're actually solving the following problem, which this picture is very similar to the one in the previous talk.
00:29:14.694 - 00:29:56.088, Speaker A: The assumption is we are the teacher. We are faced with a student. This student is a learning algorithm or an estimator. So this student is characterized by this a where a maps data space. So that means that big d up there is a particular training set. Think of it this way. It maps a training set to a parameter in the model space, right? And therefore, if I'm doing teaching, what I want is I start with a teaching goal.
00:29:56.088 - 00:30:24.386, Speaker A: I know what model I want. I'm looking at the inverse mapping. Okay? This inverse mapping could be messy depending on what your a is. And I'm going to pick, among all these possible training sets, one that I like the best. So I need to define what I mean by, like, the best. Here's one possible way to do it. I'm saying that what I want to do is to minimize over training sets.
00:30:24.386 - 00:31:21.486, Speaker A: So if you are in the machine learning setting, this really is a discrete object. It's like how many points you want in your training set and what are they? But nonetheless, I want to minimize the cardinality of my set. Okay, that's what I mean by good training set. Subject to that, if I give this training set to my student, the student is going to apply a and arrive at the target that I want. Okay, so that's the general idea of this. It turns out this problem has been studied before in computer theory, where this objective is known as the teaching dimension. Okay? So it's a distinct but related quantity to, say, VC dimension, smallest number of examples.
00:31:21.486 - 00:32:23.182, Speaker A: You will need to exactly teach a concept to a learner. Okay, so now why is this problem interesting? Besides like being a really interesting theoretical problem, I claim that this is also something that we can use to potentially improve human education. You just think of human student as your learner a. We, of course, need to assume a certain computational model of the student a. But if that's the case, if we have a way to formulate what our teaching goal is, then we can use this to essentially come up with the best lesson. Of course, here, best is defined as the shortest lesson in some way. But you can imagine generalizing both this here and relaxing this equality.
00:32:23.182 - 00:33:27.678, Speaker A: So the idea is, maybe you don't want to teach exactly that model. You just want to say, close enough is fine. And then here, instead of just the size of the training set, you can put some form of teaching effort on different training items, like you may want to teach using simple examples, for example. Okay, so what I can tell you is this idea actually works. We worked with psychologists, and we did so not education in classroom setting yet, but we did something in competitive science where we teach people to do categorization in a 1d stimuli space. So this is the typical psychological experiment that you see people do. Basically, we have a bunch of line segments displayed on the computer screen, and the human participant, we need to teach them which ones are called short, which ones are called long.
00:33:27.678 - 00:34:30.060, Speaker A: Okay, so as you can imagine, it's the Wendy threshold classification problem, right? And they receive a training set of n different line segments, each with a correct label. And then they need to learn from that and predict on future lines, segments randomly draw from different lengths. Okay, I'm not going to go into the details, but just to tell you that on that type of problem, psychologists have accumulated a whole bunch of different computational models of human like a. They have different assumptions of what a the algorithm is for human being. We took one commonly used a model, and we use the teaching framework to actually design a training set and compare it with just randomly selected training set. Training on humans. And yes, humans do generalize better using this training set.
00:34:30.060 - 00:35:47.242, Speaker A: So not too surprising, except that it's actually, on humans, super noisy, but, you know, to see it work. Okay, so let me bring it back to the question here that related to the workshop. What if we want to teach over a graph? So why do we want to do that? Maybe there are conceptual graphs in humans mind. For example, remember the animal graph? And labeling on this graph could map to how people think about different animals. For example, if we tell a child, like, hey, snake is poisonous, but let's say a cow is not poisonous, right? This is essentially like, you put seed labels on some of the nodes, and they're going to form opinions out. Some of the graph based diffusion algorithms can be used as a hypothetical cognitive model in terms of how they diffuse that information. So here's the setup.
00:35:47.242 - 00:36:38.580, Speaker A: Let's say we have a graph undirected, and let's say we have a target labeling. Yeah. So this y is a fixed and given labeling on each and every node on that graph. So that's our teaching goal. Furthermore, we need a model of the student. Now, for this group, let's just say it's mincut. So the idea is, if I give you a set of seed nodes on the graph, seed labels say binary, and you do a mean cut on the graph from that seed set, you will arrive at essentially a cut or a complete labeling of the whole graph that's here.
00:36:38.580 - 00:37:47.194, Speaker A: So y s is the seed labeling on the small set, s, and a is this diffusion algorithm, or label component algorithm on graph. We want this diffusion to eventually arrive at our goal y. But how do we choose the initial set, for example, so that it's as small as possible? And, of course, this is the inverse problem of graph based semi supervised learning. Let me show you one example here. We used a particular diffusion algorithm, not mincut, just because it's somewhat easier to compute it as a closed form, the way I. Okay, so, yeah, this is a four by four grid, just four by four grid connected. What I'm plotting here is each pixel is really a node in the graph.
00:37:47.194 - 00:38:11.456, Speaker A: And I have, let's start from this, ignore the green regions. I have four seed nodes. Two are blue, two are red. Okay? Those are the two different classes. Starting on this graph. I do the diffusion, and this is the result. I basically cut the graph in this form.
00:38:11.456 - 00:39:21.604, Speaker A: Right? So I have this. Now let's think about the inverse problem. If that's the case, if I assume this is the eventual goal I want, is there a smaller seed set such that if I give it to the same diffusion algorithm, will result in the same classification here? That's the problem. And we actually did it by brute force on this very small example, as you can imagine, I can just enumerate all two to the 16th different initiatives, sets and give it to a and see what happens. Turns out you have many, many solutions. And I'm just plotting here a histogram of solutions. So what we have here is this x axis is the size of your initial set, and these sets all succeeded in producing the final, the sine target classification.
00:39:21.604 - 00:39:45.664, Speaker A: So you have a whole bunch of them. Okay, what's interesting is, um, is this guy here, that's the smallest solution. Turns out you have two solutions, two initial training sets of size three. That's the smallest. You can go for this particular example. And they look as follows. Remember, that's the target classification.
00:39:45.664 - 00:40:33.744, Speaker A: That's one initial seed set, just happens to be two red here and one blue there. Again, ignores ring. Here is another one. Turns out these are the two. Okay, now the question is, which we have no answer yet, is, can we say anything about the smallest sign size with respect to some spectral property of the graph? And there's, of course, an algorithmic question, how do you actually find the smallest s? So I'll be happy to hear from the audience. And that's all. Thank you.
00:40:33.744 - 00:40:42.004, Speaker A: Questions.
00:40:45.544 - 00:40:53.584, Speaker B: It looks like you might have to, especially teaching humans, for example, to accomplish a task, it seems like you would have to learn the learner.
00:40:53.704 - 00:41:13.820, Speaker A: Yes. So, in fact, that's very true. It really says, like for humans, you need to learn what their essential a is. Yes. And that's an empirical question. And you can imagine we run human experiments by giving them partially labeled graph, let them finish. Right.
00:41:13.820 - 00:41:33.974, Speaker A: And try to maybe fit it against one of the algorithmic procedures. That is indeed true. And here I'm just abstracting it and just pretend that we have one of the algorithms here. Thank you.

00:00:00.680 - 00:00:33.214, Speaker A: Our next speaker that some of you know and some of you wish you knew, because Narika Rieson started with proof complexity, and she went to work on things that everybody's talking about before everybody was talking about it. And moreover, she got people to talk about them. And I. I'm sure she'll do a better job than I do explaining what you've done, but that's amazing. Please, Nadine.
00:00:33.834 - 00:00:38.530, Speaker B: Thank you very much. Can you hear me very well?
00:00:38.642 - 00:00:39.874, Speaker A: Yeah. Can you turn it off?
00:00:39.994 - 00:00:55.170, Speaker B: Okay. Thank you. So I'm so honored to have the opportunity to speak at this workshop celebrating the 60th birthday of my dear friend Tony Pitesi. Can you see me, Tony? No.
00:00:55.202 - 00:00:55.774, Speaker A: No.
00:00:57.314 - 00:02:16.016, Speaker B: Throughout her career, Tony has been a dedicated and aspiring teacher, mentor and scholar. Her commitment to academic excellence and her passion for her field of research have inspired countless students and colleagues over the years. But perhaps most importantly, Tony has been a true leader in her field, blazing a trail for women and minorities in academia. Her commitment to diversity and inclusion has been a hallmark of her career, and her tireless efforts to promote equity and fairness have inspired us all. Our friendship began in 1998, whom we met during a special year of proof complexity at the Fields Institute led by Steve Cook, Allen Borodin, Faith Allen, Terry Lakoff, and of course, Alistair Arkhart. And Tony were there in Toronto. And Maria Bonet, Ram Raz, Sasha Raz Baroff, Alan woods, and of course, Aviwig disjoined.
00:02:16.016 - 00:02:46.220, Speaker B: It was truly wonderful moment in my life. So today I would like to talk about my thoughts on proof complexity from my point of view. Before I start my talk, I would like to ask you one question. It doesn't work. It doesn't move for some reason. Okay, I see. Okay, cool.
00:02:46.220 - 00:03:33.754, Speaker B: Let's do this. What is your favorite theorem? I forgot to ask Tony what her favorite theorem was. We were so busy with talking about good food, like sushi and cooking, because both of us love cooking, so that means we chat a lot about good food and again, good food. So we didn't have enough time to discuss with each other what our favorite terms were. My favorite term is Gentzen's cut elimination theorem. No hesitation? Absolutely. Let me briefly introduce you to Gentzens sequent calculus.
00:03:33.754 - 00:04:25.354, Speaker B: A finite sequence of formulas is called a sedent. A sedent can be empty. Two sedents connected by an arrow are called a sequence. Commas to the left of the arrow are interpreted as ands, and those to the right as ors. Here's an example of a sequence. In textbooks, Lk is introduced as a system that starts with an initial sequence of the form a and constructs a proof of a theorem by applying left or right logical rules. Let us consider in reverse.
00:04:25.354 - 00:05:31.984, Speaker B: First write the theorem you want to prove at the bottom. Then by applying logical rules to the outermost logical symbol of the outermost formulas of the sequence and backwards suppose that a one in this sequence is of the form a or c. In this case, the outermost logical symbol of the leftmost formula is or. So two upper sequence were generated. The number of logical symbols in a and c in upper sequence is at least one less than that in a or circle in the lower sequence. If all paths lead to the initial sequence, you can complete the proof without any talent. However, that's right.
00:05:31.984 - 00:06:27.114, Speaker B: Ok has an influence rule called cut. This is the only one that does not predict epic sequence from the lower sequence. In other words, you need talent to come up with an appropriate cut formula x. But be glad hats are removable. This is a cut illumination column by Genton unlike many of you here today, I was not very good at math until I graduated from high school. In college, I majored in law and later switched to mathematical logic. So perhaps I have been so fascinated by the capillimation theorem, which suggests the possibility of writing proofs without talent.
00:06:27.114 - 00:07:40.644, Speaker B: However, it is not all good when cuts are eliminated. Proofs almost always explode exponentially or super exponentially. So when George Bulos wrote in his essay don't eliminate cuts, he had a good reason. By the way, I said almost always right? So what is exception? Tony Alistair and I discussed exception in our stock paper. The propositional logic version of ok, limited in the conjunction in conjunctive normal form without cut, is almost equivalent to the analytic tableau. Right? On the other hand, a system of OK with admit cuts, of course, you know, limited to CNF formulas, is almost equivalent to resolution. We have shown that there is only a quasi polynomial gap between the two.
00:07:40.644 - 00:08:21.458, Speaker B: As far as I know, that is probably the only exception. If you know other exceptions, please let me know by email. This means the proof without cut in order. In other words, the proof without talent takes a tremendous amount of time. It seems that there is a trade off between talent and time it takes to prove. And I think this is exactly what the proof complexity is all about. That is my point of view.
00:08:21.458 - 00:09:05.004, Speaker B: Okay. Regardless of what Bulow says, I could not give up the hope of writing proofs without talent to think about this. You know the possibility, probably it requires some preliminary studies. So the first order predicate logic, as we learned in logic 101, is complete. It was proved by Gedel in 1929. It can also be proved, you know, kind of utilizing LK's cut elimination theorem method. However, it is not decidable.
00:09:05.004 - 00:09:53.984, Speaker B: There is more bad news. Piano arithmetic is incomplete. Not only the original piano arithmetic, but any essential arithmetic subsystems like s twelve by bus, by semi bust, any essential arithmetic subsystems which allows gadda numbering is all incomplete. That is very sad. However, the last some good news positive result, the net, as well as well known as ghetto's incomplete. Nephilim tell us some decidable theories. Yes, these results are mainly due to Alfred Polsky.
00:09:53.984 - 00:10:52.144, Speaker B: While many of these decidable theories may not appeal to professional mathematicians, there are also interesting theories in in which rich mathematics can be developed. A typical example is the theory of real closed fields. I think, and I will come back later, how it is interesting. So some systems are incomplete, while some others are decidable. This means that when we are asked to prove why, how much talent is required depends on the context. Not only did you know what why is, but it really depends on context. Let me consider the next problem.
00:10:52.144 - 00:11:43.014, Speaker B: This one prove the following. Can you see the formula? Okay. Can you solve it? At first glance, many people may think it is a theorem of real numbers. But if you try to think why does x cubed Y plus Y is less than twelve? When y is less than one, you will get stuck. You will be in a big trouble. Instead, why don't you think in this way? You may have already noticed that the formulas Y less than one and x cubed Y plus y less than twelve appear twice. Let's just call them p and q respectively.
00:11:43.014 - 00:12:35.356, Speaker B: Then we could replace them with the following propositional formulas. Right? As we all know, propositional calculus is complete and decidable. What is the decision procedure? The truth table. Of course, writing the truth table, we found that this formula is a tautology. It does not require any talent at all. If you do not feel that you have written the proof with a truth table, you may want to draw a cut flea lk proof like this. Okay, so you may think it is really redundant, but actually the redundant ness comes from the structural rules in this figure.
00:12:35.356 - 00:13:10.604, Speaker B: But actually, you cannot eliminate the structural rules. I believe that could be another good, how to say, logic 101 or 201 assignment. So think about it. It is basically. It says basically p or not p. So the weakening is the structural rules probably required. So I'm sure you all now agree with me.
00:13:10.604 - 00:13:58.784, Speaker B: How much talent is required to prove Phi depends on the context. If phi is a proportional formula, you just, you know, write a truth table or cut free a k tree. If phi is a first order sentence, and if it happens to be logically valid, you can prove it without talent. You just write a cut free lk tree. If phi is a sentence in piano arithmetic, you need talent and luck to prove it. So probably I quit from it and I go to LCF. If phi is a sentence in the theory of real codes field, you can prove it or disprove it without talent.
00:13:58.784 - 00:15:00.358, Speaker B: So what exactly does it mean that real closed field is decidable. It means that for any LCF formula, there is an equivalent quantifier free formula. There is a very elegant and short model theoretical proof. However, there is a problem with model theoretical proofs, because they are not useful in many cases, because they do not give us any algorithms. Pelskis original proof theoretical proof is very long, complicated and tiresome. So I am not going to show that the tulskies, you know, original proof this time, you know, because this is birthday party. Nobody wants to read that proof.
00:15:00.358 - 00:15:54.784, Speaker B: I believe so. Today, probably only few people read his proof. However, his proof has a great point. He gave the concrete algorithm for quantifier elimination and showed that it terminates. Unfortunately, the size of the resulted quantifier flea formula may be super, super exponential to the size of original formula. Again, it seems that there is a trade off between talent and time. But I like to consider why talent is needed when writing mechanical proofs, especially when removing quantifiers by analyzing informal proofs.
00:15:54.784 - 00:16:33.844, Speaker B: As an example, let us prove the following LCF formula f x squared is continuous everywhere. Okay. This proposition, written in natural language with a formula if x equals to x squared, could be transformed into the following formal formula. Right? Epsilon, delta. Okay? The word everywhere goes here. Right? And the rest goes there. Right? So, four quantifiers are contained.
00:16:33.844 - 00:17:23.200, Speaker B: How can we eliminate them? Okay, so the outermost, you know, logical quantifier is a universal quantifier. So, to eliminate them, actually, you have to write the first line. The only way to eliminate it, to write, let x be a real number. Right. As the first line of the proof. By writing this, we can eliminate the first quantifier. The next quantifier is again a universal quantifier.
00:17:23.200 - 00:17:53.714, Speaker B: Right. Again. The only way to eliminate it is to write let epsilon be a positive real number. Then we can, you know, eliminate the second quantifier. Let us verify this in. Ok? Ok. Suppose that the outermost logical connective of the rightmost formula in succeeding is a universal quantifier.
00:17:53.714 - 00:19:28.134, Speaker B: By applying all right rule backwards, we can eliminate the quantifier by replacing x by eigenvaluable a in the formula B. In other words, no talent is required to eliminate the universal quantifiers in most of the theories, except for theories of natural numbers. Why are the theories of natural numbers exceptions? Because of the induction, right? So the induction is represented in Lk, as shown in the lower sequence, a new universal quantifier which is not in the upper sequence appears. In other words, unlike other areas of mathematics, in the theory of natural numbers, where induction is present, universal quantifiers may be introduced by a rule other than for all right rule. Fortunately, in LCF, we do not have to worry about induction. So we do not need to one day, you know, which for all right rule or induction be applied. You know, just, you know, for all right rule.
00:19:28.134 - 00:20:30.194, Speaker B: So the, now the most outermost logical symbol is existential quantifier. This cannot be eliminated as easily as universal quantifiers. This is because we have to find the witness delta such that for all y, for any real number y, such that the distance of x squared and y squared is less than epsilon when the distance of x and y is less than delta. So the delta should be. The delta should be a term of the Volvos we have eliminated so far, which is x and epsilon. Let us calculate delta as mechanical as possible. Find the written s.
00:20:30.194 - 00:21:35.066, Speaker B: Okay, so the, the distance between x squared and y squared must be less than epsilon, right? So by applying triangular inequalities and stuff like that, you know, we have this inequality, then solve it in sigma in terms of sigma. Then we have this. So the right most, the, the term minus x plus square root of x squared plus epsilon can be the witness for sigma. So, so we probably will. We will notice that we cannot eliminate x from this wetness. So that means f equals to x squared is not uniformly continuous everywhere. So that is how it works in natural proof.
00:21:35.066 - 00:22:28.204, Speaker B: Let's also check with Lk to see why removing an existential quantifier does not go the same way as universal quantifier. This one here you see existing right rule in LK, if you look at the upper sequence, the term t appears instead of an eigenvalue. In other words, you have to find the witness to apply exist. Right or for all left. Roll in backwards in LK. So if you wish to write proof without any talent, you may have to try every term in ascending order of geronumber. Whatever.
00:22:28.204 - 00:23:49.284, Speaker B: Again, it seems that there is a trade off between time. So I began to think about what would happen if I let the world's least math talented but fastest calculator to solve LCF problems. That was the reason why I started an AI project. Can I AI pass the entrance exams of the University of Tokyo in 2011? With advent of chat GPT, there are now many attempts to get AI to take college exams. But when we started our project in 2011, that is, twelve years ago, no team anywhere in the world thought it would be possible. I remember that when the New York Times reported on our project in 2013 2014, the article made pessimistic prediction. Nevertheless, Pony grabbed the paper and took it to the Department of Computer Science and said, hey, look, Noriko made it into the New York Times.
00:23:49.284 - 00:24:54.144, Speaker B: I love that episode. It's right, Tony. How lovely. Usually mathematical, you know, problems are written in natural language with some mathematical experience expressions like this one. Even if the problem can eventually be interpreted as an LCF form problem, it is difficult to rewrite it directly into an LCF formula. The natural interpretation of the problem should be a higher order formula like this one, right? This required the interpretation still required a huge dictionary by hand. We had to teach our AI 2000 mathematical axioms and 8000 japanese words to make it accept the problems written in Japanese.
00:24:54.144 - 00:25:35.824, Speaker B: Next, it is converted into LCF formula. It is already very lengthy. I hate to read. Then our AI starts solving the problem using the latest quantifier elimination algorithm to get the answer. Okay. A fully opened the automatic math solving machine has been a dream since the birth of the word artificial intelligence. But it has stayed at the level of arithmetic for a long, long time.
00:25:35.824 - 00:26:16.842, Speaker B: In our project, we finally succeeded in developing a system which solved the pre university level like this one from nice. The end I'd like to show you a demo, but I'm not quite sure. It moves in zoom. Is it? Is it moving? No. Oh, good, good. If somebody cannot see online, you know, please watch my TED talk. The demo is included in my talk.
00:26:16.842 - 00:26:42.614, Speaker B: So now it, you know, output it the past three. So it is the in a precise, how to say, interpretation of the natural language. Now it is converting into the LCF formula and it stop. No. Go. Go and solve it. Go.
00:26:42.614 - 00:27:44.984, Speaker B: And it outputted. The following formula is obtained by Collins quantifier elimination algorithm. Okay, so the answer is one half and it is correct. The problem with this method, however, is that humans cannot understand the lengthy answers that are output. So let me first answer the question that you will probably want to ask most. Is this method still better than big data in the statistics and based method like stat GPT. CatGPT team has not published any result how well it does on math problems, so we cannot directly compare.
00:27:44.984 - 00:28:27.084, Speaker B: But we are very confident that current state of the art is our AI invented by our machine. If you are interested, please read this paper accepted last year by Izukar. The time left for my talk is now very limited. I really regret that I will not be able to attend the party celebrating 20th birthday that will be held after my talk. Everybody is there.
00:28:31.704 - 00:28:37.244, Speaker A: You can attend on zoom. There is a zoom. There will be zoom cards with a camera special for you.
00:28:39.744 - 00:29:18.344, Speaker B: That will be good. So in closing, I'd like to wish Tony a very happy birthday, 60th birthday, and express my deepest gratitude for all that you have done for us and for the academic community. May you continue to inspire us for years to come. Thank you very much and see you all sometime in Tokyo, probably very soon. Thank you very much. Can you hear me?
00:29:20.814 - 00:29:29.470, Speaker C: So first I just wanted to say that I love to watch you cook and maybe other people.
00:29:29.622 - 00:29:30.510, Speaker B: Is this Tony?
00:29:30.582 - 00:29:31.510, Speaker C: Yes, yes.
00:29:31.542 - 00:29:34.358, Speaker B: Hi, Tony. Hi. Hi.
00:29:34.526 - 00:30:00.578, Speaker C: No, I have a more serious question. Maybe other people have the same question. So do you think that. So if you have any opinions on not the current chat GPT, but you know what, what the future is of proving. Yeah, proving theorems, you know, with talent and with explanation, you know, where there's some reflection that the algorithm knows what it's.
00:30:00.666 - 00:30:57.062, Speaker B: Yeah, well, actually, that's what it knows. Yeah, I know, I understand your worry too. And I cannot say everything about, you know, the future, you know, it's so hard to predict right now, but as long as I experienced that, the chatter GPT is, what chatter GPT is doing is mainly the, the searching. So if he cannot search, then, you know, he cannot come up with the answer. And if he wants to really, you know, prove it or, you know, solve it, you. It has to, you know, develop that, you know, semantic dictionary and the defining axioms. And it is really, really time consuming.
00:30:57.062 - 00:32:23.454, Speaker B: And the question is, if the AI can make this dictionary by itself, not, you know, asking human to work. I'm not. Yeah, no, I don't think so, probably. And also, you know, there's no other ways than the quantifier elimination or, you know, other, you know, the things that we developed in logic, you know, there is no way to get the answer because it is kind of weird, you know, if you see that the tedious, lengthy proofs that our system produces, it's like, you know, like 100 pages long. And it is, it seems to me. For the computer, it is hard to say which formula is important, which others not. It cannot.
00:32:23.454 - 00:33:26.244, Speaker B: How to say, compare the importantness of the dilemmas and the formulas that he cannot understand the redundant formulas versus important formulas. Can you understand what I mean? It seems that my AI cannot understand the importantness of the. How to say, the formulas it produces. So I don't think other than searching, nowadays deep learning machines can do better than this. That is what I can say. But it is really hard to predict the future right now in AI. Thank you.
00:33:26.244 - 00:33:43.724, Speaker B: Oh, thank you. Noriko. Yes? Hear me? Yes, I can hear. Okay. This is Maria.
00:33:45.864 - 00:33:48.040, Speaker A: Maria. Maria Luisa Bonet.
00:33:48.232 - 00:33:49.084, Speaker B: Maria.
00:33:52.904 - 00:33:55.824, Speaker A: Well, I just wanted to say that, you know, there is a lot of.
00:33:55.864 - 00:34:42.681, Speaker B: Talent in your work, you know, and I congratulate you and I miss you a lot, you know, I miss you a lot, too. Why don't you come? See, see, probably you came to Hiroshima, right? But you didn't come to the Tokyo because you are so worried about the earthquake. Probably. But, you know, Abby and Tony, of course, and also Arnold Beckmann and the islanders. Everybody came in. We have, you know, kind of room for logicians. Any logicians are welcome to come to my house.
00:34:42.681 - 00:34:54.173, Speaker B: We. Our house is called logic house. Okay? So everybody is welcome to come. Okay. So, Maria, please come sometime. Okay. Okay.
00:34:54.173 - 00:35:00.293, Speaker B: Thank you. Thank you. Is Alistair there?
00:35:01.794 - 00:35:05.374, Speaker A: Alistair was online. I don't know if he still is online.
00:35:06.074 - 00:35:07.934, Speaker B: Hi. Hi. Alistair.
00:35:08.234 - 00:35:12.614, Speaker A: He couldn't come at the last moment. He was going to be. Yeah, Alistair's here.
00:35:13.394 - 00:35:14.642, Speaker B: Yeah, I can see him.
00:35:14.738 - 00:35:20.794, Speaker A: Yeah, I guess we can see him. But you can and that's what matters.
00:35:20.954 - 00:35:39.148, Speaker B: Yeah, I could see him. That was great. Okay. Yeah. I'm so grateful. And who else? Is Sam there? I want to see Sam, too, if I can.
00:35:39.276 - 00:35:40.972, Speaker A: Hello, I'm here in person.
00:35:41.028 - 00:35:43.348, Speaker B: I'm so grateful. I'm so grateful.
00:35:43.476 - 00:35:44.664, Speaker A: Thank you for the call.
00:35:45.004 - 00:36:05.584, Speaker B: Most of my, you know, the work is due to your bounded arithmetic and also the. What was that? The kinko's copy, you know, published your lectures. Yeah, that was my textbook. Thank you very much. I'm so grateful.
00:36:05.744 - 00:36:07.896, Speaker A: Oh, thank you for the talk. That was delightful.
00:36:08.000 - 00:36:10.364, Speaker B: Yeah, thank you. Thank you.
00:36:10.704 - 00:36:12.640, Speaker A: Yeah, the talk was fantastic.
00:36:12.832 - 00:36:13.608, Speaker B: Oh, thank you.
00:36:13.656 - 00:36:20.204, Speaker A: To let you go. Vinous food is waiting. People don't want to let you go. And that's something.
00:36:22.064 - 00:36:23.484, Speaker B: Thank you very much.
00:36:24.144 - 00:36:29.524, Speaker A: I have a question, but for joining. So what is your favorite theorem?
00:36:32.984 - 00:36:43.336, Speaker C: I was stressing when. I was stressing when you asked the question thinking that you were going to want an actual answer. And what came to my mind was the completeness theorem, which is pretty much.
00:36:43.360 - 00:36:59.784, Speaker B: What you said was your favorite completeness theorem. Many people love, you know, incomplete nestorium. But, you know, I thought, you know, more in a complete nest area. And cut elimination is more positive, you know.
00:37:02.244 - 00:37:08.540, Speaker A: And just probably Tonya just gave, like, a two week long tutorial on completeness here. I'm in a reading here.
00:37:08.652 - 00:37:10.916, Speaker B: Oh, that's great. I should have.
00:37:10.940 - 00:37:13.104, Speaker C: I think you explained it better. Anyways.
00:37:13.684 - 00:37:18.534, Speaker B: Okay, thank you very much. Such a warm event.
00:37:20.594 - 00:37:25.530, Speaker A: Anybody? Well, thank you so much, Narita. This was fantastic.
00:37:25.722 - 00:37:30.730, Speaker B: Thank you. Thank you. See you. See you soon. Bye bye.
00:37:30.762 - 00:37:38.654, Speaker A: Thank you so much for making it online at this ungodly hour. It's 830 in the morning in Japan. Can you imagine?
00:37:42.134 - 00:37:44.194, Speaker C: You did it two mornings in a row.
00:37:44.614 - 00:37:55.634, Speaker A: Oh, yes. And my fault, I say, oh, yeah, it will be on Monday. But Japan is well ahead of the rest of the world, in case you don't know.
00:37:57.414 - 00:37:59.038, Speaker B: No problem, no problem.
00:37:59.126 - 00:38:02.714, Speaker A: I'm so sorry about that. But so good to see you.
00:38:04.014 - 00:38:07.454, Speaker B: That's great. Yeah. Yeah, I rehearsed it yesterday, so it was good.

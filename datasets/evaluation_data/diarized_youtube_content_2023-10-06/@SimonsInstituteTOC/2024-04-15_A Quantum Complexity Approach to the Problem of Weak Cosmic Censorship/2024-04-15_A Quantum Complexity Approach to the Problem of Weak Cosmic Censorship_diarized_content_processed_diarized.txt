00:00:01.480 - 00:00:10.174, Speaker A: Okay, I think we're gonna get started. We're a little bit over time already, so we're really happy to have Netta Englehart from MIT, who's gonna tell us about the quantum complexity approach to the.
00:00:10.214 - 00:00:12.074, Speaker B: Problem of cosmic censorship.
00:00:13.414 - 00:01:21.238, Speaker C: Thanks for having me at this wonderful workshop. So, I'm going to be talking about a quantum gravity problem, the problem of weak cosmic censorship, and using tools and techniques that are hopefully familiar to most people in the audience from quantum complexity theory. And this is based on a recent paper from last month with my student Osman Folkstrad, postdocs Adam Levine and Avita Verheiden, and my student, Lisa Yang, who's sitting right there. So, a large part of this talk, one might even say the bulk of this talk, will be dedicated to motivating and explaining this problem of weak cosmic censorship. This is a physics talk, so a lot of it will be about, why is this an interesting physics problem? Although I do promise that at least some part of it will be on how quantum complexity and tools from quantum complexity can offer a resolution. So I'm going to begin with some very broad motivation here. Now, black holes have been just absolutely one of the most insightful phenomena in quantum gravity.
00:01:21.238 - 00:02:03.406, Speaker C: They've led us to so many interesting discoveries, and much of our understanding in quantum gravity comes from the study of black holes. And specifically, I would say many, I would actually say, probably most of the seminal developments in quantum gravity in our understanding of quantum gravity hinge on the thermodynamics of black holes and the understanding that black holes are thermal objects with a microscopic statistical understanding. So, here I've drawn the kind of picture that I'm going to use throughout this talk, which is a three dimensional rendering of a collapsing black hole. So, time here runs upwards. This is not. Please don't try to assign a tensor network interpretation to any of the lines. This is meant to be a sphere.
00:02:03.406 - 00:02:34.824, Speaker C: I can't draw in four dimensions. So it's, you know, it's just around a circle here. And this is the radius of this circle. The sphere is shrinking on the force of its own gravitational field. Eventually, an event horizon forms. This is this gray region over here, and this star just keeps on collapsing, and eventually we get a curvature singularity where the curvatures are divergent and sort of general relativity completely breaks down. So, this is the schematic I'm going to use to talk about the time evolution of black holes throughout this talk.
00:02:34.824 - 00:03:02.702, Speaker C: Now, again, black hole thermodynamics, black hole statistical mechanics. One of the most insightful aspects of it has been the study of black hole entropy. So, black hole entropy, we understand count states that are black hole. We call them black hole microstates. They have the same black hole exterior, but they look different inside the black hole. And you can derive this in various different ways. We haven't established it in broad generality, but in certain cases, you can do literal alliteral counting.
00:03:02.702 - 00:03:43.694, Speaker C: They are famously done by Stravinger and Waffa. In string theory, we can do this in certain cases also in ads CFT. So there is strong motivation to expect that this is true. Now, conversely, it also appears to be true that thermodynamic ensembles in quantum gravity. So here in the Gibbs state, these are black holes, at least as long as they're energetic enough. So if you have a sufficient amount of energy, energy above a certain threshold, then the thermodynamic ensembles are black holes, and the microstates of those ensembles are black hole microstates. So this is, again, something that we can show in certain cases, most famously in certain cases in ADSC, and, in fact, in ads CFT, we can go further.
00:03:43.694 - 00:04:21.714, Speaker C: We can even match the computations in certain cases. So, for example, you can do a calculation of the out of time order correlators in ads black holes, and you can do it in the CFT, you find that there's. In the CFT, we know there's a chaos bound that has to be satisfied by these. In the bulk, we find that the chaos bound is satisfied. And I think in Syk, we can actually do an exact matching of the saturation of the chaos bound in both cases. So there's this remarkable agreement between the states that look like this and just really typical states in CFT's and what we see for the behavior of black holes. So all of this story is consistent.
00:04:21.714 - 00:05:13.334, Speaker C: If there were black hole thermodynamics, Ads CFT, Strahman, Java, all of these. This is all consistent if black holes are typical states in the Halberd space of quantum gravity. And I would say that statement is pretty uncontroversial. It's kind of like conventional wisdom in ads CFT, black holes are typical in the Hilbert space, as long as you're above some energy threshold, because black holes are energetic phenomena. Okay, now, I feel like I've motivated this very well, but let's have a sacrilegious thought here. What if black holes were not typical states in quantum gravity, even above a certain energy scale? What terrible thing would happen? Well, that would mean that there's some other extremely energetic quantum gravity phenomena. Extremely energetic, typical states, typical gravitational states that would not be black holes.
00:05:13.334 - 00:05:47.394, Speaker C: And because they're typical, they would have to match the behavior that we know is true in the CFT. So there has to be some kind of a matching between these typical states that are not, that would not be black holes under this sacrilegious thought. Well, but we would also know, we know that black holes still also. Yeah, Michelle's question. I wanted to ask if you could give a more precise definition of typical. I guess I cannot, because I don't know what the measure on the space of the quantum gravity Hilbert space is. So we'll say typical understood to be under some measure on the quantum gravity Hilbert space, whatever that measure is.
00:05:47.394 - 00:06:13.914, Speaker C: So, well, if we, under this sacrilegious thought, black holes are atypical states, which means that the fact that under this premise they match, we know they've done the calculations, they match everything we see in CCFT. That would be a remarkable coincidence. That would be kind of a conspiracy. So, you know, that seems like pretty good motivation to conjecture. Yes, black holes are typical states. Why are you telling us this? This is conventional wisdom. We all know that this probably must be true.
00:06:13.914 - 00:06:58.924, Speaker C: I'm building up to something. Hopefully it's clear now I'm going to keep on pursuing the sacrilegious thought, even though it appears that there absolutely no basis to it, because there'll be a reward for that at the end. Let's just persist with it for a second. Ask what would be these highly energetic gravitational states that are not black holes? What does such a thing even look like? And these are known as naked singularities. So let's begin with the background statement here, which is that there's a number of beautiful theorems in GR, Hawking and Penrose and so on, that guarantee for us the generic gravitational processes that are high energy will evolve to form singularities in spacetime. So singularities, you know, is the regions in space time where curvatures are extremely large. General relativity breaks down.
00:06:58.924 - 00:07:27.074, Speaker C: So usually. Again, the conventional wisdom is that singularities reside behind event horizons. They are cloaked or clothed by event horizons, so we don't see them. But if we have high energy gravitational processes that don't result in event horizons, don't result in black holes, therefore don't result in event horizons, then we have to have the singularities occurring without event horizons. So then we would, then we would have naked singularities. That would be what a. Just 1 second.
00:07:27.074 - 00:07:32.858, Speaker C: That would be what? A generic gravitational process that doesn't have an event horizon look like?
00:07:32.906 - 00:07:39.734, Speaker B: Yeah. Are you assuming that contemporary states have a geometrical interpretation in order to have either black holes or.
00:07:40.274 - 00:07:44.600, Speaker C: Absolutely. So here I'm only talking about safety states with the geometric interpretation so typical.
00:07:44.672 - 00:07:47.128, Speaker B: Among that subset of states. That's correct, yeah.
00:07:47.256 - 00:08:03.320, Speaker C: Well, I mean, okay, you could be a little bit more specific. You could say, well, do we think the typical ones have at least a causal wedge interpretation in some large subspace of the Hilbert space? And then you could ask, what goes beyond the causal wedge? Is it a naked singularity or is it an event horizon? So we could. We could insist just on a geometry emerging in part of the space time.
00:08:03.352 - 00:08:04.848, Speaker B: Rather than the full space time.
00:08:05.016 - 00:08:39.125, Speaker C: Yeah, I don't care if there's, like, a firewall behind, you know, at the event horizon. So, okay, so what would these look like in this three dimensional rendering? Well, here is a star that collapses and there's just no horizon. So it forms a singularity that can be something that looks like a line singularity here, one dimensional. You could have a higher dimensional singularity like this cone over here. So this can come in all sorts of shapes and sizes. Okay, now, other motivations for why black holes should be typical states. I know you're all convinced by now that they must be.
00:08:39.125 - 00:09:02.064, Speaker C: So, but I'm going to just keep on going for a little bit. There's an empirical motivation. If you look up into the night sky, to our knowledge, you know, we've been doing this for millennia, and to our knowledge, we have yet to see a naked singularity in the night sky. But we have a lot of evidence that we're seeing black holes there. Okay, so maybe black holes are generic notion. Generic feature in nature. Yeah.
00:09:02.184 - 00:09:05.152, Speaker B: What would happen to the sky?
00:09:05.208 - 00:09:28.056, Speaker C: That's an excellent question, which is why I said, to the best of our knowledge, we have not seen a naked singularity. We haven't seen some kind of a huge burst of energy that we haven't been able to explain using some other astrophysical explanation. So a naked singularity, we don't know what it would look like, but you might conjecture. We would expect that it would be some unexplained access that we would not be able to explain otherwise with, you know, oh, there was a neutron star that did something that causes.
00:09:28.200 - 00:09:28.924, Speaker B: Yeah.
00:09:32.744 - 00:10:02.424, Speaker C: And also there's a mathematical motivation for this. The conjecture that black holes should be generic is actually, it's much older than the information problem. It's dates back to the 1960s. And the original mathematical motivation for it was this one, which is that our universe is very close to being spherically symmetric. We know what gravity looks like for its spherically symmetric black holes. We know what the spherically unique, spherically symmetric vacuum gravity solution is, and it's the Schwarzschild black hole. We know that that's stable, and there are perturbations.
00:10:02.424 - 00:10:46.160, Speaker C: So it seems that, okay, you know, unless you have some large deviations from spherical symmetry, reasonable to expect that. Okay, probably, you know, the Schwarzschild solution is, roughly speaking, the kind of solution that we are interested in for describing our universe. So, okay, hopefully I've convinced everyone here that, yes, black holes are typical, and no one was surprised by this. Black holes, for many, many different reasons, should be generic phenomenon gravity. And this has led to the weak cosmic censorship conjecture dating back to the 1960s, but, you know, has been modified over the years to make it more and more mathematically precise. So this don't worry so much about the weak. There's also something called the strong cosmic censorship conjecture, but it's not any stronger than the weak one.
00:10:46.160 - 00:11:34.522, Speaker C: So I'm not sure why. You know, they're just kind of two separate things. Okay, so the idea is that the collapse of matter, the generic collapse of matter in general relativity, together with matter fields, and this asterisk, just refers to various assumptions about the matter fields, like energy, positivity and so on. This generically results in event horizons, and the singularities that result from gravitational collapse are generically hidden behind event horizons. So this is, roughly speaking, the statement, the conjecture of we cosmic censorship. And I'm going to make one aside here, which is very important for the rest of the talk, which is that by definition, a black hole is something that is a region of space time behind an event horizon. So when I say there exists an event horizon and I say there exists a black hole, those two statements are equivalent.
00:11:34.522 - 00:12:04.484, Speaker C: I'm going to be using them interchangeably. So this is a conjecture. It's a very, you know, it's a conjecture that's been broadly believed. It's something that articulates everything that I was motivating just now. And now, finally, for the punchline, it's false. The conjecture is false. There is a plethora of examples at this point that show that the generic collapse of matter in general relativity plus matter field, obeying all of those conditions in the asterisk, can result in naked singularities in general relativity.
00:12:04.484 - 00:12:22.346, Speaker C: So this is just a small list of the counterexamples. There are counterexamples in higher dimensions. There are counterexamples with negative cosmological constant in four dimensions. And it looks like they might be a counterexample in four dimensional, asymptotically flat space with vanishing cosmological constant. Yeah.
00:12:22.530 - 00:12:26.738, Speaker B: Are these things that we can see in practice or theoretically they exist or what?
00:12:26.786 - 00:12:41.642, Speaker C: Well, I'm not sure what you mean we can see in practice. I haven't seen one out the window. But, you know, these are solutions to the Einstein equation. They've been assembled. These are all constructive counter examples. They've been constructed.
00:12:41.818 - 00:12:42.530, Speaker B: Yeah.
00:12:42.682 - 00:12:53.530, Speaker C: We have the metric. Sometimes it's only known numerically. Sometimes it's known a little bit better than that. But these are. These are. These are known counterexamples. Now, given the way that I just.
00:12:53.562 - 00:13:05.354, Speaker B: Yeah. Could it be that they're non generic and yet somehow we are able to construct them? Would it be that there are some non generic, they are generated by some metric?
00:13:06.814 - 00:13:25.114, Speaker C: This is actually an important point. So, in classical general relativity, we can't talk about typicality because we don't have a helper space. We have a phase space. So when we talk about generic, what we mean is an open set in phase space. You can prove that these are an open set in phase space. Yeah. These are not going away anytime soon.
00:13:25.114 - 00:14:17.780, Speaker C: And so that means, given the way I just motivated, how many things depend on cosmic censorship being true, that means that we have a real problem. So, this is why I call it the problem of cosmic censorship rather than the cosmic censorship conjecture. The fact that cosmic censorship is false threatens the consistency of fundamental aspects of gravitational physics. And I'm going to tell you how quantum complexity can help us get out of this hole. So, I'm going to begin with a few observations. Now, most of these known counterexamples, most, but not all, of the known counterexamples to weak cosmic censorship also happen to violate other conjectures about quantum gravity. So, for example, even though they appear to be totally valid solutions to Gr, and they are totally valid solutions to Gr, they satisfy various energy positivity conditions.
00:14:17.780 - 00:14:48.664, Speaker C: But some of these examples, for example, violate ryuutachiyagi. Can't have Ryu tachyanagi in some of these examples, even though they're asymptotically ads satisfying, you know, the normal energy condition, or really, they don't satisfy the covariant version of this formula. Other examples violate something called the weak gravity conjecture, which is something else that's been conjectured to be true about quantum gravity, even though they look totally innocuous and, you know, legitimate at the level of classical general relativity. So this is not true for all of the counterexamples, but it's true for many of them. Yeah.
00:14:48.824 - 00:14:54.192, Speaker B: You say they violate ryu tsaki nagi. Does that mean that you can construct the counter examples in the context of ads CFT?
00:14:54.328 - 00:15:32.860, Speaker C: Yes. Well, you could ask, does it have a CT rule? That's the real question, and I think the answer is no. That these are asymptotically ads solutions to Gr with classical matter, well behaved classical matter that do not admit a CT rule. Yeah. So is there a version of the weak class of censorship conjecture, which is false in classical relative in classical GR, because we know it must be false in classical Gr, since you have counter examples, but it is true in the classical limit of quantum gravity. And there's a big difference between these two. The classical limit of quantum gravity does not give us all possible classical GR plus matter theories.
00:15:32.860 - 00:16:06.718, Speaker C: This is something called the swan plan. Some theories that look totally valid classical Gr plus matter do not admit an uplift into quantum gravity. So the question is, is cosmic censorship or some version of it, something which is only true about those solutions to Gr, which are also solutions to quantum gravity in the right limit. And that's the hypothesis we want to pursue. To test this, we actually need a quantum theory of gravity, though. And so we're going to use ads CFT for this. And I'm going to use the fact that this is the last talk in this conference before the panel, and that I think most people before me have used.
00:16:06.718 - 00:16:35.844, Speaker C: Not most, but in the last couple of days, most people have introduced ads CFT. I will not be introducing ads CFT. It's already been introduced many times. So in this talk, I'm going to give a physics level of rigor theorem. Some parts of it are math level of rigor. But since there are also parts that are physics level of rigor, I'm just going to apply that sticker to everything. And this theorem is going to guarantee typicality of event horizons in ads under the following assumption, that the fundamental time evolution of the CFT is a pseudo random unitary.
00:16:35.844 - 00:17:32.940, Speaker C: So this gives us at least a guarantee that under certain assumptions, we have enough of a version of we cosmic censorship, that not all hope is lost. Okay, so what do we want to do here? We want to prove a sufficient condition for the existence of black holes in typical states, also known, the existence of event horizons. Now, for that, I need to tell you, how do we characterize the existence of event horizons? So, if you have some point calls point p, which lives outside of an event horizon, that means this statement here means that there exists an observer on the asymptotic boundary. I have a picture in the next slide who can jump into the bulk, reach the point p, and then travel back towards the boundary. That's what it means for the point to not be behind an event horizon. This condition fails if and only if this point lies behind the horizon. You can think of it as a definition of having a horizon in the bulk.
00:17:32.940 - 00:18:07.524, Speaker C: So here's a picture. So here is the event horizon singularity behind it, and this is the asymptotic boundary. And if the point p lies outside of an event horizon, then you can have an observer. I almost put a picture of my graduate student Lisa here who jumps into the bulk, reaches pull, and then comes back out. Here's another point, can do the same thing. Once you go behind the event horizon, though, you can't come back out, so you can't come back out to the boundary. Now this region here that you can causally access by jumping in and jumping back out, we have a name for it.
00:18:07.524 - 00:18:42.714, Speaker C: It's called the causal wedge. So this is the causally accessible region. And if you don't have an event horizon in the bulk, then the entire spacetime is just the causal wedge. If you have an event horizon, then the causal wedge covers only part of the space time. Okay, so now we want to talk about event horizon specifically in the context of ads CFT. Again, our motivation here is we want to diagnose when we have event horizons when we give a sufficient condition that will guarantee for some version of typicality. So in order to do that, I'm going to talk about the ads CFT map, as contentious a point as that might appear to be.
00:18:42.714 - 00:19:35.864, Speaker C: So in general, if we have a sufficiently large code subspace, and I'm being vague right now, but I'll be more precise in a little bit, we expect that the ads CFT map is efficient. Actually, sorry, this doesn't even need a sufficiently large code subspace, but all right, the ads CFT map is efficient in log of the dimension of this code subspace outside of horizons. Just because you can jump in and you can jump back out, that's something you can do very efficiently. So the ads safety map is efficient outside of horizons. So in particular, that means that if you have a space time without any event horizon at all, the bulk demand remap is just efficient for all points. So no matter which point you want to reach, no matter what you, which if you want to reconstruct some operator at some particular point p, since no points lie behind event horizons, you can always just jump into the bulk, make a measurement at that point p and then come back out. So this is going to be an efficient process.
00:19:35.864 - 00:20:08.004, Speaker C: You can always do this. Now I'm going to assert, make one more assertion. In the limit where the bulk is semi classical, and I mean there's an emergent geometry, we take a very particular limit for that all of the operators in the bulk are low bulk complexity. Now this is in some sense, this is, you could, you could call this an assumption, you could call this an assertion. This is the definition of semi classicality. So I'm going to take this as a pillar. That does not mean that all operators in the CFT are low complexity.
00:20:08.004 - 00:21:10.056, Speaker C: It just means that in the bulk effective field theory, all operators are low bulk complexity. That means that if you do have a source of exponential complexity in the boundary, it has to be the ads safety map. Since the bulk operators are low complexity, the boundary operators are high complexity, that means that the map itself has to be high complexity. And since we know that the ads CFT map is efficient in the causal wedge, if there are sources of exponential complexity, if they are operators of exponential complexity in the CFT, that means that there's something outside of the causal wedge. And if there's something outside of the causal wedge, well then there's a boundary to the causal wedge, which means that the spacetime has an event horizon. So that's kind of the rough idea behind using various complexity arguments to diagnose the existence of event horizons. Okay, so what do we actually want to know here? We want to know if generic or typical initial data is going to evolve to form event horizons.
00:21:10.056 - 00:21:50.954, Speaker C: That's what we were interested in knowing. So I'm going to call the time evolution operator in the CFT. It's a unitary operator, going to call it UCFT. And if under this time evolution operator we have some CFT initial data, you know, some initial state, if it, you know, becomes something becomes exponentially complex, and I should have really said here, becomes exponentially complex to, it's really about reconstruction here. As long as the bulk is semi classical, the ads CFT map also has to be exponentially complex. This is the statement that I made before, right? If you're going to gain some sort of exponential complexity, the bulk is always going to be simple from the bulk's perspective. That means that you're going to get something in the ads CMT map.
00:21:50.954 - 00:22:11.504, Speaker C: Now again, the map is simple in the causal wedge. So that would mean that there must be more to the bulk than just the causal wedge and therefore they would have to be a horizon. So it boils down to essentially the fact that there might be something in the book that's exponentially hard to reconstruct and that would mean that we have to have an event horizon. Yeah.
00:22:16.724 - 00:22:22.732, Speaker B: I wouldn't be working with unitary properties anymore. Or like should I expect something else to break?
00:22:22.828 - 00:22:25.560, Speaker C: So if someone was sitting closer to the question, could just repeat the question.
00:22:25.592 - 00:22:28.928, Speaker B: Yeah, no, it's gonna be super exponential. There's like a super exponential property.
00:22:28.976 - 00:22:37.520, Speaker C: Oh, we don't, we don't, we don't really care about anything if it's exponential or more. So yeah. The thing that matters for us is exponential versus, I guess versus sub exponential.
00:22:37.632 - 00:22:38.324, Speaker B: Yeah.
00:22:39.264 - 00:23:30.750, Speaker C: Okay, so let's talk a little bit more about this time evolution operator in CFT. And when talk about event horizon formation, then we want to talk about dynamics. So again, like I said before, it's a unitary, it has features of maximal chaos, scrambling and randomness when acting on typical states. So just a few of the works that have investigated chaos and scrambling randomness in ads CFD and there's a long history of using various notions of randomness to model time evolution of gravitational systems. So Hayden Prescott used the two design to model very essential features with the time evolution of evaporating black holes. I've also been using, people have used, including myself, high random unitaries to talk about time evolution of black holes. Pseudo random unitaries defined here were used more recently, Kim and Preskell and myself with my student Lisa.
00:23:30.750 - 00:24:13.114, Speaker C: So there's a lot of history of using various notions of pseudo randomness to talk about the time evolution operator of this dual CFT. And I don't personally love using the Haw random unitaries because time evolution of the quantum gravity has to be generated efficiently. So I mean, yes, I've done it once, I'd rather not do it again. And in particular because we are concerned here with complexity classes and complexity theoretic arguments, it makes more sense to talk about pseudo random unitaries than essentially any other notion of randomness in this context. So we are going to model the time volition in quantum gravity on our choices of code subspaces using the pseudo random unit.
00:24:15.704 - 00:24:26.284, Speaker A: I have a high level of questions. So when you're picking a pseudo random unit, of course you need a secret key using some source of random. So where's the source of randomness in the time evolution?
00:24:26.904 - 00:24:28.924, Speaker C: What is the source of randomness?
00:24:30.184 - 00:24:44.428, Speaker A: I mean, like if you say it's a Pru, you mean there's. Yeah. Okay. You're about to define it. So sorry, I don't mean to be jumping, but like with, you know, you have to have some process that picks a random key. So, you know, that's very different than like a deterministic hamiltonian type evolution.
00:24:44.476 - 00:24:44.692, Speaker C: That's correct.
00:24:44.708 - 00:24:48.744, Speaker A: I'm wondering where are the random bits coming from to select the key?
00:24:49.124 - 00:25:02.348, Speaker C: So I'm not going to answer that question precisely, but I am going to ask how large should the key space be, just in order to talk about something like gravitational dynamics. So maybe that'll go a quarter of the way to answering your question.
00:25:02.396 - 00:25:02.984, Speaker B: But.
00:25:05.324 - 00:26:00.954, Speaker C: Indeed, here we have a sort of a military ensemble key space k security parameter Kappa, and we say okay, we want some sufficiently pseudorandom dynamics in order to spawn the formation of event horizons. What do we mean by sufficiently pseudo random? You know, we need to source leading order gravitational behavior. We need, we want the properties of this unitary to impact the time evolution in the bulk to the extent that to the effect that will have large back reaction and will form event horizons as a consequence of this amount of pseudorandomness. Now, in ads CFT, we really only have two parameters to work with. The only two natural parameters we have lambda hoof coupling and we have n, which is related to the central charge of the CFT and dimension of the Hilbert space. And so we can choose one or the other. In this context, I'm sort of ignoring all stringy effects, so n is the only parameter that I have to work with.
00:26:00.954 - 00:27:05.632, Speaker C: Fortunately, that parameter is also related to gravitational back reaction, and so I'm able to use that parameter essentially to parameterize the size of the key space as a way of guaranteeing that I have enough pseudo randomness. That doesn't explain where the pseudo randomness comes from. And in fact, an interesting question to ask is, well, what did the quantum gravity dynamics actually look like? And I don't expect that the unitary time evolution operator of the CFT is actually pseudorandom, just that I think it's very well modeled by a pseudorandom unitary on certain choices of code subspaces, such as ones where the energy threshold is sufficiently high. So, as I said before, the relevant parameter in holography is n squared, or different powers of n depending on your theory, which is inversely proportional to the gravitational constant. The dimension of the CFT Hilbert space is two to the poly n. This is the entire CFT Hilbert space hcft. Here I'll use h without CFT to denote the code subspace when that's relevant, and the class the semi classical limit, which is the limit where you have an emergent spacetime, that's the one I'm interested in.
00:27:05.632 - 00:27:34.740, Speaker C: That's the limit where n goes to infinity, or g, newton goes to zero. So a gravitational pseudorandom unitary, that's what we're going to be interested in. And it's a very natural definition. Take the same ensemble as above. H here, this is now a code subspace of the Hilbert space of a large and holographic quantum system. So the CFT, or Syk, if you like, and we say that this is gravitationally pseudo random. I'll use GpRU if the key kappa is polynomial in capital n.
00:27:34.740 - 00:27:57.976, Speaker C: So n, again, we can think of it as this is sort of the gravitational parameter in a sense, and it's really, in some sense, the only thing we can choose. There's no other parameter. The CFT does not have any other scale that we can pick. So now this is about the full time evolution of the entire bulk, including anything behind event horizons. What about if we're only. Oh yeah. Question.
00:27:58.080 - 00:28:10.816, Speaker B: Yeah, so when you say the entire Hilbert space, this construction only talks about Hilbert space, not something bigger than Hilbert space. It's like something more general. That's like, that's just what you're going to set is just the entire Hilbert space.
00:28:10.920 - 00:28:12.336, Speaker C: Sorry, I'm having a really hard time.
00:28:12.400 - 00:28:13.224, Speaker A: No, no, no, no.
00:28:13.304 - 00:28:16.604, Speaker B: When you're just saying like the entire Helwood space, this entire pixel.
00:28:22.484 - 00:28:47.472, Speaker C: Just this here, the theorems that we prove at the level of mathematical level do not require this. But if we're going to make sense of this in the context of ads CFT, then this is the only thing that makes sense. I'm going to state the theorems just talking about pseudo random unitaries, and then when I get to applying them, I'll talk about gravitational pseudomona munotarris.
00:28:47.528 - 00:28:56.564, Speaker A: Yeah, Luca, is there an example in which we know that the gravitational time evolution is described by a pseudo random uniform like this? That's an syk.
00:28:56.944 - 00:29:16.930, Speaker C: I think it should be true. In Syk, there's some tantalizing evidence. I don't. Maybe there's a paper I missed. But as far as I know, there isn't something that says this is literally pseudo random. I don't think there are any constructions, as far as I know, of pseudo random constructions of pseudo random unitaries that prove that you know all of the things that we want to be charged with.
00:29:17.042 - 00:29:27.694, Speaker A: But maybe relatedly, is there some intuition about the key space for Syk, or what the security parameter would be in Syk, is it related to the couplings?
00:29:28.034 - 00:30:04.404, Speaker C: I think it would have to do with, yes, it would have to do with coupling of the lattice site. That's a good question. I think the intuition, I would say the intuition is, yes, that should be the intuition, but I don't want to commit to that before I've thought about it. Yeah. Okay, so as I mentioned before, that's this, that's the time evolution operator for the entire system. What about the time evolution operator? Time evolution. If we're just talking about the causal wedge and we're interested in distinguishing between causal wedge and everything else, so what is the time, what about time volition? Specifically in the causal wedge.
00:30:04.404 - 00:30:46.754, Speaker C: So here we have some space time with we have the causal wedge. We have the black hole interior here, this region over here. This is just a moment of time slice and I've excluded everything that's not in the causal wedge. So we can say why don't we just try to model time evolution of operators in the causal wedge. So we're interested in, we're starting here and we're going to stay there. We're going to ask how do these operators change or evolve with time just exclusively within the causal wedge? Again, keeping in mind that we're most interested in telling the difference between what's going on in the causal wedge and what's going on outside of the causal wedge. So we want to understand what's going on in the causal wedge.
00:30:46.754 - 00:31:29.924, Speaker C: So I'm going to take u exterior to be any operator with some assumptions about approximate norm preservation that mimics the full safety time evolution on the causal wedge. So o here is a CFT operator that's dual to a bulk operator in the causal wedge. So the idea is that time evolution of expectation values of operators in the causal wedge can be mimicked by this u exterior even though the actual true time evolution here is this UCFT. So just going to take you exterior to be any operator that satisfies this requirement. And again, because the ads CFT map question.
00:31:31.904 - 00:31:46.724, Speaker D: So in principle, because you're tracing out part of the space, maybe you think that if I only restricted this outside area, it's like a quantum channel, but here you're saying that you can actually model it by an effective human.
00:31:50.044 - 00:32:07.388, Speaker C: We could talk about whether it should really be some kind of a channel or whether it's approx. It's good enough to say it's approximately well modeled. Again, this is not the actual time evolution. It's just something that approximates the expectation values of simple operators so why do we expect that this. Lisa, you wanted to comment?
00:32:07.556 - 00:32:14.864, Speaker E: Yeah. So we actually also handled, so like if you wanted to take UX series to be a channel, we actually can't handle it.
00:32:15.244 - 00:33:07.190, Speaker C: We haven't actually handled it, but we could, they have a theorem, we have a pre theorem that handles it, but the actual theorem has not been modified to account for that. So the technique should roughly be the same, I'll tell you which is the pre theorem that handles it as I comment on it, and which is the theorem that does not quite have it incorporated. That said, I do think that there should exist such a unitary. We haven't, we were not, we didn't prove it, but we motivated it for various, you know, for various physics reasons and other reasons, too. Okay. Now again, ADSF TMap is efficient outside of horizons. So we expect, and this is an assumption, we expect that it's possible for an efficient quantum algorithm with oracle access to UCFT to output an operator with this property, because again, bulk reconstruction in the causal wedge is efficient.
00:33:07.190 - 00:33:19.214, Speaker C: So we expect that this should be possible. And again, you can motivate it in various different ways. So we expect there's some efficient quantum algorithm that can learn the time evolution of operators outside of horizons. Yeah.
00:33:19.334 - 00:33:20.862, Speaker B: What does it mean to output it?
00:33:21.038 - 00:33:40.558, Speaker C: A classical description of ux, a circuit representation. Yeah. So there's some interesting work done in a related direction by these folks on learning operators, boundary degree operators, and it's not identical to this, but I think there's maybe an efficient map between this and what we want over here.
00:33:40.726 - 00:33:43.794, Speaker A: What exactly does it mean to learn the time evolution?
00:33:44.134 - 00:34:05.282, Speaker C: So here we're talking about quantum learning algorithms. So they're given some oracle access to the unitary operator. They can prepare any states that they are able to prepare because they're efficient. So these are polynomially complex states. They query it and then they do some processing, and then they output a circuit representation of some operator. I mean, these are quantum learning algorithms as a function of t or t. Ah, good.
00:34:05.282 - 00:34:19.054, Speaker C: So here we're talking about some fixed delta t. So this would be e to the minus ih, delta t for some fixed delta t. So we really mean learn the operator u rather than learn e to the ih. You know, fill in whatever time span you want.
00:34:20.514 - 00:34:23.106, Speaker B: Do you get access to the inverse evolution as well?
00:34:23.250 - 00:34:27.090, Speaker C: The inverse, I mean, you have access to, you're asking do you have access to u? Dagger?
00:34:27.162 - 00:34:27.866, Speaker B: Yeah.
00:34:28.050 - 00:34:32.540, Speaker C: Well, science, let's see.
00:34:32.572 - 00:34:35.384, Speaker B: Did we incorporate it?
00:34:38.324 - 00:34:40.104, Speaker C: I'm not sure we did. What do you think?
00:34:42.284 - 00:35:17.390, Speaker E: I think okay, so there's like two things here. One thing is like, Nettle will say this much better, but like, you know, we'll show that there's like a hardness of learning, which we're in the interiors. And in that case, I think that, I think that we actually just treated the pseudorandom unitary, which is the UCFT here, as an information theoretical object. So we could handle like dagger. And my understanding of HCP is that they don't need. So like in HCP, the positive part of this learning result, they actually just use you.
00:35:17.422 - 00:35:18.462, Speaker B: They don't use you.
00:35:18.638 - 00:35:19.214, Speaker C: Fair enough.
00:35:19.294 - 00:35:20.794, Speaker B: This close both ways.
00:35:22.024 - 00:36:24.650, Speaker C: Okay, so now for the logic. So we have an efficient quantum algorithm, quantum learning algorithm, that can learn to predict the expectation values of operators in the causal wedge. Convolution of expectation values of operators in the causal wedge. Next, we prove in these are theorems that I'll state precisely in a minute that under certain assumptions, which I'll state the when UCFT is a typical draw from a pseudorandom ensemble. For any efficient algorithm that attempts to learn to predict time volution under UCFT, there exists a distinguishing operator q whose time evolution cannot be predicted by this algorithm. And that means that there exists operators q whose time evolution cannot be predicted by an efficient quantum algorithm, even though this efficient quantum algorithm can predict the time evolution of all operators in the causal wedge. So that means the space time has to consist of more than just the causal wedge, since this operator q, we argue, has a representation in the bulk spacetime, so it lives in bulk space time.
00:36:24.650 - 00:37:04.474, Speaker C: And we argue this. And so that means that there has to exist an event horizon. So this is the logic and the crucial, the workhorse here is this theorem that I'm now going to state. So this is the, this is the pre theorem that I referred to earlier. So this one is work just with Lisa, the complexity of learning pseudorandom unit errors. And I should say this one also applies to channels in a slightly different form, and it also applies to hard random unitaries. So we take some pru ensemble and a Prs ensemble Hilbert space h, where a dimension to the kappa kappa is the same as before.
00:37:04.474 - 00:37:53.254, Speaker C: And so we have some quantum algorithm, a poly Kappa complexity. It's given oracle access to this unitary u. It produces an operator u hat as its best guess for u. And we can argue, we can prove this. This is actually math level rigor. There exists a constant alpha, an order, one constant alpha greater than zero, such as for sufficiently large security parameter kappa, the average fidelity between the output, the output unitary acting on our, on our state of interest, which is also random, and the actual time evolution, this is bounded from above by one minus alpha. So essentially you always fail to learn, the algorithm always fails to learn the time evolution you acting on sign.
00:37:53.254 - 00:38:07.190, Speaker C: So we're averaging over all of these. So the upshot of all this text is that efficient quantum algorithms fail to learn pseudo random time evolution on average. See? Lots of questions.
00:38:07.262 - 00:38:11.558, Speaker B: Yeah, so I guess the algorithm a doesn't get access to the state here.
00:38:11.606 - 00:38:17.354, Speaker C: At least it does not get access to the state until it has to produce its output. So it does not get access to the state as part of the training phase.
00:38:17.854 - 00:38:24.814, Speaker B: Is this task easy to access the state one time? Is it like easy if you have access to the state? Like is there an objective?
00:38:27.394 - 00:39:00.332, Speaker C: That's why we don't give it access to the state. Okay, so, but then we, we want to do a little bit better than on average, we want to show that this is true. Again, we're interested in typical states which are in typical unitaries. So we want to show this is true for typical states, for typical cases. And that means we have to use a bunch of arguments for measure concentration, which I'm not going to, I'm going to spare all of you the measure concentration arguments to just give you the results. So this is the one that we proved for pseudo random unitaries, also true for har random. We did not prove this for decohering channels or for channels in general.
00:39:00.332 - 00:39:56.220, Speaker C: Sorry. Probably it's true, probably some argument that works, but we don't, we currently have not proved it, so I'm not going to put it in the PR. So we consider the same setup as before, takes sufficiently large kappa, and there are a couple of technical assumptions that go into the star here, efficient quantum algorithms, and for a very, very large fraction of unitaries in our pseudorandom unitary ensemble, and states in our pseudorandom state ensemble, we have a bound on the fidelity. When I were only averaging over the output of the learning algorithm, we're no longer averaging over the unitaries and we're no longer averaging over the states because we're doing it as a fraction. I'm sorry, this should be poly Kappa. I'm making no reference to capital n in this theorem. And furthermore, as a consequence of one, there also exists an operator q whose expectation value is not well computed by this learning algorithm.
00:39:56.220 - 00:40:26.594, Speaker C: So the expectation value of q under this, the guessed time evolution is very different. These two are different constants. I think this is twice that one. From the actual time evolution, time evolved expectation value of q. And so the only thing we need to do to apply this typicality, typical typicality for hardness of learning to ads CFT is set kappa to poly n. So these are now gravitationally pseudo random instead of just pseudo random. Yeah.
00:40:29.614 - 00:41:04.494, Speaker D: I think when I think of these psydorandom unitaries, I don't quite remember the definition, but I would have thought that they're somehow such that learning them is almost by definition such that it's, the probability of learning them is negligible. It's negligibly small when you have. But you're saying that you're constants. Could you comment maybe on why you get this one minus constants?
00:41:05.154 - 00:41:10.130, Speaker C: You think that this should be much, much smaller? Well, sort of like one minus constant.
00:41:10.242 - 00:41:16.306, Speaker D: Naively, when I think of the definition, I would think that's like really hard to even have negative overlaps.
00:41:16.370 - 00:42:09.204, Speaker C: Yeah. There are a lot of answers I can give to this, but in the interest of time, what I'm going to say is that this is all we need. But there are, of course, there are many answers that I could tell you why, you know, should you expect a tighter bound or not? But fortunately for us, the only bound we need is one minus an order, one constant. Okay, so what is the upshot of this result for gravity? Right. We were doing all of this because we're interested in solving a deep problem about gravity, the problem of we cosmic censorship. So this theorem that I just stated means that efficient learning algorithms, quantum learning algorithms, fail to predict time evolution of a quantum gravity system that is evolving under gravitationally pseudo random time evolution. So in particular, there exists an operator that we argue exists in the semiclassical limit, whose time evolved expectation value cannot be predicted by an efficient quantum learning algorithm.
00:42:09.204 - 00:42:52.280, Speaker C: And remember, there is an efficient learning algorithm that can learn the time evolution of all operators in the causal wedge in this limit, one of the ingredients of this. But that evolution algorithm cannot learn the time evolution of q. So there's more to the bulk than just the causal wedge. And therefore there must be an event horizon. And this applies to typical states, typical unitaries, since the previous theorem used typicality. So this is just an illustration of what's going on geometrically. So if q is anywhere in the bulk, where the causal wedge is the entire bulk, then we have a contradiction that means that q has to be, can only live here where the causal wedge is not the entire bulk.
00:42:52.280 - 00:43:29.426, Speaker C: So this must be the bulk that we have for typical states when the time evolution operator is gravitationally pseudorandom. And this is what we call cryptographic censorship. Portmanteau of cosmic censorship and cryptography. And I'm going to just state this very conceptually here, since I kind of stated the technical version already on code subspaces of states on which the time of evolution is approximately pseudorandom. Typical states with a geometric bulk dual have an event horizon in the dual bulk. Now this is important because we don't have a bulk, an actual emergent bulk dual. We don't even have a definition of an event horizon.
00:43:29.426 - 00:43:53.328, Speaker C: We don't know what that means. So it's a contentless statement without it. And also these results apply. If the time evolution operators approximately ha random, we can probably generalize them to the case. To other cases, maybe. Okay, does this solve the problem of weak cosmic sensors? Let's take a look at the conjecture. The conjecture that the collapse of matter and general relativity.
00:43:53.328 - 00:44:19.854, Speaker C: This is just literally the same slide that we had before with matter fields with the same star for the various positivity conditions on the matter fields. This generically results in event horizons. And the singularities resulting from gravitational collapse are generically hidden behind an event horizon. So this was the conjecture. And what we've shown is a quantum version of the first statement. We replace generically with typical, because typical makes sense in quantum systems. Generic makes sense in classical systems.
00:44:19.854 - 00:44:53.842, Speaker C: We have an assumption about the time evolution, which is pseudorandom. So it's a version, the quantum version of the first sentence here. What about the second statement? Singularity is resulting from gravitational collapse, are generically hidden behind an event horizon. Have we shown something like that? So. Well, actually we kind of haven't yet. So we haven't really fully solved the problem of cosmic censorship. The question that we need to ask at this point is whether naked singularities and horizons can coexist in typical states.
00:44:53.842 - 00:45:37.516, Speaker C: So you could ask, wait, what does that mean? Well, if you go to the picture that I drew earlier, we had a naked singularity and we had some star collapsing. You could imagine that at some time later, an event horizon forms. So you have a naked singularity coexisting with an event horizon. And this is something that happens, for example, for evaporating black holes. So there's an instant where the naked singularity is in principle visible when the black hole is disappeared on the element. So it seems that maybe naked singularities and horizons can coexist. But then to what extent? If the naked singularity persists for a time of e to the s, that seems that the naked singularity is the typical thing and not the horizon.
00:45:37.516 - 00:45:39.904, Speaker C: So there's a lot of. Yeah. Question.
00:45:40.284 - 00:45:52.528, Speaker B: Do you expect that to be something that can happen in a semigrassically controlled setup? Because, for example, the one you were mentioning at the endpoint of the black hole, you expect black and black holes. So is that something that you're expecting?
00:45:52.656 - 00:46:37.968, Speaker C: Well, graduate Laflome is a lot like that. So, yeah, I think that could happen. The thing is, what you really care about is how long this thing is, because if it starts to be appreciably long, then you worry that you have. You can have typical states with only that. Because you could say, okay, the time evolution. I mean, if this thing, if that thing persists for time, which is, I don't know, polynomial in the entropy of the state, then you would say, well, okay, so, sure, there could be an event horizon somewhere else in the space time, but for a larger and long enough time, I have just a naked singularity. And so, you know, they say, okay, but that that state is still typical and still reproduces all of the behavior of the CFT, even though for a very long time, it has a naked singularity in it.
00:46:37.968 - 00:46:57.324, Speaker C: So I think what we want is some notion which we do define in the paper, but I'm not going to get into, because it's a bunch of, you know, classical geometry manipulations, a notion of the time spanned by a singularity, and saying that, in what sense? It has to be small in order for these things to not be typical, but rather the horizons to be typical.
00:46:57.624 - 00:46:58.404, Speaker B: Yeah.
00:47:01.784 - 00:47:21.786, Speaker C: Now another question, which is maybe related to the question I had earlier. How good is. Oh, sorry, Michelle. Yeah, I had a follow up question. Oh, please, go ahead. I guess these states were using naked singularities and horizons could coexist. Are we only worried about time like singularities, or are there time like singularities? Or.
00:47:21.786 - 00:47:57.088, Speaker C: So there's a technical loophole that you could get to with space like singularities, we're also worrying about null singularity. But with SpaceX singularities, you could. In principle, they're always behind an event horizon for the following reason. Here's a SpaceX singularity, here's the asymptotic boundary. Horizon is defined as the boundary of the past, of the entire asymptotic boundary. Well, this point here is not in the past of the asymptotic boundary. So you always have an event horizon for space like singularities.
00:47:57.088 - 00:48:24.922, Speaker C: Now, you might say that that's rubbish. This is not the kind of thing that I'm looking for here. I want this thing to just not exist. But good luck defining what you mean by this thing. So I agree with you that there's probably some way of controlling space like singularities. But the issue is just that whenever they appear, they just come with their own event horizon. So there's a notion, there's nothing in which this is a naked singularity, which is that you can have an observer here who can both send signals to it and receive signals from it.
00:48:24.922 - 00:48:31.684, Speaker C: But the having of an event horizon, the existence of an event horizon, is not something that rules these things out.
00:48:38.544 - 00:48:52.844, Speaker B: So it's fairly convincing that black hole should be, should have zero random dynamics. But how, how sharp is the connection? Like, can you say that Otox implies pseudo randomness or something?
00:48:53.144 - 00:49:38.344, Speaker C: How sharp is the connection between pseudo randomness and black holes? Is that question. You know, there are a number of papers drawing a connection between chaos and pseudorandomness. So if you want to, if you are happy saying that, you know, black holes are maybe the most emblematic feature of black holes, is there chaos? Then there's a strong connection to pseudo randomness. For me, that's sort of the most convincing one. It has to be something that generates a lot of chaos, it has to be scrambling, and it has to be efficiently generated. So for me, that was enough to say, well, pseudo randomness seems like a pretty good model. Am I claiming that the actual true time evolution operator is pseudo random? Definitely not, but it looks like it's well modeled for at least many purposes by something that's random.
00:49:39.444 - 00:49:50.092, Speaker B: I guess I was asking whether this is like a theorem of some sort. I am also convinced by the same thing. I'm just like, is there some minimal set of constraints that guarantees pseudo randomness.
00:49:50.228 - 00:50:26.574, Speaker C: And minimal set of criteria that will guarantee pseudo animus? Not that I know of. You could ask, what's the minimal set? What's the minimal thing? You could ask something else. What is the minimal thing that we need in order to guarantee the proof of this theorem? You can ask that instead. That's an interesting question. So, for example, we could probably accommodate a channel of some, you know, of some amount of conceptual way to say it, a channel with certain notion of entropy, which is large, which, you know, it's large for ha random. So we need some, some amount of scrambling or some amount of randomness for a theorem like this to go through. So I would say that's the kind of minimal thing we need.
00:50:26.574 - 00:50:57.522, Speaker C: Pseudorandomness seems like a nice model, but anything that satisfies this theorem and is efficiently generated is something that we could, we could use as a model by the connections between chaos and pseudorandom. Do you mean the connections between like chaos and like k designs or. Well, there's also connection. I mean, I. So I will have to look up the specific papers, but I believe there have been also papers about chaos and pseudo randomness. Of course, there's also chaos and k designs, chaos and power randomness. I mean, all of these are really kind of getting at the same thing.
00:50:57.522 - 00:52:00.918, Speaker C: And the question is, which one is the best model for what you're trying to get at exact designs? My understanding is that they are not known, they're not efficiently generated. So maybe you'd want to use approximate designs. I don't know. So where was I? Okay, so yeah, so the condition, what condition is actually necessary? This literally just said, now this is all in the g goes to zero limit or the n goes to infinity limit. Of course, it's very interesting to ask, can we say anything about large but finite g newton? What does this tell us about, if anything, about the firewall problem? You know, we're talking about the existence of horizons, existence of, of operators that exist that are not in the causal wedge. Can we use this to leverage anything about black hole information at finite end? Are there any other ways to diagnose the existence of event horizons? So do I have a little bit of time left? Yes. Okay, so this is related to upcoming work with the same crew that was on this paper.
00:52:00.918 - 00:52:39.844, Speaker C: And in light of the previous talk, I thought it would be good for me to also talk about this, which is holographic pseudo entanglement. So in this upcoming work, again with the same folks, we construct the bulk duals to gravitationally pseudo entangled states. Now, what I mean by so specifically we're going to be talking about states that are pseudo entangled only across one cut, not across many cuts, just there's one cut. That's the only one we're going to consider. And when I say gravitationally pseudo entangled, I mean again, there's only one parameter really in the problem and that's capital n. Equivalently G Newton. So that's the parameter that we're going to use.
00:52:39.844 - 00:53:22.974, Speaker C: So these are states that spoof an order one over G Newton or order n squared or whatever power you're using amount of entanglement. And we measure it using the von Neumann entropy. And what we do is we build, I'm going to give, I'm going to have a picture in the next slide. We build an ensemble of states that have order one over g entanglement. And by this I mean bonhomine entropy and states that spoof them for simple operators on polynomial number of copies. And this is polynomial in, um, one over g nu. And we prove physics level of rigor, proof that pseudo entangled states are always dual to bulk space times with horizons so pseudo entangled, meaning gravitationally pseudo entangled, so, so pseudo entangled with respect to this parameter.
00:53:22.974 - 00:54:07.822, Speaker C: And this proposed, this uses this strong Python's launch proposal, which is the proposal for computing the complexity of reconstruction for an ads CFT. So this gives a criterion, basically, it's sufficient and a necessary condition for diagnosing when the ads CFT map is exponentially complex. And the criterion, essentially is that you have a surface which mimics the ryutakiyanagi surface, but lies closer to the boundary than it. That's the criterion for the python's lunch. You get a geometry that kind of looks like a python that had just eaten a huge lunch. The name is not my fault. So this is coming soonish.
00:54:07.822 - 00:54:33.394, Speaker C: I think it's going to be soon, but you never know with these things to an archive repository near you, which is hopefully incentive for people to actually check out the hepth listing. And I'm just going to give the picture here of these two different ensembles of states. So I think you can probably a little faint. My apologies about that. So here. So these are the states which are spoofing entanglement. So these are two boundary states, but they're not connected through the bulk.
00:54:33.394 - 00:54:55.682, Speaker C: And these are the states with actually a large amount of entanglement. So the idea what's happening here, these are, well, they're not exactly pure states, but they're very close to pure states. They have this surface here, which looks like a Ryutaki Nagi surface. It's locally minimal. These are spatial slices. The geometry in this geometry, that surface is actually minimal. So that computes the bonumn entropy.
00:54:55.682 - 00:55:29.994, Speaker C: In this geometry, the surface is not minimal. The minimal surface is the empty set. And so the strong python's launch proposal tells you that polynomial, polynomially complex operations can only probe the bulk up to this construction here. In this case, that corresponds to the entire bulk from this side and the entire bulk from that side. So you get everything, just a minimal surface. In this case, you only go up to here. And so with polynomially complex operations, you conclude that this is the Ryu Takanagi surface, and you say, ah, the entropy is the area of this of a.
00:55:29.994 - 00:55:50.944, Speaker C: Similarly for the other side. But if you actually have access to exponentially complex operations, you would be able to go further in and realize that the Ryutak hinagi surface is actually the empty set. So these things are very close to pure. So this is, so this is what we call gravitational pseudo entanglement. And with that, thank you very much for your attention.
00:55:57.844 - 00:56:09.494, Speaker B: So all the way in the beginning, you said that black holes are typical above a certain energy threshold, and that energy threshold sort of disappeared after. And I wonder where it went, because I don't see any black holes around me.
00:56:10.874 - 00:56:21.986, Speaker C: Yes. So when the energy threshold. So that just goes into the assumption that the time evolution operator is, well, modeled by a pseudorandom unitary. I think that's just false. When you're below a certain energy threshold.
00:56:22.090 - 00:56:27.094, Speaker B: Oh, okay. Yeah. So somehow you're saying all pseudo random unitaries are also high energy phenomena.
00:56:27.514 - 00:56:40.882, Speaker C: Well, I don't know. I wouldn't put it quite that strongly. I would say that the CFT convolution operator, this is not accurately modeled by a pseudo random unitary. If you're talking on code subspaces where the energies are very low.
00:56:41.018 - 00:56:42.454, Speaker B: Yeah, that's how I would put it.
00:56:44.234 - 00:56:45.194, Speaker C: Yeah. Yeah.
00:56:45.234 - 00:57:18.854, Speaker A: So I have a kind of a meta question about your assumptions. So, two of the assumptions feel like they might be in a little bit of tension with one another, because, like, on the one hand, you know, you're assuming that the ads CFD dictionary is, you know, in polynomial time, like, is it in some region, then you're also assuming that the, you know, the time evolution has pseudo randomness in it. Well, in all these arguments about complexity of ads CFds, pseudo randomness is usually a source of exponential complexity. So how are those two, you know, so how are those two actually consistent? Is there some, like Python's lunch assumption?
00:57:18.934 - 00:57:50.326, Speaker C: That's so. I'm not. So I'm saying we, we know under very reasonable. Okay, if you pretty much know that reconstruction of the causal wedge should be efficient, I mean, you can just jump in, measure something and jump back out. So that's not a. I mean, you could say it's an assumption in the sense of it's a physical level regular assumption, but. So we take that and then we say, all right, and then we also know that the CFT, you know, time evolution of the CFT in typical states looks very chaotic.
00:57:50.326 - 00:58:23.108, Speaker C: So we think it's well modeled by pseudo random, um, basically in time evolution. And so we just put those two together. And so indeed, we simply find the thing that you kind of expressed, which is that, well, it's just not true that in typical states, you can jump in and jump back out. The only time when we know that the time evolution is simple, sorry. That, uh, that reconstruction is simple is when you can jump in and jump back out. And so we just, we're just saying that, yes, if the time volition is pseudorandom, that means that you can't just, you can't do that. And the only thing that can prevent you from doing that is an event horizon.
00:58:23.196 - 00:58:34.364, Speaker A: If your bulk has like nothing interesting in it, like no event horizons. Or like, would you still conjecture that the boundary time evolution would be modeled by pseudo random unitary?
00:58:34.444 - 00:58:36.276, Speaker C: So the thing is, so that would.
00:58:36.300 - 00:58:38.716, Speaker A: Be, that actually would be contradictory.
00:58:38.780 - 00:58:57.782, Speaker C: So a bulk like that would be either one of two things. It would either be very low energy or it would be very atypical. That would be the answer to that. So I mean, we're deriving that whenever you have pseudorandomness, you have horizons. So that tells you if you want to start with a bulk that doesn't have horizons, then either the bulk is.
00:58:57.798 - 00:59:00.622, Speaker A: Atypical, you should be incapable of producing pseudo randomness.
00:59:00.678 - 00:59:01.366, Speaker C: Exactly.
00:59:01.510 - 00:59:02.194, Speaker B: Yeah.
00:59:04.454 - 00:59:05.354, Speaker C: Go ahead.
00:59:05.814 - 00:59:16.506, Speaker E: So like, so, like this. So the first thing I actually mentioned about it seems a bit contradictory that like, you know, there are some operators that you can't learn or.
00:59:16.530 - 00:59:17.210, Speaker B: Sorry.
00:59:17.402 - 00:59:52.754, Speaker E: So like in the setup, right, like when you have a superman immunitary, it seems like contradictory that there's some operators that can be somehow learned by like jumping in, jumping back out, and there's some that can't. So like, like in, like in like more CS language, like, like whenever you have some unknown operators, I'm a unitary of boxes. But like some of the operators can be, can, like the expectation values from operators, right? Like if you have some unknown poly sized circuit, you could still learn. For instance, HCP shows that your boundary degree operates. And so like, you can think in a CS language that like, the operators you can learn efficiently correspond to this.
00:59:57.614 - 01:00:09.854, Speaker B: Is there a difference between the notion of student arguments that you introduced in the last slide and something like simple entropy or coarse graining, coarse grain entropy that can just from the outside of the.
01:00:10.754 - 01:00:41.982, Speaker C: I see you've read my papers. So this is very closely related to the coarse grain entropy. Of course. I mean, the coarse grain entropy is part of the. Let me, let me actually back up one for people who haven't read my paper. The coarse grain entropy that Stefan is referring to is an entropy that you define, a von Neumann entropy that you define by maximizing the von Neumann entropy of density matrices acting on your Hilbert space. You take the maximum subject to fixing the expectation values of all polynomially complex operators.
01:00:41.982 - 01:01:25.222, Speaker C: So you consider all density matrices with the same expectation values for all polynomially complex operators. And then you ask which one has the highest volume and entropy. So that's very closely related, of course, to the Python's lunch. The strong python's lunch is essentially motivated by the fact that the area of the outermost Rt surface is computing the simple entropy. The primary difference between the coarse grain entropy and this, the simple entropy states where the simple entropy has states where the simple entropy is very different to leading order from the actual fine grained entropy, are candidates for pseudo intangible states. There are a couple of extra ingredients. You need to go through one.
01:01:25.222 - 01:01:48.714, Speaker C: You have access to many copies. So you have to, you know, make, you have to argue that even with many copies, you can't distinguish. You have to talk about complexity of distinguishing rather than complexity of reconstruction, which are expected to be the same rough class. And you have to take into account various things like the swap test, which, you know, come in with multiple copies. The rough idea, though is really to use the coarse grant entropy, though. Yeah.
01:01:49.104 - 01:01:51.120, Speaker B: So should I take this result as.
01:01:51.152 - 01:01:55.592, Speaker C: A lesson about the pseudo entanglement or cryptographic censorship?
01:01:55.648 - 01:02:10.440, Speaker B: Cryptographic censorship. Got it. Should I think of this as it has some sort of implication for the measure of the gravitational path integral that describes the bulk, or is there some other resolution of the tension that you motivated at the beginning?
01:02:10.632 - 01:02:38.460, Speaker C: Yeah, that's an excellent question. I if you want to. Well, we proved this is a sufficient condition. I think in order to do what you suggest, we would need it to be a necessary condition. If we had a necessary condition for typicality of horizons, and we found somehow that some measure of pseudo randomness were necessary, then that would tell us something about the measure, the actual true measure. It would have to satisfy that criterion. If we want typicality of horizons, which we do.
01:02:38.460 - 01:02:55.848, Speaker C: Now, unfortunately, we only have a sufficient condition, which means that it's possible that the measure has nothing to do with pseudorandomness, or maybe it's something much weaker than that. So it would be nice to ask, and that's something that we've been talking about but not working on yet, what is a necessary condition for all of.
01:02:55.856 - 01:03:03.764, Speaker B: This to follow and just to understand. So the sufficient condition that you proved is just pseudo random time evolution. Thanks.
01:03:05.264 - 01:03:06.456, Speaker D: Follow up on this question.
01:03:06.520 - 01:03:09.614, Speaker B: Are any of them examples of naked singularity you mentioned?
01:03:09.734 - 01:03:14.434, Speaker C: Not in the swampland, are they? Not obviously in the swampland?
01:03:15.374 - 01:03:20.582, Speaker B: Yeah, not obviously. Or none of this. Like, are they? Are there anyone that's like that?
01:03:20.598 - 01:04:00.604, Speaker C: Look, completely innocuous. That look completely innocuous. Is that the question? So for what? So these examples that Osman constructed of initial data that violates dependron's inequality, they look very innocuous, but because they violate the Penrose inequality, they have to violate HRT somehow. So you could say, ah, that must be in this swamp, man. Some of the examples that Gary, George and Toby constructed, some of the valid weak gravity. But there's a region of parameter space that doesn't. I think specifically when they're talking about black holes with a dilettante, I think there's some parameter space, there's a gap between the weak gravity bound and where they find naked singularity.
01:04:00.604 - 01:04:09.492, Speaker C: So they can. So there's. There's some region where they can accommodate which doesn't actually violate any known conjectures about the swampland. Yeah.
01:04:09.548 - 01:04:49.446, Speaker B: Yes. Kind of continuing on Adam's question, actually. So I guess I'm okay with the fact that you can learn some expectations that the operators given some input state for some unitary. But I would normally think that the. That expectations value would be very similar to what you would get if you have like, a hard random unitary. So, like, I would naive think that the expectation value of this operator, no matter what, what your input state is, it would be pretty much like the one obtained from the maximum fixed state. Is this true or wrong? So, like, I'm okay with the fact that I can.
01:04:49.446 - 01:04:52.740, Speaker B: No matter what your unit theory is, you can. Can still learn some operators.
01:04:52.812 - 01:04:54.532, Speaker C: The expectation is about a degree operator.
01:04:54.668 - 01:05:11.068, Speaker B: So that's fine. But I would expect that if this unitary pseudorandom, the answer that you learned would be that the expectation value would be pretty much the trace of the operator. At least this is my intuition. I was wondering if this is dry roll.
01:05:11.116 - 01:05:12.644, Speaker C: I think Robert is in the audience.
01:05:12.804 - 01:05:13.904, Speaker B: Yeah, this is.
01:05:17.264 - 01:05:24.432, Speaker E: So, like, yeah, if you're trying to, like, use Roberts and friends algorithms to learn, like, an undue Turing, you would just get something that.
01:05:24.448 - 01:05:26.408, Speaker C: Is pretty much the same as you.
01:05:26.416 - 01:05:40.524, Speaker E: Get from har random. But like, this is actually a read. Like, this is actually reasonable. Like physics context. Like, for instance, like, if you just have access to the exterior of the black hole, like it looks like a thermal system. So I think what expect to get, like, the expectation.
01:05:45.954 - 01:05:47.174, Speaker C: Any questions?
01:05:50.674 - 01:05:52.074, Speaker A: Okay, let's think that again.

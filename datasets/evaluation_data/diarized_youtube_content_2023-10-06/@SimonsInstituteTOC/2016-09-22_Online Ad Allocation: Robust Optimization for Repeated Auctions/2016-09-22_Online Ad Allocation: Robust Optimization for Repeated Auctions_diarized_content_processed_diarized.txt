00:00:01.960 - 00:01:10.724, Speaker A: Great, thanks for having me here. I'm going to talk about online bundling and robust allocation with motivations in display advertising. So the motivating platform, like inspiring these type of problems is basically the marketplace of display ads, where we have different exchanges, publishers and ad networks, basically competing and designing auctions and algorithms, and online optimization of how to allocate impressions and so on. And research agenda is like market algorithms. Part of the algorithm research Group in New York. At Google, we work on basically different aspects of online optimization or online mechanism design. So in this talk, I'm going to emphasize on aspects of that uncertainty is present in the optimization, and in particular talk about robust allocation and online bundling.
00:01:10.724 - 00:02:03.064, Speaker A: The disclaimer is that the motivations come from display ads, but I'm going to focus on theoretical models and problems like very formal algorithmic problems. The autonomy of talk is it has two parts. I'm going to talk about online stochastic robots optimization, and two models for combining, let's say stochastic and adversarial optimization. One from soda paper and one from EC paper. These are older work. The new stuff is about doing online optimization in a repeated auction setting, where we want to optimize in a repeated auction setting and implement bundling in an online manner. And these are all ongoing work.
00:02:03.064 - 00:02:57.872, Speaker A: They're all available online and archive elsewhere. But yeah, they're ongoing work. So for the online robust allocation, I'm going to talk about two papers, one with Shayan Oskaran and Moses Adi Mogadam, one with Hossein Svandieri and Nitish Korola. The motivation, or the underlying problem for the robust allocation is online ad allocation. So let's define the problem, and perhaps all of you know about it very well, but I have to define it. So we have a set of fixed nodes and online nodes in a bipartite graph we call fixed node advertisers and online node users, or impressions and weighted edges between them. So we have some advertisers, each of them has a budget, we have online nodes, they arrive one by one over time.
00:02:57.872 - 00:03:48.754, Speaker A: When a node arrives, we have to assign it to one of the advertisers, and the goal is to do this in an online manner and maximize the total revenue that we collect. So when an online node arrives, we may apply a greedy algorithm, and in that case we allocate this node to advertiser b, and then the second node arrives, we allocate it to advertiser b and so on and so forth. So we do greedily, let's say. So we get a total value of eight. But the value of the optimum solution in this problem is going to be another matching, which is the green one. It satisfies the budget constraint, and the total value of it is eleven. So we are trying to find an algorithm that has good performance ratio or approximation ratio.
00:03:48.754 - 00:04:57.112, Speaker A: The approximation ratio in this case is eight over eleven. So the approximation ratio is a function of the instance and the pattern of the arrival of the nodes. A similar problem I can define is online weighted matching. The motivation come from display ad instead of budgets, I have degree constraints or capacities on advertiser side, and basically I want to do the same thing, but I'm solving a pure online weighted matching problem. So now I can talk about arrival models. To set the stage to define the models, I can assume that the online nodes arrive according to an adversarial model, like a worst case model, or according to a stochastic model, where like these type of nodes are drawn from some type of distribution. In the online model, we define the competitive ratio as the revenue of the algorithm over the revenue of the optimum offline.
00:04:57.112 - 00:06:00.352, Speaker A: In the stochastic model, we defined the approximation factor as, let's say the expected value of the revenue of the algorithm over the revenue of the optimum. And we want to design algorithms that have large approximation factors. Yes, so I'm a bit confused on the stochastic model. I mean, if it's overall instances, shouldn't there be some expectation in the optimum too? I mean, yes, so, like it's very informal definition of a stochastic, and when I state the theorems, I'm going to say it's a random order or iid or whatever. Yeah, so I'm trying to tell you basically the basic known results in these two models. First, in case you don't know, and the majority of you do know, and then I can define the two models that I was talking about. So, in the adversarial order model or online model, there are primal dual type based algorithms that achieve one minus one over e approximation, and greedy is one half competitive.
00:06:00.352 - 00:07:17.268, Speaker A: So greedy achieves at least one half. And primal dual algorithm looks at like a dual of a program like this and computes the dual variables in an online manner and on data. Also, the primal dual algorithms actually achieve better approximation compared to greedy algorithm like, for many instances that we have looked at, these are like for six big instances, the primal dual achieved 82% and greedy achieves 69%. So that's for adversarial order model. For the stochastic model, the idea would be to basically sample from this stochastic model, or like wait for some time until you can design, or we can compute an expected instance, solve the dual linear program, compute the dual variables, and then get a one minus epsilon approximation, competitive, let's say, asymptotically. So like, that's a very high level view of these areas. So, if we basically says that if we know the type of items, if you have good forecasting on the type of online nodes that are going to arrive, we can solve a dual linear program on the expected instance or something, or sample instance, and then if we have a good estimate, unreal data.
00:07:17.268 - 00:08:15.934, Speaker A: Also, we do achieve better approximation factor. So, like here, for example, this 87% is done by looking at one day data, taking 1% sample from the day, from the data, learn the dual variables on that 1% sample, and solve the problem on the other 99%. So, this is the story for the adversarial model and the stochastic model, the random order models. But none of these models are complete. And the problem, and the reason is that in reality, we can't have good, complete forecast on what's going to happen. All the stochastic models are sensitive to how good we can predict the future. And if you look at traffic spikes in particular, the patterns of these traffic spikes are really spiky and not predictable.
00:08:15.934 - 00:09:24.966, Speaker A: And they are related, for example, in online ad allocation, related to breaking news that you can never predict like that, or events that suddenly show up and so on. So in these settings where we have traffic sparks, actually adversarial model is not that bad. I mean, it has some benefits that you don't make any assumption on the forecast and you get good results. So the question is, how can we design theoretical models that capture this hybrid situation, that when we have good forecasts, we have a stochastic assumption on the input, we get good results under good forecast. But if we don't have a good forecast, if we have traffic spikes, we still get a good, reasonable factor. So, for example, we can come up with hybrid algorithms that combine these two, and for some of these instances even achieve better approximation factor. So, this is the motivation.
00:09:24.966 - 00:10:18.508, Speaker A: Now I'm going to tell you two specific models to address this problem. Theoretically, these are two only possible models. There are many other models to consider. The first model is what we call the simultaneous adversarial and stochastic approximation framework. So the motivation is the adversarial setting is too pessimistic, the stochastic input is too optimistic, we can have a good forecast so, let's say in practice, we have to deal with both situations. So, let's design an algorithm that at the same time achieves a good approximation factor in the adversarial model and in the stochastic model, just for the reference. If we start using, like, for example, algorithms that are based on learning dual variables, they can be very bad for the adversarial model.
00:10:18.508 - 00:10:51.904, Speaker A: So if you rely too much on the forecast, you can screw up badly. So, the formal question is this. And for online weighted or unweighted matching, you can pose this problem. So, we saw that for the stochastic model, we can achieve one minus epsilon. For adversarial model, you can achieve one minus one over e. And these are tight results. Now, the question is, can we achieve, for example, one minus epsilon and one minus one over e at the same time? And the answer is summarized in this slide.
00:10:51.904 - 00:12:00.350, Speaker A: So, in this sort of paper, a number of years ago, we said that if we look at the unweighted online matching problem, it is possible to achieve the best of both worlds. We can get an algorithm that at the same time achieves one minus one over e for the adversarial model, and one minus epsilon for the stochastic or random order model. This is under the assumption that, like degrees are large or the budgets are large for the weighted case. On the other hand, for the budgeted allocation problem, we could show that if you wanted to achieve one minus one or e for one algorithm, one minus one or e in the adversarial model, you cannot achieve better than 97% in the stochastic model. So there is a lower bound that if you want to achieve one minus epsilon in the random order model, you, you can't achieve better than four times square root of epsilon in the adversarial model. And for the upper bound, we can show that achieving one minus one over e and 0.76 is possible.
00:12:00.350 - 00:12:55.736, Speaker A: So, basically, what we show is that these primal dual type algorithms that achieve one minus one over e in the adversarial model, they do achieve better approximation factor if you look at the average case, if you look at a random order model, for example, or an IID stochastic model. So this is like a formal upper bound and a formal lower bound for this problem. And the open problem here is to close this gap. Another interesting thing to note is that. So, yeah, I have one slide that elaborates on this. So, basically, we say for unweighted instances, the best of both worlds is possible. We can get one minus epsilon competitive ratio for a stochastic input and one minus one over e for the adversarial input.
00:12:55.736 - 00:13:56.814, Speaker A: And the algorithm is very simple. For the unweighted instance. For the unweighted instance, at each time you allocate the node to the one that has basically the minimum ratio of remaining budget and the minimum ratio of what you have to allocate over what you have allocated or what you have allocated over what you have to allocate for the weighted version. On the other hand, we have the upper lower bound that if you want to achieve one minus epsilon, you can't get better than four times square root of epsilon. So I guess I did go over these results. So these results are done through like heavy mathematical programming and factor revealing mathematical programs. So another interesting question is to find a more intuitive proof or structure result that may be able to improve these results.
00:13:56.814 - 00:15:02.674, Speaker A: So that's the first model. The second model is basically tries to criticize the first model, saying that in the first model, when we want to be simultaneously good for both cases, we are still trying to be good in the very pessimistic case of adversarial model. But reality is not really bimodal like. Maybe the other way to formalize the problem is we have online notes that arrive one by one, but we have like a fraction of nodes that arrive not according to prior distribution. So we have a small but non random adversarial deviation from the forecast. So like here, for example, if in the case of traffic spikes, some parts of the day, we may see a pattern that we could not predict. So now we want to design an algorithm with an approximation factor whose approximation factor is basically a function of how much we are off in terms of the forecast.
00:15:02.674 - 00:16:31.886, Speaker A: So we want to quantify the quality of the forecast we have, and then the approximation algorithm should be a function of that quantity. So, the model, a specific model that we look at is a teacher step. Adversary can either create an arbitrary item or draw from some distribution d. And after some number of drawn from this distribution, adversary also can terminate the input. So the measure of the quality of the forecast or this distribution d is what the ratio between the optimum of what would have happened if the forecast realized if this distribution d was the real forecast over basically what really happened with the adversary giving us adversarial items. So basically, if adversary can have an impact on lambda fraction of the optimum solution, then the question is what approximation factor we can get as a function of this lambda. So we want to design an algorithm that when this lambda is close to one, we achieve asymptotically optimal one minus epsilon approximation.
00:16:31.886 - 00:17:24.293, Speaker A: When this lambda is close to zero, what forecast gives us compared to the optimum is completely off. We don't want to go all the way to zero. We want to have a good relation, or like, we want to still be a constant. So in this EC paper, what we did was to design an algorithm that adaptively checks if the forecast was good or not, and then switches between primal dual algorithm and this new algorithm. And then what we could show was basically a better relation or dependence on this factor lambda. So like the trivial algorithm would achieve this if you just randomize between two algorithms, but we achieve better dependence. I am not elaborating on these functions because it's not very useful.
00:17:24.293 - 00:18:09.704, Speaker A: I'm just talking about the model. But then we also show like a lower bound, and then there is a gap between the function lower bound and the function upper bound that we can achieve. So, but the moral of the story is, it's a formal model to combine adversarial and stochastic inputs and get an approximation factor, which is a function of the quality of the forecast, and you can apply this type of model to other problems. So that's how I conclude the first part of the talk. It would be interesting to look at these hybrid models. And I proposed like two specific theoretical models. One is simultaneous approximation, and one is the mix adversarial and the stochastic input model.
00:18:09.704 - 00:19:32.844, Speaker A: And there are many other models to consider here and like control theory approaches, and like stochastic models with volatile type distributions. So the open problem seems that, first of all, now these approximation factors, I said, is and tight, it's open to close these gaps, and you can apply these models to your favorite online optimization problem. So I would like, I mean, I think it's good to see more results in these formal frameworks, especially the simultaneous one, is very, well, very cleanly defined. I've seen like one recent paper on this topic, which I like. The other, I just added this one line for open problem, because you want to mention open problems. Another interesting question that's open in this area of online allocation is in the online, I've mentioned this over time, but maybe some people have not seen this. So in the online stochastic matching setting, like unwated, with IId non distribution, we can write a dynamic program that's well defined, and that would be the optimum online one can achieve when you have IID non distribution over time.
00:19:32.844 - 00:20:20.304, Speaker A: Basically, there is a well defined exponential size dynamic program that you can write, and that's a valid upper bound on what you can achieve. If we compare ourselves to the offline optimum, it's known that you can't do better than 82% of the optimum. I think it's fine. But if we want to compete with this online dynamic program optimum, there is no non lower bound. So particular there might exist. We may be able to get asymptotically optimal or like a polynomial time approximation scheme against that optimum. So that's like a very cleanly stated, but extremely perhaps hard.
00:20:20.304 - 00:21:04.092, Speaker A: Like, there is no good lower bound here, there is no good upper bound, and it has been not explored as much, maybe. So that's the first part. Now, the newer parts related to online bundling and bank accounts. Any questions, discussions about the first part? Maybe we can have it at the end. So, yeah, like the online bundling part is we have tools for revenue maximization. We talked about several mechanism design optimal auction problems. In reality, we are dealing with repeated auctions, first of all, and not singleton auctions in the context of advertising.
00:21:04.092 - 00:21:57.744, Speaker A: So, like, any result that applies to repeated auctions is much more relevant for real problems. So, like revenue optimizing strategies for basically in mechanism design, you either apply Myerson, which is too complex to implement, you come up with reserve price, like anything that you do. By optimizing each auction separately, you may lose a lot in what you can achieve in terms of revenue. There is this other concept of dynamic mechanism design and bundling these items over time that can help achieve much better efficiency and revenue. And that's what I'm trying to motivate. How do you define a repeated auction.
00:21:58.484 - 00:22:01.128, Speaker B: From the same players agents?
00:22:01.216 - 00:22:21.872, Speaker A: It's like you're selling a similar type of item that may come from some distribution, and you may have some information about the distribution that items come from, and then you're selling to the same type, same agents over time, even like one buyer. So like, you're interacting with this buyer repeatedly over time.
00:22:21.968 - 00:22:24.204, Speaker B: So that's why you can generate the distribution.
00:22:24.704 - 00:23:05.100, Speaker A: Yes, and I mean, like, I haven't defined anything, so let's move a little bit forward and then we can discuss. So what do I mean, first of all, by bundling. So let's say I'm running, I'm selling impressions or items over time, and these are the beads that I have. So, like the first item, I have these two beads. The second item, like the same type of item arrived, and now we have these three beads and so on and so forth. So now if I look at, for example, the blue buyer here, these are the declared bids. If I wanted to assign, like, a good reserve price against this buyer, maybe it would have been this line.
00:23:05.100 - 00:24:13.144, Speaker A: So I have to get this much revenue, like, I can get on average, this much revenue from this buyer. But if I could bundle all these items together and I could look at the average value or average number that this buyer could like, that this buyer is willing to pay, that average number is definitely more than the optimal reserve price that they can put. So there is a gap between these two numbers. And the question is, how can I design a mechanism online, mechanism that can extract this gap? So the idea that can be implemented is the idea of dynamic mechanism. You sign a contract between the buyer and the seller and say, okay, you have some prior commitment to buy some number of items at some average, or maybe you offer, like, a menu of options. And like, with some prior commitment or prior contract, you can actually achieve much more revenue, like, compared to the repeated auction. Repeated Myerson auction.
00:24:13.144 - 00:25:27.624, Speaker A: So first, I want to show you that unreal data, or like, unrealistic data sets, this can also make a very big difference if you look at real bids over time for different type of inventory models. If you assign the best optimal personal reserve that you can assign and then run repeated reserve price action, second price action with that reserve in all these data sets, you get around like 50% of the optimum, especially in display ads where the markets are not thick, they are thin. Like the number of buyers per item may be too low. But it turns out that there are very, I mean, there are realistic type of contracts that one can design. Here, for example, we call this type of buyer choice contract that when you assign, like, with some prior commitment, and I'm not elaborating on this because that's not what I'm trying to focus. I want to just show you the data, motivate and move on to the online part. There are ways to implement these type of contracts over buyers in a way that we can achieve much more revenue.
00:25:27.624 - 00:26:19.368, Speaker A: So this is a joint work with Hamid Nazarzadeh, and it's available online. You can take a look. Basically, we compare, like, what you can achieve out of, like, some sort of deals here that we call buyer choice deals, and what you can achieve in a repeated Myerson type setting or repeated optimal option setting. So, like, the point here is that unreal data, we can get much more revenue, almost twice as much revenue. Like, if we could sign, like, this type of deals. Like, it's not only for revenue, even for welfare. If we compare what we can achieve with these mechanisms, as opposed to basically, if we do repeated second price with reserve, we can achieve even more in terms of revenue, in terms of welfare.
00:26:19.368 - 00:27:49.984, Speaker A: And the reason is that the moment that we want to do repeated separate auction optimization, we have to lose something in terms of like match rate or basically in terms of allocating items to this buyer, because we have to set a reserve price that plays against the buyer gaming against us. So the point is, the data shows that, ok, offline, we can design these deals and achieve much more revenue. But the question is how can we implement bundling or this type of dynamic repricing, dynamic pricing over time without prior commitment. So what I want to achieve is instead of having the buyer commit to pay something on average or a bulk of money over time, I want to make sure that my auctions satisfy individual rationality per auction. So I want to design dynamic mechanisms or stateful pricing, that the pricing depends not only on the current auction, but on the history of the bids and the interaction with the buyer. But at the same time I want to keep the auctions individually rational, so I don't want to charge the buyer more than its bid, ever. So basically, we look at this problem and we design a simple class of auctions we call bank account mechanisms.
00:27:49.984 - 00:28:51.684, Speaker A: The idea of the bank account mechanism is very simple. It's basically to create a bank account or a credit account for each buyer. And we say that this credit account or bank account increases whenever the buyer creates extra value for us in the market, and the value decreases whenever the buyer gets, gets a discount in this auction. And like these are, I have to make these things very formal and I'll do that. But the point is, instead of keeping track of the whole state space, which is, which could be very large, I want to create a mechanism that has one state only per auction and basically make my pricing and allocation function a function of the current bid, and also this bank account number or this one state. And this would be basically what I want to achieve. And I want to make sure that I never charge the buyer more than the declared bid.
00:28:51.684 - 00:30:08.922, Speaker A: I want to satisfy individual rationality per auction. So the question is, what's the power of these bank account mechanisms? Can I achieve the best I can achieve from a dynamic mechanism using these type of mechanisms? So I can ask three questions and I'll try to answer them in the next slide. Slide. So first of all, do we achieve more revenue if I like design bank account mechanism that is trying to achieve dynamic incentive compatibility over time. So instead of trying to basically be incentive compatible or truthful per auction. I want to make sure that incentive compatible across auctions, and I want to make sure that in each auction, I don't charge more than the declared bid. So can I achieve much more than repeated Myerson? The other question is, are these bank account mechanisms optimal in an online sense compared to the optimum dynamic mechanism that can look at the full history of prices and allocations, and can we compute these optimal bank account mechanisms in polynomial time? So these are the three questions we ask, and we provide an answer.
00:30:08.922 - 00:31:09.834, Speaker A: We say yes. There are like in some stylized model that I'll elaborate in the next slide. In a model that we have, like independent valuations across, like over time, we can design bank account mechanisms that implement the optimal dynamic auction and also implement it in polynomial time. So what, like a summary of the result is we can characterize the optimal auction here, and we can show like, that these bank account mechanisms achieve the optimal dynamic auction asymptotically. And we also have a simple one third approximation, basically bank account mechanism. So, like for this talk, in this one slide, I'll tell you the model in more details. So, the model is, at each stage, we have one item that arrives with the value drawn independently.
00:31:09.834 - 00:32:07.772, Speaker A: And so this is a finite horizon model, where both buyer and seller know the length of the horizon, and we want to achieve dynamic incentive compatibility and per auction, individual rationality. So, as I said, we can say that the optimal auction that only keeps track of one state is asymptotically optimal, and we can implement the optimal dynamic auction, and we have a very simple one third approximation, like a way of simply using one state and achieve a one third of the optimum. Okay, 315 already. Okay. Five minutes. So, yeah, so this result is actually similar and related to. So this is a joint work, first of all, with Renato tang and Sang Zhu.
00:32:07.772 - 00:32:55.804, Speaker A: And it's related to a recent paper by Ashlagi, Daskalakis and Hakbano. We have some overlapping results. So our paper is on archive, and we have an earlier version with weaker results in each guy. So there is one more point I want to make before I conclude. So, the point was basically to design like repeated auctions with this extra state. But when we look at the optimal structure of these bank account mechanisms, one thing that we can observe is that when you solve it to optimality, the structure of the auction is that at the beginning, they charge more. So instead of doing a second price, let's say at the beginning, or like the reserve, they do something similar to the first price.
00:32:55.804 - 00:34:10.888, Speaker A: At the beginning, they accumulate the bank account and then they start charging less. So when we look at the utility of the buyer over time, in this time horizon, the utility of the buyer actually decreases over time. So in some one interpretation is that these online bank account mechanisms are implementing the offline bundling in an amortized way at the beginning of the mechanism. So the question is, can we design a mechanism that keeps the buyers expected utility also almost smooth over time, so we don't charge the buyer much more at the beginning and then we charge buyer less later. So that's what we try to address in this new paper with auctions, with martingale utilities. So the idea there is we want to design a similar bank account auction, but we want to add one extra constraint that the buyer's expected utility forms. Like Martingale, what you, the expected utility the buyer gets now should be equal to the utility that the buyer get in the previous state.
00:34:10.888 - 00:35:00.456, Speaker A: So it forms a martingale. So this is an extra constraint on top of per auction individual rationality and dynamic incentive compatibility. So it turns out that even this in a more restricted model of IID items, the distribution is also identical over time. In an infinite horizon model, we can design an auction that satisfies this property, and it has a very simple structure. It's a second price auction, or like an auction with a dynamic soft and hard floor. So what we do above the soft floor we run a second price auction. Between the first and second floor we run first price auction, and below the hard floor we don't allocate.
00:35:00.456 - 00:36:04.994, Speaker A: So this is like an auction that is not incentive compatible per auction. But the point is that if you make these soft and hard floors dynamic and a function of this one state that you define for each player, then you can achieve dynamic incentive compatibility. And asymptotically in an infinite horizon model, you can achieve the like the optimum dynamic mechanism revenue as well. So it has a simple structure, it has a simple update rule, it can be implemented easily and it achieves a good approximation. So that's basically the conclusion. We looked at how we can assign like do bundling over time, but without deviating too much from second price auction. With reserve, we add one state and we wanted to achieve optimum dynamic mechanism performance.
00:36:04.994 - 00:37:00.106, Speaker A: So there are several challenges that this type of auction introduced in the market if you wanted to deploy these type of things. One thing is that the moment that we start using these type of dynamic mechanisms, the optimal response to these type of dynamic mechanisms are also like more challenging. So if I'm running a repeated second price auction that's independent over time. The optimal strategy against this, even under a budget constraint, is a very simple, it has a very simple form, but it's not the case if I'm running like a very stateful or dynamic mechanism over time. So there is a question of designing dynamic options that also have good base response from buyers, or they have good properties against like algorithms that are learning how to bid against these auctions. And this is like an interesting area of research to explore. And that's something that I'm trying to also do.
00:37:00.106 - 00:37:19.674, Speaker A: Like at the moment, like to see what happens when you run the dynamic mechanism like this over time. And like you have a machine learning algorithm playing against it. How can we mess up or not? And that's the research agenda. Thank you. Questions?
00:37:22.614 - 00:37:26.046, Speaker B: So what do you mean exactly by IC in the second part?
00:37:26.110 - 00:38:06.026, Speaker A: Like IID, I said like what's the incentive compatibility constraints? So it's basically that the like, by deviating from truth telling, you don't improve like your utility, your expected utility over time. So in the first result, it's a finite horizon model with like non horizon. So it's like against all these horizon, in the infinite horizon model it has a discount and like with the discounted value. So it's basically the expected utility that you get over time. You don't improve by lying, by changing.
00:38:06.050 - 00:38:11.826, Speaker B: Your, when I look at your future expected utility, do you think a max over all strategies or.
00:38:11.970 - 00:38:14.346, Speaker A: Yes, like you look at assuming, like.
00:38:14.370 - 00:38:18.698, Speaker B: I'll do the best thing I could ever do given so best deviation every.
00:38:18.746 - 00:38:21.014, Speaker A: Day in some cases, yes.
00:38:24.834 - 00:38:47.384, Speaker B: Regarding the first 1st question that you looked at, where you look at algorithms that work well both with the adversarial model, did you think of like simpler questions? So you look at like the secretary problem, right? And you can ask whether for something as simple as that, you can do something similar, I guess for more harder problems, you cannot do that because there you would just get lower bounds.
00:38:50.004 - 00:39:38.384, Speaker A: For secretary problem against like you're saying different type of arrival model and secretaries or adversarial secretary. No, I haven't thought about it. You're like, I can't provide a good, so it may have, so I have thought about, for example, facility location in a similar setting, and it seems that we can't, for example, so like facilitation, you can do random order constant and then adversarial is log n or log n over log line. It seems that you cannot achieve both. So like there are trivial like lower bounds or something, but yeah, so that may be a good question. There are like, you can look at any online optimization problem and apply. Thank you.

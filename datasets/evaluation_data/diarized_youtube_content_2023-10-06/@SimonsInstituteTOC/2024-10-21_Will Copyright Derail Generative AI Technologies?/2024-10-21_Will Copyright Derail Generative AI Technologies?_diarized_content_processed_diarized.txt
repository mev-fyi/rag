00:00:00.520 - 00:00:10.045, Speaker A: Gracious enough to come tell us, will copyright derail generative AI technology? Okay.
00:00:11.865 - 00:01:29.781, Speaker B: Good afternoon and thanks for the opportunity to come and talk to you about what's going on in the generative AI copyright lawsuits. And the short answer to the question is that copyright very well may derail generative AI, at least trained on material that is either not in the public domain or not already licensed. So there are three principal questions. The big kahuna, as I call it, is the question about when, if at all, does making copies of works for the purpose of training data for models, does that infringe the copyright in those works? That's the issue that hasn't. That's central to almost all of the lawsuits. And so they're all pretty much the same when it comes to that question. The second question, which is not very interesting, but I will mention it anyway, because the lawsuits often include claims that generated outputs of AI systems infringe derivative work rights of the ingested content.
00:01:29.781 - 00:02:33.935, Speaker B: And the short answer here is that outputs have to be substantially similar in what copyright lawyers call their expression in order to possibly infringe the derivative work. Right. And in most cases, there's no allegation that there are any substantially similar outputs. Two of the lawsuits, one brought by the New York Times and one bought by a set of music publishers, give examples in the complaints of outputs that they were able to get from the generative AI systems that they think are infringements. And then I'll talk very briefly about the removal or alteration of copyright management information, a violation of another copyright related rule. There are several complaints that raise this kind of claim, but the courts have dismissed those claims so far. So they're kind of, they're, they're in the case, they'll go up on appeal.
00:02:33.935 - 00:03:17.811, Speaker B: But right now they're not really the, they're not really the central focus. So there are, as of today, 32 lawsuits pending in federal courts. Most of them are here in the Northern District of California. Some of them are in New York City. Three of them are pending in Delaware and one in Massachusetts. So they're kind of all over the map. One of the reasons why that's important is that, is that the law of each circuit, so California is in the 9th Circuit, New York is in the 2nd Circuit, Massachusetts is in the 1st Circuit, and Delaware is, I think, in the 3rd Circuit.
00:03:17.811 - 00:04:05.525, Speaker B: That just means that when these cases get up to the appellate courts, there could be conflicts among them, and that might mean the Supreme Court takes it. Okay, so I'm just kind of going ahead a bit just to let you know that it matters that they're pending in different places. Most of the cases are class action lawsuits, and I'll talk a little bit more about that. So the idea is a small number of actual named individuals purport to represent the interests of all people who are in their category. Okay. And so there's one lawsuit that's a class action about visual arts. There are at least eight lawsuits that are class actions involving book authors.
00:04:05.525 - 00:04:50.099, Speaker B: And again, all of these cases are in really early stages. The most prominent of the individual lawsuits are the five that are listed here. Again, part of what's interesting is one of them has to do with stock photography, one with music lyrics, one with recorded music, one with news stories, and one with Westlaw headnotes, which I'll talk about a little bit more later. So these are the. That's kind of a range of them. The question is, who's getting sued? Pretty much everybody in terms of sort of the big players out there. They're all so OpenAI and Microsoft, they have the biggest targets on their bellies.
00:04:50.099 - 00:05:32.507, Speaker B: But Meta has a couple of cases against it. So does Alphabetical. Midjourney has one, GitHub has one, anthropic has one, and so do Nvidia and Databricks. All but one of these cases are in very early stages. What I mean by that is a lawsuit begins when a plaintiff files a complaint. The first move on the part of most defendants is not to answer the lawsuit and say, yeah, I'm raising a fair use defense. They're basically, they move to dismiss the case or to dismiss some of the claims in the cases.
00:05:32.507 - 00:06:13.145, Speaker B: And so there are lots of preliminary motions that go on. Okay, So a lot of these cases have been bogged down in rounds of motions to dismiss, although none of the cases have talked about the training data cases or the training data issue on motions to dismiss. Everyone knows that's the big kahuna that we're going to save for later. Some of them are in discovery. So one of the lawyers wants to, for example, depose Mark Zuckerberg in the Meta lawsuit. And so they've now gotten permission to do that. So some of them are bogged down in discovery.
00:06:13.145 - 00:07:13.329, Speaker B: And some of them, like the Nvidia and Databricks cases, are just inactive right now. There's one judge here in the Northern District of California. Judge Chabria has made it very plain that he wants to be the first one to rule on the training data fair use issue. And he's tried to hurry the case along so that he can get to that. So he basically accused the lawyer who it had been representing Cadre, the class action plaintiff in this particular case, called him incompetent and said, you have to get some new class counsel here because I don't want to rule against your clients just because you've been incompetent. The judge actually said that in open court. But so the David Boyce firm, David Vois famous enough that even you guys would have heard him.
00:07:13.329 - 00:07:42.455, Speaker B: David Boyce, he's really super famous. Okay. If you want to say who are the famous lawyers in the United States who were, like, not working for the. Not the Attorney General or something, David Boies is, like, really, really famous. And so the Boy's firm is actually now in the Cadre case and will be representing Cadre rather than the lawyer who was called incompetent by the judge. So. So that means that there's going to be good counsel on both sides, which wasn't true for a while.
00:07:43.195 - 00:07:45.055, Speaker C: Why were they called incompetent?
00:07:45.715 - 00:08:19.651, Speaker B: Because they were not moving the case along. This one lawyer, his name is Joe Saveri, pretty well known class action lawsuit, Plain of Sky in the Northern District of California. These are his first copyright cases, and he's got seven of them. Okay. And if you have. You're trying to manage seven cases, all of which are class action lawsuits, and you've got lots of things going on, you got lots of discovery to do, you're kind of like, I'm overwhelmed. Okay.
00:08:19.651 - 00:08:41.699, Speaker B: Especially because he's a small firm. Okay. So David Boyce is like, not a small firm person. He's like a big firm person, and he's used to winning. Okay. So you probably have heard of the lawsuit that was brought some years ago by the US Government against Microsoft. Anybody heard of that? Okay.
00:08:41.699 - 00:09:29.079, Speaker B: David Boies represented the United States in that lawsuit. Okay. So he is a really famous lawyer. Okay. Anyway, sometime in the next two weeks, Concord Music's motion for a preliminary injunction against Anthropic is going to be heard. And the key question there is whether it's likely to win on the merits. So that sort of the reason to file a preliminary injunction motion here is less about wanting to enjoin this particular entity and more because you want the judge to say, is there a likelihood of success in the merits? So the defense counsel is basically saying, no likelihood of success on the merits.
00:09:29.079 - 00:10:18.345, Speaker B: Plus, there are these other 10 reasons why you shouldn't issue preliminary injunction. So I think this one's going to get denied, but at least there'll be. We'll know a little bit more after that particular hearing. There's only been one ruling so far on fair use, and that's in a case that was brought by Thomson Reuters against Ross Intelligence. So you guys won't have heard of Westlaw, but it's a database that a lot of lawyers use. Okay? And one of the things that west, the company has done for more than 100 years is basically, here's a judge's opinion on something. Now, I'm going to give you a little short synopsis of what that.
00:10:18.345 - 00:11:09.971, Speaker B: What the ruling is. So it basically tries to extract out of what was often 20, 50, 100 pages of material, sort of like a really, really concise thing. So those are known as head notes. Okay? Now, the judicial decisions themselves can't be protected by copyright law, but the head notes, which are a selection arrangement of information from the opinion, the headnotes may be copyrighted. And so what Ross did is that it got copies of west headnotes and it used the west head notes and the opinions as training data for a legal generative AI thing. Okay? And so Thomson Reuters said, that's copyright infringement. Ross says, no, it's.
00:11:09.971 - 00:11:42.391, Speaker B: It's of fair use. And the judge basically denied motions for summary judgment. Now, summary judgment is something that you kind of say, what the heck is that? Well, why do cases go to trial? They go to trial because I say the facts are A and you say the facts are B. And they can't be both A and B. They got to be one or the other. And so what is the role of a jury? Role of the jury is to say, I believe A instead of B. Okay? That's what a jury is really about.
00:11:42.391 - 00:12:23.603, Speaker B: So if there are no material issues of fact for a jury to resolve, then summary judgment is appropriate. Okay? And so both of the lawyers, both sets of lawyers said, I move for summary judgment. The judge denied both of them, okay. Saying that there were tribal issues of fact on each of the fair use factors. And I'm going to talk about the fair use factors in just a minute. But the day before the trial was scheduled to start in late August. The judge said, hey, how about refiling those motions for summary judgment? But also, please reserve the following dates for a trial.
00:12:23.603 - 00:12:47.791, Speaker B: If I decide a trial is necessary. So I don't know what was going on in his head, but that's where things stand right now. So that case could go to trial in late December, early January, and that would be the first jury finding about whether something is fair use or not. No, of course not.
00:12:47.943 - 00:12:50.327, Speaker C: Did both Litigants move for summary judgment.
00:12:50.391 - 00:13:14.033, Speaker B: That's because they are saying they basically, they each say, there's no tribal issue of fact here. You should decide this on the law. Okay, so the judge basically said, you think this, you think this. I'm not going to decide that. That's a question for the jury. Okay. That's what the.
00:13:14.033 - 00:13:37.501, Speaker B: That's what's going on in this particular case. So the question about what is a issue of law and what is this issue of fact is something that copyright lawyers have been fighting about for a really long time. And this case is going to be a good. This case and cases are going to be good examples of like, oh, God, what's a legal question and what's a factual question? Only factual questions go to the jury.
00:13:37.613 - 00:13:38.733, Speaker A: Which state is that?
00:13:38.869 - 00:14:33.335, Speaker B: I'm sorry, which state is this particular case in? That one's in Delaware. Anyway, so why are the lawsuits being brought? Well, the. There's a lot of money in class action lawsuits, particularly if you get a class certified. It creates enormous pressure on the defendant to settle the case and usually to pony up a really large sum of money. So all of the class action lawsuits are being brought in order to essentially put a lot of pressure on the defendants to sue. And the class action lawyers can be eligible for as much as a third of the take, which, you know, in one of the cases, the explicit request is for $9 billion in damages. And a third of 9 billion is kind of not a small amount of money.
00:14:33.335 - 00:15:24.245, Speaker B: And of course, the large copyright owners, such as Universal Music and New York Times, they just want a lot of money. Okay, so mostly this is about money. But as I wrote in the communications, the acm, recently, several of the complaints asked for destruction of models that were trained on infringing stuff. So destruction is kind of looming out there as a remedy in those cases, too. Now, many of the authors, visual artists, et cetera, who are individual plaintiffs in these cases, they are really unhappy and they just. You didn't ask my permission. You're not compensating.
00:15:24.245 - 00:16:20.229, Speaker B: You're producing high quality outputs because you built your models on us and you're competing in the marketplace with us, and that's not fair. So this is a nice visual to give you a sense of what the visual artists think about generative AI. Yeah. Okay, so copyright. What? Okay, so the most important thing here is copyright attaches automatically by operation of law to every original work of authorship. Once it's been fixed in a tangible medium, and digital is fixed enough, the rights vest in the authors but authors often sell or license those rights. Reproduction and derivative work.
00:16:20.229 - 00:16:41.117, Speaker B: Right. Are the most important ones. The rights last practically forever. But the only thing copyright protects is the original expression in a work, not its ideas, facts, or methods that are embodied. And it's limited by fair use. Okay? So that's the stuff that you really. You got to know in order to, like, understand the rest of the talk.
00:16:41.117 - 00:17:28.147, Speaker B: So fair uses are not infringements. Right? They're not excused infringements. They're just not infringements at all. But it's a defense, and it means that the defendant bears the burden of proof on the issues, which can be really important. There are four factors that are set forth in the statute. Basically, the purpose and character of the challenged use, the nature of the copyrighted work, the amount and substantiality of the taking, and the effect of the challenged use on the market for the value of the work. So the short version of the arguments of the plaintiffs in these cases is that all of the defendants in these cases are making commercial.
00:17:28.147 - 00:17:55.747, Speaker B: Are using the works for commercial purposes. And they're not transforming them like, they're. They're not a parody, they're not a commentary. They're basically just using them for the same purpose. And also, the outputs have the same purpose as the plaintiff's work. Right? So if it's a visual art, hey, here's my visual art. I put it up on the Internet, and then it gets downloaded and then used as training data.
00:17:55.747 - 00:18:28.953, Speaker B: And here's an output and it competes, right? That's their argument, the nature of the work. Well, again, the nature of the work. It's like all of them have different types of works. But nevertheless, the plaintiff's point of view is that you can generate high quality outputs because the models were trained on high quality inputs. That's the nature argument for the plaintiffs. And you make copies, multiple copies of. Of the works.
00:18:28.953 - 00:19:12.061, Speaker B: And that is bad, too. And there are two arguments in respect of market effects. So the plaintiffs, such as Getty Images in New York Times, say, hey, you are harming actual or emerging markets for licensing revenues for my works as training data. And the class action plaintiffs say, your outputs essentially reduce demand for human authored works and threaten authorial livelihoods. And so that's not fair. That's the kind of short version of that. The version from the standpoint of the defendants, kind of looks pretty different.
00:19:12.061 - 00:19:53.625, Speaker B: So they want to say, look, it's transformative because we're using works as training data, and training data is, like, different. So if I created a work of visual art when I Created that work of visual art. I intended its purpose was to let people enjoy the beauty of my thing. When it's done computationally, it's done for completely different purpose. You don't really care about whether it was pretty or not. You just care about its composition, its component parts. If you use the works data and not for their expressiveness, that should be okay.
00:19:53.625 - 00:20:35.779, Speaker B: And the argument is that it's okay to use works to extract information about how those works were constructed. Right. So that if you were kind of like even analyzing a novel or something like that, if you kind of extract a bunch of information from it, that's not copyright infringement. Nature of the copyrighted works, again, it depends on the particular type. But much of the. Most of the data on which the models, who are the defendants in these cases, were trained on was voluntarily posted on the Internet. And there are cases that have given that some weight, the amount and substantiality.
00:20:35.779 - 00:20:56.349, Speaker B: Yeah, I took the whole thing, but it was intermediate. So one of the things that the defendants are really going to be trying to say is, hey, here's the data set. Yeah, I made copies of it. But the model isn't a copy of the training data. Right. Or it's not a discernible copy in the way that copyright law cares about. Right.
00:20:56.349 - 00:21:26.385, Speaker B: So you can't just look at the model and sort of say, oh, here's the sentence that I really like from this particular novel. It's like, it's not there in that way. Okay. So the datasets being distinct from the models is actually one of their arguments. And then market effects. Well, it's not possible to get a license from everybody whose works are ingested. Billions and billions of things on the Internet, et cetera.
00:21:26.385 - 00:21:47.995, Speaker B: I don't need a license if the use is fair. Outputs are overwhelmingly not substantially similar. And besides, hundreds of millions of people are using these models to create new things and to make personal uses. And that's actually sort of something that's public benefit, right? Yeah, yeah.
00:21:50.015 - 00:21:56.447, Speaker C: So we know that models can omit individual copyright works.
00:21:56.551 - 00:21:57.235, Speaker B: Yes.
00:21:57.935 - 00:22:18.343, Speaker C: What is the difference between that and the model containing, like, the copy? Is it, like, the fact that in one case it's generating it, in the other case it's, like, stored internally like this? I guess the thing. As a computer scientist, it's hard for me to draw the line. I've talked to other lawyers, and I'm just, like, curious. Like, what, how you try and draw.
00:22:18.399 - 00:23:10.501, Speaker B: Yeah, I mean, some part of it depends on what the prompt is. Right. So part of the. Part of the Question I have a little slide a bit later, but I'll make the point now, which is that if you, as the person who is trying to get some output generated, essentially prompt the model to emit certain things, then if anybody is the infringer, it may be you, the person who prompted it. And that isn't to say that. So that's one of the questions in the New York Times and the Concord Music cases. Now, in Concord Music case, Anthropic has basically said, look, I didn't put strong enough guardrails in before.
00:23:10.501 - 00:24:12.093, Speaker B: I put guardrails in now. You can't do this anymore. And therefore that was just a, you know, that's not what Claude was designed for and we shouldn't be liable for it for any kind of thing. So now we know that we gotta be more careful. Now we're more careful. New York Times case initially they made a really big splash because their complaint had a lot of examples of here's the story from the New York Times and then here's, here's the, here's the thing that I was able to get ChatGPT to do, and that was included in Exhibit J. And the New York Times, as I understand, has withdrawn Exhibit Jesus, because they don't want discovery to be done on how did the New York Times engineers working for the lawyers, how hard did they have to work in order to get the substantially similar output?
00:24:12.189 - 00:24:17.785, Speaker C: And that makes a difference for whether it was contained. Like Mal has a copy of it. Interesting.
00:24:18.565 - 00:25:00.355, Speaker B: As I understand it, at least sometimes what the Times people would do is they'd input the story and then ask for the output to be a similar story. And if you do that enough times, you get an iterative thing. So you're kind of the person who is responsible for the stuff. And the question is whether the developer of the model is not directly liable because they didn't output that particular material, but whether they're indirectly liable for copyright infringement. And so I'll show you a little bit more about that. But that's the short version. Yeah.
00:25:00.975 - 00:25:16.135, Speaker C: On point two, when models are, or when work is voluntarily posted on the Internet, is there some sort of implicit license to allow people to copy it, to browse it and read it, if the courts have anything.
00:25:17.545 - 00:26:17.165, Speaker B: As it happens, there's a case. So the Field vs Google case was actually a case in which a court held that Google's copying of Field's works on the Internet for purpose of indexing and caching the contents was fair use. But the court also said that there was an Implied license, right? If you put something up on the Internet and you don't use robots txt, then you're basically, you have implicitly licensed that stuff. And I think a lot of that's what's, that's what happened for a lot of things. Common Crawl has been making copies of the Internet in addition to Google and other search engines. They've been doing Common crawl for like 17 or 18 years. So there is an implied license theory that will, that the defendants will be looking to.
00:26:17.165 - 00:27:23.553, Speaker B: But of course the another case that, that's just a trial court case, the second Circuit Court of Appeals, which is like a big, big shot among courts in The Authors Guild vs Google case, decided that digitizing millions of in copyright books for purposes of indexing and serving up snippets was fair use and kind of said, and other kinds of computational uses were also fair use. So that's important to sort of, that's one of the major decisions. There's also a case where a student sued a plagiarism detection software system for storing their papers and the court basically said look, I'm not trying to exploit the expression, I'm only using it as data. Right. And that was a case in which a non expressive use of works was considered. Okay. And the Sega vs.
00:27:23.553 - 00:28:12.743, Speaker B: Accolade case is another case the defendants are looking to because the SEGA essentially sued Accolade because accolades reverse engineered computer program in order to get information about how it needed to configure an interface in order for its code to be able to work on the Sega platform. Right. So it was basically an interoperability case and the court said that was fair use because you were making an intermediate copy of the software. Right. You weren't exploiting the expression in the software, you are basically copying it in order to extract information. And that information wasn't protectable by copyright law and therefore it wasn't an infringement. Okay.
00:28:12.743 - 00:28:59.255, Speaker B: Now the plaintiffs are basically going to say, oh, don't pay any attention to those cases. Those cases are all distinguishable. And I'm not going to go through it here, but you can see the kind of the arguments that the courts are being, are going to be faced with is trying to distinguish the first set of cases from these other cases. And there's going to be a lot of fireworks between now and then. So there are other kind of things that are in some of the cases that I think are going to be important. So the Kadri case, that's a cadre versus Meta. That's the one Judge Chabria Wants to take to fair use ruling.
00:28:59.255 - 00:29:50.213, Speaker B: One of the things that Cadre complaint talks about is that OpenAI was trained or no, sorry, Meta's model was trained on books, on a corpus of pirated books. So is that going to matter the. Out there on the Internet? Did you know about that? Sometimes you can't tell the difference between something that's just a book and something that's a pirated book. But there's Books 3 is apparently a place where 190,000 books are found that are pirated, apparently. And so if they're available on the Internet, that's going to be different from, you know, you voluntarily posted them. So that's different. And training on Sci Hub or Anna's archive might be troublesome.
00:29:50.213 - 00:30:17.219, Speaker B: So it's possible that that could, like, tip a fair use case in plaintiff's direction. It's also possible that courts will distinguish among different types of models. So I would say diffusion models are probably more vulnerable to challenge than large language models. Okay. It also. I'm sorry. So I think that.
00:30:17.219 - 00:30:28.095, Speaker B: I think that diffusion models are going to be more vulnerable to infringement claims than large language models, because large language models are more abstract.
00:30:28.715 - 00:30:32.964, Speaker C: Are you thinking in a way that. Is that because you think of LLMs as text output?
00:30:33.031 - 00:30:33.637, Speaker B: Yeah. Okay.
00:30:33.705 - 00:30:37.775, Speaker C: Because you can have LLMs that generate images and you can have diffusion.
00:30:39.845 - 00:30:40.221, Speaker B: Models.
00:30:40.253 - 00:30:41.765, Speaker C: That generate images are more vulnerable.
00:30:41.845 - 00:31:18.849, Speaker B: Yes, I think that's right. And then part of the thing is that I'm saying too, is it may depend on the data type, right. That software, because it's functional and because it has thinner scope of protection, may be more likely to be fair use than, for example, visual art or music. Recorded music. You know, you mess with the recording industry, you are really in trouble. And I'm telling you, there are two recorded music cases now, and I would not want to be the defendants in those cases. And both of those cases are being brought against small players, right.
00:31:18.849 - 00:31:28.145, Speaker B: Not big players. And so it's easier for the recording industry to squash the little guys than to squash the big guys.
00:31:28.305 - 00:31:40.337, Speaker A: So, yeah, more susceptible or more vulnerable? Because I think it's the fact that our music. I can say this sounds similar, this looks similar, but then in text, it's harder to have that established.
00:31:40.401 - 00:31:40.793, Speaker B: Right.
00:31:40.889 - 00:31:55.041, Speaker A: But this is separate. Like people going off and being like, oh, this is similar, so I'm going to sue. Is different from people being able to prove that this came from the data. Actually, with LLMs, I think they might memorize and regurgitate more than diffusion models. Like there's.
00:31:55.233 - 00:32:48.347, Speaker B: So these Kinds of. All I'm trying to say is that most people would go into this and say, oh, they're all the same. I'm saying some models may be vulnerable, more vulnerable to infringement lawsuits than others. And I was trying to give an example of that. But it's also the case that data types may matter. So one of the things about recorded music is owing to a kind of historical anomaly, only the exact sounds of a sound recording are protectable by copyright law. You can sing the same song in exactly the same way and as long as the bits are different, it's not an infringement.
00:32:48.347 - 00:33:00.661, Speaker B: Okay, that's important to kind of understand now you have to have cleared the music if the music's still in copyright. But in terms of the recording, the recording basically has the thinnest of copyrights.
00:33:00.773 - 00:33:02.185, Speaker A: I see. Okay.
00:33:02.485 - 00:33:04.581, Speaker C: And these music cases are about the recording.
00:33:04.693 - 00:33:33.205, Speaker B: What? The two music cases, there's two copyrights in every sound recording. Potentially. Right now, the music composition might have been in the public domain because it's Bach or Beethoven, but if it's not Bach or Beethoven, if it's Taylor Swift, there's a copyright on that music and then there's a copyright on a sound recording. The sound recording copyright is really thin. Music copyrights, music composition copyrights are pretty thick.
00:33:34.505 - 00:33:35.753, Speaker A: So that's how Taylor Swift was able.
00:33:35.769 - 00:33:38.005, Speaker C: To screw her first contract.
00:33:38.345 - 00:34:00.635, Speaker B: No, she was able to re record music because the copyright that the recording industry had was so thin that her re recording it and trying to sound as much like Taylor Swift's first version wasn't an infringement because it wasn't an exact copy of the bits. Okay, that's the point.
00:34:01.815 - 00:34:04.911, Speaker C: It was okay because it was. She had the copyright for the music.
00:34:04.983 - 00:34:16.455, Speaker B: Like she had the copyright in the music and she re recorded it so that it wasn't an infringement because the copyright and sound recordings is super, super thin.
00:34:16.495 - 00:34:21.063, Speaker C: So with these cases against the Genai music providers, it's going to be all about.
00:34:21.119 - 00:35:00.635, Speaker B: It's going to be, it's going to be really interesting. Okay. Because the copyrights and recorded music are so thin. And so I know the guy who's litigating it and this is going to be fun for him, but not so much for other people. Anyway, my point here is just that different data types could be treated differently, right? So that it's not going to be all fair use or all unfair use. It's going to be like some will be more likely and some will be. Anyway, it's going to take, I think, I'm estimating five to Seven years before we really have any clue market harm.
00:35:00.635 - 00:36:04.325, Speaker B: Again, to the extent that there's an existing market for licensing uses of things like Getty Images 12 million version 12 million. That can be. That's a stronger argument for market harm than in the class action case, because Anderson and her fellow plaintiffs can't give anybody a license. Right? They can't give stability a license. They can't give anybody a license because they don't exist as a class until and unless the court basically creates them as a class. Now, the more interesting question is what happens if you didn't have a licensing market before, but now that you see that other people are licensing stuff, you sort of say, hey, I could license my stuff too. Now, Reddit is an interesting example because everybody was doing training on Reddit data for a long time and Reddit now says, oh, if you're going to train on my stuff, you basically get a license.
00:36:04.325 - 00:37:00.805, Speaker B: You need a license from me, but I don't own any copyright in any of the postings. So exactly where they get the right to license, I think is just kind of interesting by itself. But also there's a question of, you know, if, let's say OpenAI trained on Reddit data before Reddit basically had a licensing market or said it had a licensing market, what happens to the next company or the next individual who wants to do it? Now? Do you have to? Do you have to. Does. Does OpenAI get a free ride? Because they did it before there was a licensing market. And how does the fact that now Reddit says there has to be a licensing market, how does that affect the fair use defense somebody might want to make along the same lines as OpenAI? Okay, so the point here is that now there's talk of collective license.
00:37:02.635 - 00:37:08.571, Speaker A: What a question of fair market does not have to do with copyright. It's a different legal.
00:37:08.643 - 00:37:48.959, Speaker B: Well, so go back to our four fair use factors. The last factor, number four, is the effect of the use challenged use on the market for or the value of the work. So if there's market harm, that will undercut the fair use defense. Okay, okay. Anyway, some people are talking about having a collective license. This is a very popular idea in Europe, and we'll see what happens with that. I think Congress would have to do it, and I don't think Congress is planning to do that anytime soon.
00:37:48.959 - 00:38:33.865, Speaker B: There are incredible practical problems with putting that together, but whatever. Anyway, the whole point here is that I'm trying to give you a back and forth. The back and forth is, hey, the purpose of copyright in the first place is to promote the progress of science. But it's, let's say, knowledge. And the large language models and other models are basically doing things that advance progress of knowledge. And so maybe that should be a reason why it's supposed to be. And again, to the extent the courts accept the idea that when you're doing the training, you're not trying to exploit the expression, you're just trying to deconstruct the thing.
00:38:33.865 - 00:40:13.355, Speaker B: An analogy that I've sometimes suggested is that if you have a little construction made out of Lego blocks, and then you take the Lego blocks apart and then you make a new construction is not a copy of the first thing. Okay? So that's, if corpse buy that kind of analogy that tips in the direction of fair use. See what I'm saying? Okay, so expression is a complicated word, but works, copyright, works contain a lot of unprotectable stuff. And I would give you this, but I think I'm just going to say there's some case law where you can extract the really valuable stuff and it's still not copyright infringement. This is a slide that I think I'll probably end on, which is that you guys, to the extent that you're doing training, may want to be thinking about how do these lawsuits potentially affect the research community that is doing this kind of work? And the answer is that none of the cases right now involve nonprofit or research oriented uses. But commercial versus non commercial is a big deal, right? And favored uses include scholarship, research and teaching. So those things point in the direction that it's more likely fair use if you do it than if it's being done for commercial purposes.
00:40:13.355 - 00:41:29.781, Speaker B: And again, to the extent that it's unlikely to harm markets for the works expression, again, that will probably favor you because there's also less likely to be kind of market harm from your use, as opposed to what OpenAI or Meta do. But all of the cases involve, except Rosa, involve big tech defendants. And there's kind of a thing of tech lash right now. And I'll tell you, none of them basically wants to push for a distinction between their for profit stuff and the nonprofit stuff. So if push comes to shove and the plaintiffs are able to get a really broad ruling that training data must be licensed or it is unfair and infringing that broad interpretation could end up harming your community. And so we should stay in touch because one of the things that courts allow affected parties who are not in the lawsuit to do is to file amicus briefs, to file other kinds of documents, basically say don't overdo it. Right.
00:41:29.781 - 00:42:05.365, Speaker B: Don't give a really broad ruling here where a narrow ruling would be appropriate. And so, but this is really important, okay, to realize that even though you think, oh, I'm a researcher, nobody was, nobody cares about me, well, guess what, if it's a recording industry, they'll go after anybody. Okay? They, those guys are just good at litigation. Okay, so I see I'm actually out of time. I do have some additional slides. You can see them, they're pretty much self explanatory and I probably can take at least one or two questions.
00:42:05.905 - 00:42:18.445, Speaker C: So I'm curious, you mentioned a lot of the factors that go into it and do political factors like, you know, if there are rulings against big tech, the US might fall behind, do these enter into any of the considerations of any levels or.
00:42:18.995 - 00:43:58.513, Speaker B: Well, you can't say it quite that way, but certainly it is in the ether and certainly when it comes to testimony in Congress, there have been several hearings about generative AI IP issues and their copyright office has held a number of listening sessions and the like. That's a place where you sort of say, look, Israel and Japan have extremely broad interpretations of text and data mining as something that's good for society. The Israeli Ministry of Justice issued an opinion that under Israeli fair use law that, that using copyright works for training data is okay. And the European Union has a text and data mining exception, one that's non wavable by contract for nonprofit researchers and another for profit type entities. But, but people can opt out, right? So that, so there's going to be this kind of like you don't want the US industry to basically collapse, right? Nobody wants that. But you got to say it a little more subtly than that. But it's part of, it'll probably be part of the public benefit argument.
00:43:58.513 - 00:44:56.607, Speaker B: So public benefit is not a separate fair use factor. But courts have routinely considered how is this lawsuit, how is the outcome of this lawsuit going to affect the public? And if it benefits the public, that's great. If it doesn't benefit the public, well, that actually is something to take into consideration. So for example, in the Google vs. Oracle case that the Supreme Court decided back in 2021, what did Google do? It used 11,500 of the Java declarations in the Android platform. And the question was whether that was fair use or not. And the Supreme Court said yes, it was fair use by a 6 to 3 majority.
00:44:56.607 - 00:45:22.075, Speaker B: And one of the considerations was that the Android platform had promoted creativity and had had a public benefit because so many people Have Android phones and have apps for them. And so that's a public benefit. Okay. So it's part of the penumbra, but you don't say it straight out.
00:45:24.705 - 00:45:51.105, Speaker A: Another question regarding the exhibit J that you mentioned. Is it common that, like, people would withdraw evidence like this and do you. Because it was weird the way that it was reproduced. Like, everyone, like, as researchers, it's really hard to memorize data like that and get it out. And we all were thinking, what is OpenAI doing that has gotten it to memorize this that is so extractable. So do you think there could have been more to the prompts or like, you know.
00:45:51.225 - 00:46:26.811, Speaker B: Yeah, this is one of those things where the Times wanted a clean case. Right. They wanted such a clean case that, see, OpenAI and the Times had been in negotiations for months. They were asking for more money than OpenAI thought was appropriate and open. I know from somebody who's at OpenAI that they thought that they were really close to getting it. And then all of a sudden the lawsuit gets brought. So they felt like hoodwinked.
00:46:26.811 - 00:46:40.723, Speaker B: Right. They felt like they had been kind of lied to and stuff like that. So you can see the Times lawsuit as just a ploy to get a higher license fee. Right. So that may be. That case may settle. Right.
00:46:40.723 - 00:47:01.849, Speaker B: And the. There's a case. Getty Images Against Stability. That case looked like a pretty strong case to me, but I haven't heard hide nor hair of it lately. So that one might have settled too. And, you know, Getty might have been willing to do it. I think you were next.
00:47:01.849 - 00:47:04.873, Speaker B: And I don't know because we have a hard stop.
00:47:04.969 - 00:47:08.803, Speaker A: There was actually two minutes off. Clock is wrong. It's 303.
00:47:08.899 - 00:47:10.755, Speaker B: Oh, okay. I. Sorry.
00:47:10.835 - 00:47:11.355, Speaker C: Is that okay?
00:47:11.395 - 00:47:18.935, Speaker B: Yeah. Did you want to ask a question? Oh, you can go ahead. Oh, go.
00:47:19.235 - 00:47:46.265, Speaker D: I was wondering, you said before that OpenAI was treating us allegedly like stolen or like, not put online legally text. But I wonder if there's a difference if, like, I'm training on the New York Times, it's subscription that I purchased. Is there a difference between, like, I posted this on Reddit and I didn't. I wasn't paid for it. This is paid content versus, like, I bought a subscription and I was told that I could learn things from this website using this subscription.
00:47:47.245 - 00:47:48.025, Speaker A: Yeah.
00:47:48.645 - 00:48:28.583, Speaker B: Again, part of what all of these lawsuits are really going to try to do is kind of put a little black hat on one of the parties. Right. So either the black hat on the Times in the case by essentially being manipulative about the license negotiations. Of course, the Times put the black hat on OpenAI through Exhibit J. So a lot of it's maneuvering around. We don't know at this point what's going to happen. But I think several of the lawsuits involved pirated books, and that kind of makes it look worse for the.
00:48:28.583 - 00:49:06.617, Speaker B: For the defendants. Now, I have a colleague who actually wrote a paper that said even if you train on or do text and data mining on infringing stuff, if you're just extracting unprotectable stuff, it shouldn't be copyright infringement. But again, it will depend on the judges. I wrote a paper actually called Fair Use Defenses in Disruptive Technology Cases that you can find on the Internet if you want. And I trace how courts have looked at the market impact of new technologies that are disruptive. Right. There have been a series of them.
00:49:06.617 - 00:49:24.575, Speaker B: Photocopy machines, hip recording machines, VCR machines, lots of lawsuits involving these kinds of technologies. So it's not anything new that the copyright industries would freak out.
00:49:25.915 - 00:49:28.307, Speaker C: So suppose that the AI companies were.
00:49:28.331 - 00:49:30.123, Speaker B: To settle these suits.
00:49:30.179 - 00:49:36.387, Speaker C: Like, would they be able to extract an agreement that, like, they can't be sued again for the same infringements?
00:49:36.491 - 00:50:00.705, Speaker B: No, of course not. No. There's no incentive to settle because the next one will come out of the woodwork. Right. And so, yeah, so far as I know, none of the cases are settled so far. There's no public announcement of settlement. But you can imagine the times settling, and that one would just go away.
00:50:00.705 - 00:50:23.555, Speaker B: That might have some spillover effects for fair use defenses in other cases, because there are several other lawsuits involving news sites. So again, there's kind of like, who's the next plaintiff gonna show up if I settle with this one? I. I think I really am supposed to stop. You tell me. Okay, you should take my question. Okay.
00:50:25.295 - 00:50:30.431, Speaker A: The question is when you said about the public benefit. Yeah, but if there is a public benefit, that sort of helps.
00:50:30.543 - 00:50:31.591, Speaker B: Yes, absolutely.
00:50:31.663 - 00:50:53.005, Speaker A: So it reminds me of the whole public broadcasting, you know, that she's seething with that. At least it forced them to put some of their money into pbs. And I wonder if there's an analogy to that. Well, here's some sort of regulatory body that puts these screws on.
00:50:55.145 - 00:51:39.121, Speaker B: So there is a theory of what copyright is about, which is that it's about the benefit to the public. Right. And so there are Supreme Court statements over and over again that the primary purpose of copyright is to promote the public good. Right. To create enough incentives for authors to author and for publishers to disseminate. But the primary goal is not to reward those entities, but is to promote the public good and to promote knowledge and the dissemination of knowledge. Right.
00:51:39.121 - 00:52:59.015, Speaker B: And so to the extent that you really buy into it, as I have in my career, that that's really the fundamental purpose of copyright, then you want to have the generative AI training happen, because that advances knowledge and enables a lot of other knowledge to be created. And, you know, it helps people. And so there'll be a lot of focus if the things get up to an appellate court, I think, on public benefit. Also, to the extent that any of these systems actually are held to be either direct or indirect infringers of copyright, then anyone who uses those technologies to generate things that came from the training data, they could be infringers too. And it was one of the things that was important in the Sony Betamax case back in the 1980s when it was pending before the U.S. supreme Court, that by the time the case got to The Supreme Court, 5 million American households actually had a Sony Betamax machine in their living rooms. And so was the U.S.
00:52:59.015 - 00:53:24.725, Speaker B: supreme Court going to say that all 5 million of those households, each of which might have, let's say, four people in it? Right. That's 20 million people. Are you going to say they're all infringers? And I think the court's going to have a hard time putting its mouth around the idea that 180 million people who are using OpenAI are all infringers too. Anyway, I think I really do have to stop.
00:53:33.305 - 00:53:38.945, Speaker C: We have a break for five minutes.

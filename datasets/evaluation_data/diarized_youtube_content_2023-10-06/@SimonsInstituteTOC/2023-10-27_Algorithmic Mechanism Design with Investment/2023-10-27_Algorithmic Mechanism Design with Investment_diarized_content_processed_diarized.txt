00:00:00.120 - 00:00:50.314, Speaker A: Associate director here at Simons. And for those of you who are unfamiliar with the Simons Institute, we're the leading international venue for collaborative research and theoretical computer science. We bring together researchers from all over the world in theoretical computer science and related fields. And I'd like to welcome you today to the workshop on matching markets. And this workshop is convened partly to mark the publication of the book online and matching based market design that came out of existence because of the Simons program in 2019. On the same topic, just to cover a few logistics for today, food is provided before the talks and during the breaks for lunch. You're on your own, but you're in Berkeley, so there are many great eateries nearby.
00:00:50.314 - 00:01:26.814, Speaker A: We ask that you not bring food into the auditorium, and there are lockers on the far side on the first floor, or if you want to leave something when you go out to lunch. And our videographer, Omid Farr, will help speakers get set up for their talks. So I want to thank Ashley, Frieda, and Lyra, who were instrumental in putting together the logistics and accommodations for the workshop today. And I want to thank the organizers, Vijay Vasirani, Federico Echinika, and Nicole Imorlikov, for putting together a great program. And I'm gonna hand it over to Frederico.
00:01:29.474 - 00:01:35.314, Speaker B: Thank you. Yeah, I think. Thank you so much, Sandy. I think you said everything that I was going to say.
00:01:35.434 - 00:01:35.986, Speaker C: So, yeah.
00:01:36.010 - 00:02:18.320, Speaker B: So the origin of this is the first of all, the matching program that we had at Simon's right before the pandemic, and then the book that this gave rise to that forms the core of the speakers for today. And also, it's unfortunate that Vijay couldn't be here because he was really the driving force behind all of this. Both the program, Simon's, the book, the four chapters that the three of us wrote. Really? Vijay wrote those chapters, and it was his idea, his initiative, and.
00:02:18.432 - 00:02:20.124, Speaker C: Yeah, so, hopefully.
00:02:23.264 - 00:02:36.432, Speaker B: And, yeah. So I propose that we do econ style introductions for the workshop. So be very brief. The first speaker doesn't really need an introduction. It's Paul Milgrom. So if you want to get started, Paul.
00:02:36.528 - 00:02:56.366, Speaker C: Sure. And they turn it off, or did that. And he's got. Yeah, he's got one for me, so I'm very happy.
00:02:56.550 - 00:03:00.074, Speaker B: Speaker is Paul. Megraham is going to talk about algorithmic mechanism design.
00:03:01.934 - 00:03:24.266, Speaker C: Yeah. Well, thank you. Thank you, Federici, Federico, for nice. I'm also missing Vijay here. Vijay encouraged me to talk about newer research. I asked him whether he wanted me to talk about what was in the book and he said, well, you know, he always wants to encourage new research. So he said, go do it.
00:03:24.266 - 00:04:32.900, Speaker C: And I wanted to show you that an old guy can still do research. So with some of my former students, Mohammed Akbar Poor and Sheng Wu Li, and a current student, Kevin Lee, and a colleague, Scott Commoner's big group of people ended up getting involved in this. The questions were asked. We were noticing that one of the great things that's happened at the boundary of econ and CS is certain ideas now are being imported from CS back into econ. But we wanted to continue this as a two way street, ideas from econ into CS. And one of the things that we were thinking about in terms of algorithmic mechanism design is the way algorithmic mechanism design is done by CS researchers, typically is you find an algorithm, you talk about how its performance and how it's affected by incentives and how it's implemented. But economists are also often interested in, in incorporating mechanisms in larger systems.
00:04:32.900 - 00:05:51.284, Speaker C: So you might be interested, for example, instead of taking the resources as given, if you were to run this mechanism, what investment incentives would it create? That's sort of the simplest basic idea. So we decided to treat the question of algorithmic mechanism design within investments. And the main question that we want to ask, well, the initial research question, algorithm mechanism design identifies algorithms that produce nearly efficient allocations and pricing that supplements the algorithm to create a truthful mechanism. But do nearly efficient, truthful mechanisms incentivize nearly efficient investments? That's the question we wanted to ask, and we're going to do it in the CS style, which is to say worst case type of analysis. So I think for this group, it hardly needs saying, I put this up here, partly because Vijay's up and is one of the authors of one of the books. But there's really a vast literature about fast approximation algorithms for hard problems. And the theorems emphasize worst case guarantees for quality of the approximation and computation time.
00:05:51.284 - 00:06:57.276, Speaker C: We wanted to ask this different question. So, again, for those of you who are not familiar with this, which is probably nobody in this audience, but just, I'll go over it very quickly. Algorithms take as inputs, values and constraints, and then they select an allocation or an outcome as a result. If the values are private information, then the computations have to rely on reported values, and the analysis of incentives for truthful reporting comes up. So we use reported values and we provide incentives by offering payments that depend on the reports. And the question about whether we can implement an algorithm by a mechanism is when did there exist payment rules that incentivize truthful reporting for the mechanism. And what are those rules? What payment rules do there? Okay, now I'm going to specialize this talk for simplicity to packing problems.
00:06:57.276 - 00:07:37.074, Speaker C: I'll talk about generalizations later. But for example, the knapsack problem is a well known hard problem for which there are good fast approximation algorithms. But the solving it to optimality is np hard. And I'm interested in packing problems for other reasons as well. There are other packing problems besides the knapsack problem that are of interest in applications. The knapsack problem or packing problem simplified the notation a bit. I'm going to say that for player n, player n has a value of being packed.
00:07:37.074 - 00:08:27.342, Speaker C: In the general model, vn is a vector which specifically specifies values for each outcomes. I'm just going to deal with the special model where the value of not being packed is zero and the value of being packed is vm. We have some set of feasible packing capital omega. We have a function of the data given values for each of the items. This is the set that will be packed and the realized welfare, the objective being maximized. Well, if you're using algorithm x and you get inputs v, then we sum over all the people. Xn is one if n is packed, and xn is zero if n is not packed.
00:08:27.342 - 00:09:22.348, Speaker C: So summing vn v x gives you the total welfare, which is the objective of these problems. So that's what I mean by packing problems, and that's the notation I'll use. The packing constraints, whatever they are, are summarized in capital omega. Okay? And we have some additional notation. The constrained optimizer is, we'll call x door of v given s is when you add some additional constraints to the, to the problem. So when you choose the argument that maximizes welfare, subject to being not only an omega but also an s. Okay, x star without the thing is the global optimum.
00:09:22.348 - 00:10:12.944, Speaker C: That's when there is no extra constraint. The optimal welfare is what you get when you use this optimizing algorithm x star and any payments that are made to individual n is a function of the report. So p sub n. So ends payment depends on the report vn that it reports, as well as the these that the other. Okay, now here we, the analysis is going to involve some economic, traditional economic concepts. When a player's value changes from vn to Vn Tilde. So for example, due to an investment, the externality is the wedge between the change in ends payment and the change in others welfare.
00:10:12.944 - 00:10:53.224, Speaker C: So the idea is that when I make an investment, if that affects you either benefit for example, if it takes resources away from you, I should be paying for those resources to ensure efficient investment. And the wedge between those is called an externality. And the externality associated with algorithm x and prices p is, this is the change in the payment, and this is the change in the welfare for the other people. I'm signing the payment. So the payment is a payment to the individual. If it's a payment from the individual, it's a negative number. And that's why the things are the signs that they do.
00:10:53.224 - 00:12:14.564, Speaker C: If the investment cost is low enough, player n may choose to invest to increase its net profit by some amount, delta, then the net welfare increases by this amount. This is the increase in the profit that the individual occurs, plus this externality that represents the increase in net welfare. So if I have an externality, a positive externality in you on plus ten, and I make a profit of five by making the investment, then the total welfare will rise by 15. And so, here's a summary of the main findings of the paper, which I will be going through. First, all non optimizing algorithms, everything that's not optimal, entail nonzero externalities and can therefore lead to welfare reducing investments. That is, I can either fail to make an investment when I should or make it, because there's going to be a difference between the welfare evaluation of an investment and the private evaluation of the investment. That can always lead to welfare reducing investments.
00:12:14.564 - 00:12:59.244, Speaker C: Okay, sure. But won't good approximations have small externalities? You might think, and that's what makes the talk interesting, is that, no. In fact, we can have a fully polynomial time approximation system that consists entirely of algorithms that guarantee only a zero fraction of possible net welfare. When a single agent can invest, no matter how good these algorithms are, as an approximate, an approximating efficiency in the allocation problem, they can provide terrible incentives for investment. I'll show that by example. Ouch. Okay, that's bad.
00:12:59.244 - 00:13:56.384, Speaker C: Do all approximation based algorithms have bad investment guarantees? No, an algorithm that excludes confirming negative externalities, which we'll call x cone algorithms. And that's x cone is a new concept that's introduced in this paper. Confirming negative externalities is another new concept. I'll show you exactly what those mean. They have the same investment guarantees as their allocative guarantees. So if you have an algorithm that satisfies this condition, and it guarantees you 95% in worst case, in the allocation problem, then it also guarantees you 95% in any investment problem that you might make associated with it. So this is an additional new condition that you would want to add to whatever else you were using to evaluate your algorithm to ensure that you didn't get any degradation in the performance.
00:13:56.384 - 00:15:20.554, Speaker C: Okay, but are there any useful x cone algorithms? Can we find anything like that? Yes, we introduce a new X cone FBTAs for the knapsack problem. That is, we take, we find another fully polynomial time approximation system for the knapsack problem, in which each one of the algorithms is x cone. And therefore it's also, if it guarantees 95% for the, for the allocation, the knapsack problem, it still guarantees 95% when you add an investment. Okay, does the guarantee change if the investor must decide subject to uncertainty? So, when we wrote the first version of this paper, it was all deterministic and what the referees objected to, it says, nobody makes investments under certainty. What if there's uncertainty? What if the investor doesn't know other people's values, or how big the knapsack is or what the outcome of his investment will be, but the uncertainty doesn't affect the guarantee. We show that the worst case problem is always deterministic. So you can put in uncertainty about all that stuff and the conclusion remains unchanged.
00:15:20.554 - 00:15:57.936, Speaker C: And then, okay, but surely there's some drawback to all of this. And yes, the theorem that I'll show you this, it's true in the generality that I've shown you for packing problems. Packing problems have something special, that there's a threshold value such that if you're above the threshold, you get packed. If you're below the threshold, you don't get packed. There's a threshold between any two outcomes. There only are two outcomes for an individual. You're either packed or unpacked.
00:15:57.936 - 00:16:53.016, Speaker C: If you try to generalize this to the case where there's n possible outcomes or more than two possible outcomes, the theorem is still true. If there's a threshold vector that makes you just indifferent among all the outcomes. But if there's not, then the theorem changes. So we don't have this completely nailed for general problems, unless we add the condition that the possible value vectors is a product of intervals, basically that you can get these thresholds. So those are the main findings, and I'll get through as much of them as I can in my remaining, what, 30 minutes? Is that what I've got? Yes. Okay, so I imagine that a lot of this is known to a lot of you, but I'll go over some of it, because probably some of you don't have it. We're going to say that a packing algorithm is monotone.
00:16:53.016 - 00:18:01.054, Speaker C: If for each item n, there's a threshold such that item n is packed if its value exceeds the threshold, and it's not packed if its value is less than the threshold. So, for example, greedy algorithms and optimization algorithms, lots of algorithms, have monotonicity. A direct mechanism, I think everybody knows what a direct mechanism is, is truthful if, for all value vectors v. Truthful reporting is a Nash equilibrium of the mechanism. So if everybody else is reporting truthfully, you can't do better than report truthfully, no matter what the, and the threshold payment rule, which is the last definition, is the payment rule that says that when you win, the amount you pay is your threshold value. So if for me to be packed under this current circumstance, I have to report a value higher than six, and if I report less than six, I'm unpacked, then threshold pricing means that if I'm packed, I'm charged a price of six. If I'm not packed, I pay zero.
00:18:01.054 - 00:18:43.724, Speaker C: And the theorem is that a direct mechanism is truthful if and only if the underlying algorithm is monotone in the sense that's defined above, and that there are some functions f, such that the amount that basically it tells you that the threshold payment rule is unique. You can take the threshold payment rule, and you can add a function of what everybody else says. So my threshold is six. If I get packed, I pay six. And in addition, I pay some function of what everybody else has paid. But I pay that anyway. I pay that whether I'm packed or not.
00:18:43.724 - 00:19:21.458, Speaker C: So there's some, as a function of what everybody else says, I pay three. And if I'm packed, I pay an additional six. The additional amount has to be the threshold. And this is all of the truthful algorithms, all of the truthful mechanisms for these problems. And I'm going to skip over the proof. There isn't a bunch of time for that. The key is to stick in the envelope theorem at some point and get a representation of the guy's utility that doesn't have the payment rule in it, and compare it to a representation that does.
00:19:21.458 - 00:19:50.554, Speaker C: And that proves that the whole thing is unique. But we'll skip over all that. Okay? A famous example that uses optimization is the Vickery Clark Grove pivot mechanism. So, here's an example application. Suppose that we have an airline flight and there are more seats booked. Then there are seats on the plane. Passengers p exceed the number of seats s.
00:19:50.554 - 00:20:36.814, Speaker C: And so what we do is we ask each passenger, how valuable is it to you to fly? We want to buy away some of your rights and give you cash instead, maybe then you take a later flight or something. Oops, what's this? What's the certificate? I don't know what that is. The s, passengers with the highest values are seated and they're charged a price equal to the s plus first highest value. Others are not seated and pay zero. That's called a uniform price auction. And that's an example of Vickrey Clark Grove pivot mechanism. You know what I can do? I think I can just turn off.
00:20:36.814 - 00:21:07.774, Speaker C: That's right, turn Wi fi off. You mentioned disappear. Yes. All right. You have to click on the slide. I have to click on the slide. Now, what's going on here? Oh, the pivot, the general case of the pivot mechanism.
00:21:07.774 - 00:21:58.572, Speaker C: Well, okay, there's a general case of the pivot mechanism is shown here, too. For a packing problem, you might charge different. So this is a packing problem at the top, too. We have seats and we have a limit that we've got 40 seats on the plane. We can have 40 people who are packed, that is, seated on the plane. More general packing problems are shown down here and optimizes and charges a price equal to the threshold price to incentivize each person to report truth. Okay, so there are three more things that I will try to get through, at least in part, during my remaining minutes.
00:21:58.572 - 00:23:03.394, Speaker C: The first are how algorithms determine investment incentives. Now, notice it says algorithms determine investment incentives. The key thing here is that normally we think of payment rules as determining investment incentives. But the uniqueness result that I showed you says basically any algorithm has a payment rule that's unique up to this constant that's added, that doesn't depend on what you report, it doesn't depend on your value, and consequently, it doesn't affect your investment incentives. So it's going to turn out that the main point at the top is that only from the algorithm alone, without asking about the payment rule, we can figure out what your investment incentives are. So, algorithms are associated with investment incentives, and then we'll take a look at, well, what are the externalities that result? And again, that doesn't depend on the payment rule either. The payment rules externalities, you'll recall, have to do with the change in your payments.
00:23:03.394 - 00:24:10.452, Speaker C: And those constants all cancel out so that it's the same for all payment rules that make the algorithm truthful. So we'll take a look at worst case analyses of algorithm externalities and prove our theorem about x cone. And then I'll introduce an F ptas that's robust to investments that will take an FB tas an existing fBtas, we'll modify it to make it satisfy the X cone property and wind up with one that preserves investment incentives. So that's the outline I'll try to get through in the remaining time. So, the first point is that, summarized in the box up here, is that all truthful mechanisms that use the same algorithm x have the same investment incentives. And formally, as a theorem, by the way, the numbered theorems are all things that are new in this paper, not necessarily all deep, but they're all new anyway. Let x p and x p hat be two truthful mechanisms that use the same algorithm x.
00:24:10.452 - 00:24:43.176, Speaker C: They differ only in their payment rules. Then, for any values that the others may have bitter ends, net return from an investment that changes vn to vn prime is the same for both mechanisms. And the point is, of course, that the go down through the proof that you have differences in payments, the constants cancel. It's only the truthful part. And this is stated and proved. Actually, the paper is at the level. So this isn't just packing problems.
00:24:43.176 - 00:25:10.898, Speaker C: The paper's at the, at the level of the more general problems I've described to you, but it applies to the packing problems as well. Okay. The numbered theorems are the new ones. Okay. It's known, and it's been known for a long time, that the Vickery Clark Grove mechanisms, including the pivot mechanism, do lead to efficient investments. Bidders profit. There are no externalities in these.
00:25:10.898 - 00:26:11.690, Speaker C: The payments take care of the externalities in these problems. So a bidder's profit is when he moves from, well, this is the profit a bidder earns. In the bickering mechanism, he gets the difference between total welfare and what total welfare would be if his value were zero. So when he does something that increases his profit, it also increases total welfare by exactly the same amount. And so, when faced with any given cost, if it's profitable to invest, it also increases total welfare net of costs. Rogerson's theorem says that in any Vickery Clark Grove mechanism, bidders profit increase from an investment at cost c, that changes its value from v to v. Hat is individually profitable if and only if it increases net welfare.
00:26:11.690 - 00:26:35.134, Speaker C: And again, I've explained that already. This is a converse to that theorem. Okay? A partial converse. It says that if you have a mechanism that leads to efficient investments, it must be optimizing something. It doesn't quite say that. Almost says that it must be optimizing something. Let's see what almost means here.
00:26:35.134 - 00:27:54.374, Speaker C: Suppose that an algorithm has the property that an investment that costs c and causes n's value to change from vn to v hat n is individually profitable if and only if it increases net welfare. So this is individually profitable if and only if the welfare net of costs also goes up. Okay, then there exists some subset of the feasible set omega, such that the welfare associated with x is the maximum over this constrained set. So this is almost the same as saying that the only mechanisms that lead to efficient investments are ones that maximize over some set which might be a subset of the actual feasible set. It's not quite that, it's very close to that. The difference is it says that the value of the algorithm has to be the same as if you were doing that. And we have a little counterexample that shows that there's some edge cases where there are other algorithms that have the same value but aren't selecting.
00:27:54.374 - 00:29:06.034, Speaker C: That is, they occasionally select something outside the set, but only when it has no impact on the value. So I think that unless you really want to get into the details, the takeaway is that the only algorithms that that lead to efficient investment are ones that have constrained optimization almost part okay, so that's how algorithms determine investment incentives, externalities and worst case analysis. Here's an extreme but simple example. When we wrote the first version of the paper, the referees hated this example, even though it completely nailed, because it doesn't resemble any useful algorithm. But it highlights the main point, and you'll see as we get into the theory that it correctly highlights the main point. So this algorithm is a satisfying algorithm for packing problems, and it's very simple algorithm. If the most valuable item that's out there is at least 99% of the total value, pack it and quit.
00:29:06.034 - 00:29:39.356, Speaker C: Otherwise, optimize. This algorithm has a 99% allocative guarantee. It certainly will get you at least 99% of the optimal value. But now let's consider an investment problem that's related. Using this algorithm, we have just two items that might be packed. Actually, it's going to be three items that I changed it. Okay, three items that might be packed.
00:29:39.356 - 00:30:04.774, Speaker C: Sorry about that. Bidder one has value zero, while bidders two each have their items, each have value one. And it's feasible to pack all the items. So it's a really easy problem. You could pack everything. So one's threshold price is zero. No matter what one reports, his payment is going to be zero.
00:30:04.774 - 00:30:58.892, Speaker C: Because with this algorithm, if he reports anything more than zero, well, there's no item that has more than 99% of the value they're going to optimize, and they're going to pack him. So his threshold, the reporting threshold, is zero. So his price is zero in a threshold option, by investing at a cost of 200. Suppose that by investing at a cost of 200 bidder, one can raise its value to be 200 plus epsilon for some positive epsilon. So he's going to earn Epsilon for making this investment. That's a strictly profitable investment if he makes that investment. But the result of the investment, when the algorithm is applied, say, oh, there's somebody who has 99% of the total value, will pack him alone.
00:30:58.892 - 00:31:29.254, Speaker C: And that reduces the net value that you could have had from two down to epsilon. And worst case is zero. Okay, this gives you a zero fraction. You can't guarantee anything higher than a zero fraction of the optimum from an investment. So this is a pathological example, of course, but it highlights, it's extreme. It gets the value all the way down to zero, but it highlights what goes on. And I'll show you how in a few moments.
00:31:29.254 - 00:32:18.084, Speaker C: Okay, so is this example too special? I claim it's not. We left it in. I claim it's not too special. What it's exploiting is the fact that approximation algorithms for the knapsack problem can have good allocative guarantees, even when they're careless about packing items that have relatively low values. And with investment, what can happen is that the gross value of an item can be much higher than its net value, and you don't want to be careless about items that have low gross values because they may be the main things for determining welfare. So that is where the possibility of large errors comes from. And that's what's illustrated in spades by the previous example.
00:32:18.084 - 00:33:02.970, Speaker C: So let's turn to an existing fptas. This is the BKV FPTAs for naphtac problems. Does everybody know what an f p tas is? Let me just say, because there's probably some people out there who don't know. It stands for fully polynomial time approximation system. And it means that you get to specify an epsilon positive epsilon, which is the. I want to achieve, I want to guarantee, when I use an algorithm, that the fraction of the optimum that I get is at least one minus epsilon. So I get at least a one minus epsilon fraction of the maximum possible value.
00:33:02.970 - 00:33:45.064, Speaker C: And I want a runtime, which is a polynomial function of the length of the data and one over epsilon. Okay? That's what it means to be a fully polynomial time approximation system. So it's a set of algorithms parameterized by epsilon, such that the runtimes are polynomial in length and one over epsilon. And the guaranteed performance is at least a one minus epsilon. Okay, so this is their algorithm, and let me go over it a little bit. So this is what the algorithm looks like. You're given a value profile, and it's computer science.
00:33:45.064 - 00:34:52.154, Speaker C: So these are integers and a target approximation ratio, one minus epsilon. And what you do to get your approximation is you construct a series of easier problems, knapsack problems, that are indexed by an integer l, zero, one, two, dot, dot, dot, and they work as follows. So what we're going to do is we're going to fix a step size, which is going to be called gamma, sub l for the elf problem, which is epsilon times two to the l divided by n, the number of items. That's the step size. What we're going to do is we're going to round everything, we're going to round them down, and we're going to truncate so that the highest possible values, two to the l plus one. So we have a step size, we have a maximum possible value that gives us a fixed finite number for each l, gives us a fixed finite number of values that each item in the approximation can take. So there's the truncation step.
00:34:52.154 - 00:35:39.030, Speaker C: Here's the rounding step where you round down using the step size, and then you optimize. And it turns out that there's a polynomial time dynamic programming algorithm that will find the optimum for this approximating problem. And then what BKV do is the BKV allocation. They take, among all these approximating problems, which are all lower bounds for the actual problem. They take the one that leads to the highest value, which is the, I guess it's shown on several screens. So I should point with this thing. They choose the allocation that corresponds to the l that leads to the highest value among all these approximating problems.
00:35:39.030 - 00:36:18.572, Speaker C: They're all lower bounds, and they show that the main theorem is that this algorithm is monotone. It guarantees a one minus epsilon approximation of the maximum. It's monotone because its optimization is monotone. And each of these things is an optimization problem, guarantees one minus n, and it runs in time, that's polynomial in the input size and one over epsilon. So this is the Bkv f p task now. But the BKB equity test is careless about packing small items. That's what's going to be.
00:36:18.572 - 00:37:09.904, Speaker C: What's wrong? Why is it careless? What it's going to do for large l is it's going to round the, where's the rounding step here, it's going to round the values down. So if you have low value items, if their value is less than the step size, it's going to round those values down to zero, and then it's going to treat them all the same. It's not going to pack them optimally at all. Okay, so this has in it, in a much subtler way, exactly the same problem that I showed you in the satisficing algorithm. So here it is. And the reason I put this thing in blue is because this is what we're going to fix. We can fix this just by changing the last step of this algorithm.
00:37:09.904 - 00:38:21.098, Speaker C: So, to take advantage of very highly valued items because of the truncation that takes place here, and you truncate to keep so that you have a fixed number of the, every time you double the upper bound, you also double the step size, so that you, for all these problems, have the same number of possible values. That's why they're able to run in a fixed an amount of time that doesn't vary with l. But in order to include the most valuable items, you have to set l large. And then low value items are rounded to zero. And those low value items are therefore going to remain unpacked. So, theorem three is that for all delta greater than zero, there exists an epsilon less than delta, such that the BKV rule with parameter epsilon has an investment guarantee of zero. Okay? So it says that no matter how good you can take the BKV Fb toss, no matter how small you take the approximation error, you can't get an investment guarantee better than zero.
00:38:21.098 - 00:39:12.678, Speaker C: And that's because you can do exactly what I did in that simpler case. And there's a proof sketch, which I know I'm not going to have time to do. So it's sort of grayed out here, but it's really the same trick where you take some low value item, you create an investment opportunity where the guy can invest a large sum of money at a large cost to make epsilon profit. It really adds nothing to the problem. It adds no great value to the problem, but it, but it results in that the approximation that you're using is one with a high l because you need to include that item. And it has exactly the same effect as the ten minutes here. I'm doing okay on time.
00:39:12.678 - 00:39:48.780, Speaker C: It's okay. So now how do we fix this? How do we find. And these are, by the way, these are extreme examples. I'm getting down to zero. There could be lots of things that make investment that where investment is damaging. So how do we eliminate investments being damaging? So first of all, how do investments hurt performance? So here's the by the way, these intuitions all correspond to steps in the general proof, but they'll give you an idea of how the whole thing works. Consider any packing algorithm and its threshold auction and some investor.
00:39:48.780 - 00:40:23.772, Speaker C: I want you to think about three barely profitable investments. It turns out the worst case is all about barely profitable investments. So I'm just going to talk about barely profitable investments. So I want you to consider three barely profitable investments that you might be able to make in a knapsack problem. So the first one is investing at cost. C raises ends value from below its threshold to barely above its threshold. So now to be profitable, he's going to pay a cost of C.
00:40:23.772 - 00:41:00.274, Speaker C: His value is barely above the threshold. So suppose it's Epsilon above the threshold. He's going to make a profit of epsilon ex post after the investment. So the cost better not be more than epsilon. Essentially, to be profitable, the cost has to be approximately zero. And if the cost is approximately zero, the performance ratio that we get from that problem with investment is exactly the same as the performance ratio that we would have had if we just endowed the guy with that value. It can't be that he's doing any damage.
00:41:00.274 - 00:41:31.236, Speaker C: Investment performance is never worse than the allocation performance. This creates another, essentially another allocation model. So it can't have a worst case that's worse than the allocation. Worst case. Okay, now suppose we make an investment. We have a guy who's already above the threshold, and he makes an investment that's just barely profitable. So it means it's going to raise his investment, his value, by 50 and it's going to cost him 49.8.
00:41:31.236 - 00:42:19.304, Speaker C: It's mixed and investment that he's going to pay the same price, but it's barely, I'm going to call this a confirming investment. And by confirming, I mean it doesn't have any effect on his allocation, just confirms the fact that he's packed. By monetization, he's going to remain packed. But if x reduces total welfare of the other packed bidders. So remember, we have a packing algorithm. It could be that when I increase my value, it causes Bernard to be unpacked. If that happens, well, then there's a negative externality and the performance is strictly worse than without investment.
00:42:19.304 - 00:43:33.386, Speaker C: And the third one is just suppose we invest at a cost of c to go from strictly below to strictly above. Well, we're going to decompose this case into these two cases. We're going to say whatever the externality is, it all arises from the part that happens after you increase your value here. And worst cases all involve fairly profitable investments. That's why we can, this is of interest to us. So what the theorem four says is that if we exclude those confirming negative externalities, those things where there's the possibility that I invest to increase my value when I'm already packed and have an externality on others, if that never happens, then the worst case investment performance is just the same as the worst case investment performance without, in the allocative problem, there's no additional losses resulting from the investment. Okay.
00:43:33.386 - 00:43:59.644, Speaker C: And then there's about uncertainty. This is just the theorem that the worst case is deterministic. Yeah, that's, that's not a hand, that's five minutes. Got it. Okay. And I'm gonna, and instead I'll talk to you about an f p task that's robust to investments. And here the idea is you do exactly what the BKV Fb Tas.
00:43:59.644 - 00:44:51.584, Speaker C: The only thing you change is the last step. At the last step, what they did was they chose the allocation. They took a look at the value of the problem, of the approximating problem, and noticed that, and took the highest value. And what we do is we take the allocation that results from the best problem, from each problem, and value it using the actual values. So they were using these approximate values we go through and say, okay, you decided that you're going to pack him and her. Okay, now we go back to the actual values and say, if we packed him and him and her, here's what the actual, and so we're not using the fact that we rounded her value down to zero when we select among these allocations. And that turns out to fix the whole problem.
00:44:51.584 - 00:45:25.104, Speaker C: The BKV, its monotone. This is the old theorem. Let's see. And when one invests, it increases its value sufficiently. The BKV algorithm will cause l to increase when it increases by enough. In an example that I won't have time to show you, it causes lots of values to be rounded down to zero. So that's a confirming negative externality, which reduces the net value to near zero.
00:45:25.104 - 00:45:54.328, Speaker C: So I'm going to use this last theorem, I'll state for you, and then conclude. An algorithm is said to be non bossy. This is a standard notion mechanism design. If we're all value profiles, v and v prime in every bit, or n. If you make a change that doesn't affect your own allocation, then it doesn't affect anybody's allocation. That's what non bossy means. And theorem for packing problems.
00:45:54.328 - 00:46:52.844, Speaker C: Every non bossy algorithm is x cone, and an algorithm that outputs the highest valued allocation from among other x cone algorithms is x cone. And so if we choose among those allocations, the one with the highest value, those were all optimizing, so they were all non bossy. And if we choose the one among them, that leads to the highest actual value instead of the highest estimated value, that is by the second condition is also x cone. And anyway, but the modified algorithm is x cone and it's an F ptas. And that's it. So there's the summary. Our numbered theorems investments are the same for all truthful mechanisms that use the same algorithm approximation algorithms that incentivize welfare increasing investments are constrained optimizers.
00:46:52.844 - 00:47:31.754, Speaker C: That has the BKV FB toss. There's zero approximations for the investment problem. X cone algorithms have the same worst case performance for both investment and allocation problems. Investment uncertainty doesn't change worst case performance. Every non bossy algorithm is x cone, and the max of x cone algorithms is x cone. There is an x cone FB toss for the knapsack problem and for several other problems as well. And that basically is, this is, do I have any time? I don't have any time, right? Am I out of time? 1 minute.
00:47:31.754 - 00:48:27.174, Speaker C: Okay, this is why we need to go farther, because this is a sort of a counterexample that's not covered by the, this is if you have randomized algorithms, the assumption that I have made that there's a threshold value is in general not true, and there's, anyway, I won't have time to go over it really, but there's, so the theory doesn't cover randomized algorithms as it currently exists. And that's a pretty significant defect that we're working on now, the unpacking problems, the product of interval is that. Thank you so much also. So let's go for break. And there we come.

00:00:01.000 - 00:00:13.434, Speaker A: Okay, so let's start. So the last formal talk of the afternoon is by Emery Yoko from Carnegie Mellon talking about weak versions of extended resolution.
00:00:15.134 - 00:00:54.830, Speaker B: Yeah, so, like the title suggests, these will be weak versions, whatever version means here, of extended resolution that are still. Yes, okay, so that are still going to be reasonably strong. And those are of a similar flavor to Jakob and Mills talks. They looked at systems that are on the higher end in terms of the strength. I will look at systems that are on the lower end in terms of strength, that are still stronger than resolution and will be able to do interesting things. So I will move a little bit quickly through the preliminaries, because most of this has already been covered. There's one disclaimer, though.
00:00:54.830 - 00:01:52.968, Speaker B: There will be a lot of acronyms in the talk for those proof systems. Try to ignore the acronyms, but I have to refer to those systems by some names, so they are unavoidable. Okay, so resolution is the system that we will build our systems on top of resolution, you know, refutes a propositional formula in CNF form by using this single rule to derive the empty clause. And in case that is confusing to some people, whenever I say proof, I actually will mean reputation throughout this talk. So, an example resolution proof of this formula, for instance, might be arranged in a tree like fashion, or it can be written down like a sequence for this talk. It will not make too much of a difference because I will be informal, but I want you to think of this like a configuration proof, where you expand or contract the set of the clauses. So you add stuff and then remove stuff from SCNF, actually, and look.
00:01:52.968 - 00:02:32.404, Speaker B: So the configuration version of this sequence like proof would be you start with the empty configuration and then you add this, you add this, you add this. At each step you have a CNF and you add these until finally adding the empty file. So yeah, an extended resolution is an extension of resolution, where at any step you can derive the three clauses expressing this, where p and q are arbitrary with roles and x is a numerator. I say p and q are arbitrary, but for reputation they're with outlets of general. T going to be the previously occurring literals in the formula. They can themselves be previously defined extension variables. So X is going to be new.
00:02:32.404 - 00:03:15.398, Speaker B: And yeah, in this talk I will talk, I'm going to consider the relative strengths of weakenings of external solution, again, whatever that means. And since I might run out of time, because I always do almost in talks, I want to show you the results. So those are the systems that we're going to be looking at. Okay, a lot of acronyms. So this minus indicates some weakening of the system. So without the minus, all of the systems that you hear, first of all, each node is a proof system built on top of resolution. And I've played them out a little suggestively here, but we'll come to that.
00:03:15.398 - 00:03:57.192, Speaker B: So the minus indicates a weakening without minus. All of these are equivalent to all of Jakob systems that you've seen. So, on top of resolution, this BC system is the weakest among all of those. And now think of having three axes here, along which you can generalize this BC system. Here you add something to the system. Here you add another thing to the system, which is orthogonal, in that they can be combined and added together to the system along this axis, you add something else again, which can be combined. So, for instance, the system that you see here can be thought of as a marriage of this one and this one.
00:03:57.328 - 00:03:57.912, Speaker C: Okay?
00:03:58.008 - 00:05:01.458, Speaker B: So, also, moving out from the origin, you generalize the system. So an arrow from a system to another means that one simulates the other. So you have simulations going in these directions and these directions that are trivial, like, this is trivial as well. And so this is trivial as well. And the point of this work is to look at the weakest generalizations of this BC virus system, which is a weak version of Xn resolution, and show that, okay, they're all incomparable, they're qualitatively different, so they're quantitatively different as well. And so what about the colors? The black arrows were already known, mostly due to chambers and Neil Tappan's work, the red arrows. So this distinction between red and green is for people who might have seen a previous version of this talk, the red arrows are the new results relative to the existing state of knowledge before the earlier talks that I gave on this, the green arrows are the new results since the last time that I gave this talk.
00:05:01.458 - 00:05:38.788, Speaker B: So I had, like, two open questions. Those are no longer open questions about the relationship between this system to these systems, and I needed a lower bond on the system to have those relationships. So, basically, the entire picture of those weakest generalizations is now resolved. And the point is less about those systems and more about the way you achieve those. They're all going to follow a simple recipe, almost like a cheap trick for proving the separations. And I repeatedly use it to get separations in all of those ways.
00:05:38.956 - 00:05:39.316, Speaker C: Okay.
00:05:39.340 - 00:05:55.356, Speaker B: And still to appreciate that you don't need to know about the details of those systems, although I will try to tell you a little bit about them. So, any questions at this point? Yes, this is the system for which.
00:05:55.380 - 00:05:57.164, Speaker D: We have no lower bounds so far.
00:05:57.204 - 00:05:57.784, Speaker C: So.
00:06:01.704 - 00:06:08.224, Speaker D: And so why care? That's all about this correspond, or at.
00:06:08.224 - 00:06:54.952, Speaker B: Least the reason I care about this, is different than Jakob might care about these systems. So for me, they correspond to being able to say in your proof the words without loss of generality assumed, blah blah blah, without needing to introduce numerically. So expand resolution can already do this kind of reasoning, but it can do much more as well. Let's say you want to study the weaker systems, which still support this kind of reasoning, but do not have to go all the way up to x nine resolution because you want to do proof complexity. You want to prove lower bounds or separations between them while still being strong enough in that. Again, this mostly follows from bastard Neil Sapensberg. You have upper bounds for all those hard tautology in this SPR system.
00:06:54.952 - 00:07:25.284, Speaker B: Some of those are not so interesting, but. So from this point on, and here and then out of the wall, the system starts to get interesting. Okay, so, for instance, you cannot exactly do this, but effectively in those systems, you can say, if I'm trying to prove the pigeonhole principle without also telling the pigeon n plus one is mapped to whole n. You don't literally say this, but you say something close to this, and then you derive this in those instances. Any questions?
00:07:25.324 - 00:07:28.624, Speaker C: No? Okay.
00:07:29.404 - 00:08:22.938, Speaker B: And like you saw in Yaakov's talk, this is based around the notion of redundancy, where you derive things that are not necessarily implied, but just preserve equisatis viability when you add them to the formula. So you have your formula gamma, which is a formula in the configuration, let's say, and you want to add a clause to it. And if it's redundant, you can add it if your goal is just to review the formula. And this notion of characterizing the redundancy is helpful for obtaining various parameterizations of those systems. Again, you saw this in Jakob's talk, but let me go over it again. So we say clause is redundant with respect to formula gamma, if only if there exists some partial assignment such that this holds. So Jakob gave a more technical explanation for this characterization.
00:08:22.938 - 00:08:58.380, Speaker B: I like to think about this a little bit more intuitively, in that if this holds, then you can say without loss of channel c. So why can you do this? Suppose you are writing some informal proof. You have some lines. At some point you say, without loss of channel to see now, you cannot just continue. You need to justify this step that you've made. And the way you justify it is you reduce the proof of not C to the rest of the proof that C assumed. Okay, so here what you do is, okay, I will not explicitly prove this.
00:08:58.380 - 00:09:32.698, Speaker B: But you're saying I will prove this from this point on. Well, you will prove this is unsatisfiable. If this is unsatisfiable, then any restriction of it is also unsatisfiable. But if the other case here actually implies this, then just by proving this, you also prove this is unsatisfiable. Okay, so this is the way, at least I like to think about this, corresponding to being able to say, without loss of generality, any questions for one. And of course, that previous motion involves implications, so it doesn't give you Kuchal proof systems.
00:09:32.786 - 00:09:33.454, Speaker C: Yes.
00:09:34.454 - 00:09:39.166, Speaker A: So when you introduce this new c, is it allowed to also introduce new variables?
00:09:39.230 - 00:09:41.454, Speaker B: Yes, so far I said nothing about.
00:09:41.494 - 00:09:53.238, Speaker D: What C can be. That's the way. So we will first generalize, extend resolution, and then we can back down to get systems between resolution and extend resolution. So yes, here the C could be.
00:09:53.286 - 00:09:56.914, Speaker B: Just one of the clauses corresponding to the extension.
00:09:58.894 - 00:10:08.602, Speaker D: So, emra, yes, I like that explanation a lot, but it's sort of, you're implicitly using also that this implication is something that is simple that we can verify, right?
00:10:08.698 - 00:10:09.374, Speaker B: Yes.
00:10:09.794 - 00:10:11.034, Speaker D: The way to think about it is.
00:10:11.074 - 00:10:12.442, Speaker B: Okay, let me first assume C and.
00:10:12.458 - 00:10:18.722, Speaker D: Then do the proof. And they say, oh, what if not C? Well, here's an easy reduction to what we did before, kind of.
00:10:18.778 - 00:10:19.042, Speaker C: Yes.
00:10:19.098 - 00:10:23.666, Speaker D: For that reduction to be easily verifiable, you would need to use a restriction.
00:10:23.690 - 00:10:27.494, Speaker B: Of the LKM, and that's where these.
00:10:27.834 - 00:10:32.898, Speaker D: Actual processes will come in. So we will use syntactic criteria that.
00:10:32.946 - 00:11:32.490, Speaker B: Will automatically justify that relationship holds. It may not be obvious how this definition actually corresponds to the thing that I've just shown, but soon I will use how this ties together with that. But let's parse the definition together. I will show you more definitions, but this is the only one that I want you to be able to follow, because it's the simplest one, and I think it's reasonable, although it's late. So a clause of this form, which includes a distinguished literal x or C prime is blocked for x with respect to a formula gamma. If for every clause that contains not x in the formula, if you had resolved this clause with all of those clauses, they all would be tautological. So this is also the motivation for why this was called blocked, because like, it's blocked with respect to taking resolve upon that literal.
00:11:32.490 - 00:11:40.134, Speaker B: So if you have such a clause, then adding it does not change the satisfiability status of the formula. Okay, so the definition is clear.
00:11:40.634 - 00:11:41.386, Speaker C: So, okay.
00:11:41.450 - 00:12:04.416, Speaker B: And by the way, tautological means sum which will occur both positively and negatively. Here's an example. So this is the formula. This is the pause. I claim it's blocked for x with respect to this formula. You just need to look at the causes where not x occurs. You have not x, not y.
00:12:04.416 - 00:12:53.534, Speaker B: But the result would be tautological because y and not y occur here. It would be topological, because z and not z occur here. You don't need to check anything. So, simple syntactic condition, which you can obviously check efficiently, even if I didn't tell you what this x is. And here's why these things are redundant. So I claim that, thinking back to the characterization that I've shown in the previous slide, if an assignment sets x to one, then it is a witness, so that I can knock the previous level. But why does it have to satisfy this? So just take some total assignment alpha that satisfies this side.
00:12:53.534 - 00:13:55.390, Speaker B: It means that that alpha satisfies this and that alpha falsifies this. Now, I claim that the right hand side here, this gamma and c is satisfied by the composition. And this composition is, again, as in Jakob's talk, apply tau first, apply alpha later, which is just alpha with alpha x split, because alpha was, since c includes x, was assigning x to zero. Now it's assigning x to one. Okay, now c is satisfied, but how about gamma? So there may be some clauses in gamma whose satisfaction depended on x being set to one. I claim those are also okay because there is some y in C prime, which is the part of the c without x, such that the negation of y is in B prime. But since alpha was falsifying c, then it still sets this y to zero, so nothing is broken.
00:13:55.390 - 00:14:24.094, Speaker B: Like you had a backup literal which already satisfies clauses of this form. So what you've done is you've exhibited that if there is a satisfying assignment to this, then that assignment satisfies this entire right hand side. And you can now generalize this in various ways. I'll show you two of those. Apologies for the name of this. I did not pick this. And this asterisk is for people who might have already seen this definition.
00:14:24.094 - 00:15:04.324, Speaker B: This is different than the definition that you're used to, but it gives a polynomial equal proof system. And this is simpler, so I like it better. And everything is the same in the definition except for this requirement. So you say here, this is tautological. Here you say this is subsumed by gamma. And subsumed means that there is some clause in gamma of which this is a b creek. And the intuitive way to think about this is these are saying that loss of trans, where the justifications in the case of block clauses is local because it cannot look too much in gamma, aside from the clauses that include not x.
00:15:04.324 - 00:15:39.140, Speaker B: But this here, you can look anywhere in gamma to find a reason why you're good. So this is one axis along which you can generalize. You can go up. So this is maybe a little bit more complicated notion of a set block clause here. Instead of this x being a literal, it's a set of literals. And again, you have this extra condition, which is kind of like this, generalizes this, and this extra condition, which is kind of like this. Okay, again, do not completely try to parse this.
00:15:39.140 - 00:16:27.232, Speaker B: Just look at the shapes to see that this is indeed a generalization, because if this was a single literal, this would be the same like set flop clause with a single literal, as l would be block, a block clause. Okay, so now we have proof systems using these notions built on top of resolution. Okay, so resolution and extension gives you extended resolution. BC is resolution plus blocked clause addition. BC minus is BC without numerables, which means that the newly derived clauses cannot include any new variables. So these are a weakening of external resolution in the sense that this is a generalization of external resolution. And this is how you restrict it back in a way that it still makes sense, and it doesn't just become resolution.
00:16:27.232 - 00:17:01.510, Speaker B: Something actually exponentially stronger than resolution, exponentially weaker than Xtan resolution. And there's this notion of deletion, which again came up in the previous talks. I do not want to get too much into it, but being able to remove and add clauses makes a difference to the strengths of those proof systems, because inferences in those systems are non monotone. So in general, if from a formula you can derive a clause, if that formula was larger, you could still derive that. Cause nothing is broken. It doesn't hold. Such a thing doesn't hold necessarily for those systems.
00:17:01.510 - 00:17:25.785, Speaker B: If you had extra things, your without loss of counties may no longer hold. So deletion makes a difference to those systems. And you have versions of this for rats, SVC, et cetera. And like I said, spR. I'm just naming it because it's a particularly strong one. SPR is like the marriage of SVC times rad addition, subset propagation redundant.
00:17:25.849 - 00:17:27.417, Speaker D: Oh, SVC, SBC.
00:17:27.465 - 00:17:27.705, Speaker B: Okay.
00:17:27.729 - 00:17:33.813, Speaker C: Yes, you mentioned that BC and BBC are generalizations.
00:17:36.113 - 00:17:38.257, Speaker B: BC is a generalization of expansion.
00:17:38.385 - 00:17:41.493, Speaker D: PR is a generalization of BC.
00:17:42.064 - 00:17:46.184, Speaker C: When you say generalization, what do you mean? Are they from a proof complexity?
00:17:46.224 - 00:17:49.864, Speaker D: I mean a strong proof is literally.
00:17:49.944 - 00:17:53.504, Speaker C: Correct as a PR or an extended.
00:17:53.544 - 00:18:06.088, Speaker D: Resolution proof, where you add the clauses, you add the three clauses that correspond to the extension. Is literally a BC valid in BC or similarly like Spc.
00:18:06.136 - 00:18:11.920, Speaker B: For instance, the generalization generalization of SPR and SPC proof is just valid as an SPR proof.
00:18:11.952 - 00:18:13.144, Speaker D: That's what I mean by generalization.
00:18:13.224 - 00:18:13.800, Speaker B: So trivial.
00:18:13.832 - 00:18:17.072, Speaker C: With their equivalent power.
00:18:17.248 - 00:18:24.424, Speaker D: They're equivalent to power. I mean, they can generalize something by then. It is a strict generalization in that.
00:18:24.544 - 00:18:27.488, Speaker B: NSPR proof is not necessarily valid as.
00:18:27.496 - 00:18:30.280, Speaker D: An SDC proof, but both are equivalent, polynomial equivalent.
00:18:30.312 - 00:18:31.204, Speaker B: Take standards.
00:18:33.324 - 00:18:39.108, Speaker D: We are looking at conversions without numericals, and this is like a key property.
00:18:39.196 - 00:19:29.064, Speaker B: Key weird property of those systems that I'm going to keep exploiting to get separations. Effectively, this is the technical term effective simulation, but with an asterisk, because it's not actually literally corresponding to the way it was defined. Effectively, BC minus without new variables simulates. Er, and I will not define what effectively polynomial simulations are, but just exhibit it with an example. So there are results of this form. Suppose that a formula gamma has an ER proof of some size, and consider this set of variables which are not shared with gamma. If you just attach this to gamma, then the new formula has a short BC minus proof.
00:19:29.064 - 00:19:41.152, Speaker B: Well, because those are new variables, but technically they're not. Now they're in the formula. Okay, so this is like a trick, but this trick is useful. For instance, in this way, you can very cheaply separate BC minus form results.
00:19:41.208 - 00:19:41.680, Speaker C: Yes.
00:19:41.792 - 00:19:50.204, Speaker A: So could you use this to say, let's resolve away a few variables, make up some room, and now let's, let's.
00:19:50.544 - 00:19:52.520, Speaker B: That'S how one of the simulations goes?
00:19:52.552 - 00:19:52.918, Speaker C: Actually.
00:19:53.016 - 00:19:55.854, Speaker B: Yes, between the versions.
00:19:57.394 - 00:19:58.974, Speaker D: Okay, let me show you.
00:20:02.474 - 00:20:11.234, Speaker B: So, consider just one extent, one use of the extension rule. Like I said, they are doing repetitions without these. The truths are not new. So you add these causes and sequences.
00:20:11.394 - 00:20:13.506, Speaker D: These are not quite corresponding to this.
00:20:13.530 - 00:20:31.076, Speaker B: Because you pick up this extra, not y, but for that reason, you include y as a cause. So then you just resolve those away, and you have the three clauses corresponding to this, and the rest is like the resolution steps are the same. So this is how that simulation works. Since BC minus does this, all of the systems do this.
00:20:31.260 - 00:20:34.144, Speaker C: Okay, and.
00:20:36.004 - 00:21:15.208, Speaker B: I will tweak this set that you're including with the formula to get easy separations between all of those systems. So I'm calling these guarded extension variables. The terminology is borrowed from the regular resolution versus resolution paper where they're actually guarding clauses. So it's a little different, but it's roughly the same idea. So yeah, decided to call them guarded extension variables. So we will start with a formula with a short, er, proof and keep in mind this, which makes this formula easy for BC. We will now to separate two systems, p and q, which generalize this BC minus.
00:21:15.208 - 00:21:52.104, Speaker B: We will incorporate extension variables in ways that are useful to only one of the two systems. And so the idea is I will guard, somehow guard the variables, but by guard I mean they will not be included plainly like this. I will have some gadget like things, though they're not exactly gadgets, but like small formulas in which these appear, but not as openly as this. And then one of the systems will be able to use these variables to simulate the, er, proof as before, although a little in a slightly more complicated manner. And the other one, although these are just there, we'll be unable to achieve any speed up.
00:21:52.224 - 00:21:52.964, Speaker C: Okay.
00:21:54.824 - 00:22:33.758, Speaker B: And how you can achieve this kind of thing is not obvious probably, but it is just like a completely trivial example. So consider this formula and suppose you're trying to add somewhere some clause that's blocked for x. So we remember the definition of block clauses, which says that formula has to, that clause has to include clash against this clause and this clause when you resolve it upon X. But well, the only thing to clash against is y here and not y here. Then that clause has to include both y and not y. So that's a useless clause.
00:22:33.846 - 00:22:34.286, Speaker C: Okay.
00:22:34.350 - 00:23:18.050, Speaker B: So in this way you can impose restrictions on the set of clauses that are derivable within these proof systems. I had a example lower bound in the simplest case to show that it's that easy if you're used to those systems. I'll just show you how short it is. Okay. There are like some lemmas here, some steps are lemmas, but this kind of a formula, which is basically a generalization of the example that I've just shown you, is no easier than the original formula gamma for this vc minus system. And proving a lower bond is vc minus is really weak. So that's why it's so short.
00:23:18.050 - 00:24:10.552, Speaker B: But still, this is quite easy compared to, for a lower bond at least. And actually this kind of formula ends up being easy for ret minus. So this is, for instance, the construction that we can use to separate ret minus and bc minus. Why it's easy I cannot get into right now, but I will show you the constructions that I used to separate all pairs of those systems. Just, I will flash them, and then I have a few minutes, and I will move to discussion. And you actually have a real economy of constructions in that using a single construction, you prove that two systems do not simulate this system. And one thing that I want to emphasize about this approach is, so this formula, this new formula with the new variables becomes easy for rat minus, regardless of where the gamma is.
00:24:10.552 - 00:24:43.736, Speaker B: So you take any formula that separates rat minus from er, minus from er, and you plug it here and you get your separation. Then you only need to think about how to construct it. There's a different kind of construction where you have, like, multiples. This just says X is equivalent to Y. I. Well, rats, for some reason, is unable to make any use of the x's and y's here. But this formula ends up being easy for both of the other systems for different reasons.
00:24:43.736 - 00:25:29.272, Speaker B: And SVC is possibly the most interesting system among the three. So to break it, you have to work a little bit more, and then you have this kind of construction where x is supposed to be the new variables that are to be used. And GEr can just work through all of this and use this x to derive the extension clauses. SBC looks at this and says, I cannot do anything unless you give me exponential sizes. So using these kinds of, like, cheap tricks, you can separate all of those. And, yeah, I have a few open questions. So, SPR minus, going back to this picture, this is like the frontier in terms of lower bonds against all systems, because this is known to be not polynomially bounded.
00:25:29.272 - 00:26:01.010, Speaker B: So is this. So is this. And so is this as part of this work. And these are probably really hard to grow lower bounds against. So that leaves SPR. So SPR minus is the system that basanthappen formulated most of their upper bonds, and some of those upper bonds hold in SPC minus. I don't know if Antonia is here, but Antonia was talking about differences in encoding between persistence and, like, the same topology being easy and difficult on the different encodings.
00:26:01.010 - 00:26:49.770, Speaker B: For instance, here for this system, both the pigeonhole principle and the bit pigeonhole principle are easy. For this system, pigeonhole principle is easy, but bit pigeonhole principle is hard. And here, if you understand the definition, like, once you understand the definitions of those systems, it literally, it makes a lot of sense that this is the case, because this system is unaware in its justifications of the entire formula. But big pigeonhole principle, in a sense, is meaningful more globally, right? So subsets of it are a little less meaningless, are a little more meaningless than the unity. So yeah, this is like frontier in terms of lower bounds. And we want separations using natural principles, as everyone said. And the third is about connecting the study of those systems to the rest of proof complexity.
00:26:49.770 - 00:27:36.650, Speaker B: So right now those are like niche and kind of new systems, so they're disconnected from the rest of proof complexity. What we know, for instance, is any system that's closed under restrictions does not simulate even the weaker system unless that system also simulates xtan. So that's known. But I more curious about the converse kind of results in that. So this is standing for the strongest versions of those systems without new variables. Is there any subsystem of regatta strictly about resolution that you can simulate in those systems? Anything, or are they completely incomparable with the rest of the processes that are commonly studied? And I also, I like this idea, although it's a hack. I would like to see other uses of the high level idea.
00:27:36.650 - 00:27:57.754, Speaker B: I have one idea where this can be used, and if you've heard of it, it's linear resolution versus resolution, because the linear resolution has some weird properties that are similar to the systems that I talked about. So potentially it could be applied to separate those, which is, I wouldn't say a long standing open problem, but an old open problem.
00:28:07.214 - 00:28:07.954, Speaker A: Question.
00:28:08.574 - 00:28:16.254, Speaker C: Yes, effective p simulations, which of those incomparably.
00:28:19.674 - 00:28:23.330, Speaker D: Oh, effective in the ordeal difference.
00:28:23.402 - 00:28:25.162, Speaker B: From the version that I doesn't have.
00:28:25.178 - 00:28:52.290, Speaker D: To have a polynomial time. So in the original effective simulation, it has very important time in this case since you don't know how many extension values you put. But this doesn't run polynomial time. So I actually not. So these probably do not stimulate, er in the sense of the correct definition of effective simulations. Oh, but you asked about separations across.
00:28:52.362 - 00:29:00.694, Speaker C: Those systems because lots of flavors of resolution collapse together under.
00:29:02.434 - 00:29:23.954, Speaker D: Based on some of the existing results, they may end up collapsing because there are simulations where you allow just one extra variable and then you can see my thing, but that uses deletion. So I'm not completely sure, but I would guess that they should probably questions.
00:29:25.294 - 00:29:26.870, Speaker C: Just, just a quick one.
00:29:26.902 - 00:29:30.606, Speaker A: So res two. So are there separations, can you prove that?
00:29:30.630 - 00:29:48.876, Speaker D: Res two can't be simulated by some of these systems? So the only non lower bonds are for. So pigeonhole principle is hard here, but.
00:29:48.900 - 00:29:50.184, Speaker C: It'S also hard there.
00:29:51.524 - 00:29:55.484, Speaker D: Big pigeonhole principle is hard here, but it's also hard.
00:29:55.524 - 00:30:03.256, Speaker E: There's two means, fossils with terms of size two.
00:30:03.320 - 00:30:03.924, Speaker B: Yes.
00:30:07.104 - 00:30:14.728, Speaker D: So an easy formula for rest two is the click coloring with very big gap between the click coloring is easy.
00:30:14.776 - 00:30:18.336, Speaker B: Here and here, SDC lines.
00:30:18.400 - 00:30:24.672, Speaker D: So click color is here and here. Because you can say without loss of penalty, the elements, the first, 2nd, 3rd.
00:30:24.768 - 00:30:27.584, Speaker B: Etcetera, element of the sleep is colored. One, two, three.
00:30:27.664 - 00:30:55.814, Speaker D: So that is expressible here and here. If you would like to write a solver, a practical solver, which one of this language do you use? I mean, to have something that is efficient with strong heuristics. And there are some solvers that.
00:31:00.594 - 00:31:01.050, Speaker C: Try.
00:31:01.122 - 00:31:06.050, Speaker D: To do this, but the difficulty is we need to. Computer business. Yeah.
00:31:06.122 - 00:31:07.954, Speaker B: Even if you claim the formula, it's.
00:31:07.994 - 00:31:09.026, Speaker D: Only working on kitchen.
00:31:09.050 - 00:31:09.738, Speaker C: All right.
00:31:09.906 - 00:31:11.626, Speaker D: Yes, but this is also good.
00:31:11.690 - 00:31:13.554, Speaker B: So I like this as well.
00:31:13.674 - 00:31:14.178, Speaker C: This one.
00:31:14.226 - 00:31:14.386, Speaker B: Yeah.
00:31:14.410 - 00:31:26.654, Speaker E: So you're talking about the satisfaction driven clustering. They use some version of SVC or SBC minus, I guess, in their thing. I think it's a version of SPC minus.
00:31:27.424 - 00:31:28.384, Speaker D: I may make.
00:31:28.504 - 00:31:36.064, Speaker B: This is here. As far as I know, that only works in really specific cases. Right.
00:31:36.104 - 00:31:37.084, Speaker D: It's not like.
00:31:44.384 - 00:31:49.844, Speaker E: But it worked rather well for certain types of digital principle, let's say that way.
00:31:52.964 - 00:31:57.104, Speaker D: But here it's like a better guided circuit. You don't have to look for a newer.
00:31:58.244 - 00:32:10.344, Speaker C: I can say that we have tried to build an SDCL solver and it works well for certain kinds of problems, but not other kind of limits.
00:32:10.884 - 00:32:12.012, Speaker D: And one of the, one of the.
00:32:12.028 - 00:32:14.584, Speaker C: Issues that we face there has to do with the branching.
00:32:17.524 - 00:32:35.254, Speaker E: So if you. I mean, the source code for this SDCL solvers online, and I had a couple undergraduate students ran it last quarter and they were able to get the same results using their software, of course. But when they used randomly permuted versions of visual principle, it didn't work.
00:32:37.794 - 00:32:38.642, Speaker B: Variables, yes.
00:32:38.698 - 00:32:39.706, Speaker E: They were permuting the variables.
00:32:39.730 - 00:32:40.294, Speaker C: Yeah.
00:32:40.954 - 00:32:45.774, Speaker E: But we didn't explore what's going on. So I don't know what the fix is or not.
00:32:46.074 - 00:32:48.210, Speaker C: So that particular song we were talking.
00:32:48.242 - 00:32:52.764, Speaker E: About, the cat, cow, cervical.
00:32:52.884 - 00:33:01.116, Speaker C: Yeah. They use a very particular branching heuristic that's kind of tuned for pigeonology. Okay.
00:33:01.180 - 00:33:16.834, Speaker E: Yeah, we didn't get into the innards of that. So I think there's. But it's interesting, they're able to find more or less the optimal visual principle, refutations of size around n cubed up to over 50 pigeons, which is a pretty amazing number.
00:33:17.934 - 00:33:22.274, Speaker D: And on that note, one more thing. So the system here that's just outside.
00:33:23.294 - 00:33:26.118, Speaker B: That'S here called PR.
00:33:26.286 - 00:33:43.424, Speaker D: And actually a short proof of Russell and pollas as example from the first day, which has hard. That's also, let's thank Emory again.
00:33:49.164 - 00:33:49.924, Speaker A: And don't.

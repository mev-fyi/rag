00:00:00.720 - 00:01:03.150, Speaker A: And it gives me great pleasure to welcome you all to the Simons Institute, as well as this week's workshop. For those who may not know, the Simons Institute is the leading venue for collaborative research in TCS theoretical computer science, and it was established in 2012 with a very generous grant from the Simons foundation, which continues to support us significantly. And the institute brings together the world's leading researchers in the theory of computing and related fields, as well as the next generation of outstanding young scholars. And we are now in the second decade of programs at the institute. They start at 2013. So this is the 11th year of programs, and we're really proud of the achievements of the wide ranging programs which have pushed the frontiers of tcs in so many directions, making progress on longstanding challenges of the field, as well as opening up new directions of inquiry and common points with other fields. So each semester we have two programs that attract several long term visitors, junior and senior to Berkeley, and these programs also include multiple workshops that convene more short term visitors on a weekly basis.
00:01:03.150 - 00:01:31.736, Speaker A: And so this is one of the first workshops for the logic and algorithms program. So I would like you to welcome to this workshop, which is titled fine Grained Complexity Logic and Query evaluation. And I would like to thank the organizers for their hard work in putting together a program for this workshop. And they are hang. No, I think they're all here. Or yeah, hung is here. Kirk Prus, Atri Rudra, and Virginia Williams.
00:01:31.736 - 00:02:08.958, Speaker A: So thank you. Let's give them a round of applause and a few logistics for the coming week before I hand it over to the scientific organizers. So food is provided before the first talk, and at the breaks and for lunch, you're on your own. But there are many options close by and you have a long lunch break, so it should be no problem. And we please ask that you leave any food and drinks, including coffee, outside the auditorium. It really helps us keep the place, you know, clean as it is, as you can see. And if you want to store things when you go for lunch or outside, there are lockers in the back other side of the building where you can store your things.
00:02:08.958 - 00:02:36.510, Speaker A: And as always, all the talks, everything is live streamed. And you can also, you know, the videos will be available on the website. And we have our videographer, Omid, who will help us with help with any speakers, any AV issues. And just another thing about publicity, if any of you are active on Twitter and you're sort of live tweeting or I guess live Xing, I should say the workshop, please Tagimons Institute, and then we will be sure to repost.
00:02:36.542 - 00:02:38.742, Speaker B: It will be good publicity for the.
00:02:38.758 - 00:03:05.414, Speaker A: Workshop and people know what's going on. And, and last but not least, I'd like to give a special round of thanks for events coordinators Ashley Hassan and Freda Orr for all the hard work managing all the logistics, so that the workshops run smoothly, as they always do, and they will also be on hand all week to answer any questions you might have. So with that, I'll hand things over to the organizers, in particular Hank, who will say a few words about the workshops. Thank you and have a great week.
00:03:09.754 - 00:03:53.824, Speaker C: Thank you, Venkat. So, welcome to the second workshop of the logic and algorithms program. So, from the first workshop and the past month or so until now, I hope you have those of you who have followed the talks and also discussions, you have realized that the fine line complexity community and the database community have been solving really the same set of problems. And the only missing link is really a query language to express the problems. And the query language is logic. So this workshop is fine, and complexity logic and query evaluation. And you see that logic is the link that is connecting the two communities.
00:03:53.824 - 00:04:29.422, Speaker C: And because we are solving the same set of problems, it would be really nice for us to talk to each other. And the goal of this workshop is to create themes under which the two communities can further, you know, express the problems and the techniques that we use to solve those problems. And the workshop is divided into five themes, five days. So, first day will be non recursive query evaluation. The second day will be an MPC. I might be messing up the order of those days a little bit. On Wednesday, that will be.
00:04:29.422 - 00:05:03.740, Speaker C: Oh, the second day is on relational algorithm. Wednesday they'll be on massively parallel computation model. On Thursday, that will be on recursive query evaluation. And the last day it'll be in incremental view maintenance, also known as dynamic algorithms. You will see that there's really the same collection of problems that we are solving in different communities. And because of that, we would really like people to talk to each other, like across the aisle, if you will. And so we are experimenting with.
00:05:03.740 - 00:05:36.434, Speaker C: With a format in which in every day, there will be one talk from each of the communities. And then in the afternoon, we create opportunities for people to discuss the ideas and the problems that way. And so I'm going to give the mic to Atri, who is running the, you know, the first day in Virginia, the first theme, and then he will explain a little more on this experimentation, and we very much welcome more ideas on how to get people to talk to each other more so that we.
00:05:41.014 - 00:05:43.914, Speaker D: All right, thanks. Hello, everyone.
00:05:45.934 - 00:05:46.286, Speaker B: Sorry.
00:05:46.310 - 00:06:27.410, Speaker D: I'm just going to ad lib for a little bit so things might not come in the most polished way that it should. So as hung mentioned, the idea, this theme for today is non recursive database queries. How many of you actually understand what that means? I'm just curious. All right. How many of you would consider more of yourself, more as a database theory person? I think the intersection is almost completely different. Okay, good. So as hung mentioned, the idea for today, and indeed the entire workshop is folks who would primarily consider themselves to be database researchers.
00:06:27.410 - 00:07:18.714, Speaker D: Talk to people who would consider them, such as primary algorithms researchers. Again, the demarcations are not strict, of course. So the plan for today is we're going to have two talks. We're going to have Nofur Kramer give a two part talk. First, uh, on, um, uh, non recursive, like, um, um, like going beyond what you all might, if you were in the bootcamp, have seen about, uh, you know, solving non recursive database queries. Um, and then we'll have Andrea Lincoln talk about for 45 minutes on fine grained complexity. The experimentation that Hong talked about in the afternoon is really an experiment in the sense that we made it up, made it up half an hour ago.
00:07:18.714 - 00:07:56.152, Speaker D: But we would really like your help. But the main goal of that, the afternoon sessions after lunch is so that we can really have cross collaborations and people talking to each other. So the way we're going to start off at two is thanks to Nofur for agreeing to that as well. She's going to start off us with a very concrete open problem that's open, focused work on. We will figure out some groups, have you all break up into groups and then you can kind of go outside, upstairs, kind of talk about it. Then after the break at 330 we'll kind of get back together and see how it goes. So we really ask for your patience and health.
00:07:56.152 - 00:08:09.134, Speaker D: As I said, we are excited about this, but we haven't done anything like this ever. At least I haven't. So we will see how things go. So we definitely love your feedback as we go. Are there any questions on.
00:08:09.294 - 00:08:11.718, Speaker B: I think it's important people have to get back here.
00:08:11.846 - 00:08:33.726, Speaker D: Yes. So two things. A, please be back here at two. We definitely need your help to kind of, if you're not here, then not going to work. And do please also come back at 330, even though I think the schedule says quote unquote optional, please do come back and at least give us feedback on how your group's discussion went so that if need be, we can. Okay.
00:08:33.870 - 00:08:49.462, Speaker B: The model you described is really the model that the American Institute of Mathematics adopts. And they have exactly this formal, very few talks and groups, but they usually pause a list of problems so that people can ponder and consider them. Is it something that.
00:08:49.518 - 00:08:49.854, Speaker E: Yes.
00:08:49.934 - 00:09:03.966, Speaker D: So both Andrea and Nofur will talk about open questions in the talk. So in the morning today they'll have it. But also at two, when we start that session, we going to start off with a concrete questions for folks, too.
00:09:04.030 - 00:09:07.794, Speaker B: I was asking if you can pause for tomorrow, the day after tomorrow.
00:09:09.414 - 00:09:35.394, Speaker D: Okay, thank you for the suggestion. We will talk about it and see if we can get that done. I don't see Paris. We will try. I think that's a good idea. I think one of the things we wanted to do, at least for today, especially for people who are not familiar, today is the day to kind of, you know, get to know kind of the various areas. But I think going forward that might be more feasible.
00:09:35.474 - 00:09:37.514, Speaker B: I'm not talking about an exhaustive list.
00:09:37.674 - 00:09:40.774, Speaker D: I understand. I understand. Yeah, yeah.
00:09:44.794 - 00:09:53.002, Speaker F: The only workshop with this format I've been to every evening there was a get together and every group said what they've done. Are you planning?
00:09:53.098 - 00:10:14.564, Speaker D: Yeah. So the 330, that's what I said. The schedule says optional, so I'm requesting everyone not to take it as optional and come back and discuss what happened from two to three at 330. Yes. Thank you. Cool. Any other questions? Sorry, I'm teaching two undergrad courses this semester, so I'm very much like, are there any questions? We're all good.
00:10:14.564 - 00:10:54.260, Speaker D: Okay. 03:30 p.m. When you report back with what you grouped. All right, so I guess without further ado, let's start off with our first talk from Nofur. Carmeli Nofur is affiliated with India and at Montpellier, done a bunch of great work on kind of solving database queries. Her talk is going to be answering questions. So typically, at least my background is algorithms to kind of think of like, it's an offline problem.
00:10:54.260 - 00:11:09.554, Speaker D: Someone gives you a database query or graph problem, you solve it and then a certain amount of time. But in databases, you have additional requirements, like you want, like answers happening in an online fashion and so on and so forth. But thank you.
00:11:17.014 - 00:11:48.564, Speaker E: I have my own mic, right. Yeah, everyone hears me, but great. So I'm really happy to be here. I think this is amazing because as a person who tries to work on database problems, but in terms of fine grained complexity over the database problems. I really feel like from the discussions that I had with fine grained complexity, people that really have like nice insights about how these things can be solved. So I think this is a huge opportunity. What's happening? I'm very happy to be here.
00:11:48.564 - 00:12:33.494, Speaker E: So the point of the talk is to understand query evaluation and how or when we can do this with what we would call ideal time guarantees. And I'll try to focus. So the idea would be that if you want to work on these things later, you'll have the basis to do that. So I'll try to not just tell you what we know, but explain a bit how these things work on examples and point out the open problems as well. It's a long talk, scheduled to be 40 minutes, five minutes break and then 40 minutes. But I guess we will have ten minutes less than that. But still feel free to stop me so that it's not just me standing here for very long.
00:12:33.494 - 00:13:06.404, Speaker E: And let's make it a discussion. Stop me with questions, remarks, whatever you want, as many times as you want. Okay? All good? Yeah. So this is the plan of the talk. We're going to start by talking about the task of enumerating all answers to a database query. We'll start with just considering the most basic form of queries, which is joints. And then we'll slowly increase the expressivity until we reach unions of conjunctive queries.
00:13:06.404 - 00:13:44.424, Speaker E: And then if I have time, I'll also talk about other tasks that, that are not just outputting all of the answers to the query. So let's start with join queries. Let's make sure we all understand what a join queries. So this is an example for a database that describes a lab and the problems in the lab. So we have one relation, which is a table that describes the problems in certain rooms. We have a table that describes who are the people in each office, and a table that describes what are the contexts contact information for. And let's say we want to send a bunch of emails to all of the people who have problems in their offices.
00:13:44.424 - 00:14:40.424, Speaker E: So what we need to do here is to join the three relations. One way we could write this query is what you see here. And if you want to understand what this query means in set notation, just because it's the first slide, this is what it means. Okay, so what happens? Is that clear for everyone? What happens if we want to answer queries of this form? First of all, we should be aware that there could be many answers. When I say many, I mean more than linear. So if we're joining two relations, and it so happens that all of the tuples agree on the join variables, then we get that the size of the output is the size of the first relation times the size of the second relation, so not linear. If we have more relations, it can be even more than second thing we should be aware of is that if we're not careful, we can have a lot of intermediate answers.
00:14:40.424 - 00:15:31.044, Speaker E: So in this case, we're trying to join these three relations. At the end of the day, we only have one answer. But if we're first joining r and s and then joining the result with c, then we get that the number of intermediate answers is disproportionate both to the size of the input and to the size of the output, meaning the computation would necessarily take a long time, because it goes through all of these intermediate answers. So this is something we want to avoid. Okay, now one thing we can notice here is that we have what we call dangling tuples. These are tuples that are part of the input, but for this specific query, they don't affect the output. If we had a way of magically identifying them and removing them, it would make in this case the list of intermediate answers to be smaller and save us time.
00:15:31.044 - 00:16:12.388, Speaker E: So let's go back to the example we saw. One thing we can do is we go over their relations one pair at a time and filter them. So we go over the office relation, we remove information about offices that don't have problems. We go over the contact relation, remove information about the people who are not relevant for problems in offices. We go back to the office, remove the information about people whose contacts we don't have, and continue like this. Remove information about rooms that are not an office. So for this query, this works well, right? We managed to remove on the ending tuples.
00:16:12.388 - 00:16:48.274, Speaker E: We just need to join what's left with. We can do that efficiently. What happens with other queries? This is another example for a query. This one describes university. We have a list of which students are registered to which exams. We have a table that describes which exams are given by which professors, and a table that describes conflicts of interests between students. And we want to know whether we have a problematic case where students and a professor that have a conflict of interest are involved in the same exam.
00:16:48.274 - 00:17:23.073, Speaker E: Now, over this input, the answers would be nothing, right? There are no answers. For example, Anna only takes algorithms. Algorithm is given by Pierre. Anna and Pierre don't have conflict of interest, and so on. This is supposed to be Anna, the same, but if we try to remove the dangling tuples by comparing pairwise relations. We see that we don't succeed, right. We cannot filter one of the relations according to another relation.
00:17:23.073 - 00:18:06.814, Speaker E: And the way you can see this visually is you can draw this graph that corresponds to the query, and you can draw this graph that corresponds to the database. And basically what this join query tells you is it asks you to find the query pattern in the database graph. So it asks you to find all homomorphisms from this graph to that graph. And the way the algorithm worked before is it tells you okay, if you see some entity that's only connected to yellow but not connected to blue, you know it won't be useful. So you can remove that. But here you don't have this. Everything is connected to all colors, but the database gives you a six cycle, while the query gives you a three cycle.
00:18:06.814 - 00:18:56.058, Speaker E: So it's hard to identify that you don't have this query over there. Is that clear, everyone? Okay, so this one's supposed to be some intuition on specific examples, but let's see what happens when we want to make that more general. First of all, we'll be talking in data complexity, and this means that we abstract away the size of the query. So when we say linear time, we mean linear in the size of the database. We should keep in mind that the number of answers can be polynomial in the size of the input database. And in a way, what are the minimal requirements we can expect to achieve. So we need at least linear time in order to read the input, and then to know whether there are any answers or not.
00:18:56.058 - 00:19:45.512, Speaker E: And then we need at least constant time per answer in order to print all of the output. We'll be using the RAM model for computation. And later in the talk we'll also allow logarithmic factors on top of what I said now, but I'll tell you when this happens. So one thing we could do is what we call worst case optimal algorithms. And this means that the time that the algorithm takes is linear in the size of the input plus the worst case output. So for example, if we want to find triangles in a graph with m edges, the worst case, or the highest number of triangles such a graph can have is m to the 1.5. So this algorithm is allowed to take m to the 1.5
00:19:45.512 - 00:20:38.064, Speaker E: time even if there are no triangles in the input graph. This is what we know as the aging bound, and they are known worst case optimal algorithms that we can apply for all join queries. What if we want to do better than that? Right? So we don't want linear time in the worst case output, but we want linear time in the specific output we have. So this would be, in a way, instance, optimal total time, and it's better over most inputs. And then something that would be even nicer than that is if we can have this sort of regular delay between answers. So we would have this guarantee that we will get the first answer only after linear time in the input, and then we'll get a constant stream of answers with constant delay. So anyway, this is the best we can hope for if we want to print all of the answers to the question.
00:20:38.064 - 00:21:31.074, Speaker E: Okay, the focus on our talk will be this enumeration. All of our algorithms would be this, which means that they also give us instance, optimal linear time. Most of the hardness results, I will just talk in terms of enumeration, but most of the hardness results, I tell you, also apply for just instance of just for the total time. So this is also really relevant for everything I say in this talk, even if I won't explicitly mention that. The long term goal would be we're given a query, a user wants to compute this query. What is the most efficient algorithm we can have for that specific query? An intermediate question would be, we're given a query, let's consider some time complexity. Can we answer this query with this time guarantees? And then we have two ways of answering this question.
00:21:31.074 - 00:22:23.192, Speaker E: Either yes, and then we give an algorithm, or no, and then we want to prove that we cannot do that. And in the raw model, we don't have a way of just proving things unconditionally. So we're going to use conditional lower bounds. And this is in a way how we're really big users of fine grain complexity work, because we're going in through papers and seeing what kind of hypothesis we can use to prove that our things work. That would make sense, stuff like that. Okay, so what makes the distinction between the yes and no in the case of enumerating the answers to join queries? Well, maybe not surprisingly, after the visualization we saw before, the key is acyclicity. So this corresponds to the notion of alpha acyclicity in hypergraphs.
00:22:23.192 - 00:22:42.356, Speaker E: But let me give you one of the definitions. A query is a cyclic if it has a joint tree. So a joint tree is a graph that describes the query where there is a node for every atom of the query. Maybe I'll stand here, I don't know. You'll see me better. There's a node for every atom of the query. This graph is a tree.
00:22:42.356 - 00:23:24.144, Speaker E: And if we consider every variable separately, look only at the nodes that contain this variable, then these nodes are connected in the graph. So this query is a cyclical. But not all queries are cyclical. This query, for example, is cyclic because if we want to make it a tree, we need two out of the three possible edges. No matter which edge we choose to leave out, we will have some variable that's not connected. Okay, so the dichotomy tells us if the query is a cyclic, then we have an algorithm with linear preprocessing and constant delay. If the query is cyclic, then such an algorithm doesn't exist.
00:23:24.144 - 00:23:51.318, Speaker E: Assuming two things that I will explain in more details later. So one thing is that it only applies to queries without self joins. And the other thing is, of course we have conditional lower bounds, so we need some hypotheses for that to work. But let's start by explaining the positive side. So this is very example to, very similar to the example you saw before. Let's say we want to join these relations. First thing we do, we take a joint tree and we set some roots arbitrarily.
00:23:51.318 - 00:23:58.084, Speaker E: I don't care which route you take. Then there is the process that removes dangling tuples. So we go over the tree twice.
00:23:58.164 - 00:24:01.584, Speaker B: Yes, you say one sentence about how you find the joint tree.
00:24:02.484 - 00:24:16.676, Speaker E: Well, in data complexity it's magic, but it shouldn't be problematic. So for example, you can start by taking a leaf, which is a node that all of the variables that are shared with other variables are shared with only one node.
00:24:16.780 - 00:24:18.624, Speaker F: Then make it a leaf connected to that.
00:24:23.574 - 00:24:54.144, Speaker E: Okay, so we remove dangling tuples. We go over the tree in two paths. First we start from two passes. Yeah, first we start from the leaves, we go to the root, and we filter every parent according to the chain child. And then we also go top to the bottom. So for example here we can start like this. Then we filter three reals according to four reals.
00:24:54.144 - 00:25:14.206, Speaker E: So we see we have no w three here. So this would never be used. And we continue like this. We filter one according to three reals. Since we already removed this tuple, we know that z three will never be used. So we can remove also that we continue like this. And then we go down and filter the children according to the parent.
00:25:14.206 - 00:25:44.394, Speaker E: When this process ends, we are guaranteed that we have no dangling topples left. And all we need to do is join, which we can do efficiently, for example by just having nested for loops. So we start by going all of the tuples we have left in the roots and then we go over all of the tuples in a child that match what we have left, what we took in the roots. We can do that efficiently with the appropriate data structures and continue it. Any questions about the algorithm?
00:25:46.294 - 00:25:51.674, Speaker F: Yes, can you give me like a one sentence intuition about why two passes is enough?
00:25:53.934 - 00:26:27.444, Speaker E: So the key here is that this is a joint tree and then this is the key. This I know, like you won't have any surprises, right? You won't start by knowing that you need to filter something and then need to filter something and then something changed and then you need to filter according to that. Again.
00:26:29.344 - 00:27:03.164, Speaker B: There is a simple observation that is based on considering a sub query that is defined by one node of the tree. When you do the if two root semi joint reduction, then you guarantee that each relation will be reduced with respect to just the sub query, but not yet reduced with respect to the rest of the query. And when you do the top down symmetry reduction, then you find a derivative, semi geometry, you said with respect to the top and down semi journeys.
00:27:04.464 - 00:27:05.976, Speaker F: Thanks, sorry for.
00:27:06.160 - 00:27:43.230, Speaker E: No, no questions are good. I don't want to just talk to myself. Any more questions? Okay, that was the positive side. Now for the negative side. So let me mention the one way of proving that that was the original way that was known for a while now. So this is the query that we saw before that we said it's a bit harder and maybe not surprisingly. So, first of all, let's rename things again to make it easier to work with.
00:27:43.230 - 00:28:27.696, Speaker E: Maybe not surprisingly, we can prove that this query is hard if we assume the triangle finding in a graph is hard. So the assumption is that we cannot detect triangles in a graph in linear time. And let's say we have a graph, we want to know whether it contains triangles. Then we encode the religions in the graphs, in the edges of the graph in the three relations. And then by definition this query just finds the triangles in the graph. So if we find the first answer in linear time, we determine that there is a triangle in linear time, which is something we assume we cannot do, right? So this was for that particular query. We want to say something similar for any cyclic query.
00:28:27.696 - 00:29:08.354, Speaker E: And we can do this with a generalization of this hypothesis. So the generalization is about finding hyper clicks. So here we mean k vertices such that each k minus one of them forms an edge. So when k equals three it's a triangle. But we can also assume that for larger k. And the assumption is that deciding whether such a thing exists in a hypergraph cannot be done in linear time. And basically what we know is that if a hypergraph is cyclic, then it necessarily contains such a thing as an induced subgraph.
00:29:08.354 - 00:29:30.344, Speaker E: So either exactly such a thing or a triangle. And then we can use a cycle and then we can use a triangle. We can apply a similar reduction in any cyclic query, basically. Okay, so, yes.
00:29:32.084 - 00:29:46.532, Speaker D: Hopefully this question was commenting useful to others. So when you're talking about cyclic or acyclic, if all your relations have only two attributes, this is just saying, you look at the graph corresponding to query and it's either a forest or not.
00:29:46.708 - 00:29:49.036, Speaker B: But for hypergraphs it's more complicated.
00:29:49.140 - 00:29:50.464, Speaker E: Right, right.
00:29:52.524 - 00:30:02.364, Speaker B: I mean, the characterization is that when you go to hypergraphs, it is a cyclic event only if the primal graph is not conformal or not chordal.
00:30:02.444 - 00:30:02.900, Speaker E: Right.
00:30:03.012 - 00:30:05.012, Speaker B: These were the two cases, the special cases.
00:30:05.068 - 00:30:05.876, Speaker E: Exactly.
00:30:06.060 - 00:30:08.530, Speaker B: The big cycles are the chordal ones.
00:30:08.612 - 00:30:08.966, Speaker E: Yes.
00:30:09.030 - 00:30:11.874, Speaker B: And the other ones are the conformal ones.
00:30:24.614 - 00:30:33.934, Speaker E: Oh, that's a great point. And I'm going to, I'm going to discuss this in more details. More questions. Yeah, four remarks. Yeah.
00:30:34.014 - 00:30:39.774, Speaker B: So for the s hyper click lower bound in the no self join.
00:30:39.894 - 00:30:40.594, Speaker E: Yes.
00:30:43.494 - 00:30:44.734, Speaker B: Even more than the era.
00:30:44.814 - 00:30:46.874, Speaker E: Yeah, I'm going to talk about that.
00:30:47.854 - 00:30:53.314, Speaker B: So what did you use? What we use is this proof, the fact that there are no self joins.
00:30:53.694 - 00:31:22.576, Speaker E: I'm going to talk about that. Any questions that are not related to self joins? Yes. So the triangle assumption is enough when you have binary relations, but if you have larger than binary relations. So for example, if your query looks exactly like this, then no, you cannot just use the triangle or. I don't see how you can do that. Yeah.
00:31:22.760 - 00:31:30.540, Speaker F: So why did you only assume that the hyper clique can be done in linear time? We believe it's much harder.
00:31:30.712 - 00:31:33.876, Speaker E: Well, that's what I need. So I just assume the minimum I.
00:31:33.900 - 00:31:36.316, Speaker F: Need, you're saying in our original paper.
00:31:36.420 - 00:32:04.754, Speaker E: Yeah, yeah. So if we have a stronger assumption, maybe we can say something about, not just that you can't do it with linear preprocessing, but you can't even do it for larger preprocessing. But I just don't, I mean, I just don't talk about it at all for the sake of simplicity. But actually in our research we didn't mention it in any paper for the sake of simplicity. Maybe we should. That's a good, that's a good point. Yeah.
00:32:09.974 - 00:32:14.954, Speaker B: This lower bound assumption converges somehow to linear if you increase the k. Right.
00:32:20.254 - 00:32:21.234, Speaker E: I don't know.
00:32:24.454 - 00:32:26.790, Speaker B: Yes, because we're counting a number of.
00:32:26.822 - 00:32:27.434, Speaker E: Edges.
00:32:32.394 - 00:32:42.734, Speaker F: We can talk about. Okay.
00:32:44.874 - 00:33:44.174, Speaker E: So before I move on to the next part of the talk, which is self joins, I know you're all waiting for that. I just want to mention a few things about the raw model, because it's something that I found really confusing in the beginning, and people are still constantly asking me, but why does it make sense? So I want to tell you why it makes sense from my point of view. So what does it mean? First of all, we need to put the input in our memory, and then we need the registers to be able to contain addresses of all of the memory we have. So it makes sense to consider that the length of the registers is logarithmic. So we assume that if we consider that the length of the registers is logarithmic, it means that we have a bound on the domain values. We need to assume something on the length of registers. It gives us a bound on the values we can put inside.
00:33:44.174 - 00:34:55.172, Speaker E: This means that if, for example, we want to sort of regulation, we don't have to be a way to do a comparison based sort. We can do something like radic sort that would give us sorting in linear time, not n log n linear. Okay, we assume that we can do basic operations in constant time, and then there are different variants that people use in different papers about how much memory is available. But for example, if we assume that we have polynomials amount of memory available, but it means that if we have lookup tables like these sort of hash tables, they can be perfect hash tables, we can just put a value in the address that matches to it and then check to see if the value is there. So we can do this in really constant time, not logarithmic, not constant in expectations, really constant time. Ok, then there are different variants on what memory you're allowed to touch, and not just allowed to touch everything, or just a linear amount of cells. And there are variants about what you can touch during enumeration.
00:34:55.172 - 00:35:42.810, Speaker E: So some people say that for real constant delay enumeration is when you only have a few pointers during the enumeration that you're allowed to move. And then for other papers, you need to really save all of the answers you've seen and use a lot of memory. So just be aware that these are things that happen in papers. If you're writing a paper, like for database people, make sure you're clear on what variant you're using, please. And then, so why, so I explain now why I think it makes sense from the theoretical point of view, and then from the practical point of view. This is a bit weird, but it only serves you logarithmic factors from what you would expect that you can really do. And in practice, logs are not that important.
00:35:42.810 - 00:35:50.250, Speaker E: So it still makes sense. So all models are wrong, but some models are still useful. So this is useful, I think, and this is why I think it makes.
00:35:50.282 - 00:36:03.934, Speaker B: Sense to question the first one is this model where you can modify everything. How do you define this in a way that makes sense? Because if your registers contain polynomial size, polynomial values, are you going to access.
00:36:04.774 - 00:36:06.950, Speaker E: But you can modify everything you can.
00:36:06.982 - 00:36:10.714, Speaker B: Access, but it's still bounded by NFC.
00:36:11.694 - 00:36:12.474, Speaker E: Yes.
00:36:15.534 - 00:36:28.782, Speaker B: The other question was about these two dimensional lookup tables. You see that there's this observation that in the run model, you can augment it by supposing that you have bi dimensional arrays, and that makes it potentially more expressive.
00:36:28.918 - 00:36:30.082, Speaker E: I don't know.
00:36:30.238 - 00:36:31.054, Speaker B: Okay.
00:36:32.874 - 00:36:36.746, Speaker E: Yeah, yeah, let's talk about it later. Is that something that Louis did?
00:36:36.850 - 00:36:37.494, Speaker B: Yeah.
00:36:37.794 - 00:36:40.654, Speaker F: Okay, let's talk about it later.
00:36:42.034 - 00:36:44.294, Speaker E: Yes. Ah, no, you're just stretching.
00:36:47.634 - 00:37:02.310, Speaker F: Like when you were talking about cyclic joints, right? You were talking about connectivity, like the nodes having the same variable being connected. So has this been explored with bounded tree width? Like you're talking about a cyclic zoo, which is like a tree.
00:37:02.422 - 00:37:02.950, Speaker E: Yeah.
00:37:03.062 - 00:37:06.234, Speaker F: You have bounded tree width, and it's like you're approximating.
00:37:07.094 - 00:37:20.434, Speaker E: Yes. So basically, if the query is a cyclic, then it has bounded tree width. The treated tree width is one, but then if the tree width is larger, you can do similar things, but you just need to pay more like, that depends on the tree width.
00:37:21.574 - 00:37:56.842, Speaker B: So that is correct if the relations have arity too. But if for higher parity relation, this is no longer tree width, it's hyperaction. Yeah, but it's, yeah, it's exactly that. It's some width notion is bounded by one if and only if the query is. Yeah, I do want to make a comment about the log factor in practice. Yeah, I have to deal a lot with customers complaining why their query is as low.
00:37:56.938 - 00:37:57.594, Speaker E: Okay.
00:37:57.714 - 00:38:00.722, Speaker B: Lock of a billion is about 30 or so.
00:38:00.858 - 00:38:01.654, Speaker F: Okay.
00:38:01.954 - 00:38:07.210, Speaker B: You know, a query running in 1 minute versus a query running in 30 minutes makes a big difference.
00:38:07.282 - 00:38:07.934, Speaker E: Yeah.
00:38:08.834 - 00:38:11.010, Speaker B: Micro break customer.
00:38:11.122 - 00:38:13.106, Speaker E: Okay, thanks for the comments.
00:38:13.170 - 00:38:17.694, Speaker B: I just want to say that if you write paper saving a lot factor, please.
00:38:20.724 - 00:38:46.164, Speaker E: Good point. Do you think this says anything about the Ram model? Okay, cool. Okay, in this talk, I won't mention all of the restrictions on memory. We assume that we can do everything we want with the memory we can access. Okay, good. And now the moment you've all been waiting for. Self joins.
00:38:46.164 - 00:39:16.084, Speaker E: What are self joins first. Okay, let's make sure. So we have this little star here. This is a query with self joins. So self joins is when we have, we use the same relation in different atoms. So here we have two self joins, right? This is a query that asks for two students that sat in the same room during an exam and got exactly the same grade. What happens to the complexity of this query? So the algorithms don't work because it's cyclic.
00:39:16.084 - 00:39:57.086, Speaker E: The hardness results don't hold because it has self joints. Let me show you why the hardness results don't hold when there are self joints. Remember, this is how we prove that the triangle query is hard. Now, what happens if we have that? That's the triangle query. What happens if we introduce another atom? We make a query of a structure that's similar to what we saw before, but now here we don't have such joint. Well, the way we would prove it's hard is we would have a construction where we, we're still reducing from triangles, but we have edges on three of the sets, and we have edges on three of the edges on three of the atoms. But in the fourth one, we put equality.
00:39:57.086 - 00:39:59.590, Speaker E: So the reduction, the construction would look.
00:39:59.622 - 00:40:03.550, Speaker D: Like this equality is just like the couples are.
00:40:03.582 - 00:40:39.234, Speaker E: I, I, these are the top ones. So the identity on all the nodes, the pairs of all of the nodes. So over this construction, the query still returns exactly the triangles. But if we have a self join, so the last atom uses exactly the same relation as before. We cannot do this construction anymore. We can't assign different relations to different atoms. Okay, good.
00:40:39.234 - 00:41:28.402, Speaker E: So what does it mean about that specific query? And in general, does it mean that it's just that these specific hardness results don't hold like the proofs don't hold, but we'd get the same results with other proofs. Well, we recently found out, thanks to a tutorial by Christoph and his co authors, that queries with self joins can be easier than queries without self joins. And here is an example for when this happens. So that's the query we saw before. It is easy. Let's prove it on a query where everything is one big self joins for, for simplicity, this is the query. Let's take an example for an input database.
00:41:28.402 - 00:41:58.544, Speaker E: This is our database. What are the answers to this query over that database? So, first of all, we have the obvious answers where. So you just take everything like this, right? So u maps to c, v maps to d, and so on. Then we have the answers. The answer where u and v are flipped. So u takes d and v takes c. And then we have the answers where u and v take the same value.
00:41:58.544 - 00:42:20.340, Speaker E: That's also a homomorphism. So you can see the list of query answers over there. And these answers where u and v take the same value, those are the key here because these are answers that basically correspond to two paths that are things that are easy to identify. Yeah.
00:42:20.492 - 00:42:39.460, Speaker D: Just to kind of make sure. So when you're doing your cell joins, sorry, this is a remote question, at least when I'm thinking in terms of graphs. The way I like to visualize these is if there are four variables, you think of this as a four partite graph. So you have one domain for x.
00:42:39.532 - 00:42:41.372, Speaker B: U, v and y.
00:42:41.548 - 00:43:03.784, Speaker D: And that what you're having over here is restriction on what are the edges can that can be between many different. And what you're saying is in the general join case there's no restriction on, say you take two partitions, whether they have to be the same or not. But in sub joins you do, and that kind of basically destroys the hardness thing because you wanted like this kind and this kind. Sorry.
00:43:03.944 - 00:43:43.834, Speaker E: Yeah, yeah, I agree. Yeah. Okay, I'll continue then, I guess. Should I help you? Or like, I don't mind that you're talking, but I'm wondering if I should be part of this too. Okay, so these answers we can see because we have this endomorphism in this query.
00:43:44.854 - 00:43:47.686, Speaker D: So in this case, if you have a subjunct like this, then you're saying.
00:43:47.750 - 00:43:51.198, Speaker B: That the domain of x are exactly the same.
00:43:51.366 - 00:43:55.514, Speaker E: Yes, it's even more than that, but in particular. Yes.
00:43:56.014 - 00:44:00.154, Speaker F: So in a query you can return something where u and v are the same.
00:44:00.614 - 00:44:47.694, Speaker E: Yes, yes, exactly, yes. And now I'm really going to show you how it's easy by showing an algorithm. Okay, so this has answers, so the answers that are not revealed and the answers that are trivial because they really correspond to two paths where u and v get the same value. Now these answers that are trivial, you can see them because there is an endomorphism in this query. So an endomorphism is a homomorphism from a set to itself. Here what it means is a mapping from the variables of the query to the variables of the query such that every atom maps to an atom. The image of this endomorphism is the two path.
00:44:47.694 - 00:45:09.544, Speaker E: You can look at it as a query. It's a cyclic, we can find its answers efficiently. These are the answers to the two path query over our database. And these answers give you answers to the original query. These answers are easy to find. You can start enumerating these first and you get a lot of time. And this time you can use to find also the answers that are less trivial.
00:45:09.544 - 00:45:32.056, Speaker E: Now, how are the answers of the image giving you the answers to the original query? Well, you just follow the endomorphism in the opposite direction. Right. And then you can. So once you find this two path and this two path, you just notice that they say they have the same endpoints. And then you find out that you.
00:45:32.080 - 00:45:34.284, Speaker F: Have something that's not trivial.
00:45:35.104 - 00:45:39.200, Speaker D: So the indication is two paths will have, the output size is pretty large.
00:45:39.312 - 00:45:40.124, Speaker E: Exactly.
00:45:44.224 - 00:45:47.160, Speaker B: I just want to say that I'm still impressed with that animation.
00:45:47.312 - 00:45:48.204, Speaker E: Thank you.
00:45:48.784 - 00:45:50.524, Speaker B: I think this is the second time.
00:45:56.334 - 00:45:58.314, Speaker E: Okay. Yeah.
00:45:58.894 - 00:46:11.834, Speaker F: So the key for why self joins become easy is because our goal is listing all outputs and everyone's doing like a count kind of query that might not hold.
00:46:12.134 - 00:46:41.694, Speaker E: Yeah, I assume. Yeah. Okay, so for self joins, this is an open problem. In general, we don't know exactly what happens. Please help. Let me tell you a bit of what we do know. Okay.
00:46:41.694 - 00:47:09.314, Speaker E: We were supposed to go on a break, but I think maybe I'll continue talking about self joins and we'll do the break a bit later. That's okay with everyone. So this is the query we just saw. I showed you an algorithm. The algorithm is based on the image you see here. That's a cyclic that you can use the answers to this image to buy time for computing everything else. Here's another query.
00:47:09.314 - 00:47:44.694, Speaker E: It's like the previous one, but now I flip the direction of this edge. Now let's play a game. I ask you, do you guess that it's easy or hard? And you have to say something. You won't be correct because I won't give you enough time. I mean, for this maybe, but I'll play this game several times. Okay, so do you guess that it's easy or hard? Okay, this query is hard. You can notice that it doesn't have endomorphisms other than the identity now.
00:47:44.694 - 00:48:09.438, Speaker E: So we don't have these images we can use and we can do a similar reduction to what we did before. And let me show you how we make this reduction work. Right, that's our query. This is how we want to encode the triangle detection. Here's a graph. We want to know whether it contains triangles. So we pretend for a moment that we don't have soft joins and we are allowed to put different relations in different atoms.
00:48:09.438 - 00:48:10.558, Speaker E: Yes, this quiz.
00:48:10.606 - 00:48:12.454, Speaker D: Are all the relations same every time?
00:48:12.534 - 00:48:21.474, Speaker E: Yes. Yes, all of the relations are the same. Thank you. I didn't say that. So from now on, until I say differently, everything is one big self joint.
00:48:22.094 - 00:48:26.834, Speaker D: Again, if I'm thinking in terms of graph theory, the underlying graph is not directed because the direction is.
00:48:27.424 - 00:48:30.084, Speaker E: Yes. Now the directions matter.
00:48:31.664 - 00:48:39.576, Speaker F: I think I'm having a whole kind of difficulty. What does the picture mean there? I just don't understand.
00:48:39.760 - 00:48:41.124, Speaker E: So this is the query.
00:48:41.424 - 00:48:42.604, Speaker F: What does it mean?
00:48:43.624 - 00:48:48.544, Speaker E: This is the pattern that you want to look for in a directed graph. That's your database.
00:48:48.584 - 00:48:50.724, Speaker F: That's when we have to be the same.
00:48:51.824 - 00:49:16.600, Speaker E: They can, they can all be different. They can all be the same. Whatever works. Yes. If you have, well, you're allowed to make them the same if that works. Right. So for example here, when, go back, this was your query, then you were allowed to make u and v map to the same thing.
00:49:16.600 - 00:49:24.614, Speaker E: If that works for you, but you don't have to. You also need to return the answers where they map to different things.
00:49:26.394 - 00:49:31.354, Speaker F: Can x and u be the same? Only if there's a database entry that's like aa.
00:49:31.434 - 00:49:33.014, Speaker E: Exactly. Yeah.
00:49:33.794 - 00:49:34.814, Speaker F: So self.
00:49:35.394 - 00:49:36.134, Speaker E: Yeah.
00:49:36.754 - 00:49:38.414, Speaker F: And you allow self loop.
00:49:38.914 - 00:49:43.654, Speaker E: Yeah, that's what your database says.
00:49:46.074 - 00:49:47.794, Speaker A: Again, to rephrase, you're just finding all.
00:49:47.834 - 00:49:51.258, Speaker B: Homomorphism from this small pattern into the big graph.
00:49:51.346 - 00:50:17.154, Speaker E: Yes, exactly. Right. So here, let's go back here. I'm asking, I'm giving you a pattern. I want to find all homomorphisms from this pattern to an input graph directed graph. Is this possible with linear preprocessing and constant delay? That's what I'm asking.
00:50:18.334 - 00:50:19.870, Speaker F: And you flip the edge.
00:50:20.062 - 00:50:26.350, Speaker E: So yes, for now it's, this is the easy case. And now I flip the edge. And now I'm claiming that this is hard.
00:50:26.462 - 00:50:31.434, Speaker F: So then why can't you make the top and the right vertex the same and then I'll become triangle?
00:50:32.014 - 00:50:57.984, Speaker E: You can, but it's still hard. Triangle detection is hard. Yeah, this is, this is basically how the hardness proof proof works. Or like here, I chose to make these two the same. So this is, this is the, I'll show you exactly the construction. Now, this is how I want to encode triangle detection. So I pretend like I can put different relations in different atoms.
00:50:57.984 - 00:51:40.394, Speaker E: So for three of the atoms I put the edges, for the fourth one I put equality. If I could do that, I would be able to find triangles. But now I'm only allowed to specify one relation for everything. So what I do is I tag all of the values with the variable names according to the atom where I want them to go. And I take the union of all of these things. And this is the relation that I put in my input. And now what would be the answers over this construction? Well, the answers will all be that a variable maps to some value that's tagged by the variable itself.
00:51:40.394 - 00:52:02.274, Speaker E: And why is it always the variable itself? Because we find homomorphisms. And in particular, the mapping from the variable to the second component also has to be a homomorphism. And the only homomorphism, endomorphism within the query is the identity, because the query doesn't have other endomorphisms. So this works.
00:52:06.944 - 00:52:11.392, Speaker A: If I want to think graph. Theoretically, you're taking your whole triangle, for.
00:52:11.408 - 00:52:15.984, Speaker B: Instance, and taking the cross product with this, taking a product with this graph.
00:52:16.024 - 00:52:27.732, Speaker E: Yes, I think so. Okay. It works because the queries are core. There are no endomorphisms.
00:52:27.808 - 00:52:34.824, Speaker D: Sorry. Where are the equality constraints, like wz? Equality constraints, oh, sorry.
00:52:41.844 - 00:53:11.930, Speaker E: Okay, now what happens if we try to apply the same proof on the query that we just said we have an algorithm for? Why wouldn't it work? So now I flip this edge back, I do the same construction, and now because of this endomorphism that this is its image, I also get the w can maps to y, so I can get values where w is mapped to something tagged by y. So I get answers that correspond to two paths.
00:53:12.122 - 00:53:14.250, Speaker F: And now I'm just the triangles.
00:53:14.362 - 00:53:46.134, Speaker E: So I have too many answers. I don't really detect triangles. I also detect two paths. Okay, so I said we don't know everything about self joins. We can generalize what we saw before a bit. So if a query sort of looks like a mirror, something like this, we know it's easy. If a query has a cyclic core, like all of the queries you see here, we know it's hard things in between.
00:53:46.134 - 00:53:55.594, Speaker E: So queries, not a mirror, but having a cyclic core, we don't always know. Let me show you a few more examples and things we know about them before we go on a break.
00:53:56.454 - 00:53:59.314, Speaker B: So secret is exactly, the core is what?
00:53:59.854 - 00:54:18.534, Speaker E: Sorry, what does secret core exactly mean? It means that the core of the query, the underlying graph, if you ignore the directions, is a cycle or. Well, in the binary case, that's what it means, but it doesn't really apply for. It just means.
00:54:18.654 - 00:54:20.670, Speaker F: Yeah, what would it mean if the.
00:54:20.702 - 00:54:23.126, Speaker B: Query is non binary relations?
00:54:23.310 - 00:54:40.166, Speaker E: You take the query, if you take endomorphisms from the homomorphisms, from the query to itself, you take the core over this type of stuff. Then what you get is alpha cyclic like. Alpha, alpha cyclic like. Yeah, the same notion of cyclicity as before.
00:54:40.230 - 00:54:44.114, Speaker F: Yeah. Important like our.
00:54:45.064 - 00:55:01.920, Speaker E: It can be more than two. It would still, the algorithm would still work. Yeah. Well, one is also okay, but it needs to be cyclic. So then the query is a cyclic. We know it's easy. Okay.
00:55:01.920 - 00:55:18.324, Speaker E: So reordering variables inside an atom can change the complexity of the query. This is something we didn't have without self joins. Very cool. Right. Let's move on. Take a query, the same query. That was easy before.
00:55:18.324 - 00:55:27.580, Speaker E: Now we introduce a unary atom on the variable here. What happens to the complexity? Try to guess. Yes.
00:55:27.652 - 00:55:28.620, Speaker F: What is a unary atom?
00:55:28.652 - 00:55:29.904, Speaker B: What is unary atom?
00:55:30.364 - 00:55:55.980, Speaker E: Right, sorry. So before. Yeah, this is where the similarity to graphs start to be a bit less clear. So before we had, we had an atom that tells us r x y and an atom that tells us ryz. Now I also introduce another atom that says s of y. We have another relation. It's a unary relation.
00:55:55.980 - 00:56:05.244, Speaker E: So for example, you can say, I know that some of the nodes are red. I want the query where this node is red. Yeah, thanks. That's a.
00:56:07.904 - 00:56:09.844, Speaker B: Pen and you can write.
00:56:12.824 - 00:56:25.804, Speaker E: Okay. Okay. Okay, thanks. Cool. So I introduce a unary atom. So I have this pattern, I want these graphs to be red. Whatever.
00:56:25.804 - 00:56:55.412, Speaker E: What happens to the complexity? Hard, hard. We can still reduce triangle detection. I won't go into details, but what we get is that now if we do this reduction, not all answers would correspond to triangles. We would still have answers where this is the image. But then the answers will just correspond to edges. So it's not too many answers.
00:56:55.468 - 00:56:56.756, Speaker F: We can still go over one of.
00:56:56.780 - 00:57:05.256, Speaker E: Them and check if we also have a triangle. But we won't have answers that correspond to the image here. This is not an image. Right.
00:57:05.360 - 00:57:11.136, Speaker F: So we don't have too many answers. Okay.
00:57:11.200 - 00:57:11.884, Speaker E: Yes.
00:57:13.904 - 00:57:24.192, Speaker F: Why couldn't the like other side that doesn't have unary relation, it can still like meet that condition though, right?
00:57:24.248 - 00:57:25.504, Speaker E: Like, yes, it can.
00:57:27.244 - 00:57:28.104, Speaker F: Okay.
00:57:29.564 - 00:57:45.140, Speaker E: Which is why answers to the image give you also answers to the entire query. But you won't easily find all answers to the entire query by going through those because you can have a lot of things that don't meet the condition.
00:57:45.292 - 00:57:48.220, Speaker D: No problem. Images like the two path thing like this.
00:57:48.252 - 00:57:56.126, Speaker E: Yes. It's the two path with the unary thing in the middle. Yeah.
00:57:56.230 - 00:58:03.822, Speaker B: So you still have a linear number of versus answer you want. So how do you give a little constant?
00:58:03.878 - 00:58:09.790, Speaker E: Well, you just look at all of your answers and then some of those would correspond to edges.
00:58:09.862 - 00:58:13.382, Speaker F: So the answer would be everything is equal and this is one edge and.
00:58:13.398 - 00:58:44.834, Speaker E: Some of the answers would correspond to triangles. To just go over all of the answers, there aren't too many of those until you see a triangle. And then if you don't see a triangle, the algorithm would finish quickly because there aren't many answers. If you do see a triangle, you would see it with linear time. Cool. So this is hard. Introducing unary atoms can affect the complexity.
00:58:44.834 - 00:59:17.944, Speaker E: Another example. Do you think that it's easy or hard? Hard can do something similar to before. Let's not spend too much time on that because we want to continue. I just want to show you what happened. Now I take the same thing as before. I add two spikes here. Do you think that it's easy or hard?
00:59:20.484 - 00:59:20.908, Speaker F: Yeah.
00:59:20.956 - 00:59:44.022, Speaker E: There were two things hard in a row, right. I can't put a third hard thing. It is easy. The two spikes make it so that like, so this spikes make, makes it so that this is an image now. And now I have two images that sort of COVID the loop. That's the hard part of the query. And then I can sort of find the answers to the images and then compare the images to check if they meet.
00:59:44.022 - 00:59:50.158, Speaker E: And there is some algorithm. Yeah. What is the intuition of adding one.
00:59:50.206 - 00:59:55.734, Speaker F: Unary and will change the complexity that isn't, doesn't it get absorbed in the.
00:59:55.774 - 01:00:13.258, Speaker E: Adjacent, the binary relation? It can get absorbed in the adjacent relations, but then it's like you don't have a self join anymore because these relations are different than the relations in the other side where you don't have such a thing that go absorb through them. You can use the unary atom to filter the adjacent relations. Right.
01:00:13.306 - 01:00:14.258, Speaker F: Like what you said.
01:00:14.386 - 01:00:18.794, Speaker E: But then the adjacent relations are smaller than the ones on the other side of the query.
01:00:18.874 - 01:00:20.054, Speaker F: So it's not like.
01:00:20.434 - 01:00:22.674, Speaker B: But you have more than one binary atoms.
01:00:22.714 - 01:00:23.294, Speaker D: Right.
01:00:25.234 - 01:00:29.362, Speaker E: In general, we don't know anything. I just have specific examples for now.
01:00:29.498 - 01:00:31.066, Speaker B: That involved just a single.
01:00:31.130 - 01:00:38.540, Speaker E: Just a single, yeah.
01:00:38.652 - 01:00:44.464, Speaker F: Is it also true that adding a unary atom can only make it harder? I think so.
01:00:45.564 - 01:00:50.384, Speaker E: We don't have a complete specification, but that's all I know.
01:00:50.804 - 01:00:52.812, Speaker F: I only know that we can make it harder.
01:00:52.988 - 01:00:55.860, Speaker B: But if you introduce more than one, you could make it easy.
01:00:55.892 - 01:00:56.300, Speaker E: Right.
01:00:56.412 - 01:00:58.704, Speaker F: Make it look like a significant, well.
01:00:58.784 - 01:01:12.764, Speaker E: If you introduce unary atoms everywhere, it's as if you didn't put them at all. Or like if you put one unary atom here and one unary atom on the other side, it's a mirror and then it's easy. Right. So two, so adding them can make it easy.
01:01:16.184 - 01:01:20.672, Speaker B: So two doesn't make. It, makes this easier, doesn't increase the.
01:01:20.688 - 01:01:30.544, Speaker E: Complexity compared to one. It can make it easier. But if you didn't have any one, and now you introduce one. I'm not sure. Yeah.
01:01:33.164 - 01:01:45.944, Speaker F: Just to, like, flavor a point. So in, in the hard case, where we have a unary atom on just the left side, you add a unary atom on the right side. If it were the same condition.
01:01:46.604 - 01:01:48.596, Speaker E: Yes, it's the same unary atom.
01:01:48.740 - 01:01:52.444, Speaker F: If it's the same unary atom, then that's near.
01:01:52.484 - 01:01:53.686, Speaker E: It becomes either.
01:01:53.740 - 01:02:09.242, Speaker F: Yeah, different unary atoms would be hard. So like how. I guess I'm. Yeah. How would you generally want to classify that then? It's like, it depends.
01:02:09.418 - 01:02:16.814, Speaker E: Well, I guess I would talk about the type of endomorphisms in the query. And then you won't, this won't be able to map to the other one. Yes.
01:02:17.594 - 01:02:20.828, Speaker D: No. For. We still sell junkies like all the relations are same.
01:02:20.876 - 01:02:26.424, Speaker E: Yes, all of the binary relations are the same and this is one other.
01:02:27.444 - 01:02:51.864, Speaker F: So I like to think about these. In the graph case, you have a k per type graph where your notes, you know, k partitions, and it seems like you're identifying some partitions. Is that right? Yes, I think so. And so that's what's making the problem. The moment you identify positions, certain things become paths.
01:02:57.124 - 01:03:27.724, Speaker E: Okay, so this is easy. And now we have three things. Introducing spikes, introducing unary atoms, reordering variables inside an atom. These are things that can affect the complexity now, but couldn't affect the complexity in subject. So this is much more complicated and we don't know what's going on. Let me just very quickly, without details, show you that it gets more complicated than that. Here's a query.
01:03:27.724 - 01:04:06.600, Speaker E: Is it easy or hard? How would you know? Right. It's easy even though we don't have images that cover the entire site, because we can somehow show that the time we would need to compare the two endpoints of the images we do have is bounded by the amount of answers we would get because we have so many spikes. Okay. But now if we take. So this is easy. We take exactly the same query, but now we flip this edge. Now it is probably hard.
01:04:06.600 - 01:04:51.792, Speaker E: Okay, I can't, I can't show you that it's hard. According to the same hypothesis. I can show you that it's hard according to a different hypothesis that I'll talk about in a moment. So it's really not just about the amount of spikes, it's because this spike maps to here and this is exactly what we need to make it work. So let me briefly say that we will go back to talking about this hypothesis in the second part. I'll make sure we get to that, even though I have to cut on other things. But if we do this construction, if we look at this image, we have extra answers where this maps to edges, and this spike also maps to edges here.
01:04:51.792 - 01:05:37.108, Speaker E: So the number of extra answers would be quadratic in the number of edges that we have, which is not good. It's not something we can just go over before we find triangles. But we can do that if we assume that we are finding triangles in a tripartite graph. And here we have a small set of edges, and then quadratic in the small set of edges would work. So we had to define vertex and balance triangle detection for something else on unions of conjunction queries, which I'll get to later. And I'll tell you why we had to define this. But if we take this hypothesis, then it allows us to do the reduction.
01:05:37.108 - 01:05:41.868, Speaker E: And the hypothesis says we have a tripartite graph with one large set of.
01:05:42.036 - 01:05:44.700, Speaker F: Vertices and two smaller sets the size.
01:05:44.772 - 01:05:55.184, Speaker E: N to the alpha, then it's not possible to determine if it has triangles in time that's basically linear. In the worst case, input size.
01:05:57.284 - 01:06:01.744, Speaker F: But if the matrix multiplication exponent is two, we could do it.
01:06:05.844 - 01:06:06.316, Speaker E: Yes.
01:06:06.380 - 01:06:08.424, Speaker B: In particular the assumption.
01:06:15.084 - 01:06:28.158, Speaker E: Okay, that's a nice image of how vutdev vertex and bias triangle detection is stronger, or implies the two things we had to use before. There shouldn't be an edge here.
01:06:28.206 - 01:06:30.394, Speaker F: I think that should be an edge here.
01:06:31.214 - 01:06:54.844, Speaker E: But it's stronger than these two things. So we could replace everything else by just using that. But let's not spend too much time on that. This is hard. And what about this query here? We don't have unary atoms anymore. Is it easy or hard? I don't know. Okay, so this is an open problem.
01:06:54.844 - 01:07:22.232, Speaker E: So even let me rephrase the general open problem. Okay, we have, we don't need unary relations to make it open. Okay, I have an undirected graph. Is it possible to enumerate all homomorphisms from this undirected graph to an input undirected graph with linear preprocessing and constant delay? What's the property of the patterns that I can do that? And the property of the patterns where I cannot do that? Or for this specific one, can I.
01:07:22.248 - 01:07:23.244, Speaker F: Do this or not?
01:07:25.824 - 01:07:26.848, Speaker B: You mean directed?
01:07:26.896 - 01:07:28.568, Speaker E: Immigrant directed. Directed, yes.
01:07:28.616 - 01:07:36.364, Speaker F: Thank you. And yeah, what is the smallest open problem?
01:07:38.464 - 01:07:48.388, Speaker E: I wouldn't just bug you with that? If you like. It's a ghost. It's supposed to scare you. Okay, you mean that literally?
01:07:48.436 - 01:07:50.548, Speaker B: So, like, all six node graphs, you.
01:07:50.556 - 01:07:56.744, Speaker E: Know the answer to no, I don't know. Yeah, it's the smallest one that I thought of that I don't know.
01:07:58.084 - 01:08:01.784, Speaker D: Maybe we can, like, one of the discussion questions is find the smallest thing.
01:08:04.964 - 01:08:05.928, Speaker F: Okay.
01:08:06.116 - 01:08:16.884, Speaker E: Let's take a very short break. Five minutes, if you want to go to the bathroom, stretch or whatever, and we'll go back here and continue. And we probably won't get to the last part, but I think the questions and discussion.
01:08:19.344 - 01:08:20.724, Speaker D: At 1055.
01:08:24.704 - 01:08:28.124, Speaker E: Oh, I only have, like. I only have 15 minutes left, right?
01:08:29.704 - 01:08:31.784, Speaker D: Yeah. I mean, if you need a couple of.

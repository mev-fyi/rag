00:00:00.200 - 00:01:06.294, Speaker A: We decided to reshuffle things a little bit. So David very kindly already covered a little bit the quantum attacks on Sidh, and also gave an introduction to Cooper Berg's algorithm, which is also very important work of David and his co authors, I've heard, and I'm going to talk a little bit more about that. So David talked a lot about things that we know how to do, things that we've come up with already to look at the quantum cryptanalysis of these systems, and also a little bit about implementation. The main goal of my talk is to tell you all the things we don't know, because I want you to solve the problems, because I don't know how to do it essentially. So please forgive me for having a lot of things we don't know. Okay, so you might think, why is this. So we've got a room full of lattice experts and quantum algorithms experts, so why should you care about seaside or isogeny based cryptosystems in general? But I'm going to focus on seaside.
00:01:06.294 - 00:01:55.854, Speaker A: So it's probably the closest to traditional diffie Hellman or elliptic curved diffie Hellman, as in it's really a drop in post quantum replacement. And that is because it's really a non interactive key exchange. So David showed this very nice picture with the group action, where it's just a very simple, not generalization simple quantum equivalent of diffie Hellman. And it also comes with full public key validation. And both of these things, as far as I know, were previously an open problem to do it in an inefficient way post quantumly. It's the smallest keys of all the post quantum key exchange candidates, to my knowledge, at the moment. And it's relatively competitive speed.
00:01:55.854 - 00:02:35.814, Speaker A: But of course, if you're a lattice person, you'll think this is hilarious if I call this competitive. So it's much, much slower than lattices, but you get the small keys, so there's some trade offs there. And it depends a little bit on your application. And also it means you can have nice pictures of beaches because we call it seaside. This is another reason why you should care about seaside. Okay, so here's a little picture to give a little bit more intuition for what's going on. So we already saw some of the proper hard math from David, so I'm going to do the easy math where I just show you a picture and sort of wave my hands a little bit.
00:02:35.814 - 00:03:19.702, Speaker A: So in seaside, what are we looking at? Well, on a very sort of high level, we're thinking of this thing as a graphic. So, I'll explain a little bit more what this graph is a bit later, but it's something that we call an isogeny graph. And the black dots, the nodes are going to. Each node is going to be an individual elliptic curve, and the lines between the black dots are going to be isogenes. So we saw a little bit about actually how complicated these lines are in David's talk, which is why I'm skimming over a little bit now. But we'll go into more details later. And on a very high level view, what you can think of is you can think of your secret key as being a path in this graph.
00:03:19.702 - 00:03:53.436, Speaker A: In this. You know, of course, this is a small example. In reality, your graph will have considerably more nodes than whatever this is, 30 or something, an exponential number of nodes. And your public key will be the endpoints of that path. You think of. Your public key is going to be this elliptic curve, which is going to be an endpoint, and your secret key is going to be an isogeny, which is a path. Okay? And so David talked about Cooper Berg's algorithm to attack this problem.
00:03:53.436 - 00:04:15.364, Speaker A: And so what is that looking at? That's looking at solving the hidden shift problem. And the shift is then the shift within the graph. Right. So the hidden shift is the hidden path. So these numbers are incorrect. I made a typo. Let me just find a pen.
00:04:15.364 - 00:05:20.092, Speaker A: So, there's a missing bracket. So, the most recent improvement in asymptotic complexity of Cooper Berg's algorithm for the hidden shift problem was in 2011. And that time complexity should be two to the square root, two plus o of one, all times the square root of log p. And that's then an improvement from the previous complexity that was the same thing, but with 1.77 times that thing. So, the asymptotic complexity of Kuperberg's algorithm is a sub exponential number. And I've lost the pointer.
00:05:20.092 - 00:05:57.464, Speaker A: Where's the pointer? Oh, here it is. Okay, cool. Good little interlude there. So, please look at this number, not this one. And so, of course, compared to a claw finding type attack where you've really got an exponential difference, this is considerably worse. But because the scheme is simpler in some way, then you still get smaller keys than you do in Sidh. But this difference with the sub exponential rather than exponential algorithm is what makes it quite a lot slower than Sidh.
00:05:57.464 - 00:06:50.620, Speaker A: So I'm already going to throw some open questions at you to solve. So the main open question is on this asymptotic complexity. Of course, the absolute golden goal is, can you reduce the power of log two p. So can you turn this square root into a cube root or something like that? Can you make it more super polynomial rather than a sub exponential algorithm? Okay, so maybe that's a little bit too much to ask, because there hasn't been an improvement in that recently. And, you know, this is a fundamental idea, but if you can, then that's awesome, and please go ahead and do it. If not, how about this constant? Right? So this constant went down from 1.77 to square root of two in eight years, and maybe we can improve it more.
00:06:50.620 - 00:07:25.674, Speaker A: And if we can, of course, that's going to make, you know, even asymptotically, going to make a big difference. And failing that, of course, the last thing you can do to try and to try and have an effect on this algorithm is figure out what's the smallest o of one you can get in the exponent. And asymptotically, that doesn't really matter. But of course, we're not really in an asymptotic work. We're in a concrete world. We want concrete parameters for NIST security level one, three and five. So this is actually an extremely important question when you're looking at specific parameters.
00:07:25.674 - 00:07:50.234, Speaker A: And there's been quite a lot of work on that in the last two years, which is quite exciting. And Chris is going to talk about all the latest advances there and the work that he's done to figure out what this number should be for the NIST parameters. So, these are the open questions on asymptotics, and please go ahead and solve them. Yes.
00:07:52.334 - 00:08:21.704, Speaker B: If I can. This is a sort of statement, rather good question, but I want to refine the first open question, reducing the power of log two p. I'm just going to conjecture, and this, I think, is more tractable than what the question stated, that if you can reduce the power of log two p, then it will have an effect across the board for all of the lattice questions.
00:08:22.684 - 00:08:25.384, Speaker A: Okay, that's pretty awesome. So, thank you.
00:08:26.044 - 00:08:31.892, Speaker B: The question of understanding the mutual reductions due to reggae and others.
00:08:32.028 - 00:08:32.704, Speaker A: Right.
00:08:33.723 - 00:08:55.103, Speaker B: He said if you could do polynomial time here, then you could do close vector quickly. But I think, I suspect that that can be refined. So to possibly give you a conditional barrier for reducing the exponent of log any further.
00:08:56.563 - 00:09:23.154, Speaker A: Okay, so I'm just going to repeat your statement for the recording. So, Greg very kindly pointed out that reducing this power of log p according to some reductions of Regev. Please correct me if I make a mistake in repeating this, would actually also give a significant improvement in the best known lattice algorithms, it might give a significant improvement. Now it's on the recording.
00:09:25.254 - 00:09:33.444, Speaker B: That is also an open question. You should go through and optimize those reductions as much as you can.
00:09:34.064 - 00:10:29.264, Speaker A: Okay, so if you optimize the reductions as much as you can, then maybe you also get an improvement in the lattice algorithms. So this is not necessarily a very tractable problem. But, you know, this is the thing that would really make a very big difference to the security of seaside and also lattices maybe if you go through very carefully. Okay, so this is the sort of asymptotic story and the high level story about understanding what the security of seaside will be. And of course, it's quite a new scheme. So in terms of the concrete complexity analysis, especially given that it's actually for a post quantum system, it's a fairly complex quantum algorithm. And us cryptographers who are not strictly quantum information theorists, bang our heads against the wall a little bit, trying to understand all of the subtle questions here.
00:10:29.264 - 00:11:21.684, Speaker A: There's still probably quite a way to go on the concrete analysis. But let me tell you at least roughly where we're at now. So when I say concrete analysis, what do I mean? I want to know what should the key size be for post quantum security level? Two to the 64, two to the 96 or two to the 128, roughly corresponding to the NIST levels, although I don't think they phrase it this way. Um, so this, uh, Kuperberg's attack, in order to apply it in this context, you need many seaside queries. And of course, question number one, how many queries do you need? Um, well, actually, I'm not going to talk about this because Chris is going to talk about this in a lot of deal detail after, after the break. Um, but this is obviously a very important question for understanding the complexity of the attack. And in the case of seaside, actually.
00:11:21.684 - 00:11:55.764, Speaker A: Oh, I had this bullet point first. Sorry. So also, how is the attack affected by occasional errors and non uniform distributions over the group? So this is really a genuine question. This is not me setting up for later. I do not know the answer to this question, and I think this is definitely a question that needs to be answered by a quantum information theorist who can look into it in more detail. Um, because we're talking about huge numbers of qubits here and very expensive queries. Um, so there's all sorts of crazy things that can go wrong.
00:11:55.764 - 00:12:58.984, Speaker A: Uh, so I would say this is a very important question that so far has not really been explored, probably just because we don't really have the tools. Uh, so it's a little bit philosophical at the moment, but it's something to think about. And, um, in the case of seaside, the queries themselves are actually hugely expensive. So in joint work with Dan Bernstein, Tanya Langer and Lawrence Panny, who wrote a lot of these slides, actually, so credits to them, we looked at this question of how expensive is each query, and we did our best to optimize it as much as we could as a quantum algorithm. And I'm going to go a little bit into more details about that, just because that's the thing I know about. Of course, then for the whole attack, you've got this very expensive query times the number of queries, then all of these other very difficult questions, like occasional errors. And so, and then there's the last question, which in this algorithm is very important, which is, what about memory? So I would suggest looking at the.
00:12:58.984 - 00:14:08.184, Speaker A: Or we would suggest looking at the parallel at metric for this, because for the algorithm that we're talking about, we're really talking about an algorithm with billions of qubits. So just I know that there's different terminology used in different fields. So when I'm talking about an at metric, what I'm really thinking about is both taking into account the memory and the time of the algorithm, and, you know, multiplying those numbers together or something along those lines. And a very important part of this, if you're thinking about implementing a quantum algorithm, is of course, somehow trying to parallelize your algorithm so that you don't have qubits sitting around, that you have to pay for constantly error correcting just because they're not working at that moment. And we tried a little bit to do some parallelization in this paper, but it's not impossible that there's more options there to help you with having qubits that are just sitting around. And so, in terms of this memory question. So we already touched on, with Greg's comment before.
00:14:08.184 - 00:15:11.714, Speaker A: We just, we touched on Regev's algorithm, who. So, Regev looks at how to decrease the number of qubits that you use at the expense of time. So in order to get a polynomial time algorithm, you have to use an exponential number of qubits and vice versa. So it's not really interesting to see what the trade offs would be and what the best thing would come to be. But in terms of saying this is what I concurrently want to do, it's a very philosophical question, because we don't know how big a quantum computer will ever be able to build on what kind of timescale? Or at least I don't pretend to know that. So one thing to look at for now is just say, I take the fastest variant, I don't care how many qubits I've got, and then worry about what that means later. So this is, you know, roughly a summary of, um, what we want to understand in order to have a real concrete complexity analysis in the quantum story.
00:15:11.714 - 00:15:40.320, Speaker A: And so I don't understand this question. I don't understand this question. Chris is going to cover this one. So that leaves exactly one. And that is how expensive is each query? And I said already it's very expensive. So let's have a little look at what a query is. What does that mean? And how can we understand how expensive it has to be? Ok, in order to do that, we need to go a little bit back to isogenes.
00:15:40.320 - 00:16:20.544, Speaker A: And luckily for me, David's already given you some idea as to what's going on there. So here's the picture I had before. So, remember, the high level overview is that your secret key is a path in this graph and that your public key is the endpoints of that path. And here on the slide, I've told you, in this example, this is definitely a toy example. Here, my prime is 419, rather than two to the 512 bits. And so what is this example? So the nodes are super singular elliptic curves, which have, in this case, they have this form here. So this is in the Montgomery form that David briefly mentioned at the end of his talk.
00:16:20.544 - 00:16:53.554, Speaker A: So they've just got this one coefficient a, and that completely determines the curve up to fp isomorphism. So each node represents an elliptic curve and each edge represents an isogeny. So now here I've written three, five and seven isogenes. So in David's talk, he talked about how to compute two isogenes and how to compute three isogenes. And you already saw the complexity go up from two to three. So here I've got five and seven. And spoiler alert, when p is bigger, these numbers also get bigger.
00:16:53.554 - 00:17:27.462, Speaker A: We get to something more like 587. Yes, Lawrence is nodding, so that must be good. 587, I think, is the biggest number. So the complexity of these isogenies grows as the degree grows. So let's just have a little zoom in on this picture to see all of the information that's being encoded here. So don't worry too much about what the formulas are. But the point is that if you just take one little edge here, which looks very innocent, you've got two nodes and a blue line between them.
00:17:27.462 - 00:18:11.344, Speaker A: And what does that mean? Well, you've got these two elliptic curves here, which we saw some pictures of in David's talk. These things have formulae which you can see hopefully, is the form x cubed plus ax squared plus x, where a is 51 and nine respectively. And the blue line between them means that there's a map between them, which is an isogeny of degree three. So an isogeny, remember, it's a rational map. So you can see the numerator and the denominator are just polynomials. And it should also be a morphism of groups on the elliptic curves. And the fact that it's a three isogeny is related to the fact that you see x to the power three in the formula.
00:18:11.344 - 00:18:53.486, Speaker A: So of course, when you get a five isogeny and a seven isogeny and a 587 isogeny, you're going to get a v seven or 587 in the power of x here instead of a three. So you're talking about something a little bit bigger. Okay, so how do we compute these things in a way that we'll be able to implement that on a quantum computer? So let's first of all just talk about how to compute these things. So what are we doing? Why do we want to compute that? Well, we want to find the secret key. The secret key is a path. The path is a series of edges in the graph. So if we can find the neighbors of a curve, then that means we can compute an isogeny.
00:18:53.486 - 00:19:28.750, Speaker A: It means we can compute a path. You don't necessarily have to find the neighbors using isogenese. Even so long as you can find the neighbors, it doesn't matter. Um, so what's our aim? In order to be able to compute a path given a curve, ea, in the example I've chosen, E 51, find a neighbor in the isogeny graph. So you might want to make your problem a little bit easier because here it's got, well, six neighbors, right? It's got two neighbors on the blue graph, two neighbors on the green and two neighbors on the red. So you want to be able to find all the neighbors. But let's look at one thing at a time.
00:19:28.750 - 00:20:00.574, Speaker A: So let's say I want to find a neighbor on the three isogeny graph, which is just that blue one. So here, now the edges are just three isogenes. All of them are three isogenes. So how do we find the three isogenes coming from e 51 in this case, ea. So remember what e 51 meant. And remember this example was over f 419. So e 51 is just an elliptic curve with this equation here, y squared equals x cubed plus 51, x squared plus x.
00:20:00.574 - 00:20:47.354, Speaker A: So what do we do? Well, we're going to choose a random point. So I use the word point because I'm thinking of this geometric picture always that David had in his talk. But all a point means is just a solution to the equation. And I say it's an f 419 point. That means that I want x and y to be in fp. So, for reasons p has order dividing 400 and 2420 is p one, what am I going to do with it then? Well, I want to find a point of order three. So remember from David's talk that when we're talking about computing isogenes, it's enough if we just know the kernel.
00:20:47.354 - 00:21:19.536, Speaker A: So the kernel in this case needs to be a group of order three. A group of order three is generated by an element of order three. An element of order three in this case is a point of order three. So what do we do? We times p by 100, 4140 is 420 divided by three. And then with two thirds probability, p is going to have order three. Again, for reasons I'm not going to go into why? You can think about it if you want. It's not that hard.
00:21:19.536 - 00:21:46.732, Speaker A: I guess. Maybe it's hard. I don't know. It's not that hard. Anyway, so with some probability p has order three, and this p, sorry, 140 times p has order three, which is then something we can just compute using, like, elliptic curve arithmetic algorithms that we've known about for a very long time. Longer than I was alive, I think. So we find a map with the kernel generated by this point of order three.
00:21:46.732 - 00:22:10.544, Speaker A: Right? So this group generated by the point of order three. This group of order three. Um, so the map is then going to be a degree three map. And we do this using the veloup formulas that David mentioned in his talk. Right? So there are formulas. You can plug it in and you get your isogeny. So what we'll be trying to do, we were trying to find a neighbor, and the image of the map is the neighbor in the graph.
00:22:10.544 - 00:22:21.742, Speaker A: So this is how you find a neighbor in the three isogeny graph. Any questions about this? Is everybody on board? Yes, Antoine.
00:22:21.838 - 00:22:31.394, Speaker C: Is it really two third or is it 280 divided by 490? Because you can't take the point at infinity when you select one randomly.
00:22:36.114 - 00:23:06.842, Speaker A: Pointed out that you can't select the pointed infinity when you take it randomly. So, no, it's not exactly two thirds, but it's almost exactly two thirds. Very good. Ten points. All right, any other questions? Anyone else want points? No? Okay, so we want to not only do this for three isogenes, we want to do it for other isochinis, but exactly the same game will work for the other two. Examples that we had. That was five and seven.
00:23:06.842 - 00:23:28.454, Speaker A: Okay, so this was the three isogeny graph. Here's the five isogeny graph. Say we want to find a neighbor on the five isogeny graph. What do we do? Well, up until here, it's going to be exactly the same, right? We're not using three anywhere here. We just say this is the curve. We choose a random point. It has order dividing 420.
00:23:28.454 - 00:23:56.634, Speaker A: Luckily, 420 is also divisible by five. What a coincidence. So with probability, almost exactly four fifths 84 times p 84 is 420 divided by five has order five. So we can do the same game. We find a map with the kernel generated by this order five point. That's going to be a group of order five. And the image of that map is going to be a neighbor on the five isogeny graph.
00:23:56.634 - 00:24:18.970, Speaker A: Okay? And then, of course we can do the same thing for seven. There's the last picture. 420 is also divisible by seven. What a surprise. And then we get this. The neighbors are going to be the images of maps with a kernel which has size seven, which is generated by this point of order seven. Yes.
00:24:18.970 - 00:24:48.674, Speaker A: Keep repeating it till you get all the labels. Yeah. So if you want to. Yes, indeed. So if you've got your isogeny graph, in this case was the union of the three, five and seven isogeny graph. And so you just keep repeating it and then you have all the neighbors. So you don't necessarily, you want to be able to compute all the neighbors, but in the algorithm, you are going to basically compute all possible neighbors in superposition.
00:24:48.674 - 00:25:23.424, Speaker A: So I'm just showing that you can do all of them. Does that answer your question? Sort of. Okay, so this was all an example. But this example, of course, just makes sense in general. So what happens in general? Yes. So some of these isogenies come from subgroups that are generated by non rationalist points, as that an issue. So the isogenes here, because of the parameters that we've chosen, will be always have a rational x coordinate.
00:25:23.424 - 00:26:06.290, Speaker A: So actually what you do is you choose an x rather than an x and a y. Sorry, the question for the recording was some of these isogenies will be generated by points with non rational coordinates. And is that a problem? And the fact that these, these things exist in this example is of course not a coincidence. And it's to do with the parameter choices in seaside. So this is also, you want that for efficient computation of isogenes in the first place. Okay, so what does this mean? How do we do this in general? Well, we play the same game, right? Instead of e 51. Oh, I should have changed that to an EA.
00:26:06.290 - 00:26:25.710, Speaker A: I didn't. Never mind. So you have ea, a general curve over fp. You choose a random point. It has order dividing p plus one. And then with probability almost exactly l minus one over l. P plus one over l times p will have order l.
00:26:25.710 - 00:26:59.010, Speaker A: So here you can see it's very important actually that l divides p plus one. Otherwise this doesn't mean anything. And the way that I constructed the example, and the way that in, in c side that it's constructed, this will happen. And you'll see that on the next slide. Then this group here with probability l minus one over l will have order l. And so you can find the map with the kernel, which is isomorphic to z mod lz. And the image of that map is going to be a neighbor in your l isogeny graph.
00:26:59.010 - 00:26:59.854, Speaker A: Yes.
00:27:02.564 - 00:27:11.384, Speaker C: It seems to be only divisible once by l. So you always get the same chunk of the l torsion. So there is a single isogeny you can select.
00:27:13.524 - 00:27:23.504, Speaker A: So there's going to be exactly one completely fp rational l torsion point. And then there's one where the y coordinate will be square root.
00:27:24.964 - 00:27:30.826, Speaker C: It's a minor seismy, and it's not, not given in that way, is the.
00:27:30.850 - 00:27:32.134, Speaker A: Minus isogeny.
00:27:34.994 - 00:27:38.986, Speaker C: You know, three plus and three minus. So, but here you.
00:27:39.090 - 00:27:41.874, Speaker A: Oh yeah, you mean, you mean from the negative eigenspace to fribinius.
00:27:41.914 - 00:27:44.934, Speaker C: Yeah, yeah. And you can't find it that way.
00:27:45.874 - 00:27:56.414, Speaker A: Well, you can just switch the sign of the point. That's right. That this is only one direction. It is. This only gives one direction. Yes. This will always give you the same direction.
00:27:57.034 - 00:28:06.994, Speaker C: You could store the points because you don't need many of them. You don't need to do randomness or whatever. You could store 1.4, but it's a different curve.
00:28:07.034 - 00:28:14.334, Speaker A: Yeah. You're always going from a different curve. That's the point. Yeah. That's why you can't store the points. You can't store points for exponentially many curves. Yeah.
00:28:14.334 - 00:28:58.204, Speaker A: So just to repeat the question for the recording. So Antoine was pointing out that because he already knows what P is going to be, he knows that there's going to be always, you're always going to find the same point of order, l which means you've always computing the same direction. You're always computing the isogeny in the same direction. And so we had some, like, acrobatics to do both ways in the paper, which I tried to sweep under the rug, but Antoine doesn't like rugs, so I'm not doing that now. And, uh, so you're always, yeah, you're always going to be ending up going in the same direction. Um, but that's not a problem. It's something you can solve.
00:28:58.204 - 00:29:53.868, Speaker A: Um, okay, so any, any more questions about this? So this is, of course, at the moment just a completely classical algorithm. Um, but each of these things is something that you can, each of these steps is something that you can implement in a quantum setting. So choosing the random point is a problem that was already solved in the past, I think, by dantania. Was that solved by you? Alligator plus, unlike Casnova and Mike Hamburg. Plus Casnova and Hamburg. Okay, so there's a quantum algorithm which is called alligator, not alligator, but alligator, to find a random point on the curve. And everything else is elliptic curve arithmetic, which on the very high level, you can just break down into a sequence of basic bit operations like ands and ors and xors and these things.
00:29:53.868 - 00:30:33.962, Speaker A: And then you can apply your generic quantum transforms. Not transforms. You can do a generic machinery to change those basic bit operations into cnots and topheles and then into t gates and cliffords. So these are things that you can. Absolutely. This basic algorithm here is something that you can implement on a quantum machine by looking at it on the level of bit operations. So this was something that we were sort of trying to estimate how many bit operations it was and how many, how much ordered, how much it would cost to compute the cycle and blah, blah, blah.
00:30:33.962 - 00:31:25.706, Speaker A: And then Dan comes along and he's like, oh, come on, guys, we should just implement something that counts the number of bit operations, non linear bit operations. So then he does his thing and then out pops a number, and then you have an exact idea of how many non linear bit operations you do. And at some point, that's easier than trying to sort of estimate what's going on. So that's what our paper is about. But of course, this was just computing a neighbor, and we need a little bit more than that to really talk about computing one query. Oops, I'm talking for too long. So what do we do on top of this? So this is the sort of, the very important little segment of the algorithm is how to compute an isogeny and how do we use that to really use Kuperberg for seaside? Okay, so computing a query.
00:31:25.706 - 00:31:50.924, Speaker A: What does a query do? It computes many paths in superposition. What's a path? A path is a sequence of steps. Each step is an isogeny. Oh, I've already said that here. Okay. Part is a sequence of isogenes, and they will have degrees, which vary a lot. You know, they're going to range from three to 587, for example, or maybe something bigger later on in life when things get broken.
00:31:50.924 - 00:32:19.728, Speaker A: And larger degree isogenes are more expensive, as we've seen. I mean, just from the formula, you can see they're more expensive. But at the same time, remember, we've got this step in the algorithm which finds something with probability l minus one over l. Right. That was on the previous slide. We were finding something with probability l minus one over l. What does that mean? Oh, I've got too many bullet points.
00:32:19.728 - 00:32:57.076, Speaker A: Okay, so these are more expensive. And because you're wanting to compute many different parts in superposition, you've got isogenies of different degree being computed in superposition. What does that mean? You've got qubits that have got nothing to do, because in one place, you're computing a three isogeny. In another place, you're computing a 587 isogeny. This needs to take the same amount of time. So you've got qubits that are just lying around being error corrected in order to make space for this to happen, which I've called bored qubits because they don't have anything to do. So you have to give them things to do.
00:32:57.076 - 00:33:12.024, Speaker A: They have to keep them excited. And that obviously costs money. Costs. Well, I suppose it is physical money. Yeah, sure. Okay. And then you've also got this probability failure at this step when you're trying to find a point of the correct order.
00:33:12.024 - 00:33:38.010, Speaker A: And that fails very often for small L. Right. So we saw for l equals three, you had something that succeeded with probability two thirds. And that's a pretty high failure rate. So what does this mean? This means you have to do it a bunch of times until you get a high enough success rate. So this combination of these two things makes the whole query computation really quite expensive. Right.
00:33:38.010 - 00:34:17.514, Speaker A: So this failure, given our inability to control errors, is quite problematic for quantum implementation. So our paper. So this is the paper with Dan, Tania and Lawrence. This gives quite a lot of optimizations and ideas and more complex variants of just compute parts and superposition in order to try and mitigate the combination of these two things. There's a whole bunch of algorithms in there, various levels. And I invite you to go and read the paper if you want to know all of the nitty gritty details of how to optimize these things. I wasn't sure that was the best way to spend my time now, so that's not what I'm doing.
00:34:17.514 - 00:35:05.606, Speaker A: But there are ways to mitigate this. But so I think on the next slide, I have just how much we managed to do. So, as I already said, along with this paper, there's a tool that provides software to compute a path using basic bit operations. So you really break down this elliptic curve arithmetic to compute isogenes into a list of bit operations that we understand how to implement quantumly. And then you just count automatic tallies of nonlinear operations and linear operations. Then what do we do? Well, I'm afraid all we do. This is not very fun for the quantum information theorists out there, but maybe you can do something cleverer.
00:35:05.606 - 00:35:56.586, Speaker A: We just apply a generic conversion. So what's this generic conversion? Well, you take your sequence of your basic bit operations with at most b non linear ones. You turn it into a sequence of reversible operations, and then you turn with toffoli operations, and then you turn that into a sequence of reversible operations with at most 14 bt gates. So you might wonder why this is the generic conversion we use and not the one where you can turn it into at most eight b t gates at the expense of o of b measurements. And, well, this is just what we chose to do, because b is very large for us, and it's an unknown expense at the moment in the context of surface code error correction. So that's what we chose to do. Maybe it was a bad choice.
00:35:56.586 - 00:36:25.542, Speaker A: Please go home and look at it and tell us if it was a bad choice. But this is what we've done with our algorithm. So we take our classical algorithm, we apply this generic conversion to get a quantum algorithm, and of course, it's possible to do this faster. I don't know how much faster. I mean, we saw a great example on Saturday in the Q hash talk that when you really look at, you're really trying to focus on the arithmetic. That's fine. Faster.
00:36:25.542 - 00:36:40.990, Speaker A: For quantum operations, you can do a lot better. So there was a nice speed up from insure from Samuel Jacques and someone else. Sorry, I forgot. Anyway, I should have written it down. I didn't. Sorry. Ans gank, kate.
00:36:40.990 - 00:37:25.704, Speaker A: Great, thank you. And so this is an open question, which, again, I welcome you to look at. I told you, it was going to be a ton of things I didn't know how to do. And so how well do we manage to do with this idea of just generic conversion? So, let's look at a case study. So, like I say, we have software so you can plug in numbers, whatever you like, to see what you would get with different parameters. So in this clmp, that's myself, Watka Castrik, Tanya Lange, Laurence Pani and Jose tranes. So, in our original paper on CSide, we just took the numbers from Koopa Berg's 2011 paper and said, this is the complexity approximately.
00:37:25.704 - 00:38:43.874, Speaker A: And we talked a little bit about the subtleties of memory and those sorts of things, but we didn't go into huge amounts of detail on what the complexity would be of the quantum algorithm, because that's a very subtle question, which has taken at least several papers since then to work out. So this is just based on those parameters. There's a place to start. Um, what do we get for, uh, the, the algorithm that we looked at, what's the cost for one query in the algorithm that we looked at? So, in this example, the finite field is Fp with, um, p of this very special form where l 74 is then the prime 587. And of course, this means the reason we take this special form is so that we have each small prime dividing p plus one, which we saw was an important part of being able to compute these rational isogenies. Okay, so what's the number that we get? Well, we do look at some different error rates, but just to pick a random one for an error rate of wanting less than two to the -32 errors, our best algorithm in our paper requires this specific number of non linear bit operations, which is just a little bit less than two to the 40. So this is what I mean by expensive.
00:38:43.874 - 00:39:17.302, Speaker A: It's quite expensive. So we really did try, I promise we tried because the previous record was two to 51, so we got somewhere between eleven and twelve bits better. So then we do our generic conversion, and that gives 43.3 t gates. But that's using two circumflex 40 qubits, so that's not completely ideal. You can also save some qubits at the expense of just another couple of bits. That's not so bad.
00:39:17.302 - 00:39:55.124, Speaker A: So this might be a good trade off to take. So you can also take 45.3 t gates using about two to the 20 qubits. And then what does that give you in the end? It gives you the total gates for one query, counting T plus Clifford to be about well, almost two to the 47. So that's just for one query. And then we'll see later on how many, how you can actually then use that to estimate the total cost of the algorithm. So Chris is going to talk about the number of queries and how to optimize Cooper Berg's algorithm to try and push down that number as low as you can.
00:39:55.124 - 00:40:27.644, Speaker A: Okay, so this is the best we can do at the moment for this error rate. But this is, again, to make it simple enough to actually do something, we've had to put all of these restrictions. Like, okay, we say this is the error rate, we say this is the parameter. We ignore everything that comes from error correction. We ignore so many things because otherwise it's just a problem that I don't know how to solve. We don't know how to solve. Maybe you know how to solve, I hope you do.
00:40:27.644 - 00:41:32.886, Speaker A: And so, like, one of the biggest questions is what to do with errors. So the paper that I mentioned, which has these numbers, I told you we'd look at some different error rates and we really write down the concrete ones for these three error rates. So this is a relatively arbitrary choice. The two inverse is just to see, like, okay, suppose that we have the most amazing error correction ever, then this is what we're, this is, this could be maybe one day in 100 years be a thing. This was taken as a sort of middling number, and then this was a very paranoid kind of number. So you can plug in different numbers to the code and get out different things and see what's most interesting. But I would say, yeah, understanding the error tolerance of Cooper Berg's algorithm in this context, in this seaside context, is very, very important to obtain accurate, concrete numbers, because we just, yeah, we don't know what these error rates are.
00:41:32.886 - 00:42:29.364, Speaker A: And there's many other places as well where error correction is going to be quite fundamental. And if the error tolerance is high, then the attack will be much better, and if it's low, it will be much worse. And so this is a sort of open question. And of course, this means advances in quantum error correction would make a very, very huge difference. So I would say this is like the main points I wanted to make about oracle errors. And then just finally, I have a list of the open questions that I mentioned, sort of summary for you to go home and solve. So the first one is the one I just said, how do oracle errors interact with Cooper Berg's algorithm? What kind of overheads come from handling two circumflex 20 qubits and like that's something that we definitely need to understand, especially taking into account this understanding.
00:42:29.364 - 00:43:33.394, Speaker A: So as far as I understood at the moment, the consensus, although please correct me if I'm wrong, quantum people, the moment the consensus is that like keeping a constantly error correcting a qubit is almost as expensive as just computing with it. So, um, I assume this is going to give a large number of overheads. Maybe you can do some parallelization to save yourself some work. I'm not sure. Um, and there's this sort of maybe fairly intractable question, but, um, at least something that should be looked at. Is there a quantum algorithm that can give a win on the asymptotic complexity that you can actually get to something better than this sub exponential with a half? Um, so that's really improving this, this power of log p here, because if you could, then that's going to have, you know, long reaching consequences for this algorithm. Um, and of course these queries are super expensive, so can we decrease the cost of one query? If you can, then on a concrete level you're going to, um, significantly decrease the cost, cost of the attack.
00:43:33.394 - 00:44:00.114, Speaker A: And that's all I had to say. Thank you for your attention. Any questions? Yeah, yeah. So I guess regarding the Oracle implementation. So if I understand right, you have a classical, classical circuit for it and then generic conversion. Yeah.
00:44:00.974 - 00:44:04.118, Speaker C: Are there any aspects of the group.
00:44:04.166 - 00:44:06.622, Speaker A: Action computation that seem amenable to like.
00:44:06.678 - 00:44:11.114, Speaker C: More direct quantum, maybe hybrid quantum classical.
00:44:11.534 - 00:44:42.824, Speaker A: Expression of the computation? Okay, so the question is, are there just for repeating for the recording, are there aspects of the, of the computation of the oracle which would be amenable to going directly with a quantum algorithm rather than using it? Classical algorithm and a generic conversion, easy answer is I don't know. Otherwise I'd have done that instead. But maybe my co authors have thought more about this. I don't know. No. Dan is shrugging, so I guess that's a maybe. It's definitely worth looking at, but I honestly don't know.
00:44:45.204 - 00:44:46.504, Speaker B: Any more questions.
00:44:48.724 - 00:44:49.164, Speaker A: Thank you.

00:00:01.600 - 00:00:27.514, Speaker A: Okay, so welcome, everyone, to the last day of the workshop. Today, the first talk will be by Avin Brum from Carmel Melania University. He's going to talk about options. All right, great. Thanks very much. It's great to be here, actually, I've been hanging out here most of the semester, and it's been great being here. It's a wonderful place at Simons.
00:00:27.514 - 00:01:08.084, Speaker A: So, yeah, so I'm going to talk about learning about auctions. The second part, reconstructing preferences and mechanisms from opaque transactions. And I'll get to what I mean by that in a few minutes. And this is joint work with Ishai Mansoor at Tel Aviv University and Jamie Morgenstern, who's now at Penn. Okay, so let me just start by. So with, first of all, a very classic problem. So given random samples of some function, maybe a linear function or a linear separator, try to learn a good approximation to that function.
00:01:08.084 - 00:02:16.914, Speaker A: So it's a very classic type of problem, kind of basically all of supervised machine learning problems like this. Okay, so now from there, let me talk about a less classic but still pretty well studied problem is given random observations of the actions of some agent who presumably is trying to do something or optimize something. See if you can figure out what that agent is trying to optimize. And this goes under the heading of, in the machine learning world, inverse reinforcement learning. If you kind of model the agent as acting in a Markov decision process, trying to optimize something, and you're watching as it's going through various states, you're trying to figure out what could its reward function possibly be that would make it act in such a way? And there's been a lot of nice work on that in the more economics setting, closer to the subject of this talk. This kind of thing goes under the heading of learning from revealed preferences. And the setting there is, you're watching the purchasing behavior of some agent.
00:02:16.914 - 00:02:55.506, Speaker A: What do they buy at different prices in different markets. You're trying to figure out what they like, what are their preferences like from looking at what they buy. And you can imagine that, you know, companies like to do this. And there's been a lot of nice theoretical work as well on this. Okay, so what I want to talk about is kind of a sort of a next level on this line, which is the following type of setting. And then I'll look at some specific problems in the setting, which is, suppose that you don't have access to the agents in isolation, so you don't actually have, you can't just directly look at them. Instead, what you can see is the result of some multi agent interaction.
00:02:55.506 - 00:03:24.034, Speaker A: So the agents go off into some smoke filled room and then out comes something. Some are happy, some are not. Something happened. You just get to see the result of some multiagent interactions, maybe a series of them. And from that you'd like to extract out, reconstruct what the agent's preferences or needs are in the setting. That's the kind of problem that I want to talk about. Okay.
00:03:24.034 - 00:04:02.222, Speaker A: And two kind of settings that I'll be looking at and I'll get into more civics. What exactly? I mean, here is one from observing the outcome of a series of auctions. So you're observing just who won. Like maybe you go to a web page and you see an ad on that webpage. So that advertiser won whatever auction was going on to show you that ad. So you see a bunch of auction, see who won. Can you try to reconstruct the preferences of the agents in this case, the agents being the advertisers in the case of an ad auction or from observing which agents end up happy in some allocation mechanism.
00:04:02.222 - 00:04:50.490, Speaker A: So here, think about maybe jobs being sent off to some server that doesn't have the resources to really handle all of them, and so it handles some of them and others don't get serviced. Can you reconstruct both the agent preferences, kind of what resources they needed and the mechanism, so the allocation mechanism that somehow decided which ones would get serviced and which ones wouldn't? That's the kind of the problem. Okay, so just to go now a little more specific and then I'll go really specific in a second. So here are the two models we'll be looking at. One is a repeated auction in sort of the classic Myerson setting. So here you have a bunch of agents. Each agent is assumed to have some personal probability distribution that you don't know.
00:04:50.490 - 00:05:17.018, Speaker A: And every time something goes up for auction, their bid, their value, let's say they bid, their value is drawn from that distribution and they bid that amount. So they bid a random amount from their own distribution. Bi. And what is Di? Di is some probability distribution over numbers. And so Bi is a number drawn from that distribution. If you want. Are the bids visible? Okay, good.
00:05:17.018 - 00:05:45.810, Speaker A: So the problem will be that you don't get to see the bids. If you could see the bids, you could start, you could just plot. But the problem is we won't be able to see the bids. We just see who wins the auction. It's always funny, like, why would you have a value that you draw from a distribution. Why wouldn't you just have some value for the thing? So the way to think about it is that orange isn't a particular person, it's a type of person or a type of company or whatever. It's what you can observe.
00:05:45.810 - 00:06:00.650, Speaker A: And so that would be a random person of that type, and that distribution would be the distribution over people of that type. That's the way to think about it. Otherwise it just finds it. Like why? Okay, it's only more general. Right. The distribution could just be deterministic. Could be, but then.
00:06:00.650 - 00:06:23.974, Speaker A: Yeah, then this problem becomes boring. Yeah. So you can just see who wins, which is not a lot of information, but then you can also participate yourself. Let's say we can participate, we can bid $10 and maybe we win, maybe we don't. And we'd like to do is from there recover at least the recoverable part. I'll get to what that means of the distributions. So that's one problem.
00:06:23.974 - 00:06:54.366, Speaker A: The other problem I want to look at is a setting that in some senses is more difficult, the combinatorial auction. There are multiple items for sale and bidders have combinatorial preferences over subsets. But it'll be easier in that we're going to assume agents are deterministic. So we're not going to have the probabilistic aspect here, but we don't know what they want. In addition, there'll be some allocation mechanism here that can't give everybody everything. And so it's going to somehow allocate things. It'll be of a type that we'll know.
00:06:54.366 - 00:07:13.834, Speaker A: I'll get to that in a second, but we won't know exactly what it's doing. And we're going to try to figure out both the allocation mechanism and what the agents want. Those are the two kinds of problems. Okay, so now I'm going to, I'm going to start actually with the second one. It's cleaner because deterministic. And so now let me get to what exactly. I mean.
00:07:13.834 - 00:07:30.638, Speaker A: Okay, so the setting I want to look at is the following. There are n bidders. Think of them as jobs. And there's one auctioneer. It's think of an allocator of resources over here. And here's what happens. Each day, a subset of the bidders participate.
00:07:30.638 - 00:07:58.020, Speaker A: So what's going to be different from day to day is just which bidders show up, which jobs want service that day. That's the only difference from day to day, the jobs are the same job. It's just which ones actually want to be serviced. Each day is different. Okay, so these three want to be serviced and what you observe is some of them end up happy and some end up not happy. So some of them got service, some didn't. That's what you observe.
00:07:58.020 - 00:08:29.048, Speaker A: You observe who goes in and you observe which ones end up happy and which one's not. Now what we're going to assume is what's happening under the hood here is there are some resources and each bidder wants a subset of them. So one bidder needs this one. So one job needs this, this and this, another one needs that, that and that. And what the mechanism is doing is it has some priority ordering over them. Some of them are more important to it and less. And it's going in this ordering and allocating the resource if it can.
00:08:29.048 - 00:08:59.164, Speaker A: If it can't, it says, sorry, I can't service you. And it goes on. Ok, so that's what we're going to be assuming and what we're going to try to do is from there reconstruct the unknowns, or at least be able to predict well when a new set shows up, who's going to be happy and who's not. So let me just say this again more formally now, just to be clear. So we have, it's still with toys, but more formally, so we have and bidders or jobs, every day some subset of them shows up. So what's different from day to day is just which subset shows up. There are m items.
00:08:59.164 - 00:09:23.094, Speaker A: These are the resources. Every bidder in this, we'll look at a few problems in this one. Every bidder we'll assume is single minded. It's called single minded. What does that mean? Single minded means each one, say bidder or job has a subset, a single subset, and they want everything in it in order to run. The job needs all those things. So the pink one needs these two, the blue one needs these two, the green one needs these two.
00:09:23.094 - 00:09:56.770, Speaker A: So they have a single subset, they want that whole thing. What we're going to assume is the mechanism has some priority ordering that we don't know over them. And then it just goes in a greedy way, goes from, you know, top to bottom allocating if it can. So, for instance, if pink and blue showed up, then pink would be happy, but blue would not because pink would get those two things and the blue needs the jack in the box, which isn't there anymore. And so blue is unhappy. But if pink and green showed up, they would both get service. They can.
00:09:56.770 - 00:10:16.046, Speaker A: Okay, what's kind of interesting here is there's a kind of non monotonicity. So for instance, if blue and green. So if green shows up, green gets service. Green and blue show up. Not good for green. Green doesn't green, blue and pink show up. That's good for green, because blue knocked green, sorry, goodbye.
00:10:16.046 - 00:10:51.004, Speaker A: Pink knocked out blue, and so then green got service. So adding somebody could actually help you because they knock out somebody who was not, who was ok. So what we observe is the set that shows up and who ends up happy and who ends up not happy. And our goal is to try to predict correctly what's going to happen when a new set of bidders shows up. So just to be okay, so clear about what the goals are. What's that? No, we don't know the resources. All we see is the set of people that show up and who ends up happy and who doesn't.
00:10:51.004 - 00:11:20.650, Speaker A: And what do I mean by predict correctly most of the time? What I mean is there's two to the n possible subsets. So we can just build a table and we'll make a mistake at most two to the n times. But our goal is to make a mistake at most polynomial and n times. So like maybe n squared mistakes. So over the course of this process, sometimes we'll get it right, sometimes we'll get it wrong. We want to bound how many times we ever get it wrong? What I mean by get it wrong or right is a set shows up. Our goal is to predict who's going to be happy, who's not.
00:11:20.650 - 00:11:33.058, Speaker A: Then we see who was happy, who was not. Did we get it right? Great. Did we get it wrong? Oops, we're charged. A mistake. So that's. Yeah, so do we know the set of toys or. No, we don't.
00:11:33.058 - 00:11:43.114, Speaker A: We just know that there are these, these sets in this, in this problem, the subsets. Right. Or something. We have to somehow. Right. Right. We'll have to do something.
00:11:43.114 - 00:11:53.954, Speaker A: That's right. Well, I'll look at a few problems. In this one. We don't, we don't know that set. How long is the sequence? What do you mean? Number of mistakes. Oh, good. So every day a subset of people shows up.
00:11:53.954 - 00:12:21.184, Speaker A: If it's the same set of people's yesterday, you know exactly what's going to happen because the same thing. But maybe it'll be a different thing. So just every day there's a difference that there's at most two to the n really different days. Possible. But we want to make a mistake at most polynomial and n many times if you have values instead of priority on them, it's wisher. Okay, let's get that. Okay, that's a great question of what about other mechanisms? And I don't know.
00:12:21.184 - 00:12:53.576, Speaker A: So we know a lot about these kind of mechanisms. And one of the open questions at the end is, what about other kind of mechanisms? I will talk about other kind of settings here, though, in terms of what the bidders are doing. But what was the comment? I mean, they don't offer how much they want to. So here in this model, there's no prices. You can imagine that in advance. The bidders paid some amount to, like, be at platinum level, gold level, silver level, or whatever. We just don't know what that level is.
00:12:53.576 - 00:13:22.484, Speaker A: Or it's some property of the job that we don't know that's putting them in some order. It also makes sense each time the blue says, I'll pay $20, you could imagine a setting like that where they pay the mechanism some money. And so they're right, there's other kind of mechanisms. And that would be another great thing to. Okay, so to get a handle on this, let's look at a special case just to get a feel of this, where there's just one item, all right, there's only one item. Just make it simpler. Everybody wants it.
00:13:22.484 - 00:13:47.612, Speaker A: Let's also make it simpler that every day just two people show up. Okay? So blue and green show up. Blue gets it, green doesn't. Okay, now here there's only n squared different things that can happen. So n squared mistakes would be boring for this problem. But could you do better? Maybe n log n mistakes. Okay? And it turns out actually, n log n you can get, and it's a lower bound.
00:13:47.612 - 00:14:23.768, Speaker A: And in fact, if you think about it, this is a lot like the inverse to the usual comparison based sorting problem. In comparison based sorting, you pick the pair to compare. The adversary tells you which one's bigger and you're charged one. Here, the adversary picks which pair to compare. You have to guess which one's bigger, and you're charged one if you got it wrong. In fact, if you think about it, the way to get n log n for this problem is to simulate the adversary in the usual sorting lower bound. What you want to do is look at all the n factorial permutations, take away the ones that are not consistent with the previous information.
00:14:23.768 - 00:15:16.254, Speaker A: When blue and green show up, you say, look, how many say blue is above green? How many say green is above blue? Go with whichever set is bigger. And if you make a mistake, you get to cut down by at least half. Now that's not a polynomial time procedure, but you can simulate that in polynomial time approximately by using efficient sampling of linear extensions of partial order. So basically what you want to do is you can, in polynomial time, randomly sample a random linear order consistent with this partial order information. So you do that a few times, you say, hey, on average, how many of them had blue above green or green above blue? If blue is higher in a lot of them you say blue, green, and more of them you say green. If they're about the same, it doesn't matter what you say, you'll cut out about half. So the usual lower bound for sorting gives you an algorithm for this, and the usual algorithm for sorting gives you a lower bound of n log n for this problem.
00:15:16.254 - 00:15:40.822, Speaker A: So the adversary can simulate merge sort. Okay, so now let's go back to the original problem where we have lots of items. Now for this one, we will not be able to get n log n. We'll be able to get n squared, and that's a lower bound. Okay, but we can get it. So here. So first of all, how are we going to try to solve this problem? Well, first of all, since we don't see the items, let's not try to learn them.
00:15:40.822 - 00:16:17.186, Speaker A: Instead, the only thing that's really important in this problem is the overlap of sets. Ok? Which ones conflict with which ones. So what we really just care about is the graph of conflicts. Which sets overlap, which ones. So for example, in this picture, pink and green don't conflict, but the rest do. So that would correspond to this graph of who conflicts with who, get this kind of this subsets. And we see, we don't know the graph, right? So we're trying to learn the graph.
00:16:17.186 - 00:16:40.954, Speaker A: Absolutely. This is where we're going to try. We're going to try to learn this and we're going to try to learn this. So we don't know the order, we don't know the graph. Should you not learn something higher dimensional than just a graph? You don't need to. So you don't need to, you just need to look at, it's just enough to look at the pairs that overlap. That's enough.
00:16:40.954 - 00:17:28.696, Speaker A: In fact, maybe this will help. One way to think about what's going on is there's some graph sitting here. And one way to think about this problem is every time step you observe a set st, which is a subset of the vertices, and then the ones who end up happy, it's an independent set in this graph. In fact, it's a very particular independent set. It's the independent set you would get if you were running a heuristic of greedily finding a maximal independent set by going in this order. Because the first guy who shows up in the order that's in your independent set, the next guy, if he has an edge to a previous one, you don't put him in until you get to one that is independent of the previous ones in there and you put it in. So what you can think of it is there's a maximum independent set heuristic that has some ordering over vertices.
00:17:28.696 - 00:18:00.284, Speaker A: You see a subset and then you're seeing the independent set that that heuristic is producing. That's one way to think about this problem. So to do this, here's a way we can solve this problem. So first of all, since we don't know anything, let's just start by assuming everybody's in conflict with everybody. This is guaranteed to contain all the true edges, maybe just has some extras, and we're going to maintain that invariant throughout. Also, let's start with all bidders at the top of our ordering. So from now on, the ordering doesn't go left to right anymore, it's going to go top down.
00:18:00.284 - 00:18:38.568, Speaker A: And these guys are all at the same level at the top. Okay? Because for all we know, they're all the same. What we're going to do is we're going to predict, using our current conflict graph, an arbitrary linearization of our partial order, meaning that right now there's any ordering will do. And then what we'll have is several levels and we'll just kind of arbitrarily linearize each level. Right. So now what happens? So the easy case here is if the correct answer includes a pair that's connected by an edge in our graph, like maybe these three show up and pink and yellow win. Well, according to our graph, pink and yellow shouldn't have both won, but so clearly that edge can't be there.
00:18:38.568 - 00:18:59.964, Speaker A: So then we can delete that edge and that's guaranteed progress. We still have this as a superset of the correct graph. Great. A harder case is it could be that the correct answer doesn't include a pair connected by an edge, but nonetheless we still make a mistake. An example might be like this. Maybe pink and green show up. We think pink is going to win, but really green won.
00:18:59.964 - 00:19:42.644, Speaker A: So in that case, at least in this very particular case, we can see, look, there's no way pink is at the top. If you lose, you can't be at the top, because if you're at the top, you'd always win whenever you show up. So we can safely demote, at least in this case, pink, to one level below. And what I mean by safely demote is not that these guys are necessarily above pink, but just that nobody's going to ever get demoted below their true level. We know pink isn't at the top, so it could be here, could be below, but no one's ever going to get the mode below their true level. Actually, what we're simulating here is an online decision list learning algorithm of helm, bold, littlestone and wermouth in a decision list setting. And we're kind of running that algorithm here.
00:19:42.644 - 00:20:34.200, Speaker A: Okay, so we're going to make that guarantee. And then what you can show, and I'm not going to show it here, but it's not too hard, is that as long as you do the following, you just look at the first mistake you make. By first mistake, I mean you go in the linearization you were using and you say, who was the first guy you made a mistake on? And there's two ways that mistake could be. It could be you thought they'd be happy and they weren't, or the other way around. If it turns out you thought they were happy and you thought they weren't happy, but they really were, then that lets you delete an edge. And the other way around, if you thought they were going to be happy and they weren't, that allows you to push the guy down. And you can prove by any kind of induction on this that as long as you only make an update on the first mistake, you're never going to push anyone below their correct level.
00:20:34.200 - 00:20:58.604, Speaker A: And so that gives you your n squared mistakes because there's at most n. Choose two edges to delete in this graph, and if no one ever gets pushed below their correct level, the total number of pushes is, well, zero plus one plus two plus three up to n minus one, which is another n. Choose two. So overall, only n squared mistakes, and that turns out to be optimal. Okay, so this is good. So this problem. So why is it optimal? Is it easy to.
00:20:58.604 - 00:21:26.124, Speaker A: Why is it optimal? This is easy to show. It's not too hard. You can give a setting where it's just information bound. Good. So let me now switch to a different setting on the bidder. So imagine, so I have these toys up for something. So imagine this is more like a toy store.
00:21:26.124 - 00:22:04.660, Speaker A: Imagine again, the bidders have subsets of interest, but really what's going on is they just want one so you have to go and buy, you just were in Berkeley, you have to go buy a toy for your kid or you go home. There's a certain subset that might be relevant, and maybe you have some ordering over them, and you're going to go and buy the top one. That ordering, it's in this or you're just going to. So the same kind of picture, but they're ors rather than ands. The bidders just want one thing, and they just want, they have some ordering, which I haven't shown over the subset that they care about. So again, the seller has a priority ordering. Bidders show up.
00:22:04.660 - 00:22:20.490, Speaker A: It goes in that ordering. The first guy gets the top item in their set. Next guy gets the top item remaining in their set. Next guy, the top item remaining in their set. If nothing is left in your set, you get nothing. And now for this problem. Let's say that you see what each bidder exits with.
00:22:20.490 - 00:22:58.350, Speaker A: So we get to see that the pink one got the jack in the box, for instance, and the blue one got the bear. If you don't get to see that, then this problem becomes computationally difficult. But let's say we observe that, so we get to see what the bidders go with. So this is called unit demand bidders. And our goal is to predict who's going to get what on later rounds. So it turns out one way to solve this is you can reduce this to the previous case. Not sort of the best way, but you can solve it by reduction in the previous case.
00:22:58.350 - 00:23:37.874, Speaker A: And the way you do that is for each bidder, you can create m copies of that one per item. And so now we have a bunch of pairs. A pair is a bidder, comma, item. And let's say two copies are in conflict with each other. Either they correspond to the same bidder or they correspond to the same item. And, okay, in addition to this, if the item is not wanted all by the bidder, let's say it's in conflict with everything. And now the ordering of bidders over items together, together with the ordering of the mechanism over bidders, creates one big ordering over all these pairs.
00:23:37.874 - 00:24:16.666, Speaker A: And now we can run the previous algorithm and observing who gets what is observing which of these pairs end up happy and which of these pairs end up unhappy. And so we can just do it directly by reduction to the previous problem. But now we have n times m. And so that's that squared n squared, m squared mistake total. That's not necessarily the best thing to do. Actually, a better way to do this is to combine this list algorithm with the inverse sorting idea that we saw before. What we can do is we can have this list of bidders with the partial ordering over bidders for each bidder.
00:24:16.666 - 00:24:55.586, Speaker A: We're going to run the inverse sorting algorithm on guessing their ordering over items. What we'll do is the very first mistake we make, we'll charge it to that bidder and say, hey you, you thought blue above. You thought this thing was above that thing. It's actually the other way around. Until finally either that algorithm doesn't make mistakes anymore or it says, wait a second, all the information you gave me is not consistent with any ordering. And we say, oops, sorry, I guess you're down one more level. So we push you down a level, restart from the beginning, and if you do that, then you'll get the n squared pushes and the m log mistakes for the sorting over the m items.
00:24:55.586 - 00:25:29.688, Speaker A: And that many mistakes total. Here you can prove a lower bound of nm log m. So there's a gap of n in terms of the upper and lower bound, but they look kind of similar, except we're off by a factor of n. Once you start talking about settings like this, it's also natural to talk about prices. So far the only difference day to day is who shows up and economic setting. The most natural difference day to day might be the prices that things are. So and so you can imagine both.
00:25:29.688 - 00:25:54.756, Speaker A: So every day some set of bidders shows up. Maybe it's the same set. And every day there's prices on items. And so who buys what is going to depend on who shows up and what the prices are. So we can take the same, let's take the same case of unit demand. So every bit, what do I mean now? So every bidder has a value on each item, which we don't know. And there are prices on the items which we do see.
00:25:54.756 - 00:26:31.304, Speaker A: And the assumption is the bidder will take the item that maximizes value minus price. So actually we don't need subsets anymore. It's just if you don't like it, it's value zero to you. So you got values on items, maybe you have value, I don't know, twelve on this and three on this and 92 on this or whatever. You have some values on things and you're going to compute value minus price for each thing and you'll take the high one unless they're all negative, in which case you'll just go away and not take anything. Okay, that's what the usual unit demand assumption together with quasi linearity on price. So you're linear in price.
00:26:31.304 - 00:27:13.330, Speaker A: You can also consider the additive case where people will take everything that they want. So these are standard models, and so you can handle this as well. What's kind of interesting here is you can set this up as sort of a series of linear programs. So what are we trying to do? So the beta, we're trying to figure out their value vector. So think of like a, let's imagine we have some bound on the values, values between zero and b. So their vector, their value is something inside this box of zero to b in m dimensional space, one for every, you know, object. So it's something.
00:27:13.330 - 00:27:56.080, Speaker A: So let's just take a big old ellipse and stick it around everything, and take the middle of that as our guess is the bidder's value. So there's our guess, the bidder's value, once we have guess, is the bidder's value, and a guess on ordering, or some ordering, we can now predict what's going to happen. We go through the ordering and give each one what that would say when we make a mistake, if we can figure out who to charge it to. So if we know, ok, pink, we know at the top of our ordering, we thought pink was going to get the whatever this is, the red cart. But really pink took the jack in the box. That must be because the value on the jack in the box minus ten is greater than, or let's ignore ties, or equal to, but let's ignore ties. The value on the red cart.
00:27:56.080 - 00:28:26.044, Speaker A: -20 that's why I took this and not that, whereas we thought the other way around. So that's like a separation oracle for the ellipsoid algorithm. That point we thought had this thing better than that. But now we just got a constraint that went the other way around. So we can chop that ellipse and shrink it, and we can basically run the ellipse. So we can run a bunch of ellipsoid algorithms, one per bitter. Every time we look at the top mistake we make, we get a separation oracle response for that guy, get to shrink his ellipse.
00:28:26.044 - 00:29:00.580, Speaker A: Once the ellipse gets shrunk down to nothingness, oops, we say, oh, I guess we have to push you down. We thought you were up here in the order you're actually somewhere else, restart your algorithm from the beginning, and so we can do that sort of thing. So what you basically have is a bunch of these linear programs. But the problem, you never know if you're quite charging the right guy, but eventually you'll figure out it was the wrong thing. You can push them down and then restart. And so by doing that we can then bound number mistakes. So let me ignore the case of the additive thing.
00:29:00.580 - 00:29:41.124, Speaker A: So what you end up getting is this many mistakes. N squared pushes down times l, where l is the mistake bound number of separation. Oracle queries of, say the algorithm or any linear programming algorithm that you like that can handle those kind of work. So as you see, actually all of these kind of techniques are very specific to the mechanism that's priority ordered. So there was a question about other kind of mechanisms and so here we're using that priority ordering a lot. All right, so that's all I want to say about this setting. Now I want to switch to the bayesian model and just say a little bit about that.
00:29:41.124 - 00:30:07.242, Speaker A: Okay, so I want to make the problem easier now. So we're going to restart fresh problem. There's just one item, not a whole bunch of these things and so forth. There's no list of anything, and it's a standard kind of auction. It's going to sell to the highest bidder. And let's, let's just, I'm going to equate bidders bids and values. So let's say sells to the highest bidder at the second highest price so that people have an incentive to bid their true value.
00:30:07.242 - 00:30:43.864, Speaker A: But we're not going to see the prices anyway. So it doesn't really matter. Let's just assume that the bids and the values are the same. Ok, so here they are, there's a bunch of people and they're bidding things and the auctioneer sells the highest bidder. But we're going to assume that bidders are stochastic. So getting back to this distributional model, every bidder has their own personal probability distribution. There's the orange distribution, the green distribution, the magenta distribution and the cyan distribution, I don't know.
00:30:43.864 - 00:31:02.884, Speaker A: So anyway, we have a bunch of distributions and at each time t their bid will be a random draw from their distribution and the highest bidder wins. And we get to observe the winner. That's what we see. We can also participate ourselves. We can bid $10. Maybe we'll win, maybe we won't. And our goal is to learn these distributions.
00:31:02.884 - 00:31:46.446, Speaker A: Okay, the setting makes sense. You get a bunch of distributions, basically you press the button, you get independent draws distributions, but you don't get to see them, you just see the ARG max and you can tell if you want or not. So just to mention some interesting facets of this even if you get to see not just who won, but how much they bid. So it's like you press the button, you see, oh, the draw from distribution three was highest and that was 72. So you get to see the value as well. It's still not a representative sample from that distribution because it's conditioned on them winning. So just like for instance, if every distribution was uniform and zero one, sure, the winner will be a random bidder.
00:31:46.446 - 00:32:38.014, Speaker A: But the distribution of winning bids is not going to be uniform in zero one. It's going to be very likely in this tiny range if there's n bidders, and it's not going to even be uniform here, it's going to slope up, right? We can do the integral to figure that out. In fact, let's define a quantity, p, sub epsilon, to be a price such that when you do this, the chance the winning price is below there is epsilon. So let's just set some value. Like for instance, in this case, it's very unlikely the winning bid would be less than, I don't know, one minus some number over n. So if the winning bid is never below a certain value, then you're not going to learn much about the distribution below there. You might learn how much probability mass is below there, but how it's allocated doesn't matter.
00:32:38.014 - 00:32:55.794, Speaker A: It doesn't affect anything. So if the winning bid is never below 0.9, then you might say, ok, half my probability amount is below 0.9, but how that half is allocated, it doesn't matter. It doesn't affect anything that you observe. So you're only going to try to be able to learn them really above that value. Below that, you just know how much.
00:32:55.794 - 00:33:35.468, Speaker A: That's really all you can get. That's what I mean by the part you can get. Your job is to try to figure out what the distribution looks like above there. So there's a really nice tool for problems like this called the Kaplan Meier estimator, which, if you haven't seen it, is sort of a very cute thing. And it comes out of the medical statistics in the 1950s. And the setting is you're doing a study of survival rates of patients after some medical procedure, but the difficulty is that patients keep dropping out of the study. And so you're trying to graph how long likely are they to live? Five years or whatever, but some of them move and whatever and they keep dropping out.
00:33:35.468 - 00:34:01.108, Speaker A: So the question is, what? Okay, so that's a good question. You're trying to plot the dropping dead, but they keep leaving, and so you don't know how to deal with that. Okay, so when I say dropping out, I mean leaving. All right, let's use. Yeah, right. So the model here is, let's assume that there is some probability distribution over survival rates. Let's say survival.
00:34:01.108 - 00:34:48.862, Speaker A: It's always nice to talk in the positive over survival rates. And there's a different distribution over when people would say leave the study, go off somewhere that's independent of the first one. So that, you know, there's some time you were going to live, there's some time that you might move to another city. These are independent. And you see whichever happens first. Okay, so if they're still in the study and they kick off, then you see that if they leave, you see that they leave and you don't know how long happily ever after or what. Okay, so the goal is to recover the first distribution.
00:34:48.862 - 00:35:13.904, Speaker A: Don't really care about the second one. And at least up to the point where nearly everyone has dropped out. So at that point, you can't really, there's no more real data anymore. And the idea is not that complicated. The idea is that you're always getting pretty good estimates of the chance someone survives one more day or one more month given you're still in the study. For instance, you start with 1000 people. In the first month, two people die and two people leave.
00:35:13.904 - 00:35:39.118, Speaker A: So, okay, is it two out of 1000 who died or two out of 998? Doesn't really matter. Does approximately the same. And that's the chance of dying in the first month. For the second month, you now have 996 people in the study. You just pretend it starts there. Out of those 996, some number die, some number leave and that next month. And it's a good estimate of out of the 996, what fraction? So you just chain them together.
00:35:39.118 - 00:36:20.094, Speaker A: What is the chance of surviving one more, say, month, given that you are still in the study at the beginning of the month? And so those things. And then if you want to plot this thing, you just have to chain these probabilities together to plot the curve you wanted to plot. So that's what they said. And if you think about it, that's very much like the auction setting where if you think about if we observe the bid of the winning bidder, then take a particular bidder, we care about Orange. Think of XT as orange's bid and yt as the max of everybody else. So either Orange won or Orange didn't win, depending which is higher, orange's bid or the max of everybody else. So that's like the XT and YT, and we see whichever is bigger.
00:36:20.094 - 00:37:01.170, Speaker A: And then we're trying to figure out this distribution so it really fits nicely into that setting. And so then to apply this, then the issue is just, well, we don't actually see the winning bid, but we can participate ourselves. And so what we can do is we can simulate this mechanism. Basically what we need to do is we need to set prices. See how often some bidder beats us at those prices, see how that changes if we change our price a little bit, how much we bid a little bit. Also look at how often we win at those prices. And then kind of based on that, we can estimate how often a bidder bids in some range, given that nobody else bids above there.
00:37:01.170 - 00:37:58.514, Speaker A: If you work out, it's relatively straightforward. The only price is roughly how often a bid or I wins with a bid in that range, given the price is below that p plus delta, which is what Kaplan Meyer's looking for. And the only sort of complicated, there are these errors that keep going up and you just have to control them so you don't blow up as you chain down. And as a technical thing to dealing with, is it helpful to view your errors having both a multiplicative and additive part that just helps in the induction as you're trying to prove that the error doesn't blow up over as you prove this. Okay, you can use this to also handle the case of subsets or different numbers of bidders of each type showing up each day, as long as who shows up on a given day is independent of the draws of the value. So it shouldn't be the case that person two showing up or not is correlated with the draw of person one's value from their distribution. Okay, we need those to be independent.
00:37:58.514 - 00:38:49.694, Speaker A: Okay. So now this sort of also extends to a lot of natural, so extended models. So, for instance, what's a little funny about this model so far, which, even though it's a standard model, is, you know, shouldn't you have more value on some things than others? I mean, you know, this clicker versus the laptop, you know, they're sort of different. So you can handle that as well. So you can model settings where, say, each item has a visible feature vector, there's some common component, a common value vector w, and the dot product of those two is sort of the common value. Okay, so certain things, you know, so you can model, you know, just certain things are intrinsically more valuable than others. And then we can add on this extra component on top.
00:38:49.694 - 00:39:24.624, Speaker A: So your value on some item is the sort of common component plus this sort of noise or individual term, which is coming from your own distribution. And so just if this was okay, so if all the items were the zero vector, it would just reduce back to the previous problem. But maybe the items are kind of different. And so you can handle that as well. So what you want to do is learn this common w so that you can subtract it off and reduce it to the previous problem, and then you can learn the d I's. Okay, so, good. So let me now just.
00:39:24.624 - 00:39:55.720, Speaker A: So I want to skip over how to do that. Okay, so just to go to some open problems. So I think. Okay, so the high level picture here is we're trying to figure out what is it that you're trying to figure out what people want from looking at what they do. But we're looking in a setting where we don't actually get to observe them in isolation. We can't really see exactly what they do. All we can see is they interact, and out comes something.
00:39:55.720 - 00:40:46.248, Speaker A: They go into this room, and out comes, you know, winners, losers, some legislation or whatever it is you know, you're trying to figure out, okay, who wanted what? And from. Okay, so from an auction perspective, I think the first natural open question, which is what asked in the talk, is, so these are priority based mechanisms. They're nice and clean. Can we analyze other natural allocation mechanisms? One nice thing about priority based mechanisms is if you know the priority, you can run it efficiently. So some mechanisms, like VCG, have this annoying property that even if you know the mechanism and you know everything, it's still computationally hard to run it, which is problematic. So, but it could be that there are other, you know, reasonable mechanisms that are. That are efficient to run.
00:40:46.248 - 00:41:32.370, Speaker A: And, you know, we could try, you know, for instance, maybe something that involves not strict priorities or it involves bidders somehow bidding for the items in some order, various kinds of things. So I think it'd be really interesting to analyze other kind of natural allocation mechanisms that could go on. You could also imagine bidders that are unhappy with their status. They have silver status, which they thought was good, but they didn't realize it. There's all these people with gold and platinum status above them, so they never get service, and so they start paying more than okay. It's also be interesting to analyze other natural classes of valuations also. So the algorithms we had aren't really greatly noise tolerant.
00:41:32.370 - 00:42:26.446, Speaker A: It'd be nice to be able to add more noise. There's a sort of technical open question there. We have a factor of end gap in the case of unit demand bidders of what you can get and what you can show you can't get, but don't really have a good intuition of which end is the correct end. And in the second part, this had this nice stochastic component, but didn't have a combinatorial aspect to it. So it was a very simplistic setting of single items. Could you do this in a more combinatorial setting where you have valuations over sets of things? A common situation is like trucking companies that are bidding on the ability to send things from different places. If you're going to bid on sending something from a to b, you'd like to also send something back from b to a because your truck went from a to b and you want to buy cycles, you don't want to buy just paths.
00:42:26.446 - 00:43:02.644, Speaker A: So you might have a combinatorial component to your value of doing various things and also interesting cases. So what if the mechanism is not truthful and this is a distribution over, there's a distribution of values and then based on the the bidders are shading their values to get you bids and so you have to do this mapping from bids to values. There's a lot of nice work actually in this sort of setting. Jason Hartline others kind of a lot of work in the area of econometrics on settings like that.

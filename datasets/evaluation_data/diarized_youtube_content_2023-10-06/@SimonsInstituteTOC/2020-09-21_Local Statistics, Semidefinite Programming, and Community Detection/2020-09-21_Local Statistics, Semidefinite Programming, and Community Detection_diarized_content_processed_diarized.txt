00:00:00.160 - 00:00:00.272, Speaker A: See?
00:00:00.272 - 00:00:11.494, Speaker B: So, Jess, I can see your screen, and I could hear you, well, just a second ago. So if you're ready, then please take it away.
00:00:11.654 - 00:01:02.300, Speaker A: Great. Thanks a lot. Just give me one moment to get my technology in order, if that's all right. Good. So, thanks a lot for the introduction, Ryan, and thanks to everyone for attending. So, yeah, this is some joint work with Siddhant, who's going to give the next talk in a moment, and with Prasad Raghavinder, who I think is somewhere out there in the crowd. And so the, you know, the theme of this workshop is computational phase transitions, and I think this will be quite in the pocket of that.
00:01:02.300 - 00:02:08.434, Speaker A: So, since we're early in the workshop, let me give just an overview of the problem set up that I'll be working in. So we're going to work in kind of a bayesian inference setting where there is some null model, um, which outputs random noise, and, um, a planted model, which outputs some sort of interesting signal that's been corrupted by the same sort of random noise that the null model, uh, generates. And we observe the output of one of these two things, and we have to decide which is which. Okay. And the details of the planted model are known to you, the practitioner. And, um, the algorithmic, algorithmic task here is just to see the sample and decide with high probability which model it came from. So decide null versus planted with probability one minus little o of one.
00:02:08.434 - 00:03:08.024, Speaker A: Okay. And, um, so I'm not going to dwell on the phenomenology of these models that's been well developed, mostly by people on this call, but let me just say a little bit. So, in many cases, there's a natural signal to noise ratio, and problems with this that measures the strength of the planted signal. So we can draw a little cartoon where the signal to noise ratio is here and it's getting larger, so the signal is getting stronger. So, initially, there's some impossible regime where, um, where no algorithm do this task, can do this decision task just because the models are too close together. And we reach an information theoretic threshold above which there's a sort of hard regime where polynomial time algorithms are no good, but maybe an exponential time algorithm can do it. And finally, at the computational threshold above that, there's an easy regime where this about successive problem is solvable by all kinds of polynomial time algorithms.
00:03:08.024 - 00:04:20.850, Speaker A: So, studying these information theoretic thresholds, we have a lot of tools to do this. Right. Sometimes it's technical and very difficult, and there's been lots of heroic work in the past 20 years on pinning down exactly what these are. But computational thresholds are somewhat of a different animal, right? Because we have to reason about all possible algorithms that could do this hypothesis testing task, and we don't have great tools to do that. So what do we do instead? Well, we like to design good algorithms that work as close to this threshold or what we believe this threshold is as possible. We also like to provide evidence for hardness evidence, which usually just means taking these good algorithms and kind of beating up on them, showing that they don't work so well below this threshold, or where we believe this threshold is, and today is going to be in this spirit. So in particular, what I intend to do is propose a semi definite programming hierarchy for generic inference tasks like this.
00:04:20.850 - 00:05:35.486, Speaker A: So, SDP hierarchy, so that in the same, in the same way as with some of squares, we can have a quite general and powerful framework for studying different reputation or certification or optimization tasks. And we can work within this framework to see how well it does. And we have this notion of how far up in the hierarchy you have to go to successfully perform the task. It would be nice to have something like this for inference problems as well. So that's the purpose of today's talk. And before I get into this fully general hierarchy, I first want to talk a bit about a particular problem, which is community detection and sparse random graphs and some of the SDP approaches to that problem and show how these motivates this more general framework, which I think can be applied to lots of other things as well. Any questions before I move on? So, okay, let me be a little bit precise about the model that we're going to be doing for community detection.
00:05:35.486 - 00:06:48.354, Speaker A: So the null model here is just the Erdos Rainey model with average degree dmdm. And the planted model is going to be the stochastic block model, of course, with n vertices, k groups, and a signal to noise parameter that I'll call lambda. So how does this model work? Well, first we choose a partition of the vertices into k groups, and then the edges are independent condition on these groups. So this is supposed to be a sigma edge independent condition on sigma. And in particular in the parameterization that I find kind of charming, um, the probability that an edge uv appears in the graph conditional on sigma is, um, one plus k minus one lambda times d over n sigma u equals sigma v. And that's, excuse me, one minus lambda times d over m, otherwise. Okay.
00:06:48.354 - 00:07:55.244, Speaker A: And one reason to parameterize the model like this is that it's really easy to write down a clean expression for the conjectured computational threshold. So the easy, hard transition is conjectured to take place when d land squared here is equal to one Keston student threshold. This is called, um. And there's been lots of work on this already, um, that I'm not going to dwell on too much, but let me just say that, you know, it's well known that, uh, this conjecture holds for belief propagation and for spectral methods, um, these particular spectral, spectral methods based on the non backtracking matrix or things like it. Um, and this is work of, uh, Macel, Niemann and sly, um, bodenar, lalarge, massulier, masselier, advance, handen and lots more. Um, so this is great. We have some algorithms that we know are good at this problem, and we'll know that they fail about where we expect them to.
00:07:55.244 - 00:08:48.492, Speaker A: But today I promised to talk about semi definite programs. So what about those? What about sdps? So, to set up the stp stuff, let me define a matrix, and I'll write it in pink because it's going to appear throughout the talk. So let's define a matrix xuv where if I've drawn a graph from the planted model, this is just a nice matrix representation of which vertices are in which groups. In particular, x, u, v is going to be one if sigma u equals sigma v, and that's going to be minus one by k minus one. Otherwise. And you can check that X is a PSD matrix. It's just the grand matrix of some nice vectors pointing to the corner of a simplex.
00:08:48.492 - 00:09:47.830, Speaker A: Um, and also that x u u is equal to one for all u, since every vertex is in the same community as itself. So, um, why have I told you about this matrix? Well, here's a little lemma. Um, you can, you can check on your own time. I think it will not be super illuminating to have me perform this calculation. You can check that the matrix inner product between this matrix and the centered adjacency matrix is about d times lambda times n plus order terms. Okay, so, uh, this is in the planted model. So the idea, once you know this, is to use this fact to design a semi definite program that is meant to perform this hypothesis testing problem for you.
00:09:47.830 - 00:11:22.324, Speaker A: So let's define SDP of a minus expected version of expected a. This is just the supremum over all matrices that have the same general structure as x. So PSD matrices, ones on the diagonal of, let's write it this way, matrix inner product of x with the centered adjacency matrix. So let's define this thing and then we're going to do hypothesis testing by comparing SDP of a minus expected a in the null versus planted models. And the virtue of this is that in the planted model, we already know that there's some feasible solution to this SDP that has a particular value for this matrix in a product, namely the planted x that I drew in pink up here. And so now to see how well this SDP hypothesis testing idea is going to work, we have to understand well how this SDP function behaves when you give the input not from the planted model, but just from the null model. And there's a nice theorem that I prefer, is that the expectation under the null.
00:11:22.324 - 00:12:11.282, Speaker A: So either way, the expectation is the same, right. Every edge has probability over n of a pairing. Yeah, yeah. Good. So speaking of, here is a theorem by Subabrata and Andrea from a few years ago which says that under the null model, this is how this SDP function behaves supreme over all of these matrices with the same structure as our friendly planted matrix x. Uh, is, uh, two root d times n plus little, or terms in n and d. And so, as the corollary, you can use right away, use this, use this function, use this semi definite program to distinguish the two distributions whenever lambda is more than two over root d.
00:12:11.282 - 00:13:13.238, Speaker A: So this is great. Um, this is, you know, very serious work, and, uh, it's a great paper. Um, the thing to note about this little corollary I have written is that this is actually not the ks threshold, right, which is kind of interesting. Um, so, uh, they also show in, in this work that, um, when k equals two and d goes to infinity, um, the, uh, this STP can perform, uh, the hypothesis testing problem all the way down to the chaos threshold. So works down to chaos. So it actually works better than this corollary that I've written. And the reason is that the SDP value in the planted model is kind of larger than the planted solution that it was intending to find in the first place, which is an interesting kind of charming feature of this proof, but this does raise some questions.
00:13:13.238 - 00:14:44.142, Speaker A: So one is, you know, how do you generalize this to large kids or small d? And the other is whether, whether this SDP, although it's amazing that it works in the case k equals two and t going to infinity, whether this is the most natural SDP to do this problem, and the fact that in the planted model, the solution it's finding is actually better than the one that you planted in the first place, feels like an indication that this is doing something kind of special. And different than you expected. So if we go back to thinking about this SDP, the interesting thing about it is that it actually doesn't know very much about the planted model at all. It knows only this one lemma that I proved on the previous slide, but it's not exploiting any other possible structure that x has beyond just the fact that it's a PSD matrix and it's diagonal entries are one. So the idea for how to generalize this is that in fact you should give the SDP as much information about the planted model as you can. After all, if you're doing bayesian inference, you know what the prior is, just throw in all of the, all of the info. So let's, and in particular this is going to look like adding some affine constraints to this SDP that you know, are satisfied for the plant index that you're actually looking for in the planted model.
00:14:44.142 - 00:15:08.074, Speaker A: And so let me tell you a little bit about what good one, good choice of these affine constraints. So let's say that gamma is a non backtracking lock on the complete graph on end vertices. Jess, I don't see anything showing up. Sorry, here we go. So it was between screens. Is that better?
00:15:09.194 - 00:15:10.014, Speaker B: Yep.
00:15:10.474 - 00:16:01.072, Speaker A: Great. So yeah, so let's say gamma is a non backtracking walk on the complete graph on n vertices. And let's define the weight of gamma. That is going to depend on the random matrix that you're looking at. This is the product overall edges in gamma of ge, just the indicator that that edge appears in the graph minus d over n. Now let's define a kind of weighted count of non backtracking walks with these funny weights. So I'm going to make this matrix a bar superscript l, whose uv entry is the sum over all such gamma from u to v, non back tracking in km length of gamma is equal to l of the weight of gamma.
00:16:01.072 - 00:17:17.754, Speaker A: Okay, so this just again counts these kind of centered weightings of non backtracking walks. It depends on the graph, the random graph you're looking at. And now analogous to the proof of this lemma from the previous page, you can prove, after all, just for instance, a one is just equal to a minus its expectation. So we can prove a lemma without too much trouble, that says that if x is this matrix that I defined from before drawn from the planted model, then matrix inner product of these two things is about D lambda to the l times n plus smaller terms. So the idea now is to add these affine constraints to the SDP. So in other words, you're going to look for a PSD matrix with one diagonal that satisfies all the outline constraints. So these are extra features of this planted x that you're looking for in the planted model.
00:17:17.754 - 00:18:22.836, Speaker A: And your SDP is going to search for a matrix that mimics this one. And the theorem is that, um, by taking l sufficiently large but constant, um, this SDP that I've hand waved a little bit here, um, can do detection down to the chaos threshold. Okay. And in particular in part two of the talk, my board work hasn't been great, so I'll put this over here. Part two, Siddhartha is going to show that in the null model, this SDP function from up here of these centered non back tracking lock chemical matrices, it gives you something like root d to be l times n. And you can check that as soon as you're above the chaos threshold. This is much larger, this quantity here.
00:18:22.836 - 00:18:36.556, Speaker A: Then all of these affine constraints are telling you it should be. And so the SDP won't be feasible and you'll be able to distinguish these two distributions. Is there any questions about this? Went through a little bit quickly, so I'll have time for a couple things afterward.
00:18:36.700 - 00:18:45.984, Speaker B: Just wondering about how the relationship of where l comes in. Possibly it's like the bigger l is like the closer you get to the chaos threshold, right?
00:18:46.024 - 00:19:03.724, Speaker A: Exactly. Thanks for that question, Ryan. So, right, so l here is kind of measuring how strong the SDP is, right. It's measuring how much information about the prior you've given to it. And the result is, in fact, that the closer you want to, the closer you are to the chaos threshold, the higher you need to make l to be able to do distinguishing.
00:19:06.564 - 00:19:17.784, Speaker B: I'll ask another question too, if you know it's all right. So this constraints that you added concern in some sense, like certain low degree polynomials, are the entries of a.
00:19:18.084 - 00:19:18.756, Speaker A: That's right.
00:19:18.820 - 00:19:27.436, Speaker B: I mean, and like it's like a very nice choice, I guess. But is it a good, like, is it a canonical choice? Is it like the best choice? Do you have any information about that?
00:19:27.620 - 00:20:12.480, Speaker A: Yeah. So that's a very leading question to leading into the next slide. Right. So I've set this all up to kind of tether this in earlier work on sdps and community detection and to illustrate this principle that you can gain a lot by adding extra information about the prior into the SDP. But Ryan's correct that this is not, this looks a little bit ad hoc, this choice, and it's not clear how we would have decided on this. And it turns out that you can kind of find these as natural choices for the things, for the ingredients for your SDP. If you use a somewhat more general framework, which is this framework I was hinting at at the beginning, a fully general and flexible SDP framework for doing inference problems.
00:20:12.480 - 00:20:42.450, Speaker A: So let me, let me say a little bit about that on the next slide here. Okay, so here it is. Right. So this is now getting into this local statistics algorithm setup. Um, instead of talking about community detection, let me talk about a very general setup for inference. Um, that's going to look a little like this. So let me be careful about this.
00:20:42.450 - 00:21:26.104, Speaker A: So I have some variables that I'll define first. These are set of variables x, which is x one up to xn and g, which is, uh, g one up to gm. And these are like variables that all appear in polynomials. Because there's variables and random variables, I want to be clear about what is which. So we have these variables, they're going to appear in polynomials, and I'm going to think of the null implanted models as random evaluations of these variables. So the null model is going to output a random evaluation, which I'll try to write in pink g. It's going to output a random pair x g.
00:21:26.104 - 00:22:46.294, Speaker A: And again, you should think of x as kind of a hidden signal, and g is the thing you actually get to observe. Right? So, and let me, let me also assume, just to kind of be completist here, that there's some constraint polynomials that kind of describe the particular combinatorial structure of the outputs, these random evaluations that the models are generating. So assume there exists some constraint polynomials, q one up to q k or something such that qi of x g is always zero. So for instance, these could be polynomials that tell you that the output is boolean or that it's has some particular norm or whatever you like, just some polynomials that constrain the form of your model. And now let me tell you something that's not going to seem useful at first, but that will be useful in a moment. So in the planted model, there's a nice map that we can think about. So there exists a map that takes in a polynomial in the x variables and returns a real number.
00:22:46.294 - 00:23:27.474, Speaker A: And this is just a map that sends a polynomial p of x to its conditional expectation p of x conditional on G. So this map has some properties. Properties are going to look familiar if you've done so's style things. So the polynomial one gets mapped to the number one, p q I gets mapped to zero for any polynomial, qi, that's one of these constraint polynomials. And any square of a polynomial gets mapped to a positive number. This is just some conditional expectation. Let me label these one, two, three.
00:23:27.474 - 00:24:26.864, Speaker A: And I'll also note that in lots of models that are interesting, these conditional expectations are kind of, well, concentrated around their actual expectations. Um, good. So, uh, the, the idea here is that you can, um, rule out, uh, g, having come from the planted model, by basically proving that no such map, no such conditional expectation function can exist, by proving no such conditional expectation function can exist. And we're going to do this. You want it to be linear, I guess this is suggested by the notation. But you want this to be linear, right? Linear, yes.
00:24:26.904 - 00:24:36.734, Speaker B: Please, just, can I also ask a question that came from Nike sun in the audience? She says on the right hand slide, is it a true expectation or an So's pseudo expectation?
00:24:37.354 - 00:25:27.144, Speaker A: Right. So this that I've drawn right now is, I'm just pointing out that in the planted model, there is a true conditional expectation, which is just literally send a polynomial to its conditional expectation. And the idea, of course, is that we're going to rule out the possibility of g being from the planted model by showing that no such actual expectation can exist. And we're going to do that by showing that no such pseudo expectation can exist. We're going to consider sufficiently low degree polynomials, we're going to write down an SDP, and hopefully, if all goes well, we're going to find that, that SDP is not feasible. Does that make sense? So here is the SDP, local statistics SDP. It has some parameters, dx and Dg, which are just degrees for the x variables and g variables.
00:25:27.144 - 00:26:43.874, Speaker A: And you're meant to find pseudo expectation from polynomials in the x variables, degree of most Dx to real numbers, linear, of course, that satisfies one through three, so it's normalized. It respects these kind of hard constraints of your setup, and it is positive. And moreover, if p of x, G has degree at most Dg, in other words, p is some polynomial that depends in a low degree way on your random instance. Then we're going to add an affine constraint which says that the pseudo expectation of p of x evaluated at the instance you're looking at, is roughly the expectation in the planted model of the same polynomial in x and G. And the idea is that this SDP is feasible in the planted model by taking this conditional expectation over here. And your hope is that it's going to be infeasible in the null model. And that'll give you a distinguishing algorithm.
00:26:43.874 - 00:27:56.022, Speaker A: And these parameters, Dx and DG are kind of degree parameters that tell you how hard the algorithm has to work to do this distinguishing task. And the setup here that I've written down is quite general, right? This could be any of your favorite inference problems. So this, this is obviously inspired by ideas of pseudo calibration in So's and later work of Sam Hopkins, David Straw applying that to inference problems in a slightly different way. But this is kind of the main tool that we wanted to propose in these talks. So the way that we found these polynomials on the previous slide is by actually trying to analyze this local statistics algorithm and finding the statistics that seem to be cropping up as important ones in our analysis. So let me end, before I pass it on to Sudan, let me just end with a couple of main results. So, for this task of distinguishing the erdos, Rainey and stochastic block models above the KS threshold, local statistics works for some degree in the graph.
00:27:56.022 - 00:28:28.864, Speaker A: In degree. In the instance that is, that it's constant. The constant is getting large as you get close to the threshold. And we prove that by showing that simplified SDP from a few slides ago works, and that basically that SDP is kind of captured by this, this larger framework. On the other side, on the lower bound side, we show that you're below the KF threshold. This simplified SDP fails. And we think that this is the main technical task that's needed in proving that the full local statistics algorithm fails.
00:28:28.864 - 00:29:16.024, Speaker A: But there's some additional technical details that we haven't yet worked out. However, we do have kind of a more complete result in the deregular case. So this is where you want to distinguish deregular random graph from a regular version of the stochastic block model. And here the local statistics degree two in polynomials and degree constant in graph instance is fully capable of solving the detection problem above the cast threshold and completely fails below it. So this is nice evidence for hardness. Now, I should point out that this works for all numbers of groups and all degrees, and it also is possible to do it in the case where the groups have unequal sizes and the kind of edge probabilities are in homogeneous. So the fully general SPM setting, which is nice.
00:29:16.024 - 00:30:07.284, Speaker A: So I'm going to wrap up there and pass it to Siddanth and let me just remind you what he's going to be doing in his talk. So we've kind of done this big picture local statistics thing, and now there's some nice technical things came up in our proof of just the SBM stuff that Siddanth is going to get to. So he's going to be showing in his talk this fact here, which is that supremum overall PSD matrices with ones on the diagonal of this matrix, inner product between this, excuse me, between the center nonmetric walk matrix and the variable in the SDP is about root d to the s times n. And this is going to prove the KF threshold behavior for this simplified SDP. So I'll pause there. I guess I can take questions now. And we can also.
00:30:08.304 - 00:30:27.008, Speaker B: Thanks, Jess. Why don't we applaud for both of you jointly at the end, perhaps, and perhaps while you're switching slides, you can answer, Jess, you can answer a question from the audience, from Anna Thomas, maybe also disable your screen share. She asks, can you summarize how this hierarchy compares to the sum of scores, hierarchy and other hierarchies such as the kikuchi hierarchy?
00:30:27.176 - 00:30:59.644, Speaker A: Yeah, absolutely. Um, right. The, I haven't thought too hard about the relationship between it and the kikuchi hierarchy, which is really great work that I've been meaning to understand better for a while. However, in terms of some of the squares, I can say some things. Right. So so's is kind of first and foremost a device for reputation or optimization. So I showed you just the null model, for instance, and I want to rule out the fact that there's a large cut or that it's colorable with k colors or something like that.
00:30:59.644 - 00:31:57.044, Speaker A: So so's is great at doing this, but there's not, there's not kind of a direct way to use so's for hypothesis testing. You have to do something like pick some feature of the planted model that the null model doesn't have and write down a relaxation which rules out that thing. But that's kind of a prior free task, right. It doesn't actually depend on what's in the planted model, it just depends on whatever particular statistic you're thinking about. So you can use the So's to do refutation and do, try to do hypothesis testing with refutation, but this isn't always the right thing to do. So this is basically tailored towards adding all of your kind of nice bayesian information about the two distributions you're trying to distinguish. This local statistics is, I think later in the week we're going to hear some from Afonso about the perils and pitfalls of trying to do hypothesis testing with reputation and the relationships between reputation and various different hypothesis testing problems.
00:31:58.784 - 00:32:03.444, Speaker B: Thanks, Jess. Let's continue with Siddhant. Siddhanti.
00:32:03.984 - 00:32:07.064, Speaker A: Yeah. Thank you for the introduction, Ryan, and thanks to all the organizers.

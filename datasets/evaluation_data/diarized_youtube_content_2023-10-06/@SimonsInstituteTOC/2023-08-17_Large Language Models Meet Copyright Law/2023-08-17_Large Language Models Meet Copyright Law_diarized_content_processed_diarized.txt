00:00:02.160 - 00:00:02.700, Speaker A: Hi.
00:00:02.974 - 00:00:45.556, Speaker B: Good morning. And I'm extremely honored to introduce Pam Samuelson, who will give us the first talk this morning on large language models meeting copyright law. And I think there's nobody in the world who's a bigger expert. So we're extremely lucky to hear from you on this topic. And Pam is the, she's a distinguished professor of law at UC Berkeley Law School and also in the I school, and she's the director of a center on technology and law. And she's just very recently written an article whose title is generative AI meets copyright. So extremely honored to have you here and interested to hear your talk.
00:00:45.556 - 00:01:01.884, Speaker B: And after your talk, there'll be a panel on topics that have to do with copyright privacy, other bias, a lot of topics connected with data, which has been a central focus of this workshop about the importance of data. Thank you, Pam.
00:01:22.054 - 00:02:32.024, Speaker A: Well, thanks for the invitation to participate in this workshop. I've been writing about law and technology since the mid 1980s, and interacting with people in the computing field has actually been something that's been very gratifying for me over the years. And so even though I don't have a technical background myself, I've been writing a regular column for communications with the ACM about law and technology issues and spoken at a bunch of conferences and the like. But part of my role in life is actually to try to be a conduit, right? A bridge between communities that don't usually talk to each other. But when it comes to generative AI, I think it's really important to understand that the law is going to have something to say about what you guys are doing. And so having at least some understanding about what are the lawyers talking about, what are the terms of discourse, might actually be something that would be helpful to you as you kind of go forward. I'm going to address three principal questions today.
00:02:32.024 - 00:04:32.060, Speaker A: One of it all is making copies of copyrighted works as training data infringe copyright in those works when, if at all, are AI generated outputs infringing derivative works, and when, if at all, is the removal or alteration of what's called copyright management information that's associated with copies of works, does that violate a copyright related rule? All three of these questions are being addressed in the litigations that are going on right now, and all three are also going to be likely topics for a study that the copyright office is going to probably be writing sometime in the next year. I thought it would be helpful to get started, but there are ten lawsuits out there right now in the United States, and there are a couple of plants also in Europe. But I'm going to concentrate on us law, but I will take questions about international implications of this stuff if and when you're interested in it. So stability is the defendant in two lawsuits, one by Getty Images, which says that the 12 million Getty Images that stable diffusion was, the model was trained on, that that actually is an infringement, and it's in common with the Anderson case. So the Anderson case is actually what's known as a class action. Anderson is basically the name plaintiff, but purports to represent the interests of all visual artists whose works have been trained for stable diffusion. And both these lawsuits say that the training data copies are infringement and that outputs are infringing derivative works.
00:04:32.060 - 00:05:22.054, Speaker A: Okay, so that's sort of the main claims in that particular case. But there's also what I'm calling a 1202 violation. That's the thing about removing or altering copyright management information, and I'll give you an example of that later. OpenAI, more recently, has been the subject of two class action lawsuits, and that's apparently on behalf of all authors whose works were used as training data. So it focuses a lot on books, but actually, if you look at what the class definition is, they basically say, we're representing all authors whose stuff got copied. And the claims are really the same as the ones in the stability cases. Meta more recently also was sued for copyright infringement and 1202 violations.
00:05:22.054 - 00:06:32.294, Speaker A: And there's a more recent lawsuit against Alphabet. Now, most of these lawsuits, all but the Getty lawsuits, are actually brought by the same law firm. So one lawyer is basically trying to kind of get a monopoly on this, on this particular thing. But there's a second, another lawsuit, also a class action, but brought by a different, a different set of lawyers. But so those are six lawsuits on copyright. OpenAI, GitHub and Microsoft were sued for, not for copyright infringement, although the complaint says, oh, terrible, massive copyright. But they basically say that the use of the open source programs to train the codex Lom, which then is used to essentially utter some code for the copilot.
00:06:32.294 - 00:07:47.884, Speaker A: And so the open source licenses in 1202 are the basis of those particular lawsuits. Interestingly, the plaintiffs in that case are John does, right, people who are programmers whose stuff was used, but they claim that actually they get death threats if they're named, because some people are upset about them bringing this particular lawsuit. OpenAI has also been sued for privacy, and some are related to it. And then there are two other lawsuits which are narrower in context, but one is focused on right of publicity violations and one on data privacy law. So that's what, those are the ten lawsuits, and I'm happy to answer questions more specifically about them as you get interested in it. It's important to understand that the lawsuits are not the only thing that's going on here. So members of Congress have actually held a set of hearings, and probably there will be more hearings going forward, and some of the witnesses have called for legislative change.
00:07:47.884 - 00:08:57.122, Speaker A: One proposal is collective licensing for uses of works that are training data to address kind of celebrity impersonations and other kinds of deepfakes. There's a proposal for some legislation on that, and there are a couple of other things that are on the table. But the copyright office held a set of what they call listening sessions this spring, and all the, all the videos and all the witness statements are up on the copyright office website, if you want to take a look at it. And they focused on different types of works. But the point is that most of the copyright owners who testified at this, at these things, furious about generative ailing, just unbelievably furious. And so based on what was said at those meetings, the office plans to issue what they call a notice of inquiry. Basically, they pose a bunch of questions and then they say, please, anybody who is interested answer those questions.
00:08:57.122 - 00:09:33.614, Speaker A: What I'm going to say to you is like a really, really big mistake not to put something in, because the copyright office is going to base its report on what it gets in response to the notice of inquiry. So if all the AI people basically sit and say, oh, I don't have to do anything about this, because those people are so ignorant, they shouldn't, you know, they shouldn't be allowed to make any kind of judgments like, guess what? They're going to do something, and you want your voice to actually be heard there. So the office will eventually publish a report and may make recommendations, recommendations to Congress about legislation or the like. Did you have a question?
00:09:34.154 - 00:09:41.346, Speaker C: When you say stakeholder perspectives here, what do you mean by when you say a stakeholder perspective? Who are stakeholders in this?
00:09:41.410 - 00:10:28.126, Speaker A: Well, most of the people who were, who were participating were people representing authors or some of them were individual authors. Some of them were working for companies or for. So it wasn't just one sided, right? OpenAI sent somebody. Stability sent somebody. So there were representatives, but there weren't very many. There were a few academics that were interested in, a few who were computer science computer scientists, and a few that were law people. But anybody who wanted to speak could actually have asked for, for a chance to be on the panel.
00:10:28.126 - 00:11:25.974, Speaker A: But that's the whole point, was that they recognized that there are multiplicity of interests there and wanted to at least hear from people who, and give them an opportunity to vent. Right. In some sense, that's part of what's going on. So that's actually on the policy front, that's going to be really important. Now you sort of say, why are they bringing these lawsuits? Well, one motivation for the lawyers is that if you win a class action lawsuit, you can win a lot of money. Right? Because class, usually what happens is that on a class action lawsuit like these, where people like Sarah Anderson, you know, she's a visual artist, but she ain't exactly rich. So what's going to happen is the guy who's basically the lawyer who's in charge of the lawsuit, he's going to basically bet the bank that he's going to win this lawsuit.
00:11:25.974 - 00:12:04.366, Speaker A: And when he wins that lawsuit, he can get up to a third of the recovery. And the lawsuit against GitHub, they're asking, this lawyer is asking for $9 billion. And so we're talking billions here because of statutory damages, which I'll talk about in a little while. So. But in addition to the money, okay. The class action lawyers love things that have bees associated with them. They obviously, you know, it's a, it's kind of a burnish your reputation to, like, set a new precedent and attract new clients and the like.
00:12:04.366 - 00:12:57.106, Speaker A: But you can't just bring a lawsuit because you want someone to get money, right? You have to have some people who are actually unhappy enough that they're willing to subject themselves to being plaintiffs in a lawsuit. And so you sort of say there are a lot of authors. The only relatively famous one is Sarah Silverman right now. But who knows who else will be attracted to the idea of participating in it, but authors, visual artists, songwriters, scriptwriters, and programmers, there are lots of them out there who object to, essentially the use of their works as training data. You didn't ask permission. You're not compensating us. The only reason that the systems actually produce high quality outputs is because you built the models on our stuff, right? If you built it on garbage, then all it would utter is garbage.
00:12:57.106 - 00:13:48.424, Speaker A: But the reason it's so high quality is because our stuff is high quality, and therefore, you owe us. Right. There's a kind of unjust enrichment nature to the claims, and it also irritates some people that, you know, this is a big corporations basically taking stuff for free and then commercializing it. And, you know, some people think that, well, that's capitalism, and some people think that's not fair. Okay? So that's kind of what's going on. And if you want a kind of graphic representation of how they feel, okay? And again, the graphic artists are really good at having a kind of ability to show through their graphics how upset they are about stuff. So this is actually the, I've seen quite a few cartoons about this, but this is the best one so far.
00:13:48.424 - 00:14:28.364, Speaker A: Okay. So I think it's actually important to recognize that this kind of, the upsettedness by a lot of these people is part of what I'm going to call a larger moral panic right now about generative AI. Obviously, you know better than I do about the open letter asking for a six month pause. I don't think anybody actually did that. But, you know, it was a call. It was kind of recognizing that there's stuff going on nationally and internationally. There are conversations about how to regulate AI, period, and generative AI in particular.
00:14:28.364 - 00:15:58.812, Speaker A: And one commentary characterize generative AI is this marxist nightmare because the work of millions of authors is accruing to a few capitalist owners who pay nothing at all for all of their labor. So you see that there's actually part of the moral panic is you're going to put me out of business, right? That when it comes to something like stable diffusion, that people are going to go and use stable diffusion to get graphic art rather than hiring a visual artist. So they're really worried about their livelihood. Authors are worried about, you know, that the script writers, right, are having a kind of moral panic about the use of AI to write scripts and the like. So this is actually really important that it motivates a lot of the kind of anger, right? So that, I mean, they're upset for one thing, but underlying their upsetiveness is, I think, this broader moral, okay, copyright in a nutshell. So copyright attaches automatically by operation of law from the first fixation of an original work in some tangible form, and it lasts for a really long time. And the two rights that we're going to focus on today are the exclusive right to control reproductions of your work and copies, and also to make derivative works.
00:15:58.812 - 00:16:54.696, Speaker A: Lasts a long time. It only protects the original expression in the work, but it's limited by fair use in some other doctrines. Really important thing to understand is that if they win these lawsuits, there's a lot of money that can be made in terms of those compensatory and disgorgement awards. Statutory damages is another type of remedy, and injunctions are important, and courts have the power to impound and order destruction of infringing stuff. So these large language models could get vaporized insofar as they are based on stuff that isn't licensed or public domain. Fair use is a limitation on the scope of these exclusive rights. And as a defense to a charge of infringement.
00:16:54.696 - 00:17:50.156, Speaker A: Courts consider four factors in deciding whether use is fair or not. The purpose and character of the challenge used. And the statute basically identifies criticism, comment, news, teaching, research and scholarship as among the kind of favored uses and non commercial over commercial. And since 1994, it's mattered quite a bit whether the, whether the challenged use is transformative. And transformative has come to be standing for a pretty wide range of things that people can do with other people's work. So the canonical example is a parody, right? So a parody will basically transform some of the expression from the original work in order to make fun of it. And then if you didn't take too much, then that's probably going to be fair use.
00:17:50.156 - 00:18:51.140, Speaker A: But increasingly, when the defendant's work has a different purpose from the original, that can actually be treated as transformative too. And I'll give a couple examples in a minute. Let's also take into account the nature of the copyrighted work. And so, so some things are said to be nearer to the core of copyright, and some things are farther away. So software generally out here, because it's got a lot of functional content, things that are kind of artistic and fanciful, tend to get sort of closer to the heart of copyright. And so that kind of is a factor sometimes in, in kind of weighing whether something is bad or not. Unsurprisingly, the amount of substantiality of the taking is a factor, and then the effect of the challenge used on the market for the value of the work.
00:18:51.140 - 00:19:51.502, Speaker A: And generally speaking, the purpose and market effects factors tend to dominate. Those are the ones that make the most difference. Now, when it comes to ingesting in copyright works, is training data. There are several precedents that actually are what the generative AI companies are really relying on. One is a case called Field versus Google, where Field basically put some of his work up on the Internet, and Google then basically made copies of it in the webinar, web crawling, and then index and cache the copies. And the court decided that that was a transformative fair use. Right? So Field put up the material on the Internet for people to read, and Google basically copied it for a different purpose.
00:19:51.502 - 00:20:03.042, Speaker A: Right? So even though it was an exact copy was made, it was transformative because it was for a different purpose. Similarly, in the author scale, the Google case.
00:20:03.218 - 00:20:04.734, Speaker C: I'm sorry, can you.
00:20:07.394 - 00:20:26.708, Speaker D: One could say if I understood right, Field, put it up for people to look at, and Google made it easier for people to look at it. So couldn't say that Google was actually working to enhance what Field wanted, rather than working against Field.
00:20:26.756 - 00:21:01.482, Speaker A: Yes, I think that's another consideration in the case. It wasn't one of the things that the court focused on. But, yeah, I think it's a consideration. It's a clear example of that is the Google books case, which I'm going to talk about now. So Google basically, as you know, copied somewhere between 20 and 30 million books out of research library collections, including out of the UC system, I think 3 million books out of the UC libraries. And the authors, Gail, said, oh, copyright infringement. Copyright infringement.
00:21:01.482 - 00:21:38.078, Speaker A: But the court basically said, look, they digitized the text of that for the purpose of indexing and serving up snippets. And the snippets were small enough parts of the work that it couldn't basically supplant demand for the original. Right. The supplant. The demand for the original is kind of a very common phrase in copyright land. And so Cor basically said, again, transformative. Even though you copy the whole thing, you can't index the contents if you don't copy the whole thing.
00:21:38.078 - 00:21:52.964, Speaker A: And so Google's copying, then, was reasonable in light of its transformative purpose. And since the snippets didn't supplant demand for the original, then the court decided it was fair use. Yeah.
00:21:53.304 - 00:21:59.324, Speaker C: Other computational users. How did they define that? Because. I'm sorry, that phrase. Other computational uses.
00:21:59.944 - 00:22:00.592, Speaker A: Yeah.
00:22:00.728 - 00:22:01.448, Speaker C: Yeah.
00:22:01.616 - 00:22:25.992, Speaker A: So the second circuit court of Appeals took into account that Google was making other uses besides just snippets and snippets and indexing. Right. That they were. They were enabling other things. So the Ngram viewer, for example, was identified as something that was kind of another use. And so there is this thing. There's.
00:22:25.992 - 00:23:06.808, Speaker A: Okay, another thing that lawyers, like, really, like, focus on is. Is something a holding of a case, or is it what we call dicta? Dicta is something that the court says, but it's not core part of the holding. So if the second circuit talks about computational uses as, like, a good thing, what's dicta? That's good dictum. It's. Dicta is from Latin, just means said. Right. A statement, essentially something that a court says, you know, I actually point to dicta all the time when I'm writing papers or writing amicus briefs.
00:23:06.808 - 00:23:21.324, Speaker A: But you have to. Lawyers always have to focus. What's the holding of the Google books case? It is that making copies of books for the purpose of indexing their contents and serving up snippets, that's fair use.
00:23:21.624 - 00:23:24.448, Speaker C: No, but you say as well as other computational users.
00:23:24.576 - 00:23:38.394, Speaker A: I'm just saying, now I'm CIO. I'm. Now I'm being a lawyer. Okay, so the holding of the case is about indexing and caching. The court talks about other computational uses in a positive way, but that's dicta.
00:23:39.174 - 00:23:39.914, Speaker C: Oh.
00:23:40.334 - 00:24:05.618, Speaker A: Doesn't get the weight right. If you kind of, like, say, what's the precedent? Right. What is the holding of the case? That's the holding of the case. And this is some dicta that people who are representing these generative AI companies are going to look to that language and say, oh, you see, second Circuit court of Appeals said, that's a good thing. Dicta is fluff. I'm sorry? Dicta is fluff. No, no, no.
00:24:05.618 - 00:24:18.494, Speaker A: It's taken seriously. It just doesn't have presidential weight. Okay. So that's. I'm doing a little law school class today here. Okay. So it's not flop at all.
00:24:18.494 - 00:25:00.834, Speaker A: Taken very seriously. But somebody who's fighting against the generative AI companies will say the holding in that case was yaks, and they didn't actually make a ruling about the computational uses. Okay. Anyway, there's another case in which a couple of students brought a lawsuit against a company that makes plagiarism detection software. And the lawsuit was really a bogus lawsuit, and the court threw it out. But the court sort of the question was whether the storage of the student paper. Right.
00:25:00.834 - 00:25:24.454, Speaker A: If you're trying to build a plagiarism detection system, you want to have lots of papers. And so they kind of ran these papers through to see whether these students actually plagiarized, but then they stored them, and the court decided that was a different purpose, therefore, it was transformative. So even though they copied the whole thing, it was fair use.
00:25:25.854 - 00:25:31.274, Speaker C: In the Google books case, how did the court decide that the demand was not supplemented?
00:25:34.294 - 00:26:20.114, Speaker A: Yeah, well, it's easy to find that decision on the Internet. And I could spend, actually, the rest of the time talking about that. But the court basically said, you can only get three snippets. It's only this many words long. And they took into account that Google basically had not done thesaurus and dictionaries and other things where there might be a greater risk of supplanting bananas than the original. But the court recognized that, in general, people are not going to go to the Google search engine in order to read the contents of a book. One of the things that.
00:26:20.114 - 00:27:12.984, Speaker A: An organization that I'm affiliated with called Audit alliance submitted an amicus brief in support of Google's fair use defense because our authors want their work to be found. And so it had this kind of information locating for the public benefit that the court took into account. Again, part of what's going on in copyright also is this kind of, like, there is this kind of constitutional purpose of copyright, which is to promote the progress of science. And so things that basically provide a public benefit are seen as, you know, you can't do everything and say, oh, it's a public benefit to put it up on the Internet. But in cases like this, that can actually be a significant consideration.
00:27:13.644 - 00:27:34.984, Speaker C: Please follow that. Is this super interesting? Sorry for the. One of the key topics now is stack overflow where people answer questions. Would that be like a thesaurus or dictionary in the sense that if AI replaced that, it would violate the standard.
00:27:36.044 - 00:27:54.576, Speaker A: If you just give me a little chance, I'm gonna go, I'm gonna go through some things that will, I think, come close to answering that question, and then maybe you can ask it after I've, I've sort of done some other things. I'm, I'm trying to get through fair use right now. So anyway, in the plagiarism case, how.
00:27:54.600 - 00:27:56.896, Speaker C: Did the company get the student papers?
00:27:57.080 - 00:28:55.290, Speaker A: The schools actually required the students to submit their papers, how much trust they had in their students. Right. Okay. So one of the things that people will say is that in the field, in the authors guild case, Google was making it easier for people to find the copyrighted works. And what the stable diffusion does is makes it easier for users to produce images to compete with the ingested images, or at least that's the way that the lawyers are probably going to try to do it. And then this kind of, like, not fair thing. And the authors Guild did a survey and said 90% of our authors think that companies should pay for ingesting our work as training data.
00:28:55.290 - 00:29:44.034, Speaker A: And of course, as you know, there are some markets emerging for licensing of ingestion. One thing actually that the Silverman complaint does is talk about that OpenAI was trained on a corpus of pirated books. So if there's infringing stuff out there on the Internet and you train on that, that might actually sort of source your fair use defense because you didn't kind of get lawful access to the works. And the, you know, if you train your stuff on sci hub. Wow, that would be really cool, wouldn't it? But you know what? That's illegal stuff. And so that could actually be cut against fair use. I'm not saying it can't be fair use.
00:29:44.034 - 00:30:44.746, Speaker A: I have a colleague, Mike Carroll, who wrote a long article that basically said that training on one implication of which is training on something like sci hub might actually be fair use. But I'm just saying these are considerations that might cast doubt on the viability of fair use defenses. It's also possible that courts will treat diffusion differently than the large language models, because here's the ingested image. You kind of put some noise in there, and then there's the output kind of, you de noise it, that kind of sounds like you copied it, and then you kind of pretended you didn't copy it, and then it comes out. And so there's kind of. That is going to. That could be a basis for treating it differently than large language models, because I think llms are more abstract than the diffusion, but I don't know.
00:30:44.746 - 00:31:13.196, Speaker A: I'm not a technical person. It's also possible that courts could decide to treat software different than music or the like. And I tell you something, the music industry, there are no meaner people on the face of the earth than the people from the recording industry of America. Anyway, the point is that there are lots of ways in which these factors could come, but against somebody. Yeah.
00:31:13.300 - 00:31:20.584, Speaker C: So in general, historically, there has been precedent for treating different modalities. Music.
00:31:23.644 - 00:31:48.342, Speaker A: I'm not predicting this. I'm just trying to open your mind to the fact that there could be some differences. And part of it is that who is organized and who has got a lot of money to. So the visual artists actually are not in a very good shape because they don't have any. They don't really have. They're like little organizations of visual artists, but they're not like a big collective. Right.
00:31:48.342 - 00:32:56.358, Speaker A: Whereas in the music industry, you have lots of players that are kind of concentrated in a small number of hands, and so they just tend to be more active in copyright land. So, but this is just, you know, I'm kind of trying to give you some of the landscape, give you a little feel for what's going on. So another sort of consideration is market harm. Right? So Getty says we have an established market for licensing use of our images as training data. And so one question is stability's use of those images as training data, did that harm the market? Well, I think their claim of unfairness is that, you know, that's a little bit dicey. And it wouldn't surprise me if that case ends up with a settlement because the market harm argument is strong. If you have an existing market and you didn't, you know, and you didn't pay for it, you just decided to take it for free.
00:32:56.358 - 00:32:57.350, Speaker A: Yeah.
00:32:57.542 - 00:33:04.848, Speaker C: So I don't understand how stability got hold of the Getty images. Are they using, like, little snapshots?
00:33:04.976 - 00:33:12.924, Speaker A: It is my understanding that what was used was URL's.
00:33:16.344 - 00:33:18.536, Speaker C: Direct URL's. You can access them so you can.
00:33:18.560 - 00:33:21.912, Speaker E: See preview images, Getty Watermark, all those.
00:33:22.008 - 00:33:22.644, Speaker C: Yeah.
00:33:24.024 - 00:34:04.102, Speaker A: I'm going to show you some images. Okay, hold on. Okay, so now, so I think Getty has a better claim than Anderson because Anderson is just one visual artist, and right now she's the only named plaintiff in that particular case. And she couldn't possibly give a license to ingest for training data for all the visual artists. Right. She don't, she don't represent, she hasn't been certified as a class, and so she can't grant a license. So essentially, there's a kind of market failure argument there as to Anderson.
00:34:04.102 - 00:35:33.534, Speaker A: Reddit has now announced that anyone who uses a Reddit post needs training, needs a license, even though Reddit doesn't actually own copyright in the post because those are basically owned anything by the people who wrote them. But now, if a generative AI developer uses Reddit, does that mean that that's unfair? And what about before they had a market set up? If you train, then are you scot free or now do you have to go back and negotiate? So these are just some considerations that will be part of what people will be fighting about in court. Another kind of idea that's floating out there a lot is the idea of a collective license. So a collective license would be something that Congress could pass somewhat legislation that basically says, hey, here's a generative AI. Companies should have to pay a certain amount of money into a pot, and then we'll sort of allocate that money to people. This actually strikes me as a really, really, really bad idea. But a lot of the people who are upset about, who are upset about generative AI, they actually are kind of like, oh, yeah, let's do that.
00:35:33.534 - 00:36:18.154, Speaker A: It's a bad idea because trying to administer something like this would be just a practical nightmare. So practically, it's a better transaction. Costs are huge. How much would everybody whose stuff was used as training data, how much would you get? You won't get a dime. You wouldn't get like maybe a penny. And how much would it cost to basically set up a payment system? Now, of course, some of the people who are representing the authors and the artists and so forth, they want billions. Right.
00:36:18.154 - 00:36:38.814, Speaker A: But, you know, there has to be some middle ground. And, you know, are you going to set up an international agency? How do you kind of, you see what I'm saying? The practical anyway. If you think it's a good idea, go for it.
00:36:39.674 - 00:36:51.934, Speaker D: Can I ask a quick question? So you mentioned billions. But if AI is going to be a substantial fraction of the economy in 510 years, shouldn't it be trillions?
00:36:52.914 - 00:38:03.478, Speaker A: Well, so there are lots of issues out there, and the question of whether or not some of the companies that are making AI technologies should provide some support for other sectors of the world, including people. I think there's a good argument for that. But I do think that right now, copyright is the name of the game. And copyright is not about protecting the livelihoods of individual creators. Okay? That's just not what we're about. It's a limited monopoly that's intended to do a certain job, which is create incentives for people to invest in making new things and sharing them with the world. And so when courts are asked to use copyright to protect privacy or to protect against defamation or other things, basically the courts basically say out, you have to be harmed in the way that copyright law concerned is concerned with.
00:38:03.478 - 00:38:51.908, Speaker A: Right. And so these larger considerations about sort of the future of work and so forth, really super important, but it's not copyright's job to solve them. Okay. So in some sense, what we have is this is the tool right now that's out there that could have a substantial impact. And the question is, should we be thinking about a larger governance framework? And I think, yeah, the answer to that is yes. But in the meantime, copyright has just got to do its job. And so that's part of what I'm struggling with is try to sort of say, you know, what can copyright law do and what copyright law can't do? And so collective license is one of those ideas out there that some people are very fond of.
00:38:51.908 - 00:40:06.544, Speaker A: So I've sort of been giving you reasons to doubt the doubt, the fair use, but there are these kind of countervailing considerations. So in general, people who are developing these systems are not interested in the expression, in the work. They're interested in the works of data. And essentially, as I understand it, essentially the documents are bags of words and raw material for certain kinds of computational uses that will then allow you to sort of get some inferences that you wouldn't be able to get otherwise. And lots of things that are contained in copyrighted works are not within the scope of protection that copyright law provides. And insofar as the generative AI enables creative things to happen, you could say that's consistent with the constitutional purpose of copyright. And one of the other things that fair use is said to do is provide some breathing, so you don't want to give so many rights to the first generation copyright owner, so that it basically squelches the ability of people to build on existing work.
00:40:06.544 - 00:41:07.654, Speaker A: So the kind of the breathing space is another one of the kind of memes in copyright land. So what is expression in a work? Obviously the sequences of words and texts and so forth. So, but there's also kind of what is called kind of the structure of work sometimes can be protected. And so infringement happens when a defendant's work is substantially similar in expression and that the defendant improperly appropriated that expression from the copyrighted work. And sometimes you kind of do a kind of lay observer. What would a lay observer think? And now I'm going to give you some images. So here is an example of Sol Steinberg's poster, familiar to many of us, and Columbia pictures decided to use poster.
00:41:07.654 - 00:41:54.766, Speaker A: And you can see that there are lots of differences between the Steinberg poster and this one, but there are a lot of similarities, too. And the trial judge decided that actually it was substantially similar enough to be an infringement of the Steinberg poster. I think another consideration is this is a motion picture company. They're used to clearing rights. If they wanted to use the Steinberg's poster, they should have paid for it. Right? And so there was kind of, this is a derivative work of the poster. And so the court decided that that was an infringement.
00:41:54.766 - 00:42:33.634, Speaker A: But what I was trying to say here is some works, especially artistic and fancy ones, are highly expressive. They have lots and lots of expression in them and not very much unprotectable stuff. Other works have a smaller amount of expression in them and contain a lot more unprotectable stuff. And so they have a thinner scope of copyright. And part of what courts try to do is filter out the unprotectables before they make a decision about infringement. So here is an example. Here's a list of the unprotectable elements in copyrighted works.
00:42:33.634 - 00:43:38.280, Speaker A: And here's an example of a case where it mattered. So Ho and Tavloff were both engineering professors at Northwestern, and a graduate student named Chang worked first for Ho. And during the time he was there, Ho developed a new mathematical model of how electrons behave under certain circumstances. Chang then went to work for tableau and Tableau and Chang published a paper and a book chapter about the model and used equations, figures, text from Ho's writings. And ho's paper was rejected about the model because it had been preempted by the tableau paper. So you can see from the standpoint of academic misconduct, this is, you know, Tablov is a creep, but was tabloff? Did Tablov infringe copyright? Well, I brought the lawsuit. You copied my equations.
00:43:38.280 - 00:44:32.792, Speaker A: My equations are really, really creative. Took a lot of effort and took a lot of, you know, intellectual effort and blah, blah, blah. But guess what? Model was an idea. And the equations and the figures and other things that were used in the tabloc paper were the only practical ways to express the model's idea. And under one of the prominent Supreme Court precedents, Baker B. Selden court said, not protected by copyright law. So here's the famous statement, and I'm giving you this because this actually has some relevance to generative AI stuff, right? The copyright of a work on mathematical science cannot give the author an exclusive right to the methods of operation which he propounds or the diagrams he employs to explain them so as to prevent an engineer from using them whenever the occasion required.
00:44:32.792 - 00:45:10.052, Speaker A: The very object of a book on science is to communicate to the world the useful knowledge it contains. But this object would be frustrated if the knowledge could not be used without incurring the guilt for piracy of the book. And where an art it teaches can't be used without employing the methods. The methods and the diagrams are necessary incidents to the art and given therewith to the public. Okay, so this is, again a statement that kind of is pithy about sort of what copyright does and doesn't protect and wants. Yeah.
00:45:10.188 - 00:45:24.192, Speaker C: Could you explain how this is different from the New Yorker cover, which also seems like it's the idea of this, of this map of the world that is being taken. How is that not the thing that's here?
00:45:24.348 - 00:45:56.104, Speaker A: So copyright is really, really, really important to say that methods aren't protected. Right? So artistic stuff. Right? Saul Steinberg's kind of like, conception is artistic, but it's an idea, it's artistic. And courts give a broader scope of copyright protection to things that are artistic. Okay. When it comes to this stuff, okay. You don't need to use the Sol Steinberg thing.
00:45:56.104 - 00:46:15.752, Speaker A: Right. If you want to write about the mathematical model in the Ho versus Taflock case, you got to be able to use the stuff. The science is basically not going to advance if. Oh, I can't. I can't talk about this thing, or I have to, like, I have to say it completely differently. Well, that doesn't make any sense. Right.
00:46:15.752 - 00:46:31.722, Speaker A: So the courts have been very clear that this kind of stuff and facts, theories, all kinds of things, unprotected by copyright law. The more you're in a nonfiction space, the more, the thinner the scope of the copyright.
00:46:31.818 - 00:46:34.066, Speaker C: So equations aren't artistic?
00:46:34.170 - 00:46:34.746, Speaker A: What?
00:46:34.890 - 00:46:39.186, Speaker C: Equations are not artistic from a standpoint of copyright law?
00:46:39.250 - 00:46:53.106, Speaker A: Absolutely not. So the fact that you guys think they're beautiful, I don't. You know, I think that's great. Okay. But I just tell you, we're in copyright land right now, okay?
00:46:53.250 - 00:46:56.694, Speaker F: And copyright land is a different space, so. Yes.
00:46:57.274 - 00:46:57.650, Speaker A: Yeah.
00:46:57.682 - 00:47:19.494, Speaker F: There was actually a fight in the Google versus Oracle case about a statement that I think it was Joshua Block made about how artistic the design of the Java API was, and boy, did Oracle try to melt that one for all it's worth. And the court basically didn't buy.
00:47:21.754 - 00:47:35.414, Speaker C: So in this case, if Ho had used some artistic rendition to better communicate his ideas, that would be more likely to be protected under copyright rather than the equations that are literally useful for describing them. Is that the idea here?
00:47:35.774 - 00:47:38.590, Speaker A: Yeah. I mean, again, there are sometimes little.
00:47:38.622 - 00:48:12.264, Speaker F: Blurry lines, but when you're talking about equations, equations are basically way outside the scope of copyright. Okay. And figures. Little more iffy text, a little more iffy. But the court will basically say, did you really need to use this in order to express the idea? And in that particular case, all the stuff that was said to be the basis of infringement was stuff that the court said was unprotected by copyright law. Okay. I'm going to actually go on because I'm seeing that the hour is going.
00:48:12.264 - 00:49:00.134, Speaker F: So can generative AI infringe the derivative work? Right? The answer is yes. This is the way that the term derivative work is defined in the statute. A work based on one or more pre existing work. And then it gives a set of nine examples, and I've given you a few of them here, translations, musical arrangements, condensation, motion picture version, etcetera, or any other form in which a work may be recast, transformed, or adapted. So it's not enough for something to be based upon. It has to have drawn some expression from the first work and used it in the second work. Okay, so can they infringe? The answer is yes.
00:49:00.134 - 00:50:30.144, Speaker F: These are examples of images that were put into mid journey, and I want Snoopy with Christmas decorations and the little doghouse. And this is what you get Snoopy is artistic and therefore gets a broad scope of protection. So these could potentially infringe. But then the question is, who's the infringer? Right? So in general, there's a distinction in copyright between a direct and an indirect infringer, right? If I make a copy of something, then I'm going to be the direct infringer. But sometimes a third party can be held if they have the right and ability to control the infringing conduct and they enjoy a financial benefit from the infringement. And several of the generative AI lawsuits are claiming that these systems are indirect infringers. The defendants in these cases are looking to the Sony, Betamax and the Groxster decisions by the Supreme Court, which have held that a technology developer is not an indirect infringer if it makes and sells technology that has substantial non infringing uses.
00:50:30.564 - 00:50:31.212, Speaker A: Okay?
00:50:31.308 - 00:51:15.116, Speaker F: So even if you know that some people are going to use it to infringe, the public has a right to get access to the technology for its non infringing uses. So that's an important consideration. And so you could say that when it comes to the snoopy thing, the people who put, who asked for the snoopy thing, their direct infringers. And if midjourney didn't kind of find the system in order to like, make these infringing copies, somebody just used it for infringing purposes. They may be able to say, hey, Sony Betamax, I have a technology that's a non infringing use, okay? There can be a link between the.
00:51:15.180 - 00:51:16.540, Speaker A: Input and the output.
00:51:16.692 - 00:52:21.340, Speaker F: So if outputs infringe the derivative work, right, that might affect how courts feel about the ingestion issue. And so there's a case that was about accolade made video games. It wanted those games to run on a Sega platform. In order to be able to do that, it reverse engineered the code to get access to interface information. It then re implemented the interface in non infringing code. And Sega sued for infringement, not based on the video games, as they were, as they were sold in the market, but based on the reverse engineering. And the court decided that was that because the interface was not protectable by copyright law, it was not part of the works expression, it was part of the works unprotectable elements, then the reverse engineering to get access to that interface information was lawful.
00:52:21.340 - 00:53:20.070, Speaker F: But the court sort of implied that if they gone in to try to get some expression from the program and then reimplemented that that might make the reverse engineering not fair. Okay, so that's just another one of the kind of things that are out there. And. But I think in general, text, images, and other things that get generated in response to user prompts are not going to be substantially similar in expression the way that copyright law cares about. And insofar as that's true, then the outputs are unlikely to infringe the derivative work, right? And the Anderson case basically makes the claim that all outputs of stable diffusion are infringing derivatives because they're all based upon the training data. And the court threw that out, said, no, you got to have substantial similarity in expression. So here's the output.
00:53:20.070 - 00:54:15.692, Speaker F: If I can match expression from that output to particular inputs, then I can make a derivative work claim, but otherwise not okay. And one complaint, and the complaint against GitHub, there's a mention of a study that found copilot suggests code matching training data in 1% of the outputs. I think 1% is probably pretty small, but it's one of those things that courts are going to have to take into example or take into consideration. Getty basically put this image in its complaint, claiming that this is substantially similar. Now, I think you can say there is some substantial similarity between these two things, but not in the expression. It's not enough that they're both basically soccer games. It's not enough that the crowd is back in the background.
00:54:15.692 - 00:54:47.914, Speaker F: It's not enough that you have the two people. Basically what's expressive is the particular details of how the work was composed. Okay. And this was composed sufficiently differently, I think, that courts would never find this to be an infringement. Okay. But this is the closest they would, they were able to come. But you can imagine that the lawyers worked really, really hard with the technologists to find as close a match as they possibly could.
00:54:48.974 - 00:54:50.834, Speaker C: But what about the watermark?
00:54:51.254 - 00:56:01.224, Speaker F: Hold on, hold on. Geez. Okay, so now we get to the things about the watermarks. Okay, so 1202, I mentioned 1202 before intentionally removing or altering copyright management information, knowing that the removal or alteration can facilitate copyright infringement. That's illegal. Congress passed this law in 1998 at a time when there was concern that what would happen is, as the kind of the digital market for copyrighted goods got going, that people would put these little watermarks on with copyright management information in it, and basically then hackers would be out there and would take it out and then substitute copyright management information that was false in order to basically then try to sell the thing, the counterfeit thing, as though they're the copyright owner, or hackers might just liberate them, pretend that they're in the public domain. And so that's the concern that gave rise to this particular legislation.
00:56:01.224 - 00:56:52.584, Speaker F: And the court recognized that it would be difficult to measure actual damages for the removal or alteration of the copyright management information. So they created a statutory damage regime for it so that every violation starts with a minimum of $2,500. Statutory damage goes up to $25,000 per violation. And the complaint against GitHub uses the 1202 claims. Right. So 5 billion lines of open source code were used to train codex. So how many violations might that be? Well, you get to $9 billion pretty quickly if you say that each one of those had copyright management information removed and that facilitated copyright infringement.
00:56:52.584 - 00:58:15.516, Speaker F: So back to this case. So you can see the Getty Images logo here, that's the Getty photograph, and you can see the mangled stuff here. Okay, so this kind of looks like alteration of copyright management information. So again, stable diffusion may be in greater, or stability may be in greater risk of liability than the others, but the copyright management information claims are in many of the complaints anyway, the point here is that Generative AI is not the first disruptive technology to have been sued for facilitating unauthorized uses of copyrighted works. Video cassette recorders, MP3 players, and dvrs were also sued, and they all essentially got off because the technologies had substantial non infringing uses. Now, just because it's a technology doesn't mean necessarily that it's going to be okay because Groxter and Napster, for example, were held liable because they induced infringers to use them. And so what we have to say is the current copyright litigation is very early stages.
00:58:15.516 - 00:59:04.454, Speaker F: I don't happen to find the derivative work or 1202 claims persuasive, but the training data ingestion issue is what I, when I, and when I gave a talk at the ICML conference, I call this the big Kahuna. This is the one that I think poses the greatest challenge. But again, to repeat, you guys really need to get your act together and submit things to the copyright office in response to that notice of inquiry because I know people who are going to submit comments and you wouldn't agree with those comments. So you want to make sure that your voices are heard in this whole thing. And again, I'm sorry, I've gone over a little bit, but, but I think I answered a bunch of questions.
00:59:10.794 - 00:59:11.370, Speaker C: Actually.
00:59:11.482 - 00:59:14.334, Speaker A: Even though we have like 15 minutes.
00:59:15.314 - 00:59:17.754, Speaker B: Schedules questions, and then we'll have the panel.
00:59:17.914 - 00:59:21.706, Speaker A: Yeah, yeah.
00:59:21.730 - 01:00:07.534, Speaker D: First, thanks for wonderful talk. I wanted to ask a somewhat different question, which is, you know, you spoke about the copyright law as it is and what its implications are for llms. But could you say a little bit about how copyright law should be re imagined in the, you know, in the face of llms, in the sense that, at least from my naive viewpoint, copyright law is intended to make it possible for people to put their creations out there in a way that, you know, and it's for society's benefit. And so if you were to reimagine, what would it look like once we have llms? And, you know, how should, how should the law be rewritten to make sure.
01:00:07.574 - 01:01:40.334, Speaker F: That there's another, there's another kind of legal issue that lots of people are exercised about and that I wrote something about in 1985, that is, who, if anybody, owns the outputs of AI generated stuff. And the copyright Office official position right now is that no copyright, because there's no human author and the fact that somebody programmed, it's not enough. The output is not the expression of an author and therefore not protectable. And so now if you create a work and you try to register a claim of copyright in it, and it contains AI generated stuff, the copyright Office actually requires you to disclose that this image or this text actually was generated by the AI system, and you have to disclaim authorship. Back in the 1980s, the last time, there was a big kind of like push in AI, and everybody was excited and the copyright people started getting excited. And that's why I wrote this paper. UK basically passed what lawyers call a sui generis, an of its own kind law.
01:01:40.334 - 01:03:09.194, Speaker F: It's kind of a little mini copyright for AI generated stuff. And so the UK actually has a law in place now there will be talk of trying to do something like that, and there are also people trying to say, hey, you know, this, this image that I just created, I used this set of prompts. So in fact, I so carefully developed it that in fact I'm the author and a person named Chris Kashanova is trying to get copyright registration based on that. Now, that particular issue is also in litigation. The copyright office, I think, is going to be upheld in its position. What would we do if we were doing a blank slate? I'm not sure. This actually sounds to me like something where it would be a good idea to get a lot of smart people together and talk about it and think about sort of going forward, what do we imagine the scenarios to be and what would be a good way for copyright law to evolve? And are there other things that, you know, there are other governance frameworks that we should be thinking about, I think right now the kind of the AI governance thing is over here and copyright is over here.
01:03:09.194 - 01:03:48.454, Speaker F: I think they actually have something to do with each other. And so, but again, we only have this one tool right now, which is copyright. And so that's the tool that the courts will have to. And the thing is that a court can't say, well, this is like too complicated, go away. If the complaint is filed and the case doesn't get dismissed outright, judge doesn't have any choice, has to decide the case. Okay. It's just the way the world works.
01:03:48.754 - 01:03:50.922, Speaker C: Did you have a little follow up.
01:03:51.058 - 01:04:22.320, Speaker E: A little follow on comment to that? I mean, I think because this follow on to how might you reimagine copyright? Because, I mean, I think in the 21st century world, it's not only generative AI over here, I think there's also every young person. Right. That there's this kind of new, how young people think, where what you do is you take copyrighted works and you do mashups. You put various kinds of filters over them and you post them on TikTok.
01:04:22.392 - 01:04:22.816, Speaker F: Right?
01:04:22.920 - 01:04:38.828, Speaker E: So, like, generating derivative works is sort of the new culture. And so it sort of seems in some sense that's in the same space as what generative AI is doing, but human done, which again, sort of suggests, like, maybe we do need a new basis.
01:04:38.916 - 01:04:39.204, Speaker A: Yeah.
01:04:39.244 - 01:05:14.348, Speaker F: Well, so what has happened in the digital world is that copyright law has had to kind of just get a grip. And so, you know, would the, would the, kind of the big content owners, would they like to be able to control the entire space? The answer is yes, but they basically say, okay, I don't really like fan fiction. But you know what? Fan fiction actually builds a fan base. And maybe I should just relax about that. And what I should focus on more is the people who are counterfeiters.
01:05:14.396 - 01:05:14.604, Speaker A: Right?
01:05:14.644 - 01:06:06.370, Speaker F: And so the, the law has had to get more flexible because otherwise we'd be throwing everybody in jail. And so peer to peer file sharing, another example is like, millions and millions of people did it. It's kind of illegal, but, you know, nobody went to jail for it. You know, there were a couple of lawsuits about it, but not very many. And, you know, somehow what happens, of course, is that the market economy basically took care of it. Right. When you have things like Spotify and Apple Music and so forth, you know, it's less risky if you use one of these services and they're sensibly priced.
01:06:06.370 - 01:06:25.712, Speaker F: You know, the only reason Apple was able to get into this market was because of peer to peer file sharing. Hey, why don't you guys want to make a little bit of money here? And so, but the pricing and the way that it was structured is definitely the result of the peer to peer file sharing.
01:06:25.768 - 01:06:26.404, Speaker A: Sorry.
01:06:34.024 - 01:06:56.224, Speaker D: I have a question about the difference between use of data in the training or work in the training data and generating some output. So if we know that there's some copyrighted work in the training data, but we could prove maybe empirically or mathematically that it's not used in a particular generation of an output, are we kind of safe?
01:06:56.884 - 01:06:57.664, Speaker A: Yeah.
01:06:58.764 - 01:07:00.264, Speaker F: The truth is that the.
01:07:03.484 - 01:07:04.512, Speaker A: Core courts.
01:07:04.608 - 01:07:49.014, Speaker F: Don'T understand the technology. They really don't. So one of the things that people in your field are going to have to get good at is translating of what is going on under the hood so that the courts basically don't say, oh, here's the training data and here's the output, and, oh, there's some similarities here. Therefore there must be infringing derivative work. So the stuff under the hood is the stuff that, as you suggest, may in fact be very useful to say, hey, this in fact is not, is not an infringement because I can prove it mathematically. And, you know, courses kind of like math. So I think that would probably work.
01:07:50.634 - 01:07:51.130, Speaker A: Yeah.
01:07:51.202 - 01:07:57.064, Speaker G: With this point about how equations can't be artistic, I'm wondering. I'm wondering if there's something deep here.
01:07:57.104 - 01:07:57.384, Speaker A: Okay.
01:07:57.424 - 01:08:28.950, Speaker G: So I once had a student who cheated on an exam, right? And I brought it to the dean. And like, here you see the two answers? You see that they're like word for word, the same, you know, except the variable names, right? And I got back a very interesting answer, which is, well, this is a math problem. Of course there's only one right answer. And, you know, I had to explain, okay, but, you know, there are exponentially many different ways of expressing, you know, what the true answer is. So, you know, in this hoe case that you talked about, like, was it actually a word for word copy?
01:08:29.102 - 01:08:56.154, Speaker F: No, it was the. I mean, the equations were exact and the figures, as I understand it, were exact. But I don't know enough about what the text was. But I would guess that probably tableau is smart enough to not use exactly the same words. Okay. But paraphrasing can also be an infringement.
01:08:57.094 - 01:09:00.966, Speaker A: Okay, one more question, and then, I'm.
01:09:00.990 - 01:09:21.865, Speaker D: Sorry if this is a repeat of a question, let's say you're really, really good at prompt engineering, putting in many, I would just say, artistic elements to how to ask your AI to do something. But that, because it's generated by AI that would not be copyrighted at this point.
01:09:22.009 - 01:09:22.729, Speaker F: At this point.
01:09:22.801 - 01:09:23.153, Speaker A: Yeah.
01:09:23.233 - 01:09:24.721, Speaker D: Okay. Thank you.
01:09:24.777 - 01:10:08.764, Speaker F: I mean, as I said, Chris Kashanova has essentially been trying to make the case that this long series of prompts yielded what, in fact, was her vision of the work. And the court sort of, the copyright office basically said no. But there's kind of a recognition that maybe. Right. So Cashonova is trying again. And so we'll see what happens with that. The copyright office is just going to have to make a lot of very, very fine, detailed distinctions between this thing and that thing.
01:10:10.724 - 01:10:18.364, Speaker A: Okay. We're going to move on to a panel, please. The panelists take a seat. What.

00:00:01.680 - 00:00:32.178, Speaker A: All right, thanks everyone. So yeah, I'm going to talk about robustness and separation in multidimensional screening. If you're not familiar with this terminology, I'll say multi dimensional, or you can mentally replace it with multidimensional mechanism design. It's exactly the same thing. So the place that I'd like to start from is the observation that multidimensional mechanism design is hard. Right. I think this is something that's familiar to all of us.
00:00:32.178 - 00:01:43.954, Speaker A: So with one dimension, say you're a monopolist and you're selling a single good to a buyer with quasi linear utility, we have a very nice solution to the optimal mechanism problem. Right, so you're trying to sell, I don't know, wireless clickers. You could come up with all kinds of complicated interactions with the buyer involving multiple rounds and randomization, but the best thing to do is simply post a single price, whereas when there is more than one good, all hell breaks loose. And we know that even when there is just two goods, even when the buyer's values for the two goods are independently distributed, and even when there is no complementarity. So the value for getting the wireless clicker and the sunglasses is the same as the value for the clicker plus the value for the sunglasses. Christos, just now at the beginning of his talk, mentioned a few of the examples of bizarre behavior that can occur, maybe bizarre, or maybe just maybe exciting, depending on your perspective. So very often the optimal mechanism involves bundling and not just selling the two goods together, but selling each good with some probability that's strictly between zero and one, at some price.
00:01:43.954 - 00:02:30.968, Speaker A: You might in fact want to offer infinitely many probabilistic bundles at different prices and let the buyer choose among them. And we have other examples of ways in which this problem maybe behaves. Surprisingly so. For example, the optimal revenue can be non monotone in the value distribution. It can happen that the buyer's values for all goods go up and yet your maximal revenue actually goes down. So these things. For an economist interested in multidimensional screening, these things are frustrating because it's an important problem we'd like to be able to have simple models to work with, right? So basically, any kind of screening problem you could think of, it's naturally formulated in a way where there might reasonably be multiple parameters affecting someone's preferences.
00:02:30.968 - 00:03:32.824, Speaker A: So monopoly sales is a canonical example that we often look at. But you can think about regulation of monopoly, say, Baron Meyerson, or you can think about a taxation problem where, say, people can produce different amounts of income at different cost of effort by choosing different jobs. Maybe a person has several jobs, or you can think about dynamic taxation over multiple periods. You can think about the problem of designing an insurance policy where somebody might privately know how vulnerable they are to different kinds of losses, or how vulnerable they are to different kinds of diseases, say, and there are lots of diseases out there. So you probably have multiple dimensions of private information. So in order to be able to be able to think about these kinds of applications, we'd really like to have a tractable way of modeling multidimensional screening problems. So what I'm going to talk about is a general but bland model end result.
00:03:32.824 - 00:04:28.894, Speaker A: So I'm going to describe a model where there are no interactions between the different goods that are being sold, either in terms of information that you, the seller, have about them, or in terms of the buyer's preferences. And the result, unlike most of the classic bundling models, is that you also want to sell the goods separately. So I think this is maybe in terms of multi dimensional mechanism design model. This is sort of the most boring one that you could ask for, but my hope is that this can be a base on which future work can build. So here is the idea of the model. You're a seller selling several goods, and you don't actually have a prior joint distribution over the buyer's value for, say, the wireless clicker and the sunglasses. You only know the distribution of values for the clicker and the distribution of values for the sunglasses separately, but you don't know how these are correlated with each other.
00:04:28.894 - 00:05:07.788, Speaker A: And you want a mechanism that is robust to this uncertainty. You evaluate any mechanism in terms of its worst case guarantee on your expected revenue. And so the result is that it's optimal to sell the goods separately. So in this case, you would post a price for the clicker and the buyer can buy or not at that price, and you separately post the optimal price for the sunglasses. This result is hopefully not surprising when stated. It's fairly intuitive, because you're solving a max min problem, right, if you like. Your adversary is nature, choosing the joint distribution overvalues for the goods.
00:05:07.788 - 00:05:31.904, Speaker A: And we know the solutions to max min problems tend to be things that equalize your payoff against lots of things that your adversary can do. And in this case, by selling the goods separately, you equalize your payoff across all possible joint distributions because, well, your profit from selling the wireless clicker depends only on the marginal distribution of values for the clicker, and your profit from the sunglasses depends only on that marginal.
00:05:33.074 - 00:05:39.218, Speaker B: Does that also imply that there is a single distribution which leads to the separate selling is optimal.
00:05:39.306 - 00:06:27.184, Speaker A: Yeah, we'll get there. So I would like to have a proof of the statement that builds directly on this observation that it equalizes your payoff against all the distributions. I have not found a proof that builds directly on this. So the actual proof that I'll outline towards the end of the talk in the last four or five minutes is a bit more complicated. But first I'll try to argue for why there is not a more obvious proof. But basically the lesson of this result is if you don't know enough to see how to bundle the goods, then you shouldn't bundle them. I stated the results so far in terms of a monopolist selling several goods, but actually the result is much more general.
00:06:27.184 - 00:07:14.256, Speaker A: So really it says that if you have an agent who has k dimensions of private information, or I should say pieces of private information, because I don't want to even think of each piece as necessarily one dimensional k pieces of private information. And for each piece you're supposed to choose a corresponding allocation. And the agent's preferences are additively separable across the k allocation problems. And he's quasi linear. So preferences are the sum minus minus a payment. Or generally, if you know the marginal distribution of each, of each type, each theta, but you don't know how they're correlated, and you have a worst case objective with respect to this, then the optimal thing to do is solve each of the k problems separately. Can I ask a quick question for you? Oh yeah.
00:07:14.256 - 00:08:10.236, Speaker A: Is it uniquely optimal to sell them separately or. There are some mechanisms that do just as well in the worst case, but, but sometimes it do better. So for the cases that I have looked into, which is where you're selling a bunch of goods and there's a finite type distribution for each good, then so generically it's uniquely optimal up to the possible cases where there might be several prices you're indifferent over. I don't know about the fully general problem. Okay, here is a related literature slide that everybody hates. This is related to several strands of work, particularly work on multidimensional screening, which many people in this room have contributed to. So there are several lines of work, the work showing that simple mechanisms are optimal or are approximately optimal.
00:08:10.236 - 00:08:33.170, Speaker A: And I think of this being particularly in that vein. So I've already sketched out the model. I'll describe it in full detail to make sure that hopefully no ambiguity. So the constituent parts of our problem are these things called screening problems. So this is a classic textbook mechanism. Design problem. It consists of four parts.
00:08:33.170 - 00:09:17.006, Speaker A: There are the space of types that your agent might have. There's a space of allocations you can choose. The agent has a payoff for each type, for each allocation that depends on his type, and you have a prior over types and a mechanism which I'll assume throughout can be probabilistic, specifies for each possible type a distribution over allocations and a transfer. And it has to satisfy the usual IC and IR constraints. So in such a screening problem you have a prior over types. Your objective is to maximize the expected payment of the agent. So what I'm interested here is a joint problem that is composed of several of these component problems.
00:09:17.006 - 00:09:45.614, Speaker A: So you're selling several goods. Each good gives you a component problem. Selling them together is a joint problem. So in the joint screening environment the agent's type is type space, is the product of the component type spaces. So the type specifies the value for each good, say allocation space. Similarly, the product of the separate allocation spaces and the payoff function is just assumed to have this additively separable form. The only thing is that you don't have a prior over types in this environment.
00:09:45.614 - 00:11:15.514, Speaker A: The joint screening mechanism specifies probabilistic allocation and a payment for each type. And there are appropriate versions of the IC and IR constraints that this should satisfy. And the allocation and the payment can depend on the entire type, right? So there is no presumption that the x one allocation depends only on type, theta one and so forth. Why is it delta piece by piece? All right, so because of the additively separable preferences, right? So in principle you could, you, your mechanism could be distribution over the whole allocation this big x, but it's enough to consider randomizing over each component independently because of separability, okay? So when you have any mechanism, you'll evaluate it by the worst possible expected profit over all joint distributions on the type space that have the given marginals. So one thing you can do is for each component you can apply the optimal mechanism for that component by itself and the agent's payment will just be the sum of the payments in each of those mechanisms. And I'll write r star one for the optimal mechanism, revenue in component one, r star two and so forth, and just r for the sum of those. So the separate screening mechanism gives you profit of r star no matter what the joint distribution is.
00:11:15.514 - 00:11:56.964, Speaker A: And the result is that you can't guarantee more than that. So talk about applications. So selling several goods, for example, clickers and sunglasses, your theta k, your type for good k, is just your value for the good, and the allocations are either you get the good or you don't get it. But I'm allowing probabilistic mechanisms. And so mechanisms in principle can specify probability of getting each good as a function of your whole type. And we know that the single good optimal mechanism is just a posted price. And so, theorem says, in this setting, this robust setting, the optimal way of selling all the goods is just post a price for each one.
00:11:56.964 - 00:12:45.344, Speaker A: You want to make this a little more complex, you can think about non linear monopoly problems. So something like Mussoor's in quality choice or quantity choice, allocating continuous quantities, where the agent's preference over quantity, say, is parameterized by his type theta k. And so in general, then within each component problem, for each good, the optimal mechanism would not be a single posted price. Instead it would be a menu of quantities that the agent could get at different prices. Usually when we write down these models, we make some assumptions to simplify the problem. So we'll assume the space of possible preference types is one dimensional, and there's some kind of single crossing or supermodularity condition in the preference, in the payoff function. We don't actually need any of these assumptions for the theorem to apply.
00:12:45.344 - 00:13:35.094, Speaker A: So these assumptions help us explicitly solve for the optimal mechanism. But even without knowing these, even without these assumptions, it's still true that the robust optimal mechanism for selling several goods is just to use the optimal menu for each good separately. And I don't want to say this is a theorem only about monopolists selling multiple goods. So there are other applications. For example, there is a discussion in the paper about application to a merely style optimal taxation problem, where you can interpret the multiple component problems either as an agent's income from different jobs that he could do, or income in several different time periods. But I won't talk about that here for reasons of time. So, before I talk about the proof of the theorem, I should describe some ways you might try to prove this that don't work.
00:13:35.094 - 00:14:32.150, Speaker A: So the proof is going to be exactly what Noam suggested. There will actually be a particular worst case distribution such that you can't get more than r from any mechanism. And so the strategy is going to be to find that distribution. So the first thing you might try is just have the different components of type be independent of each other, right? So if you're, if you, you're selling several separate goods, there's no interaction in preferences across the goods, and there's no informational interaction because these values are independently distributed. Then you would want to sell the goods separately, right? As we know, this doesn't work. So Christos just now showed us an example where you have two goods and values, one or two for both. Another way to see this fails is if you have a large number of goods and the values are IId, then by the law of large numbers, you know almost certainly what the value for the grand bundle is.
00:14:32.150 - 00:15:18.016, Speaker A: And so you can extract almost all the surplus by selling the bundle. In fact, the independent distributions basically never work. So, McAfee, McMillan and Winston had a paper where they made this observation very cleanly. If you were to start by selling each good at the optimal posted price, and then you offer an epsilon discount for just the bundle of all goods, you can see by the first order condition that a small epsilon discount actually improves your profit. Okay, so the independent distribution doesn't work. Here's another thing that you might try. So, for inspiration, actually think about the special case where there are, where you're selling k goods and the marginal distribution of values for each good are all the same.
00:15:18.016 - 00:16:10.746, Speaker A: So you know that the distribution of values for the clicker and for the sunglasses are identical. Well, one natural joint distribution you could imagine is one where the consumer is just distributed along the diagonal in this value space. And so his value for the clicker and the sunglasses are equal. That reduces this whole joint problem to a one dimensional problem. And it's clear that the optimal thing to do is to sell the whole bundle at k times the single posted price. But that's the same as in this case, as just selling each good separately at the posted price. So you might try to generalize this now and say, well, what about if the marginal distributions are not all identical? So one way to try to generalize this is by having the values for the different goods be as positively correlated as possible.
00:16:10.746 - 00:16:57.874, Speaker A: So imagine that the value for the goods are jointly distributed along some upward sloping curve in the value space. That happens to give you the correct marginal on good one and on good two. So there is a couple of problems with this. One is that when we try to get to the general theorem where you're not just selling goods, but each of your component problems is some abstract mechanism design problem, it's not really clear how to do this, because then for each component problem, the types are not necessarily ordered. But even in the particular application of a monopolist selling k goods, this doesn't always work. It sometimes works. But let me show you a counter example.
00:16:57.874 - 00:17:31.864, Speaker A: So here is a counterexample. So there's two goods good one and good two. For good one, the buyer could have value either one or two, with probability a half each. And for good two, the probability, the values could be two three or four, with probabilities one third, one 6th, or one two. These are equal revenue distributions. So for good one, you can price either at one or at two, and either way your profit will be one. For good two, you could price either at two, three or four, and either way your profit will be two.
00:17:31.864 - 00:18:10.964, Speaker A: And so in this case, if you sell the goods separately, your total revenue is three three. So if you take this, this comonctonic distribution, the distribution for which the values are as positively correlated as possible, this is what it looks like. So there's a math point on values, one, comma, two of size 1313 of size one six and two four of size one two. And I claim that this distribution doesn't hold you down to a revenue of three. So I claim you can do strictly better than three with this distribution. And here is a way to do it. In fact, here is the optimal mechanism for this case.
00:18:10.964 - 00:19:15.320, Speaker A: You allow the buyer to buy either good one at a price of one or good two at a price of three or both goods. But to buy both goods, you have to pay an extra premium, you have to pay five. If you do this, then it's incentive compatible for the low type of buyer to buy just good one, middle type to buy just good two, and the high type to buy both goods. And you calculate your revenue in this case, and it is ten three, which is more than the three you get from selling them separately. So what's going on here in this example? Can we relate this to our usual intuition about one dimensional mechanism design and see what goes wrong? Well, one thing to notice here is that this mechanism is not monotone for each good separately. So the low type of buyer and the high type of buyer are both getting good one, but the middle type isn't. And so basically, there is a kind of aggregate monotonicity constraint that holds in a multi dimensional setting, but it's not as strong as requiring monotonicity for each good separately.
00:19:15.320 - 00:20:03.994, Speaker A: And so that relaxation of monotonicity allows us to charge an extra premium for the incremental good two that the high type is getting, thereby making a profit of more than $2 on that good. So I claim that there is some particular distribution that does in fact guarantee you can't get more than three revenue. So here is the distribution in this example. It's not the only one, but it's the one that is calculated by the algorithm that I'll quickly sketch. And I don't understand what this distribution is. So if these numbers are meaningful to you, I would love to hear from you. Okay, so now I'll quickly sketch how the actual proof works.
00:20:03.994 - 00:21:21.784, Speaker A: So I'll prove just the finite version of the theorem where the type spaces are finite and the allocation spaces are finite and they're, this extends to the continuous case just by a straightforward approximation argument. So basically the proof is by LP duality. So write each of the component screening problems as a linear program. And if we know that in screening problem number five you can't get more revenue than r five, then there exists dual variables that certify that there exist multipliers on each of the constraints, such that when you multiply the constraints and then you add them up, you get an inequality that says Tada, any mechanism won't give you revenue more than r five. So I would like to simultaneously, well, I would like to construct multipliers for the joint screening program to prove the same thing, but I don't know what the joint distribution is, so I'm going to have to show this for some particular distribution that we construct. And so the trick is we'll construct the distribution and the multipliers for the joint problem at the same time. At the end we have to check that everything is non negative, both the multiplier, then the probabilities, and check that the joint distribution we constructed really is a joint distribution with the marginals it's supposed to have.
00:21:21.784 - 00:22:30.404, Speaker A: Now, there are quite a lot of constraints in the joint screening problem because you have this big multidimensional space of types, and in principle any type could, could misrepresent as being any other type. So actually look at a relaxed problem where we only use a subset of the constraints. And which constraints will I use? I'll use just the ones where a type considers misrepresenting one component of the type and all the other components are reported truthfully. And moreover, I'll use only the constraints that correspond to constraints that were binding in the individual component problem. So for example, if this horizontal axis represents component problem number one, so these five dots are types in that component problem. These blue arrows represent incentive constraints that are binding at the optimal solution here, and the red arrows represent participation constraints that are binding at the optimal solution. And similarly for problem two here on the vertical axis here is my space of joint types in the joint screening problem.
00:22:30.404 - 00:23:29.498, Speaker A: And I'm going to use just these incentive and participation constraints. So the incentive constraints are the horizontal arrows that correspond to these and the vertical arrows that correspond to these. And for the participation constraints, I'll use only the ones for the types where the participation constraint binds in every component simultaneously. And it makes sense that I would look only at these constraints because if in fact we are going to show that the separate screening is optimal. Well, these are the constraints that are binding for separate screening, so they should be the only ones that matter. So I can do this in a little bit more detail. So what exactly is a mechanism for a component problem? Well, so it specifies for, for each possible type in this component a probabilistic allocation, that is a probability of every possible outcome and a transfer.
00:23:29.498 - 00:24:16.924, Speaker A: And these have to satisfy a bunch of linear constraints as usual. So there is an IC constraint for each type to imitate any other type. There is an IR constraint, and there is a non negativity constraint that says all these probabilities are non negative. And then there is an adding up constraint that says the probabilities of each of the outcomes have to add up to one for every possible type. And by duality we know that there is some numbers. You can multiply these things by these numbers and add them up and you'll get all of the x's will cancel, and the t's will end up with coefficients equal to the probabilities and you'll get this magical inequality. So what I'd like to do is find corresponding multipliers for the joint screening problem.
00:24:16.924 - 00:25:04.076, Speaker A: So I'd like to find the joint screening problem just like the component problems have. IC constraints, IR constraints, non negativity, and adding up constraints, I'd like to find multipliers so that when we multiply each of these by the right coefficient, add them up, we get this inequality that total profit is at most r star. That is the sum of the revenues from the component problems. I put the probabilities here, though in a different color, because the probabilities are not something that currently is specified. So it's up to us to find the probabilities such that the algebra works out. So this is a proof strategy. And actually once I have described this proof strategy, it is basically straightforward to work through it.
00:25:04.076 - 00:26:02.014, Speaker A: Once you decide to do this, the algebra will lead you to what the multipliers have to be. Um, but there are a bunch of things to check. So it turns out that once you start trying to calculate the multiplier that makes this thing work, they're basically re weighted versions of the multipliers from the corresponding component problems. So for each type in the joint type space and each of the k directions, each of the k components. You're going to have to come up with some reweighting coefficient, which I'll call gamma k of theta, so that the joint multipliers on constraints involving that type in this direction are simply the re weightings of the corresponding component constraints. So only gamma looks at all the other items and the corresponding one item. Sorry, ask the question again.
00:26:02.014 - 00:27:07.404, Speaker A: So what is time different items? Is this gamma? That's right, yeah. I mean, another way of saying it is so the, you know, if I look at, for example, the incentive of this type to imitate this type, this type is getting an allocation that consists of all items, and this type is getting an allocation that consists of that consistent, that consists of all items. And in the one dimensional problem, this type has a different valuation for the first item than this type does. In the joint problem, this type has a different valuation for the first, different value for the first item, but the same value for the second item. And so that's going to make the joint constraints a bit more complex than the component constraints. And so that's where we need the gammas to come in. So basically we want to pick out these gammas in a way that makes it so that when we add up all of our constraints, all the code, all of the x's cancel out and we are left with just the t's.
00:27:07.404 - 00:27:52.134, Speaker A: Well, there are this number of gammas that we need to choose one for each joint type and each direction. And there's also this many constraints on what the gammas are because we need each of the x's to cancel out. And so this is a, this looks like it should be a uniquely determined system. And it turns out that it not only has a solution, but the solution ends up being non negative. I don't understand why the solution to this system ends up being non negative. So I can show it by a fixed point argument. The fact that it's non negative is important for the, for the proof approach to work because that means that all the multipliers are inequality constraints which need to be non negative, actually r.
00:27:52.134 - 00:28:36.774, Speaker A: And then finally, once this determines what the multipliers on the constraints are, well, we also needed to decide what the probabilities are on the joint types, but those are pinned down because we just multiply each of these constraints by the appropriate multiplier, we add them up and we look at the, we look at the resulting coefficient on t of theta and we call that thing probability PI of theta. And it turns out that those PI of theta. They're closely related to the component, the probabilities in the corresponding component problems. In fact, they are exactly equal to the marginal probabilities reweighted by these gammas.
00:28:37.594 - 00:28:38.682, Speaker B: Could you just say one more time.
00:28:38.738 - 00:29:22.250, Speaker A: While there's one construction for each xk? Oh, yeah. So for each xk, basically I want to choose these reweighting coefficients so that when I do this big adding up xk of theta will cancel out here. So that gives me one constraint for each xk of theta. Is there any sum of a k in last equation? No. So this is true for every k? Yeah. And you can do that once you have sort of identified, once you have used these constraints to pin down what gamma, the gammas have to be. This gives you a relationship between the components, the component problems, and the joint problems with gamma figuring in there somehow.
00:29:22.250 - 00:29:24.226, Speaker A: And it turns out that this comes out of that.
00:29:24.250 - 00:29:33.234, Speaker B: Do you have any notion what these gammas are in the sense of. I don't know. For instance, started with uniform distribution over two items. You have anything? No.
00:29:36.174 - 00:29:48.314, Speaker A: I've drawn a bunch of pictures of what these worst case distributions look like and haven't been able to make sense of them. If anyone can look at the pictures and interpret them, I would love to know.
00:29:49.014 - 00:30:20.194, Speaker B: Yes. My solution would be, again, not for the exact minimum. That's going to be tough. But for the direction of the minimum, I would go for next negative correlation, which means when one has high values, the other has low values. And that's exactly, yeah. Rather than, rather than full correlation, positive correlation, which is what you showed us, it seems to me. So for example, if you ask the question and the separate, be as high as possible for separate, I would say you goes for the negative correlation.
00:30:20.194 - 00:30:25.278, Speaker B: That's my, I don't know, that's your. Does your picture look like it's going that direction?
00:30:25.366 - 00:30:40.434, Speaker A: So the picture, they're generated by taking like uniform distributions. So I don't have them in this, in this talk, unfortunately. But they tend to look like there is positive correlation. The usual lesson coming from the bundling literature has been that we want to bundle when there is negative correlation. Right.
00:30:41.054 - 00:30:45.662, Speaker B: That's the point. But here we want the distribution where bundling is bad.
00:30:45.758 - 00:30:46.394, Speaker A: Right.
00:30:48.194 - 00:30:59.454, Speaker B: Rather than separate. Exactly. When someone is high, the other is low. So you are going to lose that when you bundle it. You want to sell separate, get each one the high pump. I don't know. That would be my.
00:31:01.074 - 00:31:28.734, Speaker A: Maybe we should take this offline since there's, I think, 1 minute remaining or possibly less. Okay, so here is a quick summary, and in the future I would like to build on this boundary by using this as a baseline boring model to incorporate interactions between the different components of information and see whether we can build more general and more tractable multidimensional screening models. That's that. Thank you.

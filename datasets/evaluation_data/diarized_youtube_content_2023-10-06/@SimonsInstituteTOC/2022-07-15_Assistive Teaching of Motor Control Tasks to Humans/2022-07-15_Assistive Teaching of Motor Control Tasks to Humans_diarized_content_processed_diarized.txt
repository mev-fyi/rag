00:00:03.240 - 00:00:47.594, Speaker A: Okay. Does the microphone work? All right. Hi, everyone. My name is Megha, and today I'll be talking about how we can use AI assistance to help teach humans motor control tasks like parking a car or riding, in a more reliable and consistent way. So humans need to perform a variety of motor control tasks in our everyday lives, such as through our occupations like surgery for fun and enjoyment, like playing a sport, and in everyday tasks like writing. However, many motor control tasks are challenging to learn and often take years of practice, especially for those who are unable to get access to good, specialized teaching. Furthermore, motor control tasks are even more challenging to teach others.
00:00:47.594 - 00:01:40.318, Speaker A: For example, there may be many people around us, like our parents or friends, who are able to perform a motor control task well. They may be experts at the task, but they lack the ability to teach the task to others because teaching is a much harder task. Teaching requires having good communication ability and lesson design information. It requires understanding the task beyond rote memory, and it requires an awareness of a particular student's capabilities. Furthermore, this problem will only become worse as we introduce more new motor control tasks, especially in the realm of human AI coordination. For example, with self driving cars, we're introducing a new kind of control task where humans need to learn when to intervene or need to detect when the car is entering an unsafe situation and be able to quickly take over. So you can view that as a new kind of control task or in assistive robot tally operation.
00:01:40.318 - 00:02:42.288, Speaker A: In applications such as assistive surgery, humans now need to learn how to operate these really novel control interfaces and how to augment the robot's capabilities in the most safe way. So what makes teaching motor control tasks in particular, so challenging? First, they often require having access to specialized instructors who have a deep knowledge of the different skills required for the motor control task. Second, there are strong individual variations in the students trying to learn them, such as in sports, a human's height or arm span, or whether they're left handed or right handed. A teacher needs to be able to handle all these individual variations then. Finally, there are also diverse physical conditions in the task, such as a patient's body during surgery, that a teacher needs to help teach humans to be able to be robust to when they're actually performing the task. So, in our work, we ask whether AI assistants can help teach humans motor control tasks. And in particular, we ask whether we can leverage all this expert human knowledge out there of how to perform a motor control task.
00:02:42.288 - 00:03:38.694, Speaker A: All these experts who are able to perform can we use AI assistants to help transfer that knowledge from experts to other humans who are novice students who want to learn how to perform the task themselves. So AI assistance has helped bring more accessible and uniform teaching in simpler domains like foreign language learning. And Duolingo is a pretty popular example of this. So let's dig deeper into how Duolingo uses AI assistance. First, we have this notion of skill identification or identifying what parts of a task fall under certain landscape concepts, grammatical concepts, or subject concepts. We also have this notion of individualization, automatically identifying the weakest concepts, such as the weakest words a student is struggling with. And there's been a lot of recent work, including my work in ACL last year, that's focused on improving this individualization process using techniques such as modern language models and the knowledge of language within them.
00:03:38.694 - 00:04:23.470, Speaker A: And then finally, there's this notion of curricula creation, which we'll call jills. So what is the right kind of practice, method and mechanism that students should go through in order to improve on the skills they're struggling with? And there's been a lot of work in the reinforcement learning community on optimal curriculum design and activity sequencing. So this process is a lot easier in common education domains like foreign language learning and mathematics. And that's because the skills in these domains have been standardized by educators over years, and they're also easy to detect because they're often text based. And the key challenge for us with motor control tasks is that we're dealing with a new kind of data. We're dealing with trajectories over time, which is a lot more complex. So let's look at a specific motor control task writing.
00:04:23.470 - 00:05:31.540, Speaker A: In this example, a user is writing balinese characters. There may be many experts who are able to do this, but they might not be familiar with how to teach this task. And we can clearly see that this is a trajectory over time which we can formulate as a Markov decision process with an initial state that's the xy coordinate, the action sequence of xy movements by the user, and a reward function that corresponds to their target goal sequence, so the full sequence of characters they want to write. And then we have this notion of a scenario, which is the initial state and reward pair. And then we can say that a trajectory is a sequence of state action tuples that correspond to a particular scenario, so a particular kind of target sequence the user wants to write. And so now let's be more formal about our three teaching components in the context of trajectories over time for motor control tasks, starting with skill identification. How do we identify motor control skills from motion trajectories so the key idea with our work is that we borrow from the reinforcement literature a set of algorithms on unsupervised skill discovery.
00:05:31.540 - 00:06:24.864, Speaker A: While our method is agnostic to the particular algorithm, I'll focus on one in particular called compile. So loosely speaking, compile is an auto encoder decoder framework that learns to break down expert trajectories into smaller segments of state action sequences that can correspond to different skills. And in particular, there are two components, a boundary network that learns to predict the boundaries of the next skill segment and an encoding network that learns to predict the latent skill code corresponding to that segment. And then we have a decoding network that tries to recover the action sequence based on the latent code. And then the objective we're trying to optimize for is the reconstruction loss. So then when we want to train a compile model, we can consider having a data set of expert demonstrations corresponding to different scenarios. Put that into the network, and then we'll get a train compiled model.
00:06:24.864 - 00:07:02.614, Speaker A: And then at test time we can provide a novel sequence, a novel trajectory of state action tuples. Put that in as input to the compile model. And then what you can see here is that compile has broken it down into skill boundaries. So where each skill starts and ends and these codes that will identify the different skills. And you can see here in this writing task that this horn shape that appears in many different balinese characters are all being identified as skill three. Here. The key idea is that we're using a combination of expert demonstrations and unsupervised skill discovery to help break down this complex data type of trajectories over time.
00:07:02.614 - 00:08:14.274, Speaker A: Now, how do we handle individualization and identify individual expertise from student motion trajectories? So we showed how compile can take as input and expert demonstration. But what happens when we have a novice student demonstration that's a lot noisier than an expert and doesn't kind of have all the skills? When we input it into compile, we can see that compile may not be able to detect all the skills for the check right now because the student hasn't been able to perform them. In this example, compile is able to detect skill one and the boundaries for that. But then because the student is starting to struggle at the part of the sequence where skill two is needed, compile is not able to detect skill two and then subsequently skill three and skill four. So we can now use this to help determine which skills we want to penalize and help the student learn later on. But there's this other idea of the sequential ordering of the skills, where because the student was starting to struggle with skill two, they never really even got to attempt skill three and skill four. So maybe we want to penalize skill two more than skill three and skill four, because we don't really have enough information on whether the student is able to, you know, actually perform skill four.
00:08:14.274 - 00:09:04.324, Speaker A: So we can have this temporal decay turn j to handle this. And so then, if this particular student attempt has a given reward, and for the writing task, reward can be the pixel wise distance between the student and expert trajectory, and also a combination with the. Along the x axis, the student's able to write. Given this reward function, we can now distribute the reward across the different skills as penalties and weighted accordingly by the temporal decay term. If the student got a pretty high negative reward of negative twelve, then we could assign a lot of penalty to skill two, and then less so to skill three and skill four. And then we have a diverse set of scenarios that require a diverse set of skills according to the expert. We can then use this to get a pretty reliable estimate of what are the skills the student is indeed struggling with.
00:09:04.324 - 00:10:17.656, Speaker A: And we can formulate this creation off a diverse set of scenarios as a maximum set coverage problem over the expert demonstrations and skills. And so, again, the key idea here is individualization, where we're using this to now kind of identify for different students what are the different skills that they're each struggling with. So, some skills might be uniformly challenging, while others are based on individual student capabilities they may be struggling with more so than others. And then finally, curricular creation. How do we create novel drills that now target these individualized skills that we want to help students practice? So, in many motor control tasks, such as basketball, we have this idea of drills, which are repetitive sequences like dribbling or repeated shooting with the ball that target particular skills, but also in common context that they appear. So shooting from particular locations or dribbling in a way that one might dribble in an actual game. And so, for our task, say we see that a student is struggling with skill one, what kind of drill should that student practice with? So we can introduce a hyperparameter controlling the degree of repetition, and then also a parameter controlling the common context so the context length.
00:10:17.656 - 00:13:39.904, Speaker A: So, given a set of expert demonstrations, what are the common contexts gil one appears in? And if it's a context of two, then what are the. What is the second most common skill that appears with skill one most often so that the student can help practice the transitions between skill one and the context it often appears in so then what we can see here is this would be an example drill the student would practice so it not only helps them practice skill one but also the transition between skill one and then the common shape that often appears with skill one across all expert demonstrations so to go over our approach we extract skills from expert demonstrations we then select scenarios with diverse skills use that to get a good estimate of individual student skill expertise and then use this to automatically create individualized drills so our work has more detailed experiments in synthetic models of student learning but for this talk I'll focus more on our human subject study and we have two tasks in particular parking a car and writing a sequence of balinese characters and we built interfaces for them where students participate in the teaching curriculum so let's focus on the writing task here the goal is to write balinese sequences of balinese characters the control mechanism is a continuous mouse control under the interface and then the expert we consider are real human trajectories from the Omniglot dataset which is a crowdsourced data set of human handwriting trajectories then the state space is a two dimensional state space of XY positions and then the action space is again two dimensional of the XY coordinate movement for the parking task the goal here is to park the yellow car into the blue square the control is again a continuous mouse control but this time operating a joystick toggle and then the expert here is an optimal RL agent soft actor, critic agent that achieves 100% success rate in parking and then the state space is six dimensional controlling the car's position, velocity and heading and then the action space is the acceleration and heading that the human can control so the first experiment we want to study is whether the skills return from compile this unsupervised skill discovery method whether it's actually useful for human student learning so one baseline we can focus on is just the student just practices full trajectories so that's either practicing the car, parking the car in the blue square, the complete task of that or complete sequences of balinese characters and so if this were to perform well this would mean that we don't really need to think about breaking down the task into skills or drills we can just have the human just practice the task over and over again we can also consider a time heuristic where the way we define skills is we break down a trajectory into even segments based on the time so if it takes 12 seconds then we could do three segments of 4 seconds and if this were to perform well, this means we don't really need AI assistance. We can just have a very simple heuristic to identify the skills we don't need something fancy like compile. And then we have our method which is based on compile skills. And you can see here that we're able to identify the full turn as a skill for the car versus just a straight segment. So we run a user study on the prolific crowdsourcing platform. And particularly we measure reward improvement, which the difference between student performance on the evaluation set and their pretest set.
00:13:39.904 - 00:14:28.648, Speaker A: And we can see that for both our tasks using compile skills outperforms, the students learn more with compile based skills than the other baseline methods. But in particular, we can see that the time heuristic is very inconsistent. It kind of does help with the writing task, but with the parking task, students just do not really learn that much at all with the time heuristic, which shows that our method using compile skills not only helps improve student learning, but it's more reliable and consistent across different control tasks. And then finally, our last experiment was whether individualized drills now help students learn. So we compare our focused skill based practice with randomly chosen drills. So now we have drills corresponding to targeting different skills. But this baseline doesn't have any individualized component for each student.
00:14:28.648 - 00:15:24.584, Speaker A: They just practice a randomly selected set of skills. And then we have our method that's based on individualization. So we do our process of identifying what skills a student is struggling with and then create drills that help them practice this more. And what we can see here is the distribution of what are the skills we identified as being difficult for different students and the corresponding drills for them. And so, for example, you can see for the parking task, the most common skills students struggle with are both reversing skills, which kind of makes sense based on the joystick being hard to control with reversing actions. But what you can also see here is that there's a pretty widespread distribution across individuals of what are the challenging skills, which shows that individualization is pretty important because it's not like there's just one uniform skill that all students need to improve on and struggle with. And so in terms of results, we see that individualized drills does generally improve student performance compared to our baselines.
00:15:24.584 - 00:16:15.824, Speaker A: And then we also have users self report the perceived helpfulness of the teaching sessions. And here we see something interesting. We see that participants significantly prefer individualized drills for the writing task, but for the parking tasks, participants actually preferred the skill based practice. The shorter non individualized skill based practice over individualized drills, despite actually performing better when they were taught with individualized drills. So why is there this inconsistency? And we do a closer look at the optimal expert actions in the evaluation set. And if you look at that, you can see that the optimal expert action for many of those scenarios is to reverse. And then looking at the data, we see that students who didn't receive any individualization during teaching, only 27% of them attempted to reverse in those scenarios.
00:16:15.824 - 00:17:16.522, Speaker A: Well more than half of the students who did receive individualization, individualized drills, they tried to reverse, but they reported in their feedback that they found it pretty hard to control the toggle when reversing and found it a hard skill in general to do. So what this means here is that teaching is not just teaching how to perform the task with a high reward, but also how to kind of learn the skills that the expert is using in particular. And so what we see is that students, they are learning how to perform the task better because reversing does help them kind of get a lower reward, but they're finding it a more frustrating experience because they're now having to learn a much harder skill. So the key takeaways here is that we kind of developed this method for using AI assistance for skill discovery, individualization, and Jill creation. Three teaching components we identified for motor control tasks. And the basic idea here was that it's a lot easier to do a motor control task than to teach it. So we can have access to a lot of expert demonstrations of people performing a task.
00:17:16.522 - 00:17:51.010, Speaker A: But teaching is something that's a lot harder, a lot less uniform currently that we can leverage AI assistance for. And then finally, we showed that participants did benefit from AI assistance for two pretty different control tasks. In terms of future directions, though, I want to focus on two. One is having stronger models of student motor learning. So we kind of show these crowdsourcing results. But our overall method has a lot of parameters. There's a degree of repetition in drills, the context length in drills compile itself as a method, and other unsupervised code discovery methods.
00:17:51.010 - 00:19:01.850, Speaker A: They have parameters like the number of skills and the overall task that you need to set. And it would be nice to not have to run a pretty costly human subject study for each of these parameter settings to be able to kind of identify what would lead to better learning outcomes. But right now, we don't really have good models of how students learn, particularly motor control tasks. There's been a lot more effort for more simplified tasks, and we can have naive baselines like half training or reinforcement learning agent, or having particularly semantic difficulties like having this model have trouble with reversing. But these are pretty basic and don't really kind of capture the way students might learn a motor control task, such as incorporating things like muscle fatigue, muscle memory, and forgetting over time. And then another direction to consider is the risks of our approach when there's a mismatch between the expert and the student, and how to account for student preferences. So many motor control tasks, there might be many right ways to do the task, and if we only used data from one expert, one way of doing the task, we might miss accounting for the different ways a motor control task might be performed.
00:19:01.850 - 00:19:26.864, Speaker A: One user study here kind of had they really liked the overall tool, but they had a disability, so they struggled with the actual way of the task was being performed itself. So kind of being able to estimate student preferences really well and figuring out what the right demonstrations from an expert are to teach them is important. Future direction and. Yeah, that's it. Thank you. Thank you.
00:19:29.324 - 00:19:51.254, Speaker B: Let's welcome our speakers back on stage. Since we started about ten minutes late, so we have until about 20, 12, 25, we'll collect like the five questions first. I will just keep going one direction.
00:19:54.154 - 00:21:09.834, Speaker C: So thank you both. So my question is, really just relates to Casper's presentation, and I was wondering, because as a lawyer, we're very concerned with explainability because we want reasons, because reasons are kind of the precondition of normatively challenging a kind of what is taken to be an authoritative decision otherwise. So we want to know why something's been decided. But from your presentation, it seems, this is my kind of interpretation, that this is always going to be a kind of self referential problem for the legal observer, because it seems to me that what you were saying is that information only becomes meaningful and you were using meaning in a really interesting way. If it's a difference that makes a difference to that observer, there has to be a selection of a meaningful what is the relevant difference and how that information is presented. So the medium in which it's communicated actually determines what possible understandings can be drawn. So just as I was listening to you, I was really struck that this, the way you're presenting it, was really resonant with kind of theories of second order cybernetics and systems theory, where one has to sort of basically make a cut between information and the medium in order to generate understanding in the meaning, in the medium of meaning.
00:21:09.834 - 00:21:32.644, Speaker C: And I said, that's kind of a complicated, but my question is really just whether or not you think that the outputs of a predictive system represented this way can ever be translated with any sort of certainty, or whether we will always have this kind of contingent relationship to the position of the person that makes the distinction, makes the observation of the information and how it's presented. Yeah. I don't know if that makes sense or not, but that's.
00:21:33.224 - 00:21:35.844, Speaker D: Sure. Right. I think that.
00:21:42.624 - 00:21:43.404, Speaker A: Yeah.
00:21:46.184 - 00:22:09.868, Speaker E: All right, so my question is also for Casper. Thank you so much for the presentation to both of you. I like interpretability as a field because people tend to have, like, very strong opinions other than in other parts of computer science. So here's my. With a caveat. Like, here's my own strong opinion. I think that intersubjective issues, as the ones that Bernard was hinting at, might be a result of really focusing on post hoc methods too much.
00:22:09.916 - 00:22:10.244, Speaker C: Right.
00:22:10.324 - 00:22:24.356, Speaker E: I feel that they will always kind of fail because you're trying to extract meaning from an syncretically compressed set of data. I would even argue that postdoc methods are almost an implicit, implicitly political choice.
00:22:24.420 - 00:22:24.596, Speaker A: Right.
00:22:24.620 - 00:22:49.444, Speaker E: You're treating models as if they were natural objects that you have to study empirically. You have to prod them and to analyze them. So the less strong version of that is, why are we not focusing on naturally explainable models? What's keeping us, technically or otherwise, from going, like, jumping before the point where we have to empirically analyze these systems, if that makes sense.
00:22:56.624 - 00:23:12.724, Speaker B: Do you think then, like, the computer vision algorithms or NLP algorithms that are not inherently explainable, shouldn't have been invented in the first place? I guess I'm trying to draw a boundary. I know it's like a fuzzy sort of spectrum.
00:23:13.064 - 00:23:30.972, Speaker E: You can undo it. Right. But then there's maybe. There's a middle ground, you know? So there's maybe deeper ways that, you know, goes a little bit deeper. It tends to be. But then again, the visualizations that you get from that are, you know, upcoming, not really integral. So it's a question.
00:23:31.028 - 00:23:31.628, Speaker A: So.
00:23:31.796 - 00:23:36.184, Speaker B: Okay, yeah, yeah, that's helpful. I'll leave it to the speakers.
00:23:39.804 - 00:24:37.538, Speaker F: I have a question for Casper and then for both of the speakers. So for Casper, I was wondering, do you have an example of an explainability method that's been, like, used and shown to be helpful for the intended audience? And if not, what are the biggest challenges to getting there? And then for both of you, I guess both of you are working, at least in the papers you've presented, on things where the end user is a human. Ultimately, you're outputting something that needs to be useful to a human. And I'm wondering in a lot of, like, in both interpretability and Hri, and I know, Casper, you said you think maybe we've gone too much focused on the human. The way that these methods are evaluated with people are typically in, like, very small user studies, often recruited by the person's, like, in the person's own lab. To what extent do you think, like, this is okay? Versus we need better evaluations versus, I don't know, it's outside of the domain.
00:24:37.586 - 00:24:37.786, Speaker A: Yeah.
00:24:37.810 - 00:24:40.174, Speaker F: What do you think about rigorous evaluations?
00:24:45.074 - 00:24:45.854, Speaker D: Yeah.
00:24:48.914 - 00:24:53.614, Speaker A: Wait, how many more? Okay, yeah, we'll finish here.
00:24:56.894 - 00:25:03.286, Speaker G: Well, I have a question for mega the second speaker, so maybe we can just. I'm happy to wait.
00:25:03.350 - 00:25:04.074, Speaker A: And then.
00:25:07.894 - 00:25:09.954, Speaker D: Right. Could you define helpful?
00:25:13.294 - 00:25:15.902, Speaker A: Like, just any definition of helpful has.
00:25:15.998 - 00:25:18.246, Speaker F: Shown to be helpful to an end user.
00:25:18.390 - 00:25:18.854, Speaker A: Yeah.
00:25:18.934 - 00:26:08.552, Speaker D: So who is the end user? If the end user is a machine learning engineer, then helpful is, oh, can I get some insights into why my model breaks or what's wrong with it? So that's one definition of helpful in this context. And then another definition of helpful is, oh, I've seen the explanation. So now I feel more confident about this model making decisions regardless of whether the explanation is correct or what the explanation does. So I suppose we've gone overboard into, we want to understand it. We just want to generate an explanation. But, and then this ties back to your question about what was, oh, the evaluation. I don't think it's possible to evaluate a method in such a way that then we can draw broader conclusions.
00:26:08.552 - 00:26:31.364, Speaker D: So, however we evaluate it, it's in a given context with a given people. And that's why I draw this clear separation between generating insights and presenting the insights, for example, with, let's say, counterfactual. So what if questions, you know, that this, if you generate it, and then you can probe the model, is this what if instance correct? It is correct.
00:26:31.404 - 00:26:31.556, Speaker A: Right.
00:26:31.580 - 00:26:50.636, Speaker D: So then it's just a matter of how you present it, and that probably depends on who you present to, et cetera. So, you know, there is a correct, possibly objectively correct insight, and then how you present it, to whom and for what purpose? Hopefully, that, I guess.
00:26:50.660 - 00:26:59.732, Speaker F: I don't mean, like, for a particular model. Like, you're trying to make the explanation for a model generalizable. I mean, the insights from the field of explainability generalizable.
00:26:59.828 - 00:27:02.596, Speaker A: Can you evaluate, like, oh, then I.
00:27:02.620 - 00:27:06.544, Speaker D: Suppose we should completely forget about where the explanation comes from.
00:27:06.964 - 00:27:09.044, Speaker A: I think we have the other questions.
00:27:09.084 - 00:27:55.980, Speaker D: Okay, so then the other question was context. Right? So you said that possibly we may be better off just by using transparent methods. And again, it's context dependent. If you want to deploy this model in the affects humans, then yes, of course, because all the post hoc methods can do is give you one single peak inside what's happening. So then, if we're deploying it in a mission critical situation, it should definitely be transparent. Whereas if you're an engineer or you're just curious, then why not use post hoc? It also gives you some sort of insight, as long as you understand the conditions under which it was generated, this insight and how to interpret it. So it just plays a completely different role.
00:27:55.980 - 00:28:13.644, Speaker D: And one shouldn't be used in certain situations, whereas another can be used. I'm not saying that one is better than the other. They just serve a different purpose. Thanks, Bernard. I. Sorry. Okay.
00:28:15.304 - 00:28:19.128, Speaker A: Okay. I certainly see the time.
00:28:19.256 - 00:29:14.954, Speaker H: I'm the hungry one, so I don't. This is a question for Megha, and it's a little, like, tangential. It's a question about the politics of what you're doing. And it makes me so worried. When computer science, digital technology, whatever, enters into the sphere of education and your motivation for what the project is, is very benign. You know, there are people who don't have access to these motor skill teachings, and so we're being helpful, but there is always this dimension of the deskilling dimension of saying, we don't need the teachers anymore. We're going to create methods where we can automate this process.
00:29:14.954 - 00:30:20.814, Speaker H: I'm now seeing the world through Peter's eyes, which is, number one, deskilling, number two. And your tasks, by the way, also, that were, for me, non problematic, because we're talking about parking and. And writing balinese characters. But if you have aspirations to extend it to more complex teaching tasks, I think that becomes dangerous because you can simplify. And as we've talked about, I'm not sure how much you've been with us, but a lot of these tasks must be reduced in order to be made computationally accessible. And so then the task becomes whatever is computationally, the teaching becomes what is computationally accessible. You know, education, is it reading, writing, arithmetic, or is it a much bigger transfer of human knowledge to the next generation? And maybe it just becomes the thing that we can do with an automated system.
00:30:20.814 - 00:30:34.884, Speaker H: So it's hard for people like myself, who are not technologists, but I feel like folks like yourselves who are working on this, we need to know your thinking about this. And I'm wondering if you are.
00:30:40.384 - 00:30:41.324, Speaker D: Thank you.
00:30:41.904 - 00:31:36.194, Speaker G: So first of all, great talks, both of you. My question is for Mega. One thing that I noticed about the task itself or both of the tasks that you're testing on is that they're stable and their specific tasks. But it strikes me that a big goal of motor skill development and of like, drills as a strategy is to develop skills that are kind of adaptable so that when the world changes or when there are random conditions in an evaluation, somebody might be able to adapt to those changes. So I guess I just want to hear, like, your thoughts about that or how that could get incorporated into your work or as a general topic of inquiry.
00:31:40.414 - 00:32:13.096, Speaker A: I think I have my mic. I'll start with your question first because I think I will. But with. Yeah, I think teaching, I think, like, in a way that helps humans adapt to new tasks is definitely important. We try to get that a bit with, like, having these different scenarios and conditions. So with parking, like, just like different kind of starting points, whether the orientation is towards or against a parking spot. And then kind of the skills we kind of identify do need to be able to transfer across these different scenarios.
00:32:13.096 - 00:33:10.588, Speaker A: But I think it's an interesting thing to think about, like, skills that are adaptable across very different motor control tasks because you do have this idea of, like, you know, there is something similar to words, braking in a bike and braking in a car, but they are also different. But you kind of like, there is some transfer that's happening. So I guess all I have to really say for that is like, that is like something I'm pretty interested in looking into more. But I think especially with what I talk about with human AI coordination tasks, like taking over a self driving car or assistive surgery, teleoperation, I think those are pretty new tasks that we just don't even have teachers for yet. And those are examples where we're just expecting humans to be able to adapt to them. And just as we introduce new and new technology, we're just expecting, counting on humans ability to adapt. I think being able to help teach humans to adapt better towards new motor control tasks, that's also, I think, an important thing.
00:33:10.588 - 00:34:16.004, Speaker A: And I think that ties into my response to your question, which is this is something I've been grappling with a lot, because I also feel like education is so much more than just like, teaching a task. It's also being in a classroom with other students and kind of seeing your peers learn is kind of having kind of the inspiration from a human teacher and their kind of mentorship. So I think. I never really kind of see this work as replacing that part of teaching. But I do think, and I think, like, from both my work on with, like, language learning and this work, I think just the reality is, and, you know, like, like, I meet many people who kind of do embrace a lot of these technology, like, education technology, because they just don't have access, aren't able to afford certain kind of specialized teaching. And I think I've grappled with this a lot because I also, I'm hesitant to just, like, automating away teaching. I don't think, like, we could ever really fully replace all that teachers offer, but I also do think, like, I come every point where I've had, like, pretty privileged access to kind of education, both in extracurricular activities and in school.
00:34:16.004 - 00:35:15.112, Speaker A: And I've never really faced a situation where I've, like, needed to resort to kind of getting resources for my education, like, and kind of just, like, finding them. And I do think there's an opportunity to just think about how we could, like, increase that kind of access and then kind of related to the two points. Like, I do think we're just entering this world where we're introducing a lot of kind of control tasks without even, like, thinking how to teach them. And so we don't even have, like, teachers teaching these kinds of tasks, but we're just kind of like having humans just learn through trial and error how to perform them. And I think that's where I see kind of my method being particularly useful, which is what are these kind of control tasks where we just haven't even put in the resources to learn how to have humans teach them? But can we kind of get something kind of in the middle ground as we kind of learn how to get good human teachers for them that still kind of, like, helps us learn how to do it in the process. What if Google comes to you at.
00:35:15.128 - 00:35:22.804, Speaker H: The end of your PhD and says, I'm going to pay you all this money so that we become the distributors of your method?
00:35:23.264 - 00:35:29.314, Speaker A: Like, how we don't have the local.
00:35:29.394 - 00:35:43.970, Speaker H: Teacher teaching the kid, which costs a certain amount of money, but we have think about the reality of the political economy and how these automated systems can be centralized.
00:35:44.122 - 00:35:45.970, Speaker A: The control of those can also be.
00:35:46.002 - 00:35:59.224, Speaker H: Centralized and also limited through economics. So when you say we, it's not, oh, maybe you will, but I think.
00:35:59.264 - 00:36:10.712, Speaker A: This is a concern. I'm sorry. I realized that this is also kind.
00:36:10.728 - 00:37:06.654, Speaker I: Of picking up on the discussion. I understand, Megan, where you're coming from entirely, but I wonder whether one of the things that Helen's concerned about, and maybe others, is that when we disaggregate skills, whether they're motor skills or communicative skills, from sensitivities and sensibilities, then we run the risk of really impoverishing people in terms of learning outcomes versus learning opportunities. When you develop sensitivities and sensibilities, then you're opening up relational opportunities for taking that learning to the next level and next level. So, like, I'm a surfer. I know what it would be like when people get trained to go surfing and they come out and line up and they have no idea what the sensitivities of dealing with other surfers are. There's a pecking order, there's a prioritization, there's a culture of it going on. And if they come out there without that, they get hurt or they get other people really upset, and then they get hurt on the beach.
00:37:06.654 - 00:38:00.846, Speaker I: So it's kind of like if you're not giving them a full spectrum background into what's involved in that learning test, let's say it's balinese writing, and they're not, in fact, informed that writing is a sacred act, that it's a religious sort of communion with those processes that humans have been embroiled with for centuries, millennia. Then the test just becomes a movement, a motor skill. And so it's like, I know that lots of these systems are being, say, used for working with autistic children, developing them to be able to have the skills to engage with people so they seem neural normal, but when in fact, they're not developing the sensitivities and the sensibilities, I think that's a way of neuron singing. And then maybe just put your research in a bigger context. It's not say, don't do what you're doing, but I think what Helen's saying is we need to really put it in the bigger societal context.
00:38:00.910 - 00:38:52.064, Speaker A: Yeah, yeah, I think I definitely agree. And I think the, like, example with writing is a pretty good one. And I think we did get feedback from a couple people saying they really wish they, like, knew what the characters meant. And that's something we like, oh, we didn't do, but we could have done. And I think there's just kind of like, even kind of the students desire some kind of information like this. What is balinese, like, the script used for what are interesting words that they want to learn and all? And then also, yeah, from the perspective of people who write balinese, kind of giving those, like, awareness of the task. I think maybe it's a matter of perspective whether I view it as kind of improving these methods versus not doing something like this at all because it currently doesn't adjust the sensitivity.
00:38:53.044 - 00:39:39.732, Speaker B: I have a question to you, so somewhat related to our discussion here. I think like for surfing, like take surfing as an example. I think the fact that people would just come out of surfing school, go into the beach that look a bit out of place and have still have a lot of skills left to learn, that seems fine to me. That doesn't say the surfing school is not useful. So in a sense, I think, I think that aligns with your point, which is like the skills AI teaches is sort of part of this larger picture, larger skill set you need to learn. And sort of related to that in your talk, you have this diagram about hard problems versus simpler problems, problems that worse your system to solve versus not. I found that categorization really interesting.
00:39:39.732 - 00:40:02.156, Speaker B: Can you maybe say a bit more about your, like did in your studies, do you notice anything about how AI categorize or how from a technical perspectives, what are hard versus simple problems and how does that, how much of that aligns with people's perception or our common assumption of what's difficult versus easy?
00:40:02.220 - 00:40:10.144, Speaker A: Sorry, you mean like the charts showing what were the skills found challenging for students versus not like those curved plots.
00:40:10.484 - 00:40:25.384, Speaker B: Yeah, and I think the slide before you were talking about here are some problems that you really don't need can be solved by simple heuristic systems versus here there's problems like worse your system to solve?
00:40:26.764 - 00:41:04.674, Speaker A: Yeah, I guess. So what that plot was showing was kind of what our system identifies as students struggling with. And then I think the heuristic, the idea there was like, it's like a non AI assisted way of kind of breaking down the task into skills. Sorry, just to clarify, is your question like whether kind of the skills students struggle with kind of match what, like an AI agent would struggle with or like match what we'd expect students to struggle with? The latter. That's the question. I mean, I can only speak for myself personally. Like I, yeah, I also find reversing hard.
00:41:04.674 - 00:42:01.724, Speaker A: So I think it's like not surprising that that was like found as a hard skill. I think in terms of the writing tasks, I was a bit surprised because I found that those seemed like pretty simple. So I think like, but I can really only speak. It's hard to really even know, like writing Balinese, that's not like a common like, task that people in education study even like, I don't have that knowledge of what would be a hard skill. And I think that's kind of one point I was trying to make with the distinction between this work and approaches in education for like math and for language. We just don't have like the decades of education research on motor control tasks on what are hard skills that are task specific. So it's hard to really say without kind of honing in on a particular task and hoping there are enough kind of experts out there who have done scholarship on that particular task on what would be the expected difficult skills in the same way we have for something like language learning.
00:42:01.724 - 00:42:03.512, Speaker A: Great.
00:42:03.608 - 00:42:06.564, Speaker B: Thank you. Any more questions?
00:42:07.584 - 00:42:08.112, Speaker A: Okay.
00:42:08.168 - 00:42:29.524, Speaker B: If not, we'll wrap it up. Thanks everyone. And I think there are a lot of discussions to have. I think explainability research really aligns well with auditing, like algorithm auditing. A lot of law professionals here, so maybe we can continue the conversation over lunch and any other context. But thanks everyone. Really wonderful discussion.

00:00:08.454 - 00:00:08.994, Speaker A: Social.
00:00:28.694 - 00:00:32.674, Speaker B: Welcome to the last session of the workshop of the book camp.
00:00:33.374 - 00:00:40.910, Speaker C: To finish off, we have Peggy, who is a truly interdisciplinary scientist.
00:00:41.022 - 00:00:42.606, Speaker B: She started out as a student of.
00:00:42.630 - 00:00:51.670, Speaker C: Engineering, then did artificial intelligence and machine learning, and for a PhD, she studied the visual cortex. She studies, among other things, information coding.
00:00:51.702 - 00:00:54.886, Speaker B: And computation in large populations of neurons.
00:00:55.070 - 00:01:01.794, Speaker C: Develops various models, most prominently perhaps, bayesian models of cognition, but also of mental.
00:01:06.014 - 00:01:30.414, Speaker B: So, thank you very much for inviting me. I'm very happy to be in Berkeley. So I'm going to talk about sorbasian theories of perception cognition, and I've added mental illness, because it's really the topic I'm most interested in at the moment. Can you put the microphone up a little bit? Oh, I don't know how they do it. I don't know if they switch it on. Is it better maybe on the other.
00:01:30.454 - 00:01:32.834, Speaker C: Shoulder when you turn to look at the screen?
00:01:34.214 - 00:01:35.234, Speaker D: Is it on?
00:01:36.454 - 00:01:39.234, Speaker B: Yep. Oh, is it on my pocket? I think it was.
00:01:41.694 - 00:01:43.274, Speaker D: The green light on the top.
00:01:52.554 - 00:02:44.984, Speaker B: So is that okay? So, yes, I've added mental illness because it's really the field I am interested in at the moment and where bayesian theories seems to be quite promising. So this is going to be a quick survey. It's a huge field that I can't cover in this time, of course. So the starting point is that in the world, in our experience, there is uncertainty everywhere at any moment in time, uncertainty and ambiguity. And the idea is that the brain really must deal with this. So there is uncertainty, and also because of the limitation of our receptors, because the scenes can be ambiguous, so at any moment in time, there are multiple interpretations about the world. And so the brain must deal with this uncertainty to generate perceptual representation and guide actions and figure out what's out there and what's the best action to take.
00:02:44.984 - 00:03:32.040, Speaker B: So, in this field, we have the idea that perception must work backwards to extract the cause of noisy inputs. And this is a process of unconscious inference, which we view as probabilistic. So we have this idea of the brain as a sort of guessing machine, unconsciously trying at every moment in time to figure out what's the best explanation for what's out there and what's the best action to take. So, the bayesian brain takes a lot of ideas coming from statistics. Bayes theorem, of course, which initially was just a mathematical result. Apparently, it's Laplace had already the insight that human knowledge must come from the accumulation of probabilities. And then we have Helmholtz, which is often attributed for understanding this process of unconscious inference.
00:03:32.040 - 00:04:23.304, Speaker B: He was looking at the human eye and understood it as an optical instrument. It was a very poor optical instrument, although maybe some will disagree with me, but he had this idea that it received complete information that the brain must somehow complete based on previous experience. And so then, in the nineties, people used. So, like Jeffington, Peter D'Yen, Gatsby and other people also used ideas from machine learning to view the brain as a sort of generative model. More recently, these ideas, and I'll describe how, came into experimental fields, and in particular psychophysics, with a lot of success, I think. I hope you will see that. I think in perceptual, so in visual psychophysics in particular, and in perception in general, this bayesian approach has become quite mainstream.
00:04:23.304 - 00:05:06.684, Speaker B: It has also spread in the theoretical world. And now I think there's also a lot of interest to relate those theories with the physiology, with the neural substrate, and that's proving much more difficult. And I'll discuss that as well. So, Bayes theorem. So I sure most of you or all of you know what Bayes theorem is about. So, just to briefly summarize, so, in Edinburgh, we are very interested in the weather and understanding whether it's going to rain today, which is very likely to compute the chance that it will rain today. The best thing to do is to do two things, to look at the window and look at the evidence.
00:05:06.684 - 00:05:52.182, Speaker B: So you want to compute the probability that it's going to rain today based on the evidence. So you look at this evidence, and you have some knowledge of the probability that the clouds look the way they do when you know it's going to rain. And so you can use this knowledge, and that's corresponds to the likelihood. But also you have a prior belief that it's going to rain today, and that number is going to be very different in Edinburgh and Los Angeles. And so that's your prior, and you have to also take this information into account. And so, Bayes theorem tells us that the way to compute the posterior probability, the best way to compute this is to multiply, so the likelihood and the prior normalize. So, Bayes theorem corresponds to very intuitive ideas.
00:05:52.182 - 00:07:09.154, Speaker B: It's in itself a very simple mathematical result and concept. So this bayesian theory of the brain then, suggests that the purpose of the brain is to infer the state of the world based on noisy data. And it does that using bayesian inference and representing information in the form of conditional probability distribution. So everything in the brain would be manipulated explicitly or implicitly, and probably implicitly in the form of a probability distribution. So if you're interested in the position of an object, you're not going to represent that by a number, but by a probability distribution where different locations have a different probability. So the idea then is that the brain would learn and store likelihoods, and it would also learn and store priors, and it's going to use those internal models to come up with posterior distribution, which are so the answers to the questions it would be asking all the time and beliefs about those hypotheses. And so the brain would be computing distributions and updating them constantly and using the posterior as the prior for next moment, et cetera.
00:07:09.154 - 00:08:04.758, Speaker B: So that's the general idea. The benefits of doing this are quite obvious. It is the best way to integrate information which has some uncertainty in it, to integrate it over space and over time and over also different modalities, different sensory cues, different modalities, and combine all this information without losing any of the uncertainty that is attached to it. Then to propagate this information throughout the brain without committing too early to particular interpretations and losing information about the intrinsic reliability of this information. So then the idea is that, so the brain would work with these property distributions, and only when fast, it would come up with a single number. It would collapse this probability distribution with a single action, a single answer. The way it would do that is not very clear.
00:08:04.758 - 00:08:48.868, Speaker B: But, for example, this could be done by taking the maximum of this distribution. It could be the mean, or it could also be taking a sample of this distribution. And it's not clear what the brain would do. So taking the max or the mean depends on the cost function that you assume. So you also have to, to take into account how costly it would be to make an error or how much reward you would have if you make the correct answer. So either you take a single answer, the mean or the max, or some people think, and we'll come back to this, that the way the brain works is actually by sampling in these posteriors. So in this talk, so this is the general framework.
00:08:48.868 - 00:09:51.664, Speaker B: So in this talk, I am going first to talk about the evidence we have that people behave as bayesian observers. And so I think most of it initially came from the research on multisensory integration. So I'll describe this briefly. Then I'm going to turn to the concept of priors and asking the question in perception and vision in particular, what priors the visual system uses and how we can discover them, and also learning questions around the learning of these priors. So research we've been doing, and other people, of course, then I'll try to convince you that these bayesian ideas are maybe an interesting new way to understand mental illness, with the idea that the internal models that people would work with would be different mental illness, and how again, we can uncover those differences in people with a mental illness. And finally, I will end up with trying to bridge those ideas, which are mostly at the computational behavioral level and the neural substrate. I'll talk a little bit about the controversy.
00:09:51.664 - 00:10:03.084, Speaker B: Some people believe this bayesian approach is never going to tell us anything interesting about how the brain works in its substrate and also possible implementation ideas.
00:10:03.984 - 00:10:10.722, Speaker C: Can I just ask, is it too expensive for the brain to keep probability distributions?
00:10:10.898 - 00:10:33.694, Speaker B: That seems to be a huge amount of yes. So we'll come back to this. A lot of people now believe that. So first of all, only an approximation of bayesian influence is possible, and also that these approximations can be done with heuristics. And a lot of people see no contradiction between those heuristics and thinking that the brain still does something like Bayesian inference.
00:10:34.434 - 00:10:49.884, Speaker E: Also, you can save structure like in the weights without using any energy. I mean, it only uses energy when that part fires right when the neurons fire. So you can potentially store the distribution in some ways.
00:10:57.184 - 00:11:42.816, Speaker B: So usually it's more the complexity that people think is unachievable, more than the energy cost. But we have no idea about the energy cost, I guess. So, do people behave as bayesian observers? And so we can use this Bayesian hypothesis as a benchmark for performance. And so the way we think about this is looking at where this should be expressed, and so we are looking at Bayesian. So people initially talked a lot about bayesian optimality. The way we think about bayesian optimality is not solely thinking that the human brain is optimally designed, or that we can achieve the level of performance afforded by the uncertainty in the physical stimulus. Like at the movies, we don't see a collection of static images.
00:11:42.816 - 00:12:52.260, Speaker B: We have all these illusions that are related to also the limitation of our receptors. So the way we think about optimality in this sense is really about uncertainty and about how the brain takes into account uncertainty and combine information which has different uncertainty reliability. And so the questions where we want to see a signature of this bayesian functioning is looking at how neural computations take into account the uncertainty in the measurement of each stage of processing. So combine uncertain information at different stages of processing and also combine current information with previous information. And for those aspects, the Bayesian theory makes. And I'll show you this very testable predictions that you can test behaviorally. So this has been done initially with a lot of success when people looked at multisensory integration, and in particular, so multisensory integration for simultaneous information coming from, for example, sound and vision.
00:12:52.260 - 00:13:26.114, Speaker B: So how does the brain combine information coming from different modalities, which may have different reliabilities? So we know that the brain does that all the time. Unconsciously, we fuse information coming from different modalities. And sometimes this leads to illusions. Sometimes the modality is going to dominate another modality, and this will lead to illusions such as the ventriloquism illusion or the McGurk effect. How many of you know about the McGurk effect?
00:13:28.254 - 00:13:29.314, Speaker A: Just a few.
00:13:30.134 - 00:13:41.354, Speaker B: Maybe I can show you or just in a few seconds, because it's quite fun. Have a look at this. What do you hear?
00:13:42.334 - 00:13:43.954, Speaker C: Bar, bar.
00:13:49.594 - 00:13:52.894, Speaker B: But look what happens when we change the picture.
00:13:53.234 - 00:13:54.974, Speaker C: Bar, bar.
00:14:01.434 - 00:14:39.094, Speaker B: And yet the sound hasn't changed. In every clip, you are only ever hearing bar with a ba ba. It's an illusion known as the McGurk effect. So it's a very strong illusion. You can't do anything about it. So this researcher is going to say that he spent and all his career working on this, and still he can't control it. So it's a very strong illusion where vision is going to dominate and transform the percept, and so similar effect which is happening in ventriloquism.
00:14:40.194 - 00:14:46.146, Speaker A: What is the other illusion? I don't know this one. Ventriloquism.
00:14:46.210 - 00:15:37.160, Speaker B: Ventriloquism is when you have someone with a puppet, and it pretends that it's the puppet talking. You know, it's actually talking, not his mouth, and the puppet is moving the mouth, and you believe that the puppet is talking. So mathematically, you can try to describe these things, and it's quite simple, or you can have very simple models to describe these things. So, mostly here we are looking at a situation where we are trying to mix vision and audition. And so we can describe the information coming from vision and audition. There are likelihoods, and there can be a little conflict between the two modalities, or no conflict. There is so a conflict.
00:15:37.160 - 00:16:37.204, Speaker B: So, for example, you have audition, which giving this likelihood and vision centered in different place. The bayesian theory will tell you that the posterior distribution that you will have about the location of the object when you assume that the sun and vision comes from the same object is going to be linked to combining those two distribution, and so basically multiplying those two gaussians. And so the posterior is going to be somewhere in between those two gaussians, in a way that is going to depend on the width of these Gaussians. And it's really about multiplying Gaussian. So if you know the initial mean and the initial variance, you actually know the final mean and the final variance. And so if you know the reliability by which people can discriminate sound alone and vision alone, you have the wits of discussion and where they would point if they have only vision or the sound, you have the mean of discussions, you can predict exactly. If you have now vision and audition together what people should perceive.
00:16:37.204 - 00:17:15.860, Speaker B: And so, again, the math is very simple. You're multiplying two Gaussians, and it gives you the mean of the resulting Gaussian. And so its mean, its new mean and its new width. And the result you have is that the mean of the resulting Gaussian is going to be closer to the Gaussian, which is narrower, which is more precise. And so this is linear combination. So the final estimate is going to depend on the initial estimate for each of the modality weighted by the reliability of these modalities. So if vision is much more precise, the final estimate is going to be pushed towards vision.
00:17:15.860 - 00:17:47.174, Speaker B: That's what's happening in the Magerk effect, or ventriloquism. And you also know about the width of this Gaussian. And this tells you the precision by which people can discriminate based on the two modalities together. And it tells you that this discrimination threshold, that the just noticeable difference based on the two modalities together, is going to be better, finer than with only one of the two modalities. Okay, so these are very clear predictions. There's no parameter. And you can test these things.
00:17:47.174 - 00:18:17.504, Speaker B: You can. So that's what initially Ernst and bonks have done in 2002. So they looked not at vision and audition, but at vision and touch. And they had an experimental paradigm. People had to measure the width of this object, which they could touch with a phantom glove, and they could also see. And the noise in the visual display was manipulated. So there was different levels of uncertainty in the visual display.
00:18:17.504 - 00:19:08.314, Speaker B: There was no. The level of noise was fixed in the, in the haptic display. And so they could first measure how finely people could discriminate widths based on touch, then based on vision, and they could play those equations to have the predictions about what would happen if you have touch and vision together and test whether those predictions would reveal correct. And what they found is that they did. So, for example, here, if we look at the discrimination threshold, they look first, at the discrimination threshold, if there's only touch and that's the red line, then if there's only vision, these are the blue dots. So in vision, you have different level of noise, different level of uncertainties. And so the discrimination threshold is going to increase when you have more and more noise in the visual display.
00:19:08.314 - 00:19:38.578, Speaker B: So from those you can form a prediction with the Bayesian theorem, and that's the gray area. And then they tested that by putting touch and vision together. And these are the pink dots. And they find that. So the pink dots fell into the gray area, so validating the prediction. And it also shows that. So when modality is much more reliable than the other, so here vision is much more reliable than the other, then the combined estimate follows the more reliable estimate.
00:19:38.578 - 00:20:20.648, Speaker B: So here vision, and vice versa. Here vision is very noisy and touch is more precise. So the final estimates follows completely touch. So that was very exciting at the time. And it was taken as and written in this way that people then were bayesian optimal in that sense, and so could combine the different modalities, take into account the uncertainty of each modality, and instead suddenly switch to get an estimate which was weighting the reliability of each modality. Okay. And so that was an important result back then.
00:20:20.648 - 00:20:57.716, Speaker B: And I think it was the start of a huge field, which is now a huge field. People have replicated this kind of result in a variety of paradigms. So first with vision and audition, but now people have extended to all sorts of modalities and finding very similar results. So often it's not, you find results that are close to the predictions, but not exactly. So it's slightly suboptimal. And how suboptimal is still optimal, it's not clear, but you find different degrees on sub optimality. People, oh, yes.
00:20:57.716 - 00:21:45.394, Speaker B: So often vision dominates, but also people have found domains where it's not true anymore, and in particular in the temporal domain, that's an illusion. So here you are asked how many flashes you can see, how many circles you can see in the right square. And if all goes well, you have a bit of an illusion where you see two, which is actually just due to the sound. There's only one visual flash. So in the temporal domain, sound is going to dominate over vision. And so people have also described these illusions. And so the reverse of this, the reverse of the ventriloquism here, where it's actually audition that dominates vision and how we can explain that.
00:21:45.394 - 00:22:48.290, Speaker B: So, as I've said, yeah, now this field is getting really big and it's not my domain of expertise. But it's very interesting. And also, people have extended it to situations where it's not clear whether you have to fuse the different modalities. So, clearly, if the distance between the two modalities, vision and audition increases, there's a point where you don't want to fuse the two sources of information, you want to segment them and decide that there are two objects, not one object. And so there's some research showing that you can also explain what people do in situations like this, with models where people not only infer the location of the causes, but also the causal structure. So what people do is like a sort of model comparison, where they would compute the location of the objects under the assumption that there's only one source or two sources. And then the final estimate would be the estimate given by each model times the probability of each model to be.
00:22:48.402 - 00:22:56.174, Speaker A: Likely, some prior probability. What do you mean? The probability of each model is the prior that you have in advance.
00:22:56.914 - 00:23:43.918, Speaker B: So there are also models like this, but yeah, no, there's an inference about the probability that each model is true given the evidence that you have before them. There was also models that looked at so clearly, the way you fuse different modalities depends on the modalities. And so there are some modalities that you are happier to fuse than others. And so people have thought that this was also due to priors, which incorporated knowledge about when information is usually synchronous or not. So there are situations where humans are not optimal. And so this is just an example. There's also some research looking at development, and it's known that things change with age.
00:23:43.918 - 00:24:04.502, Speaker B: And in particular, it looks like the behavior becomes adult, like in children, only when they reach something like ten years of age. And before that integration, they don't integrate as much. So that was, for the first part, sensory integration. I think it was the start of.
00:24:04.598 - 00:24:06.630, Speaker A: Yeah, sorry, I was just going to ask.
00:24:06.662 - 00:24:11.954, Speaker E: So is Bayesianism learned, then, if small kids don't do this, don't do this integration.
00:24:17.244 - 00:24:29.064, Speaker D: I mean, there's experiments within kittens where they remove their vision and then they don't do the integration. I think there's a critical period for some of this.
00:24:30.564 - 00:24:58.704, Speaker B: Some people have normative explanations for that. And the reason would be that the different modalities are maturing and that you still. You don't want to fuse all the time. And maybe in childhood you want to keep access to all the modalities separately when they continue to match. Otherwise it would be too confusing somehow. But it's a good point. But we'll come back to this, I think, in the controversies, ideas about learning, at least.
00:24:58.704 - 00:25:55.244, Speaker B: So the second topic I'd like to talk about here is whether brains form a representation of the past information that we can think of in terms of a prior belief and combine it optimally with current information. So there's also a lot of research regarding those kind of questions, clearly. So the question we want to know is how the brain is making use of previous information and what kind of priors it's working with. Clearly, to look at this priors, we need to look at situations of uncertainty. So it's in situation where we have very little incoming information that we are going to rely on our past experience. Just like if we are waking up in the middle of the night and we have to find our way, we are going to rely on our memory about the room. Clearly, how much the prior is going to influence the posterior depends on the width of this distribution.
00:25:55.244 - 00:26:41.978, Speaker B: So we want to look at situations of a large uncertainty or ambiguity. And these priors we are looking for to make sense in a bayesian sense, should reflect the statistics of the sensory world. So they should be a summary of past experience. But it's not clear on which timescale we are thinking about. That's also a question we can ask, which are the timescales that matter. So, to look at these sort of questions, people are often turned to visual illusions. So situations of uncertainty or ambiguity, like this one, where if you have never seen that before, you will probably see a lake when there's no lake.
00:26:41.978 - 00:27:32.594, Speaker B: And so things like this, we think, tells us a lot about the assumptions the brain is making. And so the brain is very happy thinking here the trees are vertical, this person is vertical and reconstructing everything. So that remains true even if it's not. And so people have looked at a lot of illusions, thinking that these illusions gives us insights about the sort of assumptions that the visual system makes. And people have identified a list of that the brain seems to be working with, or expectations that the brain has. It has an expectation that lights come from above, above us. And that's how it is interpreting these shaded objects in terms of convexity or concavity.
00:27:32.594 - 00:28:17.948, Speaker B: If light came from below, we should interpret things in the opposite way. So the light come from above seems to be a very strong. The brain is using to recover 3d dimensions out of 2d images. There's also research looking at the perception of orientation and looks like the brain expects things to be mostly vertical or horizontal. There are illusions which are related to seeing things as being more vertical, horizontal than they really are, which also would be true in the natural world. There are illusions related to smoothness, or behavior related to smoothness. We expect things to be smooth in space and smooth in time.
00:28:17.948 - 00:29:00.124, Speaker B: And again, we are happier to reconstruct things as being smoother than they really are. And also, David Neal has worked on priors related to symmetry. So we also expect things to be symmetrical and illusions related to that. Another prior that people have worked on, including us, is the notion that we experience expect things to be mostly static or moving only slowly, which would also explain a lot of illusions reported in the motion literature. And so these. Sorry. These illusions have been recently formalized in bayesian terms and models compared to behavior.
00:29:00.124 - 00:29:53.770, Speaker B: So I'll just describe a few things along these lines. So there is, so I've said this literature about the slow speed prior. So initially, the literature about this low speed prior was inspired by this problem of the aperture problem. So many of you probably know about the aperture problem. The aperture problem is the idea that if you have a line segment behind an aperture, which is what we think visual receptive field, see, we unambiguously see the motion of this as being perpendicular to the line, even if in reality, there's an infinity of interpretations that would be consistent with this image. And so you can ask yourself why the brain chooses this interpretation in such a strong way. Again, here, you can't do anything about this.
00:29:53.770 - 00:30:56.864, Speaker B: Even if you know the actual motion here, you can't control it. And one explanation, which came initially from psychologists, was that maybe the interpretation that we choose, which is perpendicular to the orientation of the line, it actually corresponds to the interpretation with slowest speed. So maybe somehow the brain expects slower speeds. And when it has to choose between different interpretation, will choose the interpretation with slower speed. And so this idea has been used recently and very elegantly by the group of aero Simoncelli. And so not that recently anymore, but there's a lot of different illusions in the motion literature. So, sadly, this link doesn't work anymore, but a lot of illusions which are related to, when you change the contrast, you see things as moving in a different direction, which are related to this aperture problem.
00:30:56.864 - 00:31:43.174, Speaker B: And so Arrow showed that with his collaborator, Weiss and Adelson. They showed that with a very simple model, which uses a prior and slow speed, you can give a unifying explanation for all these different motion illusions that before them had been explained by different models. So they view then all these motion illusions as optimal percepts, because they use this prior on slow speed, which they think makes sense, given that probably in the world things are mostly static or moving slowly. So that was an influential paper in the field showing that we can explain a lot of illusions with these priors.
00:31:44.634 - 00:32:07.388, Speaker A: The effect remain if the movement is very slow to, because if I move the line very slowly, maybe I don't have to add a correction, perceptual correction, because it already looks slow. But do you know how these effects are being influenced by the speed of the change?
00:32:07.516 - 00:33:01.406, Speaker B: So we've looked, and I'll describe this, we've looked at situations where things are moving fast, on the contrary, and look at whether people are going to update their prior to account for these new statistics. And we find that they do. So people, if you show them a lot of fast stuff, they will end up with a prior for faster motion. But it's not completely clear, and at least it was not clear at all then how this prior relates to experience and how flexible it is, and how it relates also to the statistics of the world, which would be difficult to measure. So they went on, so this is the work by Alan Stocker and Simon Shelley. And so in this work, they had assumed a gaussian prior and showed that this was consistent. So the result was consistent with a lot of these illusions qualitatively.
00:33:01.406 - 00:34:24.464, Speaker B: But they went on and they decided to use this kind of framework to actually measure in individual participants the prior that would be consistent with their behavior. So by fitting this bayesian model, so here they look at an experiment where people have to do discrimination between sort of the speed of different objects, and so they compare speed and the different level of contrast, so uncertainty. And so based on data like this, and fitting Bayesian model with a flexible now speed prior, what they do is then measure in individual participants the shape of the speed prior. So the idea here was to test whether people really use the gaussian prior or some other form of a prior, and also look at the viability between different peoples prior, and whether by looking at models like this, we could actually quantify viability between different people. And so in this paper, they give a sort of methodology. So, based on experimental data, psychopath physics fit those bayesian models and extract for each individual the bayesian prior that is most compatible with the behavior. So that's interesting, because it means we have a new tool to look at inter individual variability and look at the internal model that people are using that is consistent with their behavior.
00:34:24.464 - 00:34:57.864, Speaker B: Does that make sense? And then you can ask a lot of questions. When you can do that. It's also you can ask whether this prior that you are measuring in people's head kind of whether it makes sense, and in particular whether it makes sense compared to the statistics of the visual world. And so in this work, that's what they did. They compare. So they look at orientation here, and they look at judgment about tilt. And we know that judgment about tilt are very biased towards the cardinals and oblique as well.
00:34:57.864 - 00:35:56.406, Speaker B: And so based on their measurements, they could extract a basin prior that was compatible with the behavior. And they compared this prior with the statistics of orientation in a large collection of photographs. And they showed that qualitatively at least, the prior that people seem to be using in terms of orientation seems to fit with the statistics of orientation in natural scene statistics. So qualitatively, at least, it looks like the prior that people have in the head matches with the statistics of the natural world in this case. So that's the kind of question you can ask. We've interested in another type of question, which is whether people form priors all the time, whether we have kind of fixed priors for this natural scene statistics. Statistics are whether in a new context, we would form new priors that we will use as well.
00:35:56.406 - 00:36:36.698, Speaker B: And so, to do this, we've looked at very simple experiment involving motion perception. So we add people coming in the lab and looking at clouds of dots moving on the screen. And people had to do two things. They had to estimate the motion direction, so they had to tell us in which direction those dots were moving, and the contrast was going to go really low. The staircase, in contrast, is going to be more and more uncertain, ambiguous what's going on. And we also asked people to tell us whether they've actually seen dots or no dots. And so in this experiment.
00:36:36.698 - 00:37:20.864, Speaker B: So, yeah, it looks like this. So people have to move an arrow to tell the direction of the dots, and they have to do then this detection task whether they've seen dots or no dots. And so they do that for 2 hours on two consecutive days. So 1 hour each. And so what we don't tell the participants is that not all motion directions are equally likely. So in these experiments, two motion directions -32 and 32, are more frequently presented than the other motion directions. So what we are asking is whether, if they are statistics like this, whether participants are going to learn implicitly that some motion directions are more likely to appear than others, and if they do, how this is going to bias their perception.
00:37:20.864 - 00:38:06.938, Speaker B: So I'm not going to go into all the details, but what we find is that people are not conscious that some motion directions are more likely than others. If we force them to report about this environment that they've been presented with, they have no idea. They think it's all the same. But if we look at their behavior, we find that they have learned that some motion directions are more likely than others to appear, and this strongly biases their perception. They become better and faster at detecting those most frequent direction. Also, there are some trials where there's actually nothing on the screen. But we forced people to tell us the direction of motion if they've seen something, and to tell us whether they've seen something or not.
00:38:06.938 - 00:38:28.782, Speaker B: And on some trials, even if there's nothing on the screen, people believe they've seen something. And when they did, they have also reported some motion direction. So we can look at this. And that's the black line. When people think they've seen something when there was nothing, often it was in the direction of the expected motion direction. We have folded everything in two. So 32 is the.
00:38:28.782 - 00:38:39.502, Speaker B: The most frequent direction. So we interpret this as a form of very simple hallucination. There's nothing on the screen, but people end up hallucinating what they expect should happen.
00:38:39.598 - 00:38:44.446, Speaker A: What percentage of people tell you that they have detected motion?
00:38:44.590 - 00:38:53.206, Speaker B: So everybody does, but on a very, quite low number of trials, and the number varies. And also look at the viability of.
00:38:53.230 - 00:38:56.604, Speaker C: That they report also that direction that they think they saw.
00:38:56.724 - 00:38:57.424, Speaker A: Yeah.
00:38:57.964 - 00:39:27.150, Speaker B: Yeah. So the black line, for example, is they report the direction, but that's the situation when they tell us, I've seen something, red is the situation where. So that's the direction they report, but they've told us correctly. They've not seen anything. Yeah. Oh, I wonder if they don't have to perform the discrimination task, but if they are just, like, passively watching the screen, like, do they update the priors as well? Just so. We've never done that.
00:39:27.150 - 00:39:46.634, Speaker B: I assume so. That's a good question. So we also showed that. So they end up hallucinating what they expect. And we find that this effect was fast to develop. It was a matter of minutes, really. 200 trials that people start to develop these simple kind of hallucinations.
00:39:46.634 - 00:40:27.824, Speaker B: And also. So in the trials where there was actually some motion on the screen, we look at the estimation answer, and what we find is that there are strong biases, and people report the motion direction as being more similar to the most frequent direction than it really is. So when there was nothing on the screen, they tend to hallucinate what they expect. When there is something on the screen, they tend to see reality as being more similar to what they expect. And it really is. So then with this you can fit bayesian models. And the idea is that whether you can explain this in terms of people forming a prior belief and combining this prior belief with evidence.
00:40:27.824 - 00:41:13.454, Speaker B: And so mostly that's what we show. So we fit bayesian models, a family of them. We also fit different models that are more like decision biases models. And by fitting those models we can also extract so the likelihood and the priors that corresponds best with people's behavior. And so what we find is a lot of viability, but usually we find that, so we can extract priors for each individual and they correspond to rough approximation of the stimulus statistics. We do a lot of model comparison to convince ourselves that the bayesian explanation is the best. And it is at least it's the one that is most elegant, that describes the data in less parameters.
00:41:13.454 - 00:41:51.304, Speaker B: So that's an experiment that we've done some time ago and we've continued. I think it's interesting because it shows that participants learn very quickly about the statistics of the visual environment. It's unconscious. We don't know that we are doing this, but it still biases our experience. We hallucinate what we expect and we see reality as being more similar to what we expect than it really is. And this behavior is consistent with bayesian inference with people working with the learns prior, which is far from being a perfect description of the stimulus statistics, but a rough approximation with a lot of variability.
00:41:53.844 - 00:41:58.184, Speaker E: Did you show this? It would be interesting to see the priors developing in time.
00:41:59.304 - 00:42:02.724, Speaker B: Yes. So that's also something we are, we are looking at.
00:42:03.064 - 00:42:14.764, Speaker A: Yeah, in some sense it indicates that. Very robust, because I tend to see the following evidence as strengthening my probability.
00:42:15.224 - 00:42:55.066, Speaker B: Yeah, yeah, sort of confirmation bias can. So we are looking at dynamics. The problem here is it's, it's very fast and those hallucinations in particular, we don't have a lot of them, so the data is quite sparse. So it's not easy. But this is something we are looking at at the moment. So other types of questions you can ask related to this, and so I'll come back to this experiment as well, is whether all types of priors are flexible, you can update them or some are fixed. And so there was some debates initially about the light from above prior, for example.
00:42:55.066 - 00:43:26.868, Speaker B: So this assumption that light comes from above, is it something that is fixed or can you change this? So people are done in the sixties, I think experiments in chickens that were raised in an environment where lights come from below and looking at how they interpret 3d objects. And they found that chickens never adapt. They still think the light comes from. So I think initially people thought that this was genetically wired, and maybe it is in chickens. I don't think it has been replicated, but in humans, though. So people have been interested in these questions. And in humans, it looks like people can update.
00:43:26.868 - 00:43:58.960, Speaker B: And so this was shown initially by Adams Graf and Ernst, nature neuroscience. They look at an experiment where you have those 3d shaded objects and you can see them, but you can also touch them, and you can introduce a conflict between the vision and the tone touch. And you can make whatever is convex, concave and vice versa. And in this experiment, they show with this strong feedback that people end up adjusting slightly, not completely, but they end up changing their prior by the light from above.
00:43:59.072 - 00:44:02.124, Speaker E: How did they do this in chickens or with chickens?
00:44:03.424 - 00:44:46.564, Speaker B: So there was no bayesian modeling involved. They were just at the chickens raised in this environment with light, so dark environment, where light comes from below. And then they looked at the behavior. They add objects a bit like this, where they looked at how they picked it and how they behaved from their behavior, how they interpreted the 3d shape. I'm not sure about the details, but we've looked at this again. So what's interesting in this experiment, this shows flexibility, but this is a situation with very strong conflict. We looked at the same kind of question, but now with a slow speed prior, and in a situation where you don't have a conflict, you just have exposure, you don't even have feedback.
00:44:46.564 - 00:45:29.694, Speaker B: So the question we asked in this experiment is similar to the question I had, is, so people have a slow speed prior. It looks. But what if you are testing them in an environment where things go fast? Are they going to end up adjusting for this? And so basically, we played with this motion illusions which are related to this slow speed prior. So we measured those illusions first, and then we showed. So this is like the aperture problem, I don't see, but this is moving. And because it's so, this is an area of lines and they are moving coherently. And because of the aperture problem, you are biased to see motion as being perpendicular to the orientation of the line.
00:45:29.694 - 00:46:17.084, Speaker B: But so if you are showed that for a long time at a faster speed. And then I test you again, which is what we did, what we find is that after a few days, people end up having the opposite percept. So instead of seeing motion as perpendicular to the line, they see it as being more often oblique, which is consistent with now, assuming that speed is faster than the motion display. So we thought it's interesting because, yeah, it's just exposure. People adapt just by exposure, the speed prior they are working with. And so we did the modeling as well to see here how this speed prior then changed from day to day. So flexible priors, even for what we think correspond to the statistics of the natural environment.
00:46:17.084 - 00:47:10.362, Speaker B: So that's also a field that is growing. And there's a lot of questions you can ask with these sort of paradigms. The questions I've been interested in, and other people as well are what are the limits of prior learning if you have very complex priors? Often people have unimodal gaussian priors, we have bimodal. But can you increase the complexity of those priors? And things would still. So people would still learn. So how many priors can we learn simultaneously? Also, there are very interesting questions to ask about generalization or transfer. So here, for example, when people adapt this low speed prior and they go out of the experiment, are they going to use this new prior for looking at cars or not? And so people have found, Wendy Adams in particular, that people learn priors for specific context and they keep it for that context.
00:47:10.362 - 00:48:12.716, Speaker B: And so when they go out of the lab, they use the priors they had before. So we are just, there's a lot of unknowns here where the priors are specific to stimulus task, experimental context. People are also interested in the time scale of learning, including us and so on, learning on this priors and how we can measure that. Also, people have described the fact that maybe people are not really learning priors in the form of probability distributions, but maybe sometimes simple heuristics, by just summing the mean of the past five, say, trials, can also explain the data. So simple heuristics also can often explain the data well. And that's an interesting literature about what kind of heuristics then the brain yet to finish up a bit about this part. So I think in psychophysics, yeah.
00:48:12.820 - 00:48:35.000, Speaker C: Can you turn back to the previous? So when you ask what are the limits of prior learning? Complexity, it also refers to like how deep the tree is or something like that. How like, because we have piles that go like, go inside like many levels or something like that. So this is what you mean by, by complexity also, or in our case.
00:48:35.032 - 00:49:04.086, Speaker B: No, it's really the shape of this. And also, Luigi, what he has done is really playing with the shape of this distribution. So like the motion distribution here and looking at how finely people can learn this shape. But of course, yeah. In particular, if you start asking about structures and the prize people have about the structure of information. This is all kind of other types of complexity you can think of, hierarchical. Often we use very simple models.
00:49:04.150 - 00:49:15.886, Speaker C: Is there experience of how deep our networks of belief updates when we get different data than what we already know?
00:49:15.950 - 00:49:46.724, Speaker B: The other end, I think there is a little bit, yeah. And also when people look at, I've seen, I don't remember the name unfortunately, but people looking at whether, when people learn about structures, whether with learning, people learn about changing structures or changing in parameters. But I think it's just the start of this kind of research, and often we are limited in the model we can fit by the nature of the data.
00:49:48.704 - 00:49:57.700, Speaker A: Most of these experiments, visual or the other types of sensory biases that have been investigated?
00:49:57.772 - 00:50:16.044, Speaker B: No, no, probably vision is the dominant research, but there's a lot of things also in the temporal domain and also, yes, sensory motor domain. Now, it's by no means not only vision, vision is where I come from, but it has experience on this world.
00:50:17.784 - 00:50:35.624, Speaker A: I think. So the last question is the most important. I mean, so we saw lots of priors here in the lecture, and the question is, does the brain use this bayesian model in order to predict what is happening or some other model?
00:50:35.784 - 00:51:31.914, Speaker B: So I come back to that and the question about whether the brain is bayesian and whether that makes any sense at all to ask that question. Hopefully I get to that. So what do we learn? I think in this field, bayesian models are thought at least as elegant description of behavior. So efficient tools in terms of benchmark, but also efficient tools for describing behavior, the assumptions are often transparent. People think that's one of the advantage of these models. I think the behavior we find in vision, but not only in vision, is that it's clear that brains take into account uncertainty, combine information in a way dependent on the reliability of the different sources of information. It's clear that previous, but in a way it's trivial, that previous knowledge is taking into account and that previous knowledge is updated at all time and taking into account when interpreting new information.
00:51:31.914 - 00:52:50.550, Speaker B: Those priors that we can measure with those tools are consistent with some approximation of the statistics of the environment. What we find, as all experimental research, we find a lot of viability and we find that these are only like rough approximation of the statistics of the environment. But it seems to make sense from the disposition point of view what we find in gel. So, and a lot of people that report that the Bayesian model very easily fit very well the data they see. There's a lot of interest as well in deviations from optimality, though I don't know. There's not a lot of work trying to understand the reasons behind suboptimality, although there is in trying to relate to these heuristics. But this is more often more of an open question, how much sub optimality is there, how can we quantify it, and how can we relate it to heuristics? But for example, as I said, in multisensory integration, we find differences in development and that ideally that will give us constraints about the machinery that is behind.
00:52:50.550 - 00:53:17.454, Speaker B: Of course, that's the hope. So I'm particularly interested in the fact that those priors we can measure now in different people. So the prior beliefs, but also cost functions, likelihood, and this give us a new tool, maybe to quantify inter individual viability, and so that we can use to look at different groups, for example, and as I will transition to many, maybe mental illness.
00:53:18.354 - 00:53:41.014, Speaker C: Yeah, I'm just curious. So, like, when you speak about bias in optimality, you always, like the way I understand, you usually assume gaussian distributions, right? And this, like gaussian distributions are not maintained under non linear coordinate change. And yet you have many examples of optimal Bayesian, you know.
00:53:41.934 - 00:53:43.234, Speaker B: Yeah, I come.
00:53:43.974 - 00:53:54.474, Speaker C: It's not surprising that you are so lucky by guessing what are the true coordinates used by the brain, even though there are infinitely many possible.
00:53:56.214 - 00:54:22.870, Speaker B: I'll come back to that. There's been a lot of literature as well about differentiating bayesian and optimality and probabilistic. And maybe the notion of optimality is actually not a very good question to ask. I will come back to as well, because. So we can fit a Bayesian model to about anything. And so, and so that's not, that's not because we can fit a Bayesian model that we can say the system is optimal. But I'll come back to this.
00:54:22.870 - 00:54:55.552, Speaker B: Maybe we're certainly, we're not interested in only a gaussian distribution. Yeah. So I'd like to describe a little bit things about mental illness. That's a. So, computational psychiatry, as it's now called, is a really new field, which is growing really fast in the past five years. This is a lot of literature, but a lot of open questions. And so we think bayesian models are interesting in this field because maybe we can.
00:54:55.552 - 00:55:56.522, Speaker B: So if you think of people interpreting the world through the lens of their internal model, then maybe we can describe mental illness in terms of people having simply different internal models. And maybe with those kind of tools, we can try to measure those differences and how they have consequences in the behavior. So, for some people, including me, maybe we can describe mental illness in terms of differences in the models of the world that people's brain are working with. For example, different priors. So, for example, in depression, maybe people have pessimistic priors, or you could have paranoid priors in schizophrenia or priors in mistrust and borderline. Also, people have looked at priors about control, controllability in depression, the idea that you don't control much about the outcomes in the world. So maybe different beliefs, people work with different beliefs, and that can explain different disorders.
00:55:56.522 - 00:56:53.392, Speaker B: And also, there is the idea that maybe the way people combine incoming information with prior beliefs differs in mental disorders. And in particular, there's the idea that in schizophrenia and autism, in particular, the way incoming information is. Is combined with prior belief is somehow imbalanced. And so either. So, in general, it's thought that the weight given to the prior is actually weaker in autism and maybe stronger in schizophrenia, at least for cognitive priors. So, this is a new area of research, and there's a lot of interest from psychiatry because it goes well with the idea of. Of beliefs that would be different and the idea of measuring those differences in belief in different kind of populations as a whole.
00:56:53.392 - 00:58:12.194, Speaker B: I think in this field, we view mental illness as possibly an impairment in prediction, which would be due to having a distorted internal model of the world, which possibly would be due to either having had different experience, for example, trauma or impairments in learning, possibly due to impairments in the biological substrate of learning, for example, dopamine or NMDA. So that's the kind of ideas that are quite popular at the moment and that we want to test. So, these ideas have been published in the best journals. So, for example, in schizophrenia, it's been thought that. So there'll be a bayesian impairment in schizophrenia. It's quite messy, but the bottom line that people propose is that the idea mostly is that sensory priors would be too weak. And so that would lead to a changing and unstable world where things would be perceived as being salient when they should not.
00:58:12.194 - 00:59:01.536, Speaker B: So at the perceptual level, the price would be weaker, and maybe to compensate for that, at the cognitive level, the prize would be stronger. So the beliefs would have more impact on the experience. And that could explain hallucinations, where people would perceive their beliefs, or delusions, where they also have very strong belief that they can't change. And there is some experimental literature that is consistent with this, in particular. So, if you look at sensory illusions again, you find differences in schizophrenia and you find that people with schizophrenia are less sensitive to visual illusions, for example, than controls. And of course those beliefs at a higher cognitive level seems to be stronger than controlled. People think about in terms of impaired predictions in schizophrenia, this doesn't work anymore.
00:59:01.536 - 00:59:11.484, Speaker B: And very similar models have been proposed in autism. The idea is that in autism the sensory priors would be weaker.
00:59:14.144 - 00:59:27.384, Speaker A: You don't have to go to mental illness. I mean, think of religion. It is some kind of a trial. We keep, people really just keep interpreting the reality as if it strengthens this prior.
00:59:27.964 - 01:00:26.880, Speaker B: Sentimental, I'm not going to go into that. But we look at schizotyping. So interestingly, we look at, we are going to measure schizotypy in individuals and to find people with high schizotypy, we look at people with paranormal beliefs and to recruit them, we ask people who think they have a different connection with the world and paranormal experience. So whether it's the same thing, there's a literature about this, whether it's same thing or different. So in autism, there's this idea as well that the sensory priors would be weaker. And so this is consistent with the fact that we know there is deficits in contextual integration in autism, and also that often people with autism can be overwhelmed with the sensory input, as if they can't inhibit it by the context. So in the literature there are proposals that the sensory price would be weaker.
01:00:26.880 - 01:01:24.814, Speaker B: But it's also been noted that maybe it's not that which is happening, but maybe what's happening is that the likelihood, the precision of the vision or sensory representation is actually, it's more precise. So the likelihood would be sharper and that would have the same kind of consequences. But it's a completely different model, where here then, people believe that sensory precision will be actually higher in autism. Is there a data or is it more likely to have simultaneous autism sarcophrenia than random or less likely? Yes, there is some comorbidity. And in our data we measure schizotype E and AQ and we find a correlation, but they still think thoughts to be completely different disorders, of course, but both have social consequences. And so that's what you see as well in the questionnaires and the scores. So maybe the priors are too weak, or maybe the likelihood are sharper.
01:01:24.814 - 01:02:21.512, Speaker B: Also, other people have proposed that actually the priors are maybe similarly sharp or narrow or broad, but they are maybe more rigid and there's a lack of transfer of priors. So the bottom line is that this is a flourishing field, but it's very qualitative. Psychiatrists like it a lot because it's a new way to describe things and me and other people are interested in trying to see if this is actually quantitatively testable and how we can do that and also, of course, how useful that would be. So the type of things we've been doing is use that experiment again that I've described. So the exact same experiment was just 1 hour and a bit shorter to make it a bit easier. And now we are testing different kind of populations. So patients with schizophrenia, at the moment we have 22, we are testing people with clinical diagnosis of autism.
01:02:21.512 - 01:03:06.062, Speaker B: They're just starting, we just have eight at the moment. But also we have a larger cohort of people, people who are healthy, these are students. But we've tried to find people with high acute autistic traits or high schizotypes by looking at people with paranormal beliefs and things like that and have them do our experiment. And so we think it's interesting compared to what has been done before, because now we are really in a situation where people are learning new priors and we can see the impact of these priors on perception. And also we have a quantitative Bayesian modeling where we can really test those ideas. So I'm not going to describe all of it. So in a nutshell, what we find is that the schizophrenic patients behave very similarly to the control.
01:03:06.062 - 01:03:43.096, Speaker B: We find a slight difference in the number of hallucinations in that they actually hallucinate less than the controls. But mostly the data is very clean and they show beautiful statistical learning. One reason might be the medication, and that those, those patients who can do our experiment are well and they've been well for a long time. So there might be differences, but with the number of patients we have, they are really subtle. In schizotypy, similarly, we don't find anything interesting, interesting at all. But with AQ we have some interesting results. So I'm going to show this.
01:03:43.096 - 01:04:14.762, Speaker B: So this is, again, is LC participant, but we are now confirming the same thing in patients. So we are happy with our cohort because we have quite a large range of scores of AQ. Also, AQ compared to schizotype is much better defined. So people agree that this questionnaire, which has 50 questions, the AQ, is a good descriptor of autism. Even if it's not a diagnostic tool, it is accepted as a good way to describe autism. Whereas schizotype has many different questionnaires. We don't have a good correlation between the scores.
01:04:14.762 - 01:04:48.044, Speaker B: It's much messier. So we have a range of scores. Some of them are actually at the clinical level, even if these are LC people. And what we find. So I'll go fast, but what we find is a number of differences. So mostly we find less bias, we find less noise in the estimation, and we find less hallucination in people with higher AQ. And so we can quantify this in terms of correlation with AQ.
01:04:48.044 - 01:05:52.534, Speaker B: And again, so we find less bias, less noise in the estimation performance, and less so smaller number of hallucinations, which is so consistent with the previous literature about the fact that maybe prior beliefs would have less influence in people with autism here, autistic traits. But we can do better than this because now we have this bayesian model, so we can look at whether it's really, it's the Bayesian prior, which is different, or the likelihood. We can also test other models. Of course, what we find, interestingly and unexpectedly, is that the difference we have is not in the prior, but it's more in the likelihood. So it looks like the behavior of people with autistic traits here is more precise and their likelihood is sharper. And it's because it's sharper that the influence of the prior is weaker. It's not that they don't learn the prior, but it has less influence on the percept.
01:05:52.534 - 01:06:09.536, Speaker B: And so that's interesting. It's also going to be controversial because it supports this nonsensory precision model that has been debated for a long time, whether people with autism actually perceive the world in a finer way than controls and in which kind of situation. It's a very messy literature.
01:06:09.600 - 01:06:19.160, Speaker A: Interestingly, it is known that they are more sensitive to noise or to light. They suffer more easily from. I mean, that's something.
01:06:19.232 - 01:07:09.894, Speaker B: Yeah, but if you look at the data in terms of discrimination, performance, for example, you find results in different ways in some. Some people find better discriminability, some people less. It depends for motion, depends on whether you have first order motion or second order for orientation, you find something else. The data is actually messy, but it's been there for a long time and people really believe that's the case. But now also we need to test actual patients with autism, which have much more severe autism, and see if this is due to the fact that these are actually very, very highly functioning students. Actually, it would be different with people who actually impaired somehow by their autism. But I think it's an interesting result.
01:07:09.894 - 01:08:20.014, Speaker B: So that's for this part so I wanted to show it as an example of what we can do. So to use those bayesian tools to test these current theories which exist in psychiatry and are quite prominent at the moment to test if so, there is the claim that bayesian inference, whatever it means, would be impaired. So we can try to test that or maybe quantify differences in internal models, in priors and likelihood and see what exactly is different. So we are making some progress in that. Ultimately, as I'm sure you know, there is a bit of a crisis in psychiatry with even the classification of diseases is controversial. People really hope that this kind of tools, so not only bayesian tools, maybe also reinforcement learning, all the computational tools, will give us a way to describe behavior differently and maybe revisit the classification of disease as a vocabulary which we can use across the dimensions of diseases, which will be useful in describing differences.
01:08:22.234 - 01:08:49.102, Speaker D: So I'm interested in the fact that you didn't find anything with schizotyp. Do you know the Walpert paper about schizophrenics and force escalation, basically estimating the effects of their own actions? And do you think that that might have something to do with it? And in terms of passively sort of sensing something versus being, we did expect.
01:08:49.198 - 01:09:45.938, Speaker B: Based on previous research, that we would have strong differences with schizophrenic patients. It's, again, the literature is very messy, but people looking at visual illusions have found differences even in the visual domain, and things which are similar to us, sometimes strong differences of, or let's say some differences, have been reported. We expected initially to find more differences in schizotypy than in ASD. Yeah, some people think ultimately maybe we can use those tools even for diagnosis and in the clinic, but we are far from that. But that's the ultimate goal, of course. So I just finished with all the messy questions. So what does this tell us about the brain? Which I think is interesting, but it's a lot of messy questions.
01:09:45.938 - 01:10:40.712, Speaker B: So not everybody is convinced about the value, the interest of this Bayesian framework. There's been debates in the literature, and that's a quote from this paper about ESM Davis. Our main thesis is that Bayesian modeling, both in practice and in principle, is a misguided approach to studying the mind and the brain. And I think some people believe that we are never going to learn anything about the substrate of the brain and how these things are really implemented in the neurobiology. And so I'll describe a little bit of controversy, which I think is interesting and I think is making the field progress as well. I think the main criticism is that this framework has made little predictions for neuroscience, really that can be testable in neuroscience. And the typical reply to this is that it was never meant to.
01:10:40.712 - 01:11:31.528, Speaker B: And so we saw those levels of MA before in the previous lecture. So, as you know, Ma has described that. So the three level of analysis, the computational level, algorithmic level, implementation level here, clearly, this bayesian approach lies at the computational level, and so whether it can actually constrain or predict anything at what would be the implementation level is not clear at all. And it really meant to describe this at this level. And so the reply to this controversy by the bayesian camp is to say that the bayesian models were never, are not intended to provide mechanistic or process accounts of cognition. And the other thing is, of course, that nobody believes that exact Bayesian inference will be implemented. So it has to be an approximation of Bayesian inference.
01:11:31.528 - 01:12:01.420, Speaker B: And so how Bayesian and approximation of bayesian influence is going to be. It's not clear how far from Bayesian you can say when you are an approximation. It's not clear. So the different. So these papers are quite fascinating because they are really aggressive. So the points that have been discussed are points regarding optimality. There was, the notion of optimality was quite confusing in the initial paper and what actually was claimed.
01:12:01.420 - 01:12:47.612, Speaker B: So initially, people were found bayesian optimality everywhere, in babies, in frogs. So the question is what we meant by optimality when we were fitting those bayesian models. And so clearly, it's not that the system is optimally designed, but it's more that. So the combination of the noisies inputs is optimal. The way uncertainty is taken into account conforms Bayesian inference. That's what people meant, really, there are very important and difficult questions about falsifiability. And so again, the critique is that you can fit any kind, any data with a bayesian model if you have the right prior the loss function.
01:12:47.612 - 01:13:39.524, Speaker B: And so clearly then it became clear that the question of asking whether the brain is bayesian doesn't make any sense. And so the replies then, is that the Bayesian approach is a framework. A framework is typically not falsifiable. Only implemented models which have different parameters or structures can be compared and then be falsified. But then the question is, if it's a framework, what is the alternative framework? And I don't know a good answer to that. So clearly, what we have to do is not ask whether the brain is bayesian, but like, try to compare a family of models and find the models that are most compatible, what the brain does, and it's in those details of how the models are made that we can get information. It's not in the claim about bayesian or optimality.
01:13:39.524 - 01:14:27.004, Speaker B: So similarly to this, one critique was that those models were not compared to previous models often. And the reply to this was that, yes, but previous models were cast at a different level. They were either at the algorithmic or the implementation level. And so it doesn't make any sense to compare them. They might be completely compatible. So you can have a neural network using backprops that is actually going to be an approximation of Bayesian inference. Another critique, which I find difficult, is that whether people are just reinventing the wheel and it's just a new vocabulary to describe things that people knew before.
01:14:27.004 - 01:15:49.904, Speaker B: And so I guess the reply is that it's a useful vocabulary that gives us new insight, but clearly what we call priors, other people have called memory or plasticity. And so, and so, the link between the different vocabularies, it's not clear how to integrate knowledge as it was described before with this new framework. And finally, the most difficult critique, I guess, is the lack of neurobiological predictions. And again, so the answer to this, which is still unsatisfying, though I think, is that this approach is not in incompatible with a previously proposed mechanistic model, not even models that would be based on simple heuristics. And so the bayesian camp here replied to that there needs to be nothing intrinsically bayesian about algorithms that approximate Bayesian inference. But again, that means that in terms of the prediction, the signature we should find about this bayesian computation in the neurobiological substrate, it's not clear what we should look for. So just then, I have a few slides about still the fact that people are still working on trying to bridge this bayesian approach and the neurobiology.
01:15:49.904 - 01:16:56.190, Speaker B: So there exists models. And so first of all, there's a question about representation. How would neuron represent probability distributions? And so Peter Lath will be here, and Sophie Deneuve, and they can talk about this much better than me. But there are different models, and some assume that probability distributions are really represented entirely at all times in the brain, either the priority distribution or maybe the log of the probability, or maybe the way those priority distributions are represented is by representing the parameters of this distribution, maybe using a basis function. But the idea is that the probability distribution itself is represented probably implicitly in those models. Other people think that the way the brain work is really using sampling and so the activities represent, and we've seen that also in previous lectures, the activity will represent the latent variables themselves. And the variability that we would see would correspond to the uncertainty.
01:16:56.190 - 01:18:09.826, Speaker B: So the viability we see in the responses would correspond to the sampling process of the distribution. Often an example is given that is suggestive of this sampling hypothesis, which is the example of the necker cube or binocular rivalry. And so there's been some work trying to relate this phenomena with so models that would actually have bimodal posterior distribution and be sampling from this bimodal distribution, where the two modes would correspond to the two interpretation. And using algorithms such as MCMC, they can reproduce dynamics of transitioning from the modes that are very similar to what we see experimentally. And so often people think of this kind of phenomena as sampling from a bimodal distribution and from time to time transitioning to the other mode. I'm interested, of course, in the neural substrate of priors and how we can think about this. And that's actually difficult.
01:18:09.826 - 01:19:01.844, Speaker B: People think about this in many different ways. So you can think about where are those priors living in the brain. There is, for example, some fMRI study where they do an experiment very similar to the experiment we've done, and looking at where you would see the signature of the prior in the visual stream, and whether the activity you see, say, in v one is already the posterior or is the likelihood. And they find that there is evidence, even in v one, of the combination already of prior and likelihood. Some people think of priors in terms of top down inputs, those feedback projections, which we don't really know what they do, they might be predicting, and it might be the prior. People try, some people try to look at expectations in terms of viability in the activity of neurons. And for some people, this is going to be more like an increase in activity.
01:19:01.844 - 01:19:31.444, Speaker B: And actually, expectations and attention are very similar phenomena. So sometimes they behave the same. And then so expectations would relate to increased in activity gain, modulation upward. But also adaptation can also be sort of in terms of an expectation. And so adaptation, as you know, is again modulation downward. So, and it may depend on whether the signal is actually relevant or unrelevant. Maybe when it's relevant, it's actually upward and non relevant downward as.
01:19:31.444 - 01:20:21.256, Speaker B: Finally, I wanted to describe two ideas if I have time. Some people have been thinking of priors in terms of the tuning of the neurons and others in terms of the baseline. So I'll just describe quickly in the tuning of the neurons. Again, this is paper by hero Simoncelli but also there's other work coming also to see similar ideas here. So again, they try to relate biases in terms of perception of orientation. They extract the prior with these bayesian tools and they can also compare the prior with the statistics of the visual images. Another thing we know is that in v one, there are more neurons tuned to horizontal and vertical than other kind of orientation.
01:20:21.256 - 01:21:02.104, Speaker B: And so they put everything together and they show that if you have a simple decoding scheme like a population vector, which is reading from a population of neurons which is inomogeneous, this inhomogeneity in itself will act like a prior. And they show with simulations that you can mimic the influence of this bayesian prior just with this population vector reading out from this inhomogeneous population. So maybe we can think of the homogeneity of the preferred features of neurons in terms of a prior trying to bias the activity towards more frequent expected features.
01:21:02.444 - 01:21:15.480, Speaker D: That's true. But you said you could change it in 200 trials, so that has a lot of implications for what mechanisms of changing the network are actually feasible at 200 trials from one session, right?
01:21:15.592 - 01:21:42.804, Speaker B: Yeah. I don't think you can change the bias towards the cardinals, though. And so in our experiments, we have huge biases towards the cardinals and they remain. So, just to come back to this, I think there's a question. The mechanisms there's. In my mind, there are multiple different mechanisms and multiple different timescales. There's no reason why the way priors are implemented in the brain should have one form.
01:21:42.804 - 01:21:56.376, Speaker B: Everything we think about in terms of plasticity memory is a prior adaptation as well. And so I think all these mechanisms can coexist and some are more flexible than others.
01:21:56.400 - 01:22:07.224, Speaker D: Right. So for that time scale, like in motor learning, people would say that's cerebellar. Can you test cerebellar patients their ability?
01:22:07.844 - 01:23:32.748, Speaker B: I don't know about the cerebellum, but in the process that we manipulate in our experiments, for example, I expect to see in v one changes in the neural activity at the time scale that we are seeing the changes, whereas, for example, this bias towards the cardinal, I don't expect at the time scale of an experiment to see any change. So. Yeah, so, and finally, an interesting idea that is out there is that maybe the baseline activity of neurons represents a prior or prediction. And that's an idea that has been proposed by Matthew Angel, Joseph Fisher and others. So they looked at the spontaneous activity in ferrets and they compare the structure of the spontaneous activity with averaged evoked activity with the idea that if it's a prior, it should look like averaged evoked activity for those animals with the evoked activity corresponding to natural scene statistics, thanks to the summary of their previous experience. So that's what they've done in this quite influential paper. They looked at activity in v one, multicellular activity, and they looked at the statistics of spontaneous activity and evoked activity for natural scene statistics.
01:23:32.748 - 01:24:41.060, Speaker B: But in that case, it's the movie the matrix, and also evoked activity that is evoked by simple stimuli like gratings, artificial stimuli. And what they show is that the measure. So they look at a distance between the priority distribution of the spondylons activity and the average evoked activity. And they show that with age, the spondylos activity is going to look more and more like average evoked activity for natural scene statistics and not like average evoked activity for artificial stimuli, just like you would expect if this baseline activity really represent a prior. So a general expectation about what is plausible to API in the world, which I think is an interesting idea, which needs to be further tested, of course, yes, like almost my last slide, how approximate inference would be implemented in the brain. So basically we don't know. We have a lot of ideas coming from machine learning.
01:24:41.060 - 01:25:54.526, Speaker B: So this approximate inference could involve sampling or deterministic approximation method for some people. Some people are interested in variational approximation, which is predictive coding for some people. Some people think that predictive coding is the way bayesian influence is implemented in the brain. So these people also believe that this is very interesting now, because predictive coding then would be a good bridge. So if it's the algorithm by which bayesian inference is implemented, so we know a lot about how predictive coding can be implemented in neurons, and I hope Dana will tell us more about this. And so if predictive coding is the algorithm, then yeah, we have a bridge between what neurons do and the computation. But there are some labs, like Karl Friston, which are actually very prominent in computational psychiatry, which starts from the belief that predictive coding is the way the brain is using, is implementing bayesian infrastructure.
01:25:54.526 - 01:27:02.554, Speaker B: So as a conclusion, so I think bayesian models, I think everybody maybe agrees that bayesian models are very successful at the behavioral level as a benchmark for performance, and that they can be used to look at these internal models, where we still have a lot to understand about how those internal models are learned and the limits of this learning. As you understood, we have at the moment very simple models and very simple paradigm. I'm interested in the application to psychiatry and whether this is going to be ultimately useful for the clinic. There's a lot of confusion about the claims and a lot of debates, which I think is very interesting. Clearly, there's a problem a little bit about bridging this computational level and the neurobiological level. And so we need more models. So there's a lot of models that have been proposed as like, a proof of feasibility that neural networks can do bayesian inference, but whether we can actually determine what's being done in the brain, it's a very difficult question.
01:27:02.554 - 01:27:21.654, Speaker B: So neuroimplementation is largely unknown. And so our take in my lab has been to look at very simple priors, very simple expectation. Now, also, we are going to look at fMRI for this kind of experiments, try to understand better what's going on. Thank you very much.
01:27:28.834 - 01:28:17.884, Speaker E: Well, mostly a supportive comment for the group that believes that roughly you could think the cortex is in banks. So you can see, you think of the upper bank as the prior for the lower level below. And in that, another constraint is learning algorithms. And so when the learning algorithm is running, it's very important to sample the evolving prior. If you maximize maximum likelihood, a winner take all, it won't work. So you have to be bayesian to have the thing converge. And the other thing is, if you're forced to burn in the prior of the statistics of the incoming signal, so you have to, it doesn't have to be gaussian, you just have to accept the statistics of the input.
01:28:17.884 - 01:29:33.296, Speaker E: The only other common number to make is that it seems like a. Maybe everybody knows this, but it seems like a hidden piece of information is Judea Pearl, about maybe 20 years ago, came up with Bayes nets. And so if you have graphs which have no loops, and where you have the condition they represent, conditional probabilities are the links, then you can have an incredibly fast inference over the whole network, which is you can do update probabilities in one sweep. And so where you have the constraints, you can just pin the neurons, you know, and then everybody else ponies up there, the appropriate probabilities. And in that, thinking about that, it's important to think about the whole cortex, because a lot of times we have these balkanized ideas of the fusey fusiform face area. What is that? Whereas Jack Gallant here, working with Alex Hook, showed that people watching movies, the whole cortex lights up. So it's one baptist, one big network is working.
01:29:33.296 - 01:29:44.044, Speaker E: And so I would say on the table is at least one hypothesis on how the inference happens, and it's already worked out by Judeo Pros. Albert?
01:29:48.224 - 01:29:52.832, Speaker B: Yeah, I didn't have time to go into the details of the algorithms that have been covered.
01:29:52.848 - 01:29:53.964, Speaker E: It was a complaint.
01:29:54.904 - 01:29:57.784, Speaker B: But there's a lot of work in the domain. Of course. Yeah.
01:30:01.564 - 01:30:02.664, Speaker E: Here's the question.
01:30:04.204 - 01:30:41.616, Speaker C: I have a question with respect to the experiment that you had moving dots in different direction and in two directions, there was a higher probability. So there's also a phenomenon which is adaptation like. So if you were passively watching moving dots without making decisions and they stop, you discount that direction and you think they're going in the opposite direction, which is kind of has the opposite effect of updating your bayesian prior pro. How do you take adaptation into account in analyzing the results of these experiments?
01:30:41.760 - 01:31:17.336, Speaker B: So we don't. So in our data we have attractive biases towards the prior. So as you said, it's going goes in the other direction. We don't have signatures of adaptation, which would be a repulsive bias towards the adapter. And we also looked at the influence of one trial to the next to see if we have signatures of adaptation and so repulsive biases and we don't. One reason is because we operate at very low contrast, probably. And the temporality of our sequences, are.
01:31:17.360 - 01:31:32.324, Speaker A: They schizophrenia, the schizophrenic model, who suggested it? And do they have predictions also from it or something that we can check?
01:31:32.944 - 01:31:35.484, Speaker B: What kind of predictions would you be interested in?
01:31:37.784 - 01:31:39.204, Speaker A: The model is right.
01:31:39.654 - 01:32:23.154, Speaker B: So that's the thing. That's what we are trying. It's mostly very qualitative at the moment. The claims that are being done, and it is sometimes loosely consistent with some data, for example, visual illusion in schizophrenic patients, some people find are weaker than in controls, things like that. There are some experiments which are often inspired by these bayesian ideas, but which don't involve any bayesian modeling, which are consistent sometimes with the fact that the prior beliefs at the perceptual level would be lower and at the cognitive level would be stronger. But no, it's largely untested. That's the point.
01:32:23.974 - 01:32:25.354, Speaker A: So this is the autism?
01:32:26.814 - 01:33:06.098, Speaker B: This autism, yeah. So the initial paper were Fletcher and frizz, and there's a lot of work by the group of Carl Friston at UCL where they think about it in terms of predictive coding. And so they also related somewhat to the tritone substrate and dopamine. The dopamine. So this is what we call dopamine hypothesis in schizophrenia. So there would be impairment in dopamine and they relate prediction error and dopamine and with the idea that prediction error then would be impaired in schizophrenia. So that would explain impairment in learnings, which would lead to impairments in these internal models.
01:33:06.098 - 01:33:10.534, Speaker B: But it's very qualitative, which is interesting.
01:33:13.194 - 01:34:05.284, Speaker C: Excuse me. So I'm coming from a different background, maybe not so much familiar with the literature here. Our previous knowledge during our life that is stored somehow in our brain. So as you mentioned, it's stored as the priors and the likelihood. And these two get updated as we receive new data. So this new data comes from like, the five sense that we have this information that we sense from the environment around us. So I was thinking, where does thinking play around here? So if you block those five senses and just think about something, so is it going to change life?
01:34:06.264 - 01:34:13.600, Speaker A: If you ask people to imagine some situation, will you see effects of just imagining a situation rather than watching it?
01:34:13.712 - 01:34:50.582, Speaker B: So, for example, people are excited, psychiatrists are quite excited by these kind of tools. For example, in depression, whether. I don't know if I can answer your question at all, but, for example, negative beliefs. So we can use, and we've done that in the lab, try to use similar tools to look at. So people's behavior in kind of game like environment and try to measure their priors about beliefs about reward, for example. And so we can see that optimistic people, for example, have different priors about the likelihood of future reward. And so the question is how you're going to update those priors.
01:34:50.582 - 01:35:10.026, Speaker B: And also. Yes. So then therapy, you know, is therapy. Can you measure the success of therapy in terms of changing those priors? So maybe that relates to that. Can sinking, maybe by itself can lead to a plasticity that you can actually measure with such. Nobody has done that yet, but it's.
01:35:10.050 - 01:35:14.334, Speaker C: So difficult to design an experiment that can test these hypotheses.
01:35:14.874 - 01:35:24.134, Speaker A: You ask people to imagine something or to think about something, and then you can see if it affects the prediction of, you know, visual emotions or anything.
01:35:24.874 - 01:35:54.190, Speaker C: So again, you know, when you ask somebody to do something, it's kind of you're giving input through hearing, right? So, I mean, so suppose that mathematician was to solve a problem, and so proof dilemma, and then something on top of that. On top of that. So these, these are like storing information in his brain somehow, somehow changing prior.
01:35:54.302 - 01:35:59.402, Speaker A: Even without seeing, without interacting with the environment.
01:35:59.458 - 01:36:06.814, Speaker C: Yeah, exactly. So are there any studies on this?
01:36:07.194 - 01:36:10.134, Speaker B: Not that I know, but it's a good point.
01:36:12.674 - 01:36:15.174, Speaker C: So I think they're going to comment.
01:36:16.554 - 01:37:08.098, Speaker F: Because it ties in directly to this entry that someone said very early. So I think with all these bayesian paradigm, there's two parts to this. One, you have the prior, and then you have the likelihood. Now, somebody very early on mentioned that storing a distribution is very expensive and perhaps needless, but this applies mostly to a prior, I think, which is really a distribution of data. But I would like to point out that in all these algorithms that I described, you only ever need to sample from that distribution if you have a very massively parallel argument. Extra brews a lot of noise, but it's very cheap to sample from a distribution, very expensive to reliably store the precise value, so that perhaps it's not very hard to store a distribution, I think. And the other thing is, because you just mentioned thinking, I think the likelihood function, that's never the solution.
01:37:08.098 - 01:37:10.890, Speaker F: Distribution. That's about thinking and about reasoning.
01:37:10.922 - 01:37:11.066, Speaker B: Right?
01:37:11.090 - 01:37:26.194, Speaker F: If I think about, okay, if it's gonna rain, how likely is it that it's going to be sunny outside? That's not distribution. A lot knowledge that I store, that's reasoning that I store something very profound to that. So, again, I think that's something that's closer.
01:37:28.014 - 01:37:32.614, Speaker C: Okay, good. So they need, I think, for us to move out of here. But first of all, I just want to thank Peggy again.

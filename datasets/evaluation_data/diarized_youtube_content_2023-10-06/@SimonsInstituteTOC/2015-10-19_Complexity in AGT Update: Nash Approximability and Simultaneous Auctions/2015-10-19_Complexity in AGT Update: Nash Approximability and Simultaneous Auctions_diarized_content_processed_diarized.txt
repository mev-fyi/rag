00:00:01.080 - 00:00:17.750, Speaker A: Thanks. Thanks, Michal. And of course, the real question is, this is about simplicity and complexity. Why am I fixated on complexity? Okay. I mean, I sound like a stubborn old man. Okay. You know, but I think I have a good answer, which would be actually a better title.
00:00:17.750 - 00:01:12.924, Speaker A: Okay. Because simplicity, I think, is a little tricky. Okay, so, okay, so I'm going to talk about combinatorial options, dynamic mechanisms, and approximate NASA equilibria. These are the contexts in which I'm going to discuss complexity. So combinatorial options, listen, okay, you don't need to the definition, okay? But there is a hierarchy of valuations, of course, and we want to allocate, you know, and the problem is that VCG works, is efficient, but it's hard. And so combinatorial auctions, in some sense, is a tsp of mechanism design in the sense that every single trick has been tried on combinatorial options. Okay? It's a paradigmatic, iconic hard problem.
00:01:12.924 - 00:02:08.810, Speaker A: For example, Nissan and Ronan said, asked the question, so, you know, are these three things compatible? You know that they're in any pairs, but, I mean, can these three be done? And now we know that that cannot be done. Okay? And. And in order to, you know, in some sense, we can do what young, Costas and Matt told us, that is possible and reduce mechanism design optimization through Bayesian x equilibrium. But of course, this does not qualify as simple. All right? So. And I know that all of you know the great latest idea, which is simultaneous auctions and base NASA equilibrium. And the idea is that the auctioneer runs and simultaneous auctions and then waits for bidders to reach a Bayesian nas equilibrium.
00:02:08.810 - 00:02:45.686, Speaker A: And the bayesian NASA equilibrium determines the allocation and prices, so that. Look. And of course, then you prove price of anarchy results about this scenario. Okay, by the way, I looked throughout the web for a picture. There are hundreds of pictures of Costas. I looked for one where there is no bright, broad, carefree smile. Okay? And this is the one in which he's slightly concerned.
00:02:45.686 - 00:03:16.268, Speaker A: Okay, so wait a minute. Something feels wrong here. Okay, first of all, do we know that there is a Bayes Nas equilibrium? You know, there is Simonson Zane. That doesn't work here. And the bits are continuous, right? Well, you can upper bound by triple exponential. That's real close fields. Not very appetizing.
00:03:16.268 - 00:03:44.198, Speaker A: In fact, Jackson and Swinker have a very nice paper where they find Bayes nas equilibria, but in tiny examples. Okay, so. And it's agonizingly difficult. Okay. And sort of, you know, in other words, two items and so on. I mean, also, so it's very, very difficult. So let's go and quantize.
00:03:44.198 - 00:04:47.616, Speaker A: The problem is, in what sense is quantizing optimization? Okay? Quantization, you know, we don't have a bound that says if you quantize, you approximate, okay? You get exponential convergence, okay? You you save two exponentials, two levels. But, and even if it exists, how hard is it to find an approximate? Okay? And so, listen, I know that you don't want to see another fruit, okay? So in my combinatorial auctions, the items are closest, all right? Are closest of a formula. You have a formula, and the items are the closest, okay? And the bidders are the variables, plus another bidder. You know, this is my new trick for audience engagement. Okay? I call the last bidder. Uh, all right, so, so, um, so, uh, it's the variables and u. Okay, so the variables are additive, okay? And there are equally all clauses where their actual type appears.
00:04:47.616 - 00:05:25.484, Speaker A: So basically the variables are bayesian, okay? So they can be 50 50, true or false. And if you're like, I'm true. If I'm x three and I'm true, I like all clauses where x three and negated appears. Okay? And you are unique, demand, and you like equally all clauses. Okay? All right, that's it. That's intractable. Let's see why each of the variable bidders will bid one for all clauses where she actually appears.
00:05:25.484 - 00:05:45.352, Speaker A: Okay, that's actually easy to prove. How about you? Let's talk about you now. Okay. So that you have two possibilities. All right, the two possibilities are either bid something small to all clauses, hoping one is not satisfied. Okay, that would be great. All right.
00:05:45.352 - 00:06:38.554, Speaker A: I mean, you bid one to all of the clauses, and if one is not satisfied, then you are in luck. And this gives you your valuation times because you're going to pay, you know, times fees is the probability that fees is unsatisfied, same as above, but also PK clause and bid one, hoping its literals are false. In other words, you pick a clause and bet that its literals are false. And the utility there is v minus seven, eight. Okay? So what you have to do is that, you know, your utility in one of your strategies is this. And your strategies is this. And the question is, you must decide between these two.
00:06:38.554 - 00:07:26.844, Speaker A: And, you know, that's very difficult. By the way, what this proves is that even the best response problem is hard. Okay? So this means that we have not even started digging at the complexity of the problem. And this is the easiest of the proofs we have three proofs that sort of show increment, increasingly difficult results. So the end result is in the context of auctions, Bayes NASA equilibrium is very problematic. Okay, so it's not about only simultaneous auctions, but, but I think that it's problematic when you talk about mechanism design in general. Doubtful to exist, intractable to find if it does.
00:07:26.844 - 00:08:01.412, Speaker A: And for extremely simple valuations, it is ambiguous to approximate by some epsilon. But now you are submodular, not unique. Demand and learning dynamics are also going to be hard to approximate. You know, of course you can do smoothness analysis, learning dynamics, that's not in the cards. Okay, you can always say this, which is fine. Okay, so, you know, I accept it. I cannot convince you to respect complexity.
00:08:01.412 - 00:09:07.556, Speaker A: Okay? But then I really think that should be running BCG. Okay? If you don't respect complexity around VCG, okay, be a decent human being and don't force your customers to solve a sharpie complete problem where you could solve an epic complete problem and be done with it. Okay, so that, so this is the. All right, okay, so this is this result. Now, since we posted this result, we heard Brennan's talk this morning and Nihil's talk, and there's another paper by other people who are here, and we get full credit. We claim that these people saw the light after the results and reconsidered. What is a little more baffling is that several papers appeared, sort of, you know, and they didn't mention us.
00:09:07.556 - 00:09:36.484, Speaker A: Okay? Right? So, which is, I mean, I didn't know this was supposed to happen. Okay? This is not economists, these are people here. Okay? So, all right. In any event, all right, so let's talk about dynamic mechanisms. All right, cool. So dynamic mechanism design, it is, of course, a super interesting extension of an important problem in theory. Okay? But it's not just that, okay? It's the reality.
00:09:36.484 - 00:10:29.306, Speaker A: Okay? When you think about, for example, Adward auctions, it feels that the Adwords auction is the way we model. It is a clumsy approximation of the real problem, which is dynamic, which is important in important ways. Dynamic, all right? And there is, of course, a lot of work in economics and in AGT. And Dirk is here, and of course, Ilya is here. I'm going to, I have a paragraph about Ilya's result because we had a small disagreement about the term terminological, about the term Maersonian. Okay? So, as you are going to see, I give it different meaning. Okay, so, and so let me tell you about complexity, dynamic mechanisms.
00:10:29.306 - 00:10:49.392, Speaker A: So for the economists in the audience, this is what we did. And it's a methodology that a lot of computer scientists do. So it's sort of, you know, it's. We started extremely humble. Okay. Let's say we want to optimize revenue for one round. Okay, I guess this is solved.
00:10:49.392 - 00:11:11.408, Speaker A: All right, so let's go one, two rounds. And what framework. So we define the simplest possible problem we can. That we can prove hard. All right? And here is what we hit. I mean, it turns out we hit a wall very early. Okay, so.
00:11:11.408 - 00:11:41.466, Speaker A: And this is what I'm going to describe. This is joint work with Alex Somas, George Pierrocos and aviat Rubinstein. And so imagine that I'm selling two items. Sorry, that you are selling. You'll see. There are times the phone company wants to sell me. Wants to sell me two items, two phones, one now, one in five years.
00:11:41.466 - 00:12:10.084, Speaker A: Okay. I may be interested in both. I may be interested in either. Okay? But the point is there is one seller and one buyer. Okay? Again, simplicity here is of the essence, because we are playing the complexity game. My valuations for the two times are correlated and you know the joint distribution. Okay.
00:12:10.084 - 00:12:36.966, Speaker A: What I know is my current valuation and my prior for five years hence. Okay? So I hope everybody understands. It's a very simple problem. I have a joint distribution of how much I want something now and how much I'm going to need something else in two years. In five years. And I know what's happening now and I know my prior. You don't know what's happening now, but you know the joint distribution.
00:12:36.966 - 00:12:59.002, Speaker A: Okay? And you want to extract revenue. And we have Myers on envy. Okay. We would like something that is deterministic, incentive compatible, ex post IR, and maximizes revenue. Okay? Am I asking too much? Okay, that's. That's what. That's what Meyerson got in one.
00:12:59.002 - 00:13:41.174, Speaker A: In one round and a much more complicated situation. Okay. So it turns out that you can characterize what the generic mechanism is, and it's the following. You know, it's. I reveal my current valuation, and based on this, you post a price for now, and you post another price for five years hence, and we sign a contract that you are going to honor this prize. And prices are such that they guarantee both IC and AR. And the theorem is, it's np hard to maximize revenue.
00:13:41.174 - 00:14:40.234, Speaker A: Okay? So as I told you, we hit rock almost immediately in this direction. So there are several positive results that are actually quite proud of them without exposed IR and deterministic. The problem is, in PMP, surprisingly, there are separations between non abductive, adaptive, and randomized versions of this protocol, even in the uncorrelated case, when no contract is possible, it turns out that several rounds of cheap token happen. Okay? So in other words, the one round protocol is no longer optimal. Okay. It does not. Does not tell the whole story.
00:14:40.234 - 00:15:15.346, Speaker A: Okay, so I am. I'm going a little too fast. Okay? So I'll slow down. So let's. Are there any questions about dynamic? Okay. All right, so save your questions. All right, so approximate Nash equilibria.
00:15:15.346 - 00:15:17.014, Speaker A: All right, so, yeah.
00:15:17.394 - 00:15:21.494, Speaker B: What does make it much harder than the static Myers? And what is sort of the.
00:15:22.634 - 00:15:42.120, Speaker A: It does make it much harder than static Myerson. Yes. So, for example, for one. For one bidder, sort of static Myerson is, you know, you can look at. You can analyze the prior and find the optimum posted price. So that's very easy. Okay.
00:15:42.120 - 00:15:54.144, Speaker A: Not just easy. It's trivial. Okay. Algorithmically. And here, sort of, you know, when. When you go one dimension up, sort of, you know, something happens. Yes.
00:15:54.144 - 00:16:39.088, Speaker A: Okay. So I should have made this clear that this contrasts with Myers. So let me. Let me explain now, sort of, you know, say one moment, Ilya. Thanks, Derek, because this gives me opportunity to state my business a little more clearly. Okay? So computer scientists of our kind, which means, I guess, everybody, except for deep learning people, we believe that algorithms are the product and natural outflow of algorithms, of theorems. Okay? You have theorems, then you get algorithms.
00:16:39.088 - 00:17:31.763, Speaker A: Okay? The converse of the. Sorry. The contrapositive of this is interesting because it says if there are no algorithms, if there is complexity, there are no theorems, okay? And in some sense, a lot of us see complexity as the manifestation of mathematical nastiness, okay? And so Myerson gives us a beautiful characterization, beautiful analysis, but also algorithms, okay? And when you find complexity, you start saying, oh, my God, we are not in my arson territory anymore. So that's sort of the Ilia now.
00:17:34.703 - 00:17:49.069, Speaker B: That makes things difficult. Now, usually, like in the standard models, including Myerson's model, we assume that the agent has unlimited amounts of money, in which case we can ask him to pay a lot of money upfront, and then the expost will not be relevant.
00:17:49.111 - 00:18:38.674, Speaker A: Right, right. So, right, so all I'm saying is that is that, is that Myerson's happened to be exposed iR, okay? Myerson dove deep into the complexity of the problem and came out victorious, sort of, you know, with deterministic ex post IR and so on. Okay? Everything. All right? And the point is that exposed IR and deterministic may not be too important if you are sort of, you know, like us, a mechanist design thinker. But I mean, oh, would eBay be in business if it was not ex post IR and deterministic? I mean, I don't know. Okay, maybe not. Okay, so, good point.
00:18:38.674 - 00:18:42.214, Speaker A: Yes. All right. Yeah. So, okay.
00:18:44.044 - 00:18:55.824, Speaker C: So given that discussion, you might wonder, like, what the cost is of ex post iR. So, obviously, if you impose ex post IR and you have to do a lot more work in complexity.
00:18:58.124 - 00:19:10.812, Speaker A: You'Re absolutely right. So, you know, the price of absolute certainty or something, right? I mean, yeah, yeah, good point. Yeah. There must exist of any quantification of.
00:19:10.948 - 00:19:16.104, Speaker C: Any scenario where there's a quantification of the cost imposed by exposed iron. Let's say zero, which.
00:19:16.644 - 00:19:51.686, Speaker A: Right, right, yeah, that's an excellent remark. Yeah. So that's an interesting direction. Yeah, yeah. Excellent. Okay, so, having chewed a little time, let's go on to Nash equilibria, right? I mean, so Nash equilibria in some sense is, you know, I don't know how many of you know the story, but, you know, it's one of the paradigmatic problems that started agT, and, you know, we lucked out. And then after a few years, a bunch of us proved.
00:19:51.686 - 00:20:44.286, Speaker A: Proved a complexity result. Okay? And then, like, you know, that's a. Computer science reflects the attention shifted to alternatives like approximation algorithms. Okay? I mean, frankly, the interesting alternative is other equilibria, other concepts of equilibrium. But how well can you approximate Nash? And it turns out that there was a slow, better and better, better and better problems algorithms. And this is, by the way, additive approximation. I mean, you know, and the last seven years, nothing much has been happening.
00:20:44.286 - 00:21:00.244, Speaker A: Okay? That's a very clever algorithm due to spirikes and cothos. So. And can you do better? Okay. And my point is, you shouldn't look. Okay. We should look all the way to the. To the x axis.
00:21:00.244 - 00:21:36.776, Speaker A: Okay? We know that that's the only place to look. You know, can we do it? Can we have a polynomial time approximation scheme by which it is meant, an approximation algorithm, no bounds. Okay. It's, you know, give me an epsilon, however small, I'll give you a polynomial algorithm that achieves it. Because the reason is the following. That that approximation, that, in the case of Nash Epson approximation, is not an appropriate reduction to complexity. Okay? In other words, in the travel insertion problem, you can use sort of, you know, a one third approximation, right? In Nash, you cannot.
00:21:36.776 - 00:22:00.406, Speaker A: The reason is the following. In the travel insurgent problem, you can tell your customer, this is your approximation. This is your approximate solution. This is all that science can do. Take it or leave it. Okay? In Nash, in the case of Nash, the customer will say, wait a minute, you are telling me to refrain from best response. Why should I do that? Why should I believe that my opponent will listen to you anyway? Okay.
00:22:00.406 - 00:22:07.078, Speaker A: And so on. I mean, so it's. It's sort of. It's. It's a. It's a little iffy. Only if you can go down to the x axis.
00:22:07.078 - 00:22:33.424, Speaker A: Okay. And you can do any epsilon, in other words, however small, or you can reach Epsilon so small that no rational being would ever lift a finger to appropriate it. Okay? Only then you can say that, yes, we have something. We have changed the negative result. Okay? And that's. Again, as I said, that's what I call the cursor visibest response. All right? So.
00:22:33.424 - 00:23:12.234, Speaker A: And it turns out that we know of obstacles. For example, Costas some years ago proved that if you don't have this convention of additive epsilon, but you insist on relative epsilon, then. And actually, aviator recently generalized this slightly. This is ppid complete to achieve. Okay? In other words, it's intractable. If we wanted a relative multiplicative improvement. Multiplicative approximation.
00:23:12.234 - 00:24:02.034, Speaker A: But, I mean, intuitively, in economics, additive approximation makes sense. Recently, valve had proved that epsilon positive epsilon is impossible. Sorry, additive. There is some additive epsilon, which is impossible for multiplayer games. Okay? And this leaves the very important question, which, in some sense, is the paradigmatic question in the area. How about additive approximation for two players or three players? Right? I mean, this is what I'm going to focus on on the next slide. And it turns out that there is approximation, and we know there is lipomy syntha.
00:24:02.034 - 00:25:05.284, Speaker A: They proved early enough that you can approximate the Nash equilibrium, except you can do it in polynomial time. You can do it, however, in quasi polynomial time, okay, there is a log n in the exponent, which takes it out of the polynomial realm, but ruins are there because now you cannot attack it through complexity. It looks very difficult to attack the complexity. So, in other words, this problem cannot be PPID complete, because this would mean that all of PPAD, including finding an exact Nash equilibrium, can be solved in quasi polynomial time, which we don't believe. Okay? So, you know, conventional wisdom and actually, black box lower bounds make us believe that you cannot solve this problem in quasi polynomial time either. Okay? Is everybody. Is everybody.
00:25:05.284 - 00:25:40.384, Speaker A: We understand our predicament. Okay, so we have a interactive result. We have for, let's say, two player NASA equilibrium. We have quasi polynomial pizza, pietas, q, p, t, if you wish. And now, what does one do? Okay, how does one do? Prove a lower bound. And it turns out that it's possible. All right.
00:25:40.384 - 00:26:13.464, Speaker A: And here is the definition given a multimatrix game. By this, I mean. No, sometimes it's called the a network game. It is a game. It's a graph whose nodes are players and edges are two player games. And every player has to be consistent across all edges and can plays best response. Totally.
00:26:13.464 - 00:26:44.730, Speaker A: So, given a multimatics game, find a strategy profile so that almost all of the players are very close to their best response. Okay? Two small parameters, both delta and epsilon. Okay, it makes. It comes closer and closer to my calculus textbook. Okay. You know, but delta epsilon ash is like this. Given a multiplex game, find a steroid c profile so that almost all players are almost happy.
00:26:44.730 - 00:27:48.314, Speaker A: Can almost everybody be almost happy? Okay, and the conjecture is that it's PPiD complete for some positive epsilon delta. If delta equals zero, we know it's true. Okay, why do we call this PCP? We call this PCP for two reasons. Okay? PCP, for the probabilistically checkable proofs, is sort of the signature of a legendary kind of reduction of complete problem, if you wish, which has been used in the theory of approximability in the context of MP completeness. So why do we say that this is the corresponding thing for PPID? And the reason is the following. First of all, and now I'm addressing myself to the hardcore complexity theories here. Like in PCP, the certificate can be checked in finite number of random bits.
00:27:48.314 - 00:29:12.054, Speaker A: And second reason is, like PCP, it seems to capture the approximate and several other problems, okay? And now the theorem is that Babychenko Rubinstein, that if for some delta epsilon, this delta epsilon requires exponential time, or even any time where the exponent of n is greater than two, then the Lipton metamarkitis result is the best possible, okay? So in other words, it's a much lower bound, of course. It. I repeat, it relies on a strong conjecture, okay. That we have sort of exponential time hypothesis for this delta epsilon ash. I can give you an impressionistic vision of the. Of the proof. It relies on a recent technique that was inaugurated by Aronson, impagliazzo and Markovic.
00:29:12.054 - 00:29:36.624, Speaker A: And it's the following. You start from a bipartite network game, like I told you before, which is, you know, every. Every node has two strategies. And there are. It's sparse, okay? It has only order of n edges. And the question is, find me a delta epsilon ash. And we know that this requires exponential time.
00:29:36.624 - 00:30:22.776, Speaker A: What you do is you subdivide these two parts into square root of n sets, which have about square root of n, each of nodes. There are two players. One is left, one is right, and each player has square root of n times two to the square root of intrastratus. Okay? And in other words, this is not a polynomial time reduction, it's an exponential time reduction. It's a two to the square root of n reduction. And this two square root of n, if you do the math right, is what you need in order to bridge polynomial with quasi polynomial. And so there are many strategies.
00:30:22.776 - 00:31:06.834, Speaker A: And three games are played simultaneously. Okay? One is the game that sort of summarizes the previous game, the big game, the multiplayer game, and two other games are, the games are games that are called Althoeffers games, and they force the two players to be a little attentive to all of the minorities. Okay? And so this is my. Yeah, you can read it. Complexity still, still informs AGT, and AGT continues to do complexity into new territory. Thank you very much.
00:31:16.944 - 00:31:30.844, Speaker B: So I'd like to ask you about correlated equilibrium. If I understand correctly, it is easy to find, and also, if I understand correctly, there are price of unity results for it. So would that be a way out of.
00:31:31.184 - 00:32:35.778, Speaker A: Okay, okay. So I had, you know, I did mention it briefly in my. Excellent question, I did mention it briefly in my presentation about b and e, that even course correlate equilibrium, Bayesian course correlated equilibrium, in other words, the sort of outcome of a learning, of a learning behavior, even these are hard to approximate. Sorry, can you explain what you mean? Okay, the answer to this question, I. Right, right. Yeah. As we said that Bayes, NASA equilibria are hard to approximate, okay? In this context, in the context of computatorial options, even if you have a learning algorithm, okay? So, you know, which essentially converges to what I call Bayesian course correlated equilibrium.
00:32:35.778 - 00:33:02.416, Speaker A: But the point is that you resample the types in every step of the game, okay? That even this is, you know, for which, for which of course you have, you can have, you can have a price of anarchy. The results, even this is hard. It's hard to attain and approximate.
00:33:02.520 - 00:33:06.524, Speaker B: And that's because in the dynamic mechanism design setting, you're talking about best responses.
00:33:07.704 - 00:33:19.496, Speaker A: I guess. I guess. I guess that's essentially the. You know that because. Yes, because our proof is so crude, sort of, you know, it generalizes easily.
00:33:19.640 - 00:33:21.392, Speaker B: But I guess you could do best response then.
00:33:21.408 - 00:33:36.044, Speaker A: You. So, I mean, for this you need. For this you need epsilon, you need to have an epsilon separation. Because an epsilon separation can be lost along the learning march. Yeah. So, okay.
00:33:39.184 - 00:34:03.334, Speaker D: So, for example, in a lot of areas, right, if we, while we can do something better, then we can see a concrete connection to something changing in society. So if we go faster than light, we would go to other stars. If you could solve satisfiability in polynomial time, then we break cryptography. In this case, if you could find an epsilon delta approximation, what does it translate into? Something that you actually.
00:34:04.514 - 00:34:23.575, Speaker A: Okay, so, I mean, like PCP. This is a device for proving lower bounds. Okay. So, you know, there will be no dancing in the streets, if that's what you are asking. Yes. Right? Yeah. Am I right? You have different.
00:34:23.759 - 00:34:28.763, Speaker D: You must have part of this, right? For example, if you get some of these problems. If you could solve some of these problems.
00:34:29.063 - 00:34:52.628, Speaker A: Of course not. Wharton. So what you could do, you could reduce course match to this. If you could find equilibrium general. Then, for example, in Wharton, they have this, the course match system, which is very closely related. It goes both directions. Okay.
00:34:52.628 - 00:35:00.864, Speaker A: Yeah. Finding the location there. So there will be some rejoicing somewhere. Okay. Right. Yeah. Sorry.
00:35:01.204 - 00:35:02.224, Speaker B: Thank you again.

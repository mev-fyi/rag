00:00:25.774 - 00:02:27.624, Speaker A: Yeah, I'm trying. This afternoon, lectures, we will be talking, we will be looking at newer topics. And it's a pleasure to introduce David Stoyer, who is at Cornell University visiting for the whole semester. So he'll be here for the whole semester and he'll be talking, telling us about sumo squares, SDP relaxations and their applications to approximation algorithms or even machine learning applications. Thanks Prasad, thanks for inviting me. Okay, so the motivation, I want to start with some motivation. So we'll be trying to solve optimization problems.
00:02:27.624 - 00:03:34.964, Speaker A: And most of the discussion is very general and I have some examples. And so the kind of optimization problem that we are interested in are following form. We have some function that we want to maximize, and we have some properties that we want of the solutions coded by these kind of equations. And the solution is encoded as a real vector. And here we are thinking of n as very large. We have many variables and in the sense that we will also measure, yes, larger. We will measure the running time of the algorithms in terms of the number of variables.
00:03:34.964 - 00:04:50.994, Speaker A: Again, if you sort of talk about real value, a function on real vectors, and we have to somehow say how we encode these functions. And the way we will do this is that the functions p zero, p 01:00 p.m. are low degree polynomials. It could be degree two or degree four. So really just a constant degree. And also the number of constraints will be small and coefficients will be small. That's the basic setup.
00:04:50.994 - 00:06:18.986, Speaker A: And an example of a problem that, and this is a very expressive way of describing optimization problems. An example of a problem, how you can describe a problem in this way is, let's say for the maximum cut in a graph, a little bit larger graph g with n vertices. So how could we. So we want to find it by partition. You want to find it by partition of the vertex set of the graph such that the number of edges that cross by partition is as large as possible. So how can we encode it in this way? So the main step is to sort of encode the solutions real vectors of doing it. MAyBe the simple thing is that we think of, we have a variable for every vertex I.
00:06:18.986 - 00:07:45.754, Speaker A: We have a variable x sub I and coordinate of a vector. And we assign one to all the vertices on one side of the cut and minus one to all the vertices on the other side of the cut. And then we want to formulate, you want to express the condition that we want to maximize the number of edges that the bipartition cuts in terms of some function p zero. So you know, p zero of x should be the number of edges that cross the bipartition x. And you know this function, you know, you can interpolate it as a polynomial in these variables, and then it has this form. So here we sum up over the edges of the graph, these squares, and you see that they just count the number of edges that cross the repetition. And so this is the placian of the graph, which you've seen in the Lucas talk.
00:07:45.754 - 00:08:41.273, Speaker A: And so we're lucky this polynomial is indeed a low degree polynomial. So this fits into what we said before. Yes. So, yes, I think that's why maybe I should take the notes. Right. So what we did here is every by partition, we associate it with some vector, some vector x with plus or minus one coordinates. And now we want, you somehow want, you know, we have this, we have to specify the constraints here.
00:08:41.273 - 00:09:57.050, Speaker A: And so the way we choose p one up to pm, the way we want to choose polynomials is we choose this as a good basis of polynomials that are zero over the set that we're interested in. And good basis can mean different things depending on exactly what problem you're looking at here. It's sort of clear. What's, what's the, what's the basis that you want? So, you know, you choose the following pronoun that's just x one squared minus one, up to x n squared minus one. So the condition that those polynomials are zero says that the vector x has plus or minus one coordinates. And. Okay, so this is the basic, the basic setup.
00:09:57.050 - 00:11:10.024, Speaker A: Now, the question that we're interested in is, you know, are there efficient algorithms for these kind of problems? And as you probably know, this, this problem is NP hard, let's say even talk. Let's keep this example of next cut. So the efficient algorithms of this problem, it'd be hard to solve. Exactly. And even in the sense that. So the proof, the hardness proof, even shows that if you want to solve it exactly, it requires, under some reasonable assumptions, exponential time. And now that means that the real question is, how close can you get? And there's basic results.
00:11:10.024 - 00:12:28.144, Speaker A: His p theorem says that sort of some kind of 0.99 approximation is as hard as solving the problem. Exactly. Okay, here, I should also say, you know, I'm not sure if you remember it from Lukas talk how we measure approximation. So usually you have to, you might have to measure it depending on the problem. But in this case, some alpha approximation means. That means that the solution found by the algorithm on a particular input graph, g, is at least alpha times the value of the optimum resolution for the graph, and this is for all graphs.
00:12:28.144 - 00:13:12.424, Speaker A: Ah, so here I'm referring to the, so this is the hardness result. So this is, you know, this even 0.99 approximation requires exponential time. And. Right, and then there's this, and they are better bounds known, but for HapF results, but let me not save them. And then there's this algorithm, 0.878 approximation polynomial time, actually nearly linear time.
00:13:12.424 - 00:15:12.134, Speaker A: And assuming the in game's conjecture implies that NP hard, better approximation is NP hard, and we don't know if the games conjecture is true. And in some sense, that's finding out whether the games conjecture is true is one of the motivations of the things I'm talking about. Now, you might wonder, why do we really care about the difference between 0.990.8? So I think maybe one reason why you want to care about this is that here you maybe not interested just in the numerical value, but you want to know what's the algorithm that achieves the best possible approximation. And if you look at this, then here the algorithm that achieves 0.878, this is based on, let me call it degree two semination programming. Again, this is sort of not a very technical expression, quotes.
00:15:12.134 - 00:17:16.304, Speaker A: And now sort of something interesting happens. For example, it's opened. What? So there's, you know, just like there's degree two or some different programming, there are, you know, it's open better, there are higher degree versions of semi different programming. And so you can look at degree four, semi efficient programming, and this is, you know, it's open. Whether this gives a better, strictly better approximation, you know, and if it would be the case that that would refute this unigence conjecture in some sense, our inability to show that, you know, this version of semi free programming does not refute the nigging's conjecture explains why we are not super confident in the truth of the Negan's conjecture, and it's even a bit worse. So it's not just open that whether this decree four achieves a better approximation, but we know a bit more every known. Again, some restriction tight example for, for degree two is probably not a bad example for degree 16, and 16 is somewhat arbitrary number.
00:17:16.304 - 00:18:19.428, Speaker A: Okay, so, and here you know every known. So the restriction is known to. But this means that, you know, every particular construction of graphs where you know where we know that, or you know that degree two, when this guarantee for decree two is tight, you can actually show that decrease 16 is much better. And this is maybe somewhat surprising, especially so it means that if the in game conjecture is true, then decrease 16 should not give a better approximation for this problem. And so it means that they have to be different instances. Yes, I have a question. So here are two degrees in play.
00:18:19.428 - 00:18:57.430, Speaker A: One is the degree that you need to specify the problem. And for Maxcar, this is degree two. And to some extent you can, you know, degree two is always enough to define at least sort of combinatorial kind of problems. And then there is the degree that you use for the, for the algorithm. And those degrees are, you can, you can choose a degree for the algorithm larger. And that's the, and that turns out to help for these spread instances. But so far I didn't explain exactly what decree 16 semitrine programming means.
00:18:57.430 - 00:19:51.884, Speaker A: And do that. Okay. And so, so the conclusion of this kind of discussion is that, you know, the goal here is, what we'd like to have is some kind of unified. So we have, you know, this is some kind of, some particular example, this Mexican. And so, you know, a lot of problems, you know, of different kinds where that have this form, this kind of optimization problems. And we'd like to understand what are the best possible algorithms. And so the goal is to have some kind of unified way of attacking these problems, approaching these problems.
00:19:51.884 - 00:21:51.194, Speaker A: And, you know, in the sense that, you know, it should apply to other formulatory optimization problems and another kind of, other kind of problems where these kind of techniques seem to be useful are certain unsupervised learning problems like relational sparsity, tensors and matrix secularization kind of things. This unified way of approaching these problems is in terms of convex relaxations. And that's the main topic of the lecture today. So the basic idea is that we have these problems and we try to, there's the sense that convex optimization is easy. And so the idea is to reduce these arbitrary optimization problems to convex optimization problems and then hope that in this way we get good algorithms. So there are different ways of doing this. And what I will explain is some kind of way of looking at these context organizations that is fairly unified.
00:21:51.194 - 00:23:14.794, Speaker A: So the first one thing that we need to do is we need to convexify the problem. And means that, you know, we want to, you want to make the, you know, you want to make the problem into a convex problem. A convex problem means that, you know, you can take convex combinations of solutions and get solutions that are at least as good. So if you have a bunch of good solutions and you take a convex combination, then you want to have another good solution. And like, and there's a canonical way to make every problem context. So what's this? What's, how can you do this? So, instead of just trying to find a particular solution, what you try to do is you try to find a distribution over solutions. And, okay, so let me keep this example of Maxcard.
00:23:14.794 - 00:24:28.152, Speaker A: Just make things a little bit easier. So let's, how do you convexify Maxcard? And here you want to find the distribution d is the probability distribution over the hypercube, and you want to maximize the expectation of the polynomial that you're interested in with respect to this distribution. And so what did we gain if we gained? A couple of things. So maybe, let me just explain. What is a distribution? So, distribution is a function on the hypercube, a real valued function, and it has a property that for every point in the hypercube, it takes a more negative value. And if you sum up the values of all points in the hypercube, then you get one. And, okay, so that's the distribution.
00:24:28.152 - 00:25:35.664, Speaker A: But what we gain, so one thing is that we gained is that here, now this objective function is linear. Indeed, another thing that we gained is that now the problem is convex in the sense that if you take two distributions over the hyperfriend and you take convex combination in this sense, think of it as a function. Then this is, again, it's a distribution if d and d prime are distributions. And so the only problem here is, maybe there are two problems. One problem is, okay, so this object here is exponentially large. This is actually not the main problem. The main problem here is that we have here an exponential number of inequalities.
00:25:35.664 - 00:27:25.328, Speaker A: And these inequalities are sort of not structured in a way that would allow to, you know, to deal with them in an efficient way. And so that's the, that's the main problem. And let me also say that instead of finding a distribution and maximizing the expectation of the poem that you want to, of the function you want to maximize, it's in some sense a bit better. Where should I write this? Let me write this down here. It's a bit better to, in some situations, to think of, you want to find a distribution over the set of all optimal solutions, where c is some guess for the optimal, for the optimal value. Okay? So, meaning that instead of finding, by convexifying, I mean that instead of finding a particular solution, what you try to do is you find distribution over solutions. And a priori, this doesn't make things easier.
00:27:25.328 - 00:29:31.684, Speaker A: So, you know, in particular, you know, this problem is, computationally, at least, it's hard, but it, but what you gain is that it gives you a new perspective on the problem. And so, in particular, now we will relax the problem, we make the problem easier. And so some of you want to, you know, want to keep the property that things are convex, because then we can use convex optimization techniques, but we somehow want to simplify the problem so that we can solve things efficiently. And, you know, there are many ways of sort of explaining how this goes, but I think a very general way and convenient way to deal with these things in terms of pseudo distributions. So what is pseudo distribution? So think about it, is that it behaves like a probability distribution, distribution over, let's say, optimal solutions. So it means in terms of, in the case of max cut over optimal cuts in the graph. And, you know, it behaves as this kind of object with respect to our computational knowledge about optimal solutions.
00:29:31.684 - 00:31:00.924, Speaker A: This combination of knowledge is something that I will define in a bit. So there's a sense in which you can think about, what do you know, what do you actually know about optimal solutions? And then you can think about what it means to have something like a distribution, that something that behaves like a distribution with respect to this knowledge. Okay, and then, so once we have this, the general approach will be find the pseudo distribution efficiently and then extract a good solution. It might not be an optimal solution, but the goal is to still be able to get a good solution from this zero distribution. There will be some loss here, which will determine the approximation factors. Okay, so this is the general idea. And, okay, here there are different ways of thinking about this step.
00:31:00.924 - 00:32:32.754, Speaker A: This sometimes called rounding another way is related. It's also related to polymorphisms. We are calling it sometimes combining. And it will be clearer later in later lectures how to think about this process. So now, what is this computational knowledge, say? Why, once you've transformed the suit of distributions, things are efficient, whereas they weren't before. What changed? Yes, because we don't want them to be exactly probability solutions, but only with respect to what we know about the problem. That means that it's easier to find these kind of objects than actual probabilities.
00:32:32.754 - 00:33:54.678, Speaker A: The algorithms that will find these pseudo distributions, they are convex optimization problems. So it turns out that this will be, finding a pseudo distribution will be a complex optimization problem, which is not surprising, because finding actual distributions is also a convex optimization problem. But here, this will be a small convex optimization problem. So now, okay, so what is computational knowledge? So let's first start with what is knowledge about optimizations. So it's just a set of functions that has a property that if f is a function in the set, it implies that f of x is non negative for every optimum solution. For every solution x of value c, where c was our guess for the optimal value. And this is something that you can always, you can guess what's the optimal value.
00:33:54.678 - 00:35:04.494, Speaker A: And then just try to find, try to see if you can find a distribution for that particular value c. Now, just a bunch of inequalities that you know about optimal solutions. And now what does it mean to have a zero distribution that is consistent, d is consistent with some particular knowledge. Okay, so this just, so this just means that, you know, for every function that we know to be non negative, or, you know, that we know to be non negative over on, on optimal solutions, you want that the following expression is non negative. Okay, maybe. Let me. Okay.
00:35:04.494 - 00:35:55.194, Speaker A: The following expression is non negative sum of all points in iq, some kind of inner product between the function d and the function f. And the other condition is that if you sum up the values of d, then you get one. So it means that we replace the condition that d is non negative everywhere by the condition that, by this strange condition. And it sort of gets, gets old to write these sums. And therefore, we will give this a name and annotation. So we'll denote it in this way. Sorry.
00:35:55.194 - 00:36:59.278, Speaker A: So this summation for any function f, we will denote it in this way, and we will refer to it as the pseudo expectation. Will there be examples where the knowledge uses the optimal value c? That's a good question. Maybe not today, but there are some cases where things become much more pleasant if you, if, you know, if you use the value c. So expectation d from an expectation because d could be positive or negative. Yes, exactly. So that's what we dropped. So we no longer require that these non negative errors, but we keep the condition that these sums up to one.
00:36:59.278 - 00:37:45.934, Speaker A: And instead of non negativity everywhere, we just require that these two expectations are non negative for functions that we know to be non negative on optimal solutions. Now, yes, a lot of the examples f is low degree. Yes. Are there examples where airfare also. Good question. I don't know an example where Heidi created, but that's also an important point. So somehow clearly not.
00:37:45.934 - 00:39:13.600, Speaker A: So the question is, when can we argue about consistency with respect to some particular set of functions k? When can we deal with this efficiently and we can't do it every. For some set of functions, it's not possible to do it efficiently. So, for example, if k consists of another example. So if we choose our knowledge to be all the set of singleton indicators. For every point x, we have a function in k which is one exactly at this point x and zero everywhere else we can look at. Or let's say there is just one every report for every solution x that has value c. So if you had the indicator for every such solution in our set k, then it means that then he needs to be distribution.
00:39:13.600 - 00:40:24.694, Speaker A: Yes. Then pseudo distribution with respect to that k is actual distribution. That means that we somehow have to restrict the set of functions kick. And that's what I meant, that we, you know, that we only get a zero distribution that is consistent with our respect to our computational knowledge. And so this means that there exists, so there's some parameter d. So there exists an enter the d time algorithm that can solve the, you know, the following problem given f, given a function d. Sorry, compute the function our knowledge that minimizes the smallest expectation.
00:40:24.694 - 00:41:38.748, Speaker A: So for every function d, you want to be able to compute, you want to compute the function that minimizes the zero expectation. A different way of thinking about it is that given some function d, you want to be able to tell whether it's consistent with the knowledge k, in the sense that all these zero expectations are non negative. And if d is not consistent with the knowledge k, then you want to find some function f that is where the pseudo expectation is negative. Computational knowledge. Second, that's the definition of computational knowledge. So that there exists an enter df algorithm that can solve the following problem. You know, given a function d, compute the function f that minimizes this expectation.
00:41:38.748 - 00:42:00.404, Speaker A: So for every value of little b, you have a different set of computations. Yes. Yes. How are you given? Say again? What does it mean? Given? Yeah. Okay. That's also a good question. What is d? Yes, I think maybe I should have.
00:42:00.404 - 00:43:39.118, Speaker A: Yes, right. So here, you know, a priori d is a function on points. So that's much larger than the time the algorithm has. So you somehow have to represent d in a good way. And here, with respect to Maduro's point, we will assume that we only look at the case where this set k contains only degree d polynomials, where this t here is roughly the same as this t contains only degree equanimity. So why does this make things easier? This makes things easier because now the set of functions that we care about that we know to be non negative, they are all degree d polynomials. And so it means that in this expression, like the higher degree part of b, so you know every function capital b, you can write it as low degree part plus a high degree part, and the high degree part, it will not be able to contribute in this expression because f is a low degree point only.
00:43:39.118 - 00:44:47.728, Speaker A: So the high degree part doesn't contribute here. And so it means that we can represent d by its low degree part if, if our knowledge only contains dot de 3.1. So that means you're looking at the moments up to the d moments. Yes, that's right. So it means that the only thing that we know about, or the only thing that matters of this, of this function, capital d, is its low degree moments. But in some sense they are not actual moments because, you know, this function might take, might take negative values sometimes. And so, yes, I guess you could call these numbers pseudo moments are there.
00:44:47.728 - 00:46:01.182, Speaker A: So I know you said that we don't know of applications where high degree functions f are needed, but notwithstanding, are there interesting classes of higher degree f for which we know how to solve this separation problem? Okay, yes, that's a good question. Okay. So far I didn't specify exactly what. So that's what comes next. So next we'll discuss complete examples of what, you know, what could be, how would the set k look like? And one case is that you just let k be some kind of code generated by a small number of rays, by polynomial number of rays, and then you can always, it's always possible to solve this problem efficiently. And I mean, so there is a sense in which you can, you don't need to miss if you want things to be efficient. But we don't know of an example where that's actually useful.
00:46:01.182 - 00:46:55.580, Speaker A: So that's also a great open question to show that glow degree things are the best. This is the only thing that you have to look at. So you did this in some generality, but then at some point it didn't make sense anymore to say, to talk about things that were not logically because you need some implicit representation for D. But you say you're saying if k is in some sense finite dimensional, then you also have a finite dimensional representation for D. Yes, yes, that's right. I think that's probably some kind of necessary condition that if you look at the affine span of k, the linear span of k, that this would not be too large. Otherwise there's not no hope.
00:46:55.580 - 00:48:17.096, Speaker A: Otherwise it cannot be computationally efficient in this sense. Okay. And yes, maybe let me state the theorem which is in some sense just restarting the fact that convex problems, you can solve them efficiently. You know, here this enter the d an algorithm, you know, that, to find a pseudo distribution consistent with computation. You know, some computational knowledge. Okay. You know, and this, this is the same, maybe I should.
00:48:17.096 - 00:49:50.670, Speaker A: So there's some functions which I'm. And this is really just the observation that you can use this problem that you have to solve here is sort of the separation problem for the, this is a separation problem for these two distributions. And therefore, using the ellipsoid method or other favorite convex optimization algorithm, you can find a pseudo distribution that is efficiently consistent with some computational knowledge. So, yeah, you can either think of this as a separation oracle or some kind of algorithm that computes the subgradient of the function that you want to minimize or subtract that you want to minimize. Okay, so now there are no examples. So one example is that you can use some kind of local knowledge. And this would be, this would correspond to choosing k to be all non negative combinations of non negative b.
00:49:50.670 - 00:50:36.070, Speaker A: Shoulders. Okay, so this kind of, I mean, these are decuntas over the hypercube. A d kunta is a function that depends only on. So these are, you know, functions that, you know, they're non negative everywhere on the hypocube. So in particular, this episode by this here. And, you know, if you choose d to be, if you choose d to be very large like n, then you will also have these, you know, the set will also contain these indicators. That means d to be n.
00:50:36.070 - 00:51:10.168, Speaker A: Then you actually talk about extra probability distributions. And another fact is that, so the number of rays here. So this here is a convex cone, and the number of rays is roughly two to the d times n. Choose n. Choose d. And so it means that in this case, you can just solve this problem by trying out every ray here. And it takes time.
00:51:10.168 - 00:52:23.688, Speaker A: Roughly nice. In this year, if you use this kind of local knowledge, that the resulting algorithm is called Gerald Adams lp relaxation. Now, another kind of knowledge that you can use is some squares knowledge. And here that would be all polynomials that are sums, you know, all polynomials that are sum of squares of degree d polynomials. So these are also non negative. So it means that you can do this. Also, if you choose degree b to be very large, then you get these indicators, which means that you solve that problem.
00:52:23.688 - 00:53:31.264, Speaker A: Exactly. Now, why is it computationally efficient? Okay, so they have to look at this, this kind of problem. And basically, so this problem becomes, you know, given some low degree polynomial D. So d is, now, as we said here, low degree polynomial. You want to find the, the argument of we are interested in squares of low degree polynomials. So we go over every low degree polynomial P and we want to minimize the pseudo expectation we don't find a polynomial p where this pseudo expectation is as small as possible. And now if you look at this here, this is a quadratic form in form in P.
00:53:31.264 - 00:55:20.574, Speaker A: And so it means that, you know, minimizing that is just some eigenvalue kind of problem. Is that something that you can do efficiently? This is your separation oracle? Yes, that would be the separation oracle. So the separation oracle for some of square's knowledge would be an eigenvalue computation. So the point I'd like to make here is that the sum of squares knowledge is surprisingly close to our real world knowledge about low degree .0 is. So if you give me sort of a concrete low degree point on your inequality, then it's very likely that, at least in an approximate sense, it's captured by this somewhat square's knowledge. And that means that, that sort of means that in some sense, if you work with these, if you work with a serial distribution that is consistent with this kind of sum of space knowledge, and you think about algorithms that try to extract a good solution from a serial distribution, it's very hard for them to notice a difference between having just a zero distribution and having an actual distribution, just because our real world knowledge about low DP polynomials is very captured by this kind of sum of space knowledge.
00:55:20.574 - 00:58:34.038, Speaker A: And so this informs the following, some kind of algorithm design approach, an approach for solving this problem, for extracting a good solution. So in order to analyze this rounding step while pretending, pretending that we have an actual distribution, let's say low degree moments, actual distribution, and then only afterwards check that, that only some squares knowledge, low degrees, some of squares knowledge was used about the solutions. And this is the advantage, that some of these verification can be technically involved, and somehow dealing with it separately makes things much cleaner. All right, at least easier. Do you have, say, five more minutes? I just wanted to sketch just how you, how you can use these pseudo distributions to create neon structures to design algorithms. It's not, it's, you know, the example is chosen so that it's most familiar. But you could, I mean, for this particular example, you could also do it in a different way, which might be simpler and depending on your case, and this will be, suppose we try to approximation for max.
00:58:34.038 - 01:00:40.414, Speaker A: Try to get an approximation for max using two distributions. So suppose that we have a graph g, and it has a, you know, piper with one minus epsilon fraction of edges crossing. So one minus epsilon fraction of the edges of the graph crosses this by partition. And our goal is to find, you'll find a partition with one minus all root, epsilon of the edges crossing. How does the algorithm, so we'll, you know, the first step would be that we compute, because we will compute zero distribution that is, you know, consistent with, let's say degree two is some square's knowledge. And, you know, the condition that the Laplacian is equal to one minus epsilon times the number of edges in the graph. That just means that this fraction of edges cross.
01:00:40.414 - 01:01:51.452, Speaker A: Now we want to extract from the pseudo distribution an actual distribution, an actual solution. And the way this we can do this is. So I will explain why these steps work in a second. We sample a Gauss, we sample some real valued random variable, let's call it y, that has the same two moments as a suitable distribution, d. And then we will just output, let me just say this a bit differently. So if this distribution would be an actual distribution, what we'd like to do is just sample from this distribution. But as we said before, we only know the low degree moments of this distribution.
01:01:51.452 - 01:02:34.638, Speaker A: And if you have this in general, it's hard to sample from a distribution that has the same, it has the same, given the moments, it's hard to sample from distribution, test the same moments. But one thing that we can do is we can sample a real value random variable that has the same degree, two moments. And so all of these words are important. So it's a real value variable and tests the same degree, two moments. That's something that we can do. And I'll explain why. And then we'll output the closest point, output the point z, which is important advice.
01:02:34.638 - 01:04:59.984, Speaker A: We take the sign of the random variable y. And this is our bipartisan, okay, so this is the closest, but, you know, closest point of the altitude to the vector y. And so what I, okay, so there's one claim which will establish that, you know, that you get this kind of guarantee is that, you know, if the probability under the pseudo distribution that xi is different from xj is equal to one minus epsilon, then the probability, which is now with respect to an actual distribution of z, you know, that z I differs from dj. This will be at least one minus order root, epsilon. Now, what's sort of one step that is not so clear at this point? Maybe why can we sample the real value random variable that has the same degree two moments as this civilization d? And so what we'll do is we will, you know, we sample a gaussian variable that has, we look at, we will compute the degree to, let's say, the covariance of b. So what does the covariance mean, we look at the following matrix and this notation here, it's just exactly the same as, so we use b to weight, to weigh, to weight these matrices, we get a new matrix and we claim that this is, this will be, we will try to choose, we will sample the gaussian that has this covariance matrix. But for this, I mean, in order for this to be, if you want to be able to do this, then this matrix needs to be positive seven.
01:04:59.984 - 01:06:13.084, Speaker A: So this is the, this is the main question, why should this matrix be positive semi definitive? If this matrix is positive semi definite, then you can choose just, you know, gaussian matrix with this covariance matrix, with this covariance. I'm sorry, mu, here is the mean of the zero solution. So why is this matrix positive seminary? So if this would be a distribution, then would just be a non negative weighing of these matrices, of this PST matrices. So it would be clearly PSD. But because it's a pseudo distribution, you should verify it. And so now let's look at any vector u and look at whether the quadratic form, if you plug in u is, is non negative. And all this pseudo expectation behaves exactly like you would expect from an actual expectation using this definition.
01:06:13.084 - 01:07:07.884, Speaker A: And so this is the same as the value of the scheduled form is the same as the expectation of this square. So this identity would be true if this would be an actual distribution, an actual expectation. But because we're just using linearity, this is also true for the pseudo expectations. And now we see that this here is a square of a linear polynomial, linear polynomial in X. And that means that it's in, you know, that this here is contained in our, you know, in our sum of squares, you know, degree two sum of squares knowledge. And so it means that this is non negative for every u, and that means that the matrix is positive. Okay, thanks.
01:07:07.884 - 01:07:47.144, Speaker A: So let me just say. So it's, so, in the next lecture, I wanted to talk about limitations of these kind of algorithms and how we can use them to solve some unique games in sub exponential time. And on Friday, I wanted to talk about applications of this to finding sparse vectors in subspaces and tensor decompositions. Thank you. Since it's late, probably we take the questions offline. You want to start the next five minutes?

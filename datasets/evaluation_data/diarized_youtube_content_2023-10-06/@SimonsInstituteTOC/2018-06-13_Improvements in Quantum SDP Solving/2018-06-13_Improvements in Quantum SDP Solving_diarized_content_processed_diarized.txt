00:00:00.560 - 00:00:06.514, Speaker A: Okay, so the last talk of today will be given by Andres Kiyen. We'll talk about quantum algorithms for solving semi definite programs.
00:00:08.454 - 00:00:45.074, Speaker B: Thank you, Ronald. Yes. So I would like to talk about important algorithms for optimization. And so, SDPs and IAPs are very useful in classical optimization theory. And before I would like to go, would go into details, I just would like to mention that optimization itself is actually one of the greatest successes of computer science. So probably, as you go hit this workshop, you probably use some planning software to get from the airport here. And it's really, optimization has changed our everyday life.
00:02:44.554 - 00:02:44.970, Speaker C: Sorry.
00:02:45.002 - 00:03:28.460, Speaker B: I hope that now technology will work out. So probably you use some optimization software just as you got here. So really, optimization is like penetrating our life, everyday life. And so it is really one of the greatest success of classical computer science. And we have important applications in route planning, scheduling, resource allocation, power management, and engineering design. All of these problems use optimization protocols to succeed. So what can we do on a quantum computer? Optimization of quantum computer would be much cooler, and maybe we can solve harder problems.
00:03:28.460 - 00:04:51.514, Speaker B: So there are actually quite a few algorithms already which consider optimization in a quantum setting. And we have one class of algorithms which gives proven advantages. For example, grower search, quantum walks, backtracking SAS solvers, and backtracking in general, shortest path algorithms in a graph, minimum weight spanning tree, all sorts of graph algorithms. And they also have many proposals for heuristic one, two algorithms, for example, quantum annealing or adiabatic algorithm, or its versions like QAOA, or variational quantum eigen solvers for quantum chemistry and quantum machine learning, where we both have heuristic algorithms, and we also have some provable improvements, such as for regression and least squares. But a large class of optimization problems which can be, can be phrased in terms of linear programs or semi definite programs, which are their generalization. And until a few years back, we didn't really know how to solve these problems more efficiently on a quantum computer. What is a linear program? I'm sure most people are familiar with them.
00:04:51.514 - 00:05:21.766, Speaker B: Just let me quickly recap. So, in a linear program, you are looking for a vector which optimizes some objective function. Your objective function is this vector c, and x is the value you are looking for. And you have some constraints. So you have some linear constraints that you want to satisfy all together. And usually you assume that your solution is, for example, positive. These things can be removed.
00:05:21.766 - 00:06:13.902, Speaker B: It's just a standard form of Lp's. And now SDPs are a direct generalization of this problem. Instead of taking a real vector, you will work with an n by n PSD matrix. And the thing looks, looks like really the same, you still have some objective function, which now inner product between two matrices, and you have some linear constraints which are inert product between two matrices. And this inner product is usually taken to be just the trace inner product. So really you just get traces instead of the inner product of two vectors. So now this is an SDP, and we will consider how solving sdps, and we will just make some assumptions and notation that will be useful during the talk.
00:06:13.902 - 00:07:13.804, Speaker B: So x will be always an m by n matrix, and we will have m constraints, and we will assume that we have some normalization constraints, like the matrices don't have too much norm. Just to make sure that we are on the same page, and for some technical reasons in the work, we also need that we have some bound on the size of the solution. So this x shouldn't have too big trace. And also it's something related to a dual solution of an SDP. I will not talk too much about it, but we also need to assume that the dual solution has some bounded size. And under these assumptions, the goal is to find an additive Epson approximation of the optimum value, or maybe getting out a solution as well. But I will mostly concentrate on actually figuring out the value of the semi definite program.
00:07:13.804 - 00:08:02.594, Speaker B: So in this framework, you can express many, many, many problems. For example, max approximations of the Maxcat, the lava's theta number. They are sum of squares approximation of many hard problems, and they are also quantum applications. For example, the general adversary bound is actually just an SDP. And by solving this SDP, you can figure out things about the query complexity. So I quickly want to walk through the classical solvers, the history of how our knowledge and our techniques developed during. Well, actually it has now quite a long history.
00:08:02.594 - 00:09:21.088, Speaker B: So the first algorithm for solving linear programs was proposed by Dantzig in the middle of last century, and this algorithm is still used in practice. But it turned out that it's hard to prove, like sometimes. So it's hard to prove bounds which really match the actual complexity that we see in practice. And then later, there were other methods, ellipsoid methods, that were easier to analyze, and they were proven to be polynomial at time, but these were still not as efficient in practice. And the big realization was in 88 of Gretzel, Lobas and Scriber, that actually the ellipsoid method, although it's maybe not the best algorithm in practice, but from theory perspective, is beautiful. And actually this also gives a way to solve sdps very efficiently, at least in complexity terms. So recently, there was a large progress in different methods, like the interior point methods, which kind of combined the best of the two words.
00:09:21.088 - 00:10:30.444, Speaker B: They are really practical algorithms, and they really work in a broad sense. And the state of the art methods in terms of asymptotical complexity, they would give you something like this, where m is still the number of constraints, n was the size of matrices, and s is the sparsity. How sparse are the input matrices and these methods. This is not too bad. This complexity, this omega is just really the matrix exponent, the matrix, the exponent of the matrix multiplication complexity, which, like in practice, you should think that it's three, but we know that it's less than three, but in practice, still, you just think about it as like a three, for example. And so the nice property of these solvers, that they depend logarithmically in the precision, really, if you want to get a more precise solution, just like add more bits to your variables and everything works out nicely. However, there's an alternative approach to SDP solving, and this was proposed by Aurora and Kada in 2008.
00:10:30.444 - 00:11:25.754, Speaker B: And so their method is deeply related to gradient descent methods. And in general, we can say that they have worse error dependence, typically polynomial, still not logarithmic. However, in certain cases, you get a much better dependence on n and m using this framework. So this is the classical landscape, and now we would like to see what can we do quantumly. And so, actually, actually, so far, the quantum algorithms are all based on ideas related to Ararakala, and they give nice speed ups in terms of n and m, but they have a very heavy dependence on the precision parameter, which is actually not the original precision, but you somehow need to scale it with the size of your solutions. This is what I call delta. It's like a relative precision parameter.
00:11:25.754 - 00:11:52.994, Speaker B: And in this parameter, you get a polynomial independence, which was originally quite bad. But the big breakthrough in this paper of Brando and swore in 2016 that you actually get a large speedup in terms of m and n. And this was really the first SDP solver which showed at least some speed up in terms of quantum computing.
00:11:55.014 - 00:12:06.334, Speaker D: Here, like in Stacey's talk, it's the same issue, right, in terms of representation of the output of the input as a sort of position, rather than.
00:12:06.494 - 00:12:28.258, Speaker B: So if you only consider the value of the program, then it's just a real number, and then you can use like amplitude estimation, and that will give you some dependence on that. And this already is the complexity of getting this one single real number out. You want to get this out to epsilon precision and then this is the complexity that you need to do that for the input.
00:12:28.306 - 00:12:33.574, Speaker E: You're having access to the constraint matrices using these kind of superposition periods.
00:12:34.034 - 00:13:07.764, Speaker B: Yeah. So, okay, yeah. The input model that I described here is, the sparse input model is the same as for like, as was for hamiltonian simulation problems or in stasis talk. So you assume that you can efficiently compute elements of the matrix and locations of the nonzero elements. And that's your one query. One query tells you where are the non zero elements and what is their value in the matrix. So you don't need a quran by default, if you have some nice structure to your problem, you might be able to generate these elements much more efficiently.
00:13:07.764 - 00:13:49.084, Speaker B: Okay, so you need a quantum oracle, right? Yeah, quantum oracle, yeah. The query is to this sparse access oracle. And so, you know, this looks very nice, this m and m dependence, but the data dependence is really discouraging. And we started working on this with Uran phanapadone, myself, Sanda Gripling and Ronald above. So we are, this is three PhD students of Ronald and we really wanted to understand if this technique can be made practical and we made some nice progress. The arrow dependence went down from 18 to eight.
00:13:50.024 - 00:14:05.644, Speaker D: Can you clarify a little bit more this issue between the difference, regarding the difference between the quantum and classical oracle? If you have a classical oracle, I mean if you, if you know the system that you're trying to solve, is it easy to implement upon work or not?
00:14:07.224 - 00:14:35.674, Speaker B: Well I guess if you have some like classical algorithm which can compute the non zero elements of your matrix, then you just take this circuit, make it reversible and implement in your quantum computer. So if you really have good knowledge in terms of algorithmic like implementability of your matrix matrices in a structured way, then you can do it efficiently. But it's, yeah.
00:14:38.014 - 00:14:42.670, Speaker A: If you have a circuit that gives you the matrix then you don't need the, but in general.
00:14:42.742 - 00:15:20.034, Speaker E: Why would you, it's the same modern, but it's the way that you think of where the data comes from that makes a difference. So in Stacy, stop. We were thinking over doing linear regression on some data that we collected and in that case this data has no structure at all and so we need something to implement the workload. Whereas in that case we're thinking, well, this SDP is maybe very structured and these constraints are just, you know, checking that some entries are less than one or something like this. And so then it's very natural to say, well there's a classical circuit for this. There's also quantum circuit, and so it's, we could be able to, to implement bigger or gradient superposition. So this is the same model.
00:15:21.174 - 00:16:02.414, Speaker B: Yeah. So for example, if you would have some nicely structured matrix and you wanted to compute, say, Maxcat, then all the constraint matrices are very easy to implement once you know, what is the graph that you want to examine? That's an example. Can you remind me what capital r and little rubber. Yeah, so that was somehow the size of the solution. So that was an upper bound on the trace of x and this little kept this little r that was bound on the dual solution. That's a bit less intuitive in this picture.
00:16:04.394 - 00:16:11.384, Speaker A: Do you have any intuition how big we should think that these are? Like for like the Maxcat, as you said, or other kind of.
00:16:12.804 - 00:16:45.484, Speaker B: Yeah, yeah, yeah. So for Maxcat, essentially you have a variable for every, every vertex, essentially. And then. Yeah, it's like n indeed. So typically in graph problems, it becomes the product r r, little and big r capital r. They become like polynomial and nm typically like linear in n or m or both. So that's indeed, that limits the applicability of these results, especially if you have this.
00:16:45.484 - 00:16:50.512, Speaker B: Can you say when would these be smaller?
00:16:50.688 - 00:16:53.364, Speaker E: When would capital r, little r these form?
00:16:53.904 - 00:17:02.364, Speaker B: I will show some examples which give some speed ups, but yeah, that's the tricky part in applying especially these techniques.
00:17:03.434 - 00:17:26.214, Speaker C: So maybe just like as a high level point, can you explain, like, in which parameters has there been an improvement? I guess. Okay. In m and n, right. But sort of, you know, are all of the improvements here sort of, let's say, of Grover type, you know, like quadratic style improvements? Are there, are there any parameters in which there's a bit of more than quadratic improvement?
00:17:28.284 - 00:18:09.064, Speaker B: So there are like alternative input models, for example, when you get the matrices somehow as density operators or purification of density operators, that is just essentially the next slide. Next thing here. Sorry. So, like Brandau, Caleb, Lee, Lin swore and Wu last autumn, they showed an algorithm which essentially has logarithmic dependence on the size of the matrices. But this assumes that you have a very special quantum access to your matrices. Your matrices are somehow related to quantum states. And then it's hard to give a classic analog.
00:18:09.064 - 00:18:15.720, Speaker B: So it's really technically, it's not an exponential speedup, but maybe it would be in practice.
00:18:15.912 - 00:18:22.604, Speaker C: So when the inputs are classical, you would say that the challenge is to get quadratic type speedups.
00:18:23.784 - 00:18:36.216, Speaker B: Yeah, yeah, but it's actually, it would be still relevant because although we have nice algorithms for solving sdps. When you have, like several thousand variables, it actually becomes practically infeasible after some point.
00:18:36.320 - 00:18:43.592, Speaker C: It's not, I don't have to be solved, that quadratic speed ups are valuable, but. Yeah, yeah. Okay, cool.
00:18:43.728 - 00:18:48.844, Speaker B: Yeah. So in this case, you could get something which, which is nicer in n, but in the array parameter still.
00:18:49.554 - 00:19:08.134, Speaker C: Can I ask a question that, I mean, you may not know the answer to this, but, like. So now there's these two different classes of classical SDP solvers, like this Aurora kale class and this Lisa for that. Do you know what kinds of problems do people prefer this algorithm for compared to that one? Because maybe we should be looking at those problems, the ones for which classically people use aurora color and not behavior point method.
00:19:08.994 - 00:19:53.950, Speaker B: Yeah. So typically for graph problems, it can be really nice when, for example, if you want to approximate some NP hard problems, but maybe in the regime where approximation is not NP hard, for example, for Maxcat, then you, anyway, you cannot get closer to the optimal solution than some constant factor, and then maybe the relative precision that you want is just some constant. Therefore, your epsilon would be really just a constant, and then it's nice. However. Yeah. These applications always need some very, very clever fine tuning of your algorithm. They don't just go down the generic SDP way.
00:19:53.950 - 00:20:34.604, Speaker B: They somehow do some problem specific tuning of these methods. Okay. And so there are some, some interesting developments just recently. This year, the same people proved square root m plus square root n bound. They introduced some techniques, which is the fast quantum, or lemma. And actually, we were discussing this paper with them, and then they came up with this improvement. And at the same time, we also figured out that this.
00:20:34.604 - 00:20:48.592, Speaker B: So they first applied this fast, or lemma to this quantum input model. And around the same time, we figured out that this improvement actually gives a nice new way to do the sparse matrices.
00:20:48.768 - 00:20:50.888, Speaker A: Here you're back in the classical input model.
00:20:51.056 - 00:21:48.234, Speaker B: Yes. So this was the only point where I assumed this special input model. All the other is just the standard sparse input model. And using ideas that came up from this paper, actually, you can get not a product of m and n, but addition of these two parameters. And so they used ideas from our previous paper, and they get some not that amazing dependence on the error, which we could essentially quadratically improve using new ideas coming from actually, like some quantum data structures and from hamiltonian simulation and quantum signal processing. So a lot of the developments and techniques that you heard today actually were applied to get this nice complexity. This data to d five is still not quite satisfying, but this is the state of the art.
00:21:49.334 - 00:21:59.354, Speaker C: Just to understand, is there a classical SDP algorithm whose complexity something like m plus n times poly of s over delta?
00:22:04.374 - 00:22:11.414, Speaker B: I'm not aware of a generic purpose SDP algorithm that would give you that.
00:22:11.534 - 00:22:14.314, Speaker C: So in that case, this is more than a quadratic improvement.
00:22:14.734 - 00:22:24.194, Speaker B: Yes, but we were thinking about it, and we think that actually you can reverse now the quantum algorithm and make a classic algorithm out of it.
00:22:24.534 - 00:22:29.678, Speaker C: Okay. Okay. So you think maybe indeed that will exist?
00:22:29.806 - 00:22:30.514, Speaker B: Yes.
00:22:31.614 - 00:22:34.074, Speaker C: Thank you. Thanks.
00:22:36.494 - 00:23:39.256, Speaker B: Okay, so now I just would like to show you essentially what are the basic ideas behind these algorithms and how you get these speed ups. What is the main point? So instead of looking at this minimization problem that I started with for sdps, just would like to make it simpler. Instead of looking for the minimum, I could do some binary search. So I could just say, hey, is this trace c times x? Can I make below alpha? And if I can ask this question, I can do binary search and figure out what is the optimum very efficiently. But now I can realize that actually this constraint formally looks the same as this constraint. So I can just forget about this x and assume that the problem is just asking the following. Is there an x, an n by a matrix that satisfies these requirements? And so this is just an extra assumption that I add, which is nice for me here, but you can reduce the previous cases to this very simply.
00:23:39.256 - 00:24:31.578, Speaker B: It just makes life a bit simpler. So it's enough to solve this problem, and then you can solve all the previous problems that I showed you. And the nice thing that this feasibility problem, we just ask whether such an x exists, satisfying all the constraints or not. It's much simpler to solve. And actually it's too much to hope for designing this question exactly. I need to give some room for myself. So either I want to find an x with trace x equals one, that they solve these, they satisfy the constraints up to a delta error margin, or when actually there is no x satisfying without the arrow margin, this problem, I can say I should conclude that the problem is infeasible.
00:24:31.578 - 00:24:55.026, Speaker B: So there might be a case when there is a delta approximate solution, but the problem is not strictly feasible. In that case, I'm allowed to do either. So I might just output a delta approximate feasible solution, or I might just say that there is no solution and I can do either. In this case, your x is still.
00:24:55.050 - 00:24:58.570, Speaker A: Supposed to be PSD, right? That's a constraint that's implicit here.
00:24:58.762 - 00:25:36.410, Speaker B: Yes. X is always a PSD matrix. Yes. So now, the basic algorithm, which is motivated by essentially gradient descent in a deep level, but it's maybe not obvious at the first sight. It's just what is behind the auroracal algorithm. So essentially the idea is that I will look at a very specific form solution. So I start with a vector y, which will be related to a Euler solution, but it's just a vector.
00:25:36.410 - 00:26:11.858, Speaker B: Now think about that way. It's just zero originally. And I will have an iterative algorithm which will have some upper bound on the iteration number, which is some polynomial in the precision parameter. And the nice idea is that I want to try and find an X which is a gib state. So it means that I will construct a Hamiltonian which is a linear combination of the constraint matrices. These are also hermitian operators. So I can just, this is indeed a hamiltonian.
00:26:11.858 - 00:27:16.532, Speaker B: Then I can define x as the Gibbs state corresponding to this hamiltonian, which is just e to the minus Hamiltonian normalized. And this will have always trace one. So this is good. And it turns out that I can always find a solution in this form if a solution exists. And so the algorithm, once it defined its ansatz in terms of this hamiltonian Gibbs state, is we are trying to find a constraint that is violated, meaning that this x, that is my current gas, that will actually violate that constraint. And if I find such a value constraint, I will simply update my vector y and I will add some bit of this constraint to it, which will make progress to the good direction. And in the other case, if all constraints are satisfied approximately, then I can just simply, I am allowed to output that it's an approximately feasible problem.
00:27:16.532 - 00:28:12.564, Speaker B: And actually, I also learned something about the solution. I can learn a Hamiltonian corresponding to which it's a Gibbs state. So I don't only output a number of the, at the end of my algorithm, I don't only know the optimal value, but I will also get access to a quantum state which is proportional to a solution. Yeah. And so the guarantee is that if my algorithm doesn't output an approximate feasible solution during this runtime, then it is true that the problem is infeasible. And the proof of correctness that appeared in a paper of Lee, Ragandreva and Steuer in XV. And this is very similar to the Aurora kada algorithm, essentially.
00:28:12.564 - 00:29:08.470, Speaker B: And the nice observation of randou and Sora was. And then the later paper that this exactly fits the quantum picture. I can just work with density operators for these Anza states. Okay, so now quickly, how do you speed up in quantum ly now I need to prepare the state x. And yeah, I just assumed the usual sparse axis for the matrices that we already talked about. And so using this sparse access I can implement efficiently an operator which I call uselect corresponding to quantum simulation LCU methods. So this operator, conditioned on the state j, would just act with the inter UJ, which is a block encoding of Aj itself.
00:29:08.470 - 00:30:18.138, Speaker B: It turns out that I can implement this unitary with roughly squeeries if I have sparse access to the matrices. And another trick which comes here is that I will store my, my coefficients in this vector in a Quran using a data structure that Kerenvis and Prakash proposed. So the nice thing is that in each round of my algorithm I will only get one more nonzero element to my y vector. Therefore I can update the data structure very efficiently in each step. Also, it means that my y vector will be quite sparse. So if someone doesn't like Qram, we can just, because it's a relatively small amount of data, I can just construct the qram as a circuit and it doesn't hurt too much. Okay, so now very quickly, how does the algorithm go? You constructed this select operator and then using preparation for this y vector, you can actually form a linear combination finitaries that will prepare you in the top left block, this block encoding of your hamiltonian essentially.
00:30:18.138 - 00:31:37.288, Speaker B: So this was just the definition of hamiltonian and that's with some sub normalization. And then using quantum signal processing techniques or single value transformation techniques, however, which are like a version of it, essentially using roughly one over delta uses of this previous unitary, you can actually get an exponential. You can implement this matrix in top left blocks, which really similar to the Gib sample that you want, but it will give you a subnormalized gib state in one go. So the idea is that once you constructed the unitary at the top left block just corresponds with exponential decay. Then you will apply this matrix to one half of maximally entangled state and you will apply amplitude amplification and then you actually will get a Gibbs sample x. So this is a bit quick, but the details are worked out and I can answer later if there is some questions. So, but anyway, the, it is just a proof that the Gibbs sampling problem can be solved with the product of these complexities, which is square root n times s over delta.
00:31:37.288 - 00:32:19.004, Speaker B: So this was the cost of Gibbs sampling. Now I have a Gibbs sample, I have x. Now I just need to compute expectation values to sum data precision. That's the next step of the algorithm. And well, it turns out that if I can do this measurement, then I need roughly one over delta squared copies of the Gibbs state, this x, to figure out this value up to delta precision. And, well, it turns out that this measurement can be efficiently implemented. Again, because the a matrix is sparse, the complexity would be something like s over delta squared.
00:32:19.004 - 00:33:13.858, Speaker B: And now here comes this new addition of Brandau et al. Which essentially speed up the quantum olmma of Harrow et al. And here the addition is that it turns out that it's not much more difficult to check all the constraints simultaneously than checking one constraint. So we can find a constraint that is violated or conclude that actually all constraints are roughly okay with the same, with essentially very similar sample complexity to the case, to the previous case. I still need something like one over delta squared copies of x. I need a little bit more work to do on the gate complexity side. I need to check all the constraints in parallel, but that only gives me like a square root m factor.
00:33:13.858 - 00:34:21.458, Speaker B: More work. This is how you get the square root everything. And now you see that this step that you need to do in each iteration of your algorithm actually has this complexity because I showed you that preparing x cost square root ns over delta, and I need delta square copies. So this is just how much it costs to make many copies of my x state. And then this is the complexity coming from the quantum olama, and it is a plus because I first just prepare the Gibbs state and then do some olamma thing instead of the previous approaches, which prepare the Gib state and then apply some amplitude amplification, which then took the product of these two quantities, and you get the final complexity by observing that iteration number of the whole classical argument I showed, that is just one over delta squared. So you get this delta to the fifth and the plus of the square root m and square root n. And I just quickly want to show some applications.
00:34:21.458 - 00:35:14.814, Speaker B: So shadow tomography is a very nice application. This is due to Scott. So here the task is that you are given samples for density operator, which is unknown, and you are also given m measurement operators mj. And while you can phrase it in a way that you want to find just a vector such that the linear combination of your measurement operators give you a hamiltonian corresponding to which the Gibbs sample. So this is just a Gibbs sample corresponding to a hamiltonian that you construct. This will be very close to Rho, the unknown density operator in expectation value for all measurements that you are concerned with. So you want to figure out, in a way, you want to figure out simultaneously all expectation values for all measurements.
00:35:14.814 - 00:35:51.104, Speaker B: But you do it in an indirect way. Instead of learning all the expectation values individually, you just construct the gib state which will match the expectation value. So you can do later tomography if you wanted. But here the emphasis was on the sample complexity. So as Scott showed, actually you can solve this problem using some logarithmic factor over delta to the fourth samples. Initially it was delta to the five, but later he improved it in subsequent work. And around the same time we improved our SDP solver.
00:35:51.104 - 00:37:04.144, Speaker B: And the nice thing is that our SDP solver, which is a general thing, it actually recovers the same sample complexity in a gate efficient way that only incurs like a square root m extra gate and query overhead to the whole problem. And we have some further applications to quantum state discrimination with maximal total success probability. Here you are given many possible quantum states, but you don't know, like the new quantum state arriving falls into each category and you want to have a maximal probability of guessing which quantum state you received. And you have some optimal measurement design, which is some stochastic problem that wants to learn some classical variable and how you would do your classical experiments in optimal way. And that's we try to solve. So these applications, we get some speed ups in terms of one parameter, which is typically the number of different objects, which is like number of different states or measurement, and we have some bad dependence on either parameters. So these applications are not entirely satisfactory, but they show that you can do some non trivial things already.
00:37:04.144 - 00:38:22.424, Speaker B: And just as a summary, so I showed you a quantum SDP solver which had this query and gate complexity where you get an additive factor of square root m and square root n, but still has some non trivial dependence on the error. And what we also showed in these works, Brandau and Suur had a lower bound of square root n plus square root and is sparse xs input model for the same problem, which apart from the arrow dependencies, right. We also show a square root m over delta lower bound in a slightly quantum input model. It's not the most quantum input model, but it gives you a linear dependence already on the error. And I just want to briefly sketch a few open questions and future research directions. So, as already you asked in the talk, what we should probably do is to consider a problem specific applications, because that's how actually the classical Ararakala algorithm achieved nice results. They fine tune their algorithm actually for specific problems and.
00:38:22.424 - 00:39:13.624, Speaker B: Yeah, well it's, of course it could be still that we can improve this arrow dependence greatly. Maybe if we could improve it to like quadratic then we would start beating the interoperability methods in terms of asymptomatic complexity for interesting problems, and we don't see any obstacle like in complexity theoretical sense to do so. And yeah, of course this is just essentially one very specific way of addressing SDP solving. And it would be interesting to see if we can do some similar speed ups to more advanced methods, like interior point methods, which have nice dependence on the error, maybe allowing for more applications and. Yeah, that was it. Thank you.
00:39:21.084 - 00:39:23.044, Speaker E: Just this one by delta lower bound.
00:39:23.084 - 00:39:23.564, Speaker B: How come?
00:39:23.644 - 00:39:27.704, Speaker E: What's the assumption that you can't beat the classical log one by delta?
00:39:28.364 - 00:39:47.912, Speaker B: Yeah, so here I don't assume that I have a sparse excel to the matrices. I assume that someone gives me a unitary where the top left block is my constraint matrix. My constraint matrices had bounded norms, so it is possible to give me the constraint matrices in some such way. Yeah, but I mean, okay, what I.
00:39:47.928 - 00:40:03.334, Speaker E: Understand is on that even that input model, couldn't I run the classical algorithm, classical interior point algorithm, just recover the matrix, whatever. This will take me some time. M and n polynomial maybe, but in terms of delta, it will be logged on by delta.
00:40:04.074 - 00:40:13.098, Speaker B: But here you are given a unitary, which is a black box symmetry. Sort of. The only promise is that the top left block is your constraint matrix.
00:40:13.226 - 00:40:19.666, Speaker E: So if I need to recover classically description of the top left, and then I'll run the classical array.
00:40:19.730 - 00:40:27.544, Speaker B: Yeah, but then if you wanted to recover it to, say delta precision, then you would need to run tomography and it would already have a one over delta dependence.
00:40:36.324 - 00:40:39.012, Speaker E: No, I mean I just recovered the bits of the entries one by one.
00:40:39.108 - 00:40:40.864, Speaker A: You don't have the matrix axis.
00:40:41.284 - 00:40:53.600, Speaker B: I can't query unitarium. This is in the sparse matrix access point. This is the classical analog. This is the classical input model, sort of in a quantum way. This is a non classical input model.
00:40:53.672 - 00:40:55.416, Speaker E: Where you just implement the unitary input model.
00:40:55.440 - 00:40:56.044, Speaker B: Yes.
00:40:59.024 - 00:41:10.240, Speaker A: So this delta to the four, this r over rr over epsilon, it also exists in the Aurora Kalle algorithm. Right. So is it better than to the four or so?
00:41:10.312 - 00:41:21.724, Speaker B: They have essentially quality dependence on the error. Okay, so we get additional factors because we work with quantum state instead of writing down numbers with binary digits.
00:41:22.384 - 00:41:27.024, Speaker A: But in principle you could hope to push it up to quadratic somehow.
00:41:27.184 - 00:41:50.654, Speaker B: Yeah, or maybe even using some different iterative method which has like lower iteration number. That would be also giving you huge advantage. And we know like there are like stochastic gradient descent methods which have much better convergence in terms of the error, but it's unclear how to adapt them to sdp solving. But maybe we can do some progress there.
00:41:50.814 - 00:42:04.994, Speaker A: Then you would have a better classical algorithm somehow as well, right? I mean, you can try to improve the. This would also improve, I guess, the number of iterations of the classical SDB soldier.
00:42:05.294 - 00:42:11.034, Speaker B: Yeah, but maybe you need to solve a problem which is much harder classically, but quantum still remains easy.
00:42:14.074 - 00:42:29.854, Speaker A: Okay, sorry. One more question for the shadow tomography. I have the same question about all tomographies now. So, the sample complexity is polygorithmic on m and n, what is your time to actually find? So how efficient is your reconstruction?
00:42:31.954 - 00:42:35.858, Speaker B: So, reconstruction of what? So, okay, try to find something, right.
00:42:35.906 - 00:42:44.204, Speaker A: You tell me that the number of samples you need is log m. Log n. Yes. How much time do you need to spend on the samples?
00:42:44.704 - 00:42:50.524, Speaker B: Well, it is this, like, sample complexity times square root m and some logarithmic factors.
00:42:52.744 - 00:43:31.974, Speaker C: Right? So there's a question of definition here, right? If we ask you to output all the expectation values or reserve, then that clearly takes m time, right? Yeah, m time. Right. But if you're allowed to output an implicit description, just here is a matrix. Here's a state that approximates the value of this, your target state, on all these measurements, then you could hope to do that much more efficiently. But then there are complexity theoretic obstacles to doing that in full generality, with only polylock of m computation cost.
00:43:35.114 - 00:43:36.234, Speaker E: Okay, no more questions.

00:00:01.000 - 00:01:09.864, Speaker A: What I'm going to talk about today, just the rough plan. I'm going to give, or try to give two motivations of why this problem is either interesting or why we started thinking about this problem and then explain what the problem is. It's a combinatorial problem about the geometry of the n dimensional hypercube, and give the sort of analytical version of it, like how do you transform this as an analysis problem, harmonic analysis problem, and give you a sketch how to solve it, hopefully. I don't know how much time we have now due to the schedule shift, but anyway, I'll try to get through all of that. Let's first start with a motivation that Gil, I think, and a couple of other people had mentioned in the blog, the election interpretation thing. So let's say we have elections like we had relatively recently, and we have two parties, Democrats and Republicans, and we have a set of voters. They vote either Republican or Democrat.
00:01:09.864 - 00:01:47.008, Speaker A: And we want to see how the demographic and personal characteristics influence the political preference of a person. And roughly, we model this as a binary string. So we have different categories for each person. Each bit is zero or one, and represents either if they're male or female, if they're married or single, urban, suburban, et cetera. You can add other things, positions to certain issues, like pro life, pro choice, gun rights, gun control, et cetera, et cetera. I don't know. Somebody's surfer or not surfer, I don't know.
00:01:47.008 - 00:02:27.416, Speaker A: You can add whatever you want there. So this assuming that all possible combinations can be found, let's just now, you know, make this assumption to make my point. The set of voters could be thought of the vertices of an n dimensional hypercube, wherein is a set of characteristics that we think represent the political preferences of someone. So let's assume that we have these four characteristics. These are voters, male, of, married, urban, and religious. Male, married, urban, and not religious, et cetera, et cetera. So what we care is to find typical voters.
00:02:27.416 - 00:03:17.212, Speaker A: What are typical voters? We call the voter typical. If you take their characteristics and you vary any k of them, and you expect that largely you're going to find people that vote for the same party. So let me make that more. And we care to see if typical voters exist. So let me make that more precise. Let's say that blue is what the people that voted for democrats, and red are the people that voted for republicans. So what we want from a typical voter, x, is that if we vary any one of the characteristics of x, meaning if we take the sphere of radius, one in the cube, then most of the people around x on this sphere should have voted for the same as x.
00:03:17.212 - 00:03:57.070, Speaker A: So for democrats in that specific case, and we want to do that for every sphere. So for sphere radius two, most of them, for x to be typical, most of them need to have voted for the same party. So for Democrat here and et cetera. So it turns out that if a party wins with large enough landslide, then typical voters exist. Exist, which means exactly that. So there is an x that if you vary any character, any set of k characteristics of x, then you still find most people that vote for the same party. So, and this is what we're going to prove, actually in different terms.
00:03:57.070 - 00:04:59.344, Speaker A: But this is, this is the point of this talk. So this is the first sort of more, I don't know, motivation. That's not our motivation, but I thought it was a nice relation to this problem. The second one, the second one comes from Unigames conjecture, so it might seem completely unrelated to uni games conjecture for those of you who know what it is right now, but that's why we started looking at this problem. And I think it's worth mentioning because it's interesting, the path that we followed to come to this. So is there anybody, I don't think anybody doesn't know unigames conjecture, right? Is there anybody not familiar? Okay, I mean, I'll talk about that, but yeah, I just want to know how fast or slow I'm going to talk about this. So, union games conjecture is a conjecture, clearly about the problem being hard, and it turns out that it's mostly useful in studying the exact inapproximability of certain np hard problems.
00:04:59.344 - 00:05:56.490, Speaker A: So, as you probably have heard, a lot of the very interesting computer science problems like Maxcut and vertex cover and Max k, CSP, et cetera, et cetera. The best approximation algorithm known to this day matches the guinea games conjecture, hardness, as we call it. What does that mean? It means that if we assume that unigames is hard, which I haven't explained what uni games is, but if we assume that it is hard, then it means that the best algorithm that we know for these problems cannot be improved in polynomial time. So it's a very interesting tool of explaining sort of the theory of inapproximability. And what's the status of inapproximability of problems right now? Okay, so what is uni games? I'm going to go through this a bit fast because I want to make a point. So it's a uni games instance, is a set of equations, let's say. Now they're linear equations, modulo sum prime.
00:05:56.490 - 00:06:59.112, Speaker A: It's as hard as in the general case, but let's focus on this case now for simplicity. So we're given a set of linear equations and we are asked to find the labeling that satisfies the maximum fraction of them. Okay, so this is an instance of uni games, and we use k as the Alphabet size. So we want to assign values from zero to k minus one to all of the xi's such that most of the constraints of the form xi minus x j equals some cij mod k are satisfied. And the way people and I personally like seeing uni games is with a corresponding graph. So how do we make a graph out of an instance? We take the set of constraints and let's assume now these are the three simple constraints, and we just put a variable for each, sorry, a vertex for each variable and an edge connecting two vertices when there was a constraint connecting these two variables. And we put like the labeling or the constraint on the edge.
00:06:59.112 - 00:07:31.252, Speaker A: So this graph is representing this instance. Is that clear? So all I'm gonna use. Yeah, okay. All I'm gonna use about unit games for, to make my point is this graph. Not much else, but let me give you. So an example of the value of this instance would be an assignment that satisfies these two constraints and doesn't satisfy that constraint. Or you could use all possible three of them, and in fact this is the best you can do.
00:07:31.252 - 00:08:51.408, Speaker A: So the value of this instance in the specific case would be two over three. So this is a maximum fraction of constraints you could hope to satisfy given this instance. Okay, all right, so what unigames conjecture, say, which was made by Subash 2002, is that for every Epson and Delta you give me, I can find a large enough k, large enough Alphabet size, such that given an instance of uni games with Alphabet size k, it is np hard to distinguish between the two cases where the optimum, this maximum fraction of constraints I can satisfy is bigger than one minus epsilon, or the optimum is less than delta. So what this says, basically, is that if I have a 99% satisfiable instance of uni games, it is NP hard to even satisfy 1%. So to come up with an algorithm that satisfies 1% of the constraints. All right, and notice here that this is sort of embarrassing, that we don't know what happens, because if I told you that here is a system of linear equations, tell me if it's satisfiable or not then you would be able to tell me really fast. Linear systems of equations are easy to solve.
00:08:51.408 - 00:09:46.100, Speaker A: So what the unigames conjecture say is that if I change this satisfiability property a little bit, so if now it's not a system that's completely satisfiable, but it's almost completely satisfiable, then the problem becomes NP hard. So this is a little strange. And let me show you a really easy algorithm that uses propagation to solve completely satisfiable uni games. So here is a graph, and let's say all of the constraints are zero, are the identity constraint. I can start with a value and propagate across the edges and find an assignment that satisfies everything. So this is a very simple algorithm, but however, the sharp boundary from taking this easy problem and changing it a little bit makes it hard. I'm not, I don't think anybody really understands exactly why this happens, but let me get to what I really want to say.
00:09:46.100 - 00:10:47.156, Speaker A: So, since unigames have been so popular the last ten years or so, maybe eleven, a lot of people have tried both to prove it and disprove it. And the sort of plan of attack for the class of people that tried to disprove it was to start ruling out cases. So we looked at graphs, me and other people, many other people, and looked at this graph that before it was a triangle, this unique games constrained graph, and classified this graph according to its spectrum. So the first result of this sort of along these lines was to say, okay, if this graph that represents the instance as an expander, then uni games is no longer hard. So we know something about a graph that has certain spectral properties, and now the problem all of a sudden becomes easy, meaning polynomial time algorithm to recover an assignment, and then this. And there are a lot of people involved in this work. So I'm not, I don't know.
00:10:47.156 - 00:11:36.484, Speaker A: I should mention that Aurora and Tulsi, Anistar, Vishnoy, Cod, myself, Ragavendra, Barack, a lot of Luca has algorithms. Like, a lot of people are involved in this uni games business. So I'm not gonna give reference every time I talk about a result. But, yeah, so sorry about that. Okay, so after expanders, we as a community went one step further and said, okay, not only expanders are easy, but now local expanders, graphs with relatively few large eigenvalues, meaning of the adjacency matrix, large eigenvalues, so small set expanders in some sense are also easy. So uni games is not hard on this. On this type of graphs.
00:11:36.484 - 00:12:19.204, Speaker A: And we also looked at distributions and said, okay, we right now don't know exactly what are the hard graphs, but maybe we can find a hard distribution. It turns out that random instances, average case complexity of uni games is p. Random instances are expanders, so they can be solved in polynomial time. Not only that, but also quasi random instances, which means take any graph and just preterm randomly epsilon fraction of the constraints from starting from a satisfiable instance. This is also in p, so we don't really know any distributions. And let me say one more thing. Let's go back to this spectral profile.
00:12:19.204 - 00:13:21.996, Speaker A: So, graphs that are really sparse, like planar graphs and trees, of course, planar graphs, graphs with low genus, they sort of a folklore, you know, separator, slash abs result, aurora, barack and steroid, that shows that these graphs are also not hard for uni games. So we have this picture now where it says that how easy the graph is for unigames depends on the number of large eigenvalues of the adjacency matrix, according to this technology. So graphs with very few large or bad eigenvalues are easy. Graphs with very many large eigenvalues are easy. Now what remains, that's the question. And in fact, what remains is a class of graphs that, I mean, there are a couple of graphs that we know belong to this class, but they all sort of resemble the boolean and includes this class, of course, the Boolean hypercube. So what, as a next step, as you know, me and co authors saw that is to solve uni games on the hypercube.
00:13:21.996 - 00:14:04.244, Speaker A: This was our goal. Like what happens to this graph that we know a lot about. And we had this suggested. First of all, let me again, what's the hypercube? It's the hypercube, as we all know, sets of zero, one, strings and dimension n, let's say. And we use humming distance as like the graph distance, which is the number of bits that two vertices of the hypercube differ, and a sphere, I'm going to use spheres a lot, so let me just define it. In the hypercube around the point x of radius r, are all the points around x that differ on r bits from x. So these are spheres according to this humming distance on the hypercube.
00:14:04.244 - 00:14:42.452, Speaker A: So let me now ask, I mean, that's what we asked at the time, is how about this silly propagation algorithm? Show me that it works, or it doesn't work. You start from some point, or maybe several points, and by some brute force, like it's a small set of points. So you go through all possible assignments and you pick the best one. So you start, let's say from one point for now, but, you know, probably need to start from more. You have some assignment that belongs to the best possible satisfying assignment of the hypercube. And here's how you propagate this assignment. We saw propagation earlier.
00:14:42.452 - 00:15:15.148, Speaker A: Now we have to do something different. For every sphere around this point, let's say we already assigned found the best or some values for the sphere of radius K around this point. What do we do for the sphere of radius K plus one? For every point on this sphere, we look at the neighbors of this point in the previous sphere. So these are like, okay, they're not three here, but these are the neighbors. And we look at the constraints that are on the edges. Remember that we've already set those values. Our algorithm has set those values.
00:15:15.148 - 00:16:29.028, Speaker A: So what we do is we take the majority of the votes of what these constraints on the edges tell you and assign this value to that point. So this is a suggested algorithm that we try to see why it works or doesn't. Okay, so let's see. First of all, what do we need for this at least like the minimum requirement for this algorithm to work is that there exists a point such that there is no sphere around it, that more than some little fraction of the edges that go from sk to sk plus one are corrupted. What does that mean? It means if I think of my one minus epsilon satisfiable instance of uni games as being a completely satisfiable instance of unigames, where some adversary picked epsilon fraction of the edges and made them bad, made them unsatisfiable. Now I want this epsilon fraction of bad edges to be distributed sort of evenly. So notice that this propagation algorithm would never work if all of the sudden in some layer between k and k minus k plus one, I had all of the edges or most of the edges that go between those two spheres to be corrupted, it would be doomed to fail.
00:16:29.028 - 00:16:56.612, Speaker A: So the least we can, you know, we need to answer this question before knowing if this algorithm works or not, is to answer this. Is there a point, at least one point such that no sphere around it has a lot of errors or a lot of corrupted edges? And notice another trend. This is kind of similar as the voter thing. Is there a voter where no sphere around it has majority of republicans? If that point was Democrat.
00:16:56.808 - 00:17:02.424, Speaker B: So the zone just want is there, but you want to know if most of them are like that.
00:17:02.804 - 00:17:10.500, Speaker A: We wanted to know if there is one. We ended up proving that most of them are. But, you know, one would be enough for our purposes. Right, because it's our starting point.
00:17:10.612 - 00:17:12.316, Speaker B: But how would you know how to select it?
00:17:12.380 - 00:17:31.516, Speaker A: We would go through all of them. I mean, algorithmically speaking, you know, it's polynomial the number of vertices of the hypercube. So in the instance. Yeah, I mean, yeah, fine. Most of them is better. And that's what we get. So you show that there is a point, or actually many points for which spheres of every radius.
00:17:31.516 - 00:17:49.912, Speaker A: Yes, exactly. So this is exactly the point of the talk. This is the maximum inequality that I'm going to present. These are the two motivations which I am done with right now. And I'm going to actually talk about the actual stuff. But I wanted to get these two seemingly unrelated things and put them together and see sort of where we. Because we're not mathematicians.
00:17:49.912 - 00:18:32.592, Speaker A: I mean, we are mathematicians, I guess, but we didn't care about maximum inequalities on anything before. You know, we started working on computer science at some point. So we didn't even know these things existed. Okay, so there seem to be two differences between the problems modulated by uni games and the problem motivated by voting that in voting you accounting vertices and in the unigame. Yeah, yeah, so I'll get to that right now. And in the voting problem you have weights because, all right, the voting problem is not 100% sort of representing what we prove, unit uniform distribution, of course, and stuff like that. But it's just like a very loose interpretation.
00:18:32.592 - 00:19:07.108, Speaker A: So again, the edges question is very good. And we asked this question for edges, clearly, and then we said, okay, edges might be hard to argue. What if we ask this question for vertices? So now forget about the edges, forget about the unigames. And let me describe what we actually do. So you have the hypercube, and again, an adversary, the adversary can spoil epsilon fraction of the vertices now by making them bad. So we have a set b, which are the bad vertices of cardinality. Epsilon times two to the n.
00:19:07.108 - 00:19:50.150, Speaker A: Epsilon is some small constant and we fix some threshold lambda that's bigger than epsilon. Let's call a sphere around x of radius r bad if some lambda or bigger than lambda fraction of it is bad, meaning that the adversary has put more than lambda fraction of the points on the sphere to be red. And we call a point x ruined if there exists one such sphere. A point can be ruined only if one of them, all of them are perfect and one of them is bad. Then the point is ruined. So we're really harsh with the point. Okay, so is that clear? Sphere is bad if a big fraction of it is red.
00:19:50.150 - 00:20:48.184, Speaker A: Red points, point is ruined if some sphere is bad. So now the relevant question to what I was saying before that we ask is can the adversary that now makes vertices bad or red, I guess, and not edges can be adversary ruin all the vertices. Okay, so let's see a couple of things that the adversary could do that we could analyze, actually spoil a metric ball. So the adversary just starts from zero and spoils everything of this radius around zero. So that epsilon fraction of the points are spoiled. What happens to the rest of the points? And it turns out that only a small zone of boundary root n log one over epsilon is ruined and the rest of the points, majority of the cube in fact, is not ruined. So it means that again, all the spheres are good for this white point.
00:20:48.184 - 00:21:31.946, Speaker A: So what else can the adversary do? It can ruin a subcube. So these are the only examples we could come up with. So you fix some log one over epsilon coordinates, and let's say that the adversary spoils, makes red all the vertices on this sub cube. Again, not much is going wrong here because the only ruined points are some parallel subcubes some small distance from the sub cube. Okay, so we couldn't really come up with any worse examples than this. And, you know, we applied the mathematicians induction, as Leonard likes to say, nobody else can either. Therefore, this must be what's happening.
00:21:31.946 - 00:22:14.376, Speaker A: This must be true. More precisely, we conjectured at the time that for all lambda, there is an epsilon such that for all dimensions and for all ruined sets of cardinality less than epsilon times two to the n. Sorry, all the adversary sets the red set. So if cardinality less than epsilon times two to the n, the rowing set has cardinality less than two to the n. And I'll make this more precise later, but for existence purposes, this is enough. And lambda, root, epsilon, or some constant root, epsilon works. Sorry, what was that?
00:22:14.440 - 00:22:16.438, Speaker B: The lambda is in the definition of rooms.
00:22:16.536 - 00:22:57.486, Speaker A: Yeah, the lambda is in the definition, correct. So we ended up proving that in a more like concrete setting or definition, I guess. Whatever. But first of all, let me, let me just spend like a few minutes explaining why this theorem is non trivial and why hypercube. And why did we have a hard time proving it? Because it seems natural. It seems, you know, something that, you know, it should probably hold. However, let's, let's say the hypercube embeds into l one, and we, one could assume that that's what happens for sats graphs.
00:22:57.486 - 00:23:29.218, Speaker A: Sats graphs. The thing is that if you look at a closely related graph, that's just a z two grid mode, not n. So, let's say. Let's take the 2d torus, I guess it's called, that has two n plus a dimension, two n plus one, and two n plus one. So, around order of n squared points, I'll show you an adversary that can make not a constant fraction, even a smaller than constant fraction of points. Red. But still no sphere around.
00:23:29.218 - 00:23:49.634, Speaker A: Sorry. No point is good. So, let me say that a bit better, because I have. I don't think I. I said what I wanted to say. So, let's take this example where we have the two n, one by two n, one grid. And now my adversary makes red all the diagonals with the coordinates sum to zero mod n.
00:23:49.634 - 00:24:23.544, Speaker A: So, the red points now sitting on these diagonals, and they're about order of n of them. So, one over n fraction of the total number of points, really small. Now, I can look at any point x, take l, one balls, and ask. Or spheres. Sorry. And ask, is there any point x that's not ruined? Well, you can think about it for a second and see that there's always one sphere for x, that one fourth of it is ruined. So there is no hope for this graph.
00:24:23.544 - 00:25:04.400, Speaker A: Even if I have such a small adversary control. Like the adversary only controls one over n fraction of the points, there's no hope to find a good starting point or a good, you know, all the points are ruined. So, this is sort of a big, like, contrast between, you know, this, this type of graphs and the hypercube. And there is something specific about the hypercube that helps us. Wait, I won't ruin the suspense. Let me continue. Okay, so, the second, sort of a naive way that one could try to find or to prove what we were trying to prove.
00:25:04.400 - 00:25:32.238, Speaker A: And a second reason why this problem is somewhat hard, is the union bound. So, one could try to approach this existence of a point that's not ruined by using the union bound. It's a very natural. It's the first thing we did, actually. And, you know, let's define by capital r, sub r, the set of points x that are ruined by some sphere of radius R. Sorry. By the sphere of radius R.
00:25:32.238 - 00:26:20.180, Speaker A: Exactly. So, this is parameterized by the radius. And it's easy to see by Markov's inequality, that this cardinality, the number of those points, cannot be bigger than epsilon over lambda two to the n. However, if we wanted to say, what happens for all radii? Then we would have to take a union bound sum over all radii of these bad sets or ruined sets, and we get something useless because the dimension n comes into play. And what I mean by that x is ruined by sphere of radius r when most of the points are red, but it could also be ruined by sphere of radius r prime. Most of the points are red. And that somehow shows that this union bound is really over counting.
00:26:20.180 - 00:27:06.174, Speaker A: So this is the problem with using the union bound. And in a particular back to the subcube example, you will see that we overcount the points a lot of the times. And by using the union bound with this approach, we just get something that's bigger than two to the n, whereas we just showed that we have so little points that are so few points that are ruined. And in fact, this always happens, it turns out. Okay, so these are the main two sort of points that I wanted to get across before I move to the actual result. And if you have any questions now, it's a good time to ask probably so you can ask this question on any graph you could. Yes.
00:27:06.174 - 00:27:31.284, Speaker A: It's not true for the green, is it? Rule for expanded. Yeah, I think we've talked about this question before, too, right? You and I, or, I don't know, possibly, I remember, I mean, I've talked to someone. I'm not entirely sure. I mean, you have to have a. Yeah, I don't know. We don't know the answer to this question. I mean, we.
00:27:31.284 - 00:27:36.670, Speaker A: I guess Leonard is, is he here? Yes. You're working on this product graphs, right?
00:27:36.862 - 00:28:00.422, Speaker C: Yeah. Well, first of all, to say one thing about expanders is I doubt it's characterized in quite that way because it's really very sensitive to plus minus a little bit in the distances. Like, you know, the sphere is really sharply defined object and expanders have a little more play in them. So I'm not quite sure that's likely to be the way these things behave. We do have a conjecture which we put in the paper that this, you'll.
00:28:00.438 - 00:28:03.142, Speaker A: Say at the end, I wasn't, that.
00:28:03.158 - 00:28:08.994, Speaker C: This would hold for cartesian products of any bounded size graph. It seems very hard.
00:28:11.174 - 00:28:27.454, Speaker A: Yeah, I mean, we don't really know. I mean, we know a lot of things about maximal inequalities in general, which I'll mention in a little bit, but not for such discrete sort of graphs, I guess. Okay, another question.
00:28:28.354 - 00:28:33.138, Speaker B: The relationship between the adversaries spoiling edges and vertices. So you said.
00:28:33.306 - 00:28:56.274, Speaker A: Yeah, this is a bit, you know it's not exact. Yeah, I just wanted to say that we asked this edge question and then we asked the vertex question and we solved the vertex question. There is an edge version which is not exactly, I mean, it's harder to argue about edges. So it's open the corresponding question for edges. The thing is, what would the corresponding question for edges.
00:28:58.054 - 00:28:59.582, Speaker B: Or if you want to come back to that.
00:28:59.638 - 00:29:48.308, Speaker A: Yeah, yeah, let's come back a little bit, because there is something, but it's not, you know, exactly what this gives you. Okay, so I just want to take what I just said and put it in analysis terms. So I'm not going to do much different in the next couple of slides, just give you the sort of math version of it. So we're looking always at l two norm. So I'm going to omit the two from the norm, but it's always l two and functions in l two. So we look at the set of functions which are real valued functions on the hypercube. Take the norm, which is the standard l two norm, and represent the sort of set b, which would be the red points for us with the indicator function one, when it's read zero otherwise, and the cardinality of b is equal to the square of this function.
00:29:48.308 - 00:30:23.948, Speaker A: This is a zero one function. So, you know, it doesn't really matter if you take squares or not. But anyway, so b is our, the adversary set. They said that the adversary made red and l two squared norm of this indicator function is equal to the cardinality of b. So now we look at, we want to look at operators, but let's first see what we get from Markov's inequality. We get that the cardinality of points that a function is greater than lambda is less than the norm of a function squared over lambda squared. Simple application of markers inequality.
00:30:23.948 - 00:31:27.104, Speaker A: And moreover, let's consider any operator. If we know that this operator has bounded norm two to two norm, then we can get a similar statement that the cardinality of x such that this operator applied on f of x is bigger than lambda, is less than this norm squared, this constant, whatever this a is norm of f squared over lambda squared. So for our application, what we care is about sphere operators. What are those? Those objects are just the average of my function over the points of some sphere. So srf of x is the sum of the function f on the points on the sphere radius r around x over a cardinality of the sphere, just the average. In order to argue about the sort of ruined set, how many vertices have some sphere that is sort of has a lot of bad points. We need to introduce the maximal operator.
00:31:27.104 - 00:31:53.272, Speaker A: What is the maximal operator? Well, apply to f. You just look at all the radii. So maximum operator of this family of operators f of x. You just take the maximum over all radii of this average on the sphere. So what you really do, I think I have a picture here. Let me first show you the picture. Assume now we only have two spheres, which is not the case.
00:31:53.272 - 00:32:31.716, Speaker A: So let's say this is x. This is one sphere around x, and the average red is where the function is one and green is where the function is zero. So the average of the value of the function on the first sphere would be 0.6. The average of the value of the function on the second sphere would be 0.64. So if you take the maximum of those two is 0.64. So the maximum operator just looks at every possible radii and takes the maximum average of the value of the function on the sphere. So now what our problem means, if we wanted to find the cardinality of the ruins set, this union of ruin sets at radius of ruined points, at radius r.
00:32:31.716 - 00:33:47.034, Speaker A: This is just the points x, such that the maximal operator f of x is bigger than lambda, because that would mean there exists a sphere, there might be many. Doesn't matter that this average of the points of the value of the function of the points of the sphere is bigger than lambda. How much lambda? Okay. And all right, so the theorem that we ended up showing is that this maximal function has bounded operator norm independent of the dimension, which means that l to norm of m s of f is less than some a, which is constant norm of f for all f bounded, et cetera, et cetera. And by this, what do we get? We get the cardinality of the ruin set by this Markov's inequality that I just mentioned a couple of slides ago is less than this quantity. And you know, by picking some lambda of the order root epsilon, we get that the ruin set is very small, in fact, which comes back to the existence versus majority question. So this is the maximum equality thing that we show.
00:33:47.034 - 00:34:49.285, Speaker A: And in fact, let me, because maximum equality is not something we came up with, clearly, it's something that existed since twenties or maybe even earlier in sort of more continuous spaces. And a lot of people have done tremendous amount of work on maximum inequalities. In fact, it starts, I think, with Hardy and littlegood, who studied a similar problem. But now it's euclidean space of n dimensions. And they studied the ball operators instead of spheres, which you take everything around the point that's at distance at most r. And they considered these averages of values of functions on balls around the point and managed to show that this maximal operator, which is defined exactly the same, just take the supremum of all the balls around the point of the average of the function, is in fact bounded. But now their bound was depending on the dimension.
00:34:49.285 - 00:35:33.962, Speaker A: And notice that this is ok, because now we're looking at infinite things like a lot of balls, a lot of points. It's nothing to do with the hype. I mean, a bound on the dimension would be trivial for our case, it's just the union bound that we got before. So most of the flavor of maximal inequalities and euclidean spaces or other spaces had something to do with a dimension. Often there were some discrete results, but not which I'll talk about in a bit. So anyway, this is sort of the regime where maximum inequalities were mostly studied in analysis. And notice that we can't use this if we wanted to use some black box sort of knowledge.
00:35:33.962 - 00:36:23.744, Speaker A: It's a wrong metric space, we have balls, and there's no dimension independent. And again, as, let me stress this out again, it would be enough if we had the result for spherical means in l one. But this is what we can get as the example of the z two, this grid with the diagonals showed. So this is also something we can use, and something is special about the hypercube. To be honest, I'm not entirely sure what that is, it has to do with the spectrum. But yeah, I can really say, and these are a lot of people that worked on maximum inequalities and contributed to that. Okay, since I have a lot of time, let me say a little bit about the proof.
00:36:23.744 - 00:37:21.234, Speaker A: So the way we managed to show this, and again, let me pull this slide up, in case you forgot how inequalities are dimension independent. Say that again, sir, I didn't hear. Maximum inequalities do not depend on the dimension, the hypercube ones, yes, because I mean, if they did, then we would have done not much. But yeah, ours is just constant bound on the operator. Okay, so this is what I'm sketching how we show with a, some constant dimension independent. So our proof has two main steps. And at each step we had the set of operators, we took the maximal function, you know, with respect to this set of operators, and we compared it to another maximal function on a different set of operators that was more tractable.
00:37:21.234 - 00:38:08.478, Speaker A: So this is sort of both of the steps. Compare something to something and this something to something else, which we know bounds about. So the step one, remember, we had this s sub k, which were the average of the sphere of radius k of the value of the function on the sphere. And we defined these objects called senate operators. So senet of this family of operators, r is just the uniform average of all the operators in my family from zero to r. What does that mean? Seneth of the sphere operators of radius five would be one over six of all the sums of the sphere operators from radius zero to five. And why do we call the senate? Well, it's.
00:38:08.478 - 00:38:30.386, Speaker A: I think Leonard came up with this. I'm not entirely sure. It's because of the US Senate thing, like how the US Senate gets voted. Equal contribution from everyone. What's that? Yeah. Regardless of the population. So yeah, we could have called this something else.
00:38:30.386 - 00:38:58.110, Speaker A: But I like this. Yeah, it's very politics. A lot of politics in this talk. Okay, yes, well, we're trying to bomb juntas with senates, right? So we try to prove that democracy is better in some sense. That's what we do, because s are just the one sphere. So anyway, we define these senate operators, which are uniform averages over our family of operators. And we can take maximal functions of this operator.
00:38:58.110 - 00:39:44.374, Speaker A: So any set of operators, which is just, again, look at already ir and take the maximum of the senate of r of f of x. So in the first part, we use a method developed originally by Stein to bound this operator for the sphere maximal inequality with some constant times the operator for the zenith of spheres, plus some error term. And most of the work here is to bound this error term. I'll tell more, say more about that. Yeah, I think it was Terry Tao's advisor. Yeah, it's really hard to read his papers. That's the moral of the story from this.
00:39:44.374 - 00:40:46.554, Speaker A: It's incredibly hard to read his papers. Okay, so, yeah, this was like about a two line proof that took us maybe two months to figure out what he was trying to say. Okay, so the second step, remember now we have, we need to bound this term. Now, the second step introduces something that you saw at the bootcamp about these talks on the hypercube that Christoph gave. And it's just these noise operators parameterized by t, where basically you run n independent Poisson clocked processes and with parameter one from time zero to t, and you flip hbit if you have odd events in the you flip bit. I if you had odd events in the I th Poisson process. So this is sort of like a Poisson clocked random walk on the hypercube.
00:40:46.554 - 00:42:00.274, Speaker A: You should know everything about that by now, I guess by these lectures. So at the second step, what we do is we manage to bound the maximal operator for senates with the maximum operator for senates, for senates of spheres, with a maximum operator for senates of this n, which we call it noise operator. And after that our life is easy now, because these things were known and we know that the operator, this type of noise operators, or any semi group in fact is bounded by, in fact every p norm is bounded. But for two norm we get two root two. Okay, so what's the capital n you integrate over t? Yes, I think I have it explicitly later, but yes. Okay, so big picture, you want to bound the maximum period of spheres, you bound this maximum operator of synods plus some error term that turns out to be some constant times f. And you bound that by senes of noise operators plus f, meaning in total, you get a bound constant times f.
00:42:00.274 - 00:43:10.066, Speaker A: Okay, so let me talk a little bit more about each step in particular. So the first step we are required, like most of the work, becomes when it comes to bounding this error term, which uses some cosis words. The main step is cosis words, pretty much, but anyway, some cosis words that Olsenstein had used in his proof and some interesting thing that we didn't know before, some spectral bounds on the family of the sphere operators. And as an intuition, which does not entirely sort of apply directly, I mean we would like it to apply directly, but that's why this whole process works, is that the sphere operator of radius k somehow resembles the noise operator of k over n, because we have this nt to be the average of Sks for this range of parameters. And direct comparison is very difficult. That's why we go through this indirect way. But it turns out that we were able to show that the spectra of these two operators are somewhat similar.
00:43:10.066 - 00:43:59.424, Speaker A: And here is what it means. If you look at nt, the eigenvectors are characters with eigenvalue one over two t x for a character of a size x. And Sk is known to have eigenvalues called crouching polynomials, and these crosshug polynomials. Again, for character y of length x, we denoted Karl Chuff K of x. So what we sort of managed to show is that the behavior of these eigenvalues was similar to one minus two k over n x, which would give what we want. In fact, that's our main limit in this step, one of the proof that karao polynomials are bounded by this. What's that? Not that I know of.
00:43:59.424 - 00:44:44.184, Speaker A: I mean, we worked hard for those. I don't know. If it's already known, then I don't know. I should have known that. But yeah, anyway, so that's sort of the, sort of the step one was it came down to discuss, and this bounds on the eigenvalues of the sphere operators. And step two is sort of a more direct point wise comparison of the senate, the sphere operators with the senate of these noise operators. So let me mention a little bit why these noise operators are easy to handle, and it's because ergodic maximal inequalities already existed and were well known.
00:44:44.184 - 00:45:46.764, Speaker A: That means if you have a double stochastic matrix t, and you consider the semi group t to the r, any semi group you can prove bounded by constant maximal inequality for the Senate of semi groups, and you sort of nt, as Christophe mentioned this previous week, forms a semi group. We use known machinery, we can get that the norm of the senate of n is bounded. The intuition behind this, the second step is that while you know a priori, if you look at it, nt is indeed very different from a single sphere operator. It's just an average over spheres, almost. However, the sentence of the two things are not that different. So if you look at the coefficients of how many times sk appears in one and the other, they're sort of the same. Within constant, they're sort of the same.
00:45:46.764 - 00:46:25.944, Speaker A: And you know, I'm browsing a lot of things here, because there's some technical things you need to do, but eventually, by stochastic domination of this set by the other, we're able to show the norm comparison. Okay, I think that's it. And I still, I'm looking still for applications of this in computer science or somewhere. So if someone knows about any application, combinatorics is okay, combinatorics is okay, medicine is okay, biology is okay. I don't know. Yeah, then I still want to see what happens. Meaning games on the hypercube.
00:46:25.944 - 00:46:38.124, Speaker A: I'm still working on that. And yeah, I guess I would mention the other graphs where maximum inequality holds these product graphs, etcetera, etcetera. Okay.
00:46:47.664 - 00:47:03.860, Speaker B: One other thing to mention, which I guess we had before, but you proved, you know, a key maximum inequality, this l two to l two. Of course, in the classical theory, there's a whole restore of. Otherwise, in particular, assuming, say, just an l one bound, can you get a weak one?
00:47:03.892 - 00:47:06.356, Speaker A: One, yes, which we don't know, that.
00:47:06.380 - 00:47:50.924, Speaker B: Would be maybe the most natural missing piece. But I guess the other thing is, as you emphasize in this low dimensional example, l one doesn't work, but in low dimensions it does work if the spheres have curvature, as if you work in LP for p distance from. So somehow, philosophically one can say that what you show is that in, you know, in the hypercube, even the l one spheres have curvature. And there is actually a theory of curvature in discrete spaces. I didn't know, you know, related to mixing of Markov chains and so on, has been. And, you know, it would be interesting to say there's.
00:47:51.224 - 00:47:55.714, Speaker A: Yeah, I mean, I've never heard about that, but you should let me know what.
00:47:55.834 - 00:48:10.514, Speaker B: Yeah, you totally see, right? So curvature one over n, right? That's right. So this curvature is known to be the key in finite dimensional spaces. So maybe there is a relation between these kind of two extensions.
00:48:10.554 - 00:48:14.534, Speaker A: This is nice. Yeah, this is really nice.
00:48:16.794 - 00:48:24.510, Speaker C: Maybe I can give an answer if not a question, just another little thing. Well, first of all, in regards to the last comment, so there's. Ben Krauss was his name, so.
00:48:24.622 - 00:48:25.110, Speaker A: Oh yeah, yeah.
00:48:25.142 - 00:48:30.354, Speaker C: So I believe there's an LP version now, but not for one, not a week, l one.
00:48:30.774 - 00:48:32.630, Speaker A: But there seems to be an LP.
00:48:32.742 - 00:49:07.506, Speaker C: For p strictly greater than one version of our theorem recently, Ben Krause, I think, and I just wanted to answer response to the edge questions before. So actually, if you want to know that every sphere around a point, where by sphere you mean all the edges at a certain distance from a point, then you can easily get it from this. So if that was what you meant by the edge question. So basically you take, you had epsilon band edges duplicate their weight at each of their neighboring vertices, so you've doubled epsilon and now you get it from the vertex vertical.
00:49:07.530 - 00:49:10.658, Speaker A: I think he meant if you have a function on the edges, if you.
00:49:10.666 - 00:49:14.386, Speaker C: Want a function on the edge versions with a line graph, I think. Okay, that's another.
00:49:14.450 - 00:49:15.410, Speaker A: I don't know what.
00:49:15.602 - 00:49:20.122, Speaker B: Because I was trying to understand the implication from your results.
00:49:20.258 - 00:49:34.970, Speaker A: Well, right now there is no implication because this algorithm fails for other reasons. So there is no hope. I mean, there is hope, but not with this approach. Yeah, so, yeah, there's no, the purpose.
00:49:35.002 - 00:49:37.734, Speaker B: Of reality is to inspire good theories. So you in this case.
00:49:37.814 - 00:49:39.834, Speaker A: Yeah, exactly.
00:49:42.254 - 00:49:44.334, Speaker B: Questions? Okay, so let's.

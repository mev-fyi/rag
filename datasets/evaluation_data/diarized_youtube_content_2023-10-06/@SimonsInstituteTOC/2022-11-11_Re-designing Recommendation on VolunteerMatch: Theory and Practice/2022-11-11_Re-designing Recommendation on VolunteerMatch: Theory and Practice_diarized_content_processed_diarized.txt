00:00:00.080 - 00:00:21.874, Speaker A: Saved the best for last. So it's my pleasure to introduce Vahida Manchadi. She's an associate professor of operations research at Yale, and she's an expert on matching markets, platform design, and she's looked at a variety of different kinds of applications in her work. And today she'll tell us about volunteer match.
00:00:22.814 - 00:00:58.696, Speaker B: Thank you, Shujeep. Good afternoon, everyone. Thank you for sticking around for the very last talk of the really appreciate it. Today I'm going to share with you joint work with three great Scott Rodelic, Daniela Saban and Akshaya Serge. But before telling you about our work, I want to start by making a broader point. Many of us participating in this program work on online platforms, and that usually means commercial platforms, think Uber, Airbnb, opwork and so on. And that's great.
00:00:58.696 - 00:01:44.684, Speaker B: These platforms have given us a lot of good problems to study, but I want to highlight that similarly, in the world of nonprofits, we have a lot of good platforms as well. Here I'm just showing a few of my favorites. We have many, many more. And I want to say that I think this is a good opportunity for us too. By studying these types of platforms, we can find interesting kind of abstract research problems related to data driven decision processes. The theme of this entire program, and not only that, if we take our research idea to practice, we may be able to make a positive social impact. This is the theme of this workshop, of course.
00:01:44.684 - 00:01:55.760, Speaker B: Now, my plan in today's talk is to tell you about our work in collaboration with one of these organizations, which is volunteer match, to hopefully illustrate both.
00:01:55.792 - 00:01:56.844, Speaker C: Of these two points.
00:01:58.184 - 00:02:54.134, Speaker B: With that, let me tell you a little bit of background about volunteer match, and then I'll jump right into our research question. It match is an online matching platform, very much like upwork. But instead of helping you find a temp job, it's going to help you find a volunteering opportunity. It's the largest of such platforms that we have in the nation, with about 1.3 million monthly visitors, and it puts over 100,000 opportunities on a variety of causes, ranging from hunger to education to human rights and so on. The great platforms does a great service to society. But the challenge is that currently lots of opportunities on this platform do not receive as many volunteer sign ups as they would like to.
00:02:54.134 - 00:03:35.704, Speaker B: To illustrate this point, let me show you one sample of sign up distributions. So this is a distribution of sign ups for 100 randomly selected opportunities that all asked for five sign ups. Okay, now, if you look at the left side, we see that there are lots of opportunities that do not receive five signups. So of course that's not great. But if you look at the left, the right side, you see that we do have opportunities that receive many more than they ask for. Okay, so they ask for five, they get 30, they get 40. And this is not great either.
00:03:35.704 - 00:04:31.403, Speaker B: Why? This is just congestion in kind of market design language, right? Usually volunteering requires some kind of screening process. By sending so many volunteers, interested volunteers, to these organizations, we are going to overburden them. And that's when at some point they're going to stop responding to these volunteers. In turn, those volunteers are going to be disappointed that they may get disengaged from the platform altogether. So, so far we see that this kind of skewed sign of distribution is bad for these opportunities, bad for these opportunities and bad for volunteers. And of course it's bad for volunteer match because YMCA match doesn't make as many connections as it could have potentially made. Okay, so based on this, our research agenda is going to revolve around the following question.
00:04:31.403 - 00:05:27.194, Speaker B: How should we design VM's platform to maximize the number of useful synapse? That's kind of our high level research question. To answer this question, first we try to understand the sources of inefficiencies. What leads to this kind of skewed distributions? And one factor that we found which is within the control of the platform is the effect of the recommendation algorithm or the ranking algorithm that the platform uses. Roughly speaking, the platform uses a ranking algorithm that is kind of recency based. So it shows opportunities that have been updated or newer on top of the list. Naturally they get more attention and they get more sign up. And in some sense, VM ignores the kind of current number of signups that a particular opportunity has.
00:05:27.194 - 00:06:20.774, Speaker B: Now, it turns out there are some organizations out there that update their opportunities very frequently. As a result of this, they end up on the top of the list quite often and they get so many excess. So based on this observation, we thought that, okay, all we need to do is add some kind of a feedback loop to take into account the current number of synapses. And if you do that, maybe we are able to shift some of these excess synapse to the left side of this distribution. Right, that seems reasonable, but when we dug a little bit deeper to this data, we saw a slightly different picture. So this is what we saw in distribution. I'm just color coding sign ups based on their sources.
00:06:20.774 - 00:07:08.754, Speaker B: It turns out that on VM there are two sources of signups, internal and external. Let me first, tell you what's an external signup? These are signups that are generated by users that have direct link to a particular opportunity. Okay, so somehow I have a link to a particular opportunity page, I just go directly to that page. So I will never interact with the recommendation algorithm. So in some sense, these are sign ups from users that cannot be influenced. But we also have this internal traffic, these are the default users, right? So the ones that go on volunteer match and organically look for an opportunity. So they interact with this without recognition.
00:07:08.754 - 00:07:56.142, Speaker B: So again, based on this, digging deeper into the data, we observe this prevalence of external traffic. Let me tell you where external traffic comes from. It comes from kind of off platform outreach activities. So it turns out organizations use volunteer match for multiple purposes. One of them is of course to attract volunteers, but they also use VM for showcasing their products, managing relationship with volunteers and so on. And because of these other purposes, even when they attract traffic externally, internally, they still give the link to the dedicated page on volatile management. So let me show you one quick example.
00:07:56.142 - 00:08:47.020, Speaker B: Here's an organization that publicizes its opportunity on LinkedIn, but they still give the link to this page on volatile management. So on MLan, if I click on this, I'm never going to interact with your recommendation algorithm. No matter how good of an algorithm you design, you're not going to influence my decision, right? Surprisingly, about 30% of track click on volunteer match is actually external, a substantial amount. And as you just saw in the previous histogram, the previous slide, the amount of external traffic varies quite a bit across different opportunities. So it's not uniformly distributed. And also it's of course uncertain and unknown question Vahida. Yes.
00:08:47.212 - 00:08:54.904, Speaker D: So when you say it's unknown, at what stage do they know it? Like is there at any stage before the volunteer activity itself?
00:08:55.324 - 00:09:20.084, Speaker B: No, not necessarily. Right. So it can arrive anytime before the event. And also lots of these opportunities are not that time sensitive in the sense that they're ongoing for a long time. But good question. So feel free to ask any question. Also, following Irene's great initiative, any question.
00:09:21.944 - 00:09:37.164, Speaker D: Let me just follow up to clarify on that. So this link, when they click in, this is still hosted by volunteer match, but they were not linking within volunteer match like signups to recommendation.
00:09:37.474 - 00:09:46.986, Speaker B: It's just like I go here and I sign up for this or not, but I'm not going to ask you that. Hey, can you show me a list of possibilities among which I'm going to make a selection?
00:09:47.050 - 00:09:47.250, Speaker C: Right.
00:09:47.282 - 00:09:57.466, Speaker B: So I've decided I want to do this one potentially. Right. Great question. All right, good. So based on this observation, we are going to.
00:09:57.570 - 00:10:10.410, Speaker E: Yes, see, they see the recommend. If they see the ranking, they just decide to not. So you're saying they see the ranking, but they just decide to go to the website directly?
00:10:10.602 - 00:10:24.934, Speaker B: No, the thing is that I am on LinkedIn for whatever reason. I see this, I click on this, go directly to this national first responders Fund page, and I never go to the main page of volunteer match. Right.
00:10:25.914 - 00:10:27.054, Speaker C: But good question.
00:10:28.754 - 00:10:30.054, Speaker B: Yes, Danielle.
00:10:32.244 - 00:10:48.940, Speaker F: It'S a bit outside of the controls that you're considering in your talk, but wouldn't an option be to, if somebody goes directly to the opportunity and the opportunity is already full, basically push them to other opportunities that are similar that you might be interested in.
00:10:49.012 - 00:10:49.308, Speaker B: Awesome.
00:10:49.356 - 00:10:51.144, Speaker F: Is that happening? And if yes.
00:10:54.524 - 00:11:08.984, Speaker B: For certain opportunities, they come from an organization that also has a bunch of other opportunities and usually on the kind of bottom of the page, they show those other things. Okay, but that's a great question. I'm not considering that in my model.
00:11:10.444 - 00:11:10.916, Speaker C: Cool.
00:11:10.980 - 00:11:51.524, Speaker B: So, okay, let me just quickly refine my research question. Based on our observation, our refined research question is now how to make match recommendation that are useful to increase the number of useful sign ups in the presence of such external track. Now, before telling you what they did with this question, let me tell you that external traffic is not limited to volunteer matching. Lots of online matching platforms play dual roles. They facilitate connection, but they also facilitate transactions. And because of this second role, they attract external traffic from many different channels. Let me show you two quick examples.
00:11:51.524 - 00:12:44.694, Speaker B: One from the world of retail. On Etsy, artists sell their products, their handmade products, but they usually advertise those products in social media, say on Instagram. As you can see even within Instagram, that they advertise it. They give the link to the page on Etsy for their product. Back to the world of nonprofits donors choose is a great crowdfunding platform that helps high school teachers solicit donations for high school projects. And again, these teachers not only rely on donors choose to attract donations, they also advertise on other websites. Let's say, bottom line, this kind of multichannel traffic appears in a variety of applications, which motivates our research.
00:12:44.694 - 00:13:26.924, Speaker B: And for this question, let me quickly summarize our contributions. We make two types of contributions. One is theoretical, one is applied. On the theoretical side, we introduce a generalization of online matching, which is online matching with multi channel traffic. And for this problem, we design a new algorithm that effectively takes advantage of the external nature of this traffic. And by doing that, it does better than the existing algorithms. In the paper, we show that this, our algorithm, not only has a good kind of theoretical guarantees, but when we apply it on, in a case of study, to VM data, it does, it does pretty well in practice, too.
00:13:26.924 - 00:13:29.360, Speaker B: Yes.
00:13:29.472 - 00:13:36.004, Speaker E: So they think of the external traffic as predictable, or is it very much non stationary?
00:13:36.464 - 00:14:16.372, Speaker B: No, it can be arbitrary, as I will specify in the models. Yes, there is a question in the back. I can also repeat the question. So do you consider like preferences of users for certain places or like rank organizations based on like their impact or something? Right. So that those are going to be reflected in their kind of click probabilities, right. So if I show you different things that you have different preferences for, you're going to click on them with different probabilities. So that's on the theoretical side, our theory paper.
00:14:16.372 - 00:15:07.850, Speaker B: On the applied side, we proposed a new recommendation algorithm to volunteer match, which is inspired by our theory. After, of course, taking into account certain practical considerations and limitations, we worked with volunteer match to implement smart sort, that's the name of our algorithm, their platform, and they already conducted a field experiment in Dallas. So, and I'm going to show you the results, which is the first time that is being presented by them. Okay, so what I'm going to do is I'm going to start with this theoretical paper. Toward the end, I show you the results of our pilot. Before I start any, any other question. Great.
00:15:07.850 - 00:15:40.622, Speaker B: So let me introduce the model just like a very, again, simple generalization of online matching. So I have this bipartite graph. One side is offline, which for me would be these opportunities. Each opportunity has a capacity which reflects the number of volunteers it needs. Now on the online site, volunteers are going to arrive one by one. Of course, the innovation of our work is that volunteers can be two different types. Either they are external, in which they have a dedicated opportunity.
00:15:40.622 - 00:16:21.894, Speaker B: We are not going to make any decision for them. So think of them as a degree one node in your online bipartite matching problem, but the degree one node that you have to assign so you cannot drop. So again, no decision to be made here. Life is easy, but for internal traffic, once they arrive, we observe their compatibility patterns. And out of all the compatible opportunities, we're going to recommend one on the fly. Okay, we recommend this one. And of course, our goal is to design algorithms that maximize the size of this matching without making any assumption about the traffic pattern.
00:16:28.214 - 00:16:38.754, Speaker E: So as the volunteer match, why should I care about the matching of the external traffic in my objective? You count like the number of external traffic.
00:16:39.694 - 00:16:53.560, Speaker B: We just want to help all of these organizations, right? You cannot count them. It's fine. It doesn't change. As long as they all match. You don't, it doesn't matter which, which version you look at, just to keep things simple. We keep all of them, but doesn't.
00:16:53.592 - 00:16:56.272, Speaker C: Matter if you don't, as long as.
00:16:56.288 - 00:16:56.968, Speaker B: You don't drop them.
00:16:57.016 - 00:17:00.164, Speaker C: Okay? Yes.
00:17:03.984 - 00:17:09.640, Speaker E: Is there a distinction between volunteers or is there any. It doesn't matter whether, which volunteer will.
00:17:09.752 - 00:17:41.263, Speaker B: Excellent, excellent. So the compatibility structure is volunteer specific, right. So each volunteer has its own edges. And actually that's a good. Let me follow up on that by saying that I am presenting this in the simplest possible form, so I have zero one compatibility, and I'm making a single opportunity recommendation in the paper. And as I show you a little bit later, we do look at generalizations in which you have probabilistic compatibilities like conversion probabilities. And also I can offer you a subset, not just one.
00:17:41.263 - 00:18:39.644, Speaker B: But for now, let's keep things simple. I have these two types of volunteers, external ones, I don't need to do anything. Internal ones, I'm going to make one match recommendation among the compatible ones with the goal of maximizing the size of my match. Now, say I design an algorithm. How would I know if it's good? Of course, we're going to take the standard approach of competitive analysis. Now, most of you know how this works, but let me just spend a moment explain what a competitive ratio analysis is. So what we do here is that you give me an algorithm for that algorithm, I'm going to compare its performance of this online algorithm that doesn't know anything about future arrivals with that of a clairvoyant solution that sees the entire sequence before making any decision.
00:18:39.644 - 00:19:25.834, Speaker B: So I compute this ratio, I take the worst case over all problem instances to get the competitive ratio of a particular algorithm. All right, good. Now for a second, if I ignore external traffic altogether, again, those of you working in this area, you know that this is a very well studied problem. We know pretty much all we want to know about this problem thanks to a very nice paper about 15 years ago by Mehtos, Auberi and Vasirani. It's a really nice paper. And I'm not just saying this because one of the authors was my advisor, but it was actually pretty nice and it was an influential paper. It did influence practice.
00:19:25.834 - 00:19:44.654, Speaker B: Okay, what does this paper show? It shows that the best competitive ratio you can get is one minus one over e, and not only that when capacities are largely, they gave an algorithm that gives us a matching lower, basically achieves one minus one.
00:19:47.514 - 00:19:47.946, Speaker C: Good.
00:19:48.010 - 00:20:22.424, Speaker B: So again, this is for the case that I have no external traffic. Let me look at the other extreme in which all my traffic is external, just to make sure who is a vacant, who is not. What competitive ratio would I get if all my. Okay, good, good. So, awesome. So I'm going to get one. And the catch here is that this external traffic, by the virtue of being inflexible, is going to limit the number of mistakes that an online algorithm can make compared to an offline model.
00:20:22.424 - 00:21:03.394, Speaker B: So it limits the power of adversaries. Now, based on this, I'm going to refine my notion of competitive ratio by parameterizing it based on a parameter beta. This parameter beta tells us what fraction of entire capacity we can fill using external traffic. Now, once you fix beta, I'm going to be looking for a worst case ratio across all instances that have this much external traffic. So my question is that how much, how helpful this external traffic is or what is the best we can get for different values of beta?
00:21:05.174 - 00:21:09.542, Speaker C: So, in order to answer this question.
00:21:09.598 - 00:21:12.030, Speaker B: I'm going to first start with a warm up case.
00:21:12.062 - 00:21:12.874, Speaker C: You have a question?
00:21:13.734 - 00:21:37.704, Speaker B: Good, good, excellent. In theory, yes. For the algorithm we have, I'll show you. So just don't spoil my algorithm. Okay, but no. Okay, I already spoiled it. Okay, so warm up case, let's look at this super unrealistic setting in which all my external traffic arrives before the internal ones.
00:21:39.004 - 00:21:40.220, Speaker C: If you think about it for a.
00:21:40.252 - 00:22:27.314, Speaker B: Second, for the first bit of fraction that are external, I'm making no mistake, my competitive ratio is one. For the rest of it, it's a typical online matching problem. Thanks to the nice paper by my advisor and his co authors, and his advisor, actually, we know that we can't do better than one minus one over e. So if you think about it just a second, it's natural that the upper bound is going to be simply the convex combination of these two extreme points. So, starts from one minus one over even, you have no external traffic, goes all the way to one when all your traffic is expanded. But if you apply MSV, just naively, it turns out that you cannot get a matching lore. So the paper we show that the MSDV cannot do better than this red curve.
00:22:27.314 - 00:23:14.964, Speaker B: But if you adjust Ms TV just a little bit to get a new algorithm that we call adaptive capacity, you can get back a matching lower path. So the idea behind our algorithm is very simple and supernatural. For this special case, I told you, in this warm up case, the first bits of fraction are external. So I'm going to let them arrive and fill capacities. And then once I'm done with that beta fraction, I'm just going to adjust my capacities, basically reduce my capacities. And I pretend that I have a new problem. Instance, run Ms, which gives us this matching lower belt.
00:23:14.964 - 00:23:39.880, Speaker B: But the catch is that of course, in a general case, external traffic arrives throughout. So I don't know how much I should reduce my capacity a priori. What am I going to do? I'm going to do it on the fly. So as I get external traffic, I'm going to reduce capacity. And that's the whole idea of the algorithm. Let me formalize this for you. Here's our algorithm.
00:23:39.880 - 00:23:59.644, Speaker B: We have two counters for each opportunity, one for external, one for internal. For external ones, we don't do anything. If we get an external traffic, we do nothing. If we get an internal one, then we are going to match this internal traffic to a compatible opportunity that maximizes this penalty function.
00:24:00.744 - 00:24:02.256, Speaker C: And the idea of this penalty function.
00:24:02.280 - 00:24:21.244, Speaker B: Is that they're going to penalize opportunities that have already got a bunch of sign ups. So it is a decreasing function in both of our counters. But the whole kind of catch is that we are going to treat these two counters differently. And in particular, we are going to subtract the counter for external traffic from our capacity.
00:24:22.904 - 00:24:23.312, Speaker C: Yes.
00:24:23.368 - 00:24:33.756, Speaker B: Question, does it mean that you have.
00:24:33.780 - 00:24:38.744, Speaker D: To recalculate your algorithm for every external one?
00:24:39.444 - 00:24:47.300, Speaker B: All I need to do is to increase this counter. Right. So whenever I get an external traffic, I just increase the counter by one.
00:24:47.332 - 00:24:47.904, Speaker C: Right.
00:24:52.544 - 00:24:54.256, Speaker D: Maybe I'll follow up on that.
00:24:54.440 - 00:24:55.244, Speaker B: Yeah.
00:24:55.704 - 00:25:03.204, Speaker D: So in the actual application, do you get this external traffic information as it's coming in, or is it kind of batched?
00:25:03.664 - 00:25:04.040, Speaker C: Yeah.
00:25:04.072 - 00:25:05.592, Speaker D: How frequently are you seeing?
00:25:05.688 - 00:25:19.024, Speaker B: Good, good. That depends very much on like this, your sophistication of the technology that you use. Currently, no, it's more on kind of a daily basis, daily level. Okay. But get into all of this in kind of more apartment.
00:25:19.924 - 00:25:20.748, Speaker C: Okay, cool.
00:25:20.836 - 00:25:50.174, Speaker B: So before showing you the performance of this algorithm, I want to make a few comments. Number one, as I already told Tutoris, in designing this algorithm, I never use beta. So my algorithm is beta agnostic, which is great because it's, it's kind of not feasible to know beta upfront in practice. Second, this is a deterministic algorithm, of course, which is usually in practice when you're dealing with practitioners, the deterministic algorithm is more desirable compared to randomized one.
00:25:50.794 - 00:25:52.026, Speaker C: And the third one I want to.
00:25:52.050 - 00:26:19.424, Speaker B: Make is that I want to draw a quick comparison with MSVV. So MSVv does something very similar to what we do. It maximizes a potential function. In case you haven't seen this algorithm before, the only difference is that it treats the two sources of traffic symmetric. Now what, what do we get for this algorithm? Or in general case.
00:26:21.524 - 00:26:30.804, Speaker E: Yes, I think you wanted to teach us the simple version, right? And you drop the vertex face, but if you drop the vertex face, you don't need to.
00:26:30.844 - 00:26:38.376, Speaker B: I don't need the, great, that's why I kept it intentionally, that once you bring the weights, then you would need that exponential.
00:26:38.400 - 00:26:44.284, Speaker E: And here's my actual, so my actual question is, if you run MSDB, how would it be different from this?
00:26:46.624 - 00:27:08.664, Speaker B: MSB penalizes external traffic larger. If you compare the two fractions for MSV is always larger than the other one, the penalty is stronger. I see the fraction, the kind of you would think that you feel more than, more of your capacity, but great question.
00:27:10.964 - 00:27:11.556, Speaker C: Cool.
00:27:11.660 - 00:27:55.024, Speaker B: So this is a summary of the couple of important theorems in the paper. We show that in this general case, no algorithm, deterministic or randomized, can do better than this solid blue line, blue curve, I should say it starts from one minus one over e. Again, it stays at one minus one over e all the way to. Then you have beta equal one over e. And then it goes off, it increases with beta all the way to one when you have a fully external tract. Okay, so that's our upper bound. The kind of more important result is the lower bound improve for adaptive capacity under the large capacity assumption.
00:27:55.024 - 00:28:13.244, Speaker B: So our lower bound is this dotted blue curve. Okay, so it's very close. And we conjecture that if you tighten just one part of the analysis, it's going to be matching. But for now, the best we can show is this dotted, yes.
00:28:14.064 - 00:28:40.174, Speaker A: So if you looked at the competitive ratio just over the internal traffic. Well, if all the external traffic comes first, then you're just doing msv on the remaining capacities and you match the one minus one over e. If the traffic is interspersed, how bad can it get? Do you have any, like, can, can you achieve any finite competitive ratio or.
00:28:41.794 - 00:28:50.018, Speaker B: So it's like I am taking out the constant from my numerator and denominator, right? So like algebraically work that out.
00:28:50.186 - 00:28:50.546, Speaker C: Okay.
00:28:50.570 - 00:28:53.322, Speaker B: But I don't know, competitive ratio, you.
00:28:53.338 - 00:28:54.874, Speaker E: Won'T be able to get bounded.
00:28:55.034 - 00:28:55.682, Speaker C: Yeah.
00:28:55.818 - 00:28:59.334, Speaker A: So you could construct some example where it goes to zero.
00:28:59.674 - 00:30:03.550, Speaker B: Right? Okay, so again, for a, for adaptive capacity, we prove this lower bound this dotted curve. And of course we have. And also we show that for MSPB, we cannot do better than this dotted curve. Bottom line, by making this simple adjustment based on the source of the traffic, we get a near optimal algorithm for any value of beta without actually needing to know the value. Let me spend just a moment, maybe 30 seconds on the proof. The proof relies on this relatively recent framework that's called the LP free framework for analysis of online algorithms developed by Rajan Odwani, who is actually UC Berkeley, and his co authors. So this is like builds on the primal dual analysis, which is the standard method.
00:30:03.550 - 00:30:52.396, Speaker B: It's just slightly more flexible, which is useful for us because we want to define different kind of dual variables or rewards for internal and external. Not getting into any details. Instead, let me quickly talk about extensions and then move on to the apply. So, as I promised in the paper, we relaxed the assumption that compatibility structures is zero, one. And also we are showing only a single recommendation. We look at stochastic reward, in which we have a conversion probability for every pair of volunteer opportunities. And also we look at situations in which we offer a subset or a ranked list of opportunities to internal traffic.
00:30:52.396 - 00:31:10.904, Speaker B: And in all of this, adaptive capacity, or its natural generalization that suits that particular model still does well. And in many cases it breaks this one minus one over e barriers. Yes.
00:31:14.314 - 00:31:24.290, Speaker E: So when you saw more than one, what is the assumption about how the volunteer is? Maybe they go to both of them or.
00:31:24.482 - 00:31:42.894, Speaker B: So we have different choice models. So we look at kind of a general choice model for this offset selection, for like assortment planning, for ranking. We have a different, we have a, we look at different models for how I would search when you show me like a vertically differentiated.
00:31:46.264 - 00:31:47.044, Speaker C: Cool.
00:31:47.584 - 00:32:54.844, Speaker B: So with that, let me quickly summarize the theory part and then show you some experimental. So in our theory paper, we were motivated by the design of online platforms that played dual roles of facilitating connection and transactions. And because of this, they attract traffic from different channels. So we showed that by taking into account the fact that they have this external traffic and designing our algorithms, tailoring an algorithm, algorithms to that, we can get near optimal performance. And the nice thing about our algorithm, which makes it practical also is that it doesn't need to know external traffic. I want to highlight that beyond kind of our modeling contribution, on a kind of more abstract level, we contribute to this stream of literature that tries to break away from fully adversarial models that can sometimes be pessimistic. How do they do that? They try to come up with more realistic and motivated, well motivated traffic models.
00:32:54.844 - 00:33:02.124, Speaker B: I think it's a great area of research and perhaps we need more papers in this area.
00:33:03.944 - 00:33:05.312, Speaker C: Good future research.
00:33:05.408 - 00:33:40.364, Speaker B: I think there is a lots to be done. On the theory side, my favorite is that what if we can design at least part of the external traffic tool and it's actually motivated by what we learn about VM. It turns out that volunteer match itself is active on social media and they sent out a bunch of daily emails promoting certain opportunities. So effectively they also generate external traffic, but external traffic that is within their control. So in some sense you can think about designing at this part of external.
00:33:40.404 - 00:33:41.104, Speaker C: Traffic.
00:33:43.164 - 00:33:58.664, Speaker B: And also you can think about looking at different objective options. Here we just looked at maximizing the size of the match. With that, I want to switch gears to talk about the applied part, but before doing that, any more questions?
00:33:59.834 - 00:34:00.614, Speaker C: Yeah.
00:34:03.834 - 00:34:09.094, Speaker E: Do you have any thoughts on the version of the problem where the external traffic or degree two nodes?
00:34:12.914 - 00:34:21.058, Speaker B: That's a good question. External traffic is degree two, not meaning that I will, how would I choose between the two?
00:34:21.146 - 00:34:25.574, Speaker E: It's in your hand, it's in your control. So you can do, you can do whatever you want.
00:34:26.654 - 00:34:27.254, Speaker C: Great.
00:34:27.374 - 00:34:51.796, Speaker B: So because one way of looking a little bit better, right. So your bounds are all going to kind of be dominating the ones that we have. Right. I think there is a paper that looks at the situation in which that one is, I think assumes all the traffic is all the way or up to d. Right. It doesn't necessarily would need to be. Yeah.
00:34:51.796 - 00:35:05.084, Speaker B: I don't have any kind of like expression or analytical results to show you, but intuitively you would do slightly better than what we do. I think you want to kind of do this idea of decreasing capacity. Yeah.
00:35:05.204 - 00:35:10.700, Speaker E: I was curious, like what's the trade off, I mean, or what's the right dependency on beta and d at the same time.
00:35:10.812 - 00:35:15.064, Speaker B: Yeah, yeah, that's a very good question. I think that's an excellent research question.
00:35:16.484 - 00:35:48.540, Speaker G: I guess a related question is there's also like a, I think from the same paper by like BJN zero seven. Like there's results on like if, you know, for, if you're guaranteed for each offline vertex, a certain fraction that's going to be matched by the end, you can get certain guarantees. So it's a bit similar in that, like you're, instead of external traffic, you're just told at the beginning, like the fractions that you're able to match by the end for the offline, like is your model, like does the having the external traffic and said is it like harder or easier than that model? Is your competitive ratio better or worse?
00:35:48.612 - 00:36:03.964, Speaker B: Good, good. I think that it's not super compatible because that's going to be a very loose bound. Like, you get some lower bound based on external traffic, but that can be very off. Right, compared to papers.
00:36:05.704 - 00:36:17.992, Speaker G: Okay, okay. But the external traffic essentially guarantees you that you're going to match to like the. I see. But the external traffic, you don't know which offline vertex is going to be for.
00:36:18.128 - 00:36:34.154, Speaker B: Awesome, awesome, great. So another important point here is that beta only gives me a fraction over all things. And in fact, if I know a priori just how much external traffic each bean gets, I am back to my warm up case. You can get a straight line.
00:36:34.314 - 00:36:35.414, Speaker G: Okay, thank you.
00:36:38.274 - 00:36:38.938, Speaker C: Cool.
00:36:39.066 - 00:36:42.490, Speaker B: So one more question. Yes, yes, yes. Go ahead.
00:36:42.602 - 00:36:48.564, Speaker D: So what are some fair allocation objectives that would be interesting for this model?
00:36:49.584 - 00:36:54.432, Speaker B: You can think of Max mean, for example, you can think of like, max.
00:36:54.488 - 00:36:57.800, Speaker D: Mean over groups, or like even like.
00:36:57.832 - 00:37:06.856, Speaker B: You can think of individual max mean. If I have like, I don't know, a bunch of opportunities, I want to maximize the minimum fill rate of different opportunities.
00:37:06.920 - 00:37:07.144, Speaker C: Right.
00:37:07.184 - 00:38:09.034, Speaker B: So that could work, but you can also try to group them somehow. Oh, real words. So I want to start by highlighting that volunteer match currently is a very imbalanced market in the sense that we have many more opportunities than volunteers. And because of this, lots of opportunities don't get any attention for long periods of time and that's not desirable. So after discussions, lots of discussions with volunteer match managers, we decided to focus on the goal of redistributing the limited number of weekly sign ups that we get to as many opportunities as we can by trying to prioritize those that are currently not getting enough attention toward achieving that goal. We propose the smart sort, which is this real simple algorithm. So this is how it works.
00:38:09.034 - 00:39:05.584, Speaker B: For every opportunity, I'm going to have a counter which keeps track of the number of signups during the last week. And going back to Irene's earlier question, we can only update this on a daily basis so we don't have real time updates. Now, each time a new volunteer shows up, we are going to display to her a list, an ordered list that is ordered based on a new scoring function. This sigma I comma t. This new scoring function is a combination of our old scoring function and a penalty function. So our old scoring function, roughly speaking, is kind of tries to capture preferences for closeness and recency. An opportunity is going to have a higher score if it is closer to this particular volunteer or if it has been updated more recently.
00:39:05.584 - 00:39:49.648, Speaker B: And this penalty function is of course plays the same role as it did in our theory work. It's going to penalize or deprioritize opportunities that received some signs. Let me show you quick tour example that we use to convince volunteer match managers and go over the mechanics of this before telling you very briefly about our pilot study. Here's a two example. Let's say I live in a ward with only two volunteers from the same location. And both of these two volunteers are only going to pay attention to the top listed opportunity.
00:39:49.736 - 00:39:50.484, Speaker C: Okay?
00:39:51.424 - 00:40:26.958, Speaker B: Now say I also have two opportunities and based on the old scoring function, these scores are such that opportunity number one is ranked first. So this first volunteer is going to assign is going to sign up for that. Nothing changes in my scores. So the second volunteer is going to sign up for that too. This is going to lead to this kind of skewed distribution which is kind of the toy version of the real deal I showed you at the beginning of. So this is under the old scoring function, what happens under hours? So for the first volunteer, nothing. Same thing is going to happen.
00:40:26.958 - 00:41:00.782, Speaker B: But now for the second volunteer, because this opportunity already received, the sign up is going to be penalized. I cooked up these numbers such that it now has a smaller score. So this other opportunity is going to be shown first. This would lead to this kind of more uniform sign of distribution. Really simple example and I want to repeat the point that many previous speakers made. If you want to communicate with practitioners, this is the level of simplicity at that unit. Okay.
00:41:00.782 - 00:41:08.964, Speaker B: So we literally show the examples of this level to convince them that this idea of adding this feedback loop can be very helpful.
00:41:09.094 - 00:41:09.884, Speaker C: Okay.
00:41:11.344 - 00:41:58.180, Speaker B: After convincing them and working with them for months, we did implement a smart sort and volunteer match and we ran a pilot study in Dallas over south. Our experiment was ten weeks long. So the post treatment is going to be ten weeks after May 24 and we're going to take the pre treatment with a ten weeks preparation prior to that. Okay, let me give you some basic statistics just to get a sense of the scope of our experiments. In this pre treatment period, we had about 20,000 visitors, which is roughly about 0.6% of users. Okay, so 0.6%
00:41:58.180 - 00:42:01.374, Speaker B: of users were exposed to our treatment.
00:42:03.274 - 00:42:04.014, Speaker C: And.
00:42:06.314 - 00:42:28.894, Speaker B: These users, again, this is pretreatment period. These visitors generated about 2100 sign ups and we had about 1100 active or newly created opportunities. And hopefully these last two points show you how imbalanced this market is. So many opportunities did not get any signups during this time.
00:42:31.914 - 00:42:32.418, Speaker C: Good.
00:42:32.506 - 00:43:15.544, Speaker B: Let me show you what our treatment is. Now, we expect the effect of our treatment to be heterogeneous, right. Our goal is redistribution, so we know we're going to treat different opportunities differently, in particular those that do well. We expect them to kind of have a fewer synapse. Right. They expect to have a negative treatment effect because we are deprioritizing them in the hope that they're going to help a bunch of other volunteers that were not doing well before our treatment because of this heterogeneity in treatment effect. What they're going to do is that we're going to first partition our opportunities into different groups.
00:43:15.544 - 00:44:10.304, Speaker B: After doing that, we're going to basically conduct empirical analysis for each group separately. What do we do first, we're going to order our opportunities based on the average number of wiki sign ups they got pretreatment. This is basically their performance pretreatment. We partitioned them into bins of size 20. They're going to take the data from previous year, 2021, same region, same time period as our control, and we're going to construct synthetic controls by matching on pretreatment trends because there's a lot of seasonality. So actually we rely on a nice recent AER paper by Arkan Gelsky at all. Long story short, after doing this analysis for each bean separately, this is what we get.
00:44:10.304 - 00:45:26.874, Speaker B: So this is the average treatment effect, or the average difference in the number of weekly sign ups for this array of different beats. What do we see on the left side for the opportunities that they're kind of high performing before our treatment, before applying our algorithm, we see that post treatment we have negative effect, they got fewer synapse. But on the other side, for those that were not doing well pretreatment, now we help them to get a few more. So this is kind of one sample of the preliminary evidence we have for the redistributive effect of our policy, our algorithm. This is, again very much still work in progress, but looks quite promising. Just last week, we launched a second experiment, a much larger one in Southern California, to fully understand the effect of our policy and also fine tunes the parameters in our algorithm. But the hope is that sometime during next year, this is going to be rolled out universally.
00:45:26.874 - 00:45:35.014, Speaker B: So stay tuned for more updates on that. But on that note, thank you all. Happy to answer any further question.
00:45:41.434 - 00:45:42.174, Speaker C: So.
00:45:47.914 - 00:46:08.940, Speaker F: I understand that you see this effect with respect to redistribution, which on some level should be expected, right? Because, like, you show those things more, but do you actually see see overall that more opportunities are filled or like in some sense that is not the objective function, right.
00:46:09.132 - 00:46:34.872, Speaker B: Good, good, good. Yes. We are not, that's a great question. In terms of total number of signups, we are not impacting it much. We have that analysis. I didn't put it on the slides, but we are not impacting the total number of sign ups by doing this. Clearly, if you keep showing a lot of really, I don't know, unpopular or bad opportunities, then maybe the total number of sign up also goes down.
00:46:34.872 - 00:46:42.524, Speaker B: That's why we want to be careful in terms of like how we are doing this prioritization. That's a great question.
00:46:52.964 - 00:47:20.774, Speaker D: This kind of a follow up question to Daniel's question. Like is the organization that you're working with, do they have like what is their objective in using this redistribution? Is there, do they have a particular organizational level goal that makes it, that benefits them to redistribute opportunities to more organizations? Is there a way to measure that goal, like downstream?
00:47:20.894 - 00:47:26.582, Speaker B: Good, good. So great question. So just to make sure I understand the question, your question is what is.
00:47:26.598 - 00:47:32.030, Speaker D: The objective of volunteer match in respect to redistribution?
00:47:32.102 - 00:48:01.038, Speaker B: Good, good. So they want to help as many opportunities as possible and they want to keep them engaged. Right? So if I don't, if I am an organization and I don't get anything out of volunteer match for six months or something, I'm going to leave. So that's why they like to keep their, their update. They like to kind of help all of their opportunities kind of on a regular basis. They don't want to leave someone out for a very long period of time. Okay, so that is the benefit of redistribution on a kind of weekly level.
00:48:01.038 - 00:48:27.742, Speaker B: Right. So we are not doing it for a very long time horizon. To answer the second part of the question, one of the measures we look at is a measure of excess, which is the fraction of total synopsis that go to opportunities who get at least one. Right. So think about the distribution. Take out one kind of a baseline for every opportunity for every organization and then just compute the fraction of the rest. We call it excess.
00:48:27.742 - 00:48:36.274, Speaker B: We actually show through regression analysis that we do decrease excess, meaning that we make the distribution more uniform.
00:48:45.834 - 00:49:00.454, Speaker D: For these opportunities. Do they have capacity constraints or demands? For example, I can imagine some of them only want one person and some of them want ten people. Does that happen in this example? And if so, how do you account for that?
00:49:01.274 - 00:49:09.364, Speaker B: So does it happen in, by the example you mean that I am incorporating it in my design?
00:49:10.184 - 00:49:25.424, Speaker D: I mean, I mean like on the volunteer match platform. Do the opportunities, is it sort of like one opportunity corresponds to one person wanted, or can they have demand for multiple people in the same opportunity?
00:49:25.464 - 00:49:45.534, Speaker B: Good, good. Yes, yes, they do give a number of requests that volunteers, for example, this opportunity needs five volunteers. The other one requires, needs two volunteers and so on. So, yes, we do have that information. At the moment, we're just trying to give everyone at least one on a weekly basis. Right. First order.
00:49:53.434 - 00:50:10.480, Speaker F: Is there like a notion of preserving the overall, the long term health of the platform in terms of maybe the high demand opportunities are just better run and better organized, and so we're okay with them getting surplus. Sign up for the long term health.
00:50:10.552 - 00:50:37.856, Speaker B: Good, good for the long term health. Actually, you don't want to do that for the following reason. They're not going to reach back to the excess volunteers. Those volunteers never hear back. They get disengaged, and you end up with a platform with less number of volunteers. And at the moment, I remind you, this is a, this is a market in which volunteers are very much on the short side, so you don't want to lose anyone. That's a good question for like a different market.
00:50:38.000 - 00:50:38.776, Speaker C: Yeah.
00:50:38.960 - 00:50:59.612, Speaker A: So if you wanted to optimize for a sort of min max objective, like, you know, I want to fill every need to a certain fraction, and I want to maximize the minimum fraction I'm filling. Is there something known for that, for online matching?
00:50:59.708 - 00:51:37.848, Speaker B: That's a great question. The thing is that balance, by the virtue of kind of minimizing risk, by kind of balancing the fill rate, it sort of automatically achieves that. Right. The basic online matching algorithm. So, like, that's called MSDV, or our version, both of them, they try to keep fill rates relatively equally. Modular weights, like, I'm putting weights aside, that's why they kind of automatically are balanced. They try to kind of be fair, but that's not their objective.
00:51:37.848 - 00:51:38.584, Speaker B: Right, I see.
00:51:38.664 - 00:51:51.304, Speaker A: So is that, I mean, can you prove that as a theorem? Like, is that, so if that were my objective, would this algorithm be, um, worst case optimal?
00:51:51.844 - 00:52:09.620, Speaker B: I have not. So here's the thing. When I have adversarial model, min max is a very sensitive, objective function. I bet you can cook up examples that you get nothing. But for stochastic models, I think Will has a paper on this. Right. So there has been results, and for the stochastic arrival model.
00:52:09.620 - 00:52:10.740, Speaker B: Okay, got it.
00:52:10.812 - 00:52:11.464, Speaker C: Thanks.
00:52:15.504 - 00:52:22.096, Speaker F: So this is primarily about signups, right? Does volunteer match have any issues with folks signing up but not showing up for the actual event?
00:52:22.200 - 00:52:23.456, Speaker B: Oh, that's great. Yeah.
00:52:23.600 - 00:52:31.364, Speaker F: If so are there systematic differences between the likelihood of someone to do that given that they're an internal or an external signup or between the opportunities?
00:52:31.704 - 00:52:51.264, Speaker B: That's an excellent question. Think of this as a very young organization. You still don't have information on those kind of second stage phases but so they try to just create as many signups as possible. They don't have visibility to kind of the next stage but definitely they want to do that in the future.
00:52:54.804 - 00:52:57.984, Speaker A: Yeah. Last question and then we'll move to the next session.
00:52:58.764 - 00:53:07.316, Speaker E: Is this even feasible based on like will they have, can they have access to the information about who showed up.
00:53:07.340 - 00:53:21.944, Speaker B: To the opportunity or not directly but they can like ask organizations to give them a follow up update. Hey, did this person show up for your opportunity or not? But nothing directly for sure.
00:53:25.124 - 00:53:25.580, Speaker C: Okay.
00:53:25.612 - 00:53:27.264, Speaker A: Let's thank Vahide again.
00:53:31.884 - 00:53:32.388, Speaker B: Great.
00:53:32.476 - 00:53:34.844, Speaker A: So now to wrap up the work.

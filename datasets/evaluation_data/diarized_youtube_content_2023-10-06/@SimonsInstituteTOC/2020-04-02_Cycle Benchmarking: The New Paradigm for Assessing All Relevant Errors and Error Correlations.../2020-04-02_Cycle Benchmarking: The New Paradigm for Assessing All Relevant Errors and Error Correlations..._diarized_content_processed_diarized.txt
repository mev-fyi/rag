00:00:00.320 - 00:00:25.378, Speaker A: To the second talk of the day. Just a reminder that you're encouraged to ask questions throughout. You can do so by typing in a question to the q and a box, or you can raise your hand and I will unmute you and you can ask your question verbally. So the next talk will be given by Joe Emerson from University of Waterloo, and he'll be telling us about cycle benchmarking.
00:00:25.486 - 00:01:24.584, Speaker B: Michelle, great, thank you. Thank you for the opportunity to tell you about what we're up to. So, this is actually joint work with my group at the University of Waterloo and the people at the startup quantum benchmark. And so my co authors are listed there. And so I'm going to tell you about the experimental implementations of some theoretical methods that were developed by myself and Joel and others to understand the errors impacting a quantum system, especially a quantum digital quantum computer, programmable quantum computer, and that has multiple out that information can flow in various ways. And I'll describe that a bit as well. And I understand this is more of a theory audience, and an audience is not super familiar with benchmarking, so feel free to ask me to elaborate on any of the background information.
00:01:24.584 - 00:02:11.706, Speaker B: Okay, great. So the first thing I want to emphasize is that is the complexity of the error problem. So, you know, we've kind of comforted ourselves with this idea that we can talk about single numbers to characterize, you know, a threshold or, you know, error rates. And, you know, I think that, you know, that got us so far, but we really have to stop assuming that that's a reasonable thing to do anymore. You know, we have the exponential power of quantum computing, but the error parameters in a quantum processor grow even faster than exponential. Well, not fat. I mean, quite, you know, it's two to the four n, is what I mean, rather than two to the.
00:02:11.706 - 00:03:01.724, Speaker B: Nice. So I'll explain in more detail where that two to the four n comes from. But here, if we want to understand, truly understand the error parameters affecting an implementation, we have to worry about this massive parameter space. A point I'm going to emphasize throughout this talk, because it turns out even the experts in this idea of characterization haven't really fully appreciated. Robin Bloomkoot notwithstanding, many others haven't appreciated the importance of the fact that the errors depend on which gates are applied. So when I talk about two to the four n error parameters, that's for each different gate in principle, that you have to apply in your processor and each different combination of gates. And I'll show you some very strong evidence that this is not a second order effect, but a leading order effect in characterizing the error processes.
00:03:01.724 - 00:03:36.130, Speaker B: Of course, I'm making a markovian assumption. I'm assuming the errors are markovian on the time scale of the gates. If that's not the case, then this completely positive map model breaks down something which I for ten years, been trying to convince Richard Cleve of, and he still doesn't believe me. But if you have non markovian errors, this whole CP map formalism just doesn't even work. So here I'm assuming that we have CP maps, and so the errors are markovian on the time scale of gates. And even with that assumption, we still have a very big challenge ahead of us. So here's a kind of a fun little slide.
00:03:36.130 - 00:04:30.824, Speaker B: You know, as some of you know, I'm an entrepreneur as well as an academic now, so I've really been forced to simplify these things, these stories. And so here's kind of the simple picture I give to, you know, venture capitalists and Fortune 500 companies. So you're trying to navigate these waters to do a quantum computation, and you see these icebergs, and you obviously want to avoid them. They're the errors and the processes that are associated with their transformation. The tip of the iceberg is what we can measure via randomized benchmarking or gate set tomography. These are the errors associated with the gates themselves. And, of course, what's happening underneath the surface is the true danger, and that is crosstalk errors, correlated errors that are severely limiting the performance of processors, that will severely impact the capabilities of both NISC algorithms and fault tolerance going forward.
00:04:30.824 - 00:05:00.090, Speaker B: So, first, the visuals not to scale. I kind of realized that this figure I picture I found on the Internet is actually very badly out of scale. It looks like the bottom of the iceberg is two or three times the size of the tip. That's not the case. And similarly, for a quantum computer, it's exponentially larger. And another piece, the story I mentioned at the top of the talk is that, look, every iceberg is different. You can't measure one iceberg and say, you know, all icebergs, and the same is true.
00:05:00.090 - 00:05:39.530, Speaker B: You can't say, I measured the errors associated with some gates or with an average over my gates, which is what randomized benchmarking does. And think that you have enough information to navigate these waters. You have to identify every single iceberg to be safe, and you have to identify the errors in every distinct gate combination to. And then, of course, you have to understand the errors in your measurements as well. But here, we're just focusing on gate operations for this talk. And I'll show you some data for that. And then cycle benchmarking is the tool that's going to solve this problem, maybe not completely, but to a very high degree of satisfaction.
00:05:39.530 - 00:06:17.872, Speaker B: And so I'll tell you about what that is today. Let me move this down so I can see my slides better. Okay, so errors in a channel. So which channel is the point? So if you're going to see a lot of results out there about characterizing errors in a channel, but then what's happening is they're characterizing the errors in some kind of average channel or abstract channel. So think about the difference between quantum error correction and fault tolerant quantum error correction. So quantum error correction, you have some memory channel or some, you know, communication channel. You do an encoding to survive the errors in that channel, and then you do a decoding.
00:06:17.872 - 00:07:22.042, Speaker B: And of course, in a fault tolerance setting, you need to worry about the errors that arise in the operations themselves, both the logical operations in the circuit, the target operations of the circuit, but also the operations you perform to do the encoding and the correction steps, the recovery steps. And so the problem is much more complex when you think about the real world application of these ideas in a computation. And the same thing is happening with these quantum processors today and in the future, which is that the errors depend on the applied control, on the microwaves, on the lasers, on the system design parameters of the trap, which means they depend on the choice of gates. Robin has made a point about this in several talks. He calls it gate error contextuality, or gate contextuality. And it's this idea that the errors depend on the context, they depend on the choice of gates, on the sequence of gates that are being applied on their own or in parallel. And so the point here, which I'm really belaboring now, is that distinct gate combinations produce distinct error rates and types.
00:07:22.042 - 00:08:26.788, Speaker B: And so the cycle benchmarking tool is really designed not just to identify the errors in detail, but to identify the errors associated with very specific gate combinations that you care about for improving the design of the device, for applying error correction and fault tolerance. So just to give you a quick now picture, the cycle benchmarking protocol is the following. What you have in pink with the vertical pink block is some set of gates you care about. So this could be maybe a parallel set of c phase gates across the processor, could be a paralyzed set of t gates, it could be some mixture of c phases and t gates. It could be anything you want. But the idea is that it's one kind of moment in the circ language, it's one clock cycle in that more abstract language, where you're applying some set of gates across all the qubits in your system, which we know we have to do to realize robust, large scale quantum computing. So that's what you care about.
00:08:26.788 - 00:09:09.430, Speaker B: And then the blue gates are local randomizing gates, very much like what Andreas talked about in the previous talk. So these can be drawn from maybe the poly group or the dihedral group on single qubits, or the Clifford group. So we think the best way to do this in general is the poly group. So here you're doing random polys, and then the block that's grayed out, that's being applied m times sequentially. And the idea there is to essentially get a decay curve. And by seeing the rate at which the fidelity will decrease, you're getting the error per unit application of this block. And that allows you to isolate out spam errors.
00:09:09.430 - 00:09:55.252, Speaker B: So spam errors are called, are so called state preparation and measurement errors. So when you prepare the state with these green blocks on the left and you prepare the measurement with the green blocks on the right, those processes have errors associated with them, as well as the raw readout errors of the device itself. And if you want to isolate the errors in the pink block or in the gray block, you want to make sure that you're modding out the errors from the spam. That's the protocol. So for terminology, we call g a hard gate cycle. So the hard gate cycle, like I said earlier, could be the identity operation. It could be, which is idling the qubits.
00:09:55.252 - 00:10:24.454, Speaker B: It could be an entangling gate or some parallel set of entanglement gates. It could be anything you want. And then the natural thing to do is to understand the errors not on the pink block alone, but the pink block combined with local random gates. So we call that addressed cycle. Borrowing terminology from physics, we also call it a twirled hard gate round. And so what I'll tell you later is about how that is the NatUral thing to characterize the errors for. For now, you just have to accept that on faith.
00:10:24.454 - 00:11:18.944, Speaker B: And then basically what we're doing is some clever sampling of input states to. The problem is the error model will produce a multi exponential decay. And what we want to do is be able to isolate single exponentials to get a good fit. And so the green, in addition to the m fold sequential multiplication, the green operations are also killing off other decays, so that we're just singling out single exponentials. Associated with specific input poly operators. So the idea is that the total error on this entire gray block can be systematically explored by looking at its impact on a basis, a basis being a set of poly input states. And what we want to do is we want to sample from that set, and we want to isolate the errors associated with the action of this gate sequence on specific input states or specific poly input operators.
00:11:23.294 - 00:11:27.354, Speaker C: So I have a quick, sorry, basic question. What is a poly basis, say?
00:11:28.054 - 00:12:10.210, Speaker B: So if you think about the block sphere, the block sphere is spanned by identity x, y and z. And if you take n fold tensor products of those four poly operators, you get the set of polys, and that is a operator basis for the Louisville space. Right? So the way that works is that, you know, a unitary, the basis for a unitary is the computational basis. So you have a matrix for two qubits, you have a four by four matrix, you have four basis states. The error models are CP maps acting on that space, which are d squared by d squared dimensional for a d dimensional Hilbert space. And so now the basis is also bigger instead of the computational basis. You need a basis of four to the.
00:12:10.210 - 00:12:57.284, Speaker B: Nice. And I'll actually come back to that later in the talk. But first, let me continue with kind of motivating why this matters. You know, we have a diverse audience, so I think there's something for everyone here. And the idea is, how is this diagnostic information? We're going to tease out, who is it useful to? How is it useful? And so the idea is, what people mainly do right now is they implement their gates, and they characterize their gate performance via single numbers, which are determined by a randomized benchmarking. Or they do something more sophisticated, like gate set tomography, and they get a set of numbers associated with different elementary gates. And what I'm going to show you later is that that's really inadequate for understanding global performance.
00:12:57.284 - 00:13:56.276, Speaker B: And so if we move down to the blue box, these are the global errors estimated under cycle benchmarking. And the word global is not the perfect word here. What I'm talking about is aggregate errors. So essentially what you're going to see later is that if I have a ten qubit system and I apply a gate on qubits four and five, people traditionally have thought about what is the error on the gate by looking at qubits four and five. What we're seeing, we work with almost all experimentalists now, and what we're seeing across all systems is that you can have very dominant errors that aren't even on qubits four and five that are induced by the gate on four and five. And the reason for that is that experiments are hard, right? So in the supern qubit system using microwaves, and microwaves are long and they basically cover the whole chip. And you have any other qubits that are on resonance with that frequency are going to be excited and perturbed by the gate operation.
00:13:56.276 - 00:15:50.932, Speaker B: And so you can see a big error on qubit ten when you're just trying to do a gate on qubits four and five. So by global, what I mean is that we're looking at the errors across the whole system, and what we're doing is we're reconstructing the errors in what's called a poly channel, and I'll explain why that's the right object later. And we're finding what I call off gate errors occurring on other qubits under each distinct clock cycle, each distinct combination of gates. So now how is that information useful? So on the one hand, the people in the lab, experimentalists in the lab, need to understand how to optimize their pulse design, optimize their system design, their system operating parameters, and this information flows back to them to do that engineering. On the other hand, for NISC applications, we want to understand what is the accuracy of the algorithm, what are different trade offs we can apply to find more robust ways to implement the same global unitary by a different break, different circuit decompositions. And so I'll talk a bit more about that at the end of the talk, if there's time, and then an exciting application, is that if we, as we look towards fault tolerant quantum error correction, we very much need to understand whether or not, not just is the noise below the threshold, which is a very naive way of thinking about it, but what about all the other assumptions that go into that fault tolerant threshold? Are the errors independent? Are the independent beyond some length scale? Is the noise markovian? If we do have high weight errors, how high of weights do we have to worry about? Are there preferential errors along certain axis systems? In many experimental systems, the errors along the z axis are completely different, if not negligible, compared to errors for rotations about the x and y axis, because there's different physics involved. The errors on the x and y axis come from physically hitting the systems with pulses, the air.
00:15:50.932 - 00:16:32.220, Speaker B: The z axis rotations are performed by just changing your timing, which is very accurate. And so you basically just redefine what your rotating frame is to do a z rotation, which is error free, basically. So you have a very strong asymmetry on the different axis system for errors. And that can be exploited to get big gains in lowering the overhead for achieving fault tolerance. The other thing you want to worry about is how to optimize the decoder. The decoder will depend on detailed information about the noise to have the right prior to do the best guess about how to do the best recovery operation. So the information obtained from this flows in at multiple levels.
00:16:32.220 - 00:17:06.319, Speaker B: Whether you care about control, whether you care about NISC algorithms, whether you care about fault tolerance. The information that our tool generates is, is relevant in all those applications. I'll pause for questions. Okay, now a little bit of math. So, a general error channel can be written down in lots of ways. A common way to write it down is the so called chi matrix. So here, the polys, p sub alpha and p sub beta are all the polys that span the space.
00:17:06.319 - 00:17:31.431, Speaker B: So you have d squared of them in the lower right hand corner. P one is the tensor product of identities. P two has an x on the nth qubit, p three is a y on the nth qubit, and so on and so forth, until you have zeds all the way across. This is an operator basis for the noise maps, for the CP maps. And so we can write any CP map in terms of this. In terms of this. This is called a chi matrix representation.
00:17:31.431 - 00:18:06.874, Speaker B: It's similar to a crouse form, but it has off all off diagonal terms. Alpha and beta can be unmatched. And then the chi matrix is the set of coefficients that contains the full information about the Cp map. So that has, that chi matrix is dimension d squared by d squared, where d is the Hilbert space dimension. Now, there's a special subset of error channels called poly error channels, and that's where we remove the off diagonals. So we just have matching indices. And then the error model is described by a probability vector of length d squared.
00:18:06.874 - 00:18:42.884, Speaker B: And we think about the error channel in this context as having just a distinct probability of any of these d squared poly operations. A special case of this is the well known depolarizing error channel. So a depolarizing error channel in each qubit would assume that the errors on x, y and z are the same. And so you just have one parameter to describe the errors. On a d dimensional system. You can have a depolarizing channel, and it assumes that the errors on all polys are the same, except for the probability of no error, which is distinct. So these are very physically unrealistic but simple error models to work with mathematically.
00:18:42.884 - 00:19:23.414, Speaker B: And so the key point here is a notion of coherent errors. So if my error model is like a theoretical error model, you would say, okay, well, I'm going to dream up this error model where I just have some probability of an x error on qubit one and a different probability of an x error on qubit two. But these are all classical statistical kind of models. These are classical models of noise. I have a classical probability of each of these distinct poly operators happening. That is not what happens in the real world. So a very common leading error mechanism for physical systems is say an over rotation.
00:19:23.414 - 00:20:11.342, Speaker B: So I meant to do a 90 degree rotation or a PI on two rotation about x, and instead I did a PI on two plus epsilon rotation. That in fact tends to be the leading error on almost all systems. When you have that kind of error model, you do not have a poly error channel. You have off diagonal terms in the chi matrix. And so there are two way, two challenges. One is, can we obviously engineer a system so that the noise is not of that form, and so you can work hard on that. But one of the things I'll tell you about in this talk is a tool we developed called randomized compiling, which is a way to enforce the error model to have this poly error channel structure, which is a very convenient structure to work with mathematically.
00:20:11.342 - 00:20:51.630, Speaker B: And what that basically does is it applies random gates. You apply virtual random gates kind of interleaved in your circuit and then average over those virtual randomizations in a way that you kill off the off diagonal terms. And I'll touch on that a bit in more depth later. But that's just to give you a sense that we can't, even though it's not physically realistic, we can use software tools to reduce the error model to this poly error channel. So it now becomes very relevant because we have this tool to make it relevant. So I already jumped ahead of myself. So the point is these poly channels are not physically natural.
00:20:51.630 - 00:21:32.960, Speaker B: But as I mentioned on the last slide, we can enforce it through randomized compiling so that we can get this. First of all, randomized compiling gets rid of these cross terms. And the second thing it does is it gets rid of a lot of non markovian errors. So it forces the error model to be more markovian. And there was a nice experiment showing this a couple years ago at a Bbn. And then the point is now, once we've done that, or we assume that, then we can just simplify our problem and understanding this probability vector p alpha, which is a two to the two n dimensional probability vector of which depolarizing error is a very special case. Okay, now a little more math.
00:21:32.960 - 00:22:39.664, Speaker B: So, in general, a CP map can be written in this Krauss form, or this with the probability vector. But that's not actually the most natively, that's not the most natural way to describe error processes. A CP map is a linear map, which basically means that a great way to think about it is just as a matrix acting on a vector. And so the way to do that is you have this map lambda, which is just a linear map, taking input states to output states. And now what we can do is we can expand the input state across a basis of operators, which is just going to be our poly operators, and the coefficients b alpha encode which state you have, and then they're calculated via the Hilbert Schmitt inner product, and then similarly for the output state. And then what we can do is we can represent the map itself by the Hilbert Schmitt inner product under the following trace, which now means our CP map is represented by a matrix which acts on the vectorized form of the density operator. I assume many of you are familiar with this, but if you're not, this is such a great way to think about error models.
00:22:39.664 - 00:23:27.416, Speaker B: You should know it. And then what you acquire is then all these natural properties. So now this matrix lambda is, we call it a dynamical error matrix because, or a dynamical matrix because if you have an error process associated with some time tau, and then you have another error process associated with a second time, well, let's call it tau one and tau two, then you can just multiply the matrices together and understand the process from across both times. And so the entire problem of error analysis is just the linear algebra of analyzing these matrices. It's very mathematically natural. It's composable both under, in time and in space. So you can tensor product these matrices together to see the error process across two systems that are independent.
00:23:27.416 - 00:24:38.374, Speaker B: And if these systems are not independent, correlations will show up in the error process matrix for the joint system. And if you choose the basis b alpha to be the poly operators, then this Louvo matrix is called the poly transfer matrix. So that's the tool I will use. It's a very key tool for analyzing this. Now, because we have a linear matrix, if that linear matrix is normal, we can diagonalize it and the singular values then encode key information about the error process. Now, if we know we have a, if we know for other reasons that this error process is a poly channel, then a poly channel expressed in the poly operator basis as a poly transfer matrix will be a diagonal matrix, and the eigenvalues contain the complete information, and they relate directly to the polycrauss picture. So here, now, if we have a poly channel, we have d squared eigenvalues, and the poly operators are the eigenvectors of that channel associated with their own eigenvalues.
00:24:38.374 - 00:25:40.138, Speaker B: And correlations in the noise will be encoded in the relationships between these eigenvalues. And this was shown, or, I mean, I think it's been known for a long time, but we explicitly explored this back in 2007, where we showed that by measuring these quantities, or sampling them and estimating them, you could learn about correlations in the error model of an error channel. And then what happened in 2019. In our work with Innsbruck, we demonstrated this cycle benchmarking tool. And what that does is it is it allows you to associate this information, not with some abstract error channel, but the errors associated with very specific combinations of gates. So now we can pull out information about the correlations in the errors associated with each distinct gate sequence. And then, if you like thinking about it in terms of this Krauss picture, there's a very simple relationship that relates these eigenvalues to the probabilities in the Krauss picture.
00:25:40.138 - 00:26:09.198, Speaker B: So we have these two very nice complimentary pictures, and a simple transformation between them. And then, now what I'm going to show you is a preview of what you're going to get. So the next two figures are preview figures. So if you don't understand everything about them, that's okay. I just wanted to give you a sense of where the talk is going. So, here's the experimental data from that 2019 paper with Innsbruck. What we did is we said, let's just take a trap with ten, with up to ten ions in it.
00:26:09.198 - 00:27:04.066, Speaker B: And here we're looking at a subset of four, and we did a complete reconstruction of the errors on the four qubit system. And then again, the question is, errors on what? So, here, the errors are not on some average channel, they're the errors on the identity channel, where the only operations are averaging over the local poly operators. And so then the local poly operators enforce the noise to be a poly channel. So we know with high confidence that the channel is given by this polycraus picture, and that the only relevant information is these probabilities. And again, these probabilities correspond to specific input states that span the space of input states, these poly bases, these poly operators. And then what you find is in blue, you find the one body errors. So the biggest error they see is this 0.3%
00:27:04.066 - 00:27:35.582, Speaker B: probability of an x error on qubit one and no errors on qubits two, three and four. The second biggest error is a bit flip error on qubit four and no errors on the other qubits, and so on. But where this gets interesting, I mean, of course, that's great information for improving your pulse design. Where this gets interesting is look at the orange. So the orange are the weight two errors. These are errors with hamming weight two. And not only is it telling you the total probability of weight two errors, which is this 0.0032
00:27:35.582 - 00:28:06.226, Speaker B: here, but it's telling you the specific probabilities associated with specific correlations in the noise. And notice that these are coming in at the 0.1% level, just below 0.1%. And so you have a correlation between qubit one and three along the x axis and xx coupling. You have a Zz coupling between qubits one and three. Then you have an xy coupling between qubits one and two, and so on. So, the most interesting thing about this for theorists, I mean, for experimentalists, this information is a goldmine for theorists.
00:28:06.226 - 00:29:16.588, Speaker B: Think about the assumption we've all been hoping for, which is the errors are independent across qubits, so that our high threshold, fault tolerant proofs apply. If the errors are independent across qubits, then the errors of weight two should be quadratically suppressed relative to the errors of weight one. So if you have a probability, if you have a ten to the minus two error rate for single qubit errors, your weight two errors should be ten to the minus four. Right? Just like if you're flipping coins, if you have a, if you have a highly biased coin or, you know, you're rolling a d 100, what's the chance of getting a one? It's one out of 100. If you roll twice, what are the chances of getting two ones? Very small, right? Ten to the minus four, these errors are coming in three times smaller than the single qubit errors. So what that means is that there's very, very strong two body errors when they're only doing one body gates. So remember, what we're characterizing here are the errors on one body gates, just doing single qubit poly's.
00:29:16.588 - 00:29:59.814, Speaker B: So this is bad news in the sense that we're very far in this device from having uncorrelated errors. Now, there's two solutions for that. One solution is to, you know, put the team back in the lab and use this information to improve the design of the, of the control. And the other solution is to look at error models of error correction procedures that can handle weight, two errors. And by looking at the diagnostic information, you can say, well, if my. If I have, I can choose a code with the right distance to handle the bulk of the errors that I'm worried about. And so, here we're at the first step of a very long iterative process.
00:29:59.814 - 00:30:56.354, Speaker B: But what we now have and what I'm kind of showcasing here is that we now have the right tool to take on this challenge from both the top and the bottom. So, get the teams in the lab figuring out how to improve the design, get the theorists figuring out how to design the right codes to tackle the air models with these different gate combinations. What about super dunk qubit systems? So, we ran experiments on IBM Q. So, this is the Yorktown device, which was one of their first generation five qubit chips they put online. This data is astonishing. So, the way IBM describes its devices is they report randomized benchmarking numbers for their one and two qubit gates, right? So what we do is we run a CNot gate on qubit zero one as our hard gate round, so that pink block labeled by G earlier in the talk. And then we idle qubits two, three, and four.
00:30:56.354 - 00:31:32.574, Speaker B: And then we apply the cycle benchmarking procedure, which involves applying local random polys and then. And then amplifying the errors and then measuring them. Now, what you see on this figure is the x axis labels looking at different pairs. So the data set for this is huge. So this is a projection of the data for visualization. And so what we're looking at is the pair zero one in the first column, the pair zero two in the second column, and so on. And then what the y axis is, is each of the poly operators that span that two qubit space.
00:31:32.574 - 00:31:59.612, Speaker B: So, in other words, not just how much error occurred, but where did it occur? In the Hilbert space. And this vertical column for qubit, for the zero one pair, which is the only pair. Now, just as a rule of thumb for theorists, the cnot gate error rates tend to be ten times bigger than the single qubit gates. So the dominant errors here are from the Cnot gate. What you see is that. Oh, sorry. Lastly, this is a heat map.
00:31:59.612 - 00:33:02.434, Speaker B: So dark colors mean low errors, bright colors mean higher rates. What you see is the first column is looking at the errors on qubit zero one, and what you see is a very dark purple, which is, loosely speaking, the randomized benchmarking number that IBM reports for their CNoT gate is summing over the vertical column for the first column. And what that shows is good performance. Now, for them, good is like ten to the minus two error rates. What they don't show from that data is then when you look at what's happening elsewhere on the chip, and the rest of the chip has these very bright colors everywhere. So what we're seeing is that error rates of ten to the minus two from the CNoT gate, but the crosstalk errors induced by the CNoT are creating weight one and some weight two errors at totally different locations on the chip. Look at column three, four, qubits three and four on the other side of the chip, and you see a bright green on zi.
00:33:02.434 - 00:33:35.014, Speaker B: So what you have is a very big phase shift error on qubit three that's being induced by the CNoT gate on qubits zero and one. And before we did this experiment, we thought, okay, maybe the crosstalk errors will be 1% or 10% of the error budget. They're not only there, they're ten times bigger than the errors on the c naught. So the c naught has errors of ten to the minus two. The errors on the rest of the chip are at the ten to the minus one scale.
00:33:35.874 - 00:33:45.762, Speaker A: So what this means, can you give any intuition about why it's so peaked on these? Is there a pattern here that we should know that you can read off this chart?
00:33:45.898 - 00:34:09.284, Speaker B: Yeah. So, yeah, so, for example, look at qubit zero two. You see the bright yellow, and then the qubit pair is one and two. You see a bright yellow on the second qubit. So what that means is qubit two. So notice that this is overkill, because now, when you're looking at single body errors, that essentially the zero here and the one here is irrelevant. The point is, what this saying is, there's a very large phase flip error on qubit two.
00:34:10.024 - 00:34:10.400, Speaker A: Yeah.
00:34:10.432 - 00:34:15.200, Speaker B: And shows up as the shadows of that error show up in different ways on this figure.
00:34:15.352 - 00:34:15.784, Speaker A: Okay.
00:34:15.824 - 00:34:44.336, Speaker B: But basically what they're showing, there's a very strong phase shift error on qubit two. There's a very strong phase shift error on qubit three. And then, and that shows up in different ways here. And then what you see in kind of in lighter blue, you see errors. You see zz, XZ, and yZ errors on the zero four pair. So these are two body errors. So those are not as easily fixed by a simple phase corrections.
00:34:44.520 - 00:34:45.840, Speaker A: Okay, thanks.
00:34:45.992 - 00:35:12.804, Speaker B: So in other words, remember, the way they do the cross resonance gate is you basically apply control, and that induces a coupling so, if you're just trying to do a CNoT on zero one, you're actually accidentally going to induce, like, partial cnots elsewhere on the chip. And also single qubit phase shifts. And so this information is basically telling you what went wrong. How did it go wrong? Were they two qubit errors, one qubit errors, and. And this pattern looks completely different for every gate combination.
00:35:13.224 - 00:35:14.260, Speaker A: Okay, thanks.
00:35:14.392 - 00:35:54.354, Speaker B: Okay. And, yeah, so that's the preview, and I'll come back to this again later with more when you guys have more of a background from the rest of the talk. All right, so now I kind of go back to basics. What are ways to estimate errors? Well, these very simple errors characterizations are based on fidelities. So the average gate fidelity is you look at the error process, epsilon or e. How does it, what's its average action across states? The so called RB number, or the infidelity for randomized benchmarking, is just one minus. That number, often used with the letter r, is often used for that.
00:35:54.354 - 00:36:30.890, Speaker B: A common measure of error, figure of merit for error in fault tolerance is the diamond metric. The diamond norm. And that's a proper distance metric that's composable, and so on. And that's by taking the diamond norm between the error process and identity. And just to make sure everyone's on the same page here, I'm always imagining that you're modding out the intended gate and just looking at the error on that gate. Another interesting figure of merit is the total variational distance, or l, one norm on the probability distribution under some circuit. So I have an ideal circuit.
00:36:30.890 - 00:37:10.284, Speaker B: I have the actual implementation. They both induce probability distributions on the computational basis. And then I can measure the impact of the errors by summing over the absolute value of these differences. So, these are three common ways to measure errors. The data I was showing you on the previous slide is kind of the full information. And then these are these figure of merit metrics, which you could compute from that full information. An important story is that norm based metrics all behave kind of similarly, and they're very sensitive to coherent errors.
00:37:10.284 - 00:38:18.814, Speaker B: So this inequality here is a very important piece of information about understanding the impact of errors. So, on the left hand side of this inequality is the infidelity, which is measured by randomized benchmarking. And this fact is, there's a dimensional factor, d plus one over d, which is basically one. In the middle, we have the diamond norm, which upper bounds the infidelity. And then on the right hand side, we have the square root of the infidelity times a huge dimensional factor, the Hilbert space dimension, which upper bounds the diamond norm. So now the problem is, the diamond norm is not easy to measure, but the infidelity is very easy to measure. And so the point is, how does this knowledge relate to itself? How do these things relate to each other, rather? And so what you have is, because of this inequality on the right hand side, if I measure a randomized benchmarking number, and I get ten to the minus four error rates, what does that tell me about the diamond norm? Well, the best I can do without other information is take the square root and multiply by the Hilbert space dimension.
00:38:18.814 - 00:38:45.244, Speaker B: And what that means is that if I want to talk about comparing my RB number to threshold based on the diamond norm, the square root is going to crush me. So I measure, I do all this hard work to get ten to the minus four error rates. Really, that means I could only pass a threshold of ten to the minus two. And again, this is doing the naive thing. We're saying we're assuming the noise is independent, we're assuming it's markovian. It's none of those things. But if all of those happy things were true, my noise was depolarizing.
00:38:45.244 - 00:39:13.744, Speaker B: And I'm just checking now, what is the threshold I can pass? Well, if I do run my benchmarking, sorry, I misspoke. If it's depolarizing, then actually you're in good shape. But if you don't know that it's depolarizing, you just know that it's independent. Then you get the square root factor. So that's a major challenge. How can we overcome that? And the trick is to make sure that I'm missing a slide here. So, let me just say something verbally.
00:39:13.744 - 00:40:08.340, Speaker B: What we know about this inequality is the following. This upper bound is saturated by coherent errors. So, if the error is a one of these physically realistic over rotation errors, then I have these off diagonal terms, and it's these off diagonal terms that give the square root. If I know the noise is a stochastic noise, or so it's a poly channel, then the lower bound is saturated. So, if I have a promise that the errors are a poly channel, or in fact, more generally, any stochastic channel, so there's no off diagonal terms, then, in fact, this inequality is saturated. And the RB number is a very good proxy up to some small dimensional factor for the diamond norm. So it kills this square root, basically.
00:40:08.340 - 00:41:01.096, Speaker B: So that's the strength of randomized compiling, is that it gets rid of this square root problem, and now, the numbers we measure via cycle benchmarking, and randomized benchmarking now actually can be used to compare directly to the threshold without the square root. And so I think these points are basically the points I've already made. And the important story here is that the total variational distance acts like the diamond norm. So it's bound, bounded by the diamond norm, bounded by the diamond norm. So we similarly can predict the algorithmic accuracy for a circuit from these infidelity numbers. If we're promised the noise is stochastic. So that's why we think the right way forward is to always use randomized compiling.
00:41:01.096 - 00:41:33.394, Speaker B: Then you're guaranteed that you have a very close, tight connection between all of the quantities you care about. How do you determine if your errors are still, are coherent? Well, with randomized compiling, you can get rid of it. Now, you don't fully get rid of it. What you do is you get rid of the square root. So a coherent error that comes in as a square root becomes a stochastic error, and only comes in as the raw RB number. So it doesn't make the coherent error disappear. It turns it into a more benign stochastic error.
00:41:33.394 - 00:42:22.684, Speaker B: Now, if you're at for the engineering teams in the lab, you know that there's now two ways you can get rid of your coherent errors. One is you can just let them be, use randomized compiling and suppress them quadratically. The other thing you can do is, of course, improve your tune up and control. And so if your job is to improve your pulse design, then you want to directly measure the amount of unitarity. And one way to do this is via this unitarity protocol, which measures this quantity u, which is essentially the average shrinking of the vector in the generalized bloch sphere. So, basically what u measures is if I imagine my vector in the bloch sphere, the noise will rotate it and shrink it. And what unitarity does is it measures the amount of shrinking without caring about how much it got rotated.
00:42:22.684 - 00:42:59.398, Speaker B: So if you measure the total error and you measure the compression error or the depolarizing error, then by having those two pieces of information, you know how much it actually got rotated. And so, this is a complimentary tool set by this unitarity protocol to do this. And so that's something that's mostly of interest to experimentalists who want to kind of optimally tune up their controls. Let me just skip over that for this audience. Now, let me show what we learned about on the IBM system. This is now their 14 qubit device, Melbourne and to emphasize the story of crosstalk. So this is pretty old data.
00:42:59.398 - 00:43:51.954, Speaker B: Now, we looked at qubits zero through 13 on the x axis, and on the y axis is the error rate, this infidelity number. And what we did in blue, with blue circles is we would just pulse on one qubit at a time and run a randomized benchmarking experiment. So a randomized benchmarking experiment is just apply a random sequence of gates, see how fast you lose fidelity, and from the slope, you infer the error rate per operation. And. And then what we did, and that's the blue, that's the blue dots, the blue circles. And you see the error rates between ten to minus, you know, around three times ten to the minus three pretty consistently across the system. Then what we did is instead of idling the other 13 qubits, we did randomized benchmarking in parallel.
00:43:51.954 - 00:44:42.300, Speaker B: So we're pulsing now on all the qubits simultaneously, but not entangling them intentionally in any way. And then what you see is in orange is the local RB number, when instead of idling the other qubits, you're actually pulsing on the other qubits. And so qubit zero. When you go from idling qubits one through 13 to pulsing on them at the same time, you see a jump of a big factor of three in the error rate. For qubit one, you see a jump of almost an order of magnitude in the local error rate. Why is this happening? Because the pulses you're applying to qubits zero and two through 13 are leaking onto qubit one and inducing errors on it. So, in other words, like we saw earlier, and now this is single qubit gates, not the cnot gate.
00:44:42.300 - 00:45:36.594, Speaker B: So even the single qubit gates are causing crosstalk errors that are inducing errors on qubits you're not intending to be acting on. And then a crosstalk error often has a very strong coherent error signature because it's actually the microwave pulse is producing a rotation. So it's not a depolarization or a dephasing, but just a flat out rotation, an incorrect rotation of the qubit. So we use this unitarity protocol, which is the squares, to determine what fraction of the noise is depolarizing versus coherent. And what you see is, in the isolated RB case, where everything else is idle, you see that the squares and the circles align very well. The blue square and the blue circle are very well aligned. What that means is that IBM has very effectively calibrated their systems when they're not looking at other qubits being acted on.
00:45:36.594 - 00:46:21.754, Speaker B: But now when you're acting on the other qubits, you see a big gap opening up between the squares and the circles, and that's because of the crosstalk. So now we're seeing is a very large coherent, so a very big jump in the error, and a big portion of that jump is some simple static or systematic over rotation of the qubit for those gates. So this is really a slide that's more interest to experimentalists and the theorists. Unless there's any questions, I'll skip ahead. Now, I'll tell you more about randomized compiling. Once the experimentalists have done all the work they can do to remove as many coherent errors as possible through pulse design, you will still have coherent errors. Now what we want to do is we want to remove them effectively through a software layer.
00:46:21.754 - 00:47:07.016, Speaker B: Randomized compiling takes some sample circuit at the top here, where different colors represent different single qubit gates, whether it's an x rotation, a bit flip, or a PI on two gates, or a t gate, or a phase gate. And then we divide the circuit into rounds of single qubit gates and two qubit gates. This is a simple example. There's other ways to do it. And then what we do is then we insert, virtually in our preprocessing, we insert random polygates, or there's other general groups you can apply. And then we calculate the correction gate. So if there's no two qubit gate, then the correction gate is the inverse of the gate you applied.
00:47:07.016 - 00:47:38.374, Speaker B: And this is virtual. If there is a two qubit gate, like the yellow in the second figure, the yellow becomes red. So now we compute what is the correct correction gate after you commute through the yellow gate through the cnot. Well, then you what's the correction gate I need to do to get rid of it? So, with these correction gates, I've now undone the randomness I induced. But now we don't apply any of these. This is all preprocessing. And now you look at the second round of single qubit gates.
00:47:38.374 - 00:48:11.294, Speaker B: You apply a new set of totally iid random single qubit gates from your twirling set. Normally the polys, but there's other groups. And then you compute all that in advance. Notice that to do this, to virtually randomize, correct. And then virtually randomize and correct, all of your precomputations are in a four by four dimensional Hilbert space. So the complexity of this problem scales linearly with the gate complexity. Okay, so it's completely trivial to do.
00:48:11.294 - 00:49:08.590, Speaker B: And then what you do is say, now, instead of applying these virtual gates, let me just compile in all of these virtual gates. And so the interesting cases in this third column, I take the correction gate, I take the intended target gate, I take the new random virtual gate, I multiply them all together and find the new single qubit rotation that does all of that. And now instead of applying my original circuit, I apply this randomized circuit, and if you're lucky, this adds no gate depth, no circuit depth. Now you might say, oh, well, a lot of these like VQE algorithms and so on, you have these cnault ladders, so there's no single qubit layers. And she says that means I'm going to double my gate depth. So yeah, maybe it doubles your gate depth, but in reality, if you're running this on a system, what is the native gate in the system? The native gate on the IBM system is not a CNot gate. It's across resonance gate.
00:49:08.590 - 00:49:52.356, Speaker B: How do they deliver a CNoT gate to the user? They sandwiched their cross resonance gate between sets of single qubit gates to rotate into the equivalent CNOT. So really there's a hidden layer of single qubit gates in a lot of these systems. And so even when you think you would have to add depth, you actually don't have to add depth via this trick. And so I think it's an interesting open scientific question how often you would add some, you know, doubling or fractional depth, and I'd like to know more about that. But in many settings, you actually add no depth at all. And then of course, the upside is you create a stochastic channel. So you get rid of this square root problem, which is a huge benefit.
00:49:52.356 - 00:50:36.764, Speaker B: And so here we look at some numerics. Notice the total variational distance is a great way to think about it, which is it's basically the probability of getting the wrong bit string. So if I am producing some bit string, ideally with some probability, then TVD measures, what's the probability I didn't get the right bit string. And so what this is showing, basically, is that if your errors are purely coherent, like they might be from crosstalk or calibration errors, then you get a huge gain with randomized compiling. If your errors are natively stochastic, then you get no gain from randomized compiling. And so there's just a scaling there that's, I'll skip really quickly. How many randomizations do you need? So the trick is you create these virtual circuits.
00:50:36.764 - 00:51:08.238, Speaker B: You compile them to get a new random circuit. How many different random circuits do you have to run? Well, the answer is at most 20. So in terms of the overhead of number of runs, it's a factor of 20. Now, notice you're going to be running multiple runs anyways to accumulate statistics. So really, this is a cost that experimentalists care about, because it's how often do they have to reload their fpga? But from a theorist's point of view, this is a trivial cost. Now, here's some data. So, this is data showing how well randomized compiling works on IBMQ.
00:51:08.238 - 00:51:50.034, Speaker B: So here I'm looking at the TVD on the y axis. I'm looking at various circuit lengths. On the x axis, orange circles are the error, the probability of an incorrect solution as I increase the circuit depth, looking at deterministic circuits on the left column, random circuits on the right column. So, yes, even if your circuit is random, applying randomized compiling helps. The errors are kind of crazy and very scattered in the random circuit case. And you see kind of coherent oscillations in the lower left corner from the fact that the interplay of the coherent errors can be destructive or constructive. And so coherent errors are funny that way.
00:51:50.034 - 00:52:01.154, Speaker B: But what randomized compiling does is it reduces the error across the board, and it creates stable performance in an otherwise very unstable environment.
00:52:02.254 - 00:52:07.834, Speaker A: All right, just a heads up. We want to leave a few minutes for questions to wrap up by two.
00:52:08.174 - 00:52:31.946, Speaker B: Great. So let me just skip this piece. You saw this data already. Here's where I walked through the earlier data more carefully, and I just pretty much explained this, all of you. But now you can appreciate. So, with cycle benchmarking, you have this kind of Christmas tree of errors occurring on qubits that aren't in the action of the gate. And so, basically, RB measures this, which is very misleading.
00:52:31.946 - 00:53:01.184, Speaker B: The true errors are. The true errors are ten times bigger, and they're not seen by RB, at least, certainly not isolated RB. I talk more about. Okay, skip that. Boom. So, in terms of tools for assessing these error diagnostics, the point now being that cycle benchmarking recovers the errors in this stochastic picture. I've tried to convince you with randomized compiling, those are the errors relevant to the in vivo performance.
00:53:01.184 - 00:53:45.482, Speaker B: There's this tool called symmetrized error characterization, which we proposed back in 2007, which really imagined some abstract error channel. You could look at some correlations. It was efficient and scalable. Steve will tell you later about an implementation he did with Robin Harper and Joel Wallman, which they called efficient learning, that looks at errors averaged over all the gates. So it's not giving you the errors associated with particular gate combinations. It sees some, but not all, correlations. And I'm really going out of my way to make this point, because for reasons I don't understand, in their paper on the archive, they imply they get all error correlations, which is not the case, and it's questionable whether it's really an efficient implementation.
00:53:45.482 - 00:54:11.280, Speaker B: But the point is, the data I just showed you today, and the tool I described today, identifies all relevant correlations. It identifies them for any gate combination of interest, and it's efficient and scalable. So we think it's the right tool going forward. I think, in the interests of time, I'll skip this. This is on the five qubit chip. We look at the, at the aggregate error. So these five qubit chips are in this t design.
00:54:11.280 - 00:54:40.680, Speaker B: And here we do a Cnot gate on this pair. In the second column, we do a cnot gate on another pair. Over on the right hand columns, we do parallel cnot gates, two different combinations of parallel Cnot gates. This is actually an exhaustive set of all two qubit gates and gate combinations you can apply on their five qubit chips. Burlington, Essex, London. We did it twice on Urenz and Vigo. And what you see is just very different error profiles in the aggregate error for each of these gate combinations.
00:54:40.680 - 00:55:36.234, Speaker B: What this allows us to do is predict. Now, imagine you're going to run a circuit, an application like Bernstein, vasarani, or hidden shift. You can break that down into a set of distinct cycles, and then you can use cycle benchmarking to understand the error rate of each of those cycles, the global error rate, and then to understand how that algorithm performed. Now we can just have a lookup table, and we say, here are the errors associated with each of these gate combinations. Now, we can just add them up stochastically and get the total error budget under that application. And so here, what we're doing is projecting how well each of the devices can perform an application based on doing the cycle benchmarking to characterize the errors on each of the allowed two qubit gate combinations. And so you see the various devices, out of all of these, which one is it? I think Vigo is by far the best.
00:55:36.234 - 00:55:45.554, Speaker B: So it has a. So what? We call it the QCAP bound, the capacity of the hardware to run the algorithm. And I think I'm running out of time, so I'll take some questions. Thanks for your attention.
00:55:49.414 - 00:56:13.746, Speaker A: All right, questions. You can raise your hand. All right, we had one in the q and a box. So, can you comment on how non markovianity changes the performance? Are there any indicators in cycle benchmarking that hint to the existence of non markovian errors, even though we can't completely characterize them?
00:56:13.930 - 00:56:58.294, Speaker B: Yeah, it's true. So look. So it can detect non markovian errors as follows. When you do a cycle benchmarking experiment, you would typically, you know, you repeat that thing m times, if you remember from my older slide, and I don't show any raw data for this, but you do this m fold combination of the repetitions of the gate and what that will do. If the errors are markovian, that will produce an exponential decay. So if your fit does not fit an exponential, if your data does not fit an exponential, we know for randomized benchmarking, and we haven't proven rigorously for cycle benchmarking, but I see no reason why we couldn't push it through. Just a bookkeeping problem.
00:56:58.294 - 00:57:43.004, Speaker B: If you see a deviation from an exponential that tells you that you have non markovian errors. Now that said, it's a one sided test, so there will be some non recoving errors that can be hidden. So you'll get a good fit to an exponential for your various poly's you sample, and you could still have non recovine errors that you're not witnessing through the failure of the fit. So if the fit works, you may have residual non recovine errors otherwise. But I think the natural thing to do is to do something similar to what BBN did, which is to combine this with GST or something and actually characterize how they have a good non markovian flag test in GST. And so you could look at that that way.
00:57:51.664 - 00:58:19.394, Speaker C: Joe. Yeah, thanks for the talk. So kind of, I'm still trying to wrap my head around when you say that when you run this poly randomization, it kind of suppresses the coherent errors. So is it somehow kind of virtual in the way this error suppressed? Like, it's not, you know, physically it's not really being suppressed. Right. So what does it mean? How should I understand what's happening?
00:58:19.474 - 00:58:46.000, Speaker B: Yeah, it's actually. Yeah, it's a bit mind bending. Let me try to give you an analogy with classical physics. It's astonishing how much of all this can be understood just by thinking about vectors in three dimensional space. So if you're trying to rotate a vector by 90 degrees and you have a coherent error, so you instead, you rotate it by 91 degrees. And here I'm just talking about cartesian spin. Now, what randomized compiling does is it basically virtually flips the process.
00:58:46.000 - 00:59:22.432, Speaker B: So you wanted to rotate about the y axis. You want to rotate x to z. You rotate by 91 degrees instead of 90. Now the point is instead of doing that, you can. What's the right way to think about this? I'm probably going to screw this up, but you might see the right way to explain it. The idea is by doing, say a flip of the problem around some axis, you're going to be able to effectively, when you average over runs, you'll have a cluster of vectors around the x axis differing by one degree. Around the z axis different, but around different, the errors will be different.
00:59:22.432 - 01:00:06.304, Speaker B: You'll have a cone of errors around the intended vector through inserting random gates. So instead of doing exactly a 90 degree rotation about y, instead you apply a bit flip before and after. And then I'm screwing up the example. But the upshot of this is that you see that you will have a cone of vectors around the target vector when you average over runs. And then the average over that cone is what you measure. And the average of the cone will be a shortened vector. So the effective noise will be a depolarized vector, an attenuated vector that is actually exactly on axis statistically.
01:00:06.304 - 01:00:09.416, Speaker B: You. Can I see it now? Yeah, yeah, I think I see.
01:00:09.520 - 01:00:23.518, Speaker C: So in each run, it's not that the error has been suppressed, but you're kind of making the error go in different directions. You're sort of forcing the error to go in different directions and they average out to some non coherent error.
01:00:23.646 - 01:01:02.176, Speaker B: Another way to think about it is if you look at a rotation matrix in three dimensions, you have cos theta, sine theta minus sine theta, cos theta as your two by two matrix in your three dimensional space. And then, and then basically with randomization, you're essentially turning theta to minus theta half the time. And so then when you average the channel by straight statistical averaging, half of them will be sine theta, the other half will be minus sine theta. So the diagonals stay the same. So think of theta as the errors that one degree error. So half the time you have sine theta, half time you have minus sine theta. That attenuates the off diagonals but leaves the diagonals the same.
01:01:02.176 - 01:01:10.864, Speaker B: So that's the sense in which you remove a coherent error by just seeing its diagonal component, which is the coast theta term.
01:01:11.244 - 01:01:13.104, Speaker C: I see, cool. That was very helpful.
01:01:16.564 - 01:01:32.348, Speaker D: Joe, this is Robin. Quick question. Thank you for a nice talk. I had a question about the slide where you showed a bar chart of different weight errors for the ion trap experiment.
01:01:32.476 - 01:01:33.184, Speaker B: Yeah.
01:01:33.604 - 01:02:06.552, Speaker D: And I. Yeah. So you say here that the hard round is the identity operation. And usually in an ion trap, identities are really good. And I'm surprised to see any wait for errors. I mean, if this was a Mulmer Sorensen round or something, I could see weird things happening, but these are usually amazingly good gates.
01:02:06.728 - 01:02:54.656, Speaker B: Yeah. So that's a great question. And so we've talked with them about that. So there's two solutions. One is a failure to suppress the vibrational modes, which are always present, but you're trying to suppress them. The second, I think the dominant effect here is that the way that the Innsbruck group does its single qubit gates is they apply a global x, and then they use individual z gates, and then they use z gates to either mod out or manipulate the local gate to not be an x. So, in other words, the way they do independent single qubit gates is they do a global x gate followed by independent z gates on each qubit, followed by another global x gate, followed by another set of independent z gates.
01:02:54.656 - 01:03:14.764, Speaker B: And in that way, you can get what's mathematically independent su. Two rotations on each qubit using the usual Euler formula. What's it called? Yeah, but they're actually using global control to do independent gates. So I think that's probably the dominant error. Does that make sense?
01:03:16.624 - 01:03:26.374, Speaker D: I think it sounds like what you're saying is maybe the errors you're seeing here are actually produced by those single qubit Pauli twirling gates, not by the hard round itself.
01:03:26.954 - 01:03:38.234, Speaker B: Oh, sorry. Yeah. Let me. Let me just be clear about the terminology. So what the errors you're seeing are the errors on addressed hard round. And. Yeah, you're exactly right.
01:03:38.234 - 01:04:23.662, Speaker B: So here, if the hard round is identity, the dressed hard round includes these random polys. But now to do the random polys. So you're actually seeing the errors just on the random poly. So, yeah, probably didn't explain that super clearly. So the errors you saw there were just on iid, random poly gates on each qubit. The reason why we see these high weight errors in their system is partially because of vibrational modes that haven't been suppressed, partially because of the fact that they do iid in the individual qubit rotations via a global x gate. And therefore, you know, they will have kind of global fluctuations that will affect all the qubits simultaneously, even though they're only trying to do independent gates does that.
01:04:23.662 - 01:04:24.286, Speaker B: Yeah.
01:04:24.350 - 01:04:25.754, Speaker D: Okay, thanks.
01:04:29.334 - 01:04:31.678, Speaker A: All right, well, thank you, Joe.
01:04:31.806 - 01:04:35.494, Speaker B: All right, thank you. Thanks for organizing this. I really appreciate it.

00:00:01.160 - 00:00:55.918, Speaker A: Ladies and gentlemen, I've always wanted to have a paper that is so short it can fit in one or two pages, because then when you print it, your paper is actually just one paper. And to get us such a paper, what you need is a result which is interesting, so it can be published somewhere, but you also need an extremely clean proof of that result that can fit in two pages. And I'm very happy to say that this result that I'm going to talk about today is exactly such a result. We have a paper that is actually longer than two pages, but that's because we wanted to have like a complete paper with introductions and decent coverage. But if we wanted, we could have actually just published this paper as one paper with the result and the proof in it. So let's see this. The result is about streaming algorithms for Boolean CSP's.
00:00:55.918 - 00:01:44.860, Speaker A: And I will start by defining constraint satisfaction problems, or CSP's. I will define these problems using this sudoku puzzle that is very famous. The point is, you have nine times nine grid of cells, with each cell having a number between one and nine. Some of these numbers are there already, and in the blank cells you have to insert a number between one and nine that each row, each column, and each three times three square is all unique numbers between one and nine. In other words, each row, each column, and each three times three squared is a permutation or has distinct numbers between one and nine. And the reason this is a CSP is because you can look at all of these blanks as variables. Let's say you have n variables.
00:01:44.860 - 00:02:13.124, Speaker A: You can have one constraint function, f. That captures the fact that it takes nine arguments, and it captures the fact that all the nine arguments are distinct. And you can define clauses using that function. So one clause is, for example, f, applied to this set of nine variables in this column. And you can also apply f to this row. You can apply after this square. You have many clauses like this, and you can write this pseudo two puzzle as the set of clauses.
00:02:13.124 - 00:02:53.662, Speaker A: And a solution to the Sudoku puzzle is just an assignment to these blanks or the variables that satisfy all of these clauses. Of course, some of these are fits, so some of the clauses have fixed constants in them. This is a CSP, but it's actually slightly different from what we will use in our paper. Our CSP's will not take values over nine, it will just be Boolean. So the values are zero, one. And moreover, we will not be interested in finding an assignment that satisfies all the clauses. Instead, we shall try to see what is the maximum number of clauses that can be satisfied by any given assignment.
00:02:53.662 - 00:03:35.744, Speaker A: So two differences. One is Boolean. So of course you have a variable and its complement. And second difference is, instead of finding an assignment that satisfies all the clauses, you want to find the maximum number of clauses that can be satisfied by any assignment. We want to do this using a streaming algorithm, which basically is an algorithm that gets as input a sequence of all the constraints. So you have these three bots constraint, you have two row constraints, you have these column constraints. These are presented at the algorithm in some arbitrary worst case order, and the algorithm gets to make p passes for a parameter p over this, a sequence of constraints.
00:03:35.744 - 00:04:19.034, Speaker A: Now, we want our algorithm to have low memory, because we don't want the algorithm to just remember the entire sequence. We want it to actually make all these passes and then compute the output. And we want to know what is the smallest amount of memory or the smallest space usage that a streaming algorithm with p passes can have. We will always think of p as, let's say logarithmic in the number variables, so it is not very big. And we want to know what is the smallest amount of memory that an algorithm with p passes can have, and find out exactly the number of clauses, the maximum number of clauses that can be satisfied by any assignment. This is the problem, and it's a natural problem. So there is a lot of work on it.
00:04:19.034 - 00:05:02.066, Speaker A: And one thing that we know is that for all non trivial functions, f non trivial, meaning, for example, it's not the function that is always one, so it's always satisfied anything that is not trivial. In that sense, you need memory, and you want to know the answer exactly. You need memory that is at least omega n over p. Again, p is log in. So this is basically omega n for the exact solution. We do not know whether or not this is tight, but we do know that if you relax this requirement to a one minus epsilon approximation, you still need almost linear space. You need enter the one minus epsilon space if your function f is the mat step function.
00:05:02.066 - 00:05:28.476, Speaker A: For other functions we do not know. This is what we know. And there has been other work on Csp's that I have not covered in this table. But the reason is all of this other work. It focused on getting the right approximation factor. It restricted attention to single pass algorithms, and it wanted to know for each CSPF, what is the exact approximation factor above which it is hard and below which it is easy. We take a different direction.
00:05:28.476 - 00:06:21.484, Speaker A: We instead want to work with multipass algorithms. We want to work with dpass algorithms and we want to know exactly, remember, this is not type. We want to know exactly what is the amount of memory or space required for such an algorithm to solve CsT exactly and approximately. This is what our result is about. We want to show tight space bounds for multipass algorithms and we show a result for each of those two lines for, again, for all p and all non trivial f, where non trivial means something here. It also means something precise here for exact solutions. If you have a p pass algorithm, then you basically need n to the degree of f space, where degree of f is the degree of the function f when it is written as a multilinear polynomial over the reals.
00:06:21.484 - 00:07:09.446, Speaker A: For example, if you have the function and of two variables, then the polynomial will be x one times x two, and therefore the degree will be two. You can do this for any function and we show that for any p and for any non trivial f, the space required to solve cst for f exactly is n to the degree of f. This is for exact solutions for approximate solutions. For one minus epsilon approximate solutions we had a result for Mat Scott and we show that that result actually extends to all non trivial CsP's. If you have any non trivial space CspF and you have a p pass algorithm, then you need almost linear n to the one minus epsilon space to approximate it within one minus epsilon. These are the two results. They complete the picture.
00:07:09.446 - 00:07:47.254, Speaker A: And I will only talk about the proof of one of these results. Most of the ideas actually extend to the other one. So it is actually like, it is easy to just focus on this result and the other one will be very similar. And I will prove this in two steps. I want to prove that for any function f, any streaming algorithm with ppass format cspf dates into the degree space. And to do this, let us first see where is this end to the degree coming from. Why is this degree term appearing in this theorem? And for this let us try to understand some approaches for solving this function f.
00:07:47.254 - 00:08:17.804, Speaker A: Take a function f. Let's say it has k boolean variables and it has a boolean output. And first note that because you only have k different variables, the number of different constraints that you can have in your CSp is only into the kitchen. So you can actually capture the entire instance by keeping n to the k counters, one for each different type of constraint and just seeing how many times it appears in the sequence. Maintaining this many counter states enter the k space and with this space you have the entire sequence. So you can compute anything, you can solve the problem. Exactly.
00:08:17.804 - 00:09:15.194, Speaker A: Now, this bound is clearly not tight, because what may happen is, for example, you have k variables in f, but actually it is just a function of one variable. The other variables are just placeholders. And by this exact argument, we know that the space required for such a function is actually not k, it's n to the k, it's actually much smaller, and therefore something better is possible. But exactly how better? I claim that again, if you write f as a multilinear polynomial over the reals, and you see its degree, then you have a solution that takes n to the degree space. Why every time you see a clause, let's say a clause is x one and x two and x five, you, instead of recording this clause, you record the corresponding polynomial. So here the polynomial will be x one times, because of the negation one minus x two times x five, this polynomial will have degree degree of f. Let's say three here.
00:09:15.194 - 00:09:35.654, Speaker A: Therefore, it has at most n to the degree of f, different monomials. And you can record this polynomial by using only n to the degree of f counters. This again has all the information that f has. This remembers the entire instance. And therefore, by using n to the degree of f counters, you can solve it. Exactly. And this is a better solution.
00:09:35.654 - 00:10:23.644, Speaker A: It's not really much better, though, for many functions. For example, if f is and then degree of f is k, so these are actually the same solution. It's not that better. Can we do something that is much better than n to the degree or into the k? And our results shows that actually, no, this enter the degree of solution, which is enter the degree of f solution, which is so easy, is actually tight, you cannot do anything better, even with p passes. And the argument for this is two steps. First, you show that if first, you assume that you cannot do anything better for the function f equals and, and you show that this implies you cannot do anything better for any function. And the second part is that you actually show your assumption.
00:10:23.644 - 00:11:18.776, Speaker A: You show the lower bound for the and function, and we will take those things separately. So for the first one, I want to show that any function f reduces to the and of add td v of f. And for this I have to show that if you have an algorithm for max cspf for any function f, then that algorithm will also solve max and f, where the arity of and is equal to the degree of f. To show this, it is sufficient to show that you can write the and of, let's say two variables. This will be approved by examples I will work with only and of two and of two variables as a set of clauses for any function or even any polynomial that has degree two. How do we do that? Suppose you want to write the and of two variables. You want to write x on x two, and you are given this weird polynomial that is not x one x two.
00:11:18.776 - 00:11:56.452, Speaker A: I claim that you can still write and of x one, x two, which is x one times x two, using just this polynomial. The way you do this is you write this polynomial twice. So you get two times p of x one and x two. This is twelve x one x two minus four x one. And you also write a corresponding constraint with x two set to the fixed value one. The value of this polynomial is actually just six x one minus two x one which is four x one. And therefore the sum is twelve x one x two minus four x one plus four x one which is equal to twelve x one x two.
00:11:56.452 - 00:12:36.602, Speaker A: And what you are able to do, whatever you were able to get here, is you were able to write this and function as just the p using just the three p clauses, p of x one, h two twice and p of x one gamma eleven. This means that if you, if you have an algorithm for p, then you also have an algorithm for and and therefore it can reduce to and for general functions p or polynomials p. We have the same high level idea. We have one high degree term that we want to keep and we want to eliminate all the low degree terms here. We are lucky because you just have to add px one, comma one. But in general, you may have to subtract it. You may have more constant weights here.
00:12:36.602 - 00:13:14.806, Speaker A: But all of that can be done because if, say, if you want to subtract something, you just write x 1 bar and that makes the sign different. And again, you will be able to subtract it while actually having a plus here. So you can write a sequence of p that eventually you get and, and this is why you can reduce any function f to and of degree of f variables. And this is the first step in the proof. The second step in the proof is to actually show a lower bound for and we want to show that if you have an and function of k variables, then you need enter the case space for it. And in fact, we will show it for the or function. It's the same proof of word for and, but it will be easier to work with or here.
00:13:14.806 - 00:13:49.834, Speaker A: And the way we will show this is by showing that disjointness can be reduced to this or problem. We know that disjointness requires high communication, so it's also hard in streaming. And once we have this reduction, we also get that the or function is hard in streaming. What we need to show is we need to take a disjointness instance, which is defined by universe U. Alice has a set that is contained in U. Bob has a set t that is contained in U. And they want to know whether or not these sets s and t are disjointed or are they intersecting.
00:13:49.834 - 00:14:39.778, Speaker A: We know by standard lower bounds for disjointness that the communication required, or the memory required for a streaming algorithm to solve disjointness is actually just the size of U. Even if you're promised that either s and t are disjoint, or they intersect in exactly one set, this is the lower bound that we shall use. And for the reduction, I will show that if you have an algorithm that solves a CSP for or on n variables, then you can use it to solve disjointness on k size subsets of n. The size of this universe is n to the k. So you get your n to the k lower bound. And the reduction is the following simple set of steps. First, Alice takes her set of k size subsets of nice.
00:14:39.778 - 00:15:10.122, Speaker A: And for each case size subset of n that is not in her set, she adds the or of those variables. Bob does the same. These are some clauses that we can add. And if you look at these carefully, these clauses basically want as many variables to be one as possible. As soon as your variables are one, more and more clauses like this are satisfied. And if all of them are one, then all of these are satisfied. The other set of clauses that you add, you will actually want variables to be zero.
00:15:10.122 - 00:15:47.624, Speaker A: And this set is just, you want to add xi bar for all I and n. This is the same variable k times. So it's actually just xi bar. And this basically means all variables should be pushed towards zero for these clauses to be satisfied. Now, why does this reduction work? The reason this works is you have this force that is pushing all the variables to be higher towards one. You have this force that is pushing all of these variables to be lower towards zero. The first force is actually much higher, much stronger than the second one, because this has all subsets of size k.
00:15:47.624 - 00:16:19.510, Speaker A: This has n to the k potential possibilities, and this only has n. So this force is actually much, much stronger. And your default solution would be to set all but k minus one of the variables to be one, and those k minus one will be zero. What this will achieve is anything that has k constraints will have at least one thing, that is one, because there are only k minus one things that are zero. So everything like this will be satisfied. And also k minus one of these will be satisfied, which is the largest possible. Because you want this force, you know this force is stronger.
00:16:19.510 - 00:16:56.364, Speaker A: So you want, you first want to maximize this, and then you want to maximize this. Okay, this is the default case. But observe what happens if Alice and Bob actually have an intersection. If there is a set s that is in both the sets, then, because it's in both Alice and Bob sets, none of them added the clause or corresponding to that one set. And that means you can actually set k variables to be zero, which is all the variables in that set. And this will still satisfy everything here. But now it satisfies one extra thing here.
00:16:56.364 - 00:17:25.924, Speaker A: And determining whether or not this one extra thing can be satisfied is exactly solving whether SRt are intersecting in one location or are they disjoint. This we can write, we can write out the numbers, it will exactly be. This one extra thing is the answer of disjointedness. And therefore a CSP algorithm for r can also be used to solve disjointness on this universe, and therefore it needs space that is at least into the game. This finishes the proof and also finishes the talk. Thank you.

00:00:00.160 - 00:00:03.234, Speaker A: On markets and incentives for personal information.
00:00:04.414 - 00:00:54.444, Speaker B: Thank you, guys. You've almost made it to the end of the week. I appreciate those of you who are still standing at this point. So, as I mentioned yesterday, this is a continuation that is fairly separate from the talk I gave yesterday. If you were not here yesterday, it's fine. If you were here yesterday, you can just use the data co ops idea sort of in the back of your mind to motivate some of the questions that we'll be talking about today. So before I start to get into the economic ideas that I want to discuss in this two part discussion today, I want to step back a little bit and have us ask ourselves why we're studying privacy in the first place.
00:00:54.444 - 00:02:06.054, Speaker B: And I suspect if you do that exercise for yourself, at least part of the answer will be that you believe that good privacy protections or a good understanding of privacy can help us increase the welfare of individuals and or the welfare of society. Do you think that you're making people better off or society better off by understanding these issues or providing technology to support privacy? And there are a number of different ways that you might think that you're making individuals or the world better off. Perhaps it's because you're reducing informational harms. Perhaps you're enabling access to valuable data with new technologies. Maybe you're predicting what you see as sort of a fundamental data. Right. Whatever it is, though, I want to point to sort of the reason we're doing this, at least I suspect for many of us, is at least in part because we think we're making something better.
00:02:06.054 - 00:04:21.148, Speaker B: And that's basically the motivation for the talk today, because economics provides a rich toolkit for understanding questions of welfare, for quantifying and thinking concretely about how we make things better. And so if we're going to introduce privacy technologies that will maximize or improve welfare for individuals or for society, there are a lot of things we need to understand to make sure we're really achieving those goals. So we need to think about what is the value provided to individuals from our privacy intervention? What are the other impacts of these privacy interventions in these technologies that we're suggesting? For example, are we increasing access to data, reducing access to data, introducing new social norms, giving people an increased sense of control, increased saliency of privacy concerns, which could be good or bad? And we have to think in some way about how people and society might behave in response to the new technologies and the new ideas that we introduce, because privacy is a significant enough thing that it's not something that you can address locally. You can't take the current data landscape in the current world we live in, come up with a privacy preserving technology, and implement it here without it having effects that ripple throughout our lives and throughout society. And so it's important to acknowledge that and to realize that there are some tools for trying to think about the impacts of introducing technologies and how the entire system might change. So all this talk about value might make some of you uncomfortable. Why are we going to now talk for 2 hours about things like value, or even something dirty like money? We wanted to live in this pure world of privacy, and then I come along and talk about value.
00:04:21.148 - 00:05:43.170, Speaker B: So there are good reasons why you might be made uncomfortable by this attempt, this exercise of translating everything to the language of value. But I want to argue that it still may be a really useful tool. So why do we talk about value? Well, by translating everything to value, by talking about the value of the information, the value of the privacy, the value of the intervention, we put everything in one denomination, so then we can talk explicitly about overall effects and about trade offs. Of course, it's complicated. When you reduce a complicated system down to a single dimension, you lose something. And I agree with that objection that you may be feeling, but it still may be useful, and it's certainly simplifying. But yes, beyond that, also, in the back of your mind you're probably thinking, this is problematic in other ways, moving this to the language of value and money, isn't this making data a commodity in some way that I should be uncomfortable with? Is it validating or normalizing privacy losses that I don't want to validate or normalize? Maybe let's try to save those feelings of discomfort if you're having them and discuss them later on.
00:05:43.170 - 00:06:29.894, Speaker B: But I want to say that this is still hopefully a useful tool, even if you're simultaneously uncomfortable with some of the way of thinking about things. So before we leap into the talk, I want to give you a few caveats and then tell you what I'm actually planning to do for this talk. So the first caveat is, I'm going to talk to you today about all sorts of economic tools that I think are really useful for people who think about information and privacy. But I'm not an economist. I don't even play one on tv. I am someone who has spent time thinking about economic issues. I've written economics papers, I've read economics papers, I've been to a lot of seminars and talked with a lot of economists, but I'm still not an economist by training.
00:06:29.894 - 00:06:55.374, Speaker B: It's very likely that there are some of you in the audience who have significantly more economics background than I do. Please share that. So if I'm discussing a literature and you know more than I do about it, please speak up and share your insights. But I do have some exposure there. But I'm not passing myself off as an economist. The other thing that I should tell you is that this is sort of a strange talk that I'm trying to give you. It's not really a survey talk.
00:06:55.374 - 00:07:31.704, Speaker B: It's sort of a tasting menu. My goal is to expose you to a wide variety of ideas and literatures and techniques and vocabulary that I think are really relevant to those of us who think about privacy and data. But I'm not going to cover an entire literature by any means. I'll sample things that I think are worthwhile for all of us. But this should be the beginning rather than the last word. So hopefully I'll get you interested in reading and thinking about these ideas and getting more exposure.
00:07:32.364 - 00:07:40.724, Speaker C: So economists are not the only ones who think about value, right? I mean, don't you think, you know, scientists also think about games and value and options?
00:07:40.844 - 00:08:18.964, Speaker B: We do. We do. And then that's a, and I count myself at least 1ft in the algorithmic game theory community. But computer scientists coming up in that community generally have not gotten nearly as much training in sort of traditional economic tools and techniques as somebody who's a real economist. So I still think it's important to make that decision. That's not the formal academic training that I have the plan for the 2 hours that we have together. So the first thing I'd like to do is to basically walk you through a series of vignettes.
00:08:18.964 - 00:10:08.214, Speaker B: Basically, these are important papers and ideas in economics that have some relevance to information and sometimes privacy in particular. And I view this as sort of a basic literacy that we all ought to have, is we all ought to know some of the really most important ideas, some of the Nobel Prize winning ideas that relate to information, if we're going to go out and try to change the way that the world interacts with information. And so I'll go through this sequence of papers and try to relate them to the things that we think about and put them in some context there. The second thing that I'm going to do is then talk a little bit more specifically about data and privacy and the ways in which it does and doesn't act like the usual sorts of goods that economists like to talk about, sort of try to understand what work is left to be done in the space of thinking about privacy as something that you might offer, guarantee, buy or sell. Then I'm going to move to talking about a literature, much of which is actually in sort of the theoretical computer science and differential privacy community, um, but not all of it, on how we think about the value that individuals might get from privacy technologies, and also on relating specifically differential privacy to a number of economic ideas. I'll talk then briefly about how we can start to quantify the effects of privacy preserving technologies on society, so the broader impacts. And then at the end, I want to share a couple more vignettes of sort of other lessons from economics that are not necessarily specifically information related, but I think that are really important for those of us who are, whether we like it or not, designing mechanisms.
00:10:08.214 - 00:10:56.904, Speaker B: Okay, so that's the plan. Let's start with this sort of series of vignettes in the space of economic ideas that relate to information. And before I start, I want to mention that most of the papers that I am going to mention here, and many, many, many more, are covered by a lovely, lovely survey article of Equisti, Taylor and Wagman. I really highly recommend this for anybody who's interested in this space. You could use this article as the basis of a fantastic semester or longer course or of a reading course. It does a very nice job of organizing and laying out the ideas and providing all the references that you'd want in this space. Of course, this space is an active one, so it doesn't cover everything, but it's a very nice survey.
00:10:56.904 - 00:12:24.578, Speaker B: So, one of the earliest economic works that I know of that talks about information is Stigler 1961. And this is sort of some first effort to think about what is, what is the role of information, which didn't really traditionally have a role in economic thinking up to that point. And the argument that he makes there is that in non centralized markets, so not a market where we all sort of come to the same place in order to exchange our goods with one another, but one, for example, the used car market, where you have, if you want to buy a used car, you have to expend some effort to find out what are the cars that are available that you could buy, and what are their properties and what are their prices. So a non centralized market, it takes effort to find out information about the goods that are available and their prices. And the idea is that the effort involved in gathering this information has economic impact. So if you search more, if you spend more time and effort in learning about the prices in the cars that are out there, then you'll find better deals for yourself. And so this is one of the first efforts that I know of to sort of quantify the role of information and information gathering in an economic way.
00:12:24.578 - 00:13:16.780, Speaker B: And he argues in this paper that it's very natural that specialized traders. So in the used car example, used car dealers exist, and that one of the roles that they play in a market is to reduce search costs. So this is an argument for why, um, informationally, you might see centralization of markets. And so I think already you see immediate connections to the kinds of things that we might be interested in when we're thinking about transacting on data, um, and arguments for why you might see centralized, uh, for. For, uh, for doing such interactions. The next sort of vignette that I want to share with you is Akerloff's very famous 1970 paper, the market for lemons. Probably many, actually.
00:13:16.780 - 00:13:54.410, Speaker B: I just want to understand, when I say market for lemons, who says, I've heard that phrase before, but I don't really know what it means. Who says, I've heard that phrase before, and I could tell you guys what it means. And who says that doesn't ring any bells? Okay, good. Like, all right, so we're in good shape here. All right, so the market for lemons, what's the idea here? The idea is that information asymmetry can actually have a really negative effect on a market in the following sense. It can reduce the quality of the goods that are for sale in the market. So what's the model here again? It's useful to think about used cars.
00:13:54.410 - 00:15:02.824, Speaker B: That's also what he talks about in the paper. So imagine we're in a world where there are some used cars for sale and some buyers who want to buy used cars. And some of the used cars are good peaches in the paper, and some of them are bad lemons. And if you're selling the used car, you have pretty good information about whether it's a peach or it's a lemon, you know, whether it actually got in accidents, you know, whether or not you actually did the required repair work, you know, whether or not the guy who hired the repairs just sort of tied stuff together with a little bit of metal wire or if he did the proper work. But if you're the one who's buying the car, it may be difficult or even impossible to really get information about whether this is a peach or this is a lemon. So what's the problem with this information asymmetry? So, information asymmetry just means the two different parties that involved in a transaction don't have access to the same information. So the problem here is that since the buyer has uncertainty about the quality of the good, the buyer is only going to be willing to pay something like the average or expected price of a car that would be in the market.
00:15:02.824 - 00:15:41.886, Speaker B: So I don't know if it's peach or lemon, but I have some estimate of the prevalence of peaches or lemons in the market. So I'll pay the sort of expected value. But then so what's going to happen to the sellers? Buyers are only willing to pay the value of sort of an average car in the market. But you know, you have a peach, so you're going to sell your peach for that price. No way you exit the market. So now what does the distribution look like? Well, the distribution of cars for sale in the market just got worse and the average value just went down. And so potential buyers are willing to pay less.
00:15:41.886 - 00:17:18.304, Speaker B: But then you who also have a PhD say, forget it, I'm not taking that lower price. You exit the market and you see this sort of natural process where the value of the items that's for sale in the market goes down and down and down, and the willingness to pay goes down and down and down. And this is a phenomenon known as adverse selection. And one observation which I haven't thought about deeply in any way is that you might actually see effects related to adverse selection when you have privacy protections that are opt in. So if instead of providing universal privacy protections, you have technologies where people have to choose whether or not they're going to adopt this protection, for example, they have to actually sign up for the do not call list, then you have an interesting phenomenon that you don't have the same distribution of people who are available to contact as you do on the do not call list. So this may have interesting effects and it may have sort of an effect on how people get targeted with advertising, because the distribution of people who didn't opt out is different than the distribution in the overall population, that may drive further more people to opt out. And so there may be sort of immediate implications of adverse selection for those of us who want to think about the design of mechanisms for people to get protections or to be present or absent from a market.
00:17:18.304 - 00:18:19.414, Speaker B: The next vignette that I wanted to share with you is Spence's 73 market signaling paper. What's the idea here? What's the role of information that's going on here? So here information is showing up in the form of a signal. And what's the signal in the model? So Spence is looking at the question in some sense of why do people go to university? Takes a lot of time, effort, money in some cases. Why to go to all that effort? One traditional economic explanation for why people might go get PhD. What were we thinking? Why would people spend all of this time on this? Is because it makes them better workers, more productive, more able to make money later on. That's a traditional economic explanation. And spends offers an alternative explanation which says, maybe it's not all about making yourself a more productive worker.
00:18:19.414 - 00:19:18.044, Speaker B: Maybe some of it is about signaling that you are capable. And so what's the idea of the model here? The idea is that maybe it's just easier for people who are capable workers to get university degrees. And so the fact that you got a university degree is evidence that you're a capable worker. It doesn't actually make you a more capable worker. And this idea of costly signaling is one that has gotten a lot of attention, a lot of recognition. And one of the interesting things that happens in a lot of these systems is that you see in many cases that the aggregate cost of signaling activity might outweigh the benefits of it. So you have to decide how you want to design your model and how much going to university is actually good for society and how much it's just sort of a waste of people's time and money.
00:19:18.044 - 00:19:38.654, Speaker B: But you can set up versions of this model where people are wasting a lot of effort on signaling to each other about their abilities, where if they could actually just sort of credibly certify their abilities without having to go through all the effort of going to university and paying for it, that might actually be better for the system.
00:19:38.994 - 00:20:00.894, Speaker A: Does this also apply to, like, cost in terms of. I'm thinking about, like, Yelp super reviewers who, like, somehow have refute every restaurant in the city and then gets very. It's like a giant waste of time to me, but it's also costly as an activity and kind of signal to other people. So I'm just wondering how this interacts with crowdsource systems in more modern terms.
00:20:01.394 - 00:20:42.902, Speaker B: Yeah, so it's like, good question. So I don't know of a literature on crowdsource systems that uses this signaling model, but that's because I don't know that literature. It doesn't mean it doesn't exist. But the basic idea here is that there's information about you that you want to provide to a future employer or to somebody, but you don't have a way to credibly certify that information. You can't just do a blood test and hand over that information. So you have to do something else that correlates with that information. And doing that something else that correlates with the information is really expensive.
00:20:42.902 - 00:20:46.554, Speaker B: So I don't quite see the analogy in the Yelp world.
00:20:47.334 - 00:20:53.314, Speaker A: So I could also turn out a bunch of papers in order to get citations to improve my reputation.
00:20:54.014 - 00:21:29.550, Speaker B: Yeah, but the key idea is that the costly, in order for this model to make sense, the costly signal has to be correlated with the ability to produce the costly signal, or the cost that you incur in producing the costly signal has to be correlated with your ability. So it has to be easier for good people to produce papers. And so you could think about publications. Maybe publications are costly signals. Maybe what we really want to do at some level is just tell everybody that we're really smart, but we don't have the ability to do that. But the ability to produce papers is correlated with being really smart. So we go around producing papers.
00:21:29.550 - 00:21:34.914, Speaker B: You can tell that story. It would be a similar story. I don't quite see the Yelp connection, but maybe it's because I haven't thought about it.
00:21:35.934 - 00:21:39.074, Speaker A: The cost not being like paying for a degree, but sort of.
00:21:39.414 - 00:21:52.146, Speaker B: Yeah. So cost can definitely be in terms of time, effort, money. Economists like to do that. Dimension reduction. So we put everything in the same language. Yeah. Other questions about signaling, I should say.
00:21:52.146 - 00:21:54.458, Speaker B: I don't have signs about this. Oh, yeah, sorry. Go ahead.
00:21:54.586 - 00:22:01.050, Speaker C: So, I mean, this assumes that you don't actually learn anything in university. There's only a signal. Right?
00:22:01.162 - 00:22:57.874, Speaker B: So the extreme model says that the university degree is just about signaling, but you can, of course, write down a more sophisticated model that says the university degree is in part about actually getting useful, you know, techniques and ideas in your head and develops your abilities and your productivity as a worker. But it's also in part doing signaling, and it's also in part doing something else. But what you see in a lot of economic modeling is sort of the first model really pares things down to the simplest possible scenario where you just see a single phenomenon and then later work in the space, incorporates other phenomenon and comes up with more sophisticated models. So this is not to say that Spence actually believed that university education was completely useless. This is to say, Spence thought this was an interesting setting in which to illustrate that there may be something else going on. Yeah. Other questions about signaling.
00:22:57.874 - 00:24:25.024, Speaker B: So I should say, I don't have slides on this, but signaling has gotten sort of a resurgence of interest in economics and actually also in computer science. But usually most of the signaling I see these days is sort of a slightly different type of signaling. Instead of this costly signaling, we see a lot of literature these days on what's known as bayesian persuasion. And the idea there is there are lots of settings where there is a single mediator of some sort who acts on behalf half of a population and has the ability to signal on behalf of that population. So an example that gets used is there might be a prosecutor who represents many different clients before a judge, and the prosecutor has the ability to present to the judge sort of selective information about their clients, or they can even sort of explicitly say, guilty, not guilty is encoded in their interaction. And what we see in the debate and persuasion literature is sort of an interesting attempt to understand how an intermediary's presence can affect who gets convicted and who doesn't. And there may also be an interesting connection for us to think about in the privacy world.
00:24:25.024 - 00:25:23.104, Speaker B: The first big introduction of privacy explicitly to the economic discussion that I'm aware of is this 81 paper of Posner. So Posner's argument is that the concealment of personal characteristics makes markets less efficient. So think of it as in an employment market. You want to get a good job. Employers want to get a good employee in order to figure out who's going to be a good employee. If they just knew everything they could know about you, it would be much easier to figure out if you're qualified for the job. But if instead we introduce privacy laws that they can't actually make you do all sorts of blood tests and produce all your criminal records and everything about yourself, they have less information, and so they have to expend all sorts of efforts in order to gather proxies for this information.
00:25:23.104 - 00:26:11.174, Speaker B: They maybe have to hire less effective employees than they would have otherwise gotten, these types of arguments. And so Posner's work predicts that, for example, laws that make credit history private will result in increased interest rates, which be a symptom of the market being less effective. And he tries this out actually sort of looking sort of at natural experiments where states introduced various laws that he considers to be sort of privacy preserving laws that should make markets less efficient. I should mention, I find this paper to be pretty non pc in some of the discussion that he uses there. So I apologize for pointing you to it. But it's an interesting paper. I think it's useful perspective.
00:26:11.174 - 00:27:10.494, Speaker B: He does argue in this paper that some forms of privacy protections do have economic benefits. So privacy is not all bad for the economy. So he gives examples that in situations where privacy can potentially increase the value of the information, it can prevent false information from being privacy. Regulations of various sorts can prevent sort of libel or false information from entering the market, which could be harmful to the market. And there's a recurring theme in economics of sort of the value of privacy, being that it makes communication more effective. And this relates directly to something Coby said at the end of his talk, makes communication more effective, because you don't have to be strategic in what you say and how you say it, because nobody's listening over your shoulder. And Kobe talked to us about, maybe we should think about a post privacy world, and what are the things that privacy was doing for us that maybe we can replace with other technologies? And I think this is a common theme that fits well with that.
00:27:10.494 - 00:27:17.214, Speaker B: If one of the roles of privacy is to make communication more effective, what are the things we can do with that happen?
00:27:17.794 - 00:27:32.398, Speaker D: Eavesdropping. Someone eavesdropping. What I see is, like, it's more effective because I'm treating everyone. My information about everyone is private, then any person is person x, and I'll treat them all the same. But why is eavesdropping.
00:27:32.566 - 00:28:17.874, Speaker B: So there's this concern in a world without privacy that you want to just be able to tell your doctor, I'm a smoker and I do drugs and I have all these other risks, help me make sure my health outcomes are as good as they could be. But if somebody's listening in and might do you harm from learning this information, then your communication with your doctor will be less effective because you have to say, you know, I was wondering if we could run this test just cause. I don't know why I'd have that disease. But there's an idea that you can try to make formal, that having concerns about sort of other impacts of the information that you want to transmit can reduce the effectiveness of that transmission.
00:28:18.274 - 00:28:31.774, Speaker D: So, another comment, just in general, like, all these papers are great, but I mean, like, economics come in all these different flavors. Like, some people have, like, just more like an op amp, and some people have, like, a model and theorem.
00:28:32.194 - 00:29:16.842, Speaker B: Yeah. Yeah. So this pos, the Posner paper actually is pretty weak on the model, but it builds on other things and relates to other things subsequently, where there are models involved. Almost all of the economic vignettes that I'm giving you are papers where there was a model that was very, very influential. And I'm going to talk very, very little about papers where there's significant data evidence and very little sort of empirical stuff. I think there are reasons for, and it's not because I avoided the empirical literature. I just found these to be sort of the, the most prominent, interesting, convincing, relevant types of papers tended to be the ones with a model.
00:29:16.842 - 00:29:38.326, Speaker B: That may be because that's more the language that I speak. But I think there's also, there are good reasons why it's hard to use data to argue convincingly about the value and impact of privacy interventions and the role of data. Yeah.
00:29:38.390 - 00:29:39.598, Speaker D: So this one has a model.
00:29:39.646 - 00:29:47.914, Speaker B: So this one has a small amount of modeling in it. Yeah. Yeah.
00:29:48.814 - 00:29:54.822, Speaker C: Firstly, I think you've been very polite when all you say about it is that it's pretty non pc.
00:29:54.918 - 00:29:57.742, Speaker B: Yes. You're familiar with this?
00:29:57.878 - 00:30:12.592, Speaker C: I am very familiar with this article, yes. Most people that I know in the, or in the privacy academic community think this is an absolutely horrible paper. And so I'm not going to.
00:30:12.768 - 00:30:13.080, Speaker B: That.
00:30:13.112 - 00:30:57.484, Speaker C: It probably killed interest among economists until I think, much more recently, where we've started seeing resurgence of interest among economists for doing much more sophisticated and much more interesting work in the area of privacy. But this was actually a terrible paper and it should actually be thrown into the dustin of history. And one more thing to say, and I think you represented it well, which is there was this law and economics movement. And so Pozna was one in particular. He maybe wrote one person, kind of another cluster.
00:30:57.524 - 00:30:59.984, Speaker B: Yeah, roughly the same as this one.
00:31:01.404 - 00:31:58.908, Speaker C: That these guys in ruined economics, basically they were so enthralled with this particular analysis that they went around and they wrote papers exactly like this one about every hard, deep societal problem because they thought you can solve every problem with this model, but they kind of picked and chose their examples. So what you were saying about the positives, that wasn't like people could benefit. They were saying, isn't it funny that privacy advocates are talking about individual privacy? And look, the only people who can really benefit are corporations. They could really benefit from not being transparent. Aren't these people turning the whole thing upside up? I'm sorry. I'm being very strong about it because I actually think that this paper did real damage to privacy thinkers because it was well cited. He was obviously a very influential, he's a brilliant guy.
00:31:58.956 - 00:32:20.192, Speaker B: I mean, you know, I, yeah, so I appreciate it. I appreciate this perspective and I think, I think it's useful as a, both as a historical perspective and. But I still think that people should go and read this paper. I think, I think it's, it. Okay, now you're going to go read this paper because it's so controversial. Think about what Helen would have said.
00:32:20.208 - 00:32:21.604, Speaker A: If this weren't being written.
00:32:31.144 - 00:32:35.284, Speaker B: You just killed the rest of this talk. It was only going to get better from here.
00:32:39.244 - 00:32:46.504, Speaker C: I'm being serious that I want this, Danita, because nobody asked me if you could report me.
00:32:47.284 - 00:32:57.396, Speaker B: Okay. I don't know the policies. It's being live streamed, but I don't know exactly what the technology is. But we'll discuss.
00:32:57.500 - 00:33:05.424, Speaker C: When I gave the talk, I signed the disclaimer. Yes, but I didn't sign the disclaimer for being part of this lecture.
00:33:07.474 - 00:33:42.994, Speaker B: We'll return to that privacy issue after we conclude. No, no, I did. Wait, we'll talk about it and we'll come up with a solution. So. Okay, so, yes, the next thing I was going to say was something more reserved, I guess, along the lines of, this was a very influential paper. I think it did convince a lot of economists that basically privacy is just sort of mainly a thing that gets in the way of economic progress. Information is useful.
00:33:42.994 - 00:35:00.804, Speaker B: Why should we let people conceal information? Of course, there were some counterarguments that emerged, but most of the work was for a while, I mean, basically stopped in this space. Counter arguments include that, you know, sometimes society benefits when individuals can select the optimal level for themselves of an embarrassing activity. So, for example, we actually really want people to go to drug treatment centers. And so maybe it's good if they can do that with some privacy. It's better for all of us. And then there have been a recent, I think, interesting related points in some recent papers arguing that when you reduce information in markets, for example, in job markets, that that can have sort of unintended negative consequences. So, for example, if we don't give employers access to information about criminal records or other things that they might want to have access to when deciding whether to hire somebody, they may, in response, rely more on statistical discrimination strategies.
00:35:00.804 - 00:35:57.278, Speaker B: So I don't know anything about you except your race. So I'm going to go based on my very biased priors about what people with your race do when they get hired into this role. There's more to be said here, but I think it's just interesting to connect back to the Posner paper. Okay, so then there's a break in time and in sort of perspective, there's a reason, as Helen said, that I'm going from 1981 to 1997 here. And it wasn't really until it wasn't. I'll make it make sense in a minute. It wasn't really until I economist realized, oh, hey, this Internet thing, there's something interesting going on here that they started to return to thinking about information and also privacy.
00:35:57.278 - 00:36:33.570, Speaker B: Of course, there are exceptions, but there was sort of a gap in the literature. And so there's this paper from 97, a. Varian, that talks about a couple of aspects of personal privacy. So one of them is from the perspective of the consumer. So say you're somebody who wants to buy a package vacation, and you're going around to various folks who sell package vacations. You don't want them to know exactly what your budget is, because then they will charge you exactly that budget. So you don't want to reveal full your willingness to pay.
00:36:33.570 - 00:38:00.294, Speaker B: You want some privacy there. But Varian argues, which you may push back against, that consumers may wish for some information about themselves to be known because they may wish to receive advertisements or offers that are relevant to their interests. And so if you're looking to buy a beach vacation, maybe you want the folks who sell that to know so they don't try to sell you a ski vacation instead. The work ovarian is one of the first ones that I know of that explicitly raises concerns about secondary uses of data and resale of data, which are really important points for us to return to. I mean, because these are aspects of data as a good, that make it different than a lot of the other things that economists are used to pricing and selling. And one of the things that gets discussed in this sort of literature that grows out of here is the concern that both the person about whom the data pertains and the person sort of initially getting access to the data and interacting with them, they can't anticipate the values and harms that might come from secondary uses of those data. And so that may not be properly accounted for in that transaction.
00:38:00.294 - 00:39:22.314, Speaker B: There is a literature that emerged, sort of around the two thousands, thinking about property rights for information, which is very relevant to the discussion that we sort of started yesterday. So there are arguments in this work that thinking about information as a form of property, it could be beneficial both to individuals and to users of the data. That sort of allows you to assign proper market based compensation using all the tools that we've already developed in economics. You know, isn't that nice? There are also very simple models that sort of relate to the property rights models that are introduced. They have some interesting and disturbing consequences. So, for example, under a simple model here, a monopolist who's offering personalized pricing to some people where they have data about them, and fixed pricing, if they don't have data about you as a customer, can actually convince all of the potential customers to give away their data for free because basically the marginal, anonymous consumer doesn't have any power in this market. And so there's sort of disturbing consequences potentially, when you look at some of these models.
00:39:22.314 - 00:39:52.696, Speaker B: Yeah. So sort of like once everybody is giving away their data for free, you can't get anything for your data either, is basically the argument. It's sort of a simplified version of this model. And so the, you being that last consumer who, who wants to stand up for your rights to sell your data, you have no power in this market as it's described. That's the argument there. I mean, it's a simplified model. You can argue for and against it.
00:39:52.696 - 00:39:56.912, Speaker B: But I think there are lessons for us, even in this simplified model.
00:39:57.008 - 00:40:14.140, Speaker C: I just wanted to recommend Chris Regan's book, legislating privacy, in which she has an argument about why privacy can't be, you know, it's a counter argument to say, why can't he distribute it as an individual?
00:40:14.212 - 00:40:31.672, Speaker B: Good, right. Yeah. Thank you. Yeah. Thank you for the reference. Yeah. And I think that's an important point, is that there is a literature sort of pushing back against this interpretation of privacy as a property and property rights for information and pointing out some of the problematic aspects there.
00:40:31.672 - 00:41:20.318, Speaker B: Yeah. Okay. Another place where we've all encountered the role of information in markets is price discrimination, which has been widely studied. I'm giving you just one pointer into a very, very large literature there. Some of the work that sort of is moving into the Internet era in this space suggested through simplified models, that perhaps consumers only need regulatory protection against price discrimination if they're naive about how the information about them can be used. Of course they're naive about how the information about them can be used. So even if you don't believe this model, you should take it as an argument that we do need regulation.
00:41:20.318 - 00:41:51.984, Speaker B: I think depending on your perspective, you can interpret this in other ways. There's also been some data driven work that concludes, perhaps not surprisingly, that price discrimination is bad for consumers. But there's a lot of work in this space on trying to understand how having specific information about your consumers and allowing you to tailor your offer to the individual can consumer affects markets.
00:41:52.324 - 00:42:01.144, Speaker D: Yes. So you mentioned quite a few models so far. Can you talk a little about work on validating the models? How is this done?
00:42:02.804 - 00:42:53.152, Speaker B: Not as much as it should be. So I am much less familiar with that literature. There is less, as far as I know, that's going on that's sort of convincing and influential of that flavor a lot from my perspective, maybe I'm missing something. A lot that happens in economics is sort of proposed model and then model that builds on model that builds on model, and there often isn't a lot of sort of validation that has consequences for how seriously the models get taken. But I don't know. And that would be a really interesting sort of literature search to do that I haven't done would be to really try to match each of these sort of really influential models up with the most convincing data evidence. Maybe I'm just unaware.
00:42:53.152 - 00:42:53.776, Speaker B: Yeah, maybe.
00:42:53.840 - 00:43:04.136, Speaker A: Do you know, not of something specific, but I mean, I mean, obviously you get into all the pitfalls of behavioral economic experiments.
00:43:04.280 - 00:43:31.974, Speaker B: Yeah. So I'm going to get to some of the problems with trying to use real world data to think about this stuff a little bit later. But yeah, there are a lot of problems with it. But that's not to say, I mean, particularly for models that have sort of macro scale implications as well as the micro scale implications, one could presumably do something to test the implications of the models. And I would love to try to gather those references, but I don't have them.
00:43:37.274 - 00:43:40.154, Speaker C: I'll dig it up and I'll send it to you.
00:43:40.234 - 00:43:40.642, Speaker B: Great.
00:43:40.738 - 00:43:57.494, Speaker C: Of people who had, but I don't think you would. They're not rigorous models because there's a lot of information, there are a lot of parameter variables that you just can't actually get your hands on. Hypothetical, what would it have been?
00:43:58.794 - 00:44:24.026, Speaker B: And that's one of them. The many challenges in trying to validate these models that many times carry many parameters. Yeah, yeah, but thank you. I'd love to get references for that flavor. Okay, so I want to talk about a couple more perspectives about sort of who benefits from information. So there's some interesting work on information sharing between lenders. So think of this.
00:44:24.026 - 00:45:55.484, Speaker B: Or sort of various sort of information sharing between entities that sort of have a shared perspective and role in the market. So think of it as there are a bunch of companies that might be willing to give you loans. What's a model that can explain this phenomenon that we see that they actually share information with each other about your past credit worthiness and your past credit related behaviors that lets their competitors do a better job of assessing whether or not you would make a good customer. So at least from my perspective, information sharing of this sort, I mean, although it raises privacy concerns, sounds like it could potentially be good for customers because of the implications that you see from these models, that information sharing between lenders reduces switching costs, because if everybody knows how good a customer you are, they can all offer you competitive, good prices. It's not just the company that you're with that knows about you and knows whether or not you're a good bet credit wise. But other companies also know and are willing to offer you competing lines of credit. And then you're about to anticipate the next bullet, maybe, which is that there's actually bad news for consumers in this low switching costs, which is that it reduces the need for these companies to compete with each other to give people a good initial offer, because I can always steal that customer away later.
00:45:55.484 - 00:46:06.872, Speaker B: And so in the analysis that's been done here, the actual sort of end effect of this information sharing is to reduce the welfare of the borrowers, but.
00:46:06.968 - 00:46:10.136, Speaker D: Also a problem if you're credited to it. Not good.
00:46:10.280 - 00:46:37.316, Speaker B: Yeah, I mean, so there may many, many other things that could be harmful to borrowers about the information sharing, but the point of this is that even something that sounded like it was maybe going to be good for the consumer, the idea that it's easy to switch between companies, that sounds sort of like a good thing for consumers because it sort of pits the companies against each other. Turns out it actually, in this model doesn't even have that benefit. You were going to say something else, though, or.
00:46:37.480 - 00:46:46.784, Speaker D: No, I'm saying that's the point. You want someone else to take the risk on the unknown. Once you know that someone is good, then you compete. If you know someone is bad, you're going to leave it alone.
00:46:48.444 - 00:47:01.564, Speaker C: I would also suggest as a comparison, the insurance market, because they went in the opposite direction. Stopping flows among the different companies, more or less. Yeah.
00:47:01.644 - 00:47:57.404, Speaker B: And that's not a literature I know. So if you have good pointers there, that would be great. Yeah, sort of. More generally, there's been some work on information sharing between competing firms, which I think is a really interesting phenomenon and one that I think is very, very relevant to us because we live in a world now where there are some major firms competing who are major players in the data space, and it's really important to understand what are their incentives in sharing that information that they have about consumers. So there's a summary article, which is now kind of old, but that summarizes the then sort of current literature on the incentive of firms to share information. And there's been more recent work sort of studying information design in this setting. So what do I mean by information design? This is sort of the question of what's the optimal amount of information to share in various settings.
00:47:57.404 - 00:48:55.300, Speaker B: So there's interesting work that I think is very relevant to us in this space. And then sort of back to the question of who benefits from information. There is an interesting model of bored and Lou in this paper that looks at settings where they're sort of comparing between consumers being anonymous versus being tracked by the seller. And they assume that there's a seller who has a choice of whether to sort of show you everything that's in their inventory or to try to target. This is the lender you should buy and just show you one or a subset. And in their model, what they say is that when the consumers are anonymous, the incentive of the sellers is to provide the full catalog. And when consumers are tracked, what happens, perhaps not surprisingly, is that they get steered to the most profitable products.
00:48:55.300 - 00:49:59.774, Speaker B: And what happens in a system that has multiple sellers here is you get sort of an implicit form of collusion amongst the sellers that pushes people to actually basically not have access to the products they would have had if they were anonymous. There is another, a survey paper that I want to point you to, a more modern one, with a different take on a different piece of the literature, the survey of Bergamot and Bonatti and Mark is for information. So this summarizes a bunch of their own work, but also has great pointers into the broader literature here. The main focus here is really explicitly on markets, markets for information. So this gets closer even to the discussions we were having yesterday about data co ops. So some of the things that they see. So with a single firm purchasing data, you see, not surprisingly, sort of price discrimination effects.
00:49:59.774 - 00:50:57.534, Speaker B: And there's, you know, sort of the particular type of price discrimination effect they see is known to lower consumer welfare and overall welfare. This, of course, would sort of call into question why a data intermediary might exist. They explore a number of other models, though, sort of, maybe not surprisingly, but sort of interesting to see these parameters pop out in this way, that sort of demand uncertainty. So uncertainty about what the consumers want or how much they want and the informativeness of the information dictate how many consumers you need in order to make it profitable to run a data intermediary. And they have some models and some sort of analysis of how many customers you need in order to run a data intermediary. And one of the very nice things to point you to in this article is this quote. The optimal information policy for a data intermediary remains a wide open question.
00:50:57.534 - 00:51:56.716, Speaker B: So there's a bunch of work that's been done in this space. But there's a lot more yet to do do to understand what it means to sit in the middle in this space and elicit data from individuals and sell it to data users. How do you price it? What information do you provide about the information that you're selling? There's a lot to be done in this space. There's some nice work that they summarize here on how it's not immediately obvious how you should, how much information you should reveal as a data intermediary. Introducing noise naturally lowers the value of information that you pass along, but also lowers the cost of obtaining it. And when you think from a privacy perspective, which I think is not explicitly incorporated in these models, you see this reinforced. And so there may be a benefit to the intermediary of transacting on noisy data.
00:51:56.716 - 00:52:41.192, Speaker B: And so this is something that's interesting to those of us who are interested in data intermediaries for privacy preserving data. And then there's this concern that we'll see sort of again and again in this space. That was first, as far as I know it raised in this 86 paper, that there's this possible dilution of the value of the information you're selling because you leak information about its value through informative prices. And so if I tell you you ought to pay this much for this information, it tells you something about the content of the information, potentially, which is an interesting thing to struggle with. Yeah.
00:52:41.288 - 00:52:57.868, Speaker D: So when they talk about purchasing data, is it data is really easy to replicate, to print copies of? Do they separate between persistent data and just seeing the rights for using the data or things like that?
00:52:57.956 - 00:53:55.936, Speaker B: There is some discussion in the literature, but I don't have pointers off the top of my head. I can find them about issues of resale. But most of these models that I'm talking about right now don't have a downstream market in corporate incorporated. So there's sort of a known value to the purchaser of the data, and that doesn't incorporate sort of resale considerations. Not surprisingly, there's also literature in recent years that's relevant here in the space of auctions like sponsored search. I mean, sponsored search is a data market in some sense, and so it's relevant to look to sponsored search literature. There's also some interesting work on the sale of information that's specifically used to reduce risk.
00:53:55.936 - 00:54:40.124, Speaker B: So if you want to insure somebody, you can pay for information about them in order to reduce the risk that you take on or to understand the risk better and sort of how should you price information in a setting like that and a number of other issues that come up in this space that I think are relevant. So looking at consumer scoring as an interesting form of aggregated data, and there's sort of a whole literature there on sort of pricing of consumer scores. And I can get you a pointer. Sorry, I dropped the pointer on this one. And also, this is just one paper, but there are a number of papers in this space. And I think Stephen even has work in this area, so you can ask him. Stephen looks shocked.
00:54:40.124 - 00:55:32.664, Speaker B: I think another relevant issue is the use of the selective release of information to sort of manipulate the recipient of the information into helping you do your machine learning in the sense of being willing to be one of the explore rounds and explore exploit types of settings. So if you are a company that is telling people how to drive from a to b, in order to make that happen, you need to know what are the slow routes and what are the fast routes? And that's something that changes with time. So sometimes you need to send people on good routes that you know are pretty good, and sometimes you need to send them on routes that you don't know about. So what is the information that you can provide to them in order to incentivize them to take your advice on a route, even though sometimes you're giving them a bum deal? And so that's an important sort of additional role and sort of modern role for information, specifically in the context of learning.
00:55:34.084 - 00:55:45.604, Speaker A: That seems more like an issue or a complication of transparency. Right. As opposed to individual privacy. It's not. Right. I mean, there.
00:55:45.724 - 00:55:53.734, Speaker B: Yeah, yeah, yeah. So it's bouncing around a lot of different things. Yeah, yeah, I know. This is. There's been sort of lots of different themes. So this. I agree.
00:55:53.734 - 00:56:25.896, Speaker B: The connection to privacy is not an immediate one. It struck me as relevant mostly because there are already privacy concerns about that information that they've been gathering and then they're selectively releasing it. And it seemed like an interesting layer on top of sort of these already privacy concerning mechanisms that then some of that information is being sort of in a manipulative fashion returned back to some of the people from whom it was collected.
00:56:26.080 - 00:56:39.360, Speaker C: I think one immediate link that comes to my mind here is that if you exchange your information for getting a value and then you sometimes get much less of the value, then you are sort of tricked.
00:56:39.472 - 00:57:00.074, Speaker B: Yeah. It's this idea that you've. There's a problematic system already where you're giving information in exchange for something else, but then that something else is something based on the information that may not be sort of what it was made out to be. So, I mean, there's something interesting going on here. I don't have a direct, immediate sort of privacy problem for this space, but I thought it was an interesting literature to know that there's work going on of this flavor.
00:57:01.774 - 00:57:07.234, Speaker C: I know you gave an example, but are there actual in use examples?
00:57:07.814 - 00:57:22.270, Speaker B: Yeah. So, for example, taxi routing companies in China are actively using taxis to explore bad routes and things like this. They have to do this. Yeah. All right.
00:57:22.342 - 00:57:23.646, Speaker D: That's the way it does that.
00:57:23.790 - 00:57:54.354, Speaker B: Yeah, yeah, yeah. I mean, I'm not sure I've heard them admit this, but I've heard other people admit that they do this, but, yeah, I mean, obviously they do it. All right, so I'm going to wrap up for here. These parts are not equally sized, so we're not in as bad shape as you might expect. But when we return, we'll sort of quit this circuitous path through this sort of economics literature and focus more on sort of privacy as we know it. See you after lunch.
00:57:59.134 - 00:58:23.642, Speaker A: So we have time for a couple questions. One e. One, I'm not sure where it fits in, but a vote for something to add to this collection would be information cascades, where sort of some hiding information at the beginning of a process might help sort of gather enough information to make good decisions downstream. And otherwise you can sort of wind up in these.
00:58:23.698 - 00:58:31.064, Speaker B: Yeah, yeah, yeah. That's a great suggestion and great literature. And I can give people pointers if they're interested there. Yeah, yeah. Thank you.
00:58:32.364 - 00:58:35.156, Speaker C: Can someone explain what information cascades are?
00:58:35.260 - 00:59:29.556, Speaker B: Yeah. So, stepping back a little bit more broadly, there are literatures on understanding how well groups of people aggregate the information that they each personally have. So I can take this even a little bit more broadly to think about prediction markets and other ways of aggregating the information held by individuals. So there are various different models about how people might share the information that they have, why they might share the information they have, and how they might learn from the information that's already been revealed by other people. And one of the sobering observations is that in very natural models, where, for example, we take turns voting on whether or not we think that this faculty candidate should get an offer. So we go around the room saying, yes, no, yes, yes, yes, yes, yes, no. In a very simple model where I think that the other people have useful information about this candidate, we very quickly stop saying what we really believe and start just reflecting the information that has already been revealed.
00:59:29.556 - 00:59:47.184, Speaker B: And so, depending on how you structure the process for aggregating information from individuals, the quality of the aggregation can be potentially very, very low, and it may aggregate very little of the information that was in the room. And so there are lots of models in this space, and it's a great pointer. Thanks, Adam.
00:59:50.144 - 00:59:53.840, Speaker A: All right, so we should defer more questions to lunch break afterwards.
00:59:53.912 - 00:59:55.344, Speaker B: Sounds good. Thanks.

00:00:01.880 - 00:00:03.554, Speaker A: Okay, Rusica, are you there?
00:00:12.414 - 00:00:22.950, Speaker B: I am here and I'm ready to share. Just a second. You can hear me and see me?
00:00:23.022 - 00:00:23.634, Speaker A: And.
00:00:25.714 - 00:00:27.694, Speaker B: Do you also see my slides?
00:00:28.114 - 00:00:29.258, Speaker A: Yes, I do.
00:00:29.426 - 00:00:30.614, Speaker B: Excellent then.
00:00:33.594 - 00:01:09.194, Speaker A: All right, so let's get started. It's my great pleasure to introduce Rizicha Piscach rzica is an associate professor in the computer science department at Yale. She was previously an independent researcher at Max Planck Institute and completed a PhD from EPFL in 2011. She has won many awards for her work, including NSF Career award, a Facebook communications and networking award, Microsoft Research Award for software Engineering Innovation Foundations. So without further ado, Rosica.
00:01:11.094 - 00:02:07.964, Speaker B: Thank you very much and thank you for inviting me. Thank you, Albert. So this talk, full title, is using set solvers to prevent failures in the cloud. But if you look what is the polyp is an application talk. When Albert reached out to me and asked me if I could give this additional talk on Friday, he asked me whether that could be a talk where we talk a little bit about applications of set solving. And while when Vijay was mentioning, he mentioned those words that are kind of very applicable, like networking, like this one, or software engineering. I do consider myself a person who is working in developing new decision procedures, but nevertheless, I'm really excited about that work because what you will see now is the joint work with Anan, who used at that time be my poster.
00:02:07.964 - 00:03:17.564, Speaker B: But now he's doing really great at Alibaba research and that is a really great example, in my opinion of how sad solvers can help to solve a very, very problematic, very like untrackable problem in the industry. So previous talks were like showing how powerful hammers we have. This one will be more about showing nails. And Anan is, I'm really happy that he found the time in his busy schedule so that he can at the end step in and tell us more about real world data, the data which he works every day, and then also maybe give an outline of problems that are out there in industry. So hopefully that will also be motivation that we start to talk to each other. Because, you know, like if I, who is not even a sad developer, could come up with such nice improvement, I'm pretty sure that all of you guys will give enhanced tools that he will be able to improve a couple of thousand times. So without advertisement, let me actually go to a talk.
00:03:17.564 - 00:03:56.238, Speaker B: And we all use cloud today. Even this talk I see it's recorded will be on the cloud and all our data on the cloud. And we somehow rely on the fact that our data is always there that if we need our data, we just will always be able to access that. But then, of course, question is, is this really the case? And now to motivate our research, let me start with a very, very, very simplified version of the cloud. You have see here a couple of servers. And let's assume you replicated this data over three different servers. Three different servers.
00:03:56.238 - 00:04:44.774, Speaker B: On the surface, they're not really, maybe they have connected through several switches, but still nevertheless, there are a couple of switches. They're not really so much dependent. And we assume our data is available all the time. Now, if you look at a little bit closer, you will see that if this router dies, then also the other two switches that are connecting to this router will die and we won't be able to access our data. So now this is a simple problem, and you can say whether this really happens in the practice, you know, like, but the fact is it indeed does. So what you see here, what I showed you, this very simple example, is just mimicking a problem that has happened at Amazon Web service. When I remember that, because that was approximately time when I came to the states and everyone was very upset.
00:04:44.774 - 00:05:22.084, Speaker B: People could not access their Facebook. Lots of, there was lots of complaints. But I don't want to just trash Amazon. I want also show, you know, like the problems like this. We can constantly read about them and they are just some sorts of copy pastes from existing news. And now, of course, when a problem like this appears, it will capture the eye of a systems community. And there were many approaches that were working in that direction where they actually say, okay, in summary, they have all the time the same theme.
00:05:22.084 - 00:06:20.894, Speaker B: If failure like this has happened, let's do troubleshoot the system. Let's see what has happened so that we can solve problem after the outage occurs. And of course, now you can think about that means longer system downtime, well, prolonged recovery, and we are all now in pandemic. So we know that cure is actually, it's much better that we don't come to the face that we need to cure something, that we actually will rather be in the face that we want to prevent disease instead of trying to cure that. And this was exactly the work that when Anand was at Yale, started to work on. So what he did was he developed his first approach towards solving that problem. So I will describe that system which he called Indus, and that was the first system that was addressing this problem.
00:06:20.894 - 00:06:58.044, Speaker B: And then we started to chat. We were actually same building, same floor. So we started to talk and see whether there is a similar whether there is a better solution. And I guess to this audience I really don't need to sell bunch of new set solvers. But you will see how nicely and easily we could model this problem that you see using set solvers. So that will be, as I said, it's really application talk. And then after that Anand will tell you how to take this, apply it to the real world cloud and tell you more about the problems that are out there in community.
00:06:58.044 - 00:07:38.240, Speaker B: And hopefully you will then also after that start to talk to him and bring even more problems. So now let me now start first with this project called Indes. As you can see it was a project published at OSDI. So this is again another system conference. And what was Indus doing? Actually it worked in couple of steps. The first one is it would collect all the data about network. And then when once he would have all this data, who is connected, how is connected, who relies on both, then actually all this data would be used to model something that is called fault graph.
00:07:38.240 - 00:08:14.594, Speaker B: Now some of you might say like oh, fault graph, like in main cut set. Exactly in such type of fault graph. And then we need it. Once we have a fault graph and we say like okay, what will have to happen that, you know, like that the system crashes, then we actually will have to find all these configurations that are causing the system to crash. So now let me start to give you an overview how it was working. Like first part is pretty, would probably belong to some networking conference. So we'll just kind of give you some details.
00:08:14.594 - 00:09:04.196, Speaker B: But you know, like it's not that much set related. So we actually reused existing tools. So there is a tool, if you look at the, if you look at the example here, very simple network, there is a tool called NSD miner. And the tool would, the tool would actually scan network and derive all the data in the following form where you will have, for example here we have, I have source, that's server one. Then I have, it's connected via Internet, it can reach core one. And all the data were actually collected by this tool called Aniston Miner and they were given to us and it would be stored in the database. Now once we had this relational description of the problem, then we immediately could go to the next step which was let's build this dependency.
00:09:04.196 - 00:09:41.496, Speaker B: So let's recall again our initial replication system that we had. You put things on the couple of servers. And even easier, let's assume you only put things to two servers. So you know that your configuration, your replicating system will fail. You won't be able to access your data if every single of your servers fails, right? I will have server one will fail and notice, and also server two will fail. So, okay, that's kind of reasonable that you can assume. If all of them fails, then I know that I cannot access my data.
00:09:41.496 - 00:10:22.424, Speaker B: However, now let's look into the servers. So when server one will fail, well, it will fail if its hardware fails, or now notice it's not actually, we don't even put end anymore. Now it's enough that one of those things fails. If hardware will fail or it network successful fail, all its software will fail and so on. And we can continue on, then we can look into while the network will fail. So all this was also again constructed automatically. First step was like analyze network using NSD miner, save it in this relational database, pull out and construct this graph, which will actually explain who depends on what and how.
00:10:22.424 - 00:11:07.474, Speaker B: Now if you look at this, so now we talk about younger Nan, who was at that time not still aware that formal methods are the best things in the world. So they tried to use something called Mincut solver. But as you probably know, this is the NP complete problem. Well, the same like set solvers, but nevertheless it wasn't really scaling pretty well. So what then they did, they said, well, you know, like we need to just get approximate feelings of what they would do at every route, at every leaf. They would flip a coin and then it would be either it fails or not. So now if we assume that it failed, then, then we will put this x, or we assume that it didn't fail.
00:11:07.474 - 00:12:10.666, Speaker B: And practically based, you will immediately get one configuration saying like if aggregation switch fails and aggregation switch two spells and or they didn't fail. And when we propagate it, then we will know whether the main configuration fail or not. So now you can see this is the basis for Monte Carlo method, right? So they would repeat this process many, many times. And the more you will repeat, the more accurate description of the compositions that need to fail simultaneously. So that original deployment fails, you would achieve more and more of them. So now you can look at that and you will say, well, there are clearly several issues, right? One of them is that it is hard really to express a diverse auditing task, right? We cannot ask, like, if you just say, like, will it fail? And find me these other parts which will fail, but you cannot ask maybe anything anymore, what is the minimal component, which is what Minka said would answer. And those things you will not able to answer.
00:12:10.666 - 00:12:32.032, Speaker B: So I mean, sorry, I didn't say the others, the other one is like it. It was really slow. You will see based on the result that we will show at the end. And one of thing is like you can just kind of pinpoint the problem. There was nothing to do that. You solved the problem. So what we did, we started talking, then we said like we should use set solvers for that.
00:12:32.032 - 00:13:09.968, Speaker B: And we proposed engine, which is called, which we called rep auditing engine. And let me tell you what was the secret sauce like. We could develop a new domain specific auditing language that could easily express diverse auditing tasks. And that was pretty easy because once we modeled everything as a set formula, then it was just like boil down to find the minimal unsatisfiable core, add additional constraints. And it was constantly boiled down to solving constraints and it was much faster. Well, thanks you. Thank for, thanks for everyone for developing new and fast set solvers.
00:13:09.968 - 00:13:48.602, Speaker B: And in addition, we described, well outlined how the synthesis would work for this approach. How we would give, how we would not only be able to say, look, this will fail, but we would even give the user feedback. But if you change something, if you put it maybe on different server, then you will reduce your failure probability. So that's what we've done. Now let's go back to the problem that we started with. Again, simplified version. What does it mean? If we want to identify that this, I mean, observing just the picture, we can see that this router is problematic.
00:13:48.602 - 00:14:22.066, Speaker B: If it dies, our whole replication system will die. But how it works, we more or less have this auditing problem where we will say, well, write down, I'm using server one and server two. And can you rank me this, what we call riscref component. And we would get user would need to do this. What is in the blue box? Well, what is in the blue box is a black box for user. What would. User would get, excuse me, user would just get the answer which will say, well, you're looking at these components, you're most probably problematic is this core one.
00:14:22.066 - 00:15:01.960, Speaker B: If it dies, you don't have access to your replication replicated data, but also you will, it's the same. If aggregation switch one and two die at the same time, you are in the same trouble. So if you look what was behind that we were using again, all things that they described. That's why I spent so much time talking about this fault graph. Then we would come, then we would convert this into CNF form and use weighted backseat solvers. Now I don't, this is, don't want to go so much into auditing language and all the auditing details. Maybe just to tell you interesting concepts.
00:15:01.960 - 00:15:52.600, Speaker B: Remember I was complaining that we didn't have enough expressibility with this old approach. So now what we can do, we can say, let me rank the components, let me rank the devices which are most likely to fail. What is exactly, if I develop a certain, if I want to, if I care only about one replication system, what is the failure probability? Can you give me some recommendations? So all this is now in our language. And now to give you the semantics of this one, let me, excuse me. So a user can write properties like that and how we envision it will work. Here is our database that already analyzed network. Here is our user rights auditing problem as the one, as you have seen here.
00:15:52.600 - 00:16:48.974, Speaker B: And then based on this network user and our auditing engine, which is actually again based on set solvers, user will get report telling us more or less what is the failure probability or whatever we ask in our auditing problem. Now let me actually look more, I guess we, I promised to Albert application talk. So let me actually look into application, right. So first, I already mentioned several times risk groups in default graphs. And I guess name is pretty much self descript descriptive. This is a group in the fall graph such that if this group of the nodes fails, then we know that there will be the root failure of root node will happen. So here we look here that a two is clearly one, such a risk group, but also at the same time a one and a three jointly are also risk group.
00:16:48.974 - 00:17:29.310, Speaker B: Because if a one and a three dies, then we know that both e one and the second in one, which is actually e two should die too. And then we know that we don't have our deployment. But if only a one dies, that's fine, because if a one dies, then left e one won't be accessible. But the right line is still there and we have access to our data. So now looking at that, you can clearly see that this will take into account that we have and nodes. Clearly we can encode all this as a formula, Boolean formula. And practically the problem boils down to find satisfying assignments to Boolean formula.
00:17:29.310 - 00:18:32.352, Speaker B: So every satisfying assignment will represent a risk group. Now you can also ask, do you have negations? Yes, we will do have negations, but we are getting there. So initially it looks like we don't have them, but you can see. So now you can also look at the risk groups and you say, well, if a two and a three dies, that's bad, but it's much worse if a two dies because it's only one of them, right? So then the question is like whether all risk groups are created equal, and clearly not, because if they're smaller, there is much less chance, there is much higher chance that only one thing will die, that five things will die simultaneously. Although we know how it's in life, probably five things will die simultaneously. But anyway, we needed not only to find what a typical problem would say, find me a solution, but find me maybe the best solution in that case. So we wanted to find top k minimal risk groups, and we looked into something which is called mean cost z problem.
00:18:32.352 - 00:18:41.384, Speaker B: I don't actually look into chat. Are there any questions or is everything clear? So far? Everyone is with me.
00:18:42.204 - 00:18:43.544, Speaker C: Everything is clear.
00:18:43.924 - 00:19:11.108, Speaker B: Okay, perfect. Thank you very much. Then if you have any questions, just please stop. So let me then go, let me go back to min. Cost set problem, right? So you all know what is set problem, right? Set problem just means I have a set of variables and I want to find a solution. But there is, if you, each variable would also have a cost. So then you actually want to find a cost solution that costs the least money.
00:19:11.108 - 00:20:13.744, Speaker B: So, in, and if you ask now, how is this related to our size? Well, we can simply say, let's cost of each variable be one. In that case, mean cost solution to the problem is indeed finding the solution of the minimal size. But then, interestingly enough, once we started to model into that direction, then we realized, but it's not also, again, not only that all these components are equal, also it's not the case that all the devices are equal. Some devices are of really good quality, but some devices will constantly die. They have different failure probabilities. And now having again, the same approach of min cause set problem, we could assign the, we could actually find this component, which was not necessarily the smallest in the size. By looking into failure probabilities of each device, again, we could find the minimal failure probability.
00:20:13.744 - 00:21:16.382, Speaker B: So now let's look, maybe what would be here in the, when we've just focused on the size, you can see I'm saying each of the, each of the components has value one. That means I want to just see the size. And in that case, I can easily find that my minimal component is actually exactly a two. Now, if I want to maybe put different components, let's say, if I will say I have maybe failure probability of a one is 10%, failure probability of a two is 30%, and failure probability of a two is 20%. So clearly those are pumped up numbers. But just for easier illustration, then you can simply say you will again additionally need to multiply. Right? If a one and a three die at the same time, we will see that then failure probability is zero, zero, two.
00:21:16.382 - 00:22:03.228, Speaker B: And then again, using the same reasoning as before, we find it. Since this one has clearly the highest probability, we reported that one. Now, you can now kind of notice that I already mentioned, if a one dies and a three dies at the same time, I multiply those things, right? And if you look at the problem, it is not exactly what problem talks about. It's multiplication addition. So let me show you a trick that we did. So how to, how to reduce addition to multiplication, of course, using algorithms. And I should probably ask Anan if he still remembers the things, because what has happened was like, okay, you know, like, if you use algorithms, algorithms.
00:22:03.228 - 00:22:58.004, Speaker B: If I'm really tired, I'm sorry. If we use logarithms, that means, you know, like we want, we can really reduce multiplayer multiplication to addition. But then again, the problem was why we needed negative value was because if you look at logarithmic function, it goes like this, and we actually need it the other way. So that's why we use negative value. And we needed to multiply by 100 for simple reason, because the numbers we were getting were too small to actually compare. So this was just, let's multiply everything with 100 so that we can at least compare the values. So, and again, using, you know, like these simple tricks, we were again in the same problem that we have, min cost problem, and we again try to solve that.
00:22:58.004 - 00:23:42.224, Speaker B: And how to find. Now here comes. Where do come our negations? So far you have only seen and, and, or, but how do we find top k critical risk groups? Maybe our solution was relatively naive, because what we did, we would find top solution, then we would negate that solution and repeat the process. So maybe there is something that we're so much easier and more elegant solution. We would like to hear that from you. But with us, it was working pretty smooth because I usually don't want to see top 30 things. Like, it was just give me top five or top three to see what is the most at risk at that time.
00:23:42.224 - 00:24:49.628, Speaker B: And that's it, I guess. Now, if I one thing that is also that we're kind of very inspired by cool dipstop was computing the failure probability of the all system. Because if you think about now, imagine we have our system and we create the graph. And I'm asking you, so what is overall failure probability? If we already have those numbers and there is how you ask that. Well, the failure probability will be more or less finding models. As we said, each positive solution, each satisfying assignment corresponds to one failure, uh, event, which means that if we find how many models we have, we actually have found the overall failure probability of the system. So we didn't need to run our k loop, but it was enough that we actually just do model counting, and then we divide with two to the n.
00:24:49.628 - 00:24:56.412, Speaker B: Excuse me, there is a question, or. I don't see it. I see something.
00:24:56.588 - 00:25:01.070, Speaker C: Are you saying you did use this, or is this something you want to do?
00:25:01.252 - 00:25:03.774, Speaker B: This is what we already did implement.
00:25:04.314 - 00:25:10.474, Speaker A: So, Rusita, there is a question. What is the scale of this problem? How many variables are.
00:25:10.514 - 00:25:15.294, Speaker B: We are getting there? We are getting there. I mean, you have to stay with us until the end.
00:25:18.234 - 00:25:19.774, Speaker A: Kareem Sakala's question.
00:25:20.874 - 00:26:02.344, Speaker B: Yeah, yeah. So I will show this in like two, three slides, and then Anan will actually show you that, how to work on even bigger things. So anyway, so where we are, what we also did, right? So we could use this failure probability with model counting only if we assume that all the boxes are equal. Because in that case, if all the boxes are equal, then their failure probability is 0.5. Either it will fail or it won't. And then we could actually use model counters. Right? However, if you remember, when I showed you picture before here, everyone, each of them had a different probability.
00:26:02.344 - 00:26:33.374, Speaker B: And then how, again, we did, it was a little bit, you know, like, again, maybe there is a smarter way, but for us, it was a trick that worked pretty neatly. What we did was, you know, like, if it. If it's already one over half, then it's fine. Otherwise we would just kind of, you know, here was the tick was one over eight. One over eight is. We have to kind of introduce three fake. Fake nodes, which would actually, again, each of them have a probability one over two.
00:26:33.374 - 00:27:04.520, Speaker B: And then when you multiply failure probability of this whole note on the top, it is exactly one over eight. Now, in reality, you know, like, you won't really get one over eight, you will get something one over seven. But then we would just do approximation, because also this failure probability of certain device, it's not like this is really precise. This is like estimated failure probability. So that's the trick that we use. And now, thank you for the question. Now we want to come how fast it is, and it is much faster.
00:27:04.520 - 00:27:38.140, Speaker B: Oh, no, I want. Do I have time for repair? Maybe? Let me quickly go to tell you how fast it was, and then you can actually see. So, like, I already said we had a first implementation which was failure sampling. That was the work that Anand did as a part of his PhD studies. And so we really had an expert who knew how to write all these editing tasks. And this was the line of codes he needed to describe all these editing tasks. That was encoding problem using some minimal cut set solver.
00:27:38.140 - 00:28:26.280, Speaker B: And this was just using our aral language. And you can see the reason why we actually could do this. Well, because we already knew which problems arise in the practice. So all our components that we introduced were actually kind of tuned towards that, that we can easily express what, what system administrator wants to ask about a system. And at that time, we were young and naive and we only had our system here called at that time. We could even still use in person student, student lab, where we could actually, and we could simulate various topologies. So we had, we came with the topologies that would have 140 routers, this is the number of switches and so on.
00:28:26.280 - 00:29:04.374, Speaker B: So all these topologies were simulating using a tool. Again from networking that is used, you kind of provide parameters. And then actually, then you actually get a topology which corresponds to real life topology. So if you can see, at that time, we actually even had topology C, which was not deep, which was a bit bigger. But the, you know, like then we really needed to wait for results to get out. But I know that NAnd will tell you how he actually used this in the real real world setting. So to go here, topology C has around 70,000 devices.
00:29:04.374 - 00:29:55.866, Speaker B: And if you look how fast it was, let me actually show you. So when we were using Mincut set algorithm, because we used existing tools, I forgot the name, but it was super accurate. But it also took a little bit of time. We really needed time to compute that on these topology questions that we were asking. However, when you produce indes, that was this Monte Carlo simulator, it was getting there, you can see after ten rounds you would actually get accuracy of around 20%. After million rounds you would get accuracy, no, ten to the 5 million rounds you would get accuracy of 30%. And after ten to the seven rounds, you're almost here in the time, but you're still with the accuracy of your answer, which is closely to 40%.
00:29:55.866 - 00:30:35.702, Speaker B: So if you would kind of imagine here line, you could really see exponential growth. Now, again, thank you all guys, developers, we really appreciate that because when we run all these tasks on the 70,000 nodes, we actually got around 300 times speed up. So we were like really happy with that. And I guess Enan wants to take over here. But if we will have a time, we will just kind of tell you more about repair. But Ananya, since people wanted to see how things are working, well, maybe. Oh no, let me.
00:30:35.702 - 00:30:38.102, Speaker B: Do you want to share or do you want to talk?
00:30:38.198 - 00:30:39.874, Speaker D: Yeah, I can share my screen.
00:30:41.214 - 00:30:42.354, Speaker A: Thank you, Anand.
00:30:42.814 - 00:30:51.674, Speaker D: Thank you. Let me share my screen. So, yeah, good.
00:30:53.174 - 00:30:56.074, Speaker B: So, Aroncas, remember well the projector.
00:30:57.534 - 00:31:16.134, Speaker D: Yeah. So, yeah. So thank you very much for the story. So let's continue that. So, after I left Yale, I joined the Alibaba group. So I tried to deploy the web audit in Alibaba group. Alibaba is one of the largest cloud providers in this world.
00:31:16.134 - 00:32:00.210, Speaker D: So we are planning to add a very beginning. We are just planning to use web audio to audit any update state in our service runtime. Like showing this picture. But this is because the majority of the big outages in our network were caused by the service updates, such as changing the network path and upgrading the software component and dependencies. So our system is named the cloud canary. Well, it worked well, like what Rusika just showed. But unfortunately, our operators asked Earth whether it could be more faster because the number of our update tasks increased super fast.
00:32:00.210 - 00:32:18.868, Speaker D: And in most busy time, our operators actually need to commit one update task every 5 hours. So in addition, actually, because we are trying to target the industry scale services. So actually we have. I'm sorry.
00:32:19.036 - 00:32:24.224, Speaker A: And on quick question, when you say update task, you mean upgrading software components under the cloud?
00:32:24.724 - 00:32:49.724, Speaker D: Yes, exactly. Yeah. So, including both network and software, for example, you can say remove one link between the two switches and add another link between another two switches. This is one update. And another update might be we upgraded the version of a software from, you know, 1.0 to 2.0.
00:32:50.984 - 00:32:58.144, Speaker A: Just to reiterate, you were saying you were. You had one update task for 5 hours, is that what you were saying? That was the rate at which you're doing updates.
00:32:58.264 - 00:32:59.864, Speaker D: Right? Right. So, yeah.
00:33:00.024 - 00:33:00.844, Speaker B: Okay.
00:33:02.264 - 00:33:03.164, Speaker A: Thank you.
00:33:04.464 - 00:33:31.604, Speaker D: So, yeah, this is actually a great question. What I want to emphasize is updates is very, very important for our operators because we did a lot of updates, you know, every day. So. And update is dangerous. We need to prevent the problems resulting from the update. We are targeting the industry level services. It contains hundreds of thousands of components.
00:33:31.604 - 00:34:16.541, Speaker D: I remember just a question about the scale of the dataset because I'm not allowed to expose the absolute number of our components. But what I can say is, actually we're targeting the components. The number of components is higher than 100,000 components. It's more than that. But I cannot expose the absolute number for that, I mean our real network. And we have a new requirement whether we can do fast. So how to address this problem, because we're targeting much more components in the real scale and we have a key insight, because we are targeting the service updates.
00:34:16.541 - 00:35:20.498, Speaker D: So typically the service update just change, they do not typically change too many components from the previous update snapshot. So we can just audit the differential parts between the previous and the updated snapshots instead of auditing the entire updated snapshot from scratch. This is our key insight. With this key insight, we developed an algorithm for cloud Canary which allows us to only audit the incremental parts within an updated snapshot. We are now using wrap audit for the initialization phase like shown in this picture. During the service runtime, we just run cloud canary to do the incremental auditing and because, so this algorithm actually is not, is not trivial. So due to a limit of time, I cannot go through the detail, but I will show you the key insight about this algorithm and you can read our paper for more details.
00:35:20.498 - 00:36:18.294, Speaker D: This work was published in USDI, which is a top, top network conference last year. So the key insight here is the triangles here mean the snapshot for the photograph. And the first thing is we gather the photograph and we find the border nodes. The border nodes means the black nodes in this photograph and the border nodes are actually the root nodes for the updated sub photographs. And so after we find the border node and we only need to use the to identify the risk groups in the sub photographs. And after that we also propose another algorithm to merge the result from top to bot, from the bottom to up to get the final results. And this is very interesting algorithms.
00:36:18.294 - 00:36:50.978, Speaker D: If you are interested in that, just read our paper. And actually during this process we only audit the delta between the updates. Let me show some results. So this is a real results. We did this real deployment in our network and from this picture. So the S 1234 are the real update. So from this picture we can observe that the interval between two updates are actually very fast.
00:36:50.978 - 00:37:22.264, Speaker D: It's just a short time. We did a lot of updates in this service runtime. If we use the existing work to try to do this audit, they cannot finish the task on time because another update will come soon. If we use the cloud canary, because we only audit the data between the snapshots, actually we can finish the auditing task on time. So this is the key thing happened in our real network.
00:37:26.084 - 00:37:38.504, Speaker A: So in this cloud canary, that result that you're showing here, I have two questions here. One is the incrementality key to the fact that it's much faster than reported. Or.
00:37:40.604 - 00:37:42.412, Speaker D: Say it again, I was wondering.
00:37:42.508 - 00:37:44.204, Speaker A: Why cloud canary is so much better.
00:37:44.244 - 00:38:13.084, Speaker D: Than oh, because we only audit the data between the two snapshots. So the existing work actually including the rep audit, they audited the entire photograph from scratch. Because between the two updates, we actually only have the small part is updated. So what we need to do is just to analyze the delta part and get the final result. This is the key insight. Is that clear?
00:38:13.464 - 00:38:16.284, Speaker A: Yes. Yeah, makes sense.
00:38:16.704 - 00:38:59.220, Speaker D: Thanks. Okay, so this is the real result. Here we analyze our real cloud. So we have the following results from the case study. So the microservice update sometimes introduce the the common dependency, for example, the authentication component and access control system. So we observe, some say access control is the rule which might be the common dependency. So if that rule is wrong or it's incorrect, and it's very likely to cause the correlated failure across the entire network.
00:38:59.220 - 00:39:43.628, Speaker D: Actually sometimes that really happened. But I cannot expose that the real outages here. So power source is another one. So the power source typically support a lot of components, say the two power sources support the thousands of routers or thousands of servers. And if the power source, some problems happen in power source, that's also the dangerous. And we also need to use our system to audit whether some common dependency power source is introduced in the network area. It's also common, for example, the aggregate switch and torus switch that happened sometimes lead to the correlated failures across the entire network.
00:39:43.628 - 00:40:52.644, Speaker D: And so actually we detected a lot of such dangerous common dependencies and we fund them on time and can solve a lot of problems from our network. So the wrap audit is the first system that use the sensor to finish the efficient audit for the correlated failure. And cloud canary actually is the first system we use in the real world. And to audit the real time update. Actually we also evaluate the cloud canary in the real world data and like what I just showed. So this part is just a talk about one concrete example about how can we apply in the boss, academia and industry to build a real system. So in the end of my talk, I will tell you in the network analysis domain what type of systems we can build based on the SAT or SMT solver.
00:40:52.644 - 00:41:08.956, Speaker D: And I also want to thank Nikolai. So we actually, after I joined Alibaba, I widely used SMT solver to build a lot of verification system in our network. So here I want to show this. I'm sorry.
00:41:09.020 - 00:41:19.164, Speaker A: Yeah, Anand, there's another question by Karam. So the updates are incremental. Is the SAT solving also incremental? The SATs, all that's used in cloud canary is that leveraging.
00:41:19.204 - 00:41:36.394, Speaker D: So we actually do not use the incremental thing for the saasover. We just use the algorithm to analyze, to extract the incremental part and directly use the original SAss or, you know, to analyze the incremental part.
00:41:40.054 - 00:41:40.994, Speaker A: Thank you.
00:41:41.654 - 00:42:07.938, Speaker D: Thanks. So because I'm not quite the sensor guy, so I really want to do some smart thing in the sensor, but unfortunately I didn't do that. So what I can do is to design an algorithm to extract the incremental part and use the original SAS or to analyze it. So this is what I did. Okay. Anyway, yeah, so maybe also to tell.
00:42:07.986 - 00:42:19.866, Speaker B: You, when we were using set solver, I think we were using the, we went to competition, found the fastest set solver that was publicly available. Right.
00:42:19.890 - 00:42:20.934, Speaker D: The one which is.
00:42:21.564 - 00:42:35.572, Speaker B: Right. So that's, you know, like it's not based on a smart insights and techniques. So that's why I thought it would. It's really great that Anan is giving a talk so that you can kind of provide so much more feedback and, you know, bring more tools that we could use.
00:42:35.628 - 00:42:51.618, Speaker D: Yeah, yeah, exactly. Yeah, yeah. What we did is just to, you know, take, take a look at the ranking list about the Sasori competition and just, you know, select one week use. And to apply that in our system, this is what we did.
00:42:51.786 - 00:42:53.174, Speaker A: Which solver is that?
00:42:53.594 - 00:42:56.214, Speaker D: We use a super Mario or.
00:42:58.674 - 00:43:01.654, Speaker B: Something, something that ends with eno.
00:43:02.794 - 00:43:21.294, Speaker D: Max, you know, Max. Yeah. Maxinocyte. And also we also use the motor counter from the cudi. Yeah. And yeah, that's the motor counterpart for the failure, failure probability computation presented by Rudika. Yeah.
00:43:22.554 - 00:43:24.034, Speaker A: Okay, thank you.
00:43:24.074 - 00:43:55.016, Speaker D: Thanks. Okay, so, yeah, so this picture is just, I want to show big picture about the state of the art that apply the SaaS server SMT. Sorry. In formal network analysis, I actually classified them into three groups. The rigorous network analysis and verification and network synthesis. I guess you guys are super familiar with these three domains. And this is actually what I'm exactly working on in Alibaba.
00:43:55.016 - 00:44:49.884, Speaker D: And so the first type is the rigorous track checking for the network. And in this scenario, typically the operator, their specification, say in first order logic and convey the specification to the system. And the system automatically analyzes the target network. And the key challenge here is how to model the network or how to extract a reasonable network abstraction from the underneath. And so some existing work has been proposed, for example, like what Jester Rusika talked about the wrap audit and index belong to this domain. And we also observe another work from Microsoft. They use the software to check and test the configuration for the software.
00:44:49.884 - 00:45:30.628, Speaker D: So the second domain is formal network checking. So actually the network configuration is a big problem and the operators typically made a lot of wrong things in the configuration. Configuration is the key thing for the network. They generate the routing table, they control the forwarding behaviors of the network. And so using the SMt software in the network verification is very important direction in the network and system area. And so in this domain, actually the operator express the specification about the correctness of the network. For example the reachability one router can talk talk with the router.
00:45:30.628 - 00:46:24.258, Speaker D: I want router one can talk with router two in this class. And so I just want to check whether the routing table is correct. And here the challenge is how can we correctly express our intent and the network model, whether the network model is represented correctly. And another important thing is we want to use the SMT software to check whether the network model meets our specification. And so typically in practice we found the verification algorithm whether we can speed up the ISM disorder to speed up this process. And so a lot of status are proposed in the past years. For example, in data plan verification we know the wireflow and NLD.
00:46:24.258 - 00:47:26.768, Speaker D: NLD is also identicalized work and very much like this work and the control plan verification include the mice waiver and the ERP. I strongly suggest you guys read the papers. And in our system and network community we really want to have the super fast SMT solver to speed up the existing system. So in the network synthesis area, the operator typically express the specification and in this case we do not have any configuration for our network. And writing the configuration is very very hard. So we want to just propose some synthesis algorithm and this algorithm can generate the network configuration based on the spec. And in this area, of course the challenge is how can we express the intent and what should be the synthesis algorithm and the state of the art include the configuration repair and say the firemason.
00:47:26.768 - 00:48:40.346, Speaker D: Firemason was another collaboration between Rusik and me and her student to automatically repair the firewall and also the configuration synthesis including the CNiTe net complete like showing in this picture. And what I want to emphasize is all the work I just talked about focused on in the academia area, but whether we could build something in the industry to verify the global scale deployment. Actually the cloud canary is one instance for the global scale deployment and for the network verification and the network synthesizer. We have gap and we need a lot of work in this, in this part. So after I joined Alibaba, actually we built a system named Hoyan, which can use SMT solver to verify the configuration. And of course in Microsoft research and Nikola had a team to build another data plan verification system published in sitcom two years ago, I think. Yeah, I remember.
00:48:40.346 - 00:49:29.424, Speaker D: Okay, so I think both of the systems prove that the SMT. Sorry. Could be absolutely applied in the industry. And to do the real, you know, the real world verification for the network, this is important thing and in the network synthesis area. So I also built another system in Alibaba to synthesize the ACL rules for our network. So this ACL rule is different from, because this ACL is un network ACL, because we have a lot of switches and on each switch we have different acos. And all the acls on different nodes work together to coordinate control the reachability.
00:49:29.424 - 00:50:26.052, Speaker D: And this is very challenging to generate the ACL for this distributed setting. So again, the picture shows a lot of state of error, but all of them apply the SMT solver to enable the verification. And so, thank you much for the community. And what we need in the future is the faster SMT solver and SaaS solver and more functions, say like the incremental speed up or something. And we are very happy to use some interesting SMDSoro SAS or to speed up our tracking and verification. So again, this is the end of my talk. So in this talk, we talked about some application for the existing SaaS server and SMG server in the real world.
00:50:26.052 - 00:50:30.024, Speaker D: And I'm happy to take any questions. Thank you.
00:50:33.384 - 00:50:39.072, Speaker E: Can I say something? Yeah, this is really cool. I like, I like the application.
00:50:39.168 - 00:50:39.804, Speaker D: Thanks.
00:50:40.744 - 00:51:20.484, Speaker E: I think we need to see more applications of this technology so that, you know, the secret about, you know, what we can do is not the secret anymore, that other applications, other other communities can actually become familiar with it and they can start using it. I think as a community we have not done as much, and we're kind of reaching out to other communities to show them that what, what we can do. So I'm standing on a soapbox of it because of that has been around now for 20 some years.
00:51:23.684 - 00:51:28.864, Speaker C: Vijay, you're mute. We can't hear you.
00:51:29.324 - 00:51:35.304, Speaker A: Thank you. Kareem, Nikolai, please go ahead. Please go ahead.
00:51:35.924 - 00:51:36.824, Speaker F: Thank you.
00:51:37.604 - 00:51:38.624, Speaker B: Very nice.
00:51:40.484 - 00:51:44.504, Speaker D: Hello? I cannot hear. I cannot hear.
00:51:45.724 - 00:51:51.430, Speaker F: I'm getting a echo somehow. Not sure what's.
00:51:51.582 - 00:51:53.314, Speaker A: Albert, maybe you want to.
00:51:55.494 - 00:51:59.034, Speaker F: So the echo seems to be gone and I guess you can hear me.
00:52:01.254 - 00:52:01.994, Speaker B: So.
00:52:04.454 - 00:53:17.644, Speaker F: For the risk group enumeration. So you enumerate top risk groups and then check whether you have certain guarantees under top risk groups. So the question is, is there a formulation using quantifiers? Are you solving a problem? There exists some configuration such that under all some properties. So if you had this quantified formulation, you could ask to the SAT community, what are the clever ways of solving this quantifier? So, one method that I think colleagues in the networking space are using is employing linear programming dualities, when there's a subset that exhibits strong duality. So maybe in the SAT space there are some other, I mean, there's a variant of this. And I wonder if you can, like, use your work to inspire this community around this question.
00:53:19.664 - 00:53:20.592, Speaker B: Shall we?
00:53:20.728 - 00:53:22.484, Speaker D: So, yeah, Rudika, go ahead.
00:53:24.304 - 00:54:34.220, Speaker B: And I look at each other. Oh, there is some sorts of quantification that I didn't present, and that was in the form of synthesis, if in the quantification doesn't exist in the language, as we have, and also our synthesis is pretty, it's relatively simple and primitive, because what we did was, you would more practically say whether there exists deployment such that, let's say failure probability of deployment falls under 0.20%, and that we can show that there is this quantification that is eventually deployment. But what we do is we are solving this more or less on demand, in the sense that we are constructing the tree, and as soon as we see the tree is violating the constraints, we prune those branches. So it's not, you know, like it is. If you look at the description of the algorithm, it's pretty much, you know, like, build the tree, does it valid, cut it away, build, continue this, prune away. That's it.
00:54:34.332 - 00:54:53.504, Speaker F: That's obviously very reasonable. And then the question is whether does it scale under, say, how does it scale with the sizes of networks? And then, so the number of faults, group combinations. So if you look for.
00:54:53.884 - 00:54:57.304, Speaker B: Do you remember it now? I don't really recall, baby, do you remember?
00:55:01.744 - 00:55:48.964, Speaker D: I cannot remember that in the real world data, we didn't use that. But for the rip audit, I think the scale is, I think what, let me see, 10,000, I guess we have 10,000 components and we can synthesize within just several, several minutes. But I guess Nicolas question might be talked about in what we want to identify risk groups, whether we consider, whether we take into account the quantifier or something. Right, Nikola, is that your question? Actually is.
00:55:49.044 - 00:56:14.980, Speaker F: So, of course, they are very different. In your last slide, you had the different categories of synthesizing and network configuration, and depending on which line you're in, you have a different kind of problem you're checking, and then maybe it's in the last line where the query is find a fixed configuration such that.
00:56:15.092 - 00:56:18.474, Speaker D: Yes, yeah, yeah, got it.
00:56:18.594 - 00:56:26.834, Speaker F: And to solve that, you can't just prune one branch at a time. You want to find the fixed configuration such that for all branches.
00:56:26.954 - 00:57:02.364, Speaker D: Yeah, yeah. Depending on. We did take into account that, you know, the coinfares, like what you mentioned in the Hoya system, but yeah. What I think Rudy could just talk about is the cloud canary. You know, they're the different system. But in our work, configuration verification, we did consider that. And because sometimes we want to check whether, you know, a specific configuration rule has some problem or whether the reachability goes through from a specific path, including the specified component or switches.
00:57:02.364 - 00:57:08.424, Speaker D: In that case, we did consider that thing in the HoI system, which is the configuration verification system.
00:57:08.804 - 00:57:36.564, Speaker F: Right. But the whole question is how to inspire the SAT community. And I believe that there's one angle that, that says whether it's a metric, some QBF with probabilities or weights or otherwise, and compile it into, say, small formulas or solve these formulas.
00:57:39.184 - 00:58:01.844, Speaker A: I was going to echo the same point, Nikolai. If you can get a benchmark suite of instances from Ruzia and on, that would be fantastic. I think so. That would encourage the SAT community to be more engaged. Here is a set of hundred challenge problems, for example.
00:58:02.264 - 00:58:04.776, Speaker F: But I think there's also theoretical, I think.
00:58:04.840 - 00:58:15.636, Speaker A: Yeah, exactly. Yeah, totally. Can we hope to get benchmarks? Rosica and Inan there?
00:58:15.740 - 00:58:44.954, Speaker B: Wait, Nan is there. He disappeared. So benchmarks from Upsla, that's the one that I was presenting, are definitely available? I don't know. For Alibaba benchmarks, are they a lot? I mean, are they. It's kind of shame. I will talk to Anan if Alibaba benchmarks are available or even if they can be anonymized and anonymized somehow, I will definitely encourage him to submit and to contact you. I mean, now you know each other, so that's.
00:58:44.954 - 00:58:47.426, Speaker B: That was a totally. Right.
00:58:47.490 - 00:58:48.754, Speaker A: Yeah, yeah, absolutely.
00:58:48.834 - 00:58:49.154, Speaker B: Okay.
00:58:49.194 - 00:58:55.754, Speaker A: Thank you for a fantastic talk. Anon and Uzi cha, because he wouldn't.
00:58:55.794 - 00:59:01.664, Speaker E: Even tell you how many notes there are other than. So I think they're going to be very protective. They're going to.
00:59:02.834 - 00:59:11.374, Speaker B: Yeah, your crash. So I'm putting an Anan on the speaker. Sorry, but that's why I'm answering, because Anan is calling me to tell me that he crashed.
00:59:13.994 - 00:59:25.334, Speaker D: The Internet in my home, was crashed because some guys outside are building subway or something.
00:59:31.774 - 00:59:43.474, Speaker B: Yeah. No, Anand, the question was just do, will you make, are your benchmarks the ones that were into your follow up systems, will they be publicly available or are they already publicly available?
00:59:46.054 - 00:59:47.994, Speaker D: What is publicly available?
00:59:49.694 - 00:59:53.366, Speaker B: The data benchmark is not.
00:59:53.470 - 00:59:58.014, Speaker D: Data is not because our company is. Do not allow that.
00:59:59.634 - 01:00:07.454, Speaker B: So the answer is that he cannot because company doesn't. A system is available if understood properly, but not the benchmarks. But our.
01:00:09.154 - 01:00:25.824, Speaker D: Audit is available. Rip audit. Pass the rs five evaluation. Right. Because it's totally open source. You can ask them to use that. But Cloud canary and the, you know, the system I built in Alibaba is not available.
01:00:26.244 - 01:00:28.704, Speaker B: Okay, thank you.
01:00:29.604 - 01:00:31.184, Speaker A: All right, thanks again.
01:00:35.164 - 01:00:38.380, Speaker B: Don't worry. Don't worry. Yeah. Okay.
01:00:38.412 - 01:00:39.144, Speaker D: Thank you.
01:00:46.604 - 01:00:56.334, Speaker B: Don't worry. It happens. Now we show that networks really can be reliable. Thank you. Bye.
01:00:58.554 - 01:01:13.642, Speaker A: So, thank you, everybody. Thank you for the great speakers. So, we are ending this session today, and I believe, Albert, there is going to be a gather town, or I think there was some kind of a seminar at two, I think, by the, by the.
01:01:13.738 - 01:01:16.094, Speaker C: I'm not sure about this, to tell the truth.
01:01:17.264 - 01:01:18.844, Speaker A: By the mentees.
01:01:19.184 - 01:01:49.864, Speaker B: Yeah, maybe. Can I also say as an organizer, or the other workshops. So on Monday, we are starting with our seminar, our workshop, which will be on software synthesis, and we will have exciting, new, exciting, very tutorial that given by Bernd Finkbeiner. So all of you who would like to know a little bit more. I mean, you're sad people. You're using booleans. You want to learn more about how to use them in the synthesis, please come on Monday for the synthesis workshop.
01:01:52.124 - 01:02:00.344, Speaker A: Okay. There is a comment by Sybil. The comment is, I would be particularly interested in benchmarks for model counting.
01:02:01.164 - 01:02:03.904, Speaker B: Okay, let me send this to Enan.
01:02:05.004 - 01:02:09.426, Speaker A: All right, Albert, is there anything else? Announcement of any sort?
01:02:09.500 - 01:02:13.862, Speaker C: Well, yeah, there's. Now the gather town is in. Link is in the chat.
01:02:13.998 - 01:02:14.398, Speaker A: Yeah.
01:02:14.446 - 01:02:28.142, Speaker C: So, yeah, I just want to thank everybody for the great talks. So today it was nice to see. We started with model counting and then we followed with SMT, and then the very last talk was putting both things together. Right?
01:02:28.318 - 01:02:29.046, Speaker A: Exactly.
01:02:29.150 - 01:02:29.598, Speaker D: Yeah.
01:02:29.686 - 01:02:34.246, Speaker C: So thank you very much for the great talks and see you next time.
01:02:34.390 - 01:02:35.726, Speaker A: Yeah, thank you, everybody. Bye.

00:00:00.920 - 00:00:01.958, Speaker A: Hey, very good.
00:00:02.086 - 00:00:03.514, Speaker B: Right? Thanks, Andre.
00:00:06.854 - 00:00:35.394, Speaker A: Move to full screen. Okay. Yeah. So, there was a very good question before the break. So, we use this reflection coupling, and then if we look at the distance process, it sometimes increases the distance, and it sometimes decreases the distance. And on average, you don't gain. So then how can this be? Maybe I should wait for a few seconds.
00:00:35.394 - 00:01:36.214, Speaker A: Okay, so, on average, you don't gain. And so how can you gain from something like that? And so there are somehow two answers to that. So, one thing you can see that you gain is if you look at the distance between XT and yt, this is really some one dimensional process. And the fluctuations, the noise, is done in such a way that just this one dimensional process gets fluctuations. So somehow, if you look at the difference of the two, it will, of the two brownian motions, it will also give you only something one dimensional, because you do this reflection. And so you have a one dimensional process which now randomly oscillates. And then, you know, if you have something like this, then after some time, it will hit zero.
00:01:36.214 - 00:02:22.590, Speaker A: So it will make the distance process hit zero in a finite time. And once you hit zero, you are at the same position. And if you are at the same position, then you move on with synchronous coupling, and then you stay at the same position. So that's somehow the original argument of Lindweil and Rochas. So they showed that it meets in a finite time, and then from this, you get total variation bounds. Now, I'd like to give a different argument, which is saying that you can get a contraction in such a Wasserstein distance, but only if you choose such a concave function. And so why is that? Well, if you have your distance process, it sometimes goes up, sometimes goes down.
00:02:22.590 - 00:02:57.076, Speaker A: In average, you don't gain. But now you apply a concave function to the distance process. So then when you go up, because the function is concave, you lose less. And if you go down by the concavity, you gain more. So now, if you apply this concave function, then on average, you gain. And in that way, you can really get an average gain, not in the usual l one Wasserstein distance, but in this concave distance. And so this you can use.
00:02:57.076 - 00:03:30.624, Speaker A: And so you can get the following. So our condition is now the following. For example, so we still assume strong convexity, but only outside a given ball. There are also other results which avoid this. But in the simplest result, we assume strong convexity, but outside a given ball with fixed radius r. And then globally, we just assume an upper Lipschitz bound with constant l. So just in one, just one sided Lipschitz bound.
00:03:30.624 - 00:04:41.664, Speaker A: That means we only assume the convexity at large distances. But inside, we only assume this bound here. And we assume that these constants, l, k and r are given. Now, if this is the case, then you can design such a concave function f, which looks like this, and such that with respect to this concave function f, the wf distance will be contractive. So you can show, you can design a concave function f such that the average of f of the distance process is exponentially decaying with a rate c that you can explicitly compute. So, the trick is somehow that if you look at this distance, at this difference here, then you have something like martingale plus something, or even a submartingale. But then if you apply this concave function, it turns it into a super martingale, so into something that is really contracting.
00:04:41.664 - 00:05:06.518, Speaker A: Okay, so the statement is, you can find a concave function f, which looks the following way. It has jump at zero. Okay, I come to the question in a second. It has a jump at zero. So this is because we want to be able to bound the total variation distance. We don't have to include the jump, but we can. Then it starts with slope one.
00:05:06.518 - 00:05:39.124, Speaker A: Then the slope goes down until a certain radius r1. And then afterwards, the slope stays constant. So then it's again linear. So, you can find such a function which is explicitly given and explicit constants c amr, r1. So a is this constant here. M is the slope, c is this decay rate, and r1 is this constant. And they only depend on this parameters l, k and r, such that you get this contractivity.
00:05:39.124 - 00:05:52.124, Speaker A: And this you can prove by Ito's formula. And then as a consequence, you get the contractivity in this wf distance. Okay, so, now there was a question.
00:05:53.424 - 00:05:54.768, Speaker C: Yeah, this is Andrey here.
00:05:54.856 - 00:07:06.314, Speaker A: So, is the dependence on r typically exponential in the little c, the dependence on r? Well, this depends. So, yeah, if you have, I mean, if you have a potential like a double, well, then what will enter is. Yeah, so then you will have something exponential, actually worse than exponential, because somehow the non convexity can cause you to have such. Such a mountain pass here, something like this, that you have to cross. And this will slow down your convergence exponentially in the height of this mountain pass. And that will be reflected here. On the other hand, if you're in a situation where you do not have strong convexity, but maybe still convexity, so maybe some flat piece, then it will not be exponential.
00:07:06.314 - 00:07:58.736, Speaker A: Thanks okay, so that's what you can get. And so all the constants that occur here and this function f, they can be explicitly written down, and they only depend on these parameters lk and r. And so this tells you if your lk and r, if you can choose them in a fixed way, then you get dimension free bounds. Of course, that's a big if. You assume that outside a ball of fixed radius you have strong convexity. Of course, in many situations, the ball will depend on, the radius, will depend on a dimension, and then you do not get dimension free results. Okay.
00:07:58.736 - 00:08:43.940, Speaker A: But if you have that, you get dimension free results. There are also some variants of this approach which give dimension free results in other contexts. Okay, so then this bound also gives you total variation bounds. That was another shortcoming of the synchronous coupling, because you have this jump in the distance function, and because of this, you can just upper bound the total variation distance by this wf distance. And so if you have this wf decay, then you get also bounds for the total variation distance. Yeah, just, just use this inequality here. Okay.
00:08:43.940 - 00:08:56.854, Speaker A: And it also allows arbitrary initial loss. So you don't need any warm start. You can just start at a Dirac mass. You can just start at a single point, ask a question. Yes.
00:08:57.914 - 00:08:58.586, Speaker B: Can you hear me?
00:08:58.610 - 00:09:12.490, Speaker A: Well, yes, somehow. Yeah. Yeah.
00:09:12.522 - 00:09:25.514, Speaker B: So the question is about, so here you introduce this f. Could we prove directly what you're proving without the f, but directly with the indicator of the positive real line? So that's the first question.
00:09:25.674 - 00:09:26.538, Speaker A: And the second.
00:09:26.666 - 00:09:39.094, Speaker B: Oh no. Okay, so it's really just a device to get to tv. I was wondering if this WF gave us a bigger class of test functions in the, in the dual expression than you would get if you were to use directly the t v dual formulation.
00:09:39.674 - 00:10:19.844, Speaker A: So the point about the WF is you can get bounds in all types of norms, but if you want to get contraction, then you have to choose the right norm, and this WF is what gives you contraction. For example, if you choose total variation distance, then first for a long time, your distance will maybe be equal to one or close to one, and then only after a long time, you will get a strong decay of the total variation distance. So you will not have some uniform contraction in time. Now this WF gives you really some way to uniformly distribute the contractivity over time.
00:10:20.224 - 00:10:47.134, Speaker B: Okay, so, yeah, so you use it as a Liapunov function, I guess, but so, so, yeah. And does f in itself like this WF in itself, does it give you like, so it's bigger than the tv. So does it give you, like, are there any instances where you can find functions that, you know, guarantee that a muti and mu are against a bigger class of test functions than the continuous and bounded you would get for tv?
00:10:48.114 - 00:10:55.530, Speaker A: Yes, you can also bound, you can also bound the l one Wasserstein distance by WF, for example.
00:10:55.682 - 00:10:56.722, Speaker B: Okay, thank you.
00:10:56.818 - 00:10:58.254, Speaker A: W one bounds.
00:10:59.034 - 00:10:59.934, Speaker B: Thank you.
00:11:00.434 - 00:11:40.094, Speaker A: Yeah. And you could also do modifications such that you can control higher order Waserstein distances, but that would require some modification of this basic approach. Okay, so that's the coupling approach. So here are some more references. This is the original paper by Lindfall and Rochers. And the way I looked at it was introduced in this paper. Well, it actually goes back to results of Chen and Wang from about 2000.
00:11:40.094 - 00:12:19.134, Speaker A: And then in the way I put it here, it was introduced in this paper Ptif. Okay, so that was one approach. That was the coupling approach. Now, I said there's the second approach, which is more analytic. And at this we look now, so we look at relaxation times and both in l two and for entropy. Okay, so instead of Wasserstein distances, we are now considering divergences, which are some kind of non symmetric distances. Well, not really distances.
00:12:19.134 - 00:13:49.004, Speaker A: So the chi square divergence of a probability measure mu to mu, that's just the integral of the relative density minus one squared with respect to mu if there is a relative density, and otherwise it's defined to be plus infinity. Similarly, you can define the Kolbek Leipler divergence or the relative entropy. So this is just the integral of Rowlock rhodium u if you have a density, and otherwise it's defined to be plus infinity. So you see that these distances are sometimes infinite. Okay, so now a nice thing about these divergencies, which are just two special cases of general divergencies, is that if you take an invariant probability measure and you have a Markov process with that invariant measure, then the chi square divergence of your load time t with respect to the invariant measure is non increasing in t and the same for the relative entropy. So this is something you do not have for Wasserstein distances, but you have for these divergencies. So therefore these are very natural objects to look at.
00:13:49.004 - 00:14:47.784, Speaker A: And now you can define relaxation times for these quantities. And so the l two relaxation time is just defined as the first time where the chi square divergence of your law at time t with respect to mu has decreased by a factor of one over e with respect to the initial chi square divergence for any initial or nu. Of course, this might be infinite, but then this inequality is trivially satisfied. Okay, so the same you can define for relative entropy. So the entropy relaxation time is just the first time where the relative entropy has decayed by a factor one over e for any initial law. Again, note that this can be infinite. So, for example, if nu is a Dirac measure, it will typically be infinite.
00:14:47.784 - 00:15:52.624, Speaker A: Okay, so now you want to control mixing times by these, but this is not possible without further restriction because of these infinities here. So if you have the wrong initial law, your right hand side will just be infinite. And so a statement on these relaxation times will mean, will mean nothing for this initial law. So therefore we have to restrict ourselves to nice initial loss, and that's what is called a warm start. So we have to restrict ourselves to an m warm start. So an m warm start means the initial law has a density with respect to the invariant measure, which is bounded by a constant m. And then we can look at the mixing time which only takes into account initial loss that are already m warm.
00:15:52.624 - 00:16:23.164, Speaker A: Of course, this is somehow restrictive because usually if you can sample from something m warm, then you have already done half of the thing. Usually the problem is that you cannot even create something m warm. Okay, but anyway, this is what we can control in that way. And so then you define mixing time as before. So the first time where the total variation distance is smaller than epsilon, but for any initial law, which is m warm.
00:16:23.784 - 00:16:24.524, Speaker B: Question?
00:16:24.864 - 00:16:25.644, Speaker A: Yes.
00:16:26.184 - 00:16:33.364, Speaker B: So can you show that after the mixing time you still stay warm? So this can be iterated to obtain a rate of convergence?
00:16:35.624 - 00:16:37.080, Speaker A: Say again? What can be iterated?
00:16:37.112 - 00:16:44.924, Speaker B: So if you start warm, is it easy to show that after that at the mixing time the distribution is still going to stay warm.
00:16:46.304 - 00:16:48.496, Speaker A: So basically this condition on the relative.
00:16:48.560 - 00:16:51.764, Speaker B: Density is that preserved by the evolution.
00:16:57.144 - 00:17:03.404, Speaker A: Okay, so that would mean. Okay, so that would mean some infinity contractivity.
00:17:04.264 - 00:17:08.044, Speaker B: So this, it's just a bound, it doesn't have to be contracted.
00:17:09.814 - 00:17:30.514, Speaker A: Okay. Okay. I'm not sure, maybe I'm not too much an expert on m one things. Maybe there are people in the audience who know better than me.
00:17:33.954 - 00:17:37.134, Speaker B: Thanks. We can think about it. The answer is yes.
00:17:46.634 - 00:17:52.894, Speaker A: Okay. Should I continue?
00:17:54.274 - 00:17:55.614, Speaker B: Yes, please.
00:17:56.394 - 00:18:55.788, Speaker A: Okay. Okay, so what you can do now is bound this mixing time from an M warm start by this relaxation times. And actually what you can see is this is also not so difficult to show. I wrote exercise, you can show that you can bound the mixing time by the l two relaxation time. But then you get a factor log m in front and you get something better for the entropy relaxation time, you can bound it by this one, but here you only get a factor log lock m in front. And that's important because often the m will be exponentially large, like if we are in a product space, then your uniform upper bound will typically be exponentially large in the dimension. And then if you take only the logo, that might still not be good enough.
00:18:55.788 - 00:20:05.660, Speaker A: But if you take log lock, it's usually quite good. So that means, in particular from these entropy relaxation bounds, you can also get quite good bounds on mixing times, although restricted to an m. Warm start. Okay, so then the question is, how can you control these relaxation times? And here, the nice thing is that there's a nice analytic theory which gives analytic condition for exponential decay of the chi square divergence and the relative entropy in terms of functional inequalities. And so these are the following. So we introduce the Dirichlet form, which is associated to our generator. So that's just the quadratic form on the l two space with respect to the measure mu, which corresponds to the generator, and by integration by parts.
00:20:05.660 - 00:20:39.194, Speaker A: You see that in our case, this quadratic form is just the integral of gradient f gradient GD. So that's our Dirichlet form. And now you assume reversibility. So you assume that v is minus gradient of u. Part of the results are also true if you do not have reversibility, but in that case they are usually not so sharp. Okay, so we assume reversibility. Then you have the following equivalence.
00:20:39.194 - 00:21:53.364, Speaker A: You have exponential decay of the chi square divergence with prefactor e to the minus t over c if and only if you have a Poincare inequality. That means if and only if you can bound the variance of the function f. So this quantity here by the constant c times the Dirichlet form for any smooth test function. So exponential decay of chi square divergence is equivalent to a Poincare inequality. And similarly, you can show that exponential decay of the relative entropy with this rate is equivalent to a logarithmic Sovolev inequality. And logarithmic Sovolev inequality is a bit stronger than Poincare inequality. It says that you can bound the integral of f squared times the logarithm of f squared, and then you have here some normalization by the Dirichlet form that turns out to be exactly equivalent in the reversible case to the exponential decay of the relative entropy.
00:21:53.364 - 00:22:28.764, Speaker A: Okay, let me give an informal proof of the second statement. This is very informal. The rigorous proof would be much longer. But you see in principle, how it works. So it's just an informal computation with densities. So, let's assume the law at time t is absolutely continuous with respect to our invariant measure, and it has a smooth density rho t. And this density is bounded from below by a strict t positive constant.
00:22:28.764 - 00:23:07.624, Speaker A: I mean, the rigorous part is then how to get rid of these constraints. But this, I skip here. So let's assume this. Now, then you can compute the time derivative of the relative entropy. So that's just the time derivative of the integral of rho t, log rho t d nu. And now you can just formally differentiate under the integral, and then you can use the Kolmogorov forward equation, telling you that the time derivative of rho t is equal to lh. Actually, here in the reversible case, l is equal to l.
00:23:07.624 - 00:23:38.344, Speaker A: But I write it in that way because that's the equation in the general case. So you use this, and then you use the chain rule here. Then you get this expression here. Okay? And now you put the l to the other side. So put an l here. And then, you see, you have here minus the Dirichlet form evaluated at rho T and log rho T. So the one disappears, because if you apply l to one, you get zero.
00:23:38.344 - 00:24:26.064, Speaker A: Okay? So that means you get this one here, minus integral. Nabla rho T. Nabla loc rho t d mu. Now, you can just apply the chain rule and see that this is the same as this expression here, which is minus four, the Dirichlet form of the square root of rho T. Now you insert your loxobolev inequality. Your loxobolev inequality tells you that you can control the relative entropy by this Dirichlet form. And so if you insert that, then you get this bound here, and then you have shown that the time derivative of the relative entropy is bounded from above by minus two over c times the relative entropy, which gives you the exponential decay.
00:24:26.064 - 00:25:35.648, Speaker A: Now, so that's very instructive to do this formal computation, and you can make it rigorous, but the rigorous proof is much longer. Okay, so now you know that if you have ponchary or luxable inequality, then you can bound your relaxation time or your entropy relaxation time. So you can bound the relaxation, the l two relaxation time by one half the Poincare constant in the way I have defined it. I mean, this one half depends on how you define these constants. And you can define the entropy relaxation time by one half the Luxovole constant. And actually, turns out you have equalities here in the reversible case. Okay, so that means your l two relaxation time is really the Poincare constant, basically, which is the inverse of the spectral gap of the generator.
00:25:35.648 - 00:26:25.504, Speaker A: And your entropy relaxation time is really the Luxovalev constant, basically in the reversible case. Okay, so then you're left with the question, how can you bound this constants? And, well, for funcal constants, for spectral gaps, there are a lot of techniques for bounding these. For Loxobolev constants, it's a bit more difficult. But meanwhile, there are also a lot of techniques. And I just give you the most widely used result, which is a combination of the Bakri emery criterion and the Holly sprug perturbation lemma. And this says the following. So suppose your potential u can be decomposed in a strongly convex part v.
00:26:25.504 - 00:27:31.304, Speaker A: So for v, the Hessian is bounded from below by a positive constant kick, and a bounded perturbation w. So for w, the oscillation, that means the supremum minus the infimum is bounded by a constant, by a finite constant m. So, for example, if you have such a double well potential, then you can do that. So you can find a strongly convex potential, for example, which looks at the outside like this one, looks on the outside like this one, and then on the inside stays strongly convex, something like that. And then you see your potential is a bounded perturbation of this strongly convex thing. So you can apply this criterion here. So if you have that, then you get a loxobolev inequality, and the constant is given by k multiplied by e to the m, where m is the size of this perturbation.
00:27:31.304 - 00:28:47.034, Speaker A: Okay, you have also other things like you have factorization lemmas to get locks overlift in higher dimensions, and so on. Very nice reference if you want to know more about these analytic approaches. The standard reference is the book by Bacri Jean till de doux on analysis and geometry of Markov diffusion operators. And the second reference I gave here is some shorter introduction to Loxorlev inequalities. So if you somehow want the mainstream some of the main statements in a more brief form, that might be another possibility. Okay, any questions up to here? Okay, so then we are through with the continuous time Markov processes. But now, of course, we want an algorithm, so we have to discretize time.
00:28:47.034 - 00:29:48.144, Speaker A: And if we do that, we end up with what is usually called longevin algorithms. But really it refers to the overdamped longevity dynamics. So we again look at the overdamped longevity dynamics as we introduced it before, and now to get an algorithm, we discretize this. And, well, the easiest way to do is just to do an Euler discretization. Of course, you can also use more advanced discretization schemes, but also Euler discretization here works quite well in that case. Okay, so that if you do that, if you look at the Euler discretization and the transition step is given by. So if you're at position x, then you move to x minus h times navla U of x plus square root two h times z, where z is standard, normally distributed.
00:29:48.144 - 00:30:28.404, Speaker A: So you have an iteration with this transition step, and that defines a Markov process in discrete time. So a Markov chain, of course, you have to fix the step size. Hmm. Okay, so that gives the Markov chain, and the transition kernel has a density, which I have written down explicitly here. Okay, so you have this Markov chain. So the first possibility is you now say this Markov chain is an approximation of my diffusion. So I just use this Markov chain for approximate sampling.
00:30:28.404 - 00:31:09.824, Speaker A: So I don't change anything. I just use this Euler discretization. And if you do that, then it's called the unadjusted longevin algorithm. So the unadjusted longevin algorithm is just simulating the Euler discretization of the overdamped longevin diffusion. Ok, so now let's see which problems could occur with this algorithm. So let's again look at our simplest example where our target distribution is the standard normal distribution. So that means gradient of u of x is just x.
00:31:09.824 - 00:31:56.074, Speaker A: Now in that case, if you look at that process here. So from x, you move to x minus h times x plus square root two h z. This is just an autoregressive process. So this is just a very simple gaussian process in discrete time, and you can compute everything explicitly for this process. In particular, you can easily find the invariant measure, and it's this one. So it's a normal distribution with mean zero, and the covariance matrix is the identity, but multiplied by a prefecture. So that means it's not the same as our target distribution mu.
00:31:56.074 - 00:32:42.748, Speaker A: So our discretization has a different invariant measure than the diffusion process. Of course, that's not a surprise if you discretize. Why should you preserve the invariant measure if you just discretize in some way? Now? Okay, so we have a different invariant measure, and that's of course a disadvantage. That means you have a bias, but not just a fixed time, but even asymptotically a bias that does not vanish in the limit. So if you fix your step size h, then you will just approximate the wrong invariant measure. So you can run as long as you want. You will not get closer than the error which is between these two invariant measures.
00:32:42.748 - 00:33:10.248, Speaker A: So this you have to take into account. On the other hand, of course, if h is small, then this asymptotic bias gets small. And now let's say, let's see how small it is. So we look at the l two Wasserstein distance between u, h and U. We could also look at some other distances, but this is the easiest one to compute. Yeah. So that was the minimal of the l two norm over all couplings.
00:33:10.248 - 00:33:48.024, Speaker A: And here, turns out that in this case, the synchronous coupling is optimal because these are both gaussian distributions. So both centered gaussian distribution. So you find that the synchronous coupling is optimal. And so therefore, you can exactly write this l two Wasserstein distance in this form here. So this is just a synchronous coupling between z drawn from nu. And this is a random variable drawn from nu h. That's the synchronous coupling of these two.
00:33:48.024 - 00:34:23.623, Speaker A: Okay. And now this you can compute, of course, you get exactly this value here, which behaves like one four h d to the one half. So that's the bias between these two measures. And now you want to make this smaller than some given epsilon. And then you see, in order to do that, you have to choose h of the order d to the minus one half times epsilon inverse, at least. Yeah. So here you see a disadvantage towards metropolis algorithms.
00:34:23.623 - 00:35:04.444, Speaker A: So for metropolis algorithms, if you have exponential convergence to equilibrium, then this will only depend logarithmically on epsilon inverse. But here it will really depend on epsilon inverse because you have this asymptotic bias. On the other hand, what you get here is d to the minus one half. So you have to choose h of this order at least. Yeah. So then the question is, is this also enough? And you can give a positive answer to that in certain cases. And I've just stated a simple result, but there are much better results available.
00:35:04.444 - 00:35:56.384, Speaker A: So here I assume strong convexity. Just for simplicity, this is not necessary. I assume global Lipschitz. And then the third thing I assume is that you have a strong error bound on the Euler discretization. So you can bound the strong error of the Euler discretization. So that means the l two norm of the difference between the Euler discretization and the diffusion uniformly on a finite time interval, say zero, one for the diffusion by some constant m times h. Then what you get is that you can bound this distance between the two invariant measures by this constant here times mh.
00:35:56.384 - 00:36:54.734, Speaker A: And as a consequence, you get that you can bound the distance of the Euler chain after n steps to equilibrium in this way here. Okay. As I said, this can be relaxed substantially. And actually, the real expert on this unadjusted longevity algorithm is Alain Dumus, who's also participating in this program. And you can find his papers with Eric Mullin and with debauch, which give much better results than this. But the question that you have to answer now is, how does this m depend on the dimension? And this is something we have looked at in a recent work with Allan. And it turns out that the m depends on the dimension, like d to the one half for nice models.
00:36:54.734 - 00:37:25.034, Speaker A: So that's the same as in the gaussian case. But for general models, it might have a worse dimension dependence. So that's something interesting for actually a quite broad class of nice models. You really get this d two to the one half dependence here. But there are, I mean, we do not have really an example, but it seems quite clear that there are models where you get this worse dimension dependence.
00:37:25.614 - 00:37:28.114, Speaker B: When you talk about models, you're talking about you.
00:37:28.804 - 00:37:31.068, Speaker A: Yes, I'm talking about you. Exactly.
00:37:31.156 - 00:37:34.108, Speaker B: And so, what kind of properties do you need for you? I mean, is it like.
00:37:34.156 - 00:38:23.304, Speaker A: I mean, yeah, basically, it's. Yeah, there's some bound on. What is it? So, on, you have to take the Laplacian of the gradient of you. And I think you have to take the squared Euclidean norm, and you have to look at how that depends on the dimension. And it turns out that, for example, for product models, or for models that have a density with respect to a gaussian, or for mean field models and things like that, this dimension depends. It's like this, d to the one half. But we believe it's not the case for general models.
00:38:23.304 - 00:38:35.644, Speaker A: Was there another question?
00:38:36.624 - 00:38:38.204, Speaker B: No, I just said thank you.
00:38:38.664 - 00:39:24.000, Speaker A: Okay, thanks. Okay, so that's the unadjusted longevity. And so, alternatively, of course, you can now use the Euler step just as a proposal for metropolis Hastings. And if you do that, then you get the metropolis adjusted longevin algorithm. And this now has the correct invariant measure, but it's mathematically harder to analyze. Now, first, you can get a negative result again using conductance. So you can show that again.
00:39:24.000 - 00:40:03.754, Speaker A: If you have gaussian target distribution, then you have a similar result as for Randen walk metropolis. So the mixing time, if you start in the neighborhood of zero is lower, bounded by e to the h squared d over four. So for random walk metropolis, you had here h times d. Now you have h squared times d. So you have gained something. Okay. But it tells you that if you want to start from a cold start, if you, for example, want to start at zero, then you have to choose h of order d to the minus one half, so you don't have a chance.
00:40:03.754 - 00:41:15.194, Speaker A: Otherwise, this is only for a cold start. So for a warm start, it might actually improve here. Okay. And then the question is, can you also have a converse result? And there's a very nice paper I maybe would be interested in to learn more, because there are some authors here in the audience, I think, which gives some converse result and says that you can get mixing from a warm start in order d, log these steps. And that was actually an open problem, because together with this, with these acceptance rejection steps that you have in Mala, it's not so easy to identify the precise order of the algorithm. Okay, then I come to the last part. Somehow, all these algorithms were quite traditional that we looked at so far.
00:41:15.194 - 00:42:20.240, Speaker A: And recently, there's some interest in looking at MCMC methods, where you use degenerate noise. What's the idea behind that? Somehow, vaguely, the idea is if you have too much randomness, then this could lead to slow mixing, because you have something to diffuse it, like diffusive behavior, which is slow, and other things. So injecting too much randomness into your system might not be so good. So somehow, if you inject less randomness, it makes the mathematical analysis harder. But it might be beneficial. Then we come actually to a very parallel thing, like we saw in the optimization. So in the optimization, then, we were also looking at second order methods after the first order methods, and we have something similar.
00:42:20.240 - 00:43:12.274, Speaker A: Now, here we also look at second order, and the first 2nd order thing in continuous time is longemand dynamics. So, in longevity dynamics, if you look at it as an equation for x, it's now a second order SDE. But we write it as a first order SDE by introducing the velocity, that means the derivative of the position. So we change the state space now to having position and velocity. So that means the state space is now rd times RD. But the velocity is not only artificial, so we are only using it to invent new dynamics from the point of view of sampling. From the physical point of view, of course, it's a different story.
00:43:12.274 - 00:43:49.214, Speaker A: Okay, so our SDE is now derivative of position is the velocity, and then the derivative of the velocity is minus the gradient of u of x t. And if you do this on its own, then this is just hamiltonian dynamics. And hamiltonian dynamics turns out to have the invariant measure that we will be interested in. But, of course, it's usually not mixing because it preserves the energy. And so it's not ergodic. So we have to add something to it to make it ergodic. And then there are two possibilities.
00:43:49.214 - 00:44:40.246, Speaker A: About the second possibility we will hear this afternoon in the talk by Nisid Wischnoy, which is hamiltonian Monte Carlo. The first possibility is to add something like this. You add brownian motion times a parameter square root two gamma, which corresponds to random collisions, and you add a damping term minus gamma vt. This equation here is really somehow physical brownian motion. So this is really like particles in physics are moving if they are driven by brownian motion. Okay? So in physics, the parameter you introduce here is the friction gamma. You could also introduce a mass here, and this might actually be a matrix.
00:44:40.246 - 00:45:26.852, Speaker A: But I dropped this here for simplicity. Okay, so that's longewin dynamics. It has a unique solution for a given initial law. It's a Markov process on r. Its invariant measure is actually the Boltzmann Gibbs measure, which is, in this case, it's just the product of the measure mu we are interested in, and a standard normal distribution. So that means if we can sample from this measure, then we can also sample from mu, because mu is just the first marginal of the measure. Okay, and the Boltzmann Gibbs distribution, this has a density, again, with respect to the Beck measure, and the density is just e to the minus the hamiltonian.
00:45:26.852 - 00:46:11.454, Speaker A: So e to the minus the total energy. And total energy, if the mass is equal to one, is just u of x, the potential plus one half v squared. Okay? So that's the dynamics that preserves this measure. And somehow, since it's a second order dynamics, and since we only inject the noise in the second component, we have less randomness. Now, you can also say it's moving more smoothly. Brownian motion is wiggling around all time, but here it's moving more smoothly because the brownian motion is only in the velocity. And if we go to the position, then we are integrating once more.
00:46:11.454 - 00:46:46.234, Speaker A: We denote by pt the transition function of this Markov process. Okay. And then we might ask about the mixing properties of these dynamics. And there we again look at our running example. So we look at a normal distribution as a target. Now, I can take a normal distribution with a general covariance matrix c. So C is a general symmetric positive definite matrix.
00:46:46.234 - 00:47:29.694, Speaker A: That's our target distribution. And so that means our function u of x is now this one. And then the SDE can now be written in this form. So the derivative of xv differential of xv is just minus a matrix a times xv dt plus noise. So that means that's a linear SDE. And the matrix a takes this form. Okay, so you see that the process xv is a gaussian process because it's described by a linear drift perturbed additively by brownian motion.
00:47:29.694 - 00:48:24.764, Speaker A: And so in that case, your solution to the SDE is a gaussian process. So that means all laws are gaussian and can be computed explicitly. Okay, and that allows us, again to study this exactly. So, in particular, we can look at the Wasserstein contraction coefficient, and it's easiest to do in l two. So what is that? So we look at the time t and then we see how much the Wasserstein distance has decreased up to time t. So we look at the Wasserstein distance between the Lord time t when starting at Nu and the Lord time t when starting at Nu divided by the Wasserstein distance of nu and nu. And we take the supremum over all new and, uh, okay, so that's the Wasserstein contraction coefficient.
00:48:24.764 - 00:49:03.074, Speaker A: And you can show that actually you can restrict yourself here to Dirac measures. So you can replace mu and Nu by Dirac measures. And you get the same supremum here. So this is the same as the supremum over all x not equal to y. And if you insert here from mu and Nu Dirac measures, then you get here Ptx, you get here Pty, and here you get the Wasserstein distance of Dirac measures delta x and delta y. And that's just the euclidean distance of x and y. So you can write your Wasserstein contraction coefficient in this form.
00:49:03.074 - 00:49:56.440, Speaker A: And now in this case, ptx and pty are both gaussian measures with the same covariance. And so therefore you know that the synchronous coupling is optimal. So therefore you can compute this w two distance. And if you do that, you'll find that it's exactly equal to the operator norm of e to the minus t eight, where a is this matrix. Okay, and now you're in business because you know how this operator norm behaves. It behaves asymptotically like e to the minus t lambda, where lambda is the bottom of the spectrum of a. So the infimum of the real part of the spectrum of a and this you can compute explicitly for this matrix because you can diagonalize.
00:49:56.440 - 00:50:52.134, Speaker A: And so you just have to do it for two times two matrix. And then you find that this decay rate lambda is given by gamma over two times one minus the square root of this positive part here, where the sigma I squared are the eigenvalues of the covariance matrix. Okay. And what this means, you see best in a picture. If I now draw lambda as a function of gamma, then you see as long as gamma is small, then this number here will be larger than one. So this positive part will vanish and you will just have gamma half. So as long as gamma is small, this will increase linearly in gamma, the lambda, and that's the underdamped region.
00:50:52.134 - 00:51:35.062, Speaker A: Now, of course, if gamma is zero, if you don't put noise, you do not have mixing, it's not ergodic. Then if you put noise, if you put more noise, it increases linearly with the noise. But now it does not increase all the time. It stops increasing at a certain point. And this is the point where in the spectral decomposition for a, you change between real and non real spectrum. So at this point it changes and then it goes down again. So you see, your decay rate depends on gamma, but it's not optimal to choose gamma as large as possible.
00:51:35.062 - 00:52:12.714, Speaker A: So to inject as much noise as possible, but there's a certain amount of noise that gives you the fastest mixing. And this is exactly given by gamma equal to two over the maximum of the sigma is. And if you do that, then your lambda is just one over the maximum of the sigma is. Now, sigma is something like standard deviations. So that's something like one over the size of the system somehow. So this is kinetic behavior. So your rate behaves like one over the size of the system.
00:52:12.714 - 00:52:48.774, Speaker A: So if you choose the second order dynamics and you're in this region between under them and over them, then you get this kinetic behavior, which is faster than diffusive behavior. And again, there's a connection to yesterday where we also saw this three, this factor three, which was at somehow a borderline between underdamped and over damped. And what's the best you could do?
00:52:53.394 - 00:53:08.778, Speaker B: Question, can you make the same analysis in this gaussian case? If you decouple the gamma that you put in front as a friction coefficient and the one that you put as a noise term? If you take two parameters for those, yes, you can.
00:53:08.866 - 00:53:09.562, Speaker A: You can.
00:53:09.698 - 00:53:12.494, Speaker B: That's going to tell you to take the same value.
00:53:15.154 - 00:53:46.714, Speaker A: You get a different invariant measure. If you don't take the same value, I mean, taking the same value. So, if we look at the SDE here, we have to do it in this way if we want to get the right invariant measure. So you can put, say, some other factor here in front, but this will change your invariant measure. Then the invariant measure will not be e to the minus u, but, for example, e to the minus beta u.
00:53:49.694 - 00:53:51.270, Speaker B: I have a question, too.
00:53:51.462 - 00:53:52.234, Speaker A: Yes.
00:53:53.294 - 00:54:06.604, Speaker B: So, in this gaussian example, the, the potential, is it, like max, one over sigma I strongly conducts. So is the contraction rate exactly the same as what we have for the overdamped langevin?
00:54:07.984 - 00:54:28.174, Speaker A: No, it's better than for over damped longevance. So, for over damped longevity, you would get sigma I squared here. So for over damped longevity, this is diffusive. And so therefore, you get one over the system size squared, but here you get just one over the sigma I.
00:54:28.594 - 00:54:32.574, Speaker B: So, actually, like, the eigenvalues of c are the sigma I squared.
00:54:35.074 - 00:55:24.554, Speaker A: Yes, the eigenvalues of c are the sigma I squared. So sigma is. Are like standard deviations. Okay, good. So this shows that you can really gain by degenerate noise, but that you have to do it in the right way, that you really have to inject the right amount of noise. And, of course, this is only in the gaussian case. And now you can ask, can you prove something like this more generally? And there are indeed some results doing that recently.
00:55:24.554 - 00:56:13.874, Speaker A: So, first, in the strongly convex case, you can use synchronous coupling, and that has first been done in a paper by Chang et al. And then improved in a paper by Dallali Lian and Riot Durand. Now, in the non convex case, you can again use some reflection coupling, but not the one I introduced. You actually have to design some special reflection coupling for this degenerate noise situation, which only couples to a hyperplane. But then you can also get results in corresponding results in non convex cases. So these are the coupling approaches. And then recently, there has been a very interesting analytic approach by Xiao Lu and Wang.
00:56:13.874 - 00:57:08.140, Speaker A: So they consider a fairly general case, assuming a warm start, and what they use is a functional inequality, but actually a new one, a space time inequality. And so this is a recent approach due to Armstrong, which allows you to deal with such situations with degenerate noise. And this seems also to be quite powerful and to give quite interesting and sharp results. So seems certainly worth to look more detailed also in this approach. Okay, so that was. And then we will hear in the afternoon about hamiltonian Monte Carlo. And the difference is easily explained.
00:57:08.140 - 00:58:24.090, Speaker A: You again have the hamiltonian dynamics, but instead of adding this part in the diffusion, you just run hamiltonian dynamics for some time, and then you inject your noise by choosing a new velocity, either completely newly choosing the velocity or partially updating the velocity. So if you do that, you get another dynamics, which corresponds to something like Boltzmann equation. And so then we can ask the same question, what can we say about this dynamics? And about this we will hear in the talk by nisid this afternoon or for me this night? Okay, that's all on my talk. Since I can't be here, I thought it might be nice if you. Later, you have questions that there's a possibility to ask. So I will be available tomorrow on Zoom before the conference starts on this zoom link. Okay, thank you very much.
00:58:24.090 - 00:58:33.774, Speaker A: And then, yeah, other questions. Questions.
00:58:39.954 - 00:58:52.014, Speaker C: So you. The longevity diffusion can be seen as gradient descent with noise. So what if we try to do it with, say, Newton steps like that is normalize the gradient with the Hessian at the point.
00:59:00.824 - 00:59:28.014, Speaker A: Yes. So, okay, so there's also the riemannian manifold HMC method. I'm done, but I haven't considered this. But maybe this goes in this direction. I don't know.
00:59:33.074 - 00:59:38.106, Speaker C: I think there's some, like, other, I think Ozaki discretization or something. I guess there's some other version of.
00:59:38.130 - 01:00:16.354, Speaker A: This that does do, like a hessian type, like Newton type of update, but I'm not quite sure, like, how much of analysis there is. Yeah. So definitely, I'm not aware of, of results in this direction. It might be an interesting thing to look at. Definitely. Thank you. It looks like Nasheeth added a comment on the chat.
01:00:16.354 - 01:00:24.014, Speaker A: All right, any other questions? 1 second.
01:00:31.154 - 01:01:23.002, Speaker C: Yeah, so I was curious about this result that you mentioned about. I mean, that you can pick somehow the f, I think it was when we were. I mean, there was an f that would define a metric, and under this metric, you had this contraction, and it was kind of like one specific one that would work. And yesterday we heard about kind of geodesic convexity, and there was one similar situation where you had a function that with the wrong metric, you didn't have any sort of convexity, but if you choose the metric appropriately, then suddenly you have kind of genetic convexity. So I was wondering if there's somehow a connection between these two situations. Maybe if there is something like that. Like that you're picking your metric in such a way that your f somehow is making something juicy come back in some sense.
01:01:23.002 - 01:01:25.134, Speaker C: I was wondering if there's such a connection.
01:01:28.674 - 01:02:03.044, Speaker A: Yeah. I'm sorry I did not yet attend the talk for me night talks yesterday because that was around midnight. I'm still planning to listen to the video, so. Yeah. Yeah. I don't know. Yeah.
01:02:03.044 - 01:02:09.828, Speaker A: All right. If there are no other questions, please.
01:02:09.876 - 01:02:11.644, Speaker B: Join me in thanking Andreas again.

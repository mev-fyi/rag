00:00:00.200 - 00:01:08.994, Speaker A: Machine learning is becoming increasingly important in the context of mechanism design, with many high impact applications like pricing and online marketplaces and designing ad options. And in this talk, I'm just going to give a very brief overview of my research and mechanism design in three areas, overfitting, incentives and privacy. And I'll start off with overfitting. So, for those of you who are not affiliated with the Learning and Games seminar or workshop, I thought I'd just give a one slide overview of a classic mechanism from mechanism design. This is an auction for selling a single item, and this is called the second price or Vickrey auction with a reserve named after Nobel Prize winner William Vickery. So this is a mechanism parameterized by a single parameter row, and you can think of row as a lower bound on the amount that the seller is willing to get for the item. So the first step is to collect a bid from each agent who's participating in this auction, which is meant to represent how much they value this item.
00:01:08.994 - 00:02:29.344, Speaker A: Next, we give the item to the highest bidder if they bid at least this parameter row, and we charge the winner the maximum of row and the second highest bid. There are a lot of reasons why this is a classic auction for mechanism design, maybe the most important of which is that given this kind of interesting pricing role, you can prove that the agents are always incentivized to bid. Truthfully, there's nothing they can gain by being strategic with their bid. So it's called the incentive compatible mechanism. There are many other types of parameterized mechanisms out there beyond this one Vickrey auction. So, for example, there are many types of pricing mechanisms where you set prices for the items and the agents come and buy the items that maximize their utility, various other types of auction mechanisms, and even randomized mechanisms like batteries. So what might it look like if we were to hope to design some these mechanisms, or tune these mechanisms parameters using machine learning? Well, to answer this question, I'm going to make a standard assumption that has been made for decades in economics, which is that the agent's values are drawn from some distribution d, and we're going to assume that this distribution is unknown.
00:02:29.344 - 00:04:15.434, Speaker A: The way that this mechanism configuration procedure would look like is first we fix some parameterized mechanism family like this set of second price options with that tunable parameter row. Next, we receive a training set of agents values drawn from this unknown distribution d, and we perform some optimizations and we find a parameter setting which has high average empirical revenue over this training set. And the question we want to answer regarding overfitting is, will that parameter setting also lead to high expectations revenue on this unknown distribution d or in other words, will it have high future revenue when we actually go and field this mechanism? And these questions of overfitting have been of significant interest in this economics and computer science community over the past few decades. And I and many other people have worked on this question, and I wanted to tie it into my thesis research more generally, which was more broadly about algorithm design. So, to make this connection, I want to think about a mechanism as a special type of algorithm, where the input is a description of the agent's values for the items for sale, and the output is an allocation of those items and the payments required of the agents. So really a mechanism is just a special type of algorithm with these incentives issues that you have to take care of. So in mechanism designed via machine learning, the overall goal is to use data about the agents to optimize the mechanisms revenue.
00:04:15.434 - 00:05:31.774, Speaker A: In my thesis, research was more broadly about algorithm designed by machine learning. So using data about the particular application domain which we'll be using this algorithm, how can we optimize the algorithm's performance? So, for example, its runtime, its solution quality, or in these economic contexts, its revenue? This kind of auction design via machine learning has been studied pretty extensively from an applied perspective in artificial intelligence over the past two decades or so. But this line of inquiry was really kicked off from a theoretical perspective by Gupta and roughgarden about five years ago. And we've thought about these topics of using machine learning in the context of algorithm design for integer programming algorithms, computational biology algorithms, clustering and routing. And we have discovered overarching structure linking these seemingly disparate domains, as well as mechanism design, which has allowed us to provide very broadly applicable guarantees. Okay, so now back to mechanism design. I want to give a high level overview of what kind of questions I've thought about in the context of incentives.
00:05:31.774 - 00:06:37.474, Speaker A: So, although in mechanism design we love incentive compatible mechanisms, many of those mechanisms that are typically used in practice are actually manipulable. So agents are able to gain by lying about their true values. This is true, for example, in ad auctions and mechanisms for selling electricity, treasury bill auctions. And increasingly there's been an interest in designing auctions using neural networks, and the resulting auctions are typically not incentive compatible. So in an EC 19 paper with Nina Balkan and Toma Santolmon, we showed how to estimate how far a manipulable mechanism is from being incentive compatible. Again, using samples from this unknown distribution over agents values, or more broadly, over agents types. So using samples, we show how to estimate the mechanisms ex anti approximate incentive compatibility factor.
00:06:37.474 - 00:08:27.216, Speaker A: The key challenge in doing so is that we must bound the amount of utility the agent can gain by reporting any type over their entire type space just using samples. And this is challenging because in these mechanism design contexts, the agents utility functions have a ton of jump discontinuities. There are no notions of Lipschitz continuity or continuity convexity that we're able to depend on to provide these types of incentive compatibility guarantees. Okay, and now I'll conclude with a couple of slides on my research related to privacy and mechanism design by machine learning. So these approaches to using machine learning for mechanism design typically rely on a lot of sensitive information, including historical purchase data and the training set, uniquely identifiable browser information, and even browsing histories, which are often revealed to advertisers. So my research in the context of privacy has looked at how can we preserve the privacy of data in the training set when we're doing this type of mechanism designed by machine learning and more recently looking into the idea of masking information about users which you present to advertisers during ad auctions. And I think this is a really interesting and important area because as we've all experienced over the past couple of years, this need for data for the sake of revenue maximization has caused companies to develop some pretty perverse incentives, addicting us to their platforms in order to show us more ads and in order to collect more data about us.
00:08:27.216 - 00:08:34.684, Speaker A: So I'd especially really love to talk to people and learn more about this area this semester. So that'll wrap up. Thank you.

00:00:00.080 - 00:00:46.690, Speaker A: Welcome to the fourth morning of the satisfiability boot camp. It's a pleasure to introduce Jakob Nordstrom, who's talking about pseudo Boolean solving and optimization. Jakob got his PhD from the KTH Royal Institute a number of years ago. He spent a couple years at MIT. He was on the faculty at Copenhagen for quite a few years, maybe seven or eight years at least, and then is now a professor again at KTH. He works extensively in cutting planes and pseudo boolean solving and resolution and resource trade offs and various, I guess, related topics. He's, I would say, one of the.
00:00:46.690 - 00:01:04.964, Speaker A: One of the few people who really has feet firmly planted in both the pure and applied camps of satisfiability solving. So that's a very nice place to be. And so I guess without further ado, Jakob, the floor is yours.
00:01:05.824 - 00:01:42.384, Speaker B: Thank you, Sam. Right. I'm Jakob Nostrand, currently splitting my time between the University of Copenhagen and Lund University, commuting across the bridge. Except now in Covid times I don't do that. But today I'm lecturing from Lund University because we were allowed to do that when we're teaching or lecturing. So this is a tutorial on sudo Boolean solving and optimization. And it's divided into four parts which are pre recorded but were uploaded, shall we say, fairly late.
00:01:42.384 - 00:02:33.148, Speaker B: And so perhaps rather than being preparatory viewing, you can for this talk, you can view this pre recorded lecture as providing more in depth information. And this live talk is more like an invitation for you to go and watch these videos. So I'll start quickly by setting up some preliminaries and then I'll talk about solving of sudo Boolean decision problems. Then I'll talk about optimization problems. And finally, I hope to touch a bit on also on mixed integer linear programs programming. So let's get started. So what does this pseudoboolean thingy mean? Other than that, it's obviously a cool name, as I've discussed with Albert, like who wouldn't want to do pseudo Boolean solving? So it turns out it's apparently a fairly well established terminology since the 1960s.
00:02:33.148 - 00:03:14.564, Speaker B: What it is, you know, a pseudo Boolean function is what we theoreticians would call a function over the boolean hypercube. That's what it is, no more, no less. So the inputs are bits, true or false, which we think of true being 10 being false for the rest of this talk. And then the output is a real value. So throughout this talk we'll think about a slightly restricted setting where we insist that all pseudo boolean functions that we see will actually be linear forms. This isn't a huge restriction in the sense that if you have a non linear problem, you can always linearize, but I won't talk about that. So everything you see today will be linear.
00:03:14.564 - 00:04:02.768, Speaker B: And even for linear functions, it turns out that this is very expressible of formalism. Like most of the, say, np complete problems we know and love are very natural to represent the pseudo boolean problems. But the name of this program is satisfiability. So why should we care about going beyond sat? Well, because the pseudo Boolean format is so much nicer than conjunctive normal form. For instance, say that you want to say that a sum of six variables is at least three. Then you can just write it down in pseudo Boolean form as the linear inequality. If you want to write it as a set of clauses, then it blows up terribly and you even have to check it's not even clear what these clauses mean, and you have to check that this is directly the correct representation.
00:04:02.768 - 00:05:12.064, Speaker B: And I hope in fact, in some previous version of this talk I even had a typo in this representation without noticing, but I hope it's correct now. So there's a terrible blow up compared to pseudo Boolean form for CNF. And also, as we'll talk about a little bit, once you have your functions in pseudo Boolean form, you can actually do more sophisticated and stronger reasoning on them than you can do with conflict driven clause learning. However, what's nice is that you're still fairly close to sat, so you can try to piggyback on all these amazing improvements that have been happening over in the SAT community. Also, you can try to borrow ideas from zero one integer linear programming, which the mixed integer linear programming communities and other communities that has been making tons of progress over the last decades. And somehow sudo boolean solving sits right there in the middle. So when I say a sudo boolean constraint, then I mean some linear form compared to an integer a where the comparator is well greater than or equal or less than or equal or equality.
00:05:12.064 - 00:06:25.938, Speaker B: Li throughout this talk will be a literal that is a variable or a negated variable where negation is bar and the semantics is that they cancel to produce a 10 is false and one is true. And in fact, I'll also immediately drop this generality and insist on so called normalized form. We will only acknowledge greater than or equal inequalities. We will insist on all AI's and A's being non negative integers, and it's not so hard to see that this is actually without loss of generality, because by this rule you can always, if you have a negative coefficient, you can substitute with the literal of the opposing sign and rewrite. And in this normalized form we'll refer to a as the degree of falsity of the constraint. Okay, so, so what are some constraints that we know of? Well, if you have a clause that's clearly a pseudo Boolean constraint, because you just take the sum of the literals and claim that at least one of them is true, we saw cardinality constraints that are more general. And then you could have a even more general, fully general pseudo Boolean constraint, something like, I don't know, x one plus two, x two bars plus three, x three plus four, x four bars plus five, x five greater equals seven, something like that.
00:06:25.938 - 00:07:02.364, Speaker B: So we'll operate on these kind of constraints, and a pseudo Boolean formula is a conjunction or a collection of such constraints. And then there are two problems we can consider. One is the solving problem where we are given a formula. We want to know whether it's satisfiable or feasible. The other problem is when we also have an objective function that I will try to write as summing over I w up IlI, which we want to minimize. We always want to minimize our objective. This is without loss of generality if you care more about maximization problems than just negate your objective function.
00:07:02.364 - 00:07:33.436, Speaker B: So that's the preliminaries that we need. And now we'll talk about, we'll talk about how to do pseudo Boolean solving and optimization. A very related area is so called Max sat solving. So we'll talk a bit about that, and I hope to be able to talk also about integer linear programming or more generally. Usually these solvers are called mixed integer linear programming solvers or MIP solvers. And if you have any questions, please raise your hand. Please write something in the chat or use the Q and A.
00:07:33.436 - 00:08:18.060, Speaker B: I'll try to keep track of that. If anything is unclear, I should say that at some points in this talk I will go a bit fast intentionally. And when this is the case, I sort of have added a warning to the slides. And this is because you will find more in depth explanations in the pre recorded lectures. So, pseudo Boolean solvent, how would you do it? You're given a pseudo boolean formula. You want to determine feasibility. One approach is to just keep your input in pseudo Boolean form, and then whenever it implies something you do as you propagate as a conflict driven close learning solver would have done, and then you just run standard CDCL conflict analysis.
00:08:18.060 - 00:08:59.396, Speaker B: So this will be in principle indistinguishable from running CDCL, except that you happen to have your input in another form. So I won't say more about it than that because there's not too much to say about it. Another more sophisticated approach is to re encode your problem eagerly to clauses and then run conflict driven clause learning. This is, I think one of the early solvers doing this with amazing success was miniset plus. Two good solvers these days are OpenWbO and naps. And then another approach which is dear to my heart. So we somehow want to harness conflict driven solving ideas.
00:08:59.396 - 00:09:43.584, Speaker B: And the eager approach says let's go back to CNF and use the algorithm over there. And native reasoning with Sudo Boolean constraints goes in the opposite direction. It says no, no, no, let's keep our sudo Boolean format and let's try to lift conflict driven learning to this setting. And most of the talk will focus on this. And the two most well developed modern solvers using this approach that I know of is Sat four J, developed by the team in Lance, France and Roundingsat, which is from my research group. Okay, so, but let's talk briefly about re encoding to CNF. So as we saw on the second slide or something, representing a pseudo Boolean format in CNF is not necessarily a good idea.
00:09:43.584 - 00:10:32.114, Speaker B: We can incur an explanation blow up. So to avoid this, we use new extension variables to get a more compact encoding. And sort of, without going into too much details, the idea is that you, given a pseudo Boolean constraint, write down some boolean circuit evaluating whether this expression is true or not given your inputs. And now once you have this circuit, there's a standard way, the so called satin transformation, to write down a CNF formula that enforces a correct evaluation of this circuit. And at a high level, this is kind of what you do. And then what circuit are you going to choose? Well, in the prerecorded material I have some examples, sequential counters, the totalizer encoding, the other network encoding. I won't go into details about this for time reasons.
00:10:32.114 - 00:11:43.736, Speaker B: I just want to say that there are two things that you would want from an encoding at least. One is that if I have a CNF formula f sub C, then encodes a pseudo Boolean constraint, then, and if I have some partial assignment under which the pseudo boolean constraints propagates some consequences, propagates some variable assignments, then I would like my CNF formula to propagate the same things. So that from the solver point of view, like intuitively speaking, from the solver point of view, it doesn't really matter whether it's operating on the sudo Boolean constraint or the CNF encoding, the propagations are the same, and this is what the solver cares about. In particular, if a partial assignment already falsifies the constraint, then we would like to see that the CNF encoding propagates the contradiction. And this is often referred to as generalized arc consistency, borrowing terminology from the constraint programming community. Another thing that would be nice is that your encoding isn't too large. You want it to be polynomial size, and you really care about the polynomial also.
00:11:43.736 - 00:12:34.460, Speaker B: So as small as possible. This is one difference when you're going from the theory side to the applied side in general, like polynomial size or polynomial time algorithms won't be good enough. You're really shooting for like linear or maybe quadratic or something. Every added linear factor is a huge problem. It is possible to find encodings that achieve both generalized arc consistency and polynomial encoding size, but apparently they're not used in practice. So the most popular, perhaps encoding, or one of the most popular encodings, is the so called generalized totalizer encoding, which worst case is exponential time, but seem to be better than the theoretically polynomial size encoding in practice. Again, I won't talk more about this.
00:12:34.460 - 00:13:30.854, Speaker B: There's some more in the prerecorded tutorial. There's much more in the Sat handbook for the second edition is just being printed as we speak. So that's like briefly what I wanted to say about converting the pseudo boolean formula to CNF and running a CDCL solver. And what are some interesting well, so how good is this? Well, it turns out it's really good sometimes. In fact, the CDCL based solvers are sometimes beating the crap out of the native pseudo boolean solvers that I will talk about next. So what is the explanation for this? So I don't know if anyone has really given a rigorous explanation. I think this is a good theory question, but sort of intuitively, one reason why this would be good is because of the extension variables, because you're adding extension variables that are encoding fairly complex statements.
00:13:30.854 - 00:14:33.004, Speaker B: Like somewhere halfway through the circuit you have evaluated parts of your pseudo Boolean constraint and you have partial information, and suddenly you have an extension variable encoding that you know exactly this. This is something that a native Sudo boolean solver does not have access to, but the CDCL based solver would have access to it. It would be able to branch on. It will be able to learn clauses over these variables, which, if you think about it, will then not just be linear inequalities as for the pseudo boolean solver, but they can, since these since every variable can like, mean a linear inequality, a disjunction of such linear inequalities can become some very general polytope or something. So it would be super nice to this is, I'm really just saying fluffy intuition at this point. Somehow making this rigorous would be a very nice theoretical problem. However, this gain in performance really depends on getting a nice encoding.
00:14:33.004 - 00:15:55.014, Speaker B: For instance, one experiment you can do is you can take your pseudo boolean formula and you can permute the variables or flip the signs of the literals and then try to run a CDCL based solver. And then that can be terrible, truly terrible for performance. So somehow this conversion to CNF, you're depending on someone being nice to you when you get the problem. Also, there are other examples where even if you have extension variables, the extension variables are not able to make connections between constraints, they're just encoding a single constraint. So, for instance, if you take a pigeonhole principle formula in pseudo boolean form, and you encode it to CNF, and you run a CDCL based solver, it will suffer from the same exponential lower bound that standard resolution based solvers would suffer from. There's no way you can beat the pseudo boolean solver regardless of what your suitable encoding to CNF will be. So, but it's an entire research area to think about what are these good CNF encodings, and what are the, for instance, trade offs between propagation strength and encoding size? This would be I think there would be room for doing some computational complexity theory here.
00:15:55.014 - 00:17:00.464, Speaker B: Also to understand when the CDCL based approaches are good or bad compared to the native pseudo boolean solvers based on the cutting planes proof system that I'll talk about next to do some more theory on. This would be very nice. On the applied side, why not try to build a solver that harnesses the strength of the CDCL based approach and the pseudo boolean approach? There's also a nice kind of certification question here, or proof logging question, namely the following, that when you're running a CDCL based solver, you have this initial phase where you do a massive re encoding. How do you even know after that that your CNF is encoded correctly? How do you know that you're solving the correct problem? For now, I think there's, there is what you have to do. If you're using a CDCL based sudo boolean solver. Basically, you have to trust that they know what they're doing, that you're solving the right CNF, and this is not entirely satisfactory. It would be nice to actually know that you have translated from pseudo Boolean form to conjunctive normal form correctly.
00:17:00.464 - 00:17:58.684, Speaker B: Okay, so moving on next to what I refer to as native pseudo boolean solvers here, what we want to do is just, we want to do conflict driven search and learning, as in Satsuwe and as has been covered in previous tutorials during this boot camp. But we want to operate on suitable boolean constraints instead of clauses. So what does the CDCL solver do? Well, it does variable assignments. It decides some variables and then propagates obvious consequences until it reaches a conflict, and then you somehow do a derivation to derive a new constraint, and you backtrack. So we want to do all of this, but with pseudo Boolean constraints. So how do we do this? Well, so let us write Rho to denote the current assignment that the solver has, which is referred to as the trail. So this is an ordered set of literals that is assigned to true.
00:17:58.684 - 00:18:47.972, Speaker B: And for every literal we know whether it's a decision that the solver made freely, or whether it was propagated by some constraint. And if it was propagated, then we know why there's always a reason constraint explaining the propagation. But what does it mean to propagate? Well, an important notion here is slack, which measures how far some suitable and constraint sum of I AI li greater equal a. How far is it from being falsified by row? How much margin is there? How much slack is there? Well, the slack that you have is you can take all the literals that are either satisfied or unassigned by row. So they're either already contributing or they could potentially contribute. But the falsified literals we're ignoring because they're not contributing. And let's sum up all those coefficients.
00:18:47.972 - 00:19:14.660, Speaker B: This is like the best case contribution note here. I'm importantly using this normalized form now, so that we know that all of these coefficients and the degree of falsity, they're positive numbers. So the best possible contribution we can get from the left hand side is summing over all non falsified literals, AI. And then we know that we need to achieve at least a. So we subtract a. This is the margin. Okay, let's illustrate this on the constraint that we saw at the beginning.
00:19:14.660 - 00:19:52.504, Speaker B: So the empty assignment here you can see that you could satisfy everything that would give us 15 on the left minus seven on the right, that's eight. So the slack here is eight. However, if the solar falsifies x five, then we lose this contribution and the slack goes down to three. And now, interestingly, this slack is smaller than the coefficient of not x four. And what this means is, if you think about it, that we cannot afford setting x four to the wrong value, because if so, there's no way we can reach seven. If we screw up x four also, then the best we can get here is six, but we need seven. So this is the notion of pseudo boolean propagation.
00:19:52.504 - 00:20:22.776, Speaker B: When a coefficient is strictly larger than the slack, it should propagate. Good. So let's suppose the solver propagates. This doesn't change the slack because we contributed in the right direction. Then the solver goes off for a while and it sets x three to false and x two to true, say, for other reasons. And now you see that the slack is minus two. So we have a contribution from x four and we have a potential contribution from x one, so that's five, but we want seven.
00:20:22.776 - 00:20:48.012, Speaker B: So slack is minus two and we have a conflict. And note, interestingly, that in contrast to CDCL, we haven't even assigned all the variables in this constraint. But we already know that we screwed it up. There's no way we can save the situation now. So this is a conflict, although we haven't assigned all the variables. Okay, good. So now we know how to do variable decisions and propagations.
00:20:48.012 - 00:21:21.194, Speaker B: Now we need to think about conflict analysis. So consider this, the following CDCL trail. Suppose we have this CNF formula over here. And suppose the solver decided w to false and then propagated u, and it decided x to false, and then it propagated until it so happened that it falsified this clause over here. So what would cdcl conflict analysis do? Well, it would first. So first, note that this trail here, this partial truth value assignment, obviously falsifies the conflict clause. That's why it's a conflict.
00:21:21.194 - 00:22:23.654, Speaker B: And now what we do in the first step is that we take this conflict clause and the reason, and we resolve it over z and remove z and get a new clause, x or not y, which is falsified even when we remove z from the trail, when we remove z from the partial assignment. So even before assigning z, this clause already explains that we have gone wrong here. Continuing the conflict analysis, we resolve this clause with this recent clause over y to get u or x. And now if we remove u from the trail, u or x explains that already. This partial assignment above here is wrong, and this is an important invariant in conflict driven clause learning. Conflict analysis, like every derived constraint that we have explains why the partial assignment done so far is wrong, why it can fly. And then by maintaining this invariant, we just run our conflict analysis until we get a clause that we like.
00:22:23.654 - 00:23:02.956, Speaker B: And when we get a clause that we like, we say, ah, here we can terminate. I'm going to learn this clause and add it to my formula, and I won't go into what like means, but this is the concept of the constraint being asserting that when I backtrack, it will flip some variable. So this is. You can see more details on this in my, in my prerecorded talk or in the tutorial that we had on conflict liver and closed learning solving earlier in the week. Okay, good. So now we know what CDCL does it like. It takes constraints and uses the resolution rule.
00:23:02.956 - 00:23:45.198, Speaker B: So we want to do the same thing. Okay, so suppose here is a resolution step, and it's an easy observation that we can actually mimic this in pseudo boolean reasoning. Suppose we have. So this clause would be translated into this pseudo Boolean constraint, and this clause is this constraint, and we can add them up and then z will cancel, and we'll get x plus two, y bar greater equal one, which semantically is the same thing as this clause. Okay, so, and I'll refer to this as the generalized resolution rule. Where you take two constraints, you have a variable occurring with opposite signs. Potentially you need to multiply the two constraints to get the same coefficient.
00:23:45.198 - 00:24:26.096, Speaker B: Here we don't need to do that. We have all coefficients one and then you add and the variable cancels. So this is resolution over x one. Okay, except that if you paid attention, you see that this too shouldn't be here. I mean, in a resolution step, we should actually have derived x plus y bar greater equal one, not two y bar. But this we can also conclude, because if you think about it, the only way this constraint can be true over the integers is that this constraint is also true, because there's no way you need a contribution from some coefficient here that is larger than degree of falsity. So without loss of generality, you can always bring down all coefficients to at most the degree of falsity.
00:24:26.096 - 00:25:13.124, Speaker B: And this is known as the saturation rule. Importantly, this is not sound over the reels. It's only sound over the integers. But that's good news for us because we want some rules that are not sound over the reels if we want to do Boolean sat solving otherwise we would just be doing linear programming, and then we couldn't solve Boolean problems. And in fact, I should say for fairness sake that the way hooker defined generalized resolution is that he included this fix. But it's convenient for us to first do the resolution step and then think about the Boolean rule, because it turns out that there are different Boolean rules that you can apply, and saturation is just one of them. We'll talk more about this in a minute, okay, fantastic.
00:25:13.124 - 00:25:46.046, Speaker B: So now we know how to do conflict analysis. Also, we're just going to do CDCL does resolution. So instead we're going to do generalized resolution, and then maybe do saturation to get the clause. So let's do this on a toy example. So here we have two constraints. Two x one plus two x two plus two x three plus x four greater or equal four, and two x 1 bar plus two x two bar plus two x three bar greater equal three. Now, if you think about it, this is just a very convoluted way constraint one is just saying that the majority of x one to x three should be true.
00:25:46.046 - 00:26:21.854, Speaker B: C two is claiming that actually a majority should be false. So this is just contradictory. And our pseudo Boolean solver should be able to figure this out. So let's see what happens. Well, we start by setting x one to false, say, and when you set x one to false, then the slack here will be five minus four, that's one. And that slack one is smaller than the coefficients two here. So according to c one, both x two and x three propagate to true.
00:26:21.854 - 00:26:51.334, Speaker B: Note interestingly, in contrast to conflict driven clause learning, the same pseudo Boolean constraint can propagate multiple times, also at different contexts. In the search this is an interesting difference. But now we have a conflict because c two is unhappy. If x two and x three are both true, then we have a conflict. Then we have negative slack here minus one. So now what a CDCl resolver would have done. It would have taken the conflict constraint to c two.
00:26:51.334 - 00:27:30.464, Speaker B: It would have resolved it with the reason c one over this ill fated propagation, x three. So let's do that. And if you do the math and cancel everything out, just again, we don't need to do any multiplication because we're resolving over x three that has a two here and has a two here. So we just sum this up and then do the cancellation, and we get x four greater or equal one. And then we said we should saturate, but this is already saturated constraint, so nothing happened. So this is not great you know, we screwed up. So why did we screw up? Because we wanted to maintain the invariant.
00:27:30.464 - 00:27:58.704, Speaker B: That this constraint explains what went wrong when we remove x three from the trail. So when we remove x three from the trail, we have x one false and x two true. But X four doesn't say anything about this. It's an interesting fact that apparently X four has to be true. And we didn't know this before, but it doesn't explain what we did wrong in our search, because the solver hasn't even done anything about X four. This didn't work. It crashed.
00:27:58.704 - 00:28:56.182, Speaker B: Let me try to explain what went wrong. So the problem is that the generalized resolution rule is just taking a linear combination, and that is sound over the reels and over the reels. If you look at the propagation given x one false and x two true, c one knows that x three has to be at least one two. But it's saying, if I can just get a half, and I could also get the contribution from x four, then two times one two plus one would actually be created, plus that x one is also sorry, x two is contributing, then I would get four. So over the reals, c one just propagates one two, and then again over the reals c two says that, well, I won't be impossible, I already got x one. So if you would just give me half of x three, then I would be happy. So, over the reels, there is no conflict.
00:28:56.182 - 00:30:01.268, Speaker B: And then you do a generalized resolution step and eliminate x three, and there's, there's simply no conflict to see. So what should we do about this? Well, we somehow have to help the solver syntactically to do boolean reasoning. And one way of doing this is to try to make sure that this constraint would propagate x three all the way to one, also over the reals. Equivalently, if you think about this, it would be nice to have a reason constraint where the slack is actually zero, which means that the only way of satisfying it is that all literals contribute to full. How would we do this? This is where I'll intentionally start going very fast. It turns out that we should use the weakening rule. What's weakening? Weakening is when you have a constraint, you take some literal and you say, what's the best that could happen here? Well, LJ could be true, and if so, it contributes AJ, but the rest of the constraint still has to contribute capital a minus AJ.
00:30:01.268 - 00:30:31.390, Speaker B: So clearly this constraint implies this constraint, but it's a potentially weaker constraint. So that's why it's known as weakening. So we should take a reason constraint and we should apply weakening on it to get a weaker constraint. That's absurd. How could a weaker constraint give stronger reasoning? Well, the reason is that when we're doing weakening, we're forcing. The weakening step is enforcing Boolean ness. We're weakening by the full amount, and somehow this turns out what is needed to work.
00:30:31.390 - 00:31:03.134, Speaker B: So let me just do this very quickly. Just do the example, show what happens, and leave the explanation for the offline prerecorded tutorial. But the idea that we have is we can take the reason constraint, and if the resolveant isn't good, if it isn't conflicting, then we weaken on some non falsified literal except the one we want to resolve over. Because if we weaken over that literal, it's gone. And that would be bad because then we can't do the resolution step, and then we apply saturation, and then we resolve and hope for the best. So let's try to do that. Here's our reason.
00:31:03.134 - 00:31:25.770, Speaker B: Let's weaken it on X two. Say we get this, we saturate, nothing happens. We resolve again, we get this. Too bad. And this is still not violated by X one. So this is not violated by X one false AnD X two true, unfortunately. Okay, what can we do? Well, we can try to weaken even more.
00:31:25.770 - 00:31:53.132, Speaker B: Let's weaken also on X four. So then if we weaken on X two and X four, we're saying this could give a contribution two, this could give a contribution one, and the rest then have to give a contribution four minus two minus one, that's one. So we get two, X one plus two, x three, greater or equal one after we beginning. But now saturation kicks in. You see that there's no reason to have twos here. Once is sufficient. This constraint implies this.
00:31:53.132 - 00:32:16.156, Speaker B: And now when you do the resolution step, something interesting happens. We derive that apparently X two has to be false, and that is actually violated by the trait so far. So now we got an explanation. What did we do wrong? Well, the mistake that we made was we assigned x two to false. That was clearly a mistake. We shouldn't have done that. So now we can learn this constraint.
00:32:16.156 - 00:32:46.440, Speaker B: We can saturate it and then learn it and then propagate. And then it's not so hard to see that now we will propagate to contradiction without having made any decisions. And that means the formula is unsatisfiable. So we're done. Okay, and so this is the algorithm. And so we should. When we do the resolution step during conflict analysis we first try to resolve.
00:32:46.440 - 00:33:21.454, Speaker B: If the slack is negative, we're happy. Then we're maintaining the fact that the thing we're deriving on the right hand side and on the conflict side is conflicting. It's violated. But if not, then we find some literal that is not falsified, we weaken on it, and we try again, and we do this until we exit this while loop. And now you have to argue why this works. And I think for the interest of time, and since I want to cover other things, I won't have time to really explain to you why it works. But it does work.
00:33:21.454 - 00:34:02.834, Speaker B: And the reason is actually that you could. So what happens? We said that you wanted full propagation. You wanted the reason to have Slack Zero. You can prove that at some point during this while loop, you have to have a constraint that gets slack zero, and at that point, the conflict analysis will work if it didn't earlier. Again, I'm aware that I'm totally not explaining this well, but I think I'll leave it at this. And then I see there's a question that the trail assigned x one to zero, not x two to zero. Is there a typo in my slides? Or I don't understand this question.
00:34:02.834 - 00:34:42.454, Speaker B: So what we learned here is that x two should be false, but it was assigned to true. Or are you saying that. So, so, like, we're saying that this assignment was wrong, but then you can make the fair argument that, well, somehow it was just because of this decision. And that's true, but the constraint is just saying that x two has to be false, and then we can just back jump to top level without any decisions and propagate this. Ah, okay. So it seems that we figured out this question.
00:34:43.554 - 00:34:47.546, Speaker A: So. So, yeah, so, Jakub, could I ask a question?
00:34:47.690 - 00:34:48.250, Speaker B: Yeah.
00:34:48.362 - 00:34:54.692, Speaker A: On your next slide, you have the. You were choosing literals, l prime. Does it matter which order you choose those in?
00:34:54.858 - 00:35:39.116, Speaker B: Excellent question. That's like, for instance, should I choose one thing? You should not choose falsified literals, because then this whole argument crashes. But should you choose unassigned literals, or should you choose literals that are already satisfied? That's a good question. I think there's. These are these kind of questions where I think there would be much room for some more rigorous theoretical investigation. I think so. I don't have this in cash, and also somewhat sleep deprived after having prepared this tutorial.
00:35:39.116 - 00:35:57.662, Speaker B: If anyone in my group like Stefan got here and remembers whether we should weaken on. I think we tend to prefer weakening on either on unassigned or unsatisfied. I don't remember which one off the top of my head. I have to take that offline. But there's no, like, rigorous explanation which one you would prefer. Okay.
00:35:57.758 - 00:36:00.334, Speaker A: And it could make a difference. You could get different results depending on the order.
00:36:00.374 - 00:36:15.190, Speaker B: Oh, sure. I mean, this is a very. Conflict analysis is a very syntactic operation. So, yes. You can also ask, like. Yeah, there are lots of questions here. In fact, you could imagine that you can weaken.
00:36:15.190 - 00:36:35.844, Speaker B: Actually, one thing that works is that you can weaken away all these literals in one go, and it would. Again, it would work. Do you want to do this, or do you want to weaken as little as possible? Not clear, though, has not been rigorously investigated. Well, Jakob. But what is not rigorously investigated is the effectiveness. But the correctness is fine. No, you can use correctness.
00:36:35.844 - 00:36:59.370, Speaker B: Correctness is fine. This pseudocode will always work, no matter which choice. Which choice you want. Yes, correct. This will always work, but we will get a different constraint. Thank you. Okay, so if you compare now to conflict driven clause learning, here's like what conflict driven clause learning in the CDCL setting would do.
00:36:59.370 - 00:37:29.460, Speaker B: And I'm just illustrating this because there's only one difference now that we inserted in the innermost loop before doing the resolution step of the reason, with the conflict side constraint, we should apply this mysterious reduction step. But other than that, this whole algorithm is exactly what we have in CDCL. And so this is. I mean, I'm simplifying a bit, but I would say, essentially, this is what sat four j is doing, like this. And then Saturj. I mean, Satur J is an enormously big solver. It's doing tons of stuff.
00:37:29.460 - 00:38:00.164, Speaker B: But this is sort of what lies at the heart of the conflict analysis in Satra Jarek. Good. So, compared to CDCL, one problem is that it's harder to detect propagation. We know if you attended the CDCL tutorial, that in order to propagate on clauses, you just need to keep track of two literals that have not yet been assigned. If you know for a clause that there are two literals that have not been assigned, then you don't care if the clause is of size two or if it's of size 200. You know it's not propagating. So you don't need to watch the whole clause.
00:38:00.164 - 00:38:31.434, Speaker B: You just keep two literals. And that's, in fact, a big secret of how propagation can be so efficient for a suitable constraint. This is not true. If you look at this constraint, for instance, we clearly have to watch everything, because if you take any Xi and falsify it, then all of the others will propagate the true. And this turns out to be a huge problem. How to do efficient pseudoboolean propagation in the conflict analysis that I showed you, we're doing resolution steps. Every resolution step potentially does the least common multiple computation.
00:38:31.434 - 00:39:16.304, Speaker B: This means that integers can grow coefficient sizes explode. If you go to arbitrary precision arithmetic, you can get really large numbers and the solver grinds to a halt just because they arithmetic is so slow. And this is a real problem. An even more serious problem is that if you're evil and you take a CNF formula and you write it as pseudoboolean constraints as we've seen you can do and feed it to sudo Boolean solver, then it will just run CDCL. It will never derive anything other than clauses, but it will do so paying extra for all the sophisticated data structures that it's never using. So if your input is in CNF, you should not run a pseudo Boolean solver. That's a terrible idea.
00:39:16.304 - 00:39:50.782, Speaker B: At least if you're running this is not true if you now have an objective function. But if you're just having a decision problem in CNF, then you should not run a sudo Boolean solver. And this is a fundamental problem. So in this sense, pseudo Boolean solvers are super sensitive to the input format. Okay, well, but we said we wanted to do cutting planes based solving, so. Okay, so in the chat you're saying, well, I could detect pseudo Boolean constraints in the CNF and rewrite. Yes, we could have a pre processing step.
00:39:50.782 - 00:40:34.814, Speaker B: That's a very good point. But there is in fact in the state of the art pseudo boolean solvers, it turns out that this is not so easy to do and sat four J and Rommingsat are not doing it. I'm not aware of any other solver that does this. It's true that you could try to go in the opposite direction, take your CNF and rewrite it as a better pseudo Boolean formula. That how to do that efficiently is an open research problem and it's a very interesting research direction. Okay, but cutting planes, as in the theory literature, is defined with linear combination and the division rule where you can divide by some c everywhere and then just round up here. Again, the correctness of this rule depends on me using this normalized form where everything is positive.
00:40:34.814 - 00:40:38.808, Speaker B: And if you did Jakku, there's a.
00:40:38.816 - 00:40:42.560, Speaker A: Comment in the, I guess, Q and a about sat four J.
00:40:42.712 - 00:41:25.268, Speaker B: Does detection Saturday does what I think it does. Is this the DLLM paper? Daniel? Because I think it's fairly limited. Like in general you wouldn't be able to do this. Yeah, there's a but I think that's a limited, yeah, but you wouldn't. I don't think you run it by default and I don't think you're able to run, I mean there's also a research version of rounding set that does it. And that works better, I think, but still not good enough to be switched on like as by default. So I think it's fair to say that how to do this efficiently without taking a penalty is an open problem.
00:41:25.268 - 00:41:58.958, Speaker B: I'd be happy to talk about it offline. I think it's a challenging problem. It's a good problem. It's an obvious way to improve pseudoboolean solvers. Okay, so cutting planes defined in this way, getting back to division is in fact an implicationally complete proof system. This means that if we have a bunch of constraints and they imply some other constraint, then there's a syntactic derivation of this constraint. And for if I instead take out this division rule and plug in the saturation rule that we saw before, that's not an implicationally complete proof system.
00:41:58.958 - 00:43:01.010, Speaker B: So in some sense it seems to be weaker, maybe. So the question is what happens if I use division instead of saturation? Could I get a stronger conflict analysis? And sort of the short answer is that yes, so let's, let's do that. And again, I'm being very brief here because I want to focus on optimization and I want to focus on open problems. I refer you to the prerecorded material for more detailed overview here. But basically what we want to do here is when we do the weakening, we'll find non falsified literals which have coefficients that are not divisible by the coefficient of the propagating literal. So here for c two, x three is propagating and x four has coefficient one which is not divisible by two. So we weaken away x four and then we divide by the coefficient of x three and then we do the resolution step and boom, we have contradiction right away.
00:43:01.010 - 00:43:35.062, Speaker B: So for this particular toy example at least, division seem to be much much much better than saturation. And you can ask if this is a general claim or is just this toy example. And I think it's more of like, it's just this toy example. I think I'll get back to this in a minute. So just to say again, so now we have another reduction algorithm. And again, I refer to the prerecorded part for the details. But I'm just saying that.
00:43:35.062 - 00:44:14.720, Speaker B: So here's what we do. We look at the propagating literal l, we take the coefficient, and then one by one we pick out literals that have, that are not falsified, that have a coefficient that is not divisible by the coefficient of the propagating literal. We try to weaken and resolve, and we can guarantee that this will in the end work. And I won't try to do the proof online. You have it in the prerecorded material. Well, the proof is here, but you have to think about it for a second. Okay, so should you do divisional saturation? Well, I guess Daniel Liber and I should have a discussion about this.
00:44:14.720 - 00:44:57.904, Speaker B: Maybe. I don't know if he wants to comment on this in the chat. So here's my take. In general, if you don't know which kind of problems you're running on, then it seems division is better. What we have seen is that when you have a formula where pseudo boolean reasoning doesn't really pay off, maybe you could have basically done CDCL based reasoning. Then the conflict analysis is faster, so the solver reasons faster, runs faster. When you use division, this changes when the reasoning gets more sophisticated, then conflict analysis gets much, much slower, but it also seems to pay off.
00:44:57.904 - 00:45:33.734, Speaker B: And one nice thing compared to using saturation is that because you're dividing all the time, this keeps your coefficients small so you don't have this same explosion in coefficient size. So in fact the default setting in our rounding set solver is to do fixed precision arithmetic. And then of course you have to deal with overflow. But that doesn't happen too often. However, to be fair, there are some problems like for instance, involving verification of multiplier circuits where sat for j is so much better. And I don't know why. I wish I understood why it's better and could do something about it.
00:45:33.734 - 00:46:10.724, Speaker B: So choosing between division and saturation is not clear that you know how to choose. And we still have the problem of efficient unit propagation. Even if you use division, you still have the problem that you will degenerate to resolution. And CDCL. If someone is evil and gives you a CNF, and even if someone is nice and gives you a nice pseudo boolean encoding, it can be the case that the problem is obviously unsatisfiable. It's like blindingly obviously unsatisfiable, because if you relax it to a linear program, it's infeasible. So there are no real solutions even.
00:46:10.724 - 00:46:49.718, Speaker B: And for such a problem. Instance, cutting planes can tree like cutting planes can extremely efficiently prove unsatisfiability. And yet we have instances where pseudoboolean solvers run forever. They seem to run for exponential time, and we don't understand why. Okay, so let me highlight four slides with things that I would like to do to improve these kind of solvers. Preprocessing. As was mentioned before, cardinality detection, but also for other reasons, preprocessing seems to be very important for Sat solvers on the mixed interlinear programming side.
00:46:49.718 - 00:47:54.474, Speaker B: In MIP solvers, they call it presolving. It's also important. But pseudo Boolean solvers don't have much by way of preprocessing, and I don't know why. It seems like we should borrow techniques from MIP or from CDCL and make them work for pseudo Boolean solving. That would be a great thing to do. One really big problem what to do with the stupid CNF format? How can we if you get a decision problem encoding in CNF, how can you leverage the power of cutting planes? In particular, what about cardinality constraint detection? So what I'm aware of, I am aware of one paper that I think is what Daniel Leber was referring to in the question and answer we know, but hopefully I can get corrected in real time if I say this wrong, this is like a pre processing step where you can try to recover cardinality constraints. The problem is that it's fairly expensive, especially if it doesn't pay off, and you can only recover maybe at least at most one constraints, or maybe at least at most two constraints.
00:47:54.474 - 00:48:27.970, Speaker B: But for larger k, you can't really do it. We have a version of our solver where it's more like an in processing step. You do the detection on the fly. It seems promising, but not good enough to actually be used in practice. So I think dealing with cnfs and doing cardinality detection efficiently. And the challenge here is the challenge is not to come up with a toy benchmark where cardinality detection will pay off. The challenge here is to have it in a solver silently in the background, so that when it's not needed, it doesn't cause a performance hit.
00:48:27.970 - 00:49:04.460, Speaker B: But when it turns out to be needed, then somehow the solver automatically realizes this and does the right thing. And a general sort of more of an anecdotal claim is when you take a CDCL solver, it seems to be fairly robust these days. Like for instance, you take your cnf formula and you randomly permute the variables the clauses, maybe the signs of the literals, and most of the time the CDCL solver doesn't care too much. It's like it performs the same, is my experience. Whereas, I mean, I'm not making this as a formal claim, it's more of an observation. But for pseudo Boolean solvers, this is very much not so. They're very sensitive, it seems, to these kind of permutations.
00:49:04.460 - 00:49:39.572, Speaker B: So I think the solver technology is like, well, less well developed. Conflict analysis is a huge area. I think there is room for lots and lots of research here. Should you do division? Should you do saturation? Maybe you should do it adaptively, because apparently there are some problems where saturation is better, some problems with division are better. Or should you use some other Boolean rule entirely? There are lots of cut rules in the integer linear programming programming literature. What about those? How can you so there's one very intriguing phenomenon that I won't even have time to talk about. You have to read the paper.
00:49:39.572 - 00:50:43.234, Speaker B: But there's the issue of that. You can get literals in your constraint that clearly don't play any role, that are irrelevant, but they can really mess up the conflict analysis. What do you do about those? There are lots of degrees of freedom in how to do the conflict analysis. Sometimes you can just skip resolution steps because the slack is so negative. We already talked about how should you weaken, how much should you weaken? What should you weaken? Should you learn a general pseudo Boolean constraint? Or maybe actually the earliest solver, Galena said, well, you don't need this generality, just round everything to cardinality constraints. When you learn a so called asserting constraint, it turns out that it can be asserting at several different levels. How do you know where to back jump as far as possible, or as short as possible? Or what should you do? How should you do it with your integer arithmetic, the clause minimization that is being done in CDCL conflict analysis? It would be nice to get some analog of that.
00:50:43.234 - 00:51:36.626, Speaker B: We don't have have that. And sort of a general theme with all of these questions is how do you know what a good learn constraint is? For instance, if I'm choosing between division and saturation, I could try to do my conflict analysis step with both. I get two new constraints out, and I can choose the best one, but that in order to do that I have to see which one is the best one. And there are many parameters according to which you can compare sudo Boolean constraints, and it's not so clear what what it means that a certain constraint is better or worse than another one. And from the theory side, these algorithms define proof systems, subsystems of cutting planes. It would be very interesting to understand these proof systems better, in particular how division is related to saturation. Solar heuristics.
00:51:36.626 - 00:51:58.360, Speaker B: That's more like an applied area. I'm running a little bit behind, so I'll be brief. But basically most of the heuristics are just copied from CDCL. But again, there are lots of more degrees of freedom. So you can think about maybe you should design things slightly differently. This should be investigated. There's a wonderful PhD thesis just defended by Roman Vallon in Lanz.
00:51:58.360 - 00:52:44.380, Speaker B: Highly recommended reading. He's investigated some of these questions, but there's really room for much more work here. Also, some of the latest news over on the SAT side, like these different modes for SAT focused search and unsat focused search, or different phases for face saving. One thing that I forgot to mention here is chronological backtracking. For instance, all of these things that seem to be really, really valuable for SAT solvers that just haven't been coded up in sudo boolean solvers. It would be very interesting to do this and see what pays off and what doesn't pay off. I think there's lots of room for just for engineering work and then running experiments, evaluating, trying to understand and to improve state of the art in pseudo boolean solving.
00:52:44.380 - 00:53:27.724, Speaker B: Lots and lots of obvious research directions. Again, efficient unit propagation. There's room for improvement there even during conflict analysis to decide whether you have a certain constraint, a unique implication. Point constraint is much more difficult than in CDCL. And then a shameless self plug. I mean, for sat solvers, we have proof logging. What about sudo Boolean solvers? Shouldn't we have proof logging so that you can know that the Sudo Boolean solver is correct? This is something that I've been working a lot on together with my student Stefan Gocht and some collaborators in Glasgow and elsewhere.
00:53:27.724 - 00:53:38.612, Speaker B: But this is not the topic of this talk. So this brings us now to. Yes.
00:53:38.748 - 00:53:42.148, Speaker A: Want to mention if you would like to take a five minute break?
00:53:42.316 - 00:53:55.594, Speaker B: Yeah, that's what I'm thinking about. This might be a good place because now we talked about decision problems and we want to move into optimization. So, yeah, why don't we take a five minute break here? Sounds like a good idea.
00:53:55.634 - 00:54:04.974, Speaker A: So we'll start back promptly at 32 past the hour or two past the hour, depending on what time, time zone you're on in five minutes.
00:54:05.314 - 00:54:06.674, Speaker B: Okay, thank you.
00:54:06.834 - 00:54:13.654, Speaker A: And part of the five minutes, there's a question from. From Victor about is your bibliography available?
00:54:14.034 - 00:54:40.516, Speaker B: Ah, the answer is yes. Let's see. So I think Simons actually have the slides online. There are some typos on the Simons website that I think I corrected. Let's see if I can. Whoops. What's this? What happened now? I wanted to do something.
00:54:40.516 - 00:55:42.114, Speaker B: What happened? A lot of, a lot of effort went into the bibliography. So I'm very happy that someone is asking about this. So what you can do is let's see if you go to my web page which for some reason still resides at KTH. Don't ask. I think if you google for Jakob Nordstrom research you should end up somewhere here. And then you blow it up a bit and then you click on some presentations and here you have the slides for the live talk and then some bug fixed slides for the tutorial. So basically if you find my webpage you should be able to take it from there.
00:55:42.454 - 00:55:48.958, Speaker A: There's a link in the chat window for the tutorial slides. Yeah, great.
00:55:49.006 - 00:56:01.350, Speaker B: Thanks Mena for that. So just a small cabinet that there are some typos in those slides that have been corrected in the version that you see on your screen now. But I'll try to update the silence version.
00:56:01.382 - 00:56:13.914, Speaker A: Also I can also issue my own shameless plug that Yaakov and I have a proof complexity survey article which probably also contains many of these citations, but maybe not quite.
00:56:13.954 - 00:57:02.268, Speaker B: All right, so you should definitely get the handbook of satisfiability and drop everything else and move on to chapter seven, which I think what we covered so far is developed fairly well there in chapter seven, more so I think, than in the actual chapter on pseudo boolean solving. What will follow now in the second half is not in that chapter though. But you're right. So many of the, many of the references so far and many more references are in that Satan. And as it happens, I mean there's also. Well, so this survey paper you can find on Sam's webpage, obviously you can also find it among my survey papers. Let's see, like where is it? Ah, here, I guess this thing.
00:57:02.268 - 00:58:05.006, Speaker B: So this should be something that is very close to the published version. I think the only difference is that maybe we added an abstract here that wasn't after this, but otherwise I think that nothing in the actual text changed. So that's also highly recommended reading and containing more references even then in this talk, if there are any other questions, I'm happy to take them. I'm sort of going a bit fast maybe, but that's because I want to talk about so much. And also you have it pre recorded if you really want to. I mean, in particular, if you want to go into the details of pseudo boolean conflict analysis. I tried to do that fairly carefully in the video.
00:58:05.006 - 00:58:42.104, Speaker B: I only realized afterwards that that chunk of the video, part two of the video is something like 2 hours, which is horrible, of course, but that's because I'm doing all of this very slowly. And I'm also discussing other possible pseudo boolean rules that have been considered. Like the strengthening is something that is apparently done in operations research that would also, it's an interesting rule because it would recover cardinality constraints, but again, it doesn't seem to fly in practice. And I discuss lots of other things there in so part two of the prerecorded tutorial.
00:58:42.964 - 00:58:50.664, Speaker A: Okay, so that's been the break. So let's hope everyone's back and we can continue. And whenever you're ready.
00:58:51.884 - 00:59:22.060, Speaker B: Good. So what we did so far is we define the problem and we talked about pseudo Boolean solving. So there we just had a pseudo boolean formula. We wanted to determine satisfiability or feasibility. Now what we're going to do is we're going to add an optimization function, an objective function, and we want to find the solution minimizing this. Okay? And this is very, very related to Max sat in some sense. Max sat and sudo Boolean optimization is more or less the same thing.
00:59:22.060 - 01:00:12.534, Speaker B: So let me explain this. So the weighted partial Max sat problem is you have a CNF with some soft clauses, c one to cm that come with weights, and maybe let's have integral weights just for simplicity, rather than real value weights. And then you have some hard clauses, and your task is to find a solution, an assignment that has to satisfy all the hard clauses. And it's more interesting usually to assume that actually this hard part of the formula is satisfiable. So you can find such an assignment, and then you want to maximize the amount of soft clauses satisfied. So you want to maximize some of the weights of the soft satisfied clauses, except that now we're going to do this classic switch of perspective, which you always do when you have a max sat talk. You immediately think about the minimization problem.
01:00:12.534 - 01:01:09.230, Speaker B: So maxat is a minimization problem, namely minimize the penalty are the falsified soft clauses. And let's write a clause c, sub v for a clause c with the weight w, and the hard constraints have infinite weight. So that means that you can't afford to falsify them, because then your objective function will have value infinity. That's bad if you're looking for a minimization. Okay, so here's like an example, max sat instance. And the point is, you realize that it's fairly easy to rewrite this into a pseudoboolean optimization instance, but you just take all the soft clauses, and for every soft clause you add a new variable which you can use to satisfy this clause, but you don't want to do that, you'd rather satisfy the clause itself. So what you're minimizing is how many of these variables you're using, and the coefficients are exactly the weights or the soft clauses.
01:01:09.230 - 01:01:58.534, Speaker B: So it should be hopefully clear that this is the same problem. And this is sometimes referred to as the blocking variable transformation. The b's are the blocking variable, so the relaxation variables. So just to make sure we're on the same page here, you can satisfy everything except this clause. So the penalty of the optimal solution is three, which is by this assignment, you can also go in the other direction to take a general pseudo boolean optimization problem and translate it into Mac SaT, except that it will be Mac sat with potentially pseudoboolean constraints instead of clauses. And if you want to be formal, this is known as a weighted Boolean optimization problem if your constraints are not clauses, but pseudo Boolean constraints. And the way to do this is here is my pseudo Boolean optimization instance.
01:01:58.534 - 01:02:45.770, Speaker B: I keep all my constraints, I make them into hard constraints, and then every literal in the objective function, I negate it, and I make it into a soft clause with the weight being the coefficient. And now it should be clear that an optimal max sat solution here is indeed minimizing this objective. So this is the same problem. And the reason why this is relevant is that it seems that there's more development going on over on the max sat solving side than on the pseudo boolean side. So what I'm going to talk about now, different solving approaches, I think are most well developed on the max sat side. So I'll try to explain them in pseudo Boolean language. I want to talk about linear search, core guided search, and the implicit hitting set approach.
01:02:45.770 - 01:03:15.194, Speaker B: Let's see again, they come from Maxat, where these literals would be these blocking variables of soft clauses. But we don't need that. So we'll just think of a general linear objective that we want to minimize. Okay, linear search is easy. What you do is you just solve the problem. When you find a solution, you add a new constraint saying, I want a better solution. Then start over until you get unsatisfiable, and then, you know, you're done.
01:03:15.194 - 01:03:49.012, Speaker B: Okay, so let's do a toy example. I hope this is clear, but just to make sure. So here's some formula that I'm not telling you what it is. The objective x one plus two, x two plus all the way up to five, x five plus six, x six. You run the solver, it gives the assignment x four, x five, one, all the other false. So that gives objective value nine. So then I add a constraint saying that I want at most eight, and I run the solver again, and it finds a new solution, say, and here it says x two and x four to true, and all the other two false.
01:03:49.012 - 01:04:32.876, Speaker B: Now I get objective value six. So then I say, give me a solution with five or better, and then the solver says, onsat, say, and then we can safely return six as the optimal value of this program. It should hopefully be clear. And now if you're a theoretician and say, aha, but I've heard that binary search is so much better than linear search. We do binary search, and it appears that, no, we shouldn't, as far as I understand, for two reasons. The reason linear search is bad in theory is that you could get very small decreases, but you don't get very small decreases. You tend to get large decreases, large jumps.
01:04:32.876 - 01:05:36.654, Speaker B: And then all of these solver calls to the solver oracle are not created equal because some of them will be for unsatisfiable instances when you're looking for a solution that is too good to be true, and some of them will be for satisfiable instances where you just want to improve your solution and it is possible to improve, and it tends to be the case that sat calls are much, much cheaper than Unsat calls. So doing a large number of sat calls during your linear search, and you know that only the final call will be onsite. Whereas if you do binary search, then you could potentially do a lot of expensive onsite calls. Another reason why linear search is nice is that you get a solution quickly, even if it's not the optimal one. Once the solver has returned the first time, you have something. And there's a special actually track in the Maxat competition for any time solvers where you really care about time is limited and the best solution as soon as possible is nice. And then if you have a few more extra minutes and you can improve your solution, great.
01:05:36.654 - 01:06:22.608, Speaker B: But there might be a timeout at any point in time. And then give me the best you have, and it has been argued that in a lot of applied settings, this any time solving scenario is actually what you care about. But if you do care about optimality, a sad aspect of linear search is that until you do this final ansat call, you have no idea how good your solution is. You just know that you're finding new solutions. Good. So what is core guided search? It takes the opposite approach, and it says, let's assume that we can achieve an amazing optimization value. In fact, let's assume that we can achieve the optimal value zero.
01:06:22.608 - 01:07:00.588, Speaker B: Again, remember that we're normalized here, everything is positive, so clearly zero is the best you can hope for. So in corrugated search, you say, I think zero. That's doable. And you run your sudoboolan solver with these assumptions. So, running a solver with assumptions is that you give it some pre made decisions that it should apply before it starts its own search. And when you run a solver with assumption, one or two things can happen. Either it says sat, and then it means it found a solution that is consistent with your assumptions, and then clearly this is an optimal solution because you're making a wildly optimistic assumption.
01:07:00.588 - 01:07:42.208, Speaker B: And it paid off. There was such a solution. Now, if a solver is run with assumptions and the assumptions are inconsistent, then it will return some constraint that explains why these assumptions are not possible. And in this context, we, for instance, can learn some constraint, maybe a clause, maybe a more general cardinality constraint, saying that no, out of the k first assumptions say at least a of them have to be true. You can't assume all of them to false. And then what a core guided solver does, it says, aha. So let me then, I know that the sum of this expression is somewhere between a and k, but I don't know where.
01:07:42.208 - 01:08:25.423, Speaker B: So let's introduce new variables for this z a plus one up to z k, and let's just impose. I can certainly add a new constraint saying that sum of l, one up to lk is equal to a, which is this lower bound plus summing from a one to k. These new variables, z j, these z j's are new variables. Now, these are extension variables. And once I have this, this is an equality, I can go back to my objective function and rewrite it. And when I replace some multiple of this with some multiple of this, then I'll get a constant term update which updates the best possible lower bound. And now I have a rewritten objective function.
01:08:25.423 - 01:09:04.626, Speaker B: And then I run my core guided solver again. Okay, so let me do a toy example here with, with a caveat that I'm, again, intentionally going somewhat fast, but I just want to convey the gist of the core guided idea. Like, how would this work? Let's do the same toy example. So here's our objective function that we want to minimize again, and we say, I believe zero is the correct value. So we set everything to zero, and we run the solver with these assumptions, and the solver says nope. And then it will return some kind of constraint. It might be a general sudo Boolean constraint.
01:09:04.626 - 01:09:35.866, Speaker B: And I'll refer to this inspired by Maxat terminology. Let's call this a core constraint. Now, in the max set setting, these guys would actually be blocking variables for clauses. So this would be a subset of clauses that cannot all be satisfied at the same time. That's why it's known as a core. But in our setting, we just have an objective function. But let's call it the core constraint anyway, because it's like what it would be called if we were doing a max instance.
01:09:35.866 - 01:09:57.968, Speaker B: So, for reasons that I don't have time to go into this, this kind of looks complicated. Let's round it to a cardinality constraint. In particular, if this is true, the only way that this constraint can be true is that at least two of the variables are true. So let me write this. Let me derive the best possible cardinality constraint from this. Here it is. And now let me do this rewriting.
01:09:57.968 - 01:10:39.874, Speaker B: I know that the sum of these four variables is between two and four. So let me introduce two new fresh variables, y three and y four, and add constraints, pseudoboolean constraints. So this is syntactic sugar for two less than equal and a greater than equal. I write them down, saying that the sum of these four variables is at least two, and then plus y three plus y four. I specify that I want y three to be greater than y four, greater equal. And if you think about it, this exactly enforces the meaning of y, sub j, as the sum of these four variables is at least j. And now what I can do.
01:10:39.874 - 01:10:59.934, Speaker B: Let's look at the objective function. And I want to replace the left hand side with the right hand side. So let's look at the coefficients. 2345. I can multiply this whole equality by two, and then I can substitute two times this thingy. By two times this thingy. Okay, let's do that.
01:10:59.934 - 01:11:17.358, Speaker B: Let's see what happens. So then I get x two cancels. X three went down from three to one. X four went down from four to two. X five went down from five to three. I didn't touch x six, I didn't touch x one. And now I added y three and y four, and a constant term four.
01:11:17.358 - 01:11:46.724, Speaker B: That shows that I've derived that the best possible value wasn't zero. It's maybe four. Now what do I do? Well, let's stay optimistic and say, well, I believe four is the best possible value. So I set all of these guys, including the new guys, to zero, and I run the solver again. And now the solver again thinks that these assumptions are inconsistent. And let's say it returns this core constraint. Now, this is already a clause.
01:11:46.724 - 01:12:22.834, Speaker B: This is already a constraint. Cardinality constraints. I don't need to do any rewriting. So the sum of this is somewhere between one and four. So I introduce now three new fresh variables and add sudo boolean constraints, saying that this sum is equal to this sum, and I want z two to be greater equals z three greater equals z four. And if I add these constraints to the solver, which I can do, I mean, it's a free country, I can do this, then zj will have the meaning, z j will actually encode exactly that. The truth value of this variable will be the truth value of this constraint.
01:12:22.834 - 01:12:59.394, Speaker B: Okay, and now again what I'll do, I have this new equality. It is an equality so I can rewrite my objective function to something equivalent. And now let's look at the coefficients here. X four has a two, x five has a three, x six has a six, y three has a two. So I can multiply this whole equality by two and replace these guys by these guys. Then x four will cancel, and y three will cancel, and I will get, let's see what I will get. Something like this.
01:12:59.394 - 01:13:43.074, Speaker B: And the point is that with the added constraints, the value of this objective function is the same as the value of this subjective function is the same as the value of this original objective function, because I have pseudoboolean constraints enforcing the equivalence. So now I run the pseudoboolean solver again. And now we know, since we had the same problem when we did linear search, we actually found a solution of value six. So the core guided solver should also find this. And indeed it says that, yeah, I could actually find an assignment with all of these guys to zero. And then I know that my optimal value is six. And I can also, from the solution, I can read off the original values, if I care about it, if I want to reconstruct the solution.
01:13:43.074 - 01:14:17.024, Speaker B: So this is like a crash course in core guided optimization. This is how it works. What's nice with this, well, that we get lower bounds quickly and that helps us to cut off parts of the search space. But of course I don't know anything about the solution until the final call. Again, I'm sort of doing linear search, but in the other direction. And again, I don't have any estimate of how good my lower bound is. So somehow it would be nice to do some combination of linear search and core guided search.
01:14:17.024 - 01:14:54.564, Speaker B: This you can do in various ways. One thing you can do is called weight stratification, where you assume not everything in the objective function to true. You focus on the coefficients with largest weights and run with those assumptions. And then either it turns out that this is inconsistent, and then you get a core consisting of much fewer assumptions, so it's a more compact core. Or if it turned out that I could assume these heavyweight literals to false, then you found a decent solution already. So this is like interpolating between linear search and corrugated search. There are other things you can do that I don't have time about.
01:14:54.564 - 01:15:55.894, Speaker B: You can get independent core if you get a core constraint over, say, the first k literals, then repeat your assumption again. But omit this guys, and then you'll find if there's any other core that is in the. And then when you do the update of the lower bound of the objective functions, all these independent cores that are disjoint will contribute independently to the objective function update. One thing you can do is you can. I said that core guided search was good at cutting off the search space well, so run it in the beginning for a while, and then switch to linear search once you've gotten a good enough lower bound estimates, or do full hybrid search, switching back and forth between core guided and linear search. Now, to the best of my understanding, Max sat solvers don't really do this so much. And I think the reason for this is that the way I've described with these cardinality constraints, if you're in a max sat setting, you would need to do a lot of rewriting to CNF when you do this.
01:15:55.894 - 01:16:46.222, Speaker B: But the nice thing with being in a suitable in setting, there's all these equalities that I wrote down there are actually, they are what, what the sudo Boolean solver is operating with. So it's all native, it's all very cheap, and you can do cheap hybrid interleaving search. There are other things that we don't know how to do in a sudo boolean setting. The core minimization, which is somehow analog of minimizing your learned clauses, one thing that I don't have time to talk about really is doing lazy variable introduction. For instance, here you see, we introduced three new variables in one go. Turns out that you will have lots of new variables. Maybe you can be lazy and just introduce z two first with this meaning, and then you introduce z three and z four later if they're needed.
01:16:46.222 - 01:17:29.204, Speaker B: Turns out that this can sometimes be important. These are all applied questions. Here's a theory question. Why is corrugated search good? And how good is it? Note that the interesting thing is that now corrugated search, pseudoboolean search is actually cutting planes with extension variables. And now theoreticians of course, know that already, resolution with extension variables, that's extended friggin, that's extremely powerful. And now here we're doing extended cutting planes. So why haven't people on the plight side been doing proof systems with extension variables? Well, I think the reason is because it's hard to know to have good heuristics for which variables to extend.
01:17:29.204 - 01:18:44.948, Speaker B: But here the search is suggesting to us what might be good extension variables, namely extension variables that explain why we can't get the objective value that we were shooting for. So I think a very interesting theoretical question would be, can you somehow characterize what is the power of cutting planes with this limited form of extension? How good is it? How good can it be? Can we prove some upper bounds, some lower bounds? Because it turns out in practice this can be really powerful. Let me just show you. We actually implemented this in roundingsat, and here is the hybrid version, interleaving corrugated search and linear search. And if you compare to just doing linear search or just doing core guided search, then most of the time you get a fairly significant improvement. This thing I talked about, lazy variables. If you have knapsack constraints with a lot of different coefficients, you can see that here you have here you're not being lazy, here you are being lazy.
01:18:44.948 - 01:19:49.044, Speaker B: A fairly significant difference in the number of benchmarks you solve. Also, we have some crafted tricky benchmarks for cutting planes. These core guided techniques really pay off, except for the very annoying last line of this table, which is the academic MIP solver skip that has the rudeness of beating us on all of these instances. So that's why I also want to talk a little bit about MIP solving before we end. But it's, again sort of. Then there was a question, do I apply sub problem optimization in my hybrid approach? I don't know what sub problem optimization is, so I don't think I apply it. I mean, we just run this basically run the algorithm that I described, corrugated search, and then we switch to linear search and then we switch back and I think, yeah, I think there's like lots of things that you could probably do to improve this.
01:19:49.044 - 01:20:35.210, Speaker B: So this is just a first proof of concept, proof of concept implementation. But it shows there's really promise I'll be happy to talk about WPM two and WPM three of. So I don't know, I have to admit exactly what they do. So I definitely think there's room for improvement. So this is more like, and I think this is like this whole talk is not in order to. I'm giving this talk not in order to tell you about the beauty of a well developed technology of solvers is rather, you know, I'm trying to. My sales pitch is that there's so much that should be possible to do here in sudo Boolean solving.
01:20:35.210 - 01:21:04.546, Speaker B: Borrowing from, from Maxat, borrowing from MIP solving, borrowing from sat solving. I think there's lots of low hanging fruit here. But I think also one advantage of the sudo boolean setting is really that you have these zero one integer linear inequalities that you have the powerful cutting plane space reasoning. I think this can really pay off the question. Jakob. Yes, this keep. You said it very fast and I didn't get it.
01:21:04.546 - 01:21:30.560, Speaker B: So it beats everyone and what happens with it. It's not pseudo brilliant based or what. It's a mixed integer linear programming solver. So it's another technology. Okay, but I mean, based on this, it's a technology that maybe we should learn more about. No, that's what I was going to say. I mean, if it's a different technology and it beats everyone.
01:21:30.560 - 01:21:52.134, Speaker B: Yeah. That's why there is a fourth part to this tutorial. We're getting there. Let's see. Before we get there, can I briefly describe the problem sets in the interest of time? No, but if you. I mean, you have the reference there. This is the constraints paper.
01:21:52.134 - 01:22:08.274, Speaker B: It's on my webpage. I'd be happy to. Shoot me an email. I'd be happy to talk about it offline. I think I won't do it here. Oh, okay. So I guess here I can say very briefly, actually this is the latest suitable in competition optimization problems with limited precision.
01:22:08.274 - 01:22:57.044, Speaker B: These are some zero one interlinear programs from the MIP competition. This is a collection of challenging knapsack problems. These are our own problems inspired by the proof complexity literature. It's like a set that we've been building, accumulating over a number of years with the nice thing with crafted instances that you can design them so that they're hard in different ways. Like you need dag like reasoning with learning, or you need cutting planes based reasoning, or you need parity reasoning, and then you stress test the solvers in different ways to see if they can figure this out. And definitely, yes. So for knapsack, it's so one thing that I think is.
01:22:57.044 - 01:23:25.414, Speaker B: So I was going to move on, but Victor is tricking me into commenting more, but he's making a good comment. That MIP solver have been working on knapsack problems, so it's not surprising that they're good. Yes. And they have dedicated techniques. So that's another thing in MIP solving, there's a lot of preprocessing going on. So sciP, for instance, realizes it does some analysis, and then it says, oh, I have a knapsack problem. Why don't I try to run dynamic programming? Just because I see it's a knapsack problem.
01:23:25.414 - 01:24:10.586, Speaker B: And this is something that somehow the SAT solving philosophy and the suitable solving philosophy is, I have this specification, it is just a syntactic object. It's whatever, let's run my general purpose algorithm on it. So this is not how MIP solvers work. I think they're more like, they're really trying to analyze the structure. Especially the commercial solvers have like tons and tons of, I mean, they've seen all of these problems out there in industry and they're trying to pull all kinds of crazy tricks. And since they're closed source, you don't even know maybe what they're doing. Yeah, so, yeah, so in that sense, I mean, I think one, the positive spin on this is to say, well, there's an immense amount of work that has gone into MIP solving development.
01:24:10.586 - 01:25:20.634, Speaker B: And here you have a small research team just hacking away for like half a year, and we get this close, right, that somehow seems that there's promise in this technology. That would be my positive spin on this. Just to add to what you said, Yaqub, about MIP solvers, SMT solvers tend to have a similar flavor in that, you know, you study, analyze problem domains and add heuristics that are, they detect some pattern and they, you add heuristics appropriately, for example, rewrite rules and so on and so forth. Right? Yes. And we're going to have a talk on, on satisfiability, modular theories on SMT solving tomorrow, I think. Correct. Although it's a brief talk, and then we have an impolite constraint programming person suggesting in the chat that we should move away from the CNF as our problem format and use more expressive formulas for describing our problems.
01:25:20.634 - 01:26:01.986, Speaker B: To which I have to reply to Kieran Makrish that he should be polite when we invite him to a Sat workshop, I think, and not complain. Right? No, that's a good point. I mean, you can, you can take a different view on this, that we can model problems differently. And I guess that's, that's already one of the reasons why you would want to do pseudoboolean solving rather than, than CNF is precisely because the pseudo Boolean modeling language is nicer. For instance, counting constraints. You can model them in a nicer way, but you can certainly, you can go further and do general constraint programming where you have a much richer language. And in fact, this is something that I would also like to do.
01:26:01.986 - 01:26:54.122, Speaker B: I don't have time to talk about it, but because even in a, even in constraint programming, you have this concept of conflict analysis and learning constraints, although they call them no goods. And I think there is room for borrowing from SAT based conflict analysis and pseudo boolean conflict analysis, and you could potentially plug it into constraint programming solvers. So, but you could also, like one other way of. It turns out that sort of once the SAT solver is good enough, I think the reason why SaT is successful is that you don't need to try to detect something. The solver is just somehow good enough to do it automatically. And I think that would be one goal for sudo Boolean solving. Also, some of the underlying solving technology is so strong that you don't need to tell me that it's an upside constraint, because whatever I do with my cuts is like automatically doing the right thing.
01:26:54.122 - 01:27:15.144, Speaker B: That would be the vision, I think. Anyway, we're running badly late on time. So let's see. Oh, I haven't even talked about implicit hitting set. That's bad. Let me very quickly talk about the implicit hitting set approach. So again, we have this minimization problem given a bunch of constraints.
01:27:15.144 - 01:28:09.092, Speaker B: Let's think of them as clauses. Now then we again run the solver with assumptions, but we collect all these core clauses that have to be satisfied. And then we know that whatever assignment we have to minimize, this will have to satisfy all of these. And then what we can do, we can try to pick out a cheap ass set of literals as possible, will hit all of these clauses because we know we have to do this. So we want to compute the hitting set. And what we do is we run the solver we collect cores and in every iteration we compute the hitting set, because we know we need to satisfy these clauses somehow. But we compute the cheapest possible hitting set and then we run the solver with the assumption saying that, well, these literals in the hitting set, they're true, the rest is false.
01:28:09.092 - 01:28:52.036, Speaker B: And if we found the solution, since we're having an optimal hitting set, we know that we're optimal, and otherwise we got a new core and we add it to our set of cores and compute a new hitting set and repeat. Okay, I'm doing this a bit quickly because I want to move on to MIP solving. The interesting thing is that implicit hitting set and corrugated approaches seem to be orthogonal. Sometimes implicit sitting set is better, sometimes core guided is better. We don't have any theory on this, so here's a call to the theoreticians. Model implicit sitting set algorithms model corrugated algorithms try to prove simulation or separation results for the corresponding proof systems. There's some work on this.
01:28:52.036 - 01:29:33.828, Speaker B: I think Sam bus, for instance, has been involved in something like this. This is, I think, a paper by Iwal Filmus and Mark vinals and others. So there's some work in direction. I think there's room for much more. Or if they have complementary strengths, why not combine implicit hitting set and query edit search? So in the magset community, I think there was a solver last year that did this with some success. Or why don't we combine implicit hitting set with suitable boolean optimization? So then you're not looking for. The reason you are happy with hitting sets is that for a clause, you know, you only need to hit one literal and then the clause will be happy.
01:29:33.828 - 01:30:09.588, Speaker B: In general, if these are sudo boolean constraints, you want to find like a minimum cost partial assignment that is guaranteed to satisfy all of these constraints. It would be interesting to implement this. I don't think anyone has done it good. Still something like a little bit more than 25 minutes to talk about mixed integer linear programs. So here it is, a mixed interlinear program. We're minimizing, say, Aix. I subject to a bunch of constraints, and I guess miple seem to like less than equal, better than greater than equal.
01:30:09.588 - 01:30:44.864, Speaker B: So I switch now from my normalized form to some MIP form. In general, some of these variables will be integer valued. Some of them will be real valued. Now, if there are no real valued variables, then we have an integer linear program. If in addition all variables are bounded between zero and one, then we have a zero one integer linear program, also known as a pseudo Boolean function. This is exactly the same problem. And if in addition we add a vacuous objective, then we just have a pseudo Boolean solving problem and we can do this.
01:30:44.864 - 01:31:44.714, Speaker B: And in fact, it turns out that for decision problems, for some classes of decision problems, pseudoboolean solving technology is in fact competitive with the best MIP solvers. And if you choose evil benchmarks, then we're even better. But somehow what's MIP really shines? Where MIP really shines is when you have an objective function that you can use to somehow drive the search, and then it's very hard to even, it's hard to come up with even crafted benchmarks where sudo boolean solvers are better than MIP solvers. It can be done, I think, but they're like, it's hard, really hard to think. So MIP solvers are good. One difference compared to differences compared to the SAT community and the sudoboolin community is that the best solvers over on the MIP side are closed source industrial solvers. So that's problematic when you want to evaluate because it's hard to know what cplex Gurrobian Express doing.
01:31:44.714 - 01:32:26.420, Speaker B: You don't have access to the code. You can run the solver like scip instead, and you can look at the code, see what it's doing, and it's a very good solver, as we saw, good enough to beat all our sudo boolean solvers. But in general, these commercial solvers are even better. Another philosophical difference is if you're building a sat or sudo boolean solvers, then you want to do your search, you want to be dumb, but fast. You do fast decisions, fast propagations, and then once you hit a conflict, you back up, you slow down, you think carefully about how to do the conflict analysis. MIP is like in some sense the opposite philosophy. You can spend a ridiculous amount of effort on making your decisions.
01:32:26.420 - 01:33:16.012, Speaker B: Like, should I decide on this variable? Should I decide on that variable? Actually, maybe let's do some computation on all possible variables that I could decide on to really get a good foundation for making this momentous decision on what I'm going to decide on next. Okay, so you make sure that you make high quality decisions so that once it's time to backtrack, you just backtrack more or less. Or this is, you know, I'm not, this is my, like, personal bias take on MIP solving. I should say that this is the part of the tutorial which I know least about, so it's more like my my bias take on on MIP solving, computational complexity theorists, and as a pseudo boolean and sat solving person. So what do MIP solvers do? Well, they do some preprocessing, though they call it presolving. Then they do a lot of linear programming. And branch and bound.
01:33:16.012 - 01:33:55.644, Speaker B: We'll talk about that. They also use cutting planes, the cutting planes method. And one thing that you have to be careful about is that when you talk about cutting planes and cutting planes method and cutting planes proof system, a mid person will not understand you because they use the same terminology, but it means something slightly different. So you have to be really, really careful. Just a heads up on this. And then there are lots of heuristics that I won't have time to talk about. I'll just talk about branch and bound and branch and cut, and refer you to the prerecorded tutorial for the other stuff, or rather to the further references that are provided in the prerecorded tutorial.
01:33:55.644 - 01:34:30.702, Speaker B: So the most important technique is to relax your problem. So, some of these variables are integer valued. Let's think of everything as real valued. Now we just have a linear program solve it. This can be done in polynomial time, and clearly the solution gives at least a lower bound, or if we're super lucky and it's actually an integral solution, then you're done. Then you clearly have the optimal solution. An interesting thing is that I said you can solve this in polynomial time, but you don't use these guaranteed polynomial time algorithms, like ellipsoid or something.
01:34:30.702 - 01:35:18.694, Speaker B: You actually use the simplex algorithm, as far as I understand. And the reason for this is that we will have lots and lots and lots of LP calls on related problems. And it's really valuable to start off where you left off last, and then do a few more peoples and do something that's called hot restarts. And this is supported by simplex, but not by these other algorithms. So, branch and bound is then you choose some variable in some smart way and some bound, and then you solve two subproblems, x j greater than this bound, or smaller equal than this bound minus one. And then you do this recursively, and you grow your branch and bound tree of subproblems. Importantly, like what a satsold would do, it would go depth first here.
01:35:18.694 - 01:36:02.706, Speaker B: But you don't do depth first. Like one aspect of MIP search is that you grow your tree in different directions at different times, depending on what seems best. And then you can prune your tree, for instance, when the LP is infeasible then you definitely know that there are no solutions there. Or when you solve a problem, the LP solution is already larger than the best solutions you have so far, your incumbent solutions. Then, you know you don't need to search in that subtree. You can branch on variables, but in fact you can, and I think to some limited extent, you do branch on more general linear expressions. Now, this is very interesting, because from a theoretical point of view, this is very powerful if you're branching on arbitrary linear constraints.
01:36:02.706 - 01:36:48.290, Speaker B: This is what's known as the stabbing planes proof system, which is exponentially stronger than cutting planes. So MIP solvers are sort of inside stabbing planes, but they're not fully exploiting stabbing planes. This is my take on this as a theory person. Okay, so what's a cutting plane method? Well, it's once you solve the LP relaxation, and again you got a solution, and if it's feasible, then it's great, you can terminate. But if it's not, if it's a fractional solution, then. So, okay, so there's a stopping planes in cutting. Am I am.
01:36:48.290 - 01:37:35.994, Speaker B: I understand. Well, okay, wait, don't we have any separation? Like morally speaking? Can you cook up something that is, I mean, okay, we don't. I thought we had some cutting planes, instances which are provably hard, that are easier for stabbing planes. But I guess it was the problem that cutting planes can then do them in pseudo polynomial size or something. Okay, I stand corrected. Let me rephrase this to maybe that I think it's reasonable to believe that stabbing planes is exponentially more powerful, though this is one of these things that we theoreticians cannot yet prove, but I think we believe it. Is that fair to say, Robert Noah, would you subscribe to that? Anyway, so back to the cutting plane method.
01:37:35.994 - 01:38:34.828, Speaker B: What you do when you have this solution, you can add some new constraint that you derive in some way that is valid for your original problem, but has the property that it's violated by the solution that you found. So you're tightening your polytope and you're removing this solution that you're not interested in. And then you just repeat, this is the cutting plane method in MIP speak. And in this sense, these rules that we saw before, the division rule and the saturation rule are kind of sort of cut rules, actually. So branch and cut is when you run branch and bound. But in every subproblem that you have, you also repeatedly solve LP relaxation, add a cut resolve, add a cut, and then some heuristic for how much you should do this, and this is, I think, what lies at the heart of what mip solvers do. Here's another very intriguing cut that I would like to understand better, the mixed integer rounding cut.
01:38:34.828 - 01:38:53.194, Speaker B: And I'm writing it in a pseudo boolean way. So here's a pseudo boolean normalized constraint. These are literals. Everything is non negative here, and we're having a divisor d. And then we can. The mirror cut will produce this beautiful looking expression. Okay, let me not even try to parse what this is.
01:38:53.194 - 01:39:51.128, Speaker B: Let me just show you by example what this is and why it might be interesting. So if you have this constraint, x plus two, y plus three, z plus four, w plus five, u greater equal five, then, unless I screwed up, the mere cut yields x plus two, y plus two, z plus three, w plus four, u greater equal to four. Okay, so why should we care about this? Well, one reason to care is, you see that these coefficients all went down by one, so potentially you could lose three here, right? But the mere cut says, no, you're only losing one on the degree of false it is. Right? And you can compare this to if you divide instead, and it's very hard to divide five to get four, but if you divide by three, then you'd get five divided by three. Rounded up is two here. So let's divide and then multiply by two to get a comparable constraint. Then again, unless I screwed up like classic tcs, division gives you two.
01:39:51.128 - 01:40:20.792, Speaker B: X plus two, y plus two, z plus four, w plus four, u greater equal four, which is clearly a worse constraint. The degree of falsity is the same, but the coefficients here are larger than these. So this is a weaker constraint than this one. And I think it can be formalized that the mere cut is, like always, at least as good as division, but it can be better. How much better? Excellent question. I would like to know. I don't know if there's anything about this in the literature.
01:40:20.792 - 01:41:20.056, Speaker B: It seems that it's a very natural question for me as a complexity theorist, but it seems like the MIP community hasn't really studied these questions, or maybe I haven't read the right papers. But I think a very interesting question is, like, mathematically formally pinned down the relative strength of mere cuts and classic division. One issue with MIP solvers is that they're using floating point, and this can lead to rounding errors and do lead to rounding errors. So it's like a well known secret that commercial MIP solvers sometimes give the wrong answers. You just hope that it's not when it's running on your problem or you hope that it doesn't matter too much. You can do exact MIP solving, but it's much slower and you don't have full support for all techniques. This brings us to the question of proof logging, which is then not available for MIP solvers, despite the fact that, again, it's so my understanding that it is well known.
01:41:20.056 - 01:41:58.850, Speaker B: It's even well known, like what kind of problems you should feed to, say, Cplex and guru B to get high probability of a wrong answer. It's just that it doesn't seem to happen often enough for people to really care about it. There has been some work on proof logging, in particular, the group behind SCIP in Berlin has been working on this, but proof logging seems hard. I think this is another interesting question, like how would you and it's hard because there's a reason. One reason I think why proof logging for CDCL is doable is that it's a monoculture. You only have CDCL. If you can do proof logging for CDCL, then you're golden.
01:41:58.850 - 01:42:36.374, Speaker B: But in mips always they do a lot of different things. It's not even clear what is a convenient proof format. And also, how would you generate these proofs with low overhead? Let me try to highlight some nice questions. Exploit the power of stabbing planes. Can we develop better branching heuristics? I'll talk a bit more the conflict analysis MIP solvers are doing conflict analysis, but they're really just doing CDCL conflict conflict analysis, so they're losing out exponentially compared to sudo boolean conflict analysis. I think sudo boolean conflict analysis should be integrated in MIP solvers. Someone should do this.
01:42:36.374 - 01:43:10.114, Speaker B: Another interesting contrast to the SAT community is that you have this parallel development of sat solving and proof complexity, where proof complexity somehow provides theoretical upper and lower bounds on what Sat solvers can do. It seems that you don't have anything like this in MIP. You don't have these families of crafted benchmarks for which you can make precise theoretical statements. So it would be nice to have this. And then it's mentioned in the chat. Yeah, I was vaguely aware of this. I didn't have.
01:43:10.114 - 01:43:59.562, Speaker B: I have to admit I failed to update the references. There is a recent paper by Gleichner et al from 2021, a computational status update for exact rational mixed integer programming, which is probably a good first paper to read on this topic. Another interesting question, which leads me to the final topic here is since these MIPS tolerance seems to be so good, maybe we can steal the best ideas from them and improve our pseudo boolean solvers. So what would be the idea? Well, sudo Boolean solvers are really good at conflict analysis, but they're lousy at figuring out when LP relaxations are infeasible. Mixed interlinear program solvers are really good at this. They eat lp relaxations for breakfast. They have lots of interesting cuts, but their conflict analysis is not so great.
01:43:59.562 - 01:44:42.588, Speaker B: So why don't we merge the two and we'll get the best of both worlds? That's the idea. And I just want to tell you about something that we did not because it's the final word, but precisely because I think it shows that there's promise in this direction, but we really don't know how to do it. So this is an invitation to work on this problem. And since I'm coming from the Sudo Boolean on SAT side, I will think of the sudo Boolean solver as being in charge. But it can sort of consult an LP solver or a MIP solver, just like would be done in the MIP setting. You could also imagine like having the MIP solver in charge and being able to consult the pseudo Boolean solver for conflict analysis, for instance. That would also be an interesting direction.
01:44:42.588 - 01:45:35.364, Speaker B: But I won't talk about this here. So if you want to have a pseudo Boolean solver using an LP solver, the problem is how are you going to do this? You could just try to use it as a preprocessor, but that won't be enough because there are benchmarks that are in fact which have feasible LP relaxations, but infeasibility will occur quickly once you start searching, but not at the outset. The other extreme, doing like a MIP solver would do, solve an LP relaxation before every decision. That's just not feasible because it's a different order of magnitude from what the PB solver would do. So if you solve an LP relaxation before every decision, then the LP solver would just starve the pseudo Boolean solver. So that's the first challenge. How will you balance your time allocation? Another problem is that suppose you do run your LP solver.
01:45:35.364 - 01:46:05.696, Speaker B: It tells you that given the trail you have, your residual problem is infeasible. You should backtrack. What should the pseudo Boolean solver do? Well, it should backtrack, I guess, but it can't. It can only do conflict analysis. So it needs a violated constraint. But there is no violated constraint because if there were a violated constraint, the PB solver would occur more subtly. Maybe the LP solver is telling you to backtrack because of some rounding error.
01:46:05.696 - 01:47:06.542, Speaker B: Of course, in a Boolean solver you can't have rounding errors. I mean, you need to have sound reasoning. Third, interesting question. You have a lot of cut constraints being generated in the LP solver. Should we give them to the sudo Boolean solver also? And in fact, the conflict driven learning that is happening in the pseudo Boolean solver is also a cut generation, as it were. Should we give these cuts? You can make this formal, though I'm not doing so here, but should these cuts be passed on to the LP solver? So let me tell you what we did in a collaboration with the SCIP team in Berlin with so we balance time by keeping track of the total number of pivots in simplex, and we make sure, roughly, that the total number of pivots is never more than the total number of conflicts that the pseudo Boolean solver has seen. So if this is not satisfied, then we don't run the LP solver.
01:47:06.542 - 01:48:00.882, Speaker B: But whenever this equality is satisfied and it's time to make a decision, then we say okay, now the pseudo Boolean solver can maybe consult the LP solver. Then we run it only for pivots, which is unbound because otherwise the LP solver might never get back to us and we might timeout. So if we run for more than pivot, then we just time out. But we don't like that because that's wasted time on an LP call that didn't provide any information. So if that happens, we also double this limit P, which means that in the future we'll probably call the LP solver maybe half as often, but we're twice as likely maybe to get meaningful results. This problem of having a doing conflict analysis is actually not a big deal. Farca's lemma tells us that if we are infeasible, then we can efficiently compute the linear combination of constraint that is violated.
01:48:00.882 - 01:48:54.774, Speaker B: So we'll do this, and we'll add this as a new constraint, this linear combination, we'll add it as a new constraint to the solver, and then we can say, hey, actually you have a new constraint in your database and it's violated. And then the sudo Boolean solver says aha, let me do conflict analysis. And if there are rounding errors, this constraint is not violated, and then we just ignore it and continue. And then we've exploited trying to share these MIP style cuts with the PB solver we also tried sharing learned cuts to the LP solver. Okay, so why is this different from what mips always do? So now I'm running out of time. I think I'll maybe skip this. So this is like trying to explain in MIP language what pseudo Boolean conflict analysis is, but I'm running out of time.
01:48:54.774 - 01:49:35.840, Speaker B: You'll have to refer to the prerecorded material for this. I think that the moral of this is that. So what MIP solvers are doing is similar but different, so the propagation is stronger but slower. And the conflict analysis I claim is actually weaker because you're not operating on the linear constraints, you're operating on disjunctive clauses extracted from these linear constraints, and that's exponentially weaker. Plus, when you're running a pseudo boolean solver, you don't have the issue with floating points. So how does this perform? So here are these tricky knapsack benchmarks again, and we run roundingsat. So this is this green thing.
01:49:35.840 - 01:50:30.348, Speaker B: And then we add communication with the LP solver supplix from SCIP. This is this blue line. And then we add the Gomorrah cuts from the LP solver to the PB solver and that's this. And then we even share learned cuts from the PB solver to the LP solver and we get a further improvement. And sudo Boolean solvers without these techniques are like down here. So clearly these techniques pay off for knapsack problems. Here are the same benchmarks as before the oh well, some of them here, the suitable and competition decision instances, optimization instances, some zero one interdilinear programming problems from the MipliB, and you can see that in every category the original rounding set or skip is better.
01:50:30.348 - 01:51:03.964, Speaker B: But somehow the mixed solver rounding set plus linear programming integration is always an honorable second best. So if you had to pick one solver, you should pick it because it has a well rounded performance. It's never much worse than the best one, which wasn't what we were shooting for. We were shooting for being best, but we couldn't get that. So second best. It turns out that of course adding LP solving comes at a cost. In particular, on sudo boolean decision instances, we lose out.
01:51:03.964 - 01:51:46.952, Speaker B: On satisfiable instances, we solve fewer, not because the search is worse, but because the search is slower. So the solver gets more intelligent, but it doesn't pay off for the knapsack benchmarks. We saw that sharing Gomorrah cuts is helpful, not so much for MiP instances. And sudo boolean instances. And then we looked at one interesting thing like how useful are different constraints? So it turns out that these farcas constraints are super useful. It seems they appear much more often than your average standard constraint. In later conflict analysis, however, remember that these forecast constraints, we plug them in and then we do pseudo boolean conflict analysis based on these constraints.
01:51:46.952 - 01:52:40.580, Speaker B: And the final pseudo boolean constraints that you learn from these conflict analysis, they're actually worse than your average regular constraint, it seems, at least based on the statistics we have, we don't know why. So how would a CNF encoding with the sats already do? Albert asks. Well, this is essentially what naps is. So naps is like re encoding to CNF and running a CDCL solver. So the answer is not great. And then you can ask but how would a magsat solver do? And we don't know because the magsat solvers don't read sudo Boolean input. So this is something that I think should be changed so that we could, because I think, I think the best magsat solvers would probably be much better than this and might even beat us.
01:52:40.580 - 01:53:37.204, Speaker B: But they don't read the correct format right now, so it's hard to compare. Okay, so, but again, this is just, you know, there's lots of things you could do here. Improve the heuristics. I think we could do a lot of smarter cut generation, smarter sharing, maybe dynamically allocate the time for pseudo boolean solving and lp solving depression. Depending on some measurement how much the solvers are contributing, it would be nice to understand which constraints are good or bad. Can we somehow make use of the solution to the LP relaxation to guide the pseudo boolean solver when it's making decisions? I mentioned already, pre solving would be nice to have in pseudo Boolean solvers. Why not take the pseudo Boolean conflict analysis and plug in mere cuts instead of division? Well, there are reasons both for and against, I think, but it's definitely something that I would like to do.
01:53:37.204 - 01:54:43.334, Speaker B: Take a core guided magsat solver, or a core guided pseudo boolean solver, or an implicit hitting set based sudo boolean solver which doesn't yet exist, and combine it with an LP solver in a similar way. That's an open direction. What is lacking in roundingsat is it's fairly good at proving optimality, but it's pretty lousy at this point in time with actually finding the solutions, which is good to be able to do if you want to prove optimality, and then it helps to have a solution to prove optimality for. This is another research direction for MIP. I do believe that there should be a payoff if you have better if you try to use Sudo Boolean conflict analysis rather than CDCL conflict analysis. One other interesting idea is to solve actually general zero one MIP problems with floating point variables by having a pseudo boolean solver taking part of the boolean part, and then the floating point variables could be taken care of by an LP solver. Lots of ideas that you could try out, I think, but time is out almost.
01:54:43.334 - 01:55:27.844, Speaker B: So if I try to sum up what I said today, and also what I said in my. Well, it wasn't quite 9 hours of pre recorded lectures, but I think it's maybe something like three and a half, 4 hours. Pseudo Boolean optimization is an expressive formalism. It's true that you can have even more expressive formalisms like satisfiability, modular theories, and constraint programming. But a large number of problems, you can express them very naturally as sudo boudin optimization problems, and then you can attack them. And there are different approaches for this. You can use Sat solving and max SaT, you can use mixed interlinear programming, you can use the cutting planes based sudo boolean reasoning.
01:55:27.844 - 01:56:33.924, Speaker B: And the point is, these seem to be complementary approaches. I believe there's room for synergies, I believe there's room for getting more mileage out of these techniques by just, by reading up on what they are, understanding what they are, and then trying to combine them. Lots of highly non trivial questions when it comes to designing algorithms. And it's not so hard to actually design complicated algorithms, but then you have to implement them so that they run blisteringly fast. And then a thing like unit propagation is really, really key, because if you're losing a linear factor in your unit propagation, then you're dead. And then there's lots of, I think there are lots of nice theoretical questions said about subsystems of cutting planes, about stabbing planes, understanding the power of core guided approaches with extension variables, understanding how they compare to this implicit hitting set approach. This is not normally the kind of proof complexity theory that we do, but it is a kind of theory that could really be helpful to practitioners and inform their design choices.
01:56:33.924 - 01:57:07.654, Speaker B: And I do believe that if you're somewhere in between these areas, so it's tricky, because you need to be able to understand different communities that speak different languages. But if you do this, that means that you can sometimes see connections that are obvious with hindsight. So I believe there might be quite a lot of low hanging fruit. And above all, I think it's a lot of fun to work on this. So I hope that some of you during the semester will join me in exploring these problems. And thank you for attending the talk today.
01:57:09.394 - 01:57:38.514, Speaker A: Thank you, Jacob, for an excellent talk. Everyone should I'll clap my hands where you can see it here, and hopefully the rest of you have joined in. It is exactly 1030. So there's both the possibility of joining in Gathertown, but I suggest first we open the floor to some questions and discussion here, and then I encourage everyone to go over to Gathertown afterwards to talk a little bit. So we're open for questions or comments, other discussion.
01:57:40.974 - 01:58:31.318, Speaker B: So apparently there's two questions that I missed. So MIP solvers like scip use a cut pool. They score cuts and only consider those that score high enough. Do any PB solvers do something like that? Well, so, firstly, I'm only aware of one native ceru boolean solver with LP integration, namely the recent rounding SAT implementation. I mean, combining SAT or constrained programming with LP solving is certainly not a revolutionary new idea. It's like an obvious idea, but it seems pretty hard to make it work. And I think one of the key contributions actually, of our work, probably, which was not my idea, but the idea of my postdoc Joe de Vrend was this idea of somehow balancing the time to make sure that the LP solver gets time to run but doesn't starve the PB solver.
01:58:31.318 - 01:59:29.626, Speaker B: I think that's a really nice insight, given that what we did was basically, we tried to copy more or less what the MIP solvers do. So we generate a bunch of constraints, and then we try to keep constraints that are not so parallel to previously added constraints and so on and so forth. But I think the short answer is, I think there's lots of room for improvement, probably. So, I mean, there's a lot of smart things that MIP solver do that we don't do, just because we over on the pseudo boolean side we have. Nobody has investigated it to the best of my knowledge, and I think it should be investigated, it could probably pay off. I mean, the experimental results that I told you about sort of indicates that there's a clear payoff, is my answer to that question. Do I see any real world applications for counting or enumerating models of PB constraints? I think I'm the wrong person to ask that question.
01:59:29.626 - 02:00:13.000, Speaker B: I don't do real world applications. I do theory. And then sometimes there comes interesting computational problems from the practical side, and then I try to solve them, but I really don't care about the applications so much. For me, it's like the challenge of solving a pseudo Boolean formula with an objective function. Um, but, um, I mean, quite potentially, there are a lot of problems that you can model in pseudo boolean form instead of CNF, and all the model counting applications for those, I guess, would be, would be relevant also for. Potentially for, for pseudo Boolean formulas. I think there are potential.
02:00:13.000 - 02:00:40.624, Speaker B: I'm a little bit out of my comfort zone here, but I think something like weighted model counting is fairly natural to express with pseudo boolean constraints. That could be a possible application. Other people in the audience might be better placed to answer this question, though. I think that's the least bad answer I can give.
02:00:41.044 - 02:01:15.744, Speaker A: Okay, good. Any more questions or discussion? So there is a comment about not for Jakob, about having a proposal reading group about pseudo boolean solvers. Ask Mossimo. So I think to my mind that sounds like a great idea, and I'm sure others would agree. Probably you just have to follow up on the proposal and start the reading group, pick a few papers to get started with, and we can open a channel on ice discord for that.
02:01:16.324 - 02:01:54.804, Speaker B: I don't know if practitioners do polymath, but you could certainly imagine a polymath project on taking a good basic solver and then exploring all kinds of settings and really understanding what's going on. This is a little bit related to, I think, what also came up in Armin's talk the other day to understand, to see what these solvers are doing. I mean, I think there's lots of room for developing a rigorous scientific understanding of what the solvers do. We're really in the dark as to why certain techniques perform well and others don't. There's lots of room for improvement here.
02:01:59.444 - 02:02:18.384, Speaker A: All right, sounds like that's all discussion. So thank you again, Jakub, for a fabulous talk. And the gathertown link is in the chat window if anyone would like to come over and try to mingle virtually on the screen and otherwise. Thank you very much.
02:02:19.284 - 02:02:21.804, Speaker B: Thank you. Thank you.

00:00:01.920 - 00:00:53.374, Speaker A: Hello everyone. So I will talk about solvability of polynomial systems over finite field. So what is our problem? We are given a couple of polynomials, say f one, f two through f m over a finite field. So each fi is an n variate polynomial over a finite field. Let us say f p.
00:00:55.954 - 00:00:57.294, Speaker B: Prime or prime power.
00:00:58.034 - 00:02:26.864, Speaker A: Yeah, prime power in general. But very soon I will fix p to be a prime and we are given the finite field and this tuple of polynomials, and we are concerned about the variety of this defined by this. I will refer to this as the geometric variety, the set of all points in the algebraic closure of f p, so that all f I's vanish at the point I at the point a. But in this talk I will mostly be concerned with the rational points on this variety, which is all points in the base field fp itself. And ideally, given this bunch of polynomials, I want to be able to answer questions about the set of rational points on this variety efficiently. So what are the questions that one can ask? The first is the solvability, which is the main topic of this talk is the set of rational points. Nonempty.
00:02:26.864 - 00:03:41.660, Speaker A: One can ask to find solutions, which is find point, find a rational point on this variety. And one could also ask for the counting question what is the size of this set of rational points? And will mostly be concerned about this question, whether the variety, whether the set of rational points is non empty. But along the way, I will tell you things about these two questions also. So let me just make a few remarks about the input size and the input representation. How are the polynomials given to me? So I will, I want to talk about algorithms for these questions and their complexities. I have to tell you about the representation of the inputs. So each polynomial will be given to me as a vector of coefficients.
00:03:41.660 - 00:04:32.074, Speaker A: So, I have m polynomials. Each of them is of degree d on n variables. So if you just represent it by the knife as a list list of coefficients, you will have so many coefficients, and each such coefficient is a element of the finite field, so you can represent it using log p bits. So this is the size of the input that we have. And ideally we would like to answer all these three questions in time. Polynomial in the input size, which is which is this right? Of course, this is a canonical NP complete problem. We cannot hope to solve it efficiently.
00:04:32.074 - 00:04:34.854, Speaker A: All these three questions are np hard.
00:04:35.834 - 00:04:36.574, Speaker C: So.
00:04:43.994 - 00:05:49.034, Speaker A: Before I go on to the exact results here, let me just mention that there is a trivial algorithm for which will answer all these three questions, and which is the following. Since we are concerned only about the rational points, we could try all possible points. There are p to the n of them. So there is a trivial algorithm with this much running time, which solves all these three questions. So sort of, this will be the benchmark we will, we want to be really efficient in terms of this compared to this. So the theorem that I want to, that I will gradually build up two is the following. If you fix the dimensionality of this problem.
00:05:49.034 - 00:05:53.474, Speaker A: So for any fixed n.
00:05:57.374 - 00:05:57.886, Speaker C: There is.
00:05:57.910 - 00:06:48.334, Speaker A: A polyester time algorithm for solvability. So let me just make a few remarks about, so about this theorem statement here. First of all, I have hidden the dependence on n here. The dependence on n currently that I know is rather bad. It is d to the two to the n times s. But I suspect that this can be improved. I strongly suspect this can be improved to d to the n.
00:06:48.334 - 00:08:05.374, Speaker A: The analysis here is probably sloppy. The second thing is this builds on a series of results starting from the work of burly camp in the sixties. So I present all those ideas to you, and one can ask for similar questions, similar algorithms for questions two and three. Now, this algorithm here is a deterministic algorithm, if you are looking for a rational point on this variety. We know of a randomized polynomial time algorithm for fixed n for doing this, and counting the number of rational points is difficult in almost all cases, all cases where n is more than two, there are very few situations in which we can count the number of rational points, and that is a major area of research in algorithmic number theory, whether you can count even the number of rational points on curves over finite fields or not.
00:08:08.474 - 00:08:18.334, Speaker D: So before you go on, so, of course, the trivial algorithm is polynomial at s. So p must not appear in this somehow.
00:08:19.614 - 00:08:19.950, Speaker A: Yeah.
00:08:19.982 - 00:08:25.754, Speaker D: So here p occurs in S is the logarithm, but then it doesn't occur explicitly otherwise in that polynomial.
00:08:26.614 - 00:08:34.274, Speaker A: So here we will have running time, which is polynomial in d m and log p.
00:08:41.054 - 00:08:42.794, Speaker B: D is the degrees, right.
00:08:44.214 - 00:08:55.044, Speaker A: D is the degree of the polynomials here. Each fi is of degree at most d.
00:08:57.104 - 00:08:57.584, Speaker C: Yes.
00:08:57.664 - 00:09:00.284, Speaker B: Can you replace d plus n? Choose n by the number of terms.
00:09:01.304 - 00:09:51.706, Speaker A: Number of no, by the sparsity of these no, I do not know how to do that. In fact, there is some very recent work of qi Cheng, which seems to do something about it. But in general, dealing with sparse polynomials is much more difficult. So throughout the rest of this talk. So I will think of n as fixed. So it will be good for, I mean, for, say, n is three. It will be just easier to follow this, and for ease of presentation, I will assume that p is prime.
00:09:51.706 - 00:10:19.944, Speaker A: Most of what I say will hold over any finite field, but it will just help me with the exposition. To assume p is prime, I would not have to deal with some degenerate cases. And I will mention some open problems, which are open really when p is prime and solutions are known over small characteristic fields. And also, just to sort of.
00:10:22.284 - 00:10:22.644, Speaker C: Tell.
00:10:22.684 - 00:10:54.594, Speaker A: You that we want to avoid this regime where the trivial algorithm works, you should think of p as large. This is the main thing that we are concerned with. So think of p as maybe at least two to the d or something. So in that kind of situation, the trivial algorithm is very slow. So, any questions about the problem statement or the theorem statement before I go on?
00:10:56.534 - 00:10:57.206, Speaker C: Question?
00:10:57.350 - 00:11:03.166, Speaker E: Yes, I suppose in this range, when p is large, you could also ask an approximation version of questions.
00:11:03.190 - 00:12:06.454, Speaker A: Yes, it turns out that you can also answer approximately the number of solutions here. And deterministically. So this has an approximation algorithm, and it will just follow from what I tell you. Here will be the outline of this stock. I will try to keep this outline here. So the way I plan to present this is to gradually build it up. I will start with the case where n is equal to one, then go on to n equal to two, which will contain most of the ideas anyway, and then see that how to generalize it to n equal to three and beyond.
00:12:06.454 - 00:12:58.594, Speaker A: And within each n, I will first reduce the problem to varieties defined by a single polynomial. So in some sense, to varieties which are correspond to hyper surfaces. And then we will see how to handle the m equal to one case in all of these. So. So, let us go on to our first case. N equals one. Please feel free to stop me and ask questions.
00:12:58.594 - 00:13:08.354, Speaker A: So, now we are given each f I is a univariate polynomial in x one.
00:13:10.234 - 00:13:10.974, Speaker C: And.
00:13:16.994 - 00:14:34.344, Speaker A: We want to know whether they have a common solution or not. So, the first thing I will do is reduce it to the case where m is equal to one. And in this case it is very easy. Suppose if we look at the GCD of all the f I's, this can be computed efficiently by Euclid's algorithm. And then the main point is that the rational points of this variety are contained in the rational points of the GCD. So now we are, we have reduced our problem to a single univariate polynomial, and how to check whether it has a root or not. So now suppose if we look at the GCD of G.
00:14:36.244 - 00:14:38.852, Speaker C: With x to.
00:14:38.868 - 00:15:44.554, Speaker A: The p minus x. So now recall that over a finite field, x to the p minus x, it factors completely, and the roots are all the points in the finite field. So this, the roots of h will exactly be the rational points on gift. And now the only non trivial thing here is how to compute this GCD. And I claim that this GCD can be computed efficiently. The main point here is that this is a very large degree polynomial, so it is not immediately obvious how to do this. So basically, we want to run Euclid's algorithm for computing GCD.
00:15:44.554 - 00:16:56.434, Speaker A: But in the first step of the Euclids algorithm, recall that you will divide this polynomial by this, so you will get some remainder, and then you take the GCD of the remainder with g and so on. And the, the main observation here is that this first step of the Euclids algorithm, where you want to compute this remainder, can be done efficiently. And the way to do it is by repeated squaring. So you start with x one, compute x one square, x one to the four, x one to the eight, and so on, and multiply an appropriate subset of them together to compute x one to the p mod G. And in this entire process, our degrees never go more above the degree of G. So the degree of all our univariate polynomials stay below D. And that is why this is efficient.
00:16:56.434 - 00:17:00.994, Speaker A: So you are not doing.
00:17:03.414 - 00:17:04.154, Speaker D: That.
00:17:04.634 - 00:18:54.504, Speaker A: So it is a small modification of Euclid's algorithm. So the proposition is that h x one can be computed efficiently. And we have a name for this, we call it repeated squaring. And this is from the sixties, we already knew it. So in fact, not only does it help, so now if I just look at the degree of h, this is exactly the number of rational points on my variety. So I compute the GCD and look at the degree, and I have solved questions one and three, both of them in this case, and everything is efficient here. Now, although this is somewhat away from the main topic of this talk, I cannot help you give an idea of how to solve question two also in this case, and this is work due to burly camp, Alvin Burly camp, who was here in Berkeley, and due to canter and Zezanhof.
00:18:54.504 - 00:19:11.264, Speaker A: So now we want to find the roots of h also. So the question is.
00:19:27.494 - 00:19:28.102, Speaker C: So let us.
00:19:28.118 - 00:19:56.484, Speaker A: Say h. These are the roots of h, alpha one, alpha two through alpha e. So I am going to try to factor it and keep on factoring until I hit a root. So here is one neat observation. How do I factor?
00:19:58.664 - 00:19:59.404, Speaker C: So.
00:20:01.264 - 00:21:19.834, Speaker A: Suppose it happened that some of the roots of h were quadratic residues and some were not residues in particular, let us say alpha one was a residue. So recall that residues are in a finite field are all sort of the squares. A number is a residue if there exists a beta such that beta square is alpha, and also a number is a residue if and only if the p minus one by two h power is one. So if it so happened that one of among the pair alpha one and alpha two, one of them was a residue and the other was not a was a non residue, then if you were to compute h hat which is the gcd of h with the polynomial, both roots are all the residues in the field x to the p minus one over two minus one, then.
00:21:21.554 - 00:21:21.890, Speaker C: H.
00:21:21.922 - 00:21:28.054, Speaker A: Hat will be a non trivial factor of f of H.
00:21:33.794 - 00:21:34.370, Speaker C: So it is.
00:21:34.402 - 00:22:00.154, Speaker A: Non trivial in the sense that it is not equal to one or h. So just to summarize, if it so happened that some of the roots were residues and others are not, then we obtain a non trivial factorization of H.
00:22:05.894 - 00:22:06.794, Speaker C: So now.
00:22:12.734 - 00:23:29.854, Speaker A: How do we handle the case where all the alpha is are residues or all the alpha is are non residues? And here is the idea. It is a very simple one, but a very beautiful one. Do a random shift. So let me explain this. So suppose if I take h x h of x and shift it by a randomly chosen element from the finite field, so pick a beta at random from the finite field and consider this polynomial, call it h tilde of x one. So its roots are essentially just the alpha is shifted by the betas. Now the claim here is that.
00:23:31.714 - 00:23:32.266, Speaker C: For.
00:23:32.370 - 00:24:20.174, Speaker A: Now, since this is h tilde is obtained from h by this simple shifting. In particular, the factors of H tilde are in one, one correspondence with the factors of h just by shifting. So it, so factoring h is equivalent to factoring h delta. We know our beta, we have, we have ourselves chosen it. And the, the claim is that with good probability, h tilde satisfies this condition. So with good probability I can factor h tilde and thereby factor h itself. So with probability about half.
00:24:23.154 - 00:24:27.864, Speaker C: That is a different p, right? Yeah, yeah.
00:24:31.244 - 00:25:21.174, Speaker A: Which is about half. It's about probability half. For the shifted polynomial, one of these new roots will be a residue and the other non residue, or vice versa. So with probability about half, I can factor this and then I just keep on doing this. And if one beta fails, I just pick, try a few more beta and with very high probability, very quickly you will be able to factor h. So let me just prove this. The proof is also very simple.
00:25:21.174 - 00:25:37.574, Speaker A: So this is equivalent to saying that I want the difference to be non zero. So for the object on the left hand side. Think of it as a polynomial in beta.
00:25:38.674 - 00:26:47.774, Speaker C: It's a non zero polynomial in beta, because, for example, if you plug in beta equal to alpha one, this is a non zero number, and it is a polynomial beta of degree at most p by two, roughly p minus one by two, roughly p by two. So it has at most p over two zeros. So picked beta randomly from Fp. So there are p choices of beta, and with problem, and roughly half of them are bad. So with probability roughly half, this will be non zero. So yeah, this is a very simple and beautiful idea. It has been around for 30, maybe almost 40 years now.
00:26:47.774 - 00:27:40.454, Speaker C: We don't know how to de randomize this. So this is open. Find a deterministic polytime algorithm for computing rules. So that's all that I want to say about the case where n is equal to one. Any questions?
00:27:43.434 - 00:27:48.586, Speaker D: Is there any improvement to the probability? Like get probability three, four?
00:27:48.730 - 00:28:13.474, Speaker C: Yeah, there are some improvements to the probability. So here I just use the fact, I just used two of the roots, alpha one and alpha two. When you have more roots, you can do a better analysis, and the probability here becomes substantially less depending on how many roots you have. Question here.
00:28:14.334 - 00:28:24.330, Speaker D: So in this univariate case, it suffices to take the input size to reduce the number of terms, and that would still be polynomial time, what you've just described, right?
00:28:24.522 - 00:28:46.034, Speaker C: No. So when we want to do this GCD computation here. So in that case, the first step of the GCD computation is divide this by h and compute the remainder. So although h might be sparse, this remainder might be very dense. And then.
00:28:49.854 - 00:28:58.958, Speaker D: To improve the probability, you could just increase the running time by a constant factor and do it several times. You could get it to three, four just by doing it twice.
00:28:59.046 - 00:29:54.484, Speaker C: Yes, exactly. Exactly. Yeah. So you can improve the probability by just repeating it. Let's say if you repeat it, log three times, then almost certainly you will have found an alternative. So let's now go on to the bivariate case. We have a bunch of polynomials, f one through fm.
00:29:54.484 - 00:31:13.320, Speaker C: So for the exposition of the bi widget case, it will help me to think of my variables as x and y, rather than x one and x two. It will be easier to present things, and we are looking for last two points. And like before, the first thing one does is taking the gCd's of all the pairs. So suppose you take the GCd of f one and f, call it g g of x y. And suppose the GCD is non trivial, it is different from one then notice this, that our set decomposes into a union of two smaller things. So let's say f one is g times f one hat and f two is g times f two hat. Then the zeros of f one and f two decompose as zeros of g union.
00:31:13.320 - 00:32:27.014, Speaker C: The g zeros of f one hat and f two hat. And more generally, even if you throw in all the other polynomials, we also obtain a decomposition. So we just let keep on taking pairwise gcds and breaking our problem into two smaller sub problems until we cannot do it anymore. So after the end of this, assume that the FIS are pairwise co prime. Essentially this run Euclid's algorithm. But now in one variable. Yeah, in one variable.
00:32:32.674 - 00:32:39.854, Speaker B: Is that really what you do? You just use GCD with respect to one variable? Or is there some random choice, choice of change of variables or something?
00:32:39.974 - 00:32:58.554, Speaker C: Yeah, so there are some degenerate cases. So what he's referring. Yeah, but I will ignore that. Degenerative. There's a random shift you can do to take care of. So assume that the FISa raise Copenhagen.
00:33:00.254 - 00:33:11.094, Speaker D: This doesn't introduce a factor of two to the mix. Sorry, this doesn't introduce an x. You have to do every, every pair and then keep going. Keep going. Yeah, it doesn't do too many.
00:33:16.674 - 00:34:11.484, Speaker C: Because the degrees are going down. And if you look at the sum of the degrees, you wouldn't have changed too much. So now suppose M is two or more. Then one thing one can do is let us look at the first two polynomials. I could take the resultant with respect to say x, and call it dou y. This is a univariate polynomial in y, and since they are co prime, this will be non zero. So now any common zero of f one and f two.
00:34:11.484 - 00:35:23.940, Speaker C: So, one more thing. It will be easier for me to tell you about the randomized algorithm first. So initially I will assume the use of randomness, and then later we will see how to de randomize. So here is where the use of randomness comes in, because, so here is an elementary proposition. Now, for any common zero of f one and f two, the y coordinate must be a zero of the resultant. So if a point ab belongs to the variety of exponent two, then p must be a zero of the result. So by that algorithm that I told you, the randomized algorithm, you find all its roots.
00:35:23.940 - 00:35:57.896, Speaker C: There are only roughly d square, many of them for each of those roots. Plug that back into the f I's. And I have gotten a system of polynomials in, in one variable, and then we know how to solve that. So that's it. So if m was more than two, we know how to do it. So, now assume.
00:35:58.040 - 00:36:03.204, Speaker D: So, the randomization here, you're doing some random substitutions to put them in position. So, that.
00:36:05.724 - 00:36:08.492, Speaker C: Randomization we are using to find the roots here.
00:36:08.548 - 00:36:12.264, Speaker D: Yes, to find the roots, but also.
00:36:12.764 - 00:36:18.140, Speaker B: You need to reduce the m greater than two ks to the m equals one k. So, I would take the random linear combination of polynomials.
00:36:18.172 - 00:36:18.484, Speaker C: Right.
00:36:18.564 - 00:36:20.384, Speaker B: Take two random combinations.
00:36:21.204 - 00:36:59.432, Speaker C: No. So I could do it with just the first two of them. Yeah, but in practice, that's a better idea to take random linear combination. But I can do it just with the first two, because they are co prime. This will be non zero. Okay. So here will use what are called whale bounds.
00:36:59.432 - 00:37:39.484, Speaker C: So, let me tell you the idea behind whale bounds. And this is where it will also answer Kiran's question. We will, in fact, get an approximation algorithm for Q three. So, let me tell you what we. But before I give you the formal statement of wheel bound, let me give you some intuition. So, suppose you ask this question. Suppose I pick a univariate polynomial over FP at random of degree D.
00:37:39.484 - 00:38:22.944, Speaker C: Let's say just a univariate polynomial. And suppose I am interested in how many roots there are. So, here's the question. I pick a univariate polynomial at random of degree d over fp. And let's ask this question. What's the number of roots of h, the expected number of roots? What's the probability measure of this? This is a finite set. When you look at degree d polynomials uniformly attracted.
00:38:22.944 - 00:38:56.354, Speaker C: So the answer, it stands out is one, almost one. One plus two over p. But let's ignore this two over p. Very small. Anyway, so, in expectation, a random polynomial, a random univariate polynomial has just one root in the base field. Does this number depend on the measure? I mean, if you take. Yeah, yeah.
00:38:56.354 - 00:39:53.944, Speaker C: For the uniform distribution, it is. So, now, I can tell you about wave bounds. So, suppose if I have a bivariate polynomial over f p. Now, so, imagine doing this. So you have two variables. Suppose if you run over all possible choices of the y variable, all possible values of y in the field fp, then, in expectation, we expect, for each choice of phi, we expect 10 to pop out. So.
00:39:59.424 - 00:40:00.724, Speaker D: What'S a heuristic?
00:40:01.264 - 00:41:18.884, Speaker C: So, yeah, so, heuristically, you would expect the number of rational points on f one to be p. And the whale bounds tell you that this is indeed the case up to an error terminal. And if f f one satisfies some nice algebraic conditions. So I will tell you what that algebraic condition is most so most bivariate polynomials will satisfy this condition. It is called absolute irradiation. So suppose f one is irreducible and also absolutely relative. Then the number of rational points on f one is roughly so.
00:41:18.884 - 00:42:22.404, Speaker C: By irreducible here, I mean irreducible over fb, and absolutely irreducible just means that it is absolutely irreducible over the algebraic closure of FBI. So let me take some examples to illustrate this notion of absolute irritability. So for example, suppose square root of minus one is not in fp. Then consider this polynomial x square plus y square. This will factor over the closure like this. So this is irreducible but not absolutely irredisible. On the other hand, if you look at a polynomial like this, this is always absolutely irreducible.
00:42:22.404 - 00:44:16.064, Speaker C: And the remarkable thing is that there is also a converse of this statement, which is true. So not exactly, but there is a partial converse and but not absolutely irreducible. Then all the rational points of exponential, their singularities of f one. In particular, the number of rational points can be at most d square. So in particular the number of rational points is very small. So let us see how to use this fact algorithmically. So, I want to tell you now about the algorithmic use of this.
00:44:16.064 - 00:45:03.264, Speaker C: I have given a binary polynomial f one. So suppose I factor it into irreducible factors over FP. Then for each of these irreducible factors, I check whether it is absolutely irreducible or not. And if there is some absolutely reducible factor, we know it has lots of zeros. Otherwise we look at the singularities. So we have, and the singularities will be very small. And we have reduced our problem to a lower dimensional problem.
00:45:03.264 - 00:46:09.614, Speaker C: So since this is going to be crucial for the deterministic algorithm, I want to tell you how to factor polynomials. This is an algorithm due to chulzofin. So but instead of doing it formally, I will sort of do it in picture. It won't be formally correct, but you can turn that geometric idea into an algebraic formalism and it will work. So let's say for simplicity that we have a polynomial which has two factors, g one and g two. If I were to draw the zero set of f, it will look like this. It will be a union of two curves.
00:46:09.614 - 00:47:05.374, Speaker C: Say this curve is g one equal to zero, and the other curve g two equal to zero. And now the first idea is this. Suppose on this curve, on the first curve, I could find a lot of points. Let us say p one, p two, p d square plus one. Suppose if I could find a bunch of points on all of them on the, on the same curve out of these two. One more thing. Let us assume that we know the degree of g one, and let us say it is e.
00:47:05.374 - 00:48:29.444, Speaker C: In practice, we do not know, but we just guess it and we iterate over all possible stresses of either. So by degree, do you mean total degree or total degree? So now, if I have a bunch of points on the same curve, I could interpolate a polynomial h through those points. So I can compute the bi weight polynomial, which vanishes on all these points. And let us say I interpolate the degree e polynomial through these points, and a non trivial solution exists. And a non trivial polynomial exists, because we know that g one itself is a solution to this. Now, now just observe by Bezu theorem. So we have a polynomial of degree e, which vanishes on lots of, which has lots of common zeros, with another irreducible polynomial of degree e.
00:48:29.444 - 00:49:20.634, Speaker C: So h must in fact be just a scalar multiple of. So, to summarize, if we have a bunch of points on one of the components, we can find that component. And now, in practice, we don't have a bunch of points on a single component. So how do we do obtain them? So, suppose I have one point on this component. Let us call it p one. One point I can obtain in the following way. I could plug in y equal to zero and solve for x.
00:49:20.634 - 00:50:07.026, Speaker C: At least with randomization, I can do it. Now, start with this one point, take the tangent to the curve. At this point. You can do this. Given f goes in some sense, an infinitesimal amount in the direction along the tangent, and you will have found another point, p two, on the curve. Then start with p two, draw the tangent at p two, go an infinitesimal amount along the tangent, you have another point, p three, and so on. And that's it.
00:50:07.026 - 00:50:34.460, Speaker C: And now I sort of waved my hands in the sense that I said go an infinitesimal amount along the tangent. But if you put it into an algebraic formula, it turns out that this idea works. So this is Karl Coffin's algorithm for factoring bivariate polymer. Yeah.
00:50:34.652 - 00:50:37.184, Speaker D: How do you find the tangent? Just one of them.
00:50:37.684 - 00:51:25.984, Speaker C: Yeah. So I'll leave it as an exercise. You look at the derivative buffet, and the derivative will have two terms, since you have a point on one of the things that the other term, which is not important, will vanish. So roughly, if you just work it out, look at the derivatives of this, evaluate it as f one. You will see the tangent staring at you? So some kind of Newton helps tensor lemma for. Yes, yes, you can do it. So the technical term for this is called tensor lifting.
00:51:28.324 - 00:51:31.828, Speaker B: Does this mean you go into power series, one of the variables, or do.
00:51:31.836 - 00:53:01.374, Speaker C: You go with the power series? So now all this, if you think about it, if you combine the whale bounds with the factoring algorithm, we get a randomized algorithm for, for this question, for our solvability question, and it also gives us a randomized algorithm for this, the second question, finding a rational point, because we know that there are lots of rational points on our curve. You just take your x coordinate at random and solve for y. So, so you get this also. But counting the number of rational points on curve remains a major open question, and we know how to do it on only very few cases. I'm sorry, there's a question.
00:53:02.674 - 00:53:09.186, Speaker D: You may have answered this already, but how do you find a single root, in this case, the root that you start out with?
00:53:09.250 - 00:54:03.254, Speaker C: Essentially, I plug in y equal to zero. So I take the intersection of the curve with the x axis, and then you use the univariate, and then you say univariately. But what if your polynomial is a product of things with very few roots, and you don't find after plugging y equal to zero? So, I mean, it's a product of components with each one having very, very few roots. Yeah. So in that case, the converse assures me that in that bad situation, all the roots are singularity. So I throw in the derivatives also, and, and then I form this new system, but I have reduced the dimensionality. So, yeah, so I'm almost out of time.
00:54:03.254 - 00:55:07.844, Speaker C: I'm almost about to end. Also, to make this deterministic, there were at around the same time, similar ideas came about. There is one paper by Zau Kalpopfen and Lauder, and another by me, which the essential idea was very similar to this. Now, notice that to get this algorithm going, I needed one point on one of the curves. So I am now into the deterministic algorithm. So I am given f. I want to sort of factor it.
00:55:07.844 - 00:56:08.674, Speaker C: So I take the intersection with the y axis, with the x axis, I set y equal to zero, call this as g. And here what we did was find roots of g. I do not know how to find the roots. So the idea is this. Go to this ring, f t z by g of z. So in some sense, the element z in this ring is a zero of this. Just pretend that this is a field, and pretend that z is an actual root of your polynomial g here and run this algorithm.
00:56:08.674 - 00:57:41.644, Speaker C: And it turns out that if you think about it, it will help you answer these kinds of questions, whether our polynomial f one have any absolutely irreducible factors or not. And that turns out to be good enough for the solvability question, question number one. So here is the idea. Just run Kaltho finish. R is the field, and that is a root. In particular, you dont actually get the factors, but it gives you essentially all structural properties about the factors that you may want to know. For example, what are the degrees of the factors? What are the extensions in which, what are the field extensions in which the various factors lie? All these structural properties about the factors of f, you can answer.
00:57:41.644 - 00:57:55.272, Speaker C: So I will just end by making one remark that gives you the absolute.
00:57:55.328 - 00:57:58.364, Speaker D: Factorization of f one or this algorithm.
00:58:00.224 - 00:58:37.186, Speaker C: Yeah, I will tell you a more precise statement. It gives you a partial factorization of f such that in the following sense. So suppose you factor f over the closure f one through fs. These are the factors of f over the closure of f of the base field. Now you can collect together all the factors which have the same degree and the same splitting field they like to contribute. Yes. Which are the conjugates, and multiply all of them out.
00:58:37.186 - 01:00:03.134, Speaker C: And so this algorithm will give you a partial factorization which are all these products of things which are of the same degree and the same deterministic. It is deterministic. So much of this generalizes to n equal to three and beyond. But unfortunately, it seems that at least the naive way that I was doing in doing it, the complexity becomes doubly exponential with respect to n for n equal to three and beyond. But I suspect that it is just that I was doing a very sloppy analysis and it can be improved to single exponentially n. So that's it. Any questions? Are the variants known to be type null? Like, do you see there exist polynomials that have roots at the bounds? So I'm not sure because I did a heuristic calculation and this.
01:00:03.134 - 01:00:46.456, Speaker C: So there are some heuristics which suggest that this error bound should be about d root p or d log p root p. So I do not know whether this d square is right or not. My suspicion would be that like d log p or something like that. For the case when n equals three, when you have just one column m equal to one. In that case, what's polygon? Yes, well, number of points. Yeah, let me just decide if there are such. Yeah, so this generalizes to three variables.
01:00:46.456 - 01:01:09.164, Speaker C: Also you can find out whether it has an absolutely irreducible factor or not. And so here you can do, if you think about your algorithm, you can find the distinct degree factors in three variables, and you can also sort of find the splitting fields of the radiant factor.
01:01:13.414 - 01:01:16.834, Speaker E: The bay conjectures play some role here as n increases.
01:01:19.934 - 01:01:30.434, Speaker C: Not the full conjecture, only the bounds on the number of last minute points. Yeah, from all I've seen, it's only these bounds that we use.
01:01:31.734 - 01:01:44.586, Speaker D: I mean, you have to know of the geometry of zero sets. We really use the binary, but I think that goes to any values, maybe.
01:01:44.730 - 01:01:46.306, Speaker E: A few cases lets you predict.
01:01:46.370 - 01:01:47.094, Speaker D: Okay.
01:01:48.794 - 01:01:51.330, Speaker C: Any other do you know any.
01:01:51.362 - 01:02:00.990, Speaker D: Complexity lower bounds if the input polynomials were sparsely represented? Or do you expect that these results will generalize to sparse polynomials?
01:02:01.102 - 01:02:17.182, Speaker C: No, I suspect that for sparse polynomials things are much more difficult. So there is one result which is known that even computing the GCd of two very sparse polynomials is in general NP complete, even detecting roots too.
01:02:17.238 - 01:02:26.894, Speaker B: If you detect roots for over a prime field, if you let the prime grow, it's also NP hard. It's NP hard with respect to DPP reduction. So in one variable, sparse is already hard. Just deciding if you have already.
01:02:34.114 - 01:02:34.426, Speaker C: To.
01:02:34.450 - 01:03:06.914, Speaker E: Revisit my question one last time. So I guess in the general case, for the number of rational points, the main term is like q to the dimension of the zero set times the number of absolutely irreducible components, and then the error term is like q to the d minus a half times some something. Do we have any hope of at least finding that 2nd 2nd order term that's somehow intermediate between the full counting problem and just this? But maybe in some special case, right, for curves this is already as hard as the counting problem, but maybe.
01:03:06.954 - 01:03:11.026, Speaker C: Yeah, so for curve, and it is sort of like counting, maybe in some.
01:03:11.050 - 01:03:13.734, Speaker E: Complementary situation the degree is not too large.
01:03:18.414 - 01:03:22.094, Speaker D: Any more questions? Let's thank Niraj again.

00:00:00.440 - 00:00:46.014, Speaker A: Okay, so first talk in the last session. Okay, hello all. So I'll talk about this work we had at stock this summer, joined with Ankit, Pritesh and Dmitry. We also have a follow up work, maybe it's online this week. It's also with Robert. So finally get some application for this abstract machinery that presented at stock. The upshot of the whole work is, well, it's in the title, so it's machinery where you can start from lower bounds, improve complexity resolution, lower bounds normally easy to prove, at least not terribly difficult.
00:00:46.014 - 00:01:23.244, Speaker A: And the machinery allows you to derive more or less as a black box lower bounds in monotone circuit complexity, typically considered difficult to prove lower bounds for monotonous circuits. So it's a lifting theorem again that really works in the uphill direction, actually the downhill direction. Why monotone circuit lower bounds yield proved completely lower bound. That's an old thing from the nineties. It's called monotone feasible interpolation. I think it was mentioned in the boot camp. So this work you could see as proving a converse to monotone feasible interpolation.
00:01:23.244 - 00:02:22.852, Speaker A: So I'll just throw out an application, maybe the cleanest we can derive using this machinery, and that's to show an exponential lower bound for some monotone variant of the XOR SAt function. So I have to be careful. How do you define a monotone version of XOR Sat? And you have to be clever in order to make it a monotonic function. Here's the definition. You first imagine listing all possible xor constraints on n variables, let's say ternary xor constraints. So for each triple of variables, you have an equation saying their parity should equal zero or one, and there are n cubed roughly many such equations. So the input to my XOR Sat will be a subset of these constraints just given by an indicator vector.
00:02:22.852 - 00:03:03.324, Speaker A: So the input is for each row I pick whether I want to include this constraint in my CSp or leave it out. So something like this, that's an input to XOR Sat, specifies a subset of them. And I say that this evaluates to true if the set is unsatisfiable. So I say unsatisfiable because I want it to be a monotone function. I want it to be the case that if I flip a zero to a one in the input, that means I'm adding an xor constraint to my set, can only turn the function from false to true. But that's why I'm saying yes, inputs are unsatisfiable. Small detail, just to make the function monotone.
00:03:03.324 - 00:03:36.648, Speaker A: So we can show an exponential lower bound for exorcism. And it's interesting because exorcat is a really easy function. So, you know, gaussian elimination can solve it for you. In fact, there are really efficient algorithms for linear algebra, classical results. And in particular, XOR shat is even in nc two. So CD parallel algorithms. So you could interpret this as, oh, that's interesting.
00:03:36.648 - 00:04:07.620, Speaker A: It's a huge monotone versus non monotone separation. I think the previous example, the only one I know of, is a tar dashes function. So, that's some function you define out of the low theta function for graphs. And to compute that, you need to solve a semi definite program. So it's in p, but we don't know of better upper bounds for this function. Well, here's an even easier function. To milk this a little bit more.
00:04:07.620 - 00:04:55.414, Speaker A: You can also say that this is the first exponential separation between monotone circuits and monotone span programs over GF two. So, xOr sat, you can compute with monotone span programs. So monotone circuit complexity high, but monotonous span program complexity low. The other direction Roberts were handled, so they're now separated in both directions exponentially. I guess I could still say that another monotone versus non monotone candidate is the perfect matching function, so widely conjectured that you need exponential size monotonous circuits. Only a quasi polynomial lower bound is known. But even perfect matching, it's not quite an NC, it's in randomized NC.
00:04:55.414 - 00:05:25.754, Speaker A: So this is even slightly better than that. So, yeah, it's sold. This is interesting. It's just one thing you can get out of this machinery. In fact, we can proceed to lower bounds over any field, not just for GF two equations, but over any field. Okay, so, the way this project started out was really. So, Dimitri was telling me about a characterization of circuit size in the language of communication complexity.
00:05:25.754 - 00:06:09.522, Speaker A: And so, this was roughly a year ago, and I hadn't heard about this before, which was surprising. I guess we all know about the characterization of formula size in the language of communication complexity, namely determinist protocols and garchomp victors and games. But raspberry in the mid nineties, came up with a circuit version of this. Maybe it's not well known. I wasn't taught that. Some deficiency in my education. I mean, I blame Tony, but it's really important, because, at least to me, this mere characterization is kind of a conceptual breakthrough, because if you view these models from the right perspective, it kind of suggests a lifting theorem to be proved.
00:06:09.522 - 00:07:22.104, Speaker A: I couldn't imagine that such a thing couldn't even formulate a theorem in this direction without seeing this kind of a top down characterization of circuits. So I'm going to make sure that nobody lives today without understanding this raspberry's characterization. I'm going to spend some time on it. What Rossborough showed is that monotone circuits are characterized by the communication analog of PLS. So, pls polynomial local search is one of these classes of total np search problems in Turing machine complexity, problems that are total because of the principle that every dag has a sink and there's a natural communication analog of that. What Rossborough showed is, I'll define the communication version of this in a minute, but it shows that this characterizes there's both a monoton and non monoton version of this. But for us, the monoton circuit complexity of a function, really the logarithm of it, is the PLS communication complexity of the monotone Karchma victors and game.
00:07:22.104 - 00:07:43.174, Speaker A: So, I mean, already we have a communication model that tries out what's the query analog. So that's how this characterization suggests a lifting theorem to be proved. Yeah. Let me define communication pls and explore this characterization.
00:07:45.274 - 00:07:49.014, Speaker B: Is that also true for non monotonous?
00:07:50.554 - 00:08:34.654, Speaker A: So generally, circuit complexity is just a general kashmir without the monotonicity condition. So this, by the way, means that P versus NP is just a question in communication complexity. Okay, so here's the definition of a PLS protocol. I define it as solving a two party search problem. So generally, Alice gets an input from X, Bob gets an input from Y, and they need to find some output symbol that satisfies this relation. So it's just, just a general search problem. You can think concretely of monochrome, karch, movictos and games if you want.
00:08:34.654 - 00:09:40.324, Speaker A: So the protocol consists of a set of vertices. So maybe this set, it's a fixed set, and each node here is labeled with a candidate solution and an associated communication protocol. So if you recall the classical definition of PLS, it involves an implicitly defined graph, implicitly defined by a small circuit. Well, in this definition, I just replace circuits with protocols. Each node is associated with a protocol that locally describes this graph. So if I fix an input, and I run a protocol as a node supposed to output a description of the neighborhood of the node in a graph. So it outputs two pieces of data, a candidate successor node and an integer label, which is the potential, I call it a potential associated with a node.
00:09:40.324 - 00:10:06.970, Speaker A: So somehow the resulting graph needs to be a dag. And here's how I define it. So let's call it g. That results on a fixed input x and y. You take x and y and you run this protocol for each of the nodes. So you have two pieces of information attached to each node, and then you define it. There's an edge from this node to this node.
00:10:06.970 - 00:10:45.534, Speaker A: If this node thinks this is its candidate successor and the potential decreases along the edge. So maybe the potential is ten and here it's eight. So if these two conditions hold candidate successor and the potential decreases, I put an edge there. So the potential, it's there to guarantee that the resulting graph is really a dagger, because when you follow edges, the potential needs to decrease. So you never create cycles.
00:10:46.354 - 00:10:49.154, Speaker B: But how do you define the potential of a vertex?
00:10:49.194 - 00:11:20.322, Speaker A: The potential is associated with an edge, so it's associated with a node. And I say I put an edge if, well, the source node has a bigger potential. So the protocols gives not a potential of the successor, but potential of the node. That's right. Okay, so it defines a dag syntactically. And so we have to have some sinks. And I say that it's correct on this input.
00:11:20.322 - 00:12:20.094, Speaker A: If the sinks correspond to feasible solutions, load in this graph, which is sink. Okay, so then the associated label is a feasible solution for the input x and y. So for any search problem, you can ask what's the most concise PLS protocol that solves it in this sense, concise here, meaning the, um, complexity measure is something like this. The cost of a protocol I define as the log of the number of nodes you're using and the communication cost of the protocols. Let's say the maximum overall nodes of the communication cost. It's my notation for the number of bits the protocol communicates. So that's the whole definition.
00:12:20.094 - 00:12:28.344, Speaker A: If you instantiate this for a monotonic game, so then this is what raspberry approved.
00:12:29.764 - 00:12:31.504, Speaker B: What is the cost of a product?
00:12:32.524 - 00:13:10.244, Speaker A: The log of the number of nodes. So this is the number of bits the protocol communicates. That's just my notation. Okay, so let me sketch one direction just to kind of explore this definition a bit. So here's a monotonous circuit. I want to derive from a monotonous circuit one of these PLS protocols. And here's how what I do, I define this graph again gx y.
00:13:10.244 - 00:14:03.384, Speaker A: The nodes in my protocol is just the gates and the input inputs. And in order to define this dag on top of this, I'll first say that a gate is feasible. So let me denote it by just highlighting it. So a highlighted gate is feasible if Alice is input, evaluates that gate to true and Bob. So by the way, the top gate is always feasible, because the top gate compute is a function. And in a more so quite conviction game, I'm given yes and no inputs to the players. And moreover, feasibility can be decided by a protocol that just communicates two bits.
00:14:03.384 - 00:14:41.774, Speaker A: Alice knows this value, Bob knows this value. They exchange. So let me draw some notes that are feasible. And note that if an input is feasible, it exactly means that it's a solution. In the monotoncussion victor's engagement, it means that two players evaluate this positive variable differently. They've found a positive difference. If this happens, there are some unfeasible nodes, and I'm just going to define their potential as, okay, a large number infinity and make them point to the top node.
00:14:41.774 - 00:15:24.376, Speaker A: And then I'm going to observe that if you're feasible as a node, at least one of your children needs to be feasible. So that's going to be your successor. So that says that if you have a gate where you have a positive difference, Alice has a yes gate, Bob has a no gate. It must be that one of the incoming gates also witnesses such a positive difference. It could be both, but you can figure out a canonical successor, one of the feasible children. So maybe like this. So that defines a dag.
00:15:24.376 - 00:15:51.098, Speaker A: And all these relationships, these edges can be described by constant protocols that communicate constantly. Many bits and the sinks are naturally associated with coordinates. They are the solutions to monitor gasping game. That's basically the whole proof. It's really nice, the quadverse halt, but it's slightly more complicated, so I'm not going to go into it.
00:15:51.226 - 00:15:52.614, Speaker B: What are the potentials?
00:15:53.114 - 00:16:01.950, Speaker A: Okay, so unfeasible infinities, if you're feasible, then the height of the node, so that you can have these successes.
00:16:02.102 - 00:16:11.954, Speaker B: Good point. Or just the name of the gate, right? Oh, it's a topological sword. I see.
00:16:15.014 - 00:17:06.132, Speaker A: Okay, so this is really nice, but now you're asking, of course. Okay, what is the query complexity analog? If you have a communication model, well, you can canonically define it and denote that model by PlS decision tree version. In the query world we're going to study, as in Robert's talk, these search problems of low certificate complexity, which turns out with a loss of generality, they're always of this form. They're associated with unsatisfiable kcs. So f here is a unsatisfiable k csb k, let's say constant. And as input, you're given an assignment to the underlying variables. Let's say it's a Boolean CSB, so n variables, it's unsatisfiable on.
00:17:06.132 - 00:17:45.528, Speaker A: So some constraints need to be violated. The problem is to find one of them. So it's a query called experiment. You can ask what is the decision tree complexity of such a search problem? Turns out it captures the tree like resolution size of refuting f. But here we are interested in these dag like models. So then we look at again the query analog of Pls. So how would you define something like this? The definition is exactly the same, except whenever I have mention a protocol here I just instead have a decision tree.
00:17:45.528 - 00:17:48.204, Speaker A: So each of the nodes are associated with a decision tree.
00:17:48.984 - 00:18:17.628, Speaker B: So correct me if I'm wrong, but from this definition for the communication version you might as well just have the communication protocol be one bit because you can have an additional state, keep track of the conversation far and just have one bit that says what you know. So then you just append the next bit of the conversation.
00:18:17.796 - 00:18:23.092, Speaker A: I'm not sure I follow. It's the only obvious communication game.
00:18:23.268 - 00:18:35.884, Speaker B: Communication graph with a protocol. I'll define a new graph where the vertices are originally original vertex and partial conversation.
00:18:36.824 - 00:18:43.244, Speaker A: So associated with a note there's no unique path you can reach it. There could be many paths to reach it.
00:18:44.424 - 00:19:08.648, Speaker B: Over on the other board, say you're given a PLS protocol. It has a set of vertices and a communication protocol on every vertex. So I'm going to define a new set of vertices that the pair original vertex, partial conversation of the protocol.
00:19:08.776 - 00:19:15.760, Speaker A: Yeah, it's true. You can, there's like normal forms for these things. So you can make definition for decision trees.
00:19:15.792 - 00:19:24.484, Speaker B: We should be able to do the same thing. And it's basically like you query, it's just going to be like querying at a vertex. What is the successor problem?
00:19:28.524 - 00:19:30.864, Speaker A: Yeah, so there are different normal forms.
00:19:33.364 - 00:19:34.724, Speaker B: A branching program.
00:19:34.844 - 00:19:52.344, Speaker A: Well, I want to avoid this branching program connection. This is a lot weaker model than a branching program. So we can prove lower bounds for resolution. We can't prove lower about branching program. That's a usual pitfall. So you shouldn't think of this as we start at the root. You follow a unique path and output this.
00:19:52.344 - 00:20:05.194, Speaker A: There are more guarantees for any node that's feasible. You can trace down to a leaf and find a solution which is a lot stronger than just the kind of canonical path yielding a solution.
00:20:11.014 - 00:20:17.594, Speaker B: I think the model is going to look a lot like a branching, maybe changing the goal.
00:20:18.354 - 00:20:19.298, Speaker A: Maybe, maybe.
00:20:19.386 - 00:20:23.014, Speaker C: I feel like Demetri did this because he's not.
00:20:24.514 - 00:20:58.344, Speaker A: Yeah, so there are different in the paper. I actually use a different normal form for these. But I like this conceptual approach that you just, you don't think anything. You just take a turing machine definition and replace circuits with protocols and decision trees. It's canonical. Okay, so it turns out that this simply captures resolution width. It's the same proof almost.
00:20:58.344 - 00:21:51.810, Speaker A: Maybe I won't give it in detail, but roughly as you could replace in this picture. You know, think of the. Instead of a circuit, I have a resolution proof I have at the leaves the constraints of my formula f, and clauses where resolution derives from two clauses, a third, it's logically sound. And you could derive one of these decision tree pls versions out of a resolution proof by just modifying your definition of feasible. Now you're feasible. If so, a clause in a previous feasible. If so, I'm now fixing an input.
00:21:51.810 - 00:22:26.374, Speaker A: There's only one input. Now this boolean assignment, if the clause is falsified in a resolution proof, the top clause is the contradictory clause. It's always feasible. And if two clauses imply a third, and this is falsified under a particular assignment, must be that one of its children are to decide feasibility. Well, to decide this condition, you need to query a number of bits of x determined by the width of the clause, roughly y. At least one direction of this immediately holds.
00:22:27.634 - 00:22:30.474, Speaker B: So is this a semantic resolution.
00:22:32.734 - 00:22:33.934, Speaker A: Equals syntactic?
00:22:34.014 - 00:22:35.394, Speaker B: Oh yeah, that's right, yeah.
00:22:37.574 - 00:23:52.122, Speaker A: Okay, so, as in all lifting theorems, we can hope to characterize the communication version of this search problem, the original search problem composed with a gadget. And the main theorem is that you do get an equality. But it's somewhat abstract in that if we want to end up with monotone circuit lower bounds so far, we can start with resolution lower bounds and get some lower bounds for these lifted search problems associated with unsatisfiable theory. But some creativity is sometimes needed to find at last a reduction from one of these types of problems to monotonic archive. Previous work has given some reductions. Okay, we give more. And in fact, this kind of XOR Sat or more generally CSAt function gives a kind of a simple framework where there's a, a uniform way in which you can start with an unsatisfiable CCSB.
00:23:52.122 - 00:24:29.002, Speaker A: So fix any set of constraints. If some ccs are hard to refute in resolution, you can run through this machinery and end up with a function which is basically generalization of x or Sat and get an exponential lower one, we lose something in the exponent because of the size of the gadgets we need to use constant size. Kadjs would maybe yield strictly exponential lower bounds. That's one open problem. So you get the law of the motor circuit. Size of f is the constant factor of the resolution. Is that right? Yeah.
00:24:29.002 - 00:24:56.084, Speaker A: Okay. So there are constants implicitly, but it's stable. Okay, so I think I'm almost out of time. I just want to mention one direction. Like, there was this PLS communication model. And I just think it's such an obvious question to ask. What happens for other TFNP subclasses? PlS is just one, and apparently nobody's asked this before, as far as I know.
00:24:56.084 - 00:25:36.484, Speaker A: So we thought about it a little bit, and here's what we know. So we have pls, which is circuits. Okay. There are other classes, something called continuous local search. At the very bottom, functional p, whose communication analog is deterministic protocols. You could say this captures formulas. That's the Karschma victors and characterization.
00:25:36.484 - 00:26:27.624, Speaker A: There are other classes, like the pigeonhole class nobody's really studied. We don't know how to prove explicit lower bounds for the communication analog of this, nor can we find any models of computation that would allow such a characterization. However, final punchline. There's a class called the parity argument, and for this class, we can find a model of computation that captures it. Does anybody have a guess for it? If you don't, haven't seen this before, what would be yay. So, I don't know. So this was 95, 80 something.
00:26:27.624 - 00:26:54.184, Speaker A: Why haven't people explored this characterization? You can also ask to separate classes. For example, our main theorem, if you interpret it in this language, Xorz. It's easy for span programs over gif two. It's sort of easy for the communication class, hard for PLS. That's what the theorem says. So it implies an exponential separation, dashed arrow meaning no inclusion. But very few of these separations are known.
00:26:54.184 - 00:27:20.504, Speaker A: So in query complexity, pretty much everything is understood, all the relative complexities. But in communication complexity, very little. Sometimes separating two classes is actually equivalent to separating the monotone versions of the associated models, like it is the case here. So that's a huge project. More characterizations and more separations. Okay, thank you.
00:27:27.244 - 00:27:52.080, Speaker C: I just want to make a comment. So, I don't know, founder, he could say that's better than me. There's like. So there's uniform versions of his persistence, like s one two is like pre resolution, and team one two, like that is resolution. And they have. Sam has these theorems that beautiful theorems that show, like, the privileged functions in the systems correspond to these circuit classes.
00:27:52.192 - 00:27:57.968, Speaker A: So there was no connection in query complexity somehow? What, in query complexity though?
00:27:58.136 - 00:28:10.454, Speaker C: No, but I'm saying it's very similar. You're doing not the connection, not the lifting theorem, but the connection that you're making. Some of them where there's the uniform version of them where it was known.
00:28:22.914 - 00:28:48.574, Speaker B: Well, there's certainly connections between t twelve and res log and pls. I don't know if it's exactly, precisely the equivalent. That's very close. I'm wondering how tight you can get the lower bound to be. Let's say you don't take all n cubed linear equation, but you take just a linear number that comes out of.
00:28:48.654 - 00:29:23.234, Speaker A: Yeah, that's how you optimize parameters. Yeah. But at the moment the lifting theorem is approved in such a sloppy manner that we lose a lot there already. I think the best record at the moment is cube root of n, where n is the number of input bits as a run ras and others. And we could maybe match that if we worked hard but prove our constant size gadget lifting. Any other questions? Let's thank me. Compared.

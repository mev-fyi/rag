00:00:00.160 - 00:00:25.794, Speaker A: Great for the talk. I'm actually going to spend about half the talk, depending on your background, either introducing or reminding you of some of the challenges in multi item mechanism design. And then in the second half I'll get to our results, which is a new duality framework to address these challenges. And the whole talk is going to be pretty light on proof details. If you happen to be around next week, I'm giving the whiteboard seminar where I'll give complete proofs of everything.
00:00:27.544 - 00:00:28.048, Speaker B: Okay.
00:00:28.096 - 00:01:12.124, Speaker A: Um, so we actually saw this model in both of the two previous talks, but let me remind you of it, uh, to be sure. So say you have just a single item that you're trying to sell to a single buyer and you don't know the buyer's valuation, but you do know that he comes from some population and you have good aggregate information about this population. So how do you sell your item? Well, you announce a menu. What's a menu? It has a list of options. Every option has a price and a corresponding probability. And then what happens is this buyer walks in your door, he has some value drawn from this population, and he selects whatever menu option, maximizes his expected utility. And his utility is just the value times the probability he gets the item minus the price he would have to pay.
00:01:12.124 - 00:01:57.074, Speaker A: Ok. And so your goal as the seller is to maximize your expected revenue. This is just in expectation over buyers walking in your door the amount that they will choose to pay you based on your menu. Ok, and Nicole already mentioned this, but the seminal result for this really simple model is due to Myerson and Riley and Zechauser, which shows that the optimal menu, even though it could in principle be randomized, doesn't need to use the randomization. So the only two options on the menu are you pay nothing and you get nothing, or you pay some price and you get the item with probability one. What's this price? It's literally just finding the optimal price. And so the revenue of setting any given price is that price times the probability that a buyer who walks in your door will choose to pay it.
00:01:57.074 - 00:02:22.416, Speaker A: Okay, so that setting is really simple. Let's generalize a little bit to one item in multiple bidders. How you should parse this is that there's many different bidders who are going to walk in your door at the same time. Maybe you know something about them and that's modeled as they come from different populations. So maybe you know that bidder one is a junior faculty somewhere. You're not sure that it's yang. Exactly.
00:02:22.416 - 00:02:57.286, Speaker A: And maybe you know that you know, the third bidder is definitely someone from Seattle, but you're not positive it's Nikhil. Okay, so what do you do when these buyers walk in? You announce a mechanism. A mechanism just takes as input a bid from every buyer. It selects a winner and it charges each bidder a price. Um, without loss of generality, you can restrict attention to what are called bayesian incentive compatible mechanisms. That just means that for every bidder, it's optimal for them to report their true value, conditioned on the other bidders also reporting their true values and. Okay, good.
00:02:57.286 - 00:03:16.414, Speaker A: So then what happens is buyers with values drawn from these populations walk in your door, they are incentivized to tell the truth. So they'll report their true values to your mechanism and. Right, and then you'll get some revenue, and your goal is, again, to maximize your expected revenue. So this is just an expectation over people walking in your door, the amount that they will choose to pay you.
00:03:17.754 - 00:03:18.210, Speaker B: Okay.
00:03:18.242 - 00:03:46.414, Speaker A: And the seminal result here is, again, due to Myerson's work from 81. And he showed that the optimal mechanism, even with many bidders, still has this simple format. Okay, so let me go over the general statement first. So he shows that there exists what he calls virtual transformations. So for each population, there's a different transformation. Phi. Phi takes as input the bidder's reported bid and maps it to what he calls a virtual bid.
00:03:47.114 - 00:03:47.546, Speaker B: Okay?
00:03:47.570 - 00:03:52.334, Speaker A: And then the winner of the auction is the bidder with the highest non negative virtual value.
00:03:53.394 - 00:03:53.826, Speaker B: Okay?
00:03:53.850 - 00:04:46.034, Speaker A: So we sometimes use this terminology. We say that the auction maximizes virtual welfare because if these virtual bids were the actual values of the bidders, we would be maximizing welfare, okay? So this is how it chooses the winner. The price that it charges is what's called the critical value, which is just the minimum bid that a buyer could make and still be the winner. Okay? In the special case that all of these populations happen to be the same and they happen to satisfy a technical condition called regularity. So I've written this here, but it's actually not important that you know it for this talk, then you can say something even stronger about the optimal mechanism. It's actually just the second price auction with reserve. So this is what you see if you go and buy anything on eBay, okay? And the reserve happens to be exactly the same price that you would set if you were just selling the apple to one bidder.
00:04:46.034 - 00:05:28.624, Speaker A: Okay? I also want to tell you about a different seminal result that maybe some of you are less familiar with due to bulow and klemperer. Informally what it says is that increased competition is better than market research. Okay, so let me, let's say that you have two choices. You can either keep the number of bidders fixed if they're all from the same population and this population is regular, you can learn the optimal reserve by doing market research. Or what you could do is you could just convince one extra bidder to show up to the auction and not do any research whatsoever about the market. And it turns out that it's always better to just convince one more person to show up to the market than to learn anything about it.
00:05:29.404 - 00:05:30.264, Speaker B: Okay?
00:05:31.644 - 00:05:56.256, Speaker A: Okay, so in summary, for one item, the situation is actually really nice. So we know that the optimal mechanism is simple, it's deterministic, it happens to satisfy a stronger notion of truthfulness called dominant strategy truthful. And this is even though it's competing with the best randomized bayesian truthful mechanism. Okay, so this is really nice. And we saw that it specialized to one bidder. It's really simple. It just sets a price.
00:05:56.256 - 00:06:32.256, Speaker A: For many IID regular bidders, it's a second price auction with reserves. So what we see on eBay all the time, and even in the most general setting, it still has this somewhat nice structure. Okay, so the point is that we have really nice results for single item settings. Okay, now let me jump into multi item settings and we're going to see basically exactly the opposite is true, that even in really simple multi item settings, the situation is a bit of a mess. Okay, so before I do that, let's be clear about the model. So it's the natural extension. As before, there's some population d over bidders who are going to walk in your door.
00:06:32.256 - 00:07:07.576, Speaker A: The only difference is they now have values for both the apple and the orange instead of just the apple. Okay, so how would you sell these to one bidder? It's still the same. You announce a menu, every option on the menu still has a price. It just now has a vector of probabilities. Instead of just the probability that you get the one item, a buyer with values is going to be drawn from this population and walk in your door, he's going to choose whatever menu option maximizes his expected utility. For this talk, the buyer's valuations are going to be additive. That just means that their value for a set of items sums their value for every item in that set.
00:07:07.576 - 00:07:57.554, Speaker A: So the utility can be written in this form. And again, your goal is just to maximize your expected revenue. So in expectation over people walking in your door, the amount of money they choose to pay. Okay, so let's first try and reason about why is this not a trivial problem? Okay, so we can maybe try to design the optimal mechanism for this instance by going through the following reasoning. Okay, so in this instance, Yang's values for both fruits are drawn independently and uniformly from the set one two. So we can try to reason first that while Yang's value for the apple actually doesn't change depending on whether or not he, he gets the orange, because his values are additive. And even if we knew Yang's value for the orange, that doesn't give us any information about the apple, because his values for the items are independent.
00:07:57.554 - 00:08:22.256, Speaker A: So there's no dependency whatsoever between the items from the buyer's point of view. So it seems like maybe we should just sell each item separately at the optimal price, which happens to be one. We'd make a revenue of one per item or two in total. And kind of the surprise is that actually there's something flawed about this reasoning, and this is not optimal. And there's something better you can do, which is you can bundle the fruits together and set a price of three.
00:08:22.440 - 00:08:22.816, Speaker B: Okay?
00:08:22.840 - 00:08:50.674, Speaker A: So by that, I mean you can tell Yang you can either pay three and get both the apple and the orange, or pay nothing and get nothing. With probability three, four, he will choose to do this. So you make revenue nine, four, which is better than two. Okay, so this is already a little bit surprising that you have to be clever at all. Let's see, things get even weirder if we change the example so that now Yang's value for the apple is drawn uniformly from the set one, three. In this example, we know that the unique optimal mechanism is randomized.
00:08:51.014 - 00:08:51.430, Speaker B: Okay?
00:08:51.462 - 00:09:06.234, Speaker A: So the unique optimal mechanism has this form. You have three options. The first is you get the apple and the orange, and you pay four. The second is you get the apple with probability one, the orange with probability one, two, and you pay two and a half. And the third is you get nothing and pay nothing.
00:09:08.254 - 00:09:08.734, Speaker B: Okay?
00:09:08.774 - 00:09:25.424, Speaker A: We also know that things get even weirder. So there exist correlated distributions over additive values for two items, such that the optimal randomized mechanism has infinite rev, gets infinite revenue. But the optimal deterministic mechanism gets revenue upper bounded by one.
00:09:25.764 - 00:09:26.260, Speaker B: Okay?
00:09:26.292 - 00:10:29.640, Speaker A: So restricting yourself to deterministic mechanisms could cost you an unbounded fraction of the optimal revenue. Okay, let's also revisit this comparison between market research and competition. And let's say I told you that you could either sell both fruits optimally to one bidder whose values are drawn from the population D, or you could recruit one extra bidder to show up, but then you had to run a second price auction on each item separately. Okay, so here again, it turns out that there are correlated distributions. It's the same one from the previous example, such that for any finite number of bidders, it is better to just run the optimal mechanism with one bidder than it is to recruit any number of additional bidders. So if you get everyone in the world to show up to your auction, it's still better to just learn the market and sell your two fruits to only one person, even if you're willing to make some strong assumptions about the population. So maybe that it's a product distribution and all the marginals are iid.
00:10:29.640 - 00:11:11.684, Speaker A: It could still be the case that the optimal mechanism for one bidder is better than a second price auction for each item separately for many additional bidders. Okay, the last phenomenon I want to talk about is called non monotonicity. So let's say I told you you could sell your two fruits to one of two populations, either f by f or f by f. And I told you that f plus stochastically dominated f, ok? Now if you were only selling one fruit, it would be really clear that it's better to sell your one fruit to f plus instead of f. Because for whatever price you're thinking about setting, it is more likely to sell to the market f than f. Okay? So you will definitely get more revenue.
00:11:12.104 - 00:11:12.544, Speaker B: Okay.
00:11:12.584 - 00:11:54.644, Speaker A: But we can ask, what if there's two items and it's f by f versus f plus by f plus? And it turns out that sometimes you can get more revenue from this strictly worse distribution than the better one. Okay, so what this means is that, right, this should be somewhat surprising to you, right, that even though everyone in the market f by f likes both fruits better than their counterpart in f by f, you might make less revenue by selling it to this strictly better market. Okay, so just to summarize, what we saw for multiple items is that the optimal mechanism could be randomized and that the best randomized mechanism could be infinitely better than the best deterministic one.
00:11:55.024 - 00:11:55.480, Speaker B: Okay?
00:11:55.512 - 00:12:14.484, Speaker A: We saw that market research could be better than extra bidders even when the values are iid. We saw that you have this weird non monotonicity phenomenon. And I didn't give an example for this, but we also know now that the best bayesian incentive compatible mechanism is actually strictly better than the best dominant strategy truthful mechanism.
00:12:14.644 - 00:12:15.012, Speaker B: Okay?
00:12:15.028 - 00:13:05.750, Speaker A: So the solution concept matters. Okay, so the point of this is just to convince you there's a lot of interesting stuff already going on, just with even just with one bidder and two items. Okay, so now with that, let me just take a sideline and say, like, what drives all of these nice single item results that we have? And in my opinion, what's driving all of them is that Meyerson Seminole paper was a lot more than just designing the optimal mechanism for one setting. He proved this really nice theorem that says for any bayesian truthful mechanism, its revenue is upper bounded by itself virtual welfare. Okay, so what does this mean? This means, formally, that the expected revenue that any truthful mechanism obtains is upper bounded by the expected virtual welfare of the winner.
00:13:05.902 - 00:13:06.246, Speaker B: Okay.
00:13:06.270 - 00:13:13.754, Speaker A: I didn't define this virtual welfare function for you, but just for however it's defined, this is what the theorem says.
00:13:14.694 - 00:13:15.150, Speaker B: Okay.
00:13:15.182 - 00:13:26.414, Speaker A: Just to help give you a little bit of intuition for what this right hand side is, it's clearly optimized if I use the allocation rule that just finds the bidder with the highest non negative virtual value and gives them the item.
00:13:28.234 - 00:13:28.690, Speaker B: Okay.
00:13:28.722 - 00:13:43.894, Speaker A: And it turns out that this is just an extremely useful bound. It happens to be exactly attainable by Myerson's mechanism. This bound is exactly what enables the bulow clamper result, and it drives essentially every single item result in bayesian settings.
00:13:44.214 - 00:13:44.582, Speaker B: Okay.
00:13:44.598 - 00:13:50.874, Speaker A: And apparently, it even drives results that, you know, like Nicole's talk, that have nothing to do with mechanism design as well.
00:13:51.534 - 00:13:51.966, Speaker B: Okay.
00:13:51.990 - 00:14:12.394, Speaker A: And so I just want to point out, it's not the case that once you know Meyerson's theorem, it's trivial to prove anything you want about single item settings. But the point is that once you know Meyerson's theorem, you at least have some place to start, and then you can do interesting work to prove interesting things. But I do think that without Myerson's theorem, there's just not a good starting place to even address any results like these.
00:14:13.934 - 00:14:14.350, Speaker B: Okay.
00:14:14.382 - 00:14:21.954, Speaker A: And so the comparison to multi item settings, is it the comparable bound for multi item settings? We just don't have one yet.
00:14:22.374 - 00:14:22.782, Speaker B: Okay.
00:14:22.798 - 00:15:09.524, Speaker A: And there's an asterisk, because I'm about to contradict this for some special cases on the next slides. But in general, we don't have a general Myerson type theorem. Okay, so what. Where do we have bounds that are useful? So, the first example is started from a seminal paper of Chala, Hartline and Kleinberg, and together with follow up work of Chala, Hartline, Malik, and Zivan, they showed that for a single unit demand buyer whose values for the items are drawn independently, that item pricing gets you a four approximation. Okay, so what is unit demand? It's very similar to additive, but just instead of summing your values for each item, when you get a set of items, you take your favorite one instead. And item pricing is exactly what it sounds like. You just post a price on each item separately and the buyer takes whatever they want.
00:15:09.524 - 00:15:50.772, Speaker A: Okay, so what's the main tool? I'm just going to say like two sentences about it. So they consider a related single item setting. So basically they take the same input and they think of the items as being bidders instead of being as different items. And now when you think of a one item many bidder setting, you can use classical Myerson theory to get upper bounds. And miraculously, what they're able to show is that upper bounds in this related setting give you useful upper bounds in the original setting. Okay, so this approach was successfully used in a lot of follow up works, but I still want to offer a critique, which is that even though this tool is clearly extremely useful, it's inherently limited to unit demand bidders. Okay.
00:15:50.772 - 00:16:20.504, Speaker A: And so to date we haven't been able to use this approach and extend it beyond unit demand setting. Okay, so there's a second line of papers where we do know quite a lot, and that started from a seminal work of, I would call it seminal now of hard and Nissan, where they showed that for a single additive buyer and values for items are drawn independently, that the better of selling separately and selling together gets you six approximation.
00:16:21.484 - 00:16:22.012, Speaker B: Okay.
00:16:22.068 - 00:16:50.434, Speaker A: And so these terms probably mean what they sound like again. So selling separately just means you set the optimal price on each item as if it was the only item. You let the buyer take whatever subset they want. And Brev means bundled together, you just take all the items as one, you put a price on it, the buyer can take everything or nothing. Ok. And the main tool, I can't say anything really intelligent about this, it's just a direct upper bound. Using probabilistic tools, we now call it the core tail decomposition.
00:16:50.434 - 00:17:12.814, Speaker A: It has been successfully used in follow up works beyond the single additive bidder setting. I still want to offer a critique of this. So again, it's clearly an extremely useful tool, but really this decomposition was tailored to work well for a single additive bidder. And even though we've been able to use it for settings beyond that, it's very tricky to use exactly this decomposition correctly.
00:17:13.514 - 00:17:14.374, Speaker B: Okay.
00:17:16.034 - 00:17:18.334, Speaker A: Okay, so that's everything I was going to say. Yeah.
00:17:18.834 - 00:17:28.400, Speaker C: Since you seem to be wrapping up your literature review of techniques, where does the hug pana heart line paper on second degree price discrimination.
00:17:28.472 - 00:18:09.516, Speaker A: Okay, good. So I think, okay, so there's a missing related work slide that I realized when I saw other talks related work slides that I should have included. So what is missing is a discussion of other duality approaches to mechanism design. So there is work by Costas Allen Deckelbaum and Christos Samos. Theres another one by Elias Kotzupias and Gianna Capullos, I think. And then theres work of Jason and Nima. And so I would describe, so all three of these approaches I would describe as they get really, really clean characterizations again for special cases.
00:18:09.516 - 00:18:39.134, Speaker A: So, like Jason and Nima's approach, again is very specialized to the unit demand setting. And the other two duality frameworks are specialized to the single additive bidder setting. So I would say what is unique about our approach is that while we don't get as strong results in specialized cases, it applies much more generally than just one bidder. And it's, as far as I know, the only one where we can prove approximation results as well. Is that a. Okay. Yeah.
00:18:39.134 - 00:19:00.182, Speaker A: Okay, good. Okay, so now I'm going to get into our work and. Okay, so the takeaway from the previous slides and including this missing related work slide is that we have really great tools already. The problem is just that they're tailored to specific settings.
00:19:00.358 - 00:19:00.814, Speaker B: Okay.
00:19:00.854 - 00:20:01.554, Speaker A: So while we have been able to get some results beyond what we already know, it's really hard to, to do this properly. Okay, so the main result of this paper, this is with Yang and Nikhil I would describe as being a unified duality approach for Bayesian mechanism design. So specifically, one thing we're able to do is we're able to rederive the unit demand bound from Chalo, heartline, Kleinberg and the follow ups via LP duality. And then the cool thing is we're able to show that this same exact dual, when you specialize it to the single item setting, you get back Myerson's upper bound, and the same exact dual, when you poured it to the additive bidder setting, gives you the bound that was used in these works of hard and Nissan in follow up work. Ok, so while these three approaches used to be very different, we now understand them a lot better. They come from exactly the same duality approach. Ok, I just want to point out quickly, the approach does apply more generally, for instance, to settings like these, but I'm not going to talk about them in this talk.
00:20:01.554 - 00:20:36.154, Speaker A: I'm just going to restrict attention to the additive bidder. Ok, so what am I going to do in the rest of the talk. So I'll just try and briefly show you where duality comes from. So like I said, I'm going to be really light on proof details, but I'll just try and show you why duality comes into the picture at all. I'll try and show you what the dual solutions look like, and then I'll just state some recent applications of this approach that are outside this paper. Ok, so just to keep the talk a little bit simple, let's assume that the population has finite support. This is just so that I can use, you know, like LP duality instead of continuous LP duality for simplicity.
00:20:36.154 - 00:20:46.990, Speaker A: Okay, so where does duality come from? It comes from LP duality. So what I would like to do on this slide is show you an LP that finds the optimal mechanism.
00:20:47.142 - 00:20:47.502, Speaker B: Okay?
00:20:47.518 - 00:21:52.654, Speaker A: So I'm not going to worry about solving this LP in poly time, but I just want to show you that you can, if you can solve it, find the optimal mechanism. Okay, so what does, what variables does the LP have? So it has a variable for every possible bid profile, and then it stores for every bidder I in item j, the probability the bidder I gets item j on this bid profile. I'm going to also just introduce these helper variables, PI of vi. So this is just going to be for every bidder I for every item j if bidder I chooses to report vi, what is the probability, an expectation over the MEC, the mechanism, and in the other bidder's evaluations that they receive, item j and p of vi is going to store for every bitter I and every vector. They might report the price paid by this bidder when they report this type in expectation over the same randomness. Okay, so if these variables aren't clear, they might become clearer through the constraints. Okay, so what constraints does a truthful mechanism need to satisfy? So first it has to be truthful.
00:21:52.654 - 00:22:30.442, Speaker A: What does that mean? It means that for any bidder. So it means that for any bidder, for any true valuation vector, they should prefer to tell the truth than to tell any lie. Okay, so the left hand side of this is just exactly computing the utility of a bidder with valuation vector vi for telling the truth. And this is computing their expected utility for telling the lie vi prime. We also need to guarantee that the mechanism is feasible in the sense that it never allocates any item more than once on any bit profile. This is really easy. It's just making sure that some probabilities sum up to at most one, and then we just need to guarantee that these helper variables are computed correctly.
00:22:30.442 - 00:22:35.054, Speaker A: So if you didn't follow the definition up here, this is another way to define the helper variables.
00:22:36.594 - 00:22:37.010, Speaker B: Okay?
00:22:37.042 - 00:22:53.254, Speaker A: And then over all truthful and feasible mechanisms, we want to find the one that maximizes the expected revenue. And this is just a linear function that does that. It sums over every bidder over every type. The probability that the bidder has this valuation vector times the price they would pay, condition on that.
00:22:54.994 - 00:22:55.434, Speaker B: Okay.
00:22:55.474 - 00:23:10.254, Speaker A: Whoops, sorry. Okay, so what I want to point out is that we saw from the previous examples that the solution to this LP could be really messy and counterintuitive. Right? And I want to claim that the only reason that happens is because of these truthfulness constraints.
00:23:11.034 - 00:23:11.498, Speaker B: Okay?
00:23:11.546 - 00:23:35.908, Speaker A: So let's do a quick sanity check. So if we didn't have these truthfulness constraints, so if I just remove them and I said I still want to solve this LP, then this is really easy to do, right? So that's because the price variables actually don't show up in any of the other constraints. So I can just pick one and set it to plus infinity. And now I've solved the LP. Okay, I want to claim actually something even a little bit stronger. Oh, sorry. This is what I just.
00:23:35.908 - 00:24:23.214, Speaker A: Excuse me, what I just said out loud, that actually would be easy to optimize any linear function. Okay, and so why is that? So clearly, if any of these multipliers for the price variables is non zero, then I can just set the corresponding price to either plus or minus infinity. And if all of these multipliers happen to be zero, then I claim that this optimization is also easy. Okay, so why is this is because the only constraints I have on the x I j's is that for every bit profile, the probability that item j is allocated should sum up to at most one. So if I want to maximize a linear function of the x I j's, I should just, on every bit profile, find the bidder with the highest multiplier for item j that's non negative and give that person the item.
00:24:24.514 - 00:24:25.194, Speaker B: Okay.
00:24:25.314 - 00:24:40.614, Speaker A: Whoops. Okay, so that's what I just said out loud. This is in text. Okay, so what's the point? The point is that the truthfulness constraints are the only annoying, it's the only annoying part of this LP. And what we should do to get better intuition is we should move them to the objective with lagrangian multipliers.
00:24:41.094 - 00:24:41.526, Speaker B: Okay?
00:24:41.550 - 00:25:10.586, Speaker A: So if you're not comfortable with lagrangian multipliers, the only thing you need to know for this talk is that if I give you a set of non zero lagrangian multipliers for each of these constraints and move them to the objective, then any set of non zero multipliers gives you an upper bound on how good the solution to this LP can be. Okay, so now, okay, so now let's see, what do the dual solutions look like? Okay, so I've drawn this picture. Let me just tell you what's in this picture first, before telling you how it relates to the multipliers.
00:25:10.650 - 00:25:12.894, Speaker C: Don't the Lagrange multipliers have to be non negative?
00:25:13.314 - 00:25:33.008, Speaker A: Correct? I think I. Yes, sorry, sorry, non negative, yes, that was just a typo. I might have written non zero elsewhere where I mean non negative. I never mean non zero, I always mean non negative. Yeah. Ok, so what's in this picture? I've drawn these. So for all bidder's eye, I want to draw a picture that looks like this.
00:25:33.008 - 00:26:19.504, Speaker A: There's going to be a source in a sink, and I want to draw also a node for every possible evaluation vector that bit. Or I might have to make this picture manageable. I've only drawn two, ok, and now I've drawn edges between different nodes, and I've put some labels on them. Ok, so these red edges that I've drawn correspond to the lagrangian multipliers for the truthfulness constraints. So what I mean by that is, whatever lagrangian multipliers you wanted to use, I want you to write them on these edges, so you'll remember that there was a truthfulness constraint saying that bitter I with type vi one did not want to lie and say vi two. Instead, whatever multiplier you have for that constraint, I want you to put that on the edge from vi one to vi two. Okay, these black edges are fixed.
00:26:19.504 - 00:27:00.194, Speaker A: So when you draw this picture, the black edges do not depend on the choice of lagrangian multipliers, and the green edges you can set arbitrarily, but non negative. Yeah. Okay, so lemma that we're able to show, and I'm not gonna prove this, this is really just algebraic manipulation, is that a set of lagrangian multipliers for this lp happen to yield a finite upper bound if and only if. When you draw the above picture, you get a flow. Okay, so what I mean by that is if, when you draw this picture, every interior node has flow in equal to flow out, and all of the edge weights are non negative.
00:27:02.494 - 00:27:02.982, Speaker B: Okay?
00:27:03.038 - 00:27:49.614, Speaker A: And the intuition is just that it turns out that if this picture is a flow if and only if the coefficient for all the price variables in the lagrangian objective happens to be zero. Ok, so it's fine if you don't completely understand what's going on, but I just wanted to give you some intuition as to what the dual solutions look like. Okay, so now I told you how to get a finite upper bound. Let's see what the upper bound actually looks like. So it has a statement of the following form, which is that for any truthful mechanism, the revenue you get from that mechanism is upper bounded by that mechanism's expected virtual welfare. So let me parse what this is and connect it to virtual welfare. Okay, so I'll define this variable phij of Vi.
00:27:49.614 - 00:28:35.302, Speaker A: It's defined according to this formula. And now what is this summing? This is just summing over every profile, over every agent and every item. Their virtual value for that item times the probability that they get it on this profile. Okay, it's not important that you remember even parse this definition. All I want you to take away from it is that it does depend on the lagrangian multipliers. So, different settings of lagrangian multipliers give you different virtual transformations, which give you different upper bounds on how good the revenue can be. And the other thing, if you're familiar with Myerson's virtual values, or if you remember the definition of regularity from earlier in the slide or earlier in the talk, you'll just notice some similarity between this form and that form.
00:28:35.302 - 00:28:37.434, Speaker A: But I don't want to get into more detail about that.
00:28:38.834 - 00:28:39.458, Speaker B: Okay.
00:28:39.546 - 00:29:32.700, Speaker A: Um, so again, just to go over, the interpretation in text is that every valuation vector has a virtual value for every item. It's according to this formula, which depends on the lagrangian multipliers, the revenue of any truthful mechanism is upper bounded by its virtual welfare. And again, just to give you intuition for this right hand side, it's maximized when you give item j to the highest non negative virtual value for item j on every bid profile. Okay, and so this is the last slide I have about this result. So just to remind you. So, one thing we do in the paper is we find a specific flow such that when you take the corresponding virtual values in the unit in the single item setting, you get back Myerson's virtual values. When you port the same flow into the unit demand setting, you get exactly the bound used by Chalo, Hartline, Kleinberg.
00:29:32.700 - 00:29:55.448, Speaker A: And when you take this same flow into the additive bidder setting, you get the bound used by hardenessan okay, so this is the last slide I have. Okay. So in this paper, we actually didn't really prove any new results. Right. So the point of the paper was to understand much better a lot of results that were important from the past ten years or so.
00:29:55.576 - 00:29:55.912, Speaker B: Okay.
00:29:55.928 - 00:30:22.946, Speaker A: So personally, I think that was a worthwhile use of our time, but you might think that this is really only worthwhile to do if it lets you prove something new in the future. Ok, so this slide is mostly just to convince you that we were able to use this approach to prove something new. Maybe I won't read each of these three in detail. This is the last slide, so I'll leave it up. But I just want to point out that the point is that all three of these directions were places that we didn't have a starting point previously.
00:30:23.090 - 00:30:23.426, Speaker B: Okay.
00:30:23.450 - 00:30:38.334, Speaker A: So what this duality framework provides us is a starting point. And from this starting point we can then use domain specific techniques to get each of these three results. So that's everything I have. Thanks a lot for listening.
00:30:46.914 - 00:30:52.454, Speaker D: Does ironing under the picture at some point you see where you recover, Myerson?
00:30:52.554 - 00:31:03.314, Speaker A: Yeah. So yeah, the answer is just yes. I don't know that I can give a better explanation online, but.
00:31:06.894 - 00:31:10.674, Speaker D: The best thing to do is to give it to the bidder with the highest virtual value.
00:31:11.254 - 00:31:32.454, Speaker A: So. Right, so basically here when I'm saying virtual values, I really mean iron virtual value. So like, I tried to, maybe I was too subtle. I tried to include the bar when I was talking about Myers and virtual values earlier. I guess I could have put a bar here too. But does that make sense? Like here when I say virtual values, you should read iron virtual values if you know what that means.
00:31:33.114 - 00:31:34.734, Speaker D: And so these will be non negative.
00:31:35.194 - 00:31:57.674, Speaker A: These will the fees. No, they will happen to be. No, it's not the case that for any flow they are non decreasing. For the one we come up with, they will happen to always be non decreasing. Yeah.
00:32:00.334 - 00:32:06.674, Speaker E: Is it correct to say that the Lagrange multipliers give you some sort of relaxed truthfulness condition?
00:32:07.254 - 00:32:35.956, Speaker A: Yes. So one way to think of it is that if you restrict attention, okay, so some lagrangian multipliers are going to be zero. Some are going to be strictly positive. The ones that have a. What is it? The ones that have a multiplier of zero is basically as if they were dropped completely. So another thing we learn is for this specific flow, it doesn't actually set. Many of the lagrangian multipliers are zero.
00:32:35.956 - 00:32:49.240, Speaker A: So we learned something else, which is that actually all of these upper bounds, we didn't even need all of the truthfulness constraints in the first place. It was enough to consider a relaxed truthfulness condition, and that would still give an upper bound that can be targeted by these mechanisms.
00:32:49.312 - 00:32:54.284, Speaker E: Can you say something about for the flow that you compute, which Lagrange multipliers do you choose?
00:32:54.664 - 00:33:20.674, Speaker A: Yeah. So the only non zero multipliers are ones for where bidder with valuation. Vi does not want to lie by under reporting their value for their favorite item by the minimal amount possible. Those are. So for every bidder, there is one lie that we make sure they don't want to tell. And it's exactly that lie. And those are the only ones you need to get any of these upper bounds.
00:33:25.174 - 00:33:29.404, Speaker F: Do we know what distribution for which this inequality is actually tight?
00:33:29.824 - 00:33:30.688, Speaker A: Which inequality?
00:33:30.736 - 00:33:32.884, Speaker F: The upper bound inequality, like.
00:33:34.664 - 00:33:39.528, Speaker A: One on this slide or one on the previous? Which one?
00:33:39.656 - 00:33:46.004, Speaker F: So if the inequality is tight is equality, does that basically mean that you don't need irony?
00:33:48.544 - 00:34:06.494, Speaker A: No. So, yeah, okay. Okay. So I think it was hard to use good terminology that was not overburdensome for non experts and intelligible for experts. So you should interpret this as already having been ironed. So does that make sense?
00:34:07.354 - 00:34:14.534, Speaker F: Do we know anything similar to regular? I think that's for which we don't need irony. And still.
00:34:16.394 - 00:34:45.524, Speaker A: I guess I'm just pushing back that it's subject to me using poor language. I don't think it's a well defined question, because we don't have a defined flow. Like our flow is defined already having ironed. So it's not like there's a natural. Does that make sense? Like, it's not like, oh, there's a natural virtual value that you have to iron. There's just one virtual value that you really should think of as being an iron virtual value. But I just dropped the iron because I didn't want to use too many words.
00:34:46.344 - 00:34:53.380, Speaker G: Can I interject part of that? So this inequality always holds for any flow.
00:34:53.492 - 00:34:54.068, Speaker A: Correct.
00:34:54.196 - 00:35:06.064, Speaker G: But in order to get optimality, you need to find a mechanism where you get equality. And for that, only ironing property works. So that's kind of the correct.
00:35:08.004 - 00:35:10.604, Speaker A: If that didn't answer, I'm happy to just tell you more. Yeah.

00:00:00.560 - 00:00:01.300, Speaker A: Okay.
00:00:01.974 - 00:00:02.566, Speaker B: Hi, everyone.
00:00:02.630 - 00:00:54.198, Speaker A: Can you hear me? I say good morning. Good morning to people in California, in any case, and good evening to Michal. And I'd like to welcome Michal today, who's our theoretically speaking speaker, and she's going to talk on market design and through the lens of approximation. Let me tell you a few words about Michal, and then I will tell you sort of how we're going to handle questions and answers in so our distinguished speaker is Michal Felt. She is the computation and economics professor of computer science at the Blavatnik School of Computer Science at Bellevue University, also at Microsoft Research at studio. And especially a warm note for us. She went on to be a postdoc in two years.
00:00:54.198 - 00:02:02.842, Speaker A: So she's our very own and health research sponsor, economics, game theory, options of racial research, and she studies and analyzes algorithms and auctions, markets, networks under the sort of lens of economics, if I understand correctly, with emphasis, of course, on efficiency, robustness, fairness, which you'll tell us about today. And what else I want to say. I want to say that Michal has gotten lots of best paper awards from several conferences, in particular from on computation and economics, and she is a member of the Young Academy of Science in Israel. She's the recipient of ERC grants of fellowships of various kinds, and she is an editor in many places. And she's also listed on the list of the 50 most women in Israel and in the marker under a certain age. And in general, she's a wonderful speaker. I welcome her, and we should all welcome her.
00:02:02.898 - 00:02:03.674, Speaker B: First of all, I'm going to do.
00:02:03.714 - 00:02:56.754, Speaker A: The claps because we are on a zoom. In addition to that, I want to say how you can post questions. So there are two ways to do this, that is take questions at the end or throughout. And I think that Michal is going to welcome both modes of questioning and formally speaking, I think the way you do this, as you type your questions in the Q and A at the bottom of the control panel, and then Michal can look at them. And I guess one more thing is about this series. So, as you know, the Simons Institute was put in place by a generous donation by Jim Simons 2012. And we had this series running for quite a while, which is, theoretically speaking, it's open to the wide public and teaches us interesting trends in computation and related fields.
00:02:56.754 - 00:03:06.914, Speaker A: So the truth is, the series that I like the most and I learned from the most. So I'm really curious to hear what Michal has to say. Welcome, Michal, and take it from here.
00:03:08.174 - 00:03:38.894, Speaker B: Thank you very much. Afi. Let me just try to share my screen. Can you see my slides? Excellent. Okay, so thank you, Shafi, for the kind introduction. Thank you for inviting me. It's always such a pleasure to be in Berkeley, even if only virtually.
00:03:38.894 - 00:04:23.914, Speaker B: I'm speaking to you from Israel. So it's night time here. And as I said, being in Berkeley has this effect on me that it always, like a time machine, takes me 20 years back to the happy times of my PhD studies. So whenever I'm here, I feel like a student again, which is a great feeling. So thanks for the opportunity. I'm going to talk about market design through the lens of approximation, and I must tell you, I really hate it that I can see your faces. I tried to ask for a regular zoom session, but I understood that due to security concerns, it was not possible.
00:04:23.914 - 00:04:43.706, Speaker B: So please do ask question. I hope that I'll be able. Wait, let me just make sure I can see. Oh, for some reason, I cannot see the screen with the q and A. Okay, only one q and a here.
00:04:43.730 - 00:04:48.734, Speaker A: That and which reports noise, which I think was when I was speaking, there was some paper rustling.
00:04:49.754 - 00:04:54.894, Speaker B: Okay, so. Okay, hopefully I'll be able to do that.
00:04:56.634 - 00:04:58.654, Speaker A: Sorry, Michal, you don't see the Q and A?
00:04:59.394 - 00:05:09.908, Speaker B: Okay, let me see now. Okay, now I see noise. Good. Okay, excellent. So I can see that. Great. Yeah, it was just at the top of the screen.
00:05:09.908 - 00:06:17.430, Speaker B: And it's always nice also to give talks to, as I understand this series to wide audience. And I understand that it may even include high school students, which is also heartwarming. So welcome, everyone, and thank you very much for coming to the talk, and I hope you'll take something from this talk. Okay, so let me start with this figure. So, in the end of the last century, the Internet has emerged into our lives with many new and exciting applications and markets. Pretty much every transaction we care about, socially or economically, moved to the Internet. The Internet became a huge computational platform for many new markets and applications, like Adword auctions, and voting and spectrum auctions, and routing and social networks and cloud computing.
00:06:17.430 - 00:07:01.740, Speaker B: And everything. Everything is moved to the Internet. And as a result of this entity, something very interesting happened. These disciplines, computer science and economics. And when I say economics, I mean economics. Endgame theory, which have evolved totally independently until that point along disjoint paths started to merge and exchange ideas between them, and this exchange of ideas flowing both directions. On the one hand, computer science applications that we really care about require economic and game theoretic reasoning.
00:07:01.740 - 00:08:05.882, Speaker B: For example, in computer science, traditionally we just assume that we write protocols, we write algorithms, and our users are obedient. They'll just do whatever we tell them. So if, for example, we do congestion control in the Internet and we run TCP IP, we just assume that everybody will run the beautiful protocol we have written. And suddenly we are faced with this completely decentralized entity, the Internet, which is owned and used by many users with competing interest, and everybody is doing whatever is best for hair. And we had to adopt the strategic behavioral model so our users are not obedient. And sometimes in computer science, we also assume that maybe the users are adversarial, but suddenly we are faced with entities that are not obedient and not adversarial. They'll just do whatever is best for them, whatever is in their best interest.
00:08:05.882 - 00:09:05.280, Speaker B: And this is. In this sense, computer science had to adopt the behavioral model and the language of economics and game theory, talking about strategic behavior, incentives and so on and so forth. And in the other direction. Suddenly economists add these huge markets that are run on a computational platform on the Internet, and many considerations they were not used to care about. They suddenly had to worry about computational complexity, communication complexity, algorithms, approximation, and this language started to infiltrate their area. And, okay, so here is the theme of this talk. So I think whenever we think about computer science and economics, I think the image we have.
00:09:05.280 - 00:10:01.134, Speaker B: So if you, if you, you know, you walk into someone and ask, what's the image you have when you think about computer science? I think they'll tell you this binary world, zero, one bits, everything is binary. Everything is dichotomous, like the opening figure that, the nice opening figure we had here, it was full of zero, one. This is what computer science is in people's minds. And in contrast, economics is about this continuous world where you have these curves, etcetera. And the thing that I'm going to talk about in this talk today is I want to argue that it's exactly the opposite. I want to argue that traditionally, economics emphasized exact and optimal solutions. So usually when you read economics paper, you read about optimal solutions, exact solutions.
00:10:01.134 - 00:10:55.234, Speaker B: And in contrast, computer scientists always look into the world through the lens of approximation. So maybe we should say computer scientists are compromisers. And I want you to remember this image in mind as I move on, and we'll get back to it, and we'll try to understand the roots of this theme. But let me digress a bit, and before I start and go to this computer science versus economics, let me give you a quick, really brief introduction to the theory of games and economic behavior. What is a game? So, a game is a mathematical model of some real life scenario. Almost every real life scenario you can think about can be modeled as a game. In every game, we have a set of players, and each player has a set of strategies from which she chooses.
00:10:55.234 - 00:11:40.194, Speaker B: So, for example, maybe we are the players today, and each one of us needs to decide whether to arrive to attend the talk or not. Okay? And each player gets some payoff depending on the chosen strategy. So maybe I decided whether I attend the talk or not, and Shafi decided whether she comes. And other participants, each one of you, decide whether to come. And for every strategy profile, meaning everyone decides what their strategy is, each one of us gets a payoff. So maybe, you know, maybe if I don't show up today, your payoff will be pretty low because I'm the speaker. But maybe if someone else doesn't show up, it's not that bad.
00:11:40.194 - 00:12:11.594, Speaker B: And we have a table of payoffs for every strategy profile. And the crucial thing is that every player acts to maximize her individual payoff. Everyone. And this is the assumption that I'm going to carry over throughout this talk. This is not always true. We all know that we have some fairness considerations and some of us are altruistic. But let's just play along with this assumption that everybody asks to maximize their individual payoff.
00:12:11.594 - 00:12:41.054, Speaker B: So here is a classical game that many, I assume some of you have heard of this. It's called prisoner's dilemma. In this game, we have two players. We have the role player. So he's choosing between cooperating and defecting. And we have the column player that is also choosing between cooperating and defecting. And inside every cell, for every strategy profile, we see the payoff of the role player.
00:12:41.054 - 00:13:20.984, Speaker B: And. Hold on, player. So the game behind this game is we have two guys who have, were charged for a crime that entails five years in prison, say, but we don't have enough evidence to put them in to convict them. So we put them in two separate rooms and we ask them whether they cooperate or defect. And if they both cooperate, then we don't have enough evidence, and they both serve one year in jail. Okay? So we see that the payoff of the role player is negative one. This means that he serves one year in jail, and the payoff of the other one is also negative one.
00:13:20.984 - 00:14:06.484, Speaker B: If they both defect on each other, then, meaning they talk, they say, yeah, we did it. Then they both serve three years in jail. And the interesting thing is that if one of them cooperates, let's say the column player cooperates, but the role player defects. So we are in this cell. Then the role player goes free, he becomes a state witness, and the cooperator serves all five years in jail. Okay, so this is the game. So now we've completely described the game, and the question is, what should you do if you are one of these prisoners? And it's called a dilemma, but really, solving this game is pretty easy.
00:14:06.484 - 00:14:35.904, Speaker B: And I want to claim that in this game, defect is a dominant strategy. What's a dominant strategy? A dominant strategy is a strategy that is best for you regardless of what other players are doing. Okay, so this game is completely symmetric. Let me take the role player and let me describe to you his reasoning. So if the column player cooperates, then I say, okay, if I cooperate, I serve one ear in jail. If I defect, I go free. Of course I want to go free, so I defect.
00:14:35.904 - 00:14:57.204, Speaker B: If my friend defects, then if I cooperate, I serve five years in jail. If I defect, I serve three years in jail. Again, I want to defect. So no matter what the column player is doing, I want to defect. So I have a dominant strategy in this game. Let's look at another game. Let's call it election game.
00:14:57.204 - 00:15:58.770, Speaker B: And let's assume the population is distributed uniformly along this, say, zero, one interval. And we have our players now are the two parties, right and left parties, and they have to decide where they place themselves, okay? When they sell themselves to the, you know, to the citizens. And the assumption is that every citizen, let's say someone who is located right here, will just vote to the party that is closest to them. Okay? So a guy here would vote right, a guy here would vote left, because left is closer to them. And in this game, it's not very difficult to say that there is no dominant strategy. The best strategy for each party really heavily depends on the choice of the other player. The objective, of course, is to attract as many citizens of the population to vote for you.
00:15:58.770 - 00:16:48.892, Speaker B: And really depending on what the other party is doing, you want to move right or left. So how do we reason about such a situation? And luckily, Nash, John Nash came to our rescue, and he introduced this very beautiful notion of an equilibrium, which is just a stable outcome. What does it mean? It's an outcome. It's a strategy profile such that no individual player can gain a higher payoff by deviating unilaterally to another strategy. Okay, so we are located in some strategy profile. Each one of us decides on the strategy, and no one can improve her situation by deviating to another place, to another strategy. And.
00:16:48.892 - 00:17:25.233, Speaker B: Okay, this is a very nice definition, but, you know, definitions are cheap. Let's do what we can do with this definition to. The claim to fame of Nash is that in 1951, he proved that every finite game has a Nash equilibrium. Okay? And by the way, we may need to use randomization. Not every game has a Nash equilibrium. In pure strategy, maybe we need randomization, but every finite game has a Nash equilibrium. This is really a beautiful theorem showing the generality of this notion.
00:17:25.233 - 00:17:50.449, Speaker B: So, let's analyze these games. So, prisoner's dilemma is easy. We have dominant strategies. So, of course, if every player is doing their dominant strategy, this must be a Nash equilibrium. Right? Because no matter what the other player is doing, that's what's best for us. And let's look at this game. This profile is not an equilibrium profile.
00:17:50.449 - 00:18:42.440, Speaker B: Why? Because the left party here is attracting really not so many people, not so many voters. And if the left party moves a little bit to the right, it will attract more and more voters from the middle. And it's not very difficult to see that the only equilibrium in this game is where the two parties are essentially identical. Both of them are located exactly in the middle, and each one of them is attracting exactly half of of the population. Okay? So this is an equilibrium of the game. Okay? So now that we've understood what an equilibrium here is, let's move on to talk about another family of games called network routing games. And I want to take you about 100 years, back to 1920, and show you this very nice example.
00:18:42.440 - 00:19:39.450, Speaker B: So, here is the game. We have a network of roads, and let's suppose we have one unit of traffic. Suppose we have infinitely many drivers, and all of them want to go from point s to point d, from source to destination, as fast as possible. Okay? And they have two options. They can go either through this short but narrow road on the top, or they can go through this long but wide road in the bottom. Okay? A crucial component in this network routing game is the cost function of the edges. So, every edge has a cost function describing the delay a driver will have on the road for x fraction of the traffic.
00:19:39.450 - 00:20:19.434, Speaker B: For example, this road has a cost function, cx x. This means that if x fraction of the traffic goes here, each driver incurs a delay of x hours. For example, if half of the traffic goes on the top road, each driver will drive for half an hour. If three quarters of the traffic goes on the top road, each one will drive 45 minutes, etcetera. The bottom road is very different. Okay? So we see that the top road is very prone to congestion. It really depends on the congestion, how long it will take to drive on this road.
00:20:19.434 - 00:20:55.434, Speaker B: The bottom road is completely different. The delay on this road always takes an hour. So this road is not sensitive to congestion. No matter how much traffic goes here, each driver drives for exactly 1 hour. Okay? Because this is a long road, it takes always an hour, but it's very wide, so it's not sensitive to congestion. So, and this is the game. The game is all the players, all the drivers wake up in the morning in cts, and they have to decide whether to take the top road to D or the bottom road to D.
00:20:55.434 - 00:21:40.016, Speaker B: Socially, what we want to do is, of course, minimize average delay. How do we do that? So it's not very difficult to see that the optimal thing, socially would be to send, if we can control traffic, we would send half the traffic on the top road. Each one of them will drive for half an hour, and we'll send half the traffic on the bottom road. Each one of them will drive an hour. And this is exactly the right balance to get us to the optimal average delay, which is three quarters. Okay, I hope you can see this. Now, the question is disequilibrium.
00:21:40.016 - 00:22:10.474, Speaker B: Can someone. So this is a strategy profile. Half the traffic goes up, half the traffic goes down. Can someone improve their delay by deviating? And the answer is, of course, they can improve those people. So let's take one driver who currently, I put him on the, I told him, drive on the, you know, bottom road. He drives for an hour. And if he goes up, and think about this, every driver is this infinitesimal unit.
00:22:10.474 - 00:22:53.778, Speaker B: If he goes up, he drives about half an hour. Why not? And every driver does exactly this reasoning. And what would happen is that the only equilibrium is one where all the traffic goes up. All the traffic takes this very narrow road, which is very sensitive to congestion, and everybody is driving 1 hour. So we went up from the optimal solution, everyone is driving for 45 minutes to the equilibrium solution, where everybody is driving for 1 hour. Okay, this is dead. Now, the question is how computer science is RelEvAnt here.
00:22:53.778 - 00:23:36.418, Speaker B: I told you about routing games, I told you about equilibrium. And about 100 years ago, Pigou observed that in such a situation, the optimal solution is not an equilibrium, and an equilibrium, the only equilibrium, is not optimal. So in equilibrium, we are suboptimal. Okay, this is a nice observation. And now comes the very special angle of computer scientists. And what I want to argue here, that computer scientists are really compromisers, and we are so used to look at the world through the lens of approximation. That's what we've done over and over again.
00:23:36.418 - 00:24:16.986, Speaker B: And I want to present to you now three generations of compromises. And we always do the following. We have some objective function, f, and we measure our performance by taking the performance in a restricted word. We are restricted in some way, maybe computationally, maybe informationally, maybe in some other way. We are restricted, and we do whatever we can do in this restricted world. And we compare ourselves the performance against a benchmark in this perfect, unattainable, unrestricted world. Okay? And this is what we are used to do.
00:24:16.986 - 00:24:48.478, Speaker B: That's what we do. This is how we look at and analyze the world. For example, in the seventies, Kukarp and Levin developed the beautiful theory of NP completeness. The restrictions was computational restrictions. We wanted algorithms that run fast and are always optimal. And then Kukarp and Levin identified these NP hard problems that, well, what can we do? Probably, we cannot solve them. Always fast and always optimal.
00:24:48.478 - 00:25:26.424, Speaker B: And what we did was develop approximation algorithms. How do we measure the performance of these approximation algorithms? We take the value that can be achieved by a fast algorithm, poly time, if you will, and compare it to the optimal value of f. If we had all the time in the world without the computational restrictions. Of course, this denominator, this optimal value, is only describing some utopia. We are not. We don't even think we can get there. But this is a benchmark against which we measure the performance of our approximation algorithm.
00:25:26.424 - 00:26:31.594, Speaker B: And then, in the eighties, we started to think about informational restrictions, and we started to develop the theory of online algorithms and competitive analysis. And again, we used exactly the same formalism, a completely, totally different concept, but exactly the same formalism. We said, what happens if the input to our problem arrives piece by piece, and we have to make decisions immediately, now, without knowing what's coming in the future? So, the most relevant problem back then was paging, where we had slow memory, but very big, and we had very fast memory, very small, and we had a sequence of page requests. And whenever a page request arrived that was not in the cache, we had to decide immediately which other page to evict. And we had to make this decision without knowing the future. So, these are called online algorithms. And by online here, I don't mean Internet, I mean online in real time.
00:26:31.594 - 00:27:20.004, Speaker B: Okay, how did we measure the performance of online algorithms? We used exactly the same thing, the value of f obtained by an online algorithm compared with the benchmark. And this time, the benchmark was the best offline algorithm, an algorithm that knows the future. And we called it a competitive ratio. And then the third generation of compromises in the nineties, we started to have. We already had the Internet, and we had this problem where we can't control our users. We want to write algorithms, we are faced with some scenarios, and our users just follow their heart. They do whatever is best for them, they follow their best interest, and they act strategically.
00:27:20.004 - 00:28:09.454, Speaker B: And just like we've seen in this routing example, and they do, they play in equilibrium. And this is what Kotzupias and Papadimitrio called the price of anarchy. So we measure such scenario, we just follow what we are used to do, approximation. And we want to measure the performance of some scenario by taking the ratio between what we obtain in equilibrium and we compare it to the socially optimal value. Okay? And because of this history, sometimes, papadimitrio, for example, calls it the third compromise. The price of anarchy is the third compromise. So, let's look more carefully into this price of anarchy thing, because this concept will.
00:28:09.454 - 00:28:56.274, Speaker B: We'll just use it throughout this talk. So again, what's the price of anarchy is the value. We have some objective function, f, and the price of anarchy is the value of f, that is obtained in equilibrium, and we compare it against our benchmark, which is the socially optimal value of f. For example. In this routing example, we have drivers, and they'll do whatever is best for them. This is what we get in equilibrium, and we compare it to this centrally controlled world where we could, if we could, control the drivers and tell them where to drive. So the price of anarchy really measures the performance loss due to strategic behavior.
00:28:56.274 - 00:29:35.554, Speaker B: I want you to note that the price of anarchy is defined with respect to some objective function. Usually, we take just social welfare. We want to optimize the sum of people's values or minimize the sum of people's cost. If we're talking about losses, it's defined with respect to some solution concept, and we usually assume just Nash equilibrium. So we assume that people are playing a Nash equilibrium. And also, this is something I didn't tell you until now. In some games, we may have multiple equilibrium, we may have more than one equilibrium.
00:29:35.554 - 00:30:16.506, Speaker B: So we have to decide which equilibrium we choose. And usually we just follow the computer science approach of doing worst case analysis. So, the price of anarchy, unless I say otherwise, it's the social welfare that is obtained in the worst Nash equilibrium compared to the socially optimal value of fish. Okay, I think this is a good place to pause and ask if you have questions. I'm looking at the q and A. I don't see open questions. If you have any questions, please do type them.
00:30:16.506 - 00:30:48.674, Speaker B: I really appreciate the interaction. Okay, so, in what follows, I'm going to study the price of anarchy in three families of games. One is network routing. We'll have some good news there. The second is network formation games. We'll have some bad news, and then the last one will be the FCC spectrum auctions. And here we'll have mixed news.
00:30:50.174 - 00:30:56.154, Speaker A: Michal, I think that there is a question now, two questions.
00:30:56.894 - 00:30:58.302, Speaker B: Okay, great.
00:30:58.438 - 00:31:08.926, Speaker A: And also, I wanted to ask a third where you could give us some better, more explanation about socially optimal examples of socially optimal values there.
00:31:08.990 - 00:31:28.686, Speaker B: Okay. Okay, great. So the first question is anonymous, and he's asking, is the price of anarchy always going to be greater than one? Great question. Great observation. Yes. The price of anarchy is going to be greater or equal to one. If it equals to one.
00:31:28.686 - 00:31:54.934, Speaker B: It means that in every equilibrium of the game, we are going to be optimal. Every equilibrium will be socially optimal. This is the dream. This is the best case scenario. If the price of anarchy is one, we have nothing to worry about. A completely unregulated free market will do just, just as well as a completely regulated market. We don't need to control our users.
00:31:54.934 - 00:32:25.850, Speaker B: And of course, it's always greater or equal than one, because socially optimal is optimal by definition. If it's huge, it's really bad news. So when I say bad news, I mean that the price of anarchy is huge. Maybe it's even not any constant. Maybe it's, you know, maybe it depends on the number of users. And because we are talking about Internet applications with hundreds and thousands and millions of users, if the price of anarchy is going to be a function of the number of users, we are doomed. It's really bad.
00:32:25.850 - 00:33:09.580, Speaker B: It means that we really need to regulate the market. Otherwise we are going to be really, really in a bad situation. Okay, the second question, can you further describe online algorithms? Wow, I wish I had the time to further describe. So, online algorithms are just great. This is an amazing topic. And so let me just say a few words about it. So, online algorithms, you have some sequence of, you get your input piecemeal, you get it piece by piece, and in every time, you have to make a decision immediately and irrevocably.
00:33:09.580 - 00:33:54.774, Speaker B: Here is a very classic example. Secretary. Let's say, for example, secretary problem. You are interviewing secretaries, and you have, and you see them one by one, and in every time, let's say you interview and secretaries, and every time, you see the performance of the one you just interviewed, and you can compare the performance of this secretary to previous ones. You have no information about the future, and now you interviewed someone, and you have to make a decision now whether you hire the secretary or not. Okay, how do you do it? And we compare ourselves to the. To the best thing.
00:33:54.774 - 00:34:30.880, Speaker B: If we could see all the sequence up front. Okay, so there are some nuances. So maybe. So maybe, for example, the arrival order is random, or maybe we know an underlying distribution and we have all types of thinks of assumptions that can make our life easier. But in general, this online algorithm, the question is to compare the performance of an algorithm that needs to make immediate and irrevocable decisions to an algorithm that knows all the future. And sometimes we can do pretty well. So, this is about online algorithms.
00:34:30.880 - 00:34:59.268, Speaker B: Now to Shafi's question about what's socially optimal. So, I'm not sure what exactly you mean by this question, but, for example, in this routing example that we had before, suppose. So what's socially optimal here? Socially optimal here means that we have the minimal average delay, right, or average delay, or sum of delays. Doesn't matter.
00:34:59.356 - 00:35:03.780, Speaker A: Okay, I guess I wanted more examples, but. Yeah.
00:35:03.932 - 00:35:32.776, Speaker B: Oh, more examples. Okay, we'll see more. We'll see, we'll see several more examples. Yeah, but the point is, if we can control our users, we can just do what's optimal, but the problem is we cannot control them. Okay, what's the price of anarchy in the city problem? Great question. We'll get there very soon. Doesn't it make sense to ask for equilibrium only amongst feasible, for example, poly time computational limits? Excellent, excellent question.
00:35:32.776 - 00:36:26.144, Speaker B: So, this question hints on a very important question that I'm not going to talk about, which is computational complexity of finding an equilibrium. And sometimes one criticism there is for the price of anarchy, is that why do we even assume that people will get to an equilibrium, right? Especially if it's a computationally hard problem. It's really. It casts doubts on the predictive power of equilibrium, because, you know, if it's an np hard problem, for example, why should we get there? Excellent question. Hopefully I'll have some time in the end to talk more about it. Could we, as audience, please see all questions? I don't know. That's probably question for an admin.
00:36:26.144 - 00:36:49.516, Speaker B: And the last question, if the agents can communicate to some extent and collaborate, will the price of anarchy disappear? Amazing question. And I'll answer this question in the second game. I'll talk about excellent questions. Thank you so much. And hopefully I'll be able to satisfy all of you. So, let's keep going. So, we have the price of anarchy.
00:36:49.516 - 00:37:23.250, Speaker B: And great, we've defined it. And now one of the question was, what's the price of anarchy in this city game? In this network routing game, the answer is the price of anarchy. Here is the cost in equilibrium compared with the cost, the optimal cost. And the answer is four over three. Okay, four thirds. Is this good news? Is this bad news? So let's, let's see what it, what it. What it means.
00:37:23.250 - 00:38:00.174, Speaker B: And this is for this very specific example, what it means is that in this pigu network that I just showed you, the overhead due to selfish behavior is at most 33%. So I take it to be really good news. Okay. It means that if we had all the control in the world, we could control drivers, the situation would not be that much better or the contrapositive, now that we are in a complete anarchy. Anarchy meaning equilibrium. Everybody's following their best interest. Yeah, we are.
00:38:00.174 - 00:38:31.062, Speaker B: We are suffering an overhead of 33%. This is not that bad. And this is a universal constant. This is just four thirds. It's not too bad. But, you know, this was just one tiny example of two cities and two roads in real life. We have way bigger networks, and the networks are so complex, we have no complex network of roads and bridges and cities, et cetera, et cetera.
00:38:31.062 - 00:39:39.162, Speaker B: Also, the cost functions that I showed you were very simple. And different roads, depending on their structure, have very different cost functions. And also, I assume that all the drivers want to get from s to d in the morning. Different drivers want to go from different sources to different destinations, and it becomes a real mess. Okay? And the question is, what's the price of anarchy in this very general scenario? And the amazing answer of Roughgarden and Tardos from 2002 is this theorem. In every network routing game, as long as the cost functions on the edges are linear or affine, just like the ones we've seen, the price of anarchy is at most five thirds. It doesn't get worse than an overhead of 33%, no matter how big the network is, no matter how many drivers are there, no matter how the cost functions look like, as long as they are linear.
00:39:39.162 - 00:40:17.834, Speaker B: Okay, so this, to me, is an amazing question. Amazing answer. I mean, okay, let me do a small digression here, which I feel is important. So, price of anarchy results are quantitative in nature. We really ask for four thirds, five halves, et cetera, et cetera. And some of us, this cartoon describes some of us. I admit that sometimes I can get really excited by getting an approximation ratio down from two point, blah, blah, blah, four to two point blah blah blah 39.
00:40:17.834 - 00:41:10.432, Speaker B: And it's fine for mathematical curiosity, it can be very important. But we have to remember that price of anarchy results like approximation results. It's true that they are quantitative in nature, but they provide mainly qualitative insights about problems we care about. So, for example, in this price of anarchy result, the four thirds result really tells us that in network routing problems, in network routing scenarios, the overhead due to selfish behavior is not that bad. Let me show you one more example, which is really incredible. It's called Brass's paradox, and it's from 1960. Again, we have one unit of traffic.
00:41:10.432 - 00:41:39.926, Speaker B: Now, the network is a bit different. We have four roads. Two of them are of type x and two of them are of type one. This is the cost function on the edges. Again, the socially optimal way to drive is to just route half of the traffic up, half of the traffic down. Right? And this gets us a delay of three halves. After traffic goes for 1.5
00:41:39.926 - 00:42:37.334, Speaker B: hours, the other half goes for another 1.5 hours, and the average delay is 1.5. And now suppose the government looks at this situation and says, wait, you know, every driver driving every morning for 1 hour and a half from, say, San Francisco to Berkeley, this is no way. We have to make it better. And the way to make it better is to build this very fast road that goes from this point here to this point there. And this road is so fast that you can think about it as a teleportation, right? People just move in no time from this point to this point point with the hope that this will reduce congestion and get people faster from s to D. Okay, let's analyze what happens next.
00:42:37.334 - 00:43:32.374, Speaker B: Again, the socially optimal thing is to do exactly the same thing, route half the traffic up and half the traffic down, and again have an average delay of one point half, 1.5. However, unlike this case, where this is an equilibrium, right, you can see that in this case, everything is symmetric. There is no reason for a driver in the bottom road here to go up, or vice versa. Now, due to this very fast teleportation road, we're in a problem because people have incentive to take the zigzag road. So someone who is driving for 1 hour and a half here can say, oh, well, I can just take the zigzag road, drive half an hour here, zero here, and half an hour here. Boom. I do an hour instead of 1.5.
00:43:32.374 - 00:43:59.914, Speaker B: But everybody will do this reasoning. And what would happen is that instead of the best average delay of 1.5, the only equilibrium would be one where everybody is. Is taking the zigzag road. And then what happens? Everybody is driving. Oh, I have to wave in order to get the light back on. Everybody is driving for 2 hours now.
00:43:59.914 - 00:44:23.842, Speaker B: Wow. So we built a new ward, a new road, and the situation became much worse. By the way, surprisingly enough, the price of anarchy is again four thirds, right? Right. It's two over three over two. So again, four thirds. This is a coincidence. And we know it cannot be worse than four thirds.
00:44:23.842 - 00:44:56.486, Speaker B: So this is the worst it can go. It can get. Okay, and what's the takeaway from this example? The takeaway is that building new roads could potentially increase travel time for everyone. And this is the new thing that we see in this example. It's not just for some people, it's really worse for everyone. And the contrapositive that closing existing roads could potentially decrease travel time for everyone. And throughout history, we've seen real life examples for this phenomenon.
00:44:56.486 - 00:45:47.314, Speaker B: So, for example, in Stuttgart in Germany, it happened that they built a new road in order to alleviate the congestion. And this new road just slow down traffic really badly until they had no choice but to close it. And then the situation became better. Okay, so what seems locally optimal sometimes is really bad globally. Now let's go back to this beautiful theorem of four over three. How come we did. Sorry, how come we didn't see this result before? So this pigou example with price of anarchy of four thirds just celebrated its hundredth birthday, and it took about 80 years to come up with this result.
00:45:47.314 - 00:46:20.046, Speaker B: And the answer is, it's not that the proof was so difficult. It's definitely non trivial proof. A beautiful proof. Very nice proof. All these price of anarchy proofs are really nice and non trivial, but it doesn't take 80 years to prove them. The reason that we took 80 years to prove them is that we really needed the point of view of computer scientists, the ultimate compromisers, in order to even ask the question. And once the question was asked, we could answer it.
00:46:20.046 - 00:46:46.592, Speaker B: Or in this case, Tim Rothgarden and Eva Taros. Okay, let me take a few more questions. Okay. When you say the price of anarchy can be huge, it takes the worst case, equilibrium. Is there a pareto ranked equilibrium? Then coordination can result in better outcome. Has this been explored? This has been explored. And I'll get to this.
00:46:46.592 - 00:47:07.710, Speaker B: Exactly this point in the next application I'll talk about was supposed to be anarchy. Autosp. Maybe I had a typo. Sorry. Is there an optimal value for the price of anarchy? What should it. Oops. What should it be less than to be able to control the situation? Good.
00:47:07.710 - 00:47:59.370, Speaker B: So what's an optimal value for the price of anarchy? So, in our analysis, as computer scientists, we are looking for tight results. So, when we say that the price of anarchy is, for example, four thirds, in order to say that this is optimal or this is tight, we have to make the case that indeed, on the one hand it's always bounded by four thirds, and on the other hand, we have an example where we get four thirds. So we cannot get better than that. And then we say that the price of anarchy is tight. Shouldn't we compare the overhead with the ratio of a random algorithm? Okay, great question. And they take this question to be. So, I only described to you pure Nash equilibria until now.
00:47:59.370 - 00:48:54.044, Speaker B: But as I told you before, Nash equilibria also may be random. And if we are going to mix Nash equilibrium, this is a much bigger class of equilibria. This is really a very, very beautiful question. The answer is that by now we've developed the theory of price of anarchy, and we have machinery that gives us some extension theorems. So in many situations, we can prove it's kind of a magic. We can prove price of anarchy results for this small class of pure Nash equilibria. And the ratio we obtain for the price of anarchy extends also to larger classes of equilibria, such as mixed Nash equilibrium.
00:48:54.044 - 00:50:00.804, Speaker B: Or maybe those of you are familiar with the terms correlated equilibria and coarse correlated equilibria. And in some cases, even just outcomes that are obtained by no learning algorithms, et cetera, et cetera. So we have extension theorems that allow us to prove price of anarchy results in some situations for a small class of equilibria. And they extend magically beyond to many other types of equilibria, because, of course, potentially price of anarchy could become much larger if we go from a small class to a larger class. Okay, were cs ideas useful in the proof? Again, excellent question. Okay, let me just finish reading, or once you ask the question, do you use essentially standard math ideas? So in this case, it was cs ideas were not used in the proof, so we had to ask the question and then we just used math. In this case, it was potential function that played a major role in these proofs.
00:50:00.804 - 00:50:48.204, Speaker B: Thank you again for all the questions, and let me continue with the second application. With the second application, we'll get to some of the questions you were interested in. Great second example, network formation games. So now the figure is very similar to before, but the situation is completely different. So just stay tuned to hear the story. The story here is that we have again now a population of end players and they need to build a network. And they are all interested in this case to connect s, the vertex s here to the vertex d here.
00:50:48.204 - 00:51:21.132, Speaker B: So maybe, for example, they want to lay down Internet fiber between neighborhoods. Okay? And they have two strategies, two options. One is to build this very expensive edge, and the other is to build this cheap edge, okay? And you see now that you see the cost on the edges. So the cost of this edge is n. It's as big as the number of players. And the cost of this wire, of this edge is one. Great.
00:51:21.132 - 00:51:48.792, Speaker B: So we have n players, they wish to build a network connecting SMD and each edit. Each edge has a fixed cost for building it. For building it. This fixed cost is n. This fixed cost is one. And note that in this case, unlike the previous example, the cost of the edge is independent of the number of players using it. No matter how many players are using it, it has a fixed cost.
00:51:48.792 - 00:52:44.420, Speaker B: And this is the cost of laying down this fiber, no matter how many players are going to use it. And here is the important thing, the cost is split equally among the players using it. Okay? So if, for example, all end players, let's say we have ten players and the cost of this edge is ten, and all ten players use this edge, each one of them will pay one because they split the cost and equally between all players. And if they all use this edge, they'll each pay one over n. And if they split, they'll just pay their equal share of the edge. Let's analyze this game and what's the goal? The goal is to minimize the total cost of the network. We need a network that will connect s.
00:52:44.420 - 00:53:24.224, Speaker B: We want to choose the minimal cost in order to connect these two points. Okay? And again, this is a very, very small network, just two edges. Imagine you have huge network with many edges and many players. Each set of players want to connect different parts of the network, and every edge has a fixed cost, et cetera, et cetera. But let's analyze this very simple scenario. What's the optimal thing? Of course, what's optimal is that everyone uses the bottom edge, and then the total cost of the network is one. All agents, all n players, choose the bottom edge.
00:53:24.224 - 00:54:07.044, Speaker B: This is great. This is very cheap way to connect s 2d. However, we have a really bad equilibrium. If all the players are building the top edge, each one pays one, and no one has incentive to deviate alone unilaterally to the bottom edge. Okay. And this means, according to the definition of Nash equilibrium, that this is, unfortunately, a really bad equilibrium. And the price of anarchy here is n is as big as the number of agents.
00:54:07.044 - 00:54:32.906, Speaker B: And if you're curious about this example, I'm not going to show the proof, but the proof is very simple. So convince yourself that it cannot be larger than n. Okay, so n is tight. The price of anarchy in these Games is n. It's always bounded by n, even in these huge networks that I described to you. Okay, but something is really bothering us. And this all it is.
00:54:32.906 - 00:55:15.452, Speaker B: And the thing that bothers US is related also to one of the questions that one of you asked before. Why think about worst case equilibrium. We have a really nice equilibrium here. If everyone is using the bottom edge here, this is also an equilibrium. Of course, everybody is paying only one over n, and they don't want to deviate and pay n a loan. So why are we thinking about the worst case equilibrium? Another question that was also asked in one of your questions is maybe people can coordinate. This Nash equilibrium thing is really annoying.
00:55:15.452 - 00:56:07.138, Speaker B: It means it's stable only in the sense that one player has no incentive to deviate alone. But if all the hundreds and hundreds of people are using this top edge and paying this huge cost, maybe few of them can coordinate a Deviation and go here. Maybe all of them can coordinate a Deviation and go here. So this equilibrium makes us feel pretty bad. It feels like a very brittle equilibrium. And indeed, we have two results, two approaches of eluding these bad price of anarchy. The first approach, as one of you suggested, is to consider the best NAsh equilibrium instead of the worst Nash equilibrium.
00:56:07.138 - 00:56:53.690, Speaker B: And to just ask, do we have any NAsh equilibrium that is performing well? And the result that we have here is that the cost of the best NAsh equilibrium is at most factor order log n of the optimal cost. Okay, so now we have an exponential improvement over the really bad price of anarchy. That could be just n number of players. We went down to log n, and, again, this is tight. There is an example of a network where we have only one unique Nash equilibrium, and it costs factor log n more than the optimal one. Okay, so, great. This is the first approach.
00:56:53.690 - 00:57:34.698, Speaker B: The second approach is to stick towards equilibrium. You know, we are computer scientists. We are so used to worst case analysis, we really want things to be good in the worst case. But what we will do now is consider a different solution concept. So, as I told you, Nash equilibrium is a situation where no individual player can deviate and improve her cost. Let's consider a subclass, a strict subclass of Nash equilibrium called strong equilibrium. This is due to Uman, another Nobel laureate, who came up with this notion of strong equilibrium.
00:57:34.698 - 00:58:47.814, Speaker B: And the strong equilibrium is a much more stable outcome. It's an outcome from which no coalition of players can deviate in a coordinated way and improve the cost of each member. Okay, and what we get here, again, we get that the cost of the worst strong equilibrium is at most factor o log n of the optimal cost. So in both cases, this new definition of price of anarchy. The first takes the best Nash equilibrium, the other takes the worst strong equilibrium. They both arrive at this same price of anarchy, same loss due to strategic behavior. And I think it's interesting, so it may be a coincidence that we get exactly the same results, that the proofs are completely different, both of them use, again, in all of these proofs, both in the network routing game and in this network formation games, these are both called, they are both part of a larger class of games called a congestion game.
00:58:47.814 - 00:59:44.222, Speaker B: And usually the way to deal with such games is through minimizing a potential function. So these are also potential games. We have a potential function, and in order to find a Nash equilibrium, we want to find the local minima of this potential function. So both of these proofs are related to this notion of potential functions, but otherwise, the proofs are different. And it's interesting, because these two notions, these two approaches, are related to some type of coordination in the left. In approach one, the coordination is really coming from a third party, who just suggest the players to play in some equilibrium, maybe the best equilibrium, and because it's an equilibrium, they won't deviate. So this is one type of coordination, coordination through a third party.
00:59:44.222 - 01:00:23.926, Speaker B: On the other hand, approach two is again some type of coordination that helps us. But this time the coordination is coming from the users themselves. They coordinate themselves by coordinating their deviations. And both of these approaches turn out to give us a price of anarchy of login. Okay, let's take questions again. How often are cost functions linear? How often are the cost functions linear in real world networks? So I assume you talk about these network routing games. Very good questions.
01:00:23.926 - 01:01:10.494, Speaker B: Usually they are not linear. Usually they are more quadratic than linear. And we also have results for just polynomial of a bounded degree, cost functions. And if the degree is small, which is what's more common in roads, maybe cost function is kind of quadratic, then we also have good price of anarchy results that depend on the degree. So if the degree is small, we have nice results as well. Are those equilibria cost login for games in general or a class of games. So these login results are for these specific network formation games, just for this family of games.
01:01:10.494 - 01:01:59.874, Speaker B: Of course not only for this example that I showed you of two edges. It's for these very general network formation games where you have a general network and any fixed cost on the edges and any player wants to connect some node to another node. So login holds there, but not beyond this network formation game. Is there a different solution concept for which the price of anarchy for network formation game is constant? Unfortunately, I'm not aware of one. If you find one, I'll be happy to know. Okay, and then a comment about approximation. Here is a famous quote of Bertnard Russell.
01:01:59.874 - 01:02:27.984, Speaker B: Although this may seem a paradox, all exact science is dominated by the idea of approximation. Great. So this idea of looking at the world through the lens of approximation goes back to Bertnard Russell. Thank you, Vijay. Okay, let's continue. Last example, auctions. Shafi, how much time do I have left?
01:02:30.364 - 01:02:40.124, Speaker A: We have an hour and a half allocated for this. But if you wanted to take, I go till 315, say, and then ask Libron for questions or I don't know how much more.
01:02:41.704 - 01:03:23.464, Speaker B: So I'll just continue and I'll take questions in between and also in the end. Okay, great. Okay, so the third example is auction design. Okay? Auctions are really now everywhere we have keyword auctions. We have auctions on eBay. Advertisements are now sold by auctions and they are really the biggest part of the business model of most Internet companies. So most of the revenue of Internet companies is now obtained using auctions.
01:03:23.464 - 01:04:19.806, Speaker B: And of course, FCC auctions for wireless bandwidth. So wireless bandwidth is sold to telecom companies using auctions from, I think the mid nineties or so government procurement auctions, everything is done using auctions. And you probably know, and if you don't know, you should know that you have these keyword auctions. So every time you type a word in Google and search for it, you get some results, which are the generic results, but you also get sponsored results. And these results that you get are sold through auctions to the advertisers. Okay? So if you write hotel San Francisco, because you want to find a hotel in San Francisco, you. So online, in real time, there will be an auction.
01:04:19.806 - 01:05:08.706, Speaker B: And, and this auction will be among all those advertisers that want to sell you their hotel or maybe car rental, et cetera, et cetera. So we really have now auctions everywhere. So as a warm up, I just cannot not tell you about this wonderful auction called second price auction. So let me tell you, let me do a warm up about a single item auction. So really, what's more interesting to me is these are these huge auctions of millions of items and millions of users, and they are everywhere. But let me just zoom in for a minute and tell you about just an auction for a single auction. Okay? So here is the model.
01:05:08.706 - 01:05:38.114, Speaker B: We have one wood for sale, maybe this picture. And we have n bidders. And those n bidders have values v one to vn. So in this case, for example, we have this bidder. Her value for the picture is $20. This means that she's willing to pay $20 to obtain this picture. The goal is to allocate the picture to the bidder with the highest value.
01:05:38.114 - 01:06:11.946, Speaker B: Let's assume I don't care about revenue at all. All I want is to sell it to the bidder with the highest value, okay? In this case, I want to sell it to this lady. The problem is that the bidder values are private. I have no idea what the values of the bidders are. Okay? For example, if I want to maybe give one of you my cell phone here, I want to give it to the person with the highest value. But I don't know your values. And I do an auction.
01:06:11.946 - 01:06:31.720, Speaker B: And in this auction, this is the image I want you to have in your head, this auction. So we have these values. The values are private. They're in the heads of the agents. I don't know them. As the auctioneer, what I do get is the bids of the agents. Every agent submits a bid.
01:06:31.720 - 01:07:00.236, Speaker B: Let's say they submit bids in sealed envelope, okay? So each one of you, for example, sends me now a bid for my cell phone using private chat, and I open these bids. And every auction is composed of two rules. One is an allocation rule and the other is a payment rule. I have to decide. And both of these rules are functions of the bids. Only bids. I don't know values.
01:07:00.236 - 01:07:31.944, Speaker B: I just know bids, okay? And this is a very, very beautiful auction called second price auction, or vicri auction. This is a very simple auction that does the following. I collect all your bids. I open all the envelopes. I give the item to the highest bidder, the one who submitted the highest bidder. But that bidder doesn't pay his bid. He pays the second highest bid.
01:07:31.944 - 01:08:38.245, Speaker B: Okay? So if I got bids, let's say 180 and 60, I give it to the bidder who bid 100, but he only pays $80. Why is this auction so great? We have this wonderful magic by another Nobel laureate, Vikri, saying that second price auction is dominant strategy. Truthful, this is amazing. So just take 10 seconds to appreciate this result. What does it mean? It means that if I'm running second price auction, each one of you doesn't have, no one of you has any reason to misreport your value. So you have your own private value. But the absolutely one best thing for you to do is to tell me your private value.
01:08:38.245 - 01:09:20.679, Speaker B: Truthfully, you have no reason to somehow misreport your value. So the best strategy, and this is not just an equilibrium, this is a dominant strategy. No matter what others are doing, no matter what's the values of others, no matter what are the bids of others, the best thing for you to do is always to bid your true value. This is amazing. Okay. And this is what's called a second price auction. And just after the talk, think to yourself, what about first price auction? For example, what if the payment was just the bid, I give it to the highest bidder and she needs to pay her bid.
01:09:20.679 - 01:09:51.536, Speaker B: Would it be truthful? It won't be truthful. And no other auction would be truthful. This is the truthful auction, and this is when I'm selling one item. But now we are talking about huge auction. Let's for example, think about those wireless spectrum auctions. We are selling many, many licenses to telecom companies. And these licenses since the mid eighties are sold in what's called simultaneous ascending auctions.
01:09:51.536 - 01:10:28.164, Speaker B: So it's not that important. The details are not that important. What's important is that every license is sold in a separate auction. But the bidders, the telecom companies, have very complex combinatorial valuations over licenses. So sometimes two licenses can be substitute to each other. If, for example, they are in the same area, some licenses can be complement to each other. Maybe, you know, I want a license in San Francisco area and then in Berkeley area.
01:10:28.164 - 01:11:11.680, Speaker B: So those valuations can be very comparable. And we are selling many items. And in order to handle such situation, we have a canonical model called a combinatorial auction, where we have n bidders m heterogeneous items. So in our case, for example, the bidders are the telecom companies, the items are the just, the licenses, wireless channels, and every bidder high. Every telecom company has a private valuation function over the item, over the items. And this valuation function, as I said, can be really complex. It assigns just a real value to every bundle of item.
01:11:11.680 - 01:11:43.274, Speaker B: We're just making one assumption, that the valuation function is monotone. If you get more items, if you get more licenses, your value doesn't go down, very, very minimal assumption. The social goal is to maximize social welfare. The social welfare here is the sum of bidders values. Okay? So just think about this situation. We have many licenses, we have many telecom companies. Each one of them has a very complex valuation function over all these licenses.
01:11:43.274 - 01:12:34.708, Speaker B: And we want to partition, to partition those licenses among the bidders in such a way that the some of their values will be maximum. And we are using an auction. And remember, auction is composed of an allocation rule and payment rule based on bids. So now think about bids. As you know, maybe in this complex world, a bid would be just the whole valuation function, very, very complicated object. And the individual goal of bidderi is to maximize her own utility. What's her utility? Her utility is the value she has for the bundle she gets minus the payment, minus what she has to pay for this bundle.
01:12:34.708 - 01:13:31.664, Speaker B: Okay, good. Let's make a simplifying assumption, and let's suppose that what we are doing is simultaneous second price auctions. So I told you about this beautiful second price auction. When I'm selling one item alone, a second price auction is dominant strategy, truthful. It's best thing for me to just say my value truthfully, but now I have a very complex valuation function, and the auction is such that every item, every license is sold separately. So I have to just give one bid for each license, and then for each license, we are running a second price auction with all the bids that the auctioneer got. And the question is, is this a truthful auction? So we know second price auction is truthful.
01:13:31.664 - 01:14:33.264, Speaker B: If we do simultaneous item, simultaneous second price auctions, is this truthful as well? And the question is, of course not, because as a bidder, I don't even have the expressive power to tell the auctioneer my value. My value is this complex object over bundles of items. And I am, and I can only give bids on separate items. So this is not truthful. And I don't even have the chance to reveal my valuation. So the question is, how do we analyze this game? What's an equilibrium of the game? What's the price of anarchy? What's the efficiency, loss, etcetera? And just to give you the feeling of how difficult analyzing this game is, suppose we have 20 licenses for sale. And suppose you are a telecom company, and you're interested only in a single license.
01:14:33.264 - 01:15:29.854, Speaker B: How should you bid? So one option would be to go all in to identify one license and go all in for this license, and don't bid on anything else. Well, this might work for you, but this is also very risky, because if you don't win this license, you have nothing. Another option is to bid low on many licenses and hope that you'll get one of them. But remember, this is tricky, because in the end, you only get value from one license and you pay for everything that you win. How do you balance all these trade offs? And now suppose you want two licenses. How should the answer change? And the answer is, I don't know the answer. Analyzing how to play in these games is really, really difficult.
01:15:29.854 - 01:15:39.214, Speaker B: Let me skip, for the sake of time, this example, and skip directly to the results.
01:15:42.674 - 01:15:48.894, Speaker A: I think if you want to, you have ten more minutes before we kind of record the end. So if you want to give some time for.
01:15:49.354 - 01:16:24.344, Speaker B: Okay, good. So I'll just say this result and then I'll end. So the result is, as long as items don't have strong complementarities. And what I mean by don't have strong complementarities is just that. My valuation function has this, what's called sub additive structure, that my value for s plus t is smaller than the sum of my value for s and my value for t. This is a pretty general class of valuations. Simultaneous second price auctions have small price of anarchy.
01:16:24.344 - 01:17:11.914, Speaker B: Okay? And this is for any number of agents, any number of items, and even under incomplete information. So this is a pretty strong result. And, okay, let me skip these two. The takeaway from this is the simple auctions work well in the absence of strong complements. And now we are going back to our question, how come all the beautiful literature in economics didn't reveal this beautiful pattern? So this aligns with their thoughts. They thought that these simple auctions work well if items are substitutes to each other. And complementarities bring us a lot of messages.
01:17:11.914 - 01:18:04.894, Speaker B: But they didn't have any such result, any such theorem. And again, the answer that the reason they didn't have it is not because the proof was so difficult. Again, it's non trivial, but it shouldn't take so many years. The answer is, the reason is that they never asked this question. It's really the approximation length, that approximation paradigm that we use as computer scientists that make us ask these questions. So, okay, now I'm in the concluding slide. So, first of all, what I showed you today is that the approximation lens of computer science appears very useful in many applications.
01:18:04.894 - 01:18:57.488, Speaker B: And now I want to take, to do a little zoom out. The fruitful interaction between computer science and economics go way beyond this theme. So today I just showed you one theme. How do we use approximation, the approximation paradigm, in order to reason about economic and markets situation. But the interaction really goes way beyond this example. And if we take, if we are doing even another level of zooming out, I think this is really the golden age of theoretical computer science. I think the world has matured into interdisciplinary research, and for the last few decades, TCS has developed its theory, its beautiful theory internally.
01:18:57.488 - 01:19:36.206, Speaker B: And now it's the time for TCS to come out of the backstage and really influence the world. And we are seeing it in many, with many, many examples. Computational biology is computer science and biology. Quantum computing is computer science and physics, algorithmic game theory, economics and computation, computer science and economics. And I believe that we'll see many more examples in the near future. So just take TCS and you wherever you want to take it. Thank you very much.
01:19:36.390 - 01:19:48.294, Speaker A: Thank you very much, Michael. And those are fantastic words also for the Simons Institute for TCS, which I agree with, you have three questions, it looks like in the q and a, if you want to address them.
01:19:49.034 - 01:20:40.120, Speaker B: Okay. Are results available only for such toy models, or are there ways to make statements about real systems? Right. So, usually, in order to have tractable models, we are doing many assumptions, and we have these examples. Some of them are really toy examples, like the, you know, the small example with two bidders, two items, or very small network. But some of them go beyond toy examples. They're still, you know, assuming some real world things away, but they are reasonable, like simultaneous second item auctions. I think they are good models for, like, good approximation.
01:20:40.120 - 01:21:12.698, Speaker B: Let me, let me use this word again for these simultaneous ascending auctions that are used in practice. Okay. And then another. Okay, so Bernard von Stengel is saying I ran my own auction for selling an inherited house. For bidders, an open auction would have been word and also a second price auction. The bidders would have thought I wanted to deceive them. First price was straightforward.
01:21:12.698 - 01:21:33.584, Speaker B: You say what you would pay, and that's it. And the information stays private. Would you sell your house by a second price auction? Simplicity and trust are important, too. Okay, yeah, great. I take it more as a comment than as a question, so. Sure. Yeah, great comment.
01:21:33.584 - 01:22:10.024, Speaker B: Okay. Any thoughts on what the price of anarchy with respect to how we are doing vaccine distribution today? Is the allocation socially optimal? Wow, this is a beautiful question. I have many thoughts on. I have many thoughts on this, and I have some ideas. Some of them are a bit provocative, so maybe I shouldn't tell them. I'm not familiar with research precisely about price of anarchy. Of vaccine distributions today, maybe.
01:22:10.024 - 01:23:04.578, Speaker B: What I am familiar with is research that is integrating game theoretic ideas into the SIR and similar models. So the SIR model is, you know, is this model of how the. How the pandemic goes. I'm running out of words. Diffuses among the population, and the assumption there is that people interact randomly with each other and they get sick and they recover, et cetera, et cetera. And we have these differential equations that tell us how the dynamics will be, and these models completely ignore strategic and game theoretic issues. So there are some new papers that are trying to incorporate game theoretic ideas into those sir models.
01:23:04.578 - 01:23:42.520, Speaker B: For example, if the pandemic is really in a really bad situation now, it's reasonable to assume that people will be much more careful than otherwise. And taking these assumptions into account and into the definition, differential equation changes the type of dynamics. And I think this is a very, very worthwhile idea, because I think, really, people are taking into account, we should take into account the strategic issues. People respond. People do best respond to whatever the situation is. Another comment by Steve Tadellis. Hi, Steve.
01:23:42.520 - 01:24:16.086, Speaker B: There is a lovely new paper by Akbapour and Lee in Econometrica on the benefits of first price auctions. In the spirit of the house selling question. Oh, okay. I take it to be related to the question or comment by Bernard. Sure. Those are two amazing authors, and I encourage you to read this paper, and I'll read this paper alone. Let me also tell you that, of course, I only introduced to you today social welfare as an objective.
01:24:16.086 - 01:24:54.142, Speaker B: Of course, we have many more objectives. In particular, of course, we also care about revenue. Revenue is a very, very important objective function. And things are different when we talk about revenue than when we talk about social welfare. But those of you who are not familiar with a beautiful theorem called revenue equivalence theorem. So, if we, for example, we compare first price auction and second price auction. So, in first price auction, the winner pays his bid, and in second price auction, the winner pays only the second highest bid.
01:24:54.142 - 01:25:25.064, Speaker B: And, okay, people will behave differently. And the question is, what can we say about the revenue in equilibrium? And we have this beautiful theorem, revenue equivalence theorem, saying that in equilibrium, the revenue will be equal, because in equilibrium, the revenue only depends on the allocation, not about the payment. So, yeah, this is not really answering the question, but I just felt that I talked too much about social welfare. So revenue deserved maybe one word.
01:25:27.084 - 01:25:51.882, Speaker A: Okay, wonderful. And you even finished on time. I think we just want to give you a big applause, which means nothing in virtual days, but I will clap for you. And thank you so much, Michal, also for staying so late and giving such a wonderful talk and such an exposition of the field. Thank you.
01:25:52.058 - 01:26:04.904, Speaker B: Thank you very much, Shafi. And thank you very much for coming. And it's such a shame I couldn't see your faces. But we'll do another zoom session for this, I guess.
01:26:05.604 - 01:26:07.108, Speaker A: Thank you. Bye.
01:26:07.156 - 01:26:07.860, Speaker B: Thank you, bye.

00:00:00.520 - 00:00:02.326, Speaker A: So, next up, we have Ryan Williams.
00:00:02.350 - 00:00:06.674, Speaker B: Who'S going to tell us about the complexity of solving systems of polynomial equations.
00:00:07.334 - 00:00:41.220, Speaker A: Thanks for the introduction. Thanks for coming. So, by invoking this fine grain adjective, I'm going to allow for algorithms which slightly beat exhaustive search for solving systems. And I'm going to talk about conjectures and hardness results for slightly beating exhaustive search. So, the reason I wanted to speak about this is it has some proofs and ideas which I think would be of interest to this audience. So, let's start with the problem. So, in this talk, we'll be looking at mainly prime fields.
00:00:41.220 - 00:01:48.378, Speaker A: So FP, where p is prime and k be some positive integer. Look at degree k FP system solvability, where you're given a set of m polynomials and n variables whose degrees are at most k, and we want to know if there is a solution to them. So if there is some assignment to the variables which, say, makes all the polynomials vanish, is the zero set empty or not? So, in this talk, we'll think of p and k as small, like constants and n as quite large, and p is, say, smaller than, than k. Okay. Or say, much smaller than, like, exponential and k. So, this particular setting of parameters is of interest for various cryptosystems, like for example, like quadratic systems of equations, where the cryptosystem is based on the hardness of solving a quadratic system. So just to get useless notation.
00:01:48.378 - 00:02:45.834, Speaker A: So, if I have degree one, it's linear equations, and then I can solve this problem in p by gaussian elimination. If I only have one equation, then I'm just trying to find a root of one degree k polynomial, which would say, and I'm giving you the list of coefficients, the monomials, explicitly, and this is finding root. So this you can solve in polynomial time. But if I allow you arbitrarily many equations, and I look at f two degree circumflex two, it's already np hard. So the easiest way to see this is a reduction from the null equals three sat. So I do want to say that there are quite a few algorithms known when n is small. So, for example, Niraj gave a talk at Simons several years ago, and now we're going to run in time, which is polynomial for a fixed fixed n, but it's degree to the some exponential nn term time.
00:02:45.834 - 00:03:32.474, Speaker A: But for our case, where we're looking at just some finite field like f p, we have n variables. We want to know if we can be p to the n. Just, you know, the brute force algorithm of trying all the possible assignments. And so something that was, that was started in the fine grain semester at Simons in 2015 and eventually worked out with Lokchanov, Paturi, Tamaki, Hua Chengyu and myself. Is that, yes, you can beat exhaustive search this particular running time. So it's p to the n divided by p to the n divided by order k, some factor in terms of k. It gets worse as k grows, the improvement of exhaustive surge.
00:03:32.474 - 00:04:24.774, Speaker A: And if this is true for like p, which is not too large as a function of k, whenever p is greater, you still get some improvement over exhaustive search, though it's slightly worse. So, the first thing I want to do is tell you about this algorithm. So there's the problem again, and the statement. So I was trying to think of how to explain this algorithm in some clear and succinct way, and eventually I just decided I would constrain myself to one slide, I guess. Does the slide, yeah, well, there's a very interesting use of white space, I guess you could say. We'll see, literally white space. Yeah.
00:04:24.774 - 00:04:34.298, Speaker A: Fine grain exposition, right? Well, this is actually going to be coarse grain. That was actually, my point was that it was getting too technical, so I wanted to be coarse grain.
00:04:34.386 - 00:04:34.682, Speaker C: Okay.
00:04:34.698 - 00:05:19.800, Speaker A: Yeah. So the general idea behind this algorithm and what makes it different, I think, from lots of other types of algorithms for this problem, is to approach this in a circuit complexity way. Okay, so try to define a kind of circuit. This is some hybrid between a boolean circuit and a circuit that takes values from FP as input. And then try to massage the circuit and do some interesting evaluation on the circuit. So that's the general idea. Okay, so we're given a set of polynomials, so these are again degree k polynomials, and I partition mentally the set of variables into, say, delta n variables and n minus delta n variables for some parameter delta.
00:05:19.922 - 00:05:20.664, Speaker C: Okay.
00:05:21.804 - 00:05:28.044, Speaker A: And so I'm going to define a n minus delta n input circuit. So that's going to be on the x variables.
00:05:28.164 - 00:05:28.804, Speaker C: Okay.
00:05:28.924 - 00:05:38.140, Speaker A: And the idea, so this circuit is doing what? It's taking an or over all possible assignments to the y variables.
00:05:38.292 - 00:05:38.916, Speaker C: Okay?
00:05:39.020 - 00:06:04.178, Speaker A: So all possible delta in vectors, it's sticking that assignment in for the y variables is checking whether for all equations, that equation is zero. So this bracket is just the indicator which outputs one or zero, depending whether the predicate inside is true. Okay, so it's just brute forcing, but over p to the delta n partial assignments.
00:06:04.266 - 00:06:05.018, Speaker C: Okay.
00:06:05.186 - 00:06:55.330, Speaker A: All right, so this is a circuit that takes in f p values, but outputs a true false value, but we can think of that as a zero one value. And so the observation is, well, satisfiability for the circuit, what does that correspond to? So it corresponds to finding a setting to the rest of the variables. So some b vector on n minus delta in the variables that makes this thing print one, and that's going to exist if and only if there is a solution to the whole system. This is sort of obvious. I mean, it's brute forcing over delta n, the variable. So if I manage to find something which makes these things true on the rest of the variables, and there's a, there is a solution to the whole set. Now, I want to sort of solve the sat problem for this kind of circuit.
00:06:55.330 - 00:07:52.670, Speaker A: That's the idea where it takes in values from Fp and outputs a true false value. And we're going to solve the satisfiability problem. So, adapting this sort of well known circumplexity work of Rezaborov and Smolensky, there is a way to randomly reduce such a circuit. So even this sort of hybrid boolean and fp circuit to a polynomial of degree, which is not too large. So here it's p times delta times n times k, but it's a single polynomial, okay? So that for any particular input I might give to this circuit, this polynomial will output the correct value, in some sense, with high probability. So what do I mean by that? I mean that whenever I stick in a b, so this is a worst case type thing. So for all b, when I stick in a b, it's going to be one.
00:07:52.670 - 00:08:52.318, Speaker A: So if it's one, then the choice over the randomness of this q, sub s b, will be non zero, with probability greater than two, three. Okay, so this thing will be non zero, probability greater than two three. And this randomness, again, is over the choice of the q, sub s, not over the particular slime. And when it's zero, the probability this is zero. This should be, sorry, this should be greater than two three as well. Okay, so the point is that, like, the non zeroness is telling us whether it's true or false with some decent probability, okay? And at a high level, the way this kind of thing works is it's just anybody who's familiar with the Rosbarov Smolensky construction could work this out very easily as an exercise. The idea is what they show is for an or and for an, and you can represent them probably with probabilistic polynomials of low degree.
00:08:52.486 - 00:08:52.822, Speaker C: Okay?
00:08:52.838 - 00:09:27.764, Speaker A: And there's some trade off between the degree that you'd like to have and the error of the polynomial, sort of like the probability of error. And so the idea is you just form appropriate probabilistic polynomials for the and, and for the or here you only really need constant degree to achieve this kind of error. Here you would want larger degree. So, degrees, so you can union bound over all these things. So like delta n k roughly a degree. So just replacing these two things are probabilistic polynomials. You can get this result.
00:09:30.144 - 00:09:31.524, Speaker B: Over all the b's.
00:09:32.264 - 00:09:39.684, Speaker A: No, over all the different terms in here. So you want to say I have a probabilistic polynomial which has this property.
00:09:40.304 - 00:09:43.084, Speaker B: Statement b for all b. I can randomly.
00:09:43.664 - 00:09:57.194, Speaker A: It's a worst case randomized algorithm. So it's like in the worst case, no matter what input I've got, the probability gives me the right answer. Over the choice of internal randomness, the probabilistic polynomial is high, the quantifiers are.
00:09:57.234 - 00:10:00.946, Speaker B: B comes first, and the random choice of q, sub s is next.
00:10:01.090 - 00:10:19.890, Speaker A: Yes, yes, yes. So, yeah, all I was saying is you would want the degree of your probabilistic polynomial be, say, constant for the or and something like delta n for this one. So you can account for all the different possible errors you might get. Cause there's like p to the delta and different things you have to account for there.
00:10:20.002 - 00:10:20.854, Speaker C: That's all.
00:10:21.354 - 00:10:22.134, Speaker A: Yes.
00:10:22.514 - 00:10:33.746, Speaker D: Historical comment, maybe two further. This part is, this reduction from the Bullang case to the arithmetic case is the part in West Wall's paper that.
00:10:33.770 - 00:10:36.962, Speaker A: Smolensky for mod two. Yes, for mod two.
00:10:37.058 - 00:10:41.610, Speaker D: The other part in Smolensky's paper is doing the lower bound for mod two.
00:10:41.642 - 00:10:41.984, Speaker A: Yes.
00:10:42.074 - 00:10:44.252, Speaker D: It doesn't matter what field. Yeah.
00:10:44.268 - 00:10:51.780, Speaker A: It does matter here. So p is arbitrary. So, no, it's not. That's why there's a p there.
00:10:51.892 - 00:10:56.652, Speaker D: Yeah. No, no. The reduction to a polynomial over p. Yeah.
00:10:56.828 - 00:11:08.104, Speaker A: It's not the same. That's why I got a p there. Yeah. I was anticipating this, and I'm telling you, you gotta. Yeah. This was Vermont, too. Yeah.
00:11:08.804 - 00:11:10.892, Speaker D: Ali Shamir, 20 years earlier, had the.
00:11:10.908 - 00:11:12.692, Speaker A: Same reduction for mod two.
00:11:12.748 - 00:11:23.748, Speaker D: For mod two, which is interesting because this was in the context of Gullar matrix multiplication, reducing it to the arithmetic case. So you can use the fast matrix multiplication.
00:11:23.836 - 00:11:24.464, Speaker C: Yes.
00:11:24.764 - 00:11:26.852, Speaker D: So it's also this.
00:11:26.988 - 00:11:34.184, Speaker A: Yeah. Yes. The random subsum trick is a different thing. Yes. But.
00:11:34.674 - 00:11:35.454, Speaker C: Yeah.
00:11:35.834 - 00:11:37.450, Speaker A: Yeah. Anyway.
00:11:37.562 - 00:11:37.826, Speaker C: Yeah.
00:11:37.850 - 00:12:14.454, Speaker A: I do think that the first person that observed the generalization to mod p was smolinsky. Okay, so here's the algorithm. So we set our parameter delta to be let's say one over 100k. Okay, we're going to end up getting some algorithm like this so that 100 will end up going there. So the idea is, given our set of polynomials, we repeat the following for some constant times n times. So we want to do something so that it will hold for all the b's. So we have some high probability statement for all the b's.
00:12:14.454 - 00:12:50.992, Speaker A: We construct this random q sub s from s. So we draw a random q sub s independently for each trial. And then we evaluate that q sub s on all possible points b. Okay, so all possible p to the n minus delta n points. All right, so we get a value each time. So we do this some constant times in time, we get some table p to the n minus delta in each time. And then we return this a solution if there exists some sort of column in this table so that it was always non zero, say, for so greater than half the times.
00:12:50.992 - 00:13:38.930, Speaker A: Okay, because here, right, we have probably two thirds of giving you the right answer. So we're just looking at if it's non zero for greater than half the time. So this is a two sided algorithm, but of course we can make it one sided by using search decision and forcing it to print something and then checking that it works. Okay, so that's the algorithm. And so, well, for one, why does it work in the desired time? So the first part is that this part, one doesn't take too long when p is small enough, okay, because of the way I set delta and because of sort of like the number of possible monomials q, sub s could have, its degree will be smallish. And so this step is actually not too arduous. It will actually be a low order term.
00:13:38.930 - 00:14:36.466, Speaker A: Now, two, this is going to more or less govern the running time here, because we're looking at p to the n minus delta n time, roughly. So the point is here, given the polynomial represented as a list of coefficients, you can just evaluate it on all of the points in f p, the n minus delta n in essentially polynomial amortized time by dividing conquer approach. No matrix mult needed for that. So that's how it runs in the desired time. And the reason why it works is just a simple Chernoff bound, union bound type argument applied to this observation here. Okay, it's going to give me the, this is going to give me the correct answer about all the possible b's, okay, so it even locates like say a prefix of the, of a solution. So this is a randomized algorithm, and you can de randomize it with some with some loss here.
00:14:36.466 - 00:15:04.402, Speaker A: I mean, some, you'll have some order k. So order k term, it depends on p a little bit, just at a really high level. You can use epsilon bias generators, say, for Fp to choose these polynomials, and you can use mod amplifying polynomials to compose these layers of polynomials over the integers. That's just a really high level idea of how the de randomized algorithm works.
00:15:04.458 - 00:15:08.574, Speaker E: Why do you need the model amplifying for the, but not for randomized?
00:15:10.964 - 00:15:15.864, Speaker A: It just turned out to be convenient. In fact, it allows us to count the number of solutions.
00:15:17.324 - 00:15:19.904, Speaker C: Yeah, yeah.
00:15:20.244 - 00:15:29.784, Speaker A: I don't know if I have like a good succinct explanation for it. I mean, there are some limits on my ability to be succinct in one slide. Yeah, yeah, yeah.
00:15:33.364 - 00:15:45.830, Speaker D: P delta Mk will equal roughly n minus one minus delta n. The trade off is that degree of the polynomial will balance n minus delta.
00:15:45.862 - 00:16:01.794, Speaker A: Yeah, yeah. Like by setting this, whatever, one over 100 thing, this degree will actually turn out to be like sort of way smaller than like the thing, but yeah, that's the idea is you want to balance like how many terms you get versus like the evaluation time. That's ideally what you would like to do.
00:16:03.634 - 00:16:05.934, Speaker C: Can we just run a pit on Pos?
00:16:06.394 - 00:16:27.738, Speaker A: A pit? I mean, no, we have some probability of error. So there could be many points in which it gives the wrong answer. We're not talking about it being identically zero on all points. It's like 4.4 point. It gives us the right answer with some decent probability. Yeah, that would be way nicer.
00:16:27.738 - 00:16:55.810, Speaker A: I mean, some reduction in pit, maybe harder to de randomize, I guess, though. Yeah, yeah, yeah. Okay. All right, so that's fairly different approach to this kind of thing. So now I want to talk about a slightly more general problem, counting the solutions. So counting the cardinality of the zero set. So we'll call this a sharp DK sp.
00:16:55.982 - 00:16:56.306, Speaker C: Okay.
00:16:56.330 - 00:17:02.214, Speaker A: It's the same as before, except I want to compute the cardinality of the solutions to the system.
00:17:03.074 - 00:17:03.866, Speaker C: Okay.
00:17:04.010 - 00:17:37.134, Speaker A: And by computing the rank of the matrix, I can also do this for linear equations. A very interesting not well known result is that if you have one degree, two polynomial over FP, you can actually count the number of solutions in polynomial time. And this goes all the way back, as far as I could trace back was Carlott's in the sixties, but even before that, like Dixon log p. Sorry.
00:17:37.214 - 00:17:39.526, Speaker B: The running time is polynomial log p.
00:17:39.670 - 00:17:43.134, Speaker A: Oh, yes, I think so. I think so.
00:17:43.174 - 00:17:44.134, Speaker C: Yeah, yeah.
00:17:44.254 - 00:17:48.114, Speaker E: But this is just the canonical form, whatever you put it on your computer.
00:17:49.074 - 00:17:53.042, Speaker A: Yeah, yeah. The fact that they're quadratic, you can put them in canonical form.
00:17:53.178 - 00:17:53.442, Speaker C: Yeah.
00:17:53.458 - 00:18:00.410, Speaker A: I mean, that works for. Yeah, for odd p. That makes it pretty easy. For even p you got. So like, for power.
00:18:00.482 - 00:18:01.090, Speaker C: Yeah.
00:18:01.242 - 00:18:05.866, Speaker A: For like, characteristic two. It's more complicated. This, I guess why I put Carlitz.
00:18:05.890 - 00:18:10.778, Speaker C: There, because he actually worked for characteristics, too. Right.
00:18:10.826 - 00:19:06.780, Speaker A: So you can generalize the algorithm on the previous slide to get a similar type of thing for counting. And this problem becomes sharpie hard very quickly. So already for degree two and f two, again by natural kind of reduction, and already for degree three over f two, it's still a sharp p hard, even when you've got only one degree three polynomial and you want to count its roots. But the reduction blows up the number of variables. So this is due to Ehrenfeure and Kropinsky, and it blows it up by quite an amount. So like maybe n cubed or something. And so the natural kind of fine grained question is, well, how hard is it so exponentially hard to count the zeros of a constant degree f two polynomial? Might we expect like a, say a 1.99
00:19:06.780 - 00:19:42.386, Speaker A: to the nice time algorithm for this? If your reduction is blowing up by like, from n to n cubed, then there's no impediment necessarily there. So, recall, finding a zero of one polynomial is relatively easy. This we can do. So it's really a problem of counting versus finding. So how hard like. So finding this polynomial time, is it exponentially hard to count? That's the question we're asking. So, building on some work that I had earlier this year.
00:19:42.386 - 00:20:18.362, Speaker A: So, this is a theorem with Bryn Maura Chapman. We can prove a rather strong hardness result. So, for all epsilon so greater than zero and c, say greater than one, we're going to look at having systems of c in polynomials on n variables. We're going to have a deterministic subexponential time reduction. So p to the epsilon n time reduction from the counting problem on cn polynomials to counting the zeros of one polynomial. Okay, whose degree has increased slightly. This is an interesting.
00:20:18.362 - 00:20:54.304, Speaker A: So the thing I want to emphasize is the reason why I kept talking about the p. The factor of p is because it's important. The factor of p is actually not here. So this is actually fairly non trivial thing. So we can go from a whole system of linearly mini polynomials to one polynomial of slightly larger degree. So the idea is that this counting solutions to the system of degree k is fine grain equivalent, because we didn't change the variables at all. In fact, the number of variables did not change, period.
00:20:54.304 - 00:21:07.768, Speaker A: We just incurred this sub exponential type, running time to counting solutions to one polynomial. Okay, now, okay, it's important to say here, you know, for completeness, if we were working over the reals, this would be really, really easy.
00:21:07.936 - 00:21:08.552, Speaker C: Okay?
00:21:08.648 - 00:21:35.332, Speaker A: If we're working over the reals, we could just take a sum of the squares of all the polynomials and let's give it zero anyway, right? It just only increases the degree by a factor of two. No big deal. Well, what's interesting is that this is working over finite fields. That's the interesting part. And it's not like just sort of doing some fermat's little theorem trick where I'm raising something to the p minus one or whatever, because there's no dependence on the field size.
00:21:35.388 - 00:21:38.300, Speaker B: What is that? Fine grained equivalent. What does that mean?
00:21:38.492 - 00:21:54.374, Speaker A: It means that they're equivalent to each other in a very strong sense that the parameter n. So if you had something to just barely beat, exhaustive search for one equation would already work for a whole system, because the number of variables did not increase at all.
00:21:55.194 - 00:21:57.274, Speaker B: So you're not going to give formal definition of that?
00:21:57.314 - 00:22:07.374, Speaker A: No, I'm not going to give a formal definition of it, no. But you can think of it as yars. You have another approach to refuting the strong exponential time hypothesis. So the idea is that, like.
00:22:10.314 - 00:22:10.626, Speaker C: So.
00:22:10.650 - 00:22:52.320, Speaker A: The idea is that the ksat problem is, is believed to require, say, essentially to the end time. You cannot improve on the base of the exponent, okay? Even by any particular constant. This is a hypothesis, the strongest time hypothesis. So as k increases, it gets harder and harder, and you, just like you, for any string of nines, you can't solve it faster. But this is saying that actually, even to solve sharp k sat faster, it would suffice to count the zeros of a constant degree. So this constant, depending on k polynomial and n variables over f two in, say, 1.99 and then time.
00:22:52.320 - 00:23:09.548, Speaker A: Okay, so I'm like just changing the number of nines here for that. But the point is, the number of variables didn't change at all. So having even like a slightly better than brute force algorithm here gives you one for the original problem. That's all? That's all, yes.
00:23:09.596 - 00:23:11.940, Speaker D: It's completely analogous to what happens with k sat.
00:23:11.972 - 00:23:12.140, Speaker A: Right?
00:23:12.172 - 00:23:17.344, Speaker D: The previous result is like, for every fixed k, you can improve a little bit on the exponent.
00:23:17.764 - 00:23:26.396, Speaker A: Yeah, yeah. You can even think of this algorithm for solving systems, a generalization of k sat algorithms. Yeah, yeah, yeah. That's a good point.
00:23:26.580 - 00:23:27.348, Speaker C: Thanks.
00:23:27.516 - 00:23:49.544, Speaker A: Yeah. All right, so this is a sort of very strong harness result. Okay, so let me say how this thing works. So first we're going to make a totally dubious assumption, no justification for, at the moment, we're going to assume the number of polynomials in our system is actually small. So epsilon, in where epsilon was something we chose because we're going to assume there's not that many polynomials.
00:23:49.704 - 00:23:50.056, Speaker C: Okay?
00:23:50.080 - 00:24:22.964, Speaker A: And then we're going to remove it. Okay, so given the number of polynomials, is not too many, here's our reduction. Okay, so I'm giving you epsilon and polynomials. Okay, so let f, so let, sorry, let v one through v p to the epsilon n be enumeration of all vectors of length epsilon n. I have two counters initialized as zero. I go through all the possible vectors in this set. So I numerate all I, okay, I form a linear combination of the ith vector with these polynomials.
00:24:22.964 - 00:24:42.394, Speaker A: Okay, so I just take all possible linear combinations of the system of polynomials I've got. Right, this is epsilon n. The vectors are linked, epsilon n. So this is just the inner product. Okay, so I'm forming this polynomial. Obviously it has the same degree as whatever the degrees of these things were. If this is k, this is degree k.
00:24:42.394 - 00:25:00.106, Speaker A: Then I'm counting the number of zeros of this polynomial. I'm adding that to some running total z. I count the number of zeros of one minus the polynomial. Add it some running total. Nice. And then finally, after all is said and done, I output z minus n divided by the total number of vectors, in this case, p to the epsilon.
00:25:00.250 - 00:25:01.946, Speaker B: This is an exact reduction.
00:25:02.010 - 00:25:03.854, Speaker A: It's an exact reduction, yes.
00:25:04.234 - 00:25:04.610, Speaker C: Yeah.
00:25:04.642 - 00:25:10.694, Speaker A: So obviously this thing is degree k if all the polynomials are degree k. So in fact, there's no change in degree here.
00:25:11.514 - 00:25:12.010, Speaker C: Yep.
00:25:12.082 - 00:25:29.998, Speaker A: And this is, so this is one oracle call to counting the number of variables didn't change. Okay, so we're good. There's another oracle called accounting. This is where. So we're making p to the epsilon n times two. Oracle calls. Okay, so why does this thing work? So let a be the set of solutions of the system.
00:25:29.998 - 00:25:42.750, Speaker A: So those assignments making all the polynomials vanish. Okay, so take any solution of this. So anything that makes all the polynomials vanish makes this capital p sub I vanish.
00:25:42.902 - 00:25:43.414, Speaker C: Okay?
00:25:43.494 - 00:25:46.288, Speaker A: And it does not make one minus the polynomial vanish.
00:25:46.336 - 00:25:46.552, Speaker C: Okay.
00:25:46.568 - 00:26:00.816, Speaker A: It makes that polynomial one. And that's true for all the vectors. Okay, so that means that every solution here gets summed up p to the epsilon n times in this thing and divided by p to the epsilon. So every solution contributes one to this running sum.
00:26:01.000 - 00:26:01.804, Speaker C: Okay.
00:26:02.104 - 00:26:09.624, Speaker A: And similarly, everything that's not a solution makes the vector of polynomials a non zero vector.
00:26:09.744 - 00:26:10.264, Speaker C: Okay?
00:26:10.344 - 00:26:24.522, Speaker A: And I'm counting up the number of times that over all possible vectors that a non zero vector becomes a zero vector. When I take the inner product. Okay, that's going to happen exactly one over p of the time that it comes zero. And exactly one over p of time it becomes one.
00:26:24.698 - 00:26:25.534, Speaker C: Okay?
00:26:25.954 - 00:26:34.254, Speaker A: So those will cancel out. So it's because I'm counting up the exact same number there, they just completely cancel. And so every non solution contributes zero.
00:26:35.074 - 00:26:35.986, Speaker C: Okay?
00:26:36.170 - 00:26:43.162, Speaker A: All right. So under our assumption, this output is a correct counter.
00:26:43.288 - 00:26:43.894, Speaker C: Okay.
00:26:44.014 - 00:27:09.274, Speaker A: Of course, we've got like epsilon in there. So we would like to have, you know, some arbitrary constant times in. Okay, so it's a very, very simple reduction. Okay? So let's, let's see how to reduce, reduce to the case of epsilon and polynomials. So we're going to start with c in polynomials, and we want to end up with epsilon and polynomials. So the number of solutions to the original system equals the number of solutions to the new system.
00:27:10.034 - 00:27:10.894, Speaker C: Okay?
00:27:11.594 - 00:27:46.464, Speaker A: So our first try is to partition a set of polynomials into epsilon and groups. So each group has, say, order c over epsilon polynomials. So just group them up naturally and form a single polynomial which is supposed to vanish if and only if all the polynomials vanish. This is the first try. All right, so this is, so people who work over prime fields, this is a very common expression that you see, this is Fermat's little theorem being applied here to make sure this is always zero or one. It's a very standard kind of trick, actually. But this actually gives us degree P.
00:27:46.464 - 00:27:55.396, Speaker A: So that's not going to give us what we want in the end, it's going to give us. So I promised you ck over epsilon, there's an actual factor of p because there's p minus one there.
00:27:55.580 - 00:27:58.364, Speaker B: But even for constant b, the result is interesting.
00:27:58.524 - 00:28:12.584, Speaker A: Even for constant p, this result is interesting. Yeah, it was interesting enough for Sosa. Yeah, yeah, yeah. So the point is that like. Yeah, so this polynomial vanish if only, if all the polynomials in a group, in that group, it corresponds to vanish.
00:28:12.664 - 00:28:13.352, Speaker C: Okay?
00:28:13.488 - 00:28:19.408, Speaker A: And so any solution, original system. Is there any solution? New system and non solutions are non solutions.
00:28:19.536 - 00:28:20.244, Speaker C: Okay.
00:28:20.704 - 00:28:35.970, Speaker A: Multilinearization of this thing to get rid of p. That's not how we do it. But maybe you do. I mean, I mean, yeah, so this is kind of like, right? If I took the product of them, that would compute the OR. But I won't actually compute the.
00:28:36.002 - 00:28:36.194, Speaker C: The.
00:28:36.234 - 00:28:40.266, Speaker A: And kind of over them. So that's a little subtle. So, yes.
00:28:40.370 - 00:28:47.174, Speaker E: So this is kind of like a disjunction. So it's. If solution goes to zero for this polynomial.
00:28:47.554 - 00:28:48.810, Speaker A: No, this is like an and.
00:28:48.922 - 00:28:49.530, Speaker C: Yes.
00:28:49.682 - 00:28:52.770, Speaker A: Yeah, yeah, yeah, yeah. So disjunction would be easy. Just take the product of them.
00:28:52.842 - 00:29:01.162, Speaker E: Is it important for you that it's. It's zero one, for instance, like, zero and any non zero guy. Would it work?
00:29:01.258 - 00:29:03.730, Speaker A: Yeah, it's not important. And that's actually what we exploit.
00:29:03.802 - 00:29:04.178, Speaker C: Right.
00:29:04.266 - 00:29:08.346, Speaker A: So, yeah, there's like, this is sort of over constrained because it gives us a zero one value.
00:29:08.410 - 00:29:10.626, Speaker E: The polynomial does the work.
00:29:10.730 - 00:29:16.494, Speaker A: The determinantal polynomial. Okay, well, we'll see if what I've got is the determinantal. I don't think so.
00:29:18.874 - 00:29:20.274, Speaker B: I think we should let him finish.
00:29:20.354 - 00:29:22.218, Speaker A: Yeah, I got, like, a few minutes left, so.
00:29:22.266 - 00:29:22.894, Speaker C: Yeah.
00:29:23.664 - 00:29:50.474, Speaker A: Okay. So, to improve the reduction, I have something called Brynmore's Lima. Brynmore's my PCC. So the idea is, if you're given, say, two to the t polynomials, we can construct a degree d. You can construct a polynomial of degree two to the t times D, which does the job. So there's no factor of p. The way this works is it uses quadratic residues and actually non residues modulo pull determinant.
00:29:54.854 - 00:29:56.206, Speaker B: I don't really have to cut you out.
00:29:56.230 - 00:29:58.990, Speaker C: Okay. Okay. Okay.
00:29:59.142 - 00:30:26.604, Speaker A: So, anyway, yeah, let me skip the beautiful proof of Bryn war's theorem. So, two open questions are to, obviously, to improve this running time, improve it for, like, all values of p and and k, which we haven't yet done. And there's some heuristic reasons to believe that actually you could improve this slightly better, and that would, in fact, improve the best known algorithms for k set, whatever super strong ETH means.
00:30:27.184 - 00:30:28.840, Speaker B: Nobody believed that, right?
00:30:29.032 - 00:30:33.304, Speaker A: Nobody. That's a little. I don't know if nobody believes it, but, yeah.
00:30:33.464 - 00:30:34.864, Speaker C: Okay. Yeah.
00:30:34.944 - 00:31:02.696, Speaker A: I don't know if it's a straw man either, but I don't know. But, yeah. So the question is, could you do it with no blow up in the degree? Could you get a reduction? You don't have to necessarily go through algebra. You could do some nice algorithmic stuff. So, yeah, our algorithm blows up by some factor. If the answer were yes for k equals two, if we could preserve the agree with some extra time or reduction, then ETH would be false. So probably not.
00:31:02.696 - 00:31:05.640, Speaker A: Mainly because counting with one polynomial can be done in poly time.
00:31:05.752 - 00:31:06.312, Speaker C: So.
00:31:06.448 - 00:31:08.804, Speaker A: Okay, that's all. Thank you.
00:31:24.984 - 00:31:30.364, Speaker D: From KSAT to improving this savings in systems of polynomial equation.
00:31:33.864 - 00:31:55.224, Speaker A: If you could improve KSAT, can you improve system? So I know that if you can prove the system, you can improve KSAT. But you'd like to know if you can improve KSAT, can you improve? It's a good question. It's a natural one. I'm not sure. I hadn't thought about it. So you have to think about it for a few minutes.
00:32:00.804 - 00:32:03.564, Speaker B: Okay, Max, let's thank Brian again.

00:00:00.400 - 00:00:53.444, Speaker A: Yeah, thanks for letting me speak here. As was mentioned, it's about a problem that was posed at one of the problem solving days at assignments. So let me first explain the problem very briefly. So we are interested in spectra, hetero cones. So we recall what that is. We take some real symmetric d by d matrices, a one up to a n, and then we look at all points x in r to the n such that the corresponding linear combination of these matrices is positive semi definite. So this is some nice convex semi algebraic set in rn.
00:00:53.444 - 00:01:49.384, Speaker A: And it's interesting because it's the feasible set of the semi definite program. And yeah, it's a generalization of polyhedral cones because we can, for example, take a of x to b or all the a's to be diagonal matrices. Then this is just the solution set to finitely many linear inequalities. So now question I'm interested in is which convex sets in r to the n are spectrohedral. So which can be described with such linear matrix inequality. So there's one, one rather restrictive necessary criterion that I want to explain. Now let's look at our spectrahedral cone.
00:01:49.384 - 00:02:45.284, Speaker A: Since it's convex, we can assume that it has non empty interior. Otherwise we can just pass to some strict linear subspace, and then we take some point in the interior of s. Then after maybe conjugating this matrix polynomial from the left and right invertible matrices s and s transpose, we can assume that at this point, this matrix polynomial is the identity matrix. Now let's take look at the following polynomial. Let's take the determinant of this. So this is a polynomial in x one to xn, and I claim that it has the following properties, which makes it hyperbolic in this sense. So it's a homogeneous polynomial and it's hyperbolic with respect to e in the sense that it doesn't vanish at e.
00:02:45.284 - 00:03:46.058, Speaker A: This is clear because determinant of the identity matrix is one. And whenever we restrict this polynomial to any line in real line in direction of e, then the resulting univariate polynomial has only real zeros, and to polynomial having these properties, one can associate the hyperbolicity cone just a set of all points, that this univariate polynomial has only non negative roots. So in our case, when h is this determinant, we just get restricting to these lines. We just get the characteristic polynomial of a real symmetric matrix, which has, of course, only real eigenvalues. So this is fine. And the hyperbolic cone is when this polynomial has only non negative roots. So when a of v has only non negative eigenvalues.
00:03:46.058 - 00:05:07.638, Speaker A: So this is exactly the set we are interested in, the hyperbolicity cone. So this is a necessary criterion for a set to be a spectrahedral cone, that you can find it as the hyperbolicity cone of some hyperbolic polynomial. Then there's a major open question in this context which asks if this is also a sufficient criterion. So if you have any hyperbolistic cone, can you describe it using linear matrix inequalities? So it's, it's true when you have only few variables or small degree, but in general, it's open. So, yeah, so let's see, how can we get hyperbolic polynomials? One way we have already seen, we take this determinant of such a matrix. So this is already some interesting class of hyperbolic polynomials, includes spanning tree polynomials of graphs, or more general, the basis generating polynomials of regular matrix. And we have seen that these hyperbolic coins of these polynomials are clearly spectra hetero.
00:05:07.638 - 00:06:03.536, Speaker A: So if we want to test this conjecture on some other hyperbolic polynomials, these are, I mean, these are not the ones. Check it. So how to get other hyperbolic polynomials? So there's some operations preserving hyperbolicity. So what I want to explain now is by taking derivatives. So if you have a univariate polynomial, say of degree d, which has only really real zeros, so d real zeroes, then I claim that its derivative also has only real zeros. So this is in fact the direct consequence of Hollis theorem. So, between, which says that between each two real zeroes of p, there must be a real zero of p prime.
00:06:03.536 - 00:07:03.938, Speaker A: So there must be d minus r1 zeros of p prime. And this is the decrease, this is fine. And then we can translate this to this multivariate setting of hyperbolic polynomials. And we get that if a polynomial is hyperbolic with respect to e, then its directional derivative, which I denote like this in direction of e, is also hyperbolic with respect to e. So now we can take these determinantal polynomials, of which we know that they are hyperbolic, and take a derivative and ask if the hyperbolistic cone of the resulting polynomial is still spectra hetero. And of course, we can do this several times. We can take higher derivatives and still get the hyperbolic polynomial.
00:07:03.938 - 00:07:55.214, Speaker A: We ask, is the hyperbolic cone spectrohedral? So, and this is the question that was asked at the problem solving day, I think, by Nikhil. And it's, this is the content of the talk is the answer to this question. So, yeah, okay, so let's look at this question. So, first of all, we restrict to some special class of polynomials. So I claim that it suffices to show this claim for the generic d by d symmetric matrix. And by this I mean symmetric matrix. Each entry is its own variable.
00:07:55.214 - 00:09:03.304, Speaker A: So the entries of x are the variables x ij, where I is smaller or equal than j. And so this is sufficient to prove it for this, because if we want to prove it for general such linear matrix polynomials, we can just restrict this one to a suitable linear subspace and we get this one. So we look at this for any size d and any k between zero and d. We look at this k is derivative in direction of the identity matrix of the generic symmetric determinant. So let's try to express this polynomial in some other way. Look at the characteristic polynomial of x. You can write it as a polynomial in t whose coefficients are polynomial or depend polynomially on the entries of x.
00:09:03.304 - 00:09:55.642, Speaker A: It's chosen in such way that pk is homogeneous of degree k. For example p one is then the trace of x and pd is the determinant of x. And now if we do like Taylor series expansion of left hand side, we see that up to some scalar factor, these coefficients pk are exactly the polynomials we are interested in. Okay, but then there's also another way to look at these coefficients. So if you have a univariate polynomial, then the coefficients are just the elementary symmetric polynomials in zeros. The zeros of this polynomial in this case are the eigenvalues of x. So we denote by lambda of x the vector of eigenvalues of x.
00:09:55.642 - 00:11:17.332, Speaker A: And then these polynomials we are interested in, pk, they are just the elementary symmetric polynomials in the eigenvalues of x. And this will be the description we want to look at. So, are there any questions so far? So in any case, if you have questions, please just shout in or write in the chat. Okay, so this operation like here, having a symmetric polynomial and plugging in the eigenvalues of a matrix, this gives us an another operation that preserves hyperbolicity. So to be more precise, so that we take a symmetric polynomial h, so symmetric with respect to permuting the variables x one to xn, and assume that it's hyperbolic with respect to the all ones vector. Then we can define the following function on d by d matrices, which takes such a matrix, takes its vector of eigenvalues and plugs it into h. So this is well defined.
00:11:17.332 - 00:13:09.394, Speaker A: So, I mean, the only problem that could arise is that it's not well defined. Which order you want to take the eigenvalues but since it's a symmetric polynomial, this doesn't matter. Then it's not hard to show that this polynomial h, or this function h, it is a polynomial in the entries of the matrix x, and it's hyperbolic with respect to the identity matrix. This polynomial and the hyperbolicity cone of this new polynomial capital h is just the set of all matrices x whose vector of eigenvalues is in the hyperbolistic cone of our original polynomial that we started with. So this is some older result due to Bausch, Bueller, Lewis and send off, and we can apply it now to our situation. So recall that we are interested in the hyperpolysic cones of these derivatives, and by our previous observation, this hyperballistic cone consists of exactly those matrices whose vector of eigenvalues whose spectrum is in the hyperbolistic cone of the corresponding elementary symmetric polynomial. So using this observation and determinantal representation due to Raman Sanjal of this elementary symmetric polynomial of degree d minus one in d variables, James Saunderson could prove that the first derivative of this determinantal polynomial is spectra hetero.
00:13:09.394 - 00:14:36.928, Speaker A: Now, Peter Prentine constructed a spectrohedral representation of the hyperpolysic cone of all elementary symmetric polynomials. So there is, I think hope to generalize this method of James Saunderson to describe the hyperbolistic cones of arbitrary derivatives of dedics. So the best possible result would be of course the following. So if we, let's say we have any spectra, he tried cone which is symmetric under permuting the coordinates, then we can look at all symmetric matrices whose eigenvalues satisfy the linear matrix inequality. And we want that might ask if this set is always spectra hetero. So of course by this result from one slide ago or two slides ago, this set is at least a hyperbolistic cone, because s is a hyperbolistic cone. So the generalized Lux conjecture would imply that this is a spectrohedral cone.
00:14:36.928 - 00:16:22.304, Speaker A: But I think in this, even if we knew that this is true for some abstract reason, I think would still be interesting to have a concrete construction which takes such as symmetric s and builds a spectra he trial representation for this spectral set here. And so the answer to this question is also yes, if s is a symmetric polyethylene cone. This also this was proved by Rahman Sanyal and James Saunderson in the recent preprint and the goal of this talk is to unfortunately, not to show that this is true in general, but to give a sufficient criterion on S which guarantees that this is a spectra heterocon and this criterion is a representation theoretic criterion. So let me. So, yeah, so let's recall that if you look at representations of the symmetric group as n, then it's known that each representation is a direct sum of irreducible representations. And the irreducible representations of sn have been classified. They are in bijection to partitions of n, and I call a representation of sn short if it corresponds to a partition of length at most two.
00:16:22.304 - 00:17:01.944, Speaker A: So for n equals four, these three are short representations. So this is like the, this young diagram corresponds to the partition four or four. This is three plus one. This is two plus two. So these are all short representations because they have at most two summons in the corresponding partition of n. These two are not short. So this is two plus one plus one, and this is one plus one plus one plus one.
00:17:01.944 - 00:18:04.262, Speaker A: Okay, so, questions so far. Okay, so yeah, so I call the representation short if it consists only of irreducible representations corresponding to partitions of length at most two. So the, I think the basic example of the short representation of, the most important example for this talk is the space of homogeneous multiefine polynomials. So polynomial is multi ethyne. If each monomial that appears in this polynomial is, is square three, so each variable appears with degree at most one. And this vector space is sn representation. So sn acts on the space by permuting the variables.
00:18:04.262 - 00:19:46.874, Speaker A: It's clear that if you permute the variables of the multi affine polynomial, it stays multi affine. Then, using elementary representation theory, one can show that this is in fact so the space of degree d multi affine polynomial or homogeneous degree multi affine polynomials is in fact induced representation of some smaller group of the trivial representation of some smaller group. And then one can apply Young's rule to get a decomposition into irreducible components. I will be more precise on this, more explicit on this decomposition later. So now we know what a short representation is. So the main result is that if we have such a short representation of Sn and linear map from r to the n to the set of symmetric bilinear forms over this vector space v, which is compatible with the respective actions of Sn, then we can take the preimage of the set of positive semidefinite bilinear forms here. This will be a symmetric spectra heterocoan in R to the n, and under these conditions the corresponding spectral sets set of all symmetric matrices whose eigenvalue is in S is a spectra heterochrom.
00:19:46.874 - 00:21:09.744, Speaker A: So from this result we can also then deduce our result that we were originally interested in. So we can take Petr's representation of the hyperbole cones of elementary symmetric polynomials and show that they in fact come from such a short representation. And then apply the theorem and we get a spectrohedral description of these hyperpolycytic cones. One can do some analysis on the size of the size of this of the matrices describing this hyperglycem will be like of this magnitude. So for fix the number of derivatives k, then the size of the hyperbolic of the matrices for describing the hyperplistic cone will grow only polynomially. If you increase k and n simultaneously, then to be exponential. So in the last few minutes, let me give some idea on the proof of this main theory.
00:21:09.744 - 00:23:06.234, Speaker A: So the more precise statement is the following. So we take a short representation and such as n linear map and then we can to v we can associate so v is a representation of Sn, we can associate to it a representation of the orthogonal group and map, which is on linear. So it's compatible with the action of the orthogonal group from the space of symmetric matrices to the symmetric bilinear forms on W, which is compatible with our original map. So a matrix here is sent to something positive semi definite here, if and only if the vector of its eigenvalues is sent by our original map to something positive semi definite. So how, how can we do this? So we have already seen that this space of multiefine polynomials of homogeneous of degree d decomposes into b plus one irreducible representations. I can also tell you which subspaces of this space are these irreducible sub representations. So this, the one corresponding to the partition n minus ii consists of all polynomials which are in the kernel of the of the d minus I plus one fold application of the derivative in direction e.
00:23:06.234 - 00:24:39.456, Speaker A: So if you take d minus I plus one times derivative of polynomial here you get zero, and moreover it is in the orthogonal complement of all those polynomials where already the d minus I derivative vanishes. This one can. So since the e, the all ones vector is invariant under the symmetric group, it's not hard to show that these are in fact sub representations. And then by the knowledge that the decomposers in d one components, we can prove this. So now we want to get from this some representation of the orthogonal group, and for this we replace the multiefine polynomials of degree d by the vector space spanned by the d times d minus of the generic symmetric n by n matrix. So why might this be a good idea? So if you restrict the elements here to the space of diagonal matrices. Then you exactly get back this vector space, and then using some representation theory, you can decompose this again into irreducibles.
00:24:39.456 - 00:25:49.924, Speaker A: It's not important what this EII stands for. It's just important to note that this space of minus of the symmetric matrix also decomposes into d plus one different irreducible components. And these irreducible components can be described in the very same way as the ones in the multi affine case. It's the kernel of the d minus I plus one fold derivative. Now in direction of the identity matrix intersected with the orthogonal complement of this. So these on representations are kind of very similar to these sn representations, and this is what we do. So if we have short representation v, we decompose it into irreducibles and replace each of these irreducibles by the corresponding irreducible representation of on that we get in this manner.
00:25:49.924 - 00:27:21.366, Speaker A: And yeah, then we also want to replace our map phi by some on linear map. For this we have to understand what kind of maps can we have from r to the n to space of symmetric bilinear forms on a short representation. So for this we observe that if v decomposes into irreducibles, then the space of symmetric bilinear forms decomposes into blocks. And then we have to see what kind of Sn linear maps we can have to all of these blocks. So we have to understand Sn linear maps from rn to symmetric bilinear forms on an irreducible short representation and to the homomorphisms from one irreducible to another irreducible representation. And now I'm running out of time, so let's look at these ones. So one can show that basically these are sn linear maps from rn to this function of this homomorphism space is basically given by the derivative.
00:27:21.366 - 00:28:51.034, Speaker A: So point in r to the n is sent to the directional derivative in direction a and, and we have seen that we can view these vector spaces as subspaces of the multi affine polynomials. And then it makes sense to apply this derivative operation and then we want to replace it by something which is compatible with the orthogonal group. And for this we just take again the derivative, but now in direction of a matrix rather than just a vector. And something similar works for the symmetric power. And then we can construct first from any v such a representation w of o, and then from any map which is sn linear, get such a map which is o linear. And then we can show that this actually satisfies these conditions. And this proves the main result, which I've already seen, has as a consequence this problem, whether or not these derivatives of detonantal polynomials have a spectratural representation.
00:28:51.034 - 00:29:00.824, Speaker A: Okay, time is up. Thanks for the attention. And yeah, are there any questions?
00:29:11.524 - 00:29:32.004, Speaker B: Thanks a lot, Mario, really nice talk. One question is, do you have a. So, in your talk, or you considered iterating derivative with respect to the hyperbolicity direction, but do you have a sense of whether you could take mixed derivatives with respect to different directions in the hyperbilicity cone?
00:29:36.304 - 00:30:18.904, Speaker A: Yeah, this is a good question. I don't know. I mean, I think that this, so this method using this orthogonal group symmetries, I think this will not work if you go into different directions, because I mean, only the identity matrix is. Yeah, I don't know, this would be a good next question. Also, not taking just derivatives of, of determinantal polynomials, but of hyperbolic polynomials whose hyperbolic cones are spectrohedral. It would be nice to harm that. Yeah.
00:30:28.124 - 00:31:20.804, Speaker C: So yeah, I had sort of the same question as Nikhil, but maybe a twist on it. So your result, when you have just one power of a directional derivative, then it corresponds to these elementary symmetric polynomials. But if you do it for, say. Yeah, if you do it for two, say just yes, you have a power of one directional derivative and a power of another one. Would it correspond to some primitive then not elementary symmetric polynomials, but some other. Yeah, some other primitive hyperbolic polynomials that you need to show has, have this spectrohedral representations in your, but maybe more special spectrohedral representations that fit your sort of schema.
00:31:23.744 - 00:32:51.604, Speaker A: So, yeah, I mean, what would maybe be, I mean, let's say, I mean you can, you could for example, maybe take some symmetric polynomial, which is not the power of x one plus xn, and then plug in the derivative operations like the, the partial derivatives into this polynomial, you know what I mean? Like, like taking for example, the elementary symmetric polynomial, and replace xi by partial I. So maybe this would be a good, I don't know if this method would work, but then you would keep this symmetry. So maybe this would work, but I don't know if it preserves hyperbolicity. So I guess you will be the, the one to tell me if it's preserve cyberpolicy if you do this.
00:32:55.464 - 00:33:06.616, Speaker C: Yeah, I can tell you from the top of my head right now because. Yeah, but presumably, thanks for your great work.
00:33:06.640 - 00:33:08.684, Speaker A: Thanks by the way. Thanks.
00:33:14.204 - 00:33:28.984, Speaker B: And this, this bound on the dimension. So I guess in the case of elementary symmetric polynomials, if you allow projections, you can reduce that bound a lot. I don't know. Is there a sense of whether you can do that here?
00:33:32.044 - 00:33:34.156, Speaker A: You mean if you allow for projections?
00:33:34.340 - 00:33:42.014, Speaker B: If you allow projections of spectra Hydra, then I mean, I guess I would. Just remembering the situation for elementary symmetric polynomials.
00:33:42.954 - 00:33:57.734, Speaker A: Yes, for these derivatives, I think this is some work by Parillo and Saunderson. Then I think it also is very small, like polynomial in n or something.
00:34:00.514 - 00:34:04.014, Speaker B: So by allowing projections, they can do it.
00:34:05.974 - 00:34:32.293, Speaker A: By the way, if you allow for projections, then there's a general statement is true, just shown by Sanjal and Sonderson, that if you have a symmetric spectra heedral shadow, then the corresponding spectral set, like all matrices with eigenvalues, is in this original set. This is then again a spectrohedral shadow. Okay, projections. This is very well behaved.
00:34:34.513 - 00:34:37.933, Speaker B: That's by Sunyal and that's by who?
00:34:38.633 - 00:34:39.721, Speaker A: James Saunderson.
00:34:39.817 - 00:34:42.173, Speaker B: Saunders and Sonya, yes.
00:34:44.513 - 00:35:05.954, Speaker D: Any other question, Mario? So, and with regards to this last result that you said, do you know if the size of the spectra hydro shadow is comparable? Like is it polynomial in the size of one or the other? Or they just prove that it is a speculator shadow without giving bounds on the size?
00:35:06.734 - 00:35:13.674, Speaker A: I don't know. Yeah, I would have to look at the paper. I suspect that they have good bounds in this case.
00:35:15.814 - 00:35:16.494, Speaker D: Okay, thanks.

00:00:01.520 - 00:00:28.800, Speaker A: So, first of all, let me welcome all of you to this workshop. It's a real pleasure to have such a great group participating here. I'd also like to thank, like Rahul did, the Simons foundation for hosting it and Daria for supporting it. And then he has a great man. So congratulations to Jean Ann. Knowing Jean, of course, retirement means nothing. He's as active as ever.
00:00:28.800 - 00:00:48.860, Speaker A: So I think I first met Jean, I think around 1984 or so. I took a class from him, I remember. And so I've known him for almost like 60% of my life. And Cardima is a close friend, apart from being a colleague. And it's been one of the high points so far. So congratulations. So my job here right now is just to serve as, I guess, the master of ceremony.
00:00:48.860 - 00:01:13.510, Speaker A: So the first two lectures. And the first speaker is going to be Professor PR. Kumar. Looking around me and seeing this crowd, I think it's perfectly obvious that Kumar needs no introduction. So I guess all I'd say is that he was already a legend in research when I was a graduate student. So that should give you some idea of how great he is. And he's always been held out by internal discussions as one of the exemplars of research style.
00:01:13.510 - 00:01:38.698, Speaker A: There's at least three major things that all of us know about. So one is definite work in adaptive control from his early career. Then all his work on manufacturing lines, where these fantastic glue kumar counterexamples. And various questions that are still being studied. And then more recently, the work on scaling laws for wireless networks. And there's lots of research topics that have had a huge impact. I'm also leaving out.
00:01:38.698 - 00:01:41.294, Speaker A: So on that note, let me hand it over.
00:01:46.914 - 00:01:47.934, Speaker B: Is this on?
00:01:48.314 - 00:01:49.454, Speaker C: Yours is on.
00:01:49.954 - 00:02:14.914, Speaker B: I don't need this. Right? So it's a great honor to be here for Jean's retirement. But I think for people like Jean and Praveen and all this word retirement doesn't mean retirement. It probably just means that you won't have a class every semester. And I'm sure he'll be applying to deria for contracts and so on. So. Yeah, so we need to redefine this word.
00:02:14.914 - 00:02:51.930, Speaker B: Okay. So, you know, John has had an illustrious career of research achievements. And I just thought I'd mention a few of them that, I mean, to me, are just things that I'll always remember. Beautiful early work on flows in queuing networks, characterizing when they're Poisson, when delays are independent. There's this non overtaking condition and this little gem of a work I really like. I mean, all of you know, queuing networks know that if you have feedback, the process is not Poisson. And it's always a mystery.
00:02:51.930 - 00:03:24.594, Speaker B: I mean, why is it? It's a horrible process. It is not markovnial, none of those things. But yet it has this geometric steady state distribution. And I think Jean's beautifully simple explanation of adding a delay and then taking the delay going to zero is just fantastic. So very unnoticed thing, small note probably, but a jewelry. Then all this. Very nice work on quick simulations with champ and so on, swapping of arrivals and services and so on.
00:03:24.594 - 00:04:02.794, Speaker B: Also very elegant use of coupling, etcetera, to prove results. In fact, there was a paper about 40 years ago or so that me and my student wrote a humongous long paper. And I think John followed it up with a, I don't know, a couple page short proof based on coupling. Fantastic multi arm bandits. Again, simple proof interchange, even to that well studied area. Their proof was very, very nice. Then, of course, more recently on CSMA, seminal work on Max weight for input cube switches in the early days of ATM.
00:04:02.794 - 00:04:41.766, Speaker B: God knows what happened to ATM. But decoupling, decoupling, I think it lives on in mpls or something like that. Decoupling bandwidth, this notion, and then more recently, network security, economics of networks, network games and so on and so forth. But more also than the research. He's also been a role model for research values, not just in what is a minimum publishable unit, but also in the presentation style and very high standard for theoretical results. Role model for research. His papers are completely shorn of adornment.
00:04:41.766 - 00:05:10.758, Speaker B: In fact, I was tempted to coin a word today and define a new word. So somebody, if you want to use this in future works, credit me with it. Walrand, I suggest, is an antonym of the word hype. And that's not just hype, doesn't mean opposite, doesn't mean understatement. There's also some beautiful simplicity, getting to the heart of the matter, etcetera. So all his papers are just absolutely to the point. Okay, explain.
00:05:10.758 - 00:05:28.834, Speaker B: Get to the key idea. In the simplest possible way, no sentence is wasted. But that also means that you have to read each and every sentence. Don't skip one sentence, or you'll miss a whole chapter in somebody else's book. And in the same style. Lots and lots of books. Okay, again.
00:05:28.834 - 00:06:01.104, Speaker B: And exemplary understatement. Modesty. So to Waldron, is the antonym for hype. And this, I put an exclamation mark because I would not have bet a penny on this, but he's also been a very successful entrepreneur and continuously held a lot of very high standards for everybody to emulate, both in research and dissemination. Fantastic. And it's a great honor to have known him for so many decades. It's a smaller percentage of my life than Venkat's, but longer period.
00:06:01.104 - 00:06:50.896, Speaker B: Okay, so you know, a long time ago I was giving a talk, we had a Murie, we had a couple of muris, Neshroff had a muri, Jean had a murie, and we used to have presentations. And I was giving one talk once on some delays or something, and John asked me, what about the strategic case? At that time I didn't have an answer, but in a totally different area, I've been looking at some strategic things, so I thought I would talk about that. And as you all know, this is the work of my student k Ma, who is somewhere. Where are you, K? Is there? So any questions, please ask him. Okay, so what is this problem? So it's motivated by the problem of power systems. So there are many, many generators and loads. There's nuclear power plants, there's coal, there's wind, there's hydro power, and there's many loads.
00:06:50.896 - 00:07:30.220, Speaker B: You can have storage services, which may store and sell industrial loads, commercial loads, load serving entities, which are aggregators of many, many small loads, like an Internet service provider or something. And they all have different dynamics, uncertainties, costs and rewards. So for example, nuclear power plants like to maintain a constant output. Coal power plants, you may want, you can ramp them up, but they may take a certain time. So you have to make decisions on when to start ramping and so on. Wind, random hydropower, also random, okay, load serving entities. So this is like an Internet service provider.
00:07:30.220 - 00:08:26.710, Speaker B: You collect together a bunch of smaller loads, say homes, and then you exploit the flexibility on when to turn acs on or off, etcetera. And then thereby you try to match supply, because big name of the game when you use renewable power is that you cannot adjust supply, so you have to change demand to meet supply. So these are trying some kind of an aggregator model, then you have commercial models. So commercial company like Walmart may decide to pre cool its, its store in the morning and then cut it down at the afternoon when its power is not expensive, and then turn it off entirely at night. Whereas an industrial load may do something else, a storage service may decide to buy power when the price is low and then sell it when it's high and so on. So there are many, many many entities. And the point is that by and large you need to exactly balance power and generation and consumption.
00:08:26.710 - 00:09:06.128, Speaker B: There's a little bit that you can store in the inertia of the generators and also in the heating of the transmission line. But by and large, you have to maintain balance at all times. So you have all these stochastic entities, some controllable, some not, that you have to balance. And there is a thing called a system operator in the US. It's an, in many places, an independent system operator called sitting right there, ISO. And that the job of that system operator is to maintain balance at all times, but maximize social welfare. Social welfare is the sum of the utilities of everybody, okay? And we also have some objectives.
00:09:06.128 - 00:09:43.196, Speaker B: The we do not want to subsidize the, so we want to maintain budget balance. And also things like individual rationality. That is, somehow the pricing structure should be that people will participate in the market, not drop out. And also, even though there are things like, which ensure truth telling, you want to charge a fair price. So I'm going to call that, you want to charge the Lagrange multiplier. So I'm going to call that Lagrange optimality. And you need to do that without knowing the details of all these entities, the details of their models, their internal state, stochastics, etcetera.
00:09:43.196 - 00:10:31.014, Speaker B: Now of course, ISO can ask them, but they can lie. Example Enron. And so the question is, how can the system operator operate? That's a fundamental problem that k has been looking at. So the mathematical problem is there's a bunch of stochastic dynamical systems, standard state control noise, and the social planners goal is to maximize the, there is a finite time horizon, there are a capital n agents, these are the utilities of the agents. And it wants to maximize the sum of the utility over a horizon of all the agents. And while maintaining balance at all times, total consumption equals generation without knowing dynamics, utility functions, states, etcetera. So that's the problem.
00:10:31.014 - 00:11:49.614, Speaker B: Now in the deterministic case, there are solutions for this. Suppose the agent has a utility function and it can lie and bid some other utility function. Then all of you are familiar with the VCG mechanisms. We can construct a mechanism where the agent has to pay a price, make a payment PI, and the net utility, or the quasi linear net utility is the utility derives from the consumption of generation minus the payment and the allocation. So after these people bid, the central planner chooses the allocation to maximize the social welfare or the reported social welfare. And this payment, you like to define it in such a way that each agent internalizes the social externality. And so the VCG mechanism has a certain form of a payment structure.
00:11:49.614 - 00:12:44.684, Speaker B: Basically, as I said, you internalize other peoples utility and it ensures incentive compatibility. That is, truth telling is a dominant strategy. And if it is unique, then you will do that, assuming some kind of rationality. Maximize, it is social efficient. That means it maximizes social welfare. And there is a more general mechanism where this part of the payment can be any function, not including eyes own reported utility. So the, so this deterministic static case can be extended to deterministic dynamic cases in a very straightforward way, or simply by looking at the entire open loop sequence as a decision.
00:12:44.684 - 00:14:01.642, Speaker B: So it extends immediately, but, and it extends so that you, when you report, I can ask you to report your dynamics, your initial conditions, everything, and then I can ensure truth telling is optimal or dominant. But in the stochastic dynamic case, the states of the agents are private random variables, and the social welfare, for optimal allocation, I need to know the states of these private systems. So the social welfare planner needs to ensure that agents reveal their states. And in fact, this is the key part, because there are disturbances and randomness occurring all over the place. When you are dealing with wind and consumers and behaviors and so on, you want to take these disturbances into account in pricing and so on. I mean, if a turbine blade breaks, or there's some excess wind somewhere or whatever, so you want them to report the states, their own states, but there's difficulty. Suppose the, we will consider the case where the utility function and the dynamics are known.
00:14:01.642 - 00:15:09.604, Speaker B: And suppose the social planner asks the agents to report their states. Then the natural extension of the VCG mechanism is just to extend it by taking into account the cost over the time horizon and putting in some conditional expectations where u star is the optimal solution to this stochastic control problem. But the problem is that truth telling forms a sub game, perfect Nash equilibrium. But it's not a dominant strategy. Okay? In other words, if everybody else is telling the truth, then you should respond truthfully, but it's not dominant, because you could declare your states in a stochastically inconsistent way with the dynamics. So all this dynamic programming sort of optimality that you do just goes out of the window. So there is a fundamental obstacle in trying to extend VCG from deterministic to stochastic dynamic.
00:15:09.604 - 00:15:24.432, Speaker B: Fundamental obstacle. Okay, there's yet another. We are ambitious. We even want to do more things. We also want to achieve budget balance. That is, ISO should not need to subsidize the agents, and we want. So that is budget balance.
00:15:24.432 - 00:15:46.384, Speaker B: The total payments are greater than or equal to zero. Individual rationality means that by participating you don't get negatives, net utility. And there's another obstacle. There's no mechanism that can satisfy all these properties. Incentive compatibility, maximization of social welfare, budget balance and individual rationality. So that does not exist. And I want one more objective.
00:15:46.384 - 00:16:19.628, Speaker B: I want them to charge a everybody to be charged a fair price. That is, they should be charged the Lagrange multiplier, which would be the price in the absence of any strategic considerations. And lying. Okay, so what can the social planner do? That's the issue. So is there any hope? And it turns out there is hope in almost, I think this may be the only case in which there is hope. It turns out that the good old linear quadratic gaussian problem, I don't even think you need gaussian Gaussian. You can, there are certain possibilities there.
00:16:19.628 - 00:17:01.324, Speaker B: But the good old LQG case, actually, you can actually extend this theory. So this is the standard LQG problem. We are looking at the fully observed case. But you can do that for the partially observed, and I am going to denote by capital X U, the concatenated system of everybody. So the idea of incentive. So our idea is the following, okay, so at each time s, there will be a random disturbance that occurs to every agent, right? And I want them to declare their disturbances so I can price things properly and make the market efficient. That is my goal.
00:17:01.324 - 00:17:45.094, Speaker B: So the ISO charges a VCG payment, taking into effect, taking into account the effect of the disturbance at this particular time on all future states, and balancing for this particular disturbance. So we going to do disturbance by disturbance as we go along in time. So we going to balance for each disturbance. And there is some independence there. So we are going to exploit all these things. And due to the superposition of this linear systems, the future states can be written as the sum of the effects of past disturbances. And the quadratic nature of the cost renders this additional interaction as a product, some kind of product between independent variables.
00:17:45.094 - 00:18:15.108, Speaker B: And then we can show an expectations expectation that these things cancel out. And this will allow us to get x anti results. But x anti not in a, is little stronger in the sense that it is still conditional expectations, not just expectation. So that's a broad idea. And the solution is the following. We call this a layered VCG mechanism. We will ask agents to bid their states, their noises at time s minus one.
00:18:15.108 - 00:19:09.838, Speaker B: And then what we will do is we will propagate the system forward from this noise, together with allocations which are based on this noise and the trajectory resulting from the particular disturbance at that time can be thought of. And then the superposition of these things would be the total state. So you look at all previous disturbances and look at their effect at time t. That will be the state. So that superposition. And then similarly, we'll also decompose the allocations so that the total allocation, that is consumption of generation, is the sum of the allocations due to the individual disturbances. So in a similar way, the random social welfare, that is, without the expectation, you can write it as the sum of layers of random social welfare in this way.
00:19:09.838 - 00:19:53.862, Speaker B: But then there are quadratics, because the state at time t is a superposition of any effects. And you take quadratics, you get cross terms. So there are cross terms of this sort. They can only be eliminated in expectation. And that is what I meant by x ante. So basically the scheme is the agent I bids a state, which is effectively the noise at time s. The social plan maximizes the utility of that layer, if you will, and collects a payment in the standard VCG sort of a way, or a groves sort of way.
00:19:53.862 - 00:20:35.094, Speaker B: And now in order to make this thing through, we need to, for the agents to be rational. Okay, so what's the definition of rationality we need? So it's like they need to be persistently rational. So in what sense? So let's, I'm going to define this by backward induction. What I mean by rationality, I'll say that an agent at almost at the very end is rational. If there is a unique, if there is a unique dominant strategy, then it will use that. So that's my definition of rationality at time t minus one. But the uniqueness will come in because of the positive definiteness of the cost.
00:20:35.094 - 00:21:26.670, Speaker B: And then we'll say that it's rational at time t if it adopts a unique dominant strategy at time t when there is one, under the assumption that all agents will be rational at future times. So under this persistent rationality assumption, truth telling is a dominant strategy. But in the stochastic case, we do need to know the system dynamics and so on. In fact, there is a counterexample if the dynamics are not known. So unlike the deterministic kishmi. Okay, the next question is, so this may be the only case that you can do the strategic problem in the stochastic dynamic case that I know of now. But we also want to go after budget balance and individual rationality.
00:21:26.670 - 00:21:59.898, Speaker B: So how to ensure that this layered VCG payments satisfy budget balance in individual rationality? Very simple. I am going to scale up the first groves term in the payment by a factor c to try to achieve this balance. So we will simply scale that, or this is actually the VCG scheme. And that is what we call the scaled VCG mechanism. So this is an example of groves now. Now we would like to choose the c to achieve balance. So we'd like to do one parameter scaling of these payments.
00:21:59.898 - 00:22:46.750, Speaker B: There's a constancy for everybody. But if c is chosen as a function of the bids, then we lose the gross property. Because this has to not depend on agent I's bit. All right. So however, what we can show is that under a certain market power balance, which, which I will define in a second, it turns out that there is a range of values of c that ensures budget balance and individual rationality. And the hope is that because these agents are always interacting in the market place, ISO is doing this, running this auction every day. Hopefully it can get a knowledge of the range of cs that work or tune it to get budget balance.
00:22:46.750 - 00:23:45.716, Speaker B: It is not just a unique value, it is actually a range. So that is the hope. And what is this market power balance condition? So take the optimal solution with agent I excluded the optimal reward and look at the maximum. So basically this maximum is the social welfare of everybody minus the least, the smallest fish in the pool. And we say that the outcome satisfies market power balance if the number of agents minus one times the max is less than this. So basically the way to interpret it is that no one agent has a humongous effect or too little an effect. The theorem is that if the socially optimal outcome satisfies market power balance, then there is indeed a range of cs of tuning this parameter, such that the scale VCG mechanism is incentive compatible, efficient budget balance and individual rational at the same time.
00:23:45.716 - 00:24:35.124, Speaker B: And perhaps you can think of this market power balance condition as an economic justification for load aggregators. So you do not want these individual homes to participate in marketplace, they are too small a fry. And if you aggregate them so that they all have kind of equal cloud more or less, then, then you can actually get social welfare maximization. But we also want more. We also want them to pay the fair price, the Lagrange multiplier. So we have an asymptotic, we can show asymptotic Lagrange optimality. So Lagrange optimality simply means that for the constrained problem, if there's unique solution, then the payment that you make is actually the payment of the price of the Lagrange multiplier times the allocation.
00:24:35.124 - 00:25:26.384, Speaker B: And what we can show is that if some of these things are bounded, all these agents, then asymptotically, as the number of agents increases, there is a range for each n. And these things satisfy the fact that they converge to one. And we can get actually asymptotic Lagrange optimality. So as things scale up, you get the exact thing. If you have a large number of equally, somewhat equally powerful containers in this market power balance, then you get nearly the fair price for everybody. So some thoughts on what this scheme is. So todays bidding is essentially static and it does not allow for really genuine dynamic optimization of uncertain resources.
00:25:26.384 - 00:26:03.192, Speaker B: So we want to exploit wind to the hilt, we want to exploit renewables to the hilt, but we also want to exploit the flexibility of consumers and so on. And all that is dynamic and stochastic and it doesn't really allow that. So maybe wasteful of resources. So we definitely need a stochastic dynamic bidding scheme. Now on the other hand, we also want to satisfy incentive compatibility, social welfare optimality, budget balance, individual rationality and the correct price premium, some kind of fairness. So I call that Lagrange optimality. Now, so here is a proposal.
00:26:03.192 - 00:26:44.504, Speaker B: Proposal is large LQG systems can today be solved. So even if you are an ISO and you have 1000 people submitting LQG, perhaps computationally this should be feasible. Nowadays it can just run a big computer and so can LQG become the workhorse of dynamic stochastic bidding. That is the suggestion. And there is some kind of precedent to that. I mean if you look at open any text book on power systems, there will be the cost of, when they explain economic dispatch or anything like that, they will always talk of the cost of generating a power p as a quadratic. So I talked to my power system colleague, they said, yeah, linear quadratic sums.
00:26:44.504 - 00:27:36.754, Speaker B: So and in the deterministic case, just tuning just one parameter can achieve all of this. Just one parameter. And is this possible that because of repeated interactions, the prior knowledge that you acquire, is that enough to tune c? And perhaps, maybe, of course. But if they game that learning also they can get into a different thing. But is that a possibility? And does this market power balance condition for social welfare maximization provide economic justification for load aggregators as agents to permit social welfare maximization? And KMA is investigating all these things. That is new job in PNNL. Okay, so again John, thank you for the opportunity to be here and wish you the very best and continued success in everything.
00:27:42.414 - 00:27:52.438, Speaker A: Thanks for the great talk. We have a few minutes of questions. So I didn't understand. So your individual rationality.
00:27:52.486 - 00:28:08.174, Speaker B: And they are exposed x anti but in a condition expectation sense. But then. So let us think of x post as almost surely x anti as expected value. So this is xanti but conditional expectation.
00:28:08.914 - 00:28:11.866, Speaker A: And there is, of course, an impossibility.
00:28:11.930 - 00:28:14.610, Speaker B: Theorem which says, in general, you cannot achieve all properties.
00:28:14.642 - 00:28:16.854, Speaker A: So in that proof.
00:28:17.554 - 00:28:50.794, Speaker B: So this is of course. So this is not in general, I am saying that given this system, there is a range and you want to tune in that range. If you say all systems, then there is an empty system. So there is prior knowledge. And the question is, can you use prior knowledge to do these things? Yeah, I'm just wondering about the impact of the number of market players. So, for instance, for the asymptotic Lagrange, do you have any idea how just writing this paper. So I think the convergence rate.
00:28:50.794 - 00:28:57.654, Speaker B: You're asking. The convergence rate. Right. One over n. One over n. Okay, there it is. Yeah.
00:28:57.654 - 00:29:04.962, Speaker B: I think it's like a law of large numbers kind of a thing or whatever. Right. Vijay, did you have a question?
00:29:05.098 - 00:29:13.428, Speaker C: I was wondering, this market or the condition that he had the market, does that give you these properties for the static system as well?
00:29:13.556 - 00:29:14.028, Speaker B: For the what?
00:29:14.076 - 00:29:18.316, Speaker C: For a static system, for a standard VCD setting, if you have the.
00:29:18.420 - 00:29:28.660, Speaker B: Yeah, right. Yeah, so, yeah, exactly. It would. So in the, for example, the deterministic LQ problem.
00:29:28.732 - 00:29:30.744, Speaker C: So not having a single powerful player.
00:29:31.124 - 00:29:51.296, Speaker B: Yeah, exactly. But powerful or weak, you have to interpret this properly. Yeah, basically, agents are roughly. You're not comparing equation to equation. You're just saying in this influence exert on the market, at the end of the day, given the dynamics and utilities and so on, they're kind of comparable. That's what it says.
00:29:51.440 - 00:29:52.764, Speaker A: Dalit, did you have any.
00:29:54.904 - 00:30:00.284, Speaker C: So just coming back to the budget balance, in individual rationale, is it at every time step or is it.
00:30:00.984 - 00:30:12.360, Speaker B: No, actually, in the way we do it is we do it for every layer. I mean, that's stronger than what you would need if you just wanted to completely exante. Right, but actually does. Yeah, most of the time.
00:30:12.392 - 00:30:29.016, Speaker C: You need it for time. I guess. The one thing, I mean, there is also the Bergman Walimaki type mechanism which would operate in this context. How would what you have compared with what they.
00:30:29.160 - 00:30:32.344, Speaker B: I don't know. I think that's one thing.
00:30:34.684 - 00:30:43.036, Speaker C: They don't specialize in the LQG, but that depends on using the fact that there's an optimal dynamic programming solution.
00:30:43.100 - 00:30:46.092, Speaker B: I see. Okay. I don't know how to say, but.
00:30:46.108 - 00:30:50.464, Speaker C: They don't get budget balance. It's like a standard BCG version.
00:30:53.284 - 00:30:57.384, Speaker A: We could take one more question. Depressing me.
00:30:58.924 - 00:30:59.364, Speaker B: Thanks again.

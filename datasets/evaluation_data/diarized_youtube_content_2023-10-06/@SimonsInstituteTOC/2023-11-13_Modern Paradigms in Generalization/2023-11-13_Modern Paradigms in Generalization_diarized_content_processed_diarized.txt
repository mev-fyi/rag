00:00:26.184 - 00:00:56.060, Speaker A: Thank you for attending this longer presentation. The plan is to use most of it. Setting up my tower. Yeah. Thanks, everybody, for coming so. And listening to everybody else as well. So, as Umesh mentioned, for the first half of the LLM program, there will be a parallel program, which is a little bit more classical, but we're trying to be non classical.
00:00:56.060 - 00:01:36.018, Speaker A: That's why it's called modern paradigms and generalization. And there are seven organizers. So it's Peter Bartlett, Daniel Sue Poling low, Tony Pitasi, Andre Usdeschi, myself, Matus, and rich Zemmel. And then we have four workshops. And so I'd also like to credit the workshop organizers, who have already been doing quite a bit of work. For those of you that know how the Simon Institute operates, the workshops are kind of the lifeblood of how a lot of these programs work, and workshop organizers have to do a lot. So two of the workshops are done by me and Andre, and then we have two glorious other workshop chairs, Smokey from Colombia and Fanny Yang from a little bit about the program and what it means.
00:01:36.018 - 00:02:14.338, Speaker A: So, what I mean by generalization is the fact that you have a machine learning algorithm, and you just run it on some data you have literally lying around, and then you expect it to work on data you haven't seen. Now, I don't know why all of you think this should work, okay? But there's really no reason it should. And there's really no math that says that it will. And there's math that says it won't. But again, so generalization classically means machine learning. Algorithms are given data, and then you expect them to work on future data. And in the classical setup, there's a very strong paradigm, which is data is drawn IID, and in the future, you see IID data from the same distribution.
00:02:14.338 - 00:03:02.442, Speaker A: Now, just a show of hands, how many people think this ever happens? Like, ever. What's the example? There's an infinite number of things to consider. I'm sure that it happens sometimes. I see, um. Yeah, so, unfortunately, if you open a textbook, you see examples like spam filtering, and spam filtering, hilariously, is the absolute worst example, because if I were designing spam, I would try to optimize against what the person designing algorithm is doing. I'm definitely not being IED. So, um, if you, if you look at what generalization means now, I'll just give two examples and I'll say a third one verbally.
00:03:02.442 - 00:03:34.164, Speaker A: So, you know, you buy a self driving car, you'd like to take you home. It was definitely not trained on your home, hopefully. And another example is, let's talk about llms, right? So what llms do is you feed text into them and you expect something reasonable. Now let me tell you how far this is from IID. You can look on the Internet. There are entire sub communities on the Internet where all they are doing is trying to find crazy inputs to these llms, okay? They're explicitly trying to break their training data. Okay? I'm not just talking about the jailbreaks, I'm talking about everything they do with them.
00:03:34.164 - 00:04:44.424, Speaker A: So these, all these, it's not just that the paradigms are completely different, but the philosophies are completely different. If you open a machine learning textbook, you'll say, we're trying to say things like with probability one minus delta, the algorithm does something very close to the optimal thing. And just the funny thing is, you know, that's actually a very strange guarantee if you think about it. So if you drive over a bridge like Golden Gate, do you have a guarantee with probably one minus delta that the Golden Gate bridge is not going to collapse? Does anybody know what kind of guarantee you do have on the Golden Gate bridge? On the Golden Gate bridge? And why do you trust it? So why should we trust lms? And what I'm saying is that it's not just that the techniques are going to have to change, but the goals are going to have to change. So there's a lot to do in this program, okay? So let me tell you a little bit more. The high level goals of this program are to taxonomize modern settings and make old and new tools. So I don't think all the old tools have to be thrown in the trash, but I do think we need new tools, and I think all of us think that.
00:04:44.424 - 00:05:22.420, Speaker A: So we're going to make a taxonomy of the settings and what tools we can use and what tools we need to create. So extract tractable and hopeless questions. As a mathematician, I'm very good at producing questions I cannot answer, and it's kind of a waste of time. And so we'd also like to do some tractable questions. We'd like to make our own progress and inspire other people to make progress. I spent a long time making this green sentence because we'd like to, of course, mesh with the, with the U mesh, that's the green line. So I view our program as sort of like tangential and complementary to the LLM program.
00:05:22.420 - 00:05:54.430, Speaker A: We will sort of study what they're doing and also do some of our own things. And another thing is very important actually, which is refocus the ML theory community. So a lot of us, faced with how rapidly the settings have changed, are a little bit lost as to what to do. And the place where this is actually the most difficult is for PhD students. So PhD students in memo three really don't know what to do. And a lot of top students are questioning what they should do with their futures. And so this is a very sad situation and a very scary situation.
00:05:54.430 - 00:06:30.000, Speaker A: And we all view part of the purpose of the program to sort of refocus and determine, you know, what we should be doing. And it relates to this question I said earlier about the guarantees on the Golden Gate bridge. By the way, another puzzle about the Golden Gate bridge and the one minus delta guarantee on the Golden Gate bridge. Does anybody know the one time that the Golden Gate bridge, that it actually started to groan and the columns started to point towards each other? It happened once. Does anybody know what caused it? What? Yes. Yes. So if I tried to prove a theorem that says the probability one minus delta over the types of car traffic you have on the Golden Gate bridge, it will stay up.
00:06:30.000 - 00:06:57.842, Speaker A: That guarantee would have told me nothing about that incident, which was people walking across the bridge, only people. It was an anniversary. So. Okay. So another thing is the activities of the program. So, for those of you that aren't familiar with the Simons Institute, there's the workshops which you see externally. But there's a lot of nice stuff that happens between the workshops, and that's part of the job of the organizers to set those things up.
00:06:57.842 - 00:07:25.394, Speaker A: And what's always very exciting is to have reading groups. We have weekly reading groups, green people from the area, too, from Berkeley, and things like that. We have four workshops broadly. There's going to be a bootcamp. There's going to be kind of a workshop focused on three practice gaps, one on distribution shift and one on future settings. The last one on future settings we're quite excited about. We plan to have things like philosophers showing up, because what does generalization actually mean? Like, do I generalize? I.
00:07:25.394 - 00:08:10.594, Speaker A: Not really sure. And then there are the mini workshops that Umesh talked about where the industry day is a great day to talk about that, because part of the purpose of the mini workshop is to have industry participants come and visit. And Umesh has done this for quantum programs. And I was also one of the organizers of the deep learning theory program four years ago, and we had people from industry coming for that. Actually, Preetam, who is here, was one of the people that was coming and visiting us from Google at the time, I think, and then, of course, has been highlighted. This might sound like a joke, but a very good way to get people to do math together is to get them to do things like cook together. And this is my last slide.
00:08:10.594 - 00:08:39.126, Speaker A: I just want to say a little bit about why the Simon Institute is very important. And actually, I think the Simon Institute is more important for people like me who actually come from outside the Bay Area. So the Simon Institute is a. A wonderful way for us to meet lots of people. And, you know, if you look at our program, we have people coming from all over. We have participants and chair. Chair of one of the program workshops coming from Europe and from the 2019 program.
00:08:39.126 - 00:09:04.734, Speaker A: The Simon Institute forms many long lasting collaborations. So there was, for instance, one research fellow in the program who met her postdoc advisor, and then now she's my colleague in the Cronce Institute. And there are many such examples. I can point to many examples where some people did not know each other at all. They came to the Simons Institute, and they're still active collaborators. There are many such from the 2019 program that I did alone. So this, for me, is the most valuable thing about the Simonstitute.
00:09:04.734 - 00:09:26.346, Speaker A: And for those of you unaware, this is quite rare. So there are many conferences and things where people just talk to their friends. They leave. They met their friends a lot, but the Simon Institute's very good. And this picture is paper I did with two friends who are close friends now, but I didn't know at the time. This is me, and this is our 600 foot tall friend, Peter Bartlett. So the pink is.
00:09:26.346 - 00:09:36.074, Speaker A: And, yeah, the other thing about the Simons, too, is whenever I come, I always feel like I get a good. Get the pulse of the entire community. That's what I wanted to say. Thank you.

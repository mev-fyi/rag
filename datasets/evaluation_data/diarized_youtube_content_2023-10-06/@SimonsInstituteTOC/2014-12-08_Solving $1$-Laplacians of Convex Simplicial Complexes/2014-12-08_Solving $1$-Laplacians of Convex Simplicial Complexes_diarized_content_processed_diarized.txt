00:00:02.440 - 00:00:31.036, Speaker A: So today I'd like to talk about solving one Laplacians, which is a slight generalization on the regular Laplacians, which is a zero Laplacians. And unfortunately, we can only do this in very special cases for complex simplicial complex. And then. But of course, we can do it fast, given enough restrictions. And the co authors are Michael Cohen, Brittany Fosse, Amir Niriri, Richard Pang. And there's another person I'm missing here, is that's Noel Watkington, which I just found out about, but I'll have to change the slides afterwards.
00:00:31.100 - 00:00:31.540, Speaker B: Okay.
00:00:31.612 - 00:00:59.326, Speaker A: Anyway, so all these things really boil down to simply solving regression. So regression is you have some data, and you'd like to fit it with some kind of curve, say a line, and then the goal is to fit that data. And I claim that laplacian solvers are no special thing. That's all they're doing under the hood. So let's. So, in particular, right, remember that if you have an over constrained system, you want to solve a equals b. In general, you can't solve it.
00:00:59.326 - 00:01:13.886, Speaker A: So what do you do? You multiply both sides by the transpose, and then you solve this system, and magically, the system a transpose a is now symmetric and positive, semi definite. And so this is what makes a lot of this stuff work.
00:01:13.950 - 00:01:14.674, Speaker B: Okay?
00:01:15.454 - 00:02:32.434, Speaker A: And so, of course, the big question, you know, and there's huge amount of work in this conference related to this problem, and that is, can we eventually solve the general case faster? And there's sort of all the usual starting points on that is, how do we at least reduce the number of rows? And so there was all kinds of nice work on that. Okay, so, in particular, the case, the standard case we've been looking at in these talks so far, is what's called symmetric diagonally dominant. And what that corresponds to then, is a symmetric matrix for which, for every entry, the sum of the off diagonals is. Is less than or equal to the diagonal, okay? And so these actually have a nice correspondence. Every non zero entry off the diagonal simply corresponds to an edge, and it's simply the negation of the weight of that edge in some sense. Okay, so then there's a huge line of work on how you solve these, starting, you know, in nearly near time with Bielman and Tang, and then some work with Yanis and Richard, for which we got down to a single log. I think an important point to point out is that not only can we solve these things fast, sequentially, but we get near linear time algorithms which also work in parallel.
00:02:32.434 - 00:03:13.824, Speaker A: So it's not clear how much parallel you need, but at least. So a lot of nice problems. Like the simplest question is, how do you find the, you know, single sort shortest path in a possibly negative weight graph? It's not clear how to do that without going through graph Laplacians efficiently. And so those are all special cases for which these solvers can be applied. And so, of course, the state of the art is this nice work of Richard and Dan, where they show that, in fact, not only can you do these in near linear time, but you can do poly log depth. So in other words, you can throw out billions of processors at one of these things without any problem, you just have to buy the processors, but ignoring that problem anyway. So that's what we know.
00:03:13.824 - 00:04:16.604, Speaker A: And then, of course, there was another paper with too many authors to list here, for which we got it down to a half a log. So let's go on. So there's another whole approach which we ended up using for this, which is related to this work of Kos, or what they showed then, and Leeds, so that in fact they don't get as fast a solver, but they solve a very interesting problem, which is viewing, solving symmetric diagonally dominant, or graph Laplacians, as an energy minimization problem. So as a simple convex problem. And magically, that's just a very nice way to see the world and whether it's better or not, but it looks like it generalizes nicely in what we'll talk about. So how should we think of Laplacian? Well, eventually I'm going to want to go to higher dimensional topology. So I'd like to recouch graph Laplacians in terms of very simple topology, so that we can then generalize it to higher dimensional topology.
00:04:16.604 - 00:05:02.230, Speaker A: Okay, so the simplest is, you look at a matrix, which I guess I'm calling b transpose. For some reason, we many people call it just b, but I claim for topological reasons, it's nice to think of it as b transpose, and then b stands for boundary. Okay, so what it is, it's a matrix, right? So that every column corresponds to an edge, and then it has two entries for the two endpoints of that edge, one plus and one minus, and that corresponds to this kth edge. But actually, if you go ahead and you just put two one s in that, that really doesn't cause a problem. All that corresponds to is symmetric diagonally dominant systems. So in general, you can simply consider these boundary operators. For us, we won't actually go back and consider this case.
00:05:02.230 - 00:05:48.256, Speaker A: But just to point out that that's really the only distinction is whether you allow both two positive entries or not. Good, so then rewriting the graph Laplacian problem instead of using the usual b, from now on we're going to use these partials and we're going to rewrite this. Right, so now what happens is the graph Laplacian problem is what you do then is you take this boundary operator and then you transpose it. So this says we should go from vertices back to edges. From edges we should multiply by some physical quantity like the conductance and then multiply back to get some kind of residual to vertices. Okay, boundary operator. And if you want.
00:05:48.256 - 00:05:59.992, Speaker A: It's nice to think of writing this this way. And so therefore really all we've done is we can sort of ignore this constant. But in general, throughout the rest of the talk let's assume that all the conductors and resistors are one.
00:06:00.088 - 00:06:04.204, Speaker B: Okay, good.
00:06:05.464 - 00:06:34.376, Speaker A: And so then just rewriting this equation says we want a voltage so that when we convert that to a flow, then that flow has the property that when you convert it back to a residual at the vertices, it meets your demand. And this is exactly the regression problem we started with at the beginning. So in some sense we really are just doing simple regression. It's just that we've restricted ourselves to very special kind of matrices for which we can do it faster. Okay, that's all that's happening.
00:06:34.400 - 00:06:35.724, Speaker B: Right, good.
00:06:36.744 - 00:07:22.290, Speaker A: So the important thing here is that partial one has at most two non zeros per column, so its factor width is called two. A very beautiful paper by Dash and Spielman I think in 2008 for which they show that you can solve any factor worth two problem quickly. That's a very nice result, which I don't think is well known and should be, but anyway, it's very beautiful piece of work. So of course the big open question is can we ever solve anything besides factor? We're too fast. And of course it's not clear. I think there were some people, I think Aaron and Tat claimed that they could, but I think. Not sure the details of proof that in fact factor width three is sort of complete in some sense, but I'm not sure.
00:07:22.290 - 00:08:01.242, Speaker A: It'd be nice to see that look, something like the reduction from General CNF to three CNF. But it'd be interesting. But I think there's some problem with the number of variables when you do that. But anyway, so that's, but anyway, so what we'd like to do then is the whole point of this is to try to wander off and look at problems of factor width more than two and see if we can still solve them. Okay, so there's some work in this direction. Bowman, Hendrick Mavas said that, in fact, you can solve any elliptic finite element problem by reducing it to basically a factor with two problem preconditioning. Okay, so this is for special cases like the heat equation and stuff, and higher dimensions.
00:08:01.242 - 00:08:31.458, Speaker A: And then Dash and Spielman looked at linear elasticity. I'm not exactly sure what headway they made there, but they at least, again, tried to look at higher factor width problems. Okay, so what generalization are we going to pick here? What we're going to do is say that really what we have is our graph really consists of vertices and edges. These are really just zero and one dimensional simplices. So we'll now introduce two dimensional simplices and maybe even four dimensional simplices. And we'd like to solve the equivalent problems.
00:08:31.506 - 00:08:32.254, Speaker B: Okay.
00:08:34.634 - 00:08:36.514, Speaker A: So that's the whole goal.
00:08:36.594 - 00:08:37.214, Speaker B: Good.
00:08:40.034 - 00:08:53.450, Speaker A: So then what I'm going to do is actually. So to rewrite this. So when we say Laplacians, the topologist would say those are zero Laplacians. And what we're going to look at today are what are called one Laplacians, which is one higher dimension.
00:08:53.522 - 00:08:54.934, Speaker B: Okay, good.
00:08:56.244 - 00:09:09.436, Speaker A: And this is all related to this thing called Helmholtz and Hodge decomposition, which we can all view as just related to the question of whether your flow in a graph is a circulation or a potential flow. And really that's the same thing.
00:09:09.500 - 00:09:11.020, Speaker B: Okay. Okay.
00:09:11.132 - 00:09:17.412, Speaker A: And then we'll talk about what cases in the one laplace and we can handle, and then we'll discuss the linear time algorithm.
00:09:17.468 - 00:09:19.484, Speaker B: Good. Okay, good.
00:09:19.644 - 00:09:56.662, Speaker A: So why higher dimension? So let's just do the first simple case, and, of course, which is going to motivate the stuff that topologists do anyway. And that is really related to Navier Stokes, for which you have a curl, probably the easiest to think of Maxwell equation, which you have electromagnetic radiation, and the right hand rule, which says if you have a current flow, this gives you a magnetic field at right angle. So what happens then? How do we then formulate this as a discrete version of that? And so that's what the goal is. You should just keep in the back of your mind that really we're trying to do some kind of thing where we have some kind of right hand rule.
00:09:56.718 - 00:09:57.094, Speaker B: Okay.
00:09:57.134 - 00:10:03.606, Speaker A: Where you. A flow through a triangular face is going to induce a circulation on its edges.
00:10:03.710 - 00:10:04.374, Speaker B: Okay.
00:10:04.494 - 00:10:16.594, Speaker A: And we're just going to formulate that and then try to solve that. Okay, then whether this solves Maxwell's equations, that's not so clear, but it should be useful. I mean, there's a bunch of restrictions that we can't do there.
00:10:17.374 - 00:10:17.998, Speaker B: Okay.
00:10:18.086 - 00:10:22.134, Speaker A: And then later on, what I'd like to do is talk about why that may be related to social networks.
00:10:22.174 - 00:10:24.114, Speaker B: Okay, good. Okay.
00:10:24.814 - 00:10:58.680, Speaker A: No, we just did. Okay, so let's redo the zero Laplacian. So the thing that we're missing then, in order to understand that, is you really need a boundary operator that goes from zero dimensions to no dimensions. And so in that case, it ends up being very simple. It's just the. Let's assume that, remember we have roll Laplacian. We think of this as a graph.
00:10:58.680 - 00:11:32.076, Speaker A: And so therefore, let's assume the graph is connected. Otherwise it's slightly more complicated. And then what happens now is, I claim the boundary operator is simply just the all ones operator. It simply takes your vertices and just takes the sum of the values at the vertices and returns that sum. Okay, this gives you a natural operator, which we end up calling down, which the topologists call down. And the reason is because you start with something of dimension zero, you go to something of dimension minus one or whatever, and then you go back up to dimension zero again.
00:11:32.140 - 00:11:32.652, Speaker B: Right?
00:11:32.788 - 00:11:35.804, Speaker A: So in our case, this is just then a matrix of all ones.
00:11:35.844 - 00:11:36.068, Speaker B: Right.
00:11:36.116 - 00:12:03.246, Speaker A: This is a big dense matrix. And then there's the up operator, which is our standard Laplacian here. And then when you combine them, you get the nice property. This is then called the zero Laplacian. And this is the mix of the two. And why is this nice is because this now is nonsingular. So the beauty now is we've sort of, in a clean topological way, allowed us to handle the null space problem, which we didn't.
00:12:03.246 - 00:12:38.474, Speaker A: If you notice, we always do in a sloppy way, we sort of push it under the rug. That's what the topologists tried to do. And in higher dimension, that's going to be important. So then, of course, now let's understand this in a very pedantic way. So how do you solve this equation now? Well, you have a v, a potential or a voltage, and you're trying to reach some residual. So again, what you do is you say, well, d can be read as a direct sum of an up and a down, where the down is simply, simply returns. I guess there should be a superscript here.
00:12:38.474 - 00:12:42.238, Speaker A: It simply returns the sum of the values at the vertices.
00:12:42.326 - 00:12:42.910, Speaker B: Right.
00:12:43.062 - 00:12:44.874, Speaker A: And so that should be.
00:12:47.694 - 00:12:48.166, Speaker B: That'S how.
00:12:48.190 - 00:13:07.660, Speaker A: Much we should remove from this. And then when we remove from that, that gives our d up and then we just solve this equation, right? So this is just the classic thing we always do, right? You simply remove, you make sure that the demand has the property that, that the sum of the demands is zero, right? And this is just a pedantic way of saying that.
00:13:07.692 - 00:13:09.076, Speaker B: Right, okay, good.
00:13:09.220 - 00:13:21.812, Speaker A: And so that's what we want. And so what makes all this work is this very nice property that if you take the boundary operator one and then apply the zero, you get zero.
00:13:21.948 - 00:13:22.676, Speaker B: Okay?
00:13:22.820 - 00:13:32.086, Speaker A: So in particular this equivalent to saying that the kernel of this map contains the image of the other map. And in particular in our case when the graph is connected, we get equality.
00:13:32.180 - 00:13:32.974, Speaker B: Okay?
00:13:33.474 - 00:13:46.570, Speaker A: And so all this stuff really is very fancy. But you know, if you've taken strang's linear algebra course, which I think is required at MIT, and you look at chapter three, this is what's called the four fundamental subspaces theorem.
00:13:46.642 - 00:13:47.130, Speaker B: Okay?
00:13:47.202 - 00:13:50.338, Speaker A: So it's all very simple stuff. It's not really anything fancy.
00:13:50.386 - 00:13:51.094, Speaker B: Okay.
00:13:51.714 - 00:14:11.916, Speaker A: Okay, so from now on we're gonna have simplicity, zero and one, two and three dimensional and we're gonna use names, vertices, edges, faces and cells. And so in general we're going to have some kind of triangulation. So our triangulation is going to be some messy thing that looks like this here, right? So it's going to have edges, vertices and tests.
00:14:12.100 - 00:14:13.264, Speaker B: Okay, good.
00:14:14.964 - 00:14:50.090, Speaker A: So then what we want to do, let's start using phantere terminology. So a zero chain then is a map from vertices to the reals. So this is the one we talked about. The partial operator, you have values at your vertices and it returns in our case simply the sum of the values. You have another operator that takes you one chains which takes you from which, no, I guess these are just scalars. So it simply assigns values to the vertices, this one assigns values to the edges. And then we'll have another one that assigns values, real numbers to the faces.
00:14:50.090 - 00:15:25.218, Speaker A: And then you could imagine similarly for tests. And so quite often we call these potential voltage or residual flows. These are flows, and then we'll call these fluxes. So the way we're thinking of this, right, is we're thinking of the value here being how much flow or electric current flows through this triangle, right? So good, okay, and then we have operators that go between these, right? So in particular then our partial two then takes us from two chains to one chains. Partial one takes us from one chains to zero chains, right? This is all sort of standard.
00:15:25.306 - 00:15:25.914, Speaker B: Good.
00:15:26.074 - 00:16:02.440, Speaker A: Another nice way to think of this is really you have a post set, you have a complex and you have a boundary operator that takes you from top to faces to edges to vertices, back to the components. And so we have these nice maps here. And now the critical fact is that we're required, when we set up this map, that this property is true, that remember we have this plus or minus one's running around on the edges and throughout the whole map we have to decide on the right sign. And the critical thing is to set it up so that this is actually true, so that everything works.
00:16:02.472 - 00:16:02.640, Speaker B: Right.
00:16:02.672 - 00:16:04.912, Speaker A: So this is what we, this is required of us.
00:16:04.968 - 00:16:06.592, Speaker B: Right, good.
00:16:06.688 - 00:16:08.336, Speaker A: And of course that's equivalent to saying this.
00:16:08.400 - 00:16:09.004, Speaker B: Good.
00:16:10.624 - 00:16:20.104, Speaker A: And so then the question is, there's a slight question here is when we put one of these chains on the right hand side, should we call it residuals or demand or potentials?
00:16:20.144 - 00:16:20.560, Speaker B: Right.
00:16:20.672 - 00:16:35.064, Speaker A: And when we put it on the left hand side of an equation, let's call it a flow. Okay, good, so then what is partial one? Well again it consists of two parts. It consists of a down operator.
00:16:35.184 - 00:16:36.270, Speaker B: So what's this?
00:16:36.432 - 00:17:21.210, Speaker A: So this says you take a flow on your graph, from that you compute a set of potentials and from that you generate a flow. So this takes you from flows to flows. This says the same thing. This says it takes a flow on the edges, it returns fluxes on the faces, and from the fluxes on the faces it returns back a set of flows on the edges. So both of these operators then take you from flows to flows. And of course these are very different because notice that this is a potential flow where this is a circulation. So the reason we're dividing these up very carefully is that this operator is computing the potential part of the flow.
00:17:21.210 - 00:17:26.298, Speaker A: And this operator is, I mean looking at it. And this operator is looking at the circulation part.
00:17:26.346 - 00:17:29.304, Speaker B: Right, sorry.
00:17:30.204 - 00:17:32.464, Speaker C: The first one I believe is the projection map.
00:17:33.324 - 00:17:34.264, Speaker B: Say it again.
00:17:34.564 - 00:17:36.076, Speaker C: It's a projection map.
00:17:36.260 - 00:17:43.188, Speaker A: So these are, yeah, so these are also, you're saying that the image is clearly determined by this.
00:17:43.236 - 00:17:43.564, Speaker B: Right.
00:17:43.644 - 00:17:48.484, Speaker A: So this, so no matter what you put here, you're only going to return a potential flow.
00:17:48.524 - 00:17:51.404, Speaker B: Right? Yeah.
00:17:51.484 - 00:17:53.812, Speaker A: So it's going to give you into the flow so you can also view it.
00:17:53.828 - 00:17:54.172, Speaker B: Right.
00:17:54.268 - 00:17:55.300, Speaker A: So it's projecting.
00:17:55.332 - 00:17:55.500, Speaker B: Right.
00:17:55.532 - 00:18:00.540, Speaker A: And so we need to, what is this second one? This one here.
00:18:00.732 - 00:18:01.156, Speaker B: Right.
00:18:01.220 - 00:18:02.748, Speaker A: So let's see. I think I have more slides.
00:18:02.796 - 00:18:03.188, Speaker B: Let's see.
00:18:03.236 - 00:18:19.228, Speaker A: No, let's. So what this is doing here, right, is it says, this operator says the way to think of it is you have some kind of triangulated space and you have a flow on the edges. So that flow on the edges is going to induce a flux on the face.
00:18:19.396 - 00:18:20.174, Speaker B: Right?
00:18:20.364 - 00:18:32.762, Speaker A: So what happens then is if you have, if you have a triangle here, and I put some number of units of flow alpha on this edge, that's going to induce a flux of size alpha here. Right, for the unit case.
00:18:32.818 - 00:18:35.814, Speaker B: Right. Okay.
00:18:36.194 - 00:18:41.394, Speaker A: So, I mean, the other way to think of it is, you know, physics, which I should really understand.
00:18:41.554 - 00:18:42.018, Speaker B: Right?
00:18:42.106 - 00:19:09.876, Speaker A: It says that if you have, right, an electrical flow on the edges, that's going to induce a magnetic flow. Right, good. And then on the other hand, once you have this magnetic flow, so then what's going to happen now that's going to then induce some other stuff here. So you're going to get some beta, and then what you're going to do then is combine these back to get something on this edge. So, just very similar. So, topologically. So it's just, I claim, mechanically, what we did for graphs.
00:19:09.876 - 00:19:24.734, Speaker A: What did we do for graphs? We did exactly the same thing. Right. We took a potential value on the vertices. From that we generated a flow on the edges. From the flow on the edges, we returned a residual.
00:19:25.114 - 00:19:26.714, Speaker B: Right, good.
00:19:26.874 - 00:19:32.090, Speaker A: And so that was quite a projection, that delta. Well, I think one down can't be a projection.
00:19:32.122 - 00:19:32.602, Speaker B: Yeah.
00:19:32.738 - 00:19:36.774, Speaker A: I think what we want to do is do a projection. Let me just go on. So what's going to happen.
00:19:38.914 - 00:19:39.362, Speaker B: Is, what.
00:19:39.378 - 00:20:00.544, Speaker A: I want to claim is this is what's true. And that is, if you look at the image of these two operators, they're orthogonal. And I claim in the case, whatever this means, that if beta is zero, this is the Helmholtz decomposition that we get that infected the whole space. So in some sense.
00:20:07.484 - 00:20:08.772, Speaker B: Projections. Right?
00:20:08.948 - 00:20:09.876, Speaker A: In the end, these are.
00:20:09.900 - 00:20:13.932, Speaker C: Right, they weren't in the early lower dimensional case.
00:20:13.988 - 00:20:16.264, Speaker B: So, yes, let's see.
00:20:17.004 - 00:20:58.958, Speaker A: I think that we required to do the projection before we started, right? In some sense, right. We removed the part of the potential which we didn't sum to zero, and then we went back and solved it. So that's what's going to happen here. So what we're going to need, we'll do is we'll do some kind of projection. So another interpretation to this is what's really happening here is that the image of this thing here, of course, is contained in the image of this map. But notice that this map has the property that it returns the circulation for each face. So it's a sum of circulation.
00:20:58.958 - 00:21:52.994, Speaker A: So it is a circulation. So this returns some kind of circulation on the edges. On the other hand, this operator here returns something that's a potential, and in this case, we get, I guess, all potential flows, right? So what's happening here is that it's decomposed. These things are returning these two different types. So what's going to be crucial then is that we can break the solution up into solving two separate problems, right? The up and the down separately, similar to what we did in the zero laplacian case. That's what's going to happen. So there's a very nice exercise to give in a graph theory class, and that is that if you take all the flows on a graph, that, in fact, you could look at those that are circulations, and those are, in fact, orthogonal to potential flows for unit size resistors.
00:21:52.994 - 00:22:55.154, Speaker A: And in fact, there's another nice exercise to show that, in fact, it spans all flows. So the set of all flows can be written uniquely as a potential flow in a circulation, which is sort of a fact that somehow gets used, but somehow I don't think we prove it directly, usually. Right? But anyway, so that's what's going to make this all work, right? It's really, we're decomposing these flows into two kinds. So let's go back to the KLZ algorithm. So what do they do at a high level? What they do is that they solve a dual problem, right? So they're trying to find a zero potential. So I'm going to put zeros here for whether that helps, right, to meet some given demand or residual. And so the way they do that then, is they solve this dual problem, which they say, I'm looking at all flows which meet the demand, right? So I simply replace this term here with the flow and I look for that flow and then I just ask for one of minimum energy.
00:22:55.154 - 00:23:02.962, Speaker A: So it's a classic Thompson's principle or whatever, for electricity, right? So instead they just solve this problem instead.
00:23:03.058 - 00:23:04.134, Speaker B: Okay, good.
00:23:05.714 - 00:23:37.560, Speaker A: So they do another sort of very simple trick, and that is they say, okay, I want to solve this problem, so how should I do that? Why don't you just start by finding any old flow that meets the demand, and then why don't I then just add a circulation until I minimize the energy? So at a high level, this is a kos algorithm. So then all they have to do then is, of course, they have to figure out how they're going to do this, but ignoring that for the moment. Then they just solve this, right? They find any old flow and then they will try to find one of min energy.
00:23:37.672 - 00:23:38.736, Speaker B: Okay, good.
00:23:38.800 - 00:24:11.438, Speaker A: And so we're going to try to use the same piece of technology. So for ours, we're going to do the same thing. So what do we do? First of all, we want to solve this equation. So what do we need to do? So, by the helmholtz, what we do is we first of all wanted to break our demand up. So of course, our demand here now is a flow. So we want to break our flow up into a circulation and a potential flow.
00:24:11.586 - 00:24:13.394, Speaker B: Okay, so.
00:24:15.534 - 00:24:36.874, Speaker A: And so what we'll do is we'll do that. Let's worry about that later. And so, once we figure out the circulation part of our demand, then what we'll do is this, then we'll find any other flux on the faces which meets that demand. And then what we'll do is we'll cycle through all those fluxes, which.
00:24:40.074 - 00:24:40.426, Speaker B: We'Ll.
00:24:40.450 - 00:25:08.354, Speaker A: Cycle through all those fluxes for which we minimize the energy. And so that's going to be how we're going to go about solving this. What we're going to do then is just apply kos idea, and that is just find some flux which meets the demand. It may not be a min energy one. And then we'll simply then add in more flux to try to minimize the energy. Just try to just do their trick over again. And one higher dimension.
00:25:08.354 - 00:25:50.664, Speaker A: But the first thing we need to do is we need to take this demand, which is an arbitrary flow, and we have to write it then as a decomposition into a circulation and a potential flow. This is very classic, but let me just go through that. So this is where the projection would come in. So the first we need to compute, let's compute the down part. So I claim when you work that out, that's just a simple projection operator, you simply then compute. You take your demand and your flow, and then you convert it to a residual. Then you apply the inverse operator and go back.
00:25:50.664 - 00:26:25.580, Speaker A: This is just a classic formula for projection operator. So I claim when you do this, but of course, this inner term here, the only hard part is solving this system. And that, of course, is just a zero Laplacian, which we know how to do. So therefore we can do this. So then quickly we can figure out how to compute d down. And then if we want d up, then we just assuming there's no error, we simply subtract this from our d, and that gives us our d up. So we simply then do a very classic thing of decomposing our demand, which is now a flow into a circulation and a potential flow.
00:26:25.692 - 00:26:26.344, Speaker B: Good.
00:26:27.764 - 00:26:29.852, Speaker A: And then we just solve the two problems separately.
00:26:29.908 - 00:26:31.184, Speaker B: Right, good.
00:26:31.724 - 00:27:15.508, Speaker A: So then the hard question now is, okay, so now we have our circulation, and we need to then go back then and find some flux which meets this demand. So, the interesting problem here is, topologically, this all of a sudden becomes quite interesting, because in the 1d case, what do we do? We simply take a spanning tree. And it's very easy to see that you can always find a flow on that spanning tree which meets a given set of demands at the vertices, simply because it's a spanning tree. And basically, you can apply gaussian elimination.
00:27:15.596 - 00:27:15.820, Speaker B: Right.
00:27:15.852 - 00:27:16.966, Speaker A: It's upper triangular.
00:27:17.100 - 00:27:17.682, Speaker B: Right.
00:27:17.818 - 00:27:47.544, Speaker A: What's going to be here? Case here, it's going to be very hard. And what we're going to have to do is there's very few theorems known about this, but there's a very nice theorem of Chillingsworth, who proved that if you have a complex 3d simplicial complex, that, in fact, there is a way to do it. In that case, it is what's called collapsible. And so that's going to allow us then to find some flow that meets the demand. And in some sense, that seems to be the hardest part of this whole thing. And it'd be nice to have some better ideas for that.
00:27:48.164 - 00:27:51.904, Speaker B: Okay, so.
00:27:54.844 - 00:28:01.244, Speaker A: Suppose that we have found some flux that meets our circulation demand.
00:28:01.404 - 00:28:06.144, Speaker B: Right. Good. Did I skip the slidebook?
00:28:10.624 - 00:28:17.800, Speaker A: So then how are we going to do this? So, suppose we found some flux that meets our demand.
00:28:17.952 - 00:28:18.648, Speaker B: Good.
00:28:18.816 - 00:28:35.244, Speaker A: So now what are we going to do? So, now we're going to look at all other fluxes. Okay. Subject to this condition. But I think this condition is trivial in. No, so this. So now we're going to look at all of the fluxes for which it's zero.
00:28:35.544 - 00:28:36.180, Speaker B: Right.
00:28:36.312 - 00:28:46.148, Speaker A: So which it produces a zero flow. And we're going to try adding this to our system to minimize the energy. Then it's not too hard to see that this is equivalent to our original problem.
00:28:46.276 - 00:28:46.944, Speaker B: Good.
00:28:48.444 - 00:29:39.918, Speaker A: But now, we'll use a simple trick here, at least, to make it work in this case. And that is to say, well, let's assume that we are in some kind of place where beta two is zero. In other words, all we're saying is that it's the case that we can pick up all flows, all circulations, as some combination of fluxes. So that's what beta zero says. It just says this. Well, assuming that this is true, then this simply says that this flux can be obtained in one higher dimension by just looking at potentials on the tets, such that when you apply partial three to it, you get that particular flux.
00:29:39.966 - 00:29:40.554, Speaker B: Right.
00:29:40.894 - 00:30:08.338, Speaker A: So let me just draw a quick picture here. So that's just simply saying the following. And that is, we're trying to get some kind of flux coming out of this face here. One way to get that is what we do is we have some kind of value inside here, say heat, and then we just apply that, and that gives us then fluxes on all the faces.
00:30:08.386 - 00:30:08.974, Speaker B: Right?
00:30:09.314 - 00:30:30.206, Speaker A: Coming out. So what I'm assuming here is that we're able to obtain all the fluxes, right, with zero. With this property as simply having potentials on the tets, this means assume that.
00:30:30.230 - 00:30:34.278, Speaker C: There is actually a bunch. What you start with is a bunch of tetrahedra.
00:30:34.366 - 00:30:34.590, Speaker B: Yeah.
00:30:34.622 - 00:31:16.822, Speaker A: So we're assuming for simplicity. So what we're assuming now is that we have a 3d simplicial complex. And so not only that, but on these tets, we're also given. So the tets are nice in the sense that we can generate that this is true. Namely that if you look at all the fluxes for which they generate no circulation, that those can be obtained as simply applying, having a pressure or whatever inside each tet, corresponding to this being simply connected. Yeah, I think it corresponds in our case. Let's do the simplest case is that it's a simply connected ball, right? So for instance, it's a ball.
00:31:17.018 - 00:31:19.870, Speaker B: Right, of tets. Right?
00:31:20.022 - 00:31:22.834, Speaker D: This is what's usually called homology in rough.
00:31:24.934 - 00:31:25.294, Speaker B: Yeah.
00:31:25.334 - 00:31:29.734, Speaker A: So I think the equivalent to saying the homology is trivial, that it's basically a ball.
00:31:29.854 - 00:31:30.278, Speaker B: Okay.
00:31:30.326 - 00:31:35.110, Speaker C: So does Betty one equals zero say that a graph is a tree? Is that connected?
00:31:35.262 - 00:31:38.830, Speaker B: It's just that it's connected.
00:31:38.902 - 00:31:39.794, Speaker C: Is that all?
00:31:40.894 - 00:31:41.246, Speaker B: Yeah.
00:31:41.270 - 00:31:41.834, Speaker A: So.
00:31:44.514 - 00:31:56.214, Speaker D: So it only makes sense to talk about it at the level where, like, it doesn't make sense to talk about a tree, whether the homology there, until you introduce what the faces are.
00:31:57.234 - 00:32:08.762, Speaker A: So I think beta zero corresponds to connected. Beta one corresponds to that. It's something that looks like a sphere. Right. And beta three corresponds to being a ball, right?
00:32:08.938 - 00:32:13.346, Speaker C: Yeah. I think the Betty numbers are just the different kinds of cycles you can.
00:32:13.370 - 00:32:14.434, Speaker B: Get on a surface.
00:32:14.594 - 00:32:22.898, Speaker C: So a ball is Betty number, is Betty number zero. If you get the Betty number to be one, you get a torus. So you have two kinds of cycles that don't.
00:32:22.946 - 00:32:24.666, Speaker B: You can't melt one kind of cycle.
00:32:24.690 - 00:32:29.186, Speaker C: Into the other kind. And that's what. So it's just tracking, like, overall global.
00:32:29.250 - 00:32:31.014, Speaker B: Structures in this shape.
00:32:34.544 - 00:33:04.380, Speaker A: So assuming that we have all these properties, which would be nice to get rid of, then we can now go back and make the following substitution in this equation. We can substitute in here, this term here, into this equation, and try to solve it. So now let's assume that we have a flux which meets our demand circulation. Let's assume that Betty two is zero. Then really, we're trying to minimize this equation.
00:33:04.532 - 00:33:06.624, Speaker B: Okay, good.
00:33:07.284 - 00:33:59.694, Speaker A: And what I claim then is that minimizing this corresponds to solving an equation that looks like this for some d three. So let's see that that's sort of trivial. So we're trying to minimize this term here. I'm not sure this is necessary, whether this is confusing, but we just expand this product here, and we get three terms, right? We're going to get a term, a constant term, we're going to get a linear term in f three, and we're going to get some kind of quadratic term in f three, right? If we compute the gradient for these things here, of course this is going to go away. This term here becomes just a constant. This term here becomes linear in f three. And so if we set this to zero, now we're just trying to solve an equation that looks like this, where d three is this term here.
00:33:59.694 - 00:34:19.410, Speaker A: So I claim that solving this thing. So if we try to minimize this, all we need to really do is be able to solve equations of this form. Is that too fast or not necessary? Wasn't clear. I'm sure it's either confusing me to.
00:34:19.442 - 00:34:26.197, Speaker D: Do the one laplace, you don't need to go to solving an equation on faces.
00:34:26.245 - 00:34:30.253, Speaker C: So why do the two laplacian. Do we have to go to solving an equation on.
00:34:30.413 - 00:35:13.368, Speaker A: Oh, because we're going to dualize it and claim we're back to zero Laplacians, because that's all we know how to do. I mean, our problem is that in some sense, we did a Fourier, we wandered off in this direction, tried to prove something interesting, and then what we did is cobbled together as much as we could so that it was publishable, right? So, I mean, that's the way to think of it, at a high level, right? And that worked. But still, on the other hand, you know, somehow, if you're going to go off in this, you need to say something interesting. Otherwise they don't let you publish a paper. But it's still, I think, non trivial. Right? The people that do, you know, physics and stuff like that, simulations say they had never seen this before. Okay, so that's interesting.
00:35:13.368 - 00:36:25.804, Speaker A: Okay, so did everyone agree then that if we go back then to doing this, if we want to solve, if we're given, right, so if we're given a flux that meets our demand and we're trying to minimize this equation, it suffices to simply solve something that looks like this, right, but what does this correspond to? This corresponds to, so what I claim is that if we have a 3d simplicial complex, that if we're trying to solve this, this just dualizes, right? Because what is this? This simply says we have the value in the middle of every tet, right? And what are we trying to do? We're trying to generate values. What does this say here? Right, this says we have the value at each one. We need to then find values on all the faces so those correspond to edges. So maybe just try that as a dual here, right, so we have this picture now that looks something like this, right, there's this cat.
00:36:27.504 - 00:36:28.224, Speaker B: Right?
00:36:28.384 - 00:37:47.112, Speaker A: And it has a dual vertex inside going out through each of the faces coming out here. And there's another one here somewhere else, right? So under the hood here is this degree, four vertices, vertex. And what are we trying to do here? We're trying to find values here, we're trying to find a value here at these guys, right? Which have the property that when you view that as a flow on these edges, right, that's this part here, and then you go back and you take those flows and you look at the residuals at the vertices, you get what you wanted, right, so this is precise, this, and if we dualize it is this equation here. So we're back to where we started and then we can use the same hammer. So then the hammer then just says, oh well, since we've made a huge number of assumptions about being a 3d simplicial complex and all kinds of other things, magically it boils back to something we know how to solve. So there's just a zero Laplacian and then we're home free. Okay, good, but so the interesting point on all this.
00:37:47.112 - 00:38:28.206, Speaker A: So this is all nice, you know, we threw in a lot of assumptions, it would be nice to get rid of those. But we still have this other interesting problem here. And that is how did we ever get any old flux that meets our demand? Unfortunately that ends up being interesting. Good, so was the whole work in the fifties by whitehead on what's called collapsible complex. Okay, and so, so there's a thing called edge collapsing. So an edge collapsing is something we see all the time. So if you have some kind of graph with a vertex of degree one.
00:38:28.350 - 00:38:28.870, Speaker B: Good.
00:38:28.982 - 00:38:57.594, Speaker A: A collapsing. Then, topologically, simply says you remove the vertex and the edge. But the way we think of it is you're in the middle of a solve. So you have some residual you'd like at this node, and you have a single edge here. Well, the only way you're going to get that residual there is by applying the appropriate amount of flow on that edge. So, therefore, topologically, you can think of doing this. But under the hood, you can think of it as you're in the middle of trying to figure out the flow on that edge to meet a given demand.
00:38:57.714 - 00:38:58.374, Speaker B: Good.
00:38:58.914 - 00:39:36.308, Speaker A: So, equivalently, you can do the same thing here. So, suppose now you're trying to have a given circulation on the edges of a triangulation, and you're trying to figure out how much flux to put on the faces to meet that demand. Well, if there's only one edge on this, if there's only one face common to this edge, the only one that's going to give you the flow on this is this face. So therefore, you're forced to set the flux here to be equal to the flow you want on that edge. And then when you remove it, of course, then you have to update it and readjust the demands on the remaining edges. But you can keep going in that fashion.
00:39:36.396 - 00:39:39.072, Speaker B: Okay, good. Okay.
00:39:39.208 - 00:39:57.536, Speaker A: So, of course, you can do the same for solids, right? If you have, for instance, you're trying to get a given flux on this face, and it happens to be only common to a single tet, then you can simply. Then you have to set the value in that tet to meet the value you want on that face.
00:39:57.600 - 00:39:58.920, Speaker B: Right, good.
00:39:59.072 - 00:40:07.688, Speaker A: So. But this lends itself to a very nice topological question, then, is, you know, when can you take some kind of topological structure and get this to happen?
00:40:07.776 - 00:40:09.256, Speaker B: Okay, good.
00:40:09.440 - 00:40:25.000, Speaker A: Okay, good. So there's certain kinds of things that are collapsible. So, in particular, this here is a collapsible. It's a tree. This is also collapsible. If you check it out, you can just go through and remove them all. This is not right.
00:40:25.000 - 00:40:27.776, Speaker A: If you're missing these faces, you can't collapse this.
00:40:27.960 - 00:40:30.044, Speaker B: Okay, good.
00:40:30.424 - 00:41:05.460, Speaker A: Of course, what would happen then? Of course, what does. You know what Lorenzo and crew do? They would say, well, of course, you wouldn't keep all these edges because you don't need that many in order to meet the demand. You would just take a subset of those edges which formed a tree, and you would use that. You would jettison the extra edges. So the question is, how fast can you decide whether a 3d simplicial complex is collapsible? And also, how do you determine if it has a sub complex that allows you to meet the demands and is still collapsible?
00:41:05.532 - 00:41:07.100, Speaker C: What's the difference between. Lustin.
00:41:07.252 - 00:41:08.788, Speaker B: Sorry, what's the difference between.
00:41:08.836 - 00:41:09.652, Speaker C: Ls two.
00:41:09.828 - 00:41:15.024, Speaker A: Between. This one here, this has a gray here, and this is white.
00:41:15.524 - 00:41:16.664, Speaker C: I saw that.
00:41:17.644 - 00:41:28.324, Speaker A: I know. I just couldn't resist. Sorry. So that means that this is a triangle in the complex. This one has. This is not a triangle in the complex. You don't have the face.
00:41:28.324 - 00:41:29.184, Speaker A: It's missing.
00:41:29.684 - 00:41:30.464, Speaker B: Yeah.
00:41:31.124 - 00:41:32.092, Speaker A: It's just a skeleton.
00:41:32.148 - 00:41:33.516, Speaker B: Right. Okay.
00:41:33.580 - 00:41:34.260, Speaker A: That's the distinction.
00:41:34.292 - 00:41:35.344, Speaker B: Thanks. Sorry.
00:41:36.924 - 00:41:42.772, Speaker A: Okay, so how do you even decide if it's collapsible, let alone whether a sub complex?
00:41:42.828 - 00:41:43.284, Speaker B: Right.
00:41:43.404 - 00:42:20.934, Speaker A: Well, it's NP hard to. In general, for three complexes, there's a whole crew of people that worry about this stuff, and they have all kinds of negative results. So the question is, of course, how to get positive results. That seems to be harder. And there's a bunch of np hardness results in this way. It's open for three balls whether you can decide. But there's a very interesting result from way back in the sixties that said that if you have a convex triangulated body, so in other words, a bunch of tets which have been glued together to form a convex body, then that is actually collapsible.
00:42:21.254 - 00:42:21.994, Speaker B: Right.
00:42:22.454 - 00:42:31.854, Speaker A: And it's actually non trivial. The proof is quite clever, actually. You have to actually do something to make sure you don't get in trouble, because remember, we didn't say anything about what the shape of these tets are.
00:42:31.894 - 00:42:32.286, Speaker B: Right?
00:42:32.390 - 00:42:33.914, Speaker A: This is an arbitrary mess.
00:42:36.454 - 00:42:41.014, Speaker C: You have any simplicity? Composition, proper simplicity, composition of a simple axis.
00:42:41.134 - 00:42:41.462, Speaker B: Yeah.
00:42:41.518 - 00:42:43.142, Speaker A: Of a convex simplex.
00:42:43.198 - 00:42:43.750, Speaker B: Right.
00:42:43.902 - 00:42:48.334, Speaker A: Take a convex polytope in three D and triangulate the interior.
00:42:48.714 - 00:42:49.410, Speaker B: Right.
00:42:49.562 - 00:42:52.654, Speaker A: Then that's collapsible. That's what this theorem says.
00:42:53.554 - 00:42:55.414, Speaker C: I see. Any.
00:42:56.634 - 00:43:09.794, Speaker A: And the reason it's non trivial is because you have to be careful what order you do this. Right? So of course, you would start by removing some outer face and the tet it's common to. But you have to be a little careful how you do that.
00:43:09.834 - 00:43:10.274, Speaker B: Right.
00:43:10.394 - 00:43:12.828, Speaker A: But anyway, he was able to show that that works, right?
00:43:12.906 - 00:43:14.488, Speaker B: So this is a topological result.
00:43:14.536 - 00:43:18.392, Speaker C: So it's not obvious to me why convexity is important. Is there an interpretation?
00:43:18.448 - 00:43:18.896, Speaker B: Yeah.
00:43:19.000 - 00:43:24.336, Speaker A: Yes. But if you go through the proof, it's very. It comes in very in the way he does it.
00:43:24.360 - 00:43:24.496, Speaker B: Right.
00:43:24.520 - 00:43:26.204, Speaker A: He has to be very careful.
00:43:27.144 - 00:43:40.744, Speaker C: So when I was talking to clever with Avas for that, about the slivers, he said, you know, if the sliver flow to the boundary, they didn't matter anymore. Isn't it somebody?
00:43:42.884 - 00:43:43.900, Speaker B: I don't know?
00:43:44.052 - 00:44:06.108, Speaker D: So, by the way, note, this is not a purely topological thing, right? You can have two simplicial complexes that represent the same topological space, and one of them is, you know, for example, three balls. That's one topological space. There are lots of triangulations, and one of them can be collapsible and one of them can't. So it's a kind of like, combinatorial property.
00:44:06.156 - 00:44:14.628, Speaker A: Two combinatorial. I guess I was assuming by topology we meant combinatorial topology, right. But if you're not, then it's different.
00:44:14.676 - 00:44:16.744, Speaker B: Right? So that's not so clear. Okay, good.
00:44:18.484 - 00:44:57.692, Speaker A: Okay, so. And then. And I guess, as we just said, this is all correspond to gaussian elimination, right? So, in fact, it has a nice interpretation. So, of course, when you're in the middle of this thing here, you know, we're applying this operator. When we remove an edge, right? This corresponds to doing some kind of gaussian elimination, right? And notice when we do this and we drop a face, what we're really doing is dropping one of the columns in the matrix. So it has very simple interpretation because these are higher dimensional in the particular case we're doing, right. So they have very natural interpretation.
00:44:57.858 - 00:45:01.364, Speaker B: Okay. Okay.
00:45:02.784 - 00:45:14.644, Speaker A: So now there's sort of. The question is, just in case you haven't thought about this, the obvious simple cases to work out is what happens if you have a triangulated sphere.
00:45:15.184 - 00:45:15.992, Speaker B: Okay?
00:45:16.128 - 00:45:25.644, Speaker A: So if you take your favorite sphere and it's been triangulated for you, right? So that there's these triangles.
00:45:27.454 - 00:45:27.958, Speaker B: Good.
00:45:28.046 - 00:46:03.920, Speaker A: So this is one of the complexes. So then what I want to claim is that, of course, it's not collapsible, as the whole thing goes, because there's no edges that are on a single face. But if what you do now is you remove one of those faces, then it becomes collapsible. And also, it's not too hard to prove. It's a nice exercise using Euler's formula to show that, in fact, the remaining faces have the property that they generate their circulations, generate all circulations on here, right. So it works out just perfectly.
00:46:03.952 - 00:46:05.124, Speaker B: Right. Good.
00:46:05.424 - 00:46:33.284, Speaker A: So then the next interesting question is, what happens if you take something like a projective plane? So. And this is a nice exercise also, to work out. I think Nathan Linneau was playing with this stuff for some other reason, and you end up with a similar kind of thing. So, in case you forgot what a projective plane is, project of a plane is where you take a disk and you identify opposite points. So, for instance, this is X x, y z.
00:46:34.184 - 00:46:35.160, Speaker B: Okay.
00:46:35.352 - 00:46:52.596, Speaker A: And now what happens here is this is a nice triangulation. Again, same as before, but unfortunately, you don't have enough triangles. So what happens in this case? If you work it out, you need all the faces to get all the circulations. You can't throw any of them out. And if you don't throw any of them out, it's not collapsible.
00:46:52.740 - 00:46:53.332, Speaker B: Okay.
00:46:53.428 - 00:47:04.692, Speaker A: So this gives you one that's sort of stuck. I think there's a simple solution. You just take the double cover of this, and then you work in some higher dimensions similar to the symmetric, diagonally dominant systems. But I don't work that out.
00:47:04.748 - 00:47:05.580, Speaker B: Okay.
00:47:05.772 - 00:47:17.762, Speaker A: So it's interesting that very simple things happen. There's all kinds of other much more complicated things. There's things that doesn't have and all kinds of other topology things that are much more complicated. It wasn't clear.
00:47:17.898 - 00:47:19.490, Speaker B: Okay, good.
00:47:19.682 - 00:47:38.132, Speaker A: So, in the last few minutes, let me just claim that most of us here are not really that interested in doing physical simulations because there's slightly more money in other things, like social networks and all. So let's try to maybe sell this as a social network thing.
00:47:38.218 - 00:47:38.656, Speaker B: Okay?
00:47:38.720 - 00:48:01.472, Speaker A: Go to first cut. So, I claim that triangles come up quite often in social networks. There's a huge number of papers on this whole area of finding all the triangles in a social network. Magically. This is very useful for all kinds of reasons, right? There must be 100 papers on, first of all, counting triangles, but also why you would want to know the number of triangles. And this somehow tells you all kinds of things about a social network.
00:48:01.608 - 00:48:02.144, Speaker B: Okay?
00:48:02.224 - 00:48:32.280, Speaker A: So that's the first thing. There was actually papers by target and crew where they showed. And I think Jakob, one of the students, when he worked at Facebook, said that, in fact, clustering based on triangles seemed to give better results. In other words, what you do is you start by taking your social network, you find all the triangles in it, and you glue two triangles together if they share an edge, and then you use that to cluster. And as I understand, I don't think there's any proof any of this that that somehow gives a much better way of doing social network clustering.
00:48:32.452 - 00:48:34.124, Speaker B: Okay? Okay.
00:48:34.904 - 00:49:09.944, Speaker A: Recently, there's a student, Bobas, has showed that. So the other question is what you'd really like to do in social network is find cliques. Well, first of all, chances are there may be an edge missing in some large clique, and so then it's not any longer a clique, but so what you'd like to do is find something that looks like a clique. So the simplest, of course, is what you do is you try to maximize the number of edges to vertices in a subgraph. Unfortunately, that gives you things that are too big. So what he did is he went back and he said, well, let's count the number of triangles to the number of nodes in a subgraph. And magically that gives you something much better.
00:49:09.944 - 00:49:35.156, Speaker A: And it's still computable in polynomial time. So those are all things that are well known. Let me ask you a question that I don't know and that I think would be interesting. And that is, are the eigenvectors or values of our one laplacians of social networks useful? And there should be some equivalent version of a Cheeger kind of theorem for social networks, or at least it'd be nice to know why not.
00:49:35.220 - 00:49:35.804, Speaker B: Right?
00:49:35.964 - 00:49:38.904, Speaker A: So if you compute these eigenvectors, is that interesting?
00:49:39.204 - 00:49:39.876, Speaker B: Right.
00:49:40.020 - 00:49:45.516, Speaker A: And if not, then that may say that this is the wrong approach for this whole thing.
00:49:45.700 - 00:49:49.970, Speaker D: I have seen sher inequalities for entire order of eplassium.
00:49:50.052 - 00:49:52.594, Speaker A: So it's already been done. So that's good. I don't remember.
00:49:53.494 - 00:49:55.342, Speaker C: Okay, I'll find the reference for you.
00:49:55.398 - 00:49:56.430, Speaker A: No, that'd be nice.
00:49:56.542 - 00:49:57.798, Speaker B: Okay, good.
00:49:57.926 - 00:49:59.394, Speaker A: And I think that's it.
00:50:04.414 - 00:50:05.554, Speaker B: Okay, thank you.
00:50:09.774 - 00:50:11.834, Speaker C: I think we have time for questions.
00:50:17.274 - 00:50:18.654, Speaker A: More time for coffee.
00:50:19.354 - 00:50:25.294, Speaker C: I should expect that if you do some kind of a clustering based on this eigenvector of the.
00:50:28.234 - 00:50:36.274, Speaker A: Yeah, yeah. Because somehow it's going to be assigning values to vertices, to triangles. And so then you can sort the triangles by that.
00:50:36.314 - 00:50:50.504, Speaker C: Is there easy direction of some kind of, one is the harder and one is the easier direction. Is it related trivially to some quantity that you apply to optimize?
00:50:51.764 - 00:51:15.354, Speaker A: Yeah, well, that's the first question, right? I mean, is that even interesting to sort? I mean, the obvious thing is you sort the triangles by their value, right? And roughly, that's what cheeker says to do, right? And then you do something with that, right? If you sort the vertices, the triangles by that, does that tell you something interesting about the social network? All right, I think that's the first actual question.
00:51:16.494 - 00:51:30.278, Speaker C: So, Gary, I am interested in social networks, but I am maybe exceptional in this room, also interested in scientific computing. So what PDE's are amenable to this style of thinking.
00:51:30.446 - 00:51:30.894, Speaker B: Yeah.
00:51:30.974 - 00:51:43.898, Speaker A: So that's why there's this other co author, Mike Noel Walkington, who is a numerical analyst. And we found this big, huge book. You can find very big, fat books on things like doing Maxwell's equation, because that's critical in radar.
00:51:43.946 - 00:51:44.154, Speaker B: Right?
00:51:44.194 - 00:52:11.274, Speaker A: I mean, the critical thing in radar is you need to figure out whether there's a plane in there or whether that's some other kind of thing, a duck. And so somehow you need to do those things. And so these calculations would be very important. But we never got enough into the book to figure it out, other than there is this slight problem. And that is, normally, when you're doing radar, what you do is you have a convex ball. That's fine, but you also have a hole in the inside where the airplane is.
00:52:11.314 - 00:52:11.850, Speaker B: Right.
00:52:12.002 - 00:52:28.754, Speaker A: And so you need to be able to work in some kind of annulus. So then there's all these nice topological questions. So what we really need to do is find five more co authors that really have a good handle on topology, and then maybe we can make headway.
00:52:28.874 - 00:52:43.310, Speaker C: This issue of simplicial nested simplicial rom complexes and all this stuff, you know, it's a relatively hot topic in numerical digitizations for PDE's these days. And so language they use is similar to what you.
00:52:43.382 - 00:52:43.774, Speaker B: Of course.
00:52:43.814 - 00:52:52.078, Speaker C: I mean, you borrowed it from them. And it's not an area I have expertise in, but I certainly have access to people who do have expertise in it.
00:52:52.246 - 00:52:52.790, Speaker B: Yeah.
00:52:52.902 - 00:53:00.352, Speaker A: It would be fun to sit down with someone for which, you know, the language, you know, barrier isn't too big and discuss this.
00:53:00.438 - 00:53:00.972, Speaker B: Right.
00:53:01.108 - 00:53:18.244, Speaker A: And so the hope is, like, maybe one possibility is with Noel or someone like that, be able to have sort of a three or four way conversation trying to understand. Also, it'd be fun to bring in an apologist because I'm not sure to first cut. They worry about, you know, these messier kinds of questions, like collapsibility and stuff like that.
00:53:18.284 - 00:53:18.460, Speaker B: Right.
00:53:18.492 - 00:53:27.616, Speaker A: I mean, somehow I think the book that he found some of. There's a very big, famous book on this stuff and didn't worry about this particular aspect of it.
00:53:27.640 - 00:53:28.204, Speaker B: Right.
00:53:28.584 - 00:53:30.284, Speaker C: Making an act is good.
00:53:32.024 - 00:53:32.360, Speaker B: Yeah.
00:53:32.392 - 00:53:34.644, Speaker A: So, like, someone, like, have Herbert involved, right?
00:53:35.784 - 00:53:58.184, Speaker C: Ten years ago, he's continued to make this claim, which I clearly can't use as a condition. He basically said any of the sliver floating to the surface that matter. He just literally said that way. And. Well, I didn't explain, but it seems like this surface one you can somehow peel it off, sounds like.
00:53:58.484 - 00:54:00.276, Speaker B: Yeah, I don't think. I mean. Yeah.
00:54:00.380 - 00:54:05.572, Speaker A: So the trouble is then you look at these things like, you know, the dunce have, which I still haven't got my head around.
00:54:05.628 - 00:54:06.252, Speaker B: Right.
00:54:06.428 - 00:54:09.572, Speaker A: You know, and it's interesting to look it up when you go online.
00:54:09.628 - 00:54:09.796, Speaker B: Right.
00:54:09.820 - 00:54:20.896, Speaker A: I mean, there's also good youtubes on that. But anyway, so it's just simply a single triangle where you identified all three sides back on itself called the Dunsat. And that's very complicated.
00:54:20.960 - 00:54:21.472, Speaker B: Right.
00:54:21.608 - 00:54:24.844, Speaker A: Let alone anything else. Right. There's Bing's house.
00:54:30.064 - 00:54:48.548, Speaker C: All the aztec ratio are good except the one that you can somehow collapse. So somehow you have a chain of collapse that leads you to a new one that has good aspect of you. It has a numerical stability somehow to say this is a good system.
00:54:48.716 - 00:54:49.036, Speaker B: Yeah.
00:54:49.060 - 00:54:56.716, Speaker A: I don't see how just throwing in the fact that all the tests are nice is somehow going to solve the problem. I'm a little worried that it's more.
00:54:56.740 - 00:55:04.900, Speaker C: Subtle than that because tests are nice. Normally, it has nothing to do with solving this.
00:55:05.052 - 00:55:07.380, Speaker A: Yeah, but somehow we need something stronger here.
00:55:07.412 - 00:55:07.916, Speaker B: Right.
00:55:08.060 - 00:55:26.602, Speaker A: We need somehow, like, just how do you find a flow? And my feeling is there's probably some other tricks that make this stuff work. There must be more ideas how you do this, adding other tests or some other kind of. I mean, it's not really clear whether it hurts to add other stuff to the system or not.
00:55:26.738 - 00:55:27.414, Speaker B: Right.
00:55:27.754 - 00:55:32.814, Speaker A: You know, I could just imagine this is wide open. We're just not very imaginative at this point.
00:55:34.234 - 00:55:35.414, Speaker B: What should be done?
00:55:41.494 - 00:55:48.414, Speaker C: Other questions? Social networks. That's probably more interesting. Let's have a coffee.

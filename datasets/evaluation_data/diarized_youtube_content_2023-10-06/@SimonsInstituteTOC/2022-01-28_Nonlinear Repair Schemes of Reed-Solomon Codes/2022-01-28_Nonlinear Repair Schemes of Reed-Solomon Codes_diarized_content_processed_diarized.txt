00:00:01.160 - 00:00:58.104, Speaker A: Hi everyone. I'm Ronnie. I'm a PhD student at the department of Computer Science in Tel Aviv University. My advisors are Amir Spielke and Ishak Tamo. The title of this talk is nonlinear repair of fruit Solomon codes, and this is a joint work with Raktama. Our work deals with the repair problem, which is a problem from a relatively new research area called coding for distributed storage systems. So, let me first say, what are distributed storage systems, what is their goal, and how error correcting codes fit in? So the task of a distributed storage system, which is just a collection of many nodes, is to store data reliably over long periods of time using this distributed collection of storage nodes.
00:00:58.104 - 00:01:40.574, Speaker A: Now, the problem is that individual storage nodes can fail, and by failure I mean that the data that was stored on these servers is erased. Now, since the data was erased, we want to recover it. And recovering erase data requires redundancy. So the solution is basically use an erasure. Correcting code. Code in this talk is a map from fq to the k to fq to the n. And as we always do, we abuse notation and say that c is also the image of such a map.
00:01:40.574 - 00:02:40.314, Speaker A: Now, we say that c is a linear code if it is a linear subspace of dimension k. And the notation that we use is brackets nk code, where n is the length of the code words, k is the dimension of the subspace, and q is the size of the Alphabet. And note that fq here means the finite field of order q. Now, in distributed storage systems, we always use MDS codes. And MDS codes have the following property, which is that the code can correct from any n k erasures. So what is an erasure? An erasure is replacing a symbol by a question mark. So as you can see here, c one and c two were replaced by question marks and c three wasn't.
00:02:40.314 - 00:03:40.494, Speaker A: Now back to the property. The property states basically that if someone takes my code word and performs up to n k erasures anywhere he wants, and he gives me back the result, then I can basically know what the original code word was and disposes of. Decoding this corrupted code word is done efficiently in linear MDS codes. So now, after defining codes and MDs codes, we can see what is coding for distributed storage system. So when you think about coding for distributed storage systems, you can imagine the following scenario. You take a data which can be a file, and you cut it into k chunks of data. Each such chunk is going to be a symbol in a finite field of order queue.
00:03:40.494 - 00:04:32.678, Speaker A: Now, these k symbols together will be encoded to a single code word using an MDS code. So as you can see in the picture, c one, c two up to cn is a code word. Now each symbol in the code word is going to be distributed to a different server. Okay, so as you can see in the picture, c one is stored inside s one, c two is stored inside s two up to cn, which is stored in sn. I didn't say why we use MDS codes. We use MDS codes since the trade off between erasure correction capability and storage overhead in MDS codes is optimal. As I said, individual nodes can fail.
00:04:32.678 - 00:05:17.942, Speaker A: So let's consider the following problem. We have end servers that store our code word as before and assume that the last server failed. At this point we bring a new server called the replacement node, and this server needs to replace the node that failed. And in this process the server needs to recover the data that was on that server. An algorithm that recovers the lost data from the remaining nodes is called the repair scheme. If we look at the slide, we see that the nodes transmit to this new replacement node some function of the data that they store. Let's see here.
00:05:17.942 - 00:06:16.854, Speaker A: The server s one transmits mu one of c one and up to the server n one. Let's say transmits mu n one of c n minus one. Now, this replacement node gets all these values and recovers the data that was on that server that failed. The repair scheme is called linear. If the mu I's, which are the functions that compete the data that is going to be transmitted are linear functions, and by linear I mean that they are linear over the base field of the finite field fq. The bandwidth of the scheme is the total number of bits transmitted from the nodes to the replacement node. If we look back on this slide, we see that the nodes transmitted mu one of c one up to mu n one.
00:06:16.854 - 00:07:32.196, Speaker A: Then the bandwidth is this sum and the log is taken in the base of two. Since the bandwidth is measured in bits, let me say here that all the logs in this talk are going to be in base two, and that for simplicity of notations we shall avoid ceilings. The bandwidth is a parameter which we want to minimize. And why we want to minimize the bandwidth because in real life scenario a replacement of a node requires a huge amount of bandwidth. And why is that? Basically, a server stores a lot of data, and not only just one symbol, as in our example, it stores a lot of symbols. If we manage to minimize the bandwidth that is required to recover a single symbol, then we minimize the bandwidth which is required to recover many symbols, and minimizing the bandwidth will eventually increase the reliability of the system. And therefore minimizing the bandwidth is a huge problem in the area of coding for distributed storage systems.
00:07:32.196 - 00:08:37.384, Speaker A: This leads us to the repair problem. The goal is to design codes together with repair schemes that have small bandwidth. And the requirement from these repair schemes is to repair not only the last node, the nth node, but also the first, the second, basically repairing any node. This problem was initiated in the paper of Dimakis, Godfrey, Wu, Wainwright and Ramchandran in 2010, and this problem again is highly relevant also in modern distributed storage system. For example, Google and Facebook already deploy in the storage systems codes, and even in this distributed storage system, the failure of a node is not a rare incident, it happens. And when it happens, the bandwidth is a critical issue. So minimizing it is an important problem in coding for distributed storage systems.
00:08:37.384 - 00:10:00.304, Speaker A: First, let's consider what is called the trivial repair, okay? So, as we said before, our codes are MDS codes, and the MDS codes have the property that it can recover from any n k erased symbols. So equivalently any k servers, any k nodes can send their symbol to the replacement node, and the replacement node can compute the entire code word and find out also what was the failed symbol. So in this example, the first case, servers transmit, each one of them transmit its symbol. So the server that received all of these values computed c one up to cn, and therefore he knows what Cn is. So let's examine the properties of this repair. So it is linear, since every server transmitted its symbol and the symbols came from right finite field, the bandwidth is k times log q, where q is the Alphabet size. And the question is, is it optimal in terms of bandwidth? So the answer is no.
00:10:00.304 - 00:10:59.264, Speaker A: The main idea to achieve small bandwidth is to contact more than k nodes and receive fraction of information from each node. If we look at this example, we'll think of the situation where s one, let's say, sends half of the bits of c one, or for example s one, computes a function of c one and transmits only one bit. Okay? And as it turns out, contacting more than k nodes and receiving fraction of information from each node can reduce the bandwidth. So in the same paper of the Mackis et al. They show the lower bound on the bandwidth that is needed in order to recover a lost node. And the bandwidth which is denoted by b, has to be at least this quantity, where d is the number of nodes that participate in the repair. In the literature it is called helper nodes.
00:10:59.264 - 00:11:54.314, Speaker A: Now, note that if we sign instead of d we sign k. The bandwidth b has to be at least k times log q, and this matches the trivial repair. Note that in the trivial repair we indeed contacted exactly k nodes. Now note that as de starts to increase, then this quantity becomes much smaller. A code that achieves this bound with equality for any failed node and using any set of dhelpal nodes is called NKDMSR code. Now there are several MSR codes with linear repair schemes. These are just few examples.
00:11:54.314 - 00:12:56.774, Speaker A: All of these constructions in order to achieve this bound with equality, they indeed conducted more than k nodes and received partial information from each node. But none of these codes is the most famous code, which is the Reed Solomon code. So what about Reed Solomon code? So let's briefly recall what are Reed Solomon codes. So we take n distinct points in this finite field of order q, and we denote by f subscript k all the polynomials, the single variable polynomials of degree at most k. Then the code is defined by the following map. So I take a polynomial of the great most k and I map it to the evaluation vector of this polynomial at this and distinct points. And this is the nk rit Solomon code, which is defined with the evaluation points alpha one to alpha n.
00:12:56.774 - 00:14:17.344, Speaker A: Now the question is, why care about Reed Solomon codes? So Reed Solomon codes are basically everywhere, and in particular, ritzolomon codes are in current distributed storage systems. Facebook uses Reed Solomon code with parameters 14 instead of n, and k equals ten. So designing repair schemes for Reed Solomon codes with better bandwidth can find immediate applications in these storage systems. The repair problem of Ritz Olmon codes can be thought of as a new polynomial interpolation problem. Recall that in the classical interpolation problem we have k distinct points and we want to find the polynomial of degree at most k minus one that goes through all of these points. Here the question becomes how much information is needed from the points f of alpha one up to f of alpha n minus one in order to determine f of alpha n. Know that in the classical interpolation problem we need to find out the entire polynomial, while here we need just to find out a single evaluation point.
00:14:17.344 - 00:15:32.258, Speaker A: So let us review some known results. Sianmugampa, pilopoulos, Dimakis, and Kerr showed the trivial repair of Rs codes is not optimal. Basically, they gave examples of linear repair schemes with better bandwidth. Then Grossomint Waters gave a complete characterization of linear repair schemes. Fruit Solomon codes let me note here that if linear repair schemes of Fritz Solomon codes outperform the trivial repair scheme in terms of bandwidth, then it means that the code must be defined over a field extension. And why is that? Let us look at this slide here and see that for the muis to be linear, it must be that the muis are functions from a field to a subfield. Then Tamoye and Barak showed that Rs codes are NKD, MSr codes for NKD and n.
00:15:32.258 - 00:16:32.964, Speaker A: They gave explicit constructions of such codes. The thing is that their extension degree was exponential in n log n, meaning that the field size is something like two to the n to the nice. And they proved an almost matching lower bound that says that the extension degree has to be at least exponential in k log k. And again, this means that the finite field has to be of order true to the k to the k. And this is infeasible in practice. So the goal is reducing the Alphabet size. So how can we reduce the Alphabet size? So al Rabi and Guruswami showed that any MSR code, not just Solomon codes with linear repair scheme, must have large Alphabet size.
00:16:32.964 - 00:17:33.544, Speaker A: So what about nonlinear repair schemes? Can nonlinear repair scheme help us reduce the Alphabet size? And our starting point was to look at Reed Solomon codes over prime field. And why is that? Because any repair scheme for Reed Solomon codes over prime field that outperforms the trivial repair scheme must be nonlinear. This is because there are no linear functions from a prime field to a proper subset of the prime field. So let me now introduce our results. So our main result is the first nonlinear repair scheme. As far as we know, the first theorem is that almost all two dimensional Reed Solomon codes over prime fields are asymptotically n 2D MSR codes for Ned. And I'll define in second what asymptotically means.
00:17:33.544 - 00:18:47.764, Speaker A: The second theorem is a construction, and it holds for any k and d up to n over two. We give an explicit construction of RS codes where every node can be repaired with bandwidth that asymptotically achieves the Katsu bound. We know that this construction falls from being an MSR code because it doesn't hold for any set of d helper nodes. And by asymptotically in both theorems, we mean that the bandwidth achieves the cuts bound plus an additive factor that depends on n and why. We call it asymptotically because in coding for distributed storage, we think of the Alphabet size as being larger then n the number of servers. We also prove a new lower bound on the bandwidth that is required to repair a node when the code is read Solomon codes over prime fields. If we have an nk reed Solomon codes over prime field, then to repair a node.
00:18:47.764 - 00:19:52.788, Speaker A: Every node must transmit at least this quantity of bits and know that the first term corresponds to the cut set bound and the second term is our improvement of the cutset bound. This quantity is small, but it says that we cannot get as close as we want to the cutset bound. We now discuss the intuition behind our nonlinear repair. Assume that we have these functions mu I such that the repair of the nth node succeeds. Then these functions are from this finite field of prime order to some subset. Now the preimages of mu I for every element in the subset give a partition of the prime field of size a. When we look at the data transmitted from the servers to the replacement node, we can think that the servers basically transmitted the following sentence.
00:19:52.788 - 00:20:37.334, Speaker A: C two belongs to the third set induced by the partition of mu two. Okay, so instead of thinking about functions, we will think about partitions. So now I'm going to describe the proof idea. Let's look at the following partition of fp. Okay, so I start with the first group are just the number zero to t minus one. A one are the numbers from t to two, t minus one, and we continue this way. So, know that every set in the partition is of size t, except for the last set, which is of size less than t.
00:20:37.334 - 00:21:20.788, Speaker A: Now I'm going to describe how the repair scheme for the nth node looks like. So I take n minus one elements in my finite field, which are not zero. Then I'm going to define a partition of FP for every distinct node. So the node that stored c one is going to have the following partition, gamma one times a zero. This is the first set of its partition. Then gamma one times a one, the second set of its partition, and so on. Now c two is going to have a different partition that depends on gamma two.
00:21:20.788 - 00:22:15.954, Speaker A: So gamma two times a zero is going to be the first set. And we continue this way so that every node will have its own partition, which is defined by the gammas. Now note when I say an element times a set, then I mean that I multiply each element of the set with this element. Now the repair scheme is going to be the following simple process. Each node is going to send me the index of the set that the symbol belongs to. So let's say, for example, that c one belonged to the first set in the partition of gamma one, and c two belongs to the third set in the partition of gamma two. Then every server transmitted me the index of the set.
00:22:15.954 - 00:22:57.282, Speaker A: So the first node transmitted zero. Then the second node transmitted two, and the last node here transmitted s minus one. Now I'm going to phrase a condition such that if the condition holds, then the repair succeeds. So the condition is as follows. So I take two distinct code words in c. If on both c and c prime, the nodes transmit the same values, it must be that they agree on the last value, meaning that cn equals cn prime. So if we look back here, then suppose we have c and c prime.
00:22:57.282 - 00:23:50.644, Speaker A: Then consider the case where c one and c one prime belonged to the first set, c two and c two prime belonged to the third set, and so on. Then if they agree on the last coordinate, then the repair succeeds. Okay, and this makes sense when I think about Reed Solomon codes. Then I can picture this condition and see that this condition basically says the following. So for any two polynomials that on alpha one, the value on alpha one is inside this set, and the value on alpha two is inside this set, and so on up to n minus one. Then the condition states that on alpha n the polynomials agree. What we did in our work is we phrased an even simpler condition.
00:23:50.644 - 00:24:36.518, Speaker A: Okay, we worked with this condition. So what the condition says for every code word, if it holds that for any j up to n minus one, cj belongs to the set gamma j times the interval from minus t to t, then cn must equal zero. So this is the condition, and the proposition states the following. So if the condition holds, then the repair of cn succeeds and the bandwidth is n minus one times log to the base of two ceiling of p over t. First, let's see why. This is the bandwidth. This is the bandwidth, since recall that every node sends us the index of the set.
00:24:36.518 - 00:25:37.904, Speaker A: So to represent this number we need at most log of the number of sets, and the number of sets is p over t. Let's prove the proposition. Now I assume towards the contradiction that the repair does not work. So this means basically that I have two code words such that on both the nodes return the same set indices in that cn does not equal cn prime, meaning that they do not agree on the last coordinate. I define the difference of these code words and know that since the code is linear, then c double prime is a legal code word. It holds that cj for any j between one and n minus one belongs to descent gamma j times the interval from minus t to t. Therefore, we got a contradiction to our condition.
00:25:37.904 - 00:26:22.104, Speaker A: This is a contradiction to our condition. Since c double prime on all the indices from one to n minus one belongs to this set of gamma j times minus t t. But on the last coordinate it does not equal zero so our condition does not hold. Note that in the third bullet, we used the structures of our sets in the partition. Recall what our sets are. Okay, so these were our sets. Now, the partition was just taking some element and multiplying it with every set.
00:26:22.104 - 00:27:32.984, Speaker A: So if I take two elements, let's say in gamma one, a two, and I do one element minus the other, then since a two has the elements from two t to three, t minus one, then when I do one element minus the other, then I am the interval from minus t to t. Okay, so let's go back. So what we need, we need to show that there are alpha one to alpha n evaluation points by which we define our reed Solomon codes and values gamma one to gamma n minus one, for which the condition holds. We also need to maximize t in order to achieve small bandwidth. Okay, as t gets larger, the bandwidth gets smaller. Now, note that I showed you a condition for repairing the nth node. The condition can be formulated such that all the nodes can be repaired, but each node requires different gammas.
00:27:32.984 - 00:28:50.116, Speaker A: So this is exactly what we did in our work. For the open questions, we have the immediate open question to construct or show existence of rs codes over time field that are asymptotically MSR codes. So note we show that almost all two dimensional Reed Solomon codes over prime field are asymptotically MSL codes. And in terms of constructions, we provided a construction for larger values of k that even though they have good repair properties, they are not MSR codes. And another interesting open question is to better understand the tension between p, the field size, and k, or n, the dimension or the length of the code. And we know that there is a connection between our work on repairing Reed Solomon code and the leakage resilience of shamir secret sharing schemes. So better understanding the tension between p and k has applications in that field.
00:28:50.116 - 00:28:56.644, Speaker A: Also, thank you for listening and hope to see you in the live session.

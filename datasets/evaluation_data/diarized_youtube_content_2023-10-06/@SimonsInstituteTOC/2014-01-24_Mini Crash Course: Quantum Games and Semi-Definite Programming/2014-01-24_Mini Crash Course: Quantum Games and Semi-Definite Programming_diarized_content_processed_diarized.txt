00:00:00.720 - 00:00:35.170, Speaker A: This is going to be a little bit of a different nature from the previous talks, so a little bit more focused, a little bit more technical. I mean, some of it, I have general slides and then some of it will be on the whiteboard. We also have a little bit more time, so I'll try not to abuse it, but this is modular. I can easily cut stuff out, so please stop me a lot and ask questions. The audience is kind of diverse, probably, so I might be assuming a little bit too much of you. If I do, stop me right away. So I'll talk about quantum multiplayer games, this kind of.
00:00:35.170 - 00:01:14.774, Speaker A: So I mean, we've heard a lot about them today already. It's an area that has a long history and recently there's been some interesting progress. So the goal is to do a couple things. I mean, one is to sort of bring you up to date on some recent results, but more than that, try to give you a feeling for the area, right? So that you'd, as Umar said, maybe you'd feel comfortable maybe proving your own results in the area or at least sort of using it so it becomes less intimidating. So I don't know if I'll get there, but we'll try. So that's why there's a question mark, right? So let's see. So I have a little bit of motivation to start.
00:01:14.774 - 00:01:59.304, Speaker A: So the. So we'll be looking at those games from a computational complexity point of view, because that's the point of view that's adopted in classical computer science, the study of classical multiplayer games. So I'm not going to review those too much, but they have a very long, rich history behind them. They were introduced in the, their study started sort of in the eighties, and it had two motivations. Some motivation came from cryptography, people studying the possibility for having zero knowledge proof systems, and the other came from complexity theory, studying the notion of interactive proofs. And the games sort of came out of these questions. So from cryptography, from complexity theory, very long, very active period of work studying games led to the PCP theorem.
00:01:59.304 - 00:02:54.346, Speaker A: You can think of PCP theorem in many different ways, but one of them is to, one of the points of view that led to the PCP theorem is this games point of view, which is so you can really think of them as just a different way to think about constraint satisfaction problems, but it's a different way that lets you ask different questions and maybe is more useful to study different kind of problems. For example, the problem of parallel repetition is a problem that arises easily when you phrase things as games less. So when you phrase them as constraint satisfaction problems, it's also an area that's still very active. There's a lot of open questions in the study of classical multiplayer games or classical constraint satisfaction problems. I'm not going to go into them too much. So we're going to be looking at quantum multiplayer games. Um, and these are older in classical multiplayer games, but we know much less about them.
00:02:54.346 - 00:03:21.044, Speaker A: So they're basically asking for such a theory that has been developed in the classical case. This is sort of what I want to try to give a starting point for in my talk. So I'll give you a little bit more motivation later. So let's see, what's the agenda. So on slides, I'll give you a few definitions, a little bit of motivation. Um, I'll state a bunch of open questions just to. Just to say what is the.
00:03:21.044 - 00:03:47.948, Speaker A: The state of the art in the study of the multiplayer games? And then I want to go and switch to the whiteboard and try to do what. What Umesh said. So he. He said, you know, I learned it at the same time as you guys. So, um, that we want to be giving a sophisticated and basic picture of the area. You said something like this. And actually here my task is easy because the area is sort of young, and so the basic picture and the sophisticated picture are basically the same thing, which is just the.
00:03:47.948 - 00:04:16.074, Speaker A: The. Of the theory that I'll try to describe. So mostly what I'll focus on is try to describe something you could call, although it's not usually called like this, a cook Levin theorem for quantum multiplayer games, which would just be a basic np hardness result. Right. If you think of the cook Levin theorem, saying that three SAT is np hard is sort of a basic NP hardness result for constraint satisfaction problems. Classical constraint satisfaction problems. I want to try to give you a flavor of the same theorem for quantum multiplayer games.
00:04:16.074 - 00:04:22.274, Speaker A: Well, you know, hopefully I get to explain more what I mean, then there'll be some conclusions.
00:04:25.134 - 00:04:30.254, Speaker B: Is it completely off topic to ask for the game viewpoint of string satisfaction?
00:04:30.294 - 00:04:39.006, Speaker A: Yeah, next slide. It's on topic. Thank you, Lev. Other questions or. I think so. You can ask me again after the next slide. Yeah.
00:04:39.070 - 00:04:47.378, Speaker C: When you say what they prove, then the two proverbs games are also begging for a theory, or just in particular the three and more two.
00:04:47.426 - 00:05:06.834, Speaker A: No, no, this is two, actually. Most of my talk will be about two. Three is also, you know, begging for it, but most of the talk will be about quantum two. So it depends what you call theory. So I'll say you know, what is known about that theory? So there is a theory. So I guess I did. I call it embryo of a theory somewhere.
00:05:06.834 - 00:05:26.844, Speaker A: Yeah, yeah. Here. So this is what I describe. So I'm not saying, I'm not creating it on the spot. So this exists. I mean, I'll give citations, but it goes nowhere as far as this, let's say. So that's why I'm saying it's begging to be developed along the same lines as hopefully as productively as it was developed here.
00:05:26.844 - 00:05:53.558, Speaker A: All right, so this is what I wanted to start with. Just recall the correspondence between classical constraint satisfaction problems and games. Just phrase them as the same thing. And also, this is a way for me to say what these games are, which might not be clear for everyone. So, I'll start with a constraint satisfaction problem. Some of you might have seen this before. It's a particular CSP.
00:05:53.558 - 00:06:29.194, Speaker A: It has nine variables, six constraints. So you can think of these nine variables as being arranged in the little square. That's the nine variables. And then the constraints are that these variables should be assigned plus minus one values, such that if I take the product of the variables in any column, I get plus one, and if I take the product of the variables in any row, then I get minus one, such the constraints. We can try to satisfy the constraints column by column. Here I got stuck, right, because x nine wants to be plus one on the one hand, minus one on the other hand. So there's a good reason for this, is that my system of constraints is not satisfiable.
00:06:29.194 - 00:06:47.656, Speaker A: Maybe you can see the reason already. The column constraints are saying that the product of the nine variables should be plus one. The raw constraints, they're saying that the product should be minus one. So this is incompatible, right? So I can't say. But this is just a constraint satisfaction problem. So let's make it into a game now. So what's the kind of games I'm talking about? So it's like this.
00:06:47.656 - 00:07:08.494, Speaker A: I'll describe it for this square, but you could do it for any local constraint satisfaction problem. So, the game is run by the referee. This person here, he asks questions to the players. So Alice and Bob are the two players. They play the game, they cooperate, they try to win in the game, but they're not allowed to communicate throughout. They can meet up beforehand. They know what the rules are, they can decide on the strategy.
00:07:08.494 - 00:07:36.610, Speaker A: But once the game has started, no talking. So here's the game. The referee picks one of the six constraints uniformly at random, and he asks Alice about it. So for instance, the second column. And then he picks one of the three variables that appears in that constraint and asks Bob about it. Then the players have to reply with assignments to the values of the variables they were asked about. Alice, the three variables, Bob, the one variable such that Alice's answers satisfy the constraint and Bob's answer.
00:07:36.610 - 00:08:08.604, Speaker A: So Bob only got to see one variable, right? And because he doesn't communicate, he doesn't know if he was asked X eight as part of the second column or as part of the third row, right? He only knows X eight. He has to provide an answer to X eight that is consistent with what Alice said. So in that case it works out. He said one, she said one. So it's ok, they're accepted. So given a game in general, there's one quantity that we're going to be talking about throughout the talk, which is the maximum success probability of the players in the game. I'll write it as Omega.
00:08:08.604 - 00:08:32.882, Speaker A: Ms here just means magic square game. It's this game in general. This is just g for the game. So it's the maximum success probability that's taken over the randomness that's part of the description of the game. So the referee here chooses his questions at random, and if the player is wanted, they can use randomized strategies. So here, maximum success probability, turns out is equal to 17 over 18. Um, what's relevant for us is that it's not one.
00:08:32.882 - 00:09:10.544, Speaker A: Um, and the reason it's not one is because the system of constraints was not satisfiable. This is something that happens in general. I could have started from any CSP, make it into a game and you have a nice correspondence in between. Well, if the system of constraints had been inside this variable, it would be clear that you can win my game with probability one. Right. Just find an assignment that satisfies all the constraints and always answer consistently according to that fixed assignment. What's also not completely obvious, but is true, is that if this thing is not satisfiable, then you cannot win the game perfectly with probability one.
00:09:10.544 - 00:09:38.042, Speaker A: I know if everyone can see this, it's represented here. Maybe we can do it on the example of the magic square. And suppose that you can win that game with probability one. And let's look at what Bob does in the game. Bob is asked just variables and he provides answers. So in his mind he must have a little table like this which says, well, what is every answer, every possible answer that he could give to every possible question. So we can look at Bob's table and if they win the game with probability one.
00:09:38.042 - 00:09:55.356, Speaker A: This table must be consistent with Alice's table. Alice has a bigger table. She has one assignment of values for every possible constraint. But if they win in probability one, Bob must be consistent with Alice. Alice must satisfy the constraints. So Bob here, this assignment must satisfy all the constraints in the square. So they won with probability one.
00:09:55.356 - 00:10:38.262, Speaker A: My constraint satisfaction problem would have been satisfiable, but it's not. So they can't win with probability one. The problem here is that when Bob is asked x nine, he says one. But when Alice is asked third column, there, she says minus one for x nine. So they get caught for that one possible question. So this explains this value here. This is something that's very general, and it has one important consequence, which is that if we know that deciding Sat is NP hard, then we have, as an immediate corollary that deciding whether, given a game, deciding whether the value of this game is equal to one or not one is an NP hard problem, right? Hopefully that's clear, because just because of the previous correspondence, right, the value is one if and only if the formula is satisfiable.
00:10:38.262 - 00:11:24.684, Speaker A: So deciding the one is just as hard as deciding the other. So correspondence, you can push a little bit further. Um, it's not only that this is satisfiable if and only if this is perfectly winnable. It's also that this is almost satisfiable if and only if this is almost perfectly winnable. So this correspondence, up to some scaling, respects the maximum satisfiability of the consensus component, the maximum number of clauses that are simultaneously satisfiable, and the PCP theorem. So if you accept the PCB theorem says that approximating the maximum number of clauses that are simultaneously satisfiable in the three stack formula to within some small constant factor, this NP hard. So as a consequence, we also get that approximating the value of these games is NP hard.
00:11:24.684 - 00:12:02.852, Speaker A: All right, so that's for classical games. Now we look at quantum games, quantum multiplayer games. The main difference is just going to be this. Now, I consider strategies for my players that still do not allow communication, but might use entanglement. So the two players come up, start the game sharing an entangled state, and then they can make, upon receiving their questions, they'll make a measurement on their share of the state. This measurement will produce outcomes, and they can use these outcomes directly as their answers, or do some post processing whatever they want in this entity, the answer is back, right? So we all know. I think everyone knows.
00:12:02.852 - 00:12:31.542, Speaker A: I mean, does everyone has a background in quantum information here, or are some people just curious, sort of assuming because of the previous talks, I'm assuming everyone knows a little bit of quantum. Well, if you don't speak up. So this entanglement is going to allow for correlations. Well, we've seen the chsh game, right? So everyone has seen such things. So their success probability might increase. And this is what happens in this game. Actually here.
00:12:31.542 - 00:12:57.054, Speaker A: It's very striking because there is a strategy that uses entanglement, just a pair of VPR pairs. It's a very simple strategy and it wins in this game with probability exactly one. It's very striking because it means that this nice correspondence we had completely breaks down because the constraint satisfaction problem is the same. I didn't change the square. It's still not satisfiable. Exactly same situation as before. But now I can win the game with probability one.
00:12:57.054 - 00:13:27.762, Speaker A: So these are the questions. So why, how come I can win the game 41 even though this system of constraints is still not satisfiable, and that's because this here, this arrow doesn't exist anymore. A quantum strategy. If I think about what is Bob doing before he was classical, and I could say for every question he has an answer, and let's list the answers. Now he's using a quantum strategy. This quantum strategy involves measuring his state. So for every question he has a measurement.
00:13:27.762 - 00:13:57.926, Speaker A: So I can make a table of measurements. There's no way that I can say, well, you know, what would he answer if he was asked? X one and x two and x three and x four. This would involve repeatedly measuring the state. But if the measurements are incompatible, there's no meaningful way in which to make this repeated measurement. This is the table would depend on the order in which I make the measurements. There's something that broke down. We allow quantum strategies and we lose the fact that to every strategy in this game we could associate some global object, which was just the list of all possible answers.
00:13:57.926 - 00:14:12.766, Speaker A: Quantum strategies only have a local nature. They only let you define for every pair of questions the probability distribution on answers that arises from making the corresponding measurements. So this is why this thing broke down. Is it a problem? Yes.
00:14:12.870 - 00:14:24.354, Speaker B: Can you explain that? Like, what's the problem with creating a table? That's for each question for Alice gives the projective measurements on the state. Like the projected state on that.
00:14:25.734 - 00:14:54.578, Speaker A: Yeah. So we can do that. We can have a table. So the one I suggested was for every question to write down what is the measurement? And maybe the state, I mean, the state is the same all the time and you're suggesting the post measurement state maybe, or something. Yeah, no, that table exists, but I can't link it back to this, to the constraint satisfaction problem. What I can't create is a consistent, I mean, the sense of meaningful assignment of values. But of course I can say what quantum strategy is and we'll see it later.
00:14:54.578 - 00:15:02.294, Speaker A: I mean, it's a concrete object indeed. There's just a bunch of matrices, but there's no assignment, no global assignment.
00:15:04.014 - 00:15:15.318, Speaker C: So when you look at the left. So does it make sense to say you are looking for a quantum solution or it does not make sense. So you are definitely looking for a classical solution.
00:15:15.406 - 00:15:52.834, Speaker A: Yes. So there's many interpretations you could give to giving a quantum solution. One is exactly this one. We'd say that the classical constraint satisfaction problem has a quantum solution if and only if there is a quantum strategy that succeeds with RD one in the associated game. That's kind of the point of view that I'm going to take in the talk, because we're interested in the games to start with, not necessarily the constraints problem, but you could have others. You can think of a quantum solution to a CSP like this as a non commutative version of the classical solution. And in that particular example, this is not something I'm going to go into, but I think it's an interesting question, so I'll just mention it.
00:15:52.834 - 00:16:41.536, Speaker A: The reason why, I mean, one way to think of the reason why the success probability is one, in that case is exactly that. There is no classical solution to the CSP, but there's a non commutative solution. So in what sense? In the sense that there exists a bunch of nine matrices x nine. So you can think of them as in that particular case, they're just four by four complex matrices, their hermitian, and they square to identity, so they have plus minus one eigenvalues. So this is kind of the correspondence and they satisfy all equations in the sense that, for example, x one times x two times x three matrix product is equal to the identity, et cetera. And then the one that needs to be minus one will equal minus identity.
00:16:41.560 - 00:17:09.464, Speaker C: This is the kind of thing I meant, so that's very cool actually. But I want to say that this translation from this CSD to this game is slightly artificial because like, because if it was a bipartite game, you wouldn't have to, like on one side you wouldn't have to do the variables and on the other side the constraints, but.
00:17:09.624 - 00:17:11.200, Speaker A: You could just, you could just do.
00:17:11.232 - 00:17:14.240, Speaker C: The constraints and that would be the natural translation.
00:17:14.352 - 00:17:15.784, Speaker A: If it's bipartite to start with. Yeah.
00:17:15.824 - 00:17:25.533, Speaker C: You are already designing kind of a. Like a translation method, which is. Which is not carved in stone in some way.
00:17:25.693 - 00:17:31.341, Speaker A: No, that's a very good point. Sorry. In this case. In that case, I could.
00:17:31.437 - 00:17:38.713, Speaker C: In this case you could, but it's. You couldn't do it always. No, it's not bipartite. You couldn't do it.
00:17:39.253 - 00:17:54.684, Speaker A: You could do this always, but not. Yeah, yeah. So this is why I. So you're right. You're completely right. There's some arbitrariness and there's many ways in which you could think of making such transformation. If the CSP is bipartite, there's maybe perhaps more natural one.
00:17:54.684 - 00:18:01.472, Speaker A: Classically, they're all equivalent. They all sort of preserve the maximum satisfiability. Quantum. It's not clear at all that they're equivalent.
00:18:01.568 - 00:18:31.962, Speaker C: And so I just want to say to that is that when you do this translation, like classically, then you translate the CSP to another CSP, a sense. And. And there is a difference between, I mean, the new CSP has this extra structure and when, for instance, it comes to the prior repetition, then for games with this extra structure, it's easier to prove the per repetition theorem than without this extra structure.
00:18:32.098 - 00:18:32.370, Speaker A: Right.
00:18:32.402 - 00:18:38.886, Speaker C: The projection proof is easier than, let's say, the round routes proof, but.
00:18:38.950 - 00:19:10.836, Speaker A: Okay, so these are all very good points. So the reason I'm choosing, I'm not. I also don't intend to set this transformation in stone. What I'm interested in is studying complexity theory of multiplayer games, not necessarily of CSP's. So I'm interested in any kind of game that arises from a CSP in this way or not. The reason I'm taking this transformation is just because I want to use the classical theory to prove things about the games themselves. But you're right.
00:19:10.836 - 00:19:20.964, Speaker A: And this is one reason why I'd be wary of saying what is a quantum solution to a constraint satisfaction problem, because, you know, so we've already seen two different things. I mean, you suggested some more.
00:19:21.124 - 00:19:24.180, Speaker C: Yeah, but this feels like a quantum solution to that.
00:19:24.252 - 00:19:26.220, Speaker A: No, that's a non commutative solution to that.
00:19:26.252 - 00:19:33.544, Speaker C: But it doesn't have like a good size. I mean, this. This feels carved in stone as opposed to this translation.
00:19:33.584 - 00:20:06.494, Speaker A: It is, it is, but it has the advantage that it's mathematically natural. And I think this is very, very interesting. The reason I'm sticking with this is that this is what arises in quantum theory. I mean, this is the thing that you'll be able to apply, this is what shows up in device independence. This is what shows up when you study entanglement non locality. So this is the, I mean, if you're interested in quantum information, it's, this would give you, you know, probably insights, but it's, this is the real problem. So this is what.
00:20:06.494 - 00:20:22.238, Speaker A: But I agree, certainly lots of nice things to be said about it. Let's call it a non commutative formulation.
00:20:22.426 - 00:20:29.718, Speaker B: The non commun, can you use that to devise the strategy? Can you extract the strategy that they use?
00:20:29.806 - 00:20:59.266, Speaker A: Yes. So this is a stronger requirement than succeeding in the game. So if you give me such matrices, I'll come up with a strategy for this particular game. Again, this is not something very general. One nice thing to observe about this. You know, how come this is possible? Just because before we said this is not possible. How did we prove it? We multiplied all the nine variables in two different ways, right? By columns and by rows.
00:20:59.266 - 00:21:31.614, Speaker A: And we said the products should be the same. It can't be one and minus one. Here it's okay with the matrices, because if you multiply the nine matrices by rows or by columns, again, you get the product of the nine matrices, but in different orders, right, by rows or by columns. So it's fine that it would be identity and minus identity. This is an exercise coming out of these matrices. They're four by four, the tensor products of poly matrices. It's easy to talk a little bit more about what is happening here, connect to things that maybe some in the audience know.
00:21:31.614 - 00:22:14.082, Speaker A: I wanted to relate, oh, and also to the title of my talk, which was supposed to be about semi definite programming. So this situation where, here, where what I said is what happens with quantum strategies is that they have this local existence for every pair of questions you have a distribution on answers, but you don't have a distribution on answers to all possible questions jointly, only the ones that arise in the game. This is also something that happens when you study linear programming or semi definite programming, relaxations of constraint satisfaction problems, or classical multiplayer games. I won't say too much about this. If you don't know about sdps, SDP relaxations for CSP's, then you won't follow the slide. But it's okay where you have this constraint satisfaction problem. Here the constraints are on the edges.
00:22:14.082 - 00:22:45.014, Speaker A: You take the relaxation. SDP relaxation. The SDP relaxation will give you vectors associated with each variable, such that when you take something like the inner products of the vectors along the edges, you can interpret that as a distribution on assignments to the pair. For example, x one, x four. That is going to satisfy the constraint of high probability. So, given any pair of vectors, you have a distribution on answers or assignments for that particular edge. But there's no distribution, no global distribution to all the variables that you can extract just from the vectors themselves.
00:22:45.014 - 00:23:14.684, Speaker A: This is what you do when you start the SDP hierarchies. You try to build upon that. So quantum setting is very similar to that with local existence, no global existence, but have a little bit more structure. And this is what we want to try to be using when we study quantum multiplayer games. What differentiates them just from these vectors here? So I'd say what quantum strategies are, but they're not just vectors, they're matrices. These matrices are sometimes positive, sometimes they have bounded operator norm. But we'll get more into that.
00:23:14.684 - 00:23:33.098, Speaker A: I just wanted to point out the connection at that level, and I'll make it again later, because this is just one side. We've seen this already. I just wanted to motivate. So, from the physics point of view, why do we study these games? They started from Podolsky Rosen. They didn't call it a game, they called it a thought experiment. But the, this is what happened to them. I mean, they observed.
00:23:33.098 - 00:23:59.474, Speaker A: That. Seems that quantum mechanics predicts these very strong correlations that can be obtained by measuring particles that are space time separated. And this is sort of contrary to intuition, or depending how you phrase it, it can be contrary to intuition. And the way they phrased it, it was contrary to intuition. So there was lots of confusion. But then Umesh mentioned this. I mean, Bell came along 30 years later, and he reformulated their paradox in a more mathematically sound way.
00:23:59.474 - 00:24:34.970, Speaker A: You know, just by saying, you know, there's no causation, so there's no communication in between these particles. It's just that the distributions that you generate have correlations. They have stronger correlations that you could do classically or that you could do using local hidden variables. And then later, cluster, Horner, Simone and Holt built upon Bell by creating this CHSH game. They called it CHSH inequality. So this was a much simpler formulation even than what Bell had. And the great advantage of their simple formulation is that it lends itself to making experiments.
00:24:34.970 - 00:24:49.962, Speaker A: So then this still was a game. You could think of this as a game with continuous inputs, outputs. This is a game with two inputs, two outputs per player. So you can do the experiment. It's been done many times, verified. So quantum mechanics is non local. We have to deal with it.
00:24:49.962 - 00:25:32.198, Speaker A: This is why we understand one of the big motivations, why we want to understand these games in the first place. This is the kind of questions that arise when you study the games, the kind of questions that come from foundations of quantum mechanics. Mostly you want to try to understand entanglement, and these correlations generate from entanglement. But recently there's a whole new array of questions and applications for quantum multiplayer games that's been surfacing, and we heard about these applications in the, in the previous talk, so I'm not going to go over there more. We might hear more about them later in the week. All right, so these are my games. I've sort of said this already, but just again, say the model.
00:25:32.198 - 00:26:12.874, Speaker A: What are the games? We consider they could have any number of players, mostly going to be two players in this talk, but could be three players, four players. They can also have, in principle, more than one round of interaction, although again, I'll stick to games that have one round of interaction for the talk, but you could think of them as being a bit more general. And the main quantity is this maximum probability of acceptance. Right? And the game again is specified explicitly to everyone. So everyone has a complete list of all the possible questions in the game. What is the probability that this question is being asked all the possible answers? And what are those valid answers? Everyone knows that the only thing they don't know is which question the other guys got. And that is what makes it hard to, to play in the game.
00:26:12.874 - 00:26:42.198, Speaker A: So if there's no star, this omega here, this will be the classical value, the optimum over classical strategies. And we already saw this. So this is a quantity that's NP hard to approximate as a result of the PCP theorem within constant factors. I mentioned this. So then the one we look at is the omega star. So this is the maximum success probability of quantum strategies so they can use entangled states. And this we don't know.
00:26:42.198 - 00:27:14.606, Speaker A: Or. Well, I'll say what we know, but the question that I'm asking here that we want to be studying is what is the complexity of computing or approximating this quantum value word? We saw proof of this here. I mean, assuming PCP theorem, we saw that proof broke down when you studied this value. And now suddenly we don't know. Given a description of the game, can we figure out what is the maximum success probability of quantum players in the game? When, what is the optimum strategy? It could be easier. It could be harder. The one thing we know is that this value is larger than this value.
00:27:14.606 - 00:27:45.952, Speaker A: This is clear. I'm allowing you one more resource. You have to do better. For instance, if this value was always equal to one, if you could always win with priority one, it would be a very easy problem. We don't expect this to be the case, but we don't know questions so far. So now I have. Okay, what's coming up? I have three slides of sort of state of the art open questions that I'm going to flash by relatively fast just to give you a flavor of where the area stands, what kind of questions people ask, what kind of techniques are used.
00:27:45.952 - 00:28:07.486, Speaker A: Some of it will be lost, but I'll get back to them at the end of the talk. Once I've shown you these open questions, I will get to the board and we'll start talking about this in a little bit more detail, formalize the situation a little bit, and tell you what we do. Yeah. So the problem is well defined, but are you going to explain more why.
00:28:07.510 - 00:28:09.438, Speaker B: It is important and why we should care about it?
00:28:09.486 - 00:28:25.780, Speaker A: No. So which problem? So you can ask me now. So where do we. I think you care. Right. Because you've written papers where you study games and you've observed that it's usually sort of hard to work with these games because you have few analytic tools. Right.
00:28:25.780 - 00:28:55.776, Speaker A: And actually, one of the class of games you focus on in your papers are XOR games, which is the one class of quantum games for which we know an answer to this. And the answer is, we can compute it in polynomial time. And I think we've observed that. I mean, the reason it can be computed in polynomial time is because there's a semi definite programming formulation for computing this value in the particular case of x four games. And that's extremely useful. Right? Because we have an SDP, we have algorithms under that is some structure that can be used to study device independence. I mean, these questions, in the end.
00:28:55.840 - 00:28:57.968, Speaker B: Well, I guess there are more papers that IMSF wrote.
00:28:58.016 - 00:28:59.844, Speaker A: I'm not sure about the value of them, but.
00:29:02.784 - 00:29:04.408, Speaker B: For that paper, I think already.
00:29:04.496 - 00:29:24.414, Speaker A: And what we use is the property. Yes. Yeah. So I think, I mean, this is something you could ask the general. This is maybe a general question about complexity theory, and I should let the experts answer. My understanding of this is just, this is an object. It's like the basic object is a multiplayer game.
00:29:24.414 - 00:29:54.198, Speaker A: This you want to understand because it has to do with foundations. Entanglement, it's used in device independence. It's sort of an abstract concept that shows up a lot. You want to understand it, so you want to be working with it. And this question of what is the complexity? This is like a basic question that will let you categorize which games maybe are easy to work with, which games are hard to work with. It's sort of a basic high level question that you're asking. Answering this doesn't have any direct applications, but it has bearings on the understanding.
00:29:54.198 - 00:30:26.234, Speaker A: So it's not like, I wouldn't say, for example, a similar flavor question is when you study quantum pc p theorem. Right. We'll talk about tomorrow, I think, Aram, a little bit Friday where there you try to really connect the complexity theory question with physical question, what is the complexity of quantum states here? I'm not trying to do that. I'm just saying this is a basic object that shows up a lot. I want to understand the object and the length. My lens is complexity theory. If I come up with polynomial time algorithms, this is great because it means I have found some structure that's useful.
00:30:26.234 - 00:30:41.306, Speaker A: If I show that some NP hardness result, well, it means that it's complex. I know that answers. Yeah, I'll get to that. We don't know.
00:30:41.330 - 00:31:05.646, Speaker C: I mean, if, like classically, the Tukluvergne correspond to constraint satisfaction problems, and solving constraint satisfaction problems is amply hard, and you would guess that like quantum, the solving correspond to quantum constraint satisfaction problems.
00:31:05.750 - 00:31:06.150, Speaker A: Yeah.
00:31:06.222 - 00:31:10.478, Speaker C: So where is the catch? You will tell about the catch.
00:31:10.526 - 00:31:35.854, Speaker A: No, this is an open question. There's no catch. Let me get, let me get to my questions. And then what's a quantum constraint satisfaction problem? Local hamiltonian system? System, maybe? No, no, this is, okay, this I'm not going to get into, because this is. Yeah, we should talk about this offline because we can talk about this for hours.
00:31:36.674 - 00:31:39.054, Speaker B: What's the ether and afro bound for?
00:31:39.354 - 00:32:16.912, Speaker A: No, let me do the next slide. Okay, so what's, very briefly, what's known and what are the open questions on this problem that I've been raising, computing or approximating the entangled value? So, two obvious observations. I mean, one is it's a quadratic optimization problem, just because Alice, Bob, just like in the classical case, but there's no a priori bound on the dimension of the strategies that I'll be using. So there's no obvious upper bound on the complexity in this, of this problem. And for all we know, there's also not any, sorry. There's no obvious upper bound, and there's no known upper bound. So we don't know.
00:32:16.912 - 00:32:43.634, Speaker A: So this problem could be as complicated as you want. There's no upper bounds there particularly. It could be QMA hard. Very well, we don't know there's particular issues that arise when you try to define the value for infinite dimensional strategies. I'm not going to get into these. So for me, we'll only focus on finite dimensional strategies here. So for that case, you can define.
00:32:43.634 - 00:33:23.490, Speaker A: There's a semi definite programming hierarchy which provides better and better upper bounds, converges in the limit, but there's no bound on the rate of convergence. So you don't, it doesn't give you any upper bound, converges in the limit. But you do know what is the dimension of a strategy, let's say the dimension of the entangled state, you know, Alice's times, Bob's, for example. I'll get to that also when we so start writing an equation. So upper bounds, there's none on this problem we don't know. It could be very hard lower bounds. For a long time there was few.
00:33:23.490 - 00:33:51.198, Speaker A: Now we know a little bit. So one thing we know is that exactly. Computing this entanglement value is NP hard. This result from 2008, 2009, and this is basically what I'm going to sort of prove for you, not in full detail, but almost all detail. So you'll know how to prove this. How we get around the difficulty that we had before. We also know that it's for the case where you allow more than two players, you allow three players or more.
00:33:51.198 - 00:34:20.954, Speaker A: Then we know that the problem of computing approximating the value is an NP hard problem. So it's a hard problem. This is even true for three player XOR games. So these are the best lower bounds that we know. These are kind of techniques that go up improving the lower bounds that we're going to insist. In some cases, we have point number time algorithms, basically two cases. One, I already mentioned two player Xor games, and then a slight generalization, two player unique games.
00:34:20.954 - 00:35:02.374, Speaker A: So for these two classes of games, these special types of games, there are polynomial time algorithms based on the use of semi definite programming that give you very good, in that case, exact computation of the value, in that case, good approximation to the Omega star quantity, but I won't describe those. A big open question here is what happens for general two player games. I would say that's the major open question in the area. For three player games, we know that it's at least NP hard. Maybe it's QMA hard, I don't know, but it's at least NP hard. Two player games. In some cases, we have algorithms, but these are very specific kinds of games, more general games we don't know.
00:35:02.374 - 00:35:19.506, Speaker A: My guess would be it should be NP hard, but it's not proven. So, open question. You cannot think of it as a search for PCP theorem. Yeah, you can. It's one definition of what it would be. Yeah. So I guess quantum pC pTM is already taken.
00:35:19.506 - 00:35:39.074, Speaker A: So for the local hamiltonian problem, and they're different. That's why I'm not saying it. But, yeah. You know what? You interpret PCP, right? Yeah. I mean, this could be just as well, right? Yeah, it could be maybe called PCPA and PCP. Yeah, let's find better names. But, yeah.
00:35:40.014 - 00:35:42.198, Speaker B: Sorry, what are you calling the PCB?
00:35:42.366 - 00:35:55.174, Speaker A: The last line. Last line. I mean, I guess, positive answer to last line. Yeah, you could. So, you know, I mean, then there's this result, right? And you could say, well, let's. Which result? The NP hardness. But for three players.
00:35:55.174 - 00:36:04.762, Speaker A: Right, right. So then you can insist on having two players, which is what I'm doing here, because it's. So basically you're saying, well, in the.
00:36:04.818 - 00:36:07.482, Speaker B: Classical PCP theorem, two players is the.
00:36:07.498 - 00:36:15.938, Speaker A: Same as having a proof, and here it's not. Yeah. In the quantum case, it's not. And so in the quantum case, local.
00:36:15.986 - 00:36:17.738, Speaker B: Hamiltonians is the same as having a.
00:36:17.746 - 00:36:30.662, Speaker A: Proof, and two players is a different thing. Yeah, yeah. I mean, that's the problem. It's just that there's. You're not agreeing with the use of PCP theorem for this. No, no, I don't mind using PCP theorem.
00:36:30.718 - 00:36:31.470, Speaker B: I'm just clarifying.
00:36:31.502 - 00:36:35.594, Speaker A: I'm saying that there are three different concepts here. Okay. What are the three? Okay, so.
00:36:37.614 - 00:36:46.500, Speaker B: Classically, you know, there are three things that are the same, right? One is. One is constraint satisfaction. That is, you write out a proof.
00:36:46.532 - 00:36:48.132, Speaker A: And how many bits do you want to access?
00:36:48.268 - 00:36:52.796, Speaker B: And the third one is multiplier, you know, two provers, these are all the same.
00:36:52.860 - 00:37:02.524, Speaker A: Yeah. Quantum me. Constraint satisfaction corresponds to local hamiltonian proof. A quantum proof. You just have a quantum proof that you access constantly. Many.
00:37:02.644 - 00:37:05.516, Speaker B: Those two are the same. And then this is a third one.
00:37:05.540 - 00:37:07.924, Speaker A: Where you have two provers, and that's not the same.
00:37:08.084 - 00:37:09.420, Speaker B: And that's not the same. Exactly.
00:37:09.452 - 00:37:11.236, Speaker A: For the way reasons that Tama showed.
00:37:11.260 - 00:37:14.372, Speaker B: With the magic square, where classically, you.
00:37:14.388 - 00:37:15.956, Speaker A: Know, you ask one player one question.
00:37:16.020 - 00:37:20.820, Speaker B: And then that depends on a truth assignment. And then the second one you ask.
00:37:20.932 - 00:37:22.916, Speaker A: How many constraints do you satisfy?
00:37:23.060 - 00:37:24.500, Speaker B: Whereas the fact that you can cheat.
00:37:24.532 - 00:37:29.620, Speaker A: And, you know, there's this cheating quantum strategy in Magic squares really illustrates that.
00:37:29.772 - 00:37:32.984, Speaker B: It'S not the same thing necessarily.
00:37:37.864 - 00:38:26.574, Speaker A: I didn't get into that because I wanted to avoid it, but it's an important clarification. Great. So add more open problems related to the structure of these when you think of them as interactive proofs. I'm going to skip that, maybe just so the last open problems slide, because it has to do with questions that arise from the study of these games, but that have to do with, specifically with respect to the entanglement that's used in the games. So, some interesting, I mean, one of the motivations for studying the games is to understand different entangled states. You take a game and you ask, what kind of entanglement is the optimal entanglement that you can use in the game. And there's some interesting things that happen there that I'm not going to go into.
00:38:26.574 - 00:38:43.044, Speaker A: But for instance, for those of you who know, like a natural state to be using is maximally entangled state. But this is not always the best state to be using in games. There's other types of states. They're universal states. They're called embezzlement states. So you have. Nice.
00:38:43.044 - 00:39:33.914, Speaker A: That's a question. Some of the interesting questions have to do with this dimension problem that I mentioned already, right? Given a game, even a very simple game, how much entanglement do you need in order to play? Well, optimally or near optimally in this game? So, strikingly, there's an answer, a question that we have no answers to. And I find it extremely surprising. I'm not going to do it, but I could write on the board an example of a game that has very similar to Magic Square, like three questions, three answers, very simple. I can't say anything about how much entanglement is needed to win the game optimally or even near optimally. Not even a law of decreasing returns, saying that at some point, it just doesn't help to have more and more entanglement. You're doing only slightly better, but not more.
00:39:33.914 - 00:40:23.784, Speaker A: We don't know. What we do have is lower bounds. So we have examples of games, for example here. These are XOR games that have n questions per player. And we know that to succeed in these n question XoR games with success probability, that's at least the optimum minus epsilon, you need a number of qubits that scales polynomial in the number of questions times epsilon, right? So as you allow more error, or, well, whatever it should be, but there's no upper bounds. So. And there's even some, some kind of cute little games for which it seems that if you want to play, at least if you want to play optimally in the game, you need infinite dimensional entanglement like, if you put a cap on the amount of entanglement, then you're not being optimal.
00:40:23.784 - 00:40:47.940, Speaker A: But they're not games as I've described them. There's two examples known so far. There's examples of games that have two players, but the questions are quantum. It's not something I'm getting into, but they have this property that you need infinite entanglement to play optimally. And there's another example where the questions and answers are classical. In fact, there's only two questions per player, but the players are allowed to give answers that are arbitrarily long. So classical answers, but they can be arbitrarily long.
00:40:47.940 - 00:41:12.376, Speaker A: It's not required in the game, but it's allowed. And for that game also, you probably need infinite entanglement to win it. Infinite dimensional to win it with the optimal success problem. This is a quick flash through, maybe just a flavor. If you haven't understood all the questions, it's not so important. I'll get back to some of them, maybe at the end, but now let's see. So we won't run through all of this.
00:41:12.376 - 00:41:27.630, Speaker A: So don't worry. Maybe I should stop here. So what's coming up? Um, we have about 45 minutes left, so. So this should be enough. So what do I want to do? Um, I want to get back to this, uh, magic square game, but more general. We'll do the same game, but for three stat. Right.
00:41:27.630 - 00:42:04.410, Speaker A: So, start from a three stat formula and define the game in the way that we did before. And I want to analyze this game. So I want to just tell you how we describe the quantum strategies, what happens, how you work with them mathematically. There's going to be a couple equations, and then I want to sort of start describing what the theory that you could come up for working with these quantum strategies, like a theory of tests and gadgets and reductions. I won't go through too many of those. But first, I'll describe a way to measure proximity between different strategies. This is like saying, you know, strategies that give almost always the same answers, but for quantum strategies, it's not trivial.
00:42:04.410 - 00:42:37.322, Speaker A: So I'll describe this, and then I'll describe a couple little gadgets. One of these gadgets I call the confusion game. This is a gadget that you're going to be able to compose with the game, and it's going to enforce some kind of partial commutativity between the strategies. Kind of get rid of this example that we had here in the case of the Magic square. And so there's going to be a bunch of applications for this confusion gadget. One of them is that we'll prove this np hardness result for the, for the quantum value. Then there's other applications that I probably won't have time to get into.
00:42:37.322 - 00:43:11.258, Speaker A: One of them is direct product testing of quantum strategies with application to parallel repetition. Something I probably won't go into also is going further, going from hardness of computing to hardness of approximating. I'll say more about this maybe later. I don't think I'll give you any details. And you could do more. So you could come up with other types of games or gadgets to prove these lower bounds. I guess I mentioned this here just to say that the kind of stuff that we're going to go through lets you prove not only what I'll prove, but also many other of the things that I've described.
00:43:11.258 - 00:43:48.180, Speaker A: Oops. And that was it. That was it. So do you have questions on what happened so far? Where we're going, why we are doing it? This is a good time to stop me. So, same model of multiplayer games and I'm actually no, so I'll stick to the model of games that I explained the transformation. This is how my three side game is going to be defined. But then I'm actually going to add in some little gadgets.
00:43:48.180 - 00:44:09.792, Speaker A: So because this transformation that I described from constraint satisfaction problem to game is not sufficient to get np hardness result, we saw that in the Magic Square game. It's not good as a transformation. So actually what I want to do is change it, tweak it a little bit, make it a bit of a stronger transformation. So now we have something that works. So if the CSP is not satisfiable, the game is not winnable, but on.
00:44:09.808 - 00:44:11.848, Speaker C: The game sides, you always talk about.
00:44:11.896 - 00:44:25.704, Speaker A: The same kind of two players. Classical questions. Yeah, yeah. Other questions.
00:44:26.404 - 00:44:32.444, Speaker B: Maybe just a resolution ambiguity that the fact that the two definitions of Omega Star is slightly confusing.
00:44:32.484 - 00:44:33.292, Speaker A: There's two definitions.
00:44:33.388 - 00:44:37.188, Speaker B: You said that there's some. There's two different definitions of Omega star.
00:44:37.236 - 00:44:42.832, Speaker A: In the limit for inventory, not in the limit in the infinite dimension of the dimensional case. Yes.
00:44:42.948 - 00:44:47.368, Speaker B: Since you haven't bounded entanglement, that doesn't mess things up for you.
00:44:47.496 - 00:45:09.202, Speaker A: No. So, no, because I'm going to choose one definition, I guess. So I'll define what finite dimensional strategies are and then there's going to be a well defined limit as d goes to infinity. And this will be monotone. So it'll converge to something. I could come up with a different definition. That's directly infinite dimensional.
00:45:09.202 - 00:45:39.946, Speaker A: That might not coincide with my limit definition, but I'm not going to use. I'm going to use the limit definition. Other questions? Okay. All right. So I was looking for. So the first point was just to go back to this game. Free sat game.
00:45:39.946 - 00:45:44.174, Speaker A: I'm going to describe the game again and describe what strategies are in the game.
00:45:51.434 - 00:45:53.654, Speaker B: It would be a tragedy to write in the middle.
00:45:54.514 - 00:46:07.096, Speaker A: No, but I mean, the thing, the problem is you write stuff and then once you open the things, you lose it. Right. So I don't know if it really makes. Oh, this is not a white. I was going to write on this thing. I see. Okay.
00:46:07.096 - 00:46:09.964, Speaker A: Okay. Thanks. Okay. Okay. Okay. Okay. Good.
00:46:27.084 - 00:46:28.144, Speaker B: Tv show.
00:46:41.204 - 00:47:29.700, Speaker A: I hope you're not too worried. I mean, I'm trying to keep this light. There's going to be a little bit of notation, but it won't get much worse than it's going to get in the next ten minutes. Okay, I'm going to make one assumption about the kind of games that I consider, which is that they treat all the players symmetrically. So all the games assumption, it's not a crucial assumption, it's a convenient assumption. So all games treat players symmetrically, which means that who plays Alice and who plays Bob is not set in stone, but it's decided randomly at the start of the game. So there's two players, one and two, and each of them will receive a question saying, you're playing Alice, and here's your question.
00:47:29.700 - 00:47:34.024, Speaker A: You're playing Bob, and here's your question. And then there'll be a random permutation.
00:47:35.404 - 00:47:39.572, Speaker B: And they don't have to succeed at all if they're both told they're Alice.
00:47:39.628 - 00:47:51.964, Speaker A: Right. They want to be both told Alice, but. Yeah. Yes. Don't they have to be consistent in that case? No. No. So this is a very important point, actually.
00:47:51.964 - 00:48:19.824, Speaker A: Yeah. Umesh is right. But Leonard was also right. So this is later on, we're going to change the games. As I mentioned, there's different little gadgets that we'll put in, and one of these will be that sometimes with some probability we're actually going to tell both of them you're Alice and ask both of them to give the same answer. But I'll explain that this is something, an extra layer that we're putting on top of the James. It'll be an extra requirement because it's not without loss of generality.
00:48:19.824 - 00:48:38.782, Speaker A: It'll be useful, but we'll do that later. So what are strategies? There's three elements. There's a quantum state and then actually two elements, quantum state and measurements. Right. So the quantum state is just this unit vector in D dimensions. CD D squared. I guess CD tends to CD.
00:48:38.782 - 00:49:03.738, Speaker A: I'll use the same D for Alice and Bob's dimensions. D is any integer. And then there's measurements. Because the players are treated symmetrically. There's not really Alice or Bob's measurements. There's just for every question that you can be asked, and I always implicitly assume that when you ask a question, you know, if it's an Alice kind of question or Bob kind of question, I'm not going to make the difference. So there's just a set of questions, Q and then for every question.
00:49:03.738 - 00:49:44.542, Speaker A: So for every question Q and Q, there's a measurement. So this measurement is a PoVM AQA, right. So it's a bunch of d dimensional matrices indexed by the answers and they satisfy the usual conditions. So they're positive and they sum to identity. I'm calling all of them a so far because I'm just putting all the questions into one question set. Thinking of this Alice Bob thing as being part of the label of my question. What's Pobm? Yeah, it's this.
00:49:44.542 - 00:49:57.890, Speaker A: So it's a positive operator valued measure and it's just the name that we give to these two conditions there. When I do this. Oh, you see me there. Okay. Because I was seeing you. Yeah. So it's just saying, it's just a measurement.
00:49:57.890 - 00:50:25.764, Speaker A: It's a general measurement. The requirement is that they're positive matrices that sum to identity. Right? So for those of you not really familiar with the quantum formalism, throughout the whole talk, you can think of these as if it's easier as projector matrices. So they have zero one eigenvalues and they sum to identity. One way to think of them is a partition of the identity. They're just subspaces. Each AQA projects on a subspace, and for every question you have a bunch of orthogonal subspaces.
00:50:25.764 - 00:50:39.564, Speaker A: Each of the subspaces is labeled by a possible answer. Wait, what's greater than or equal to zero here? Yeah, sorry. So please do this when I write poorly, because you mean positive. Semi definitely. Oh yeah. You mean PSD. PSD, yeah, sorry.
00:50:39.564 - 00:51:04.100, Speaker A: So for example, a projection satisfies these and we can think of projections. Okay? And so there's one important thing that I have to say, which is this is this is it. That's it. That's a strategy. What kind of distributions on answers does this strategy give rise to? Right. This is just the measurement rule. So I'll write it like this.
00:51:04.100 - 00:51:27.966, Speaker A: Given I fixed a strategy, what is the probability that I provide a pair of answers? A and a prime? Given that I was asked questions, Q and Q prime. There's different ways you can write this. I'll write a few different ways. So the standard quantum information way to write it is like this. AQA, AQ prime. A prime. I hope you're not confused by the fact that they're both A's.
00:51:27.966 - 00:51:50.374, Speaker A: Right, but this is like a nice question. This is a bob question. Sorry. That's the standard way to write it. Another way to write it is to say that this is. I see. Let me write it in a way that might be useful as an inner product between two vectors.
00:51:50.374 - 00:52:24.318, Speaker A: So now these are two complex vectors. How did I define them? UQA. I define as applying the matrix AQA to the left hand side of my state side. And the other is it should be a U prime or U tilde or whatever. It's a q prime, a prime applied to the right hand side. So this is the same, this is just notation for this inner product between two vectors. But this may be connected to this semi definite programming thing that I mentioned before.
00:52:24.318 - 00:52:51.618, Speaker A: So these quantum probabilities, they're like inner products of vectors, but with additional structure. They're not any two vectors. They're vectors that can be written as a result of applying the matrix on an implanted state. And I'll give you one more way to think about this, which is something that I was first taught by classical computer scientists. This is Irith Dinhur. We were talking about these things. And she had a very different way to think about these probabilities, which I find useful.
00:52:51.618 - 00:53:41.084, Speaker A: So let me write it for you. So I'll rewrite this in a different way, again, equivalent way, as a trace of a product. Transpose is transposition applied to a, and there's a k here that showed up. This k is a different way to think of the entangled state. So I'm out of space, I'm going to use this here and then I'll erase it. K is just a square matrix that has as coefficients of the state, the coefficients of the state. Let's say I would write it like this, something like this, the I j coefficient of the state psi.
00:53:41.084 - 00:54:08.814, Speaker A: If you can't parse this, don't worry about it. Actually, for all practical purposes, you can think of k as being the identity matrix. In that case, I'm just taking trace inner product between two matrices. But here's another way of thinking of these states. And probabilities. The state you can represent as a square, that's psi. If a big square is indexed, the rows are indexed by basis vectors on Alice's space.
00:54:08.814 - 00:54:38.956, Speaker A: So here, this is Alice, and the columns are indexed by basis vectors on Bob's space. Inside here are the coefficients of psi. So inside here, I have a bunch of coefficients. They're complex numbers and the sum of the squares is one. That's the normalization condition. So, entangled state is any table, like this table that has complex numbers and the sum of the squares is one. Okay, now, Alice's strategy are operators that act on the left hand side here and bobs act here.
00:54:38.956 - 00:55:05.944, Speaker A: And you can think of any measurement that Alice makes as partitioning the rows into a different partition here. So let's say there's only two possible outcomes. She makes a partition like this. That's Alice's choice of measurement. Bob makes another choice. Maybe that's his choice of measurement, this partition. And then what's the probability that they get a certain pair of outcomes? The probability that Alice gets the outcome associated to this half of the partition.
00:55:05.944 - 00:55:51.334, Speaker A: And Bob, the one associated to this half, is the sum of the squares of the coefficients here. So the sum of the squares is of everyone is one. So it's consistent. And I don't know if that's helpful to anyone, but that's one way you can think of how these probabilities are generated with one twist, which is that Alice can not only choose, you know, subsets of rows for her different answers that she's going to measure in, she can apply a random unitary, an arbitrary unitary on this side before making her selection right. And this choosing different unitaries correspond to the fact that different measurements don't commute. If she was always simply choosing a subset of rows and bob a subset of columns, this would be a classical strategy. Maybe this helps, maybe it doesn't.
00:55:51.334 - 00:56:13.986, Speaker A: I'm going to be working with this formula, but I just wanted to say maybe a different way of. Different ways of thinking about it. But that's what I needed to say about strategies. So, is it clear, my notation, it's okay.
00:56:14.090 - 00:56:26.734, Speaker C: I'm thinking that it's okay. Is the function that defines the game or is the underlying probability distribution or it defines the underlying probability.
00:56:30.054 - 00:56:44.794, Speaker A: This k here, k is the state. K is just another way to think of the state. You can think of this state. This state has d squared coefficients. And I can think of them, you know, as a long vector that has d squared coefficients or as a d by D matrix. And that's what K. There's no game so far.
00:56:49.934 - 00:56:53.210, Speaker C: And what defines the game is the.
00:56:53.382 - 00:57:42.550, Speaker A: It'S not defined yet, but it would be. No, it would be what is the set of questions? What is the set of answers? And, you know, with what probability do I choose these questions and what are the valid answers? Okay, so let me define the game now, unless there's another question. Okay, so the game to start with is the same game that we saw before. So I think Phi will be a three side formula. So, generalization of, I mean, not really, but. So it has clauses c one up to cm, and these clauses act on variables x, one up to xn. Right.
00:57:42.550 - 00:58:25.558, Speaker A: And so the game is like this. So the first step, we do, as I said before, in terms of symmetrization. So we choose Alice, Bob at random. So by this I mean we tell each player, you know, you're going to play Alice, you're going to play Bob one way or the other. So there's no two alices. One is Alice, the other is Bob. Then we choose a random clause, also uniformly at random, and we choose j and then a random variable in that clause.
00:58:25.558 - 00:59:11.114, Speaker A: So I'm going to be a little bit sloppy and I'll write it this way. Random in the clause. This is just one of the three variables the clause acts on. And then we send the clause to Alice and the variable to Bob. Okay. And then the last step is that we receive answers. So, Alice is supposed to give us three values because she was asked about the whole clause, the three variables ABC from Alice and another value from Bob.
00:59:11.114 - 00:59:45.524, Speaker A: And then we'll check that Alice's answers satisfy the clause, which I'm going to write just like this, satisfy CJ. And we also check consistency. I don't want to write this formally. So this is just saying that, you know, whichever variable Bob was asked about, he gives the same answer as Alice. Right? Same game, the same game as before. There's nothing new there. All right, so that's the game.
00:59:45.524 - 01:00:17.044, Speaker A: Now the players can use any strategy. What's the quantum value of the game? So the optimum success probability, how do I define it? So, I'll define it in this way. Of this particular game, g five will be the supremum over all strategies. So, overall dimensions, states and measurements. And I have, for every question, I have a measurement here. The questions are of two types, clauses and variables. So I have two types of measurements.
01:00:17.044 - 01:00:44.496, Speaker A: So I'll write them. I have a, which are indexed by clauses and they provide trips as answers. And then I also have the b's, I call them B's, which are indexed by variables. See, I call this w. That answer is d. So that's the strategy, and I'm taking the supreme removal strategy. So what's the success probability? So what's the success probability? I just have to write down what happens in the game.
01:00:44.496 - 01:01:44.004, Speaker A: So what happens in the game is first I choose a clause at random, and then I choose a random variable in that clause. So I'll have one, three all possible variables in the clause, and then I send this over and I'm going to count score. When you give a correct answer. So what's the probability? You give a correct answer? It's the sum of all possible answers of the probability you give that answer. So I'll sum over all ABC, which satisfy the clause, and then D, I'm not summing over because D should just be whatever value it's supposed to be because of the consistency. And then the probability will just be what we had on the board on the left hand side. So I have a CJ ABC answered B s D, sorry, where d I haven't defined, because it's a bit of a pain, but it's, you know, whatever the consistent is one of ABC, depending on what the question was.
01:01:44.004 - 01:01:51.724, Speaker A: That's the definition, that's the quantity that we're looking at. Is it? Can everyone read me here?
01:01:52.144 - 01:02:00.872, Speaker C: I just want to say, so, of course I studied multiple games and so I understand the definition. It's hard to understand it for the first time.
01:02:00.928 - 01:02:01.168, Speaker A: Yes.
01:02:01.216 - 01:02:26.414, Speaker C: See it for the first time, yes. Anyways. But I think that's very nicely comes out like in your blackboards, that on the left is the correlation what the players actually are making. And in the middle, that's the definition of the game, the correlation that actually we want to achieve. And what is on the third slide is kind of the inner product between the two.
01:02:26.834 - 01:02:29.266, Speaker A: So, so that's a mathematical, so the.
01:02:29.290 - 01:02:41.462, Speaker C: Correlation what we can achieve, and the correlation what we want to achieve. So we want to get them as close as possible. And that's what that formula, right?
01:02:41.638 - 01:02:46.390, Speaker A: Yeah. You can think of games as linear functions on the space of correlations.
01:02:46.502 - 01:02:54.982, Speaker C: And then of course we want to pick our matrices aqs such that that's best achieved.
01:02:55.158 - 01:03:33.694, Speaker A: Yes. So, and what you're saying is also true when you study the classical values, of course, one remark is that you might be able to see that if I set d to one, so I don't take supreme over d, I force it to be one. Then let's write it like this, right, d one, then this is just the classical value. This is just classical assignments, because if you look at. What's the strategy when d equals one, the state is a one by one state. It's nothing. It's a complex number, so it's just a phase, it goes away.
01:03:33.694 - 01:03:53.590, Speaker A: And then these positive PSD matrices which sum to identity, they're just a distribution. They're positive real numbers that sum to one. So they're just a distribution. So I'm saying for d equals one. For every question I have a distribution on answers. That's a classical strategy. So when I said d to one here, this is just one way to express what is the optimal.
01:03:53.622 - 01:04:07.754, Speaker C: What you're saying is that the middle board does not change, only that class. We cannot achieve as many correlations or as wide range of correlations as quantumly. And that's why we have a better value.
01:04:09.014 - 01:04:35.134, Speaker A: Yes. Can you make one more, further, one further observation, which is that the. So the classical value, which is for d equals one. We've seen this before. Of course it's going to be less than the quantum value, which allows any kind of d. And I want to add one more here. And again, I'm not going to insist, but I can write here the SDP value.
01:04:35.134 - 01:05:11.582, Speaker A: Okay? This would be the natural SDP relaxation of the classical value of the game. And it shows up here. The reason you have this upper bound that holds is basically what I wrote here on the left, on the left board. One way to think of these here is as an inner product between two vectors, right? U, etcetera, dot v, etcetera. And these vectors satisfy the natural constraints that you'd put on an SDP relaxation. So, you know, the sum of their squared norms will be one. I could enforce that.
01:05:11.582 - 01:05:35.018, Speaker A: They're orthogonal for every question if I wanted. So, from a quantum strategy, I can define an assignment, a solution to the, to the SDP. So prasad earlier, I don't know if he's still awake or facade. Okay, there's something called. Oh, you're there. Okay, so from a quantum strategy, you can get a vector solution to the basic SDP relaxation of the game. It's going to satisfy all the constraints.
01:05:35.018 - 01:05:56.234, Speaker A: The quantum strategy has a little bit more structure. These vectors come from, come from somewhere. And this is what we're trying to use, this extra structure, because we know that if we used only the vector structure, then I'd never get to an NP hardest result, right, for an SDP. So. All right. But this is not important for the remainder of the talk. It was only for those of you who are already familiar with these SDP relaxations.
01:05:56.234 - 01:06:32.864, Speaker A: Okay. And the claims that we've already seen before that are pretty obvious claims. So I'm making two of them. The first is that the classical value is related to the maximum satisfiability of the formula. So if the formula can satisfy all the clauses or certain factors, this is the maximum fraction of clauses I can satisfy with any assignment, then the value of the game is bigger. I can do at least as much, and you can check that the value, it won't be much more. So you have, because of this consistency checking, etcetera, the correspondence is not exact, but you have something like this.
01:06:32.864 - 01:07:09.242, Speaker A: Are you using d in two different ways as dimension? What's the other way? Oh, yeah, sorry. D will always be the dimension, except when it's not. So here it's not. Yeah, sorry. Here it's just a bit, which is the bit that Bob answers for his question x, which should be w. So from now on, it'll be the dimension. Okay, so this is clear.
01:07:09.242 - 01:07:29.344, Speaker A: It's an easy exercise. It's kind of what I described on the first slide. And another thing that we know from the magic square is that there exists some formula, not quite the magic square. The magic square is not three sides. It had disparity constraints. We can make it into a three side formula such that the formula is not satisfiable. Right, because it comes from the magic square.
01:07:29.344 - 01:07:56.808, Speaker A: But the value of the quantum game that's associated to it is equal to one. So this inequality here doesn't hold. If I put the quantum value right, and that's the problem that we have. All right. Okay. So that's all stuff we had seen before. Okay, now maybe a more interesting remark.
01:07:56.808 - 01:08:29.534, Speaker A: So I'm going to define. It's not going to be needed. You don't need to define it, but I'll define the commuting quantum value of the game. So I define it informally. What is this? The same thing, but I restrict or constrain all the bob's measurements. So all these matrices, measurement operators that Bob applies. Okay, well, there's again the D to commute.
01:08:36.234 - 01:08:36.834, Speaker C: Right?
01:08:36.954 - 01:09:12.094, Speaker A: Let's say, let's say, let's define this. And so now I make a claim, which is that this value is equal to the classmate value. So in other words, if I knew for a fact that just Bob is restricted to applying measurements that always commute for any pair of questions, then they wouldn't be able to use anything about entanglement. This would be wasted. Whatever d. I'm not placing restrictions on D here. You know how obvious this is? I think it's worth just checking.
01:09:12.094 - 01:09:42.030, Speaker A: The proof is easy. What I can do is that if this is the case, I can define a new measurement. So I'll define a new measurement, which now is this global measurement. This thing that we said before doesn't exist because in which order do you measure the questions, et cetera? Now I can define it. I can define, let's call it c. It's going to be indexed by all the variables, and here answers for every possible variable. And I'm just going to take the product of all the biggers.
01:09:42.030 - 01:10:06.036, Speaker A: So b x one, a one times. So this is times Bxnan, I just take the product. So this is meaningful because they commute. If they didn't, well, I could take the product, but it wouldn't be permission, it wouldn't be positive. But because they commute, this is makes sense, it's positive. And if I sum over all answers, I'm just summing each of the terms and I get the identity. So this is a measurement.
01:10:06.036 - 01:10:34.556, Speaker A: It's well defined measurement, because the B's commute, it's a measurement that doesn't depend on anything. I mean, I indexed it by all the variables here, but fine, all the variables we know this is the formula. Everyone knows the formula, so I can remove it. Another claim is that because the B's commute, I have an equivalent strategy for Bob. If my original strategy for Bob was okay, I received question x one, I make this measurement, produce the answer a one. That's the strategy. Now I do a different strategy.
01:10:34.556 - 01:11:14.454, Speaker A: I receive question x one, put it aside, make this measurement, get answers for all possible questions, and then send back the answer that was associated to x one. So send back a one that's a different strategy, but it produces exactly the same correlations. If I measure this thing, but I ignore all but the first answer, this corresponding to marginalizing all but the first answer. So I'm summing over them. So I sum all these b matrices, but because they sum to identity, they all go away, and it's as if I had applied b. So it's the same strategy. It's the same strategy for Bob, except that this measurement, I can make it even before the game starts, right? Because I don't need to know what my question is.
01:11:14.454 - 01:11:53.114, Speaker A: So before the game starts, Bob applies this measurement. He gets answers for every possible questions, and when he gets his questions, he provides the answer. So that's a classical strategy. Okay, so what I've said is that if Bob's strategy in the game is made of operators that all commute, then I have a way to find an assignment to my constraint satisfaction problem, which is, define this measurement, which is a global measurement, doesn't depend on the question. Measure it, get all the answers simultaneously, and then use these answers as part of the game. And that's a classical story. So this proves this.
01:11:53.114 - 01:12:37.974, Speaker A: Intuitively, it's kind of clear. I mean, I'm saying the measurements commute so they're compatible, so I can make all of them simultaneously, and there's no quantum anymore. Intuitively, it should be clear. And formally, it's also clear it's easy. But now it suggests something, right? It's saying what we knew all around, but it's saying that what we need in order for this to go down below one to respect some kind of inequality like this, is that we need to be enforcing some kind of commutativity. On Bob's strategy. If we manage to enforce this, to make it the case that his measurement operators commute, maybe even a tiny bit, then we'll, you know, be back on track, because we'll be making the quantum strategies closer to the classical strategies.
01:12:37.974 - 01:12:42.034, Speaker A: This will be tighter, and then we won't have this. This happen anyway.
01:12:42.974 - 01:12:46.234, Speaker C: You just prove one direction where the other directions. Obvious.
01:12:46.934 - 01:13:06.704, Speaker A: Yeah, yeah. Because classical strategy is always commute. They're one dimensional, so everything commutes in one dimension. I mean, you say, okay, what I proved is this right? Yeah, but the other direction is obviously.
01:13:11.234 - 01:13:18.978, Speaker C: Because you gave a particular commuting strategy. But how do you know that all commuting strategies.
01:13:19.066 - 01:13:40.544, Speaker A: No, no. That's how you do two different sides. So, to do this side, I take a commuting strategy, and I say, I can make a classical strategy out of it, so the best classical will be better. So this is this inequality. How do I do the other side? I start from the classical strategy. I make a commuting strategy out of it, and then the best commuting will do better. But making commuting strategy out of classical strategy is not doing anything.
01:13:40.544 - 01:13:46.572, Speaker A: Yeah.
01:13:46.708 - 01:13:47.904, Speaker B: What about Alice?
01:13:48.924 - 01:13:53.652, Speaker C: Why is it clear that all of.
01:13:53.668 - 01:13:54.984, Speaker B: Her measurements can commute?
01:13:55.324 - 01:14:02.644, Speaker A: No, but it doesn't matter. So I don't need it. So I could. It's not needed for the proof. So why is this?
01:14:03.824 - 01:14:10.724, Speaker B: I thought that a classical Alice would be part of the definition of just w with no star. The classical version.
01:14:11.544 - 01:14:14.804, Speaker A: Sorry, can you say it again just the way you defined it?
01:14:15.464 - 01:14:19.752, Speaker B: I thought that the definition of w of g was both analysis and classical.
01:14:19.808 - 01:14:39.344, Speaker A: That's correct. That's correct. So I haven't. You're right, I haven't fully specified what is my classical strategy. So I started from a commuting strategy where only Bob commutes, not Alice. But now I'm defining a strategy where everyone is classical. And I didn't need to assume that Alice commuted.
01:14:39.344 - 01:14:41.372, Speaker A: Ok.
01:14:41.388 - 01:14:43.484, Speaker B: I thought that here you just found the strategy for Paul.
01:14:43.604 - 01:14:58.844, Speaker A: Yeah. I didn't say what Alice does, so it's a good point. So let me do it again. It's a complicated classical strategy because it involves setting stuff up. So before the game starts, but this is allowed. We set stuff up. So how do we set stuff up? We actually create that state.
01:14:58.844 - 01:15:21.864, Speaker A: Bob measures it using the thing that I described there. And he writes down all the answers. And then he goes and gets ready for the game to start. Alice, she keeps the state, everything, and she puts it there. And then when Bob receives his question, he answers what he wrote down. When Alice receives her question, she makes the measurement on her half of the state, and she has everything anyways. And then she sends back the answers.
01:15:21.864 - 01:15:52.844, Speaker A: So you can tell me this is not quite a classical strategy, but I'll say it's okay. What's important is that it doesn't use any entanglement, because Alice was using everything. And so you could make it into a classical strategy by saying she could simulate all this stuff she doesn't need. Thanks. All right, so don't worry. We're kind of making progress. We have a couple more things to do, and then we'll be done.
01:15:52.844 - 01:16:43.914, Speaker A: So I'm going to define two little gadgets or two little subgames that we're going to add to our three stat game to make it to a game that you could call entanglement robust, for which, if the formula is not satisfiable, then the value of the game is tricky. This is the question. No, sorry. So there's two small games that I want to use and explain their utility, and then we'll add them to the three set game and then will be done. So the first is a consistency game. The other is a confused game. Consistency game is the game Leonard was asking earlier.
01:16:43.914 - 01:17:18.456, Speaker A: The motivation for introducing this game is to find a way to measure closeness between strategies, to say what it means that two strategies are close. So I have classical strategies. These are just lists of answers to all possible questions. And it's clear to say that what, two of these are close. Right. I'm just saying that two classical strategies are close if they give the same answer to most questions, quantum strategies, it's less clear. What is it the case, how do you say that two quantum strategies are close? Yes.
01:17:18.600 - 01:17:23.084, Speaker B: Shouldn't you first go to non deterministic possible strategies in order to.
01:17:23.584 - 01:17:55.444, Speaker A: Yeah, you're right. But actually that would be almost as tricky as doing it in the quantum case. Um, so, you know, you could say, let's make it deterministic and let's worry about it. But, but there you have an issue, which is, um, whether they define on the same probability space or not. So if you define them on the same probability space, then there's a meaning to saying that, you know, for, for every fixing of the randomness or for every atom in your probability space, they give the same answer on most questions. Which questions they give the same answer to might depend on the atom. So that would be one definition.
01:17:55.444 - 01:18:23.404, Speaker A: But I'll do the quantum right away. It'll give an answer. But thinking productively about your question would give an answer to the quantum case. So it's because, so you could answer that at different levels. For instance, you could say, well, I want to say, I mean, it's pretty clear, right? I defined what a quantum strategy is. So what is, when is it that two quantum strategies are close? When they're close, right. So when these entangled states are close as vectors and when these matrices are close.
01:18:23.404 - 01:18:47.662, Speaker A: Nope. Norm maybe or something. Right. That's the definition of being close. But it's too strong a definition. It's not going to be useful when I analyze games, because when you analyze games, the only thing that you see, the only thing that matters is the probability distributions, is what the verifier can see in the game. There's no way that you can say anything about the measurement operators themselves, whether it's useful to say anything about the measure.
01:18:47.662 - 01:18:50.326, Speaker A: Well, okay, for instance, if you do.
01:18:50.350 - 01:18:54.246, Speaker C: A unitary transformation, everything, they are not going to be closed at all.
01:18:54.310 - 01:19:23.812, Speaker A: And yet it's the same if you do local unitaries. Yeah, yeah. I mean, another way to say it is that these measurement operators could have a lot of junk. There could be a lot of stuff in some corner, for example, some corner of space, intuitively, in which Psi, the state has no mass. And then I don't care about this. So at least it should take both of them into account. The strongest definition is too strong, but the weakest definition would be to say, okay, I just want to preserve the local distribution.
01:19:23.812 - 01:19:51.926, Speaker A: So two strategies are close. If for every pair of questions or most pair of questions, I get the same or close in statistical distance distribution and pairs of answers. Right now, that's too weak. Why is it too weak? Because I want to be, we're going to be composing games. We want to be able to use that. And having a distribution which just only talks about the distribution of answers is not going to be something that I'm going to be able to use when I compose games. So I want something a little bit stronger.
01:19:51.926 - 01:20:21.254, Speaker A: I want to say that two strategies are close, if they're close, when I play any game using them, if they're part of different types of bigger games, roughly. So this is the definition I'm going to give. Two definitions. They're equivalent. One of them is mathematical and the other involves the game. I'll give the mathematical definitions first. So I'll say that if we have two strategies, a and b, I'll define maybe the distance, let's call it distance.
01:20:21.254 - 01:21:00.698, Speaker A: It's going to depend on the state between a and b. And it's going to be this, it's going to be, it's going to be slightly game dependent, but not too much. So let's see. Let me write it. Right. It's very, it's sort of a very natural. So it's just the difference, the l, two norms between the vectors.
01:21:00.698 - 01:21:30.438, Speaker A: After you apply the measurement operators on the left half, for instance, of the vector, you just take the average over all possible questions. So for this, I need to have a distribution on questions. So this definition is distribution dependent. Okay, sum of all answers. So that's the mathematical definition. Another way to think about it is to say that the post measurement states are close after you make the measurement. And then let's give another definition.
01:21:30.438 - 01:22:01.524, Speaker A: This one I'll write, this is the game definition. I'll write consistency between a and B. And this will be simply defined as the probability that Alice, well, that there's no Alice in Bob. So there's a and b. There's these measurements. This also depends on PSi. These measurements provide the same answer, the same output.
01:22:01.524 - 01:22:33.904, Speaker A: Right. Same answer when asked the same question. Right. You imagine that. So it's the success probability in a certain game, which is this consistency game, which is a simple game where you'd imagine that you send the same question to Alice and to Bob, and they give you answers, a, a prime, let's say b, and they win if a equals b.
01:22:40.364 - 01:23:00.600, Speaker B: I have a question for you. So you're defining the distance on strategies here. But I was under the impression from earlier that a strategy was a set of povms and a state. So are you assuming that these two strategies have the same state associated with them.
01:23:00.712 - 01:23:13.164, Speaker A: The same state, yes, that's correct. Good point, actually. Yeah. I haven't been precise about that. Yes. So it's only defined for strategies that use the same state, same set of questions, same set of answers, and same. Okay.
01:23:13.244 - 01:23:19.764, Speaker B: Would the, would the distance measure generalize to just, if you had a different state associated with just the LT?
01:23:19.804 - 01:23:23.544, Speaker A: I mean, I could write it down, but I don't know if I could do anything with it. Yeah. Okay.
01:23:25.684 - 01:23:28.036, Speaker B: The state might have been.
01:23:28.220 - 01:23:30.292, Speaker C: Well, just to clarify that if all.
01:23:30.308 - 01:23:40.684, Speaker B: You had was a bunch of joint EPR pairs and that was your starting point, then it doesn't seem like such a huge assumption to say that that sort of. What? Or is it a huge assumption?
01:23:41.024 - 01:23:41.792, Speaker A: Which assumption?
01:23:41.848 - 01:23:43.816, Speaker B: Well, what if Psi, what is Psi doing for them?
01:23:43.840 - 01:23:43.976, Speaker A: Right.
01:23:44.000 - 01:23:45.884, Speaker B: So maybe it's a bunch of joints.
01:23:46.184 - 01:24:02.124, Speaker A: Yeah, I mentioned this in the open questions. Actually, it is an assumption. So it's a restriction for the players to say you have to use ZPR pairs. There's games for which you can't do as well if you're forced to use EPR pairs.
01:24:03.844 - 01:24:05.684, Speaker B: Take a big and battling state.
01:24:05.844 - 01:24:21.024, Speaker A: Right. So, right. That's another answer, which is there is some of the state which is not EPR pairs, which is good for every game a priori, we know what that state is. So we could fix that state. That's good. Maybe that would say that. Well, actually it doesn't really matter.
01:24:23.084 - 01:24:26.984, Speaker C: Could you say the tensor product of the two states?
01:24:28.244 - 01:25:18.608, Speaker A: Yes, but then a would act on one and b on the other, and then I'm not. So that would be sort of equivalent to just replacing this by Phi, but I'm not sure that would get me very far. Okay, so there's two claims here that I'm not going to write down, not prove, because the audience is getting tired and I want to get to the point. But they're easy to prove, easy exercises. One claim I already made, which is these two are equivalent measures in the sense that if this is small, then this is high and vice versa. In a very linear sense, this is almost one minus this, but not quite. So if the strategies win in the consistency game, then they're close.
01:25:18.608 - 01:25:26.060, Speaker A: If they're close, they win in the consistency game. Why aren't they equal?
01:25:26.092 - 01:25:32.140, Speaker B: Don't you just kind of align your question with the vector difference or why aren't they equal? Why isn't it just one?
01:25:32.172 - 01:25:55.884, Speaker A: Yeah, equal. Sorry? Oh, why aren't they equal? No. So there's an important difference between the two and this is something I should say. The first thing is that, okay, here's one answer to your question. D of a and a equals zero. This is pretty clear. This is not always equal to one for a and a.
01:25:55.884 - 01:26:17.932, Speaker A: So what if they are just always. For instance, think of a random strategy, something completely randomized. You're not being consistent. You're not winning in that game. So actually I should qualify what I said before. The equivalence is between this being small and both this and the AA guy. Sorry.
01:26:17.932 - 01:26:43.576, Speaker A: Under the assumption that the AA guy is large. So I should write it. So the lemma, or the claim is that suppose that a is a nice strategy in the sense that it's consistent with itself, right? So it's self consistent then. Okay, I'm not going to write it, but then they're close to each other.
01:26:43.640 - 01:26:49.564, Speaker C: So here you have to add that if different, then they should answer differently. Right? Otherwise it's trivial.
01:26:50.104 - 01:26:50.792, Speaker A: Sorry.
01:26:50.928 - 01:27:02.744, Speaker C: So if you ask different things, then they have to answer differently. Otherwise they can just always answer zero to everything. And then it holds that when.
01:27:02.824 - 01:27:26.714, Speaker A: Yes, of course it's easy to win in this game, but that's not the point. It's like this, right? It's not hard to come up with an a such that this is zero. I can define it for you, but so this one. Okay, that was a bad answer. Maybe a better answer is this is going to be a sub game in the. I'm not going to play this for itself. For instance, when I play, I'm going to compose with the three side game.
01:27:26.714 - 01:28:10.762, Speaker A: And now instead of doing this, we'll probably, yeah, I'll try to wrap up with probability half. I do this game, and with probability half, let's say I tell both of them to play Bob and they have to provide the same answer. But when you're told play Bob, you don't know if the other guy is playing Bob. You know if you knew, then of course everyone always answered zero, but that won't. Another way to see the difference between the two quantities, which makes the equivalent, not completely obvious, is that here I think of the operators acting on the same half of PSI, whereas here they're acting on different halves. So there's something to prove. All right, so I define my last game, and then, which is the confusion game.
01:28:10.762 - 01:28:46.226, Speaker A: So this is the important game, but it's very simple. Simple but useful. So it's like this. There's an Alice and a Bob again. So you choose Alice, Bob at random, and then now you choose two questions. Q q prime, independently at random. So I'm leaving the at random vague again.
01:28:46.226 - 01:29:43.510, Speaker A: This is using some fixed distribution, right? For instance, if it's three sat uniform distribution, the clauses Q q prime at random, and then you send the unordered pair q q prime to Alice, and you send, let's say the first one. This was unordered, so it doesn't matter q to Bob. So Alice got two questions, Bob got one. Then you receive a prime from Alice. She has to provide you two answers, and b from Bob. And you check, well, in that case, a equals b, right? If, if Alice says a was for q and a prime was for q prime, then I checked that they gave the same answer on Q. The point is that Alice doesn't know which of her two questions she's being checked against with respect to Bob.
01:29:43.510 - 01:30:20.574, Speaker A: Right? So it's kind of a sophisticated version of the consistency game. Right? Again, it's easy to win this with priority one, but that's not the point. What's the point? So the point is as follows. The important thing you can prove, and it's not hard. I don't want to get into the proof, but it's just a few lines of algebra, which is that if we have a strategy for that game. So a strategy for that game will be measurements for Alice and measurements for Bob. And let's suppose that I have a strategy that wins in this game.
01:30:20.574 - 01:30:55.690, Speaker A: So I'll write it conf for confusing, just like consistency of a and B. Suppose that this is large, one minus epsilon. And suppose also that b, the b measurements would win. You know, if I was to play the consistency game, telling both guys you're Bob, they would also win. So the two conditions then. Can you read? I'm writing stuff really low on the camera. It works.
01:30:55.690 - 01:31:12.006, Speaker A: Okay. So then we have the following two strategies are equivalent. We have that. So, using my distance measure that I had before, Psi. And Psi is the same state that's used by everyone all the time between two different measurements. One is the a. I'll just write Q q prime.
01:31:12.006 - 01:31:34.996, Speaker A: So we remember it's the a's that's here. And these measurements are close to other measurements that I could construct from the b's. I'm going to write it in a non symmetric way. I should write it symmetrically. But, and it's just the product of the two. There's a little loss in the parameters here. Root, epsilon.
01:31:34.996 - 01:32:31.548, Speaker A: Okay, I'm saying this is the distance measure. So I'm saying, suppose my players, you know, if I'm to play these two games with them, and they use strategies a and B, whatever, that are successful in those games, then it must be the case that Alice's strategy on Q and Q Prime is actually close to some kind of a product strategy that I could obtain from Bob's measurements. For those of you who know the proof of this, the intuition for why this would hold is kind of related to the, how's it called? Almost gentle measurement. Lemma. The idea is that if you win in that game, Alice makes a measurement. When Bob makes his measurement on the corresponding Q, we know what his answer is going to be. His answer is going to be the one that Alice provided, because they're consistent if they succeed well in the game.
01:32:31.548 - 01:32:46.932, Speaker A: So it means that when Alice has made her measurement, if Bob makes his measurement, the answer is already determined. So the state is not going to change. In particular, if Bob makes his measurement Q and then Q prime or Q prime and then Q, the state doesn't change. It's the same thing. Yeah.
01:32:47.068 - 01:32:49.180, Speaker B: I mean, since that's not always permission.
01:32:49.292 - 01:32:49.932, Speaker A: I know.
01:32:50.068 - 01:32:51.308, Speaker B: Like root, BQ.
01:32:51.436 - 01:33:12.584, Speaker A: Yeah. So both are true. But this is also true because, I mean, this definition, you can use it even if B is not her mission. And it's true. But you're right. The proper way to write it would have been to have, say, BQ in the middle and sandwich it by two roots, two square roots of BQ primes, and it would also be correct. All right.
01:33:12.584 - 01:33:25.320, Speaker A: I mean, they're two different strategies.
01:33:25.352 - 01:33:25.760, Speaker B: Right.
01:33:25.872 - 01:34:05.732, Speaker A: I'm mixing up a bit too many things, but. So when I write a and B here, they're not Alice or Bob, but that's why I wrote the queues, I guess, just to make it clear that a is just the measurement operators that are associated to this kind of questions in the game, and B's are the measurement operators that are associated to this kind of questions in the game. Which, when I wrote this here, I thought of the first as being Alice's measurements and the second as Bob's measurements. But both of them can be meaningfully applied on either side of the state, and they're just two different sets of questions that correspond to two different kinds of questions in the game. And I'm saying that they produce the same results whether you apply this one or this one.
01:34:05.828 - 01:34:09.908, Speaker B: So this forces Bob's strategy to be almost commuting, is the idea.
01:34:09.956 - 01:34:27.406, Speaker A: Right. Right. So Aram is ahead of us. The. This in itself actually has interesting consequences. For instance, you can think of it as a direct product test, and you can use this to get some parallel repetition results, but I'm not getting into that. One consequence of this, and the triangle inequality for the distance measure that you know is going to hold.
01:34:27.406 - 01:35:11.320, Speaker A: Maybe there's a square, you have to. But is that the distance between B and then BQ and then BQ prime and BQ prime and then BQ when they're both close to the same thing? Because this Q cube prime there was unordered right as well. So it's close is root, Epsilon. So I know that if I play this little test here and the players succeed with high probability, then Bob's measurements, operators approximately commute up to some small epsilon in this distance measure. So I'm not going to get into why. You know, there's a long story to tell about the difference between approximately commuting and exactly commuting. I'm not going to tell it.
01:35:11.320 - 01:35:39.508, Speaker A: I'm going to tell you what is the final game we play and what is the result about it, and then I'll be done. Then we can have more questions. So here's the two modifications that I make to my game. So it's going to be a little bit complicated, more complicated, but not too much more. So this is the three start game. The game is like this with probability one, three. I'm going to do three different things.
01:35:39.508 - 01:36:27.156, Speaker A: So one, three do. So the first thing that I do, a, is this, okay, that I did before, probably one, three, b. I'm going to play the consistency game, and then I'll write here on the variables, not the clauses. We only care about Bob. So what this means is that I choose just one variable at random, send it to both guys, and ask them, what value do you assign to that variable? And I check that the answer is not the same. And then the last thing is, I'm going to play the confused game. Okay.
01:36:27.156 - 01:36:49.580, Speaker A: Also on the variables. So now it means that I take two random variables, two variables at random, send both to Alice and one of them to Bob, and they reply answers. And I check that the answers match for the answer. That was the question that was sent to both. So I do these two things. That's it. And then, so I keep losing the eraser.
01:36:49.580 - 01:37:15.244, Speaker A: I don't know whether. Ah, okay. How come they have only one? So what's the theorem you're headed towards? Yeah, I'm writing it right now. Okay. And then. Yeah, and that's the last thing I want to write on the board. So the theorem is, the theorem is that take a formula, right, five.
01:37:15.244 - 01:37:43.234, Speaker A: So suppose there's two parts to it. So suppose phi is satisfiable. Then the value of this game, three sat star associated to phi, is one. Okay, fine. You can win with priority one, because the formula was satisfiable. This is fine. And then the other part is, suppose phi is not satisfiable.
01:37:43.234 - 01:38:20.504, Speaker A: Let's say it's one minus epsilon. Then the value is not one. So we don't have this magic square thing that happens anymore. The omega star of the basic three sat game could be one, but the three sat star game is at most one minus. And then there's a big loss here. N, the number of variables times root epsilon. Basically, because I got root epsilon here for every pair, and then I have my n measurement.
01:38:20.504 - 01:38:56.500, Speaker A: So I get a loss of a factor n here. That's the theorem I wanted. And then the corollary is that deciding between these values for the preset game is one, or is at most, let's say, n cubed. For safety. N is the number of variables. So this is np hard. But why n cubed? Yeah.
01:38:56.500 - 01:38:58.684, Speaker A: N squared times a constant. I just wanted to.
01:38:58.844 - 01:39:00.162, Speaker C: Why you have squared?
01:39:00.268 - 01:39:01.926, Speaker A: Why is it one over n to.
01:39:01.950 - 01:39:03.158, Speaker C: The minus one times?
01:39:03.246 - 01:39:18.158, Speaker A: I want this to be strictly, you know, small. I see there's an n there. Oh, the epsilon is. It's n root epsilon. So I want to take epsilon to be at most, a constant over n squared. A small constant over n squared.
01:39:18.326 - 01:39:22.830, Speaker C: So formula does not look right. The n Times square root of epsilon.
01:39:22.942 - 01:39:23.246, Speaker A: Okay.
01:39:23.270 - 01:39:25.926, Speaker B: It should be like epsilon squared over. Nice.
01:39:25.980 - 01:39:29.854, Speaker C: Yeah. Epsilon squared over n would look like much nicer.
01:39:30.754 - 01:39:32.214, Speaker A: No, no, of course.
01:39:32.674 - 01:39:35.762, Speaker C: No, but. No, no, no, but look, sorry, I.
01:39:35.778 - 01:39:45.418, Speaker A: Did it the wrong way wrong. You're right, you're right, you're right, you're right. I'm sorry. Yes, yes. What should it be?
01:39:45.546 - 01:39:47.378, Speaker B: How about epsilon squared over n?
01:39:47.426 - 01:39:53.388, Speaker A: So I want epsilon to be. No, n. No, I mean, m should.
01:39:53.436 - 01:39:56.424, Speaker C: Not be a multiplier. It should be in the denominator.
01:39:56.724 - 01:40:13.424, Speaker A: Yeah, yeah, you're right, you're right, you're right. Oh, I see. Because I'm doing the. Sorry. I guess it should be something like this. Yeah. I think what I wrote there is still current.
01:40:13.424 - 01:40:45.034, Speaker A: So this is. Well, it doesn't appear in this form, but it's the first to prove this. Mp hardness for two player games. This is Ito Kobayashi Matsumoto, 2009. They were building on some paper of Kempe, Kobayashi Matsumoto, myself, 2008 or nine or something. But sort of at the time, we didn't really look at it in. In this way.
01:40:45.034 - 01:41:02.314, Speaker A: So. Yeah, I should stop. I'm going to stop. I wanted to have some philosophy, but.
01:41:04.614 - 01:41:09.602, Speaker C: I'm interested in that. I mean, you say that there is a theory emerging.
01:41:09.798 - 01:41:52.984, Speaker A: Yeah. So for me, this is like, this is when you do reductions between constraint satisfaction problems, right? You have a theory of gadgets and reductions that preserve approximation, that preserve the maximum satisfiability of certain assignments. And you understand very well what kind of gadgets you can perform and what's their effect. You can make these games, you can change the constraint graph, make it into an expander. You can do different things. Also, you can study, you have diet product tests, and you have all kinds of gadgets or tests that you use in order to achieve certain things about games or constraint satisfaction problems. And I think we don't have such a thing for quantum games.
01:41:52.984 - 01:42:24.844, Speaker A: And I think it would be useful to have. So this is why I present it in this way, because people don't think about it in this way. I mean, I was just preparing this and trying to clean things up a little bit. And I think these, thinking of this in this way, that when you play these multiplayer games, you can play different subgames, confusion game, consistency game. I had others, for instance, there's a anti commuting gadget, and this is a gadget that you can use to enforce that the entanglement dimension is very large. So there are all some kind of. And then you have a toolbox.
01:42:24.844 - 01:42:52.294, Speaker A: And then if you try to achieve something called dimension width, for instance, you're going to use this anticommutativity. If you're trying to. In this case, I was trying to do something in a way that's not interesting. I'm trying to prevent my quantum guys from being quantum, make them commute. And I know I have this confusion game I can absorb. Even if you study devices, the kind of things Yawyun was talking about before, it seems like it would be very useful to have a good understanding of these different objects and what consequences. So this is why I also.
01:42:56.394 - 01:43:05.366, Speaker B: If I understood the right b and C here, are to make, basically, to make Alice involved, use a classical strategy for part a. Yeah, but so I thought.
01:43:05.390 - 01:43:06.646, Speaker A: That part of the rules was that.
01:43:06.670 - 01:43:13.222, Speaker B: They know what kind of question they're. I mean, if they know they're getting a b type question, can't they arrange.
01:43:13.358 - 01:43:24.914, Speaker A: No, no, no. The types of questions, they're not a, b and c. They're just Alice Bob, which in that place is just a clause or variable, but it seems like you're not.
01:43:25.814 - 01:43:31.094, Speaker B: But the reward function for their answer is determined probabilities. Is that how I should think about it?
01:43:31.134 - 01:43:31.994, Speaker A: The what? Sorry?
01:43:32.614 - 01:43:35.514, Speaker B: The reward function is different in the case.
01:43:37.534 - 01:44:09.766, Speaker A: Yes. So for example, so in that, okay, let's be the player. From the point of view of the player in that game, what do you see? You get asked only one of two possible things, either a clause or a variable. That's what you see. And in your mind, what you should be doing is giving answers, assignments of values to what you were asked about the three variables or one variable that are part of a satisfying assignment. For the whole formula, this is what you're supposed to be doing. You're supposed to have agreed both players on an assignment of variables that satisfies all the clauses.
01:44:09.766 - 01:44:18.122, Speaker A: And when you're asked one variable or three variables or whatever, this is what you answer. This is what you're supposed to do. So you don't know. For instance, if you ask the variable, you don't know.
01:44:18.138 - 01:44:22.186, Speaker B: There's no way to win if it's satisfiable. But the game that you've defined here involves other parts.
01:44:22.250 - 01:44:26.602, Speaker A: Yes, yes. Right. I'm just saying the player is not aware of which part is.
01:44:26.778 - 01:44:33.706, Speaker B: But I thought that in order for this to be a game, you've got to tell the player what like the function is the referee is using to evaluate their answer.
01:44:33.770 - 01:44:51.668, Speaker A: Yes. And they know it. It's written here on the board. But it's just that if you're told, hey, you're being Bob and here's a variable, give me the value. This is what you're told. And you know the specification of the game. You know that it could be the case that the other guy is playing Alice, in which case you're here.
01:44:51.668 - 01:45:18.632, Speaker A: Or it could be the case that the other guy is Bob, in which case maybe you're here, is another bob and you're here. So it's the same kind of indeterminacy as we had before. What you don't know is what the other guy is. And in this particular type of game, it is the case that you know what the other guy is. I mean, it matters in terms of what's going on. But you. Yeah.
01:45:18.648 - 01:45:34.492, Speaker B: The thing that I wasn't understanding was that the referee is allowed to, the function that they apply to the answers that Alice and Bob give is allowed to have. Like they're allowed to flip a three sided coin in order and then evaluate it using criteria a, B or C. Yeah.
01:45:34.508 - 01:46:09.376, Speaker A: Yeah. But that's not really more different than what we had just in the basic three sat game where in a way I flipped a coin to select the clause. And then I flipped a coin to select a variable in the clause. And so when I asked Bob about the variable, or let's say, sorry, when I asked Alice about the clause, she doesn't know what the other coin was, so she doesn't know if she's being checked against variable number one, two, or three with respect to Bob. And you could think of this as playing three different games. One game is I asked the first variable to Bob. The other games, I asked the second variable to Bob.
01:46:09.376 - 01:46:31.094, Speaker A: So it's the same kind. And of course, it is necessary that there's some unknown. Thanks. Did you have a question or. No, I'm sorry, behind you. I thought so. Would the natural analog be that constant factor approximation to this? Is NP hard or QMA hard? That's a good question.
01:46:31.094 - 01:46:52.376, Speaker A: Let's start by proving that it's NP hard. So it depends where you start, really. I mean, it's a good question. You know, it seems natural to classic. So, okay, classically, it's NP hard. So at least I know where to get started if I want to prove that the quantum is. For instance, I look at Eritre's proof of PCB theorem and try to.
01:46:52.376 - 01:47:16.740, Speaker A: That also involves a lot of gadgets. Do they go through or not? And this is a program. I think it's an interesting program. We can be QMA hard. So in principle, it could be. And we've seen these results that Umesh mentioned about testing that Anne mentioned also, where within QMA, you're trying to verify the existence of a quantum witness right here. You're a purely classical verifier running this game, and you have a classical interaction.
01:47:16.740 - 01:48:06.340, Speaker A: So can you really verify your QMA hard hard problem by having this kind of interaction? Yeah, maybe you can, because this is what these results on Q, MIP equals MIP, et cetera, are saying. So maybe it is. But is it in QM? I have no idea how you'd get started, but no, it's not. There's no upper bound on the thing, so it's not. I guess there's. I think QMA is kind of natural, but I definitely wouldn't bet anything on this being NP or on NP or QMA being the right answer. But I think some of Umesh's results in these tests, they are new from just a year or two ago, and they are pointing to the possibility for having QMA hardness.
01:48:06.340 - 01:48:19.112, Speaker A: Whereas before we thought that NP would be the natural answer. Because of these new results, it's not clear anymore. And this w. You said there's two definitions. What are you using here? Oh, I'm using this one, the limit.
01:48:19.128 - 01:48:20.544, Speaker B: Of the finite dimensional answer.
01:48:20.624 - 01:48:39.544, Speaker A: And the other, what is this so supremum over all dimensions and strategies in that dimension. Oh, I see. So it's limit. So I can. Yeah, actually, I'm not. There's another definition which is equivalent in finite dimensions, but when you take the limit, they're not anymore. We don't know if they are.
01:48:39.544 - 01:48:45.340, Speaker A: Yeah, but I could say what it is. You have a fixed game and you allow arbitrary dimension.
01:48:45.372 - 01:48:45.716, Speaker B: I see.
01:48:45.780 - 01:48:50.664, Speaker A: Okay. Yeah. So, I mean, it's like saying I allow arbitrary strategies, which.
01:48:52.004 - 01:48:53.604, Speaker B: Arbitrary but finite dimension.
01:48:53.724 - 01:49:04.942, Speaker A: Yes. Right. So. And you could debate that. I mean, some people say, why not allow infinite? And then it's just then you have to work with sister algebras. And I'm not fluent actually. It's.
01:49:05.118 - 01:49:17.474, Speaker C: It is in QMA. No. Or because. Because we are talking about the approximate version. So. So if we fixed the. If we fix the dimension.
01:49:17.934 - 01:49:18.534, Speaker A: Okay.
01:49:18.614 - 01:49:20.230, Speaker C: It would be in Q and a. Right.
01:49:20.342 - 01:49:31.590, Speaker A: What do you mean by in QA? If you fix the dimension, this is in exponential time in the dimension. Because the. That's the size of my exponential space. That's the size. If I. Sorry. Polynomial.
01:49:31.590 - 01:49:46.342, Speaker A: If I fix the dimension. Yeah, it's an exponential time in the dimension. If I fix the dimension, the strategy is an object that has size, d squared times the size of my game, the number of questions. And so in time, exponential. Indeed I can.
01:49:46.398 - 01:49:53.038, Speaker B: But maybe it's in QMA two or something like that. If you fix the dimension.
01:49:53.086 - 01:49:54.634, Speaker A: If it's in. Oh.
01:50:03.474 - 01:50:11.374, Speaker B: So this might have been asked before, but is there a natural definition for a metric on the space of all quantum strategies?
01:50:12.554 - 01:50:30.614, Speaker A: So that's not what I had written before. You mean that's completely game independent, you mean or. Yeah, I mean, like I suggested, the definition, but it had some drawbacks. It used the same state and it depended on the question sets and answer sets.
01:50:30.734 - 01:50:31.302, Speaker B: Right.
01:50:31.438 - 01:50:31.998, Speaker A: Okay. Yes.
01:50:32.046 - 01:50:50.314, Speaker B: I was wondering if lead to a general definition. One thing I've seen in the literature is they define the distance between two strategies according to both the distance between the initial states and also the post measurement states and sort of like the maximum. So if all of those happen to be close, then they say.
01:50:53.754 - 01:51:18.710, Speaker A: Okay, but here again, to define post measurement, you know, you have different measurements for different questions. So you have to say how you incorporate the questions. You could do everything coherently, maybe have the. But still you need a distribution on questions. I think it makes sense to take the game into account. Because the strategy is anyways indexed by questions. Questions are not arbitrary objects.
01:51:18.710 - 01:51:23.134, Speaker A: They're part of. They come from a game. And there's an implicit distribution of the question.
01:51:23.294 - 01:51:27.862, Speaker B: You could, you could make like the questions themselves, a classical register.
01:51:27.998 - 01:51:38.134, Speaker A: Right. You can do that. Yeah. So then. Yeah, let me take. Okay, let me zap. Go ahead.
01:51:38.134 - 01:51:41.474, Speaker A: Mario has had his load of questions and we should feed the audience.
01:51:42.314 - 01:52:03.134, Speaker B: So, definition of similar strategies. Is there a way to, is there a sense that you can mod out by that, sort of create a new strategy on a different space so that you don't have to, that should exist or.
01:52:09.134 - 01:52:16.034, Speaker A: I don't know. I mean, if you think about it, even classically, I don't know exactly what it means or if it's useful.
01:52:17.254 - 01:52:20.382, Speaker B: Do you have a feel for what two similar examples?
01:52:20.438 - 01:52:38.482, Speaker A: Well, two strategies that would be, think of, you know, vectors that are close. I mean, at some level that's, that's just what it is. Then what does it mean to mod out by vectors that are close? You want to create equivalence classes of vectors that are far.
01:52:38.538 - 01:52:47.094, Speaker B: I guess I was under some big impression that though somehow the strategies were in some sense different, but not different in this measure.
01:52:48.714 - 01:52:54.814, Speaker A: Yeah. They can be different as operators in terms of operating norm, but be close in that measure. Yeah, that can happen.
01:52:56.434 - 01:53:02.914, Speaker B: So how do I relate that? You said think of vectors that are close, but the operators are not close. So what am I thinking about?
01:53:08.494 - 01:53:09.766, Speaker A: I didn't get the question.
01:53:09.950 - 01:53:19.154, Speaker B: So in the answer to the question, I asked about similar strategies that are actually, that are measured to be similar but are different, I said I don't have a feel for an example of that.
01:53:20.334 - 01:53:39.604, Speaker A: No, no. Just think of a case where the, the measurement operators are very different. Right. In some corner. So the operator norm is very different, but the state, the entangled state, so has no mass on that corner. So for all practical purposes and for all you care, they're the same.
01:53:39.684 - 01:53:43.292, Speaker B: So isn't that an example where you should be able to mod out? By that I mean you should sort.
01:53:43.308 - 01:54:12.724, Speaker A: Of be able to. Yeah, but it's not, but it's not that easy. So yeah, you could, you could say, for instance, okay, if some Psi has some small coefficients in some corner, let's just. Some small Schmidt coefficients, for instance, let's just get rid of that. And then now we could be talking about the operators, but it's not, it's tricky to do that because if you think about what Psi looks like typically. Right. What's this universal state? The Schmidt coefficients, they scale like one over square root.
01:54:12.724 - 01:54:38.396, Speaker A: So it's not easy at all to say. There's no clear tale like it. It's a divergent. It's a complicated question to try to look at. You want to go ahead. I mean, those questions. Yeah, well, we need a moderator who takes questions.
01:54:38.396 - 01:54:39.624, Speaker A: I don't know. Speak up.
01:54:40.044 - 01:54:56.964, Speaker C: Do you have another question to ask? If three players games are fundamentally different, like, for instance, can it be that you prove that these are QMA in QMA, but three players are not in QMA? Can it be or.
01:54:57.384 - 01:55:14.732, Speaker A: Yeah. So, for example, the status of things right now is that the approximation problem for three player games is NP hard. And for two player games, we don't know. For example, we know it could be NP for two player games and NP hard for three player games. You mean constant constant approximation. Right. This is.
01:55:14.732 - 01:55:39.728, Speaker A: Right. Constant approximation. So three player, there's some intuition why they could be different between. Because monogamy, because tripartite entanglement is very different in bipartite, and some other intuition, which is to say, well, you know, as soon as you have two, it's the same. Right. So did you, have you had a question? If you don't have it anymore, there's another question.
01:55:39.816 - 01:55:46.284, Speaker B: So how do you compare the techniques here and the technique used to prove the lower boundary star?
01:55:47.024 - 01:56:30.958, Speaker A: They're similar, except that you have to, it's like going from what we did there is cook level, I don't know, basic. So it's similar ideas, but you have to analyze further games or tests. So these low degree tests, linearity, well, actually, you just load the greed test. So there also. But the modification is going to become much heavier. It's going to be the same kind of modification that you do when you prove the PCP theorem. So you could say that when you proof PCB theorem, you start from the three sad game, but then you start doing very complicated, building complicated games on top of that, right, where you stop asking directly for the variables or the clauses, but you think of these as being encoded in values of polynomials, and you ask about the values of polynomials at other points.
01:56:30.958 - 01:56:32.846, Speaker A: And so you do these kinds of things.
01:56:32.990 - 01:56:36.434, Speaker B: So are you still adding new gadgets to the game?
01:56:37.094 - 01:56:43.394, Speaker A: Yeah, in a way, you're modifying the game. Yeah, but you. To the point where you lose track of the original game. I mean, you're not playing this anymore.
01:56:46.454 - 01:57:00.114, Speaker B: So I asked earlier about the state dependence of that, and it was mentioned that there is a best state to choose. What is that state?
01:57:00.654 - 01:57:47.510, Speaker A: So is Patrick still around? Yeah. So there's a nice paper by Patrick Haydn and Vin Van Damme that explores this state. It's because the embezzlement state, there's many you could have, but here's one definition. It's just like this. So I mean, there's one for every dimension, and you need to take it into large enough dimension, but it's going to look like one over a constant. And then there's a one dimension. So the point is the scaling of the Schmidt coefficients, right, that they have this decrease, but like inverse square root, so pretty slow.
01:57:47.510 - 01:58:13.014, Speaker A: So it's definitely not flat, definitely not a maximum timeless state. And also something that you can't chop off so easily because the decay is so small. And there's variations on that, but this is one that will work. So it has the property that for any other state that you want, it has the property that for any other state that you like, any state, you can generate that other state from this one by making local operations, local unitarians. That's why it's called embezzlement.
01:58:13.594 - 01:58:15.546, Speaker C: Because all that matters is the Schmidt.
01:58:15.570 - 01:58:22.774, Speaker A: Coefficients right up to local operations, but that they're allowed to do. Thanks.
01:58:26.674 - 01:58:30.134, Speaker B: Okay, maybe we should stop and thank Thomas for a great time.
01:58:34.874 - 01:58:36.786, Speaker A: And we'll reconvene tomorrow morning.
01:58:36.890 - 01:58:39.554, Speaker B: The first talk will be at 930 with coffee before that.

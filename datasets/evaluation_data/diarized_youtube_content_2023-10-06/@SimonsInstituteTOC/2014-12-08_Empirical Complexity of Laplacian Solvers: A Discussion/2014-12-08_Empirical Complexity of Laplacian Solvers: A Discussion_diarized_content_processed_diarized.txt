00:00:00.160 - 00:01:23.490, Speaker A: But what I want to do with the remaining 20 minutes or 25 minutes that we've got is I have to give you a short introduction to two slides of my own philosophy. Then I would like to invite discussion, both further discussion about the structure of the laplacian world championships. And I have a big slide of questions here that we can discuss. And then I also would like to invite people in the room who have been involved in various kinds of implementation and experiments to give their points of view on things. I know that there is a non zero number of people in the room who have actually implemented some of the combinatorial laplacian solvers, and I'd like to hear from them. You know, depending on how many people raise their hands, give them, give them, give, give a few minutes to people. The people listed on the slide here, Eric and Kevin, are collaborators in an implementation effort that we've done, which is not a fast implementation, but a sort of counting complexity implementation, which I will say a little bit about at the end, depending on how the time goes.
00:01:23.490 - 00:02:33.276, Speaker A: I will either describe extremely quickly, in 30 seconds, or in detail, depending on how the time goes. So, but by way of introduction, let me just talk about graphs and sparse matrices for 1 minute. Solving sparse linear systems has been a foundation of scientific computation for many, many years, and graph theory has contributed to sparse matrix computation for 50 years or so. For example, in symmetric gaussian elimination. Symmetric sparse gaussian elimination. One of the algorithms that came out fairly early in this history is something called nested dissection, a term in an algorithm that was made up by Alan George in 1971, which is essentially a divide and conquer way of ordering the rows and columns of a matrix to get a sparse factorization. That was 1971, and over the years since then, people built better and better separators, better and better nested dissection algorithms.
00:02:33.276 - 00:03:37.676, Speaker A: Algorithms, and also did better and better theory to show stronger and stronger optimality results for it. And generally speaking, over the last 50 years, there have been a huge number of graph algorithms that have contributed to practical numerical linear algebra, to solving linear algebra on supercomputers. That's a different talk. But the point I want to make here is that nested dissection took something over 20 years to go from an algorithm with an implementation for a special case to the algorithm that everyone used for doing sparse gaussian elimination. What happened in those 50 years? Well, things became more generally applicable during most of that time. Local greedy algorithms that were not optimal asymptotically beat out nested dissection what happened in those 20 years years was that n went to infinity. Well, it got closer to infinity in some metric than it was at the beginning.
00:03:37.676 - 00:04:23.594, Speaker A: And what also happened was that algorithms for heuristic and approximate algorithms for partitioning graphs got lots and lots better. And somehow in the early 1990s, it all came together, and nobody used anything but nested dissection anymore. So combinatorial Laplacian algorithms, Pravin Vaidya, of course, did his work. Around 1990 or so, Spielman and Tang made their tremendous end times poly log breakthrough in 2004. This is far from being a complete list. But then Giannis and Gary and Richard in 2010 brought the exponent on log n down. And John et al.
00:04:23.594 - 00:05:12.074, Speaker A: More recently gave an algorithm that you can actually describe to somebody in half an hour that's only a log factor slower than that. Okay, it's been 20 years. So why are combinatorial laplacian algorithms not the algorithms that everyone uses for solving laplacian systems, which lots and lots of people do? That's the challenge. So Sivan raised a lot of questions. People in the audience raised a lot of questions about the laplacian world championships. I would like to spend a few more minutes extracting discussion on these session set questions. I would like.
00:05:12.074 - 00:06:29.144, Speaker A: Let's see. Yanis, would you be willing to spend a few minutes? Let's do this first, and then if there's any time left at the end, I'll talk, and other people will talk. But as Sivan said, I think, well, I think this is enormously important at this point in time. I think probably I count as one of Siwan's full professors, who spend most of his career doing high performance computing. But I think it's time for this community's, this specific piece of what this community has done to have a significant, real practical impact in large scale computing. So I think this is a great idea. Why should you participate? What would make you more likely to take part in this? What are the incentives we should do? Oh, and we talked a little bit about what are the right metrics and so forth and test drafts and so forth.
00:06:29.144 - 00:06:49.044, Speaker A: A lot of these questions Sivan's already talked about. But one thing I'm interested in is the incentive question. You're sitting there thinking, boy, this is a great idea for somebody to do. What would make you think, boy, this would be a great idea for me to get involved.
00:06:49.664 - 00:06:53.956, Speaker B: So the question is, how many here are doing it?
00:06:54.120 - 00:06:56.664, Speaker C: How many just give a shovel of hands?
00:06:58.764 - 00:07:06.864, Speaker B: How many groups are actually working or different groups, distinct groups are actually working on implementing various how many.
00:07:13.124 - 00:07:14.064, Speaker A: Years ago.
00:07:16.564 - 00:07:18.924, Speaker D: Optimization that I like to compete with.
00:07:18.964 - 00:07:22.364, Speaker B: Those, but it's not directly solving the classes.
00:07:22.484 - 00:07:46.592, Speaker E: Wait, that would be great, because one thing we need is generators for instances. And now we have algorithms that take max flow and solve them by the plus linear systems. But I don't have natural max flow instances. If you have a max flow instance you want to solve, then we should. It'd be great to somehow include those. Then they have to pipe through an algorithm that turns max fun to solving linear systems.
00:07:46.768 - 00:07:47.772, Speaker F: We could perhaps, I don't know if.
00:07:47.778 - 00:07:58.994, Speaker E: You guys think we could agree on one or two, because certainly the linear systems you get at the end of those routines are very different than the ones you get at the beginning. So the aggregate time would be interesting.
00:07:59.614 - 00:08:05.874, Speaker G: How much is it, sorry, just Laplacians. And how much is it just symmetric diagonally dominance?
00:08:08.094 - 00:08:32.304, Speaker A: Our focus is on laplacian linear systems specifically. I mean, of course there are reductions and so forth. You have to draw a circle around something. I mean, there's a huge, there's a huge literature outside the theory community on more and more general versions of matrix problems, but yeah.
00:08:33.044 - 00:08:35.744, Speaker B: So how many groups do we have?
00:08:36.324 - 00:08:40.260, Speaker A: How many people, maybe is what you get by your shirt very well. Okay, how strong was the word?
00:08:40.292 - 00:08:49.415, Speaker C: Like, you know, he's working on. I have three undergrads who are trying to figure out your code.
00:08:49.559 - 00:08:56.363, Speaker F: Is that what to say? That's working on.
00:08:56.663 - 00:08:58.287, Speaker A: Can I make a. John?
00:08:58.455 - 00:10:29.484, Speaker H: Yeah, so, I mean, I think Gary Scoop did actually implement the whole thing. And I am conjecturing that Gary strongly interacted, was practical, and so that's a little hard to arrange. So I would suggest that as part of what your infrastructure is going to provide, you provide essentially a way of hosting interests and abilities. And there's a term for that. I've actually been working quite a bit in this area, innovation marketplace. But just to give you sort of the idea and the crudest version, you would basically allow people to blog about, you know, post about their capabilities and their needs. So very primitive website would do, you know, one webpage for capabilities, and people would post how they could be accessed.
00:10:29.484 - 00:11:04.124, Speaker H: So, I mean, I think people misjudge how difficult it is actually to produce working code. And I think some people in the supercomputing community might be quite excited and willing to provide those capabilities, but John Gilbert is. You guys are fairly well connected with that community, but you need to get them involved with this, right?
00:11:04.424 - 00:11:36.756, Speaker A: So to some extent, it's a coincidence that we're pitching this to the theory community first. It's our intent to give similar talks with different emphases in other communities. But one thing, 1.1 point that I think is important that you're making, John, is that, is that matchmaking is going to be a real important job for the organizing committee. I think that's absolutely true. And one thing, you know, one thing.
00:11:36.780 - 00:12:20.384, Speaker H: It'S going to be your responsibility that it implicitly has to be. I mean, it's really almost more important than posting the problems and post the results. It's actually something that you've never done before, but I think it's absolutely essential. So you have to have a public, essentially a marketplace, but a posting, really bulletin board where you post, people are able to post their capabilities, and without that, you're going to be down to, I think I count three groups competitive with all sorts of lost opportunities.
00:12:21.004 - 00:12:34.540, Speaker A: Without that, certainly making connections between people with different skills from different communities is going to be one of the most important parts of this. Sivan?
00:12:34.612 - 00:12:44.780, Speaker D: Yeah, I want to add to that. I mean, I completely agree that it takes people with different kinds of expertise to write a solver. That's good.
00:12:44.892 - 00:12:52.584, Speaker H: No, I'm not just saying that. I'm saying that you have to provide some format, some well thought out format.
00:12:53.924 - 00:13:51.874, Speaker D: To facilitate people to communicate. Yes, I agree. The point I wanted to make here is that it's possible for high performance computing team, existing high performance computing teams to participate on their own. So here, you know, on the hill, people from Berkeley lab can probably form a team and come up with something reasonable. My concern is that if they do this without strong theoreticians, they will, you know, they will reap the relatively shallow ideas and that there are deeper theoretical ideas that are too hard to understand and to fold into the implementations, and that we will not extract the most benefit. So I think it's important for theoreticians to participate in order to make sure that the implementation sits on a theory that's as deep as necessary rather than is as deep as somebody can digest.
00:13:53.534 - 00:14:22.486, Speaker A: Sivan mentioned that. I mean, of course, everyone knows that Gary and Yanis and Richard and Gary's group, going back many years, have been centrally involved in a lot of these implementations. And I wanted to give, I wanted to ask Giannis in particular if he would be willing to spend a few minutes talking to us about his perspective on this whole question. Giannis, would you be willing to talk to us for a few minutes?
00:14:22.590 - 00:14:23.158, Speaker B: Yes.
00:14:23.286 - 00:14:30.434, Speaker A: Thank you. I'll even give you the microphone. How about that? Well, it's for the recording, yes.
00:14:32.054 - 00:15:49.346, Speaker B: So suppose I haven't prepared for this, but what I can say is that we worked on this solver back in 2009, and I think the last time I touched it, we touched it was in 2011. So there have been no changes in the code since then, probably 2010. And so, as you may know, it's actually not based on the papers with proofs. So it's based on a different idea that Gary and his student developed earlier, which is based on using extra variables called Steiner variables for actually constructing preconditioners. And what we did is to actually work on the theoretical part and understand these preconditions a little more, and also combine them with multi grid type algorithms, which gave this over. So now this over. From what I hear, a lot of people have used it in their own at least, and it works well for many people.
00:15:49.346 - 00:16:51.360, Speaker B: But I can certainly say that it's far from being. There's a lot of room for improvements there, both in the combinatorial constructions and the condition numbers, but also in the actual implementations, software engineering issues. For example, in there there is a metric background application routine, which is basically hand coded. It doesn't use any existing libraries. In the past we have also worked on trying to parallelize matrix of XML with Gary and Guy Blalock and Kanata Musang, and we actually obtained four times speed up in an eight core machine, but that required an extensive implementation of meta modifications. So perhaps we haven't, you know, this is not yet out. The combination of the two, the CMC and a much better metrics random application core is not there.
00:16:51.360 - 00:17:49.694, Speaker B: So that's one improvement that perhaps we can make and other improvements, practical improvements. So certainly it will be helpful to have people that understand details about coding and have them work on it. Now, there is possibly something that can be done in terms of the condition numbers, improvement of the condition numbers. So, well, there is this work by Harold Reiki. He's there. Okay, so he was hiding. He constructs this one single trees, congestion approximators, you can call them, that are Steiner trees, trees with extra nodes.
00:17:49.694 - 00:18:50.914, Speaker B: And the ideas in the CMC solver are based on this type of ideas, very close and inspired by his work. Actually back then, like in 2007, when I worked on this for my thesis, we weren't actually able to find them fast. And there has been a lot of progress in actually designing combinatorial algorithms for finding these trees fast. And the latest contributions by research who gave, who observed that we can actually find them in nearly linear time. Now, based also on Harry's recent work. And I believe that it is, we are very close to actually coming up with a theoretical, better theoretical understanding of these standard preconditioners. And what I mean by that is to actually write a paper which claims an upper bound for this approach, strict upper bound, like we have with sub graph preconditioners.
00:18:50.914 - 00:19:11.702, Speaker B: And this particular theoretical direction may not look very necessary at this point. We have all these other strong upper bounds. But I think if we actually prove it, improve the upper bounds for this type of preconditioning, we will actually get a much better CMZ like code in terms of the condition number.
00:19:11.798 - 00:19:18.398, Speaker C: So, Johannes, and theoretical insights from your, from your implementation.
00:19:18.526 - 00:19:19.174, Speaker B: Yes.
00:19:19.334 - 00:19:27.004, Speaker C: Questions? Can you talk to me about what, as a card carrying theorist, what value did you get out of doing an implementation?
00:19:27.664 - 00:20:30.266, Speaker B: What value did I get as a theoretician? The value that seems to be the most important part, at least now it looks like, is that there are people, the code has been published for a number of years now, and there are people in other communities, for example, data mining, that slowly find their way to the code during the years. And a lot of that is due to Dan Spades, who has posted a link to my code. And actually, I see a lot of traffic coming into my webpage from his web page. And so I have actually helped people apply or use the code. And in the process, you know, the code is used for certain problems they have, for example, data mining. I will actually be talking about that tomorrow a little bit, and. Sorry.
00:20:30.266 - 00:20:48.006, Speaker B: And so I'm actually in this way, I can also help them directly in some of the problems they have. So I think it improves. It improves the interaction that happens between different communities, more applied. And so, so that's something we gain from, from it.
00:20:48.070 - 00:21:02.438, Speaker D: If I can reinterpret what you said. Yes, excellent leading question. Okay. What you gained is you get your gate or you're gaining citations from people using your code that demonstrate impact outside of your field.
00:21:02.526 - 00:21:13.640, Speaker B: I would say. I will say no citation, citation, including citations. But I think the most valuable is actually collaborations. I've had people that I actually work with people collaborate with people and try to solve problems.
00:21:13.752 - 00:21:49.772, Speaker I: But, you know, here is a question I have, and actually, that probably addresses some of this point, is that I would love to get involved here, but, you know, I am definitely, I will not even try to program anything because this will be a disaster. How can I find person who will be willing to like to talk to me? Like, sort of the point is, I say, I know some of you are, you know, how to code, but you are like half of the country away from me, and, you know, like, this is for me, this is the problem. I would love to collaborate with someone who understands the system side of this applied algorithms and try to do something more, but I can't find that as such a person. How do you go about it?
00:21:49.788 - 00:21:55.772, Speaker B: It's like, you know, how do you go about it? How do you find people? That's a good question. We have one more question.
00:21:55.828 - 00:22:03.770, Speaker G: Yeah, I guess another way to phrase this is that we in this room are excited about this question is, how do we get people who are not in the room excited about it as well?
00:22:03.802 - 00:22:04.906, Speaker A: Because that's the whole point, to build.
00:22:04.930 - 00:22:31.582, Speaker C: This collaboration I'm actually more worried about. So I'm glad to hear that you think people in the room are excited about this. I was more worried about this community being enthusiastic than I was about a more traditionally applied community. I think the challenge, of course, will be that if a pure theoretician starts to direct someone in an implementation train wreck, dead ahead. I mean, there's going to have to be give and take and respect on both sides.
00:22:31.638 - 00:22:48.590, Speaker I: No, it is. I'm not saying that I will, like I need an undergrad who will just code it out. That's not the point is they're just saying, but you need someone who understands that aspect. Exactly. To have a discussion and saying, okay, I have this crazy idea and this person will tell me, this will not work because of. And that's exactly what I need. I don't have it, and without this I would be hopeless for you.
00:22:48.622 - 00:22:54.426, Speaker G: So you think they applied people with great incentivize to actually collaborate with us and learn these algorithms?
00:22:54.550 - 00:23:36.422, Speaker C: I hope so. That's certainly our goal. I have a concern that they'll want to take the existing algorithmic basis that they have, just try it on these problems, they'll work on the meshes, they won't work on the hard instances, and, you know, end of story. The hope is that the insight from this community will lead to more highly robust and more broadly applicable implementations that are more consistently performant and creating the incentive on their side to reach out and embrace. And frankly, these are not simple papers to read.
00:23:36.598 - 00:23:37.502, Speaker F: I don't have to tell any of.
00:23:37.518 - 00:23:42.742, Speaker C: You that certainly for an applied community. And so I think there will have to be a lot of given to.
00:23:42.758 - 00:23:43.314, Speaker H: Me.
00:23:45.384 - 00:24:41.228, Speaker F: Basically, is that indeed the gas machine helped with prosthesis and application are actually fairly large. But on the other hand, I think having a concrete package, even though hybrid rudimentary, does create other people you know, opportunity for other people to look into it. 30 years ago, I had a minor experience of it, you know, although my thesis we are writing for separated theorem based on geometry, and I think John Newman was first person to coach me to at least write a very small code in Matlab. And very quickly was someone just willingly poured into the thinking machine scientific library. The next thing I saw is people take the math lab code and just professionally coding to the scientific library. No, no, it's Leonard Johnson and his students.
00:24:41.316 - 00:24:42.384, Speaker A: Oh, he did, too.
00:24:43.604 - 00:25:15.284, Speaker F: Just directly, without my interference. And even the first time I feel really proud of is a math lab math work published, what do you call calendar. One of the calendar has the petition reproduced and with our name printed on it. So I think it somehow. But otherwise, if it's just a paper, absolutely. People will say, nice to know you can do this. And it is very hard for somehow breakthrough into the application.
00:25:15.284 - 00:25:40.904, Speaker F: That's why I think it's terrific to have complete end to end package that people can easily plug into some other application. So that's why I think Alexander is correct in sense, that you can't just write the code. You have to have a good interface, you have to have all those good designs so that people can simply somehow plug in. Then I think other people may improve afterwards.
00:25:43.324 - 00:25:46.084, Speaker A: I think we should probably, probably we should wrap up.

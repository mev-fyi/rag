00:00:00.200 - 00:00:01.032, Speaker A: The next session.
00:00:01.158 - 00:00:06.314, Speaker B: First speaker is Benoulis Pontarakis. Talking about mechanism design beyond risk neutrality.
00:00:06.654 - 00:00:39.036, Speaker C: Hi, my name is Manuel Pundrakes. Thanks a lot for having me here. So I'm going to talk about Megan design beyond reach neutrality. I'm currently a postdoc at UT Austin. So let's start with a brief introduction to what mechanized design is. So, there are several definitions for mechanical design. The one that I particularly like is it's a system of, we have a system of individual rational agents and our task as a designer to design an incentive structure in order to achieve a given objective.
00:00:39.036 - 00:01:08.904, Speaker C: So what is the most famous example of this is auctions. We have a set of self interested buyers. They're interested in an item that the auctioneer wants to sell, and the auctioneer's goal is to maximize the revenue. But given there are multiple people here that are interested in other topics where mechanics is applicable, let me give you some more examples. So, yeah, and the way. Sorry. So the way to achieve this is the elicit bids to know to determine the allocation of the payment.
00:01:08.904 - 00:01:56.524, Speaker C: Another example would be transportation networks. Our goal here would be to minimize congestion. Drivers are interested in minimizing their personal route, the time of the personal route time, whereas our goal is to minimize total congestion. And the incentive structure here would be a form of negative incentives. For example, place toll on several routes so that it incentivizes some change in the routing in the routes that the drivers are choosing, so that we get a total, in total, minimize the total contest. Another example from energy is the energy markets. The particular topic that I like is demand response.
00:01:56.524 - 00:03:19.234, Speaker C: What do we do in demand response? We are trying to incentivize energy consumers to reduce their energy demand during peak times. And how do we achieve this? Will provide positive incentives through coupons for reduction in energy consumption. So our goal here is to, for example, let's say this is an experiment that has been done in Houston 2016, where people were given some monetary incentives if they reduced their ac temperature, they increased their ac temperature during peak times, and there was very little positive feedback about the effect of these incentives. So from a computational perspective, why are these problems interesting? First of all, traditional, this has been studied from an economics perspective. So there's a lot, a lot of work in mechanical design in the economic literature. However, due to all of these applications are increasing in scale, and there are actually some real time computational demands. Think of online auctions happening on the Internet, or demand response that has to happen within an hour.
00:03:19.234 - 00:04:39.734, Speaker C: We have some need for an interest for efficient algorithms and the main question we'd like to study is what is the tradeoff between the quality of the outcome and the computational tractability. So back to Vijay's comments before, is this is the field of algorithm mechanics design, where our main goal is to study what is this trade off between how can we do better mechanism and also respect computational constraints and be fast and also sometimes also have simple solutions? So far, everything I know so far has nothing to do with risk. It's the standard mechanic design. And the last slide is about algorithmic and design, how algorithmic thought can help in solving these problems. So what about risk? So, a typical assumption, that is in mechanical design, and especially the way that in algorithm mechanism we studied the problems, is that we assume that the agents are risk neutral. So our optimality conditions and everything we do relies heavily on this risk neutrality. But in reality, in practice, agents are not indifferent to risk.
00:04:39.734 - 00:05:57.244, Speaker C: Two very famous examples for that is auctions, where in practice, usually buyers over bid compared to what the theory would predict for their best response if they were risk neutral. So usually agents bid more in a first price auction than the theory would suggest, which implies some sort of risk average behavior. In contrast, for energy demand response, this particular study that I referred before using randomized coupon, have great impact on affecting the customer behavior. So the consumer behavior, sorry, that should be consumer. So we see that in this case we have some sort of a risk seeking behavior where a randomized reward would elicit better response. Or if you want fix on the type of response you want, you can do it in a cheaper way if you use some sort of lotteries. Both these examples motivate the study of mechanisms and the computational aspect of mechanisms when there is no risk neutrality, when we have some sort of either risk averse or risk seeking behavior.
00:05:57.244 - 00:06:52.288, Speaker C: So the talk overview, I will focus on a single item auction because this is one topic that has been studied and there is a lot of work behind this. And as you most results here usually carry over in different settings. And I'm going to give some overview for what optimal options are for risk neutral agents. Then I'm going to talk about what happens if we, how can we take advantage of risk average behavior and how complicated the optimal algorithm becomes. Then I'm going to go to the risk seeking behavior and show how we can take advantage of the risky behavior by using a simple solution instead. And then I will conclude with some future directions what I think are important topics in this area. Okay, so let's start.
00:06:52.288 - 00:07:23.504, Speaker C: So let's, let me define first the setting of a single item auction. So we have an auctioneer that has a single item to sell. There are n buyers interested in the item, and each buyer I has a value vi for the item. The important thing here is that this value is private. So this value is known only to the buyer I, the auctioneer and the rest buyers. Instead, they don't know that value. What they know is that it's drawn from some distribution f.
00:07:23.504 - 00:08:15.472, Speaker C: So, simplicity. Here I assume that this is common distribution. But all of these can be extended if the values are drawn from heterogeneous distributions, and that should be the setting. And how does a mechanism, an auction look like? In such a setting, the buyers report bids to the auctioneer, and then the auctioneer, given these bids, will decide on the allocation probability and the payment for its buyer I. So that amount here will tell you what is the probability of receiving the item given the bids of everyone else. And this is exactly the payment that you have to pay. The bias goal in this setting, in this risk neutral setting, will be to maximize that amount.
00:08:15.472 - 00:09:09.834, Speaker C: What is this amount? This is the value that you have for the item. The real value times the allocation probability minus the payment. So the goal of the buyer I would be to maximize that quantity, whereas our goal as an auctioneer in this case would be to maximize the revenue, would be the summation of the payments. Now, a typical assumption in such a setting is that a mechanism is truthful if it's the best interest for its buyer to report their true value. And there is a lot of theory behind why we can actually restrict our attention to only truthful mechanisms. Yes, distribution is identical for all buyers, and for this presentation I assumed it's identical. But all of this work can be done with different distributions.
00:09:09.834 - 00:09:51.494, Speaker C: I will get back to this. When I present the main characterization, I'll tell you how things may be a little bit different. So, so far, that's the model. So let's see an example, a very trivial example, with a single buyer. This is going to be an example I'm going to use throughout the whole talk to show you the difference what happens when, in the presence of a risk neutral, risk averse and a risk seeker seeking buyer. So we'll have a single buyer with a value v drawn from a distribution uniform zero, one standard example. Can I ask a quick question? Yes.
00:09:51.834 - 00:09:54.610, Speaker B: So the buyer knows his value. Yes.
00:09:54.722 - 00:10:21.496, Speaker C: So that distribution is from a point of view of the seller, of the seller, and in this case only the seller. But for multiple buyers, it's also going to be from the perspective of the other buyer. So its buyer doesn't know exactly the value of other buyers. They know only the distribution and they all agree on the distribution. Yes, we agree on the distribution. Yes. So this should be like a market research or something, right? This is according to market research.
00:10:21.496 - 00:10:35.760, Speaker C: All we know is that this value is drawn from some distribution. But yeah, this is a common prior model where everyone agrees on the distribution. And for this case, the symmetric prior.
00:10:35.952 - 00:10:39.352, Speaker A: And also the distributions are independent across different.
00:10:39.408 - 00:10:41.328, Speaker C: Yes, these are the way independent.
00:10:41.496 - 00:10:47.416, Speaker A: It doesn't matter if they disagree on the distribution of dominant structure.
00:10:47.520 - 00:11:03.416, Speaker C: Yes. Yeah. The optimal is going to be dominant strategy, but not necessarily when we assume risk. Right. But yeah. So what is. How would you.
00:11:03.416 - 00:11:49.744, Speaker C: So I'm giving you the situation where you are an auctioneer, you have a single buyer. That's what you know about this buyer. How would you proceed with designing an auction or a scheme for this case? Well, the most typical thing you would imagine doing is to offer a price, a pricing mechanism, right? Essentially offer a take it or leave it offer of p. What does this mean? Is that the buyer will accept if the value is over p. So that's essentially using the previous notation would be that we receive the value of the buyer and then we allocate it if the value is over p and zero otherwise, and we charge them p if they win or not. But, you know, you can view it both ways. This is the simple way, this is the formal way.
00:11:49.744 - 00:12:22.564, Speaker C: So if we restrict our attention to this sort of pricing mechanism, our goal would be to. And our goal is maximize revenue. We have to solve that problem. So the probability of this is the price that we put the target, the price that we put on the item times the probability of this item being sold. And solving that equation, we get optimal p is equal to one, two, and we get the revenue of a quarter. That's everyone that knows a little bit of revenue maximization. This is the typical example they first encounter.
00:12:22.564 - 00:13:08.272, Speaker C: And then the next question is, what about the optimal auction for this setting? What if we allow randomization or multiple offers or any sort of crazy things? Can we do better? Well, the answer is no. This is the best thing we could hope for. This simple pricing mechanism is optimal for the case of a single buyer. This is due to margin's characterization of the optimal auction, one of the most celebrated results in mechanical design and microeconomics, I would say, in general. And also that applies for multiple buyers, of course. And what we get here is the second price auction with a reserve. Now back to your question here.
00:13:08.272 - 00:13:45.084, Speaker C: The reason why? Because I wanted to have it. A simple description here was that if people are coming from a symmetric distribution, then it ends up being the second price auction with a common reserve. If they have from different distribution, it's not the second price, slightly different, but it's still very simple in the sense that it's deterministic, it's dominant strategies that we described before, but it's slightly harder to describe. So that's the only reason why I use the common parameter. So the symmetric prior. So this is the situation. So we should be happy.
00:13:45.084 - 00:14:43.788, Speaker C: There are some things that someone could try to study more here. For example, what if we use this oxygen in a setting where agents are not symmetric? And several questions like that have extensively been studied in algorithmic literature. But the thing that I would like to change from this standard model today is, as I said, the risk neutrality. So this whole theorem, this characterization, is heavily relying on the fact that the agent is risk neutral. So essentially that the agent is maximizing that amount here, however. So let's give you an example. Let me give you an example to depict what risk neutrality means here is if I give you an option one, which is a price of a half, an option two, which is a price of one with probability half, and price of zero.
00:14:43.788 - 00:15:21.324, Speaker C: Otherwise, risk neutrality implies that both of these look the same for you, like, and to every agent, they cannot distinguish between these. But as you feel like, at least that's what I feel, that in practice, that shouldn't be a decision that they would like. They would not. These are not interchangeable, these are different things. The perspective of a someone making a decision in practice. So yes, as I said, the risk of buyer likes this option the same, but not what we expect. So, to model risk in this case, we're going to use the standard and traditional notion of expect utility theory.
00:15:21.324 - 00:16:14.210, Speaker C: According to this utility, the agent is maximizing a utility over their rewards. So if we perceive that amount here as a reward, then our goal is to maximize the expectation of a utility function of this reward. The reason I use capital here, because these are essentially the random variables. So these are essentially what we get here is the realizations before you could think about this case here, that could be like the expectation of x. So that would be taking the expectation inside here is taking the expectation outside for some utility function u. So given that notation, given that definition, sorry, how would we define the risk neutral behavior? Well, a risk neutral agent is any agent that uses a linear u. So using a linear u is equivalent.
00:16:14.210 - 00:16:50.308, Speaker C: Maximizing that quantity is equivalent to maximizing the thing that's inside an expectation. So we just get what we had before. But if we want risk aversion, we get with a concave u. And if we want a risk secret, we get with a convex u. So by changing these u accordingly, we get the behavior that we would like to have. So let's do a sanity check here, or let's go back to original exam, to the exam that we had. We have option one that seems to be the one that should be preferred by the risk averse agent.
00:16:50.308 - 00:17:50.916, Speaker C: And this should be the one that should be preferred by the risk seeking loathing agent. So the risk averse agent, using just the definition of concavity, we can see that they should prefer this, whereas this agent should prefer the other option. That's clearly by just definition. Now, the, the natural question is what happens when we don't have risk neutral agents? Now, I described to you the optimal auction for risk neutral agents. And now suddenly I tell you, well, your agents are not risk neutral anymore, they are risk averse or risk seekers or something. Should you worry suddenly whatever I was doing doesn't produce as much revenue as it did before does? There are risk averse or seeking agents negatively impacting the revenue. In this case, you think about it.
00:17:50.916 - 00:18:45.448, Speaker C: Should that be the case? No. The optimal risk neutral auction is deterministic, right? So if you, if. Since the optimal was deterministic, if you suddenly switch to risk averse or risk seeking agents, whatever was giving you the optimal revenue for the risk neutral case is still giving you the same revenue, you don't risk. Behavioral agents do not change their decisions on deterministic auctions. So you're as good as before using the optimal maersonian auction, but you're losing potential. Right? So the idea here is that adding this, assuming that the agents have some sort of behavior towards risk, either risk aversion or risk seeking, there is some, some advantage to, in brackets, exploit that behavior and obtain more revenue. Sounds bad, but think about, like, think of the other application.
00:18:45.448 - 00:18:49.992, Speaker C: But that could be good. Like. Yes.
00:18:50.128 - 00:18:54.312, Speaker B: What do you mean when you say the action is deterministic or is still random as associated with other people's play?
00:18:54.368 - 00:19:26.812, Speaker C: Right? Yeah, yeah, but I'm. Right now, I'm focusing on a single buyer right now, so I'm doing all this work for the single buyers. So right now, example, yeah. Should have said that I'm focusing on the single buyer. So right now, everything is deterministic. You should be happy that everything you were doing before, you can do it again. You can solve for the same price and you get the same revenue.
00:19:26.812 - 00:20:11.688, Speaker C: But you can get tech advantage of this behavior. So let's revisit that example and consider the case of a risk averse agent. So again, we have our prior is uniform, zero, one, and let's assume that particular utility, which is the square root. This is a concave utility. So I just chose it for no other reason, was the first thing that came into my mind. So now, remember, before, what we did is we're offering a single price if when that was linear. So now I'm changing a little bit the algorithm by adding an extra choice.
00:20:11.688 - 00:21:11.034, Speaker C: So, instead of offering only that option, I'm giving you the option of buying the item at the price of a half with certainty. I'm also telling you that, look, there's this lottery you can pick that you can obtain the. What's going to happen is the moment you pick that lottery, then I'll throw a coin, a bias coin, that's, with probability, a quarter. You'll win the item, and then, and only then, you're going to pay another quarter. So you have to decide which of them is best for you. Now, what do you expect to happen in this case? Well, if we look by adding that, so if we just remove the option two, we get exactly the same result that we would get in the original setting, where we get a revenue of a quarter, right, where every agent above a half is getting option one, and every agent below a half is not taking any offer. Now, we have introduced that option here.
00:21:11.034 - 00:22:01.876, Speaker C: What's going to happen is, first of all, everyone that has a value below a quarter, who's not going to pick anything, everyone between a quarter and a half is going to pick that option, because that strictly gives them some positive utility. Whereas before they were getting nothing. But what happens is some agents that are in the proximity of a half will want to switch to the bottom option, because they were getting almost nothing before, and now they have an option of getting something right. So you introduce that option, you suddenly get some new types that will be accepting your price, but now you lose someone from the top of the one that was giving you the highest price. So let's calculate that. We'll just find the sweet spot where that happens. Well, that happens to be 31 over 60.
00:22:01.876 - 00:22:41.842, Speaker C: That's very close to a half. So what means is that all of the agents that are between 31 61 are going to pick that choice. Between a quarter and a 31 over 60 are going to pick that option, and then the rest are going to pick nothing. So how much is the revenue out of this? Well, it will get slightly over a quarter. So we did better. We introduced a new option and we did better, something that was not possible with risk neutral agents. What is happening here? Intuitively, we could do the same thing with risk neutral agents, but what would happen is this would backfire, and essentially we would lose more revenue that we would gain by producing that object here.
00:22:41.842 - 00:23:42.324, Speaker C: But the reduced probability of that option here makes these agents that are risk averse, not so eager to drop this certain choice that they have and go down to that cheaper but more, but very risky in brackets option. So that's, that's what? So this, the amount of people that leak to the bottom options is shrink massively due to the risk aversion. So, and generally, for risk coverage agent, there is, this is just an example. This has been, this is a problem that has been extensively studied. These are the two papers that, if you like risk covers, you should definitely read. These are the seminal papers in this field. And so they have studied and understand what is the optimal options for some relatively severe assumptions.
00:23:42.324 - 00:24:32.046, Speaker C: And this is considerably complicated. You can actually imagine doing the trigger that did before by feeding options all the time, and eventually further and further and further increasing the revenue it could get. So something like that happens, could happen in the ottoman oxen. There are some work tries to find approximation, but that's what I think is what I think is the most interesting direction for the research to go in this particular problem is to just identify approximations that can do good compared to the very complicated optimal auction. And generally, this intuition that first price auction performs better in the presence of risk coverage agents. So that's what we know about risk coverage agents. Yes.
00:24:32.190 - 00:24:39.502, Speaker A: In what sense is what you proposed at auction. It looks like the seller presents some options to the buyer, right?
00:24:39.598 - 00:24:39.966, Speaker C: Yes.
00:24:40.030 - 00:24:42.114, Speaker A: You didn't tell us what the buyer actually bids.
00:24:42.894 - 00:25:02.734, Speaker C: Okay. Yes. So in this any. Okay, yes, you are right in the. I glossed over it. For the case of a single buyer, this bidding game can be done by offering. Like, there is an equivalency between bidding and offering options.
00:25:02.734 - 00:25:05.178, Speaker C: What would it be in your example?
00:25:05.226 - 00:25:08.254, Speaker A: Because I guess what you bid would depend on what your value is.
00:25:09.434 - 00:25:31.714, Speaker C: What I would do is I would reverse engineer exactly how you should behave, and I will tell you I will behave optimally for you, and I commit to that. And then you just put your value and I behave exactly like that. So if your value is between this and this, I'm giving you that option. If your value is between this and this, I'm giving you that option. If I do that, there's an equivalency between the two case.
00:25:31.794 - 00:25:43.258, Speaker A: You don't have to answer if it's too complicated, but I'm just trying to imagine if I am a person with a value of x whatever, and presumably this is what I'm going to get, this probability, if I'm going to get the item for these prices.
00:25:43.346 - 00:25:43.754, Speaker C: Yes.
00:25:43.834 - 00:25:47.614, Speaker A: What would I actually tell the seller? It's not clear from what you described.
00:25:48.294 - 00:26:39.546, Speaker C: Yes, it's not clear because this particular implementation is like this standard notion of how an auction should run like is not necessarily how they're really being implemented. This is a way of unifying how exactly we define an auction through an allocation and a pen probability for the case of a single buyer. It's much more intuitive to think of like there is an equivalency between that definition and me offering you options and then chooses what you like. So instead of doing the auction by bidding, all I'm doing is these are the options I'm giving to you. Choose your best, the corresponding optimal. So the corresponding version of that auction with allocation function is just the one that tells you I'm going to do the best response for you. Just tell me the truth and I'm going to do the best thing for you.
00:26:39.546 - 00:26:54.554, Speaker C: These are the options I'm going to consider and I'm going to just do what you would do if I gave you this option. Yes, yes. You can do that by splitting your value and then the option that you define the option. And yes.
00:26:59.774 - 00:27:16.494, Speaker A: Many pieces of probabilities, can't you approximate risk aversion by a more complicated function over hundreds of goods? If I had many small pieces, and these are exactly probability increase in the probability.
00:27:19.554 - 00:27:41.906, Speaker C: I was actually sometime was trying to solve that connection. I don't think I have reached the conclusion. I'm not sure about that answer, but it's something that I was thinking at some point. Yes, yes. Yeah. But this is kind of what you do. Like essentially you're offering, you're saying that what, what this can grow like is going to be okay.
00:27:41.906 - 00:28:22.654, Speaker C: I'm going to essentially extract your value by saying you beat your, I'm going to charge your value slightly under your value, but I'm guaranteeing you that a good probability of allocation and the next person is going to guarantee slightly less, but you charge a little bit less. What eventually you get is you lend this person's value and you charge them for it. Right. So I think, I don't know how much time I have, but ten minutes. Good. So, yeah, so that's existing work. So let's go to risk seeking agents, because kind of like, this is my contribution in this talk.
00:28:22.654 - 00:29:23.556, Speaker C: I just read this. So the main question I would like to ask is, are optimal options for risk seeking agents as complicated as the risk averse counterparts? As we saw and alluded and briefly described, risk averse optimal auction design is complicated, and it may involve a very complicated mechanism. So we asked this question here. Now, one problem we reach with risk seeking agents is the problem where under extreme case of risk seeking behavior, the mechanism obtains infinite revenue. So you can think about the case that you can always, if an agent is infinitely risk averse, you can offer them an infinite gamble where you can get infinite money. We circumvent this by always assuming an upper bound m on the max on the exposed payment. So we say in no circumstance you could ever pay more than m or charge someone more than m.
00:29:23.556 - 00:30:13.228, Speaker C: And you can think of it as the buyers have some sort of a budget that they cannot go beyond ever paying from their pocket that money. So given that assumption, let's go and revisit that example, the one we started for the risk average case before. So again, we have this, and then we consider the exponential utility here, e to the x minus one. And let's say the maximum value here is two. So the 18 is between zero and one, but we can tell them at most two. So how would we proceed with taking advantage of risk seeking behavior? Here we offer one choice. Now, we will offer the item with probability one, but instead of offering at a fixed price, we'll use a randomized price.
00:30:13.228 - 00:30:47.562, Speaker C: So p is equal to m, the maximum value with probability half, and p is zero, otherwise. So we are telling them, I'm going to give you just a take it or leave it offer, but it has to be randomized like this. So it's a gamble, essentially. And then the next question is, how many people will go for that gamble, for what types of this, in the support of this distribution, this gives them positive utility. Well, you can just compute it, and roughly around 0.56, that's what you get. You get actually revenue of 0.44,
00:30:47.562 - 00:31:46.260, Speaker C: which is significantly more than 0.25. So what we saw here is by adding an extra option without adding an extra option, by just editing the single take it or leave it offer, adding randomness, we actually managed to improve the revenue in the presence of a risk seeking agent. That shouldn't be very surprising, right? So risk seeking agent wants gambles instead of giving them a random fixed price. We give them a gamble, which they like more, and they are willing to essentially go negative from a risk neutral perspective to go to that gamble. But the most interesting thing is yes, that should be the first intuition. But is that the best thing we can do? Well, the answer is actually yes, which is recent work with Evdo Chia, her student Gerry Young and myself, where the optimal option for a risk seeking buyer is a randomized take it or leave it offer. But our main assumption here is the exponential utility function.
00:31:46.260 - 00:32:25.684, Speaker C: So we're relying on that assumption to show that, and we extend that to multiple buyers. And it's actually kind of interesting that we discover some sort of like a new auction. That is, we call it the loser pay auction. Maybe you're familiar with what's called the ope auction, where essentially you pay your bid in the beginning and then you always pay your bid. Think of the same thing, but if you win, you also get a refund. Whatever you bid, you also get it back to make the losses and the wins as extreme as possible. And this actually happens to also be optimal for this case also assuming exponential function.
00:32:25.684 - 00:33:26.130, Speaker C: And the question is, how limiting is exponential utility functions? Well, unfortunately, it's not sufficient. One option offering just a single randomized negative leave it is not optimal for quadratic utility functions. So we first got our lower bound there counterexample. That's not generally optimal, but we don't know yet if we need infinite or how many we need or how much exactly we lose. The only loss we found here, it was very, very minimal. So there's still open question, what is the optimal option for a general, for general convex utility function? And if this happened to be very complicated, can we approximate with an optimal mechanism? These are now I'm kind of concluding with these two interesting cases that I showed to you about how we can exploit risk behavior in actions. And I want to finish with like three directions that I think are interesting to study in this topic.
00:33:26.130 - 00:34:38.354, Speaker C: And generally, if someone is interested in using behavioral assumptions in some sort of an algorithm problem, are the following. So, dynamic settings, in dynamic settings, because of the extra uncertainty about the future, for example, not only I don't know about other bias values, but I also don't know about my future valuations I have for things that will happen in the future. So there's a sort of like massive increase in like uncertainty, which makes things with risk even more complicated for that. Particularly, optimal auctions, like for dynamic settings, are tailored for risk neutrality and actually have almost zero revenue with risk average agents. We had an example in the static setting where by not taking advantage of risk aversion, we were not harming ourselves, we're just not gaining as much as we could. But for dynamic settings, optimal options starting, failing if we have risk aversion, for example. So that's a very interesting topic to see what happens here.
00:34:38.354 - 00:35:28.716, Speaker C: Another one is the expected utility theory. I mentioned briefly that this is the traditional way of modeling risk. There are some other interesting, it has several flaws. I think some prior talks people have, like I think had talked a little bit about that. But expect utility theory has several flaws. The typical model of utility theory that's used in behavioral scientists is the cumulative prospect theory, where think of it as an additional to the typical theory, where people have also subjective form of probabilities, where they have a weighting function where they can weight the probabilities apart from actually applying the utility function of the wealth. And it can cover several cases where the expected tilt fails.
00:35:28.716 - 00:36:16.174, Speaker C: And finally, maybe, I think it's the most important one is risk robustness, where all of this talk was assuming that even if we agree on a good risk model that we all like, all of these results I described really require that you know the exact risk parameters perfectly. But this is even more unrealistic than, you know, like we already assume we don't know their values, how can we know their risk parameters? So it's kind of like, can we do all of this work in a risk robust manner, where we design algorithms that work in a family, for a family of risk parameters, rather than for a fixed one? And if you ask the question, can we do all the last three together? That's not possible. That's another recent work. And with that, I would like to thank you.
00:36:22.114 - 00:36:40.262, Speaker B: Yes, so one common constraint people think about in mechanism design is exposed rationality, which roughly says that you don't want to charge your agents money without giving them something which selling lotteries violates. So how much do you achieve without violating bads?
00:36:40.318 - 00:37:30.284, Speaker C: If you're playing? We assumed interim IR, of course, because otherwise you wouldn't be able, I'm not sure, for risk averse, you can. For risk averse, you can obtain social welfare without violating anything. Actually, the optimal, it's always, the ex post IR is always optimal for risk averse, because the otmal lottery only charges you if you win for risk averse, and it's only the case for risk seeking behaviors where you actually want to go beyond their. Otherwise you can't really take advantage of the risk seeking behavior. So now, whether or not there is room for. For exposed rationality and risk seekers. I'm not sure about this.
00:37:30.284 - 00:37:35.644, Speaker C: I wouldn't be surprised if there is a result that says you're going to do more, but also maybe slightly, I don't know.

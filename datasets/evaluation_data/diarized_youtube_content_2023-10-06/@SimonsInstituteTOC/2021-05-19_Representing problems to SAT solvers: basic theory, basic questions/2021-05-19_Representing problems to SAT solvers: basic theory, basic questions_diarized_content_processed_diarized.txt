00:00:00.200 - 00:00:57.134, Speaker A: Let me start by introducing Oliver. So, Oliver Coleman is a professor at Swansea University, and I had a pleasure of knowing him when he was a postdoc at the University of Toronto, and told all of us grad students a lot of very interesting things. He's one of the people that I know who have done really foundational work in both the theory of such solving and the practice of such solving, including his recent work with marine on solving combinatorial, hard combinatorial problems, and the theory of upper bounds and all sorts of things. And today, I guess I shouldn't take any more followers time, so Oliver will tell us about encodings, please.
00:00:57.874 - 00:01:07.694, Speaker B: Thank you, Antonina. Let me start sharing. They are all on the same page.
00:01:10.754 - 00:01:11.418, Speaker A: Hello.
00:01:11.546 - 00:02:12.272, Speaker B: Good afternoon everybody. Or good morning, good afternoon, good evening. Glad for the opportunity to talk a little bit about this and that, what I typically call representing problems to such solvers. Let's dive into it. I will start with a kind of generic outline, talking a little bit about what this is all about, but shying away from really giving a proper theory that would be far too formal, and that it takes far too much time. Then I decided for today to tell you about a scheme which I invented something like eight or ten years ago, which seems to me pretty cool and a little known. So this is about translating non boolean variables to boolean variables.
00:02:12.272 - 00:02:50.874, Speaker B: To my understanding it generalizes or known schemes, and I thought it can be easily explained. And so I think that would be good to show you. And then on the theory side, so I worked on these notions of generalized hardness, upper and lower bounds. Likely there won't be so much time for that, so will be only an overview, be basically on topics. Oliver, I'm sorry to interrupt, there's a chat window blocking some of the frame there, if you don't mind removing that. Okay, I saw also.
00:02:51.694 - 00:02:52.470, Speaker C: Thank you, thank you.
00:02:52.502 - 00:04:05.542, Speaker B: You can see it because I give to my students also, then obviously try to look at the chat window, and if somebody wants to tell me, but now it's then your task. If somebody wants to know about something for me, then we can can interrupt it. So, a generalized hardness, a little bit of an overview, and then a little bit of a conclusion. This is the framework. Here I consider some universe of variables, and variables have a finite domain, so I go beyond the Boolean domain, that's clearly for many applications necessary, but I still stay to start standard constraint satisfaction problems with finite domains. So here in this talk, I do not venture at all in this infinite domains or other SMT related topics. Values are typically used epsilon in the domain of a variable, then say an assignment to all variables at the moment called a global assignment.
00:04:05.542 - 00:04:57.808, Speaker B: When I use it for defining semantics, often use it in f. It's just a map which for every variable assigns a value in its domain and the set of all global assignments, or the total assignments over the set of variables, and then send the product in the usual sense of the domains, just to mention. But if you have problems with formalism, don't worry too much about this. And then we typically start, what is the problem? We typically start with semantics. So at least in some sense, I believe that obviously the starting point I call p like problem s to emphasize it, is a semantical point of view. And this just means we have this kind of implicit understanding. Implicitly it is defined how to evaluate a total assignment to two and to false.
00:04:57.808 - 00:05:39.580, Speaker B: So you see, so I do not go into optimization here. Any other cases. So just true or false. Also QBf and extensions are not discovered covered here. Okay, so given now this semantic view, we want to represent it in some form to some form of satsuva, and also I believe so one has to, one should distinguish between these two different situations. B stands for a big unknown problem, like a big combinatorial problem, you just want to solve it. And now then you use all the tricks available.
00:05:39.580 - 00:06:42.690, Speaker B: So the semantics is well defined, but it is unknown, you don't know what the result is. Obviously, since it's really a big unknown problem, anything is allowed for the representation. We are not restricted to polita means in the whole thing in some sense will take a long time anyway. So we throw all of our resources, and here the representation typically only needs some form of such equivalence doesn't change satisfiability and unsatisfiability, but otherwise we are free. But then in this realm of encodings, it's often beyond this situation. C like constraint, where, where we actually, so the semantic is well understood, let's say a very easy example is at most one constraint, you have boolean variables, and now you want to say at most one of them is true. This shows up this perhaps one, I believe so from those non trivial constraints, the most used one.
00:06:42.690 - 00:07:20.550, Speaker B: So in principle there's no, the semantics is perfectly understood. So, and this is just a building block in a bigger problem, which for the moment I call PSP time. Something bigger here. Now we are very much more restricted, so the constructions should be in poly time and more difficult. And I go to don't go into any kind of theory about this. The semantics is to be maintained by the representation. And so some form of logical equivalence is needed, since you solving the at most one constraint on its own is, there's no point, of course it's trivial.
00:07:20.550 - 00:07:52.926, Speaker B: Or the pigeonhole formula. You know what the pigeonhole, what the truth value of the pigeonhole formula is, but it's just a building block, it's something else. So some form of logical equivalence is needed. And often, let's say if the constraint is by nature non boolean, then one would fix the encoding. Let's see. We will see later how that looks like. But typically a fixed encoding is typically used so that it can communicate with your other constraints in this talk, so implicitly.
00:07:52.926 - 00:09:02.558, Speaker B: So two problems which are so the sat solving are considered the sat solving, whether there exists total assignment at all, at all making the whole thing true, or. But in principle I think it's reasonably related to sharp sat solving. So determining exact, determining exactly the number of satisfying assignment. Now, when I say the representation is typically done, so perhaps I believe it should be done in following the two steps. So we start with that semantic view of that non boolean constraint or problem. Now I think one should first make explicit to do the encoding, where I use only encoding for the step of handling the variables from the non boolean variables to the boolean variables, and thereby also creating a boolean problem, a Boolean function in a sense, which I call just b of s. So it's basically the same problem.
00:09:02.558 - 00:09:46.442, Speaker B: So b like Boolean s still semantic. So I think so, because you can, it is not just the variables, but also the constraints which you stipulate on. The problem can vary, especially if you are solving a big problem, not a very, not a well defined constraint. This encoding typically should use the original variables, but encoded in some form. And once you have this Boolean function, then you can go to the CNF representation. So I only will consider a CNF Satson in here. Boolean CNF starts with that's the final end.
00:09:46.442 - 00:10:48.388, Speaker B: We start with something non CNF, non Boolean, and then we go to Boolean CNF. And first we handle the variables and also think about the semantic side. Now from the non boolean to the boolean semantics. And then we worry about the CNF representation, a good CNF representation, good in terms of speed, and this in general uses an auxiliary variables. They are very powerful, but little understood yet. So there are two slides where do some general remarks on it, which might be obscure to you, but I thought we are theoreticians and perhaps a few remarks here. This is now a remark which perhaps you don't like, it's about this general theory of, of these conditions and their compatibility.
00:10:48.388 - 00:11:52.476, Speaker B: So I believe. So the following would be a reasonable framework for, if you really want to do a heavy duty general framework, that these constraints you see, you have in this situation, C, you have different constraints, and then you have different non Boolean variables, which are translated in some form to Boolean variables, but then that they all communicate to this other in a compatible way. This can be formulized by commutative diagrams, would be a very natural thing that the, you can, you, you cannot pre solve these things, you see. So the utmost one constraint, there is no way that you can somehow solve it already, but it must be properly maintained so no essential information is lost. What does it mean? Could be translated by faithful functors and the theory of institution and category altogether would likely be a good framework if one needed to do this heavy technical work of very complicated, complicated conditions, which are. But we are not in this situation yet. So I just wanted to mention it.
00:11:52.476 - 00:12:35.816, Speaker B: So in my department. So there's a lot of formalization going on of complicated systems. And from that I would guess if one wanted to do this heavy work, then this direction would be a useful thing. But for now, we can just leave that aside. I hope you don't mind that I mentioned this. Okay, so now we come now to the second part after this very rough introduction, this generic translation scheme, this one, but here I start already. So that only works starting from a more concrete starting point, which is of course general, but nevertheless, we need what they're called a generalized CNF, or non boolean CNF.
00:12:35.816 - 00:13:14.678, Speaker B: So in these papers of mine. So I outlined this general theory, because quite a lot can be done with generate CNF, which are more general than boolean cnfs, but not as general as one could think of, so that they have still a lot of probabilities. So we have variables, have finite domains, the literals. Now the literals have this restricted meaning. They can only express that a variable is not equal a value. So in case the domain is zero one, then of course these are just your boolean literals in disguise. So I will just obviously denote it by v epsilon.
00:13:14.678 - 00:13:48.712, Speaker B: V epsilon is a literal. And because we are CNF, CNF is always negative, expresses negative information. The falsifying assignments are the easy assignments, while the satisfying assignments are the final target, but are the hard assignments technically. And so v, comma epsilon means v, not equal. Epsilon clauses are finite sets of literals, such pairs, finite set of pairs and clauses are finite sets of clauses always understood as a seen f. So we have a literal. A clause is a disjunction of such literal.
00:13:48.712 - 00:14:29.034, Speaker B: One variables not equal this value, another variable not equal another value, and so on, combined with or and the whole thing as usual in constraint satisfaction, a big end assignments. Let's just spell it out. So it's all trivial now, but let's spell it out. A partial assignment is any finite subset of a global assignment. It just means we're just assigning some values to some variables. A partial assignment falsifies a clause, see if all literals in it. The partial assignment is defined and sets it to its value, because the literal says we not equal epsilon.
00:14:29.034 - 00:15:27.204, Speaker B: And then we need to falsify all values in the clause. And phi satisfies the if there is some variable such that it's not equal, fees fortifies a clause, if it fortifies some clause, and it satisfies it if it satisfies every clause. So, partial assignments, as maps are just sets of pairs, arguments and their values, and they're exactly the same as the clauses. So mathematically, sets partial assignments are exactly identical with its clauses, but they play a different role. So one can think of this study of the generalized CNF as the logic of partial assignments, because our expressivity is somewhat restricted. You just say variable, not equal epsilon. But once we restrict our input to that, which of course makes it a general bigger, then.
00:15:27.204 - 00:16:16.230, Speaker B: But then we have quite a lot of good possible opportunities to do. Okay, here comes the second general remark, how one could consider a mathematical theory of the encodings. Perhaps, you know, perhaps you have seen the proof of compactness, logical compactness via topological compactness. It's just, see, the space of total assignments is just a topological space using the product topology. If you know topology, then you know how that's actually called a boolean space, such a space, what you call the counter space. But what does it mean? See, our boolean, our literals, what do they do for the falsifying assignments? They fix one value is fixed and everything else is arbitrary. V not equal.
00:16:16.230 - 00:16:45.922, Speaker B: Epsilon fixes one value, everything is arbitrary. This is exactly the so called sub basis of the topological space. And the clauses are then, see, you have now several of these things. In order to falsify clause, several of these literals must be true. So you fix exactly finite number of variables to their values, and everything else is arbitrary. That's the meaning of a clause. And this is exactly what the canonical basis elements are of this topology.
00:16:45.922 - 00:17:13.526, Speaker B: It was completely trivial. So even if you don't know what topology is, it's exactly clause sets semantically. And now these translation between variables can be understand. I don't know what you would quote it, but that we are in a theory seminar. I thought I mentioned it could be understand as continuous maps. But that was last. Such a remark here.
00:17:13.526 - 00:17:44.102, Speaker B: Now, very concrete. Now this is now the general translation scheme called the generic translation legend scheme. So we have now these non boolean variables and we want them typically finally to translate them into boolean variables. But it, but the scheme is completely arbitrary. You can, you don't need to have boolean variables at the end. Anything else? Basically, I replace literals by clauses, by disjunction. In a disjunction, we put in another disjunction.
00:17:44.102 - 00:18:15.848, Speaker B: That's completely harmless. Okay, so what we have, we want to translate this f. So, a generalized clause set, and for the variables, I typically write this v. So that's a set of variable v we consider. And now, so the basic idea. So for a variable v, we consider an unsatisfiable clause that might be have non boolean variables, might be all boolean variables. If you want to translate into boolean problem, then all of these variables in here need to be boolean.
00:18:15.848 - 00:19:12.504, Speaker B: But it's just an unsatisfiable clause that is joined for every variable and different variables get the typical variable disjoint clause sets. And now so every value, remember, so our literals are this v, not equal epsilon, written as this v comma epsilon. And now we assign to every literal, a clause in this set, you see? So v is an unsatisfactory clause that in one clause, for each value, a different clause is chosen, and it is must be a necessary clause. That means without the clause, that clause, it becomes satisfiable. Okay, and now we are ready to define how the translation looks like. First, we translate a single clause, and then we just take the literals in it, which are these pairs, v comma epsilon. And you see, the sphere of v epsilon is a clause.
00:19:12.504 - 00:19:49.696, Speaker B: We take the union of all of it. So in a sense, so we substitute these literals by these disjunctions, logically speaking. Now this in general will not cover all the clauses in that unsatisfiable clauset here. So every variable, I call it a set of clauses not used by any v comma epsilon. So these are those unused clauses. And then the translation of the whole clause that just translates every clause, literal, bilateral. Oops, sorry.
00:19:49.696 - 00:20:12.112, Speaker B: This is a disjunction, literal, bilateral. And then all, and then just adds all of those remaining clauses, which haven't been used. That's it. And now this is satisfied. Bt equivalent to f. How does it work? So if we, now let's two directions. If we have a satisfying assignment for f, let's call it f.
00:20:12.112 - 00:20:55.234, Speaker B: Small f is a satisfying assignment for capital f. And now we need to assign, now for every variable, we have those variables in phi of v. So these clauses, which altogether are used in replacing these literates. And now we choose exactly. So you see this v have originally on the left hand side, and this small f, exactly. One of these literates is false or the others are true. So we want to mimic that on the side of the clause set.
00:20:55.234 - 00:21:21.528, Speaker B: But now, because it's irredundant. Irredundant means there is an assignment which satisfies everything else except of this clause. That's what we use. This clause is unused. You see, this is a clause which corresponds to this f here to that choice. What which value is chooses here? This clause we. Okay, this is false.
00:21:21.528 - 00:21:41.144, Speaker B: We make it also false. Didn't need to make it false. If we could make it true, would be nicer, would be easier to satisfy the whole thing. But okay, so we can't do better. But everything else is true. And in the other direction, it's an even easier in the other direction. Now we have, we have this translation, the sphere of f satisfied.
00:21:41.144 - 00:22:38.058, Speaker B: And then for a variable in the original problem, we know this phi of that variable is false, is unsatisfiable. And so there is one clause falsified and from, and we choose here, such as the comma epsilon. And think about it. So it's completely easy. It is just a correspondence between this semantic structure and these literals. V naught, equal, epsilon, all are two except of one. And then these clauses on the other side in this unsatisfiable closet where the redundant ones can also be made that everything else other than the redundant clauses are two.
00:22:38.058 - 00:23:03.474, Speaker B: So that creates that correspondence here. Now just perhaps, hopefully you're not too confused. So let's go now to this example for polyden to become very clear. The diet encoding, the easiest one we have our. So these are our values. Epsilon one to epsilon M. These are our values and m values.
00:23:03.474 - 00:23:25.592, Speaker B: And then we'll not know what is now the unsatisfiable closet. By the way, we can treat every variable on its own. We are committed free. So we don't. We can say for one variable we do it like this, for another variable we do it like that, probability free. But this is the unsatisfiable clause set you see, v one over vm one or v two or vm is true. And then all the unit clauses.
00:23:25.592 - 00:23:57.838, Speaker B: And that is clearly unsatisfiable. It's also minimally unsatisfiable. And now what do we choose for each literal? V not equal epsilon, we use this vi complement. So you just use one as one of these m unit clauses. So that means we replace literals by single literals. And there, you see, after about five minutes. So as I expected, I will only come to cover.
00:23:57.838 - 00:24:26.382, Speaker B: So that part. But I thought it would be really useful because such a nice scheme. You haven't seen it likely. So tell you about it. Okay, so a single literal. So, because every variable here, every variable here corresponds to a value. And then here we have these, we have very little unused, let's see, at least one clause, at least one of these values is true.
00:24:26.382 - 00:25:08.784, Speaker B: And we could also add the binary clauses. We could add the binary clauses, is up to us whether we do this or not. The mechanism, of course, allows it and could also save some variable here. See? So here we are not using this one, but we could use one less variable here. And then assigning, say, the last value to that long clause here could be done. The direct encoding is typically most used because it's of quality, a great interoperability. So you can communicate kind of other constraints.
00:25:08.784 - 00:25:40.126, Speaker B: Now on the other end, you have something which is now very savvy, the logarithmic encoding, but it doesn't interact well. So we take now the case logarithm, we take logarithmic, many variable. Now what is the unsatisfiable closet? It's just this closet. Sorry. So this should know to do absolute value. So, exactly. So this sentence a little bit wrong here.
00:25:40.126 - 00:26:19.040, Speaker B: So, I mean, these k variables, we have these k variables, and you take all two to k clauses containing these k variables. So the most, in a sense, most trivial, unsatisfiable clause set. And then I denote this a of v, one to vk, or two to k clauses of length k, which makes it unsatisfiable. And then for every vcoma epsilon, I would take any of such clause. And then if the whole thing is not a power of two, then there will be unused clauses. So. Well, with the unused clauses, we could do resolutions on them and shorten them if you wish.
00:26:19.040 - 00:27:06.494, Speaker B: So. But I don't want to go into these details. So in this uses obviously much less variables, but we can, but we now substitute a block of k variables in it. And typically these variables are all over the place. So in all experience, so they are not understood by the satsuva, they don't seem to work well. And finally, the nested encoding, that's like here, see, it's like this one, but we make it a stronger, minimally unsatisfiable closet, namely, you see, so we just add in the second clause, we can add v one to it, because v one is already negated here. So can we for the second, for the third clause, we can add v one and v two to it, and so on.
00:27:06.494 - 00:28:07.102, Speaker B: So that corresponds to the scheme of splitting on a clause, where you can always negate the previous variables which have already assigned to, and this uses now one less variable, but it has exactly as many clauses as there are variables. And then we can choose any order here, neural clause are remaining the special property of the nested encoding that preserves the hitting property, so that if originally every two clauses have a clash, then this stays the same in the Boolean case. And you can actually prove nice combinatorial things. But experience is that, especially on satisfied instance. Actually this can show super performance, because it's more satisfiable than just the direct encoding. It's a kind of a variation on the direct encoding, which is in a sense more satisfiable. And so especially local search algorithms typically like the nested encoding more.
00:28:07.102 - 00:29:08.814, Speaker B: Okay, so let's just hopefully one or two minutes on this, on this very first slide here on this, on this hardness and measure as well. Perhaps you want to see the slides to read. So that's the kind of we measure the quality of in KC for constraints. How well can we represent, how well can we represent these constraints? And we start with a measure of hardness for unsatisfiability based on resolution complexity, either tree like or deck like resolution that we use the width, but in an improved asymmetric version, which also does not depend on the initial clause length. So that's really important for this practical applications here. In theory you can get away with it, but here at the point. And then we extend this hardness measure, which some form of resolution complexity, by considering the worst case over all applications of partial assignment.
00:29:08.814 - 00:30:08.078, Speaker B: This way extended to arbitrary. And we have now to this absolute versus relative. We have now to distinguish whether there are, whether we take into these hardness the auxiliary variables into account or not. If we don't take it, if we don't have auxiliary variables at all, then we get a great hierarchy, we can. So, adding a little bit to the hardness, even with full resolution, even with DAG like, we have only exponential size representations, while with the strongest tree like we get with one level more short representations. If we allow the auxiliary variables and have relative hardness, we don't take them into account for the hardness. Then all hierarchies collapse, not to level zero, but to level one, because the uncontrolled auxiliary variables, they can do poly time computations, and this can then simulate all kinds of resolutions.
00:30:08.078 - 00:31:06.674, Speaker B: But the main question is, do we get stricter case also this auxiliary variance when considering absolute hardness? And then we have just this. Now we're nearly finished. We have now this absolute lower bounds there on the Bessier et al. Proved that basically you have no good representations if you at all policies arc consistency, which means three like one relative hardness, they don't exist. And while you do using monotone circuit lower bounds, I later used in this to also prove that general x orchard system of constraint don't have in the same sense any good representation by using monotone span programs. If we had good representation of it, then one could translate these monotone span programs to monotone sockets. Then we apply these monotone circuits lower bound and this doesn't work.
00:31:06.674 - 00:31:44.118, Speaker B: But there are also positive cases like fixed parameter tractability. So my feeling is so pigeonhole problems are really hard for such if you have a lot of them, bad luck, you can't. So the satzel won't be good. Xor you have more. Okay, so here we are. So on the negative side, I would say so x or reasoning and kinetic constant reasoning cannot be represented in such a way to solve us provably so that exponential lower bounds for resolution can be overcome. So they will always exist.
00:31:44.118 - 00:32:29.864, Speaker B: Whatever you do with however, whatever clever representation we do, or whatever auxiliary variables you use, they will have inside then these hard resolution lower bounds. So such solving likely has to be extended. Of course there is this hope on extended resolution, but I think it will be only very special. But for this scope, for interesting special cases. And then this whole thing which I had in the second part, the transition from non boolean to boolean variables, to my understanding, there is this is always done ad hoc, completely ad hoc. You just do it in some form and then you're happy you have the Boolean stuff and then you reason. But this whole area from the non Boolean to the Boolean problem, I believe so there's quite something to be done.
00:32:29.864 - 00:32:33.300, Speaker B: A little bit overwhelmed, but I hope it's one too much. Thank you.
00:32:33.452 - 00:32:39.544, Speaker A: Thank you so much, Oliver. That was really interesting. Any questions? Comments?
00:32:42.244 - 00:33:42.344, Speaker C: Yeah, I have a question Slash comment. So if you compare, let's say, what happened with start solving with linear programming there is a huge emphasis on the in or on problem modeling. People understand that linear programming is a basic algorithm, but they build environment describing more general problems and ultimately reducing it to linear programming. And we, we have not reached that level yet that we maybe also said programming can be viewed as a little bit in the direction of the general problem solving environment. We are very much kind of in the engine and maybe the difficulty of doing good reduction is explanation. But I'm kind of why are we not moving to the next level in such solving?
00:33:45.164 - 00:34:13.422, Speaker B: Key intuitive thoughts on it. I definitely agree. So this kind of the theory of structures, what makes a problem hard or easy or. So this definitely needed, but. So let's say for example these hardness approaches, they have only a restricted reach. So I think you can do something with it. But, but five years ago I was more excited about, about it.
00:34:13.422 - 00:34:52.727, Speaker B: But finally really so you can do certain things with it, but not much. So just this, the NP completeness and beyond of the problem makes it just so hard to little tiny change in the problem and it's all different. So I think this non continuous way of how it works. So definitely so, so hopefully so in our workshop we can make some step forward. It is absolutely needed, but currently so we are quite weak with it. It is all based on intuition. At least I know it with myself.
00:34:52.727 - 00:35:01.683, Speaker B: I think I have quite a good intuition how to do my Cuba and conquer approach and all of these things and whatever. But it's hard to formalize.
00:35:04.223 - 00:35:15.894, Speaker A: Great, more questions. If you are an attendee, you could raise hand and or you could type in chat or Q and a.
00:35:18.754 - 00:35:21.654, Speaker C: You made it and all. Now they have to find some constraint.
00:35:26.994 - 00:35:38.744, Speaker A: Okay, so maybe let's, if you think of more questions, we could do it at the end of the session. So thank you one more time. Thank you so much Oliver for everybody.

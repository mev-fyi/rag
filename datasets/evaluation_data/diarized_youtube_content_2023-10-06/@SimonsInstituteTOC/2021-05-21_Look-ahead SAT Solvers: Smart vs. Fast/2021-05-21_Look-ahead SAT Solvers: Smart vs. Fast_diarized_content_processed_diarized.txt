00:00:00.360 - 00:00:53.314, Speaker A: So today we're going to talk about non CDCL solvers. This is the theme of the session today. So CDCL Solver has been another amazing accomplishment of the past 25 years. I call it the SAT revolution. But I've been on the record that as much as the CDCL have been successful, there is a bit of monoculture in the sad community and we need to look at other, other type of solvers. And that's what today three speakers will tell us about three different type of solvers. And the first talk is by Maran Julie, who is talking about such solvers, but non CDCL focusing on smart versus fast, or as some people call it, a Brennan versus the speed demon.
00:00:53.314 - 00:00:55.224, Speaker A: Go for it, Marin.
00:00:55.964 - 00:01:35.724, Speaker B: Thank you. I'm excited to talk with you about look ahead solvers. Lookahad was actually the topic of my PhD thesis, and it is something completely different than CDCL. Although it's not as powerful as CDCL on the industrial instances, it has quite some also applications and some interesting reasoning. And I gladly want to kind of go over some of these cool techniques with you. This talk will focus on four parts. First, I have a kind of a rather large introduction on satpat focusing on lookahad.
00:01:35.724 - 00:02:40.872, Speaker B: And I think the most cool thing I think of look ahead is actually the so called local learning aspect. And frequently when I see other papers now about lookahad, they kind of ignore this aspect. There's lots of cool local learning that one can do. And I kind of want to kind of go over a handful of these techniques. And at the end of this talk, I want to kind of show how look ahead can be used for very hard and challenging problems in combination with CDCL, which is known as cube and conquer. Moshe already mentioned this, and I guess most of the audience is very aware about this Sat revolution, the enormous breakthrough that we had in the last 20 years when solving sat. Until the mid nineties, we were only able to solve formulas with up to, say, thousands of variables and thousands of clauses.
00:02:40.872 - 00:03:25.134, Speaker B: And today we can solve many problems arising from industry with millions of variables and millions of clauses. If you kind of look back to the early SOT research, say the first 40 years of SOT research. So from the late fifties till the late nineties, it was all based on DPL. And let me kind of. Because this is actually also one thing that Moshe taught me. If you want to built an algorithm, you have to kind of decide whether you want to focus on being smart or being fast. And typically you cannot do both because the data structures don't allow you, if you want to do something very smart, you need very detailed data structures, and it prevents you from being fast.
00:03:25.134 - 00:04:29.040, Speaker B: Once it comes to satisfiability, you also actually have a second choice. You also have to decide whether you want to focus on finding a solution or trying to prove whether no solution exists. And if you kind of summarize to say, the first 40 years, so the late fifties to the late nineties in sot solving, then almost all approaches were focused trying to be smart and trying to find a solution. And I think the main breakthrough actually came when the people decided, okay, let's try to be fast and try to find, to refute the formula. And actually a satisfying assignment is just a counterexample that no such refutation exists. But there actually has been a lot of cool work in those 40 years and also later that are really worth exploring and also have their own applications. And so this is most of the group to actually look ahead.
00:04:29.040 - 00:05:28.444, Speaker B: And I will talk about this now. So first, very short, what is lookahead? Lookahead. What it tries to do is it tries to make a binary search tree of the search space, and it tries to make the tree as small as possible. How does this work? In each node of the search tree, you pick a variable and then you split it into two nodes, one where the variable is assigned to true and the other one where it's assigned to false. Picking the right variable for the split is very important and can reduce the search stream, sometimes by orders of magnitude. This approach with the right heuristics is very effective on a broad range of problems, although all of them tend to be relatively small, say up to thousands of variables and thousands of clauses. Its main weakness, because the heuristics are very effective.
00:05:28.444 - 00:06:16.994, Speaker B: However, they are also expensive, and if you deal with variables over formulas, with, say, a million variables, this is completely impossible because these things are just too expensive. CDCl, most of you probably know at least the basics of it. It is not trying to be smart as look ahead, picking the right decision all the time, but it tries to be fast. And so what it does, it does very cheap heuristics to pick a variable and then assigns it. Simplify. Again, a simple decision and only the reasoning starts to really kick in once you hit the conflict. This conflict is turned into a clause which is added to your database and we continue.
00:06:16.994 - 00:07:04.436, Speaker B: This has been very effective on large problems, which I call easy, because sometimes the runtime of the CDCL solver is linear, even in case for unsatisfiable ones. This is only possible if these problems are easy. So there are short proofs for these formulas and CDCL really knows how to quickly find them. One of the main weaknesses of CDCL is that it's very hard to paralyze. But I will actually, at the end of this talk, talk about how we can combine lookahead and CDCL for some effective parallelism. Something I briefly want to touch is local search. Local search is another solving paradigm which is quite effective on a range of problems.
00:07:04.436 - 00:08:16.754, Speaker B: It starts with a full assignment, and then it starts flipping the true values of some variables until satisfying assignments is found. Some problems that take years with both CDCL or lookahead or their combination can be solved sometimes in seconds with local search. Local search has the same as property as CDCL. All the data structures are really focused on trying to do things fast. So although most of the people that heard about SATA are aware of these extremely important progress on industrial instances, but also in the last couple of years, there have been a lot of progress in solving long standing open MAF problems using a combination of lookahead and CDCL. And without this combination, it would be impossible to solve these problems efficiently. Now let's go a little bit more into detail how Lookahad works.
00:08:16.754 - 00:09:27.204, Speaker B: So Lookahad is based on it builds a DPL tree which dates back to the early sixties, and I already mentioned it. It builds a binary search tree, and in each node of the search of the tree you pick a variable which ideally splits the space into two much easier subtrops. And at each step of the recursion you first simplify the formula. With unit propagation you can also do some additional stuff, and then you do a split and this you repeat. There are two important heuristics here. The first one is which variable do we pick at each node in the tree? And the second one is which of the two branches are we going to explore first? If the formula is satisfiable and you pick the right one, you will just straight walk to a solution. So it can be very beneficial to spend some time to figure out which branch might be the more satisfiable.
00:09:27.204 - 00:10:35.964, Speaker B: And although I won't talk about it in this talk because it's only 30 minutes, but you can do all some interesting ways to jump through the search space or through the tree to find a solution fast using lookerhead techniques. A very simple example. So on the slide there is a formula with five clauses. If you would pick in this example x three as your first decision, then you have a small three with only two leaf nodes. However, if you, for example, pick variable x two, then the number of leaf nodes doubles and so on this small example, you see that just picking the wrong variable doubles the size. In practice, for hard problems, picking the wrong variables can actually result in trees that are orders of magnitude larger compared to picking the right ones. So it's very important to pick the right variables for the split.
00:10:35.964 - 00:11:18.614, Speaker B: I already used the word look ahead now several times, and most of you probably don't know exactly what it is. So let me be very brief on to give first a high level thing here. The look ahead sot solver is a DPL solver where lookaheads are used to pick the decision variable. And what is a look ahead? A lookahead is you pick a variable, assign it to a true value, and then simplify it as much as possible. This is typically only done by unit propagation. And then you do two important things. The first thing is you measure the reduction.
00:11:18.614 - 00:11:55.552, Speaker B: And there are many ways to measure the reduction. For example, you can measure the reduction of the size of the formula. You can the reduction in the number of variables. I will briefly talk about this more on some later slides. And then what you can also do, and what I figured out in the last decade is that possibly the most important thing, what you can need to do afterwards, is to learn as much as possible. And the learning that is here is completely different than CDCL. And this is what I call local learning.
00:11:55.552 - 00:12:36.608, Speaker B: And most of the middle part of this talk will be on local learning techniques. Once you've finished the local learning, then you backtrack and you do a look ahead for another variable. So this is the high level steps of lookaheads. Now let's look at an example. So on the bottom of the slide you see a formula f learning. And I will use this formula throughout the remainder of this talk. And how does a look ahead work? So we start by picking a variable on a truth assignment, for example, x two and false.
00:12:36.608 - 00:13:16.776, Speaker B: And so we assign x two to false. And what you see now here is that this clause becomes units. All the literals except for one are falsified, and so you are forced to make x one false. This in turn makes this a unit clause, and therefore forces x six to be false as well. And now this clause becomes unit, forcing x three to be true. Afterwards, there's no simplification it's possible anymore. And so that part of the look ahead is over.
00:13:16.776 - 00:14:03.434, Speaker B: But now we need to do the next step, which is measure the reduction. So on the next slide, I will show you this and then we will talk a lot about learn if possible. Now, so this is exactly the same formula and the assignment of the look ahead on the prior slide. And now the question is how are we going to do the measurements? So one way is, for example, is to count the number of satisfied clauses. In this case we have eight clauses and seven of them are satisfied. So there's a lot of reduction if you use that metric. You can also look at the number of implied variables.
00:14:03.434 - 00:14:41.014, Speaker B: In this case, this is three of them. The number of satisfied clauses tends to be a very bad metric. The number of implied variables is quite a bit better. But the best method typically in practice is to count and actually weigh the number of new clauses. And new are the clauses that are reduced but not satisfied. In this example, this is only the clause x four, x five or x six. This one has been reduced from a ternary clause to a binary clause.
00:14:41.014 - 00:15:45.636, Speaker B: And what you do in lookahead typically is you count the number of reduced clauses and then make the shorter clauses more important. And actually you also put a lot of weights in there and the weights you can maybe view as what is the probability that the random assignments would satisfy the reduced clauses. And this heuristic is now used in most of the state of the art solvers. Do some weighing of the reduced clauses. So now we have all aspects of the look hat architecture, which is on the top. We built our DPL tree. And in each node, before kind of deciding which is the decision variable, we look at the simplified formula and then we do look ahead on all the variables or subset of the variables.
00:15:45.636 - 00:16:39.764, Speaker B: And a look ahead is we assign it to a true value, simplify the formula and do some measurements. So for example, the numbers over here show, for example, the reduced not satisfied clauses. And these are the heuristic values. And then we need to combine them because you pick a variable and not a literal, and the best practice is actually to just multiply these numbers and the highest multiplication is the one that you pick. But notice here is that if you do a look ahead, sometimes the look ahead can result in a conflict. So if we assign x three to false, it can result in a conflict, which means that all satisfying assignments must have x free to true. And this is actually the kind of easiest way of local learning.
00:16:39.764 - 00:17:33.364, Speaker B: And local learning is very important to pick the right decision. And so, although we can compute these values in the first kind of iteration over all the variables, it is very important to first do a lot of local learning, which improves the accuracy of the heuristic which in turn makes a tree much smaller. Okay, now let me focus on the local learning. So we all, so what CDCL is doing is it hits a conflict and adds a clause to the formula. And this clause is logically implied by the formula. Lookahead is not doing any of this kind of global learning. The clauses that are added are only valid for that node of the search and OLED.
00:17:33.364 - 00:18:36.484, Speaker B: And so what we're going to do is we're only going to learn clauses, typically units, and binary clauses that are valid for that node and everything below it. And because they're only valid at this point in the search, it means that as soon as we backtrack, we have to remove them all. And this also makes the data structures much more complicated because you need to do a lot of accounting which clauses are valid where. Let me first talk about the easiest part, and we already talked about it, which is the filled literals. So we do a look ahead on L was true. If it results in a conflict, then we know that L has to be false in all satisfying assignments. If both the look ahead on L and the look ahead on not L are filled literals, then we actually found a dead end situation, and that node is, and we need to backtrack.
00:18:36.484 - 00:19:35.940, Speaker B: This notion of field literal can also be generalized to this so called double look ahead. And double look ahead is we actually pick two variables and two true values, and then do unit propagation and see whether they result in a conflict. For example, our learning formula, we assign x four to false, x six to true, and then by unit propagation, x one has to be true, x two has to be true, x three has to be true. And then we have our falsified clause. And this means that we can learn the clause x four or not x six. This double look ahead is very, can be extremely effective on some problems. But notice that this is very expensive, right? Because we need to pick two variables.
00:19:35.940 - 00:20:27.940, Speaker B: So the complexity of doing it for all possible assignments for two ones is cubic, because also the unit propagation can be linear in the number of variables. So it can be very expensive. But for some problems it is very effective, but for others, it's extremely costly. So, Jakob, let me do the, what is the question? It's obvious why we cannot learn properly a globally valid clause. Yeah. So Jakob mentioned that of course, the locally learned clauses, we could add them as globally ones by putting the prefix in there. But at least in practice.
00:20:27.940 - 00:21:39.924, Speaker B: So Oliver implemented this in his solver, the okay solver. But in practice, this is not very effective. So the clause is typically because you pick the right decisions, that they are no longer valid elsewhere. Now let's talk about another local learning technique which is called hyperbinary resolution. We have a variable x prime that occurs in many binary clauses, and it occurs there with the literals not x one to not x n. And we also have a long clause x or x one to xn. If you're going to look what happens with unit propagation, that if we make x prime false, then the unit clauses all propagate x one to false, x two to false, xn to false, and afterwards the long clause becomes unit because all the literals x one to xn become false, which forces x to be true.
00:21:39.924 - 00:23:30.434, Speaker B: So if we have this situation, then we observe that not x prime implies x, and this happens by unit propagation. But the interesting thing to notice here is that if we make x false, then just the long clause would reduce to a clause just one shorter, and there's no unit propagation. And so what hyperbaric resolution does is it picks all these binary clauses and the long clause and by resolution merges it into a single step into a binary clause x or x prime. And after adding this binary clause, we have x not x implies x prime, and we're actually going to find these hyperbinar resolvents using unit propagation. So we do unit propagation. So we start with x two, and then we have the unit x one comes from this binary clause, x six comes from this binary clause, and x three comes from that binary clause. And for all of the ones that are not implied by an x two binary clause, we can add a hyperbinary resolvent, this one or this one, and the latter one is the most effective one because this one is due to a binary clause, but this one is due to a ternary clause and would improve the unit propagation during future look aheads.
00:23:30.434 - 00:24:23.814, Speaker B: Now another technique is called necessary assignments. So we do a look ahead on x is true, x one is true, which would imply x two, x three and x four to true. And now we do another look ahead with x one to false, which would imply by unit propagation, x six is false and x three is true. Notice that in both cases x three is forced to true. So either we assign x one to true, or if we assign x one to false, we both have x three is true. So therefore x three has to be true in all assignments satisfying assignments. In case we do hyperbinary resolvements, we also would find that x three to false would be filled literal.
00:24:23.814 - 00:25:04.678, Speaker B: But if we don't do this, actually we wouldn't find this. But doing necessary assignments is actually a way to find this much more quickly. Another technique is alter keys and alter keys. This is a bit more exotic. An altar key is an assignment that satisfies all the clauses that are taxed by it. Example is the pure literal, which there's no complement of it. So if you assign the periodical to true, then only clauses get satisfied.
00:25:04.678 - 00:25:31.834, Speaker B: Also, satisfying assignment is an altar key because all the clauses are satisfied. So clearly. Also all the clauses that are charged are satisfied. Interesting. Altar keys are the ones actually in between pure literals and satisfying assignments. And the nice thing that you can do is if you find an altar key, all the clauses that are touched by the altar key you can take out. And the resulting formula is satisfiability equivalent to the original one.
00:25:31.834 - 00:26:22.344, Speaker B: Then there's also this notion of the one alter key, and a one alter key is all clauses except for one are satisfied. So there's one clause that is reduced but not satisfied. All the other ones are satisfied. Now we do, for example, a look ahead on x one, which results in the assignment that x two, x three, x four are also assigned to true. Notice that all the clauses that are touched by the assignment have satisfied literals, a green literal. And therefore the formula is satisfiability equivalent to x five or not x six. And this technique can also help to reduce the computational cost on unsatisfiable instances.
00:26:22.344 - 00:27:26.846, Speaker B: A little small side note here is that lookaheads can quickly solve two sub formulas by simply doing only lookaheads. You never have to branch either a lookahead results in an alter key, or. And then you can force the literal to be true, or look ahead results in a field literal, and you can assign it to false. And yes, let me, because I'm kind of a bit short on time. So let me first finish the talk, and then we can talk about a bit more about the, the aspects here that we go beyond resolution. Another cool thing here, and this is actually much more effective than alter keys because alter keys are kind of rare. The one alter key learning so now we assign x true to true to false.
00:27:26.846 - 00:28:19.128, Speaker B: Sorry. This implies x one to false, x six to false, and x free to true. Now we have a one autochey. Notice that this clause is the only clause that has been reduced but not satisfied. Now the question is, how can we do any learning here? Because if we had an auto key, we could just take all the clauses out. But what can we do here? The observation here is that if x four would have been true, then the assignment x two false would have been an alter key, right? Because x is four would have taken this clause out. And therefore, if you would assign x two to false, this would have been an alter key.
00:28:19.128 - 00:28:52.964, Speaker B: And the same holds for x five. If x five would have been true, then x two to false would have been an alter key. And as a consequence, you can learn the binary clauses, the one autarky clauses, not x two, or not x four, or not x two or not x five. So x four implies not x two and x five implies not x two. And the one alter case actually happen very frequently. So while the altercies hardly happen, one altar keys frequently happen. And you can do this locally.
00:28:52.964 - 00:29:55.616, Speaker B: So this rounds up the local learning aspect of this talk. So it is very important to look at hat solvers, because the local learning really also improves the accuracy of the heuristics and thereby making the tree smaller. And some of these techniques are also used in, in CDCL solvers for preprocessing and in processing. Now let me briefly remark some remarks about kubernetes. So, although lookahead is not effective on large formulas because things are expensive, you can actually use lookahead in combination with CDCl to solve very hard formulas. This is what we call cube and conquer. And what does Kubernetes conquer do? It builds the DPL tree to some level.
00:29:55.616 - 00:31:05.030, Speaker B: And then for all the leaf nodes in the DPL tree, at some cutoff level, we are going to call a CDCl solver. And so we have, we split our formula f into n different subformulas, the leaf nodes at some cut in the DPL tree, and then we solve them effectively using CDCl and for several problems. So I've been showing this on some mathematical problems, but also some industrial problems. We can have linear time speed ups even with thousands of cores. And for example, this technique has also been recently integrated in the SMT solver z three. I won't have time to go into detail here, but let me briefly explain what I think is going on, because Kubernetes, we frequently witnessed super linear time speed ups. How is this possible? How? I see lookahead.
00:31:05.030 - 00:32:06.566, Speaker B: Lookahead is really good in able. If so, if there global argument why the formula is unsatisfiable, then you need to make a good global split. At some point, after doing enough splits, the formula there becomes some local argument why the formulas are unsatisfied. In case there's a local argument why the formulas are unsatisfiable, you shouldn't do a global split, because then the argument will be there in both of the branches. And so once you need to do in order to get Kubernetes conqueror effective is you split until a short refutation exists, or at least heuristically, you expect it to be there. And then you call the CDCL solver, and the CDCL solver will find you the local conflicts quickly. And so the plot shows kind of, that you get this speed up more and more when increases.
00:32:06.566 - 00:32:57.854, Speaker B: But at some point for this problem, the splitting cost becomes so expensive that the splitting is more expensive than the total CDCL cost. Now, to conclude. So I presented some aspects of the look ahead architecture. Look ahead tries to be smart instead of trying to be fast. And it tries to be smart both by picking the right variable. And an aspect that I really didn't talk about much is it tries to be smart by picking the right branch. This is very effective on small and hard formulas and also can be used very effectively for some hard problems in combination with CDCL.
00:32:57.854 - 00:33:28.934, Speaker B: So it's important that we have these effective splits. And a very important aspect of this is the local learning, which I discussed. Something I didn't have time to discuss is that you really need to kind of massage your data structures in order to do this all efficiently. But this is one of the key things to make lookahead effective in practice. Okay, that concludes my talk. I see lots of questions. Morshe, how are we going to do this?
00:33:31.954 - 00:33:36.614, Speaker A: I'll pick the last one. Karem, what would you like to say or comment or ask?
00:33:42.074 - 00:34:10.654, Speaker C: Sure. My question was, it looks like, I mean, look ahead was done in earlier solvers. I forget the name of the solver, but this guy from Sweden. So there is BFS and there is DF's cuban conquer does bfs followed by depth first search, which is CDC Health. Can you view this as just one point on the spectrum of how to combine depth first versus breadth first and learning in these most different styles?
00:34:16.114 - 00:34:21.260, Speaker B: What do you mean with just one aspect or because there's many other ways of doing this, you mean?
00:34:21.292 - 00:34:43.984, Speaker C: Yeah, yeah. I'm saying instead of just doing like in cuban conquer, you do look ahead and then CDCL. What if you do a little bit of look ahead, do a little bit of CDCL and then stop CDCL and do more look ahead and then do CDC, do CDC and so on for. So you. You interleave breadth first and depth first, depending on what you're learning and what's happening in the search space.
00:34:44.684 - 00:34:46.796, Speaker B: Yeah. So we have a paper.
00:34:46.900 - 00:35:11.283, Speaker A: Let me, Marian, let me maybe augment the question. Suppose that we look at this, the cuban conquer and look ahead. It's just another kind of set of, we have arsenal of heuristics and we decide dynamically to use them as appropriate rather than make a decision up front. Are we are going to use CDCL or we are going to do look ahead?
00:35:12.543 - 00:36:29.700, Speaker B: Yeah, so actually I had a paper, I think quite some years ago with a student in Delft, which we called concurrent Kubernetes, where we had a CDCL solver always running in parallel with the look ahead. So in every node we let the CDCL solver run on the same problem, and the look ahead solver tries to figure out the best split and the first one that actually finishes kind of returns. And that was reasonably effective, although it didn't give a major improvement. And also Armin has an implementation in tringerling where also this combination is trying to do it as effective as possible in practice. And tringling has been quite effective in several of the SAT competitions. So tringling splits the search space using look ahead, but then runs the subproblems using CDCL. If they cannot be solved within a certain time limit, all of them are split again.
00:36:29.700 - 00:36:38.760, Speaker B: And this is repeated. So this is actually what you kind of suggested is what happens in the sulfur tringling, right? Army.
00:36:38.912 - 00:37:20.760, Speaker C: So it's been done. I mean, I'm just curious. I'm intrigued by the fact that, you know, you can learn in a local context something that might be extremely helpful in, you know, you know, either proving unsat or finding a sat. And the indications of what is happening in that part of the search space could actually inform whether you want to do further look ahead or further, you know, CDCL. Again, you know, what you said at the beginning, which is smart, not fast. You know, forget about, you know, being fast now, but, you know, that seems to be unexplored yet, you know, exactly where you want to do this switch from one way of doing things to the other way.
00:37:20.912 - 00:37:50.344, Speaker B: Yeah, but to some extent, you can also see the, in processing also as a bit of this. Right, in processing, dust field, literal detection and other, other things that you might do in a look ahead solver. And so you might kind of incorporate lots of these look ahead techniques actually in an in processing phase of the CDCL solver. So you don't do any of the splitting, but you only take the local learning part, which in my experience is one of the most effective things also of look ahead techniques.
00:37:51.004 - 00:37:52.824, Speaker A: Oliver would like to make a comment.
00:37:54.644 - 00:39:11.104, Speaker D: So on this question of making it dynamic, so I think that's extremely important and I believe it's that in the lookerhead solvers currently should have a better chance of getting a good theoretical handle on it because it's inherently simpler. You have all these processes related to tree growth and the solver measures anyway, a lot of data which is underutilized yet all of that look ahead and so on. There's a lot of data which I believe and I'm working on that we could make much more progress with that and then definitely so this interleaving of these different techniques. So kind of the look ahead perhaps more at the planning, as Marine perhaps said, the look ahead has more, the planning oversight is less good possibly with solving the problem, but it has a better statistical overview and this kind of combination, as per said, in the future, I believe there's a good chance because the look ahead heuristics we understand somewhat better, I think quite a bit better than the CDCL heuristics.

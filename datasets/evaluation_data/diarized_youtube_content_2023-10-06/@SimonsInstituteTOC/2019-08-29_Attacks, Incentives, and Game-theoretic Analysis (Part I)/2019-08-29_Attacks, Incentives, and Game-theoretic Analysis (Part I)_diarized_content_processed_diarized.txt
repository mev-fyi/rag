00:00:01.320 - 00:00:26.228, Speaker A: Should we start? So just an announcement. You probably saw in the program Agilos could not make it. So his talk. So this talk is not about proof of stake. As you see. This is the talk that was supposed to be this afternoon and I'm going to give it this morning. Then Georg is going to talk about cryptocurrencies in the afternoon and agilos is.
00:00:26.228 - 00:00:47.240, Speaker A: Is going to be simulated tomorrow morning by me. Again, that would be proof of work. Yeah. I have some auxiliary input, but given the time I got the slides I'm bounded in the running time. So we have four talks, we have.
00:00:47.272 - 00:00:51.644, Speaker B: Four tolerance for one byzantine talk. Which one of the talks will be byzantine?
00:00:52.464 - 00:01:52.414, Speaker A: There's going to be byzantine aspects in this talk? Yeah, actually in every talk is going to present in aspects. I'm going to try to be as honest as possible. So the general theme of the talk is rational analysis of consensus distributed computation in general. And if you read the papers, and I really mean the paper, not just, you know, the research papers, the papers, you just say bunch of terms, attacks, things that are like selfish mining, block withholding. Then you read like provable security, we can prove this bitcoin is secure. You read the claims like we can have a blockchain that gets 99% resiliency. Many of these things have a rational aspect and in general it's pretty hard to put a structure in this landscape.
00:01:52.414 - 00:02:20.274, Speaker A: It's kind of a jungle. There's good news. All this stuff boils down to two statements. It's rational to buy and or mine cryptocurrency, and it's not rational to buy and or mine cryptocurrency. So everything here is one of the two statements. This is the good news. The bad news is that when you have two contradictory statements, it's really hard to make sense out of it.
00:02:20.274 - 00:03:24.574, Speaker A: So what I will assume from the fact that you're currently here is that for this audience it's rational. To understand what's rational and with this motivation in mind, I'm not going to just throw attacks and different types of analysis of those attacks in this talk, but I'm going to split my talk in two parts. In the first part, roughly the first hour, I'm going to discuss attempts that have been done in the literature to combine cryptography and game theory and address rational aspect of protocols in either discipline. And in the second part I'm going to focus more on incentives in the concrete setting of consensus and blockchains. Let's start with the first part. In trying to find parallels, my first to go place was Wikipedia, the temple of knowledge. If you see the definition of games theory, it says that it's the study of mathematical models also taking the direction in between rational decision makers.
00:03:24.574 - 00:04:27.768, Speaker A: This is the definition of cryptography. It comes from the ancient Greeks Kramer and dangard, as we heard here, and I'm not, you know, the etymology of the word is nice to know, but not relevant here. So it's the practice and study of techniques for secure communication in the presence of third parties called adversaries. There doesn't seem to be much in common with this. If you look closer, you will identify two sub disciplines of those two disciplines, namely mechanics design, being a sub discipline of game theory and a secure multiparty computation. What is mechanism design again? Wikipedia definition it is a field in economics and game theory that takes an engineering approach to gain the engineering approach to designing economic mechanisms or incentives towards desired objective strategic settings where placed rationally. What is secure multi party computation? It's a subfield of cryptography with the goal of creating methods for, wherever you say, italics.
00:04:27.768 - 00:05:13.824, Speaker A: That's my salt to the Wikipedia definition for mutually distrustful parties to jointly compute a function over their inputs while keeping those inputs private. And I would add, while ensuring that deviating parties cannot disrupt the computation so the output will be correct. So under this general definition of secure multiparty computation, you can capture also secure or fault or undistributed computation. Consensus can be thought of as a sub problem of multiparty computation. I know some people might disagree, but this is the case. If we take this definition of MPC, we can think of MPC without privacy, and this is effectively fault tolerance computation. All right, now if we look closely at those two definitions, we can start drawing parallels.
00:05:13.824 - 00:05:45.784, Speaker A: First of all, the goal of mechanism design is to design economic mechanisms for something, right? And secure multi party computation creates methods for something. For what? Mechanism design wants to create a mechanism or a method towards a desired objective. In secure multiparty computation, this desired objective is slightly more concrete. Compute a function, not too concrete. Compute an arbitrary function of their inputs while preserving privacy and correctness.
00:05:46.124 - 00:06:15.802, Speaker C: Why you cannot just view it simply as the multiparty computation or the cryptography is like online. It's like an adversary that you don't know how it behaves and you want to counteract any behavior. While the mechanism design, you assume that you know how the other party behaves, you have a mathematical model of their behavior, and now you want to do so. It's about the adversary. Do you know the mechanism operates or not?
00:06:15.858 - 00:06:45.594, Speaker A: I can see it like that. But the adversary is something that we as cryptographers understand very, very well, but it's a very counterintuitive notion for explaining security, right? Like if you don't know what an adversary is supposed to do. I've talked to people where I tell them that the adversary is supposed to capture a corruption of parties and they really think that he's capturing the party. So it's not. So an adversary is something that we cryptographers think of for stating our results. But you're actually. Right.
00:06:45.594 - 00:07:31.498, Speaker A: So the main parallel here. So they're both trying to create methods to some goal. Here the goal is slightly more specified, and here it's left a little bit more vague. But their main difference is that there was assumption in mechanical design is that players act rationally, whereas in secure multiparty communication, players don't trust each other. All right, so I want to discuss how attempts that the community has made to bridge those two differences. And then in the end, I'm going to also highlight the issues in bridge those differences, the different disciplines. Right? So let me first start with some very, very, very basic background on both.
00:07:31.498 - 00:08:18.134, Speaker A: So I'm gonna have like three or four slides that are gonna bore everyone that's doing game theory, and then a couple of slides are gonna bore everyone doing cryptography. And then I'm gonna tell you when to, you know, wake up again. All right, so one of the basic notions in game theory is what is known as strategic game. This considers a number of parties, let's say m parties, and every party can play an action. There's an action space that defines what the parties can do. And the strategy of a party in this simple strategy games is one action from the action space, and then the profile or the combination of the party strategies yields some utility. And here I take the very simple approach that the utility is just a real number.
00:08:18.134 - 00:09:03.463, Speaker A: That's just for simplifying. So that's without loss of generality? Well, it is without loss of generality, but I mean, the most common definition, game theory would just consider utilities as orderings among different profiles. That's what I mean. Yes, it is with general. So the classic example of such a game, which you all might have heard is the so called prisoners dilemma, where the idea is we have two prisoners that are put in separate interrogation rooms and they have the option to confess for a crime or remain silent. Confess. You can think of it as blame the other one.
00:09:03.463 - 00:09:43.106, Speaker A: And the idea is that if they both confess, then they both get five years in prison. If they both remain silent, then you cannot pin the crime to them. So none of them get a little bit of prison, but way less than if they both confess. And if one confesses and the other doesn't, then the one that confesses is free. He gets a deal, he gave up the other guy, and the other guy gets a long time in prison. So it's. How can we analyze such games? The very, very, very high level goal of game theory is to use the utility.
00:09:43.106 - 00:10:34.426, Speaker A: So, obviously, like, you know, less years in prison are preferable to more years in prison for most people. So we use kind of this preference to make a prediction about how the parties will behave in such a situation. And this prediction is usually captured by some solution concept, which says that parties in general would like to be in a stable solution. What does it mean to be in a stable solution? A classic example is NASA equilibrium, which says that no party has an incentive to unilaterally deviate. So if everyone sticks to his equilibrium strategy and I try to deviate, I don't win. By doing that, I don't increase my utility. All right, so finding Satsna's equilibrium is.
00:10:34.426 - 00:11:23.094, Speaker A: Satzana's equilibrium is very easy. We just look at the game, and we analyze it with how the part is play. So we can first look at the yellow prisoner and assume that he confesses. Now we try to figure out what's the best strategy that the blue prisoner can have. In this case, of course, it's also to confess, right? Because if he doesn't, he's going to get 20 years in prison. We can look then what happens if the yellow prisoner doesn't confess? Once again, the best response, the best value in this case of the blue prisoner is to confess. And then we can look at the possible actions of the blue prisoner.
00:11:23.094 - 00:11:53.346, Speaker A: What happens if he confesses? The best thing that the yellow prisoner can do is also confessed, because otherwise it gets 20 years versus five. If the blueprint remains silent, then the best response is to confess again. So if you look the overall game, you see that the single point in which it's. When you go there, no one has an incentive to unilaterally leave is confess. Confess. There's something interesting happening here, which is that, intuitively, you would expect that this. Remain silent.
00:11:53.346 - 00:12:38.272, Speaker A: Remain silent is a potentially better solution. This is a fallacy of the NAS equilibrium, which has been discussed extensively in economics, and I'm not the expert to discuss it, but if you talk to the experts, I'm sure they will explain you what the issues are. So this intuition that this could be a better solution comes from the fact that you're thinking of just everyone getting one year in prison as a better social function, in a sense. So this was a very simple game. Another classic game is the so called matching pennies. Here you can think of everyone choosing a side of a coin, like heads or tails, and if so, everyone like two parties. So if the two parties agree, then p one wins.
00:12:38.272 - 00:13:10.034, Speaker A: If they disagree, then p two wins. If you look at this game and try to analyze it the same way we did before, I'm not going to do it here in interest of time. But you can see that there is no pure nash. There's no single strategy that parties both want to play, and they are not willing to unilaterally deviate. But there is what is called a mixed nash. What is a mixed NAS is the part is rather than just playing one single strategy, they play a distribution, probability distribution, over different strategies. And here the good mix nas is to randomize 50 50.
00:13:10.034 - 00:13:55.338, Speaker A: The reason is you can observe that if this happens, if p one randomizes 50 50, then p two doesn't care whether he plays heads or tails. You get the same expected utility, and therefore p two denotes a randomized p one doesn't care, and this is a stable solution. I'm going a bit fast here. I'm assuming many of you have heard that, but if not, it's good to know another type of games, which is very interesting when we try to discuss combinations of cryptography and game theory is what is known as biases and games. So in the games that we discussed so far, everything was known, right? Everyone knew exactly the utility. All parties knew exactly the utility of other parties. In BSN games, what we have is in addition to the action space, we also have types.
00:13:55.338 - 00:14:47.940, Speaker A: So each party has a type. The easiest way to think of it is if you think of the prisoner's dilemma, for example, the type could be, I'm altruistic, I really want the world to catch the bad guy, or I'm selfish. And this, of course, has different utilities. And now the utility function is defined not only on the vector of strategies, on the profile of strategies, but also on the profile of types, because every type is changing the way a party might behave. Now, what's interesting in these bias and games, and the reason that I bring them up here, is that the assumption is that parties might have partial information on the types. So it might be that they don't know at all what the other one party doesn't know at all what the other, what the type of the other party is, or he knows with some probability and so on. And that might ring a bell to every cryptographer.
00:14:47.940 - 00:15:40.344, Speaker A: It's similar to the inputs. So when we discuss inputs to a protocol, we assume that whoever is trying to do something bad to the protocol or trying to decide whether to deviate and how, like the adversary has either no or some partial information about the distribution from which the inputs come. So that's about game theory. Now just a single slide about mechanical design. This is like a very big subdiscipline, and maybe someone who is in the area would be interested in giving a talk just about mechanical design here in this program. And the basic mechanism, I'm not going to do that. What I'm going to say is, what is the main difference? The main difference is that game theory, what is the scope? It's like, here's a game, analyze it, predict what's going to happen in mechanism design.
00:15:40.344 - 00:16:35.466, Speaker A: I don't give you the game, but I'm telling you, I would like to achieve this goal. Give me a game that achieves it. So design a game design a mechanism that achieves it. And to be a little bit more concrete, because that's way too abstract you can think of, I want to auction an item, and I want to auction it in such a way that the auctioneer gets the best price he could given the set of bidders, and that the goods go to the bidder that values them the most. So that's a classic mechanism design goal. Or a different mechanism goal could be design an election in which parties are willing to truthfully vote for the candidates they really prefer. And the outcome of the election is maximizing some social choice, which the goal of the mechanism defines.
00:16:35.466 - 00:16:48.274, Speaker A: For example, helps the environment boost the economy. You can define your own choice. And of course that might give different elections. So much about the game theory, mechanical design side of things. Yeah.
00:16:48.614 - 00:17:02.630, Speaker C: On the game theory, you say that there is a Nash, the probabilistic Nash equilibrium for every game. What mechanism design? For every setting there exists a mechanism design which will achieve.
00:17:02.702 - 00:17:22.194, Speaker A: No. You can have restrictions on the goals and on the incentives. I guess economists can correct me, under which you can prove that you can design a mechanism. There cannot be a mechanism for every goal. Yeah. I mean, yeah. I'm going to give an example of a goal that seems not to have a mechanism in reality.
00:17:22.974 - 00:17:24.214, Speaker D: What's the best you can do?
00:17:24.254 - 00:17:51.690, Speaker A: Yeah. I mean, yeah. So even the goal at times is left up to the mechanical designer because. Exactly, you know something's going to be there. Thanks all right, so coming to the cryptography side of things, and when I say cryptography here, I'm going to mean multiparty computation. So I'm going to, I know that people working in mechanical design don't like mechanisms of design being called game theory. I'm going to do it.
00:17:51.690 - 00:18:02.294, Speaker A: And as compensation, I'm going to make sure that when I say cryptography, I mean multiparty computation, that cryptographers are also pissed at me. So everyone here can object. So.
00:18:06.214 - 00:18:06.894, Speaker E: Mediators.
00:18:06.934 - 00:18:34.638, Speaker A: And it's going to come up. Yes, it's going to come up. This is an interesting area for what we're doing here. All right, so in MPC, Mutu gave already introduction. So I'm going to go fast. So we have a number of parties, let's say four parties here. Each party has its private input, some data, and the parties want to perform some computation on those inputs and arbitrary computations.
00:18:34.638 - 00:19:20.590, Speaker A: This computation could be just perform a majority vote. If those are votes, it could be agree on a common output. That's how consensus can be captured. And the classic and the goal of MPC is to allow those parties to perform this computation by running a protocol over some communication network. Now, to make this goal interesting, we will require that even when some parties misbehave, this protocol still has some core security properties, and the most common are privacy and correctness. Privacy says that parties that sit don't learn anything more than their inputs and outputs. And correctness say that the output is going to be defined on the inputs of honest parties and the effective inputs of parties.
00:19:20.590 - 00:20:18.396, Speaker A: At Citra, there is some input defined even for citrus. In cryptography, the way to capture this is by assuming a central adversary who corrupts parties and defines what their strategy is going to be and actually coordinates their attack. So this is there to capture worst case assumptions. Cryptographers, we are a little bit hysteric because we don't know what can go wrong, so we just assume that everything can go wrong. In particular, those guys might always talk to each other and might coordinate their strategies to attack the protocol in the worst possible way. That's what the adversary is supposed to capture, as Mutu described already in his talk. The way the more a formal way of capturing these security requirements is by comparing the protocol to an ideal world in which there is a trusted party that knows the computation that is to be performed.
00:20:18.396 - 00:20:59.356, Speaker A: And what it does is it takes the inputs from the parties and returns the outputs. And now security, the security definition, the formally we have secured definition, will require that every attack to the protocol can be mapped to an attack, to this ideal world. So whatever the adversary can do, any ways that the adversary can break the protocol can be mapped to ways that you can break the ideal evaluation. And this is the dream world. We cannot get better than that. Right here we have someone that does what we want for us. So, more formally, for every adversary, cryptographic adversary, of the type I described, there exists a simulator.
00:20:59.356 - 00:21:19.556, Speaker A: This is another adversary, an ideal adversary that might use the real adversary. And this simulator makes sure that those two worlds look the same, look indistinguishable. So you can think of it as the inputs and outputs of parties in these two worlds are indistinguishable when seen as random variables.
00:21:19.740 - 00:21:27.540, Speaker C: Yeah, you have two elements here. You have the adversary and you have the communication to the center.
00:21:27.612 - 00:21:28.076, Speaker A: Yeah.
00:21:28.180 - 00:21:41.068, Speaker C: People communicating between themselves. And actually, when. I don't know much about multiparty computation, but that multipart computation is also the aspect of synchrony and asynchronous, you know, do solve the problem eventually.
00:21:41.116 - 00:21:46.672, Speaker A: Synchrony have the aspect. I'm not sure how. I mean, consensus.
00:21:46.728 - 00:21:47.120, Speaker E: Consensus.
00:21:47.152 - 00:22:08.244, Speaker A: You can. Yes. So I've hidden it here. So this is your resources. This is your communication resources. If you want to run a synchronous protocol, this communication resource will include a clock, for example, a global clock, and then you can run, or a synchronizer. You could, in principle, think of a synchronizer, since it is a distributed, fault tolerant protocol, as an MPC that uses weaker assumptions.
00:22:08.244 - 00:22:30.254, Speaker A: But this thing I've drawn here as a network, but it's not necessarily a network. It can be something much stronger. You can even have broadcast among those parties that run the protocol. It's really what they use in the real world, whatever the real world means for the protocol, what they use in the protocol to exchange messages and emulate this trusted party. What?
00:22:30.334 - 00:22:33.990, Speaker C: The answer is no. There is no asynchronous problem.
00:22:34.062 - 00:22:56.450, Speaker A: Of course there is a synchrony. If in this world, I just have a network, then the protocol is asynchronous. It's really a question of assumptions. The answer is yes. Yeah. So what is depicted here is asynchronous. I mean, he said that multiparty computation is distributed systems.
00:22:56.450 - 00:23:11.736, Speaker A: Yeah. It's an abstraction of fault tolerant computing. Anything you do in fault tolerant computing, I can describe it in this way, in particular, asynchrony. I do describe it already. This guy is just an asynchronous router. If you want synchrony, you would need a clock. This guy would also give to those guys.
00:23:11.736 - 00:23:20.804, Speaker A: It's a question of assumptions. And the beauty of this definition is that it forces you to define your assumptions in the real world. Otherwise you won't be able to simulate.
00:23:21.784 - 00:23:32.698, Speaker C: Usually a synchrony we know can be defined as synchrony, where the adversary jumps from. Mobile adversary, what you call it? Mobile adversary. Asynchronous mobile adversary, essentially.
00:23:32.826 - 00:23:33.330, Speaker B: No.
00:23:33.442 - 00:23:43.586, Speaker A: In cryptography, mobile adversary means that the adversary grabs a party, corrupts him, and then lets him go and grab someone. Someone else. No, no. Asynchrony means that you can think always.
00:23:43.650 - 00:23:45.242, Speaker C: The world is always synchronous.
00:23:45.298 - 00:23:59.000, Speaker A: We can take this offline, but this might be a class of terminology in the two worlds. But in cryptography, when we say synchrony, we mean that the adversary can arbitrarily schedule delivery of messages. That's what we mean by asynchrony.
00:23:59.152 - 00:24:00.480, Speaker E: But mobile is something different.
00:24:00.552 - 00:24:11.720, Speaker A: Mobile is completely different. Mobile is that I can corrupt guys and I can let them and corrupt other guys. That's mobile, at least in crypto. I understand that this might be FLP is synchronous system. Yes.
00:24:11.832 - 00:24:23.870, Speaker C: Only that one processor may not send a messaging around another processor. It's one fault per round. But mobile, that's all there is to it.
00:24:23.902 - 00:25:10.996, Speaker A: Let's take this offline. It's just terminology we're discussing here. It's not going to come up in the talk. So now, a point I want to make is that if you think of the two disciplines, you will observe that they've actually been looking at the same problems. Not only the same problems, but to a large extent the same problems, but asking different questions. So if you look at voting in mechanism design, we ask the mechanism designer to design a method, a mechanism for parties to vote in such a way that we will guarantee that they will truthfully report their input. They will vote for the guy that they would want to vote.
00:25:10.996 - 00:25:54.452, Speaker A: They won't play games. The output of the voting implements some social function or maximize some payoff. And again, the social function is up to definition. And implicitly in this problem description is that the mechanism can make use of a trusted tallying authority. So when a mechanism designer designs a mechanism for voting, he assumes that there is someone that's going to get the votes and is going to do what the mechanical designer says should happen with the votes and announce the result. And similarly issues that are not, for example, cryptographers. We are very sensitive about this thing, and in game theory, it's not addressed at all, is the issue of registration.
00:25:54.452 - 00:26:07.064, Speaker A: Who can vote. In game theory, it's assumed that everyone who can vote is part of the original game definition. In cryptography, we've just seen a bunch of talks that discuss the permissionless model, and this is not the case.
00:26:08.064 - 00:26:08.804, Speaker B: And.
00:26:10.824 - 00:27:01.202, Speaker A: The other assumption which we're going to see is one of the trickiest, is that in game theory or mechanical design, it's assumed that the parties take their decision, play their strategies locally without communicating in any other way than whatever the mechanism possibly allows them. It could be, there might be rounds, but the decision is completely local, it's not coordinated. So this is kind of a typical question of mechanism design for voting. And if we look at cryptography, we also ask to design a voting protocol, right? Same thing. Design and voting protocol such that, assuming that. Design and voting protocol such that, assuming that. But now what is the such that part we care about privacy of voters, where usually it's not addressed.
00:27:01.202 - 00:27:37.644, Speaker A: This is usually not addressed in mechanical design. So we care that when the protocol is played in reality, the vote of a party doesn't leak to other parties, only the outcome leaks to other parties. And we care about some other properties like inquestibility. So we care that the vote doesn't carry receipts. So we have several, I mean, there's a lot of very long literature in cryptography analyzing voting. Seems the fundamental difference is that cryptography is all about coordination. The attacker coordinates all the bad players.
00:27:37.644 - 00:27:44.904, Speaker A: So our definition is assumes coordination, but it's not clear it has to. So I'm going to get there.
00:27:45.024 - 00:27:47.200, Speaker D: So there is single corrupted parties.
00:27:47.312 - 00:28:06.658, Speaker A: Yes. But all the corrupted parties are coordinators. Yes, I'm going to get there. I'm going to get there in like five minutes. Okay, so now I'm going to discuss exactly these issues. So approach that have been taken to combine cryptography and game theory. And by that I mean multiparty computation, mechanism design.
00:28:06.658 - 00:28:57.288, Speaker A: And this is often called rational cryptography as opposed to rational multiparty computation, which is not rational cryptography. It's a little bit confusing landscape. But as opposed to what? As opposed to rational multi party computation, which is usually used for a subset of rational cryptography. You know, the terminology is kind of inconsistent there, but I'm going to use rational cryptography for the combination of the two rather than the specific problems. Okay, so the first question that comes in one's mind is like, okay, here we're doing theory, which if I ask the question, why should you even care about this thing? Right? The answer is obviously because it's fun. There's no question about it. But there are actually reasons why not only us, but the world should care about this combination.
00:28:57.288 - 00:30:01.094, Speaker A: And the reason is that the fact that those disciplines have been looking at different questions of the same problem means that we can possibly combine these questions and get a better answer to the problem. So in game theory, we might be able to use cryptography to relax some set of assumptions. We're going to see examples of that, or to play games in environments which are networked so that there is no mediator, for example. And then in cryptography, we can again use game theory to relax assumptions. And we're going to get more concrete to that. But this is just an outline, and even more interesting for the case of analyzing protocols against incentive driven attacks, we can actually use game theory to improve resilience and efficiency of solutions we have. So let me say a few words about the first part of how cryptography can help game theory.
00:30:01.094 - 00:30:46.912, Speaker A: And hopefully I convince game theorists that they need us. We need them. So hopefully convince them. So the core question here is, again, we saw that one of the main properties of mechanics design is that in a big class of games, a very interesting class of games, which is called mediated games, mediated mechanisms are the type of mechanisms that itay also referred to. They assume a central entity, which is often referred to as the mediator. So voting is an example of such a game. If you think of dealer based card games, like poker would be the example of such a game.
00:30:46.912 - 00:31:09.664, Speaker A: You have a dealer that distributes cards, and if the parties want to play, they either need to openly talk to each other and open cards one by one, or they need to talk to the dealer and he will do it for them. So in many interesting games, we have a mediator. And then a very natural question is, is it possible to remove the mediator from the picture? So I want to give you an example.
00:31:10.644 - 00:31:15.036, Speaker E: You know, this is an established area in brainstorm, in addition to cryptography.
00:31:15.180 - 00:31:30.124, Speaker A: Yes, I'm not defining it here. No, no. I'm going to even, like, give results that combine. Yeah, of course, established. Depends on whom you asked. But, yeah, I mean, game theorists would not consider it as mainstream, but, yeah, I agree with you. It's established.
00:31:30.124 - 00:32:15.034, Speaker A: All right, so here's an example. So assume that we have four parties that they want to have an election. You can imagine what those four parties might want to vote on. Right? And assume that we ask our super brilliant game theorists to design a mechanism for this election. Parenthesis, if you do manage to design a mechanism for this election, please do that before October. But, yeah, I mean, it seems a hard problem, at least so far. Now, assume that they do give us a mechanism for this election.
00:32:15.034 - 00:33:17.608, Speaker A: This mechanism, as I said before, is going to be of the type that those guys are going to have a strategy, which is how to vote, and there's going to be a way to tally and output the result. In other words, it will inherently have a trusted party, which tallies for them. So a very natural question to ask is, you know those guys are not co located, right? They're in completely different areas, and they might or might not have reason not to trust the trusted party. So one thing which is desirable here is to decentralize, remove this trusted party from the picture, decentralized its function, its functionality, and have the parties emulate it. Do we know how to do that? It's a tricky question. Do we know how to decentralize this trusted party and have it emulated by the parties?
00:33:17.716 - 00:33:18.404, Speaker B: Yes.
00:33:19.024 - 00:33:51.826, Speaker A: Multi party computation. Right? Again, it's a tricky question. So it seems rhetoric, but it's not. And why is that? So what does it mean to how to have those parties running multiparty computation? It means that each party is running a protocol and they communicate over some, over some network. It can be a network, it can be a weaker mediator, it doesn't really matter. And they try to emulate the trusted party. So now those parties are rational agents, right? They have incentives.
00:33:51.826 - 00:34:20.674, Speaker A: They want to get something with what they do. So the protocol is no longer a standard cryptographic protocol. Right. None of them can be assumed to be honest. First of all, they all want to get something. And hence this protocol needs to be considered a game and analyzed assets. So this is a different type of a game, where the strategies of the parties are their actions in the protocol, combination of the actions in the protocol.
00:34:20.674 - 00:34:58.832, Speaker A: And I didn't mention how those things can be captured. But there is this concept in game theory, which is a very well established concept concept which is a sequential game. And the idea is exactly this one. So we can have a game in which parties take turns into playing actions. Actions can be protocol messages. And the way in general to represent such games is by means of a tree where the root of the tree is assigned to, let's say, now this is a two party game, but you're extending to multiple parties assigned to one of the parties. And he can, let's say, do one of the two moves.
00:34:58.832 - 00:35:31.294, Speaker A: This is like there are two possible messages. Then the second level is assigned to the other party, and he can, for each of those moves, answer one out of two moves. And so on. So it's a binary tree for space reasons, right? So in reality it would be a much, much, much larger. And so we can represent games in such a way. And this gives rise to a very, very interesting class of games known as sequential games. And the biasian form of those games is particularly convenient for capturing cryptography.
00:35:31.294 - 00:36:03.816, Speaker A: Why? Because we have a very good correspondence on the notion. So I already told you that biases and games have types. So every party has a type that defines to some extent how he's going to play. This is the, in cryptography we call it input, right? My input defines what I'm going to do in the protocol. It defines my messages. So we can, and conveniently, types are parties don't have, in game theory, parties don't have complete information on top types exactly in the same way as in cryptography. So we can map inputs to types, inserts again.
00:36:03.816 - 00:37:02.140, Speaker A: And then, rather than requiring security, saying that no adversary can attack the protocol, we will require stability, which says that if I manage to design the game in such a way, let's say that it's Nash, then no one is going to be willing to not play this strategy design. So this is the mapping of protocols, cryptographic protocols, the game. Now there is the issue, which is why the question that I made was tricky. We are using an NPC, right? What does NPC tell us? It tells us that every adversary can be simulated. But what kind of an adversary? Every adversary that potentially corrupts several parties and has them coordinate their actions. This completely destroys the game. So if you think of what game we come up with here, it's not the game that the original mechanism designer gave us, right? That game, everyone was in his room.
00:37:02.140 - 00:37:37.514, Speaker A: He was playing his action and telling it to the mediator. In this game, the guarantees we're getting is that when they, I mean, cryptography was intended to say, even when they collude, we can simulate. But this even is a big problem because now cryptography says, forget, even when they collude, we can simulate. That's a problem. That's not what the mechanism was designed to achieve. So in principle, the stability of the mechanism might be disturbed by the fact that we're using an MPC protocol. So bottom line, collusions are an issue.
00:37:37.514 - 00:38:13.238, Speaker A: And you can take a folklore attempt and say, I don't care, there are no collusions. I'm going to run my cryptographic protocol. Right? And this is actually often done. So if you think of all this literature, cryptographic literature about playing mental poker, the protocols that have been suggested would not allow you to play mental poker or at least analyze. So if you had proved something good about poker, that there is a good strategy, then this statement wouldn't transfer to the play mental poker protocols. Exactly. For this reason.
00:38:13.238 - 00:38:14.514, Speaker A: Because. Yeah.
00:38:14.934 - 00:38:30.594, Speaker B: So can you elaborate a little more? So if I try to model NPC as a sequential game and even a single player, no collusion, e is byzantine, you know, is faulty. It would still be controlled by the adversary, and the whole game changes.
00:38:30.934 - 00:38:33.830, Speaker A: Well, I mean, if it's only a single faulty player, it's less.
00:38:33.862 - 00:38:36.214, Speaker B: Why is there such a big difference? Can you elaborate?
00:38:36.334 - 00:39:07.074, Speaker A: Because. So what happens here is that in the game, it's not just a single. What does it mean, a single party is faulty. It means that in the game you're considering only one guy might misbehave. And that's not the model we live in. The mechanism said that everyone might misbehave, but with a goal. So at the point where you say, I only consider adversaries that corrupt one guy, you don't have really the game you had before because you have restricted this player here to play his own strategy and he might not want to.
00:39:07.414 - 00:39:09.034, Speaker E: What's your solution concept?
00:39:09.734 - 00:39:19.846, Speaker A: You can think of Nas, you can think of subgame perfect, you can think of several collision resistance or just not. I'm going to get to that. No, I'm considering like, the standard. Not collision. Again, I'm standard notions.
00:39:19.990 - 00:39:23.398, Speaker E: So then I go back to that question. If you're only worried about one party.
00:39:23.486 - 00:39:24.154, Speaker A: Yeah.
00:39:24.534 - 00:39:25.634, Speaker E: What's the proper.
00:39:26.614 - 00:39:42.818, Speaker A: Think of playing poker over? I mean, I'm gonna. So let me get to that in three slides. It's gonna become much, much clearer. It's a problem with the definition. It's the problem that the security definition does not exclude collusions. It explicitly allows collusions. And this is an issue.
00:39:42.946 - 00:39:48.130, Speaker D: Is it about collusion or about the fact that nobody should be honest? That honesty is not.
00:39:48.322 - 00:39:53.054, Speaker A: This is about collusion. The fact that nobody should be honest is a separate issue. Yeah.
00:39:54.394 - 00:40:04.250, Speaker C: Why? Collusion is not necessarily disrupting the game, Bobby. They want to maximize now depends on the game.
00:40:04.282 - 00:40:21.014, Speaker A: First of all, right, think of poker. Yeah, but you can think of poker, right? If you're playing poker, it's a completely different game that if you're playing poker with Safi and Dalia and they're playing just by themselves or if they're showing their car to each other, it's a completely different game. You need to reanalyze it.
00:40:22.454 - 00:40:27.934, Speaker B: So again, if you were not worried about collusion, the definition would be fine.
00:40:28.014 - 00:40:30.270, Speaker A: Yes. If I'm not worried about collusion, definition would be fine.
00:40:30.382 - 00:40:31.034, Speaker B: Why?
00:40:32.014 - 00:41:34.984, Speaker A: I get there in a few slides because I'm going to give an example of where things fail. Ok, so one way to rectify that is to tune our game theoretic notions of stability to explicitly allow for collusions. And this is actually, I mean, it's based on the notion of k resilient mass equilibrium, which existed already from the very old results on game theory. But in more recent work, Eta et al showed that there is an issue with k resilient. I mean, the game theory community knows that there is an issue, but they actually described a way of rectifying this issue. So what's k resilient? It says that no set of k parties has an incentive to deviate. Rather than saying that no one by himself has an incentive to deviate if the others stick to their strategies, k resilience says that no k parties have incentive to deviate.
00:41:34.984 - 00:42:26.138, Speaker A: And an observation there is that this is not a very stable intuitively solution. Why? Because it might be that no case has any sense to deviate, but still, if one of them leaves the coalition and does whatever he wants, the remaining parties lose. And this gave rise to the so called t immune equilibrium, which exactly excludes this event. So the combination of k resilient and t immune is Katie robust. And using MPC, we can get Kt robust equilibrium, at least I think in the information, very exciting computationally. I don't think you guys proved something. You can, but I mean, can you use PKI, can you use signatures in it? We can discuss it later on, but information theoretic MPC would work and would give you this type of equilibrium.
00:42:26.266 - 00:43:00.064, Speaker E: So I guess just one intuition. So the fact that you have a coalition of size k in a Nash equilibrium means that the thought process in your mind as a coalition is everybody else is running the protocol. What is my best response? So in that thought process, the fact that you're thinking that everybody else runs a protocol, you're basically thinking that everybody else is honest. So the natural game theoretical thought process of an equilibrium has the same mathematical analysis as the standard cryptographic protocol.
00:43:00.644 - 00:43:08.824, Speaker A: True, but there we can get, I mean, there comes. Everyone can be rational versus cryptography, where we know that not everyone can be corrupted.
00:43:10.454 - 00:43:15.834, Speaker E: I can say this in a precise mathematical manner. I can say this in a precise mathematical manner.
00:43:16.574 - 00:43:26.914, Speaker A: Of course. I know, I've seen it. But again, the answer is, it's a difference in scope. Right? So you are making this thought process.
00:43:27.414 - 00:43:37.686, Speaker E: It'S actually not a difference in scope. You can show that one model covers the other. If you have a result here, you can get a result here. You can show how these are.
00:43:37.870 - 00:43:46.694, Speaker A: I'd be very happy to see more about this thing. I mean, that might be my limited understanding of the results, but, yeah, I'd be very happy to show you.
00:43:46.814 - 00:43:55.862, Speaker F: I'm just trying to understand this definition. So the first k resilient is saying, if I'm a coalition, I cannot benefit myself from deviating. And the second line is about, this.
00:43:55.878 - 00:44:07.628, Speaker A: Is up to the utility definition. You can define the utility so that the coalition has, any coalition has a global objective. Like, think of it as the sum of the utilities. Or you can define utilities which are more fine grained.
00:44:07.756 - 00:44:11.504, Speaker F: Like if it's zero sum, then they're kind of the same, right?
00:44:12.164 - 00:44:14.156, Speaker A: You mean the resiliency and the immunity.
00:44:14.340 - 00:44:15.604, Speaker F: Zero sum that they're grain.
00:44:15.644 - 00:44:17.344, Speaker E: This is not, this is not the.
00:44:17.804 - 00:44:18.988, Speaker F: It's not a zero sum.
00:44:19.036 - 00:44:21.144, Speaker E: This is not fully precise.
00:44:21.444 - 00:44:23.836, Speaker F: Okay. So I guess I'm not understanding.
00:44:23.900 - 00:44:24.544, Speaker E: Yeah.
00:44:25.124 - 00:44:28.876, Speaker F: As I see it, if it's zero sum, they're kind of the same. If they're not zero sum.
00:44:28.980 - 00:44:29.252, Speaker A: So this.
00:44:29.268 - 00:44:49.464, Speaker E: The team Yoon talks about players where you have pre bayesian knowledge about their utilities. You don't know how they behave. So intuitive. You should think about the team Yoon as the players that are completely byzantine in the cryptographic notion and the k resilience. Are the parties in your coalition that are rational in that sense? They're afraid of punishment.
00:44:51.044 - 00:44:54.944, Speaker A: There is a question which is like, parties in the coalition, can they have competing utilities?
00:44:55.774 - 00:44:57.174, Speaker E: I have a few hours. I can talk.
00:44:57.214 - 00:45:08.326, Speaker A: Okay. Okay, good. So let's defer this to a few hour talk by Itai. The same game would have different behaviors under different sets of utilities, right?
00:45:08.350 - 00:45:19.030, Speaker E: So this is a solution concept. Very important. This is not the same game. This is just about the solution concept. Utility function does not change. Action space does not change. Extensive form does not change.
00:45:19.030 - 00:45:20.922, Speaker E: This is the solution concept.
00:45:21.118 - 00:45:29.894, Speaker A: Let me continue. And then, you know, we can, we can. I'm actually. I'm just throwing this slide there because I wanted to tease the audience into the existence of. Yeah.
00:45:30.314 - 00:45:35.730, Speaker D: I thought, well, maybe you're gonna take a minute slide, so why not use the call?
00:45:35.882 - 00:45:36.674, Speaker A: The what?
00:45:36.834 - 00:45:37.694, Speaker D: The call.
00:45:39.554 - 00:45:40.818, Speaker A: The call what? Sorry.
00:45:40.906 - 00:46:21.024, Speaker D: So there's another part of game theory which looks at corporate games, okay? And, like, the setup of the game is a bit different. You ask, suppose we can write contracts with each other. We all commit to something and then the definition of the game is what the coalition of us, the subset of the players, can achieve. So, for example, it's used to collide bargaining. And tools from this framework were used, for example, to think about collusion in auctions. So if there's some part of the bidder scored and it's a bit, of course, they can do better in an auction. So you ask, I want to get an auction such that no subs and no coalition could do better even if they were able to write contracts.
00:46:21.024 - 00:46:23.344, Speaker D: That's called call selecting options.
00:46:23.684 - 00:46:29.384, Speaker A: I'm not familiar with it, so I cannot answer. But, you know, that's another solution. It should probably have been here.
00:46:29.804 - 00:46:31.544, Speaker D: Yeah, collusion resistance.
00:46:33.244 - 00:47:44.574, Speaker A: So the solution that I'm familiar with is coming from the other side, coming from the cryptographers trying to fit our theory into the demands of game theory. And this has to do with, you know, if we identify the problem, the problem is collusions we haven't intuitively identified, but it will come, then what we can do is we can say, okay, let's try to get security, which does not explicitly allow collusions, does not explicitly assume that parties that misbehave in the protocol collude. So the idea here is to transition from this definition where we have a central adversary and parties that deviate, we call them corrupted, do that in a collaborated manner. And this means we don't really care about the information we exchange in the execution. We transition from that to a notion of security where parties have local adversaries corrupting this. So each party has his own little adversary correcting him. And then what we require is that any combination, so those adversaries don't communicate, right, they're completely separated.
00:47:44.574 - 00:48:10.834, Speaker A: And what we require is that any combination of adversaries in the real world, so namely any combination of local attacks, can be mapped to a combination of simulators in the ideal world. So every combination of local, non communicating attacks to the protocol can be mapped to a combination of local non communicating attacks to the functionality.
00:48:13.614 - 00:48:22.262, Speaker C: How do you formalize, if this is a general adversary, these adversaries are general. How do you formalize the notion of.
00:48:22.318 - 00:48:26.254, Speaker A: Local adversary, an adversary, by chance, doing.
00:48:26.874 - 00:48:29.146, Speaker C: What a global adventure we would.
00:48:29.330 - 00:49:02.264, Speaker A: They cannot. And a very simple example is going to come. I mean, obviously. So those adversaries are very, first of all, how do you formally specify them? It's usually the easiest step, which is the adversary is a Turing machine. So the big question is, if you take the player set and you consider the experiment, whom does the adversary replace in the classic experiment, he replaces the corrupted guys all together as one machine. And here each party who is corrupted is replaced by his adversary. So formally you can define it intuitively.
00:49:02.264 - 00:49:37.434, Speaker A: Once you go to this definition, you can no longer play the standard MPC protocols. And I'm going to give an example. I mean, it's very easy to see why. So I can already give this example. The reason is that in the protocol, let's say that we're trying, we have like a trusted party that does voting or poker, and our protocol is over a communication channel, then this adversary might send a random message to this adversary, and there's absolutely no way that those guys here can output it. They can both output it in the real world and they cannot output it in the ideal world. This gives you some intuition on why standard MPC would not work.
00:49:37.434 - 00:50:22.308, Speaker A: Standard MPC. I'm going to give more one theorem. Well, I'm staying in the very formal level because I was supposed to be. So one theorem that you can prove is that if you managed to design a protocol that implements a mediator in such a way, and then in this mediated world, you have proved something about your game, then whatever you've proved will transfer also to the protocol world. That's a way to see why we are interested in this collusion free in.
00:50:22.316 - 00:50:27.780, Speaker F: The real world and in the ideal world, they're not. In both worlds, they're not allowed to collude.
00:50:27.852 - 00:50:42.420, Speaker A: In both worlds, they're not allowed to collude. But in this world, they're just sending one message to the mediator, and the mediator is computing the output. And in this world, they're running potentially an arbitrary protocol over some communication resource. The crucial point here is that even.
00:50:42.452 - 00:50:44.300, Speaker C: The ideal world, there are multiple simulators.
00:50:44.372 - 00:51:05.708, Speaker A: Yes, yes, the local aspect. So this is enforced by the fact that those guys cannot communicate. So if you want to have any hope of proving that your protocol simulates is distinguishable from the ideal world, if you want to have any hope of doing that, you need to guarantee that the views of those adversaries are as independent as the views of those simulators.
00:51:05.796 - 00:51:07.732, Speaker F: So this doesn't imply normal NPC, and.
00:51:07.788 - 00:51:09.624, Speaker A: No, normal NPC won't give you that.
00:51:10.764 - 00:51:12.852, Speaker F: Is it incomparable to normal NPC?
00:51:13.028 - 00:51:26.532, Speaker A: Yes, but you can use normal NPC and some extra assumptions to get it. I'm going to say how, but yeah, you cannot. Normal NPC will not give you that. Yes, it's very easy examples. Right. All normal NPC. I mean, I have it.
00:51:26.532 - 00:51:59.186, Speaker A: Wait, I have it in slides. So all normal NPC use randomness, right? They exchange commitments, they exchange encryptions, they exchange challenges. What you can do is you can have the parties from the beginning knowing, look, if my first commitment finishes in one, this is the way of me signaling to you that my input's first bit is one. Now, the adversaries can just use this information to output, correlate output there first bit of their inputs, the signal. Have no idea if this is not part of the output functionality. So it's a very simple case. It's really, really simple.
00:51:59.186 - 00:52:51.446, Speaker A: I mean, there's an even simpler example that you can run your MPC protocol and just what I said before, and just have like, one of the parties, one of the adversarial parties choose a random value and send it to the other, and then they both output it. There's no way to simulate this view. So this definition, does it make sense to generalize it in a setting where if you have a game that you have analyzed to make sense against certain sets of collusion, selection of collision types, you know, like, no, collusion is one example, and arbitrary collusion is the other extreme of, then you can just basically quantify over such adversaries? I believe so, yeah. I believe so. You will have a more fine grain. I don't know. There might be, I don't know of interesting games of this type, but yes, this is a possible extension which one might think.
00:52:51.446 - 00:53:21.304, Speaker A: So Al is saying that here we have full isolation of parties. Maybe what we want is a more relaxed version of isolation of parties, where any combination of two parties can actually coordinate their actions. That's a different version of local adversaries. I'm not sure how useful it is. This I know because of the theorem that I informally stated before this theorem, it's useful for replacing mechanisms. The other one, I'm not sure result.
00:53:21.384 - 00:53:23.600, Speaker E: Here in terms of the solution concept.
00:53:23.632 - 00:53:28.880, Speaker A: Or any solution concept. I mean, I don't know if any, but any non solution concept would work. So say it again.
00:53:28.912 - 00:53:29.768, Speaker E: So any known.
00:53:29.896 - 00:53:47.364, Speaker A: For any known solution concept, you can preserve. If there's an equilibrium here, you can preserve it here. It's going to be a strategy here. It's very natural. Right? So what happens here because of the local adversaries is completely, once you see the output of the mediator, it's completely simulatable. So you learn nothing. There's no signaling.
00:53:47.364 - 00:53:55.784, Speaker A: If this definition is true, there is zero signaling. So you effectively live in the game theoretic setting, you see whatever you would see in the game and random crap.
00:53:56.204 - 00:54:04.340, Speaker F: So in your example where this guy sends r to the other guy. Like, why can't you do this in general, for these people to share stakes?
00:54:04.452 - 00:54:18.906, Speaker A: You can. That's what I'm saying. You can, you cannot. I mean, this is effectively an impossibility result that you cannot implement this, not only NPC's don't implement this definition, you cannot do it over an arbitrary network. So this is a very strong definition to satisfy in the real world.
00:54:18.930 - 00:54:23.094, Speaker F: I can just think of it as a single adversary because they can just exchange messages over.
00:54:23.474 - 00:54:40.644, Speaker A: Yes, but you don't need to. So the whole point is that those are two deviating parties, and what you want to capture is that they don't collude, they cannot signal to each other. And this, of course, if you have a network, you can signal by just sending your signal. So this, this is.
00:54:41.864 - 00:54:45.536, Speaker F: So it's not meaningful in the real world to say there are local adversaries.
00:54:45.600 - 00:54:52.624, Speaker A: It is. You need stronger assumptions. You cannot. So if you have a network, an arbitrary network, you cannot do it, but you can do it at a stronger assumption.
00:54:52.664 - 00:54:56.640, Speaker E: So otherwise you bring NPC that can abort.
00:54:56.752 - 00:54:59.044, Speaker A: The size of what the coalition.
00:55:00.464 - 00:55:03.760, Speaker E: You said you can, you can serve, you can provide any solution concept.
00:55:03.792 - 00:55:04.008, Speaker A: Yeah.
00:55:04.056 - 00:55:06.880, Speaker E: If the game had like a solution concept with a very large coalition.
00:55:06.952 - 00:55:07.564, Speaker A: Yeah.
00:55:07.864 - 00:55:10.856, Speaker E: Your MPC would have to be something with abort.
00:55:11.000 - 00:55:25.324, Speaker A: Yes. But what you can do is you can actually use techniques that hide this abort until the very end of the game. You cannot correlate your strategy with the abort. So you're right, if abort is visible at some point of the game, then I can use abort to signal. That's what you're saying, right? Or not.
00:55:25.664 - 00:55:29.004, Speaker E: You can just. I mean, you just not achieve your simulation.
00:55:31.204 - 00:55:46.436, Speaker A: I achieve security. Why not? I achieve security with a board. Right. It's just that I need to be very careful to make sure that a board doesn't occur during the protocol execution. I only observe it in the end. If I do that, then I'm getting. I'm getting a version of the game with a board.
00:55:46.436 - 00:55:48.764, Speaker A: But that's okay. It doesn't change my strategy.
00:55:48.884 - 00:55:54.836, Speaker F: Are you saying you're going to impose constraints that don't allow these people to adversaries to talk in the real world and to load?
00:55:54.900 - 00:56:16.386, Speaker A: Yes. Yes, you have to. Or, I mean, it's not that they don't allow to talk. You can. I mean, you can do different, different things. So the standard definitions, the standard solutions that we have, what they do, what they do is they assume that part is talked through a mediator. But it's not a mediator that solves, that computes the function for them.
00:56:16.386 - 00:56:47.646, Speaker A: It's a mediator that re randomizes their messages, that kills any correlation they might be sending. So the easiest way to see it is that the standard tools we use in MPC are commitments, encryptions, secret sharing and so on. All this stuff can be randomized so that whatever you're sending and whatever I'm receiving, so the commitment is on the same value, but the random, you know, the actual commitment that I'm seeing is independent from the commitment string you sent, how the mediator is going to get it from you, and then before sending it to me, he's going to re randomize it. So I'm going to get a randomized version of it.
00:56:47.670 - 00:56:51.094, Speaker F: So are you assuming that the real world is an admedian hybrid?
00:56:51.174 - 00:57:27.060, Speaker A: Yes. The standard solutions assume that it's a. An f meter hybrid world. And to relax a little bit, this assumption, and not live in the similar version as the ital result. So what we can get is a version in which when you work over the mediator, if the mediator performs the way you want him, so he's honest and he randomizes, and he doesn't look like sneak inside and talk to the adversary. So if he behaves like that, then you will preserve your equilibrium. And even if he doesn't, you will still preserve the standard cryptographic security.
00:57:27.060 - 00:57:43.900, Speaker A: So if you think of playing poker with such a mediator, the statement would be that if the mediator is honest, then whatever you've analyzed about your poker game will transfer to the mediated setting. If he's dishonest, then at least your cards won't, you know, your exact cards won't click if you fall. Yeah.
00:57:43.972 - 00:57:46.024, Speaker D: Can you check if the mediator is honest?
00:57:48.834 - 00:58:02.770, Speaker A: Good question. I don't answer anything about it. I mean, in the original solutions, I think not. No, not. I think in the original solution, no. So the answer is solutions that we have. Don't check.
00:58:02.770 - 00:58:21.034, Speaker A: Whether you could check, I'm not sure. Maybe that's a very good idea, actually. What was the question? If you can somehow check that the middle is honest, or you can distinguish when the game actually succeeded as a game, or when you fall back to cryptographic security. Yeah, I mean, that's a very good question. Solutions we have don't do that.
00:58:21.574 - 00:58:28.670, Speaker F: Is the goal to reduce the trust in the mediator? Like I can just make the mediator play the whole poker game, right?
00:58:28.702 - 00:58:29.814, Speaker A: No, no, the goal is to reduce the trust.
00:58:29.854 - 00:58:30.006, Speaker B: Right.
00:58:30.030 - 00:58:54.742, Speaker A: So you cannot, I mean, you can do what you're saying, but then you won't get this fallback securely because then you need to give him the inputs. And actually in a very, very recent work, what we saw is that you don't necessarily the mediator but modulo abort, which we can counter in other ways. You can have like local hardware tokens and publicly observable broadcast channel and you can still play a similar strategy.
00:58:54.758 - 00:58:57.974, Speaker F: So I don't understand the fallback security. What is the statement of fallback security.
00:58:58.014 - 00:59:37.334, Speaker A: Says that if the mediator is corrupted, you get standard cryptographic security so he cannot break correctness or privacy, but parties might collude. Okay, can I do like another like three, four minutes before the break or are we already, we're resuming anyways in 20 minutes, so maybe. Okay, so then let me stop here. And after the break I will speed through some of, of the more kind of general things that I had to say and jump into more blockchain consensus related.

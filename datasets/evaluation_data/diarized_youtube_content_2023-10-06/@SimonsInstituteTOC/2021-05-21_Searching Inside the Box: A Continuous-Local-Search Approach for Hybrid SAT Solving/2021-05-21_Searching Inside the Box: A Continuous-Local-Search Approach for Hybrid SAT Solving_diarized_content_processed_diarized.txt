00:00:00.240 - 00:01:06.684, Speaker A: Hello everyone, my name is Zhu Wei Zhang and it's really my great pleasure to speak here at Simon's Institute. Today I'm going to tell you about our work on a continuous local search approach for hybrid SAP solving, and this is a joint work with Anatasa security, Anshumani Srivastava and Mouse Vardy. So when we are talking about set solving, what are we really referring to? I guess in most cases we mean CNF solving. Of course, CNF is the most prevalent and successful format in said community, but there are also other very important and useful non CNF Boolean constraints which are much less studied in this community. In graph theory there are a lot of examples. For instance, for vertex covering, it's more convenient to represent this problem by either coordinator constraints or pseudo Boolean constraints. Another example is the hypergraph two coloring, where not all equal constraint is the most natural representation.
00:01:06.684 - 00:02:05.994, Speaker A: Well, in cryptography actual constraints play important rules for composing protocols like SHA one, and I'm sure that you can list other applications to demonstrate the importance of non synaptic boolean constraints. So what have people done for handling non CNF constraints? There are two main lines of research. The first one is encoding. Encodings have been discussed in previous workshops, but here I want to make the list some limitations of encodings. First is about size. Here is the histogram about the blow up of number of variables and classes if we just want to encode a tag navy constraint with 250 variables. So you can see the blow up here, and it is no doubt bringing a heavy burden to the sep solver and slow them down.
00:02:05.994 - 00:03:20.134, Speaker A: Besides the size, encodings can vary a lot by other aspects like arc consistency and the solution density. So usually different servers prefer different encodings. And the takeaway message here is that just because encoding is found for type of constraint doesn't mean it is server friendly. Well, the second aspect for handling non CNF constraint is to use extensions of CDCL based set solvers. There are a bunch of tools developed in this area, but we want to make the point here that they need to design algorithms for each specific type of constraints, while a uniform way for handling different types of constraints is still lacking. So both of those lines of research kind of rely on CDCL subsidy servers, relies heavily on the property of seeing that format. So we are thinking about can we use a more general approach, namely local search? So local search.
00:03:20.134 - 00:04:28.010, Speaker A: In local search, usually the objective function is defined by the number of constraints of formula satisfied by some assignments. There are many, many classical algorithms in this area. GSAT is one of them where you start from a random initial point and you just keep flipping the variables with the best value until you reach a solution. Local search gives us interesting theoretical results and in practice it was shown to be effective on hard random and crafted instances as well as matte side instances. So we want to ask, can we use discrete load research for non synapse solving? Let's see what happens. So remember that discrete little search also relies on some properties of synapt, which is an unsatisfied clause, can always be fixed by flipping just one variable. But does this probably also hold if we want to solve non synaptic constraints? And probably not.
00:04:28.010 - 00:05:24.970, Speaker A: Let's say the following example. Here we have a coordinator constraint with four variables. And suppose we start from this all false assignment. Now it is onsite fired and we will try to flip one variable, let's say the first one, to make this new x. Now there are two things to notice. The first one is that the constraint is still on set. The second thing is that, and even worse thing is that if we just use the way we define the discrete objective function in CNF solving, we will see no change to the discrete objective, although we think that we are making some progress because we are closer to satisfying this coordinated constraint that indicates some problems with using discrete objective for non CNF solving.
00:05:24.970 - 00:06:40.104, Speaker A: The first one is that discrete local search is limited to flip a single bit per iteration. Second, discrete objective function fails to capture the progress towards satisfying a non CF constraint. So maybe stay in discrete domain is not enough and here is what we are planning to solve those problems. As for discrete objective fails to capture progress, we plan to design a continuous fitness function to measure the progress. Since this rate load search is limited to flip a single bit per iteration, we are thinking of just search inside of the box and do continuous research so that we are kind of flipping more than one bit simultaneously. Maybe we'll just flip each bit slightly, but we can manipulate a subset of bits instead of just one. I think it's a good point to wrap up a little bit and show you some really good work on continuous approaches for set solving, which is not a new thing because people have developed both convex realizations and non convex polynomial representations for set solving.
00:06:40.104 - 00:08:14.784, Speaker A: For the last part, we do have LP relaxation and SDP relaxation. Those relaxations gives us due to theoretical guarantees, but they usually fail to give high quality solutions in practice. While on the right the same formula is usually transformed into a sum of product polynomial, but in the previous literature they failed to give sufficient theoretical analysis about this transformation and also note that this transform only applies on CNF format. While we want to solve non cnf constraints as well, one point that both of those directions are missing is the success of gradient based techniques achieved in machine learning, and we believe that those advantages and new techniques are not fully leveraged in the set community. So we want to explore the potential of continuous local search. So here I will just show you the overall workflow of our framework and the goal is to design an effective framework that handles different types of constraints uniformly we are giving so our input is hybrid boolean formula and we can do some kind of transform which I will describe later to generate a multilinear polynomial. Then we will be able to do continuous optimization based on some gradient approaches.
00:08:14.784 - 00:09:10.034, Speaker A: We may end up converting to global maximum, local maximum, or set a point, but no matter which point we convert to, we can always discritise it to check if it is a solution or not. If not, we just go back and do random restart. In the rest of this talk I will be decomposing this framework into different pieces and show you how each component actually works. The first and the most important part of our framework is how we define this continuous fitness function. Let's go for it. Remember that the discrete objective function is just the number of satisfied constraints. As we discussed before, this function is kind of too discrete so that it fails to capture some small progress towards satisfying nonsense enough constraints.
00:09:10.034 - 00:10:04.692, Speaker A: So, can we define a real value fitness function for the boolean formula? Usually one of the ways people do it is to define a real value function by probability space. Here is how we do it. We want to define a fitness real value function for all the real vector which are constrained in the Boolean box from minus one to one. So we can define a probability space based on the real vector a. The probability space will be applied on all the Boolean vectors. So here is how we do it. These coordinates of the Boolean vector will be independent from each other and the value of xi will be only decided will be only related with the value of AI.
00:10:04.692 - 00:11:18.934, Speaker A: So roughly speaking, if AI is positive, then xi has a greater chance of being one if sampled from the probability space sa and if AI is negative, then vice versa. Here is an example. A is a vector and here is a table probability table showing how what's the probability of each variable taking some specific value, and we can sample a Boolean vector from this table. So after we get this probability space, one of the way that we can define our real vector real value function is to use the probability that the formula is true under this probability space. So this looks good. But unfortunately this probability is sharply complete to evaluate because it reduces to the model counting problem. But we can step back and compute something easier, which is the expectation of the original objective function under this probability space.
00:11:18.934 - 00:12:40.834, Speaker A: So what happens if we choose this representation? Now, the capital f the fitness function measures how many constraints are satisfied in expectation under the probability space, and we can next try to maximize this fitness function with respect to a, which is constrained in the Boolean box where a is a real vector. So generally speaking, this real value fitness function gives us a way to measure how good a real vector is. While we're doing search, the next question to ask is how to evaluate this fitness function. A naive approach takes at exponential time, of course, but it turns out that this fitness function can be evaluated in polynomial time by the so called Wash Fourier expansions, which I will describe in the next slide. The wash Fourier expansion is the main theoretical technique we are using in our framework. While Ryan has written a remarkable textbook on this topic, I will just give a brief introduction. It is basically a technique which transforms boolean functions to multilinear polynomials.
00:12:40.834 - 00:14:01.804, Speaker A: For example, if the formula is x and y, then I will claim that this polynomial is the four expansion. The reason is if you evaluate this polynomial on all the four possible discrete assignments, you will see that the Boolean function and the polynomial agree with each other. And this phenomenon is general in the sense that every single Boolean constraint has a unique representation in multilinear polynomial that agree with the constraint on all the Boolean assignments. But what happens on the real vectors? The polynomial itself does not prevent us from evaluating it on real vectors. If we do so, we may generate a surface in high dimensional space, which is useful in our framework. So how does it help us to evaluate our objective function? Recall that we define our real domain fitness function by the expectation. So by the linearity of expectation, we can expand this representation to the sum of probability that each constraint is true under the space that we defined by a the real vector.
00:14:01.804 - 00:15:13.980, Speaker A: One of the contributions we made is that this probability can be computed exactly by evaluating the Fourier expansion if we just use the same real vector a on both sides of the equation. So now we are able to rewrite our fitness function by the sum of Fourier expansions of each constraint. Here is an example. Now Phi has two different constraints and we can transform them both into their corresponding Fourier polynomials and add them up to get our polynomial representation of fitness function. So we will be able to evaluate it. So here finish our first part and the second part is about versatility. So since we are motivated by handling non cf constraints, and so we will see how we do it, recall that our fitness function is defined can be rewritten as the sum of four expansions.
00:15:13.980 - 00:16:45.676, Speaker A: So if we have a new type of constraint, and we know the closed form for expansions of that constraint, then we are good. But for what type of constraint can we do it? Fortunately, many types of interesting constraints have their closed form for expansions from absorbed to cardiovascular constraints to not or equal constraints. And including Cnafene CNF clauses, we further proved that for all symmetric constraints, we have their closed form for expansions. So here comes to the last part, and I believe that in this part a lot of questions can be raised. For example, can we say anything about global maximum center points? Or local maximum? Or how fast is the convergence? Or after we discredit size the convergence points? What is the quality of this assignment? So let's answer these questions regarding convergence and rounding. The first thing I want to tell you here is about global and local Matthew, another contribution we made is to prove global maxima are all preserved in real bots. So if we what do I mean by that? Let's first consider the scenario in discrete load research.
00:16:45.676 - 00:17:43.004, Speaker A: In discrete research, phi is satisfiable if and only if the maximum of the discrete objective value is the number of constraints. This is easy to see, and what we have proven is that this theorem also holds in the continuous space. So here I need to replace the discrete objective value to our fitness function, which is real value. And now the maximum operator is applied on all the possible real vectors in the box constraint. And the maximum of the fitness function is still the number of constraints. So that means the fitness function is well behaved inside of the tube and it won't exist. Exit the number of constraints, we cannot end up finding some global maximum inside of the tube.
00:17:43.004 - 00:18:39.654, Speaker A: So it's not always realistic to convert to a global maximum. So we have to consider the case where we go to a local maximum. Can we say anything about locomotive? To answer this question, we need to study the geometry of multilinear polynomials. So, multilinear polynomials are globally non convex and non concave, which is not useful for optimization. But locally multilinear polynomials are always convex along some directions, while concave on some other directions. So as a result, neither of this ball shaped local minimum nor this local maximum can appear on the surface of multilinear polynomials. The only place which may trap our search is such a saddle shape.
00:18:39.654 - 00:19:42.024, Speaker A: But saddle shape is not the worst thing in search, because we have a great chance of escaping from it. Formally speaking, if we do not apply our robots constraints on every point, there will always be a direction where we can increase the value, the polynomial value. But if we impose our bots constraint, then this escaping direction may be towards a boundary, so we may still encounter local maximum along the boundary. Or in other words, local maxima should be on the boundary. So this kind of reveals the discrete nature of our framework, despite of its continuous appearance. So we formalize our intuition by proving that all local matzma are almost discrete assignments. So what do I mean by almost discrete? Let's say an example.
00:19:42.024 - 00:20:26.384, Speaker A: Now phi is x or y. Logically speaking, if one of x or y takes value two, then no matter what value the other variable takes, phi should always be true. This also holds in the polynomial world. So now f is the corresponding polynomial. And we can see on the plot that on the blue point, at the blue point we can, we can move the blue points along the axis without changing the polynomial value. So that means we can round the fractional coordinates, which does not matter at some specific point. So those points are so called almost discrete.
00:20:26.384 - 00:21:52.814, Speaker A: Because if we just reach this point, I think we should stop search and maybe do random restart, because continue searching is not useful at all. What we proved is that you can start from a fractional point at the beginning, but if you are able to converge to a local maximum, then you will finally end up with the following point where most of the coordinates are discrete, which means they are either plus one or minus one, while a small set of variables are fractional. But we don't care about those variables because changing the values of those variables does not affect the value of the fitness function. In other words, for a local maximum, rounding preserves the objective value. So this somehow gives us some guarantees about the solution quality of local maxima, because runding now does not harm, which is different from the case in both LP and SDP relaxation. Well, rounding tn cost loss to the objective. In other words, local maxima are meaningful and they do provide good quality solutions for some more relaxed problem like mat set.
00:21:52.814 - 00:22:50.836, Speaker A: I also want to answer the question about how fast can we converge. First of all, I want to emphasize that our framework does not limit anything about which optimizer you should use. So you can use any optimizer as long as it solves the constraint polynomial optimization problem. But here we will focus on the projected gradient ascent approach. For those who are not familiar with it, it is just general gradient ascent, but projecting the outlier back to the bottom region by finding the nearest point. Sometimes when it happens, the projected gradient will be different than the original gradient. A point is called a critical point if the projected gradient at that point is absolute small.
00:22:50.836 - 00:24:02.480, Speaker A: And one of our theorem is that if our framework uses projected gradient descent, then it will always converge to a critical point in polynomial steps. But what does a critical point look like? In most real life cases, critical points are just local maxima which we prove that they have good quality. But theoretically speaking, a critical point can still be a saddle point. So you can see a gap here. On one hand we prove that local maxima are meaningful, but on the other hand we can only prove that we will converge to a critical point. The reason this step exists is because of a saddle point is a critical point that is not a locomotive optima like this one, although in real life cases SATA point rarely exists, but in some crafted instances they can appear. For example, those are the gradient plots for absorbs.
00:24:02.480 - 00:24:53.634, Speaker A: You can see that just at the middle of the boolean box, saddle point exists where the gradient vanishes. But practically we observed that our framework seldom converts to such starter points. So an open question we raise here is to prove that our framework does not convert to the seller point with high probability. So till here I think the framework has been introduced. So in this slide I want to tell you some improvements that were made on this framework. In our newest paper where we use a new representation of boolean constraints called binary decision diagram. We use BDD to handle coefficient bounded pseudo boolean constraints.
00:24:53.634 - 00:26:08.874, Speaker A: Since the efficiency of computing the gradient is very important for continuous local search, we accelerated the gradient computation by BDD significantly. Also, we are aware of the fact that inside community converting to a global maximum is much more important than just having a local maximum. So we also used adaptive constraint weighting borrowed from discrete research to get better global convergence. So if you are interested in any topics of those, I encourage you to refer to our newest paper. So it's time to show you some experimental results. The highlight of our framework is its performance on some small size plain madsat computation, where our approach gives the best solution for most cases compared with other matchset solvers. While we also tested our tool on on some real hybrid boolean formulas containing xor and pseudo boolean constraints.
00:26:08.874 - 00:27:02.944, Speaker A: Well, we observed that our server is better than discrete load research servers, but it cannot match the performance of state of the art CDCL server or sudo boolean servers. Yet. Of course the state of the art servers are well engineered and usually the continuous operation is much more expensive than its discrete counterparts. So we believe that those results already show some great potential of this framework. On large industrial instances, the cost for differentiation is really too expensive, so we need to work on that. All right. In summary, we are motivated by handling constraints that beyond CNF, we want to explore the potential of continuous methods in set and set solving.
00:27:02.944 - 00:28:09.064, Speaker A: Our framework exhibits nice theoretical results, as well as interesting open questions as a continuous based approach. In practice, our server can act as a complement to existing servers. Since the framework can be decomposed into parts, it should be, it should benefit from the improvement from each area. For example, tracked both structures of boolean constraints and the techniques in continuous optimization. As for challenges and the future directions, first of all, the four gradient is really expensive on industrial benchmarks, so we want to compute imprecise gradients. Second, we also want to learn from discrete research to combine that with our framework to design a solver with better performance. Third, since the neurosymbolic approach is really popular now, our solver exhibits good potential of being as a layer of neural network, as a differentiable optimizer.
00:28:09.064 - 00:28:39.084, Speaker A: Also, we want to visualize the real value fitness function to see if we can find any insights of different logical formulas. We also want to connect our algorithm with some well known message passing algorithms like survey propagation. And we will dig more into this. With that, I would like to conclude my talk. Thanks for listening and I'm happy to take questions.
00:28:44.084 - 00:28:50.316, Speaker B: Thank you Zhiy, for a very nice talk. Looks like Jacob has a question, I think.
00:28:50.460 - 00:28:56.944, Speaker A: Yes, please. You mean in chat.
00:28:59.324 - 00:29:04.084, Speaker C: Do I get it right that this is an incomplete method that is good at finding solutions?
00:29:04.244 - 00:29:06.980, Speaker A: It is complete, yeah.
00:29:07.052 - 00:29:21.334, Speaker C: And so did you considering like combining it with some complete method that could do like the unsatisfiability part and maybe you would do the search part or this is on the list of things to do, or it doesn't work or.
00:29:22.354 - 00:29:48.324, Speaker A: Yeah. So if you mean by proving unsatisfiability by other completely different methods, yes, of course we can do that. But if you mean proving unsatisfiability by algebraic approach, like groups and basis, uh, like other approaches, then we, we think people have done that before, but they fail to scale well, so we haven't done that yet.
00:29:50.384 - 00:30:03.664, Speaker B: But there is, Jacob, there is interesting insight, for example, how you look at resolution from this algebraic perspective. So it turns out the resolution here translates to, to linear operations, right gue?
00:30:03.744 - 00:30:05.204, Speaker A: Yes, exactly.
00:30:07.024 - 00:30:10.912, Speaker B: So there is a potential to do, to add, for example, kind of inferencing.
00:30:11.088 - 00:30:18.204, Speaker A: Yes. So there is a potential, but it's hard to see how they can be as efficient as resolution currently.
00:30:22.024 - 00:30:23.604, Speaker B: Other questions or comments?
00:30:25.784 - 00:30:51.470, Speaker D: Yeah, I would have a question. So, like, would it not also make sense to have an imprecise encoding into BDD so similar like what the hooker and other colleagues from CMU are doing for optimization, like dropping those sort of high degree monomials you have in your four year, because you're only saying here on this conclusion slide, sort of imprecise gradient, but you could also do an imprecise, imprecise encoding.
00:30:51.622 - 00:31:17.760, Speaker A: Exactly. So I think using an exact representation of the polynomials corresponds to cut off some nodes of the corresponding BDD. So they are basically the same. It's just a spectrum method with keeping the major component. Okay, I have a quick question.
00:31:17.912 - 00:31:18.884, Speaker B: Yes, Oliver.
00:31:19.944 - 00:31:51.504, Speaker E: So, in the first part, for the basis depending, so you define that expected expectation depending on that variable a. And then in the second part, as I understand it, you optimize over that a. Now, that expectation looked, did not fully grasp it, but it looked natural to me. But are there alternatives to that, or do you think that's it? So that's the natural choice to that basic definition from the first part.
00:31:52.904 - 00:32:06.032, Speaker A: Well, so is a question about whether we can do better than defining a fitness function based on expectation. Can we use alternative definitions?
00:32:06.208 - 00:32:07.016, Speaker E: Yes.
00:32:07.200 - 00:32:10.992, Speaker A: Yes. So, do you have any comments, Moshe?
00:32:11.088 - 00:32:13.884, Speaker B: No. Maybe even change the probability distribution?
00:32:14.304 - 00:32:37.764, Speaker A: Yes, yes. Those are all promising directions, but we did try several different representations, but the expectation is the most suitable one because it is multilinear, which means it is somehow smooth and. Yeah, so it's a balance between. Is it computable, is it computable and precise?
00:32:40.224 - 00:32:52.384, Speaker B: So, last question, I'll read the questions from the, from embry, which is, did we consider to doing parallel search starting from multiple points and then using perhaps the power of GPU's?
00:32:52.724 - 00:33:25.514, Speaker A: Yes, that is definitely a promising direction, because our framework exhibits a good potential of that. So, yeah, I believe that the performance of our framework depends on how many trials you're doing, and if we can manage to parallelize it on GPU's, it would be very nice. But since the search contains some logical steps, it's not clear how to do it at this moment.
00:33:28.374 - 00:33:33.094, Speaker B: Okay, well, thank you. Thank you, Gwei, for the presentation. Thanks for all the questions.

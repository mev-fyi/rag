00:00:02.080 - 00:01:01.100, Speaker A: All right, thank you. So this talk is going to survey a couple of recent papers, a lot of it joint work with Shuchi Chala and Dennis Denikopalov, and also with my PhD student Sam Tigart, just as a public service announcement. So we're diverging in our day of mechanism design from mechanisms where we're going to run one mechanism that's worth billions of dollars, to situations where we're going to run billions of mechanisms worth a dollar. Okay? So that change is going to bring in very different kinds of techniques and methods for thinking about mechanisms which are going to be therefore very different. Okay, so I want to introduce you to the protagonist of this talk, and that is a first price position auction. So many of you are probably familiar with this concept. You have n positions.
00:01:01.100 - 00:01:36.310, Speaker A: These positions are ordered in decreasing weight. So the first position is the best, the last position is the worst, and you can think of the positions having corresponding allocation probabilities. So a bidder assigned to position I gets allocated with probability wi. Okay, I'll have n bidders. The values are drawn iid from a continuous distribution f. And I'm going to be studying what happens when bids are in Bayes Nash equilibrium. We'll typically look at position auctions where bidders are assigned positions by order of bids.
00:01:36.310 - 00:02:01.320, Speaker A: So all I care about is the order of bids in a position auction. I don't care about the actual magnitudes of bids. Okay. Bidders will pay their bid when they're allocated. So bidder allocated I is going to get received service with probability wi, and they're going to pay their bid also with probability wi. Okay, so here's how I like to draw a picture of this. I have my positions and I have these w's.
00:02:01.320 - 00:02:05.464, Speaker A: And this is the picture I tend to like to draw in my head. So there it is.
00:02:05.584 - 00:02:08.992, Speaker B: W two s. Too many w, two.
00:02:09.008 - 00:03:03.356, Speaker A: S. So the results that I'm going to talk to you about today are the following, coming from the three papers I had on the COVID slide in the exact same order. So I'm going to talk about a result showing you that the equilibrium in this IID position auction is efficient, symmetric, and unique. There's only one equilibrium in this auction. Okay, I'm going to talk about how you can do statistical inference in this auction, which may be useful if you want to optimize over all feasible allocations. You can allocate, given some constraints of the weights that you have to say optimize, say, revenue. You can do that.
00:03:03.356 - 00:04:01.472, Speaker A: We're going to actually be looking at optimizing welfare. And you'll see why we need to know the statistics as we get into the talk. So statistical inference is actually easy for these kinds of auctions. And then the last result that I'm going to talk about is that let's suppose you didn't have an environment that was a position auction, but you had any old single dimensional environment with linear utilities and independent values, which is sort of the canonical model of auction theory. If you have any of these environments, I can reduce that environment to I deposition auctions. And so in some sense, if you understand I deficient auctions, you can understand everything with these caveats. Okay, so with that said, you know, this model of auction theory, this auction in particular, is a fundamental auction that we understand very well, we should understand very well, and we actually do.
00:04:01.472 - 00:04:47.812, Speaker A: And so I'm going to go over that in the talk. Okay, good. So I'm going to start out with some motivation for why I care about, in particular the first price variant of position auctions and the first price variant of any auction. And that is the following. So auction theorists like to start doing auction theory with the revelation principle, which says that if you have an auction with a good equilibrium, there's always an auction, the truthful auction, that has the same quality equilibrium. And so you might as well, if you're doing auction theory, first restrict attention from all possible auctions to only the ones with truth telling as equilibrium, and then study those instead. Okay, so that's the revelation principle.
00:04:47.812 - 00:05:24.534, Speaker A: There's some issues with this. We actually saw some in the last section where the revelation principle didn't apply. And there's some more. So if you look in real life at these mechanisms, and again, I'm talking about the kinds of mechanisms where I have billions of them, each worth a dollar, those mechanisms are rarely truthful mechanisms. So the fact that we first restrict to the revelation principle means we're actually missing the mechanisms we actually care about. Okay, but good. The revelation principle says if I find a truthful one, there should be the one I actually want in that class, too, hopefully.
00:05:24.534 - 00:06:11.946, Speaker A: And actually undoing the revelation principle, going to say the first price implementation of whatever mechanism I want tends to give you ridiculous seeming mechanisms. We'll do this exercise in the next slide. Okay, so a conclusion from this high level discussion is that we maybe need a theory for understanding and designing non revelation mechanisms themselves from the beginning. Okay? And so I'm going to be talking about those kinds of ideas today. Okay, so here's the motivating problem I want you to have in your head throughout the entirety of this talk. Okay, so suppose I really want to solve this problem. I don't want to solve the I deposition auction problem.
00:06:11.946 - 00:06:49.664, Speaker A: I want to solve single minded commentary auctions in a bayesian environment. Okay, so I have m items n bidders bidder. I has value vi for a known bundle si of goods and no value for anything else. This is the standard single minded commodore auction model. But I'm going to study an eve in setting, so players value vi is drawn independently from distribution fi, and this can be different across the different players, so it's not iid like the position auctions was on the previous slide. Okay, so I would like to have a commentary auction with first price payments and a good Bayes Nash equilibrium. That's my goal.
00:06:49.664 - 00:07:24.954, Speaker A: Okay, why do I want this? Well, maybe because of some rules or something I'm required to having a first price auction, or maybe because of some other interactions. The second price auction isn't truthful. The ECG auction is not truthful anyway, so I don't care about it. And so this first price auction has maybe better strategic properties. So let's talk about that. Before I do, I'm just going to use notation capital x, the same way it was used in previous talks for the set of feasible outcomes. So Paul, Ilya and everyone was talking about this.
00:07:24.954 - 00:08:00.226, Speaker A: So this is just an indicator back here telling me who served, who's not served. And so if two players are served, it better be their sets of items that they wanted don't intersect. Okay, you can think single money commentary auctions. Throughout the talk, I'll be talking in general about any oldx you want. Yeah, are the sis private or. No, they're public. Okay, so the first thing I promised you I would do is I talk about undoing the revelation principle.
00:08:00.226 - 00:08:44.074, Speaker A: So if I want to design this auction, I start out in my theory land, taking the revelation principle, designing the truthful auction. That's VCG. Okay, now I want to undo that. And the way you undo that is to use revenue equivalents with a payment identity. We'll talk about that more later, but this is how it goes. Okay? So let's just look at if we were in VCG, what a player would pay, an expectation conditioned on them winning. Okay? And so for player I, with any value vi they might have, I can write the function si of vi as the expected payment they make conditioned on winning with value vi.
00:08:44.074 - 00:09:51.854, Speaker A: Ok, now what am I going to do in my auction? I get some bids, I'm going to then sort of guess that these sis were strategies and invert the strategy from bids to get values. Okay, well, now that I have values, I can use the VCG outcome by just finding the feasible set that maximizes the total surplus of values. Okay? And so then I output that and I'm going to charge winners their bids. And here's the sort of obvious when you think about it. Well, if I run this mechanism, what is the Bayes Nash equilibrium? Well, what is a Bayes Nash equilibrium? One of them is to use the player to use strategy profile s. Okay? And that's because it's the strategy profile that gets them exactly their VCG equivalent payoff. And it has exactly the same allocation rule as VCG and it has the same effective payments as VCG.
00:09:51.854 - 00:10:46.394, Speaker A: And therefore the Bayesian's calculation tells you that's in equilibrium. Okay, so is this a good mechanism? Do we like this mechanism? So this is really complicated because these strategy functions like, you know, and your mechanism has to know these and then the bidders have to believe that you correctly calculate these and it's just ridiculous, right? So it's complex, highly dependent on the prior. You need the prior to calculate these sI's, then you need to invert them. So you better need your inversion to not have like, you know, large jumps and stuff, because things are not changing very much and it's huge. There could be more equilibria if you did this noisily with algorithms that weren't quite right. As Paul and others were saying, this is just going to be a mess. Okay, here's another approach.
00:10:46.394 - 00:11:52.090, Speaker A: This approach is to follow the perspective of the price of anarchy literature. That is, let's look at simple mechanisms that are in this space that I'm going to plug my battery in, look at simple mechanisms in this space and prove that these simple natural mechanisms have good equilibrium. This is not really mechanism design, it's mechanism analysis. And you have to get lucky that you identified some simple things that happened to have good equilibria in the first place. Okay, so here is the simplest possible thing you might think of for a single mining common control auction. I'm going to ask for bids. I'm going to output the set of things that maximizes the weighted sum of bids, the weighted allocation by bid, right? So maximize the sum of bids of players you serve, okay, and charge the winners their bids.
00:11:52.090 - 00:12:57.394, Speaker A: It's first price, okay? And fortunately, the price of anarchy here is n, meaning there are example, commentarial auctions and distributions where there are equilibria base Nash equilibria where the welfare and equilibria is a factor of n from the welfare of the, of optimal outcome. Okay, so here's another mechanism you could run, and that is, well, instead of using the optimal algorithm to optimize your sum of bids, use a greedy algorithm. It turns out greedy algorithms have much better strategic properties, and so this equilibrium is going to be much better. And you can show that the equilibrium actually improves to root m rather than n. Actually, I probably should have said m there, where m is the number of items. So it goes from m to root m, which is much better. Okay, but look, a root m approximation actually is still really terrible.
00:12:57.394 - 00:13:45.114, Speaker A: Okay, so we still don't have simple mechanisms for this setting that are actually any good. Okay, so here is again our protagonist, the first price position auction. Unlike the setting of single mining commitorial auctions with asymmetric players, the equilibrium is always efficient, symmetric and unique. So it's always optimal. So this is a great situation, actually, finding equilibria is also really easy in this auction. And so what I'm going to be showing you in this talk is that this auction has great properties. And furthermore, I can use this auction to solve my previous single minor common turtle auction problem and get a arbitrary, close to optimal solution.
00:13:45.114 - 00:14:28.984, Speaker A: Okay, so it's going to be an approximate reduction I'm going to give you, but it's going to be like a ptas. It's going to give you, for any epsilon you want. It'll give you a one minus epsilon approximation. Okay, I'm actually going to do this backwards because I think the real motivation for me telling you all this stuff is this reduction in the fact that these position auction is just fundamentally important. So after I show you this reduction, I'm then going to show you all these nice properties, which hopefully you're then much more motivated to see. Okay, so the reduction, okay, so here's the environment I'm talking about. I have n agents.
00:14:28.984 - 00:15:06.294, Speaker A: They have independent values, not identically drawn, just independent. There's some feasibility constraint x. You're trying to optimize social surplus, say. Actually, all the methods I'm going to talk about today also apply to revenue, but I'm just going to focus on social surplus because it's easier. So here's the approach of the reduction. Okay, so let's consider each bidder, and in the auction they're going to bid some bi, okay, which means given that their value comes from the distribution, there was some function, strategy function mapping their values to bids. And so there's actually some distribution of bids that are coming from that bidder, the other bidders face.
00:15:06.294 - 00:15:48.270, Speaker A: Okay, let's suppose that I had t minus one other samples from this bidder's bid distribution. Let's suppose I had those. Then I could take this bid and calculate this bidder's rank amongst those other bids from the same distribution. Meaning where is this bidder in the order of all these bids? Okay, and then I'm going to given all the ranks of all the bidders who actually show up. And these are ranks of bidders amongst their own distribution, not ranks of these bidders amongst. I don't care about this is for bidder I only, I do this now, I have bidder eyes. Rank.
00:15:48.270 - 00:16:12.474, Speaker A: Suppose he's fifth. Okay, and suppose bidder j is second. So, given all these rank information, I then allocate to the bidders optimally, given the rank information only. Is there a question? Yeah. Once you've computed the ranks, do you throw the g distributions away, or are you taking account of the g's when you're up to lane? No, everything's thrown away, only the ranks. So rank information only.
00:16:12.974 - 00:16:14.714, Speaker C: This is me. Sorry.
00:16:15.174 - 00:17:04.744, Speaker A: We'll get there. Okay, so let's suppose I only tell you the ranks of some bidders, but, you know, their values are drawn from a distribution f fi for each bidder. Okay, so given I had t samples from a bid distribution, I told you this bidder is fifth, you could update your prior on their value to get a posterior distribution on what their value is, given that they're fifth. Okay. And given your update, actually, since you only use the ranks, all you care about is the expected order statistic of this bidder. So if he's fifth, you care about the fifth order statistic of your distribution. Okay, so what do you do? Given only the rank information, you calculate the expected order statistic of that bidder, and you then optimally allocate, given the order statistics.
00:17:04.744 - 00:17:34.592, Speaker A: Given the expected order statistics. So given the values, they have an expectation from your posterior, you allocate. So to do this, we need to know Gi, which is no, to do this, you need to know fi, I don't care about the order statistic of bids. I care about the order statistic of values. I want to optimize value. A bitter to even come up with the rank to do step two, we only need to know Fi. I'm about to fill in this blank space here.
00:17:34.592 - 00:18:14.188, Speaker A: You see all this space I have to fill in? Ok, good. So we're in the environment where we're running billions of mechanisms that are worth a dollar, which means where do I have all these distributions and stuff? Well, probably I ran the mechanism before. Okay, so imagine for player I, there's actually a population of players. And I actually ran this mechanism before on this kind of player and before I had other random draws. So I'm just going to say, let's just use t minus one previous runs of the mechanism to get these values. Okay, so now I don't need to know g, I just look back at my data. Okay, for the last t minus one times I ran this and used those bids.
00:18:14.188 - 00:19:02.564, Speaker A: And so each player I say, well, how did you compare versus the last t one bids I have of people in your role in the mechanism? Sorry, when you say expected order statistics, how would that, I'm not sure I understand the parenthetical remark. An order statistic is a random variable and its expectation is the expected one. So the fifth orc is a random variable. I just care about its expected value because I'm at the end of the day, get the expected value if I allocate to that guy. So I don't care what its exact value is. I need to know some information about the distribution. So this is not, so when I, before I put up this single mining common control auction, that inverted this strategy function.
00:19:02.564 - 00:19:11.846, Speaker A: Right. So we'd have to add some information too. I claim I have to have a lot less information to do this. We'll actually make that really formal, what information we need. Yeah.
00:19:11.990 - 00:19:21.502, Speaker B: So just understand the story here. We have sequential mechanisms and the participants are all different over time. So the participants today are all different from yesterday.
00:19:21.558 - 00:19:30.114, Speaker A: I'm gonna make the story very concrete in the next slide. Okay. So, but yes, what you think is gonna happen is gonna happen. Yeah.
00:19:30.454 - 00:19:33.606, Speaker C: Can you say something about why this assumption is importantly different from just knowing.
00:19:33.630 - 00:19:35.436, Speaker A: J, if you're doing this billions of.
00:19:35.460 - 00:19:37.036, Speaker C: Times, why not just say, you know.
00:19:37.060 - 00:20:20.904, Speaker A: G, if you're willing to say you can line up these previous beds as being from the same type of better, that's fine. However, I think working with an empirical distribution is better than working with an exact distribution because then I'm worried about how correctly I've estimated this. And all I'm saying is actually just use the t minus one samples that you have. Okay. So yeah, you could, I mean, I'm using a weaker assumption and it's sufficient. Okay, so what does player I think about this mechanism? Well, they're going to get one of these ranks because they're basically competing with other, the t minus one other copies of themselves to get ranked. Right.
00:20:20.904 - 00:20:48.554, Speaker A: And so what does my mechanism do to a player ranked five? Player I, if they're ranked five, it allocates to them with some probability independently of their bid. Okay. So if you rank five, you get some allocation probability for player. I. Should I be thinking of this I as being the same guy in each of these iterations or different people in the same role? Think of it never being the same guy. Different people in the same role. Yeah.
00:20:49.094 - 00:20:54.024, Speaker B: And you don't observe history, right? You don't know what the previous people did.
00:20:54.724 - 00:21:30.324, Speaker A: That's right. The players don't observe history. There's new players drawn from the distribution each time. So I want to state this again. So, from player eyes perspective, the outcome of this mechanism looks to them like a t player position auction, because I didn't use their bid information, I only used their rank information. So they're basically competing amongst the t minus one other bidders that came previously to be high ranked. And once I know your rank, this step two is going to induce a probability of service for every rank you could have.
00:21:30.324 - 00:21:59.144, Speaker A: Those are your position weights. So it looks to a player like a position auction. You can ask, how good is this position auction compared to the optimal welfare? And as you let t grow large, you would assume that you get arbitrarily close to the optimal welfare. Indeed you do. And that rate that we proved in this paper is something like root n over t.
00:22:03.004 - 00:22:16.112, Speaker C: So sorry, maybe I don't remember all the beginning, but this last theorem about the high welfare. What do you assume of the type distribution, these values?
00:22:16.168 - 00:22:21.640, Speaker A: It's independent, but it's a single dimensional, or players are single dimensional. Yes.
00:22:21.792 - 00:22:26.004, Speaker C: And it's just how much you allocate to them. That's all. There's no, okay.
00:22:28.744 - 00:23:01.472, Speaker A: This is the standard single dimensional linear utility model of auction theory. So these are results for any setting in that single dimensional linear model of auction theory. Okay, good. So I want to answer some of these questions I've had about exactly what is the model which I'm using for previous rounds. So here, this is supposed to be informal. So suppose I had these samples, for example, here, right? Now, let's try to make that more formal. Okay, so we're talking about the independent private value model.
00:23:01.472 - 00:23:53.436, Speaker A: I have n bidders, bidderized values vi drawn from public distribution. Fi, I want to start by asking the question, when does this model make sense? Okay, does this model make sense if we're going to run an auction once to sell billions of dollars of spectrum? No. Okay. In that model, we're going to have to, we probably are not going to be imagining people are responding to priors that are like this. Okay, this model makes sense in mechanism setting, settings of mechanism design where there's a lot of uncertainty in what's going on, there's a lot of uncertainty in who you're going to be competing with, which you, that's why you model uncertainty here. And we're able to learn about this uncertainty you have maybe by repeated interactions in the game or something. So something's happening a lot.
00:23:53.436 - 00:24:35.254, Speaker A: Okay, so I'm going to take the following population interpretation of the independent private value model, which is this. So let's imagine I have for each bidder in the stage game of the mechanism, a population. So I'll have n populations total. In each population, bidders have deterministic values, fixed values. Okay, then what do I do when I run my mechanism? I independently draw a bidder from each population and run the mechanism on that population. Okay. The thing I really care about is when we're doing a lot of this, so we're going to actually repeat this independently, maybe indefinitely.
00:24:35.254 - 00:25:13.214, Speaker A: Okay? And I'd like to have good mechanisms for this iterative population model. Okay? So I think I've answered probably the questions about exactly what my model is. This is my model. Good. So in this iterative population model with some feasibility constraint x, what am I going to do now? Making my mechanism more specific from the previous slide, I'm going to call it the ranking order statistic mechanism. So given my bids in each iteration, I'm going to calculate the rank of bid I from t minus one. Previous calls to the mechanism of this bidder, which is independent, draws from the same population.
00:25:13.214 - 00:25:44.184, Speaker A: And then I'm going to allocate the surplus to optimize the following thing. The surplus of expected order statistics of the values given the ranks. So for each rank of a player, I know what the expected order statistic is of people from that population with that rank for t draws. And I use those fixed numbers in my mechanism to optimize. In step two, as Ben pointed out.
00:25:46.744 - 00:25:48.204, Speaker C: Bidding behavior.
00:25:49.104 - 00:25:53.644, Speaker A: I am not studying a dynamic situation in terms of bidding behavior.
00:25:55.584 - 00:25:57.320, Speaker C: I'm assuming it's in equilibrium.
00:25:57.432 - 00:26:34.778, Speaker A: I'm assuming that bidders bid in equilibrium for what's happening, which is this. In fact, to look at what's happening, you have to figure out what each bidder thinks. So they get to play once, they never play again. Basically, imagine my population is a continuum, okay? And they to them it looks like they're drawn from an Ie distribution and they're competing for these ranks. So it looks to them like a position to auction. So that's the equilibrium that's going to happen, is the equilibrium of a position auction. Okay? Oh, I have that here.
00:26:34.778 - 00:26:51.514, Speaker A: So again, these players, the player I, is competing with these t minus one other players to be the one who's ranked each rank. And so they compete in this position auction because each rank corresponds to an allocation probability in this downstream mechanism.
00:26:53.014 - 00:26:53.342, Speaker C: Okay?
00:26:53.358 - 00:27:01.314, Speaker A: And as I said before, it's this approximation. Yeah.
00:27:01.774 - 00:27:08.032, Speaker B: You assume that in every period they know in which period they are and they play base and mesh equilibrium.
00:27:08.128 - 00:27:42.424, Speaker A: Given that information, it doesn't matter which period they're in, the periods are all symmetric. No, it's running forever. If you wish you could imagine an ongoing mechanism where the fundamentals are very, very slowly evolving, much slower than t. Okay, so t, for instance, like how slowly things evolve in your population, puts a bound on how big t can be. If you want, you can think of it that way.
00:27:43.564 - 00:27:45.796, Speaker B: You sort of like expect naively, that.
00:27:45.820 - 00:28:41.870, Speaker A: The rate would be square root instead of cube root. Is there a good reason? Yeah. So let me discuss the proof a second. So if you restrict to values that are bounded between zero and one, okay, then you could analyze the additive loss of this mechanism. And in fact, at a prior paper with Bobby and Azarosh, that you could interpret a theorem of that paper as actually proving this bound with a square root. Okay? Now the reason why we lose the square root and get the cubic root is to deal with the obstacles in going from a bounded range to the fact that there could be very rare people who have very high value. Okay? Now the bad thing about rare people very high value is when you look at their order statistics, they might not show up, they might not like influence the order statistic very much.
00:28:41.870 - 00:29:23.570, Speaker A: But when they do show up, you really want to serve them and you might not be because their expected oracle tick is low. Okay, so how do you address this? Well, people that show up very rarely but have very high value fortunately show up very rarely. So in fact, they never show up together and no one notices they show up. So you can basically do whatever you want for these guys. Okay. And so balancing these terms of never showing up and doing whatever you want is going to introduce the cubic terminal. Any more questions on this? Sorry, I'm still confused.
00:29:23.570 - 00:29:25.578, Speaker A: So it seems that in each round.
00:29:25.626 - 00:29:33.934, Speaker B: You'Re actually running a different mechanism because the map of your rank.
00:29:36.074 - 00:29:36.506, Speaker C: To the.
00:29:36.530 - 00:29:40.114, Speaker A: Order statistics is different according to the rounds.
00:29:40.274 - 00:29:46.274, Speaker B: But somehow you are assuming they're playing in the same same equilibrium gi.
00:29:47.214 - 00:30:28.690, Speaker A: So your first assumption was wrong. So in each round, I'm running the exact same mechanism. But actually another way to think about this that might help you is imagine instead of for each player looking back t minus I rounds, instead it's batching groups of t. So let's take t rounds of this mechanism, call it one mechanism. Instead of looking back, I also look for each player, I look basically over that interval of window t. And then you exactly get this position auction interpretation. And then observe the following for each player I, there's no difference in looking back t minus k and forward k, and just looking back t minus one in terms of what you do.
00:30:28.690 - 00:30:34.950, Speaker A: That's an equivalent probabilistic question to them. Yeah.
00:30:35.022 - 00:30:57.622, Speaker B: So now it's basically a game. It's not just a game with the players who are simultaneous with you, it's a game in which you're playing with all the past players and future players as well. Right? Because you're what you get depends on that. So if the theorem says for any Bayesian mesh equilibrium of this big game that has this infinitely many players, this, you get this approximation.
00:30:57.798 - 00:31:22.914, Speaker A: So there's, let's talk about uniqueness of equilibrium in first place position auctions. The theorem is that for each agent I. This looks like a position auction. Okay? You are not actually competing. It's like the problem they are solving is equivalent to a position auction. Okay? There's a stationary distribution of bids that you get in these auctions, and you're specially in those bids. There's only one equilibrium there.
00:31:22.914 - 00:31:56.822, Speaker A: So there's only one thing that happens. And actually, I would love to now talk about that. Okay, so how do you prove uniqueness of equilibrium in an auction? You show that there exists an equilibrium that you like, so the welfare optimal equilibrium exists. I'm going to skip that. That's standard. Then you show that among all symmetric equilibrium, there's only one, and that's also standard. Both of these use the revenue equivalence theorem, and then to show non existence of asymmetric equilibrium, you could use a bunch of differential equations.
00:31:56.822 - 00:32:39.934, Speaker A: What I'm going to do is show you the revenue equivalence proof of this result that there are no asymmetric equilibrium using only revenue equivalents. To do that, I need to tell you revenue equivalence, which is starting from the standard Bayes Nash equilibrium calculation of Myerson. The allocation rule from a player as a function of their value in equilibrium is xi and it's a function, increases in their value, and the payment they get is given by this formula let's understand the formula. So, here's xi monoton increasing. This term vixi just gives you a square of width vi height xi. This integral is the area underneath the curve. That's that.
00:32:39.934 - 00:33:00.112, Speaker A: Okay. And so the payment has to be the area above the curve. Good for you guys for this talk. All I care about is, is this. If you tell me the allocation, the utility is the area underneath the curve. Great. This is known as revenue equivalence.
00:33:00.112 - 00:33:27.138, Speaker A: In fact, the payment identity and revenue equivalents are basically the same thing that auctions with the same allocation rule have the same revenue. So now I want to show non existence of asymmetric equilibrium. I'm going to restrict to just a single item auction here. The proof extension to position auctions is almost no extra work. And this will simplify the notation. So we'll do that. Here's a first theorem you might want to show.
00:33:27.138 - 00:34:07.024, Speaker A: Suppose I have two players in a first price auction with a random reserve that we don't know in advance, but we do know the distribution of it. Then this two player auction has no asymmetric equilibrium. That is going to imply a corollary that in n player first price auctions, there are no asymmetric equilibrium. Why is that? Well, player one and two face a random reserve given by the distribution of bids of players three through n. So players one and two have to have the same symmetric equilibrium here by the theorem. Okay, but then repeat the same argument for players one and I. So everyone's playing the same strategies.
00:34:07.024 - 00:34:44.224, Speaker A: Okay, so it suffices to prove this theorem. This is the theorem I'm going to prove on the next slide using revenue equivalence. Okay, so how do all revenue equivalence proofs work? They work by using two equations. For some of the fundamentals of the problem, I'm going to use utility. So, two equations for the agent's utility, we have equation two, which comes from the revenue equivalence formula. This came from the previous slide characteristic of equilibrium. It's the integral of the area underneath the allocation rule.
00:34:44.224 - 00:35:32.284, Speaker A: But if it's a first price auction, I have another equation for a player's utility coming directly from the definition of the auction rules. So if they have value v and they bid s of v and they win with probability x of v, their utility is their value minus their bid times the probability they win. That's from a first price definition. Okay, now I have two equations for utility. I'm going to use those to get a contradiction in multiple equilibrium. Okay, so my proof is by contradiction, and I'm going to assume that strategies cross twice if they cross zero times or one time. A variation of the exact same proof can argue that can't happen either.
00:35:32.284 - 00:36:19.728, Speaker A: So we're just going to see one of the parts of the proof, which is when they cross twice. So here's my picture. I have value space here, and I've drawn the bids that pitters are making as a function of their values. And here's bidder one beating out bidder two over some interval where they cross twice. Okay? I'm trying to prove that can never happen. Okay, a claim I'm going to use as a subclaim here, which I'm not going to actually show, but it's kind of obvious, is if at the same value player one is bidding higher than pL2, then player one is also winning with higher probability than pL2. In that equilibrium, it's kind of obvious.
00:36:19.728 - 00:37:23.338, Speaker A: You have to write it down and be careful. And I'm not going to do it. Let's just assume it. So I have these strategies across this point where pL2 one is outbidding pL2. So we conclude that the allocation rule of player one is strictly bigger than the allocation rule of pL2 on this entire interval. Okay? Now by equation two, one of my equations for utility, I can write down the difference in utility of player one for values on this interval. So the difference in utility from v prime to v double prime to v prime is this area underneath the curve here, okay? By the fact that x one is strictly bigger than x two on this interval, that is strictly bigger than the difference in pL2's utility, okay? But now let's use claim one and equation one, our second equation.
00:37:23.338 - 00:38:04.598, Speaker A: So claim one says this inequality holds, but it's equal if they're equal, okay? And so at the endpoints v prime and v double prime, they're exactly crossing. And so their allocations are equal. So if their bids are equal and their allocations are equal, then by equation one they have to have the exact same utility, which means their difference in utilities must be the same contradiction. Yeah, so it seems like there's some continuity of strategies being imposed. In fact, I did assume that. I didn't say it out loud as on my previous slide. For this talk, I assume continuous strategies.
00:38:04.598 - 00:38:11.624, Speaker A: In the paper we do discontinuous ones. This is the main idea though, and that you can see much more cleanly with continuous strategies.
00:38:12.444 - 00:38:14.636, Speaker B: So where did you use the unknown reserves?
00:38:14.700 - 00:38:58.404, Speaker A: The unknown unknown that was on the previous where did I use it? And claim one has to argue something with this reserve, and I don't need to use the reserve. I just need to make sure it's robust to that and claim one deals with that. Okay, inference. Before you go to inference, what is the broader setting in which you can show uniqueness? This is rank based rules with payments based on your bid, not other things that are happening. Okay, so GSP, the second price payment rule, which where your payment based on other people's bids doesn't hold, Unicos doesn't hold, and we know you can still hold for second price rules.
00:38:59.194 - 00:39:18.274, Speaker B: So in the actual auction, so to understand the reduction to the position auction, so you don't care about getting higher position, but how much you care about that depends on the strategies of the other builders that are playing with you. Right. Higher rank will give you make me more likely to win, but that also depends.
00:39:18.314 - 00:39:33.804, Speaker A: No. So I want you to remember that once I compute these expected values every suppose you're player one, there's some other pL2. So pL2 is uniform from all of their ranks, always.
00:39:35.344 - 00:39:37.520, Speaker B: What if he uses a different strategy?
00:39:37.712 - 00:39:44.176, Speaker A: No, pL2 is always uniform amongst their bids and therefore is uniform amongst the ranks.
00:39:44.240 - 00:39:47.648, Speaker B: I assume that he uses the same strategy today as he was using yesterday.
00:39:47.736 - 00:39:48.432, Speaker C: Yes.
00:39:48.608 - 00:39:50.100, Speaker A: No, these are different bidders.
00:39:50.272 - 00:39:55.340, Speaker B: So what I'm thinking about. What about equilibria where players use different strategies and different.
00:39:55.492 - 00:40:25.044, Speaker A: So let's talk offline because I want to talk about inference. So there is no problem with that. Let's talk offline. Okay, let's talk about inference. So I want to talk about a very specific three bitter example setting to talk about inference. So auction a is selling one item to one of three bidders. Auction B is selling two items to three bidders.
00:40:25.044 - 00:41:22.058, Speaker A: And I'm going to consider auction c, which is mixing between a and b, which is going to sell one item and half an item. And this looks like a position auction. Okay, the question I want to ask is if, suppose I've observed bids in c, can you estimate the revenues of a and b? So if I run one auction, can you estimate the revenues of another auction? And it turns out if these auctions are all position auctions, this is a really simple task. Okay, just to give you an overview of the results, we're going to talk about, if you have n bid samples from bid c, you're doing an n position auction and your auction b, you ran with probability epsilon. Okay, then I can estimate the bids of the revenue of a and b directly from bids in c directly. I never infer values, so directly inferring revenue. Okay, my estimator is very simple.
00:41:22.058 - 00:41:43.904, Speaker A: It's a weighted order statistic. What does that mean? I have some weights I've computed beforehand. I take my bids, I sort them, I take the weights and I multiply them point wise and sum them up. And that's my estimator. Okay. No complicated bandwidth functions or anything that you usually do if you're doing this kind of inference. My timer says four.
00:41:43.904 - 00:42:00.848, Speaker A: So the rev investor is a way to order. I mean, I can stop in one if you want. I'm just saying my timer says four, you only stop in one.
00:42:00.996 - 00:42:02.124, Speaker C: That's in the curious.
00:42:04.504 - 00:42:57.024, Speaker A: So, this estimator for revenue b has error that this is the bound we were able to prove for it. It's the standard square root, the number of samples you'd expect. And then you have some terms based on the number of players in position auction, and most significantly, the dependence on epsilon. The probability that you actually ran b is logarithmic in one over epsilon. And this should seem quite surprising, because if you actually did an ideal controlled experiment where you sent epsilon traffic to a and got the bids in a and one minus epsilon traffic to b and got the bids in b, and then just added those revenues up, then you'd have error, basically square root of one over epsilon, right? Because the number of samples you have is epsilon. Nice. So the error would be square root of epsilon n.
00:42:57.024 - 00:43:38.998, Speaker A: Okay, so we get this bound. Let's see, I have 1 minute to tell you how this works. So, this is the standard way you do econometric inference. So you basically solve for the bidder's values in terms of their bids. And you get this as the equation to convert bids into values. And the big annoying thing here is you need an estimator for the derivative of bids. Okay, this is bids and derivative bids and some allocation rules.
00:43:38.998 - 00:44:21.944, Speaker A: Okay, you then plug in your values and solve for equilibrium and calculate revenues. This is the equation for revenue in auction, given the values, okay, if you do this by calculating values, you have to do all this stuff that gets really bad rates and stuff with bandwidth functions, decimal derivative of bits. So what we do is we actually just plug these equations together before we try to do anything. And then we have an integral with a derivative which we don't like. We integrate by parts to get rid of it, and we get a term that looks like this. Some coefficient times the bid function, which is if you then look at it at even intervals of one over n gives you a weight or a statistic. And so that's that.
00:44:21.944 - 00:44:52.254, Speaker A: To conclude, id position auctions, they're actually implicit in every independent private value model. So therefore, something worthy of very careful study. And I showed you they have all these nice properties and. Thank you. I still have 1 minute.
00:45:06.734 - 00:45:07.574, Speaker C: Well, thanks again.

00:00:00.640 - 00:00:50.220, Speaker A: So hi everyone, I'm very happy to introduce our reason work. So this is joint work with Grant Schenebec. Let's start by considering a scenario where we have two agents, Alice and Bob. They want to predict their election outcome. And the outcome is a random variable W, which can be D or Alice has a private information xa. Bob has a private information XB and they want to exchange their possibly very complicated private information according to some protocol. And they also share some common knowledge like their joint distribution over their private information and their outcome W.
00:00:50.220 - 00:01:55.880, Speaker A: So basically Z just on alternate making announcements that can depend on the private information and the previous announcements. And one example can be the just alternate announcing their posterior belief about the election outcome. So here is a concrete example. So considering, I mean their conditioning on the icom they are private information, just like ID bits and conditioning on the outcome is like D wins in the end, the Probability Alice receive one will be 90% and same for Bob. And I mean the prior probability for the outcome is 50 50. So they have this prime information, Alice receives 1, Bob receives 0. And first Alice will declare her posterior conditioning on her private information, which is 1.
00:01:55.880 - 00:03:09.188, Speaker A: In such case she will believe with 90% probability D wins. And then Bob actually can infers from Alice declaration first that Alice actually receives one. And in that case Bob will update his belief to this posterior conditioning on his private information zero and the fact that Alice received one and in such case go back to 50% and Bob will announce the belief. And in that case, because Alice knows that Bob already infers her information and report aggregated information. So Alice will update her belief to 50% too and announce it and the distribution agreement. So in fact Allman proves that like regardless what what protocol they use, as long as like their belief for this probability is a common knowledge between them. And in that case they must have the same belief.
00:03:09.188 - 00:04:20.272, Speaker A: And in other cases like they just cannot agree to disagree. And here comes two natural question and the first question is okay, how long they need to reach this agreement to have this common knowledge? And also does this agreement imply that they are private information already being aggregated? And to the first question Erin said in 2004 proves that they can actually reach their agreement quickly. So basically it depends on how they agree in the end. But even though they can reach their agreement quickly, still we have the question does this agreement mean for? And sometimes the answer is no. Let's consider this counterexample. So here we come to this different situation. In the previous situation, Alex and Bob's and private information Are independent conditioning on the outcome.
00:04:20.272 - 00:04:56.172, Speaker A: Here they are private. They are just like each of them flip a coin independently and the outcome depends on the xor. Sorry, the outcome is the xor of their results of the coin flips. In such case, their private information are independent. But conditioning on the outcome, it is not independent. It's just like the opposite case of the previous example. And here in this case, let's assume that Alice receives tails and Bob receives tails.
00:04:56.172 - 00:05:51.820, Speaker A: And first Alice will declare 50% which is her posterior belief conditioning on her private information. But in fact no matter, Alice receives heads or tells she will they hurt her posterior belly of his 50%. In such case, Bob infers nothing from Alice's declaration and he will report his posterior belief based on his private information. Still 15 and same thing like Alice won't infer anything from that either. And they just reach agreement. But this agreement actually, I mean, doesn't aggregate the information, because if we really explicitly review their information, they could determine the outcome. So here in this situation, they reach agreement, but it doesn't mean aggregation.
00:05:51.820 - 00:06:49.934, Speaker A: And we call this scenario false agreement. And if it's more than two people call it false consensus and then the question changes. Okay, if we already show that agreement may not imply aggregation, then we are curious then when does agreement imply aggregation? And this is a question this paper is interested in. So we actually provide a natural information theoretic framework to solve this question. And it also reproves these previous quick consensus results. Okay, so here is the main theorem. So we consider scenario where Alice and Bob's private information are conditionally independent conditioning and outcome.
00:06:49.934 - 00:08:09.640, Speaker A: And intuitively it just means that they are private information similar, they're just like substitutes. And we show that in this substitute setting, no matter what communication protocol they use, actually approximate agreement, we will like formally define agreement later. Actually implies that Z actually gets this on approximate aggregation. So basically their agreement almost their agreement approximately aggregates all of their private information. And okay, so before we talk about the formal thing, let's talk about this high level proof. So the key lemma here is that if their information satisfies the substitute structure, we can prove this sub additivity is like the value which we will define it formulate later. So the value of their the value of their private information is less than the sum of the value of their individual private information.
00:08:09.640 - 00:08:41.840, Speaker A: Okay, so this is this sub additivity. And with this sub additivity we can prove that. Okay, so conditioning on the history, everyone agrees like approximately. And in that case it actually implies that conditioning on the History like we're. I like the. Sorry. If like Alice agrees approximately, which means that her private information is has a small.
00:08:41.840 - 00:09:46.210, Speaker A: Like it's like its value is small now and also like the value of both private information is also small. I mean otherwise they will disagree. And then the important thing like because of this sub additivity, if the individual value is smaller than the value of even we put their private information together is also small. And if like if even we put there together is also small condition on the history, it means that the history has already aggregated all information and that means aggregation. So here is this high level proof for this main result. And we are see that using the right information theoretic framework, this definition for value and the sub additivity, they can all like follow naturally. Okay, so let's talk about the formal proof.
00:09:46.210 - 00:10:34.908, Speaker A: So we first introduce some information theory backgrounds. Even if you're not very familiar with it, we can just talk about this high level idea. So considering we have three random variables X, Y, Z. The entropy of a random variable measures uncertainty of the random variable. So if it's not random, it's deterministic, it has zero entropy. And the conditioning entropy regarding two random variables, it means that conditioning is kind of like given one random variable, what is remaining uncertainty of the other random variable? Expectation. And the mutual information measures, they are like shared information between them.
00:10:34.908 - 00:11:40.940, Speaker A: It's kind of like their correlation. And here is similar analogous definition for the conditional mutual conditioning given some like Z was the remaining expected shared information between X and Y. And here comes a not very commonly used information theoretical concept which we call this interaction information. So it actually measures like the shared information among three random variables. It can be also written as a mutual information between X and Y minus the conditional mutual information between X and Y conditioning on B. So in fact we can understand everything intuitively using this Venn diagram. So the set each individual set can be understood as this entropy individual entropy and the like important thing is this like this intersection of these three things.
00:11:40.940 - 00:12:18.480, Speaker A: We can understand it as this interact inter. Sorry this interaction information among these three variables. And we can also like this conditioning thing is like some is is. Is also like the differ operation in the set theory. So basically we can understand everything using this Venn diagram. And using with this background we can formally define what does that mean for this approximate agreement. So so we see like around T.
00:12:18.480 - 00:13:41.650, Speaker A: It changed this approximate like more than two people approximately. A consensus mean that for all individual agents the mutual information between her private information xi the outcome W conditioning on the history like HT is history conditioning on the previous like the H3T round announcements is less than epsilon. So basically this another thing that like conditioning on the T runs history agentized prime information has more mutual information with outcome. Intuitively it just means that this is like individual value of this private information is not very significant here. So in that case we just see that it's like for all agents satisfy this inequality. We just say that they all reach this epsilon mutual information consensus. Okay, and then we can prove this lemma things are like if we have this substitute structure and then we will have this sub additivity.
00:13:41.650 - 00:14:50.440, Speaker A: So basically it's a kind of like modular thing here is like when X and Y are independent continuing on Z we can prove first D have a non negative interaction information. And that actually implies that this conditioning on X thing will reduce the mutual information between Y and Z. And it's like also similar for like this is just all symmetric. So it's the same for like YZX or zxy. And then this actually implies this sub additivity. Like the mutual information between the N X and Y is less than the mutual information between D and X plus the mutual information between Z and Y. These three things can be actually proved by this Venn diagram.
00:14:50.440 - 00:15:51.224, Speaker A: So the reason why independence like the first like the non negative interaction information because we can write down the interact in the interaction information among X and Y and Z as the mutual information between X and Y minus the conditional military information between X and Y conditioning on z which is 0 when x and Y are independent conditioning on Z. So in that case we have it just equals the mutual information between X and Y. And mutual interaction information can be positive, can be negative, but mutual information is always positive. It's one parting property. And because of that this is positive. And for other conditioning or reduced conditioning reduce mutual information cell addictivity, mutual information. We can just prove that to the chain rule.
00:15:51.224 - 00:17:15.490, Speaker A: Or I mean use this Venn diagram. Just think this mutual information as intersection and this conditional thing as like different like operation. Okay, So I mean this is like if we have this information theoretic background and then we can easily prove that when this is substitutes we have these sub additivity of the mutual information. And that actually provides us a formal proof for our main result. So after T runs we have like the H, the capital HT represents all the public announcements during the T rounds. And after two rounds we get we aggregate the amount of information we aggregated is the mutual information between the trunks announcement HT and outcome W. But in Fact, if we can explicitly review our agent's private information, I mean the total amount of information we can aggregate is the mutual information between all private information x1, x2 until xn and outcome w.
00:17:15.490 - 00:18:27.390, Speaker A: And in such case the amount of information that hasn't been aggregated is the R difference. And by using some chain still we're just using the chain rule. Again, this exactly is the conditional conditional mutual information between all people's private information and W conditioning on the history. And in that case we can just use the subjectivity if they are, I mean if they are all if conditioning on W or people's private information independent like this substitute thing, we can prove this. We just generalize our previous lemma to n people and prove this sub additivity for n agents. And in such case the conditional mutual information between all private information W conditioning on history is less than the sum of this individual private information. The mutual information between private information xi and W conditioning on the htree.
00:18:27.390 - 00:19:32.678, Speaker A: And I mean as we defined before here they already reached this epsilon among epsilon mutual information consensus. So the individual mutual information will be less than epsilon and in total you will less than an epsilon. So here this is like this formal information theoretic proof. And in fact like we mentioned before, within this information theoretic framework we can also prove this quick consensus result quickly. Like basically we have a very natural potential function which is aggregating information like we mentioned before, the mutual information between these G runs and public announcements and W. And also we need to kind of like analyze the growth rate of this potential function. And this is like this amount information of their declaration.
00:19:32.678 - 00:21:05.774, Speaker A: Like we just use this small hit to represent at round T agent I's public announcements. So basically the growth rate basically equals the conditioning of mutual information between agent eyes public declaration like for Agent 9, like her public declaration and outcome conditioning on what happens before she makes her announcements. And here comes to this quick consensus thing. So basically when some of them has large disagreements, they just disagree with like with other people. In that case, her private information actually has a very high value. And in that case if the protocol is defined properly and we just use the protocol like paper, they just exchange their posterior belief or they just doing this discrete version their posterior belief follow from Aronson 2004. Within that protocols we can show that if their private information has a high value, then their public declaration will also have high value.
00:21:05.774 - 00:22:25.870, Speaker A: And this actually implies that the potential, the growth rate of this potential function is large. And this potential function is always, I mean, I mean the mutual information of the mutual information between the history and outcome is always less than the entropy of this outcome is bounded. In this log two base is bounded by one and in that case the potential function is bounded and it has a high growth rate. And I mean it's just like we will reach our consensus pretty soon. And it also has a connection to this prediction market. So basically, if we are considered prediction market with log scoring rule and people they just change their belief from this current posterior belief to their to the to their current the current posterior belief according to conditioning on the history and to the posterior belief conditioning history and her private information. In that case they will be paid this conditional mutual information thing.
00:22:25.870 - 00:23:01.070, Speaker A: And then this epsilon mutual information consensus means that they cannot make a lot of money expectation using their private information. And the quick consensus means that the market will quickly reach account conversions. And there's no first consensus substitute. This means that one paper's information structure satisfies substitutes. Then the convergence implies aggregation. Okay, so here is a summary. We propose this information theoretic framework.
00:23:01.070 - 00:23:23.600, Speaker A: It can help us easily prove that no false consensus with substitutes. And we also prove this quick consensus. In fact, we will prove another strategic revelation result. And you can read the papers for more details and future. Hopefully this framework can be employed in other scenarios like learning, like social network. Thanks.

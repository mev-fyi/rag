00:00:00.680 - 00:01:05.204, Speaker A: I'd like to thank the organizers for inviting me here, and thank you for coming to the talk. This talk is booster population on random graphs. In particular, I will focus on booster calculation on the random graph. This is based on joint work with Tama Shimakai, a postdoc of mine at Tu grads. So what is booster population given a graph? And we also given a so called infection threshold r, which is a natural number. And what we do is that we start from a so called, a set of initially infected vertices. So we know that there is a set of initially infected vertices, and then in each step every uninfected vertices becomes infected if it has at least our infected neighbors.
00:01:05.204 - 00:02:18.896, Speaker A: It's a kind of deterministic process and it's just that we infect everything if it has our infected neighbors. And once it is a vertex become infected, it becomes infected forever. And this posterior percolation graph has been introduced a long time ago on batty lattice. Perhaps the physicists know better about batty lattice in the context of disorder system, but I will not talk about it because I don't know much about it. But then the dependency between the final set of infected vertices on the set of the size of the set of initially infected vertices has been studied a lot. So how big should be the initially infected vertex set, so that perhaps almost all the vertices become infected in the end? Or maybe only a small number of additional vertices might be infected depending on the size of the initially infected vertex set. And this has been studied a lot on infinite trees, finite read, and also random graphs such as random regular graphs.
00:02:18.896 - 00:03:10.424, Speaker A: We have seen a lot of nice results on the random regular graphs in this conference, and also the air dose ready random graph GNP, or the so called Biden random graph GNP, and as well as in homogeneous random graph. And sometimes we call here in this community stochastic models in a very, very general setting. But in this talk I will focus on the graph setting in g and p. As I said, we have a freedom of the infection threshold. So let's say r equals one. What happens to just do the synonym to check when r equals one? It's kind of simple. Given every vertex, if, if it has at least one infected neighbor, it will become infected because the infection threshold is one.
00:03:10.424 - 00:04:30.546, Speaker A: As a result, a component containing any component containing at least one infected vertex will become eventually infected. What does that mean? Is that any component containing at least one infected vertex will eventually infect it. It's kind of easy to analyze. Therefore, from now on I will focus on the case when the r the infection threshold is at least two, and throughout the talk I will denote by a the set of initially infected vertices of given size, say a, and which will be chosen uniformly at random among all the sets of vertices of given size a. Of course, by symmetry we can take any deterministic set of that size. So without loss of general theorem, I will assume that a, the initially infected set will be a set of integers, one through a and a of f or s of f will we will denote the final set of infected vertices. As I said, a lot of study has been made between the relation or the behavior of the final set, or the size of the final set versus the size of the initial set.
00:04:30.546 - 00:05:27.884, Speaker A: So as this conference is about phase of transition, so natural question is there of phasor transition in terms of that, or is there any threshold phenomena? If so, what is the critical value? And if so, then what is the width of the critical window? These kind of things has been studied, among others, by Janssen, Uchak, Trova and Valje. So there are other works, but I will just focus on this one as I would like to talk more on one of the things that they have shown. Indeed, this is dramatic simplification of their wonderful work. More than 50 pages of the paper I just put on this one slide is, among other things, what they show is the following. So we say we fix the r infection threshold. We fix the size of the infection initially infected set. What we can vary in this world is the probability distribution.
00:05:27.884 - 00:05:49.744, Speaker A: So h probability p. If the h probability p is at least n to the minus. So one over n much much. It's not fixed. It will also be a parameter. So what you can imagine fixed rubber, I will fix p satisfying this range. I fix p.
00:05:49.744 - 00:06:09.032, Speaker A: So there are two models. Did you ask question correctly? Because I was messing with. So there can be two models. When you want to change something, you can fix r and p and change the size of a. Or you fix r and p. No, no, sorry. A and change the p.
00:06:09.032 - 00:06:53.534, Speaker A: I will talk about the model where I will fix p and change a. There are two models, but I think I messed up. Thank you. So now fix fix p satisfying this one over n is much much larger than one over n, but much much smaller than n to the power of minus one over r. Given any such p, what we can show is that with high probability there is a threshold such that if the size of an initial infected set is smaller than a critical, then only a few additional vertices are infected. Just to denote it in this session. Although as I said it's much more is known.
00:06:53.534 - 00:07:29.294, Speaker A: On the other hand, if the size of the initial infected set is larger than acritical, then with a high probability almost every vertex becomes impacted in the sense that the final set is over n. And as I said, I overly simplify the result. Indeed, we do know the explicit formula for the a critical. The critical size of the initial infected set, as well as the width. Width will be the square root of the critical value. So we know almost everything. But as I said, the results hold with high probability.
00:07:29.294 - 00:08:34.286, Speaker A: On the other hand, I didn't write here the result. It's not that because it's boring, but because it does have a different behavior and kind of simpler. So let Br is now at least two, and for example, when p is equal to a big o of n to the minus one, we know that the GNP consists of either only of small components. If the p is much smaller than one over n, or if it's an average degree is bounded, let's say d, then we do have a giant component and a lot of small components. So still what is clear is that in this regime we do have lots of small components. So in order to infect almost every vertex it's clear that we have to infect. We have to start with the vertices which are infected and lies on each of these small components, like in this picture.
00:08:34.286 - 00:10:02.562, Speaker A: In order to infect almost everything in this regime, as I said, because it consists of so many small components, we have to start with almost every vertex infected, everything in that component. Of course, when p is, if the graph has average degree constant, average degree, it's a little bit more sophisticated. But nevertheless you can show that in order to have almost every vertex being infected, you have to start with almost every vertex infected initially. So in this regime we had two kind of constraints, and now in this regime, why this regime is kind of separate, let's say in this regime, theta of n to the minus one over r, if you look at it. So say this is a set of infected vertices and look at a vertex and check whether there are at least our infected neighbors. Of course we can easily checked the number of infected neighbors. Number of vertices, expected number of vertices, sorry, with at least our infected neighbors we can compute easily neighbors, we can compute it easily because it's sort of binomial coefficient.
00:10:02.562 - 00:10:46.866, Speaker A: This is roughly n times. So I have n minus infected vertices. If we are in the initial case, then it's almost n times p to the r. But on the other we are in this regime. So this is just constant. So we have a constant number of expected number of vertices which has at least r infected neighbors with constant probability. Maybe we will infect such vertices on the other one can show that indeed, if you start with the initial set of infected vertices of constant size, if this constant is at least r, then with the positive probability there will be almost all population, meaning almost every vertex becomes connected.
00:10:46.866 - 00:11:24.538, Speaker A: It's kind of rather easier consequence. And if you're looking in this regime, if the p is much much larger than n to the minus one over r, now this quantity becomes infinity. And then you can also show, using other method that indeed also any initial set of constant signs eventually spread to the entire set with high probability. So there is an interesting regime here as well. But as I said, I will focus on this regime. We want to improve this part. As I said, much of the results are known, as I will show you in the next slide.
00:11:24.538 - 00:11:59.724, Speaker A: But our target is to show this not with a high probability, but exponentially high probability. One of the motivation was because Valliere asked us to do that in some conference because we had other results. And then he asked us whether we can do this also for GNP. And we walked a little bit and played a little bit in India, despite surprisingly there were very elementary mathematics to show this. So all from now on the formulas may look complicated. Mathematics behind it will be very elementary. So now we fix r is at least two p.
00:11:59.724 - 00:12:50.784, Speaker A: As I said, the most interesting regime, p is much, much larger than n to the minus one and much much smaller than n to the minus one over r. Now I will show you many technically looking quantities, but I will explain later. Hopefully we'll be able to explain how how these quantities appear. Naturally, the first thing will be our kind of time, t zero. Let me also why this time is this quantity one plus delta, which will influence the kind of failure probability later times one minus r factorial divided by n times r power of p to the one over r minus one. I promise that I will show you why these quantities appear here delta. We want to wish to make it as small as possible because it will be influencing the exponential failure bound.
00:12:50.784 - 00:13:35.850, Speaker A: But the way we make our proof so elegant, I mean very short proof, we had to use the result on giant component in order to apply that particular technique. We have some restrictions, technical restriction. So delta should be larger than n times p to the r. Because of that restriction, we know that this quantity tends to zero. But then we raise to the power one over two times r of r minus one, and it should be larger than n times p. Now, n times p is a growing number. So we put some negative power minus one over four times I minus one, as I said, due to the condition of p, this delta is little of one.
00:13:35.850 - 00:14:11.334, Speaker A: As I said, we want to make it as small as possible, but this is what we can do. Then there are two other quantities. There are more essential. To define it, we need the probability that binomial distribution with parameters t and p is at least r, which I denoted by PI of t. Then I was telling this a critical. The critical value for transition in terms of the size of the final set is this quantity. So, minimum minus minimum of n times PI of t minus t divided by one minus PI of t.
00:14:11.334 - 00:14:44.990, Speaker A: Why did appear naturally, you will see later. As I said, I promised, which, if you compute it, this is approximately of this number. See, this quantity is appearing there and here as well. It's all the same. And t critical is the smallest t where this minimum is reached. So, if you compute it, you will see that this quantity appears everywhere, as I said. But this nevertheless is much, much smaller than p to the minus one, as I said.
00:14:44.990 - 00:15:38.944, Speaker A: Hopefully I will be able to show you why these quantities appear naturally. But if we work on some so called r core problem, the maximum subgraph of a graph whose minimum degrees at least are, you will see that not exactly this formula, but something similar formula might appear. So, when you analyze this one, you might wonder whether this has to do with our core of the final intaction set. But I think there is a relation. But up to now, I cannot formulate it in a most elegant way. Nevertheless, to state the CRM, let omega zero be any function which is much, much larger than the window size of the window, the width of the window, namely square root of AC. Then, if the size of the initially infected, this initially infected set is equal to ac, so a critical minus omega zero.
00:15:38.944 - 00:16:15.778, Speaker A: If you want to reread it, of course, you can read it as. As like set size of the set minus criticality normalized by the size of the window. You can also read it in this fashion. Then, with a high probability, I will read it later. The size of the final infection set is at most t critical, as I said. Indeed. On the other hand, we can show not only with high probability, with the explanation initially, high probability to be with one minus one minus is missing.
00:16:15.778 - 00:16:49.984, Speaker A: Sorry. One minus. So, one minus x pulse minus some constant times square of the omega zero divided by t zero. So, the reason why I didn't write in this session, as the Janssen Uchak turbine value did is we want to quantify this failure problem. Just write the failure problem. Sorry for that one minus x. So to capture this value probability, we have this speed of the convergence and this influence this failure probability.
00:16:49.984 - 00:17:35.700, Speaker A: And for the most t zero is also influencing our failure probability. On the other hand, as you can imagine the other way around, when this quantity tends to positive infinity, then what? The answer that r showed is that with high probability, the size of the final set is n minus little of n. So we improved it by showing this exponential bound. Again this quantity, the constants are different. We have a rather lengthy ugly formula, but very formula. And again, this failure probability depends on this omega zero square of the omega zero divided by t zero. By looking at it, you might see why we plug in this one.
00:17:35.700 - 00:18:32.970, Speaker A: So if we want to have a better smaller failure, probably we wish to have delta very small. We believe that this is not optimal, indeed we can do better. But as I said, the proof is really elegant using this powerful theorem by Bolivarsch and Riordan, and therefore we have this unwished bound on that. But if you want to improve it, maybe you can have different approach. So let me say a few words about the proof, how we should prove it. Yeah, so you're saying Ac coincides with these parameters mpr with the size of the r core? Not exactly that, not alcohol of the GNP, but I think alcohol of the. If I have known if I'm a God, I don't have a religion.
00:18:32.970 - 00:19:10.886, Speaker A: If there is a God, then I will know the final set of the infection, final infected set, then this will be the alcohol of that one. But of course, we are just a baby, we don't know the structure. We just don't know. But we are just looking at the size, not even a structure. So why I'm talking about it is that if I look at this proof, how it goes or how we prove it, it does mimic the so called warning propagation thing that I have done with arming Goya Oglan recently. Where is Catherine? With Kathryn scoops as well. It is not exactly the same, but it kind of gives me a feeling that it has to do with it.
00:19:10.886 - 00:19:27.834, Speaker A: But the problem is that I don't know the finite structure of the final set, whether I can correlate with. Very nice. Galatin wasn't tree, not with the average degree, but I have to contract it so it has some loose connection. But I don't know the connection. That's the annoying part.
00:19:29.814 - 00:19:30.526, Speaker B: Two questions.
00:19:30.550 - 00:19:59.470, Speaker A: So one is the expiration rate of decay. Do you think that's the best possible. No, as I said, it's the proof. Delta is a. Why does it matter what the delta is? Delta is kind of some fixed number. I can also say not equal, but I can also make it as small as possible if I wish, if I can prove it. But as I said, one part, indeed the most elegant part of the proof uses the giant component.
00:19:59.470 - 00:20:27.898, Speaker A: I have to put this thing in the weekly supercritical regime. And this is just technical thing. I mean, look at this one, this is on the bottom. The smaller t zero is, the better. I wish to make delta to be zero. Delta can be zero. If delta is zero, then I will be completely happy because it matched to my t critical time where the threshold appears now will be very.
00:20:27.898 - 00:20:57.968, Speaker A: But I have to go a little bit further. This TC is indeed is the lower bound of the infected set at time TC. At time TC, the number of vertices that are infected will be at least tc that TC. But anytime t. I will show you in the proof. It's hidden anytime tt. I haven't talked about this time, but each step, I was talking about each step there is the step, whatever the step was.
00:20:57.968 - 00:21:16.344, Speaker A: And you will see that, as I said, if t zero was not t zero, but tc. You see from this one we went a little bit farther so that we have a sharper concentration. So my wish is that if delta is zero, I will be very happy. We can discuss later.
00:21:19.204 - 00:21:49.400, Speaker B: Just about the connection with the core calculation. If the graph were regular, then there is an exact duality between bootstrap percolation and the dynamics of the reduction to the r core. Not to the r core, to the degree minus r core. But here you are in a regime where the degrees are very much concentrated. So if you approximate this by, I mean, if you approximate GNP by a regular graph.
00:21:49.472 - 00:22:00.310, Speaker A: Regular graph with infinity degree infinite. Yeah. P times n. P times n, yeah.
00:22:00.462 - 00:22:04.238, Speaker B: And then it's quite natural to have the connection with.
00:22:04.326 - 00:22:39.440, Speaker A: On the other hand, if the degree is unbounded, this Galton. So what I was saying is that there is a very elegant approach to the cakewalk problem through the Galton wasn't tree with multi type. Galton wasn't trained. It's not single type, but multi type to remember whether vertices in the core or not. So really it's a kind of beautiful thing. I wanted to apply it, but the point is that there we have to use this local structure, namely the GNP with the boundary degree can be approximated by the Galton Wassen three. But if your degrees are bounded, it's not anymore true, because of the correlations between the things.
00:22:39.440 - 00:22:48.694, Speaker A: So I don't know whether there will be this elegant, super elegant multitype galcon tree associated, but as well, thank you for mentioning it. So.
00:22:50.594 - 00:22:56.890, Speaker B: Okay. I was not saying that it was a way to prove it, but a way to say that it was quite natural that.
00:22:56.962 - 00:23:13.778, Speaker A: Yeah, it is. Yeah, exactly. So if you work on this click of things, if you look at this, you will see, oh, yeah. Oh, my God. This is this function that is appearing all the time, not only conceptually, but also quantitatively, analytically. If you see this function, it's kind of, oh, bubble. There should be connection.
00:23:13.778 - 00:23:46.450, Speaker A: And as you said, loose connection. So this is about all this technical statement. As I said, I just highlight this blue thing. The reason being that if Svante is watching this video so that he doesn't complain. So most of the things which is written as black is almost the same as Janssen or chakravavalier, except that they don't use the binomial, but they use the pozong. Of course, we know that Pozong and binomial are relatively very close relatives, but it's some. If you look at the windows inside, but sometimes they make difference.
00:23:46.450 - 00:24:49.102, Speaker A: But in this particular case, it doesn't make any difference. So we change, twist it a little bit. But asymptotically they are the same. And also instead of this one minus exponential, probably they have this with high probability, with additive error terms. So the rest of the talk, I want to give you some ideas about the proof, as I already said several times, that it's really short and elegant proof or elementary proof. We will use the reformulation due to Scalia and Tomba and then we will set up some martingale so that we can have the number of infected vertices is concentrated around its mean with exponentially high probability in the early stage of the process. It's true only at the early stage of the process and in the subcritical case because the number of infected vertices will be small enough so can just imply we can apply this martingale concentration result to the subcritical case.
00:24:49.102 - 00:25:11.108, Speaker A: On the other hand, for the supercritical case, I have a lot of typo. Indeed. So I was changing this morning. And so indeed I planned this talk to be a blackboard talk and I realized there is no blackboard and there is a whiteboard and then there was no shifting up and down. So I decided to make it quick. So sorry for this, all this typos. Anyway, it's an early morning.
00:25:11.108 - 00:26:02.194, Speaker A: The brain thing in the supercritical regime, because we want to go further, the martingale concentration is not strong enough. The reason is that in the super critical case we already infect at least a t zero vertices, whatever that number was. And then, because then the probability that the martingale is sufficiently concentrated decreases dramatically once we reach this t zero infected numbers. So we have to do something more. On the other hand, we have infected enough number of vertices. Then comes this elegant thing. What is it? Is the subgraph spanned by vertices with exactly r minus one infected neighbors grows so that it contains the largest component.
00:26:02.194 - 00:26:36.058, Speaker A: The largest component, it's not yet linear size, but kind of a p to the minus one size. Once any vertex in this giant component is infected, every vertex in the giant component will be infected. As I said, the size of the giant is not yet linear, but on the other, you can just make the other vertices infected quickly using turn off. So that's my plan. So how it works? As I said, I promised that I will do some reformulation. It looks very technical. Therefore I will use just a black whiteboard.
00:26:36.058 - 00:27:45.206, Speaker A: What is written? You don't need to read it. We will examine the infected vertices one by one and determine the vertices that has exactly our neighbors. In the previously examined vertices, this is written and we denote by z of t to be the set of the examined vertices a of t be the number of vertices that are infected. So what is it? So, as I said, forget about it. So given a time t, we have a set z t, let's say z t minus one to describe a z of t. I will do this in each step. And if there are infected vertices that has not been, not yet been examined, as I said, the set of vertices that are infected are denoted by ft infected vertices at time t minus one and set the number of vertices, set of vertices that are examined among infected vertices.
00:27:45.206 - 00:28:30.598, Speaker A: If there is an additional vertex which does not lie in z t minus one, but lies in t minus one, so that are infected but not yet examined, let's call it ut. You can select it in arbitrary manner as you wish. You select one vertex the difference and you include it in your set. And you call this new set as z of t. The set of vertices that are examined and what you do then and outside the walls that are not initially infected. It doesn't matter whether they are infected or not, but I ignore them. I just look at all the vertices that were not infected initially, all the vertices up to n minus a.
00:28:30.598 - 00:29:55.070, Speaker A: So this is just n and check whether it has r minus one infected neighbors, am I doing correct? Yes, at least r neighbors in the examined vertices, not in fact it's indeed infected, but examined the vertices. So what I have done here is I want to associate this quantity with some indicator random variable. I put one, if the vertex AI plus a plus I has at least r neighbors in z t, the examine the vertices, otherwise zero, then I'm ready to define a of t. So a of t, the set of infected vertices at time t will just be the union of the initially infected set. So initially infected set, I set the a so one through a union of the vertices that has at least our neighbors in z. This is what is written here. Then it is easy to see that z of t the isam in the vertices, the set of the examined vertices will be the subset, or strictly the subset of the a of t the infected set.
00:29:55.070 - 00:30:44.416, Speaker A: That's how we define it. And we set the large t be the minimum time t such that the infected set is identical to the examined set. Why? Because if there is no vertices which is infected but not yet examined, I have no vertices to examine. Therefore the percolation stops there. There will be no further infections once we reach that point. This is identical to the minimum t such that the cardinality of a of t is equal to t. So each time we examine one vertex so at time t, we have examined all the infected vertices and this is target function and the final set of infected vertices will be identical to a of t.
00:30:44.416 - 00:31:19.424, Speaker A: So this has been used also in the Jansson et al. Paper. And I promise that I will show you some, some numbers where all these strange computations occur, because it's kind of a very simple, I may not do, because the time is running out. How much time do I have? Only ten minutes, it seems like it, yeah. So I skip it. Why this all concept is up here. It's really cute, just calculus, but I just move on to the martingale.
00:31:19.424 - 00:32:21.064, Speaker A: If you look at it, if you look at what's going on, is that in each step, in worst case in a of t, we might infect n minus a of t vertices in single step. It was the case of course, but it might happen in the early stage of the process that we are targeting for martingale a of t is usually little o of n. So in worst case we might just infect in one step n minus little of n vertices. Yes, but if you work on martingale concentration inequalities, of course what is important thing is the maximal one step difference. If it's linear, we don't have any hope to have a very sharp concentration. So we have to refine this martingale, this is how we do in this picture what is going on is the following. We distinguish the vertices.
00:32:21.064 - 00:33:11.084, Speaker A: I will read this part first before defining this quantity, because it looks terribly complicated, but it's not. So this quantity was just the saying that look at the vertex I plus a plus I and check whether it has I at least r neighbors in z of t. We will refine this, just looking one by one vertices until a plus I. We check it for a vertex. After that a plus I plus one. That's it written here for the vertex a plus I plus one on what we will do is we will check whether it has r at least our neighbors in zt minus one. This is very technical matter, but it helps us a lot.
00:33:11.084 - 00:34:17.423, Speaker A: Now we have this quantity up to here we use this nice x time ti, but up to here. From here on we will use the examine the set in one step below j j, because j can run anything. So this is where it's written here, whereas written here we set up some some random variable mti. So this pair will define a total ordering using the lexicographical order. So for any such which is non zero, so it is kind of trivial low bound condition. We define the random variable m to be the sum of the random variable x t j, where j runs from one through I and check whether it has r at least r neighbors in zt minus PI hat of t. This is almost a binomial, except the stopping time condition divide by one minus PI hat of t plus.
00:34:17.423 - 00:34:55.584, Speaker A: We check the rest of the world for those j larger than a plus I, whether it has at least our neighbors in the previous step set t minus one. And you do this, then one thing that is easy is that the cardinality of a of t. I just read it off from here. It was cardinality is the size of the set a zero. It was a plus indicator random variables. From here on the other hand, using this quantity, by taking the last one, n minus a, this sum disappears. What is left is here.
00:34:55.584 - 00:35:21.138, Speaker A: So you do just a little arithmetic, the first year calculus, even the high school students can do that. So if you do this, you obtain this one. Why this is nice. We understand very well the binomial random variable. Of course it's a stopped binomial random variable, but we understand it very well. It's highly concentrated. And m this new random variable, if it does have nice behavior, then we are done.
00:35:21.138 - 00:35:58.464, Speaker A: It does have a nice behavior indeed. The sequence of random variables m zero, n minus a through the end forms a martingale. Just to make sure, I wrote down the definition of martingale. But maybe in this I don't need to explain it. So it does form a martingale and you can use a standard martingale inequality. But on the other hand there is a very nice one due to Chang and lu, which extends the result of the Macdermid. It's quite powerful for our purpose, so we used it and we get the Martingale concentration for the subcritical case we are almost done, as I promised.
00:35:58.464 - 00:36:48.080, Speaker A: The reason is that if you look at the a critical which was defined, I just rewrote the definition using the t critical. It's just the quantity that I have written there and also a of Tc we know, so number of infected vertices at the critical time we know, and we do just a little arithmetic. Then in the end we get that the number of infected vertices until critical time is smaller than critical time with exponentially high probability. So as I said this, in the constant, I hide this constant, but there was also other term, this kind of very technically looking inequality indeed. So subclicker case was quite easy. Now super critical case, it's indeed nice. So I will just use a picture to prove it.
00:36:48.080 - 00:37:39.640, Speaker A: You do not need to read it. As I said, this is the kind of the part that I like most. The martingale inequality in the subclicker case is not yet enough, but nevertheless it does produce a huge set of infected vertices of size. As I said, at least t zero plus omega zero over two. And I divide this set into parts, namely my examined set of vertices. It's quite huge and little reservoir for later periods. I call it a one because it's too lengthy.
00:37:39.640 - 00:38:43.696, Speaker A: And this part a two size of the a two is about omega zero over four. So this part as a reservoir I keep it. Then what we do is you look at the set of vertices outside of that world and check whether it has exactly all minus two neighbors, I minus one, sorry, neighbors in there, and I call it b hat. It's written there set of vertices which has exactly all one neighbors in that examine the vertices up to time t zero plus omega zero over four. Then it's not yet Iid random variable, some of the Iid random variable of that one. But on the other hand, the number of vertices that has that many neighbors is stochastically dominating some nice binomial random variable. Therefore we can also say the size of the set in a very nice manner, and indeed the size of the set is one plus epsilon times p to the minus one.
00:38:43.696 - 00:39:56.500, Speaker A: Of course, epsilon is hiding all this dirty constant or quantities depending on n, omega, zero and delta. Nevertheless, if you look closely how this epsilon is defined or behaving, we can show that this is in the so called weakly critical regime of the GNP, and it does contain a giant component b of size of this size. So it does contain a giant component of size, almost two epsilon over one plus two epsilon p inverse. What is a good thing about is that we do not have only with a high probability result, but also exponentially high probability result due to with exponentially high probability due to bullock Riodhan will appear this year, hopefully. So he has done, they have done all the work that I need, thanks to them, although you're trying to prove it, and they were quicker. So due to other reasons, they wanted to apply this result to the local limit theorem for the giant component. Nevertheless.
00:39:56.500 - 00:40:38.148, Speaker A: So using this one we can guarantee that with high probability there is a giant component. It's not yet, it's not yet big enough. So what is one can show is that once a single vertex here is connected to additional infected vertices, then it has exactly our neighbors that are infected. Therefore this vertex will be infected. But since this vertex will, yeah, spread the infection through the whole component, this bee will be completely infected. So now we have a giant infected set. It's not yet enough.
00:40:38.148 - 00:41:09.624, Speaker A: As I said, the size is still not far away from end n which we are targeting for. So what we can do is we just kind of repeat what we know. You check the set circle, but it has r at least r neighbors in b. Before I came here I gave a talk in oberbolfact two weeks ago. At that time we repeat this business there. If some of you are in the talk. So we just look at I minus one neighbors here and then we check whether there is additional vertex here.
00:41:09.624 - 00:41:50.966, Speaker A: But we don't need to do that. Indeed, we can just do honest check whether the vertices outside these two has at least our neighbors in b it does have with exponentially high probability. Furthermore, the size of this will be at least delta minus one, p minus one. It's not yet close to n, so what can you do? You just repeat check whether outside the world has at least our neighbors in the infected set. Yes it does. D. The size of d is as we wished and minus little of n.
00:41:50.966 - 00:42:06.374, Speaker A: We can show using the Chernoff, Chernoff Chertnov. And of course D is contained in the final infected set, and we are done. And as I said, very simple proof for rather complicated looking result. Thank you very much for your attention.

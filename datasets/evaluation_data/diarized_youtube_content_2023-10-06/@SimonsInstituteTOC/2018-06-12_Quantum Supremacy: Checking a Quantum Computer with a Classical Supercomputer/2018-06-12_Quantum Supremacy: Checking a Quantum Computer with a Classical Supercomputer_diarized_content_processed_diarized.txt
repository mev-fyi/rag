00:00:00.160 - 00:00:06.474, Speaker A: Good morning with John Martinez from Google and UCSB, who will tell us about quantum computing and quantum supremacy.
00:00:07.854 - 00:00:55.918, Speaker B: Thank you very much for the nice invitation to speak to you today. The present day, the computing power that we have is vast. It's enormous. But even with that, there's continued need to make even bigger and faster computers. And this is getting to be a little bit of challenge, because the fundamental transistors that you're building to make the computers are kind of hitting physical limits. And Moore's law, which has described the exponential increase of computing power over time, is kind of slowing down. And in fact, recently the big gains in computing power has been achieved by building big data centers and also now looking at new architecture.
00:00:55.918 - 00:01:57.464, Speaker B: And if you, for example, look at Google, besides having cpu's in their data centers, they also have graphical processing units, and now they're making special purpose architecture and hardware called tensor processing units. Here's a picture of the latest third generation TPU that Google has built to solve machine learning problems. And this has about a little bit greater than about 100 petaflops of performance. So this is at the world record supercomputer. But of course, this is only for certain problems in machine learning. So the idea of building special purpose computers and architectures to solve important problems is alive and well, and lots of things are happening. And of course, there's great interest in Google and elsewhere to see if we can do the same thing for with qpus or quantum processing units.
00:01:57.464 - 00:02:40.108, Speaker B: And can we harness quantum mechanics to solve certain problems way, way faster than you can and eventually do with any we do with a classical computer. And because of this, there's kind of an interesting time now, a very exciting time. It's kind of a quantum space race where we have a bunch of programs, national programs, trying to go ahead and develop quantum technology and build a quantum computer. And in fact, there's a bill winding its way. And I think we'll be introduced soon to have a big national program in the United States doing this. And of course, there are lots of companies involved, one of them being Google. And again, it's great.
00:02:40.108 - 00:03:12.066, Speaker B: We're all drawing different things. It's progressing very rapidly. It's very exciting to see what's going on now. As you read about this in the press, there's a lot of talk about the number of qubits, and kind of this year, there's been a lot of talk about making 50 qubits, and I'll talk about why that number is here because of quantum supremacy. And it's great this is a new frontier. We have to do that. But the main point I want to get across today is it's not just the number of qubits that matters, the quantity.
00:03:12.066 - 00:03:50.862, Speaker B: It's the quality of the qubits that is incredibly important and needs to be discussed, at least in scientific conferences. And, in fact, in my view, quality is way more important than quantity at this point. We have to solve the quality problem, and that's just kind of a frontier. We have to be. And I'm going to explain in detail what I mean by that, because I want potential users of the quantum computer. When you're looking at seeing what's going on in the field, for you to understand what's really important. Now, let's just do a quick.
00:03:50.862 - 00:04:41.480, Speaker B: Everyone knows this quantum data is really interesting because the information can be in a superposition of states, in some sense, making a parallel processor a zero or one at the same time. As you add more qubits, the Hilbert space, the state space, doubles every time you add a qubit, which means it's exponentially growing with the number of qubits. That's why we care so much about the number of qubits. And then by the time you get to n equal 50, the amount of parallel computation you're doing to the 50 is taxing the size of present day supercomputers. And when you run the algorithms, you're taxing the time it takes to run these algorithms. So that's why this number is so interesting. And, of course, we can hopefully scale up beyond 50.
00:04:41.480 - 00:05:13.512, Speaker B: The number 333 is actually very important for me because two to the 330, this is a math people should know. Two to the 333 is about ten to the 100. Or a googol, obviously, very important milestone. Okay. But of course, you only get n output bits, so you only can do this with special algorithms. That's fine. Now, this kind of discussion here is great, but you're talking about perfect qubits that have no error.
00:05:13.512 - 00:05:50.442, Speaker B: Okay. That doesn't exist at least yet. I mean, we eventually think we can do that, but qubits are fundamentally have errors, and you have to deal with it. So how is that happening? Well, the way I like to explain that is that when you take classical information, you can think of it as, say, a coin on a table and who has coins in their pockets anymore? So we get out your cell phone. So you can have the cell phone up or the cell phone down, representing zero and one. And the important thing to remember with classical information, that this information is stable. If you have a little bit of noise in the system.
00:05:50.442 - 00:06:25.962, Speaker B: It may lift up, but then there's a restoring force and dissipation that makes these two states stable, at least for most the kind of computers you would build in a quantum state. That, of course, can be an arbitrary superposition of zero, one. So it can be zero. It can be zero plus one or one and actually kind of phase in it. So you can think about it, a coin freely rotating in space. And now when you have any amount of noise to that coin, it's going to rotate a little bit and give you an error. And the point is, is this kind of continuous space that it lives in.
00:06:25.962 - 00:07:25.534, Speaker B: It's an analog system, so it's sensitive to small errors, and you fundamentally have to deal with errors, whereas in classical, it's digital, it's self correcting, and things are a lot easier because of that. Okay, now, when you have these single qubits, you can also put them together to do a computation, very much like in a classical circuit, where you have information, then they have through some one bit, not gates and two and gates. And you can write a theorem that with these kind of two logical operations, you can do any kind of operation you want. Here's an example of an adder in a quantum circuit. One qubit arbitrary rotation, a two qubit CNoT, like an XOR gate, classical logic, you can then do an arbitrary calculation. You can't copy information, but you can still build your algorithms nevertheless. So here you have the individual qubits, you have the individual single qubit rotations.
00:07:25.534 - 00:07:48.598, Speaker B: Here are the two qubit gates. And you build up together a circuit here. And you can do an arbitrary computation, provided you initialize it and measure it here. This is kind of laid out in space. Here it's laid out in time, kind of like how you would think a normal cpu program. But the analogy is very good. Now, the problem, of course, is I told you that these had errors in it.
00:07:48.598 - 00:08:33.104, Speaker B: So by the time you make a complicated calculation, you're going to probably have some errors coming out here that's going to mess up your final state. And what you do, of course, is you use quantum error correction, which basically encodes the qubits, one logical qubit state into many physical qubit states. You can't measure if the qubits have changed, or else you'll change the state. But you do some kind of parity measurements to figure out that there were bit flips. And then with enough parity measurements, you can figure out which one did. So basically, you have this error correction circuit where you're doing parity measurements over and over again. And then you do some classical error decoding and logic to, to fix error correction and also do logic on it.
00:08:33.104 - 00:09:12.090, Speaker B: This is actually similar to classical systems where you use a clock and a d flip flop and doing logic to kind of synchronously do the calculation here. Here the synchronization goes with the error correction. The important point here is, look, we want to build a quantum computer with about ten to minus nine errors, maybe even ten to minus twelve, because that's how many operations we have in our circuit. Okay? So you want some exponentially small errors, okay? That's not where we are experimentally. That's where we're going to go. And to do that with, say, the surface code, you need about 1000 qubits and 0.1% error.
00:09:12.090 - 00:09:36.730, Speaker B: So this is nice. See, this error in par 1000 is way, this is kind of reasonable. Maybe we can do that. It's not anywhere near this, but that's something we think we can do. And of course, the downside here is we have to build a lot of qubits to do that. Well, you know, this has billions of transistors or trillions of transistors in it. You know, maybe we can eventually figure that out.
00:09:36.730 - 00:10:20.158, Speaker B: So that's the difficulty in the fan. So note here that we have quantity and quality in order to go ahead and do error correction. So what I think, you know, as you people are talking about the progress in making a quantum computer, this is not, you're building a system. So it's not a one dimensional horse race in the press as the number of qubits. It's both the qubits quantity and the quality in the same device. And of course, there's lots of other things you have to worry about, but these are the main ones, at least for right now. So if you want to talk about where we are right now and what we need to do, you talk about the quantity number of qubits.
00:10:20.158 - 00:10:56.824, Speaker B: You talk about the quality. And this, for example, is the worst qubit operation, as opposed to the best thing that qubits do, which is typically what physicists want to talk about. It's always an engineered system. It's the worst that matters. Okay, so it's a limiting error rate. So I was telling you, for ten to the minus nine errors, you need about ten to the minus three error per operation, you need about 1000 qubits for one logical qubit. And then if you have higher error rate than the number of qubits you need for logical qubit goes up, and if you have a lower error rate, then the number goes down.
00:10:56.824 - 00:11:38.460, Speaker B: It's kind of on this curve here. Now, the important thing to, of course, note is that as the error rate goes up, this starts to diverge and, in fact, blows up at the error correction threshold at about 1%. So that's kind of 1% characteristic of what we have to do. Of course we have to do better because we don't want to build an infinite number of qubits. Maybe mathematically that wouldn't bother you here at this institute, but in building something, we have to make this a finite number. And I'll call here above ten to the minus two, I'll call this the death zone, where if we had an infinite number of qubits, we couldn't do error correction. Right.
00:11:38.460 - 00:12:07.168, Speaker B: You have to be so good and then doing that. Okay, so, and then, so this is kind of where we have to do. I call on this scale the error correction gain. It's kind of like transistor gain. You know, if you build a new transistor technology and your transistors, you say you can scale to billions of those transistors, but the transistors have no gain. It's going to be useless. Right? The transistors have to have some gain to build a real circuit.
00:12:07.168 - 00:12:25.128, Speaker B: So I'm calling this error correction gain where the gain has to be greater than one, maybe typically around ten. That's not unusual for transistor technology. Maybe ten to 100 is what you typically want to do. And that's kind of similar here with doing the error correction. Okay, so that kind of tells you. Yes.
00:12:25.256 - 00:12:27.280, Speaker C: Gain of what's the what?
00:12:27.352 - 00:12:43.572, Speaker B: I'm just saying that by adding more qubits, your logical system gets better. So you have some information gain. It's just that it's qualitative.
00:12:43.748 - 00:12:47.308, Speaker A: Where is this graph coming from? Where is this graph coming from?
00:12:47.356 - 00:13:05.744, Speaker B: This graph is coming from when you work out the error correction theory of what you need to do for ten to minus nine errors, you know, you work it out. If you have lower, you have a worse error rate, you need more qubits. That's the trade off you can solved by looking at the error correction theory.
00:13:06.124 - 00:13:08.068, Speaker C: When goes a single logical qubit?
00:13:08.236 - 00:13:12.604, Speaker B: That's a single logical qubit. That's all we're talking about here. Yes.
00:13:12.724 - 00:13:13.596, Speaker C: Ten to the minus two.
00:13:13.620 - 00:13:14.820, Speaker B: Is that a provable boundary?
00:13:14.852 - 00:13:17.596, Speaker C: Is that we don't know any codes that do better?
00:13:17.700 - 00:13:58.848, Speaker B: No, this is for the surface code, which kind of has the best balance, but you can do it for all the codes, this is the easiest case we know of. Okay? Now, given this, and given the fact that you, when you read press reports about quantum computers and they talk about quantity, you know, how many qubits they're making, whatever you would kind of think, well, yeah, you know, they have some gain. They're below the threshold. And then, you know, once you're below the threshold, quantity matters. I mean, obviously, the better the error, the fewer quantity we need. But then it's kind of like, as long as you have some of this error gain, it doesn't matter. But this is what's really odd.
00:13:58.848 - 00:14:28.116, Speaker B: That's not the case at all. The case is that the typical qubit error rates that people are talking about are error rates around 5%, some a little bit more, some a little bit less. You're up here in the death zone. So if you're just talking about quantity at this point, it's kind of like hype, okay? It's not where we want to be. We want to be down here. Okay? And you can, like, say you can, it's great. You know, we're getting to 5100 qubits, whatever.
00:14:28.116 - 00:15:13.044, Speaker B: This is all great. But if you don't have the quality, well, you know, are we going to be able to do this kind of thing? So what we're doing at Google is our strategy is to really focus first on how to get the error rate down and then to move across here, because it's well known that, you know, in management circles that you want to solve your hardest problem first. Okay. And get everyone thinking about that. So what happened is this is nine qubits, a little bit under ten to the minus two. This is what we did at UC Santa Barbara. And because we were kind of dipping our toll underneath this threshold line, this is kind of why we decided to move to Google and build this thing.
00:15:13.044 - 00:15:43.196, Speaker B: And what we're going to do today is talk a little bit about the quantum supremacy experiment at .1 here at about 50, 72 qubits, a little bit lower error rate to show quantum supremacy. I'll explain that then. Number two, with that, you can't classically simulate that anymore. Maybe we can find some near term applications that will be useful. It's not known whether we can do, but certainly we can look for that. And then around 0.3
00:15:43.196 - 00:16:19.020, Speaker B: here at 1000 qubits and ten to the minus three error, we can do logical, we can do error correction and at least make one really good qubit, a ten to the minus nine error, which is what you need and then, of course, you want us need to scale it up something to like a million qubits, million physical qubits, 1000 logical qubits to do a full quantum error correction. So this is kind of the trajectory that we need to get to. So that's the goal. And we have to make our qubits better as well as making more of them. Yes.
00:16:19.212 - 00:16:27.924, Speaker D: So this ten to the minus two and 5% that you're talking about, if I understand correctly, is for the two qubit K's, right.
00:16:28.084 - 00:16:30.532, Speaker B: Those are the hardest things to make. I understand.
00:16:30.668 - 00:16:51.844, Speaker D: So, coming up and up until now, there was in the past decade or so, some important ideas in engineering and physics that completely changed the picture for one qubit gates and qubit longevity. So my question is.
00:16:54.024 - 00:16:54.920, Speaker A: I mean, would.
00:16:54.952 - 00:17:02.584, Speaker D: You expect some change, some. Some very new ideas that would completely change the picture for.
00:17:03.284 - 00:17:43.244, Speaker B: Yeah, and it's great that people are looking at those ideas. There are things that people are doing that are improving upon what we've done in the past. It's kind of our thing. There are other people, like topological qubits, who are trying to fundamentally address the question, and all these ideas are good. The main point I want to make here is, you know, it's not so. Look, it's great to write a nature or science article to have a new gate, but when it's only 70% fidelity, which is enough to get you in nature and science, it's great. But it's not taking you down here where you want to go.
00:17:43.244 - 00:18:19.686, Speaker B: You want to do the metrology. You want to develop not just a new gate, but a good gate and a damn good gate in order to address the field. And the hard part is, you can't just do that on one or two qubits. You have to do it on lots of qubits, because making it on lots of qubits pushes against making good qubits. And you have to do everything at the same time really well, this is hard. So I just want to point out this is really hard. I'm not sure everyone's talking about it in a serious way, that we have to solve this problem if we're going to build a quantum computer.
00:18:19.686 - 00:18:58.908, Speaker B: We can't just hope it's going to happen. You have to work hard on it. But I want to give just some examples of what's going on. This is in kind of the published or at least in public literature, between the Google, this is four years ago, a five qubit device. This is old, recent IBM and the Righetti. And what happens is when they build these big systems, they can measure the individual two qubit gate fidelities. And what I do here is you can histogram them, but that's an integrated histogram where each of these steps represents another gate that they made here.
00:18:58.908 - 00:19:25.982, Speaker B: And this is nice because you can see what's going on for small number of gates and kind of see what the probability distribution is like. So you see, for the Google five, we had five qubit gates around 0.5 to about 1% error. The IBM gate, it goes down to ten to minus two, but it goes all the way up to about 10% errors. And here's Rigetti starting at about 7% and going up to about 20%.
00:19:26.158 - 00:19:28.430, Speaker C: I didn't understand what these different gates are.
00:19:28.542 - 00:19:29.474, Speaker B: Excuse me?
00:19:30.294 - 00:19:32.674, Speaker C: Are these at different times the same gate?
00:19:33.694 - 00:20:00.392, Speaker B: These are the two qubit a gate errors. And each one of these steps is another two qubit gate with their errors. So you have a distribution of two qubit gates from 1% to 10% qubits on them. So there are 20 qubits. And so the best two qubit gate of the 20 qubits that you have has error rates down there. But the worst one is the top. And so that's what the.
00:20:00.392 - 00:20:26.710, Speaker B: And this is the point I want to make, is when you listen to physicists and you see tables in review articles, they tend to tell you the best one. I mean, we do that. Other people do that, which is fine. Okay. We want to know what's best. But the reality is, when you build a complicated system, things get hard, and you actually see a distribution. And the distribution here is maybe a factor of two.
00:20:26.710 - 00:20:38.274, Speaker B: So that's not so bad. But here the distributions are factors of ten. Okay. It's, you know, between your average and your worst is a factor of five. Okay. And. Okay.
00:20:38.274 - 00:20:47.346, Speaker B: We're working on it. They'll get better and we'll understand what's going on. I just want to say it. I mean, to be honest, you have five qubits. They have 20. Yeah. So this is a lot easier.
00:20:47.346 - 00:20:54.842, Speaker B: Clearly. Clearly, yeah. Yeah. Well, you know, there's the data, so that's fair. That's fair. It's hard. I want to just say it's hard.
00:20:54.842 - 00:21:12.868, Speaker B: Okay. And that you have to talk about the average fidelity as well as the best. Ok. And remember, that's on top of the fact that you have to not just show one or two brigades. You have to do many qubits. Right. So this is hard.
00:21:12.868 - 00:21:30.904, Speaker B: And all I'm really trying to say here is. Look, this is the death zone, okay? We need to get down here. All of us need to make it better. Okay. By, you know, some. A little bit. Of course, they have to get the average and some more.
00:21:30.904 - 00:21:51.694, Speaker B: Oh, by the way, when we made our nine qubit device, the average fidelity is compatible with this. So it's not so crappy when you scale up a little bit. So that's good. Is that published? Yeah. I'll show you the data. So, you know, we have to get better. So for here, we have to.
00:21:51.694 - 00:22:14.190, Speaker B: We know that about a factor of two here or so is our control. And another factor of two or so is that we have to make the coherence of the qubits and some other things that are going on there. But the real difficulty actually is moving. This is making all of the qubits work well and understanding all the physics and getting rid of all the dirt physics. Yes.
00:22:14.262 - 00:22:19.514, Speaker C: When you measure gate fidelity, you measure the effect that the gate has on the two qubits on which it acts.
00:22:20.904 - 00:22:45.920, Speaker B: So what you do to measure these gate fidelities is you take the two qubits and you make the two qubit gate, and you do that in a bunch of times, putting known but random single qubit gates in between something called randomized benchmarking. And then by looking at the random states and looking at the decay of the. Of the final state, you can get an error per gate.
00:22:45.992 - 00:22:49.512, Speaker C: But you look at the fidelity over the whole five qubits or just the two qubits.
00:22:49.568 - 00:23:27.570, Speaker B: No. Yeah. So these tend to be experiments only on two of the five, or 20 or 19 or whatever. And you're gonna say, well, what happens when you run it on a complicated experiment with many qubits? Can you still get that gate fidelity? So, even though we're doing here, this is kind of the best case scenario. You want to know what happens when you run it on a complex thing, and I'll show you how to do that. If I have enough time, I'd like to have enough time, but I'll show you how to do that. That's what the quantum supremacy experiment allows you to do, which is important, of course.
00:23:27.570 - 00:23:34.134, Speaker B: You want to get, this needs to be good, and then you have to be able to control your whole system all at once.
00:23:35.274 - 00:23:43.954, Speaker C: Is there any simple explanation in terms of architecture, architecture for the difference between your design and ivf design?
00:23:44.814 - 00:24:20.494, Speaker B: Yeah, you could talk about those kind of, those kind of differences, and everyone is going to say that their architecture is the best and whatever, and that's fine, but you can do that. I'm going to say that if our qubits didn't have some peculiar physical problems with them, these would probably all be good. But I'm saying, my opinion is that what makes one architecture better than the other has to do with some subtle errors that are in the qubits that you have to work around.
00:24:23.114 - 00:24:32.102, Speaker C: Coming back to Thomas question, so, could you do the following. So you want to measure with errors?
00:24:32.178 - 00:24:32.834, Speaker B: Yeah.
00:24:33.254 - 00:24:46.798, Speaker C: Could you measure it while engaging the other qubits into qubit gates, which are intensive products? So you could still measure the error rate here, just while the others are active?
00:24:46.966 - 00:25:22.178, Speaker B: Yeah, you can do that if you want. And then these are called simultaneous benchmarks. And you want to show that if you really turn the other ones off, or maybe not so often, you're getting the same thing. So there's a bunch of things you can do like that. Generally, if you separate them properly, you don't have a degradation of this quantity. But of course, what's harder is if you start interacting them do the errors add in a simple minded way? And I'll show you an experiment that hopefully that'll get to that. Okay.
00:25:22.178 - 00:25:53.126, Speaker B: Given you're asking a bunch of questions, I'll go over the hardware. What this is, is an integrated circuit, super like qubits. This is all ground plane. These are cuts in it. This cross here forms a capacitance between the cross and ground. The Josephson junctions at the bottom are basically nonlinear inductors, where you can vary the inductor by putting current into here and flux into here. And this makes a non linear lc resonator that forms the qubits, essentially a six kilometer gigahertz microwave oscillator.
00:25:53.126 - 00:26:22.214, Speaker B: Very high quality factor, very low dissipation and non linear, so that the zero one transition is a different frequency than one two. And then you can stay in the qubit space. Okay, here's a picture of the nine qubits that I'll give data on instead of the x's. These are is. So we have our two control lines. One controls the frequency and phase, the other the amplitude of it. With a microwave pulse, we connect to this line here to read it out.
00:26:22.214 - 00:26:54.430, Speaker B: And then these are actually coupled together. You can couple together simply with capacitors, but we do that with some variable mutual inductance. So we can have a swap operation where a photon swaps between two gates, which is controlled by the line here. It's either turn, the coupling is turned to zero, or turn positive, or turn negative, depending on how much current. We flow in these here, and then we have nine qubits here. Okay, so we're going to do a nine qubit experiment. Now, let me tell you something here that's not so obvious.
00:26:54.430 - 00:27:19.620, Speaker B: We calibrate this and we get everything to work. What we'll do is we'll calibrate what happens when this photon swaps from here to here via this gate. So we calibrate the gate. So we calibrate this one separately. This one's off. And then we calibrate this one, and then we calibrate this separately. When we run the algorithm, we're going to turn all of these on at the same time, which we didn't calibrate for.
00:27:19.620 - 00:27:58.286, Speaker B: Is it going to work? And this is kind of the problem. You can have good two qubit gates, but what's going to happen when you turn everything on at the same time? Is it still going to work? Is your calibration going to work? And it's not clear. You have to do experiments to show that you know how to do that. And we'll show that indeed, if you model everything right, so you know what's going on, we can essentially get the same behavior when everything's turned on. Everything's working at once as we got with the individual gates, but that's not obvious. You have to show that that's what's, that's hard. So here's the latest qubit chip.
00:27:58.286 - 00:28:21.454, Speaker B: These are eleven qubits here, eleven qubits here, 22 qubit chip. This is their qubit chip made with special processing. We flip chip this. There's little indium spheres that connects here to here. So the two chips gets together. This is the wiring we put inside a printed circuit board. Wire bond to it, bring those wires out to align, and then we control them.
00:28:21.454 - 00:28:52.454, Speaker B: That goes into a dilution. This package here, this goes in with a bunch of cables going down to the device. This package is in a dilution refrigerator at about ten Millikelvin. So this is so that the thermal energy kt is much, much less than the quantum energy, which is about a third of a Kelvin or so. So it's a big factor between those two. And thus you can get rid of all the thermal effects. And then all these wires are taken up to the top of the cryostat.
00:28:52.454 - 00:29:25.728, Speaker B: Here's a picture looking at the top of the cryostat right here with all the wires coming out. And those wires go to this breakout panel. And then we wire that to these crate of electronics here, which controls everything. So this is I took this picture yesterday. This shows about 200, a little bit more than 200 wires connected to our qubit and then connected to electronics. And then we just control it and use the vise. Oops.
00:29:25.728 - 00:29:59.574, Speaker B: And then here it is. Is a dilution refrigerator, control electronics. And we sit behind our computer all day measuring the qubit and trying to get it to work. Okay, so let's talk about the quantum supremacy experiment. You measure that two qubit gates are working at a certain level. Well, what happens when we build the whole system? Is it still going to work? Okay. And the way we're going to test that is something we call the quantum supremacy experiment with about a 50 qubit system.
00:29:59.574 - 00:30:41.824, Speaker B: Okay. We're going to run a simple algorithm on that 50 qubit system and get the outputs. And then to check if those outputs are correct, we're going to compare them against the simulation from a classical supercomputer. Given that 50 qubits is so many, you have to use a supercomputer to do that. So it's basically this little physics experiment taking data with that versus this big classical supercomputer. So it's interesting. Why do we want to do this? Some of our competitors have been saying, oh, this is just a Google marketing ploy of doing quantum supremacy.
00:30:41.824 - 00:31:56.870, Speaker B: And I'm going to say that's actually kind of right in the sense that computer scientists have been hearing about quantum computing for a long time and hearing about the potential for a powerful quantum computer. But all they hear about is, like, two qubit spooky entanglement experiments winning, and actually shows something powerful. So what we're trying to do in this to the computer scientists is showing that you can build something that computes, something that's powerful in the sense that it has to be checked with a quantum computer. So, okay, at least Google executives understand this, and that's all really I care about in terms of the science. The whole point of the quantum computation is computing on this gigantic Hilbert space. What evidence do we have that theory actually allows us to do this? And we expected the case, and if it doesn't work, we're going to explain, blame the experimentalist. But in classic physics style, you want to say, well, how big of a system can you make so that you know that superposition is still working? Okay.
00:31:56.870 - 00:32:48.758, Speaker B: And finally, in terms of the engineering point, when you build any computer, you have to do some tests to see if it's working. So typically what you do with a regular computer and your operating system, whatever you do, a hello world experiment where you just have to do the simplest thing you can think of to show that you know what you're doing. And this is kind of the simplest algorithm you can think of that does a full test, and you check whether your whole operating system, especially your hardware, is working. So again, the computer scientists like this. So this is kind of a computer science centric experiment. So it's just, you run an algorithm where you take the qubits, single qubit gates, two qubit gates, do it over and over again. And the two qubit gates are control Z C nots, that's known.
00:32:48.758 - 00:33:44.578, Speaker B: And then the single qubit gates are randomly chosen from known gates, which are Clifford operations, 90 or 180 degree operations on the rotation, or some non Clifford operations. So it's a randomly chosen but known operation. You then with that, run the quantum computer and measure a bunch of times, let's say 100,000 times. And given the randomness nature of it, you're kind of expecting all the possible two to n possible outcomes. Okay? And then you would, you know, you randomly guess any outcome as a probability one over two to the n. However, you calculate what this is supposed to do, just integrating the Schrodner equation or other ways of doing it, so that you get the probability to get this. Now, what's interesting is when you actually look at this quantum system, you don't get a uniform random distribution.
00:33:44.578 - 00:34:39.069, Speaker B: The distribution of states is actually very similar to what you see in laser speckle, which I'm showing here with a laser going through a ground glass. That diffuses the light. But you see, in certain directions, the light is bright, and in certain directions the light is dim because it's not a uniform distribution. The statistics, the coherence of the light makes some directions more intense and some less intense. And similarly, the probabilities of measuring all these states, there are some states that are more probability and some states are less probability. And the way you check that, of course you're going to measure the most probability ones. The way you check that via sampling here, is that for a particular state that you measure, you look it up in here, what the probability should be.
00:34:39.069 - 00:35:19.964, Speaker B: And since that probability is higher than the average, if things are working right, that's going to be bigger than p classical, and this is going to be bigger than one. In fact, when you do it properly, the difference between a random choice and the full quantum speckled choice is one. And then you can tell the difference whether the thing is working. And what's interesting is if you have one error, like a bit fip or phase flip or you programmed it wrong or something. You get to the classical. So it's a very sensitive test of whether everything in your quantum computer is working properly, which is, of course, what you want to know.
00:35:21.104 - 00:35:28.920, Speaker C: Can you just say one word about why the uniform distribution is the appropriate thing to measure yourself against? You just chose that?
00:35:28.992 - 00:35:57.502, Speaker B: Well, you just say, if you have no information, because it's this random, complicated circuit you're going to. The only guess you could have is that it's going to be uniform distribution, and that's what happens classically. So if I take classical light, white light, shine it through the ground glass, is going to look uniform. I take coherent light, it's going to have this speckle pattern. And same thing here. The coherent states have the speckle pattern. I can talk about that later.
00:35:57.502 - 00:36:21.938, Speaker B: I just don't have time to go into it. That's just what happened. Verifying that you're not sampling from the uniform distribution is not sufficient here, although. But it is necessary. So the idea is you can get about 100,000 samples in about a second. That's what the quantum computer does. And to calculate this, it might take days.
00:36:21.938 - 00:36:58.534, Speaker B: I mean, you have to measure 100,000 samples. And this is so much bigger than this that, you know, the quantum computer looks powerful, much more powerful. And of course, this is all growing exponentially with systems size. Okay, so that's, that's the basic idea in the experiment. I mean, how long a depth do you need to run? So the depth is actually important. So the computational complexity gets hard at about 45, 48 qubits, and the depth here should be around 40, 43, something like that. So you need has to be deep as well as wide.
00:36:58.534 - 00:37:02.980, Speaker B: You have to go through those details, but yes, so you have to do both of those.
00:37:03.092 - 00:37:05.764, Speaker C: So you have to implement over 1000 gates.
00:37:05.884 - 00:37:13.264, Speaker B: Yeah, over 1000 gates. And thus you need about ten minus three error. And you can do a little bit worse than that, turns out.
00:37:13.884 - 00:37:15.180, Speaker C: But the errors you had on even.
00:37:15.212 - 00:37:38.244, Speaker B: Just five qubits, they were ten to the minus three. They were five times ten to the minus three. So we have to improve that a little bit. And then, you know, you can have, on average, a couple errors and still see a signal. So there's some things you can play with. There's an exponential decay. You have to go through the statistics of it carefully, but we can talk about it.
00:37:38.244 - 00:38:47.934, Speaker B: So this idea even work? Can you test the system? So we took that nine qubit device and ran a slightly different but similar in concept quantum supremacy experiment, where this is the example for five qubits. And we ran that and we measured all the two photon states coming out of here. Okay? So we run through that and then in blue we see the probabilities. After measuring this a bunch of times and you see that there's lots of small ones and a few big ones. This probability distribution coming out of this looks like speckle, looks like qubit, speckle, lots of small, few big. We change the instance, the programming that we did to it and you're going to get another speckle pattern, okay? Which is different than this. Again, lots of small, few big ones here, instance three here, instance four, okay? And basically I'm going to say that the speckle pattern, okay, so you see a speckle pattern and you can look at the statistics of that.
00:38:47.934 - 00:39:45.368, Speaker B: You know that your quantum computer is coherent because you saw a speckle pattern, okay? So just from the raw probabilities, you can tell that, of course, what you really want to know is, was the speckle pattern what you predicted? Okay? So by calibrating the system very carefully, and this is about a year of work. This is a lot of work, okay? And calibrating, doing everything right, you can get model predictions for what we programmed in. And those are in the red dots. And you see where the blue is low, the red is low, and where the blue is high, the red is high. And then when you change to another instance, you see the same thing, that it matches here, it matches here and matches here, which tells us that when we control our system, we really know what the Hamiltonian is. We know what's going on with our quantum computer. It has been calibrated, it's verified to work properly because the speckle pattern matches the theory.
00:39:45.536 - 00:39:56.200, Speaker A: John, is it? I don't understand. Isn't that too good to be true? Meaning, I mean, isn't that. You basically said that your error probability is kidnaught.
00:39:56.312 - 00:40:49.444, Speaker B: So this is only five qubits and I think only like five depths. So it's not, you know, not very many operations, okay? So in fact, is it too good to be true? Do you expect that this is the experiment you do for between three qubits and nine qubits, you run this algorithm, okay? And then you do the depth of it, which is the number of cycles, okay? And you expect the higher the depth or the more number of qubits, the worse the fidelity is going to be. And exactly, that's what we see. We see all these are sloping down for more cycles. We see when we go from three to nine, the fidelity goes down and you can work out what the error is per cycle. And basically all this data collapses into the idea that you see about 0.3% error per gate and per cycle.
00:40:49.444 - 00:41:18.768, Speaker B: Okay, so this is consistent with what we expect for the basic gate fidelities. When you run a complicated system, it works properly. You might say, well, why is it 0.3% and not 0.5%? The particular algorithm we ran, it was a photon number conserving. So we threw out a small, like less than half of the data where that didn't happen. Thus you're not seeing energy decay things.
00:41:18.768 - 00:41:24.436, Speaker B: So it's going to be a little bit better and in a way that makes sense to us. So this number makes sense.
00:41:24.500 - 00:41:27.108, Speaker A: Just to clarify, a cycle is the depth of a gate.
00:41:27.236 - 00:41:32.544, Speaker B: Yeah, that's basically a cycle would be this.
00:41:37.444 - 00:41:40.504, Speaker D: Why are you calling it photon number conserving?
00:41:42.804 - 00:41:57.994, Speaker B: It's a slightly different algorithm where we put in n over two photons, and then we just do swap gates as the entangling operation. So we conserve photon numbers. It's a little bit different algorithm.
00:41:58.294 - 00:41:59.390, Speaker C: They don't know what you mean by.
00:41:59.422 - 00:42:16.104, Speaker B: Photons in the superconducting. Okay, it's the number. Yes. So, yes, thank you. So I call a photon a qubit one state. So it's an excitation. So if we have nine qubits, actually.
00:42:16.184 - 00:42:18.524, Speaker D: Photons, in the sense of Maxwell's equations.
00:42:21.584 - 00:42:31.224, Speaker B: These are nonlinear, slightly nonlinear qubits. So these are almost harmonic oscillator states. So that's the jargon we use. I agree. It's not so good.
00:42:31.384 - 00:42:31.952, Speaker C: Okay.
00:42:32.008 - 00:42:33.576, Speaker B: Okay. It's excitations.
00:42:33.720 - 00:42:36.008, Speaker D: Well, you're allowed your own definition.
00:42:36.176 - 00:42:44.314, Speaker B: Okay. It's just jargon. Sorry. When you study electronics, you have to learn a lot of jargon. So. Sorry. We use that.
00:42:44.314 - 00:43:20.092, Speaker B: Ok. You're computing about 500 states in parallel here. Ok. That's the Hilbert space. Just to show we can do other things with it, we're going to take this nine qubit device and map the problem of quantum materials. Problem of basically a two dimensional sheet of atoms with an applied magnetic field. Let's say a nine by nine array maps into nine qubits using the correct gauge.
00:43:20.092 - 00:43:57.184, Speaker B: And then you look at the excitation energy of that system versus applied magnetic field, where one corresponds to one flux quantum into an atom cell, which physically would be about 10,000 Tesla. So this is a huge. So you can't do this in the lab. You can of course approximate that with some different experiments. You can of course compute that. The interesting thing about this problem is when you predict that for this particular system, you see this very complicated diagram. It similar to the Hofstadter butterfly.
00:43:57.184 - 00:44:46.370, Speaker B: When they first computed this, you see kind of a gap here. You see lots of structure in this. So when we run our quantum computer and map it to this problem, we know it's working really well, but are we going to be able to see this kind of structure to it? So, you just calibrate the system, you check it, and then you run it, just like you would use a regular computer. And when you do that, you get dots as your experimental data, which you see, you know, agrees very well with all the structure that we're seeing here. We see all the nice little bumps and wiggles here. In fact, the difference between experiment and theory is a few megahertz on hundreds of megahertz scale. So, you know, it does a good computation.
00:44:46.370 - 00:45:12.290, Speaker B: I say that you'd probably. We've done other experiments, look for correlations of the. Of the excitations and the like. You know, you can. You can get a lot of physically meaningful information out of it. So, this shows that you can get what I would say is physically useful information out of a quantum simulation that matches what you expect. Of course, it's still kind of a toy problem.
00:45:12.290 - 00:45:32.454, Speaker B: It's only nine qubits. So, hopefully, we can match something on a real problem to something that we can do on quantum supremacy and then measure something that would be very hard to do computationally. But that's. That's what we're hoping to do in the future. Yes. Yeah. Okay.
00:45:32.454 - 00:46:14.514, Speaker B: So what we have right now is we've built a bristlecone chip, and what we have are these transmon xs arranged in a square grid, and we've put in this extra space here. We put in our resonators to read all of them out. 2d grid, nearest neighbors, and 72 qubits. Here's the chip with all the lines coming out on the outside. And this is in the refrigerator and getting tested right now. And, you know, things look interesting, but there's nothing to report. We have to get all this calibrated and figure it out really well.
00:46:14.514 - 00:46:47.514, Speaker B: Okay, so, I just want to summarize here when the main message here is, you needed both quantity and quality of the qubits. Okay. Quantity is pretty easy. To measure quality, you need to know what your limiting error is, which is generally the two qubit gates. That's the hardest thing, not just the best, but you want to know average when you build a big system. Okay? And, of course, this quality has to be measured at quantity. And also, although you're measuring the basic errors, you want to know what the system errors are, too.
00:46:47.514 - 00:46:50.814, Speaker B: Okay. And I've showed how quantum supremacy can do that.
00:46:52.034 - 00:46:54.374, Speaker C: Your system error is smaller than the.
00:46:54.994 - 00:47:18.664, Speaker B: Yeah, and that's like I said, that's because in our. This is in brackets. That's because we've subtracted away our energy decay terms with a particular post selection we did. But I'm going to say that if you weren't to do that, your system errors would be about 0.50.6% similar to this. It's a different device and different measurements, but it's compatible. These are very compatible.
00:47:18.664 - 00:47:35.000, Speaker B: I'm just saying that. Yeah, the system errors here would be good. We have some other measurements that say that these system errors here are compatible with the 0.50.7%. It's really compatible with that. But you want to do those experiments. Okay. Those are the big things.
00:47:35.000 - 00:47:58.154, Speaker B: Of course, there's more huge number of things you have to worry about building a system. I want to point out, speed is important. As you're looking at it, there can be a huge difference in the speed between different technologies, maybe up to a million. And, you know, okay. It depends what you're doing as it matters, but just be aware of that. And also, the things like connectivity matters, too. Okay.
00:47:58.154 - 00:48:15.032, Speaker B: Error correction. You need at least a 2d. Clearly more connections gives you more things to do. So that's something you have to worry about. It's. So here's are the numbers that I talked in this thing. I went from one d to two d in bristlecone.
00:48:15.032 - 00:49:21.236, Speaker B: We have 72 qubits, and we have to see how this is. I think we're going to be able to get numbers similar to this, but getting everything to work at the same time is hard. And, you know, we just have to do the careful measurements before I talk about it. So we're optimistic, but, you know, we have to do it, and that's just, this takes time. Okay, thank you very much. Could you say a little more about how you measure the system error? So the system error is basically by doing the quantum supremacy experiment and getting those, comparing what we expect, theoretically, experimentally do the quantum supremacy experiment, we can back out the total fidelity of the whole operation, and then we back divide out all the number of, say, two qubit operations to get the basic two qubit gate error.
00:49:21.340 - 00:49:24.020, Speaker D: So you expect the errors to just add linearly.
00:49:24.172 - 00:49:50.028, Speaker B: Yeah. And that's actually still probably something. People will debate whether that's happening for real. And we have to test that. But that's kind of what we see so far. Within a factor two, if you design the algorithms right, you can add the errors. Probabilistic, you know, classically, that's kind of a strange assumption.
00:49:50.028 - 00:50:12.632, Speaker B: It's not necessary. What I would say is you do things when you build your algorithm to change the state in a way that you can compute, but to kind of randomize whatever errors you're having so that this kind of thing happens. And that means you're compiling it properly, and that's why it works. But this is a big deal.
00:50:12.688 - 00:50:17.804, Speaker A: There'll be more time for discussion later because there'll be a q and a in the afternoon. So I think we'll move on.
00:50:24.604 - 00:50:25.092, Speaker B: All right.
00:50:25.148 - 00:50:31.004, Speaker A: The next speaker is Ben Reichardt from USC, and he's going to tell us about testing physics with small.

00:00:00.320 - 00:00:01.994, Speaker A: Reed Solomon, proximity test.
00:00:03.454 - 00:00:25.674, Speaker B: Thanks for the invitation. So I'm going to be talking about deep fry. Which stands for something unlike many of the other types here. And it's ultimately about some interesting questions about polynomials. So the setup. So I'm going to say very, very little about starks. Which is another form of sublinear time proving.
00:00:25.674 - 00:00:47.706, Speaker B: The main ingredient of stacks is a certain protocol. In the original stacks, there was a certain protocol called the Fry protocol. Which stands for something which we'll see soon. And I'm going to recap what that protocol is. At some point. I will say things. I'll describe what the protocol is.
00:00:47.706 - 00:01:02.018, Speaker B: I'll describe a new, optimal analysis of this protocol. And then I'll finally talk about what deep fryer. So deep fry is a deep version of fry. And deep stands for something. It has meaning. Good. So a few slides on what the setting is.
00:01:02.018 - 00:01:20.604, Speaker B: The setting is IoPp's interactive oracle. Proofs of proximity. And the setting is for sublinear time proof verification. There's a verifier who has access to some string f. That's a long string, f. The verifier hasn't even read the whole string. Just gets to poke it at a few places.
00:01:20.604 - 00:01:38.564, Speaker B: And a prover tries to convince the verifier that f has some property. So the verifier asks questions of the prover. The prover replies. The prover can reply either by just giving an answer. Or the prover can also reply by writing down another string. Which the verifier can then ask, look at in certain locations. So.
00:01:38.564 - 00:01:55.550, Speaker B: And then in this, there's some prover time. There's a verifier time. And there's the total length of all the proofs written down by the prover. And these are all quantities of interest that we want to minimized. So in picture, there's a proof of this verifier. There's a common string, f. We count the number of accesses of the verifier into f.
00:01:55.550 - 00:02:18.226, Speaker B: And that it is by allowing that, that we can hope for a verifier that runs in sublinear time. It sends some questions. The prover responds with some answers, some questions, some answers, etcetera. And the verifier gets to poke any of these FIS. And read individual locations. Okay? And we have two requirements for this. The completeness and the soundness.
00:02:18.226 - 00:02:53.294, Speaker B: The completeness is that if f has the property. The prover should be able to convince the verifier to accept with probability one. Since we are in the sub linear time setting, you cannot hope to be dead sure that f has the property. If f doesn't have the property, but is very, very close to having the property, then you must end up accepting that with reasonable property. So this is inevitable just because we're working with sublinear time. So the best soundness we can hope for is that if f is delta far from the property, then the prover cannot convince the verifier to accept with high probability. So this is our goal in the completeness case for f, with the property we want to accept with probability one for f.
00:02:53.294 - 00:03:13.590, Speaker B: In the soundness case, if f is delta far from the property, we want to reject with high probability. So that's the setup. So sublinear. You mean for the input strength sublinear time in the input string? Yeah. Which was that long string, f. That's right. The running time sublinear.
00:03:13.590 - 00:03:29.142, Speaker B: What was the question? There is the input string, and then there's the messages of the program. Right. Sublinear time, sublinear in the input string. That's right, yeah. Right. That's right. Good.
00:03:29.142 - 00:03:59.890, Speaker B: So for this. So for this problem, there are many, there's a very long history, which was covered very well in the whole workshops. So I'm not going to say much. I'm just going to talk about one particular thing. This is the Stark protocol by Bbhr, Ben Sasson et al. And amongst all the many protocols described in this workshop, the claim to fame of stocks is that they are practical, they have fast verification, they have no trusted setup, and they're post quantum. I'm not an expert on all these things, but I know that these are the claims to fame.
00:03:59.890 - 00:04:22.814, Speaker B: The claim to notoriety of this is that it has large proofs which. Okay, this is unfortunate, but people are working on it as we speak. And there are two main ingredients to starcs. One is encoding computations using univariate polynomials. And the second aspect is verification of polynomiality. And so I'm not going to talk much about the first aspect at all. I'm only going to talk about the second one, which is the verification of polynomiality.
00:04:22.814 - 00:05:03.050, Speaker B: So I should mention that many recent works in this area, encoding computational univariate polynomials was a big step because in a lot of the classical PCP stuff, multivariate polynomials was where all the action was. And even daring to think you could do something with univariate is quite new because univariate polynomials are inherently very non local. So it was brave that things could happen this way. And it's quite interesting. So what I'm going to talk about is IOPP is for the property of being a low degree polynomial. I have a string. I wanted to know, is it a low degree polynomial or is it far away from being low degree? So this is the setting.
00:05:03.050 - 00:05:43.694, Speaker B: We have a finite field f of size q, we have an evaluation domain d, which is of size n. N need not be the same as q, and we have access to some function f from d to q, d to fq, and we have help from approval. And we want to know, is this close to a univariate polynomial degree? Without help from approval, you have no chance, because if you just make a small number of queries into the domain d, it's consistent with some univariate polynomial. As long as the number of queries you make is less than the degree, there's some univariate polynomial consistent with what you see. So the prover is essential in this model. So you want the locality to be less than deep. Yes, that is right.
00:05:43.694 - 00:06:16.534, Speaker B: And so if f is a polynomial degree less than Rho n, we accept f is far from polynomial to degree less than Rho, and we reject. And Rho is going to be a parameter which we think of as a constant, maybe 0.1. So there is a protocol given for this problem by Bbhr. This is called the fry protocol. It built on some slightly earlier works, also in the late tens. So it's a very elegant, fast protocol. For this, my goal is to describe.
00:06:16.534 - 00:06:34.514, Speaker B: I will describe this protocol completely, and its properties are the following. It has on order n prover work order and proof size, order log n, verifier time and order log n queries with order log n rounds and with all constants are extremely small.
00:06:35.654 - 00:06:37.194, Speaker A: And time is field operations.
00:06:37.614 - 00:07:07.582, Speaker B: Time is field operations, that's right. And you say order and prover work. That's a bit fishy. You're talking about polynomials of degree, and isn't there an FFT involved? But the answer to that is it's order and proverb. Work after f has already been computed. So once f has already been computed, only further work is only order n. Inevitably, in any stock or whatever proof system you have, the computation of the function that's supposed to be the low degree extension of something would have involved an FFT, where n log ns would have gone on.
00:07:07.582 - 00:07:50.770, Speaker B: But at this stage it's only order n. Is that ok? I should mention so for this, if you ask for the same problem and you relax the requirement of, let's say elegant, then. So it's actually elegant too. But it's not concrete. So this is a result of ale and nick and Ariel and others, which solves exactly the same problem with much better theoretical bounds. It has order n log n prover work, but order n proof size still order poly log n verify time, but only constant queries and two rounds. So this is really, really impressive.
00:07:50.770 - 00:07:54.894, Speaker B: On the just raw parameters.
00:07:55.234 - 00:07:58.050, Speaker A: Can we have to get the proof size to be sub linear?
00:07:58.202 - 00:08:09.224, Speaker B: Yes, yes. Because of very recent results by Ron and Noga from a few days ago. And that's a. Yeah.
00:08:11.284 - 00:08:13.264, Speaker A: Depends on the query complexity.
00:08:16.164 - 00:08:42.351, Speaker B: Good. And so this has big constants. Okay, so I'm now going to describe the fry protocol. Okay, let me also mention it's open whether you can do linear proof size in one round, namely a PCPP for this problem. It is known how to do an n poly log n proof size for this problem. This is by Ben Sasson, Sudan. This was a very influential work.
00:08:42.351 - 00:09:15.926, Speaker B: It was the first time univariate problems were really used. It lies underneath both the results I mentioned. So the main building block of the fry protocol is an algebraic sketch. I'm going to describe it first in terms of properties, and then I'll tell you what it is. So you're given a function f defined on a domain D, and it also takes in a seed x. And what it outputs is a function defined on another domain of half the size. So it looks a bit like an extractor takes in a seed.
00:09:15.926 - 00:09:29.586, Speaker B: It has a long. Takes in a long function, gives you a short function. And it has properties. So now the properties are. So it is local. Every entry of f prime depends on just two entries of f. It is degree respecting in that.
00:09:29.586 - 00:09:54.854, Speaker B: If f is a flow degree, so is f prime. If f is of degree rho n, this is rho times n over two. So it's still the same fractional degree. And it's also. And this is the most important part which makes it useful, is Farness preserving. If f is far from low degree polynomials, so is f prime. And then there's some quantitatives in how far is far? And that's where the soundness action happens.
00:09:54.854 - 00:10:14.034, Speaker B: So these are the properties of algebraic sketch. Once you have an algebraic sketch, I can now describe to you the fry protocol very easily. But just to get a sense of it, let me tell you what's also inside the algebraic sketch. So here it is. I'm describing the whole algebraic sketch. It's quite simple. It's based on the same ideas that go into an FFT.
00:10:14.034 - 00:10:45.350, Speaker B: So this only works when the domain d is size of power. Of two. And we make d is the nth roots of unity, where n is a power of two. Good. And so first, let me tell you what to do on polynomials. If f is genuinely polynomial, what you do is you break it into the odd part and the even part. This gives you two polynomials, g of t square and h of t square g and h, since they take t square as input, are naturally defined on the n over two th roots of unity, because you're already squaring beforehand.
00:10:45.350 - 00:11:28.408, Speaker B: So g and h are naturally defined on this domain d prime, which is n over two wth roots of unity. And you use x to give. So you use the seed x to take a random linear combination of g and h. And this is the algebraic sketch of f, takes f and the seed x, and it produces this. If the observation is that if f was degree d, then the algebraic sketch is degree d over two. That's clear. You can also make this definition for any function f, even if it's not a low degree polynomial, just by this formula, at any point, if you want to evaluate at this point u, look at the two square roots of u and computer f at these two points and do some linear combinations with x and y.
00:11:28.408 - 00:11:49.770, Speaker B: And so this is a formula. This is the algebraic sketch of f with input x. And it is clear from this that low degree polynomials go to low degree polynomials. So now I am telling you what the fry protocol is. Given this algebraic sketch, we start with f. There are two phases. There's the commit phase where the prover has to write down a bunch of things.
00:11:49.770 - 00:12:23.264, Speaker B: And then we're going to check what he writes. The verifier first picks a random x zero and asks for the algebraic sketch of f with respect to x zero. That's half the size. Then we do it again and we get f two and f four, etcetera, f three, etcetera, and each one of them is half the size of the previous one. So these all shrink and the total amount of proof length written is o of n. Good. Now the query phase to check that what the prover wrote is actually okay.
00:12:23.264 - 00:12:47.892, Speaker B: And. Yeah, and so the observation was that if you started with a low degree polynomial with degree rho rho n, this would be rho of n over two, rho times n over two, rho times n over four, etcetera. At some point you would get a constant degree zero polynomial evaluated at a bunch of points. And you have to make sure that they're all constant at the end. That's what we're hoping for at the end. Okay, so now the query phase. The query phase has.
00:12:47.892 - 00:13:16.374, Speaker B: I mean, it's almost obvious what we want to do. First, we use the locality property to check that each fi is consistent with its fi minus one. So you check this consistent, and finally you check that the last one is constant. And this is the protocol. There's some subtleties in where you do the checking, but, okay. At this level of talk, it all works. Okay, now I'm going to give you a sketch of the analysis and highlight the main lemma that happens inside.
00:13:16.374 - 00:13:24.094, Speaker B: Okay, so the analysis. Oh, fry is fast. Read solomon iopp.
00:13:26.634 - 00:13:28.054, Speaker A: Or f for short?
00:13:28.634 - 00:13:47.734, Speaker B: F for sure. In fact, my whole talk is f for sure. So let's get so. Okay, so if f was truly a low degree polynomial, it's clear. You could have done everything. All the f I's would have been low degree all the way through, and at the end, you'd have got a constant. All the test would pass.
00:13:47.734 - 00:14:18.304, Speaker B: The soundness is, suppose f was far from low degree. We have some farness preservation. So now you want to show that the protocol rejects with high probability. Okay, so then you take two cases. Did you write all your f I's? Honestly, was f I truly the sketch of f I minus one? If it was then, and fi minus one was far, then so is f I. So if at every stage, you wrote your sketches honestly, then you would have stayed far, and at the very end, you'd be far from constant, and you would have caught it.
00:14:18.644 - 00:14:24.268, Speaker A: Wait, is the main thing you need to prove that, really, this sketch can't get you closer to.
00:14:24.356 - 00:14:37.782, Speaker B: Exactly. So the farness preservation property is what I will discuss. It's one of the properties that we will prove. That's right. And if you had honestly written all the sketches. Yeah. Okay, then we caught you.
00:14:37.782 - 00:15:09.266, Speaker B: And if you didn't write the sketches honestly, then I would catch you in the local consistency between fi and fi minus one. But again, there's some subtlety about where exactly you do the checking. But anyway, at this high level, it just works. The subtlety is. Oh, you could make errors of different regions in different levels, and they could. Overall, you could just make one over log n fraction errors at every level, and they could be all in disjoint parts so that by the end, you made. Yeah.
00:15:09.266 - 00:15:28.794, Speaker B: Okay. And you can fix it. I'm not saying that now. Okay, so now I'll tell you what the theorem about the soundness guarantee of Fry is. This is what we prove. Yes. So, I forgot to say, this joint work with Leo Goldberg Elie Bensasson and Shivangi Saraf.
00:15:28.794 - 00:16:11.574, Speaker B: The theorem is that if f is delta far from polynomials of degree rho n, then whatever the prover does, phry rejects with probability min of delta and some quantity. If rho is a small number like 0.1, then this, this min of delta and whatever is just delta. And this is the best you could hope for for this result. Previous, the original analysis gave a minimum of delta and one fourth. So it wasn't able to go into the higher rejection probability zone. And a previous analysis with Ellie and Shivangi gave one minus rho to the one fourth using some other method.
00:16:11.574 - 00:16:35.012, Speaker B: And finally, and this sort of came as a big shock to us, is that one minus rho to the one third is necessary in this. So there is no tighter bound for Fry. And the necessary is in the sense that, ok, there are certain settings where for infinitely many values of row, you can set up situations where there's a proverb strategy to cheat.
00:16:35.108 - 00:16:38.828, Speaker A: Is there a way for avoiding these settings in the application?
00:16:38.876 - 00:17:03.268, Speaker B: Yes. So, one example. So these settings we only know how to produce in fields are small characteristic and also when the evaluation domain is the whole field. So if the evaluation domain is just a subspace or a subgroup which is incomparable to the size of the whole field, then these counterexamples don't survive. And there could be a better fry theorem for them. So this lower bound is for this specific protocol. It's for this specific protocol.
00:17:03.268 - 00:17:08.624, Speaker B: And it's also for a slightly more general problem, which as far as slightly more specific problem, which.
00:17:10.743 - 00:17:22.363, Speaker A: Okay, is it possible for a random subset? Then it's delta, like the sketch is delta on a random subset.
00:17:23.343 - 00:18:03.896, Speaker B: So you're asking, if you start with a random function, is the rejection probability full? Oh, right. Good. We don't even know how to define fry when the evaluation domain is. So, in fact, very good question is, how do you do fry over a general domain? Here we use some algebraic structure of the domain. What would you do in such a thing? And so, the main action in this analysis is the farness preservation lemma. So I'm going to give a full proof of that right now. I don't know how time, but.
00:18:03.896 - 00:18:06.924, Speaker B: Okay, really, I have only five minutes.
00:18:07.664 - 00:18:08.992, Speaker A: You started five minutes later.
00:18:09.048 - 00:18:34.970, Speaker B: Oh, good. Okay, great. Okay, I'll just keep going. Okay, so our hypothesis, we have functions u and v such that u plus xv is delta. Close to polynomials for many choices of x. I wanted to show that u and v are both far. Wait, did I skip the slide? The algebraic sketch is related to linear combinations of functions, random linear combinations of functions.
00:18:34.970 - 00:19:00.834, Speaker B: So the heart of the analysis of the algebraic sketch is this lemma, which is you have two functions, u and v, and for many choices of x, u plus xv is close to polynomials of low degree. Then u and v themselves are close to polynomial degree. That's what the statement is. I am now going to prove this. So the hypothesis is this. We have two functions u v. So that for many choice of x, u plus xv is delta cross.
00:19:00.834 - 00:19:40.074, Speaker B: So let px be the polynomial close to u plus xv. So this is for some x's, we have a px. For those x's, we also have a set sx, which is the set of coordinates of agreement between px and u x. And note that the size of sx is at least one minus delta. This is our assumption. So the idea is to study triple intersections of these sets sx. So the first observation is, if you take three random x, y and z from this collection of x's, their expected intersection size is one minus delta cubed times n.
00:19:40.074 - 00:20:00.764, Speaker B: Each one has size one minus delta. The expected triple intersection is one delta cubed times. And the values of the polynomial of px and the value of u plus xv. Right, right. The evaluation points of agreement. That's right. Yeah.
00:20:00.764 - 00:20:37.374, Speaker B: Okay, so we took a random triple intersection and it has big size. How big? Well, the way I set things up. So remember there is a min with rho to the one third. So it is such that we can assume that this is always greater than rho plus epsilon. So every triple intersection is b. Now the next observation is that if the s x intersect, sy intersect sz is bigger than rho n, then xpxxpy and z, sorry, y p y and z p z are collinear. That is what the claim is.
00:20:37.374 - 00:21:07.716, Speaker B: To see this. First, note that x u plus xv, y u plus y v and z u plus z v are collinear. That is, by definition almost. These three points are collinear, and u plus z v agrees with p z in many points. U plus y v agrees with p y in many points, and u plus x v agrees with p x in many points. How many points in all these points? Well, what do you mean by collinear? These are elements of fq to the n plus one.
00:21:07.880 - 00:21:11.268, Speaker A: So write px as a vector of all of its values.
00:21:11.316 - 00:21:11.980, Speaker B: Okay.
00:21:12.132 - 00:21:18.084, Speaker A: And then x comma px is a vector of one, one dimension larger. So it's.
00:21:18.204 - 00:21:35.880, Speaker B: I see. So u plus xv is a vector. Yeah. So. Yes. So this is not just in the 2d space, this is in n plus one dimensional space. These three are collinear just by definition.
00:21:35.880 - 00:21:54.484, Speaker B: Just by. I mean, we made them collinear. They are clearly collinear. These are also polymers. What I am showing, this is close to this. This is close to this, and this is close to this. And furthermore, the sets where the agreements happen is this set, which is as big as rho n.
00:21:54.484 - 00:21:56.712, Speaker B: It just means.
00:21:56.768 - 00:21:58.880, Speaker A: That if z is some linear combination.
00:21:58.952 - 00:22:04.804, Speaker B: Of x and y, then p same linear. Yeah. Right?
00:22:05.864 - 00:22:07.136, Speaker A: Yeah. Good.
00:22:07.200 - 00:22:49.980, Speaker B: And since this set is bigger than rho n, which is the size of an interpolating set for a polynomial of degree rho n, the agreement, the collinearity on such a big set implies the collinearities of the polynomials themselves. Okay, so this is the most complicated slide of the talk. Okay, so combining this, so we now have many triple intersections that are big. And whenever there's a big triple intersection, you have a collinear triple. This means that there's actually a big set of x's for which x, p, x's are all collinear with each other. And so that means px looks like q plus xr for polynomials q and r for many different x's. So this was the action.
00:22:49.980 - 00:23:22.320, Speaker B: And once you have this, we can finish it up. We know that for many x's, u plus xv is close to q plus x r rearranging u minus q is delta close to x times r minus v. This happens for many x's. When can a vector be close to many scalings of another vector? Well, the vectors basically have to be zero most of the time. And so that means u minus q is close to zero, r minus v is close to zero, and also on the same set. And this implies something more. Okay, so that was that.
00:23:22.320 - 00:23:44.032, Speaker B: I'm zooming ahead. Questions. Oh, finally, I'm going to say a little bit about deep fry. So, deep stands for domain extension for eliminating Britain. Yeah. Okay. Yeah, I'm doing it in the contrapositive.
00:23:44.032 - 00:24:30.154, Speaker B: If for many, x is, u plus xv is close, u is close to some polynomial, and v is close to some polynomial, and that is what we do. So deep fry. Okay, so I am not going to prove anything about it. Maybe if I just convey the main idea, I will be happy with that. So, first, what do you do with approval? When you have access to approval, what kind of questions do you ask them? Do you ask them questions for which you know the answer, and you're just checking if they're honest? Or do you ask them questions for which you don't know the answer. And just wait to see if you can catch them in a contradiction. So, so far, what we did in deep fry, in Fry, was we just asked them to give us the algebraic sketch.
00:24:30.154 - 00:24:53.424, Speaker B: Any entry of the algebraic sketch, the verifier can check themselves. Remember, that's how we did our local checks. Okay, so that's what we did in the Fry protocol. Now, in deep fry, we're going to ask questions for which we just couldn't possibly check ourselves. But we'll just take the answer, incorporate it into our view of the world, and carry on. And at some point, hope to catch the prover. So, what we're going to do is we're going to ask questions that the verifier doesn't know.
00:24:53.424 - 00:25:15.434, Speaker B: Okay? So, what could you ask? So, here is a question that you could ask the prover. You could say, oh, you have a polynomial in mind. Tell me the evaluation of it at this other point, which is outside D. The verifier has no way of checking that. Because that involves a linear combination of D. Different evaluations, or row. And different evaluations from the domain.
00:25:15.434 - 00:25:40.214, Speaker B: But we can take it and say, okay, we'll take that into account, and let's carry on with the protocol. So, you just ask for a little extra information and take it into account. So, what we'll do is we'll pick a z from the big field, fq. And ask, what is pz for? You have a polynomial evaluate it at z. And if it was truly a low degree polynomial, the prover has something to do. And if not, they would just make something up. And then, hopefully we'll catch them later.
00:25:40.214 - 00:26:02.934, Speaker B: So, this is the tiny bit of algebra that will enable it. Suppose the prover claimed that p of z is a. Then the polynomial p of t minus a is divisible by t minus z. So the ratio of those two. This is the polynomial division, is. Is a low degree polynomial. P of t minus a over t minus z is a low degree polynomial.
00:26:02.934 - 00:26:31.694, Speaker B: So now you had access to this function f. We can incorporate the information, the prover's claim about p of z, into this f. We can create a new function, f star, which looks like f star of y, is f of y minus a over y minus z. And this ought to be a low degree polynomial. And if it's not? So, suppose f star was. If f was truly a polynomial. Which did not take the value a at z.
00:26:31.694 - 00:26:44.630, Speaker B: Then this would be a horrible polynomial here. This would be a rational function. Sorry. It would not be a polynomial. It would be a rational function. And this is extremely far from all low degree polynomials. So this is something we should help us catch the proverb.
00:26:44.630 - 00:27:32.776, Speaker B: So here is a fact. If f, if you did this process, then the distance of f star from degree b minus one polynomials you had a function f and you did this process, then distance of f star from degree b minus one polynomial is exactly the same as the distance of f from degree b polynomials consistent with the claim. So the prover making the claim and then you modifying your function and working with that is the same as weeding out all candidate polynomials which are close to f, which don't, which are not consistent with the claim. We're really believing that claim. So now the high level structure of the protocol is something, I'll race through it. So you start with f. You ask, you pick a random zi outside the domain.
00:27:32.776 - 00:27:56.126, Speaker B: You ask for the claims of the values of f on zi. You can ignore this because we won't get into that much detail. Incorporate this into your function f. That incorporation is something you can do locally. The definition of this modified function is just something you can simulate yourselves given oracle access to app. So we take this new function and ask for the algebraic sketch of that and continue with that. So that's what the new protocol is.
00:27:56.126 - 00:28:28.938, Speaker B: And the query phase is just to check local consistency with everything. So this is exactly the same protocol, except we also asked along the way for claims about the values of these FIS outside, and we incorporated them into the function in this division method. And the soundness theorem is that this improves from one minus rho to the one third or one minus rho to the one half. This one to the one half is a holy number. It's the Johnson radius for list decoding. Read Solomon codes, but we don't know how to get rid of it. It's a very famous open question.
00:28:28.938 - 00:28:56.886, Speaker B: To improve the list decodability of read Solomon codes up to radius one minus rho. And if it is true that you can list decode this with polynomial list size up to radius one minus rho, then the ultimate theorem happens. So this would have been min of Delta and one minus rho. But Delta is always less than one minus rho, polynomial degree rho. Every function is within distance rho of one of them, one minus rho one of them. So this would have been the ultimate theorem. We don't know how to do this.
00:28:56.886 - 00:29:09.344, Speaker B: This is the famous open questions. So if that was true, then we would have the ultimate analysis. And there's a new Farness preservation. Maybe I don't have time for that. So, okay, it's a statement about something.
00:29:11.324 - 00:29:16.868, Speaker A: Can you say something about the improvement? So you did this sort of deterministic step, right? Was there any randomness?
00:29:16.916 - 00:29:33.328, Speaker B: No, there was. It was a uniformly random z picked outside. Okay, so I'll do it in one picture, you made a claim about some value outside. This is the picture. There are many. The prover has many polynomials in mind. This u plus x v is close to many polynomials.
00:29:33.328 - 00:30:08.446, Speaker B: It will hedge depending on what the x is. It may go to closer to a different polynomial. It's nice to have many polynomials close by. But if you're pre committed to what the value is at some z outside, and it's a random z, then, and this is z can be taken from a much larger domain than what d is itself, then. So degrees here are so small compared to the size of this big domain. So wherever you claim a value, you'd have to be consistent with only one polynomial and not many. So you'd only be able to maintain one polynomial that's close to your function as you cheat.
00:30:08.446 - 00:30:51.584, Speaker B: And when you have only one polynomial to worry about, then it's much easier to do the analysis. So that was some intuitive reason for why committing to a value outside reduces your space for cheating. And one can imply the same method improves the stark reduction from general computation to polynomiality, proving you can ask for values outside the domain where your function is committed to, and you just ask for it and incorporate it into whatever is written and it helps you. Good. And some open questions, which I just leave. Thanks.
00:30:58.484 - 00:31:10.172, Speaker A: So while we talk question. Yeah, so is the conjecture about the sentence of deep fry, is it equivalent to improving the list decoding radius of retelling code?
00:31:10.228 - 00:31:14.584, Speaker B: No, we don't know that. Yeah. So, yeah.
00:31:14.964 - 00:31:30.160, Speaker A: Does this sound, does this have properties as a code? Like if you give the values f minus fa, if you add to the read Solomon code also, we see the evaluation.
00:31:30.272 - 00:31:50.004, Speaker B: Yeah, you can consider rational functions. That's also a very good code, but it stops being linear and then things get messy. So I don't know if that's. Yeah, so I should also say all these lemmas that I stated about Farness preservation. There are analogs for general error correcting codes, depending only on the distance. The polynomials were a bit of a distraction.

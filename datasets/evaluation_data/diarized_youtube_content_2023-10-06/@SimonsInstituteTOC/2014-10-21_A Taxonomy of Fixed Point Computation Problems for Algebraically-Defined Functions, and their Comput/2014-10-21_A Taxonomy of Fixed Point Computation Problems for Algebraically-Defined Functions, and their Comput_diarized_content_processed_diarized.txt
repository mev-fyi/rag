00:00:02.120 - 00:01:14.948, Speaker A: So the title is rather long. It's about the complexity of fixed point computation problems defined by algebra for algebraically defined functions. But I was quite influenced by Frank's email when he pointed out to us that we need to be careful about how many slides we're trying to go through. And I realized that it's much more sensible if I try to focus on a particular subtopic. And this is what I will try to do fairly shortly after the start of the talk, is to focus on algorithms for branching Markov decision processes and probabilistic min max polynomial Bellman equations for them. And some of the key things that I would like to be able to get to, which I think would be of interest to some of the people in this audience, is a generalization of Newton's method that works on the piecewise differentiable functions defined by these Bellman equations, and not only works, but allows us to obtain a polynomial time algorithm for approximating the value of these branching mdps. And I also like to get to some nice open problems at the end that I'd like to tell you about.
00:01:14.948 - 00:02:04.596, Speaker A: But I do want to spend a little bit of time at the beginning giving you the complexity landscape of where these problems sit in my worldview of complexity. Okay, so, fixed point computation problems. Everybody knows Brouwer's fixed point theorem. Every continuous function from a compact convex subset of euclidean space to itself has a fixed point. And computationally, we're assuming somehow, many, many computational problems boil down to we're given a function, somehow a brower function of this kind, and we're asked to compute or approximate a fixed point. So, of course, in general, all of the fixed points may be irrational valued. So when we say compute, we don't necessarily mean exactly.
00:02:04.596 - 00:02:49.556, Speaker A: We're often happy with approximation. But what do we mean by approximation? And there are two sort of different standard notions of what one might mean by approximating a fixed point. And the two different notions have rather different complexity implications, so in different contexts. So one notion would be that we're given this function, and what we want to compute is a point, a rational vector that is almost fixed by the function. So the point is not moved by more than epsilon. And for concreteness, I'm fixing the l infinity norm. But in general, one could imagine other it doesn't matter.
00:02:49.556 - 00:03:26.984, Speaker A: So, a different notion is near approximation of the fixed point. And here what we want is we want to compute a rational vector in the domain which is near an actual fixed point. Are almost points near near points, or can they? No. So, in general. So, of course, in the limit, yes, in the limit, it's true. But it turns out that it's not the case. You can have, in fact, for example, the thick, let's say, Nash's functions for Nash equilibria, which are Brouwer functions.
00:03:26.984 - 00:04:10.320, Speaker A: It turns out that you could be a excruciatingly close, almost fixed point, but be nowhere near the unique Nash equilibrium of the game that you're studying. So these things make a difference in general. So near in general tends to be a stronger notion. And in fact, formally, you can show for so called polynomially continuous functions, meaning once you've got a reasonable bound on the modulus of continuity of the function, then if you get near approximation, you've got almost approximation, but not the other way around. Okay, so in this talk, I'm interested in near approximation. Go ahead. Yes.
00:04:10.320 - 00:04:44.048, Speaker A: Brouwer's fixed point theorem tells you the existence. Okay, okay, thanks. So it guarantees it for you. Okay, so now we're, so we're interested in near approximation. And not only that, I'm interested in worst case complexity, and I'm interested in worst case complexity in the Turing model of computation. Okay, so, okay, so we can define complexity classes that essentially capture a whole plethora of such fixed point problems. And here's a complexity class.
00:04:44.048 - 00:05:45.598, Speaker A: Well, I'll give you two versions of it. One is a real valued version, so this is not really, you can't make sense of it in the Turing model. The other is an approximation version, fixed b, sub a, is the approximate version of it. And that's the one that we should focus on in some sense. But so these are classes of total search problems. What are they? So, the input is given to us by an algebraic circuit or straight line program using gates plus times and max and rational constants, positive or negative rational constants having n input variables x one through xn and n output gates such that the circuit represents, in the obvious way, a continuous function from the unit n cubed to itself. Now, and you might say, well, how do you know it maps the unit n cubed itself? Either you can just be told that, or you can actually syntactically constrain it using max and min so that it does do so.
00:05:45.598 - 00:06:42.780, Speaker A: Okay, so in the case of the approximate version, we're also given an error parameter epsilon as input. Okay, now what do we want? We want to compute a fixed point of f, or in the approximate version, we want to compute an epsilon near approximate fixed point. Okay, so everybody with me, right now, we close these search problems under suitable reductions. In the case of the real valued one, we have to be careful what notion of reduction we mean. And there we just mean that you transform the problem into a fixed point problem, and then any fixed point that's given back to you through a separable linear transformation, you can get back the answer to your problem. And in the case of the approximate version, it's just the standard polynomial time search problem reductions. Okay, the resulting complex class we call fixed p and, respectively, fixed pa.
00:06:42.780 - 00:07:05.234, Speaker A: And it may not seem like a particularly robust class, but trust me, it is. It's very robust. You can add all kinds of other operators to this class and it will not enhance its power. You can change the domain to any convex polytope domain. You can even have ellipsoid domains. It doesn't change the power of this class.
00:07:05.694 - 00:07:07.234, Speaker B: Repeat those definitions.
00:07:08.414 - 00:08:04.054, Speaker A: Which part of it? This is the definition of the class. Any problem that is reducible to computation of a fixed point of an, of a function given to you by an algebraic circuit using gates plus times and max, that's it, right? And the function maps the unit n cubed to itself. Any function that is, any problem that is reducible to that. Think of it as just polynomial time reducibility. The reason why I had to be a little bit careful is because in the real value case, I have to tell you, well, what do you mean by polynomial time reducibility? If I give you a real value vector, how are you going to look at it? And I'm saying the only way I'm going to look at it that way is just a separable linear transformation. So the elements of this class are functions, sequences are functions. The elements of this is a search problem class.
00:08:04.054 - 00:09:06.414, Speaker A: So basically, I give you such a function, I give you such a function specified by a circuit, and I ask you give me any fixed point for it, or give me any approximate fixed point for it. It's a total search problem class. Search problem classes are class of problems where the input is a string, okay? And the output can be any one of the solutions to that problem. Right? Now, for example, in discrete search problems, like, for example, I don't know, take the problem of finding hamiltonian cycle in a graph, phrased as a search problem is give me a hamiltonian cycle. There are maybe more than one hamiltonian cycle. Any one of them will do. Okay? Here, this is a search problem where I say any one of them will do, any one.
00:09:06.414 - 00:09:58.358, Speaker A: What is the exact meaning of that class? It's specified right here. It says, I also give you an epsilon and I give you the. So I'm kind of conflating two definitions together. The sub a one is the approximate one, the other one is this. You know, it's living in a, in a model of computation that we don't know how to deal with, namely real value computation. But nevertheless, these both have, you know, these are very robust classes, and they have a complete problem in both cases, computing a Nash equilibrium, or epsilon, approximating a Nash equilibrium. In the case of fixed pa for a game with three or more players, given the game and given Epsilon is, well, respectively, fixed p complete and fixed pa complete.
00:09:58.358 - 00:10:41.834, Speaker A: And this is not the only complete problem. Computing market equilibria for various kinds of markets, and so forth. There's a lot of complete problems for this class. Okay, now, you might have heard of a complexity class called PPAD, defined by Papua new in the early nineties. I don't want to dwell on this side. As I mentioned, I really want to get to the latter part. The only thing I want to mention is that if you've heard of PPAD before, corresponds precisely to the piecewise linear fragment of fixed p, namely, restrict yourself to just the gates plus and max and multiplication by rational constants and take the same definition, and that's p pad.
00:10:41.834 - 00:11:49.784, Speaker A: Okay? And Scarf's algorithm also tells you that almost fixed point computation for polynomially computable, polynomially continuous brower functions is a problem that's in PPAT. Okay? So in other words, you can extract from Scarf's algorithm the fact that computing an almost fixed point for well behaved functions is a problem that you can basically boil down to the piecewise linear fragment of fixed p. Okay? Okay. So, and there's these well known results going back to 2006 by Daskalakis et al. That say computing a so called epsilon Nash equilibrium, which is something that is almost Nash equilibrium for a three player game is PPAD complete. And computing an exact rational nash equilibrium for two player games is PPaD complete. For two player games, the underlying functions are piecewise linear.
00:11:49.784 - 00:14:14.102, Speaker A: And Scarf's algorithm, however, does not in general, give us a way to compute a point that is near an actual fixed point, okay? And that so computing something that's near an actual fixed point is not reducible to kind of piecewise linear fixed point computation problems for, you know, in other words, there's this distinct difference for these more for this more enriched complexity class, fixed p, which includes multiplication, than for the piecewise linear fragment. Okay? And in fact, we can pinpoint precisely the extra hardness that you get for approximation problems for this complexity class fix p, and for many problems in it, by discussing a very basic, what seems like a ridiculously simple decision problem, which is you're given as input an arithmetic circuit or straight line program that just has input one and plus times and minus gates. Right? And you're just trying to decide whether the output value of this circuit, there's some designated output gate, and you're trying to decide, is the output value positive? Okay? So, you know, you might say to yourself, well, what the heck? Why don't I just evaluate the circuit? So what's wrong with that? Why can't we just evaluate the circuit? Because of repeated squaring, the numbers could get astronomically big. Even with a circuit of size n, you could build up numbers that are of the form two to the two to the n. So you, you couldn't write down those numbers in binary representation in a succinct way, necessarily. And this PoS SLP actually captures essentially the power of polynomial time in the unit cost arithmetic Ram model of computation, in the sense that it's actually complete under Turing reductions, if you like, for this class. Okay, so in this really lovely paper by some of the people in the audience, they showed that posycel p is decidable in the counting hierarchy.
00:14:14.102 - 00:15:21.234, Speaker A: So if you don't know this class, nevermind, but it's somewhere just below polynomial space, and nothing better is known. So we don't know that, for example, this is in NP or in the polynomial time hierarchy, and so forth. Okay? Okay. So now let me relate this positive cell p problem to even getting any non trivial approximation of, for example, a Nash equilibrium. So any non trivial approximation of a Nash equilibrium is positive. Hard in what sense? So for every epsilon greater than zero, you can reduce Paas SLP to the following problem. You're given a three player game with the promise that it has a unique Nash equilibrium, which is fully mixed, and the probability with which player one plays its first pure strategy, let's say it's some specific pure strategy, is either less than Epsilon or greater than one minus epsilon, and you can't tell which of the two is the case without solving PoS SLP.
00:15:21.234 - 00:16:48.230, Speaker A: Okay? So in other words, any non trivial approximation of Nash equilibria, which happened to be the fixed points of the kinds of functions that I was describing to you before, is going to be at least as hard as this problem, which really is a linchpin problem for understanding the difference between the complexity, understanding the difference between polynomial time in the Turing model versus the arithmetic unit cost arithmetic model. Okay, so what makes these fixed point problems hard or easy? So all of these problems are in general not np hard, because existence of a solution is guaranteed. PPAD hardness, sort of papimishus notion of PPAD PPAD hardness captures a combinatorial difficulty of computing, or even almost approximating a fixed point, but it does not. But there can also be an additional numerical difficulty for near approximating a fixed point, which is not captured by p pad hardness. Namely, it is captured by this positive cell p hardness. And the interesting thing is that these two difficulties are really orthogonal in the sense that you encounter fixed point problems that have only one of these difficulties, but not the other, and the other way around. And there's also a bunch of problems that have some kind of intermediate status in terms of their difficulty.
00:16:48.230 - 00:17:21.138, Speaker A: And so fixed ba complete problems have both of these difficulties. So. And this is, there's no way on earth that I can do justice to this picture. What I'm trying to depict here is that there's two different axes, combinatorial difficulty and numerical difficulty. And there are, you know, sort of problems that are combinatorially rather hard, fixed point problems that are combinatorially rather hard. But there are also some intermediate combinatorial difficulties that you encounter. So Pghard stands for parody game hard, and if you don't know what that means, ignore it.
00:17:21.138 - 00:17:51.274, Speaker A: But on the other axis. So pause. SLP hardness, sads for numerical difficulty. And there are also some intermediate difficulty problems, like square root sum hardness and so forth. So these are problems that we don't have a good handle on. And they seem more tractable potentially than positive lp hardness, but nobody has any answer for it. Okay, I've laid out the landscape, and now you can just forget about what I said.
00:17:51.274 - 00:18:41.392, Speaker A: What I wanted to do is say, lay out the complexity landscape within which I want the worldview to be set for the rest of what I'm going to talk about now, I'm going to talk about much more tame fixed point problems. Namely, we're going to restrict ourselves to monotone, algebraically defined functions. So in a sense, a monotone fragment of what I was talking about before. And as we'll see, these have many applications. Okay, so let's talk about a classic stochastic process, multi type branching processes. So these go back to Kolmogorov, and even before that, in the one type case, they go back to Galton and Watson in the 19th century and so forth. So they're very, very rich history in probability.
00:18:41.392 - 00:20:02.824, Speaker A: Okay, so what is this process? You have a bunch of different types in the population, you can imagine a population of different cell types, there are red cells, blue cells and green cells. In each generation, an object of, let's say, of the red type will in the next generation give rise as offspring. Potentially it will give rise to two blue ones, a green one, and a red one with probability one third. Or it will give rise to a blue one and a red one with probability one half, or it will give rise to nothing, meaning it will die with probability one six. Okay? Likewise for a blue type with probability one fourth, it'll give rise to two red ones, and with three, four, it'll die. Okay? And a green one with probability one, it'll give rise to that, right? So, for example, if we start with one red object, then in the next generation we might have used that rule and generated that, right? So with one three probability, this might have happened. And then in the next generation, the blue ones might have died and the red one might have also died, but the green one, without choice, had to give rise to that.
00:20:02.824 - 00:20:51.834, Speaker A: And we keep going. So this gives, essentially this is a stochastic process generating a random labeled tree starting from one object, right? And, but in some cases we may end up becoming extinct. The entire tree is finite. Okay? But it need not be finite. Okay, so here's a question. What is the probability of eventual extinction starting with one red object? So let's write down some polynomial equations for this. So let's associate a variable x, sub red to the probability of eventually going extinct, starting with one red object, okay? So what should this probability be? Well, it's not too difficult to see that.
00:20:51.834 - 00:21:58.464, Speaker A: Well, with one 6th probability, we're immediately going to go extinct. And then with one third probability, what we have to do is independently we have to go extinct from one, from two blue ones, a green one and a red one. So essentially what we're doing is if we associate similar random similar variables with the probability of going extinct from one blue type, then essentially we have this monomial representing the probability of going extinct if we chose that, and we have that monomial for that and so forth, right? And we can likewise write down equations for the other types, right? So we get nonlinear fixed point equations, n equations in n unknowns. Fact is that the extinction probabilities are the least fixed point in the unit n cubed, in the unit three cubed. In this case of these equations, least, what does least mean? Least fixed point means. It's a good question. These happen to be, and I'll describe that in a minute.
00:21:58.464 - 00:22:19.878, Speaker A: So these happen to be monotone functions. The right hand sides here are monotone and the mapping. So maybe let me do it like this. I'll explain least in 2 seconds. Okay, look at the polynomials on the right hand sides here. They're very special. They're what I'll call a probabilistic polynomial.
00:22:19.878 - 00:22:52.304, Speaker A: Each of them is a probabilistic polynomial. Basically, the coefficients are non negative and they sum to one. Okay, a probabilistic polynomial system of equations is n equations and n unknowns, where all the right hand sides are probabilistic polynomials. Right. You're with me. Okay, so every multi type branching process with n types corresponds to one of these, and vice versa. And what I'll call a monotone polynomial is a polynomial where the coefficients are non negative, but do not necessarily sum to one.
00:22:52.304 - 00:23:22.408, Speaker A: Okay. Monotone polynomial systems are defined similarly. Okay, well, sorry. This should be monotone, right? So, monotone polynomials are defined similarly. So here are some basic facts. So, a probabilistic polynomial system, not only is it a brower function, not only does it map the unit n cube to itself, but it's also a monotone map. So, does everybody here know what a monotone map is? Oh, no.
00:23:22.408 - 00:24:17.840, Speaker A: Okay, so I'll have to write that down, f from domain to domain d, where let's say this domain is any lattice, but let's just pick. So, a function from the unit n cubed to itself is monotone. If for all x, y in, if x less than or equal to y coordinate wise, then f of x is less than or equal to f of y coordinate wise. Okay, so that's what it means to be monotone. Okay? Is that clear? Yeah. Okay. So this defines a monotone map from the unit n cubed to itself.
00:24:17.840 - 00:25:04.086, Speaker A: And monotone polynomial systems, if you basically extend the non negative orthon with infinity, they define a monotone map from basically the non negative orthon with infinity attached to itself. Okay. And you might ask, well, wait a second. What's the arithmetic? It's just the standard semi ring when you attach positive infinity to that. Now, a probabilistic polynomial system has a least fixed point in the unit n cubed, and this follows directly from Tarski's fixed point theorem. Tarski's fixed point theorem tells you any monotone map from a lattice to itself not only has the least fixed point, but it has a lattice of fixed points. And so there's also greatest fixed points and so forth.
00:25:04.086 - 00:25:43.786, Speaker A: But I don't want to dwell on it. But. So this is a freebie. A fixed point theorem gives you that. And likewise, Tarski's fixed point theorem tells you that any monotone polynomial system has at least fixed point, including possibly some coordinates, or maybe all coordinates that are infinity. But we'll call it monotone polynomial system feasible if it so happens to have a non negative real least fixed point. Okay, so what does it mean to be a least fixed point? It means that you are a fixed point and you are, coordinate wise, less than or equal to any other fixed point in the non negative orient.
00:25:43.786 - 00:26:40.298, Speaker A: Okay. Okay, good. Furthermore, the least fixed point you can obtain as simply the limit of iterating the polynomial system, or whatever it is that you have iterating it starting from the zero vector. So, doing what you like, value iteration, or others call it piezo iteration. I mean, there's 100 names for this, okay? But now and again, the least fixed point corresponds to the vector of extinction probabilities that we want to compute for branching processes. And for more general monotone polynomial systems, it actually defines something called the partition function for the corresponding weighted context free grammar, but I'm not going to dwell on that. Okay, so the question is, can we compute these guys efficiently? Can we compute them in polynomial time? So let's use a standard workhorse of numerical methods, Newton's method.
00:26:40.298 - 00:27:25.234, Speaker A: Um, so Newton's method, we, I mean, I don't need to tell people here what Newton's method is, but restricted to the polynomial systems that we're trying to solve. The expression for Newton's method looks like that. In other words, we're looking at the jacobian matrix. So this p prime is the jacobian matrix of the polynomials on the right hand side of these equations. And this is what it looks like. Okay, so everybody with me? Okay, so we can decompose a system of such equations into its strongly connected components. So yesterday, Pablo Parello was giving a talk about sort of chordal decompositions here.
00:27:25.234 - 00:28:24.310, Speaker A: I'm talking about a much more basic kind of decomposition. This is just, you look at the variable dependency graph, where suppose you have an equation, xi is equal to pix, right? And suppose some variable xj occurs with a positive coefficient on the right hand side. Then you have a, in your variable dependency graph, you have an edge from xi to xj. And it's, if you think about it, it's sort of brain dead obvious that what you want to do is decompose such systems of equations into strongly connected components and solve them bottom up, because there are parts of your system that don't even depend on other parts of your system. Okay, now if you do such a decomposition, and importantly, if you eliminate the zero variables in your system of equations. By zero variables, I mean those variables that will evaluate to zero in the least fixed point. They can actually be detected very easily by doing just an and or graph analysis.
00:28:24.310 - 00:29:22.928, Speaker A: It doesn't, you don't even have to look at the numbers in the polynomials. So once you eliminate those, if you start from the zero vector, both for ppss and more generally for all feasible monotone polynomial systems, Newton's method converges monotonically to the least fixed point solution. Okay. In our original papers on this stuff, we gave no upper bounds at all for the number of iterations that might be required. We actually proved PoS SLP hardness for any non trivial approximation of the least fixed point for monotone polynomial systems associated with a model that's a bit more general, in fact, quite more general, than these multi type branching processes that I described to you called recursive Markov chains. So I want to just describe that to you in a second. So this is an example of a recursive Markov chain.
00:29:22.928 - 00:30:22.778, Speaker A: So think of this as a finite state Markov chain, except it can call itself recursively. These are actually used as sort of basic models of probabilistic procedural programs. So imagine you've got a procedure a that with three fourths probability recursively calls itself, and regardless of what value is returned, whether value one is returned or value two is returned, it recursively calls itself again. Okay? And then with these probabilities, it ends up going to the, you know, to the two different exits, which you can think of as the two different possible values that it could return. Okay? So the question is, what is the probability of terminating at exit two starting from the entry? And again, in a very simple way, we can write down equations for this in the same way that we did before. So let's write down equations corresponding to the probability of terminating at exit one and terminating at exit two. Terminating at exit two.
00:30:22.778 - 00:31:15.814, Speaker A: Well, with one fourth probability, I do it directly. Directly, but with one two probability. If you calculate it, you'll see that the probability that I will terminate at exit two, I might have to do it recursively, either by going through here and then going through there, or by going through there and then going through there. Right? And if you just write it down, you get these polynomials. The coefficients no longer sum to less than or equal to one. These polynomials nevertheless have a least fixed point in the unit n cubed, which gives the termination probabilities that we're interested in okay. And unfortunately, any non trivial approximation of these termination probabilities is positive Celpi hard for these more general recursive Markov chains, even though Newton's method monotonically converges from zero to these values.
00:31:15.814 - 00:31:59.446, Speaker A: So, and I don't, I don't have time to explain it, but in fact, approximation of this least fixed point can be put in this earlier complexity class that I had defined. Fixed p. Okay. Fixed pa. Okay. So in other words, we can boil it down to a unique, in fact, brower fixed point computation problem for algebraically defined functions. Okay, now, what is Newton's worst case behavior for these kinds of systems? So, this was studied by Esparza, Kiefer and Lutenberger after our initial work, where we showed Newton's monotonically always converges to the least fixed point.
00:31:59.446 - 00:33:04.754, Speaker A: What these guys looked at, they looked at it in more detail, and firstly, they gave some bad examples, in fact, rather simple bad examples, that show that even for probabilistic polynomial systems, where the least fixed point solution is the all one vector, Newton's method requires exponentially many iterations as a function of the encoding size of the system of equations, even to converge to within one bit of precision. In other words, to give you additive errors strictly less than one half, it requires exponentially many iterations as a function of the encoding size of the system of equations. Okay. And for strongly connected equation systems, they also gave an exponential upper bound. But they didn't give an upper bound when the system of equations is not strongly connected. But more recently, we gave a matching exponential upper bound for all of these. Basically, any feasible monotone polynomial system, there's an exponential upper bound on how long it'll take for Newton to converge within desired precision.
00:33:04.754 - 00:33:44.824, Speaker A: But, okay, that's not what I'm interested in. I want to tell you about this, which is that for these probabilistic polynomial systems, we can actually get a polynomial time algorithm using Newton's method. And so, in other words, given a probabilistic polynomial system, we can compute a rational vector within j bits of precision in time polynomial, both in the encoding size of the system and in J. And this is just in the standard Turing model of computation. Okay, no infinite precision arithmetic or anything like that. And we're going to use Newton's method. But you should immediately ask, how are you going to do that? You've just told me that Newton's method requires exponentially many iterations.
00:33:44.824 - 00:34:46.323, Speaker A: The catch was this. The bad examples were in the case when the extinction probabilities happened to be all one okay. And it turns out that that is a special case that we can deal with separately using some classic results. So, um. So, um, so it's for, so, being able to decide whether the extinction probability starting from a given type or maybe another way to say it is. Um, we're trying to determine whether the least fixed point of one of these probabilistic polynomial systems is equal to one in some coordinate. And this, it turns out, you can boil down to determining whether the spectral radius of the moment matrix, which is basically the jacobian, evaluated at the all one vector, deciding whether or not that is less than or equal to one, basically allows you to decide whether these things are one or not.
00:34:46.323 - 00:35:12.084, Speaker A: And you can do that in polynomial time. You can decide for non negative matrix n by n matrix to decide whether its spectral radius is less than or equal to one is easily in polynomial time. And in fact, subsequent to us showing that it's in polynomial time, these guys have pointed out that it's in fact in strongly polynomial time. So you can boil it down to solving a system of linear equations. Okay. And deciding whether a coordinate is zero is actually very easier. It's easily in p time.
00:35:12.084 - 00:35:40.206, Speaker A: So, okay, so what do we do? What's our algorithm find and remove all of the variables where in the corresponding coordinate, the least fixed point is zero or one. Plug those zeros and ones into the equation, getting a remnant equation. All right. On that resulting system of equations, just run Newton's method starting from zero. Okay. I'll tell you later about how to deal with rounding issues. Theorem.
00:35:40.206 - 00:37:12.394, Speaker A: The theorem says that given a probabilistic polynomial system with at least fixed points strictly between zero and one, if we apply Newton starting at the zero vector, then all we need are four times the encoding size of the system plus j iterations of Newton's method to get j bits of precision. Okay, and now what do we do about round off error? It turns out that Newton's method is converging monotonically, and if you carefully, in a careful way, round down to a multiple of a sufficiently large number of bits, but only polynomially many bits, then if you do that, then basically with just a couple of extra iterations, you can get the same thing. Okay, so basically what this then shows is that we obtain a p time algorithm in the standard turing model of computation for approximating these least fixed points. Okay, let me give you some idea of the proof, and I think the ideas will be familiar to many of you, but it'll highlight what's going on. So for a probabilistic polynomial system. When the least fixed point is strictly between zero and one, this matrix, the jacobian of p prime evaluated at q, is a non negative square matrix. And we can show that if these conditions hold, then its spectral radius is strictly less than one.
00:37:12.394 - 00:38:27.190, Speaker A: And so therefore this matrix is nonsingular. And in particular, Newton's method, if you remember, is going to be defined because this thing is nonsingular. And since this is nonsingular, obviously, and since the spectral radius of this is less than one, this equality holds. So if you think about it, a crucial role on the convergence behavior of Newton's. So basically, we can show that the number of iterations of Newton's method needed to get within distance epsilon is log of the norm of this matrix plus log one over epsilon. Okay? And now the norm of this inverse matrix is, as you can appreciate from seeing, this is going to be tied to the distance between one and the spectral radius of this matrix, right? Because the further away you are from spectral radius one, the faster these powers are going to converge to zero, which in turn is going to, it turns out it's going to be closely related to the distance between the least fixed point vector and the all one vector. And turns out we can lower bound that.
00:38:27.190 - 00:39:56.322, Speaker A: In other words, we can show that when you remove the all one vector, when you remove the one coordinates, not only is it the case that you are not in the singular case, you're sufficiently far away from the singular case such that Newton's method is going to converge fast, fast, and it's going to basically get you there in polynomial time, even with rounding. Now here's another interesting side bit from that. Remember this pos Slp problem that I was telling you before? It turns out that the problem of deciding, suppose I want to decide whether in some particular coordinate, suppose I give you one of these probabilistic polynomial systems, and I want to decide, you know, is the extinction probability starting with type I less than or equal to p. This problem is equivalent polynomial time equivalent to positive cell p. And the key reason has to do with the fact that basically for these systems, we can get not just quadratic convergence, but quadratic convergence with explicit and good constants. So effectively we can get a result like this that says with, again, somewhat more, but still linear number of iterations of Newton's method, you can get exponentially many bits of precision. Okay, okay, okay.
00:39:56.322 - 00:40:39.736, Speaker A: Now I want to get to sort of. So far there's been no novel algorithms. I'm just using Newton's method as such. So now we're going to talk about branching Markov decision processes where things will get a little bit more interesting. So now what do we mean by branching Markov decision process? It's just like a branching process, except now we have some types that you control. Okay? So I don't know, imagine that you're using these things to model cancer, tumor progression. There are different types of cells, and by injecting some medicine into the setup, you, you put some control over the reproduction of yellow cell types.
00:40:39.736 - 00:41:39.844, Speaker A: Okay? You are able to either make them turn blue, go blue, or red. Now you might want to maximize or minimize the probability of extinction, for example, or other quantities associated with the stochastic process, but now it's a controlled process. So again, it describes a partially probabilistic, partially controlled process for generating a random labeled tree. Okay, so let's write down some equations for the following. What is the maximum probability of extinction starting with one red type? Okay, well, again, for the first three types, again, now let x, sub r denote the optimal, the maximum probability of extinction starting with one red type. Well, here there's no choice. With one 6th probability, we're going to go extinct.
00:41:39.844 - 00:42:39.748, Speaker A: With one three probability, we're going to generate these guys, and our goal is still the same to maximize the probability of extinction, and we have to do it from every one of those, and those are independent things. So these polynomials give us the right equations for these types, and for this last one, that's the only new case, is we just have to take the maximum over the monomial corresponding to the top and the monomial for the bottom. Notice that the right hand sides, max is a monotone operator. The right hand sides here define a monotone function. The maximum extinction probabilities are the least fixed point solution of these systems of equations. Okay, again, now we can define maximum probabilistic polynomial systems where the equations look like this. Xi is equal to max of a bunch of probabilistic polynomials, and we have n equations and n unknowns.
00:42:39.748 - 00:43:25.260, Speaker A: We can similarly, so I should have mentioned we can also do minimum, right? So what is the minimum probability of extinction? Similar equations, except now we have min instead of max. Min is also a monotone operator. The minimum extinction probabilities define the least fixed point are given by the least fixed point solution. So we've got max ppss and min pps's. These are the Bellman optimality equations defined by these things for maximizing and minimizing extinction probability. So we'll use max min to refer to these things. Again, all of the things basically, this is like a carbon copy of what I said before.
00:43:25.260 - 00:44:03.288, Speaker A: All of the things I said before still hold these. Define monotone maps. The least fixed point is exists. It's given to us by the limit of iterating the function starting from the zero vector and the least fixed point is what we're trying to compute. And the question is, can we compute these things efficiently in p time? So, before we were using Newton's method, but now we don't have the functions that we have now have max and min in them. So these are no longer differentiable. They're only sort of piecewise differentiable, if you like.
00:44:03.288 - 00:45:19.394, Speaker A: So what do we do? How do we apply Newton's method to this? So it turns out we can get. So this says that there's a polynomial time algorithm for computing the least fixed point solution to these Bellman equations. And we do it by a generalization of Newton's method that uses linear programming in each iteration. But the generalization is very sort of straightforward to describe. So let me tell you, everybody who's looked at Newton's method, you'll realize what is Newton's method doing? Each iteration of Newton's method basically amounts to taking your original function, looking at the best linear approximation for it, the first order Taylor approximation, and solving that and using that as your iterator. So this is just, what is, this is what Newton's method does. So if I apply Newton's method at current vector y, what I'm doing is I'm trying to solve this equation where this function is just the first, the linear approximation of the original function, linear approximation at the point y.
00:45:19.394 - 00:46:05.240, Speaker A: Okay, now what if I've got maxes and mins in, in my equations, what do I do? So, it turns out you can do the following thing. Given a max pps, just do the obvious thing. So, in each coordinate, the function looks like this. It's a maximum of a bunch of probabilistic polynomials. The linearization of this is just the maximum of the linearization of each of those pieces. Okay, so basically, my Newton iteration, my generalized Newton iteration is going to be to compute a fixed point of this linearization of this function. But I have to be careful which fix point, greatest or least.
00:46:05.240 - 00:47:10.370, Speaker A: And I can do it, it turns out now, since I've got maxes inside my, these are now max linear equations, right? So I've turned my equations into piecewise linear, okay? And it turns out I can use linear programming to solve each of these iterations. Okay? So in other words, I can turn these iterations into optimization problems that effectively boil down to linear optimization problems. And this constitutes one iteration of this generalized Newton's method. And now, so what's the algorithm? The algorithm is find and remove all the variables that are zero or one. Now, in the case of these branching Markov decision processes, it's no longer about detecting whether a certain matrix has spectral radius greater than or equal to one. It's about spectral radius optimization. And it turns out that we can nevertheless do that using linear programming so we can detect which coordinates are one or not on the resulting system of equations.
00:47:10.370 - 00:48:14.712, Speaker A: If we apply generalized Newton's method starting from the zero vector, and if we round down sufficiently after each iteration, then this computes in, you know, can be used to compute. So each iteration is computed in polynomial time, and it gives us a polynomial time algorithm for computing, in the standard Turing model of computation, a polynomial time algorithm for computing the least fixed point solution for these max min probabilistic polynomial systems. So in other words, Bellman equations for branching Markov decision processes. Okay, all right, so that's a whole mouthful. And so these are some of the key lemmas that go into the proof, but I can't really describe these things in any. So one can generalize this to branching simple stochastic games, where you have both max and min operators, and you get corresponding equations where there's both maxes and mins. The least fixed point is again the extinction, probably the optimal values of these games, actually the values of these stochastic games.
00:48:14.712 - 00:49:33.206, Speaker A: And I'm not going to describe that stuff, but let me just say it like this. So we have polynomial time algorithms for branching mdps and branching processes. These algorithms also yield NP, or in fact PLS complexity bounds for approximating the value of the corresponding branching stochastic games. So, can we use this generalized Newton's method to solve other classes of plus times max fixed point equations? That's something that I'm interested to find out. Where, where else can we apply this kind of thing? But what I want to do now, in the last few minutes, I know I've been going rapidly. I want to try to highlight some open questions that I think are sort of pivotal open questions at the core of the complexity issues surrounding a lot of these problems having to do with this problem PoS SLP, and kind of put forward a couple of wacky conjectures or interesting conjectures associated with those. So remember this pos SLP problem, I just give you a straight line program with plus times and minus input, just one, and you're just supposed to decide, is this straight line program going to output a positive value or not? We can't just do it, do the naive thing and compute the values because they're going to, because we don't have infinite precision arithmetic.
00:49:33.206 - 00:50:33.540, Speaker A: Okay, so can we get any better upper bounds than the upper bounds given by Alan de et al. By Peter Bergser and Miltersen and Kelgard Peterson? So they gave this counting hierarchy upper bound, which is really, we would like to do a lot better than that. And so here is a very basic approach and a corresponding conjecture saying that it's not going to work. So my first conjecture says that a naive approach shouldn't work, but we at the Bo, at the moment, we have no idea whether it works or not. So if you give me a plus times max circuit, right, that's evaluating some integer, right? And you want to know whether this is evaluating a positive integer. Well, you can just guess a monotone plus times circuit. So in other words, just guess a circuit that has input one and plus and times gates.
00:50:33.540 - 00:51:10.044, Speaker A: So obviously it's going to output something that's positive. Or you know, if you want, you can have also input zero. So you allow yourself the output zero as well. Okay. And then that's a witness of positivity. And then all you have to do is certify that if you subtract the first circuit from the second circuit, the output is going to be zero, right? And that we can do checking whether the output is zero we can do in corp, because in fact it's equivalent, polynomial time, equivalent to polynomial identity testing, which many of you will have heard of. This is, this was shown in the same paper by Alan de et al.
00:51:10.044 - 00:52:22.584, Speaker A: That these problems are actually polynomial time equivalent. But in fact, the fact that this problem can be done in corp goes back to schonhage in the sixties or early seventies or something like that. Okay, so now, okay, many people here will already know this notation, but, so, for an integer a, let tau of a denote the size of the smallest plus times minus circuit expressing a, and let tau plus of a denote the size of the smallest monotone plus time circuit expressing a. Okay, so here's a conjecture there exists. So the conjecture is basically saying you're not going to be able to pull this off with just monotone circuits. So there should exist a family of positive integers where the nth such integer an requires encoding size, basically n. In other words, that's the size of the smallest circuit that it has, but such that for some fixed c, we're going to get basically, we're going to get exponential lower bounds for monotone encodings of those integers.
00:52:22.584 - 00:53:07.424, Speaker A: We don't know this for polynomials. There's an old result by valiant. So valiant proved that there is an exponential lower bound for monotone polynomials being expressed by. So there's an exponential gap between monotone polynomials being expressed by non monotone circuits versus monotone polynomials being expressed by monotone circuits. But the lower bounds for polynomials don't work for integers. There's fundamental breakdowns in those arguments. Okay? And the current state of the art for this is really abysmal, and I don't even want to tell you what it is, because it's almost, you know, basically it's not an exaggeration to say we know almost nothing about this question.
00:53:07.424 - 00:54:22.034, Speaker A: Okay, okay, so, but what I want to then say ask is now here is a maybe more bold or crazy thing, so you can do a better approach. Let me call a circuit quasi monotone if it consists of some squared sub circuits. So maybe a picture will do here. So what do I mean by quasi monotone circuit? So, monotone circuit is just a circuit with just plus and times gates, okay, and non negative inputs or positive inputs. Here I allow you to have sub circuits that are arbitrary plus times and minus everything circuits, but the catch is at the end, you have to take that last gate and square it. Okay? And that's your input to here. Okay, so it's sort of obvious that this generalizes both, it generalizes both monotone circuits and sums of squares, right? And we already know from Lagrange's theorem that already a sum of four squares is enough to give you any integer.
00:54:22.034 - 00:55:30.544, Speaker A: But the question is, how big do those things have to be? There's results in number theory that tell us that asymptotically, as a number n goes to infinity the number of different representations of that number. Just as a sum of four, four squares is theta n. And as the number of different squares increases, that number also goes up. But never mind those facts, they don't have much of a bearing on this question. At least, you know they don't, but, okay, so let me give the question so given, so another approach to certifying positivity of an arithmetic circuit would be to guess a pair of quasi monotone circuits, c prime and c double prime, as witnesses of positivity for the original circuit, and to verify this equality. And I'll re express that down here. So this very optimistic conjecture, which one can call a very effective positive stellensatz for integers as kind of maybe as a way of giving you food for thought says this works.
00:55:30.544 - 00:56:25.962, Speaker A: So the hope is that there is some polynomial such that for any integer there exists a pair of quasi monotone circuits whose encoding size is polynomial in n, where n is the number of gates needed to express a in a non monotone circuit, and such that a is given. Now I'm conflating notation here a little bit. These are both circuits and the values that they evaluate to, right? So these c prime, sub a and c double prime, sub a are denoting quasi monotone circuits. They evaluate some value. That's another way of saying this. Right? And this equality I can check in corp. So basically, if this conjecture were true, this would tell me that positive cell p, not only is it in this complexity class.
00:56:25.962 - 00:56:47.574, Speaker A: Merlin. Arthur, it would also tell me that any progress on polynomial identity testing would give me progress on placing positive in np, for example. Okay, sorry, I'm out of time. Thanks. Questions?
00:56:49.134 - 00:56:50.574, Speaker B: Do you see any difference between the.
00:56:50.614 - 00:57:24.906, Speaker A: Max pps version and the min pps version, or from your, from this viewpoint, they're kind of the same? Well, they are in terms of the complexity. No, we get the same, we are able to, but the proofs are rather different. It turns out they're not symmetric. So the proofs require some different machinery inside to deal with. The max version has some kind of complexity properties underlying. Yes, that's right. So maybe I can say some things that might illuminate that for you.
00:57:24.906 - 00:58:12.380, Speaker A: So, firstly, the thing is that the Max case, one can relate it to kind of geometric programming in posinomial form. But even that connection doesn't necessarily bias polynomial time, because the recursive Markov chains that I showed you before, I can also encode those as a geometric programming problem in postnomial form. In effect, I get a result about geometric programming. Here's a result about geometric programming. There are geometric programs in polynomial form where they are feasible. The feasible set is guaranteed to be in the unit n cubed. Okay? And yet, any number non trivial approximation of simply the optimal value of the geometric programming problem is positive.
00:58:12.380 - 00:59:07.592, Speaker A: LP Hart so in other words, how is that consistent with the polynomial time solvability? It's not polynomial time solvable unless the feasible region is full dimensional. So methods like the interior point method and methods like ellipsoid, these do not have an interior in general. Okay, so basically, what I just told you about geometric programming. I don't know whether word for word the same thing holds for semi definite programming, and I think that's actually a mildly interesting question. So geometric programming seems to have certain characteristics that make it even slightly more challenging in a certain respect than semi definite. But we can talk about that offline regarding this last conjecture. As we know, polynomials are easier to understand than integers.
00:59:07.592 - 00:59:52.566, Speaker A: Now I wonder what would we get if we, is there a similar conjecture for say real polynomials? So you have a real polynomial, non negative, I don't know, straight line complexity and they want to certify it. So in fact, in fact I don't even know the answer to the following question. So valiant proved that monotone polynomials require. Right, now take what I've done. In other words, in a sense, now you're not just asking for monotone polynomials, but rational functions of polynomials of the. Right, expressed in the right way. Right? So in other words, these are.
00:59:52.566 - 01:00:25.444, Speaker A: Now I'm giving you a richer formalism for expressing monotone polynomials. Does there just in the realm of polynomials, is there an exponential lower bound? In other words, this would be a strengthening of valiant result. I don't know whether that's true. I don't know. So from what's called Artin's theorem, we know that you can write. So I'm sort of trying to sort of bring some of that into this context. I have absolutely no idea.
01:00:25.444 - 01:00:41.004, Speaker A: Things in valiant theorem, as you yourself know very well, this lack of cancellation property for monotone polynomials is crucial. And I don't know how to go beyond those things.
01:00:41.924 - 01:00:42.764, Speaker B: So, I have a question.
01:00:42.804 - 01:01:11.592, Speaker A: So, thinking in terms of ardent theorem, why do you need to add the plus one? Why do you want the plus one? Well, because otherwise I just want to be sure I don't divide by zero and the I can. Well, all I would have to do is in some other way certify that this guy's not going to be zero. Okay. And I can do that by running the core p algorithms that require checking whether that thing is going a rational sum of squares and it's a. But the plus one changes that. Yeah, yeah, I agree, I agree. So this is just a kludge.
01:01:11.592 - 01:01:29.504, Speaker A: I put the plus one here in order to make sure it's not going to be dividing by zero. I'd be happy. Perfectly. That's a. Thank you for pointing that out. I'd be perfectly happy for anything that certifies non negativity of the number a. You know, that is a succinct certificate of non negativity of the number a.
01:01:29.504 - 01:01:58.124, Speaker A: In a sense, what I'm trying to do is simply cook up as succinct a mechanism as I can for certifying non negativity of a number. Right. A number that's described by a non monotone arithmetic circuit. Okay, you showed us this conjecture that some integers are easily computable by general circuits, but hard for monotone circuits. This previous slide. Yes. All right.
01:01:58.124 - 01:02:37.992, Speaker A: Do you have candidates? So, here would be my candidates. Okay. And I'll tell you, in trying to think about this, I've sort of realized that some intuitions that you might have about polynomials fail for the integer setting. But here would be a candidate. Valiant showed his lower bounds for the perfect matching polynomial for planar graphs. Okay. So he showed that perfect matching polynomials for planar graphs that can be obtained by Castellane's theorem, that can be obtained by a non monotone arithmetic circuit of polynomial size.
01:02:37.992 - 01:03:37.204, Speaker A: But he showed that they require exponential size. Right. As a monotone circuit. Now, imagine that you take the variables in those polynomials and into the ith variable, you plug in an astronomically big number, two to the two to the I n squared, or to some sufficient power, k. Okay? And by the way, this is related to a trick that was used in the paper by Alan der Bergesera and others. So you apply, you plug in these astronomical numbers into those polynomials, right? Of course, you can express these numbers monotonically easily, right? Just by repeated squaring. And the hope, the guess, the idea is that those numbers ought to have the property that you are not able to express them by monotone circuits in polynomial size, but you're able to.
01:03:37.204 - 01:04:17.474, Speaker A: Well, you're obviously able to do so by non monotone circuits in polynomial size. But I'll tell you, I conjectured this sort of confidently at a workshop in Princeton over a year ago, and I was too naive. I thought it would be easy to at least get super linear lower bounds on these things. And it's. Wow, it's a real. I don't know. So there's more than a 50 50 chance that on one of the two conjectures that I'm giving, it's wrong, you know, so these are just hopes or something, you know, don't take my conjectures as you know.
01:04:17.474 - 01:04:21.754, Speaker A: Okay. Any other questions?
01:04:22.294 - 01:04:35.954, Speaker B: Yes, Mike, that's actually a kind of funny thing. Were found by scarf, by the algorithm. There's also a team from Princeton around how Kuhn was.
01:04:37.914 - 01:04:38.554, Speaker A: Yeah.
01:04:38.674 - 01:04:48.802, Speaker B: And then Smale defined a global Newton differential equation. Is your Newton's method the same as Smale's global Newton's?
01:04:48.898 - 01:05:11.328, Speaker A: Well, it's all Newton's method. The question is, under what conditions does it work, when does it work? And as far as I understand the literature around smales work and so forth. One has to assume some things about, you know, starting at a regular point and certain. So I don't. I don't know whether the results there are kind of.
01:05:11.376 - 01:05:26.404, Speaker B: This one was a little different. It was the beginning of this whole study. And what they do is take a proof of Broward's theorem, which is that you can't retract the cell onto its boundary, pull back the boundary values to define curves. Each one of those curves has potentially.
01:05:26.784 - 01:05:28.632, Speaker A: Right? Yeah.
01:05:28.728 - 01:05:30.616, Speaker B: So the curves actually do tend to.
01:05:30.680 - 01:06:02.190, Speaker A: But that's a continuous curve. And so, in a sense, it's a homotopy method. And the question is whether the discretization of that might cause any. So I absolutely agree that there's a continuous. I mean, you know, all of these, the algorithms for converging to equilibrium amount to some kind of path following method. The issue is whether the discretizations for it are, you know, kind of. If you want to talk about it in the Turing model of computation with worst case complexity and so forth, you need to worry about all of the nitty gritty.
01:06:02.190 - 01:06:16.794, Speaker A: And that's something. I don't know if somebody had worked out all of those things for Smale's method, but these are all, essentially, morally speaking, very, very closely related things.
01:06:18.414 - 01:06:20.554, Speaker B: George Newton's method works better than.
01:06:21.214 - 01:06:52.484, Speaker A: Oh, no, no. But that's a very good point. This is a very special class of equations. These are monotone polynomial systems of equations, or monotone min max polynomial systems of equations, where, miraculously, magic happens that first we're able to, in polynomial time, eliminate the singular points that cause nasty problems. And then after eliminating the singular points, it turns out we're sufficiently far away from singular so that convergence of Newton becomes globally fast. Right, fast. And.
01:06:52.484 - 01:07:36.130, Speaker A: And moreover, we can even do rounding and get the whole thing in polynomial time. So everything is kosher, you know, but, you know, for more general things, all bets are off. In fact, that's why I was asking this question is like, I would really like to know where else I can apply this generalized Newton's method, the one where I'm taking the maximum polynomial equations and I'm piecewise linearizing them. And yet it magically works. Right? So where else does it work? Another question. At the beginning of the main things, but at the beginning, you define this fixed p class and the approximate version. Now, the upper bound is p space, so what do we know about it? Only p space, so.
01:07:36.130 - 01:08:05.826, Speaker A: But the upper bound is this. Yeah. Let me, let me try to relate it so other things that people here might be familiar with. In a certain sense, you can think about this fixed p as somehow, let me say it like this, decision problems underlying this kind of class fixed p sit both in the existential theory of reals and in the universal theory of reals. Okay? We don't know the decision problems for the existential theory of reals. We don't know them to be p space hard. They're contained in p space.
01:08:05.826 - 01:08:43.842, Speaker A: But for all we know, that by some magic, we may end up being able to get. So, okay, here's an even more wildly optimistic conjecture that someday in the future we may be able to put, let's say, existential theory of reals, the decision problem for it. We may be able to put it in NP with an oracle for pos SLP. Don't ask me why. I'm hoping for some. If we were able to do that, then, and if my other conjectures hold, then all of those things would collapse to the polynomial time hierarchy. Of course, this is a million years away, but I'm just saying that right now, we don't have.
01:08:43.842 - 01:09:07.694, Speaker A: So, extension theory of reals is, for obvious reasons, NP hard. But it's not co NP hard. We don't know that it's co NP hard. And likewise for the universal theory of reals. So, fixed p is like a total search problem that's sitting in that domain. And both because there always exists a fixed point, you can essentially sort of boil the underlying problems. So in a certain sense, weird collapses would happen.
01:09:07.694 - 01:09:26.162, Speaker A: We don't have NP's complaining this fixed speed that we don't know. Oh, certainly not. No, no. These are not NP hard problems. Right. So. Yeah, so that's what I was trying to say, is that they're both in the existential and universal theory of wheels, roughly speaking, and therefore we don't have NP hardness type results for it.
01:09:26.162 - 01:09:28.714, Speaker A: So we have time for a break. Let's thank. Yeah, sorry.

00:00:01.760 - 00:00:24.674, Speaker A: All right. Good morning, everybody. It's a pleasure to welcome to introduce Vasilis from Microsoft research, talking about econometrics and game theory and interactions with machine learning as well. I'll be monitoring the online questions and I will interject myself during the.
00:00:25.724 - 00:00:54.932, Speaker B: Thank you everyone for coming. One also announcement is the in the afternoon, we're also going to have the town hall at the end of the last session. So please come if you want to, you know, bring ideas on what reading groups you want to do during the semester and other activities that you might like to have during the semester. That's the place to discuss that because we're going to finalize the schedule by the end of the week. All right. So yeah, let me jump in. So I'm going to be talking this hour and the next hour on.
00:00:55.068 - 00:00:56.244, Speaker A: Do you have the slides on?
00:00:56.324 - 00:01:26.054, Speaker B: Oh, I didn't, I didn't create the tiny URL. I'll do it right after the first session. Sorry for that. I'll be talking for these flowers on econometrics in games and auctions. It's going to be relatively high level given the richness of the literature. So I'll be presenting sort of the lay of the land and some particular proofs that I sort of like find interesting. And hopefully I'll give you pointers to papers if you want to read more for each of those sub areas of econometrics and games.
00:01:26.054 - 00:02:18.674, Speaker B: So what is the overall motivation? Our goal is to be able to analyze data that are coming from strategic interactions. These types of data could be looking like entry market entry data by competing firms. One concrete example that has been analyzed in the literature is airline market entry. Trying to understand why some airlines enter some markets whereby market here is a city pair. So why do some airlines choose to do their odds and others don't? Markets could be a supermarket entering a neighborhood. So that's a market or other retail markets. So we're trying to understand here why did these participants in those markets chose what they chose and what are the parameters of their utilities? How would they behave if the market changes, if there's a stock in the market, things like that.
00:02:18.674 - 00:03:35.134, Speaker B: Another prominent example is bidding data from auctions. And this could be their more classical applications of auction theory in procurement, auctions for drilling rights, or for other competitions that the government holds. Or even more modern applications such as online ad auctions where multiple bidders bid for ad slots on the Internet over there. We want to understand why did bidders bid what they bid? What is their value for the auction? That's being run. What would change in their bidding behavior if we change the mechanism? And these are the types of questions, another type of data, another set of applications that I'm not going to go into, but is also very interesting for people, especially in theoretical computer science community, to look into, is understanding data from strategic network interactions. So you would look at a network that was formed based on some strategic considerations, and trying to understand what were the utilities of people, why they formed these links and not others. And then maybe you could make policy decisions based on the results of that analysis.
00:03:35.134 - 00:04:34.284, Speaker B: So these are some examples. More generally, you know, the most general framework that you can imagine is the following, very abstract. We're going to be assuming that we have samples z of observable quantities from a game that's being played repeatedly, maybe samples from the game that was being played here, being played there, being played there. So we're going to imagine a situation where the same type of game with different parameters is being played multiple times. And we see all of these samples, and we assume that all of these games have some underlying structural parameters that are common, and these are theta, not. So this could be the parameter of a game, which could be my value for bidding in this type of auction, or my utility for forming a link to costas, or the impact of competing with another firm in this particular market. Type of market.
00:04:34.284 - 00:05:42.614, Speaker B: And what econometric theory for games is trying to do as a field, is address identification and estimation questions in a variety of game theoretic models, assuming that players are playing according to some kind of equilibrium notion. More traditionally, NASA equilibrium. But we'll see, maybe in the second hour, some recent work within the theoretical computer science community trying to move away from NASA equilibrium, or more traditional would be nas equilibrium, or variants of it, generalizations of it, for, say, dynamic games or repeated games, if you want to have a very stylized example in mind of particular cases that have been analyzed, and that we're going to also go into more detail in the rest of the talk. Here's a very concrete example. You want to analyze entry games with private socks. So, in this example, we have two firms deciding to whether to enter a market. And this you could imagine, for example, the airline story, where you have two airlines trying to choose whether they're going to participate in this particular city pair route.
00:05:42.614 - 00:06:44.122, Speaker B: So what we observe in the data is entry decisions. So whether this firm entered or not in the market from different markets in the world. And for simplicity here, we're going to assume that all of those markets have two participants, those two participants have some profits from entering. So this is the profit of participant one, which is some part of that profit is determined by the state of the market. So x, say, are some observable characteristics of the market, of the particular market for from its sample. And so the state of the market, which is x, the characteristics of the market affect the payoff that the profit is expecting to get out of the vendoring. But importantly, what makes it into a game is that my payoff is going to get a hit by depending on whether the other player is going to enter.
00:06:44.122 - 00:07:30.344, Speaker B: So if the other player enters, my utility is going to be changed by a delta one, which typically would be negative. So my utility will be decreased if the other player enters and not if the other player doesn't enter. Then there's also some private SoC in each of those samples that we have, which is very idiosyncratic to that particular sample and which serve like is any heterogeneity across these markets that cannot be captured by the observable characteristics that we have and which are typically not entering the. Yeah, so that's. So this is sort of like a noise, the analog of a noise in a regression problem. And similarly for participant number two, we're going to have this profit equation.
00:07:32.564 - 00:07:38.820, Speaker A: So, could you discuss a little bit the assumption that fi is provided to any I to a role in place?
00:07:38.972 - 00:07:39.664, Speaker B: Yes.
00:07:40.604 - 00:07:45.420, Speaker C: So in this example, because this is.
00:07:45.452 - 00:07:46.508, Speaker B: The type of games that I'm going.
00:07:46.516 - 00:07:49.652, Speaker C: To analyze in this talk, because I.
00:07:49.668 - 00:07:51.108, Speaker B: Didn'T have enough time, I'm not going.
00:07:51.116 - 00:08:22.532, Speaker C: To go into the other type of assumption. So we're going to be looking at games where these idiosyncratic shops are private to a player, so they're not observed by both players. And across markets, we're going to assume that they're IAD. The most important part is that when a player decides whether to enter or not, they don't observe. What was the shock of the other firm? This changes completely the type of game. So if a player does not observe.
00:08:22.548 - 00:09:30.172, Speaker B: The other players error, then this becomes a game of incomplete information. We're going to be typically assuming in our solution concept that they have some belief about that sock, and we're going to be looking at a bayesian game where they best respond in expectation over that belief. Importantly and well, if they knew the other player Sox, then we're in a complete information game. And basically the equilibrium is going to be some nice equilibrium of a complete information game. Why this changes completely, the econometric analysis is that in the case of complete information, each player, when they best respond, they know something that we, as econometricians, when we look at the data, we don't observe. And so this completely changes the types of estimators that we can build and the types of identification strategies in, particularly when we are, when you're in such situations of complete information where we don't know some parameter that the player uses to best respond, typically the parameters that we care about are not point identified. We can only get bounds on those parameters.
00:09:30.172 - 00:10:25.264, Speaker B: There are typically multiplicity of equilibria coming from the fact that this is a very sort of like non random game. So there's no smoothness in the randomness of the epsilon. And so typically they're multiplicative equilibria. And this multiplicity also leads to partial identification of the parameters we're interested in. But in the incomplete information case, which is harder for the player, is actually easier for the econometrician that we're going to look into today, because the player, when they best respond, observes exactly sort of what we observe, we're going to be fine, and we're going to be looking at techniques for point identification of those parameters, which could be delta one and beta one, delta two and beta two. So these are the parameters that we care about understanding how competition affects player entry and how the market state affects player entry. So these are the quantities that we're trying to understand from the data that we observe.
00:10:25.264 - 00:10:57.762, Speaker B: So why is econometric analysis in games useful? First of all, from a scientific perspective, these quantities could be economically meaningful. How does competition affect other players firms, or how different states of the market affect the payoffs? You could just give economic meaning to them, and there could be just scientific interests. Another, more sorry, another question.
00:10:57.818 - 00:11:17.614, Speaker D: I think in a very, very similar game, people have done experiments, actually, people like play Nashville, and then they end up like, the answer in most cases is no. So then if the answer for like, even like single games is no, so how should I think about the result?
00:11:19.194 - 00:11:26.196, Speaker C: So, you know, like NASA, Gulgmu has been a staple of economic analysis for so many years, and so econometric theory.
00:11:26.290 - 00:11:27.120, Speaker B: Is based on that.
00:11:27.192 - 00:11:37.336, Speaker C: But we'll see that there is some results that we've been working on in the teachers community also look at learning in games and things like that, violence of that. So here I would say that there.
00:11:37.360 - 00:11:39.416, Speaker B: Could be situations where NASA equilibrium, maybe.
00:11:39.440 - 00:11:43.032, Speaker C: In games where players are sort of.
00:11:43.048 - 00:11:48.472, Speaker B: Like intelligent friends that have departments that are going to strategize over whether they're.
00:11:48.488 - 00:12:10.730, Speaker C: Going to enter or not, maybe there's enough market analysis and enough analysis, enough economists in that department that the NASA column is going to be chosen. So it could be relevant in some situations, maybe not in more complex markets like adoptions, where these are algorithmic bidders and they don't really know exactly what that market is. The payoffs from every game are so small that it's not a big decision.
00:12:10.882 - 00:12:15.218, Speaker B: So let's just try and see what happens. Is going to be more the behavior.
00:12:15.266 - 00:12:17.586, Speaker C: But maybe more important decisions.
00:12:17.610 - 00:12:18.722, Speaker B: There's going to be more analysis, and.
00:12:18.738 - 00:12:20.410, Speaker C: Maybe the players play at an equilibrium.
00:12:20.442 - 00:12:21.610, Speaker B: And maybe the game is not so.
00:12:21.642 - 00:12:24.586, Speaker C: Complex that harness results from the TCS.
00:12:24.610 - 00:12:26.738, Speaker B: Community kicking for that particular situation and.
00:12:26.746 - 00:12:32.706, Speaker C: They managed to find an equilibrium. Or the equilibrium is smooth enough that you make assumptions about the beliefs that.
00:12:32.730 - 00:12:36.054, Speaker B: It becomes some sort of easy problem in a continuous space.
00:12:42.354 - 00:12:44.626, Speaker C: The other important reason for understanding those.
00:12:44.650 - 00:13:54.936, Speaker B: Parameters is to be able to perform counterfactual analysis. So what would happen if we change the game? This is especially interesting here because we're imagining situations where we completely change the mechanisms underlying the data that we observe and then we're trying to predict. This is completely different from the standard paradigms or say, in machine learning, where we assume that the data that we're going to try to predict are coming from the same distribution as the data that we used to analyze, because we completely change all of the mechanisms underlying the behavior of players if we change the games. So there's a huge extrapolation here, and in some regimes maybe you could apply techniques from machine learning to do the extrapolation. But here we're talking about a completely different distribution and without any mechanistic assumption on how these two distributions are coupled based on ideas from game theory and, you know, like behavioral assumptions of players. It will be very hard to do this extrapolation without structural assumptions. So in some sense, structural econometrics help you extrapolate even more.
00:13:54.936 - 00:14:36.380, Speaker B: Of course, at the caveat that the extrapolation is correct if your structural model was correct. So you can go further, but your results are a bit more brittle to your assumptions. Similarly, maybe we care in markets about performance measures that depend on those unknown parameters. Maybe we care about what was the welfare in that game that was actually being played. Maybe that welfare depends on the private values of players. So if we want to be able to calculate that performance measure, we need to infer those parameters first, and then we can also use these approaches to test game theoretic models. Maybe we estimate structural parameters here.
00:14:36.380 - 00:15:35.324, Speaker B: This is going to predict some type of behavior when we make some change in the mechanism. If we don't observe that behavior, we can invalidate some types of behavioral assumptions in games. I should say that econometric theory in games is a very rich literature, especially in the last 25 or so years. I'm going to be posting this picture along with the slides, so it's very hard to read. But this is sort of like my attempt to try to create a map of the literature in econometric games for someone that wants to jump in and read from the beginning and knows nothing about that. Some distinctions on the different streams of the literature is whether we're looking at games with discrete actions. So binary decision games or continuous actions like auctions, where your choice is a bid.
00:15:35.324 - 00:16:40.494, Speaker B: So auctions is a whole sub field of econometrics in games. And there's been works on understanding estimation of parameters under the independent private values model, or under correlated values or affiliated common values. Within the discrete there's a distinction of whether you're looking at static strategic interactions. So one sort or dynamic repeated strategic interactions with a state where the actions change the state, and in the static. Again, as I said before, it makes a big difference whether you're in the complete information setting where techniques like multiplicity of equilibria and set inference kicking, or whether you're in the bayesian setting where point identification is more relevant. And techniques like two stage estimators that we're going to talk about in this hour are the standard approach for estimating parameters in these games. All of this is based on more classical econometric theory, and these are sort of like.
00:16:40.494 - 00:18:11.294, Speaker B: If you want to read about more classical econometric theory, I'm going to do a very brief primer on the theoretical foundations and the statistical foundations of econometric theory. Typically, it's large sample asymptotic theory, nonparametric and semi parametric estimation, and some more eclectic topics that are particular to learning in games is this set estimation literature in statistics. All right, so let me now just first jump into the brief primer on econometric theory, which will not be particular to econometrics in games, but just in general when you're trying to estimate some parameter of a model based on data. And what are the techniques and tools that are typically being used? Any questions about the introduction? So the standard setup in econometric theory, we're given a sequence of IAD data points, and each of those data points is drawn from some distribution that's parameterized by some unknown parameter theta, not. And given those samples, we're trying to recover that unknown structural parameter. Of course, there are generalizations, correlated, serially correlated, weekly correlated, whatever. But this is the most standard setup.
00:18:11.294 - 00:19:47.554, Speaker B: The parameter space where this unknown parameter lies in is going to characterize the type of statistical problem that we're dealing with and the hardness of it. So if that parameter is, say, a vector in some finite dimensional space, then we're essentially in a parametric model and we're doing parametric estimation. If that unknown parameter, many times could actually be a whole function, maybe we don't know the demand curve in a market. And so the unknown parameter is this whole function, and we want to do non parametric estimation of that function without making parametric assumptions. Many times in econometrics, we're in a mixture of these two situations where we care about some parameter that we impose, we impose some parametric assumptions for some parts of the, of the world and we care about that parameter, but we allow some other parts of our data generating process to be unmodeled, to be left nonparametric, and we don't really care about those. And so it's this weird situation where in order to estimate the parameter that you're interested in, you need to estimate all of those complicated nonparametric functions which you do not care about, but they are required in order to be able to estimate the target parameter of interest. And this is sort of like the semi parametric inference literature.
00:19:47.554 - 00:19:55.994, Speaker B: And typically questions there will be, can we be robust to the estimations of those complicated objects? What is the question?
00:19:57.514 - 00:20:17.922, Speaker A: Your first bullet says, given sequence of iv data points, should I assume that you have distribution over everything or like, sort of like in the entry game you talked about before, you know, kind of like the exit. Characterizing the markets could be just arbitrary with some nice color distribution over everything. You put distribution over the markets, everything, yeah.
00:20:18.098 - 00:20:34.580, Speaker C: Just to make sure, like some sort of fixed design analysis, you could also look at that. But here I'm going to be looking at everything. Again, it's random. So then you know the first main goal.
00:20:34.732 - 00:21:07.954, Speaker B: If we knew this population distribution, d of theta naught, if we actually knew the distribution, does that pinpoint theta? Not exactly. Right. So that's the identification question. If I give you the sort of like the distribution. If you give you infinite samples, can you tell me what theta naught is? Or are there multiple theta notes that are observationally equivalent? And the second is the estimation. We want to devise an algorithm that outputs a parameter theta hat when given n sample that converges to theta. Note, at some rate.
00:21:12.734 - 00:21:19.318, Speaker C: Yeah, this is even beyond stem matrix in games, this is just estimation period. In some sense.
00:21:19.446 - 00:21:25.114, Speaker D: It's not like I'm just responding to my player response.
00:21:26.894 - 00:21:55.896, Speaker C: Even for the dynamic game setup, you can still formulate inference questions that look like this after you. If, for example, you look at samples from different markets as independent samples, you look at trajectories, you could also look at independent samples of trajectories, for instance. But this is, yeah, this has nothing to do with, not, has nothing to do, this is not specialized with econometrics in games.
00:21:55.960 - 00:21:59.768, Speaker B: This is just like inference. And you can think of it in.
00:21:59.776 - 00:22:24.884, Speaker C: The context of the static entry game that I mentioned. How would you go about applying this framework? So once you recover this data, how do you want to use it? What's the purpose? Yeah, as I said in the second slide, you could do something meaningful, like if you know, what is the effect.
00:22:25.584 - 00:22:27.804, Speaker B: Of education on income?
00:22:28.184 - 00:22:29.600, Speaker C: You could just say that, right?
00:22:29.632 - 00:22:31.360, Speaker B: So this could be a parameter based.
00:22:31.392 - 00:22:33.324, Speaker C: On your data points, right?
00:22:33.984 - 00:22:35.200, Speaker B: So it could be, you could use.
00:22:35.232 - 00:22:36.656, Speaker C: It to understand if you change the.
00:22:36.680 - 00:22:40.564, Speaker B: Game somehow, maybe you're now in a new market with a different x.
00:22:42.014 - 00:23:04.118, Speaker C: What equilibrium behavior do I expect to see if I change x over here? What do I expect? How do I expect my firms to behave? Or maybe I care about some welfare measure that depends on those parameters. And I want to calculate that because I care that whether the equilibrium is approximately efficient.
00:23:04.286 - 00:23:06.394, Speaker B: So I need to estimate that.
00:23:10.124 - 00:23:21.764, Speaker C: Question one, at least the player, I mean, we, that we're trying to solve the task, do we know the family d? And we just trying to learn the parameter.
00:23:21.924 - 00:23:22.476, Speaker B: Yeah.
00:23:22.580 - 00:23:47.526, Speaker C: Okay, and the second question. Oh, you would like to add something? Okay, the second question is, at the end of the day, however, do we really need to learn theta zero or to learn something like an oracle, an approximation of the distribution? I mean. Yeah, yeah, yeah. For many tasks you actually do, as I mentioned, all of these examples.
00:23:47.590 - 00:23:49.030, Speaker B: For many of those you actually need.
00:23:49.142 - 00:23:55.342, Speaker C: An accurate, yeah, but you know, like there could be some tasks and we'll.
00:23:55.358 - 00:23:56.654, Speaker B: See maybe at the end of the.
00:23:56.734 - 00:24:04.936, Speaker C: Second hour how if you care, for example, about revenue, you could bypass learning the full distribution of values, if that's.
00:24:04.960 - 00:24:06.008, Speaker B: What you care about.
00:24:06.176 - 00:24:19.072, Speaker C: But then, you know, like you can view it from the semi parametric inference viewpoint that what you care about is revenue, that's theta not, and that you're trying to estimate, you need the distribution of value, which is another non parametric function. That's, you need that in order to.
00:24:19.088 - 00:24:21.084, Speaker B: Estimate that, but you don't care about it.
00:24:24.304 - 00:24:35.336, Speaker C: So what properties of these estimators do we typically analyze? Some finite sample properties, like, you know, bias, you know, is our estimate unbiased as I sample the variance of the.
00:24:35.360 - 00:26:07.738, Speaker B: Estimator and the mean squared error, and then large sample properties are typically very important. As n goes to infinity, does our estimator converts to the truth? And very importantly, in social science applications, can we characterize the distribution, this asymptotic distribution of our estimate, so that we can report confidence intervals on the estimate of interest? Right? So, if we're going to make a big decision based on the estimate, we want to know how confident we are about that estimate. And to do that, we need to understand what is the confidence interval. Say, we want an interval so that with 95% probability, the truth is going to lie in that interval. Asymptotic normality, which is a sort of characterization of the asymptotic distribution of our estimate, is going to help us do that, because if we know that roughly based on, you know, some say, root n is alpha n of our estimate, when you normalize that by root n, it's asymptotically normal, you can put some normal distribution, you know, some normal distribute distribution around your estimate with some variance v and divide by, you know, n. And that would be your, your proxy for a confidence interval. And then the other thing that people in econometrics many times study is, is this limit variance that we characterized the best limit variance that we could hope for across all estimators that we can think of.
00:26:07.738 - 00:27:28.550, Speaker B: And so that is the efficiency. Okay? One general class of estimators that is typically used in econometric problems is what is known as the generalized method of moments. Many times, all of our econometric assumptions on the world, like the fact that people best respond or the fact that this is an optimal price, or other assumptions about how people behave, can be translated into moment conditions that your data generating distribution needs to satisfy. So typically, you can translate them into such a condition about the d of theta that I mentioned before, that in expectation over d of theta, this moment, which depends on the data, and theta is equal to zero. So those assumptions about the world typically give you such constraints in the population limit. And given such population limit constraints, a natural analog of an estimator is the empirical analog of that population constraint. So you can write down the empirical version of that expectation and solve that empirical estimating equation being equal to zero.
00:27:28.550 - 00:28:50.416, Speaker B: And that will give you an estimate theta hat, which you can then analyze whether it's close to the truth or not. For instance, you know, like if you're saying a linear regression setup where you assume that your data are coming from some linear function of the unknown parameter theta plus an error term epsilon, that is min zero conditional on the covariates z, you can typically, this will imply that the following moment condition is satisfied from your distribution that if you multiply the residual y minus zeta theta by the covariates, this is going to be zero by a simple tower law, because this is just epsilon, and epsilon condition on z is zero. So this is a moment condition that is implied by your assumptions about the world that your error is mean zero. And then you can analyze the empirical analog, which is basically the OLS estimate. So this equivalently, you can view this moment as the derivative of the square loss, but you can also think of it as a moment constraint. Another internal class of estimators is where you, you express your parameter of interest as the minimizer of some loss function. In the regression example, it's the square loss.
00:28:50.416 - 00:29:38.438, Speaker B: So your parameter theta naught, you might be able to characterize that it is the minimum of some criterion, q naught, which depends on the distribution. So that's a hypothetical criterion. But then you have empirical analogs of that q naught. Maybe this q naught is a popular expected loss, and you can replace that with an empirical loss and optimize the empirical loss. And that's your estimate. One very typical example is the maximum likelihood estimate, where your criterion is the likelihood, and you replace it with the empirical analog. Another example is where you start from a moment condition, but your moment condition might be over identified.
00:29:38.438 - 00:30:23.606, Speaker B: So you have, you might have more constraints than parameters that you're estimating. So then you move to an estimator where you minimize the sum norm of those moment constraints. And typically you would reweight those moments to minimize variance of your estimate. And that's what this w matrix over here is doing. It's a matrix that is typically chosen so that the variance of your estimate is minimized, so that you choose moments that have lower variance than others. And that leads to the GMM estimator, which is basically the minimum falls into this extremum type of estimators. Why do we talk about these particular types of estimators? Because there are general theorems for them.
00:30:23.606 - 00:32:03.050, Speaker B: If, for instance, under very benign assumptions that, for instance, theta naught is a unique maximum, that q, the criterion, is continuous and uniformly converges over the space theta to the population criteria, and then you can immediately get consistency. So those types of estimators will typically be consistent and this will, for instance, be satisfied if that criterion is an expectation of some loss function. Another type of general theorem that you can get for these types of estimators is asymptotic normality. And this is another reason why people in econometrics tend to like formulating their estimator as one of these estimators, because that would immediately give you asymptotic normality and some easy to use plugin formulas for the variance and the confidence interval. And I'm going to briefly show you a proof of asymptotic normality. It's three lines, because we're also going to try to prove, use a variant of that to analyze the two stage estimators that we're going to see in games in the next section. So how do you prove asymptotic normality for such an estimator? Any questions so far before I move into the three line proof? So, suppose you have an extreme type of estimator.
00:32:03.050 - 00:32:46.124, Speaker B: Equivalently, you can formulate it as a moment estimator where the first order condition is satisfied. So you can, since you're maximizing that criterion, the derivative, the gradient of your loss function, is going to be equal to zero on average, this empirical average. So you could also have started with moment based estimators. The proof would be the same. What do you typically do? You take that empirical analog and you linearize that equation around, around the truth. This hypothetical truth that you're after is there.
00:32:48.064 - 00:32:49.576, Speaker A: What is bar versus half?
00:32:49.640 - 00:32:49.928, Speaker C: Yes.
00:32:49.976 - 00:32:50.952, Speaker B: So you linearize it.
00:32:50.968 - 00:32:54.008, Speaker C: You apply a mean value theorem that you apply here.
00:32:54.096 - 00:33:02.124, Speaker B: First order taylor expansion and theta bar will be some point in between, some point in between theta hat and theta naught implied by the mean value theorem.
00:33:03.044 - 00:33:03.864, Speaker C: Um.
00:33:08.564 - 00:33:59.474, Speaker B: Now you can rearrange this and you're going to have root n of this difference that you care about to characterize. So this is the distribute. The distribution of this quantity is what you try to characterize can be written as the inverse of this mean value jacobian multiplied by this root and normalized empirical average. This quantity over here, because theta hat by consistency converges to theta naught and theta bar is a point in between. Theta bar is also going to converge to theta naught, and this empirical average is also going to converge to the population average. So under some regularity conditions, you can show that this quantity over here is going to converge in distribution to this.
00:34:00.254 - 00:34:18.034, Speaker C: Expect question, what is the rate that theta is converging to theta zero? You know, you know, if the rate for, because of the root ten that is going to the infinite no, I thought there's no other term.
00:34:19.414 - 00:34:24.934, Speaker B: Okay, so this pattern converges to this in distribution.
00:34:26.634 - 00:34:31.214, Speaker A: Okay, so to be clear for that, though, I mean, theta, what happens to theta power?
00:34:31.674 - 00:34:57.714, Speaker C: Theta bar converges to theta not because theta hat converges by consistency and this empirical average converges to the population by just as you know, you know, you need some conditions for that over the space. But so this quantity converges to this hypothetical jacobian, the expected certification evaluated at theta naught.
00:34:58.294 - 00:34:59.678, Speaker A: So it's a inverse there.
00:34:59.806 - 00:35:00.894, Speaker B: Yes, yes.
00:35:00.934 - 00:35:06.846, Speaker C: So the thing inside converges that, and then you invoke another asymptotic theorem called.
00:35:06.870 - 00:35:07.990, Speaker B: The continuity of the inverse.
00:35:08.022 - 00:35:24.228, Speaker C: As long as this hessian is bounded away from zero its eigenvalues, this inverse is going to converge to the inverse of that. That's another sort of asymptotic theorem. Then this quantity over here is an empirical average, a root and normalized empirical.
00:35:24.276 - 00:35:58.784, Speaker B: Average of some random variable or random vector. Right? And by a central limit theorem, this is going to converge to this normal distribution. And so then you apply what's known as Slutsky's theorem and says that this converges in distribution to this, this converges to this improbability to this is convergence distribution to this. This whole thing is going to converge distribution to a normal, where you also need to pre and post multiply this variance by the inverse of the jacob.
00:35:59.484 - 00:36:24.612, Speaker C: Just to be sure. We say that theta hat minus theta zero converges to zero or root ten times theta before consistency just means that theta hat minus theta naught goes to zero. And here we prove that root end times of theta hat times theta naught. You have something that exists. Okay? Yeah. So you're gonna get root inconsistency. You're gonna get the rate.
00:36:24.612 - 00:36:30.700, Speaker C: You first prove the simple consistency. Now you also get the routine rate. You actually even get, like something stronger.
00:36:30.732 - 00:36:33.144, Speaker B: Which is the distribution of that difference.
00:36:33.964 - 00:36:45.874, Speaker C: And then in practice, so that's the typical proof there. There's several regularity conditions. There are alternative proofs that use more complex theorems which avoid some of those regularity conditions.
00:36:46.034 - 00:37:23.442, Speaker B: But this is what you will find if you look at the standard textbooks from the early nineties. In practice also, people tend to use bootstrap to estimate the variance of that asymptotic distribution and then plug it into a normal bootstrap based estimate, which is slightly more accurate in finite samples. But you could also just do a plugin. After you estimate theta node, you can plug in in the formula here, theta hat. And that would also be an accurate estimate, a consistent estimate of your bottoms. There are consistency theorems for that.
00:37:23.458 - 00:37:29.314, Speaker C: The bootstrap will convert. There are also some rates, but, yeah.
00:37:29.354 - 00:37:29.934, Speaker B: So.
00:37:33.514 - 00:38:05.030, Speaker C: Rates on the difference, on the distance. But other proofs are more asymptotic, newer proofs, um, more finite sample. You can, you can also pass out the finite sample rate out of them. But, yeah, you need. The other nice thing is that typically, if you formulate like that, your estimator like that, then it satisfies the regularity conditions for the good stuff to work. Uh, if you're. Because your estimate here is sort of like satisfying what is known as asymptotic.
00:38:05.062 - 00:38:07.190, Speaker B: Linearity in the limit, you can view.
00:38:07.222 - 00:39:02.938, Speaker C: It as a, as a simple average of something. And whenever you satisfy asymptotic linearity, the bootstrap also works for the reason that the bootstrap works for some laborators. And so that's one high level intuition. But there are more recent proofs that go beyond asymptotic linearity. But this, you can show that if you take out and subtract quantities, those are going to be lower order terms, and then you're going to be ending up with this hypothetical thing, multiplying this average, and that's going to be the leading term, and the others are going to be lower. They're going to be converging faster than one over ten. Okay, so, and if you want to look, for example, like in this year's Europe, we also had with Morgan Austin paper on the bootstrap, when applied to.
00:39:02.986 - 00:40:11.474, Speaker B: More complex machine learning estimators and provable guarantees for the bootstrap. So we have a concrete proofs over there if you want to look at more recent techniques for proving bootstrap consistency. So, okay, so I think I'm gonna not gonna cover all of the things that I wanted to cover, but I might, you know, rush through the dynamic games, where I just wanted to give you the rough idea, but I'm gonna definitely talk about, how do you apply these techniques to the idealized scenario we talked about in the beginning, the market entry games. So, the high level idea that I was saying, at equilibrium, agents have beliefs about other players actions and best respond. If the econometrician observes the same information about the opponents as the player does, then we can estimate those beliefs from the data in the first stage. It's going to be concrete in the next few slides, and then you can use best response inequalities to these estimated beliefs in the second stage to infer the parameters of the utility of interest. So that's the high level structure of how these estimators work.
00:40:11.474 - 00:41:23.044, Speaker B: You first estimate those beliefs that people have when they best respond from the data non parametrically, and then you use the best responding equalities to devise a final step estimation strategy of the parameter of interest. So, let's go back to the entry games. We're going to be assuming that the firms best respond only in expectation, in this case of incomplete information, where I don't observe your private soc. So when I'm deciding whether to enter or not, I'm going to be taking an expectation over your decision to enter or not with respect to epsilon two. So my expected payoff PI one is going to not contain here your actual choice in the end, but it's going to be your probability of entry given the state of the market. So this is what I am calculating as my expected profit from entering in expectation over epsilon two. And this is what you're calculating as your expected profit from entry in expectation over epsilon one.
00:41:23.044 - 00:41:27.964, Speaker B: It's a function of the distribution.
00:41:29.144 - 00:42:21.806, Speaker C: So your probability of entry is a function of the distribution of the private SoC, and the equilibrium strategy distribution is known. Yes, I know your distribution of epsilon two. I don't know your institution realization of your epsilon two, but it's like an option. I know the distribution of your value and I know my value. So how much can you relax this assumption? Like having parameters, you know that. Then you estimate from the data, say I know your distribution up to some parameter, and then I try to recover that from the data, assuming that the agent knows that's what I need. Are you imposing the distribution here of the epsilon or so? Okay, so for the particular estimation strategy I'm going to post here, I will.
00:42:21.806 - 00:43:01.686, Speaker C: There have been relaxations for lifting up, but for this particular one I will. Yeah, sort of a high level question which connects to this is how these assumptions about the distribution of the epsilons connect to the properties of the estimator we just saw. Yes, I haven't looked clearly at the cases of non parametric assumptions on the error, like what types of rates, but there you can view that the epsilon during the sort of like in a semi parametric world where the distribution of epsilon, which is a function, is estimated non parametrically somehow from the data, and.
00:43:01.710 - 00:43:03.494, Speaker B: Then you're plugging it in to estimate.
00:43:03.534 - 00:43:06.450, Speaker C: The parameter of interest. So you need to understand how varies.
00:43:06.482 - 00:43:08.414, Speaker B: From the nonparametric component affect.
00:43:08.754 - 00:43:21.498, Speaker C: So that is, I don't know if it's here, because we're going to be imposing some parametric assumptions on those distributions. We're going to be getting parametric rates again, not easily. We're going to have, there's going to.
00:43:21.506 - 00:43:26.654, Speaker B: Be something to work out here, but, yeah, so that's.
00:43:27.914 - 00:43:34.814, Speaker A: So can you explain your terminology here? PI one contains a random variable and PI two contains a random variable.
00:43:34.854 - 00:43:35.198, Speaker B: Yes.
00:43:35.286 - 00:43:36.646, Speaker A: Is it a conditional expectation?
00:43:36.710 - 00:43:43.274, Speaker C: So PI one is a conditional expectation condition on epsilon one, but an expectation of epsilon two, conditional epsilon one and x.
00:43:43.814 - 00:43:47.462, Speaker A: Is it conditional epsilon two? Are you using the equilibrium strategy?
00:43:47.518 - 00:43:47.950, Speaker B: Yes.
00:43:48.062 - 00:43:49.558, Speaker C: So they are using the equilibrium size.
00:43:49.606 - 00:43:49.790, Speaker B: Right.
00:43:49.822 - 00:44:08.134, Speaker C: It's a fixed point, so they've calculated some equilibrium strategy, sigma, which is your probability of entry conditional on x. And so when I calculate my expected payoff from entry, I'm going to be taking, what is the probability of your probability of entry conditional on x, which.
00:44:08.874 - 00:44:10.538, Speaker A: I estimate your strategy?
00:44:10.666 - 00:44:27.776, Speaker C: I know the distribution. So I, as a player, know exactly the distribution. I calculate the base Nas equilibrium that Bayes Nas equilibrium has this form of probability of entry conditional on x, and that equilibrium has to satisfy best response.
00:44:27.800 - 00:44:30.256, Speaker B: Conditions that when I decide to enter.
00:44:30.360 - 00:44:49.364, Speaker C: This is my expected payoff. And it should be that. My probability of entry should be the probability that this payoff is positive. Otherwise I wouldn't have that. And your probability of entry should be the probability that this payoff is positive.
00:44:54.364 - 00:44:56.824, Speaker A: Why am I doing probability matching?
00:44:59.644 - 00:45:09.948, Speaker C: So your goal is to estimate beta one and delta one, for instance, right? Or beta two and delta two. So I'm just writing down here, what does it mean for these sigmas to be in equilibrium?
00:45:09.996 - 00:45:12.344, Speaker B: And these are going to help me to estimate those betas.
00:45:12.684 - 00:45:19.928, Speaker C: They don't do this. They did this calculation internally to find a fixed point and then decide whether.
00:45:19.976 - 00:45:21.244, Speaker B: To enter or not.
00:45:22.264 - 00:45:49.036, Speaker C: But this equilibrium have to satisfy these promises that you decide to enter when this happens, and if this is how you decide whether to enter or not, this is your probability of entry. So because we are at a steady state, this is what should go into the other players consideration. So this is the equilibrium assumption. Now, we haven't said anything about the parametrics. This is just what is implied by.
00:45:49.100 - 00:45:50.580, Speaker B: Our assumption that people pay a bayesian.
00:45:50.612 - 00:46:10.362, Speaker C: Equilibrium in this game. And here comes, you know, that you can. An easy way to estimate these things is to impose some parametric type of distribution on these socks. Most friendly one is this extreme value.
00:46:10.418 - 00:46:23.626, Speaker B: Type distributions in machine learning, you're going to call them like a gambit distribution, or like the thing that gives rise to the multiplicative weight updates sort of algorithm. But yeah, so you're going to make some assumptions about those distributions that you're.
00:46:23.650 - 00:46:26.178, Speaker C: Going to say that they're going to.
00:46:26.186 - 00:47:18.518, Speaker B: Give closed form, closed form solutions to this probability calculation. So if your epsilon follows that extreme value type distribution, this probability that this quantity is positive, is equal, is proportional to the e to the first part, the non random part. So for this particular type of distribution, this probability is proportional to that. So it is logistic function, where this is the utility part, the, you know, like the logic part in the logistic function. That's what this gives us. It gives us this clause form solution. So this is just, you know, it's not trivial how you calculate fixed points for this.
00:47:18.518 - 00:47:26.914, Speaker B: But there must be some work I haven't gone into, haven't reviewed that for this tutorial, so I won't say much.
00:47:33.004 - 00:48:00.340, Speaker C: The claim is that they chose one fixed point. And given the data, I can estimate that fixed point without any assumption, because given the data, I observe x and I observe yi, so I have x and yi, I can calculate nonparametrically what is the probability of entry conditional on X. So this probability of entry sigma I.
00:48:00.372 - 00:48:02.304, Speaker B: Of X is there in my data.
00:48:02.724 - 00:48:10.868, Speaker C: My data tells me what is that probability that for each player. So I do not, I don't need to use even, not even the equilibrium assumption to calculate that.
00:48:10.956 - 00:48:12.904, Speaker B: I can just estimate that from the date.
00:48:14.604 - 00:48:22.060, Speaker D: If you're player one and you don't know epsilon two, how can you assume that epsilon two is also distributed onto.
00:48:22.132 - 00:48:33.194, Speaker C: An extreme value distribution? You know the distribution, you don't know the realization of that sample. So you know that both shocks are drawn from this extreme value distribution.
00:48:33.354 - 00:48:36.374, Speaker B: But you never see what epsilon you got.
00:48:36.674 - 00:48:38.178, Speaker C: I don't see what epsilon you got.
00:48:38.266 - 00:48:39.522, Speaker B: I just know that your epsilon is.
00:48:39.538 - 00:48:42.002, Speaker C: Distributed based on that. And my epsilon is also, and you.
00:48:42.018 - 00:48:44.014, Speaker B: Know that my epsilon is distributed according to that.
00:48:49.984 - 00:49:03.952, Speaker C: Good belief about epsilon one, right? Like, what is this grief of epsilon one? Yeah, but like, say, both of those beliefs are extinctile. So everyone knows the distribution and the.
00:49:03.968 - 00:49:05.368, Speaker B: Value for his own and only the.
00:49:05.376 - 00:49:06.608, Speaker C: Distribution for the other players.
00:49:06.736 - 00:49:07.136, Speaker B: Yeah.
00:49:07.200 - 00:49:18.514, Speaker C: So it's the same as in a, in a bidding, in a private auction, right? I know the distribution of players and say for simplicity, that all players are distributed according to this extreme type player values and we play based on.
00:49:19.734 - 00:49:22.038, Speaker B: So I can calculate those probabilities if.
00:49:22.086 - 00:49:26.814, Speaker C: Say, the x's, say, are discrete. So say we only have like ten types of markets.
00:49:26.974 - 00:49:28.670, Speaker B: I can go to every type of.
00:49:28.702 - 00:49:39.942, Speaker C: Market x for every realization of the variable x, and I calculate the fraction of times across all of my instantiations of that type of market that player.
00:49:39.998 - 00:49:41.574, Speaker B: One entered and the fraction of times.
00:49:41.614 - 00:49:57.388, Speaker C: That they didn't enter, and that's sort of the fraction of times at the ender, and that's the probability. So I can have a non parametric estimate. I calculate these empirical averages for every market type. If x is continuous, then this is a complicated continuous function to estimate parametrically.
00:49:57.516 - 00:50:02.464, Speaker B: But if x is discrete, then this is just calculating empirical frequencies.
00:50:03.724 - 00:50:07.332, Speaker C: And then once you have those estimates, you can plug them into these sort.
00:50:07.348 - 00:50:48.384, Speaker B: Of like, fixed point equations, like these best response equations now, because now you have the estimate sigma hat. So it doesn't, all of a sudden, it doesn't become a fixed point equation. It's like I gave you sigma two. Now give me beta and delta, given that sigma one must be satisfying this. So, if you give me sigma hat of my opponent, my decision to enter is, follows this logistic rule. And now, estimating beta and delta is a simple logistic regression where x and sigma minus I hat of x are the covariates of that logistic regression. So I can run a logistic regression and estimate beta I and delta I.
00:50:48.384 - 00:51:55.614, Speaker B: Okay? As I said before, if the, if the states, if the x's are discrete, then estimating non parametrical sigma is just empirical frequencies. And there are, you can prove root and rates for those empirical frequencies. And so you do have guarantees that your first stage estimate is going to converge to normal. And then you have the second stage estimate, which depends on this first stage estimate. But the question is, is the second stage estimate, which is now, say, a GMM or like a, you know, like a extreme value falls into these types of estimators that we said in the first day, in the first part of the talk, does it still maintain those properties that we said? The only difference is that we plugged in an inaccurate estimate of something in that moment. And so the question is, does that inaccurate estimate affect the distributional properties and the error rates of that final estimate and how.
00:52:08.814 - 00:52:09.638, Speaker C: They'Re very sensitive.
00:52:09.686 - 00:52:11.438, Speaker B: Yeah, yeah, yeah.
00:52:11.606 - 00:52:14.126, Speaker C: They're very sensitive. And that's why some people have looked.
00:52:14.150 - 00:52:16.590, Speaker B: At non parametric variants of these entry.
00:52:16.622 - 00:52:33.394, Speaker C: Games where you make non parametric assumptions. But, yeah, they're very sensitive, but they give you immense statistical power. So you only have, like, say, 50 markets. I'm not sure I would go with the not, you know, like the insensitive but very statistically high volumes estimates for this particular estimate. Right?
00:52:33.434 - 00:52:38.254, Speaker B: So, you know, that's the trade that you would face in practice.
00:52:43.514 - 00:52:47.174, Speaker C: And so this question is a general question about two stage estimators.
00:52:48.874 - 00:54:18.930, Speaker B: So where you have a moment that does not only depend on the parameter of interest, but also depends on other quantities that you don't know, but you need to plug in and you've estimated them in a first stage and doing the same type of Slutsky asymptotic normality theorem, you can no longer easily argue that this is asymptotically normal, because it depends on this h hat, which is a function of your data. But then you can do further linearizations around that h hat. This is going to be a normal quantity when you do a Taylor expansion. And then the question is, does this go to, to zero? And if you sort of rewrite it as one over n times the first part and root n times the second part, this will go to zero. Only if this root n normalized first adjustment goes to, or won't go actually go to zero. If this first adjustment goes to some normal, then you, with some work, you can show that this whole thing is still asymptotically normal. So as long as you, your first stage estimate is asymptotically normal, or more concretely, asymptotically linear, this whole two stage approach will still be asymptotically linear and so normal.
00:54:18.930 - 00:55:24.914, Speaker B: And you can do your standard confidence interval construction or bootstrap based confidence intervals. But this is problematic when this h hat is a function, even in a 1d space, this h hat will not be root and consistent because you're estimating non parametrically, a function in a 1d space. So it won't have root in rates, will have slower than rooting rates. And so this type of approach is going to be problematic in that situation. So even if you have just a single x characteristic of your market, and that was continuous, and this approach trivially wouldn't give you the routine rates. But because I think we may 5 minutes, there are approaches that will allow you to still show routine rates for these two stage estimators, even if that quantity that you don't know is a non parametric function. And this is some other work by Barry Hong Kong and Nikkei Pelov.
00:55:24.914 - 00:55:36.974, Speaker B: And remarkably so, that even if those first stage beliefs, you can't estimate at root and rates, you can still estimate the final parameter, the target parameter, at root and rates.
00:55:41.274 - 00:55:42.694, Speaker A: Under what conditions?
00:55:43.074 - 00:56:39.334, Speaker B: Yeah. So it requires that those sigma hat estimates, they're not very slow. Like, again, you're going to have this, if they're n to the one four consistent, not root n consistent, then you're going to get return consistency for the target. So you get like a squared improvement for the target parameter of interest, as long as you can estimate those quantities at n to the one four rates, which will be okay for a 1d variable x. Or it might be okay for if you use adaptive estimators for like machine learning based estimators and subject to some, you know, like sparsity assumptions or high dimensional linearity assumptions, other assumptions on your, on your beliefs, which will be high level and hard to check that your beliefs will satisfy those assumptions. You can also show that, but at least for. Yeah, even for, even for the 1D case, I haven't.
00:56:39.334 - 00:57:08.154, Speaker B: I don't recall seeing like the proof that sigma, like the properties that Sigma will satisfy, which is the outcome of this fixed point, are all fixed points satisfying certain smoothness assumptions? Most probably, yes, but I don't recall saying you need to argue that your equilibria will satisfy those high level assumptions that you typically impose for statistical inference. Sometimes these are hand waved and sometimes people do the do the job and actually prove, but many times these are just hand waved.
00:57:09.294 - 00:57:15.314, Speaker C: But there you all your fixed points are smart lipsets.
00:57:15.614 - 00:57:18.734, Speaker B: Yeah, for the one decade to the list.
00:57:21.234 - 00:58:00.410, Speaker C: And the idea how to do that is you don't use the actual logistic regression. You try to debias the logistic regression estimate to remove the effect from the first stage estimate. And this leads to the literature on orthogonality. And I'm only going to be able to give you pointers for that. If I have time, I could go through the proof. But basically you add a Bias correction term to your second stage, which will allow you to to kill a first order term for that spine from that final linearization. So instead of doing here a first order TayLOr expansion around your h node, you're going to second order TayLOr expansion.
00:58:00.562 - 00:58:01.922, Speaker B: Any manner of analysis is going to.
00:58:01.938 - 00:58:17.556, Speaker C: Imply that the first order term over here is going to be equal to zero. So if you choose your moment correctly in the second stage, you can cancel the first term, and then you're going to only be left with the second term, which then would only require that n to the one four of your error goes to zero.
00:58:17.700 - 00:59:21.334, Speaker B: So that's roughly the proof approach. And I think I'm going to stop here. Was it the final section that I'm just going to define what people have worked on, but I'm not going to give you the very details of the estimation. Another very class, large class of games that people have analyzed from the econometric perspective is dynamic markovian games, where you assume that players play over time and there's a state of the world st typically observed, an observed state of the world. People, again have these private socks, these epsilon eyes that happen at every period, and they're private to each player. Again. And only distributional assumptions are being made about what I know about my opponents.
00:59:21.334 - 01:00:30.364, Speaker B: Given the state of the world and those socks. I'm going to choose my action at the current period, and my action is going to, my profits are going to take this additive form of some deterministic profits that do not depend on the private SoC and some, and some private SoC profits. So these are sort of like, yeah, this deterministic part, and this is the epsilon shock to your payoff at that current period. And typically what you want to estimate are these sort of like non idiosyncratic payoff functions. You want to understand these functions without the, you know, idiosyncratic soft, that sort of like a random noise. After players choose an action, the state transitions as a function of both the action profile of players and the past period action. And people assume that what you observe is the outcome of a steady state policy.
01:00:30.364 - 01:01:46.370, Speaker B: So it's a mark of a steady state mark of equilibrium, where people choose a mapping from states and private socks to an action for that current period. And that action is going to be maximizing my utility, my expected discounted future reward. So I'm going to be calculating a discounted future reward under this markovian equilibrium assumption. And it has to be that what I chose now is larger than the expected payoff, discounted pay for that I would have chosen had I played any other action. So these are the computations that are going into every player's head in order to choose how to play. And under this assumption that people play according to this markovian steady state equilibrium, you want to reverse engineer and found the power, find the parameters of these profits, which again, you can use then to do all of the things that we talked about, why econometric analysis is useful. This is still bayesian.
01:01:46.370 - 01:02:57.264, Speaker B: This is like, yeah, like a dynamic bayesian game where people typically apply this to dynamic oligopoly markets. So you have two firms competing over time in some market, and this is how you apply these types of models to that and try to estimate profit. And again, the estimation methods heavily depend on this distribution of Arabs that we assume. So there's still going to be one step that's very brittle here, which is called the inversion step, where you go from probability choices of actions into deterministic parts of the payoff. So these new eyes over here, you make assumptions that say that if I observe the probability choice of a player, like as a function of the state of the world, and then I can reverse engineer and find the map, the new I or something. So like, if you assume that these epsilons are extreme type, then you can use a sort of like a logic rule again and again. Those are, these estimation properties will be brittle to those assumptions.
01:02:57.264 - 01:03:46.654, Speaker B: So that was, that's it. So for the first part. So the recap of the main idea at equilibrium, if agents have beliefs about other players actions and best response, and the econometrician observes the same information as what you observe about your opponent, you can take this two stage estimation approaches, where you estimate nonparametrically some components of the observed distribution and then use best response inequalities, either simple ones in the static game, or if you go into the slides, more complicated ones in the markovian game, you can recover the structural parameters that you care about. And these are some references that if you want to look into more detail. Thanks.
01:03:52.074 - 01:04:01.974, Speaker A: There were several questions during the discussion, the talk. If there are any burning questions, please ask them now, or we can go have more coffee.
01:04:09.194 - 01:04:11.414, Speaker C: So when you look at kind of.
01:04:11.454 - 01:04:20.430, Speaker E: Non asymptotic analysis, it seems to depend on a lot of assumptions. Like we're in a linear model and we have error estimated correctly.
01:04:20.502 - 01:04:22.598, Speaker C: And this, that, how do, how do.
01:04:22.646 - 01:04:47.100, Speaker E: People think about these convergence bounds? Do they think like, oh, this model isn't exactly accurate, but maybe it's close enough. Do they think these bounds don't mean very much? Do they think these bounds are what we can prove now? But in ten years we're going to have fancier models, improve bounds, more general cases, and those are going to be useful. Like how do they, so many times.
01:04:47.212 - 01:05:10.104, Speaker C: The approaches that I made, there are two ways to do it. Either you truly believe about your model, or you just look at what your estimator is solving for and you try to abstract away and say, it's not really that my estimator uses all the information about the model.
01:05:12.814 - 01:05:13.662, Speaker B: I impose, but.
01:05:13.678 - 01:05:30.646, Speaker C: It just uses this moment condition and this is what I'm estimating, and then try to give other interpretations of what they're estimating. That's more general than assuming a linear model. So that's one approach. In general, though, the reason why people try to prove this bounds is not.
01:05:30.670 - 01:05:33.742, Speaker B: To say that we're, it's mostly in.
01:05:33.758 - 01:05:53.360, Speaker C: Order to put uncertainty intervals even subject to the model that you're, that you're imposing, right? So that is why the most of these are important, because even if I'm assuming that the model is correct, what I'm getting out of this is, I mean, I do know how certain you are given the data that you have.
01:05:53.472 - 01:05:55.232, Speaker B: Even under my assumptions. Right.
01:05:55.288 - 01:06:08.710, Speaker C: So that's why these are useful. Yeah. And so even if it's converting to some constraint solution, given the model that you assumed, you want to know the.
01:06:08.742 - 01:06:11.154, Speaker B: Uncertainty of your, of your estimates.
01:06:12.934 - 01:06:17.902, Speaker E: So they're kind of like optimistic bounds in some ways. Best case uncertainties that we have.
01:06:17.998 - 01:06:18.674, Speaker B: Yeah.
01:06:23.614 - 01:06:57.954, Speaker C: Like a lot of, some particular place where structural grammatics are being used is understanding antitrust. Like, you know, like if you want to, if a merger is okay to do you do some competition? Structural, they're not used. I mean, in economics professions, they're used, but in actual decision making, in authorities, they're not used. They're too complex. They don't, they don't do research. Well, the dynamic, yeah, the dynamic is not, I've seen it in papers. I don't know if I've seen empirical papers where people apply.
01:06:58.114 - 01:07:04.626, Speaker B: I don't know what they use in the, in the fed. In the fed or something, or wherever these things are being used. But I've also seen, you know, like.
01:07:04.650 - 01:07:08.554, Speaker C: Demand estimation problems, like demand estimation approaches.
01:07:08.674 - 01:07:17.654, Speaker B: I've actually seen used in practice, even within Microsoft. So where it's not, it's a single, it's sort of like a single agent problem. Yeah.
01:07:18.954 - 01:07:24.814, Speaker A: All right, so interesting discussions for the coffee. It.

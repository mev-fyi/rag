00:00:00.200 - 00:00:08.554, Speaker A: Okay, so the next talk is by Susanna de Rosenda, who's going to tell us about the average case hardness of clique for regular resolution.
00:00:09.494 - 00:00:50.604, Speaker B: Hi. So, yeah, this talk is click is hard, on average, for regular resolution. And I'm Susanna Dirazendi from KtH and now Simon. So this is based on joint work with Albert, Hilario, Massimo, Jakob and Alexander. Okay, so the problem here is we're given a graph, and we want to know whether it contains a k clique. Okay, a click of size k. So, for example, for the ones that haven't seen this talk yet, this graph, does it contain a clique of size? Let's say five.
00:00:50.604 - 00:01:06.914, Speaker B: What would you think? Yes. Well, yes, right. It looks like it. Yes, it does. There you go. Click of size five. Okay, so does it contain a click of size six? No, of course not.
00:01:06.914 - 00:01:15.254, Speaker B: Right. One answer. Yes, one answer. No. So, no. And this is a proof that it doesn't. Well, it's five colorable, so it cannot contain a click of size six.
00:01:15.254 - 00:02:15.584, Speaker B: Okay, so this is our problem. And while it is a, like, fundamental combinatorial problem, it's easy to determine if g contains a k click and time n to the k by simply brute force algorithm. And the question is, well, is this optimal? Can we do any better than this? So what are the lower bounds we know? Well, assuming eth, then there's no end to the little low of k algorithm. But can we prove any unconditional lower bound? Right. Well, in particular, it would show that p is not equal to np. So what about bounded computational models? What about what algorithms actually do? So, this is a corollary of our main result. So, state of the art algorithms require time n to the theta k to decide whether a random graph contains a k, click n to the omega k.
00:02:15.584 - 00:02:57.384, Speaker B: Um, okay. And to analyze these algorithms, well, we need to formalize, well, what is the method of reasoning they use? Um, and if you look at a graph that does not have a k click, and the you look at the trace of the algorithm. Algorithm, it has a proof of the fact that there's no kclick. And if we can lower bound the size of such proofs, well, we're lower bounding the running time of the algorithm. And, well, this brings us to the topic, which is resolution. So what is resolution? Well, I guess we've all seen this a few times. So we have an unsatisfiable CNF formula, and our goal is to certify unsatisfiability using the resolution rule.
00:02:57.384 - 00:04:08.654, Speaker B: So we resolve over a variable x, we have clause c or x, d or not x, and we obtain the clause C or D. So here's an example of a resolution proof, and we say that if the dag is a tree, that this is tree like resolution. If we look any path from contradiction to an axiom and there is no variable which is resolved twice, then we say that this is a regular proof. Okay? So for example, this proof is regular if you check any path. So here we're resolving over w, we're resolving over what are we resolving over x, x and then over y and then over z. So in this path here, there is no variable being resolved twice, and this is true for all paths. Okay, and the size of the of the resolution proof is just the number of nodes in the DaC.
00:04:08.654 - 00:04:53.964, Speaker B: All right, we'll also be interested in the branching program model. And here we're interested in branching programs that solve the falsified clause search problem. So what is this problem? We're given an unsatisfiable formula, an assignment to the variables, and our goal is to find what clause is unsatisfied by this assignment. Okay, so here's an example of such a branching program. So it starts by querying variable z, and then if it gets one, it goes in one direction, zero in the other. And suppose then queries x, and then it gets one. And this assignment, z being false and z being true and x being true, falsifies this clause.
00:04:53.964 - 00:05:45.634, Speaker B: Okay, so this is a branching program solving the falsified search problem. And as you might notice, there's some similarity between these two objects. So here's our branching program, and here's our resolution proof. So from a resolution proof, we can always obtain a branching program solving the falsified search problem. And it's not very hard to see. Well, every time here you're resolving over variable z, and the branching program can query z, and it will maintain the property that at every node, the assignments partial assignment, it knows so far falsifies the corresponding clause in the resolution dag. Okay, so there is this correspondence.
00:05:45.634 - 00:06:26.904, Speaker B: And for, so for a branching program, we can also define tree like branching program, which is also known as a decision tree. Read once branching program, it's similar to the regular resolution. So here no variable is queried twice in any source to sync path. And the size is again the number of nodes in the duck. And here are the correspondence we have. Well, a decision tree solving the falsified clause search problem is equivalent to tree like resolution. Also read one's branching programs are equivalent to regular resolution.
00:06:26.904 - 00:07:05.220, Speaker B: But if you look at just the general branching program then. Well, this can be exponentially stronger than resolution. Okay, so in this talk we'll be talking about regular resolution, and we'll be using this correspondence between readworms branching program and regular resolution. So in order to study the click problem, we need to define an encoding. Here. I'll give like the simplest encoding for this talk, although the result works for stronger encodings. So we need two types of clauses.
00:07:05.220 - 00:08:02.654, Speaker B: So first we have variables xvi, and the meaning is that vertex v is the ith clique member. And then we have clauses for every I and k we have a clause that says that there exists an ith clique member. And then for every non edge in the graph we have a clause saying that these two vertices cannot both be click members because there's no edge between them. Okay, so from this encoding we have that. Well, this formula is satisfiable. If and only if g has a k, click right and feel free to interrupt me and any points there. Any questions? Okay, so what was known before? Well, there was an end to the omega k lower bound for tree like resolution.
00:08:02.654 - 00:08:54.336, Speaker B: Also, when k is large, a large polynomial, then we have exponential lower bounds for general resolution. But there are many reasons to care about small values. Ok, so that's what we're focusing on here. There are also results that hold for a different encoding. So for the binary encoding, which is an encoding, which is easier to prove lower bounds for, then we do have an end to the omega K lower bound for general resolution. And just a few years, a few days ago, this other result came, which is also lower bound event to the omega k for Kres. So for resolution over log, log and dnfs.
00:08:54.336 - 00:09:45.144, Speaker B: Okay, okay, so we would like to prove this for general resolution, but so we have this milestone in between for regular resolution, which is what we obtain here. Okay. And this is also an interesting problem, because the usual proof complexity tools we have for proving lower bounds, they seem to fail for this problem. Yes. Can you say something about binary versus, not like, is there a way to go from proof of one to the other? So from binary to the unary encoding, if you have this bound for general resolution, you cannot obtain one for unary. Not sure. The other way around, I'm not sure.
00:09:45.144 - 00:10:10.178, Speaker B: What these authors show is that if you could prove for the binary encoding a log n resolution over log n Dnf's, then you would get something for unary encoding, but you would need something stronger. Yeah. Than what they have unary for general resolution. Yeah, yeah. So what proof techniques do they use.
00:10:10.346 - 00:10:12.294, Speaker C: The pyramid encoding flow bar?
00:10:12.774 - 00:10:52.224, Speaker B: There is a random restriction. Okay, so yeah, so for our unary encoding, these techniques don't seem to work. Okay, so in order to prove a lower bound, we need a hard graph instance. So here's the candidates. It's a complete k minus one partsite graph. So it has many k minus one clicks, but doesn't have any k click. And, well, it happens that this is hard for a tree like resolution, but for regular resolution it's easy.
00:10:52.224 - 00:11:36.954, Speaker B: So regular resolution can do this in two to the kn squared. So if we're thinking of k small, this is small. And in fact this is true for any k minus one colorable graph. Okay, so let's try a better hard instance. So if we look at etosh runy random graph, so we have n vertices and we include every edge with probability p, then, well, the threshold for having a k clique is p about that and to the minus two over k minus one. And if we choose p slightly below, then we already know that with high probability there will be no k click. So these are going to be our hard instances.
00:11:36.954 - 00:11:58.994, Speaker B: So here's a slightly more formal statement of our theorem. So for k up to n to the one four, if we choose p slightly less than the threshold so that there's no k click with high probability, any regular resolution refutation of the clique formula has length n to the omega k. Yes.
00:11:59.374 - 00:12:13.064, Speaker A: Is there an analogous result, or did people study just pigeonhole principle for average case? Because the pigeonhole principle is somewhat hidden inside the clique function.
00:12:13.484 - 00:12:49.684, Speaker B: Right. So the way I presented it, that's true. So this is like a simple encoding where it is. Yeah, and you can trivially get a two to the k lower bound. So actually you can add some clauses which, um, which gives some ordering on your clique members. So that if, let's say, vertex are numbered from one through n, so if vertex one can only be a smaller click number than vertex two. Okay, if you add those, then you, you cannot embed pigeonhole here.
00:12:51.184 - 00:12:54.136, Speaker A: Yeah, so that's our results from about.
00:12:54.200 - 00:13:07.894, Speaker B: Case pigeonholes hold up, average caged pigeonhole. So given a random graph and, well, I guess it's an expander. Right.
00:13:12.634 - 00:13:15.138, Speaker A: Okay, doesn't matter, we'll check it later.
00:13:15.186 - 00:13:54.914, Speaker B: Okay. Okay. All right. Okay, so, okay, so this is a tight lower bound because there is an upper bound of n to the okay, which can be done even in tree like resolution. So tree like resolution can do this brute force algorithm. And what we prove is slightly more general in the sense that even if we have smaller densities, we get some lower bound, and the lower bound degrades with the smaller density. So if the graph is sparser, it seems easier to prove that there's no k click.
00:13:54.914 - 00:14:33.754, Speaker B: Okay, so now let's go to a proof overview. Okay, so what makes a graph a hard instance, right? Well, a random graph, we would guess it's hard. But what is it that makes it hard? So here are some ideas. Maybe it has many, like small clicks. Okay, it doesn't have any k click, but it has many small clicks. So maybe this is what makes it hard. Well, we know this cannot be because a k minus one protein has many k minus one clicks, and it's not hard.
00:14:33.754 - 00:15:01.932, Speaker B: So let's try something else. Well, good expansion, right? We all know that random graphs are good expanders, so maybe this gives hardness. And we tried this, but we couldn't get it to work. Maybe it's not enough to only have expansion. So our third attempt is that in some sense, we have small clicks. There are many different ways we can extend it. Okay, and I'll get back to this later.
00:15:01.932 - 00:15:49.364, Speaker B: We can make a right technical definition that will make this work. Okay, so here's overview of the proof. We wish to define some combinatorial property, which we'll call clique denseness, such that for any click dense graph g, we have a lower bound of n to the k. And then we show that with high probability, erdosurini graph satisfies this property. Okay, so we'll focus on mister one and the definition of this property. So the proof technique will be a bottleneck counting algorithm in the style of Hawkins. So, let's go over this.
00:15:49.364 - 00:16:33.924, Speaker B: We have a regular resolution refutation of this formula. You can think of it as the read once branching program, and an assignment to the variables defines a path from, from the root to some, from the sink to some source. Uh, which at every point. So at every point it. The clause present at that point is falsified by, by the assignments. Right? So we can follow this path. And here the idea is we wish to define some sort of bottleneck node for which we can prove two things.
00:16:33.924 - 00:17:23.264, Speaker B: That every path in a distribution, which we will define, traverses some bottleneck node, and the probability that alpha traverses some fixed bottleneck node is small. So this is the general idea in bottleneck counting algorithms, techniques. Okay, so then what do we have? We take a union bound. So we know that for any fixed bottleneck. Sorry. We know that the probability that there exists a bottleneck b, such that alpha traverses b is one, but for any fixed, for any fixed b, we know that this probability is small. So by a union bound argument, we get a bound of antenna.
00:17:23.264 - 00:18:29.024, Speaker B: Okay, so this is the idea of what we want to do, except we'll need a twist to it. Okay, and the twist is that we won't be able to define a single bottleneck node, but we somehow need two nodes. So we'll define a bottleneck pair and the rest will be exactly the same. So we'll have the same relation. Okay, so our goal will. So I'll define the distribution of the paths now and define what the bottleneck nodes are. And then our goal, which I'm going to write here, will be to define the combinatorial property such that the probability over alpha that there exists a bottleneck pair ab, such that alpha traverses ab.
00:18:29.024 - 00:19:23.854, Speaker B: So this is one. And the second property we want is that for any fixed ab, the probability that alpha which reverses ab is less than n to the minus negative. So this will be our goal in order to define. Oh, wait, before I get to that, I can already define, uh, the distribution on the paths. Okay. It's a very natural distribution. So we'll start at the source, and at any point we, when we query a variable, we'll do the following.
00:19:23.854 - 00:20:06.204, Speaker B: Um, if there is no way that this path will falsify such an axiom. So, so this axiom is saying that there, that there is some ith click member. So when will there be no way that this will falsify? Well, if it already identified an Iithclick member, then there's no way it's going to falsify. Um, there are also other cases for, for, for example, uh, if it's queried some, some XVI before, some x UI before, and it forgot it. Since this is regular resolution, it cannot query it again. It can only query it once on every path. So then it will never be able to falsify this axiom.
00:20:06.204 - 00:20:59.964, Speaker B: In order to falsify this, it needs to remember that all the xvi's are zero. So if there is no way alpha will falsify xvi, then we can safely answer zero. And if we set XVI equals one, and this falsifies some edge axiom. So this means that I already identified some clique member, and now this is not a neighbor of a clique member I identified. So I should not say that it is a quick member, else I will immediately get a contradiction. So in this case, I also answer zero. So I'm somehow forced to answer zero in this case, and otherwise if we're not in any of these two cases, then I'll just throw a coin and with probability n to the minus one two, I'll answer one, otherwise I'll answer zero.
00:20:59.964 - 00:21:58.512, Speaker B: So this will be the distribution on our paths. And now in order to define what a bottleneck pair is, I'll need the following definition. So, the common neighborhood of a set of vertices. So this is the neighbor, these are the neighbors of this vertex, and these are the neighbors of the blue vertex. So if I look at this set, at this set r, the common neighbors will be just the intersection of the neighborhoods we can think of. Well, if r is a clique, then the common neighbors of r are the possible extensions of r forming a clique. Okay, what are ways I can extend r and still have a click? Okay, now one more definition.
00:21:58.512 - 00:22:37.464, Speaker B: So if I, if I have a set w of vertices, and I will often be interested in how many ways can I extend this clique r inside w. So suppose that I have many common neighbors of r inside w, then we say, well, w extends r in many ways. Is this clear? Okay, so now we can define what our bottleneck pairs are. Yes, I can.
00:22:40.484 - 00:22:41.644, Speaker A: Extend, you mean by.
00:22:41.684 - 00:23:44.744, Speaker B: One verb by one vertex, extend by one vertex, yes, exactly. So I'll define the bottleneck pairs, and at the same time I'll prove 0.1. Okay, so given a path alpha from our distribution, we can make the following observations. Well, alpha will falsify some of these wide axioms. So why is this? Well, we're never falsifying an edge axiom. So the short axioms we're never falsifying. So when it ends, it will have to be falsifying some of the membership axioms.
00:23:44.744 - 00:24:56.644, Speaker B: Okay, now suppose that we fix j. Suppose alpha is falsifying this xvj. Then we know that, well, alpha must query all the xvjs for all vertices v in our vertex set, and it must set all of these to zero. That's the only way it can falsify this clause. And now, okay, and now one more observation is that alpha, so any path in our distribution identifies at most k clique members. And why is this the case? Well, if, right, so alpha identifies at most k clique members. And this is the case because if I ever identified a clique member on some ith position, I will never answer one for I again.
00:24:56.644 - 00:26:24.240, Speaker B: Okay, okay, so now what we can do is so consider a path alpha. We can split this path into t segments. It was split it into t segments such that in any of these segments here, alpha is identifying less than k over t clique members. So for every path there exists such w zero w one up to wt that splits it in this way. And you can think of t as a small constant, say t equals five or something ten. Okay, now since we know that all these variables have to be queried and set to zero, and this is regular resolution, so it only does this once on any path. This also defines a partition of my vertices in v according to when were they set to zero in between which of these, so this will define some partition.
00:26:24.240 - 00:28:18.016, Speaker B: So this will be w one wi so v be the, okay, and now I will say that wi minus one wi that this is a bottleneck pair is a bottleneck pair if the following holds. So if this wi, so the vertices that were set to zero between wi minus one and wi, if this extends all small clicks in many ways. Okay, this somehow represents that progress has been made here. So this path has to set all of v to zero in the jth block. And this represents that, oh, between these two, a lot of progress was made. In general, we could think that, oh, if wi is large, then a lot of progress is made. If I was between these two vertices, I set many things to zero, but this is not enough because maybe there was, these were all the non neighbors of one vertex I already identified in my click.
00:28:18.016 - 00:28:30.224, Speaker B: So it was really easy to, it did not require any coin flipping. So in this sense, the idea is that it will require a large amount of coin flipping. Okay.
00:28:34.924 - 00:28:37.704, Speaker A: Why should we think that there is such an I?
00:28:39.164 - 00:29:21.934, Speaker B: Right, so we want a combinatorial property that guarantees that there exists such an I. Exactly. So what will this combinatorial property be? Yes. Oh yes, right. So the first part of the click dense definition is that we want some combinatorial property that, such that there will always be such an I. And this is the formal definition. So for all small clicks, let's say a size at most k over 20, the common neighborhood of r is large.
00:29:21.934 - 00:29:46.174, Speaker B: This will be the combinatorial property that will guarantee that there exists an I. And because this will imply that if I partition v, then there will be such an I. For any partition of v into t parts, there will be such an I such that I lose only a t here in both what large means and the size of the small cliques.
00:29:50.494 - 00:29:52.194, Speaker A: Sorry, why does it follow?
00:29:54.014 - 00:29:55.950, Speaker B: It's a very simple argument.
00:29:56.062 - 00:29:57.286, Speaker A: It's not something that we should see.
00:29:57.310 - 00:30:12.534, Speaker B: Maybe. No, no, it's very simple. I mean, you can prove it by contradict. Suppose there's no I. Then you look at the r's such that this is not true. You put them together and you'll get an r such that this is not true. It's very simple.
00:30:12.534 - 00:30:59.084, Speaker B: Okay, so, okay, so this will guarantee our point number one. Now we need a second part of the definition which will guarantee the point number two. Okay, so this is what we want to guarantee. And now we'll have two cases. Okay, so in one case on. So I will call these bottleneck nodes a and b. So suppose Ab is a bottleneck node.
00:30:59.084 - 00:31:30.744, Speaker B: In one case we have that at the vertex a. We have already identified many clique members. Okay, so at least epsilon k clique members. Yeah, yeah. Chris, the first property that you want for fleet density. Yes, number one. Now we want a property that will give us number two.
00:31:30.744 - 00:32:37.750, Speaker B: No, no, I'm going to try to lead you to understand why we need this property. Okay, okay, so, okay, so first there's an easy case which is. So if a already identifies many click members. And why is this easy? Well, the partial assignment at a has these epsilon k variables which are set to one, and we know that ones are always the result of a coin flip. So then we already automatically get that the probability that alpha passes through a, not even through b, but only through a, is already n to the minus k. So this is an easy case. Okay, so now what happens if a identifies less than epsilon k clique members? And okay, so let ra be the set of vertices set to one at a.
00:32:37.750 - 00:33:15.484, Speaker B: So the clique members a identifies. And let w be the set of vertices that are set to zero between a and b. Okay, uh, we know that each non force zero has probability, uh, one minus n to the minus one two. So suppose we have like many non force zeros. Okay, so something a lot larger than n to the one two. Um, then we would get that. The probability that, uh, alpha traverses ab, well, it has to set all of w to zero from a to b.
00:33:15.484 - 00:34:21.864, Speaker B: So then we would get an exponentially small bound and then we would be fine. And, well, there seems to be some hope that something like this could be true, because we know that Ra is small and w extends all small clicks in many ways. So if it is a possible extension of Ra, it will not be a forced choice, it will not falsify any edge axioms. So then we have hope that we could get such, so many coin flips. So why is this not enough? Well, before querying the vertices in w, maybe our path identified more clique members. So let our alpha be the set of, uh, vertices between a and b that were identified as clique members. Okay, so if we knew that these would still leave enough non forced zeros, then we would be fine.
00:34:21.864 - 00:35:21.594, Speaker B: We would have a some probability which is exponentially small. But if this does not happen, then let's say that this r alpha is probably problematic for this w because it somehow rules out almost all the possible extensions of this clique inside w. And the property we want must guarantee that the probability that we choose on our alpha that is problematic for w is small. So this is the, what we need to finish the proof. Some property that we'll guarantee is this. Okay, so this is the property that we define. So first, what we said was to guarantee one was that we can extend any k over 20 clique in many ways.
00:35:21.594 - 00:36:11.374, Speaker B: And now for two, what we need is that for any set w that can extend k over 100 clicks in many ways. So the idea is it looks somehow like what a random w would look like if you chose it. So it can extend small clicks in many ways. Then it can also extend almost any k over ten click in many ways. So now I'm going to choose click, which is a lot larger than what my guarantee gives me. And I still want that for almost all of these I can extend it in many ways. And here will be a more formal statement and attempt of a proof by picture, definition by picture.
00:36:11.374 - 00:36:55.710, Speaker B: So this would be. So for any set w that satisfies the top that extends any k over 100 clique in many ways, then there exists a small set s such that any k over ten clique that cannot be extended into w in many ways must intersect s in many vertices. So suppose this is a w, and for all small r's there are many ways I can extend it into w. And now we take a much larger r prime. And now maybe this shrunk more than what would be expected. Maybe it's very small. Yes.
00:36:55.782 - 00:36:59.434, Speaker C: Is there any equation why this is not true for a k minus one?
00:37:00.254 - 00:37:49.874, Speaker B: Yes, yes, I can. Let me finish this and then I'll tell you. Yes, okay, so suppose now I have like an r prime which has a small number of possible extensions inside w. So this means that it intersects the set s a lot. So for every w there must exist a set s such that any large r prime that has small number of possible extensions in w must intersect s a lot. So this will restrict the number of problematic r's r primes they can have, because they any r prime that's problematic must intersect s a lot. So this is the combinatorial property that will give us number two.
00:37:49.874 - 00:38:17.324, Speaker B: And this was something we could not just get out of expansion. So. Right, okay, so yes, your question. So why, why is this not true for k minus one partite graphs? Right. So let's see. Yes.
00:38:19.064 - 00:38:28.640, Speaker D: So I think with the naive statement of the second property, it almost seems like it could be true for a k minus one colorable graph. But I think that this is actually saying something stronger.
00:38:28.672 - 00:38:29.152, Speaker B: Right.
00:38:29.288 - 00:38:37.896, Speaker D: You're not only saying that you can also almost any k over ten click, you're also saying that like the errors are somehow like localized. Does that make sense?
00:38:38.000 - 00:38:40.204, Speaker B: No. What do you mean the errors are localized?
00:38:41.544 - 00:38:43.204, Speaker D: Yeah, if it's not helpful, don't.
00:38:44.944 - 00:38:59.144, Speaker A: The easiest way to see it is that a set that contains k minus k over 100 colors, we extend any k over 100 clicks, but click. But not any larger click.
00:39:01.484 - 00:39:46.392, Speaker B: Will we extend any. Okay, let me try to get a picture. So what happens for the k minus one protein graph is that we are looking for k clique members and the k minus one proteight graph. So actually the picture looks like, so this would be like I equals one up to I equals k, and these are my variables. So this would be like the rows are like for v. So this is like v equals one up to v equals n. So this is my variable x vi.
00:39:46.392 - 00:40:31.924, Speaker B: So x eleven. Okay, and if it's k partite, what we mean is that here, let's split this into like k minus, it's k minus one partite. I'll split this into k minus one blocks. And the edges that are present are only between these blocks. So since we don't care inside here, we can think of it like that. So these edges are present but not edges inside here. Okay, so, okay, so now what happens is that there, let's see.
00:40:31.924 - 00:40:58.820, Speaker B: Okay, so I can have a set. I'm not sure we'll be able to do salon. Yes.
00:40:58.892 - 00:41:06.696, Speaker C: So firstly, I mean, we're cheating in two ways, right? Firstly, firstly, we don't need to extend the cake lately. A common neighborhood of any guys that.
00:41:06.720 - 00:41:08.520, Speaker A: Don'T necessarily need to be a clique.
00:41:08.632 - 00:41:45.420, Speaker C: Although I don't know if that's so important here. But I think the example, like somewhat cheating example is suppose you have a clique on all the other parts of the partition. And now look at just one part, look at half of those vertices and clearly that half extends like all the cliques of the other guys in many different ways. Okay, but now look at the second half of that part. As soon as I pick up any vertex in that second half, of course, now I can no longer extend it with a clique in the first half.
00:41:45.452 - 00:41:54.620, Speaker A: Of this part, but that's only if you extend the k minus two click. It's very different with the cable.
00:41:54.732 - 00:42:23.202, Speaker C: No. So I think, I think it translates to this setting of the point is like that there would be, if I just look at one part of my kpopartite graph, then any vertex in the first half of that part rules out that I could extend the clique further with any vertex from the second half of that part. And that is not a small set, that's like a very large set. That's like half of that part. And I think that's sort of, you.
00:42:23.218 - 00:42:25.898, Speaker A: Cannot take two vertices from the same part.
00:42:25.946 - 00:42:54.540, Speaker C: Yeah, that's the whole point. So that means that as soon as I, like, I take that part, I chop it up into two parts subparts, then any vertex from the first subpart, as soon as I get that, I cannot take anything from the second subpart. And so that is a set s that sort of makes things crash. And it's not the smallest, that's like a huge step. So that's, does that feel roughly right?
00:42:54.732 - 00:43:24.914, Speaker B: It does, although I wouldn't need to go offline to go into details. Okay. So I can get back to you later. Okay. Right. So now some conclusions. So, well, we proved an n to the k average case lower bound for regular resolution, and it holds for, well, it's a weak but a non trivial proof system.
00:43:24.914 - 00:44:05.344, Speaker B: And while some open problems would be. Well, can we prove this for Erdos? For any random graph? Can we prove this hardness for an explicit graph? What about Ramsey graphs? So, yeah, so we have a, suppose we have a graph that has no click of size log n and no independent set of size log n. Can we show that for those graphs we need enter the log n. Can we extend this to general resolution? And, yeah, and beyond general resolution. That's it. Thank you.
00:44:12.424 - 00:44:27.856, Speaker A: Okay, let's take questions while Liang sets up. You left off axioms not XDI or not x mu I. That's saying the mapping from vertices to fleet numbers is in objective. But your proof still applies in that.
00:44:27.880 - 00:44:39.994, Speaker B: Yes, yes, it still applies. Yes. Yeah. For simplicity, I guess. Yeah, yeah, exactly. And number one, first part.
00:44:47.334 - 00:44:53.674, Speaker D: Yeah, so you said that like an error trendy random graph satisfies this property of high probability, like for what values of p?
00:44:54.094 - 00:45:32.964, Speaker B: For what values of p? Yeah. Right. So if you're a bit below the threshold, it's fine. So you can go quite a bit below I guess I can tell you it's so that the threshold was the p was n to the minus two over k minus one. So then, I mean, if you put a parameter eta here and you choose, like, eta greater than one, we're below the threshold. So I think what we do is eta up to. I think it's square root k or something.
00:45:32.964 - 00:45:36.644, Speaker B: It's something that depends on k.
00:45:42.024 - 00:45:43.096, Speaker A: Other questions?
00:45:43.160 - 00:45:45.244, Speaker D: Is there any connection to planted clique?
00:45:47.064 - 00:46:02.854, Speaker B: Well, I guess planted clique when in so's you talk about planted clique and you look at the proof complexity, what you're doing, it's actually, you're just proving that random graph does not contain a k click. So I guess it's very similar.
00:46:06.754 - 00:46:10.074, Speaker A: Other questions? Well, it's. Thanks, Susanna.

00:00:00.160 - 00:00:35.344, Speaker A: So she did her PhD from the Christian Albrechts University in Kiel. Sorry, I graduated from Christian Albert's University at Kiel and did her PhD from University of Leiden in the Netherlands. And subsequently she became a professor at Aachen University. She works at the intersection of SAT, SMT solvers and computer algebra systems. And in 2015 she independently came up with this concept of combining SAT solvers and computer algebra systems. So without further ado, Erika, please go ahead.
00:00:36.164 - 00:01:18.208, Speaker B: Thank you. Thank you for the nice introduction. You can hear me? Yes, perfect. It is so nice to see young researchers like Curtis being fascinated from these beautiful problems and finding elegant solutions. And indeed, this combination of SAT and cas offers very much possibilities for also new ideas. So what I would like to show you today is also a new idea based on previous ideas, which we get when we try to combine these systems. So I would like to talk about the marriage of two words and what nice things can come out.
00:01:18.208 - 00:01:48.868, Speaker B: And I will try to focus on the intuition. I will not go into details a little bit, technicalities, but not much. But let us start at the beginning. So what we want to do is we want to solve logical formulas by SMT solving. And we look a bit into the solving mechanisms of SMT solving. And what we see is that there are different modules in it. And these modules are combined, but they are not combined.
00:01:48.868 - 00:02:26.520, Speaker B: Just putting them aside like by courtesy also have seen. I would call it what the SATs over solves, a kind of abstraction, but it is dedicated to the problem. So what in SMT solving is beautiful and impressive that often putting together pieces results in new methods. So propositional logic. We know Curtis used this also in the upper level of his solving methods. And what I will focus on also is real algebra. And we know that this is of course more complex.
00:02:26.520 - 00:03:05.116, Speaker B: Even representing satisfying assignments is more complex. But computer algebra systems already addressed the problem of satisfiability checking. So I focused today on quantifier free formulas. But the Boolean combination is still challenging. And then I do not introduce SMT solving. I assume that most of you know. But in traditional SMT solving I would like to emphasize again that also there is sat solver interacts with the theory solver, but they do not have equal rights.
00:03:05.116 - 00:04:22.464, Speaker B: The satsova is first. That's why it is called lazy sat modular theories, because the theory is evaluated lazily. So the set solver goes ahead and searches for solutions for the Boolean skeleton, for the Boolean structure of the problem and consults a series solver to check consistency in the real domain. And now what kind of theory solvers can be put in into this series solving approach. We know a lot of decision procedures, probably UI experts in some of them. So the question arises, can we simply plug in these procedures into SMT solving? And the answer is, well, not directly, at least not directly in an efficient way, because the sats over incrementally search for solutions and in the less lazy solving it will frequently ask the series solver for a set of constraints, then for an extended set of constraints, an extension of this, and so on, until a solution, full solution is found or a conflict is detected. So this should work incrementally.
00:04:22.464 - 00:05:29.644, Speaker B: And if the theory is or the constraints in the theory are inconsistent, it should give an explanation in form of a tautology of a lemma and should be able to backtrack. I will not go into these details how to adapt these decision procedures, but this was the origin of my research and of our SMT solvers, because we said, well, there are so many interesting decision procedures which are not yet efficiently embeddable in SMT solving. So let us try make them SMT compliant. And on the way we detected a lot of. So some extensions have been straightforward, but some others are very interesting. And what with interesting, I mean, we could not only adapt these decision procedures, but we could even gain more insight into the nature of the problems, and thereby also improve or change modify algorithms and find new ones. So first to our solver, before I will give you an example.
00:05:29.644 - 00:06:20.102, Speaker B: Our software is called SMT red Real algebraic toolbox is read at its heart. There is a C library called Carl for real arithmetic computations. This can also call external computer algebra systems if they are installed a few. I do not go into these details, but using Carl, we develop a set of SMT solving modules, and these modules can be combined to an SMT solver. And this is something individual for our solver. So these are the modules that we offer. Currently, you see that our weight is on real algebra.
00:06:20.102 - 00:07:02.018, Speaker B: This is on the bottom, but we have also some basic modules and some non algebraic decision procedures. And we implemented nearly everything that we could find. And we can combine these procedures strategically by defining an initial module and then defining callbacks for it. And that means that this module is solving the original problem, and for sub problems it can call other modules. And which module is called might depend on certain conditions. I'll show you an example. Traditional SMT solving has a sat module and the theory module.
00:07:02.018 - 00:07:28.324, Speaker B: Assume the theory is now the cylindrical algebraic decomposition for real algebra. So here you see a piece of code, how we can define this strategy. And then we combine a solver with this code. And then you have a statically combined strategy. So this SMT survey executes this strategy. But the strategy is still statically combined. But it can be dynamic depending on the conditions.
00:07:28.324 - 00:07:54.780, Speaker B: So for example, we can add also the pre processing module. We can add bit blasting to eliminate finite domain integers. Or we can call for example the virtual substitution as an incomplete method. Before we go to the heavyweight CAD or even interval constraint propagation. We can branch on whether the sub problem is linear or nonlinear. And this, what is, I mean, with dynamic. So it is also problem dependent.
00:07:54.780 - 00:08:43.736, Speaker B: Or we can branch whether the problem is integer or real or mixed real integer. And then we can call different backends for those problems. What is the best suited? Now let me come back to SmT solving. So I mentioned that sats over the satin theory do not have equal rights. The SATs over is kind of first in the lazy Smt sorvik. And what happens in the satsova is that if you have a propositional formula in c and f, then one of the components in the satsova is resolution. So we have the resolution rule.
00:08:43.736 - 00:09:26.884, Speaker B: It offers a complete decision procedure for propositional logic. It can be used for quantifier elimination. But why do we have the SAT solvers? It is because there is a combinatorial blow up. So in practice it is not so efficient. Now how is it made more efficient in the nineties is that it is combined with exploration. So the idea was that try first going some direction, apply some cheap look ahead. In this case it is a Boolean constraint propagation to direct the search, not to run to every silly conflict.
00:09:26.884 - 00:10:09.960, Speaker B: But if we recognize that we cannot continue, because in that part of the subject search space, there is no solution. Only then we look the heavy proof system, in this case resolution. To explain why, that means to construct only the part of the proof, which is necessary a little exam to demonstrate we have these clauses. So first we propagate. Given some atoms must hold, we propagate it and then decide. For example, assign force to a did short look at propagation, we cannot imply any consequences. Now we assign force to b.
00:10:09.960 - 00:10:55.354, Speaker B: And now we see here, because a is false and b is for c must hold. But in the other clause not c must hold. And only here to this case, where we know there is some conflicting case, we apply Boolean conflict resolution. Now probably all of you know this, so why do I explain it to you? This is because there was another idea recently, and this is the model constructing satisfiability calculus. It is not our idea, but it is a very nice idea. The idea is now we give Boolean search and theory search equal rights. They work hand in hand, being consistent with the decisions of each other.
00:10:55.354 - 00:11:46.144, Speaker B: But now also the theory should be able to make decisions assigning values to variables. And whereas in the Boolean case, we assign truth values to propositions, in the theory case we will, if you're in real algebra, assign real values to real valued variables. And then we also had a kind of propagation theory propagation, and it is not that clearly formulated, but we can interpret it this way. And we also have conflict resolution in the theory. How does it look like if we do it only on the theory? Assume we have constraints in one of the clauses, which should be true according to the Boolean structure. Now the theory also propagates first. This we can skip.
00:11:46.144 - 00:12:12.274, Speaker B: It decides. Let us look for which values there is a solution. Let us try x equal one. But these guesses are such that univariate constraints evaluate to their assigned truth value. But now we do not have any univariate in x, so we can choose whatever we want. Then the next variable would be y. We have also no univariate.
00:12:12.274 - 00:13:01.554, Speaker B: Let choose one try. What happens now? We want to assign a value to z, but now this constraint is univariate. It says that z squared is less than zero and it is not satisfiable. So only now we would involve a theory explanation procedure that could say, for example, that if the constraint holds, then x and y should not be both positive, because then we cannot satisfy this constraint. One of them should be negative, and then these two kinds of search go in parallel. You can combine them as you want, but they should agree. So if the series, if the Boolean solver says that this constraint is true, then the Siri assignment should also make it true.
00:13:01.554 - 00:13:57.474, Speaker B: Okay, so this is not new. Why do I talk about it is because there is something we can derive from it, a new type of method. But let me explain this idea on the Fourier Modskin variable elimination, because this is quite easy to understand and good for illustration. So the idea is if you have a set of linear constraints, no multiplication, then we can use quantifier elimination in that we bring in all constraints, the variable to be eliminated on one hand side. So we get a set of lower bounds green here, and a set of upper bounds red. And then we can assure that there is a value for x that satisfies the constraints. If the lower and upper bounds do not define any empty intervals, that means each of the lower bounds should be less or equal each of the upper bounds.
00:13:57.474 - 00:14:30.344, Speaker B: This is all. And then we can eliminate every variable that you want. And at the end, when we eliminated all variables, given that there are no parameters, we can decide satisfiability by checking the resulting constraints of a constant. So, for example, if you have these four constraints, we first want to eliminate x one. So x one has here two lower bounds and one upper bound. We combine each with each, so we get two constraints and the one without having x one. We just keep.
00:14:30.344 - 00:15:26.944, Speaker B: We go on eliminate also x two. So here we have again two lower bounds and one upper bound. We combine each with each and then we recognize there is a conflict because one cannot be less equals zero. So this set of constraints is unsatisfiable. Now, if we use Fourier mosquito, MmC that to explain conflicts, how does it look like? So this method is also complete, but it is also like resolution, combinatorially heavy. So let us try to do something else and use furiomoskin and SmT solving to explain a conflict. So what happens? We have here assumed these four constraints should be true, and now we try to guess in the theory domain values.
00:15:26.944 - 00:15:50.408, Speaker B: So first we want to guess the value for x two. This constraint is not yet univariate and this one neither. So our look ahead goes only for satisfying univariates. But this constraint is univariate and it should be true according to the Boolean assignment. So we can choose any value that is at most zero. Let us choose zero. It is a nice number.
00:15:50.408 - 00:16:11.304, Speaker B: A lot of things can zero out. And these are the constraints. If I substitute zero for x two. Okay, let us continue. We want to guess also value for x one. And now we have here three univariate constraints in x one. And we see we have a problem because x one should be larger, equal to two, but less so equal zero.
00:16:11.304 - 00:17:10.437, Speaker B: This cannot be satisfied. And now we have the two constraints which stay in conflict for this assignment, and we can use furiabotskin to derive a new statement, namely, if both constraints hold, then x should have the value at least one. Now we can learn this clause and then backtrack, because the choice for x two was wrong for the given x x one cannot be chosen. So we undo this for x two and choose another one that satisfies Navis constraint. And the problem here is that you learn constraints and you lift this up into the Boolean level. That means you need propagation again to direct the search away. Perhaps we could turn around and put this idea another way.
00:17:10.437 - 00:17:41.144, Speaker B: So we thought, cannot we? Instead of putting Fourier motskin into MCz cannot be put a kind of MCz into Fourier motskin. So let us guide the Fourier Motzkin elimination procedure by exploration. So let us do the same. We start and guess a value for x two. We have one bound, it should be less or equal zero. So let us get zero. Now we try to get the value for x one.
00:17:41.144 - 00:18:26.134, Speaker B: And we see, well, here we have a lower bound zero, we have here a lower bound two, and here an upper bound zero. So these two are in conflict. For this value, I cannot extend it to the next dimension. So let us explain it why we apply one fully mosquito to get this constraint. And we see that our current simplified it means that x two should be at least one. And now, because our current assignment does not satisfy it, we backtrack and choose a new value. Okay, perhaps we try to choose one, but we see that it should be at least one, at most zero, which is not possible.
00:18:26.134 - 00:19:19.900, Speaker B: So again, we explain this by applying to these two conflicting statements, one step, one four, emot, skin step, and we are done with the proof. So we even recognize that this constraint is not relevant. So we do not need to apply it. So this is the idea, but we do not want to do it for Fourier Mottskin, because linear arithmetic is quite efficient with the existing method, we want it to do for nonlinear real algebra. And in order to explain that just shortly, I need to give a little bit background to the cylindrical algebraic decomposition, which I assume that you not all know. I will not go into very much details, but let us first start with the univariate case. So, we have an univariate polynomial, and we would like to know whether it has a certain side condition.
00:19:19.900 - 00:20:02.294, Speaker B: So, for example, whether it can get negative. And the key, while real algebra is decidable, or at least for the univariate case, the reason is that each polynomial has finitely many real zeros, at most the degree of the polynomial. And if we can compute these zeros, if we could compute it, actually we cannot compute it. We can isolate them, but we can compute with them symbolically. So this is possible. And then we know that between two zeros, a sign of the polynomial is invariant, okay? Because it is a continuous function. So between two zeros, it cannot get from positive to negative or the other way.
00:20:02.294 - 00:20:49.754, Speaker B: So if we can compute the zeros, we do not need to know how the function looks like. We take the zeros and samples between them and left and right, and then we just substitute all of these into the polynomial and check the sign. And then we can answer this question. If one of the sample fits, the problem is satisfiable, otherwise it's unsatisfiable. And this idea can be extended also to the multivariate case. But there it is of course a bit more complicated, because polynomials have non finitely many zeros, but continuous varieties, which you can see here for these two constraints, two polynomials. The blue one has the variety here, and the green one is this line.
00:20:49.754 - 00:21:34.444, Speaker B: So if you want to check now the satisfiability of this, we also need something like sign invariant regions. And the cylindrical algebraic decomposition defines, by certain procedure which I do not want to explain here, defines so called cylinders, which are stacks of sine invariant regions. It's text. I mean, for example, look at here in the middle we have here a sign invariant region over the whole width of the cell of the cylinder. And then on top of it we have one sign invariant region, cuts through the whole cell, the whole cylinder. Then here we have next one. Here we have a next one.
00:21:34.444 - 00:22:29.218, Speaker B: And why it is nice is that now I can guess any x value here within this interval, and either I can extend it to a sign satisfying point, or none of these x values can be extended. So I can guess any values incrementally, dimension by dimension. And then if I test all of them, then I can check the satisfiability of this formula. This is a very nice method, but its disadvantages, of course, it is for complexity, doubly exponential inverse case. So it's heavy. And there was a very, very nice idea for the model constructed satisfied. The calculus actually was designed for CaD as an explanation mechanism behind it.
00:22:29.218 - 00:23:03.018, Speaker B: Let me give you an intuition how it works. The same as Fourier mods, but now we guess values for real valued variables and evaluate them over polynomials, which is a bit more complex because we need to be able to guess real algebraic numbers. But let us not go into the detail, but only the idea. So for example, we get 0.5 for x. This is here we could choose it freely because there is no univariate constraint in x. Now let us plug in x equals 0.5
00:23:03.018 - 00:23:46.874, Speaker B: to the problem, and we get this one. Now we have univariate constraints in Y and we see that this one is not possible, again for a similar reason than before, because this is a square and a positive number cannot give a negative sum. And now we need to explain it. And the idea is to generate a CaD from this polynomial. So from the only from the conflicting constraints, we take the polynomials and generate the CAD, but not the full Cid, just the cell. And in this case, because it is not possible. The reason is this quadratic polynomial.
00:23:46.874 - 00:24:39.252, Speaker B: And we get as an explanation that none of the values here for x should be taken. And how to explain this, because now we need to argue about zeros of polynomials. This is done in the way, if the constraint c one holds, this is the blue one, then x should not be less than the first zero of this polynomial. This is the discriminant of this polynomial, which the first zero of then is this point defining the x value, where this turnaround happens, so that the solution set pops up. Okay, so you see already one problem. We need to be able to compute with the zero expressions for polynomials, of this representation, for zeros of polynomials. And then we continue.
00:24:39.252 - 00:25:05.124, Speaker B: So for example, we get now we have here an univariate problem in x. So we choose a value which satisfies this constraint. For example, we can choose this value 1.2. And now we evaluate the polynomial. At this point we get new constraints and we try to search for a value for y. And it is also not possible. But now we need both constraints.
00:25:05.124 - 00:25:50.502, Speaker B: And again, now we construct the Cad for these two polynomials, but not the whole Cd, just one cell description. And this describes us. Actually, this area in X can be excluded. And then if we continue, you see that now the expression learned get more complex. And then first, once we have luck, we guess x equals two. And if we substitute, we can extend it to a solution. Okay, and now what I explained for the Fullimetsky method, the question was that we asked ourselves, well, if we can put CAD or not much to CAD.
00:25:50.502 - 00:26:53.446, Speaker B: Like said construction, a CAD cell is constructed as explanation. If this is helpful, would it be also helpful to put kind of MCZ exploration into the cadence? Because how does this MCZ search looks like? Well, it gets its sign value and then it excludes certain areas by explanations from higher dimensional spaces. And then once for this x value, there is no other possibility, we choose another one. And so it will try to cover the whole state space with exclusions until there is no possibility left. And we know that the problem is unsatisfiable, or it finds a solution somewhere. And the problem is that if we want to put explanation into the CAD, it constructs cylindrically, so we do not learn there in the sense that we learn new clauses and propagate in them. This mechanism is not in CAD.
00:26:53.446 - 00:27:26.540, Speaker B: So somehow, in order to make this method useful for the CAD, we need still a kind of cylindrical structure for the search. It doesn't work otherwise. And the idea is, well, just make it cylindrical so what we do is we also guess. And if the guess is wrong, then we generate explanations as before. But once one dimension is completed, I have no further choice. Everything is excluded. Then we take the cylindrical intersections of them.
00:27:26.540 - 00:28:07.400, Speaker B: So in this case, you see, within this area it is fully covered. And now the magic is to adapt the projection operators of the CAD, such that we can compute this cylinder as large as possible, using as few projections as possible. And then when we are done, then we go into the search tree. At other places we also guess. And by the continuation we exclude pieces. And then if we excluded the whole, so the guess cannot be extended. Everything in the next dimension is covered by explanations.
00:28:07.400 - 00:28:58.636, Speaker B: Then again we fit a cylindrical structure around it, exclude it and then continue. Also here Vivier cover and continuous cylindrical extensions. And now you see what we get is not a cylindrical algebraic decomposition anymore, but it is a cylindrical algebraic covering, because the cylinders might overlap. Okay, is it good in practice? Here see some results. What you see here is the traditional SMT with Cad Ss series solver. In the next one you see a modification with the CAD statical structure. First project dimension, visor, everything, and then lift up.
00:28:58.636 - 00:29:54.614, Speaker B: For those who know how the CA is working, it is modified that we can make a partial projection, can try partial samples such that we can detect satisfiability without doing the whole work. The third one is the covering, and the last one is the MCZ. It is called Nsat. And you see that the covering is good, but it is not better than ns. But this covering does not yet have this incrementality included. It has still the static projection structure. So if we improve this and add this incrementality, then we have the chance still to beat the currently best approach MCZ with CAD for nonlinear arithmetic.
00:29:54.614 - 00:30:51.058, Speaker B: And one more interesting point is, if you compute here the running times for the benchmarks that we took from the the SMT benchmark set, you see that the difference is not really big. So here a lot of things that both can solve relatively fast, and here some divergence. But here you see a lot of benchmarks that NLsat can solve, is hard for the covering, but also a lot of benchmarks that the covering can solve heart for any asset. So this would be interesting to look at whether that is really only heuristical, because these are really a lot. So here you have something like 300 benchmarks and you have something like 500 benchmarks. So this is not, does not seem to be accident, but we cannot explain it yet. Okay.
00:30:51.058 - 00:31:43.414, Speaker B: So I hope that my talk could give you a little bit of impression, what MCZ does and how we can turn it around to put this exploration idea to compute some decisions procedures with exploration. So guide the search by exploration and how it nicely can extend existing methods and improve them. And actually this is also very good related to Vas Curtis maid, because he also tries to explore in the SAT case. And then basically the CAS gives these explanations. But there it is not the boolean abstraction and the other cases, but the division is different. But I see parallels in both of them. So thank you for your attention and if you have any questions then I'm happy to answer.
00:31:45.394 - 00:32:27.534, Speaker A: Thank you for a great talk. Erica, fantastic talk. Questions please. Erika, I had a couple of questions. You mentioned that your integration is essentially in some way similar to the MCSAT. The way you integrated Cad into the SMT solver was through this MCSat approach, right? And it was integral to how your technique works, correct? Is that fair?
00:32:27.694 - 00:32:51.224, Speaker B: Yes. So there are two different approaches. One, the NLSAT. This is the MCZ. It was called NLsAt by the authors. And this guesses at the boolean level and at the theory level and learns explanations. It says, if the following constraints hold together, then exclude this CAD cell.
00:32:51.224 - 00:33:55.982, Speaker B: And what we propose is it is a pure series solver for conjunctions of constraints. And we use this guidance to look first and only if we have conflicts. Then we apply the generation of CAD cells. But now we keep this cylindrical structure in the search. And this allows us not to learn, because we always at the same cylinder, we look at the future and the higher dimensions, and if we exclude them, we backtrack, so we do not learn. Therefore all this propagation falls away. And yeah, so the difference is that the cells that are generated by MCZ to cover the state space, to exclude all real values in the domain, are not structured, therefore they can also be reused, but they must be learned.
00:33:55.982 - 00:34:50.584, Speaker B: And in all these learned constraints you need to propagate and therefore it might be expensive. And also for each cell generation you need to start the whole projection and so on from anew. So the idea was, let us keep the CAD structure, so we do a similar thing than the original CAD does. So it is really only a series solver in traditional SMT solving. But inside of the CAD we apply exploration not to consider always all polynomials, but only those which matter, because we explore. And we see for this partial sample, certain sign conditions cannot be satisfied together. And then the computer cell only in the CFD of those constraints which matter.
00:34:50.584 - 00:35:00.394, Speaker B: And this is the big, big speed up that we gain, but thereby we lose the decomposition, but we get a covering.
00:35:01.374 - 00:35:06.558, Speaker A: So in other words, you actually flip the search versus theory.
00:35:06.686 - 00:35:49.724, Speaker B: Exactly. We fit it. So basically, in MCZ, you have the boolean and the theory guess first, and then you derive something, learn it, and you need the boolean level to propagate to lead away from these in the future. We do not learn, do not propagate, but need the cylindrical structure to remember what we excluded already and what we need to check in the future. It is because it is mathematically quite a bit involved. It is not easy to explain it easily, but this is what you say is exactly the point. Flip it.
00:35:49.724 - 00:35:52.160, Speaker B: Exactly. Yeah.
00:35:52.272 - 00:36:07.964, Speaker A: I had one more question. So I think McSAT was approached as a distinct architecture for SMT solvers. But to the extent that I know, other than NLSAT, nobody has kind of quite picked it up.
00:36:08.944 - 00:36:16.384, Speaker B: Well, yeah, actually, NSAT was introduced first and then generalized to MCZ. True.
00:36:16.504 - 00:36:17.204, Speaker A: Yeah.
00:36:17.544 - 00:36:48.714, Speaker B: I think it was picked up for floating point something. Floating point arithmetic computations, I think. But I am not so much aware. But I think that it could be promising also to other theories. If you can generate generalizations, these are the explanations. If you find something unsatisfiable, to generalize it to an element from a finite domain, such that you can also assure termination. Right.
00:36:50.934 - 00:37:00.566, Speaker A: More questions, please. If not, let's thank Erica again for a wonderful talk. Thank you, Erika.
00:37:00.710 - 00:37:01.886, Speaker B: Thank you for the invitation.
00:37:01.950 - 00:37:09.862, Speaker A: Thank you. Thank you. Next is Emery. Yoko. Hi, Emery. Could.

00:00:02.160 - 00:01:01.544, Speaker A: Okay, our second speaker this morning is John Allenstein, the second part of solving polynomial equations. Thank you, John. So today's talk will talk about isolated solutions. First, how do we use homotopies to compute isolated solutions? What's sort of the geometry behind positive dimensional solution sets, and how can we do computations on them? And then at the end, I'll talk about complexity of, of the solving approaches and how it relates to smale 17 problem. So, if you recall, we're going to take a polynomial system f, and let's assume that it's a square system. So the number of variables is equal to the number of polynomials that we have. The nice thing about square systems is it's sort of well conditioned.
00:01:01.544 - 00:01:50.474, Speaker A: I can perturb the coefficients and my solutions will still exist. And the idea is to set up a homotopy plus t times g of x. You give me f. My goal is to construct g appropriately and now trace the solution curves. So we want to set up this and then trace solution curves defined by h equal to zero. The nice thing about this is each solution curve can be tracked independently. So we have a good parallelization of this solving approach.
00:01:50.474 - 00:02:42.376, Speaker A: Okay, so the first thing we want to do is how do we set up g? And there's different approaches. And let's start with the most basic choice of setting up g. And this is what's called a bayesiohomatopyl. So, Bayesu here corresponds to Bazou's theorem, and it'll be generically sharp with respect to Bazou's theorem. So assume that di is the degree of fi. And now I'm just going to take my homotopy to be very simply, one minus t plus t times the following system. X to the d one minus one.
00:02:42.376 - 00:03:22.494, Speaker A: X one to the d, one minus one, xn to the dn. So my g of x is this very nice simple system here. What do we know about g of x? Hopefully, we can all write down the solutions to it. It should be clear. So g of x equal to zero as d one times n times dn solutions. They're all nonsingular. Everything is nice about g.
00:03:22.494 - 00:04:09.964, Speaker A: What's the problem? As I originally have it formulated, suppose f has coefficients which are real. This system has coefficients which are real. The real numbers cause some issues. So we want to take advantage of the algebraic closure of the complex numbers and add in some complex number here, where gamma is a complex number. We have to move away from the reals to the algebraically, their closure the complex numbers. Good. And so now we can prove a theorem that for all but finitely many.
00:04:13.584 - 00:04:15.364, Speaker B: Sorry, why do you need the gamma?
00:04:18.424 - 00:04:50.304, Speaker A: So if we don't have the gamma there, think about, think about f here, having, let's say, x squared plus one is our f. And now we want to deform from x squared minus one times one minus t plus t times this. This has real roots. This has complex roots. The only way to get from real roots to complex roots is to pass through a singularity.
00:04:51.524 - 00:04:54.860, Speaker B: Oh, I see. You want to avoid similarities on your path.
00:04:54.932 - 00:05:39.324, Speaker A: Exactly. Very good. Okay. And as you will see here, that's one of my statements of the theorem. So for all but finitely many points on the unit circle and complex numbers, the following things hold one. There are d one through dn, continuous solution paths. Let's say x such that.
00:05:39.324 - 00:06:49.936, Speaker A: All right, let's move to the other side of the board. What would be nice properties of this? Well, the first thing we would like is they should satisfy our equate. So for all t in the interval between zero and one. The other thing that would be nice is that they were smooth. So this example that I wrote up here for jm, I believe, had a singularity at t equal to one, two that I've now erased. So we would like these to be smooth so that the condition number is finite along the path and so we can nicely trace along them. However, we have no control over what happens at t equal to zero at f.
00:06:49.936 - 00:07:38.324, Speaker A: So the only thing we can say this is, this is for the open interval. Open on the left side at t equals zero, we have no control over f. You gave me f. I don't know what the solution. I pick g so that at least away from zero, everything is nice. Good. What else would we like? The next thing that we would like is to look at the set of endpoints such that x, sub t, is solution path, and the limit as t goes to zero actually exists.
00:07:38.324 - 00:08:17.412, Speaker A: Okay, so maybe it's helpful to draw a picture. This picture is morally correct, but not mathematically correct. So here's my t and here's my x space. Over here at t equal to one, I have the roots of unity, that they're appropriate choices. And then over here, I don't know what I have. I have some points, I have some curves. I don't know what I have.
00:08:17.412 - 00:09:06.114, Speaker A: And now I have these nice, small continuous path that sort of, I don't know, come over like this and maybe some go off and diverge to infinity. So this is the correct statement. So if I look at the set of endpoints, the limit points which converge in my affine space. What would we like to be? True? We would like to be true. Remember, this is the isolated point, the isolated solutions. We would like this to be true and indeed it actually is true. So the set of endpoints contains all of the isolated solutions.
00:09:06.114 - 00:09:36.174, Speaker A: And obviously every endpoint is also a solution if something stronger than this is actually true. And in fact e contains a point on every connected.
00:09:39.384 - 00:09:43.324, Speaker C: Component, not algebraic component, but connected components.
00:09:44.624 - 00:10:05.214, Speaker A: Exactly. So it's not irreducible, but it's the connected components in the euclidean, euclidean topology over the complex numbers. So here I drew sort of a, some kind of connected piece. I'm going to at least find one point on that connected set.
00:10:06.514 - 00:10:10.346, Speaker B: So if there's an embedded component, you won't necessarily find it.
00:10:10.410 - 00:10:26.082, Speaker A: Exactly. So as we talked about yesterday, if I have x squared and xy, I'm guaranteed to find a point on the line x equal to zero. But I may or may not find.
00:10:26.178 - 00:10:32.014, Speaker B: The embedded .2 intersecting lines. All you're guaranteed is you'll hit one.
00:10:32.054 - 00:11:43.644, Speaker A: Point on one of the two lines exactly. Only one? Maybe one, maybe more, I don't know. It all depends upon sort of your choice on the start system where it ends up. Okay, what happens if the system has no solution? Ah, then all paths go to infinity. So if this system had no solutions, let's say x and xy minus one, all the paths will go to infinity. What else would we like to be true? Suppose X star is indeed isolated, an isolated solution. How many paths would we like to converge to? X star, the number of paths, let's call it ending at X star, is exactly the multiplicity of your system.
00:11:43.644 - 00:12:38.574, Speaker A: So if you have a multiplicity two root, for example, let's say I want to solve x squared and I start with x squared minus one. Here I don't need a gamma. Gamma, well, gamma is equal to one. Works here, you can rewrite this as x squared minus t. And now you can simply draw the picture at t equal to one, I have one and minus one, and both of these converge to the origin. So x squared has a multiplicity two root. I have exactly two paths converging to it.
00:12:38.574 - 00:13:29.184, Speaker A: Okay, so that's the end of the statement of the theorem, and it's true. And people have brought up many concerns. And so let me address some of those. If my system has no solutions, then all of my paths will diverge to a infinity. How do I track a path that has infinite length? My computer cannot do this. I'll be long dead before my computer ever reaches infinity. So how do I do this? Well, I transform my path into a compact path by going to projected space.
00:13:29.184 - 00:14:53.564, Speaker A: So compactify to yield finite length path. So, there was a homework problem that I'll talk about, sort of, to demonstrate. We have two xy plus three, x plus four, y minus one, and then y squared plus five, x plus two, y minus three. And we correctly found out last night at the homework session that this has exactly three real roots. Okay, so now I set up my homotopy. Xy t is f of xy times one minus t plus gamma times t times x squared minus one, y squared. And so the picture, if you think of x, y, and c two in this direction and t between zero and one.
00:14:53.564 - 00:15:51.034, Speaker A: Over here I have four points. Over here I have three points. I know that three of the four paths have to converge smoothly to those three points, and then the other one has to diverge two and three. So now let's compactify this. So we want to go from c two and embed that into p two and see that we can turn this infinite length path into a finite. All right, so now let's say that x, y, and z are my coordinates in p two. C plus four, yc minus c squared.
00:15:51.034 - 00:16:21.054, Speaker A: Y squared plus five, x. C plus two, y minus three, z squared. One minus t plus times t. X squared minus c squared. Y squared minus c squared. Since this is a compact space, all four of my paths have to be compact. And so the picture looks exactly like this.
00:16:21.054 - 00:17:13.250, Speaker A: Here's the t, here's the x, y, z. And can anyone tell me what the point at infinity is? Yes, it's the 10 zero. And so, in the affine case, I was diverging to infinity in this direction. And so all I've done is I compactified it. So now I explicitly see the endpoint is exactly the direction as I go to infinity. Okay, good. So you avoid infinite length paths by compactifying things, and different compactifications lead to different types of homotopies, as we will see shortly.
00:17:13.250 - 00:17:50.694, Speaker A: Why did I compactify c two into p two? Maybe I want to do c, cross c and compactify this into p one, cross p one. And that exactly is a two homogeneous Bayesux theorem, which we'll talk about very shortly. So, the choice of compactification will impact how well or efficient your method is for solving. What are some other issues? Singular endpoints.
00:17:59.484 - 00:18:12.164, Speaker D: A priori, you. Well, here you can say that because they are low degree and there is some arithmetic abstraction, but a priori, you don't know that that path that goes to infinity goes at an isolated point, right?
00:18:12.244 - 00:18:16.868, Speaker A: A priori, I do not know. But plug in z equal to zero and you see.
00:18:16.916 - 00:18:25.014, Speaker D: Yeah, yeah, yeah. Here we can, right, we have paths that go to infinity. They can go to some positive dimensional.
00:18:25.084 - 00:19:00.200, Speaker A: Component that can be exactly. And my theorem still holds. If I switch from affine space to projected space, I get a point on every connected component at infinity or every connected component over the projector space. And so if it lies at infinity, I get a point on it. Okay, so in this one, all four of the endpoints in projective space were nice isolated non singular points. So I can use Newton's method to quadratically converge. Hopefully it was demonstrated in the homeworks, the power of Newton's method, quadratic convergence is very powerful.
00:19:00.200 - 00:20:09.024, Speaker A: Singular endpoints don't know what's going to happen. I could diverge, I could linearly converge. I don't know. So how do we handle singular endpoints? So how to compute the endpoint when the Jacobian is rent and the idea is to stay far away from the ill condition, it's only singular exactly at t equal to zero. So if my t is positive, I'm in a nice well conditioned region except in the middle. So here's my t. And now I'm thinking of t as a complex number at t equal to zero.
00:20:09.024 - 00:20:57.944, Speaker A: I have a ranked efficient jacobian everywhere else. My jacobian is full ranked. So can I use things in this well conditioned region to approximate an ill conditioned answer? Has anyone seen things like this before? Yeah. So one way you can do is you can just track your past close and then sort of project in some direction. And what you know is that x sub t has a series expansion.
00:21:01.554 - 00:21:02.494, Speaker B: Close enough.
00:21:02.954 - 00:21:39.954, Speaker A: I think there's an a somewhere in there. Maybe that's close enough. Eaux has a series expansion. We saw series expansion in a ball containing t equal to zero. And of course this is an open ball, as I've demonstrated here. So x sub t in this ball has a puiseau series expansion and at t equal to zero is where I want to find it. So I can do exactly what you suggested, sort of.
00:21:39.954 - 00:22:24.874, Speaker A: So one option is to pick points in this ball. So that is compute x of ti for various. I fit a Puiseau series so series and then evaluate x equal to zero. Good.
00:22:27.694 - 00:22:30.398, Speaker E: You're assuming an isolated point.
00:22:30.526 - 00:23:42.334, Speaker A: No, no, the nice thing is it's isolated with respect to the homotopy x of T away from zero. But at T equal to zero, I don't know what happens? It could be isolated, it could be positive. Nonetheless, I have a puissot series expansion. So, let's think back to the very simple homotopy I wrote down before x squared minus t, one path was on the positive square root and the other path was on the minus square root. And for those that don't know what Quiseau series are, these are fractional Laurent series with a constant denominator. So here I have an actual power series in T to the one half. Good.
00:23:42.334 - 00:24:51.574, Speaker A: So in general, x of t. And let's switch a marker. In general x of T. Looks like this summation for j equal to k to infinity of a, sub j times t to the j over c, where k is some integer, it could be negative, and c is a positive integer. C has a name. And this is what's called winding number. So, the winding number is a complex analytic number which says that if I do loops around this, this is the number of times I have to wind around before I come back to where I start.
00:24:51.574 - 00:25:49.634, Speaker A: So this should suggest something about Cauchy's integral formula. So either we have a puissot series and we try and approximate it, or we could just go the route of using complex numbers and do Cauchy integral. Integral. So this says that x sub zero is one over two PI c integral from zero to two PI c x, sub r e to the I theta e theta for zero to two PI I two PI c I theta f c. Yeah, good. Yeah, sorry. Two PI c.
00:25:49.634 - 00:26:29.084, Speaker A: And for. I know this is true because it's on a small ball. So if my radius is sufficiently small, then I get this. Okay, so that's one way to approximate singularity points. Just so you know, these go by the name of end games. What happens at the end of my path? Okay. After I've approximated these.
00:26:29.084 - 00:26:30.608, Speaker A: Yes, go ahead.
00:26:30.656 - 00:26:33.808, Speaker F: How do you find the winding number we have before picking this?
00:26:33.976 - 00:27:10.804, Speaker A: Ah. So one way to find the winding number is to actually do what I said, do loops around it until you come back to where you started. The other way is just to think, okay, this winding number is going to be some positive integer. So I'm going to test that c one and c equal to two and c equal to three, and try and approximate it. If you have enough points, you can make a very good educated guess on what it is. It's a difficult question. One way you actually compute it by integrating around the curve.
00:27:10.804 - 00:28:32.356, Speaker A: The other way is you just guess. Okay. Even if we can approximate our endpoint accurately, we would like Newton's method, Newton's method, the power of quadratic convergence there. So how to restore quadratic convergence of Newton? So the idea is my jacobian is ranked efficient. There's extra conditions that are going wrong there. So if I add in extra conditions to my system to remove the singularity. So let me give you an example, and I hope everyone has seen this before.
00:28:32.356 - 00:29:41.558, Speaker A: Univariate polynomials of multiplicity m. What do you know about a univariate polynomial of multiplicity m? So in the univary case, suppose that f of x star is equal to zero and the multiplicity of f at x star is m. Can I construct a new system such that x star has multiplicity one? Hopefully you've seen this before, but I'm going to add a twist to it. Of course, you know that the m minus first derivative, it satisfies the m first derivative and is not singular. But I'm going to add a twist to it and just keep all of the other derivatives. Start with the system I have. Add the first derivative.
00:29:41.558 - 00:30:08.610, Speaker A: Did that make it nonsingular? No. Add the second derivative. Did that make it non singular? No. Keep going until I've added the m minus first and now it's non singular. So now I know that g of X star is equal to zero and the multiplicity of g at x star. The deflation methods, I'm a little confused.
00:30:08.682 - 00:30:16.306, Speaker B: At the order of events. So you're doing it in method, it doesn't converge.
00:30:16.410 - 00:30:17.094, Speaker A: Yes.
00:30:17.434 - 00:30:29.314, Speaker B: So then what? So then you just start. Then you throw in all the first derivatives, and if it still doesn't converge quadratically, you throw in all the second derivatives. Is that what you're doing?
00:30:29.394 - 00:30:45.596, Speaker A: Exactly. But you add in rank conditions on the. So in the univariate case, you just, there's just one derivative to add it, but in the multivariate case, there's directional derivatives. So in this direction, this derivative vanishes. So I need to add that into my system.
00:30:45.780 - 00:30:55.884, Speaker B: But how do you know? How do you. That's. Okay, good. So that's exactly my question. How do you know which ones? So all you know is that Newton's method is not converging.
00:30:55.964 - 00:30:56.412, Speaker A: Exactly.
00:30:56.468 - 00:30:59.290, Speaker B: So how do you know which derivative to which direction?
00:30:59.322 - 00:31:23.290, Speaker A: So I go back to my methods to approximate my solution better. I know this will work, but I can't integrate things. I can only numerically integrate them. So now I use a higher order numerical integrator. Compute this more accurately. And now plug it back into my system, find the derivatives which vanish. Add those in.
00:31:23.290 - 00:31:29.812, Speaker A: Did it work? No. Come back. Compute more efficient, more accurate directions.
00:31:29.868 - 00:31:30.532, Speaker G: How do you select?
00:31:30.588 - 00:31:32.260, Speaker B: Yeah, that's the question.
00:31:32.372 - 00:31:35.972, Speaker A: Okay, so let me tell you the easiest way.
00:31:36.068 - 00:31:37.704, Speaker C: Just trade that it was square.
00:31:39.044 - 00:31:43.372, Speaker A: Of course, my system here is not going to be square anymore. It's going to be over determined.
00:31:43.468 - 00:31:45.612, Speaker B: I'm not worried about that. I just don't know.
00:31:45.788 - 00:32:14.720, Speaker A: Okay, so here's the easiest way to say it. And so, this was fOCM paper by myself and Charles Walker. Take f and say you have a good approximation to x star. So this is approximately zero. Now compute the rank of the jacobian. So, if I have a good approximation, I can use SPD to compute this. And so, let's say this is r.
00:32:14.720 - 00:32:26.064, Speaker A: So now I'm going to take my system and I'm going to add in all the r plus one by r plus one minus of my jacobian.
00:32:30.644 - 00:32:31.564, Speaker B: That's a lot.
00:32:31.684 - 00:32:51.364, Speaker A: That's a lot. But the nice thing is, is that you don't need all of them. You only need the co dimension, many of them on the average. For explicit computation, you can pick which ones you need at your point. You're interested in.
00:32:53.344 - 00:32:55.576, Speaker B: How you avoid picking a direction.
00:32:55.640 - 00:33:01.328, Speaker A: Yes, I see. Yes. And now you iterate. This is my new system. Compute the rank of.
00:33:01.336 - 00:33:05.204, Speaker B: The fact that these are a very high degree doesn't bother your computer?
00:33:06.024 - 00:33:09.324, Speaker A: What bothers my computer is the fact that there's a lot of them.
00:33:10.384 - 00:33:13.848, Speaker B: More than that. The degree is r times the degree.
00:33:13.936 - 00:33:24.184, Speaker A: Exactly. Because all I'm doing is local computation. There. I can efficiently evaluate each one of these minors and their derivatives. I don't need to expand them out.
00:33:24.304 - 00:33:30.724, Speaker G: So when you go to second and third and fourth derivatives, do tensors get actually used in tensor methods?
00:33:31.504 - 00:33:34.536, Speaker A: Not right now, but it could be. You could.
00:33:34.680 - 00:33:35.804, Speaker G: Structure depends.
00:33:35.924 - 00:33:40.544, Speaker A: Yes, absolutely. So does that clear things up?
00:33:41.244 - 00:33:41.980, Speaker B: I'm fine.
00:33:42.052 - 00:33:42.796, Speaker A: Okay.
00:33:42.980 - 00:33:46.796, Speaker D: The fact that this is overdetermined doesn't cause any problems?
00:33:46.860 - 00:33:57.544, Speaker A: No, because there is a subsystem which is full rank, and that's all I need. It's a full rank subsystem.
00:33:58.324 - 00:33:59.852, Speaker C: You just take a generic subsystem.
00:33:59.908 - 00:34:00.664, Speaker A: Exactly.
00:34:01.544 - 00:34:06.336, Speaker D: And we don't care that doing this, we throw away all the other solutions. Right now we are only there.
00:34:06.400 - 00:34:22.792, Speaker A: I'm only interested in this particular solution. For your other solutions, you might have to do something completely different. Your multiplicity may be different, doesn't matter. But for this particular solution, how do I restore quadratic convergence of Newton's method?
00:34:22.968 - 00:34:31.635, Speaker D: For this one, for the Newton iteration, the derivatives, it's not quadratic. It's not quadratic anymore. You take this Newton inverse moot universe.
00:34:31.699 - 00:34:58.133, Speaker A: No, you take a random subsystem of this, which is the next, the next thing. So you could either take a pseudo inverse of this, of this, or you could take a random substance and then use that for your newt's method, and you get quadratic convergence in both of them.
00:34:58.553 - 00:35:02.417, Speaker D: Okay? And if you take a random subsistence, the multiplicity will be.
00:35:02.505 - 00:36:08.014, Speaker A: Yeah, that's exactly my next statement here. So singular things naturally lead to over determined conditions because there's extra, extra minors that vanish. So there's extra conditions that vanish there. How to handle over determined systems? Okay, so start with your polynomial g, your system g one through gn, and x is x one through xn. And now look at this system, a times g of x, where a is an n by n matrix. So now my f is a square system, so I can do all computations with f, whereas g is an over deterrence. All right, and so now we're to Bertini's theory.
00:36:08.014 - 00:38:03.244, Speaker A: How do the solutions of f and g relate? And in particular to Peter's question, what about the multiplicity? So this is Bertini's theorem. So there is this risky open dense subset of the n by n minors n by n matrices, let's call it u, such that for all matrices a and u, what's the relationship between f and g? Obviously, if I have a solution of g, a times zero is still zero. So I know that this contains everything that I started with. What about the extra stuff? What happens to the extra stuff? It satisfies a randomization, but doesn't actually satisfy. My system consists of finitely many non singular. And I have to tell you what is respect to non singular with respect to f solutions, points. I have solutions.
00:38:07.264 - 00:38:16.244, Speaker B: What I thought you would expect, other than since this is so. Oh, I see.
00:38:18.104 - 00:39:32.622, Speaker A: Okay, so my system, my randomized system contains everything I had before, plus some non singular points that are sort of somewhere lying out there. The more important thing is what happens to the multiplicity. Suppose I have an isolated solution of g. Then the multiplicity. If x is in here, then the multiplicity of f is greater than or equal to the multiplicity of g with equality if either is one. So if my multiplicity of my overdetermined system is one, then the multiplicity of my random sum system will also be one. So if either of these are one, then, you know, the other one has to be one, or the multiplicity of f of x star is equal to two.
00:39:32.622 - 00:39:43.774, Speaker A: If this multiplicity is two, this one also has to be two. Okay, let's look at an example.
00:39:48.234 - 00:39:50.774, Speaker B: Why do they have to be equal if they're two?
00:39:51.634 - 00:39:56.962, Speaker A: If the multiplicity is two, then it's singular and therefore it's singular with respect.
00:39:57.018 - 00:39:58.974, Speaker C: To g, because that can't be one.
00:39:59.354 - 00:40:01.294, Speaker A: Singular things can't have multiple.
00:40:02.274 - 00:40:03.494, Speaker B: Why can't it be?
00:40:05.664 - 00:40:18.644, Speaker A: It can't be higher. Because if you think of multiplicity, f is greater than. Yeah, yeah, f contains stomach.
00:40:19.544 - 00:40:21.604, Speaker B: Sorry, a little dyslexic today.
00:40:27.104 - 00:40:32.846, Speaker A: So let's look at this system. X squared, xyy squared, just to know. Yep, go ahead.
00:40:32.870 - 00:40:37.726, Speaker D: Simplicity of f and x star is larger than two, then we don't know.
00:40:37.790 - 00:41:00.204, Speaker A: Don't know. And this example will demonstrate. Okay, what is the multiplicity of g at the origin? Three. Three. Very good. One, x and y are the standard monomials and there's three of those. Take a random subsystem.
00:41:00.204 - 00:41:46.544, Speaker A: I'm going to use notation like this. Well, let's just stick with the standard notation. And here a lies on my zyristy open dense subset. What is now the multiplicity. So my multiplicity is four, and that obviously is upper bound on three but not equal. Now comes a user based question for those that have used bertini, the software, which answer does Bertini give you three or four?
00:41:50.864 - 00:41:58.084, Speaker C: It's probably going to take advantage of the structure and give you three, but I've never used it gives you four.
00:41:58.544 - 00:42:36.394, Speaker A: For t gives you four because that is exactly equal to the number of paths which converge. Because this is a square system. This equals the number of paths, and that's what pertaining the software counts. Counts how many paths converge. And so that's what Bertini, the software will give you. So that's just a quick aside that if you have over determined systems, make sure you understand what the software actually is computing. Okay, questions, concerns.
00:42:37.214 - 00:42:46.272, Speaker G: So, is there an issue in picking the a? Maybe you might like to be interested in picking a somewhat sparse a still in some other sense generic enough.
00:42:46.328 - 00:42:46.704, Speaker E: What about.
00:42:46.744 - 00:43:13.304, Speaker A: So we are to pick again. So you can take for instance, this reorder your g's so that you like the ones at the top and you don't care about the ones at the bottom. Now you can sort of randomize the ones at the bottom up to the top. And here the same theorem holds on a zyristy open subset of the choice of matrices b.
00:43:13.384 - 00:43:15.824, Speaker C: That's simply because it only matters about the row space of a.
00:43:15.904 - 00:43:16.704, Speaker A: Exactly.
00:43:16.864 - 00:43:18.224, Speaker C: Just taking the shoe itself.
00:43:18.344 - 00:43:28.128, Speaker A: Exactly. So you can add in structure onto your a's. You don't have to be completely dense, completely dense matrix. You can add in lots of structure.
00:43:28.176 - 00:43:29.536, Speaker G: Well, I'm also thinking about pushing the.
00:43:29.560 - 00:43:30.848, Speaker A: Number of paths down.
00:43:30.936 - 00:43:33.564, Speaker G: Maybe if I locally, and I'll think.
00:43:33.604 - 00:44:24.854, Speaker A: About some polygons or something like that. Right. We'll leave it at that. Okay, so now let's return to Steiner's problem. So the question is, who remembers Steiner's problem from two days ago? A couple people. Okay, so it was count the number of conics tangent to five given general conic. Very good.
00:44:24.854 - 00:45:07.504, Speaker A: I'll get to that. Okay. And remember, if I pick one conic, I have a hypersurface of conics tangent to that, and the degree of that hypersurface is six. So this translates into a system of five polynomials here, x is in p five, and you can think of conics as equivalent to p five. And the degree of fi is six. So this is a square system. And so now you track six to the fifth, which is 7776 paths.
00:45:07.504 - 00:46:21.454, Speaker A: What happens to those paths? I know I'm going to get the isolated solution solutions because my space is compact. All of the other ones have to converge, and therefore they have to converge to the line, to the double lines. So if I can do arithmetic in my head, lie on the so called double lines, maybe I should just say is a double line. So these are honest conics, tangent. And these are double lines, which are fakely tangent because you have the multiplicity coming from the double. So Steiner in 18, roughly 1860, had access 18 48, 48 had access to modern computers. You can do this computation relatively fast and see that the answer is not 7776, but indeed 32 60.
00:46:21.454 - 00:46:44.914, Speaker A: This also proves that there are no other connected components. The only connected components in this system are exactly the double lines. So that's a nice application of bazoo homotopy.
00:46:45.734 - 00:46:54.326, Speaker D: So they are all in the same component, all these 4500. Yes, but this year, then you see it, right?
00:46:54.390 - 00:47:49.344, Speaker A: You actually see that this one of these, each of these conings is a double bond, right? It can factor as a linear square. Okay, so now Barrett sort of gave a hint that maybe you want to do some extra structure on here. Bayesuhomotopies usually are not what you want to try. They overestimate the number of solutions very often. So, typically systems have a rich structure, and by that the system f. And so you want to exploit that structure in your homotopies. If you think back to my, it's not exactly the same one, but close enough.
00:47:49.344 - 00:48:30.724, Speaker A: Y squared plus two, x plus three, y minus two doesn't matter. This wasn't the intersection of two quadrics. It really was the intersection of a curve of degree one one and a curve of degree one two. There's really three solutions there on C cross C. So now I should be able to construct a start system which has that same structure. So this is linear in X and Y. So pick your favorite linear in X and Y.
00:48:30.724 - 00:49:09.404, Speaker A: X minus one times one. This is linear in X. So pick your favorite linear in X and then quadratic in Y. And so there you go. These both have, have the same two homogeneous structure. And therefore, my theorem at the beginning of the lecture holds for almost for all but finitely many choices of gamma. You get exactly what the rest of the theorem says.
00:49:09.404 - 00:49:19.244, Speaker A: And now hopefully you see how to count. If I take x equal to one, x is not two, therefore one of these two.
00:49:19.284 - 00:49:21.984, Speaker D: Why did you take a cubic one back there?
00:49:23.364 - 00:50:23.744, Speaker A: But so the degree of this is one one and the degree of this is one two. And so I need one linear in X and two linears in one. So even though it's not cubic, as you would think of cubics, it is bi degree one two. And therefore I need a polynomial of bi degree one two. Ok, so this is multi homogeneous. What are some other structures that you would like to exploit? Polytodes. I want to exploit the monomial structure of this system.
00:50:23.744 - 00:51:26.334, Speaker A: So now instead of this start system, I create a new system and I'll explain the notation in a second. So I'm going to replace this system here with this system. And each one of these boxes means pick your favorite random number. So I've taken my given system and thrown away your coefficients. I don't like your coefficients. I'm going to substitute my own coefficients and I'm going to generate them from my favorite random distribution, solve this system, and then track the homotopian paths over to here. And so Baron can tell you much more details about this than I can.
00:51:26.334 - 00:52:02.794, Speaker A: How many points do you have to have over here? So the number of paths is equal to the BKK bound for your system, so the mixed volume of the corresponding Newton polygon. So you can use the combinatorics to compute this bound and then use the polyhedral nature of this to compute the solutions and then to form from there. Okay, where are we going?
00:52:04.214 - 00:52:11.274, Speaker B: What if you have sort of determinantal type equations? Do you have a special thing for those?
00:52:12.094 - 00:52:54.812, Speaker A: So the art of, of homotopy construction is knowing how you constructed your system. So then you can construct a good start system. So typically anything that you can find, anything which is a constructive bound on the number of isolated solutions. So if you have a constructive way to bound a number of solutions, typically you can turn that into a homotopy. So for determinantal things, there is a constructive way to bound the number of things. And so if there are problems of interest, generate the family of those generically that will have that bound, and then therefore you can set up the whole thing.
00:52:54.908 - 00:52:57.156, Speaker C: Well, the problem is solving one instance.
00:52:57.300 - 00:53:36.554, Speaker A: Yes. So there's two problems. One is counting the bound. So how do you actually compute this bound for, for instance? And then the other thing is, how do you actually find the right number of solutions to the system that agrees with this? And then you can do the homecoming. So this is the art. And systems that many of you generate have lots of structure, and the art is finding that structure and being able to exploit it. There's a lot of room for generating special types of homotopies for your systems of issues.
00:53:36.554 - 00:54:05.850, Speaker A: Yes. How is the randomness, the randomness is helping me here, that this will have all of these solutions, because I have the constant term here. I know this is true. All of these solutions will be non singular and isolated. And so therefore my homotopy paths will be smooth, except at the very end, possibly. So the randomness is guaranteeing me this non singular solution.
00:54:05.922 - 00:54:10.602, Speaker E: That is guaranteeing also that this system is well posed.
00:54:10.658 - 00:54:12.018, Speaker A: Yes, yes.
00:54:12.066 - 00:54:14.986, Speaker E: So this is another important issue, numerical analysis.
00:54:15.050 - 00:54:15.874, Speaker A: Absolutely.
00:54:16.034 - 00:54:17.322, Speaker B: With high probability.
00:54:17.498 - 00:54:18.066, Speaker A: Of course.
00:54:18.130 - 00:54:22.294, Speaker B: These are guarantees, not like unconditional, right.
00:54:23.694 - 00:54:28.406, Speaker A: With probability one, based upon your reasonable choice of random numbers.
00:54:28.550 - 00:54:34.494, Speaker H: It seems like the new system that you created is harder potentially to solve than the one that you started with.
00:54:34.574 - 00:54:49.234, Speaker A: And Frank pointed this out. That's the arc. So what did Baron do here? He deformed to sort of binomial systems. Binomials are much easier to solve and then lifted back to solutions here. So that is also the art. How do I solve this system?
00:54:50.644 - 00:54:53.380, Speaker H: Well, you might as well just deform your original system then.
00:54:53.492 - 00:55:09.756, Speaker A: But this could have singular solutions. This could have positive dimensional components. At least I'm deforming to a solution that I know is nice. So what if you tricked, let's say, your four favorite points, and then, so.
00:55:09.780 - 00:55:11.332, Speaker G: That you know the solutions of the.
00:55:11.348 - 00:55:37.484, Speaker A: Other system and then choose your coefficients, which vanishes. Absolutely. That's the thing, right? Why did I, why did I pick this one? Why can't I pick, so a one, b one bi for I equal one to four, and then find the two polynomials that vanish at exactly these four points. They're equivalent.
00:55:37.864 - 00:55:46.768, Speaker C: So absolutely well, it's actually extremely easy to find, given a solution, to find a system of the structure you want that has that as a solution.
00:55:46.816 - 00:55:47.288, Speaker A: Absolutely.
00:55:47.336 - 00:55:50.376, Speaker C: And that's also a method that people are thinking about.
00:55:50.440 - 00:56:41.146, Speaker A: Yes. So my favorite homotopies right now are newton homotopies. Pick your favorite y, and at t equal to one, I have a solution, and now I can deform from y along my curve. So it's very easy to write down a homotopy, pick y, write down a homotopy that vanishes there. You can also do what are called fixed points, homocho these, and. I don't understand, I don't understand.
00:56:41.210 - 00:56:42.714, Speaker B: You're doing f of x minus t.
00:56:42.754 - 00:57:29.084, Speaker A: F y is a fixed point. I pick y first, and then I construct this homotopy. And when t is equal to one and x equal to y, I have a solution. You can also do plus t times x minus y star. And again, when t is equal to one, y is the solution of this. And now I can track that path. I don't have, in this case, at t equal to one, there is a unique solution, but in this case there could be more multiple solutions that I don't know what they are a priori, I'd have to confuse.
00:57:29.084 - 00:57:48.232, Speaker A: Good. So let's get a different pen. Just a question about. Go ahead. Yes.
00:57:48.288 - 00:57:50.204, Speaker E: Why is that called Newton homophobic?
00:57:50.804 - 00:58:50.804, Speaker A: This has been asked several times by several referees on the same paper, different papers. And the reason is, the best answer I can give you is there are some classical papers in engineering that call these Newton homotopies, and therefore I'm sticking with their name. That's the best answer I can give you from roughly the sixties. Yes. So that's the best answer I've given the referees who asked in the fixed point. That's a similar, similar thing. These have been used for 40 or 50 years, and they just sort of got the name afterwards.
00:58:50.804 - 00:59:56.744, Speaker A: Okay, I shouldn't have erased this. All of these homotopies that I've written up are all in a general class called coefficient prime parameter. And the idea is, if I can solve for a sufficiently general point, then I can change either my coefficients or some other parameters and solve at the system that I want. So here, my, my parameter space is the set of all bivariate polynomial systems, where the first polynomial has degree one one, and the second polynomial has degree one two. So this is really a homotopy inside of that space. The same thing with this. This is a homotopy in a set of polynomials with the same monomial structure.
00:59:56.744 - 01:00:30.094, Speaker A: And you can sort of generalize this. So if I look at Steiner's problem, suppose I solve Steiner for miconics. C one through c five. I know there's 3264 solutions. And now suppose I want to solve for new conics. C one prime through c five prime. I can deform in the space of conics from the solutions to this to the solutions to this.
01:00:30.094 - 01:00:43.482, Speaker A: And I only need to track the right number of tasks. So here I'm going to have a generically sharp homotopy that consists of 3264. Is that the right number? Yes. Okay.
01:00:43.578 - 01:00:46.218, Speaker C: So why do you know you're not going to have to pass through a double line?
01:00:46.306 - 01:01:03.914, Speaker A: Ah, very good. You're going to take a general path in your parameter space. And the only way you can end up at a singular point is if your conics were degenerate. So with probability one, the path between these two will.
01:01:06.094 - 01:01:10.038, Speaker G: Now, this feature is a little different from the previous one, the sense that it's no longer linear.
01:01:10.086 - 01:01:24.294, Speaker A: T is not linear six. Exactly. So here I really have a non linear parameter space that I'm moving through. Over here, I have a linear parameter space, the linear affine space given by these eight coefficients.
01:01:24.954 - 01:01:26.218, Speaker C: Why are those nonlinear?
01:01:26.306 - 01:01:29.498, Speaker G: Because it's a discriminant. So two co next to the tangent is six.
01:01:29.546 - 01:01:30.066, Speaker A: Six.
01:01:30.210 - 01:01:32.574, Speaker C: Oh, right, right. It's a three six.
01:01:33.154 - 01:02:06.192, Speaker A: Gotcha. Yes. Thank you. So, everything you would like to hold for linear spaces also holds for irreducible parameter space. And as long as you can still inside your irreducible family, all the theorems I've said will hold with proper respect. Good. Should we give time for discussion? What time did I start?
01:02:06.328 - 01:02:07.004, Speaker B: Quarter.
01:02:07.384 - 01:02:29.424, Speaker A: Okay. I still have plenty of time. Oh, sorry. Okay, let me end with this. My apologies. At least let me state smale. 17th problem.
01:02:29.424 - 01:03:37.254, Speaker A: So, the idea is I want a deterministic procedure for computing a root of a system in polynomial time on the average. Okay. What does it mean to compute a root? It means to compute a point in the quadratic convergence zone of Newton's magnitude. And if you replace deterministic here with uniform probabilistic, probabilistic. This has been solved by beltron and Pardo. And if you keep deterministic, I believe the best is n to the log. Log n, where n here is the input size.
01:03:37.254 - 01:03:45.306, Speaker A: And this is by Berger. Please forgive me as I misspell your.
01:03:45.330 - 01:03:49.014, Speaker B: Name, but he could probably tell you the correct correction.
01:03:50.634 - 01:03:52.474, Speaker D: It's an I, not an.
01:03:52.514 - 01:03:54.734, Speaker H: If you write it messy enough, you can't tell what.
01:03:59.624 - 01:04:21.044, Speaker A: Okay, I'm done. Thank you. Questions? What you can think of this is the number of steps my path tracker has to take is polynomial in the input slash.
01:04:22.224 - 01:04:23.572, Speaker B: What are the average?
01:04:23.768 - 01:04:58.604, Speaker A: Pick your favorite probability on the set of polynomials with a fixed degree. Okay. But the original statement of the problem did not say, use this probability, but pick your favorite or smale's favorite probability space on the polynomial system, and then on the average, you can track this path in polynomial time.
01:04:59.704 - 01:05:18.176, Speaker H: So going back, maybe rewind 15 minutes when people were talking about the homotopia and so on. If I give you a arithmetic circuit where I draw the circuit, for instance, that computes a given polynomial, can you then design a better homotopy, knowing that's the way I'm going to evaluate my.
01:05:18.200 - 01:05:27.684, Speaker A: Polynomial in theory, you would like to how to do it in practice, I think will be problem dependent.
01:05:28.544 - 01:05:32.924, Speaker C: We'll also number of solutions understandable from the circuit.
01:05:34.784 - 01:05:35.328, Speaker A: Yeah.
01:05:35.416 - 01:05:36.164, Speaker F: I mean.
01:05:38.504 - 01:05:53.866, Speaker H: Time in mind, I have a lot of my favorite types of polynomials that I never write them down exactly, but I know how to evaluate them and I can tell you how to evaluate them. And it sounded like what you said is, if I have a method to tell you how to evaluate a polynomial, then you can design a homotopy to.
01:05:53.970 - 01:06:02.134, Speaker A: What you have to do is have a method which you can solve a polynomial in sort of the same class of those polynomials.
01:06:04.354 - 01:06:08.918, Speaker H: Assuming if I tell you a root of that polynomial, in addition to telling you how to evaluate.
01:06:08.966 - 01:06:11.674, Speaker A: No, no. The structure of that polynomial system.
01:06:15.214 - 01:06:52.874, Speaker E: If you have a program to evaluate the polynomial, your program works in a certain number of steps. Each steps computes a new variable, an intermediate variable from the previous ones. That's one equation. So you have an implicit part polytope boratic program. So this can be used. Those will be polytopes with maybe even three points each. It's not clear if this will be easy to compute mixed volumes, but it is possible in principle.
01:06:53.614 - 01:06:54.198, Speaker A: Yes, sir.
01:06:54.246 - 01:06:59.254, Speaker G: So suppose I have a p adic chip or black fox that can do p adic arithmetic really?
01:06:59.334 - 01:07:01.552, Speaker A: Really, really well, yes.
01:07:01.688 - 01:07:04.564, Speaker G: Would you use it? What's the first thing you would do with it?
01:07:09.224 - 01:07:17.724, Speaker A: I would try and design an unbreakable code in this context. Good.
01:07:18.704 - 01:07:20.440, Speaker G: Where do you see a potential of.
01:07:20.472 - 01:08:15.934, Speaker A: The adic methods rather than numerical complex? So what you're trying to do here is you're trying to, is you're trying to set up a system of equations. So as I write this system down, I haven't implicitly told you where my x's or t's come from. This really is a system of equations, and you pick your favorite field that you want to do the computation for. If you think in terms of the homotopies, then I have to have some kind of continuity properties to be able to track my system. But this is really just a system of equations that hopefully defines some curves. And if I can do chadic arithmetic.
01:08:15.974 - 01:08:18.478, Speaker G: On these, you're doing a dynamic, you're running a dynamical system.
01:08:18.566 - 01:08:19.514, Speaker A: Absolutely.
01:08:20.114 - 01:08:21.090, Speaker G: Dynamics.
01:08:21.242 - 01:08:53.020, Speaker A: Exactly. So if you want to, you know, x sub one is a solution of here. And then my dynamics says that my jacobian got this inverse times. Anyway, so if you use the dynamics, you have to have continuity of t. So t here has to be continuous, and then you can sort of use nice kind of lifting methods to approximate.
01:08:53.092 - 01:09:01.784, Speaker D: And by the way, there is a master thesis by Paul Briding where we transfer some of these things in this.
01:09:02.724 - 01:09:03.876, Speaker A: To the p edx.
01:09:04.020 - 01:09:10.476, Speaker D: But locally everything is very nice, even nice complex numbers. But there is a global problem because.
01:09:10.540 - 01:09:12.404, Speaker A: This is totally discontinues.
01:09:16.304 - 01:09:17.280, Speaker D: Breaks down.
01:09:17.392 - 01:09:19.204, Speaker A: Yes, absolutely.
01:09:20.904 - 01:09:22.964, Speaker G: The purple rich identification.
01:09:23.424 - 01:09:35.368, Speaker A: Maybe we can talk about any other questions. Sorry for going over time. Sorry.
01:09:35.456 - 01:09:36.324, Speaker E: Do you actually.
01:09:40.444 - 01:09:42.464, Speaker A: Sorry. The people that know me are not.
01:09:47.084 - 01:09:48.396, Speaker B: Chaotic paths.
01:09:48.540 - 01:09:50.436, Speaker A: Oh, it depends on.
01:09:50.540 - 01:09:51.916, Speaker C: He's asking about chaotic paths.
01:09:51.980 - 01:10:49.744, Speaker A: Yeah, it depends on how you set things up. And so I've done experiments in the general case, and there, everything is nice. But then also for particular systems, you have what's the best homotopy? How do these paths behave if things go off to infinity? Do they come close together? So conditioning. Conditioning is a major problem. So if I have paths that come close together, how do I correctly track between these two things? How do I design homotopies so much? My paths are far apart, so that I don't have ill conditioning nearby. These are lots of experiments that I and others have run. And the nice thing is, is that while you can design homotopies which come close together, you have to use higher precision to be able to see that they're separate and design algorithms to be able to handle these things.
01:10:50.884 - 01:11:02.204, Speaker F: Yes, but once you adapt the precision, are you, are you approvally able to say that you have a correct answer because you have used the correct precision?
01:11:02.544 - 01:11:27.960, Speaker A: So I'm going to, I believe it was a recent paper by you and Mike Shu to provably adapt the precision. So what's currently, he doesn't even know what I so implemented in my software, Bertini, is a heuristic adaptation of the.
01:11:27.992 - 01:11:30.364, Speaker D: Precision with Lakey and tetra.
01:11:32.224 - 01:11:36.644, Speaker A: Yeah. There are new certifiable ways to.
01:11:39.504 - 01:11:49.104, Speaker E: Let I answer like this, you fix a precision, you can do the calculation and prove you have an approximate root.
01:11:51.324 - 01:11:51.636, Speaker A: If.
01:11:51.660 - 01:11:55.944, Speaker E: You have an exact root. And with this generate.
01:11:58.004 - 01:11:58.548, Speaker A: You need a.
01:11:58.556 - 01:12:13.800, Speaker E: Certain precision to get to that point. And that precision is estimated and well understood. It depends on the condition number at that point root is well posed.
01:12:13.952 - 01:12:14.872, Speaker A: No problem.
01:12:15.048 - 01:12:19.680, Speaker F: Well posed in the sense that it's exactly non singular.
01:12:19.752 - 01:12:23.564, Speaker A: No, it's a non singular. The exact root is non singular with respect.
01:12:28.024 - 01:12:34.736, Speaker E: To the norm of the inverse of the derivative. There are a few correction term, but it's essentially that.
01:12:34.920 - 01:12:44.386, Speaker F: So in principle it's possible to do numerical algebraic geometry in a way that your answers are provably, I mean, your.
01:12:44.410 - 01:12:46.698, Speaker A: Answers are proved by your running.
01:12:46.746 - 01:12:48.490, Speaker F: Yeah, when you run the program, you have a.
01:12:48.562 - 01:12:51.242, Speaker A: If your endpoints are non singular, if.
01:12:51.258 - 01:12:55.574, Speaker F: Your endpoints are non singular in the sense that they can still.
01:12:57.994 - 01:12:59.026, Speaker A: Converge.
01:12:59.210 - 01:13:00.546, Speaker F: So you have to start with the.
01:13:00.570 - 01:13:16.912, Speaker A: Correct number in the sense that if I have a generic sharp homotopy where the number of star points is equal to the number of endpoints, I can provably guarantee that I have all of the solutions here. They're all distinct, everything.
01:13:17.088 - 01:13:20.964, Speaker F: But if the pet's numerous, then you.
01:13:21.344 - 01:13:50.284, Speaker A: How do you. So the notion of approximate root means I'm in the quadratic convergence zone. If we match, if it's a singular point, what does the quadratic convergence here mean? You have to come up with a new definition of how do I approximate this root? Do I give you a deflation type algorithm where I remove the multiplicity and now prove that that was the right way to remove the multiplicity here?
01:13:52.104 - 01:14:10.498, Speaker F: So I guess what I'm trying to understand is looking at the size of the coefficients and the degree of everything. Is there an obstruction to doing the middle class brick geometry to probably get the.
01:14:10.666 - 01:14:25.434, Speaker A: The obstruction is the root separation. Bounds are whatever they are, exponentially, doubly exponential. That is the fundamental. What is your barrier?
01:14:26.454 - 01:14:28.902, Speaker E: Is your input real and complex numbers.
01:14:28.958 - 01:14:30.554, Speaker A: Or integers.
01:14:35.734 - 01:14:54.894, Speaker E: That makes a difference because with real and complex numbers you have a surface of imposed system. If you have integers, in principle, if it is nondescript degenerate, the condition number will be smaller than a certain bound. And if it is degenerate, well, you can still.
01:14:59.394 - 01:15:02.454, Speaker H: I suggest that we continue the discussion over lunch.
01:15:07.194 - 01:15:11.694, Speaker B: So especially for computer scientists interested in.
01:15:12.894 - 01:15:15.622, Speaker A: Like that will be very basic.
01:15:15.678 - 01:15:19.674, Speaker B: I break geometry at 5510. Soda?
01:15:20.574 - 01:15:45.504, Speaker A: Yeah, thank you. It's got a nice. Sorry for G cross hormones in. So on the average things are well.

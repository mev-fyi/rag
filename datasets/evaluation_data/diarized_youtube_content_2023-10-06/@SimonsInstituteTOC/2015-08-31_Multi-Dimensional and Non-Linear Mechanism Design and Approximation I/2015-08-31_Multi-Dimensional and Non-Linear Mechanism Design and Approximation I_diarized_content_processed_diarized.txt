00:00:02.000 - 00:01:13.494, Speaker A: So this series of two talks will be on multidimensional and non linear mechanism design, and I'll give some application to approximation at various points in the talk as well. Today I'm going to focus on one perspective you can take on this problem, which is to understand the problem modularly. In other words, how do you construct multiplayer auctions from single player auctions? And so it's going to focus on multi to single agent reductions and what we can learn about the structure of good mechanisms from the way that the multiplayer mechanisms interact with the single player mechanisms. This is chapter eight of a textbook manuscript that I'm currently working on. Any decade now, it should be ready. And chapter eight was something I've been working intensively on this summer, which is why it's very fresh in my mind. It's something I wanted to share with you, this sort of unified way to think about these kinds of questions.
00:01:13.494 - 00:01:42.254, Speaker A: Unfortunately, chapter eight is actually not quite ready yet, so it's coming soon on the webpage here, if you're looking for notes for later. Okay, so I want to start out by giving you some results that will be consequences of the theory I'm going to develop so you can see what we're working towards.
00:01:43.354 - 00:01:43.874, Speaker B: Okay.
00:01:43.914 - 00:02:41.214, Speaker A: And what I wanted the entire, most of this talk will be. And today and even tomorrow, we'll be trying to draw connections between the multidimensional, non linear setting of mechanism design, which is, I guess, not as well understood as the simpler single dimensional linear settings that the classical economic theory has described. And so in order to understand these more complex mechanisms, I'm actually going to try to understand them in the same terms as we understood the single dimensional linear agent case, which is fairly easy to understand. And so I'm going to be drawing those connections throughout the presentations. So I want you to compare these results to similar results, you know, from the single dimensional theory. Okay, so here's one result. Suppose you have multi dimensional agents.
00:02:41.214 - 00:03:33.154, Speaker A: In particular. You could be selling a car that you could paint either red or blue, and the agents might have a different value for different colors. You could paint it, okay? And so if you imagine that the values for the colors are drawn iid from each player's IID on the uniform square for their value for blue or red, then the following auction is optimal. Just run the second price auction with a reserve, and always sell the person who wins their favorite color car. Okay? And that should look a lot like. Wow, I misspelled Myerson's name. That should look a lot like the single dimensional theory, which you're familiar where the optimal auction for single dimensional linear agents with IID players with a nice distribution is the second price auction with reserve.
00:03:33.154 - 00:04:20.074, Speaker A: Here's another result for this time for nonlinear agents. If you're selling a single item to agents with values uniform, zero, one, and they have a common budget, so there's a maximum they can pay, and that's the same maximum for everybody. Okay, so it's a symmetric environment. Okay, then the optimal auction is actually also relatively simple. It's an all pay auction with a reserve price, meaning people who aren't willing to bid a certain amount aren't even considered. But there'll be what we'll call ironing at the top, meaning there's a, the high valued agents will all bid the same amount, and if there are more than one that bid that amount, you'll pick a random one to win. So they'll be basically ironed.
00:04:20.074 - 00:04:55.594, Speaker A: Okay, I put ironing at the top in parentheses, because when you actually implement this, you don't need to actually iron at the top. The agents will do it for you. Okay? You just run the all pay auction with a reserve. They're not going to pay more than their budget, so they'll all automatically iron themselves in the correct way. Okay. Um, I'm gonna. This theorem is actually Lafont and Robert, but I'm going to give you a proof of this theorem, which follows much more closely the below Roberts marginal revenue approach.
00:04:55.594 - 00:05:37.534, Speaker A: Okay, so these are some results for optimal mechanisms with multi dimensional and nonlinear preferences. I now want to tell you how, because we've viewed these similarly to the single dimensional settings, we know, we can automatically get approximation results that are related. Okay? So in the multi dimensional setting, you can automatically get these kinds of approximation results. If I just post a uniform price for these IID agents, then I'm going to guarantee an e over e minus one, which is 1.58, which is the same as one over 0.63 that Tim was talking about the other day. Approximation.
00:05:37.534 - 00:06:42.542, Speaker A: Okay? And this is via a correlation gap result of yan in the single dimensional setting. And it automatically extends to this multi dimensional setting because we're gonna have viewed it in the same, using the same working pieces as the single dimensional linear case. Okay? Similarly, a recent result with some co authors who, Saeed, is actually around in this area and will be probably spending some time here in this special semester, is that even if you have asymmetric distributions? So imagine here we have uniform zero, one, and they're all iid. But imagine everyone's uniform zero sum, upper bound, but the upper bounds are different for different players. So now we have an asymmetric setting. Okay? And so the optimal auction there, like this one, is going to be basically look like a, you know, highest virtual bid wins kind of a thing, the same as a single dimensional setting. But that auction's not so practical.
00:06:42.542 - 00:07:34.044, Speaker A: So you might wonder, can you get away with just posting a uniform price that's anonymous to everybody? How well does that do? And in fact, the same question was wondered for single dimensional linear agents, and it was proved in these papers. And that theorem automatically extends. Okay. An extension for this result with common budgets is that, well, if you have a lot of players, you don't even need a reserve. Okay. It's sort of extending the below Klemperer result to this setting because we viewed it in the marginal revenue framework. To prove this theorem, we can use that same viewpoint where there's a sort of marginal revenue version of the Bielo Klemperer theorem to show that the all pay auction with no reserve is a good approximation to the optimal one.
00:07:34.044 - 00:08:17.068, Speaker A: Okay, good. So this is sort of to motivate what we're doing. We're going to try to understand optimal auctions in the same terms in which we understood the single dimensional linear case. These much more complicated cases of multi dimensional players or nonlinear players. And because we did that, we'll get for free a lot of extension theorems where you'll see the single dimensional results will automatically extend to the more complex environment. Okay, so I'm going to be talking about multi to single agent reductions. I'm going to give you two reductions, and they're going to work in different cases.
00:08:17.068 - 00:09:17.564, Speaker A: Okay, the first and easier reduction, I'm going to call the ex anti reduction, and I'm going to reduce the multiplayer problem to an ex anti pricing problem for the individual agents. And what is that ex ante pricing problem? I'm going to look at each single agent and ask for any probability that I serve them. What is the best mechanism that serves them with that ex ante probability? If you solve this problem for every ex ante probability, then we'll be able to construct a mechanism from those single player mechanisms. Okay. And the multi agent composition mechanism will be the marginal revenue mechanism that you may be familiar with from below and Roberts. Okay, this approach does not always work. It will work if and only if the single agent problem satisfy a property, which I'll call revenue linearity and we'll discuss in more detail later.
00:09:17.564 - 00:10:13.474, Speaker A: Okay. But in particular, there are two common cases that you might think about that satisfy this revenue linearity assumption. One is the standard single dimensional linear utility preferences that we're used to talking about in auction theory from Myerson's theory. And another case is a large class of multidimensional preferences, which I'll talk in much more detail about tomorrow. Okay? It includes the uniform zero one squared example of the red blue car that I just was talking about. That theorem on the previous slide is just an instantiation of this reduction and its optimality. The other reduction is, I'll call the interim reduction, and it's based on interim allocation rules of the players and in fact, solving an optimization problem that has the interim allocation rule constrained everywhere.
00:10:13.474 - 00:10:50.724, Speaker A: So the single agent problem is a constraint on the entire allocation rule, not just the ex ante probability of service. And the multi agent composition mechanism is going to look like a stochastic weighted optimization. And I don't want to go into more detail about what this is now. We'll talk in much more detail later. One point is this is a much more complicated procedure. This is more complicated, and also this is more complicated. There are no assumptions you make on the preferences here to do this.
00:10:50.724 - 00:11:52.222, Speaker A: So the multidimensional settings that you can't solve because they're not revenue linear, you can solve here with this approach, and you can also solve nonlinear utility preferences, either single or multidimensional. Doesn't matter. Okay. Examples of nonlinear preferences are budgets like I had in the previous slide, or a risk aversion. Okay? And the example theorem from their previous slide about the optimal auction for budgets is instantiating this framework in a symmetric environment where actually there's some simplification you can do to make this not so complex. Okay, so what's my agenda? My goal really is to have you understand what these reductions look like, have some intuition for them, and understand what's fundamentally different about the settings where you can use one or the other. Okay? That's my goal.
00:11:52.222 - 00:12:32.134, Speaker A: Okay. So I'm going to start with some examples of optimal single agent mechanisms. So you can see already the single agent mechanisms for the two cases. The revenue linear case and the non revenue linear case are behaving very differently. Okay. And then once we see them behaving very differently, we will then, you know, construct the ex anti reduction and prove its correctness, and then we'll construct the interim reduction and prove its correctness. Okay? Again, the things I want you to think about here, this is a unified framework for thinking about mechanism design.
00:12:32.134 - 00:13:23.932, Speaker A: And I really want to highlight the differences between the revenue linear case where basically Myerson Bulow Roberts theorem extends to the non revenue linear case where it doesn't have to use more sophisticated methods. Okay, so I'm going to now work through some examples of some single agent mechanisms. Please feel free to interrupt if you have questions and want to clarify what these examples are. Okay, so I'm going to start with the public budget preference. So here's just a simple public budget preferences, which is the same example I had in the first slide. So I have an agent with a private value t for receiving some good. I can give them the good with some probability x and charge them some payment p.
00:13:23.932 - 00:14:13.792, Speaker A: Okay, they have a public budget, and so their utility function is this. They get utility t times x minus p. That's your usual quasi linear utility, except that requires that the payment be at most the budget. If the payment is bigger than the budget, they have negative infinity utility. This is a somewhat standard model for thinking about budgets. Okay, I'm going to use as a running example for everything I show you in this talk will be for t is uniform zero one, and the budget is a quarter, and every picture is a real picture, meaning it actually corresponds to when I show you an optimal auction. It's that case, the uniform zero one budget a quarter.
00:14:13.792 - 00:14:53.450, Speaker A: Okay. Whereas the theorems will actually be more general than this case. But I'm not going to show you the more general picture, even though it's going to be just an obvious extrapolation. Yeah, I know this minus infinity is completely standard, but would it be good enough really to do minus the loss? So if you're seeking. I have no idea. I have no idea. Okay, so I want to start by talking about some ex ante pricing mechanisms.
00:14:53.450 - 00:15:43.054, Speaker A: Meaning second, we're going to want to optimize given some constraint on the ex ante probability I serve a player. What is the revenue optimal mechanism for that constraint? So, let's just look at a couple mechanisms that satisfy some constraint. Okay, so I'm going to start with an ex anti constraint of one, two, so, meaning come up with a mechanism which serves the agent with ex anti probability of half. The mechanism may randomize and the type of the player is random, and so it's going to be serving with probably a half in both the randomization of the mechanism and the type of the player. Okay, so here is one mechanism. I could offer the player a three quarter lottery, meaning x is three quarters, and charge them if they want to buy that lottery, one quarter. Remember, they have a budget of a quarter, so that's a binding budget constraint for them.
00:15:43.054 - 00:16:33.094, Speaker A: Okay, and if they don't want that, they can have nothing. So what does this do? Well, you can solve for what is the indifferent type, the type that doesn't care if they buy this or not buy this by saying, okay, what type has t times x minus p, which is three quarters equal to zero, t times one four times. And it's exactly the type of one three. So the allocation rule looks like this. The types with type below one three don't buy. The types above one three buy, but they only buy with probably three quarters because it's a three quarter lottery. And as usual, if you're used to thinking about single dimensional auction theory, the payment in an auction, if I write the allocation rule in type space like this, is just the area above the curve.
00:16:33.094 - 00:17:12.730, Speaker A: So the shaded area that I've denoted b is actually the payment that the high type makes, which is equal to the budget, which is a binding budget constraint. Here is another example. I want to tell you where this example comes from. Let's suppose I ran a two player, all pay auction for players of this type and asked what the equilibrium was. That equilibrium produces an allocation rule. It happens to be this. Okay, what's going on here? I started with highest bid wins, but if I disfront highest bid wins, the top guys are going to over spend their budget.
00:17:12.730 - 00:17:46.010, Speaker A: So they want to lower, they want to pool themselves with lower types. But if the top players start pooling themselves, then some of the lower players are going to also want to pool, because then they win with some higher probability, because they get a chance at winning when they're pooled with the high types two. So the high types drop down, the low types and low types drop up. And you get the lowest type. That's indifferent between dropping up is this guy, everyone else is as before, and these guys are all pooled. Okay. And you can calculate out the area, this b, it's exactly a quarter as before.
00:17:46.010 - 00:18:27.142, Speaker A: And you could calculate out the probability of the ex ante probability. And it's also one two, as I desired. Okay, these are two mechanisms. Good. Let's think about this ex anti pricing question. I want to come up with the single player mechanism that has the highest revenue but serves with ex ante probability, say at most one half. What is that? Give you a hint.
00:18:27.142 - 00:18:28.434, Speaker A: It's one of these. Which one?
00:18:34.074 - 00:18:35.174, Speaker B: Biggest area.
00:18:37.874 - 00:18:59.046, Speaker A: The biggest area. So the b's are both the same for them. Right. So the question. Right, the thing is that everyone here who wins pays b. And here, some of the people pay some lower amount because the guy with the type here pays the area above the curve for that type. So here we sell with probably a quarter and everyone pays b.
00:18:59.046 - 00:19:33.154, Speaker A: Here we sell with probably, sorry, one two, and everyone pays b. Here we sell with probably one, two, but some people don't pay b. Does that make it easier? Which one's bigger? Okay. And in fact, a is optimal. Okay. And in fact, the theorem you can show is that a mechanism of this form is optimal. And all I want you to get from this is the following, is that the probability of the lottery, which was three, four here, changes with your ex anti probability.
00:19:33.154 - 00:20:14.804, Speaker A: Okay? So you're taking this curve and, you know, squanching it down as you change the probabilities. Okay? Any, any questions on this? We'll review the example further once you make it more complicated, but I'm happy to, by the way, I also did not tell you what happens when the budget's not binding. When the budget's not binding, it's obvious what happens. You just post a price. Okay, so this is the budget binding case here. And the budget's obviously not binding when this equation can't be satisfied by anything.
00:20:16.624 - 00:20:19.244, Speaker B: So the mechanism of the lift was also for two agents?
00:20:19.754 - 00:20:39.538, Speaker A: No, this is a single player question. I just. This came from somewhere. I looked at what the interim allocation rule was for a two player mechanism, and this is what happens. This doesn't come from any two player mechanism that I ever thought of. It just happens to be a single player mechanism. You could post this lottery.
00:20:39.538 - 00:21:10.670, Speaker A: What happens then? Okay, let's move on to unit demand preferences. Okay, so it should not say single dimensional there. Unit demand preference is multi dimensional. How am I going to notate this? Sorry, this notation is a little bit clunky. An allocation is going to be a probability of getting item alternative one or alternative two. Okay? It better be that your unit demands. You only want one thing.
00:21:10.670 - 00:21:15.804, Speaker A: So it better be that the total number of things you get is the most one. Okay, and I'll have a payment p.
00:21:17.784 - 00:21:23.404, Speaker B: Sorry, Jason, I don't understand. X one is the probability to get the first. Good.
00:21:24.664 - 00:21:30.524, Speaker A: X one is the probability to get the first item. X two is the probability of the second item.
00:21:30.904 - 00:21:37.896, Speaker B: If x one and x two are both 0.9, I might get both items, but I might not get any items.
00:21:38.000 - 00:21:52.758, Speaker A: You are thinking about these as independent random variables. They are not. These are the probability of getting. It's like the simplex. There are two outcomes. You get one, two or zero. And it's a simplex, so it sums to at most one okay.
00:21:52.758 - 00:22:26.668, Speaker A: Your private value has two coordinates. Your utility is just the sum of your value for the things you get. Your standard linear utility definition. Okay, my running example is t is going to be uniform zero, one squared. Okay, I want to do the exact same thing we did before. I want to ask you, what are some mechanisms that serve with ex ante probability? Q hat for, say, q hat equals one half. Okay, here's something you could do.
00:22:26.668 - 00:22:37.810, Speaker A: Only ever sell item one. If I want to sell with probability one two, and I only want to sell item one, I better post the price of a half, the player's uniform zero one. Is there something else you could do?
00:22:37.882 - 00:22:40.214, Speaker B: Q hat here corresponds to x one plus x two.
00:22:41.234 - 00:23:09.594, Speaker A: Q hat corresponds no to the probability. Yeah, so the probability they buy anything in expectation over the types. And both could be random, the types and also the x's, either the first one or the second. Yes, that's correct. And in fact, later I'll just say x to denote the sum of the two. So I need x less than one. Okay, so that's something I could do.
00:23:09.594 - 00:23:33.534, Speaker A: I could also sell them the lottery. And this would actually be a price one half. So at price one two, you can either get, you get 50 50 of the first item or the second item. Okay, but, so if you win, you win with probability one though, right?
00:23:34.154 - 00:23:36.414, Speaker B: So what's the heading on this?
00:23:37.154 - 00:23:39.734, Speaker A: So does this uniform lottery over items?
00:23:40.354 - 00:23:44.934, Speaker B: Does the right hand example have two hat equals a half or two hat equals one.
00:23:46.074 - 00:23:48.214, Speaker A: They both have two hat equals one half.
00:23:49.514 - 00:23:52.654, Speaker B: But right now your circle probably, except.
00:23:52.694 - 00:23:55.794, Speaker A: That you only have a high type with probably one half.
00:23:56.774 - 00:23:58.754, Speaker B: You said probably one conditional.
00:23:59.414 - 00:24:32.094, Speaker A: Exactly. In both of these, you're served with probably one condition on being served, but only some types will be served. And that type being served are the areas given by their shaded regions. Here is another allocation rule. It's a uniform pricing of a price of square root one half. Why square root one half? Well, I want this area to be one half. I want this area to be one two, which is the same as this area being a half, and that area is one two if my price is square root one half.
00:24:33.354 - 00:24:46.594, Speaker B: Okay, so this is for unit demand. So Q had the exact probability of service. Kind of makes sense. If it was additive, how would you define the exante problem?
00:24:47.974 - 00:25:27.364, Speaker A: I would have to define a different kind of ex ante problem for additive if I had a feasibility constraint across the multiple agents that had the externality for the different items. So I'm going to be focusing today on settings where the externality between players is a single dimensional externality. If you have a multidimensional externality between players, which is what Kosas I believe is asking about, then you'll need to define a different ex ante pricing problem. I'm not going to talk about that today. The different ex ante pricing problem is actually in said Alai's 2011 paper. Okay, so, good. I have three mechanisms here.
00:25:27.364 - 00:25:30.144, Speaker A: I'll give you a hint. One of them is optimal. Which one is it?
00:25:36.784 - 00:25:38.760, Speaker B: The one on the right.
00:25:38.952 - 00:25:41.804, Speaker A: Yeah. So wait, I call them all a.
00:25:55.424 - 00:25:57.444, Speaker B: You can spot somebody with deadline.
00:25:59.704 - 00:26:43.154, Speaker A: Okay, so C is right. And if you remember the first slide, you should recognize c being the right answer. And in general, what's the right answer? It's going to be the uniform price that is calculated here. What is this max? This max is because actually, when you have too high a probability, you actually don't want to sell without total probabilities. You're allowed to not sell with the total probability in the next pricing problem. Okay, so I want to post the price that corresponds to the price that has this area exactly equal to Q hat, but I don't want to go below square root one three, which is what this constraint is saying.
00:26:45.254 - 00:26:48.074, Speaker B: How do you tell from looking at the picture which is optimal?
00:26:49.654 - 00:27:10.814, Speaker A: You can't. In fact. No, no. So I want to remind you, my agenda. My agenda is give you examples of what optimal mechanisms look like in the single agent setting. I'm then going to talk about the reduction. We're focusing on how do we build optimal mechanisms from the single agent mechanisms? And knowing what the single agent mechanisms look like is going to help us do that.
00:27:10.814 - 00:27:20.578, Speaker A: Tomorrow I'm going to go and derive how to show that these are optimal. Ok, good. Any other questions?
00:27:20.706 - 00:27:34.674, Speaker B: Yeah, maybe it's still a question, but could you give some motivation as to why we would want. When are we given like an exogenous probability that we want to select?
00:27:36.134 - 00:28:09.944, Speaker A: No, I won't, actually. And the reason why I won't is because I'm using it as a tool to build the optimal mechanism. Okay. So I don't actually care about that question in itself. Okay. I care about that question as a building block in constructing optimal multiplayer mechanisms. One of the reasons why I think this viewpoint as a reduction is so important is that if you look at some of the literature where people are studying single player problems, they're not necessarily studying these ones, and they should be, because these are the ones from which you can construct multiplayer mechanisms.
00:28:09.944 - 00:29:00.984, Speaker A: Okay, so that completes my survey by example of ex ante pricings. I now want to talk about the more complicated single player problem, which the second kind of reduction is going to use, which is interim pricings. So to do that, I'm going to have to introduce some notation for allocation rules, etcetera. Okay, so I'm going to define the allocation rule for types to be x. It's just the probability that the type is served. And answering a previous question of Costas, that's going to be in the unit demand case, it's the sum of the probabilities. You get either item, it's to probably get anything.
00:29:00.984 - 00:30:21.754, Speaker A: Okay, so if you have a mechanism in mind, and we will usually have a mechanism in mind, then I can measure the relative strength of two different types of the players from the distribution by asking which one has a higher service probability in that mechanism. Okay? And I'm going to call the quantile of an agent q to be the measure of types with higher allocation probability in the mechanism that we were thinking about. Okay, so given a mechanism, I look at all the allocation probabilities. What's the probability that a random type has a higher allocation probability than this type? That's the quantile of the type. Okay, and the important definition, the important property of quantiles, is that for any type from the distribution, quantiles always uniform zero one, because any ordering by strength will always give you an ordering zero one when you look at their relative strength. So now I'm going to take my allocation rule in type space and define an allocation rule in quantile space, which if you add a mapping types quantiles, just maps them. Okay? But let's actually think about what that is.
00:30:21.754 - 00:31:15.220, Speaker A: So the allocation rule in quantile space is if you take the allocation probabilities of the player of the types and you sort them in decreasing probability with widths equal to sort of the probability they show up, then you get this allocation rule in quantile space for discrete type spaces. It's very intuitive. For discrete type spaces, make a rectangle with width the probability the type shows up, and height the probability that type is served. You take those rectangles and you sort them in decreasing order. And the profile, the top profile will be an allocation rule. Okay, this is the allocation rule in general for a mechanism in quantile space. Okay, let's do some examples.
00:31:15.220 - 00:31:50.374, Speaker A: So, public budgets, we saw this allocation rule before in typespace types were just uniform zero, one. So what is the allocation rule in quantile space? Well, you know this measure, one half of types all get served with the highest probability, which is three quarters. So there's that big rectangle, and then these other infinitesimally agents get served with decreasing probability. And so they're just here. Okay. And actually for uniform zero one, it's just, you just flip it. Okay.
00:31:50.374 - 00:32:34.274, Speaker A: F is the density function. Okay, so what about this unit demand example? What's the allocation rule here? Well, these types receive a good with certainty. What measure are there? There are a half of them. These types receive the type not at all. So if I take the allocation rule and sort it and put it in probability space, then a half measure get it with certainty, a half measure get nothing. This is the allocation rule in quantile space. Okay, I now am ready to define this interim pricing problem.
00:32:34.274 - 00:33:19.494, Speaker A: The interim pricing problem assumes that I'm given an allocation constraint y, which is the same form as an allocation rule in quantile space. Okay, I'm going to use hats, by the way, for constraints. Every time I have a constraint, I'll put a hat on it. So y is just a monotone decreasing function from zero one to zero one. Why hat? And what I would like you to do is come up with a stationary transformation from quantiles to quantiles. So from uniform, from zero one to zero one that is stationary. So if I take a random quantile from uniform zero one, and I put it in my transformation, I get a random variable that's also uniform zero one.
00:33:22.394 - 00:33:29.938, Speaker B: Okay, so what is stationary? I don't know what stationary means in this context. Good.
00:33:30.066 - 00:33:55.994, Speaker A: So I'm going to put into sigma a quantile q. That quantile q is drawn from the uniform distribution. I would like the expected value of sigma Q if I don't tell you Q to also be from the uniform distribution. That's what I mean by stationary. It takes a distribution as input. And if that distribution is uniform, gives you the same distribution out.
00:33:59.054 - 00:34:01.986, Speaker B: Yeah. You want it only for the uniform distribution.
00:34:02.050 - 00:34:39.934, Speaker A: Only for the uniform distribution. Okay. I want you to find one of these, one of these sigmas. Okay. And then I want you to find me a single agent mechanism with allocation rule that is upper bounded by the expected allocation constraint when I remap things by sigma. Okay. Any sigma.
00:34:39.934 - 00:34:55.924, Speaker A: No, you're finding both these things. So why wouldn't I take Sigma as the identity? Because if you take Sigma's identity, you won't be able to come up with as good mechanisms as if you don't take Sigma as the identity. Okay. That would constrain you artificially.
00:34:57.024 - 00:35:00.244, Speaker B: Is it a permutation? I'm trying to understand what's going on here.
00:35:02.224 - 00:35:41.424, Speaker A: I'll tell you one of the kinds of things you're going to want to do with sigma. You're going to want to take an interval between a and b, and you're going to want to just uniformly redraw it. So if I condition on a type being in some interval, quantile being in ab, and I ignore it, and I redraw a new type from that interval, what's the new distribution is still uniform. Zero, one. Okay, that's how we're going to use sigma in constructions. I want to give you another way. If you find this definition confusing, I'm happy for you to take the theorem I'm going to prove as the definition instead.
00:35:41.424 - 00:36:46.804, Speaker A: So let's define the cumulative allocation rule as just its integral. Okay? So the cumulative allocation rule for q hat is integrating the allocation rule from zero to q hat. In other words, let's think about this. Q hat is a constraint on the quantile, right? So I take all the players with quantile stronger than q hat and ask what's their expected probability of being served? Okay, so the allocation rule y is feasible for allocation constraint y hat if and only if the cumulative allocation rules satisfy the point y's domination condition. This is like, so this is like, basically asks for majorization. Basically, if you want to think of it that way. Okay, it's like a majorization property.
00:36:46.804 - 00:36:51.880, Speaker A: For those of you who know what that means, the definition of feasible is.
00:36:51.912 - 00:36:54.684, Speaker B: There exists sigma such that the second point holds.
00:36:56.504 - 00:38:13.584, Speaker A: Yes. So you'll say y is feasible if there exists sigma such that this is true. I mean, the theorem is that these are the same things. So if you found that definition confusing, you can just take this as the definition. Okay? In other words, it's a constraint on every prefix of strongest types of the ex ante probability you serve typing that prefix. Okay, I want to actually prove this theorem by showing you how to construct the sigma that you want for this theorem, okay? And the main idea is that if I take an allocation rule y and I use some sigma that resamples on some interval av by ignoring the actual quantile that was in absolute and drawing uniformly from ab instead. Okay, that'll replace the allocation constraint y hat, little y hat with its expectation, and that replaces the cumulative allocation rule with a line segment connecting the two points.
00:38:13.584 - 00:39:13.934, Speaker A: Okay, so here are pictures. Okay, let's suppose my allocation constraint y hat is the straight line, the 45 degree line, and let's suppose that allocation rule y I want to implement is this stair function, the black stair function, and this violates Richard's property that it's always point wise less than it. But we can actually implement this stair function from this allocation constraint y using such a sigma. Okay, how are we going to do it? The first thing I'm going to do is throw out probability to make the ex anti allocation probabilities the same. Notice that capital y of one is just the total probability the guy served. So this point and this point, this is the ex ante probability of y. Hat this is the ex ante probability of y.
00:39:13.934 - 00:40:01.324, Speaker A: How can I make them the same? Well, if your type is, if you're in the weakest types here, I'll just set your y hat to zero. Okay, that would take this curve, which is still increasing, and make it flat. Okay, so that's how I go from the dotted line to this one, truncated here. Then the next thing I want to do is use the fact that resampling on interval ab is replacing a line segment in the cubic allocation rule. So I want to take this curve, which goes like that and make it look like this curve here. I can just take that interval and resample it. Okay, so I resample between zero and this somewhere here.
00:40:01.324 - 00:40:18.634, Speaker A: Okay. And then I get this dotted curve, okay. And then I can resample on this interval to take that thing and flatten it to this line. Okay, that's the construction.
00:40:21.534 - 00:40:26.754, Speaker B: Can you motivate this a little bit? Like where is this allocation constraint coming from again?
00:40:27.254 - 00:40:43.654, Speaker A: Again, no, I don't want to motivate it. The same answer as before. I don't care about these problems. These problems are coming from a multi agent reduction. I'm going to have to solve them. No, but it's good to remember that. So thanks for asking.
00:40:43.654 - 00:41:31.514, Speaker A: Just say it's going to be a separation oracle for somebody. Okay? So I want to now look at example interim pricings. And my example is going to be for the allocation constraint y hat. This is the -45 degree line is the one we were talking about in the previous slide. Okay? So here I've shown the constraint with a dotted line, and I've shown what is the optimal allocation rule for the public budget example previously, given that allocation constraint. Okay, and what does it do? It irons the top, it reserves prices at the bottom, and in some middle interval it's greedy. It's the highest type wins, or smallest quantile, the strongest quantile wins.
00:41:31.514 - 00:42:30.028, Speaker A: Okay, and that corresponds back in type space to this allocation rule. Okay, good. What about the unit demand case? Again, taking the exact same unit demand example, the allocation constraint y hat is the -45 degree line. The optimal allocation has this allocation rule here. Just the reserve price, greedy, allocating by strongest quantile until the reserve price and the mechanism in two dimensional space looks like this. The reserve price, as I said before, is square root one three, and will allocate with increasing probability to the types as they get higher highest coordinate. Okay, so these types are the ones where they prefer item one.
00:42:30.028 - 00:43:00.434, Speaker A: These are the types that prefer item two. And we're allocating probability in terms of their highest coordinate. Okay, again, for this part of the talk, I don't need you to understand how to get this from the constraint or anything. I just want you to understand what these things look like. Okay. I want to point out something is quite different about these two scenarios, which I haven't written here in this slide. I'll just tell it to you.
00:43:00.434 - 00:43:53.234, Speaker A: So I have written it here. So this reserve is the same reserve that you would get for every single allocation constraint, y hat. For every single allocation constraint y hat. Y would look exactly like y hat, down to the quantile two thirds, which corresponds to reserve of square root one three in price base. That is not the same. For the public budget example, these two thresholds, which one of them is where you iron and one of them is where you put the reserve price, these will be different for every allocation rule you choose. Okay.
00:43:53.234 - 00:44:30.224, Speaker A: And the thing that's important about that is in the unit demand case, there's something that's sort of unchanging about your authorization problem. No matter what the constraint is, the problem is unchanging. Whereas for the public budget case, actually things are moving. You change your allocation rule, the things that were relevant before are no longer relevant. You have to think about other things. Yeah. Changing your allocation rule versus changing why? Hat? I'm sort of thinking of, y hat is this sort of exogenous, unmotivated thing that's coming from space.
00:44:30.224 - 00:44:50.122, Speaker A: Yeah. Y is the thing we actually want to implement. Right? Yeah. So can you clarify a little bit? Which. Yeah, so I'm thinking about changing y hat and asking how the optimal mechanism changes. And these things I need to know. So when I gave you the y hat of one minus q, okay.
00:44:50.122 - 00:45:20.884, Speaker A: Meaning this one, I got these particular iron, the top, and reserve price the bottom, with these particular parameters. Those parameters depend on y hat. If I give you a different y hat, you get the exact same structural picture. Iron the top, reserve price the bottom. But the reserve price will be different, and the ironing region will be different. Okay? That does not happen here. For every single y hat, you get the exact same reserve price.
00:45:20.884 - 00:46:31.398, Speaker A: Okay, one thing we can point out from this previous slide is what was the optimal ex ante mechanisms for this problem? They were just posting a uniform price, right? What is this mechanism? It actually looks just like a convex combination of posting uniform price for different probabilities of posting the price. So the interim optimal mechanism is going to be a combination of ex anteople mechanisms in the unit demand example, that's not true in the public budget example. Okay? Also the ordering on types. So we said, we defined, we said that for every mechanism, you could map types to quantiles by looking at the probability that the type wins in that mechanism. So for the unit demand example, for every single allocation constraint, you give it, the same ordering is fine. The orderings are consistent. There's one ordering on type that's always the ordering.
00:46:31.398 - 00:47:25.824, Speaker A: And in fact, that ordering is kind of obvious to see. You want to order them by their highest coordinate because that tells you when they're going to win or not, because they're all basically competing in this auction for who's got the highest favorite item. Okay? So I'm calling that second property orderability, when every single agent interim mechanism has the same order on types. Okay, I'm going to define some notation. So if I give you a constraint y hat and I want you to optimize revenue subject interim constraint y hat, I'm going to denote that by rev of y hat as the optimal revenue I get for that constraint. Okay? Then this revenue linearity property, more formally, is just the following. If I give you two allocation constraints, the sum to be a third constraint, then the revenue is just the sum.
00:47:25.824 - 00:47:58.584, Speaker A: The optimal revenues for those constraints is just their sum. So, natural linearity property defined on this revenue operator on the allocation constraints. Okay? And this is not a coincidence for the uniform case. It's actually a fact. For every revenue linear case, revenue linearity implies orderability. So you'll always get this convenient ordering property if you have revenue linearity.
00:48:01.884 - 00:48:03.144, Speaker B: And the converse.
00:48:03.884 - 00:48:37.604, Speaker A: No, and the converse. Let's see. Let me not say anything right now. Yeah. Think of it as taking a commas combination instead of a direct sum like I've written here. So write y hat as the combination of two other allocation rules. And then my first one will be the coefficient of the first one times the first one, and this is the coefficient of the second one times the second one.
00:48:37.604 - 00:48:41.364, Speaker A: Okay? So think of it as convex combination. Yeah.
00:48:42.904 - 00:48:43.776, Speaker B: Constraints.
00:48:43.840 - 00:48:44.484, Speaker A: Yes.
00:48:52.024 - 00:48:52.392, Speaker B: Okay.
00:48:52.408 - 00:49:41.384, Speaker A: I now want to give you the ex on t reduction. Okay. In particular, I'm going to show you that revenue linearity is going to imply that the Myerson Buellerobert's mechanism of marginal revenue maximization is just going to extend naturally to give you the optimal mechanism for these settings. Ok, so to define marginal revenue, we've, for every exonte constraint q hat, we've solved the ex ante pricing problem. Let's define r of q hat to be the revenue for every q hat. And then this will define a revenue curve, which is going to be a nice, actually concave function. I can take its derivative and let that derivative be the marginal revenue, and call the derivative of the marginal revenue.
00:49:41.384 - 00:50:20.514, Speaker A: And then the theorem that you will recognize from the single dimensional theory is the following, that the optimal revenue for a constraint y hat is just equal to its marginal revenue, meaning the revenue is equal to the expectation of. If I were to view sort of marginal revenue as a virtual value, I get sort of the surplus of marginal revenue. This theorem has the assumption of revenue linearity. I should have written it here.
00:50:20.874 - 00:50:22.294, Speaker B: Y hat is interim.
00:50:22.914 - 00:50:52.554, Speaker A: Y hats are always interim. Yes, yes. Y and y hats are interim allocation rules. Okay, so here's the proof. So another way to reinterpret what this revenue from the ex auntie pricing is. It's actually the revenue of the interim mechanism with a constraint that steps from one to zero at q hat. So if I had y hat equal to this, I would get optimal revenue equal to r of q hat.
00:50:52.554 - 00:51:35.890, Speaker A: And then any allocation constraint y hat can be viewed as a convex combination of reverse step functions. Coefficients are the negative derivative of the allocation rule. Okay. So then, using revenue linearity, I can write the expected revenue as well. This is just the combination of a whole bunch of other step mechanisms. What is its revenue? Therefore, its revenue is the probability that I run the q hat mechanism times the revenue of the q hat mechanism, which is this. Okay.
00:51:35.890 - 00:52:23.404, Speaker A: And that expectation you can view as an integral, and you can integrate it by parts to switch where the derivative is to get the marginal revenue definition. This is exactly the analysis you would have done if you were doing the single dimensional case. Yeah. Optimal revenue. What are you optimizing over? Great question. Let's remember that. So, the interim pricing problem for every allocation constraint y, I want to find a mechanism, every allocation constraint y hat, I want to find a mechanism y that is constrained by that mechanism via some resampling transformation sigma.
00:52:23.404 - 00:52:40.404, Speaker A: Okay, over all such mechanisms that satisfy this constraint. That's your question. And I gave you some examples of that, where. Here's what I did when I gave you allocation constraint y. Hat. You came up with this y when I gave you this allocation. Y hat.
00:52:40.404 - 00:52:43.464, Speaker A: The same allocation at y hat, but I had a public budget. You gave me this other y.
00:52:45.124 - 00:52:48.024, Speaker B: Sorry. So there are prices also.
00:52:50.284 - 00:53:12.688, Speaker A: Yeah. So I've just written this in terms of the allocation rule, but there are prices that make it all incentive compatible because I. This is over single agent mechanisms that are antenna compatible, but those I don't have to talk about here. I'm just talking about the allocation control. And you want to maximize the revenue that comes from that. That's implicit in that optimization question, just.
00:53:12.696 - 00:53:22.724, Speaker B: To make sure I understand. So you are optimizing both over Sigma and then for a fixed sigma, you still have to optimize over the mechanism. It's not that for a fixed sigma there's.
00:53:26.604 - 00:53:44.344, Speaker A: That is correct. But I would view it slightly differently as when you optimize y, there will be an implicit sigma that comes out of it. So, in fact, I would just write this constraint as your constraint and ignore sigma and just optimize with this constraint. Okay. And you'll get sigma for free.
00:53:45.764 - 00:53:48.984, Speaker B: So for every sigma there is a mechanism.
00:53:53.624 - 00:53:54.444, Speaker A: Yeah.
00:53:55.424 - 00:53:59.284, Speaker B: So you can reset full types in whatever way. Yeah.
00:54:01.384 - 00:54:43.070, Speaker A: That's not so exciting because for every sigma, the allocation rules monotone. For every monotone allocation construction mechanism. Okay, so that's the proof that optimal revenue is always equal to marginal revenue. Yeah. So this convex combination of allocation rules, is that coming out in the expectation over the quantiles? Is that what's happening here? Yes. So the point is I have a monotone decreasing function. Okay.
00:54:43.070 - 00:55:12.374, Speaker A: I can write every monotone decreasing function as a convex combination of functions that step down where the probability on this is the negative derivative of that function at this point. So this first part of the equation is just rewriting the revenue linearity equation where the terms in it are the, the allocation rule weighted by the probability that I have that allocation rule in there.
00:55:15.874 - 00:55:19.290, Speaker B: So the analysis of previous slide. This is for single dimensional setting.
00:55:19.402 - 00:55:30.254, Speaker A: No, this is for any setting that's revenue linear. I should have written that here. So for revenue linear settings, this holds. The only assumption I used was revenue linearity. Here.
00:55:38.414 - 00:55:43.622, Speaker B: The allocation is equal potential for, given that's the preferences.
00:55:43.798 - 00:55:48.874, Speaker A: So I'm keeping track of the allocation as a single dimensional quantity here.
00:55:51.054 - 00:56:06.178, Speaker B: So I guess I'm going. So your previous claim that the allocation is monotone, when you look at it in the quantum space, there's a mapping from the multidimensional preferences to this quantile space. If you reshuffle that in whatever way.
00:56:06.346 - 00:56:28.854, Speaker A: You'Re right, you don't get it at IC, but I'm mapping quantiles to quantiles in my construction, not types to quantiles. But you're correct that when you solve this problem, you implicitly have to figure out the mapping from types to quantiles. Because any mechanism will map types to quantiles, as I defined in the previous slide there, induces a mapping. So you must have figured that out.
00:56:29.794 - 00:56:40.586, Speaker B: Okay, so your problem here is, I give you this y hat in quantile space, you have to figure out the mappings.
00:56:40.770 - 00:56:58.962, Speaker A: Figure out, look, so every mechanism induces an allocation rule, right? So over all mechanisms, find one that induces a rule that satisfies. Let's forget this, just this property. Yeah, yeah.
00:56:59.018 - 00:57:03.614, Speaker B: So there's the implicit assumption that I always get my most preferred object. If I get one.
00:57:06.794 - 00:57:55.378, Speaker A: I have an IC assumption, which means this mechanism basically looks to you by the, via the taxation principle, like a menu. You always choose your favorite outcome, okay? That might not be your favorite item if it's priced higher than your other items. In some mechanism in the unit demand example I was talking about, it will always turn out to be that way. But you only notice that once you solve the single player problem completely, which I haven't done yet, I'm going to do tomorrow. So that's a detail of the single player problem, which I don't want to talk about today. We'll talk about that in great depth tomorrow, you know, items or whatever, and set up compatibility constraints. Okay, good.
00:57:55.378 - 00:58:27.588, Speaker A: So let's now say what is the optimal multiagent mechanism under the revenue linearity property? And you can define the marginal revenue mechanism for orderable agents. And remember, every revenue linear agent is an orderable agent because revenue linearity implies orderability. So step one is you map agent types to quantiles via the ordering. That's, that's implicit in the single agent problems. Okay, so this is a type profile. So it's all the types of all the players. And you get a quantile profile by this mapping.
00:58:27.588 - 00:59:20.434, Speaker A: Then I'm going to calculate the marginal revenues of all of the agents at the quantiles I get from this mapping. Okay? And then I'm going to serve the agents to maximize the total surplus of marginal revenue. I find the XI's that are feasible and maximize the sum for a single agent. I just choose the guy with the highest positive marginal revenue. And finally, to find the outcome and payments for each player, I'm going to look at how much they could increase their quantile, meaning go to lower types and still be served to find a critical quantile, which is the quantile at which they couldn't increase it anymore. Okay. That critical quantile has a mechanism that's defined by solving the ex ante problem for that quantile.
00:59:20.434 - 00:59:47.374, Speaker A: That player sees the mechanism. That's the ex ante mechanism for that quantile. So now to answer the question of why do we care about these mechanisms? Those actually appear in the construction here. You're going to then use that ex ante mechanism. And notice that this player has higher. This player will always actually be served by this mechanism.
00:59:48.154 - 00:59:59.334, Speaker B: Jason, is the critical quantile the one in which your probability falls all the way to zero or it falls at all lower than what your current probability is? I'm not sure if it's critical.
00:59:59.774 - 01:00:28.874, Speaker A: That's a great question. So. And because implicit in that question is that these players might be served with probabilities, but actually, if once you've done this, x is going to be zero one. Okay? And that's going to come out. So, in fact, a property we had in a single dimensional setting, which was the allocation who wins and who loses, it's deterministic, is maintained in this setting. It will always be zero or one. Okay.
01:00:28.874 - 01:01:01.814, Speaker A: Okay. So the theorem is this mechanism is optimal. How do you prove this? Well, we point wise optimized marginal revenue. And marginal revenue is equal to optimal revenue, always, by the previous theorem. So we have to have optimized revenue. Now, is it incentive compatible? Well, the revenue curves are concave, so the marginal revenue curves are monotone. So these critical quantiles I needed here exists, and this is IC, which is the standard proof that you approved this mechanism if you were Roger Myerson.
01:01:01.814 - 01:01:36.052, Speaker A: Okay. Okay. So I want to return to my example, which was revenue linear, which is the uniform zero one squared case. So the red blue car types iid uniform zero one, and reinterpret what this marginal revenue mechanism is. And we'll see. We get the exact same thing I said I would get at the very beginning. Okay? So again, the uniform zero one agent is revenue linear.
01:01:36.052 - 01:02:17.532, Speaker A: And the revenue curve r of q comes from posting a price, a square root one minus q hat. Okay, so it looks like this, okay, you can plot out what the revenue you get from this is if you post this price and you're selling with probability q hat, your revenue is q hat times the price you get. So q hat times square root one minus q hat, that's the revenue curve, which has this form. And you can see it's optimized at q hat. Equal two thirds. Okay, how do we map types to quantiles? Well, by strength. And remember, the ex ante mechanisms are always sort of just posting higher and lower uniform prices.
01:02:17.532 - 01:02:58.654, Speaker A: So the stronger players are the ones that have a higher value for their favorite item. Okay, and so what is that? So, given your type is t red t blue, then your quantile is one minus the max of t red t blue squared, which is how you can convert. If your type was here and tmax was here, you convert that back into probability space by asking, how many people are stronger than you? Okay, so now I want to maximize marginal revenue. I have an IID setting. So as usual, the values of marginal revenues don't matter. It's just the ordering matters. And so we just care about who has the highest marginal revenue and the person with the smallest quantile has the highest marginal revenue.
01:02:58.654 - 01:03:32.514, Speaker A: Right. And they're the person with the highest favorite item coordinate. Okay, so serve the agent with the smallest quantile, less than two thirds, and they start to have negative marginal revenue. And so that's serve the agent with the highest maximum value charge, the second highest maximum value, or reserve square root. One, three. The same mechanism I said would be optimal on the first slide. Okay? And so revenue linearity implies this mechanism is indeed optimal.
01:03:36.134 - 01:03:44.314, Speaker B: Can you remind me how you knew this was revenue linear? And more generally, how you know an aesthetic revenue linear? Or how you.
01:03:47.414 - 01:04:20.824, Speaker A: So I didn't give you a general method for determining whether a setting was revenue linear. I will give you a general method tomorrow for determining whether a setting is linear. So I'll give you two answers. One, you can solve a program to check revenue linearity, a mathematical program. You can just plug it in and ask with revenue linear. It's not a very nice answer. The other answer is you could observe the structure of the single of the interim optimal mechanisms, which is what we did today.
01:04:20.824 - 01:04:54.774, Speaker A: So we saw this interim optl mechanism for the unit demand case. And if you look at this allocation rule, what is it doing? It's gradually increasing probability as you get higher coordinate for your favorite item. Okay, what were the optimal ex ante mechanisms? They were just posting uniform price. So you can implement this allocation rule by taking a combination of those exonting mechanisms. Therefore, it's revenue linear.
01:04:55.954 - 01:05:00.414, Speaker B: Okay, that didn't depend on the allocation constraint.
01:05:00.714 - 01:05:27.994, Speaker A: Exactly. And that's the point. So the point is it will always look like this. For any allocation constraint, it'll have this exact same reserve price, and it'll be greedy up to that reserve. So the curve will match the thing up to the reserve, then it'll drop to zero. Any more questions?
01:05:29.854 - 01:05:32.034, Speaker B: I think that are not linear.
01:05:33.694 - 01:06:25.904, Speaker A: Okay, so I am out of time, which means I'm going to push the discussion of the general setting to tomorrow when things are not revenue linear. Okay, but so to conclude for today, we saw two examples, unit demand, public public budget and unit demand. They behave very differently when I look at their single agent problems. And the structure of the behavior of the single agent problem for the unit demand case was especially nice, which allowed us to use very simple marginal revenue tools to understand what offer mechanisms are. Okay, so next time we'll see how to, how to solve for optimal mechanisms when we don't have this nice structural property. In particular, we'll work out the OPTL mechanism for the public budget example. We'll do a bunch of other things as well.

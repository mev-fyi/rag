00:00:00.720 - 00:00:01.834, Speaker A: So welcome back.
00:00:02.294 - 00:00:33.682, Speaker B: The first speaker of this afternoon session is John Hongshtein. So he is working, actually, he started working at the University of Notre Dame. He's going to talk about solving polynomials. So this is the first direction of two. So thank you, Hiro. And I want to thank the organizers for the invitation, not just for this talk, but to be here the whole semester. So before I start, there's a workshop.
00:00:33.682 - 00:01:57.114, Speaker B: The second workshop is on solving polynomial equations. So this is jointly organized with Frank Sotale and then Pascal courant. So we'll bring in lots of good speakers to tell you more about solving polynomial equations and their applications as well, the complexity of them. So for my first talk, many of you might be familiar with symbolic methods, so I want to sort of give you a quick my interpretation of symbolic methods, and then also sort of tell you the basic idea of numerical methods. And then the rest of my talk will say, try and answer the question, what does solve mean? And then my next lecture on Thursday, I'll actually go into more details about numerical algebraic geometry and how do you actually solve things? Okay, so from a symbolic standpoint, symbolic, you can think of, say, Grosvenor basis or resultants, eliminance, etcetera. And what you want to do is you want to take your system of equations. So you have a given system of equations, system of polynomial equations.
00:01:57.114 - 00:03:19.594, Speaker B: Let's say f one of x, one through xn is equal to zero through fn, x one through xn, zero. And what do these methods do? All of the symbolic manipulations is, they manipulate the polynomials, or I will say, deform, to produce new sets of equations, new equations which are easier to solve. So we've been doing this in linear algebra for a long time. So let's write down a linear system of equations. So we have x minus nine, y plus eight, z is equal to five two. X minus three, y minus z is equal to minus five, x plus three, y minus two, z is equal to two in 1 second. Can anyone tell me what the solution is? No? Okay, good.
00:03:19.594 - 00:04:25.194, Speaker B: Suppose I did some manipulation, and if my math is correct, these two sets of equations define the same solution. And hopefully from the second one, you're able to actually see how to find the solution. Z is equal to five halves. Plug that into here, compute y, plug y and z into here, and compute x. So these two sets of equations define the same solution, but one of them is much easier to solve than the other one. So this is the basic idea of, say, Grosvenor basis is here you have these so called pivots in linear algebra, and pivots are replaced with leading terms or the leading monomials of algebraic equations. So you turn a system of equations which, say, is dense into something which has sort of nice pivots, and that way you can easily answer your question.
00:04:25.194 - 00:05:39.654, Speaker B: So this is how I see symbolic methods, is turning your system of equations into an easier system that you can now quickly solve. All right, let's move on to sort of numerical. So the basic thing of numerical algebraic geometry, the basic tool is homotopy continuation. And the idea is you want to solve f of x equal to zero by first solving a new system, g of x equal to zero. There's a lot of art involved with choosing this new system G, and we'll talk about some of the foundational ideas behind that throughout the two lectures. The system you give me is too hard to solve, so I'm going to ignore your system and solve my own system. That's easy to solve.
00:05:39.654 - 00:06:18.116, Speaker B: So, for instance, suppose my f of x is x squared plus three, x minus five, and two xy plus y squared minus three, x plus two four is. You might see an idea of how to solve this. The first one's quadratic and one variable. You can find the solutions, plug it in and get the y's. Compare that with this system. G of xy is x squared minus one, y squared minus one. You should be able to immediately solve g.
00:06:18.116 - 00:07:20.044, Speaker B: And now what we want to do is use the solutions from g to give us the solutions to f. That's the whole idea of this. So we're going to set up a homotopy. And for simplicity, let's just take a linear interpolation f of x times one minus t plus t times gx. And we want this to be equal to zero. So this defines the system of equations. And for simplicity, let's assume here that f is f one through fn, and x is x one through xn, where these are the same size.
00:07:20.044 - 00:08:07.360, Speaker B: So I have the same number of equations as I have variables. So I have a well constrained system. And now let's assume that g of x equal to zero has d solutions with the determinant of the jacobian of g not zero at each x star, such that g of x star is zero. So not zero. I said not zero. I didn't write it. Very good.
00:08:07.360 - 00:08:32.884, Speaker B: Thank you. So these are called the non singular solutions. So assume that all the solutions are nonsingular. This is a system of equations of n plus one. In n plus one variables, there's nx's and one t and n equations in n plus one variables. So you would hope this defines a curve. And almost everywhere it does.
00:08:32.884 - 00:09:12.624, Speaker B: And let me tell you what I mean by that. So what you should think about is your tight here is a complex number, and what happens at t equal to one. So let's plug t equal to one. In here, one minus one is zero. So my f term vanishes and I have one times g is equal to zero. So essentially I have g equal to zero. At g equal to zero, I have d solutions.
00:09:12.624 - 00:10:33.540, Speaker B: Everything is non singular. So think back to analysis. We have the implicit function theorem tells us that locally, nearby, my solutions can actually continue as I change t. So the implicit function theorem, it says that for t near one solution, pass x, sub t of h exists and are smooth solution of g equal to zero. So at every point of g equal to zero, I know that there's a solution path passing through there. So as I vary t, I get these nice curves. And what you can show is for except for finitely many values of t, this is always true.
00:10:33.540 - 00:11:34.648, Speaker B: So move from analysis, local analysis, to algebraic geometry. And except for finitely many t star, we have exactly d solutions, all non singular to h of x t star equal to zero. So now the art is we want to get to zero. We started at t equal to one. We want to get to zero. We don't know if the path along zero to one is actually good. And many times it's not, because the real numbers have some interesting properties.
00:11:34.648 - 00:12:07.824, Speaker B: So many times I'm going to have some of these t stars lying here. But I know that there's only finitely many things. And over the real numbers, this is a two dimensional set. The complex numbers are two dimensions. And so that means I can draw an arc that misses these points. And that's going to be my deformation. I'm going to deform along an arc that misses these points.
00:12:07.824 - 00:12:46.474, Speaker B: How do you construct such an arc? Well, that's a probability one statement. And so let me tell you sort of the whole idea. How do you know you're on a bad arc? Ah, very good. How do you know you're on a bad arc? You have less than these solutions, or one of them is singular. You only know it when you, you only know it after the fact. Yes, yes. And this is exactly where the probabilistic methods numerical offspring.
00:12:46.474 - 00:13:15.544, Speaker B: And so what I mean by that is, methods work except on a zerisky closed proper subset.
00:13:18.044 - 00:13:21.492, Speaker C: You don't know to prove that if it's a correct solution.
00:13:21.668 - 00:13:31.664, Speaker B: Yes, that's correct a priori. I don't know how to prove I have the correct solution, but if I have the wrong solution, then I can verify that I have a singularity.
00:13:32.444 - 00:13:34.900, Speaker C: How do you know? How many solutions do I have?
00:13:35.092 - 00:13:45.244, Speaker B: Because I choose my g, and because I've chosen g, I know I have that many solutions. Think back to x squared minus one, y squared minus one. That has four solutions.
00:13:47.064 - 00:13:50.804, Speaker C: How verified for some concrete point, or how many solutions?
00:13:51.504 - 00:13:56.444, Speaker B: You just have to exhibit them. Yes, just write them down.
00:13:57.984 - 00:14:00.984, Speaker C: Are we looking at real solutions only or any?
00:14:01.064 - 00:14:43.544, Speaker B: This talk is over complex numbers. I'll leave Cynthia to maybe talk about some kind of aspects of real upgrade geometry, but I will mention about real numbers very briefly in my second talk. If Cynthia doesn't say, okay, good. So what you move from in the symbolic case. In the symbolic case, you can prove that every computation you do was correct. You can prove that if you subtract two integers, you get another integer, and all of your computations in your Grosvenor basis are correct. Whereas numerical methods, we rely upon the probabilistic nature of Zyriski closed sets, they're small.
00:14:43.544 - 00:15:27.074, Speaker B: The probability that a random point lies on a given Zyriski set based on your probability distribution is probability zero. So the methods work with probability one by switching from always correct provable results to probability one results. The idea is now that we can solve much bigger polynomial systems. And once you know the answer afterwards, you can then go back and prove, using your favorite tools, that what the method gave you was correct. And there are several people in the audience who have used numerical methods to find the answer, and then going back with some other technique and actually prove that that answer was correct.
00:15:27.814 - 00:15:36.278, Speaker C: Just one more quick heuristic question. Does the structure of the singular points give us some heuristic knowledge on how to design good g's?
00:15:36.366 - 00:16:33.354, Speaker B: Yes. Yes. Okay, so I'll get into this very briefly, but because you're given f, you can look at its structure. What are the degrees of it? What are the monomials that appear in it? What kinds of things should happen at infinity that will lead you to design g to match this? And there's an arc to this. I won't be able to say much of it, but I'll lead you there in a little bit. Okay, so that's my introduction to the difference between symbolic and numerics. Because you have a solution like this, you know that x sub t is analytic with h of x sub t equivalently equal to zero.
00:16:33.354 - 00:17:31.764, Speaker B: And so what we've done is you can turn this into a path track. This defines a curve parameterized by t. And so you've turned algebraic geometry into a differential equation solver. And so let me tell you that this is what's called the Davidenko differential equation. We start at a known solution of g equal to zero, and then we adjust with respect to t based on the jacobian times the system. So you immediately see from this differential equation, my jacobian has to be full rank in order for it to be invertible. So here's where I'm going to see if I run into problems.
00:17:31.764 - 00:18:25.254, Speaker B: So we've turned solving polynomial systems f of x equal to zero into solving differential equations, and then use your favorite differential equation solver to come back to find the solution. Okay, good questions so far. So that's my brief introduction to comparing symbolic to numerical. Now let's move on to what we mean by soft. I think maybe you could just give a little history as to when these homotopy methods started being used. So the history is quite interesting in that homotopy methods have been used, they predate computers. Homotopy methods have been used since sort of the late 19th century for solving pdes.
00:18:25.254 - 00:19:26.214, Speaker B: And so PDE and Ode people have been using sort of homotopy methods to solve their methods, at least from a theoretically rigorous standpoint. Davidenko differential equation. So, before people were thinking of these paths using topology, and Davidenko in the 1950s had this idea, instead of using topology, let's use differential equations and come back to it. And this was about in the mid fifties, and then throughout the sixties and seventies, and then sort of exploding in the eighties, nineties and two thousands, this sort of window method sort of really took off in algebraic geometry. I think the first people to do it came from a mechanism of design, robotics. Yes, yes, exactly. So mechanical engineers have been using these to design mechanisms since the late fifties, early sixties, in the very basic first computers.
00:19:26.214 - 00:19:36.194, Speaker B: So the long computational history has been there, as well as the theory from the late 18 hundreds. Okay, good.
00:19:36.274 - 00:19:42.254, Speaker C: Does this method can work for any kind of equations, or there is, like, limitations for what kind of equations can be used?
00:19:42.794 - 00:20:48.214, Speaker B: So, as I wrote down the homotopy, it works for square systems where the number of equations is equal to the number of variables. You can always, it depends upon what you mean by solve, and that's what the next whatever length of time I have left is. What do you mean by computing the solutions? Do you mean computing some components? Do you mean finding isolated points of an overdetermined system? But every problem can be reduced down into exactly what I told you. You have a square system of polynomial equations. It takes some tricks to get it there, but it mainly depends upon the person asking the right question. What kind of solutions to this system are you looking for? Okay, so let's move on to solve. So when you ask your favorite program to solve this system, what are you asking it to do? That's sort of the fundamental problem here, is trying to find out what you're looking for so that the software can give you the answer you're looking for.
00:20:48.214 - 00:21:10.580, Speaker B: So let's think back to classical times. So, one final mention. Yeah, absolutely.
00:21:10.732 - 00:21:18.292, Speaker C: Up till this point, have you anywhere used the fact that we are dealing with polynomials or is immaterial?
00:21:18.388 - 00:21:57.784, Speaker B: So far, what I've used is that there's finitely many solutions at the end, finitely many isolated points. Everything here, this whole deformation works with any kind of analytic function. And so you can do homotopic continuation over analytics. You just can't prove that you have all of the solutions. To get sort of the methods to prove that you find everything you want, you have to use outbreak challenge. But also if you have finitely many bad points, I mean, somehow, yes, that should rely on polymorphs, right? At some extent. Yes, it does.
00:21:57.784 - 00:22:19.876, Speaker B: Yeah. Thanks, Greg. Okay, so let's think back to the ancient period. Say Egyptians solve meant to sort of write formulas in terms of the coefficients. So I hope everyone can answer the first two. Right. So x here is minus b over a.
00:22:19.876 - 00:22:42.774, Speaker B: I'm assuming this is linear, which means a is non zero. Throughout the talk, the next one, I hope everyone has gone through high school algebra. Good. X is minus b plus minus b squared, minus four ac all over two. A. Anyone know the cubic formula? It's very complicated. Yes.
00:22:42.774 - 00:23:32.394, Speaker B: What about the quartic formula? Has anyone ever looked at the chordic formula? Okay, a few people. Good. And then what happens? So, avo Ruffini, in roughly 1830s, no formula, no, there's no algebraic formula. There's an analytic. Yes, of course. No formula with radicals, no formula involving plus minus times dividend radical such that to solve general acquaintance, etcetera. Very good.
00:23:32.394 - 00:24:29.014, Speaker B: Okay, so I look at this and say 300 years ago, they predicted that computers were going to take over algebraic geometry. This shows that we need computers to help us. We need numerics to approximate our solutions. We need computers to refine, to reinterpret our polynomials. So sort of 30 zero year old math theory, together with modern computers sort of have led to this computational algebraic geometric sort of revival that's my pitch for that. Okay, good. So we can't write general formulas down, but what we can try to do is maybe solve means to compute a solution.
00:24:29.014 - 00:25:06.394, Speaker B: So I give you a system f of x equal to zero, and I ask, does there exist a solution or is there no solution? Okay, so let's say the univariate case. Univariate case. I give you a univariate polynomial, degree d. Does there exist a solution? Yes. Yes. Fundamental theorem of algebra. Good.
00:25:06.394 - 00:26:01.864, Speaker B: So if a univary polynomial of degree d has d roots counting multiplicity. So, univariate polynomials. And this was used in the previous talk. We always know solutions exist. What about positive dimensional things? And this is Hilbert's weak most. And it says that if f, which is again f one through fn equal to zero, has no solutions. Has no solutions, if and only if there exists g one through gn, such that I can write one as f one times g, one plus f g.
00:26:01.864 - 00:27:14.314, Speaker B: Okay, so how is this useful? In particular, how is this useful to what we're studying this semester? Let's look at three by three matrix multiplication. So pick your favorite r and look at the system. I equal one to r of a by jk times b. I, l, m times c. I n minus k times l. M times n. Let's erase chronic or deltas of these mn and oj.
00:27:14.314 - 00:27:53.292, Speaker B: And here I loop over all jk, l, m, n and o from one to three. Sorry, I'm not sure I understand the notation. Okay, so you pick JKl and Mo in one to three, and I'm going to write down this polynomial. Okay, so I have 729 polynomials. I have six choices here and three to the 6th. So what is a, b, and c? Yeah, you got it. So the Aijk are variables.
00:27:53.292 - 00:28:11.060, Speaker B: Yes. A, b, c are variables which live in cross three. Cross three variables. Indeterminates. Okay. And o is an index. An index.
00:28:11.060 - 00:28:26.180, Speaker B: Okay. Maybe I should change it to pull. Yeah, and it'd probably be better if I were greek or something, because it's a completely different type of index. Okay. All right. Okay. Just aesthetics.
00:28:26.180 - 00:29:00.964, Speaker B: Yes. So these have a name. These are called the Brent polynomials. And what's known about them? When r is less than or equal to 18, f of r equal to zero has no solutions. Who is. Why are these called Brent polynomials? Because there was a paper of Brent which were the first ones to write them down. And if you read Lauderman's paper, he refers to this paper of Brent.
00:29:00.964 - 00:29:53.380, Speaker B: Good. So that means whenever r is less than or equal to 18, I can find a linear combination or a polynomial combination in my ideal, so that one is in there. Okay, what's also known if r is greater than or equal to 23, f of r equal to zero. So this was, I guess, f of r equal to zero has solutions. And the first one to show this was Lauderman. And so between 919 and 22, it's unknown. So you can answer questions about complexity of three by three matrix multiplication just by trying to exhibit or prove that no solutions exist.
00:29:53.380 - 00:30:08.604, Speaker B: So we don't care about all solutions. We just want to know, does there exist any solutions? So what's the relationship of this matrix multiplication? If you have a solution, then these tell you exactly how to do the matrix multiplication.
00:30:08.984 - 00:30:18.112, Speaker A: I think this expresses. I was confused what this express is that the tensor of three by three matrix multiplication has ranked at most r. Yes, exactly.
00:30:18.168 - 00:30:26.752, Speaker B: This corresponds to the tensor of matrix multiplication. And this corresponds to a general tensor of rank r. And it's showing that the rank of this tensor is. Absolutely.
00:30:26.768 - 00:30:29.368, Speaker A: Because the choice of indices is a bit unusual, but.
00:30:29.416 - 00:30:37.760, Speaker B: Yeah, okay, sure, sure. Okay. Okay. Yeah. Okay, good. Thanks, Bear, how much coffee you've had.
00:30:37.792 - 00:30:40.984, Speaker A: It's busy. Yes, it's busy, as clear as it gets.
00:30:41.024 - 00:30:50.244, Speaker B: Okay. Okay. So if someone can answer this question between 19 and 22 this semester, that would be a great advance.
00:31:06.994 - 00:31:09.746, Speaker C: Numerical methods will lead to kind of an.
00:31:09.850 - 00:31:41.006, Speaker B: What's the problem? A lot of variables. There's 729 polynomials here, there's 27 times r variables. And so for the r that we're interested in, this is under, this is overdetermined. You have more polynomials than variables. Numerical methods like well constrained systems, but here is an overdetermined system. What that means is, any perturbation here, you're going to get no solution. Numerical methods like stability.
00:31:41.006 - 00:32:14.150, Speaker B: And so that's the fundamental reason about numerical methods here. Okay, good. So let's move on to numerical methods. How can you use numerical methods to prove that there exists a solution? So prove there exists a solution using numerics. So what I'm looking for here is, I'm looking for probably integers. There's a question. Oh, go ahead.
00:32:14.150 - 00:32:14.750, Speaker B: Sorry.
00:32:14.902 - 00:32:24.314, Speaker C: If you take, say you can take subset of polynomials here, like 27 times r. Yes. Will it always give you a solution?
00:32:25.614 - 00:32:47.934, Speaker B: It will. On, if you take the closure of those, you'll get a solution. I believe so. And so now you have to sort of look and see. Okay, I have a subsystem which has a solution, but there could be many points above it. How do I find the one that corresponds to the actual solution of all of these equations. Yes.
00:32:47.934 - 00:33:55.376, Speaker B: Okay, so here we're really looking for an integer or a rational solution so one that we can just plug in. How could we use numerics if we don't have such things that we can evaluate? And so here I'm thinking of my system f, and I'm going to switch, I won't switch notation. I'll stick with the same notation, fn. And here x is x one through x n. So I have a well constrained system, and now I take my favorite point, and I look at what happens when I do a new iteration. So what is a new iteration? X zero minus the jacobian f inverse times f of x here. And now you can take this point x one and do a Newton iteration on that and keep going.
00:33:55.376 - 00:35:33.114, Speaker B: And so you get a sequence of points x zero, x one all the way down, where x k is equal to the Newton iteration of the previous. Good. So if, you know, if the limit as k goes to infinity of xk exists, then this limit is a solution. So if this has a limit, then you know you have a solution. Another nice fact is that if the Jacobian at my solution is invertible, then there is an open set open neighborhood of x such that for all x zero. So open neighborhood u for all x zero and u the limit as k goes to infinity. Maybe I should call this y.
00:35:33.114 - 00:36:20.174, Speaker B: Sorry. So this statement is if the inverse exists, is that what you're trying to say? Yes, if my solution is nonsingular. So if my solution here is nonsingular, then there's an open neighborhood such that if I pick any point here, Newton's method has to take me back. And not only that, it has to take me back there fast. Y k minus my point x has to be in the quadratic convergence to the k minus one, y zero minus x. So not only do I have to converge to my solution, I have to converge there very fast. Quadratic.
00:36:20.174 - 00:37:54.690, Speaker B: So how do you prove you have such a point? How do you prove you have convergence? So prove quadratic convergence. For example, the nice thing about this is no knowledge of x, the limit point is needed, or any other solutions of that. So I can use alpha theory to test just by knowing this point y zero. I don't need to know how many solutions. Do there exist other solutions? I can test everything locally at my given point. Gregario and I have been discussing, and there's many people in the audience who would like maybe to have some kind of seminar involving alpha theory, numerical solving and things. So if you're interested, we can talk.
00:37:54.690 - 00:37:55.218, Speaker B: Very good.
00:37:55.266 - 00:38:03.152, Speaker C: But what about the neighborhoods? Sorry, but what about the neighborhood? So, you need to know, what is the neighborhood?
00:38:03.248 - 00:38:13.016, Speaker B: So, when you apply the theory, you know, at this point, there exists some ball. Where there's a solution that lives inside of that ball is the knowledge of.
00:38:13.040 - 00:38:14.960, Speaker C: How big the ball has to be needed.
00:38:14.992 - 00:38:41.886, Speaker B: Anyway, at any point, if you know this point, then, yes, you can find bounds on the ball. But if you don't know that point, and we're assuming we don't, then we just have some other point. Does it converge? So, yes, it's both ways. If you know x, you can get an idea or lower bounds on the side of U. And if you know y zero, you can get lower upper bounds on the distance. But if you know x, what do you care? You're done, right? Exactly.
00:38:41.950 - 00:38:44.934, Speaker C: No, sometimes you don't know x. You know the bounds.
00:38:45.054 - 00:39:07.386, Speaker B: Right. But if you know x, you're done. Yeah, but this is more about you guess a. Yes, in real life, you're guessing why, and then you. Exactly. You know. So take it back to homotopic continuation.
00:39:07.386 - 00:39:52.910, Speaker B: We follow our path until we're close to the end. Take that as our y zero and prove that it converges. That's sort of one way of using. Sorry, can you say your cosmos, what is this alpha theory that you're using? So, I don't want to go into details today, but essentially it's a rules for when Newton's method quadratically converges. And if there's significant interest, I can include that in my talk on Thursday, if that would be of interest, too. Would you be interested in. I guess? I have no idea what such a rule would look like.
00:39:52.910 - 00:40:30.620, Speaker B: Okay, well, I don't need no details. Let me tell you. The first thing is you need to know how far does Newton iteration? And then the second thing you need to know is arithmetic. Makes sense to me. How bad are your derivatives? One over k minus one. So this is kind of like a condition number. And this is the distance of Newton's methane.
00:40:30.620 - 00:40:58.046, Speaker B: And now you take alpha to be the product of those two. And if this number is small enough. 0.15. I forgive the magic number. Then Newton's method converges. Newton's method converges quadratically. I switched from x to y zero.
00:40:58.046 - 00:40:59.234, Speaker B: I apologize.
00:41:05.274 - 00:41:07.946, Speaker C: Is this norm specific? Does that depend on the.
00:41:08.050 - 00:41:18.334, Speaker B: That's the two norm. This is the two norm, and this is the operator norm. This is a tensor, and this is the operator norm.
00:41:20.114 - 00:41:28.734, Speaker C: It requires these things to be in the two norms. Sorry, it requires the value of alpha to be less than in the two norms.
00:41:29.234 - 00:41:30.054, Speaker B: Yes.
00:41:32.724 - 00:41:48.732, Speaker A: Well, maybe one could add that there is a beautiful upper bound because this gamma is complicated. It involves high derivatives of order, but you can upper bound it by quantity condition number, essentially, which only involves first orders. Yes, it's much nicer.
00:41:48.788 - 00:42:31.064, Speaker B: Yes, there's a nice upper bound, and that's actually what we implemented in alpha certified. If you have polynomials, this is a finite maximum. And so you can actually, in theory, compute it. But computing higher derivatives and norms and nodes is not practical. How much time do I have? Good. So, symbolically, or exactly, if we can produce the coordinates, then we can just evaluate it and see that sequence zero numerically. We just have to get close and then rely on some other theory to prove that there is a solution.
00:42:31.064 - 00:43:06.654, Speaker B: Okay, there was a quick aside here. I made the assumption that my solution was nonsingular. If you look at the system, and this is in your homework, 29 over 16, x cubed minus two xy y minus x squared. The solutions of this is the only the origin, its multiplicity three. But if you take a random point in c two, which is not the origin, the method diverges. And so that's part of your homework. Problem here is be careful.
00:43:06.654 - 00:44:24.034, Speaker B: When Jacobian is not invertible, you can get some crazy behavior. This is just a nice simple example of some behavior. Okay, so I leave that one to the homer. What's another way we can think of solving equations? So maybe you want to think of solving means counting. So, before I first said, does there exist a solution? And now the next question is, how many solutions are there? So, to solve my system means to count the number of solutions. Okay, so in the univariate case, we already have the fundamental theorem of algebra, which says that a degree d polynomial has d root counting, multiplicity. What happens in general? Well, in general, it's quite interesting.
00:44:24.034 - 00:44:54.794, Speaker B: The only things that we know of, sort of in general, are upper bounds. So when we design homotopies, we design the g so that it has an upper bound on the number of solutions. And one simple way to find upper bounds is Bezou's theorem. Oh, you mean if the number of solutions of g is an upper bound, the number of solutions of f. Exactly, yes. Very good. So if f one through fn.
00:44:54.794 - 00:46:13.854, Speaker B: Let's go back to algebra's notation. Then the set of solutions x such that fi of x equals zero, I equal one to n. If this and this, then the number of points is bounded by d one times dn. And what I have to do is be careful. So what can go wrong? Well, it could go that I have infinitely many points in here. And how can I bound infinitely many points by this? If then let's go to this, where v zero of f one through fn equals the isolated points in my solution set. So, if I ignore all the positive dimensional components and just look at the isolated points, I'm going to have finitely many of them and abound on the number of isolated points is the product of decreasing.
00:46:13.854 - 00:47:27.584, Speaker B: Moreover, my set of solutions are all isolated and bound is sharp on a Zariski open dense subset of polynomials of degree di. What I mean by that is, if I take all of these polynomials in particular fi to be general in the set of all polynomials of that fixed degree di, then my bound is sharp and all the points are isolated. They're all non singular. Everything is nice, almost everywhere. Bezou's theorem is true. What's the problem? The problem is, many of the polynomial systems we want to solve lie on this sort of singular locus. They're not on this risky open set.
00:47:27.584 - 00:48:23.604, Speaker B: And that's where the challenge comes in. How do we handle sort of the so called bad set where they suit theorem? Okay, so let's, let me give you a historical fact or historical example of using Bayesian's theorem. And so, this is Steiner's problem, I believe, 1848. Count the number of conics tangent to five given general lines. Conics. Conics. General conics, sorry, conics.
00:48:23.604 - 00:48:56.394, Speaker B: And c two. I should look at my notes rather than go off to. Good, okay, so pick five general conics, and now you want to count the number of conics candidate. What happens if I pick. Pick one conic and it's general. Then there's going to be a hypersurface of conics which are tangent to that given one. So there's a hypersurface.
00:48:56.394 - 00:49:57.524, Speaker B: There's a hypersurface of conic's tangent to a given one, and the degree of it is six. Good. So now Bayes, whose theorems all this question is asking is how many points are in the intersection of these five hyperplanes. So I'm intersecting hyperplanes, hyperplanes are defined by a polynomial. And so I'm just intersecting five polynomials. So Steiner said, the answer is, and this is why this is infamous. Steiner said, well, I have six polynomials, five polynomials of degree six.
00:49:57.524 - 00:50:54.104, Speaker B: And so I should expect 7776 solutions. The problem is, this is not correct. And the reason for this is he forgot about the double lines. So this bound, this number, added the double lines in there and double lines are some family, but we're only interested in the isolated points. The family of double lines lives in there as a one dimensional I. And so you have to remove the count for the double lines. And the actual answer is 3264.
00:50:54.104 - 00:51:42.116, Speaker B: So just as Newton's theorem, Newton's method, you have to be careful when the jacobian is not invertible. You have to be careful about Baziou's theorem. When you have positive dimensional things that lie in there, they can throw your count off. Good. If you want a nice historical or nice computational look at Frank's book, which I believe is upstairs in the library for this, you can ask. So this was all over the complex numbers. Now you can ask the real question, how many can be real? So of these, 3264, how many can be real? And it turns out that all of them can be real.
00:51:42.116 - 00:52:01.524, Speaker B: There's a nice construction again in Frank's book that shows. That shows this due to Fulton. Yes. The pictures are. Who also asked the question? Fulton asked the question. Fulton asked that question and he answered it. Yes.
00:52:01.524 - 00:52:05.176, Speaker B: Good. So maybe, may I ask questions?
00:52:05.280 - 00:52:16.608, Speaker A: I wonder what happens geometrically. So you have this hype. If you pick one conic in general position, this defines a hypersurface of conic tangent to the given one.
00:52:16.656 - 00:52:17.048, Speaker B: Yes.
00:52:17.136 - 00:52:21.008, Speaker A: And then you take five of those and you intersect.
00:52:21.096 - 00:52:21.648, Speaker B: Yes.
00:52:21.776 - 00:52:31.642, Speaker A: So you will get, I mean, 3264 isolated points plus components of positive dimension.
00:52:31.698 - 00:52:34.818, Speaker B: Yeah. And the opponents of positive dimension are exactly the double lines.
00:52:34.866 - 00:52:35.774, Speaker A: What is that?
00:52:40.314 - 00:52:57.566, Speaker B: It's a square of a linear equation. Yeah. They're tanger for free. Yeah, exactly. P two and p five. Okay. All right.
00:52:57.566 - 00:53:41.094, Speaker B: So the last thing, I think I might be running out of time. The last thing for your homework is to look at polynomials like this. X plus four, five minus one and y squared plus five, x plus two, y minus three. And by looking at polynomials like this, I sort of hope that you'll be thinking about designing homotopies to solve such a. So let's look at this here. I have two quadratics, degree two. So Bazu's theorem says that I have less than or equal to four isolated solutions.
00:53:41.094 - 00:54:40.304, Speaker B: How many do I actually have? They have. Well, this polynomial system has structure. And one of the structures it has is that the x's only appear linearly. So if I look at what happens, I can rewrite my system in the following way. I have two y plus three and then four, y minus one and then five and y squared plus two. Y minus three times x, one is equal to zero. So because my x's only appear linearly.
00:54:40.304 - 00:55:19.554, Speaker B: I can rewrite this as sort of a matrix equation like this. This is a non zero vector. And whenever I have a non trivial kernel, that means that this matrix has to be ranked efficient. So this implies that the determinant, so let's call this matrix a doesn't depend on x. The determinant of a of y has to be equal to zero. And this is nothing more than the resultant of my system. If I call, let me just say this is f one, f two.
00:55:19.554 - 00:55:53.494, Speaker B: So this is nothing more than the resultant of f. What's the degree of this polynomial? It's degree three and it's univariate. Every polynomial of univariate of degree three has three solutions. Counting multiplicity, it turns out you can show that it's all multiplicity one. And suppose I have a y that satisfies this. I'm going to get a unique x where this is true. So this turns out that this has three solutions.
00:55:53.494 - 00:57:30.154, Speaker B: The nice thing about cubic equation cubic things is you can simply write down the discriminant and you can count the number of real solutions. So, part of your homework asks what's the number of real solutions to this? And you can do that quickly with discriminant. All right, so what is the additional structure of my system here, which reduced my count from four to three, and it was the fact that x's only appeared linearly, whereas my original polynomials were quadratic two. And so you can generalize this to a multi homogeneous Bezier's theorem and design homotopies based on it. So, multi homogeneous Bay zoo, and for time constraints, I'm just going to assume the two homogeneous case end here. So assume that. Let's say that if my system f is defined, I need two variables, x and y is defined on pick your favorite space, affine space, product space, or the reverse of them.
00:57:30.154 - 00:58:36.990, Speaker B: The count is the same for any one of them. So how many x's are there? There's n xs. How many y's there are ny's of them. Then the number of isolated points is less than or equal to. I'll write down the bound and then I'll tell you all the ingredients. The coefficient of the term alpha nx times beta ny in the polynomial, or in the expression product eigenvalue to nx plus ny of dxi times alpha plus dyi times beta, where fi has bi degree dxi. Okay, so that's a long, complicated expression.
00:58:36.990 - 00:59:33.324, Speaker B: Let's look at it in this simple case, and then I'll be done for today. So this one is defined on c cross c, otherwise not known as c two. But I'm going to think of this as c cross c because that's how I'm going to find as p one cross p one. Okay, so now look at the degrees. So what is my degree of x? In the first equation, x appears linearly, so the degree in terms of x is one. And the first equation, y, also appears linearly, so that's also one. So this is a quadratic polynomial that has bi degree one one.
00:59:33.324 - 01:00:09.174, Speaker B: Let's look at the next one. X's only appear linearly, but y appears quadratically. So it's a quadratic polynomial of type one two. And all this is saying is now take the permanence of this matrix, one two. Take the permanent, because you have to traverse one x and one y. And the number of ways to make this matrix go through is exactly the permanent. And so this is two times one plus one times one, which is three.
01:00:09.174 - 01:00:53.116, Speaker B: If you want to use this fancy coefficient expression here. What we're really looking at is what is the coefficient of the cross term alpha times beta in alpha plus beta times alpha plus two? Beta coefficient of alpha is one, coefficient of beta is one coefficient of alpha is one coefficient of beta is two. In the second expression, what's the definition of alpha and beta? They're just symbols. Oh, I see. They're just symbols. Yeah. So all I'm asking is what is the cross term here? So I need alpha times beta, that gives me two, and beta times alpha, that gives me coefficient of one.
01:00:53.116 - 01:01:13.724, Speaker B: It's in my cross term is. So with that in the homework, I ask you to find the two homogeneous bayesian count for eigenvalue, computing eigenvalues of a matrix, which is a nice sort of extension of this. All right, I should stop there.
01:01:20.544 - 01:01:22.264, Speaker A: So we have a little more than.
01:01:22.304 - 01:02:12.920, Speaker B: Ten minutes of questions. Yeah, we'll go back here. So earlier on, you talked about like probably one of finding a nice homotobies. Are people interested in questions like finding a small set of homotopies, one of which will necessarily work? So instead of having probabilistic construction, having some sort of potential. Yeah. So in the homotopy construction, going back to the beginning, t times g of x. So because it's sort of with probability one, what people do in practice is pick different g's and do the computation, make sure to get repeatable results afterwards.
01:02:12.920 - 01:02:57.686, Speaker B: So you know that for any particular g, if I set it up with probability one, it'll work. But now you have to understand that that works over talking about the blue shoot smell model, that works over that model of computation. However, my computer has finitely many bits in it, and to do the numerical computations, so you use adaptive precision, increase sort of the accuracy that you have, but then also just pick different start systems and rerun the same problem and make sure you get repeatable results. Not in practice, because I understand the practice. Yes. But like, in theory, can you find just a collection of G's? One, yeah, there's gonna be. What it turns out is there's gonna be a whole family of G's that work.
01:02:57.686 - 01:03:13.714, Speaker B: Can you actually pick one? You may be asking, oh, you give a list and one of them will work. Yes. So you're gonna have. What you're gonna have is a whole family of them, which all work. And so anyone in this family will. I hope I answered your question. Okay.
01:03:14.254 - 01:03:35.058, Speaker C: Does this kind of, like, theory can lead to proof of lower bounds for tensor n? Say, if I give you some tensor, which I believe is n cubed over three, then that is possible. That you will give, like, proof, probabilistic proof, that it has actually a rank of n. Crypt over three.
01:03:35.146 - 01:03:40.454, Speaker B: If the polynomial system is small enough that you can actually solve it.
01:03:43.314 - 01:03:45.122, Speaker C: Polynomial time solution.
01:03:45.218 - 01:04:01.374, Speaker B: Oh, no, not polynomial time. And you get non zero, then there's no probability at all. Exactly. Non zero is non zero. So you have a sequential.
01:04:04.914 - 01:04:09.254, Speaker C: If you will get the solution when you know the kind of high probability.
01:04:12.054 - 01:04:13.254, Speaker B: That would be nice. Yes.
01:04:13.294 - 01:04:16.590, Speaker C: But you say that there is no way of solving it in the eponymous.
01:04:16.742 - 01:04:20.394, Speaker B: No, it would be nice if you could.
01:04:20.934 - 01:04:31.234, Speaker C: I'm sort of changing the subject. Is there a good, nice story for the worst case of this problem? For the worst case analysis of algorithms for this problem?
01:04:32.854 - 01:04:39.234, Speaker B: Worst case is you're going to have singularities and you're going to hit the singularities.
01:04:40.174 - 01:04:41.634, Speaker C: How about the symbolics?
01:04:43.414 - 01:05:23.132, Speaker B: So let me rephrase what I'm talking about. So, there are numerical methods to handle the singularities, but to get provable results about singularities or not. For example, I don't know if Peter will talk about this throughout his talks or somewhat. You can use alpha theory to certifiably track these path, and you can prove every step along the way that everything is nonsingular and it's nice. And if the whole path is non singular, then you get a finite time algorithm to track that path and compute the endpoint. Whereas in practice. So that's in theory.
01:05:23.132 - 01:06:15.424, Speaker B: In practice, you do different tricks to handle singularities. One interesting question is, is suppose I give you a numerical approximation of a singular point. How do I know that there actually is a singular point for that system? Newton's method probably will either converge linearly or diverge, or who knows what happens. So are there different approaches to be able to. You can take the numerics, go back into symbolic expression expressions, and then sort of use that symbolic expression to prove that there's a singularity there. But it's really, trying to find good algorithms for singular cases is really hard. There are heuristics that work pretty well, but if you want provability.
01:06:16.804 - 01:06:19.464, Speaker C: But the symbolic methods do work.
01:06:21.324 - 01:06:23.682, Speaker B: Yeah. Grosvenor basis. Absolutely correct.
01:06:23.818 - 01:06:27.734, Speaker C: And is there any concise form of.
01:06:28.314 - 01:06:31.018, Speaker B: The worst case doubly exponential?
01:06:31.186 - 01:06:35.978, Speaker C: So it's basically in the number of terms the degree and the number, and then.
01:06:36.066 - 01:06:36.450, Speaker B: Yes.
01:06:36.522 - 01:06:37.854, Speaker C: Okay, so it's double.
01:06:40.434 - 01:06:48.614, Speaker B: In the degree, in the degree and number of variables polynomial in the degree.
01:06:49.134 - 01:06:50.798, Speaker A: I think if you just want to find.
01:06:50.846 - 01:06:57.590, Speaker C: I think I made my point. It's probably not a very well known answer.
01:06:57.622 - 01:07:01.470, Speaker B: Right? I think it's well known. I should ask the complexity.
01:07:01.502 - 01:07:13.326, Speaker A: I think it's only single exponential if you, only if you just want to find the solution in geometric way. But however, if you want to understand it algebraically with multiplicities and everything, then.
01:07:13.350 - 01:07:24.506, Speaker B: It will be double exponential. Okay, so the drop of bounds. So my double yes or similar solution was correct. Good. Just a comment.
01:07:24.570 - 01:08:06.916, Speaker C: If you want the worst case for omotopy, you need to make concessions. For instance, you should admit that the input is by integers and the size by integers, the coefficients of the polynomial integers or rationales or whatever. So in that case it is possible to get results in terms of the, among other things, of the size of those integers, assuming that the system is non degenerate. So there will be a worst case for non degenerate systems. And you don't know if you system is the generator.
01:08:06.980 - 01:08:18.116, Speaker B: Not at the beginning. Worst case in general is your computer doesn't work. Yeah, your computer doesn't terminate, but you can get, usually you can get, I.
01:08:18.140 - 01:08:18.756, Speaker C: Know who to talk to.
01:08:18.780 - 01:08:33.376, Speaker B: Okay, thanks, John. You should point out, when you talk about adaptive precision, you can notice that you're getting close to a singularity. Absolutely. With the condition number that's really important for the algorithm. Absolutely. And I hope Peter might say something about this on.
01:08:33.480 - 01:08:35.928, Speaker A: I think I will talk about it in the workshop.
01:08:36.016 - 01:08:36.384, Speaker B: Okay.
01:08:36.424 - 01:08:38.856, Speaker A: And I will talk about different things in the tutorial.
01:08:38.920 - 01:09:05.420, Speaker B: Okay. Very basic things. Very good. So, and because I wrote up gamma here, there's this conditioning that gamma handles. And that sort of tells you sort of how many digits do I need to accurately handle my roots there? Conditioning is very important, and I think your talk in this thing is on conditioning, but also throughout the sequence. Other questions?
01:09:05.612 - 01:09:16.652, Speaker C: Yes, it's just a naive question, probably. So the Zeus theorem is giving some kind of worst case number of possible solutions. Is there like a notion of an average case number of solutions or if.
01:09:16.668 - 01:09:27.637, Speaker B: You'Re looking at random polynomials or something? I'm very curious. Theorem is sharp in the average case over the complex numbers. I think in general polynomial.
01:09:27.685 - 01:10:09.162, Speaker A: If you are over the complex numbers, it's not a very interesting question, because almost surely you will get this number of however, over the real. It's a very interesting question. There are lots of interesting open problems. So for instance, there is this very nice result by shooting smale, which is kind of average Bezou theorem, which says that if the equations are chosen a drain according to some gaussian invariant gaussian distribution, then the expected number of real solutions is just a square root of the product. This is very beautiful. There are many, many open questions, and.
01:10:09.178 - 01:10:29.230, Speaker B: There'S a certain type of probability distribution for that. And if you change your probability distribution, you get a different expected number. I didn't hear Google keyword.
01:10:29.302 - 01:10:42.674, Speaker C: Google keyword. So that I can introduce myself, we give you the reference complexity and real computation.
01:10:43.714 - 01:10:56.774, Speaker A: If I may advertise my book that I wrote in Felipe Cook, the tightest condition, it's on the shelf. We have there the alpha theory and the gamma theory, and we also have the square root of product of the degrees.
01:10:58.994 - 01:11:01.214, Speaker B: Very good. So there's a book on the third.
01:11:01.714 - 01:11:08.494, Speaker A: And it's that it's not the main fossil step, but it's also in there with a slightly different proof than the origin.
01:11:22.394 - 01:11:38.704, Speaker B: So if there is no other question. So let's thank the speaker again. Click. The next culture starts at research. I know.
01:11:40.764 - 01:11:41.664, Speaker A: Daniel.
01:12:06.174 - 01:12:08.754, Speaker B: If there are no solutions, then you have to track.
01:12:13.494 - 01:12:13.894, Speaker A: My name.

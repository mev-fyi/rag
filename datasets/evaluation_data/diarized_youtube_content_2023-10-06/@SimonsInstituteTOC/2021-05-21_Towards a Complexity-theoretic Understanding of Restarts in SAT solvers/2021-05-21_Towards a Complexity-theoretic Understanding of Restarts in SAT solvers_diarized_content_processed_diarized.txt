00:00:00.440 - 00:00:14.390, Speaker A: Now it's my pleasure to introduce Ian Lee. Ian is a PhD student under my supervision at the University of Waterloo. He's going to talk about restarts and sat solvers. Ian, the floor is yours. Thank you, Ian.
00:00:14.542 - 00:00:58.584, Speaker B: Thank you. Thank you everyone for coming to the talk. So, the work I'm going to present is a joint work of myself and Noah Fleming, Mark Vinoz, Tony Pitasi, and so, during previous talks from this program, the restart problem has been mentioned several times, and it's quite big open problem in the research of that. So before we go into the details of restarts, let's look at why do we care about the restart problem in the first place. So, from the empirical perspective, we simply know solvers with restarts outperform solvers without restarts. Analogy is like adding cross learning to a DPL. The gain is massive.
00:00:58.584 - 00:01:49.124, Speaker B: And another reason is restart is a quite natural heuristic or choice to consider when you are working with a search procedure. The intuition is if your search procedure kind of gets unlucky and going to a bad part of the search space, you would like the procedure to restart and then try somewhere else. And potentially it can get lucky. And from a theoretical perspective, right, I'm going to refer to this in famous results again. So it's proven that CDCL, with non deterministic branching and restarts is p equivalent to general resolution. However, this theorem kind of relies on, you know, having restart being one of these assumptions, and it's unclear. If you take out restarts, the equivalent still holds.
00:01:49.124 - 00:03:15.024, Speaker B: And this result is important because with this result we can go back and open our proof complexity toolbox and then start lifting results to solvers. And another thing is, if you happen to work on the restart problem before, I think you agree with me that the restart problem is super interesting to work with, so why not? So talking about the history of restart a bit. Right? So restart have been studied extensively in the broad research area of search and optimization problems, where the idea is to use restart to escape local minima or maximum. And restart was first used or adopted in DPLL setting, where upon invocation, the software basically erased the assignment trail and started search from anew. And later restarts in CDCL software are a bit different. Upon invocation of restarts, the software erased the trail, but it also keeps some other information it has learned or gained during the search. For instance, one of the things restart doesn't erase is the learn clause database, and it also preserves activities in visits branching, and it also preserves phase saving values.
00:03:15.024 - 00:04:30.664, Speaker B: But coming back to the questions, right? Like are risk stars really useful for cell solvers? And how do we justify it empirically, and how do we prove it theoretically? In this talk, I'll focus more on the theoretical side. So there has been two perspectives of this restart problem, like empirical perspective and theoretical perspective. So on the empirical side, people have proposed possible explanations of the power of restarts. So probably the most famous one is this heavy tail explanation, which applies to some randomized version of DPL solvers. And the idea is it was absorbed that different runs of randomized DPL solvers, the solving type of different runs of DPL over times, has a huge variance. So in other words, chances are if you just run the solver multiple times, one after run will give you a really short proof, or can find a satisfying assignment really quickly. So if we feel like the solver restarts, the solver can exploit this huge variance in the solving time and potentially get lucky.
00:04:30.664 - 00:05:22.658, Speaker B: But this explanation doesn't really live to CDCL setting perfectly, because there are a variety of reasons. But I'll mention two reasons here. First reason is the model being considered here is randomized model. While CDCL servers are usually more complicated in the sense that, for example, we are working with locality based CDCL solvers, which means the choice variable being branch on are not completely randomized like in this setting. And another reason is perhaps the more important reason is that CDCL servers have closed learning. And more importantly, these closets are not removed across restart boundary. In the DPL setting, once you restart, I'm literally starting the search from scratch, I'm looking at the original formula, and then.
00:05:22.658 - 00:06:57.414, Speaker B: But in a CTCL setting, once you restart, you're essentially working with a new formula. And another explanation is this restarts compact assignment trail this is quite intuitive, because at some point your assignment trail is too long, and then it contains literals that may not really contribute to the conflict you are working on, like the software is working on at the moment. So chances are it's good to restart, and then only the solver will naturally branch on the variables that are more and more recent and more local. And this hypothesis was later verified by one of our paper, which exploits this observation and then proposed a machine learning based reseller policy. And on the theoretical side, it's quite a common approach to model solvers without restarting the proof system, and then by establishing the existence of a candidate class that could potentially separate out this exponentially separate out this proof system and general resolution, one can prove whether restart can give you exponential power. However, the final answer of whether restart is really needed, is still open. But a common consensus among communities is that CDCL solvers without restarts are weaker than general resolution or the solver with restarts.
00:06:57.414 - 00:08:33.976, Speaker B: So as we were start working on this problem for a while, we started realize the restart problem is actually quite subtle and allowed me to explain that. So if you look into inside the saasover and you unpack it and look into each of the components, there is actually a collection of components, right? So for example, you have variable variable selection, you have value selection, you have conflict analysis back jumping, you have clause vision restarts, and possibly a few more like for example, how variables are propagated due to like too much literal or something else. And the idea is that each of these components can be implemented, or there can be like different heuristics you can choose to boot in which components, right? For example, for variable selection function, you can say my solver branch non deterministically, which is a fair assumption. Or I can assume my solver branch is purely random, right? Or I can even weaken it to say the solver has to branch according to a predetermined static ordering. And for conflict analysis, we can have first UIP, we can have decision learning scheme, we can have second UIP, we can have third UIP, right? So I guess the idea is to say, by choosing a specific implementation of a component in solver, and by putting all the components together, we end up with what we call configuration of a SAS solver. As you can see, there can be many, many configurations of CT cell SAS solvers. This raises a very natural question.
00:08:33.976 - 00:09:54.766, Speaker B: In the context of restarts, does there exist a configuration such that restart at exponential power, while in the same time there exists some other configuration where restarts doesn't add any power and the answer turns out to be yes. We were able to show that in our set 2020 paper we were able to establish four separate and two equivalence theorems between solvers with and without restarts. And in this talk I'll briefly discuss two of the more important results separation results we got in the paper. So the first one is we separated out trunk CDCL with and with, essentially separated out trunk CDCL with and without restarts. This model is inspired by the drunk DPL model by Alec Noich at all. And I guess the only modification is that we are adding cross learning to lift DPL to CDCL. And just to talk about the model a bit, by drunk CDCl we mean the solver with backtracking and non deterministic variable selection, but random value selection and clause learning.
00:09:54.766 - 00:10:43.574, Speaker B: So on the high level, the solver is smart enough to know what variables to branch on, and it has the choice to do so. But what it doesn't have control is what kind of polarity are assigned to these, uh, these variables. And this is exactly the property we exploit to prove the separation. So what we prove that for a class of satisfactory formula, which we call a ladder formula trunk, CDCL without restarts takes exponential time while drunk CDCL with restarts takes polynomial time. And this is with high, uh, with high probability because we're dealing with some random model here. And the second result is based on what mark just presented. It's for a model of CTCL with visits branching.
00:10:43.574 - 00:11:58.824, Speaker B: So we consider CDCL with back jumping and visis, variable selection and phase saving value selection. And we proved that for unsatisfied formula, which is based on the pitfall formula mark just presented, we show that CDCL solvers with visits without restarts takes exponential time, while CDCL with visits and research takes polynomial time again with high probability. Before I go into the more of a detail of this discussion, I want to just stay on high level and talk about, you know, how is our approach differ from the previous approach. So it's mainly different from perspective, right? From previous approaches, SAS operas are usually modeled as proof systems. And then we are implicitly dealing with unsatisfiable formulas and then talking about proof size, lower bound or upper bounds with them. And in our setting, we are also considering satisfiable formulas because restart can have different impact in these two contexts. And then even though they are related, we may end up getting different insights in both domains.
00:11:58.824 - 00:12:59.904, Speaker B: And another difference is, again, when we're considering a proof system, you're implicitly assuming some non determinism within the system. But in our approach, we are studying a more fine grain of configurations of assessors, and where we weaken certain heuristics from being non deterministic to some weaker, weaker version. So why do we consider weakened heuristic in the first place? Right, because again, because the subtlety we absorbed from four restarts. So there seems to be a very subtle interplay between solver heuristics and the power of freestars. The power of restarts seems to only become more apparent when certain heuristics are weaker than non deterministic. So I'll now present kind of like a high level proof methodology. And as you can see, I stole this picture from Mark.
00:12:59.904 - 00:13:45.664, Speaker B: I'll explain our lower bound, upper bound argument on a very high level. So just to describe this pitfall. Right. So I guess there's also a story here. So we first, as we were working on the restart problem, we first developed this ladder formula which we were trying to show the separation in a satisfy setting. And then we attended one of Mark's talk on this pitfall formulas and he realized there's something in common. So we started collaborating and then it seems like we can generalize the formulas we constructed in both cases and then think about it on a high level in the sense of this easy trap and hard construction.
00:13:45.664 - 00:14:23.164, Speaker B: So the pitfall formulas have three components to it. A heart formula which we know are like have known lower bounds for resolution and for trapped. There's also a trap part which kind of tricks the sovereign in focusing on the, on the hard formula. And then there's an easy formula. And in our case, for separating restarts, we are using a small backdoor for the easy formula. And more specifically, we are using weak backdoor in the satisfiable case and strong backdoor for the unsatisfiable case. And just to remind everyone what factor means.
00:14:23.164 - 00:15:17.524, Speaker B: So a weak backdoor is defined for satisfiable formulas. It's a set of variables where there exists assignment to the weak factorial variable. And if you set the variables accordingly, the remaining formula becomes trivial to solve. So in other words, if you can somehow argue the solver can assign these variables correctly, then you can easily find a set assign assignment. And a strong backdoor is defined for unsatisfiable formulas where definition is under every assignment to the backdoor, strong backdoor variables, the underlying formula becomes easy to solve. So in other words, if you keep querying on the strong backdrop variables, you can prove the form and you have a small strong backdoor, you can prove the formula easy. So the lower bound argument for our restart separations kind of works like this.
00:15:17.524 - 00:16:03.884, Speaker B: You want to argue with our restarts. With high probability, the solver will fall into the trap and needs to refill the hard formula before escaping. And this is similar to what mark was saying. And in the upper bound setting, essentially want to say the solver with restarts can exploit the small backdoor. And for strong backdoor is about finding the backdoor variable to start with and then to branch out. And for the weak backdoor setting, it's about finding the desired assignment to the weak backdoor variables such as remaining formula is easy to solve. And just to go into a little bit of more detail into this, these two results.
00:16:03.884 - 00:17:21.052, Speaker B: So for the drunk CDCL separation, we are considering backtracking, which undo the most recent decision level upon learning a conflict and non deterministic variable selection and randomized value selection. And the latter formula is a satisfy satisfiable formula which contains a login size weak factor and all but one assignment to the weak factor variables implies getting trapped, which in our case we make. The formula implies Satan. And in the no register case it's kind of hard since we are, since the drunk solver doesn't have a, you know, doesn't get to choose what values are assigned to the variables. So it's very likely that even if the solver focuses on the weak factor of variables, it won't be able to assign them to the desired assignment. So the argument will say without restarts it's hard to branch on, assign the variables to their desired polarity and with high probability, and thus implies a hard formula to solve. For riskstars we would like to argue the solver can keep querying the backdoor variables until they assign them correctly, and if they're not assigned correctly, just simply restart.
00:17:21.052 - 00:18:32.116, Speaker B: And because the solver has non deterministic variable selection, it can just keep branching on these backdoor variables until finds the desired assignment. And for the visit results, we are considering a model with back jumping, which is the software erases all literal assignment trail that's from a higher decision level than the second highest decision level in the learned clause. And we have our business variable selection, except we have a random tie breaking mechanism. And we also consider a version of restarts that resets activities. And we have a phase saving value selection which basically assigns the value assigns a variable according to what priority it was assigned last time. And if a variable was never assigned, we simply assign it false to begin with. So the pitfall formula is an unsatisfiable formula which contains a constant size strong backdoor, and with no restart we want to argue with high probability.
00:18:32.116 - 00:19:40.024, Speaker B: The first conflict will bump activities of variables in the hard formula, and this is exactly what Mark was showing earlier. But with restarts, we can restart, use restart to reset activities because we have the condition that whenever you restart, you resets the activities of all variables. And additionally with this random type breaking we can use these two properties to kind of keep restarting and trying to find find the strong backdrop variables to branch out. And we also have four other, two other equivalence results and two other separation results on other like configurations of CT sass servers. One of them being, you know, like we're considering a really weak version of static static CTCL solvers and some non deterministic DPL setting and we also have a version of drunk DPL and also have a separation result on this weak decision learning scheme. This was a private conversation with Robert. Robert.
00:19:40.024 - 00:20:56.234, Speaker B: And just to state some key insights and takeaways from this work, credit so there are three, mainly three folds. The first point is the power of restart is quite subtle, and then the power of restart may only become more apparent when certain heuristics are weaker than non deterministic. And we also consider satisfiable, both satisfiable and unsatisfiable formulas. And the last one is this pitfall, a framework where we can embed an easy part of formula and then embed a hard formula, and then use a trap mechanism to connect the two to construct formulas that are suitable for separation results. And just some open questions. Of course, the big question still remains, whether CDCl solvers without restart is p equivalent to general resolution still remains open. And another question I would like to bring up is the difference between backtracking and back jumping.
00:20:56.234 - 00:22:06.094, Speaker B: Backtracking. If a solver only backtracks, then it's clearly a solver without restarts. But back jumping are sometimes referred to as mini restart, but it is never really formally studied. So the idea is, even if you can have a super long assignment trail to start with, and then you're somehow like, having a hard formula embedded at the end of this assignment trail, it's still possible to learn a conflict that involves some very few literals from the top of the assignment trail. And by back jumping, you have options to back jump all the way up to somewhere near the root of your trade. So this is a quite powerful thing you can do, but this is still not as powerful as restarts, because you can never back jump the first literal you branched on, unless you prove the whole formula is unsatisfied. So I think formalizing and understanding the difference between backtracking and back jumping in the middle and restarts can be a quite productive direction to think about.
00:22:06.094 - 00:22:09.854, Speaker B: And this concludes my talk. Thank you very much.
00:22:10.434 - 00:22:38.154, Speaker A: Thank you, Ian, for a fantastic talk. Thank you so much. Questions, please. Okay, so I had one question, Ian, about your thoughts about use of restarts from a proof size versus proof search perspective. Did you have any ideas there, or any initial thoughts?
00:22:38.534 - 00:22:55.958, Speaker B: Right. So it's tricky, like, what you are really comparing with, right? So, like, if you want to think about restarts from an automatability point of view, right? Are you comparing, like, are you assuming a formula has a short restart proof, or are you, like, what are the.
00:22:55.966 - 00:23:06.188, Speaker A: Assumptions similar to what Mark showed? Like Mark showed essentially an automatability separation. Right. In his result for vsips.
00:23:06.356 - 00:23:21.104, Speaker B: I think what makes sense is maybe we can consider different versions of restart policies. Like maybe one you are, like at a fixed interval, and some other sensitive. Maybe by then you can talk about automatability. Right. Like how. Yeah.
00:23:22.044 - 00:23:31.064, Speaker A: Okay. Any additional questions? Yep, Sam, go ahead, please.
00:23:31.144 - 00:23:58.754, Speaker B: Yeah, I was wondering if you could say a few words about the equivalence result you stated. First, I think it was for static CDCL. Right? So definitions. Yeah. So the model we're considering is quite constrained from some perspective. Right? So by static, what we mean is. So, first of all, the software has backdropping and it's using static variable selection and static value selection, right.
00:23:58.754 - 00:24:20.054, Speaker B: This is kind of like before you even run the solver, you kind of predetermine the ordering of the variables, right. And each time you want to branch on a variable, you just branch according to this ordering, right. It's a very fixed order. So the idea is if you have a solver. Solver without restart. Sorry, with a solver. Sorry.
00:24:20.054 - 00:24:40.964, Speaker B: Using the software, with restart, even if you restart, you still have to kind of follow this fixed ordering, right? And then you are basically reconstructing the trail to the point where before you call the restart on a high level. So, yeah. So does that answer the question? Yes. Thank you.
00:24:43.504 - 00:24:55.446, Speaker A: All right. Thank you, all the speakers for a fantastic talk. Thank you, Paul, Mark, Noah and Ian. And we'll meet tomorrow, I guess, same time. Thank you, everybody. Bye.

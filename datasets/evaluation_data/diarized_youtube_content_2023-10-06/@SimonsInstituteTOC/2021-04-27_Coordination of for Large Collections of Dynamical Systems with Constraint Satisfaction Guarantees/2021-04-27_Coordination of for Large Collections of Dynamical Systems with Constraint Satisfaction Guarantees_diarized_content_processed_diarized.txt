00:00:02.160 - 00:00:04.394, Speaker A: I'm here, I'm here. Just a second.
00:00:06.054 - 00:00:13.114, Speaker B: All right, so Paulo, this is your applause. Thank you very much. Beautiful talk, very nice questions.
00:00:13.854 - 00:00:55.514, Speaker A: So it gives me really great pleasure to introduce Netzmi. Reason is because I just today when we were chatting before, I recall that we know each other already for around ten years. And at that time Netsmy was a postdoc at Caltech, but in the meanwhile she became very famous and did lots of work in control three. So I was just checking her website and it's really impressive. The list of award that she got for her research. She got NSF Career award, DARPA Young Faculty Award, NASA Early Career Award, DARPA Directors fellowship, and I could just go on this way. I would probably take all her time.
00:00:55.514 - 00:01:10.774, Speaker A: So she's really doing great. And she's now associate professor at University of Michigan. And thank you very much, Nesme, that you agreed to give a talk at this seminar. So the floor is yours.
00:01:14.874 - 00:02:19.474, Speaker C: Sorry I muted, thanks so much Susina and the others, for inviting me and for organizing this event. So I am going to talk about our work on coordination of large collections of dynamical systems with some constraints, satisfaction guarantees, and this is joint work with two of my former students, Petar Nelson and Yunus Shahin, and my current student Sun Ho Jan and collaborator Johanna Matthews. She is working on smart grids and power systems. She motivated this research and she's still pushing us to solve more realistic problems in more realistic settings. So I will just get in the problem directly. So if you are solving a synthesis problem, you have two components that goes into your synthesis engine. One is your system model and the other one is your specification.
00:02:19.474 - 00:03:11.858, Speaker C: And most of this talk will focus on the model part. And I will ask how we can scale this model to be fairly complex or large scale in a certain sense and still synthesize and give guarantees. And at the end, I will also mention a new class of specifications that we came up with using the type of systems we were looking into in this work. So the system models I will be looking at would be differential equations. So this is the most general form of the model that I will present. But then I will specialize and I will show you the specific structure that arises in many different contexts that we will use. So there's some state space here.
00:03:11.858 - 00:04:04.694, Speaker C: You either have a continuous time differential equation or discrete time difference equation. You have some states x, you have some continuous control inputs. Continuous meaning these input set is in rn, you have some discrete control inputs, you have finitely many choices. This also appear a lot in cyber physical systems, if you have switches or valves, those type of components, you have disturbances, both discrete and continuous. Continuous disturbances are something we are very familiar in control. So these are things that directly affecting your dynamics. And discrete disturbances, you can think about it as failures or some outside signals you should respond, things like maybe a traffic signal that you are responding.
00:04:04.694 - 00:05:00.970, Speaker C: And in most of the problems in real world, we have hard constraints both on the inputs and states. We have infinite horizon specifications. So typically in control we look into stability type things where we care about what happens in the limit. But here we will be looking at both transients and infinite horizon properties. So there is this hybridness both in the system and in the controller. So there are many cases, even if you don't have hybridness in your system to satisfy complex specifications, you might need hybrid controllers and you need this robustness that Paulo very well motivated, I guess. And the focus of this talk would be what can we do when the state space is in rn, a subset of rn and n is very large.
00:05:00.970 - 00:05:50.080, Speaker C: Is there a class of systems and some structure that we can utilize so that we can solve synthesis problems where n is very large, so there are many methods out there for cps, control synthesis and scalability is a big bottleneck that we have been attacking from different directions. And there are many factors that affect scalability. So state space dimension is one. But there's complexity of dynamics, complexity of specifications, and the types of results you might want to get from this process. And again, in this talk, I will try to address scalability from the perspective of state space demands. So there is quite a bit of work. I am seeing state of the arts here, here.
00:05:50.080 - 00:06:51.184, Speaker C: But most of the references that I am going to give, they are going to be like four or five years old. So we are doing much better these days. But we know how to solve synthesis problems for hard state input constraints, hybrid dynamics, complex specifications using temporal logic for small scale systems. So there are applications where you are trying to control an individual robot, or a couple of rooms in a building, or you are trying to control an individual vehicle, or certain subsystems of an aircraft, or more complex system. But these are usually small state spaces in small system scale problems. And here are some results from the literature that tries to apply synthesis type ideas for cyber physical systems. And depending on the specification complexity, the dimension of the state space you can handle is roughly like this.
00:06:51.184 - 00:07:56.072, Speaker C: So if you have very simple safety type specifications, maybe you can do 1520 dimensional systems. Now, these numbers are a little better. As I said, this is a bit dated and if you keep increasing the complexity of the specification, the system dimensions that you can handle drops a little bit. And there are tools out there for solving these problems as well. So there are also medium scale systems that people develop synthesis methods for, and they use some properties of the system dynamics to develop such methods. So what are those properties? So monotonicity is one of the properties that that was shown to be useful in the setting using some multiscale abstractions and hierarchies and composition were shown to be useful. If you use these type of tricks, maybe these are tricks standard and some of them are tricks standard in computer science.
00:07:56.072 - 00:08:53.862, Speaker C: If you bring in these type of tricks of compositionality and such, then you can scale a little bit up. And there is also large scale systems. There is work on large scale systems where you do parametric verification of hybrid automaton or abstraction of large scale stochastic systems. But these works, they don't do synthesis, but they look at abstractions or verifications, those type of work. But there's a recurring theme here. If you start scaling up, you are utilizing structural properties, and we want to see if there are other structural properties we can utilize to make this synthesis process much more scalable. I started to talk with this large collections of systems, and I will give two motivating examples.
00:08:53.862 - 00:09:33.284, Speaker C: One is emergency response with a robot swarm. So there's an emergency, an earthquake. You want to deploy a large collection of robots. There could be quadroaders, there could be ground vehicles, and you want to do some certain rescue mission, and you want to plan trajectories for individual robots in a dynamically consistent way. And you have different types of requirements. Maybe you want sufficiently many robots in different areas, and maybe you want not too many robots in certain regions. If there's a bridge that's about to collapse, you don't want to send too many robots there.
00:09:33.284 - 00:10:33.512, Speaker C: Then there are this individual collision avoidance or charging reporting type constraints for individual robots. Let me show you another example in a very different class of systems. This is a problem in smart grid. This is the coordination of thermostatically controlled loads. If you are not familiar with what thermostatically controlled loads are, these are fridges, water heaters, air conditioners that has a thermostat in it and that turns on and off. And it has been shown that you can use these devices and change their duty cycle a little bit. And if you use these devices in a large number, in a neighborhood, and you start changing their duty cycle, these can be used to help demand response, so they can be used as storage devices.
00:10:33.512 - 00:11:28.354, Speaker C: If you have renewable energy coming in, you can store energy in these devices and you can use that energy when you are leaking your renewable generation. Again, there are certain requirements for these devices. You don't want to turn on too many of them. At the same time, you don't want these devices to synchronize because then you will be extracting too much power from the grid and that's dangerous for overloading the grid. And you want to have sufficiently many of them to be on, especially if you have some renewable generation and you want to use these as storage devices. And there are local temperature constraints. You don't want to do it by violating people's comfort constraints or by spoiling their food in their fridge.
00:11:28.354 - 00:12:39.190, Speaker C: So what are the common structural properties between these two different looking examples? The first properties, there's a large number of systems, but small number of classes. You don't have zillions of different quad rotors, so you maybe have hundreds of a certain type, hundreds of certain other types. Similarly, air conditioners and fridges, they are very similar, and you have this large number within each class, then the constraints and requirements are related to how many of them are in a certain mode or how many of them are, are in what region. So there is this similarity in the requirements as well. And one other thing that's important here is that identity of the individual systems is not important in satisfying these type of requirements. So if you have a search and rescue mission, you don't really care if quadrotor number one goes and rescues person number one, or quadrotor number ten goes and rescues that person. So there's that symmetry type property there as well.
00:12:39.190 - 00:13:16.466, Speaker C: And for simplicity, I will assume dynamics are identical for each class and there is only one class. And I will show how to relax them later. So let's try to mathematically formulate our problem. Let's look at maybe air conditioner and the temperature of the air conditioner evolves with respect to these dynamics. If the air conditioner is on, you have certain dynamic evolution, and if it's off, you have certain dynamic evolution. Evolution. And you are controlling this on off level.
00:13:16.466 - 00:14:20.924, Speaker C: You are trying to figure out when to turn on, when to turn off. We have a collection of these air conditioners in a neighborhood or in a city, so we have a large number n of these air conditioners that we can control. From the customer's perspective, there is a desired temperature that they want to achieve in their room. So you only allow small deviations from the desired temperature. So there's this local constraint from the customer's perspective, and there's a global constraint from the utility companies or power companies perspective where you don't want to turn on too many of these devices at the same time. And I am indicating that with this indicator function of which of these devices are on, and I want the sum of the devices that are on simultaneously to be bounded so that I can control the power consumption of these devices. I can generalize this.
00:14:20.924 - 00:15:28.552, Speaker C: So I have a switch system, I am controlling these switches, there are m different modes, and I have n identical devices of this form. There are local constraints where I want these states to be in certain sets locally, and I want to have the number of systems in a certain mode in the power case, number of systems extracting power from the grid to be bounded. And I can have different bounds for different such modes. So, and the structural property, if you look at this problem, is that both dynamics and specifications have this permutation invariance. So I can just swap the location of my states and I swipe the location of my specifications, and I will get the exact same formula. And we want to use this permutation invariance to develop a scale scalable method for solving these type of problems. So here is how we develop a solution for this problem.
00:15:28.552 - 00:16:42.350, Speaker C: The first thing we will do is we will construct a symbolic abstraction then for an individual device, and we will try to aggregate them to define an equivalent problem. Then I will show you some properties of this aggregation and abstraction process, and that will reveal some fundamental limitations. Then we will develop an optimization based approach for solving the problem in this aggregate model. So what is a symbolic model? If you have a nonlinear system or any dynamical system, you can construct a graph structure that captures certain properties of the system. And for this we use some methods developed by Paulo earlier. And essentially what we will do is since I am controlling the switches for each switching mode, this is my face portrait. I will grid up my state space, and from each point in this gridded space, I will simulate my dynamics for a time discretization.
00:16:42.350 - 00:18:30.032, Speaker C: I will fix time discretization as well. I will simulate my state for delta units of time, and I will look at where the simulation ends up, and I will just connect the two points in a graph if this simulation ends up closest to this other point, and I will do it for different dynamics, and I will in the end construct a graph using these individual simulations from graded points. And if you do your time discretization and state discretization carefully, one thing you can show is that for every walk on this finite graph, which you can imagine jumping over these points, there exists a continuous trajectory of the system, whose time and state discretized version, or whose time discretized version will be epsilon clause, to this walk that jumps on grid points. And similarly, for every trajectory of the system, there is going to be a corresponding walk on this graph, and that time discretized version of this trajectory will remain epsilon close to the walk. Here. If you interpret the walk as jumping over these grid points, and to achieve that type of by simulation, we use this incremental stability property of the dynamics. And you can show that there is a smart way of choosing your state discretization and time discretization, such that you can guarantee that you can achieve this epsilon closeness as long as you do your state discretization and time discretization properly.
00:18:30.032 - 00:19:58.424, Speaker C: But we are doing it for an individual device, and we have maybe thousands of these devices. So how do I go from this graph structure that represents an individual device to a graph structure that represents thousands of devices? So, traditionally, you can take these graphs and take, you can imagine these are automata, and you can try to construct a product automaton, but we don't want to do that because n is large and my product, automotive will be large. So what I will do instead is I will treat this graph as a histogram, because all of my systems have identical graphs. And if I treat this as a histogram, and if I have ten systems whose states are closer to this upper left dots, I will just put a ten over here in this node of this graph, in the v zero node. And at each time I can take a snapshot of where my dynamics are. And from that snapshot, looking at where each state are, I can form a histogram on my graph by assigning numbers on these nodes of this graph that I construct. And it turns out that depending on how you turn on and off these systems, you can write the dynamics of this histogram.
00:19:58.424 - 00:20:31.890, Speaker C: And this is what I am going to do next. But before that, I want to, I forget I had this slide. I want to mention a few relaxations there. So, if you construct this graph in the way that I described, this graph is deterministic. So from action, deterministic in the sense that from each node with the same action, you go to a single other node. But you can also relax this. And we assumed everything is identical so far.
00:20:31.890 - 00:21:22.364, Speaker C: You can also relax this to mild heterogeneity. And if you have some disturbances or parameter differences between different systems, there is still a smart state discretization and time discretization, it's a little more constrained. That will give you these type of graphs. So you can, if you discretize your state and time carefully, all stable systems look alike. So that's the high level idea. So if you have stable systems, you can find these discretizations in state and time that will give you identical graphs. And once you have the identical graphs, as I said, you can treat this graph as a histogram, and you can now look at how these numbers on the histogram evolve.
00:21:22.364 - 00:22:29.038, Speaker C: And to define that, I will define a different type of state that essentially counts the number of systems in a given mode. It's a given node of this graph, and I will call it w, and I will define my inputs is the number of systems at a given node of this graph that switch from mode one to mod two. And with these state and input definitions, then I can write the dynamics of this histogram, how this histogram evolves as I switch my systems from on and off. And it turns out that these dynamics of the histogram is, is a linear system. It's a linear system evolving on an integer letter with some constraints on the inputs. And this input constraints essentially says if I don't have any system at a mode, at a given node, I cannot switch them. So there's a lower bound on what I can switch.
00:22:29.038 - 00:23:34.424, Speaker C: That's my input constraint, and there's an upper bound. If there's n systems in a given node, then I can add most of its n systems at a given time. So the dynamics on the histogram is a linear system on an integer letter with input constraints. Then I can state this theorem. If my original problem has a solution, original synthesis problem has a solution, then there exists a solution to this linear problem where you have some input constraints and your counting constraints ends up being linear constraints in this new domain as well. Next, quick question. What do you mean by the original problem? The one before we did the epsilon b simulation, or the after the epsilon simulation with continuous time switch system problem, where we are designing these switches for individual systems.
00:23:34.424 - 00:23:43.660, Speaker C: And if that problem has a solution, then this problem has a solution up to an epsilon accuracy. And if this problem. Okay.
00:23:43.692 - 00:23:44.584, Speaker B: All right, thanks.
00:23:45.404 - 00:24:29.424, Speaker C: Okay, so essentially these are up to this epsilon accuracy. If you just that epsilon accuracy affects how you shrink or expand your safety constraints. These two problems are equivalent. That if I want to solve my initial switch scheduling problem, I can go and solve a linear problem. And the nice thing about this linear problem is that the state dimension here does not depend on the number of devices that I have. It only depends on the size of the graph that I have. So this is really giving us a problem that's dimension independent if the dimensions is measured in terms of number of devices.
00:24:29.424 - 00:25:20.786, Speaker C: Okay, so I will try to find a solution for this problem, and the solution strategy would be given an initial state. I will try to steer the system into some nice states from which I can find periodic inputs. So there will be this prefix suffix type constraints. I know I am running out of time, but I will try to quickly go over that. Then if I can find some periodic conditions, then I can guarantee my periodic inputs and behaviors. Then I can guarantee my constraints will hold indefinitely. And there's also, you can do some analysis on this system to show when the systems are steerable.
00:25:20.786 - 00:26:27.870, Speaker C: And that's related to controllability in linear systems. That tells you, we came up with a special controllability condition for this type of systems evolving on integer grids. That tells us about some of the fundamental limitations. So this is a reachability property, and you can figure out when you can steer the histogram from an initial state to an arbitrary final state just by looking at the cycles and connectivity of this graph. And essentially, if all the connected components of this graph has period one, and if you have a single connected component, then you can achieve any modes of this histogram, you can achieve any distribution on the histogram. Okay, so as I said, there is a, we want to find this prefix suffix type solution so that we can generate periodic solutions in the end. And to do that, what we will do is we will just look at the cycles of this graph.
00:26:27.870 - 00:27:16.656, Speaker C: Because cycling through a cycle in this graph corresponds to a periodic behavior of my system. And if you want to say certain systems are in a cycle, that ends up being a linear constraint as well. So I can write down everything with linear constraints, and I can write this big linear programming problem to solve my original problem. So you don't need to worry about what all these constraints, all you need to know is they are all linear constraints. The only thing is that these counts on the histogram, they are integers. So if you impose integrality constraints, this is a mixed, this is an integer linear program. And if you relax those constraints, this is a regular linear program.
00:27:16.656 - 00:28:15.162, Speaker C: And the important part is that this is independent of the number of systems n. So we have some analysis of this thing. If you are solving the integer problem without relaxing to reels, the solution is complete in the sense that there exists a prefix length and cycle length for which this problem will be feasible, if and only if the original problem is feasible. And for any ILP solution you can extract a solution to the original problem. And from the ILP solutions you can get certificates for non existence. And for the LP solutions there is a nice finite cycle length that you can consider with which you can round the solutions, and rounded solutions gives you a solution for your original problem. So, this is a bit technical.
00:28:15.162 - 00:29:13.154, Speaker C: I will just pass on this and I will show you some examples. So this is a typical duty cycle of a power or a thermostatic control load. What we are essentially doing is we are changing this duty cycle by our schedules, and we are also shifting them in time so that they are not synchronized. And we can achieve, we can track arbitrary power trajectories that are requested by the grid operator. So I will quickly show something else. So we started with discounting constraints and we said, okay, maybe we can also think about counting things over time. Instead of having this, my counting things should be invariant all over the time.
00:29:13.154 - 00:30:12.034, Speaker C: I can have counts that are evolving over time. And we define two different logics. One is counting temporal logic and counting linear temporal logic, and the other one is counting linear temporal logic plus essentially this is like LTL, but instead of regular propositions, now you have an atomic proposition and number pair, and you interpret this thing over collections of systems, and you can encode time evolution of these constraints. So you can say things like, eventually I want at least five robots in a given region, I never want more than two robots on this bridge, and things like that. And you can also encode things related to asynchronous. So I will just wrap up. So we came up with this synthesis technique that exploits symmetry and permutation invariants.
00:30:12.034 - 00:30:51.568, Speaker C: It works across scales, so it works for ten systems or 10,000 systems. And in the limit, this also has some relations to mean field games, if you are familiar with that. And we are looking at applications in different domains, and we have this new logic as well that we have some analysis for. And going back to the initial picture, we could change the scalability landscape using these logics, of course, for a limited class of problems. So I will stop there. I think I will.
00:30:51.696 - 00:31:04.044, Speaker A: Let me also give a big clap for everyone. Thank you very much for the talk. So, are there some questions? I think we can probably take at most one questions, because we are a little bit running late.
00:31:08.464 - 00:31:19.924, Speaker B: So I have a question, so can you handle this way also collision avoidance? I mean, you don't need to. I mean, you can scale up collision avoidance to like thousands of.
00:31:21.064 - 00:32:17.514, Speaker C: We can handle collision avoidance as well. It's a little trickier, but we have ways so you can encode collision avoidance in this logic, which essentially says at a given location, there should always be at most one. But that's if you look at the optimization problem that we are solving, encoding it in the semantics of the logic, or encoding in the syntax of the formula is not the most efficient way. Since we are writing down this linear constraints, there's a trivial linear constraint that you can add rather than writing it in your logic formula and coding it. So there's a more trivial way of collision avoidance, but it's captured in the logic as well, if you want.
00:32:17.974 - 00:32:18.798, Speaker B: Thank you.
00:32:18.926 - 00:32:36.074, Speaker A: Thank you. Okay, let me just quickly brief abuse my power as a chair. So one question is like, in this new logic with counting, do you think that you will be able to apply all your previous techniques or so we can.
00:32:38.014 - 00:32:51.162, Speaker C: The things that we use this for, if you start with a graph rather than continuous dynamics, everything that we develop, we can apply to this logic.
00:32:51.318 - 00:32:56.254, Speaker A: But then how histograms and stuff will work if you have counting, maybe I missed something.
00:32:56.674 - 00:33:43.446, Speaker C: So we are dividing the state space into regions, and we are assigning atomic propositions to those regions, and then we are essentially counting the number of systems in these different regions. So we are counting the number of systems that satisfy a certain atomic proposition at a given time. So if you can imagine, if you imagine this is n different infinite trajectories at each time, we are counting how many of atomic proposition one is satisfied, how many of atomic proposition two is satisfied, and so on. And we are interpreting this logic over that structure.
00:33:43.630 - 00:33:47.894, Speaker A: Okay, I see, misunderstood something initially. So thank you very much.
00:33:47.974 - 00:34:23.589, Speaker B: And let's, sorry, I just want to make one observation. So we, at some point, you know, quite long ago, we had superposition temporal logic, linear superposition temporal logic, linear superposition logic, where we had a sort of a state abstraction. And so we actually, we were not counting, we were computing densities of formulas that are true. So, you know, so if you think of this, you know, you could say with densities that something happens.
00:34:23.741 - 00:34:28.477, Speaker C: So lp relaxation in the limit goes to densities.
00:34:28.645 - 00:34:29.669, Speaker B: Yes, yes.
00:34:29.821 - 00:34:36.381, Speaker C: Essentially there's a relation with density type, mean field type approaches as well. But I will, I will check out your work.
00:34:36.517 - 00:34:37.593, Speaker B: Yeah, thanks.
00:34:38.453 - 00:34:51.073, Speaker A: Okay, so please let me stop sharing. And we have our final speaker of today. That's Yasser. Yasser. Wait, where is, are you sharing? I clicked accidentally.
00:34:53.853 - 00:34:56.605, Speaker C: I'm sharing now. Can you see my screen?
00:34:56.749 - 00:35:14.893, Speaker A: Yes, so we will really have to. Who is your chair? Am I Orado? Are you okay? It looks that it's me, so let me be. It's really pleasure also to introduce our speaker, Yasir Shukri, who is now a.

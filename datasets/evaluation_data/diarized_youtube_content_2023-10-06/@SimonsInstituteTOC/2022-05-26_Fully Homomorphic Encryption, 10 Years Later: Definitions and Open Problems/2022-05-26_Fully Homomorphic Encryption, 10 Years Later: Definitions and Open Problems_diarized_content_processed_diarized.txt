00:00:00.120 - 00:00:52.526, Speaker A: Algorithms has been sort of, like, tremendously important in theoretical computer science, actually. I remember the first time was l cubed, where they were teaching it again and again in the algorithms class at Berkeley. And Daniele has worked on both sides, both the algorithms for lattices, like he has the first exponential algorithm for CVP, the exact CPP closest vector problem, and the cryptographic applications of it, like sampling trapdoors for lattices and so forth. And Daniele has done this for many, many years, spanning more than three decades. And I'm extremely, especially proud that Daniele is actually my student in the past, I guess, always a student, and I agreed to give this talk, and I'm incredibly grateful to him because he's like an amazing expositor as well. So thank you, Daniele.
00:00:52.630 - 00:02:06.480, Speaker B: Okay, thank you for the introduction, and thank you for the invitation for having me here. It's a great pleasure to talk here at the simplest. So I'll be talking about fully homomorphic encryption for the non cryptographers. Well, let me first tell you briefly, informally, that encryption traditionally is a tool that can be used to encode messages in a way that you can store them or transmit them while protecting their content, so that unless somebody knows your secret key, the content of the message is protected by this encryption barrier. Fully homomorphic encryption is an enhanced form of encryption which allows not only to secure, store, and then retrieve your data, it allows to perform computations on encrypted data without decrypting it, and in fact, without even knowing the decryption key. Now, this is a technology that opens a lot of doors to potential applications. Think of using a lightweight device like your laptop tablet, and keeping your data stored on the cloud.
00:02:06.480 - 00:02:48.036, Speaker B: On some big but untrusted server, you can still encrypt all your data, keep it securely stored, and not only retrieve it. If you want to retrieve the old data, you can even get the cloud, the server, to perform computations for you on the encrypted data without revealing any information about the data itself. And of course, the result of the computation would still still be in encrypted form. It can be sent to you, and you can decrypt and read the final result. Now. So, this is a very powerful tool. And let me start with a brief outline.
00:02:48.036 - 00:04:37.086, Speaker B: I'm skipping a lot of things, of course, but just to put this in a historical context, the problem of whether this was possible at all was posed a long time ago already in 1978, by Rivest, Adelman, and Bertuzos. They posed this as a problem, but without having any solution to perform arbitrary computations on encrypted data. There were some crypto systems supporting some very basic operations. But when we talk about fully homomorphic encryption, the f, the fully stands for the ability to perform arbitrary computations either described as boolean circuits or described as arithmetic circuits or your favorite programming model. Now, it was not until 2009 that the community somehow made a big jump forward with a breakthrough result of Craig Gentry that proposed the first candidate solution to the problem, to perform arbitrary computations on encrypted data, and also introduced a boost technique that helped developing the field and come up with many other solutions to the same problem. Sorry. So only this problem, the community, the cryptographic community, started really believing that it was possible to do this two years later in another fundamental step, bracheris, va contanata, and came up with the first solid solution to this problem based on standard lattice problems, standard complexity assumptions on lattices.
00:04:37.086 - 00:05:46.340, Speaker B: And this work was crystallized the following year in a work by giant Riberkische and Verkontanatan in what is now called the BGV scheme, which is an efficiency improvement over the original BV proposal. And it is fairly close to certain form of homomorphic encryptions that are still currently in use. Now, what happened from 2012 to 2022 in this last ten years? So a lot of things happened. So this was just the beginning. And there's been a steady stream of works improving fully homomorphic encryption schemes, which at first were purely theoretical constructs showing that something was possible into something that is getting closer and closer to being actually usable. And new schemes were proposed, efficiency improvements, additional features. There's been a driving community of both theoreticians and more applied people building libraries that implement fully homomorphic encryption.
00:05:46.340 - 00:06:45.756, Speaker B: And so sil, he, Lib, Cc and Palisade. So these are just examples. There are many libraries out there implementing various forms or some sub collection of homorphic encryption schemes that have been developed through the years. Still, all of these schemes and solutions, they are all based on lattices. So the same type of mathematical problems already used by BGV, and they all make use of these bootstrap trapping technique. So this fundamental technique introduced already back then in 2009, and it is still a big component of any solution that can perform arbitrary computations now. So all this activity during this last ten years, and it was a lucky coincidence that this coincided with the ten years of life of the Simons Institute here.
00:06:45.756 - 00:07:51.736, Speaker B: And as already mentioned by Rachel earlier this morning, there have been some, there's been a lot of activity at the Institute on Lattice Cryptography in related areas. So in 2015 we had a full program on cryptography that included bootcamp tutorials and workshops on lattice cryptography and fully homortic encryption. And in 2020 we had a full program just dedicated to lattices, not only for cryptography, also lattice algorithms and lattice complexity. And this week is actually the first week of the lattice, a summer cluster that will go on till the end of June. And it has been great to be able to gather the community of lattice cryptography, fully homophobic encryption and related area, and bring everybody together here at the institute year after year. So let's get more technical. So today I want to talk about fully homophobic encryption, but without getting into the technical details of the constructions.
00:07:51.736 - 00:09:01.972, Speaker B: So I tried to give something that has some technicalities, but it's a fairly high level, so hopefully won't be too hard just before lunch. So I will first start with a description, with a more technical description of the traditional definition of fully homomorphic encryption. This idea of being able to compute on encrypted data. And then I will briefly, but very briefly, make a detour into lattice cryptography to show what are the problems, the technical problems that need to be solved when you want to do that. We'll see that the ciphertexts are noisy, and this is the problem that was initially solved using bootstrapping. The reason I'm talking about this is because bootstrapping is still the only way known to build these schemes, and there are some important open problems related to it. After that, I will present a new perspective on bootstrapping and the definition of homomorphic encryption, which I think may shed some light on these problems and time permitting, which means I will probably skip that, because we are already a little bit behind schedule.
00:09:01.972 - 00:09:47.758, Speaker B: I may mention approximate encryption, approximate homorphic encryption, which is another problem, another variant of homorphic encryption that has been receiving a lot of attention in the last few years, and it also raised some interesting, important definitional problems. Let's start with simple encryption. In an encryption scheme we have a very simple syntax. We have a key generation algorithm, an encryption algorithm, and a decryption algorithm. And you can use this generation algorithm to produce a pair of keys, a public key and a secret key. Now, for the purpose of this talk, the distinction between public and secret is not that important. If you want, you can think of all algorithms being performed using the secret key, except for the evaluation.
00:09:47.758 - 00:11:03.074, Speaker B: Evaluation is something that should be performed in a typical application by an entrusted server. So that's should be a publicly computable operation. So in a start and encryption scheme, if you have a message m, you encrypt it, and then you apply the decryption algorithm you expect to find exactly the message you started from. So homorphic encryption introduces a new algorithm into the picture, an evaluation algorithm that takes as input a function, a function that you can think of as the description of the program that you want to compute on your data, and the correctness definition. The correctness condition associated to homomorphic encryption is the following. So if you start from a message m and you encrypt it to produce a ciphertext, then you apply this function, this evaluation function to evaluate a function f homomorphically. On this ciphertext, you will obtain one more ciphertext which when decrypted gives as a final result exactly what you would expect f the result of performing the computation in the clear without any form of encryption.
00:11:03.074 - 00:11:37.752, Speaker B: Now this is the traditional definition of what a homomorphic encryption scheme is, is a good definition. It closely model what you want to do in an application. And this was the initial goal of homomorphic encryption schemes. Now let me tell you a few words, just a few words about lattices. So in a lattice crypto system, keys are vectors. And here I will just focus on using secret keys. So the secret key, think of it as a vector with n coordinates, with n integer coordinates.
00:11:37.752 - 00:12:30.904, Speaker B: And the way you use this vector s to encrypt a message m is the following. You generate a random matrix a, typically with entries from some finite rings integers modulo q. For some not too large q, you also generate a random noise vector e. And by noise I mean that this vector is chosen at random by the small coordinate. So it could be gaussian noise or uniform entries over a small interval. And you encrypt the message m by outputting this random matrix a and then a vector b, which is this expression here given by as plus a scaled copy of the message m times a scaling factor delta perturbed by this noise vector e. And we'll see in a moment why you want to scale the message m.
00:12:30.904 - 00:13:28.764, Speaker B: Now, how do you decrypt this ciphertext? You can take this vector b. So this is the decryption algorithm. You take a and b is this expression here you can first of all you can subtract as from it. So you know a, which is from here you know s, which is the secret key. And as you perform this subtraction, you will be left only with this component delta m plus e, which when divided by delta will give you exactly the message m up to a small additive perturbation, which is the error vector divided by delta. So if delta is small enough, if delta is smaller than delta over two, if the error e, then noise is smaller than delta two. Then if you round this vector to the closest integer, so component wise, one coordinate at a time, you will remove the error and recover the original message.
00:13:28.764 - 00:14:01.384, Speaker B: Now it's easy to see how this very simple encryption scheme is also homomorphic. It's not fully homomorphic. I mean, in fact you can make it into a fully homomorphic scheme. But here I'm just showing you that it's a parse addition. So addition is almost trivial. So if you add up to ciphertext, a ciphertext c zero that encrypts the message m zero, and a ciphertext c one that encrypts the message m one, then when you adapt and ciphertext are matrices. So you just perform a normal standard matrix addition.
00:14:01.384 - 00:14:55.926, Speaker B: If you factor out the s and delta, you collect the like terms. You'll see that the sum of two ciphertexts is an encryption of m one plus m zero, with an error which is the sum of e one plus e zero. So if the original input noise was less than delta four, then the result in ciphertext is an error which is less than delta two, and you can decrypt the final result. Now this very simple property also highlights a limitation of this type of cryptography. Errors build up so the noise gets bigger. So for example, if you perform three additions instead of two, then their error may become bigger than delta two, and then decryption may lead to the incorrect result. So it's a very limited form of homomorphism.
00:14:55.926 - 00:15:45.048, Speaker B: I didn't show you how to do multiplication, but multiplication has the same kind of issue, and the error grows even faster than by addition. But there is this fundamental difficulty of error growing out of bound. Now this is precisely what gentry solved by introducing this bootstrapping technique as a technique to reduce the amount of noise in a lattice based ciphertext. This was done as follows. Assume that you have a schema that can support operations, but only up to a certain point. It supports operations of a certain size, but then beyond that, the error may become too big and you cannot keep computing. You want to reduce the amount of noise in this ciphertext.
00:15:45.048 - 00:16:19.090, Speaker B: So what is suggested is to look at the decryption function. So, decryption function takes a secret key and a ciphertext. Usually we think of this as a function described by the secret key which operates on the ciphertext as an input. Now we want to look at this by reversing the role of the two inputs. Think of decryption as a function that is described by a ciphertext. Every ciphertext describes a corresponding function, and the function takes as input the secret key. And what it does is just to decrypt the fixed ciphertext with that key.
00:16:19.090 - 00:17:36.242, Speaker B: Now why is that interesting? It is interesting because it gives you a way to compute the identity function, which may seem trivial, but in a way that improves the quality of the ciphertext. Now, using the previous definition of correctness that I gave before, if you evaluate this function fc on input and encryption of the secret key. So now the input is to this function is the secret key, we give it to it in encrypted form, and then we evaluate this function f homomorphically, so they will still decrypt, so it will produce the result which is the original ciphertext. M the output of decryption, it will produce this value in encrypted form, because you are performing this computation homomorphically. But the amount of noise in the final result does not depend on the input ciphertext. The error in the input ciphertext is being, so to speak, decrypted away. And the noise in the result of the evaluation only depends on the noise in the encryption of the evaluation key, which is independent of the computation that you performed, leading to decipher text.
00:17:36.242 - 00:18:29.574, Speaker B: So this allows to set up the parameters of lattice cryptography appropriately, in a way that when you perform this, the error of your ciphertext goes down. So you can clean up a ciphertext, reduce the error and keep computing. For example, you can compute more and more additions. Now these techniques, this technique requires to publish an encrypted copy of the secret key of a scheme. Now, encrypting a key under itself or under the corresponding public key. So this classic problem in cryptography is called a circular security problem. So, is an encryption scheme still secure even if you publish an encryption of the secret key under itself? And the standard notion of security for encryption, the one that we know how to achieve, typically does not have this extra feature.
00:18:29.574 - 00:19:27.512, Speaker B: And addressing the circular security issue, which is required to apply joint resistance trapping technique, was a big open problem back in 2012, and is still today a big open problem in the area how to deal with circular security. So what I want to do today is to look at the fully homomorphic encryption problem in a way that sort of sidesteps the circular security. Is there a way to formulate solving circular security would be great. Of course, one way to address this is to prove that any fully homomorphic encryption scheme can be turned into a circular secure one. We don't know what the answer is. But for the case of simple non homomorphic encryption scheme, there are some theoretical evidence. There is some theoretical evidence showing that that's not possible.
00:19:27.512 - 00:20:07.932, Speaker B: Are black box operations showing that you cannot achieve circular security in as a black box way. But perhaps you can still do it based on a specific assumption, like the learning with error assumption used by cryptography and lattice based cryptography. And that's still an open problem. And so I want to take a different look at the problem of building a fully homomorphic encryption and try to identify what is this difficulty. So in order to that, I look at a different problem, the problem of composition. Consider the following setting. So you have a message m and you wanted to perform a sequence of computations on it.
00:20:07.932 - 00:21:05.098, Speaker B: First you want to apply a function f on it to get a new message f of m. And then you wanted to apply another function g to f to get g of f. Now this is a two step computation, and you can think of doing it homophobic. You first evaluate a function f homorphically on c zero. C zero is an encryption of the original input message. Then you run again the evaluation algorithm to evaluate homomorphically function g on c one to get a ciphertext c two. And assuming that the scheme that you're using is an encryption scheme which supports, according to the definition, given the homomorphic evaluation of both f, can you conclude that the result, if you decrypt c two, you get g of f of m, you get what you want, and the result is that the answer is that that's not necessarily true.
00:21:05.098 - 00:22:01.282, Speaker B: So that may not be the case. And the reason is, technically, if it is a lattice based solution, is because the error may get bigger, and then when you give it to g, the error is too big to perform the computation. But this something that can be traced to the definition in a way that is independent of the mathematical problems which are used underneath. So the problem is the following. If you look at the definition of homorphic encryption, so we have this picture, we have a message m encrypted to c zero ue function f, and we know that this output c one decrypts to f of M. Now, there is a mismatch between the output guarantee of this evaluation c one decrypts to f of M, and the requirement on the input to apply the homomorphic evaluation of g. Here you want f of M to be encrypted into c one.
00:22:01.282 - 00:22:45.006, Speaker B: You want c one to be the result of applying the encryption algorithm going up rather than the decryption algorithm going down. And it's easy to convince yourself that these are different properties. So saying that c one is an encryption of m one and send that to c one decrypts to m one are different properties, and the first property implies the second one that comes from correctness. It means that if you take a message m, you encrypt it and encrypt it. You get the same m, but in the other direction. If you start from a ciphertext, you apply the decryption algorithm and then you encrypt it again. Typically you will end up with a different ciphertext, if not just for the fact that the encryption is randomized, so you will not get the original value.
00:22:45.006 - 00:23:34.056, Speaker B: So there is this mismatch of input and output in the definition, which led me to propose a different definition, which is the following. Something I like to call fully composable homomorphic encryption, or composable fhe if you prefer. And this is the definition. So I require that for every ciphertext c, if you decrypt c and then you apply the function f, you get the same result as first evaluating the function f homorphically and then decrypting the result. So this is slightly different from what we had before. Notice in the previous definition. In the traditional definition, we are going up with the encryption algorithm, then we do homomorphic ablation and down, and we ask this diagram to commute here.
00:23:34.056 - 00:24:34.542, Speaker B: Also we are making a commutivity requirement. But what we do is to always start from the ciphertext and the properties are both described in terms of the decryption algorithm. So if you decrypt an, evaluate f, or evaluate f homorphically and then decrypt, you should get the same result. So in some sense, decryption commutes with function evaluation. And the nice feature of this definition is that now you have something composable. If you perform two computations in a sequence, first f and then g, the output guarantee matches the input requirement, and you can conclude that if your scheme is a fully composable homorphic encryption scheme, then you can do this. Now this is a very powerful property because it allows to, instead of fully, typically refers to the fact that you can compute arbitrary programs on encrypted data in fully homorphic encryption.
00:24:34.542 - 00:25:10.918, Speaker B: Here I'm just focusing on the composability. Once you have composability, you don't need to be able to evaluate arbitrary programs. You just need to be able to evaluate any small instruction set. The elementary operations of your programming language and then you can combine them any way you want. You can put them together to put arbitrary programs together, but that's not required to be analyzed in the context of the definition. Let me skip this. It's easy to see that one definition implies the other one that is fully composable is a strengthening of the previous definition.
00:25:10.918 - 00:26:33.860, Speaker B: But let me skip that and jump to the conclusion, which is so you can think of this definition as a different way to describe what is being achieved by this bootstrapping technique. So rather than thinking of it as a lattice specific method to clean up cipher text and remove errors, which are details of lattice based implementations, but things that don't even show up at the definitional level, there is no reason why homomorphic encryption schemes should have some kind of noise in them. Now you can think of the bootstrapping technique as a method to transform a scheme satisfying the traditional fully homomorphic encryption definition, where you go up right and down into the fully composable definition. The construction is exactly the same, so it is just the same as joint resolution. I'm just saying that I'm changing the problem that is being solved by that solution. You can think of it as a method to show that if you have a scheme satisfying the weaker traditional FHE definition, and the scheme is also circular secure, then you can combine, you can build a new scheme which is a composable fhe is a fully composable homomorphic encryption scheme. Then the proof goes, just as in the previous case.
00:26:33.860 - 00:27:39.126, Speaker B: But now you can think of the problem of solved by bootstrapping, not in terms of noise, but as a problem of connecting two different definitions. So you can ask without talking about noise or bootstrapping. If fhe, the traditional definition, is something that implies the composable fhe, is there a way to go from one to the other one? Given an arbitrary, fully homomorphic encryption scheme, can you turn it into a fully composable homorphic encryption scheme for a modest set of operations, say addition and multiplication, that can be used to implement arbitrary circuits. And notice that in this question there is no mention to circular security. So there is no need to prove that the scheme is circular secure. In fact that the scheme may not even be circular secure. And I'm pretty sure that if you can do this, then you can also modify the construction to make sure the final result is not circular secure, just using in some trick.
00:27:39.126 - 00:28:25.194, Speaker B: So it is a way to describe the problem without bringing circular security into the picture. And perhaps it could be useful to get a better understanding of the difficulties behind this open problem of basing fully homomorphic encryption on standard assumptions. Of course, if that's not possible, it would be interesting to show some kind of separation, showing, for example, that there is no black box construction of a fully composable homomorphic encryption schemes from the traditional homomorphic encryption schemes. So, and with this I will conclude the talk. I will skip the approximate encryption one and we can approximately go to lunch after this. I'll just show the picture.
00:28:37.874 - 00:28:53.426, Speaker A: So, I have a question. So can you do this composable thing for a class that's, would you get benefit for thinking about composable homomorphic encryption when you don't go for the fully? So if you restrict computations, yeah, yeah.
00:28:53.450 - 00:29:58.214, Speaker B: So you can use different classes of functions, and I mean, you can pose the problem with any class of functions that is closed under composition. You can apply the definition, you can also apply the definition to a limited class of functions that only supports bounded composition if you like. So the definition can be adapted to capture all of those things. So in terms of constructions and what you need to get to the final result. So if you solve the problem assuming circular security and using bootstrapping, then if you have an fhe scheme non composable, supporting essentially the decryption function of the original scheme, if using that, you can build a fully composable scheme supporting just additional multiplication or any other set of operations of your choice, then you would get the full composition a composable solution for the type of computations that are described by those operations.
00:29:58.874 - 00:30:00.294, Speaker A: Got it. Thank you.
00:30:06.234 - 00:30:39.956, Speaker C: I have a sort of a funny question about this, you know, in terms of the role that Lwe plays in fully homomorphic encryption. So I guess one could ask, why is it such a, you know, why does it play such a big role? And is it the, could it possibly be that the noise, which is such a big problem, is actually the feature that makes it possible? Or what is it that that's really playing this role? And how come this is so important in this?
00:30:40.060 - 00:31:17.224, Speaker B: Well, honestly, I don't believe, I think that noise may not be the correct intuition. I mean, that's what has guided lattice cryptography so far. But then when we abstract the problem and we try to understand, oh, what is the difficulty? Perhaps thinking about noise is not the right way to go. I mean, if I give you the code or one of these libraries implementing the current versions of fully homophobic encryption, I mean, go find where and what part of it is something that can be considered noise. So we know that encryption is randomized. So that's something that. I mean, there's no escape.
00:31:17.224 - 00:31:45.624, Speaker B: It has to be randomized then whether there is something that actually is noise or not. Yeah, maybe we should stop thinking about noise. Or you're basically asking if perhaps we should do. No, we should really think about noise and understand why noise is so fundamental. To me, noise seems something that is very specific to lattice cryptography. It's something that we hardly find in most other mathematical problems used for cryptography.
00:31:45.744 - 00:31:57.642, Speaker C: Yeah. So is there an alternate to Lwe for fully homomorphic encryption, then the noise? No, no. Is there another construction which doesn't go through Lwe?
00:31:57.778 - 00:32:26.738, Speaker B: No, no, no. So this current. So this talk was just about problems and definitions. I don't have any other solution to do this. But if you achieve these fully composable homorphic encryption, then whether internally is using something which is noisy or not, that's something that would be completely hidden by the definition. So it's the noise sort of disappears at that level. You can do composition in a way that is fully composable.
00:32:26.738 - 00:32:46.374, Speaker B: So noise is not something to worry about. So it would make it easier to use. But as it is based on what we know so far, I don't know if it helps to come up with a different solution. But, yeah, it was more of a way to get a better handle on the problem. Thank you. It.

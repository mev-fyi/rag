00:00:00.360 - 00:01:01.714, Speaker A: From where we stopped. So now, so now we will start, I will start talking about gradient flows in a very informal way. You will see much more on gradient flows in Cathy Craig's lecture tomorrow. But let me give just an informal introduction now. So, to gradient close in Elbert space. So let me now assume h to be so h ilber space. So if you want, you can still think h equal to rd in general.
00:01:01.714 - 00:02:11.336, Speaker A: So let phi be a function from h to r c one. And now given a point x zero in H, we want to define the gradient flow starting at x zero. So the gradient flow phi starting at zero. So the gradient flow indicated by gf from now starting from x zero is given by the following od, that is x at time zero equal to x zero, that is the starting point. And then the time derivative of x is equal to minus the gradient of phi at x of d. So let me illustrate this with a, with a simple picture. So this is our phi.
00:02:11.336 - 00:03:10.964, Speaker A: So in this case it's also convex, but it's not necessary convex. So this is our point x zero. And then the gradient flow follows the direction of minus gradient of phi. And so this is now an OD system. And let me do an observation. So, note that if X of T is a solution of Gf, it holds that it does the following. So we do the time derivative of phi along x of T, and we see that this is simply gradient of phi of X of T scalar product x dot of T.
00:03:10.964 - 00:03:54.594, Speaker A: And this is by definition of gradient flow minus the gradient of phi square. This is positive. So this is negative. And what is telling us this very simple computation is telling us that a, the function phi decreases along the curves x of T. And this is very important. And also tell us that d over dt of phi of X of T. So the time derivative of phi of X of T is equal to zero if and only if X of T is a critical point of phi.
00:03:54.594 - 00:05:17.356, Speaker A: So if and only if modulus of graphi at x of T is equal to zero. So in particular, so if Phi as a unique stationary and as a unique stationary point. So think to the case. So in this picture, this is our, our stationary point that is also a global minimizer. In this case, then we expect that as time goes to zero, x of t converges to this global minimizer x bar. Okay, now we want to give a meaning to this expression where we see that we are comparing x dot t to the gradient of a certain function on an inverse space. Let me change page here.
00:05:17.356 - 00:06:29.024, Speaker A: It is so, as a general fact, a given phi from h to r, we can define the differential of phi at x. This is a function from h to r s. So the differential of phi at x in the direction v is defined as the limit as epsilon goes to zero of feed of x plus epsilon, v minus phi of x over epsilon. And this, what is telling us, this is telling us that if phi is regular enough, then the map, the phi of x belong to the dual space h star. You have seen already all these notations in Sg Wilson talk on the first day. The differential is in the dual space. And on the other hand.
00:06:29.024 - 00:08:20.442, Speaker A: So on the other hand, if t x of t is a curve at values in H, then x dot of t is just a limit as epsilon goes to zero of x, t plus epsilon minus x of t over epsilon and this belongs to H. So we are comparing something that is in the dual of H and something that is in H. So we need. So to define a gradient flow we need to identify h and h star. And this can be done if we introduce a scalar product. So if we indicate by the brackets a scalar product on h times h, then we can define the gradient of fear as the unique element as the unique element of h such that the scalar product between radiant phi of x is exactly the differential of x in direction v for all v in H. Okay, in other words, this color product allows us to identify the gradient and the differential.
00:08:20.442 - 00:09:26.708, Speaker A: And there, and thanks to this identification, we can now make sense of x dot of t equal minus gradient of phi of x of t. So this all makes sense for now. Now. So to define the gradient flow of phi, we need a scalar product and then the gradient flow depends on the scar product. So to define a gradient flow so of phi we need a scalar product and then the granule flow depends on the choice of this color product. Okay, we will see it soon. So I will not enter in the question about how to construct solution to this problem because you will see this in the lecture by Katy Craig.
00:09:26.708 - 00:10:51.454, Speaker A: But also you have seen it in a way with an approach via implicit Euler in the crash course by Asher Wilson. So I will now focus on some features of these gradient flows besides the fact of finding a solution. So remark uniqueness and stability. So let phi be convex and x of t y of t. Solutions of gradient flow starting from x zero and y zero respectively, phi c one just to the manipulations. So if we do, if we do the time derivative of the norm of the difference of these solutions at mt, so the norm of x of t minus y of t squared. This is the scalar product between x of t minus y of t against x dot of t minus y dot of T.
00:10:51.454 - 00:11:46.706, Speaker A: And by definition of gradient flow, since they are both solution, this is minus x of t minus y of t. Sorry, it's a comma and grad of phi of x of T minus grab phi of y of T. And this is smaller than zero. Where this, this inequality comes from the fact, so comes from the convexity of female. So also this standard derivative is smaller than zero. And what is telling us, it's telling us that the gradient flow is unique and stable. So by stable I mean that effect zero and y zero are close.
00:11:46.706 - 00:12:27.744, Speaker A: Then x tie xt and yt remain uniformly closed for all times. And this is a very important feature of gradient flows. And now to go on, I need another definition. That is the definition of sub differential that we have also seen, some of you may also have seen in Ayesha Wilson talk. But just let me mention it again for having a self contained lecture. So, the notion of sub differential, generalize the notion of derivative to convex functions that are not necessarily differentiable. Think for example to the function modulus of x.
00:12:27.744 - 00:13:37.282, Speaker A: So let me now go to give a definition of subdifferential. So. So, given phi from rd to r convex, we can define the subdifferential of phi at x. So, the sub differential of phi at x can be defined as the set of all y in Rd, such that for all z we have the following. We have that phi of z is larger than phi of x plus y z minus x. And the sub differential of phi is the union on all x in Rd of the product x times dv of x. Okay? And this is contained in Rd times RD.
00:13:37.282 - 00:14:29.134, Speaker A: Now let me just draw a picture, because this definition will be even more clear with, with a picture. So what does it mean to be a sub differential of x? Suppose that you have a convex function that has a corner. So this is, this with a bit of imagination, from your side is a convex function phi. And this, in this point, the function is not differentiable. There is a corner. So then you can draw all the lines that are passing through x zero, so that are tangent. And so all these lines, so the slope of all these lines are in the sub differential, in the subdifferential.
00:14:29.134 - 00:15:34.390, Speaker A: So of course, this is a generalization of differentiability. So if phi is differentiable at x dot actually x bar, then the sub differentiable, the sub differential of phi at x bar is equal to the gradient of phi at x bar. So just for example, if you have the function modulus of x, this is zero and so the subdifferential, the sub differential at the origin is the set. So the sub differential of modulus of x at the .0 is the interval minus eleven. But this was already shown before. So let me now pass to an important example.
00:15:34.390 - 00:17:35.264, Speaker A: That is how to, let's say to see the heat equation as l two gradient flow of the Dirichlet energy. So example sl two gradient flow of the dhl energy. So now for this example we have h, that is l two over d. So note that we are in infinite dimension and our function is phi of u that is defined as follow is defined like as one half integral over rd of gradu squared in the x if u is in w twelve of rd and plus infinity otherwise. So the claim we call this so few, is the Dirichlet energy. So the claim is that the sub differential of phi at u is non empty if and only if Laplacian of um is in l two. And in that case the sub differential of phi at u is equal to minus laplacian of u.
00:17:35.264 - 00:18:50.380, Speaker A: So, to formally show a bit how to see this thing, let me just show briefly an implication. The other is very similar. So I wanted to let you still see the directional energy. So assume that the Laplacian of view is in l two. So now we use the definition of phi. So for any w we have that phi of u plus w minus phi of u is equal to the integral over rd to gradu scalar product graph w in the x plus one half integral of modulus of graph w square. And this, this latter quantity is always positive.
00:18:50.380 - 00:20:07.400, Speaker A: So this is also greater equal of the integral over rd of grad u scalar product grad w. And then integrating PI part, this is equal to minus laplacian of u w dx and now if you recall the definition of sub differential, you have phi of u plus w minus phi of u larger of equal of this. This quantity, and being in the differential would mean phi of u plus w minus phi of u larger of equal of the scalar product in l two between b and w. So let's say minus Laplacian of u plays the role of the v in the different definition of the sub differential. So you can see that we proved our implication. So this means that minus Laplacian of U belongs to the sub differential of phi at q. So when we add that, we can say that the gradient flow with respect to delta scalar product is eight equation.
00:20:07.400 - 00:20:57.996, Speaker A: That means that dt of u d of t belongs to minus the sub differential of phi at u of t if and only if dt of ut. Let me explicit also. The x variable is equal to Laplacian of u t of x. And this is a very simple example in the theory of gradient flow. But this is an l two gradient flow. So now we are ready for the very last part of this mini course, where I will introduce a differential structure on the space of probability measures, starting from the Bremeaux Brunier formula. That is a central formula for us.
00:20:57.996 - 00:22:08.604, Speaker A: And then I will introduce Otto's formalism, and this will allow me to show how to interpret data equation as gradient flow with respect to the bus and to distance of a certain function. This can be also done for other diffusion pd's, but we will not see it today. And again, all the computations are really formal, and you can see a more rigorous version of this in the next lectures and also in the books by Ambrosio G by Ambrosio, Gili, Savare, and in many other other places. So let me now start with the benamubinia formula. Let me go away. So, continuity equation. And okay, so now we consider omega in RD convex.
00:22:08.604 - 00:23:12.686, Speaker A: Also, omega equal to Rd is admissible. But keep in mind now, omega convex subset of RD. Set root zero bar to be a probability measure with finite second moment over omega and v. The vector field so goes from zero t times omega in Rd, v is smooth and bounded. So here, bounded, but it's not needed. It's a bounded vector field tangent to the boundary of omega. So if this is omega, and this is the boundary of omega.
00:23:12.686 - 00:24:14.578, Speaker A: So this is omega. At each point, we can draw the normal vector that is nu. And then we have that at each time the vector field is tangent to the boundary of omega, then what we can do is that we can associate a flow to the vector field phi. So let x of t be the flow associated to v. That means that we have that x dot of t, little x is equal to the vector field phi at time t. At position capital x of t, little x, and the starting point of capital x of zero, little x is little x, and then set.
00:24:14.756 - 00:24:16.234, Speaker B: Michaela, can you hear me?
00:24:16.574 - 00:24:17.206, Speaker A: Yes.
00:24:17.310 - 00:24:30.974, Speaker B: Yeah. Can you clarify how you define the vector field inside outside the boundary? So here you just say tangent to the boundary of omega, but is just anything inside, outside.
00:24:31.134 - 00:24:32.598, Speaker A: I'm not considering anything.
00:24:32.646 - 00:24:34.274, Speaker B: So inside.
00:24:36.894 - 00:25:14.522, Speaker A: Inside omega. No, I'm not saying anything. Now, is a general vector field. I'm not saying how it is defined inside omega. So I'm just saying that to each to any smooth vector field I can associate a flow. I want it tangent because in a sense I want nothing to escape from omega. Also because these measures with some second, with the second moment bounded.
00:25:14.522 - 00:26:34.304, Speaker A: And we want to keep also this other measure that I'm defining now rho t in the space of probability with second moment bounded. So we set now rho t to be the measure that is obtained from rho zero bar. If we do the push forward through x of t, so the map x push forward rho zero bar. And we can say that this again still belongs to the space of probability measures with the second moment over omega. And if we call vt our vector field, just I put the peddx t for because it's here easier than the continuity equation. That is dt rho t plus divergence of vt rho t equal to zero. This is ce old in the sense of distributions.
00:26:34.304 - 00:28:31.504, Speaker A: This, I'm sorry, with also the constraint that Bt scalar product new on the boundary equal to zero. This holds in the sense of distributions. So now we are ready for the definition of action of this couple rho t and b t. So definition here the term action really reminds what happened in classical mechanics, and it's actually the same. And it's very natural also to see how this will be linked to the Wasserstein two distance. So given a pair rho t v t, solving the continuity equation with mu equal to zero on boundary of omega, then the action of rho t is the following functionality defined as follows, is the integral in zero between zero and one of the integral of omega vt of x squared root t of x dx and dt. And with this definition we are now ready to introduce the Bernamon Brunier formula that relates the action with the continuity equation and also with the wassers n two equation.
00:28:31.504 - 00:30:22.224, Speaker A: And as you may remember, the action function in classical mechanics are also used as a minimizer, let's say along along paths. So this is the same, the very same spirit. So theorem so given now row zero bar and rho 1 bar in the space of probability measure over omega. With second finite moment, it told that the two Wasserstein distance squared between rho zero bar and rho 1 bar is the infinum of what of the action with the constraint that rho zero is equal to rho zero bar, rho one is equal to rho 1 bar, and that rho t and v t satisfy the continuity equation dt plus divergence of rho t b t equal to zero and dt dot mu equal to zero on the boundary of omega. So this is a specific link between the action and the busses and to distance. And the quality happens if rho t. So the quality if rho t is at bust geodesic as we presented it before.
00:30:22.224 - 00:31:58.414, Speaker A: And vt is vector field such that the flow associated to bt satisfies xtx equal t t of x plus one minus t x. And that is exactly what what we have seen before for the jurassics in wasserstein. Now with this great formula we can start a reasoning to arrive to Otto's formulation. So to Otto's definition of vast halar product and of gradient flow in vast time two. So let me start again from this definition. Let me write it again more explicit. So wasserstein two between square between zero rho zero bar rho 1 bar this is the infimum over rho t v t integral between zero and one of integral over omega vt squared rho t this is tx, this is dt such that we have the continuity equation.
00:31:58.414 - 00:32:47.844, Speaker A: So dt I will not write it all the time. So dt rho t plus divergence of vt rho t equal to zero. And then we have vt scalar product with nu. So vt tangent to the boundary and rho zero equals zero bar and rho one equal rho 1 bar. Now we have two minimization, one minimization over rho t and one minimization over vt. And one can prove that since one of the constraint is let's say we are minimizing also over vt. So the vector field and we are minimizing upward of integral on omega.
00:32:47.844 - 00:33:15.064, Speaker A: So probably it's better if I copy paste. Let me see. No, probably I'm too bad with the other. So all this. But next time I will not copy paste. I'm sorry, I did a mistake. So I pay my laziness.
00:33:15.064 - 00:34:46.728, Speaker A: So such that divergence of vt rho t is equal to minus dt rho t and vt new equal to zero. And all this is in the t. Now we have a nice expression here inside the time integral that is this one. And we can select this expression to be the norm, to be the norm of dt rho t at the point rho t squared. So then after this, for the minimization in rho t we need to add that root zero, that rho zero is equal to rho zero bar and rho one is equal to rho 1 bar for the second minimization. So now we use that for each time t given rho t and dt rho t one can minimize with respect to all vector fields such that the divergence of rot vt is equal to minus dt of rho t. So therefore we can define the wasserstein norm of the derivative of dt rho t at rho t in this way, as I, as I, as I mentioned so in pink.
00:34:46.728 - 00:36:07.674, Speaker A: So take this, the Wasserstein norm, and once we have this fastest time norm. So let's say we can then define also a gradient from that. So in other words, thanks to the continuity equation, at each time t, we have a constraint of the divergence of bt routine that allow us to rewrite the benamubier formula in this way. So we have w two distance between rho zero and rho 1 bar to be the int on rho t of integral between zero one of the fastest time norm of dt rho t squared at the point rho t in dt such that rho zero equal rho zero bar and rho one equal rho 1 bar. And this is veramo premier. So now, after some computations, it turns out that the optimal vector field vt is given by a gradient of a function, if you want, and if we are done, I will show you the computation in the end. But I keep these computations, let's say only if we have time for now.
00:36:07.674 - 00:38:21.602, Speaker A: So let's just, let's just take for good that bt is given by a gradient of a function psi psi t. And here again we see the special role of the gradient of functions for minimizing, because vt is the optimal so the optimal vt, it's given by the gradient of psi t. So we get that the wastestine norm of dt rho t at rho t squared is equal to the integral over omega of gradient of psi t squared rho t dx, where psi solves an elliptic Neumann problem. This of course, assuming that rho is nice and smooth. So psi solves psi t solves divergence of rho t gradient of psi t equal minus dt of rho t on omega with the constraint, with the Neumann with the Neumann condition that we have zero condition, so on the boundary. And this problem admits a unique solution up to constant, so exist unique solution up to constant. So more generally now we can say that given rho a probability measure over omega h, a function from omega to r such that the integral over omega of h is equal to zero.
00:38:21.602 - 00:39:26.658, Speaker A: And this condition is just to ensure that the elliptic problem as a solution. So h will be here, this will be the h that we see now, and we want h to be to have integral zero, in this case of dt rho t. The condition was automatically verified because this is the derivative in time of rho. But the integral over omega of rho is equal to so the derivative is zero gives zero. So it's fine. And we can define the wasserstein norm of h at rho squared to be integral over omega of grad psi squared rho dx, where psi solves divergence of rho grad psi equal minus h with Neumann boundary condition. Okay.
00:39:26.658 - 00:41:22.286, Speaker A: And of course once the norm is defined, we can canonically construct a scalar product. So definition so given now h one and h two from omega to r both with integral zero, so integral over omega of h one equal integral over omega of h two equal to zero. So we can define the vastness color product of h one and h two at row. So define the bus system in the following way. So we take h one h two scala product through to be integral over omega of grad psi one scar product grad psi two rho dx, where we have the equation satisfied by psi one and psi two, that is divergence of rho grad of psi I equal minus h I on omega. And we have as before d psi I over d nu equal to zero on the boundary I equal twelve. So this is the definition of Wasserstein scalar product that I know that looks really counterintuitive, I mean, because of this, of this complicated formulation.
00:41:22.286 - 00:44:02.134, Speaker A: But I hope that the flow of total make sense. So let me now go on from that, because once we have a scalar product, as before, we are allowed to define the gradient of a functional in the Wasserstein space, because the goal is to define gradient flows in the Wasserstein space. So now given a functional capital f from the space of probability over omega or r, so its gradient with respect to the Wasserstein scalar product at row bar is the unique function grad w two f of rho bar. Of course, if it exists such that we are that graph over in verse ten, two of f at rho bar against variation of a curved rho epsilon evaluated that epsilon equal to zero. This is at the point rho bar is d over d epsilon evaluated at epsilon equal to zero of the functional of rho epsilon for any smooth curve rho epsilon from minus epsilon zero, epsilon zero to p omega with rho zero equal rho bar, because everything now is centered in rhobar. And so this is the fundamental definition that we needed. And now the next goal is to find an explicit formula for the Wasserstein gradient of a function, because this is not yet clear really what it means.
00:44:02.134 - 00:46:48.062, Speaker A: So if we denote by delta of calligraphica of rho bar delta of rho, the l two first variation of f. This is simply the function in l two. So this is the function such that d over d epsilon evaluated at epsilon equal to zero of f of rho epsilon is equal to the integral over omega of this first variation d f of rho bar with respect to rho against d rho epsilon d epsilon at epsilon equal to zero in the x. And recalling the different the definition of gradient, since this is equal to this is equal to the grid to the scalar product between the gradient of inverses and two f of rho bar against these variations, this is equal to grab w two f of rho bar against this variation curve, the rho epsilon over epsilon in the epsilon against rho bar. And now if we denote by psi the solution of the of the equation divergence of grab psi rho bar equals minus zero epsilon over d epsilon evaluated epsilon equal to zero. What we can recognize, so this we again zero Neumann boundary condition. What we can recognize is that now we'll try again to copy paste.
00:46:48.062 - 00:48:29.284, Speaker A: Let's see if I manage we have that the gradient in busses time two of calligraphy f is equal to minus integral over omega of the l two gradient l two first variation of the functional at rho bar with respect to rho divergence of grad rho bar in the x. And this is exactly, I'm sorry, this is with a plus. This is a bit plus and then minus because we integrate by part and this is integral of the divergence. So of gradient of this first variation scalar product against rho bar dx. And this will really ease the definition of the Wasserstein scalar product. So we can deduce finally that the gradient in Wassersten two of the calligraphic f of rho bar is equal to minus divergence of grad of the first variation at rho bar of our functional rho bar. And this is the formula that we needed.
00:48:29.284 - 00:49:48.864, Speaker A: And just let me now conclude with an example. So now if f of rho is the integral over omega of u of rho of x dx. So it has a simple form with u that goes from r to r. Then for any smooth variation epsilon in rho epsilon, it holds that d over d epsilon epsilon equal to zero f over rho. What it is is simply d over d epsilon of integral over omega of u of rho epsilon of x dx. And this is equal to integral over omega of u prime of rho bar of x d rho epsilon over d epsilon at epsilon equal to zero in the x. And you see now that this is exactly the l two first variation of the functional that we were discussing above.
00:49:48.864 - 00:51:35.234, Speaker A: And so we have that the l two first variation of f at rho bar is equal to u prime of rho bar of x. And therefore, the gradient in bus sn two of the functional can be rewritten as minus divergence of rho bar, gradient of u prime of rho bar, that is, minus divergence rho bar u second at rho bar graph rho bar. And an example now that is very special is the case where u of s is s log s, so f that is equal to the integral so f of rho that is equal to the integral over omega of rho of x log row of x. This is the entropy function. Then, with this special. In this special case, then u second of s is one over s. Therefore, the gradient, the wasserstent two gradient of the entropy functional at rho bar is equal to minus Laplacian of rho bar.
00:51:35.234 - 00:53:31.180, Speaker A: So, to conclude, given f. Oops, I did a mistake. Given f from PI two over omega to r, then a curve of probability measures rho from zero t to p two over omega is a dragon flow of f in busses time two starting from rho zero bar. If dt of rho t equal minus gradient in bassett of f of rho t, and root zero equal root zero bar. And this tell us that the vastest time gradient flow of the entropy is data question. That is dt rho equal minus grad vast sn two of f of rho, and that is equal to laplace of rho. And this was what I really wanted to say to give a sense to this, to our class, to arrive to see something important.
00:53:31.180 - 00:54:06.104, Speaker A: Although all this computation were really, really formal. Now, I don't know if we have time, but it's really not necessary. If you want me to explain it, I can show you why. If the vector field is a minimizer, then it is the gradient of a certain function p. But this is mostly up to you, because we are already late on the schedule due to my technical problem. So I again apologize for the technical problem that we had in the beginning. I hope now it was okay.
00:54:13.244 - 00:54:19.664, Speaker B: Excuse me, how long would it be to present the laptop? It's a matter of two or three.
00:54:21.524 - 00:54:32.922, Speaker A: No, it's not really a matter of two minutes. So it's fine. We can skip it. It's nice to have a jolly that one can skip if it's late.
00:54:33.098 - 00:54:49.614, Speaker B: Okay, so thanks. Any questions from Jenna? Okay, so I have no questions. Thank you. It was very clear.
00:54:51.334 - 00:54:55.710, Speaker A: So thanks again and have a nice continuation. Bye.

00:00:00.120 - 00:00:09.954, Speaker A: Right, let's start. So in the first talk of the last session, Ryonyan will tell us about explaining softholding using causal reasoning.
00:00:12.014 - 00:00:54.414, Speaker B: Hi everyone, this is Jung Yang. Today I'm going to talk about our recent work in the past year about explaining cell solving using causal reasoning. This is a joint work with Arijud Shah, Theodore Baluta, Matthew Sod and Gudeep Samir. I think RJ and Gudeep are in the audience. SAS solving has been making significant progress in the last few decades and people are now using satisfactor as a powerful black box in managed systems. And every year in a SAT competition, new solver come out and a new technique come out and more and more hard benchmarks can be solved. However, as Karin indicated in his talk, we don't really understand how satisf works.
00:00:54.414 - 00:01:32.618, Speaker B: We don't know why the powerful tool we built performed reasonably well on these hard mp problems, and we don't know why sometimes it gets dark on simple benchmarks with even hundreds of variables. In this talk, as a first step towards this end, we use cause reasoning. Try to understand how satisf works. You may argue that actually we learned, we have known that how the satellite works. There are some rules of some. Like we know clauses with low LPD have greater utility. Here, LBD is short for literal blocks distance.
00:01:32.618 - 00:02:30.950, Speaker B: It defines the number of distinct decision levels of literals in a clause. And we use utility as a measurement of how useful the clause will be in the future solving. We will come back to its format definition later in this talk. Now, right now, let's assume like utility as a measurement of the usefulness of the clouds, and the higher the value is, the more useful it will be. And yeah, you may argue that we have no clouds with low LPD clause where low Lp value have greater utility because we have used this heuristic in class deletion heuristics, and we implemented the resulting solver and found that the solver performed pretty well. Right? And also you can argue that a small clause has greater utility and we have in modern satisfactor, we always prefer the small clause which contains like maybe one literal or two literals, but for the large clause it contains more than like five or six literals. We will remove it shortly.
00:02:30.950 - 00:03:48.764, Speaker B: Yeah, you may argue that we have known we ran a lot, a lot of empirical experiment and we find this result. But does it mean we really understand how sad style works? Here is an example. So in my hometown, there is a strong correlation between the sales of ice cream and sales of the air condition. During summer people start buying more and more ice cream and also the sales of air condition increases and in the winter people don't want to buy more ice cream and also the sales of the air conditioner drops as well. And apparently we can find a strong positive correlation between the sales of ice cream and the sales of air conditioner. If I own a shop owner store like to sell the air conditioner, I can use the sales of ice cream as a good predictor for the sales of air conditioner. But does it mean I really understand how that works because in reality we know that the cells of the ice cream does not cause the cells of air conditioner, right? And if we look at this scenario for a little bit, well we realize that temperature is a real reason because temperature causes both the cells of ice cream and cells of air conditioner.
00:03:48.764 - 00:05:11.804, Speaker B: This may also happens in contact with self solving. There may be some potential factor which affects both LPD and cloud tables that we don't know. Let's come back to the sad solving in order to understand how the SAS solve works, we collected a bunch of the statistical data about the factors inside cell solving. For example, the propagation it defined represents the number of propagation the solve, the clause was involved and use the recent it represents a number of conflicts since the clause was used in the previous conflict conflict analysis, this variable factor used the recent representative. At this point we're looking back what was the last time this clause was used in the conflict analysis? And then we calculate the difference between the time step and we found that there was a strong correlation between them because if the clause was used more often in propagation, we found that this clause was also used more recently in the conflict analysis. But does it mean that we understand why we have this kind of correlation? This works why we can use a propagation as a good predictor for the user. Use the recent if we use cause reasoning, we can find that actually there is a potential factor LBD, which causes both propagation and use recent, which is a real explanation for this correlation.
00:05:11.804 - 00:06:15.954, Speaker B: In order to identify this kind of potential factor and also better understand how the SAS solver works, we propose our approach based on the causal reasoning. And here I show the overview of our approach. Our approach start with data generation because in order to understand how the solver works, the first step is to generate the data about the factors we want to analyze. We ran a set solver on a bunch of benchmarks and we collected the data during the solving like what's a branching risk that you are using and what's the size for the clause and what's LBD of the clause and the clause utility. And after we collect this statistic data about factors, we can run some standard structural learning algorithm to learn the causal relationship between these variables. Then cause a graph as shown here. It represents that LBD causes both propagation and use recent, and propagation causes the user recent.
00:06:15.954 - 00:07:06.452, Speaker B: And after that we can encode the question of our interest into a causal query. And for example, if you are interested in the question which clause with low or high LBD has greater utility? We can encode this problem into this question into a causal query asking for the impact of the LPD on clause utility. After we get the query, we can use causal reasoning to calculate the causal effect and use the result to answer the original question. In the following slide, I will look into each component in detail. Let's start with the data generation. If you want to understand how sas all work, how to generate the data about the factors we want to analyze, we collect them. We use unsat formulas.
00:07:06.452 - 00:07:41.854, Speaker B: Later I will explain why we need unset formulas. We collect this and set formulas from the SAG computation benchmarks over the past few years, and we run a set solver and collect a bunch of data during the solving, such as a branching heuristic and cloud size, the LPD of the cloud, and also the time and means like how long has this clause existed and also clause utility. Here we give formal definition for the class utility. It represents the number of times a clause has been used in asset proof during the next 10,000 conflicts.
00:07:42.014 - 00:07:43.474, Speaker C: What does maple mean?
00:07:46.014 - 00:07:54.354, Speaker B: Maple is the heuristic used in the maple syllabus. The question is, what does the maple mean? Maple is a branch heuristic used in maple sylver.
00:07:59.974 - 00:08:06.114, Speaker D: What exactly does used in onset? You'll have to repeat, what does used in onset proof mean?
00:08:06.454 - 00:08:34.370, Speaker B: Using insight proof. Oh yeah, I will explain more. Yeah, so in the insight probe. Yeah, we have to highlight that using the insight probe is different from the use in the conflict analysis. That's why we need ansight formula. We start from the final empty clause and we run the develop proof and we find out how many times this clause was actually used in the proof. Sometimes you generate some clause.
00:08:34.370 - 00:08:36.574, Speaker B: We should not use it in a final proof.
00:08:38.754 - 00:08:42.654, Speaker D: But is this the actual SATs solver proof or is it what you get from drat trim?
00:08:43.594 - 00:08:45.454, Speaker B: Yes, it's a SAS solver proof.
00:08:46.754 - 00:08:52.810, Speaker D: It's the rad trim. Okay. Which is okay, which is very different from what the SATs solver did, but. Okay.
00:08:52.882 - 00:10:06.524, Speaker B: Yes, and we, yeah, so that's why we have to collect this data after solving is finished. Starting from the conflict of empty clause and use derive proof to figure out what's the value for the clause utility, and we use this value to indicate the usefulness of the clause. And note that we generate the data using the crystal ball framework, which is needed by mate. After we get the statistic data about the factor we want to analyze, we can use a standard structured learning algorithm to learn the color relationship between these variables, which is Verizon by the color graph. The color graph encodes which variable causes another variable, but which variable does not. For example, in this graph, the LBD represents the LBD of the clause and size represents the clause size and the vertex propagation represents the number of times the clause was involved in propagation and utility represents the clause utility, and a directed edge represents the causal causal relationship between two factors. For example, the direct edge from LBD to propagation.
00:10:06.524 - 00:11:34.612, Speaker B: It means that LPD causes propagation. The causal graph actually gives us a good visualization of the what's the relationship between these factors and how these different components different factors interact with each other. However, inside the causal graph we only know the qualitative relationship between these variables. For example, we only know that LPD causes propagation, but we don't know that what's the exact impact of LBD on propagation? Is that very large or is that very small? And in order to get that quantitative relationship, we have to encode the question of our interest into a causal query and then use causal reasoning to calculate the causal effect and use that effect on the original query. Now let's start from a simple example to look at what kind of query our approach can handle. Remember in the previous slide which I showed that we have the assumption in the modern satisfactor the clauses with low LPD has greater utility, which motivates us to ask the following question, which clause with low or high LBD has greater utility? This question can be encoded into an ate query. An ate in the context of cause raising represents every treatment effect, and this expression at x one ab represents the effect on the effect on the factor y.
00:11:34.612 - 00:12:20.384, Speaker B: If the factor x changes from b to a. In our example, the ate query incosite what is the change of the class utility if the LPD increases from one to two? If this change is positive, it means that as albidi increases, the class utility increases and therefore a large clause with high LPD will have a higher utility, which disproves our assumption. But if the if this change is evaluated to be negative, it means as albeit increases, the class utility drops. And we can infer that the low LPD clause will have a greater utility, which will match our observation. A question about the causal graph.
00:12:23.884 - 00:12:29.520, Speaker E: So how do you get the direction in the causal graph? How do you know in which direction the causality goes?
00:12:29.652 - 00:12:32.504, Speaker B: I mean, call the learner direction in a color graph.
00:12:32.664 - 00:12:43.232, Speaker E: Yeah, but what in your data supports this directionality? So how can you get this out of the kind of data that you, you generate? You're not doing interventions, you're not, yeah.
00:12:43.248 - 00:12:44.760, Speaker B: We are not blocking a clause from.
00:12:44.792 - 00:12:53.404, Speaker E: Propagating to see what the effect is. But so you're, so how do you, how can you, conceptually, how can you get that out of the kind of data you have?
00:12:54.624 - 00:12:57.616, Speaker B: I mean, how to get the data or how to learn a direction from the data.
00:12:57.680 - 00:12:58.760, Speaker E: So if you have that data.
00:12:58.832 - 00:12:59.170, Speaker B: Yeah.
00:12:59.232 - 00:13:02.142, Speaker E: How can you see in it in which direction? Causality?
00:13:02.278 - 00:13:21.542, Speaker B: Yes, we can. So there are two kind ways to get to the direction. The one is you said that we can use intervention, but instead of sets our many variable factor, we cannot intervene. The other way is to learn from observational data. That's what we did. And there are a bunch of standard method you can learn from the observational data. For example, there will be one called a hill climbing.
00:13:21.542 - 00:14:42.008, Speaker B: We first start from empty graphics. On every step we add, remove or reverse an edge and to see that if the graph fits the data better, and we repeat this process until converge to a stable outcome. Now let's look at another type of question we can answer. Yeah, so in a modern setup solver, uh, for the data, for the cloud deletion heuristic, we use a multi tile hierarchy that is like for the low LB clause, we think that they will be useful in a long run and we store them in the first tire, which will be preserved for a long time. However, for the high LB clause, which we preserve in the second, store in the second tire, and which will be preserved for short time because we think that there will be no use in the near future. And which motivates us to ask the following question, which clouds with low or high LPD experience a rapid job in utility overcome? If you look at this question, it's asking for the causal effect of time on clouds utility. But here we have an extra condition that is either low or high LPD.
00:14:42.008 - 00:16:11.424, Speaker B: And in order to answer this question, we have to encode it into a conditional query that is called kit katie. In terms of the cause, reason is short for conditional average treatment effect. It means k of xyC, ab it means that we have ate query given a condition C. Condition C and in our example it means that like for low LBD is our condition and we encode it, LBD is no more than six when the RBD is normal six, what's the change of the class utility as the time increases from zero to 10,000? If this change is positive, it means that for the low LPD clauses, which I'll be less than or equal to six, its utility does not drop over time. But for the high LPD we have the condition LBD is greater than six and we encode it into the CAD query to calculate what's the change of class utility as time increases from zero to 10,000 when LBD is greater than six. And if this change is negative, it means that for the high LBD clause its utility indeed drops over time. Our final evaluation is indeed negative for the second one, positive for the first one.
00:16:11.424 - 00:17:17.040, Speaker B: It verifies our observation in the causation heuristic in modern cell solvers. Moreover, we can have, we can have our approach support. Another candle question I heard this story from mate that in the previous implementation of the glucose, they are intended to preserve the large clothes for fixed LBD. Usually we think like a small clause is more useful, but in the previous implantation of glucose for the closet with same RBD, they preserve. They preserve the intended preserve the large cloth. They found that this kind of unintended implantation surprisingly outperforms their intended implantation and which motivates us to ask the following question. Which type of clause, large or small, has greater utility? And what if the LPD is fixed? And this question actually has two sub questions.
00:17:17.040 - 00:18:38.064, Speaker B: The first is ask what's the effect of clause size on clause utility that can be encoded into an ate query? Similar to the question one, it means what's the change of the clause utility when the size increases from one to two? If this change is negative, this means as we increase the size of clause, the utility jobs, and then we can infer that the small clause has greater utility. But in order to answer the second question we need, there is a special condition when albedo is fixed. In order to answer this kind of question, we come up with a query called acate, which represents the ate while the variable z is fixed. Others are similar to the ate. In our example, it means that when LBD is fixed, what's the change of the what's the change of class utility as the size increases from one to two? If this change is positive, it means that for the clauses with the same with fixed LBD. Large clause has higher has greater utility and if this evaluation is indeed positive, which will match our observation in the previous implementation of glucose. After we formulate all the question query, we can use causal reasoning to evaluate this query and get the final causal estimate.
00:18:38.064 - 00:19:52.510, Speaker B: If all of this estimate matches the inequality, we can answer the original question and in this talk we skip the details about the calculation of the causal effects because we are more interested in the answer. How is LBD defined when size is one? What is LBD defined when size is one? Okay, let's look at the answer to the question. To query, we start from the first question, which clause with low or higher bd has greater utility? In the previous slide we have encoded this question into the ATU query which is finally evaluated to be a negative number, negative 0.26 and the negative value tells us that as LBD increases from one to two, the clause rotated drops. Therefore, we can draw the conclusion that low LPD clause has greater utility. For the second question, which clause has low or high LPD experience a rapid job in utility over time which has been coded into two k queries. The first query is for the low LPD clause and our data.
00:19:52.510 - 00:21:25.506, Speaker B: It was evaluated to be a positive number, 0.38 and the positive number means that for the low LB clause its utility does not drop over time. The second key query is for the high LB clause which evaluation can get the negative result and the negative value tells us that for the high LP clouds its utility actually drops over time. Then we can draw the conclusion that high LPD clouds experience a rapid drop in utility over time, which matches our observation in the cloud deletion heuristic of modern sams solvers. Finally, for the last question, which type of cloud, large or small, has greater utility? What if the orbit is fixed? The first ad query is validated to be a negative value so we know that the small clause has greater utility and the second acad query is also evaluated to be negative value. So we know that as even for the clauses with fixed LPD, as we increase the size from one to two, the clause utility also drops so we can draw conclusion small clause still has greater utility even when the LPD is fixed, which disproves the observation in the previous implementation of glucose, but it matches the implementation in other modern SAS solvers. Besides this three kind of question, actually our approach can be used to answer other interesting questions.
00:21:25.506 - 00:22:39.022, Speaker B: For example, we can compare the impact between two factors and withdraw the conclusion LBD has greater impact than cloud size and also it can be used to identify the new factors for the. For example, for the clause deletion heuristic. Besides the widely used factor LBD cloud site and clause activity, we found that propagation has the greatest impact on cloud utility. Maybe it can be used to design a new heuristic for cloud detection heuristic and moreover we can use it to investigate the interaction between different heuristic and we found that for branching heuristic, maple leads to greater utility than basic and for restart heuristic, we found that lube a leads to the greatest utility against the LP based and geometric restart heuristic. In the future, we plan to study the cause effect on the solving time. We want to investigate which heuristic and which factor has a positive effect on the solving time and which, which here is still which factor has a negative impact on the solving time, which can help better help us understand how the SAS solver works. And also this framework can be used to study the hardness of benchmarks.
00:22:39.022 - 00:23:19.514, Speaker B: We can study the color effects of the attributes of benchmark on the solving time. And this kind of attributes of benchmark can include a number of variables and number of closets for the formula and also the trivia of the primary graph or trivia of incident graphics. And it can be can help us to identify like which kind of benchmark, which kind of benchmark is hard for the multi solver solve and why, which kind of benchmark is easy to solve. We hope that our framework can help us better understand how SAS solver works and can motivate the design of new solver heuristics. That's all. Thank you.
00:23:28.824 - 00:24:30.884, Speaker C: Okay, I'm trying to remember the term, but anyway, there's something like temperature that Armin used in order to decide for restart. You just mentioned Luby and geometric and things like this, but. But it was something like how many short clauses have been derived in the last thousand conflicts or something like this. I mean, when you get a conflict, sometimes you get long clauses, sometimes you get short clauses. And so Armen had some kind of way of saying that if you know, if you're going good, then don't restart. But if you haven't come up with anything, then you're probably in a bad part of the search space. You might try to make a query, something like that.
00:24:30.884 - 00:25:55.374, Speaker C: But the main thing I want to know, usually when I'm running a sat job, is it close to finishing? You know, I can look at things and saying how many propagations do I do per conflict? Or something like this? Or I can say how many unit clauses have I derived, but it's been sitting there for half an hour, everyone. Is there anything I could measure that would tell me that I'm getting closer to the answer? And so far I haven't found that magic thing. Every once in a while, I look at the result of a two hour run, and I've been printing statistics out every 10 seconds, and I look at the statistics that happened during the last minute before it finally succeeded. But I haven't been able to notice a pattern where I could predict that I'm getting somewhere, because, of course, sometimes, or a lot of times, it just times out. So I'm just sort of encouraging you to try to study something that gives an indication as to progress.
00:25:57.554 - 00:26:20.754, Speaker B: Yes, I think that's very important. If we can have come up with the indicator for the program, I think we can use this statistical. I can, like, we hope that we can use this statistical analysis to find this kind of indicator for the progress inside of SAS solver. Some. Sometimes I think it's very not that easy to define what's the progress.
00:26:25.974 - 00:26:41.980, Speaker C: With the look ahead solver, I have no problem. I sort of go lexicographically through everything, but with the CDCL server, I don't have any monotonic indication of how many cases I've looked at.
00:26:42.092 - 00:26:57.504, Speaker B: Yes. I think the first step is we have to have a clear and informal definition for what the progress is. Yeah, yeah, I still have to think about that.
00:26:58.184 - 00:27:23.904, Speaker C: Yeah. So try to find a combination of causes that that's highly correlated with progress. Anyway, it might be possible, by looking at your data, to figure some characteristic. I mean, I don't know, use deep learning or something that.
00:27:29.764 - 00:28:11.006, Speaker D: Three quick remarks. One thing that I think would be interesting if you would compare with there. I mean, previous work has been done on analyzing proof logs from SAT solvers to try to figure out and answer precisely these types of questions. So Laurent Simon has an old paper, post mortem analysis. We have a cocala Nordstrom paper in CP 2020. And another that, the second remark is that when you do this kind of analysis, it's kind of important that you actually analyze what the solver did. And one of the things that we saw in our CP 2020 paper is that the drat trim proof will be very, very different from what the solver actually did.
00:28:11.006 - 00:29:03.818, Speaker D: So if you're, like, trying to analyze solver performance, then you should not use the drat to improve. And then the third challenge, I think, for all approaches so far, which would be also interesting to talk about, is that. And the complaint we've been giving, which I think is justified, is that sometimes when you figure out, oh, this is better, this is worse. And then you talk to a Sat practitioner and they say, yeah, yeah, sure. But that's just because you're only looking at this heuristic that I have. It's for sat instances and you're only analyzing on Sat. So when we're saying like, this is bad and this is good, somehow we would need to also think about could we somehow do generate proofs for SAT instances and somehow analyze effect also on those instances? Because some heuristics, when you talk to the practitioners, they might tell you that this, I specifically expect this to be good for satisfiable instances.
00:29:03.818 - 00:29:13.030, Speaker D: And then in this kind of analysis, and also in our analysis, we won't see it because we're only running on unsat instances, I think the practitioner like.
00:29:13.062 - 00:29:18.274, Speaker B: Mate, they think like Satan, actually the same. Do you want to give comments?
00:29:19.574 - 00:29:42.850, Speaker F: I can ask two and three maybe, and maybe I can say something about what Don said. So regarding the D red proof. Yes, you told this to me. I didn't believe it for a year. And then I believe you now and it's a fraud proof now. And we have elaboration and all that stuff. We can rerun everything here and probably it will take a week or two and it will all overfront.
00:29:42.850 - 00:30:05.894, Speaker F: So we have fixed this issue. We recognize that you were right. So you were second. The third thing that you said about unsat versus sat and can we do this over SAT? And we can do this over Sat. And actually I did this already over drat trim. I hacked it so that it works on satisfying. You have to think a little bit about it and you can make it work.
00:30:05.894 - 00:30:21.014, Speaker F: It's not a big deal. Actually, it's a trick that I can explain in 2 seconds. Everybody will get it. It's not a big deal. And then it works over Saad and then you can do the whole thing. The whole thing. Just what you saw here, over sat instances just as well.
00:30:21.014 - 00:30:40.434, Speaker F: And we did it. So I can learn over sat if I want, but that's over Dirat. I haven't hacked frat yet. It's an interesting code base. One day I will understand rust and then I will, you know, but once I understand the compiler, which changes every week. So keep. I'll keep at it.
00:30:40.434 - 00:31:20.454, Speaker F: And finally, regarding what dawn has said about understanding statistics, and I actually agree with you that we need to use either machine learning to get there or some kind of experimental statistic, I mean, statistical analysis using sort of data digging, data exploratory data analysis, because we. The data. The problem is that the data is 100gb and no same person will be able to understand it. So we need to do something with it. And the best I personally could come up with was machine learning. And the best Jung came up with clearly is better. And his causal analysis, which I think is actually better.
00:31:20.454 - 00:31:36.474, Speaker F: But these are both to some extent automated methods with some human interaction doing it like by hand, is. I don't know if that's possible. Maybe somebody who is better at statistics will give me an answer.
00:31:53.934 - 00:31:54.734, Speaker B: I couldn't extend.

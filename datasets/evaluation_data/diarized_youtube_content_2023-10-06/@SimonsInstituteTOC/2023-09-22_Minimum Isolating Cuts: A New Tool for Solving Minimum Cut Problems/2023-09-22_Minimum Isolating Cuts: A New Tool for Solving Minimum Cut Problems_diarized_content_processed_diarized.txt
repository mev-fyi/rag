00:00:12.480 - 00:00:41.534, Speaker A: Okay, so welcome everyone, back to this afternoon session. So next talk will be by Jason Lee. He is a fellow here at Simons, and soon he will be assistant professor at CMU. So Jason Lee has done a lot of great works in graph algorithms, and today he will talk about isolating cut, one of the most beautiful new techniques in recent years that I like a lot.
00:00:41.874 - 00:01:19.024, Speaker B: Thanks. Adaptable and try. So this talk will be on isolating cuts, which I will describe as a new tool for min cut algorithms. And before I give the talk, I'll give a little disclaimer that all results discussed in talk will be in a static setting. So we will be, we'll make no mention of dynamic graph algorithms. But as we've seen in previous talks in this workshop, there's a close connection between static and dynamic graph algorithms. For example, we've seen that dynamic arms often use static arms as like during renew, during initialization, or as a rebuilding step, for example, rebuilding a certain data structure after some number, certain number of iterations.
00:01:19.024 - 00:02:10.584, Speaker B: And also static algorithms also use dynamic algorithms to speed up each iteration. But regardless, the focus of this talk will be not so much the setting itself, but the main tool that I'll be discussing, which is isolating cuts. So let's begin with some background minimum cuts. So a cut is a set of edges whose removal disconnects the graph in some way, and a minimum cut is a cut of minimum cardinality weight. The precise definition of minimum depends on the particular variant of minimum cut being studied. In this talk, all graphs are undirected. And we think of, we either think of the graphs unweighted with parallel edges or weighted with non negative weights.
00:02:10.584 - 00:03:07.086, Speaker B: And finally, so for example, in this case, uh, these are valid graphs that we'll be studying. On the other hand, we will not be studying direct to graph in this talk. So two classic variants of min cut are the global min cut, which is just the minimum weight cut, uh, that disconnects the graph in some way, and st min cut, which is a cut that given s, vertices s and t disconnects to two vertices s and t. And one classic result in this area is that by the max flow Mincut theorem, the St max flow equals the St min cut. In particular, any ST min cut can be solved by running max flow and then post processing in linear time. So, for example, in this graph here, the following is a global min cut. And here, this is the SD mincut for these vertices s and t.
00:03:07.086 - 00:03:54.986, Speaker B: And note that the St mainga is not necessarily the global. So in this talk, we'll be studying both the running times of these problems, but also the relationship between how these problems relate to one another. So here. So one classic and simple result is that there's a global Mincut algorithm that can be solved using many ST mincut calls. And here's the algorithm. So let's fix any s to be any arbitrary vertex and just find the St min cuts over all other vertices t and report the smallest of these cuts as a global min cut. And note that because there must be a vertex t on the opposite side of the global min cut, we will recover the correct global min cut.
00:03:54.986 - 00:04:48.264, Speaker B: And this is an algorithm that solves global min cut in n minus one calls to SD min cut, or equivalently to SD max flow. So, um, this is a brief like landscape of the historic history of global mincut. So first we have an algorithm running n minus one max flows. And then there's been, since then there's been specialized algorithms for global mincut that, um, for example in this, in these works they, they figure out ways to run max flow quickly. This, they figure out ways to speed up the max flows on each iteration. And then later on there's been more faster improvements that run independent of any maximal calls. And finally, a class of resolve cargo showed that there is a near linear time randomized algorithm to solve this problem independent of any max.
00:04:48.264 - 00:05:52.576, Speaker B: So one famous open problem that Carter post in his randomized global min cut work is can we obtain a deterministic global mint algorithm to match the randomized running time? But in particular, what's interesting is at that time, even for max flow, it was not known whether determinants of global min cut algorithm can rerun and can be solved in deterministic mass flow time. So recently there's been some exciting progress in this area. One classic result, which recently won the Fulkerson prize, is that the, the global min cut can be solved in near linear time for simple graphs. These are graphs that are unweighted with no parallel edges between vertices. This result has been improved and has been viewed in different perspectives. But again, these are simple graphs. And one result that we'll talk, we'll be studying this talk is that we showed the work with myself and demanipar negrahi.
00:05:52.576 - 00:06:49.924, Speaker B: We showed that there's a deterministic algorithm for global mincut that runs in poly log mass locals. Subsequently, this work by myself has improved the running time of the turbanistic global min cut all the way to almost linear, which matches the best running randomized algorithm. This should have been n to the one but the techniques are quite different and we'll mainly focus on the result version. And our main idea I want to study in this talk is the notion of isolating cuts. Formally, to motivate the notion of isolating cuts let's revisit the simple min cut algorithm from before where we just fix a vertex s and iterate over all other vertices t. And note that really all we need from this algorithm is to find another vertex t on the opposite side of the global min compound. If we can find such a vertex t then we have the global min cut.
00:06:49.924 - 00:07:42.530, Speaker B: And then the high level question we want to ask is how do we efficiently find two vertices on opposite sides of the global mean cut? Here's one simple observation. Suppose that we're also promised that the main cut is balanced and let's say it's in the most balanced way possible. There's exactly n over two vertices on either side. Then we can just do random sampling procedure where the sample two vertices s and t and with probably half there'll be an opposite size of the main cuts. And if that were true then we would recover the global min cut and we can just repeat this login time to succeed with high probability. So in other words, if the mincut was balanced, if there were linear number of release on each side, then, then we can solve this easily in login many calls to estimate. Of course the mayhem may not be balanced.
00:07:42.530 - 00:08:15.006, Speaker B: There could be, let's say k vertices on the smaller side where k is much smaller than n. And here one thing we could do is suppose we sample instead with rate one over k where k might be much smaller than n. Then when constant probability we still sample exactly one vertex on the smaller side. And once again we can repeat this login times to sample exactly one vertex with high probability on some iteration. And finally we can get rid of this. We can always guess k by doubling. So that's not an issue.
00:08:15.006 - 00:09:11.354, Speaker B: But of course the issue is we may sample many vertices on the larger side and this is exactly what the isolating problem will try to. So let's more formally define the problem. So suppose as the smaller side of a mincut and we obtain a subset of vertices t, the sampled set such that exactly one vertex on the smaller side is in t. And the problem we want to solve is given the setting we define for any vertex t in our sample set of terminals, a minimum cut that separates t from the rest of the vertices. So think of, you can think of it two ways. You can think of this cut as isolating the vertex t from the rest of the vertices. Or you can think of contracting the rest of the vertices into a single super vertex and just running st.
00:09:11.354 - 00:09:59.342, Speaker B: And the catch is we want to output this cut, such a cut for every single vertex t in our terminals. And we call this isolating cuts probe. So for example in this diagram here for this green terminal d here, the following cut is a valid isolating cut for this terminal. But of course you want to find the isolating cuts for the all the other terms as well. Any questions about the definition of the problem? So we call this problem the isolating cuts problem. And of course one naive solution to solving this problem is by simply once again contracting all the other terminals and do super vertex and finding the semen cut and doing this for every terminal t. This takes the size of t many Maxwell calls.
00:09:59.342 - 00:10:36.194, Speaker B: But of course the size of the terminals can be large as n. And the key lemma, which we will show, we will prove in this talk is what we call it. The isolating cuts lemma is that the isolating cuts problem can be solved much faster. It can be solved in just log of n many. So before I cover the isolating cuts algorithm and its proof, let's first discuss how the isolating cuts immediately implies a simple randomized global main cut algorithm. And here the key additional degree is just simple random sampling. As we discussed before.
00:10:36.194 - 00:11:28.008, Speaker B: Let's sample, let's kind of guess by doubling the value of k that we want. More precisely, let's iterate over, let's say login levels of I and sample each vertex with probably one over two to the I. And for let's let this terminal, let the sample vertices be the terminal set t and we'll just repeat this login times to succeed with high probability. And then we'll run isolating cuts on each iteration and return the smallest cut ever found. So the current is actually very simple. If we take the correct iteration I, then with constant probability on each iteration we succeed with constant probability that we sample exactly one vertex on the smaller side. And the isolating cost lemma will return a valid min cut for that terminal.
00:11:28.008 - 00:13:15.764, Speaker B: And since we look at all of cuts found over all iterations, we will indeed recover the global min cut. And finally, what about the other cuts we find? Well, they're all valid graph cuts, they're all valid cuts in the graph, so they can only be larger. So taking a global minimum will indeed recover the correct global minutes. The running time is algorithm will be dominated by polylog calls to isolating cuts lemma plus some near linear time post processing, and therefore, and we will show that the isolating cuts can be solved in polylog max flows and therefore the entire algorithm will run in polylog maximum. So let's next, let's see how the Iceland cosmos proved. So hold on, it's not showing it on the other screen. The key idea for the minimizing cuts is that we want to first compute.
00:13:15.764 - 00:14:01.148, Speaker B: So here's a setting here for convenience we'll rename the terminal set to be r. Think of it as the red vertices in the graph, and let's say sv is the isolating cut for each red terminal v. And the first idea is you want to compute an upper bound for each isolating cut. So we want to find these cuts, these subsets c of v, which include each Sv. So Sv is the set of vertices on the side of the isolating cut that contains the isolated vertex. We'll find an upper bound kind of um, c of v that contains sv. And we also want the Cv to be disjoint, to be vertex disjoint.
00:14:01.148 - 00:15:36.774, Speaker B: So it's the first step of the algorithm and to see why this suffices, um, for each CV, let's imagine contracting everything outside CV to a single vertex and then t and then just running the the min cut St min cut between the isolated the terminals. And because CV is an upper bound, this will still recover the correct SD min code. Now, what is the running time of all these SDmin calls? Note that because the sets CV are disjoint, each edge in the original graph is at most two such graphs, the contracted graphs in the worst case, and that is between two different cv. And if you contract the outside for each of these graphs, it will belong in those two graphs, but it will not belong in any other graph once you contract it. So therefore the total size of all the graphs, the contracted graphs on which we run sDmin cut is just at most two m, and therefore the total size of the grass on which we run max flow is also at most two m. And you can kind of like fold all these graphs into a single max call on a linear number of vertices edges. So that's the first step of the algorithm, and let's see how we can construct these upper bounds for each isolating.
00:15:36.774 - 00:16:22.254, Speaker B: So the first step is suppose. Suppose we compute a set of bipartitions of the terminals such that each pair of terminals is separate by at least one of them. So one easy way that you can see this is possible is if we just randomly partition the terminals into two sets, then with half probability. For any given pair s and t, they'll belong to a different size. And if we repeat this like log of r many times with high probability, we will, there'll be one partition that separates s and t each s and t. But of course there's also like deterministic ways to do this. For example by looking at the binary, like taking a binary representation of each vertex and going over the bits of the binaries.
00:16:22.254 - 00:16:56.614, Speaker B: That's a bit technical. I won't, I'll skip this in the talk. And then for each. So, so in this example, suppose that these red vertices are the four terminals. Then the following two bipartitions indeed separate every single pair s and t. Then for each pair, for each bipartisan, we'll compute the min cut separating the two sides of the bipartition. So for example, for this bipartition we can compute this cut here, and for this one we can compute this cut here.
00:16:56.614 - 00:18:06.064, Speaker B: And next, the claim is that if we take the union of all the min cuts we ever found, this separates all of r in the sense that if we, if we delete the union of all these edges in all these min cuts, then every single terminal vertex will be separated from all the others. And this is simply because for any two vertices in the graph, there exists some bipartition that separates these two and the corresponding min cut will separate those two vertices. And since we take a union of all the min cuts, this will indeed separate all of it. And now the key claim is that if we remove all the union of the edges of the cuts, then if you look at for each terminal, the connected component containing that terminal, then it kind of contains the isolating cut. So here, think of the green cut as the isolating cut. The upper, the kind of upper bound we obtain is the, is the kinetic component containing this vertex. And we'll show that this component kind of contains the correct isolating cut.
00:18:06.064 - 00:18:53.692, Speaker B: And the proof of bias is by a simple application of sub modularity of cuts, also known as uncrossing. If you look at this is the bipartition cut. And this is the supposed contradiction that the correct isolating cut kind of went beyond this component here. Then by uncrossing these two cuts, we get these two cuts. And the sub modularity of cuts shows that if we uncross, the sum of the two cuts can be at most the original two cuts. Then next, notice that this uncross cut here is still a valid cut between these by partitions. So this value here is a most.
00:18:53.692 - 00:19:36.704, Speaker B: So the cell here is at least the initial min cut between this by partition, and to remove these two from the equation, we get that the uncrossed cut here is at most the original estimate cut. And therefore we could have replaced this cut here by this cut here, because it's also an isolating cut minimize. So we can kind of do this until we find, nicely cut that does not cross any of the. Any questions about this? So that concludes the question.
00:19:42.744 - 00:20:00.536, Speaker C: I think I'm just missing something. Like you're saying that we find the, is this an algorithmic thing or an analytic thing? When you're saying that you can have an, if you have an isolating cut, that sort of goes too far. You can replace it with an equally good isolating cut.
00:20:00.560 - 00:20:00.744, Speaker B: Right?
00:20:00.784 - 00:20:03.688, Speaker C: Doesn't go too far, yeah. Is that an algorithmic thing?
00:20:03.856 - 00:20:32.064, Speaker B: Right. So you can think of it as an algorithm proof, where you kind of replace it each time. So this is purely for in a proof setting. So we're trying to prove that this upper bound number one way, you can think of it as you can just kind of iteratively replace, algorithmically replace cuts until they don't cross anymore. Or you can also think of us, take the, like inclusion wise minimal cut and assume for contradiction, it crosses over and get a contradiction this way.
00:20:32.144 - 00:20:38.216, Speaker C: Okay, I think my confusion was that your algorithm doesn't know what the isolating cut is, but this is all just.
00:20:38.240 - 00:21:23.854, Speaker B: To prove a structural theorem. So more precisely, the upper bound lemma. This upper bound here is really like, we're kind of assuming that these SV cuts are inclusion wise minimum, and therefore they must be contained. So that kind of concludes the isolating cuts lemma. And recall that this immediately implies a very simple randomized global mincut algorithm, which runs in, if you collect all the log factors, it runs in log cubed, and many SEO exposes. So this algorithm now is actually very simple. It's two pages, and we discovered this back in like 2020 or so.
00:21:23.854 - 00:22:19.024, Speaker B: And since the algorithm is so simple and it implies such a natural result, that global mincut can be reduced to polylog SD min cuts. And since this result was not even known before, we thought we were like, we had something special going on. We thought we had a brand new idea that had potential to be developed in the future. At the same time, we realized that, um, the concrete result here, global min cut in polylock max flows, does not imply anything new, because Carter already solved global min cut 20 years ago. He showed that the randomized global min cut algorithm in near linear time, which is even faster than even the current best max log. So unfortunately we found it hard to sell this real result in this way. And instead the way we sold our result was we showed that you can de randomize this entire procedure.
00:22:19.024 - 00:23:04.454, Speaker B: So in particular you can de randomize this vertex sampling here and the eisling cuts lemma is also deterministic. You can do the bipartitioning deterministically. And the final result we showed in our first paper was a deterministic min cut in polyloc max flows. And this indeed did improve upon the previous best deterministic program. And the new tools we kind of. The new tools he added in this work are pretty standard tools such as color coding determines the specification, experiment, decomposition. But in spirit, the main, like technical, the main conceptual contribution of this work really was the simple global main cut reduction, and in particular the idea of isolating cuts.
00:23:04.454 - 00:24:07.856, Speaker B: Any questions so far? Is the runtime of the deterministic reduction nearly linear or almost linear? Good question. It's actually almost linear at the time, at the time max flow wasn't even almost linear. So we can kind of like, kind of like sell as near linear, but assuming near linear max flow, it's still almost, is that still open? If like you can improve that overhead? Good question. It's still open, but I have ongoing work trying to improve. Thank you. So the first row was nice, but in spirit, like the real contribution of this work was a simple global main cut in part of the isolating cuts. So that gave us hope that perhaps isolating cuts can be applied to much, a much more broader set of mincut algorithms.
00:24:07.856 - 00:25:20.354, Speaker B: And that's indeed what we found. So in subsequent work we showed that isolating cuts also we could also apply isolating cuts to solve faster vertex connectivity. This is, instead of removing edges from a graph, want to remove vertices from a graph. With this graph we showed that with Nanonkai, Panigrauhi, Sierra, Nurek and Sirochai, we showed that vertex connectivity can be solved in polyloc max flows, which is by the recent breakthrough of max flow, almost linear time. And this was the first improvement in the other result we showed was if you consider the more general Steiner quantity problem, which is given a set of terminals, finding the min cut that separates that set of terminals, we showed that in the same work, essentially by the same construction, Steiner connecting can also be solved in polylock max flows. And what's interesting about this problem was that there was no previous non trivial element for this problem. So in the most general weighted graph setting, the previous best result was just the linear max flows.
00:25:20.354 - 00:26:01.368, Speaker B: So we kind of had the first non trivial item that's also optimal. It was also very simple. More recently, we've also managed to apply isolate cuts to various forms of connectivity augmentation. There's a problem of finding a minimum wage set of edges to make a graph tau connective for and some value tau. This means that we want to, we want the min cut of the augmented graph to be at least tau. And our first result was we showed that through isolating cuts we can solve this problem using polymax flows. And since then we further improve it to near linear time independent max flow.
00:26:01.368 - 00:27:19.182, Speaker B: And also, I say finally, in other work that's not my own, isolating cuts has been improved, has been extended to more general settings, for example hypergraphs, symmetric, some other functions, and so on. So. But the story of isencuts doesn't end here. Next week we study more general variants of min cut in particular problems that require us to find multiple mincuts. So two classic problems in this area are the single source min cut, which requires finding, which is given a source vertex s, find the Sc min cuts to all other vertices t and even more generally all pairs make our problem. We're going to find the min cuts for all pairs of radioactive and note that the single source main cut algorithm naturally reduces to n minus one calls to max flows by simply iterating over all t and running the max and a less a classic non trivial result is that even all pairs mint cut can be reduced to nmyc one max flows. And this is by classroom who they show.
00:27:19.182 - 00:28:02.294, Speaker B: The all pairs min cuts can also be reduced to n minus mxls. This is non trivial because the trivial algorithm will require n score n. The bottom line is a single source makeup and all pairs make can both be solved using n minus one maxwells. And this was, this was the state of the art before I work. So here's like a kind of a diagram of the landscape of minecut problems. At the very top we have the hardest problem, all pairs mincut, which can be solved in NMy one max flows. This reduces to an easier problem with single source main cut and an even easier problem Steiner main cut.
00:28:02.294 - 00:28:51.558, Speaker B: And by this recent work here we show that standard min cut is equivalent up to poly log factors to esteem in cut. And finally, here we have global min cut using in near linear time by cargo independent of any max loops. A recent work in this area showed the following equivalents that all pairs is actually equivalent up to polylock factors to single source mint. So in other words, in other words to improve on all pairs mint, it suffices to improve on single source mint. Okay, so at this point, know that there's kind of like two classes of, uh, results here, two classes of problems. The first, uh, class will all require like, linear number of max flows. And the second class here all require poly lock max flows.
00:28:51.558 - 00:29:54.516, Speaker B: And of course, there's also a result here that requires no max flows. And what's, what's interesting about, um, about these, uh, single source and all pairs Maxwell problems is that more than 60 years later, these remain the fastest algorithms for these problems. And this is not due to lack of trying. In recent years, there has been fast albums for special cases of these problems. For example, unweighted graphs, simple graphs and various forms, various restricted graph families, and in fact, nothing was known prior to our work, even for approximate variance of these problems. So if you want to allow, let's say, one plus seven approximations for singles resolve pairs, the best thing you could do was run n minus one approximate maximals. So, first realness area is, we showed that we gave an algorithm for one plus answer approximate all paramedic.
00:29:54.516 - 00:31:00.678, Speaker B: You can just polylock calls to the isolating cost lemma and this required polylock force. In turn, that requires polylock calls exact max flow, which is almost linear time. So, one thing, one caveat in this result was that in order to solve approximate all pairs, we actually required calls to exact max flow. Since then, this has been cleaned up in the sense that it suffices to solve a form of approximate max flow. And this can be solved in near linear time, not just almost linear, this is subsequent work. But of course, the result of exact all pairs may still remain open until subsequent work where the two groups of the two all pairs main cut groups working together, we kind of banded together and we showed that actually the all pairs makeup problem, or more precisely, the Gomer hootery problem, can be improved for the first time in 60 years, which the first result in this area. In the first resolve.
00:31:00.678 - 00:31:40.874, Speaker B: In this area, we show that a quadratic time suffices. And indeed, we did follow the recipe of single source min cut. We reduced to single source min cut and showed that this problem can be solved in n squared time. And here's like a brief high level overview of how we solved this. We first, um, use black box. Black box used approximate all pairs bank algorithm, plus, um, if we iterate over all powers of one plus epsilon, then we show that we can reduce this problem to the case where we have a terminal set t and we want to output the estimated cuts. Um, and we want to output the estimates given the promise that all the correct values are within, let's say a one plus epsilon factor.
00:31:40.874 - 00:32:28.108, Speaker B: So we kind of reduce this problem by kind of iterating over all powers of one plus epsilon. And in other words, our new goal is given the promise that the correct values are all within one plus epsilon about each other, output the exact values. This turned out to be not trivial, and here's a brief overview of how we did it. We kind of used what is known as Steiner tree packing. This is like a generation of if you're familiar with carger's near linear time min cut out when he used spanning tree packing, we use a Steiner variant of this. We pack Steiner trees instead. And by using this key property that all the correct the mincut values are within one plus s on each other, we can show that we can pack enough Steiner trees.
00:32:28.108 - 00:33:53.404, Speaker B: Such a random randomly chosen Steiner tree crosses the min cut in at most four edges in on average. And here the main ingredients were cut sparsification, this multiple multiply multiplicative weight update method that we've seen in previous toxins workshop and also like because Steiner Tree is itself np hard, we resorted, we instead use it on approximate steiner. And this one in particular was very useful. Next, we would sample a login set of slanted trees to reduce our sample size and still preserve the fact that on average or with high, probably at least one of these sino trees intersects the cut enamel's four edges. And finally we showed that, we showed an algorithm to compute the estimated cut assuming that there's almost four edges in crossing the four edges of the Steiner tree. Processing this cut and here the key part we used is that here the key ingredients we used was the icelandic and also like various techniques. So first up here takes n squared time because we're running multiple weight update on the sparsifier containing n edges.
00:33:53.404 - 00:34:48.674, Speaker B: We might as well spark some graph first because all clause are preserved out to one plus epsilon. And it's known that there's a form like width independent multi weight update that runs in iterations number of edges in the graph. And the second step here is dominated by caused isolating cause. And therefore our total running time was poly log max flows plus an additional n squared running time. So subsequently in a paper that will appear in this box, we sped up the stein and tree packing using advanced dynamic data structures. For example the robust core data structure that Aaron Brinstein talked about. And indeed this algorithm is now basically a near optimal because we can use the breakthrough result of exact max flow novels in your time to get garment hue in almost linear time.
00:34:48.674 - 00:35:32.584, Speaker B: So basically, um, we kind of have a satisfying conclusion of all these mincut problems. We show that all these makeup problems that we discussed in including the hardest variant can all be solved in all of them. So, so all of this is one plus epsilon. Um, so all of this is exact. Okay, because earlier you were talking about one plus epsilon. The question was, are all these results one plus epsilon? Turns out all these results do hold freeze act setting. But for the Garmin Hill tree or all pairs makeup problem in particular, we use approximate one plus epsilon as a black box step towards getting the exact.
00:35:32.584 - 00:36:29.034, Speaker B: So, the final slide, I want to discuss future directions for main cut problems. And the most interesting direction is directed graphs. And so the first natural step we could, we tried was trying to generalize isolating cuts to direct graphs. Unfortunately, there is one issue, which is that the isolating cuts lemma, if you look at the proof of why it works, requires both sub modularity and symmetry of the cut function. For directed graphs, we have submodularity. But you know how symmetry, for any given cut, the edges, the direct edges going from one side to the other is not necessarily the same as edits going from the other side. And actually turns out if we play around with definition, we can actually achieve symmetry, but then break some modularity.
00:36:29.034 - 00:37:09.358, Speaker B: So it turns out like, we don't have a definition of, of for director graphs that she's. Both these properties that are necessary to get ice link as two. And this difficulty of directed graphs has indeed be seen in literature. For example, in historically, Minka diagraphs have trailed behind undergraphs. Until recently, the best running time was still mn. And in recent work, we have some partial improvement where we showed that direct amendment can be solved in just square root and Maxwell's. But of course, this does not seem like the right algorithm.
00:37:09.358 - 00:38:06.594, Speaker B: Turns out like, feel like there's still some stack in this argument, but we don't know how to improve it further. And I leave as an open problem, can we get direction main cut? Thank you. Questions for Jason. Yeah, so Leah and Panigrahi claimed that this can, for at least Steiner trees, you know, be extended to hypergraph cuts. Is that something that you think that actually follows entrepreneurs? Oh, so it does indeed extend hypergraph cuts. For example, global hypergraph min cut can also be solved in poly lock max flows. But this is not a result that we observed.
00:38:06.594 - 00:38:54.434, Speaker B: This was by Chandra Chakari and Ken Kornrood. They observed that more generally, for some modular, for any symmetrical modular function which includes hypergraph cuts, you can solve polylock max flows, or instead of max flows, some kind of like symmetric function, asymmetric function minimization. All right. Right. Yes. So this, this real, this result here, can you explain what a directed cut is and what we're trying to do in the directed case? Because I failed to understand what's the difference with the undirected case. So for directed cut, directed cut, the, it's not symmetric on width on two sides.
00:38:54.434 - 00:39:18.704, Speaker B: So for example, one concrete way to define it is find a vertex at s such that the, to minimize, find a vertex at s, of course, not the entire set, and not empty set such that to minimize the number of directed edges going out of sight. But you don't care about that just going inside s. So for example, the graph has to be strongly connected if the, in order for the migrant to be not zero.
00:39:31.524 - 00:39:38.940, Speaker A: If I assume that the Mac flow is like linear time, strongly polynomial time, then will you get everything in linear time strongly?
00:39:38.972 - 00:40:08.858, Speaker B: Yeah, that's a very good question. So for the first few. So for the, so this result, yes, vertex counting, of course, only works for unweighted graphs like this is in a setting where the vertices have, are unweighted, each vertices weight one. We don't know how to make this work for a weighted vertex. I believe this result here does do some scaling approach. So it's not quite strong polynomial. I might be wrong.
00:40:08.858 - 00:40:31.070, Speaker B: It's been a while. This result here, I believe is also independent scaling. You just directly apply. How about like Gomerly hootery, right. In garment hue. So we, so our current algorithm does use some scaling. Does use, does it? Overall powers of weapons epsilon.
00:40:31.070 - 00:40:38.554, Speaker B: So it's not strongly polynomial, but we suspect that this can be made strong. We just, we haven't worked with all details. Okay, thank you.
00:40:48.534 - 00:40:56.374, Speaker A: All right then let's thank Jason. Thank you. So we have a break for.

00:00:00.240 - 00:00:05.714, Speaker A: The first talk will be given by Zeev Scully, who will tell us about the robustness of the Gittins index.
00:00:06.534 - 00:00:41.164, Speaker B: So, thanks, Venkat. So, hi everyone. I'm Ziv. I just graduated from CMU. I'm going on a bit of a journey, and I'll end up at Cornell, starting as an assistant professor in Ori starting next fall, and I'm very excited about that. What I want to talk about today is a theme that I explored in my thesis in the kind of context of scheduling and queuing systems, but that I'm very interested in exploring more broadly. And that's part of why I'm really glad to be here this semester with lots of experts in kind of different areas to see to what extent these ideas have legs beyond the queuing world.
00:00:41.164 - 00:01:29.460, Speaker B: And this idea is something called the Gates index. So I'll say I'm actually barely going to talk about what the Gates index is, but the main thing you need to know for this talk is that the GIssens index is a sort of a general technique for solving a variety of stochastic optimization problems that involve choosing between lots of independent alternatives. So you can think of a multi arm bandit problem. And specifically, the Gissens index solves the bayesian multi arm bandit problem. It also solves Pandora's box problems, and one I'll talk about today, which is scheduling in queues. But the common sort of thing about the Gibsons index in all of these settings is that there are optimality proofs, but these proofs are brittle. If you slightly perturb the assumptions, all of a sudden you don't have optimality anymore, and it becomes much less clear what we should do.
00:01:29.460 - 00:02:13.864, Speaker B: So, for example, all of these optimality proofs rely on having a single server. That is, you're pulling one arm at a time, opening one box at a time, serving one job at a time. What should we do if we have multiple servers? Also, all of these optimality proofs assume that you've implemented gittins perfectly with exact computations. It turns out the Gissens index, it's actually a number that is sort of how good is this arm? How good is this job to serve? What if you don't exactly compute that number? Because it could be hard to compute the optimality proofs. Don't give us a good idea. And then the last thing is that all of these settings are cases that I'll call like they have a fully specified stochastic model. One way to say this is that you can formalize this as an MDP, where you know all of the parameters.
00:02:13.864 - 00:03:06.650, Speaker B: Typically just solving that MDP is kind of too expensive, which is why we care about things like the Gibson's index, which gives us neater solutions to optimality. But what if we don't have full knowledge of all the parameters? Okay, so, and the way I sort of view all of these questions is they all are instances of, or at least kind of related to versions of this question, which is do Nier Gittins policies have near optimal performance? So as an example, I think of multi server scheduling or multi server, multi armed bandit as well. If I'm pulling the two best arms, that's like pulling the best arm twice as hard, roughly speaking. So that's nearly get insy. So is that nearly optimal? And in my thesis I studied this question in the context of scheduling in queues. And so that's what I'm going to focus on today. So let me tell you a bit about what scheduling in queues even looks like.
00:03:06.650 - 00:03:23.634, Speaker B: So this is a single server queue. We have a server that can serve jobs that are arriving over time. Jobs that are waiting for service will be in this queue. And this is a job. So a job is going to be a test tube. Its height is its size, that's how long it needs to be served for. And we'll represent that service as filling the test tube with water.
00:03:23.634 - 00:03:58.776, Speaker B: And so we can talk about the progress we've made so far in a job, its age, and then the remaining work call, its remaining size. And we have these jobs arriving over time according to some stochastic process. And the important thing about the stochastic process that you need to know today is that each job size is independently drawn from some distribution s. Okay? So at some point we'll finish a job. When this job exits, the total amount of time it's been around from arrival to completion is called that job's response time. This is sort of both the time serving the job and sort of time it spent waiting. And so we want low response times, right? Because we don't like waiting, most of us.
00:03:58.776 - 00:04:39.066, Speaker B: So that's the sort of main metric we're going to care about today. Okay? And now we have a choice, right? We have an empty server. We get to choose which job to serve next. And so when I say scheduling, what I'm really talking about is continuously making this decision, what job am I working on? And I can decide to change my mind at any point and start working on a different job. Okay? So if I don't like response time, right, I want low waiting, I might ask, how should I schedule in order to minimize the average response time over all jobs? So this is a classic question. And in this setting where I sort of can see each job size, age, remaining size, I have perfect information. The classically known answer is something called shortest remaining processing time.
00:04:39.066 - 00:05:19.716, Speaker B: I always serve whichever job has the least remaining size. The intuition is that whatever I can get off my plate the quickest, I should work on that, and that's reducing the average number of jobs that are always waiting. And that's a helpful thing. This is the known size scheduling. What about scheduling with unknown sizes? What does this look like? It looks like I have a test tube, but I don't know how tall the test tube is. I'm just going to fill it with water, and at some point the test tube will politely inform me that it's done and exit the system. Okay, so how should I schedule in this sort of world? So first, what are we even using when making our scheduling decisions in this world? Well, one thing we can see on the slide is that I've drawn the age right.
00:05:19.716 - 00:06:09.854, Speaker B: It's reasonable to assume we know each job's age because we can measure how long we've spent serving the job so far. It's also pretty reasonable to assume that we can know the job size distribution, say, from historical data, although I'll return to this at the end of the talk. And so, based on these two things, an idea we might say is, well, I don't know a job's remaining size, but it could compute its expected remaining size. And so this would result in a policy called Serpt, always serve the job of least expected remaining size. And so the way I like to sort of write down what this policy looks like is that it assigns each job a rank or priority as a function of how long I've been serving it. And we'll use the convention that lower rank is better. And so a job's rank is going to be its expected remaining size conditional on having reached age a.
00:06:09.854 - 00:06:33.758, Speaker B: So that's, this is the remaining size. This is conditioning on the fact that the job has reached age a and thus isn't smaller than a. Right. And so, just as an example, if for this particular job size distribution, this is what Serpt looks like, it's kind of adapting its priorities based on information. It's learning. As a job passes age one, we realize, oh shoot, this job isn't just size one, it's going to be bigger. So I'll give it a worse rank.
00:06:33.758 - 00:07:19.946, Speaker B: Similar deal at age six and so SERPD is this kind of very nice idea, right? Natural generalization of SRPT. Turns out it's not optimal, which you would guess if you remember the second slide of the talk where I told you that there's this thing called the Gissens index, and that this gives the optimal solution. So the Gittins index, it's a bit more complicated than SERP, but has a very similar intuition behind it with some fancier details you can ask me about. So, it's more complicated, but it's optimal. And this is a sort of classically known result. Although even talk to me after, if you're curious about exactly what classically known means, because it turns out it was a bit more complicated than that. Okay, so this is kind of what Giessen's index looks like in single server scheduling.
00:07:19.946 - 00:08:43.578, Speaker B: I'm taking the job size distribution, my stochastic model, and I'm crafting on a job by job basis, this priority function based on that job size distribution. And basically, by just always serving the job of least rank, I end up with this optimal scheduling policy when I have a single server, and when I'm exactly computing this whole thing, uh, to exact precision, and when I exactly know the sub job size distribution, s. Okay, so, so this optimality result, um, right, has that thing needs a single server, needs exact computations, needs fully specified stochastic. Um, and so, in my thesis, I studied this question and got two out of three. So, uh, so basically, we showed that for some definition of near optimal, uh, which is actually different in each of these bullets, we showed that if you do the natural generalization of gittens in a multi server setting, where you basically, instead of taking the single best rank, you take the k best ranks and put those in your servers, then you get near optimal mean response time. If you only compute the gittins ranks within some multiplicative approximation ratio, we showed that you then end up with the same approximation ratio in a sort of near optimality result. Um, and the way we did this, um, kind of.
00:08:43.578 - 00:09:12.268, Speaker B: And the thing, the reason I'm excited to explore this theme, more is less about, you know, these results, but more about the tools that underlie them. Um, and so my thesis is called a new toolbox for scheduling theory. And two of the tools in that toolbox you saw on the title slide, one is called wine, the work integral number equality. Um, and then another is a sort of general way of thinking about queuing. That's called the mark of process job model. Um, and these are. And the both of these ideas are things I think might have analogs outside of queuing, so I'd be happy to discuss them.
00:09:12.268 - 00:09:45.382, Speaker B: And then the last theme that I think is really important is thinking about this fully specified area. And there's lots of open questions here. So one example would be, I said, it's reasonable to assume we know the job size distribution. What if we've learned the job size distribution from data? We don't know the exact distribution. How can we adapt Gittins for that setting? Do we need a distributionally robust version of Gittins? What does that even look like? I know it. I have started thinking about this problem, but it's very hard and I'm very interested to collaborate with folks on these sorts of things. Anyway, thanks for your attention.
00:09:45.382 - 00:09:46.714, Speaker B: Happy to take questions.
00:09:50.174 - 00:09:55.594, Speaker A: Thanks for the lovely talk. Questions for Zeev, and maybe the next speaker can set up meanwhile as well.
00:10:00.454 - 00:10:10.754, Speaker B: The multiple server case. Can we prove that the optimal solution always exists? Or like, how do we know that it's near optimal?
00:10:11.894 - 00:10:13.086, Speaker A: Can you repeat the question?
00:10:13.150 - 00:10:47.014, Speaker B: Yeah, sure. So the question is, what do we even know about the optimal solution in the multi server setting? The answer is, we don't know very much. What we actually show is that gitins with multiple servers in certain, under some generous assumptions, it actually approaches something even better than the optimal multi server policy. It approaches single server gas. If you smush all the servers together into one big bad server, which is even better than having a multi server system. And actually exact lower bounds on the multi server, optimal are still an open question in queuing.
00:10:50.074 - 00:11:09.734, Speaker A: Maybe time for another question. There's any. Thanks again and go to the next talk. Yeah, so the next talk is on incentive aware machine learning for decision making by Chara Purimata.

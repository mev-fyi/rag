00:00:00.320 - 00:00:19.382, Speaker A: Okay, great. Thanks a lot for the introduction. It's really, really a pleasure to be here. I had the great opportunity, I guess, of being. Of participating in some of the other Simons programs in previous years. And it's really nice to be back. So, the audience, I think it's quite mixed, which is great.
00:00:19.382 - 00:01:09.108, Speaker A: I think we have a nice mixture of experts in the domain. I think a lot of people that perhaps are not experts in optimization. And I think the goal, at least of the talk is very much to mix at any point. So, let me start by trying to explain a little bit words in the title, right? So, first of all, I guess I think many of you have at least some idea of optimization, but I want to tell you at least a little bit about the historical roles of optimization. But also, what exactly is this watershed? I mean, it's a very, it's a very loaded term, and we want to see exactly what is. What are the reasons for choosing this. So what's optimization? I guess, in general, I think many of you are familiar with this notion of I have some kind of function in there, and I'm really trying to find the best possible value diagram.
00:01:09.108 - 00:02:01.194, Speaker A: Right. I try to write as few equations as I can, but the idea is, if you represent perhaps the graph of your function, what they're really trying to find in there is a point where your function achieves a new value. And optimization really goes back many, many, many years ago, actually, one of the earliest. I don't know how many of you are familiar, but one of the earliest problems in optimization is a famous ISO parametric problem, something called Dido's problem. That really has to do with the question of what's the maximum surface that you can, that you can circle by looking with a given role, let's say. I mean, it's a beautiful story. I don't have time now to go out all the details, but if you've never seen it, you can think about it.
00:02:01.194 - 00:03:13.374, Speaker A: But in particular, optimization began, I think it's more formal life. Once there was calculus, once we had a way to talk about, okay, that should be better. So, once we have, or once we had a more formal notion to talk about optimality conditions, and that gave us a very interesting and very insightful connection, for instance, with notions of physics, right. Whole variational principles. What's kind of interesting is, in recent years, there was like, also other notions that come into place, notions of convexity, notions of complexity. And one of the things that's so important and so interesting about optimization is it's not an isolated area of research, but it has pervasive connections with many, many areas, ranging from game theory, control theory, combinatorics, theoretical computer science, and number of other areas. The other thing that's very interesting, I mean, it's not just a mathematical question, but also it's really essential and ubiquitous in a number of scientific and engineering domains.
00:03:13.374 - 00:04:19.356, Speaker A: So in particular, one of the things that when we teach optimization courses, we always emphasize that there's a whole bunch of industries, industries today that they just would not be possible or they would be completely different if they didn't have access to optimization technology. So in particular, if you think about the way that an airline is run, this is actually optimization enters pretty much in every single stage of the pipeline. When you think about how do you design an engine, when you think about how do you simulate, using computational fluid dynamics, when you think, how do you plan routes, when you think about how do you price, how do you schedule your crew, how do you do maintenance at all? And each one of these steps, somehow optimization enters in the picture different flavors. Optimization, some may be more continuous, some may be more discrete, but all over the place, these kind of things. The same thing is true when you think about finance and insurance. Every financial product right now, it's essentially the result of some kind of fairly clever combination of optimization and simulation. E commerce is another example.
00:04:19.356 - 00:05:49.884, Speaker A: But really, it's a very, it's really the source, I guess, of a number of quite interesting industries. So there's a lot of, when I talked about optimization, of course I draw this cartoon, I'm drawing this cartoon in there of just a function I'm trying to minimize. But of course, all the details, all the difficulty of optimization problems, they come in terms of how is this function actually described, what is allowable set of solutions? And all those considerations essentially give rise to a very nice variety, very rich and incredibly rich variety of different classes of optimization problems. So this picture, this optimization tree, or optimization taxonomy, for instance, was from the old version of the NIO server, where somehow your kind of have this nice classification, depending if you look at continuous problems or discrete problems, by the way, that's exactly the first order distinction in our Simon's program. We're trying to essentially try to bring these two things together, and then in here, you go in different branches, depending if you do integer, stochastic, constraint, whatever. And much of this, or many of these distinctions really arise from starting in the 1950s with the development of linear programming. And one of the things I think researchers in optimization have been doing is really producing more and more classes of optimization problems for which we can understand, for instance, efficient algorithms or solid.
00:05:49.884 - 00:07:10.218, Speaker A: And again, depending if you're more a continuous person, more a discrete person, a convex person or a non convex person, you will find somehow something in there that it's likely to. To be helpful for you, right? So one can discuss, and in fact, people have discussed for a long time, which ones, of all those distinctions are perhaps the most essential. And there's a famous quote, I mean, anybody that does optimization knows about Leinor, kind of this very famous quote of Rockefeller that says, it's coming from this paper on this nice review paper almost 25 years ago, about Lagrange multipliers, kind of trying to, or making the point that really, this big distinction, the big watershed in optimization, what really determines somehow what flavors of tools you should be using. It's not really about linear problems and nonlinear problems, which is very much the traditional mindset when you think about optimization, but it's really about convexity and non convexity. So one of the things I want to explain is a little bit why somehow this is a very sensible thing to say. Rockefeller certainly knew exactly what he was talking about, but also that perhaps this distinction is a little bit less sharp than we think, that it may look at the beginning. And similarly, the same is true, perhaps, or many of these other distinctions.
00:07:10.218 - 00:08:02.660, Speaker A: Perhaps we shouldn't really think about continuous and discrete as being totally different from each other. Perhaps there are techniques that we can apply from the continuous to the discrete, how we can perhaps try to think at least some aspects of all these complexity of optimization problems in kind of nice and unified way. So again, hopefully, we have some idea of what I mean by optimization. So let me try to explain again a little bit what this convexity stuff is. I know that at least half of you are experts on this, but let me at least give you the one slide summary version of what is convexity and why do we care about and convexity? Again, let me ignore equations. I don't care about the equations. It's really a very simple and very natural property of a set, right? So a set or the property of a set being convex is really learning.
00:08:02.660 - 00:08:39.558, Speaker A: Or what if you have two points in your set, whether the whole line segment between your points belongs to the set? So, something like this, for instance, is nice and complex. If you take any two points in the set, the whole line segment between x and y, for any x and y is going to be contained in the set. But something like this set over here will not have this property. If you like equations, that equation is something like this. But again, it's really about the geometric picture. So there's a nice notion of convexity, not only for sets, but also for functions. And again, you can write the definition.
00:08:39.558 - 00:09:14.966, Speaker A: This is the definition of complexity, where lambda is in zero one. But perhaps if you understood the definition for sets, then the definition for functions is exactly the same. What we ask is at the epigraph. I mean, the set of all the function values above the graph of the curve. If this set is convex, then we'll say that the function is complex. So somehow we really only need one definition. And even without any theorems, it is perhaps clear why functions of this type, they're going to be nicer from the optimization point of view, that functions of this type, right, more than anything, there's many reasons.
00:09:14.966 - 00:09:56.724, Speaker A: But let me just give you one. Certainly, because whenever you have a function of this type, then any local minimum in there is also going to be global. But whenever you have a function that looks like this and the same property is not true. And again, one can quantify all of these, and one needs to put enough technical conditions for what I'm saying to be exactly true. But generally speaking, convex optimization is a lot, lot simpler than general non convex optimization. And this is perhaps some of the points I'm trying to summarize in here, why convexity is so important and so ubiquitous all over the place, why it's such a wonderful technology. On the one hand, the definition is extremely simple.
00:09:56.724 - 00:10:46.158, Speaker A: I just summarized it in one slide. And again, I think there's a lot of things that I think you can imagine that are consequences of this. But the geometric, the geometric properties, the geometric consequences of this are actually extremely rich. There's a lot of consequences that come with this. Also extremely important, which I'm not saying anything at all in this talk, is that this is also an incredibly powerful modeling approach. So it turns out that most of the time in practice, we don't just write an optimization problem, and then we look at it, and then we say, hey, we happen to be convex. But actually, the way that we would models, the way that you use parsers or modeling environments, they can be adapted or it can be constrained in a way that only convex optimization problems are going to arise.
00:10:46.158 - 00:11:37.002, Speaker A: And in particular, in engineering, this has been enormously powerful and enormously influential. I mean, Steve Boyd's notion of disciplined complex programming is one very nice way of formalizing this problem, but also, there's very nice algorithmic consequences, right? I mean, again, modulus and minor technicalities we know that convex optimization problems, they can be solved fairly efficiently in theory and in practice. And the other thing, of course, is there's been a lot of applications of. So somehow, I mean, it is really justified, this notion that complex problems are very special and very useful. And we really want to understand this. It's certainly incredible. But of course, this is a very rough cut, just dividing the world into convex and non convex.
00:11:37.002 - 00:12:46.954, Speaker A: Leno is perhaps a little bit simplifying things so much because we do know that there's not just one distinction in there, but there's actually a lot of them. Depending on who you talk to, they may tell you, oh, no, really, the most important difference in the world is where things are continuous or things are discrete, including some people in this audience, some other people will tell you, oh, no. What really, really matters is whether things are linear or nonlinear. I don't really care about perhaps convexity or not. But if you have linear programs and linear underlying functions, and everything's nicer or constrained versus unconstrained, there's a lot of, like I said, of all these possibilities. And in fact, I told you about this nice tree that was in the old Nio server, the new Nio server. It actually has a much more complicated taxonomy of lino kind of all the different kinds of optimization problems, or lino kind of, you can classify them on whether you're uncertain, deterministic, nonlinear equilibrium problem, second order, all kinds of classifications, all of them are important.
00:12:46.954 - 00:14:19.530, Speaker A: There's reasons why I think our optimization community has developed all these different plans. But really, let me be very specific about this. All these distinctions, all these particular program classes are extremely important. But really, what I'm trying to understand, what I'm trying to, at least there's a single idea that I want to communicate today that really there's quite a bit that we can do, or there's a fairly interesting circle of ideas that we can try to use while at least for a while, ignoring many of these distinctions. And this is what I'm really trying hope that I will convince you that really, if at least for a while, we ignore all these subtleties or not so subtle distinctions, then perhaps you can do interesting stuff. So, in a sense, what they're really asking is, all these distinctions or watersheds, are they real? How sharp are there? Is it really an issue that something is either convex or non convex? Or I can think about things in the middle? Do I really want to think about something linear and something nonlinear? Or I can put again, like a finer gradation in there. And of course, if you're familiar with any aspects of mathematics, you know that such things are often quite likely, right? Think about, for instance, even if you think about some geometric surface, for instance, you may think about the linear case, but really, if you're a little bit more sophisticated, you think, okay, really, the linear case is somehow having curvature equal to zero.
00:14:19.530 - 00:15:17.554, Speaker A: And then you may think, okay, perhaps in situations where I have small curvature, I can think or do something interesting, or the same thing, if you like matrices, you can think about an invertible matrix, right? An invertible or non invertible is a short distinction. But again, the more that you know, you think, okay, really what I should care about is how close to invertible a matrix is, right? Notions of condition number, for instance. Similarly, we have a lot of TCS people in here. If you think about polynomial time versus exponential time, perhaps again, that's a very rough distinction. And you may want to introduce parameterized complexity, parameterized families of problems where you get some additional parameters in there. So in a sense it's not a new concept, this idea, of course, of giving sharper distinctions in there. But what I'm really interested is what happens in the context of optimization.
00:15:17.554 - 00:16:08.958, Speaker A: So, clear questions? Good. Okay, so now you know, I told you, okay, convex is great Leinor, non convex is not great. So perhaps one of the simplest things that one can try to think, in fact, one that's enormously successful in many contexts, is to try to make things convex. So for instance, if I have, let's imagine that my feasible set is something like this, just a disconnected set of points, like it happens in many combinatorial problems. Then one thing that you may think about is, ok, let me try to take the convex hull of the solutions. So what is a complex is really the smallest convex set that contains all the points in the original set. It's a nice operation that will take any set and it will return you the best convex approximation if you want.
00:16:08.958 - 00:16:54.640, Speaker A: I haven't said anything about computability, but certainly it's a geometric operation that we can do with my set. And similarly with a function, if you have a function which is not convex, then I may think about what is the nicest convex function or the closest convex function to my given function. And this is what's called usually the convex envelope of my function. These are great things. It's perhaps among the first things that you can try, that you should try whenever you're facing a problem, if you can compute these ones. But it has some cons learning or some difficulties in the applicability of this. The main one is typically obtaining descriptions of this may be very difficult, although in principle, it's easy to say the convex hull is the smallest convex set that contains your points.
00:16:54.640 - 00:18:29.636, Speaker A: Then you may not be able to write, to explain this to your computer. You may not be able to write some nice description of this convex hull that you can use it. And of course, if you're a combinatorial optimization person, you know that this is always the case, right? On the other hand, depending on what kind of problems you're interested in, you may lose information, right? So if in here, I look at the convex hull of the solutions somehow, really the convex hull doesn't, it forgets about all these points in interior, right? So I don't have, perhaps if I optimize an arbitrary function over my set, then Leno kind of, it may forget, or I may not keep track of leno kind of information in there. So somehow, for some things, computing convex hulls is not, even if you could, it would not be the right thing to do. Right, good. So the question is, what can we do? This is one way in which we can take some problem, perhaps combinatorial, perhaps non convex or whatever, produce some kind of nice complex problems. The question is, are there other alternatives? Are there other ways that you can try to approach this problem? And one of the insights, I mean, a very old insight, is that really, sometimes it's just a matter of how you think about the problem, right? That in a certain sense that one can make very, very precise, pretty much any set of any problem, you can really think about it directly as a convex problem, perhaps in a very large dimension, perhaps even in an infinite dimension.
00:18:29.636 - 00:19:21.882, Speaker A: But there's a very natural way in which I can think about learning of a set in any space as being associated to a complex set. So let me try to make, let me describe it first, and let me give a couple of examples. So conceptually, it's quite easy. So essentially what I would do is I would think about my set being convex, where every point in my set is actually giving me a new dimension. So let's think about the case where I have a finite set in here. I just have four points over there. And then what I'm going to do is, instead of, I'm going to associate this set, if you want, with a simplex in four dimensional space, where every extreme point, every corner in here corresponds exactly to my point downstairs, right? So if I have a finite set of points in rk, whatever k happens to be, but I have n points.
00:19:21.882 - 00:20:16.554, Speaker A: I'm really going to associate to this an n dimensional simplex where n in here maybe very, very large, right? On the other hand, if I have a continuous set, think about in here having some kind of complicated set, which is continuous, then I'm going to associate with a simplex, but in an infinite dimensional space, right? So think about exactly the same picture, but now with an infinite number of corners. Of course, that doesn't make much sense. So this is not exactly the same thing as taking the convex hull. Let me emphasize this, because in here, my set lives in r two. If I were to take the convex hull, this convex hull would live in r two. But this set in here is living upstairs in a large dimensional space. But what is true, that's actually very interesting, is that there's a bijection or there's a correspondence, if you want, between the extreme points in here and the points answers.
00:20:16.554 - 00:21:10.954, Speaker A: So this construction, you know about it, there's many, many, many different ways of thinking about what's happening in here, depending on what your background is. One, let me give you three or perhaps four. One is certainly, instead of thinking about my set, I think about the space of probability distributions on my set, right? When you think about it, what am I doing? Probability distributions on points are exactly associated with a simplex in four dimensional space. If my set is more complicated, then I would have to think about distributions on my set. But the point is that naturally has some nice complexity structure. The same thing is true if you think about, another way of thinking about this is that you go to a functional space, you're thinking of the space of functions on your set. And again, there's going to be some natural linear structure in there, or convex structure in there.
00:21:10.954 - 00:21:49.398, Speaker A: If you've ever seen anything about games, that's of course the idea that we can go to mixed strategies in a game. We can randomize over our actions. And now you get nice, nicer structure. In control theories is something called relaxed controls. Again, depending on which part of the world you're coming from, I'm pretty sure you've seen some versions of this in one form of the other. And by the way, I told you, this is not just about convex or non convex. Exactly the same thing is true when you think about the distinction that we think in differential equations or controls or physics between linear processes and nonlinear processes.
00:21:49.398 - 00:22:31.232, Speaker A: Exactly the same thing is true when you write not the dynamics of your system, but you write the dynamics of, for instance, probability distributions on your state space, on your phase space. What's called a newbie equation, if you know what that is. Or Fokker, Planck, or Leinorgan of any of the classical equations in probability theory, once you go to probability space, leinorgan of, then in that case, everything becomes nice and linear. By the way, I think many of you have heard, for instance, people saying quantum mechanics is linear regardless of anything. This is exactly what one means when you talk about the linearity of quantum mechanics. It's linearity in phase space. Again, this is perhaps not very important.
00:22:31.232 - 00:23:26.468, Speaker A: What I really want you to focus is this picture. There's at least a very formal process where we can take any set and lift it or think about it in some kind of thing, in some infinite dimensional space. And this is great. It's the kind of things that I think when you're in grad school, you think about it, who it blows your mind. But when you really go into the details, this is not terribly practical. I mean, often, right? Because, again, doing things in some infinite dimensional space, it may not be very useful unless there's some structure up there. Now, the question, the real question that I want to discuss today is, can you get away? Are there situations where you can get away, not just with an infinite dimensional space like before, but with a finite or even small dimension? This is really what I'm asking.
00:23:26.468 - 00:24:00.320, Speaker A: If I started some non convex setting here. I know that if I go to infinite dimensional space and there's going to be some nice convexity structure, but that's not really useful. The question is, can I get away with finite dimension? And hopefully small, like, can I convexify things in some way? So let me give an example. Now, you know that this is not, like, a crazy idea. It's a very simple example. Or, for instance, learning how can I take a non convex set? That's my doughnut. The doughnut I ate this morning, actually, bagel.
00:24:00.320 - 00:24:25.034, Speaker A: I ate a bagel, not a donut. And this is defined by these quadratic inequalities. It's set in the plane, defined exactly by these quadratic inequalities. And obviously, it's a non convex set. It's perhaps one of the simplest non convex sets that I can write. And again, let me remind you, take any two points, I look at the line segment, and of course, it's not contained in there. So let's imagine that I'm trying to solve some kind of problem over this set.
00:24:25.034 - 00:25:23.400, Speaker A: Clearly, I shouldn't be able to use convex optimization, because this set is just not convex. Now, what I claim is that there is a way of essentially taking this set and lifting it to some nice dimensional space are three reals in such a way that it will be nice and complex. So the map that I want to use, a very simple map in this case, I'm just going to take x and y to x, y and x squared plus y squared. So essentially what I'm doing is I'm taking the plane in here and I'm mapping it into the surface of this paraboloid over here. So there's a nice map where you take any point in there and it goes up there into some point. And I want you to know this. What happens, I want you to think in here, not of the surface in there, but actually of the convex body that I would obtain if I fill this in and I slice it with these two hyperplanes.
00:25:23.400 - 00:25:59.234, Speaker A: So this is filled with water by slice it in here, and I slice it in here. So I get like a nice barrel like thing and notice something wonderful that happens. Every point downstairs is a projection of an extreme point of this convex set. I can't really define extreme point. Extreme points really mean something that's on the boundary. It's not a complex combination of other things. So something wonderful happens if I optimize over here, over this nice complex set defined by these inequalities, any linear function.
00:25:59.234 - 00:27:02.020, Speaker A: The minimizer downstairs is going to give me a point in my beaker in there, right? So really, instead of solving like a bad non convex problem down here, I can just solve some nice convex problem over this convex. So, natural question, what is going on? Where did I get this map from? How we can use this in a more, in a better and more interesting way. Is a phenomenon clear what's happening in here? If not, questions would be great. No questions. Good. Okay, so really not, you know, again, of what I'm talking about. I told you before that we started an arbitrary set down there, and there's always a way of producing this thing up.
00:27:02.020 - 00:28:07.684, Speaker A: In ideal infinite dimensional space, whatever, everything is nice and wonderful, but we're never going to get there. So the question is, are there things that you can do in the middle either? Can you produce somehow not just finite dimension, but hopefully small mappings in there with this property? So, in particular, what we want to understand and develop are systematic and efficient ways of doing this in here. This construction was extremely ad hoc. I just wrote this. But the question is, again, how could go and write this in a more systematic way without going all the way to infinity? And there's a technology for this, something called hierarchies of relaxations. What I really want to do is to at least explain the basic ideas of why such things are even possible. Yeah, well, so certainly here, when you optimize any linear function, any linear function up here, this will always be on the boundary of this cell.
00:28:07.684 - 00:28:43.634, Speaker A: So the point is, remember that I really want to optimize some function in here. So the point is, you can rewrite any nonlinear function in here as a linear function up here. Again, in this case, there are some restrictions, but in the general setting, any function that you would write in here, it will become a linear function in this space. Yeah, it's a great question. Good. So, ok, I mentioned the word hierarchies in the academic field, or whatever. There's lots of, and lots of hierarchies, depending on who you are.
00:28:43.634 - 00:29:59.340, Speaker A: You may worry about comparisons between different academic fields. Anyway, there's a lot of interesting things about this, but what is this? I mean, of course, hierarchies have a very, very long history in optimization, right? This is not somehow a new notion in different forms, although there's a lot of somehow things that we understand, I think, a lot better. There are very classical constructions in integer programming. When you start with integer programs and you produce families of linear programs that will have essentially these kind of features. But in particular, what I want to focus on is perhaps, I think it's fair to say this, one of the most powerful ways that we have of producing these kind of hierarchies that really are based on these notions of samos quarries. And I'll try to explain a little bit why something like this will appear in here, and also why somehow this is all going to rely on something called semi definite programming, which is a very interesting class of complex problems. So I'll explain, I'll come back exactly from this, but again, at the high level, and there's many different ways of interpreting, what they're really trying to do, is to produce a parameterized family, just like in here, of approximations to my convex body, perhaps in higher and higher dimensional spaces.
00:29:59.340 - 00:30:47.880, Speaker A: So I mentioned in here this funny word, semi definite programs or semi definite programming. Let me at least give a picture. I think if you've never seen semi definite programming, it may help at least to get into the right class. If you've seen semidefinite problems, if you know what semi definite programming is learning, then I think this geometric picture may actually help you also. So what is a semidefinite problem is a very, very nice generalization of this class of problems called linear programs, which are essentially, optimization problems are defined over polyhedral sets with finite remaining inequalities to the case where the feasible set is now the intersection of a subspace and the cone of positive semidefinite matrices. So these are symmetric matrices, which are positive semidefinite, that is sn. And I'm intersecting this set with a subspace.
00:30:47.880 - 00:31:26.874, Speaker A: And what I'm trying to do is to optimize a linear function over that intersection. This looks like a crazy thing to do, but it turns out that it's a wonderful and incredibly powerful family of convex optimization problems. Let me just make a couple of observations. First of all, this includes linear programming as a very particular case. When you restrict to the case of just diagonal matrices, the diagonal matrix is positive semi definite only if all the elements are non negative. But in particular, what's nice about it is that somehow it's as canonical a class of problems as 1 may hope for. There's a beautiful duality theory.
00:31:26.874 - 00:32:36.300, Speaker A: It's convex and finite dimensional. We have wonderful algorithms to solve this, and modulus and minor technicalities is that things are solved in polynomial time. So this is an underlying, I'm really going to use this kind of as a black box, but there's a lot of, an incredibly variety of problems across engineering and science and math and whatever that are reducible to this form, even though in principle they may look nothing like this. So if you want to learn one thing, I would recommend strongly to learn about semi definite programming. So I told you about learning of somehow these notions of learning or trying to construct these kind of maps, or all these families of hierarchies that people have built. And the way I like to think it, somewhat, perhaps not very nice. Is that really what you do, is you're building a machine? What the hierarchy is, is really a machine that will take your non convex problem, some non convex formulation in there, it has a knob in there that will allow you to say how much you're lifting.
00:32:36.300 - 00:33:04.396, Speaker A: And in the end, what's going to come is some convex optimization problem. Exactly. Some semi definite problem. So what people have done is essentially build better and better machines over there. And one of the things that I want to explain is perhaps one of the nicest ones that we have, this one over here, and why somehow it's fairly canonical. It's really difficult, I think, or we don't know ways of building. I think things are better than these kinds of machines.
00:33:04.396 - 00:34:08.791, Speaker A: And I will tell you a little bit. What's the evidence that perhaps these machines are optimal in some particular sense? So remember what I told you? What were we doing before? In my example about the bagel? I was taking any point downstairs, any point, all points downstairs, and I was mapping them upstairs. So it turns out that Leinorganov, the way that these relaxations work is they take a very nice map, a very nice canonical map, to take any point downstairs and map it upstairs. And what they do is they take a point x and they map it into the symmetric tensor product of x k times. Right? And this is what we then know by this, if you've never seen or you don't quite know what this is, really, think about taking any point x. I form all the monomials of the greek k in the variables x, sub I. And that's exactly my pointed map, by the way, if you're a machine learning person, and I think all of us are apparently learning in recent times, think about this as very much like a polynomial cardinal.
00:34:08.791 - 00:35:02.094, Speaker A: I mean, this is doing something very, very similar to what the polynomial kernel is doing, or the feature map associated to the polynomial kernel. It's essentially very, very similar. What's kind of interesting, like in my picture, is that not only you need to map things upstairs, but you also need to understand, hopefully, the convex hull of the image of your points, right? Like all the way back in my example, I was taking my donut, my bagel, I was mapping it upstairs. And in this case, I have a nice description of the image of the doughnut of the bagel under this map. I can write more or less explicit inequalities for this ritual. And it turns out that essentially, this is my condition b. If you want, I want to be able to effectively describe, or at least approximately, this convex hull of the image.
00:35:02.094 - 00:35:55.262, Speaker A: So this looks like a crazy problem. How would you do this? But when you really think about what I was doing before, I was mapping my points through this tensor product, and then I take a linear function in here. That's what taking the convex hull means, and trying to understand all the inequalities that are valid in this object. And a linear function on the tensor product is nothing but a polynomial. Right? So what I'm really trying to understand is whether for any linear function, this polynomial is actually non negative. That means exactly that, whether the set is contained, the image of my set is contained on the half space associated to the point. So what do we need to do? We need to understand, again, we're reducing it to perhaps a more complicated problem, but we really need to understand this notion of non negativity.
00:35:55.262 - 00:36:56.164, Speaker A: When the polynomial in several variables is non negative. And by the way, before telling you how this is done, let me mention that this problem, understanding the convex hull of a set, is a really, really important and ubiquitous problem in many areas. Of course, in combinatorial optimization, this is a bread and butter of trying to understand the different algorithms. But exactly the same thing is true. For instance, when you look at other objects, not just convex hulls of finite set of points, like in the combinatorial case, but for instance, if you're trying to understand the convex hull of an algebraic variety, the convex hull of a point and a group action, the convex hull of some curve, and the group action, there's a lot of situations where somehow this is really what the object that one is trying to understand, the convex hull of something and understand, depending on who you are, may mean very different things. It may mean computationally, it may mean geometrically. I want to understand the structure of the equations that define it.
00:36:56.164 - 00:37:40.098, Speaker A: It may mean algebraically. Again, depending on who you are understanding, may mean very different things. Let me go back to what's happening over here. I told you, hopefully you believe me, that once I take my set, I map it in here with my map phi, and I'm trying to understand linear inequalities up here. That's the same thing as understanding polynomial inequalities down there. And again, if you're a kernel person, you know exactly what I'm talking about. But then what are we going to do? I mean, I need to understand whether some polynomial is non negative.
00:37:40.098 - 00:38:44.584, Speaker A: Perhaps the simplest and obvious things that I can try to do is try to say, okay, if my polynomial is a sum of squares of some other polynomials, and certainly this is going to trivially imply that p is non negative. There's a whole bunch of things that one can say about this, but the only thing that we carry here is that this is an obvious sufficient condition for p being non negative. And in particular, this condition is going to be computable or reducible to semi definite probleming. So when I put these two observations together, really what that means is the following. That the way that these constructions work is exactly by this combination of taking point sound stirs and mapping them with a feature map or a polynomial map, like here, usually exactly this Veronese map, the symmetric tensor product. And then what you do is you replace a notion of a convex hull, which is looking at all the valid inequalities on your set, by all the valid inequalities that you can prove using a samos coordinate composition. And this is all that's going on in here.
00:38:44.584 - 00:40:18.920, Speaker A: These conditions, for simple reasons, they become better and better. With fixed k, they're extremely contained in each other, and for every fixed k, these are polynomial time solo, since the dimension of this space is actually order of n to the k, and under very mild conditions, what this will give you is exactly that. These hierarchies are complete, that in the finite case, after finite remaining steps, you actually converge to the complex hull or to the feasible set that you want. In the infinite case, you will have asymptotic convergence. And again, I would not concern in here about the details of how this works, but the point is this actually realizes exactly this picture or this promise that we wanted of giving us a gradation, or of moving between my original non convex or discrete or whatever you want to think about set downstairs, all the way up, we have leno, this infinite dimensional space, when everything's wonderful and we live forever. And in the meantime, for any fixed k, we have better and better approximations, and sometimes, more often, even very small values of k may be sufficient. Right? So again, let me summarize, perhaps at this point, some of the things that are going on, really, all these hierarchies business gave us an explicit way of trading off how much convexity do you want versus how much are you willing to enlarge the dimension of your problem? We know what I told you before.
00:40:18.920 - 00:40:51.930, Speaker A: If I don't care about dimension, dimension goes to infinity, then we'll get complexity for free. On the other hand, when the dimension is small, my problem may not be complex, but there's a trade off in there, right? And hierarchies gives us one way, they give us one way of realizing this trade off. Of course, this is just talk. We need theorems that will show that what I'm saying is true, and they will quantify exactly how much we gain and we lose. And this is absolutely possible to do. We've done it. People have done this.
00:40:51.930 - 00:41:36.704, Speaker A: But the results may depend on specific problem classes. Right? For some problem classes, this is great, you gain a lot. For some other problem classes, it seems that you don't gain a lot. But on the other hand, we don't know anything that does it any better. And this is the other point that I want to emphasize, because sometimes it's a little bit confusing that when we, again, I gave you four, like this list of lino kind of, I think, you know, six or seven hierarchies or hierarchy machines that people have developed. And when you think about what makes one good or bad, right? I mean, never focus on just convergence, that after so many steps, whatever, you get the right. Because usually those results are kind of, somehow there's nothing interesting that goes on in there.
00:41:36.704 - 00:42:24.194, Speaker A: I think what's really important is to understand either quantitative results that will quantify exactly these kind of trade offs or empirical results. One of the very surprising parts of this whole sum of squares machinery in particular, as opposed to some of the other ones, is that really, it works very, very well in practice for relatively small values of k. We knew from before many hierarchies that will work with exactly the same kind of theoretical properties in the sense that asymptotically converge. But what was very interesting, what was very surprising is how well they perform, even for relatively small values of k. And again, I will not say too much about this. Okay, I have, like five minutes I need to wrap up. So there's been a lot of applications.
00:42:24.194 - 00:43:23.264, Speaker A: I will not spend time discussing any of them in detail, but really, pretty much, if you have any problem in whatever domain it is and polynomials are involved, I strongly suggest that you at least try to see whether these techniques can actually help you or not. There's problems that exist on the surface. They don't look at all like these techniques may be useful, like things that have to do with quantum information or things that have to do with fluid dynamics. And it turns out that you can do very, very interesting things, or robotics, and you can do very interesting things using this kind of machinery. The other thing, and this is also, I want to point out to some of the things that are going on at the Simons in this term. Leonardo Kendall is really trying to understand a little bit more the gap, I mean, or if there is a gap between theory and practice. One of the things, as I mentioned, that's very interesting of these kind of things, is that they're extremely good asymptotically in asymptote, the kind of regime where people in theoretical computer science usually work.
00:43:23.264 - 00:44:04.228, Speaker A: I don't care about the actual practical efficiency of an algorithm. I care most of the time about their asymptotic properties. But also they're kind of extremely good for many problems that involve a reasonable number of algorithms. It's very interesting, for reasons that I don't think we fully understand, why this kind of thing should be working well at both ends of the spectrum. People are actually using this in practice. If you actually want to solve, you want to make your robot walk. Some of my colleagues at MIT are actually using this kind of technology in order to understand how you compute controllers to stabilize a robot.
00:44:04.228 - 00:45:18.150, Speaker A: On the other hand, many of my colleagues at theoretical computer science are actually like here, they're trying to understand what are the limits of these kind of machineries. Let me also mention again, I don't have a lot of time to say something about practice, that a big part in here, what I describe, is, of course, only the tip of the iceberg, right. There's a lot of work that goes on. When you're given a problem, you don't just take it at face value, but you really try to exploit as much structures as possible. And there's a lot of work, and there's a lot of special techniques that will allow us to learn, or given an optimization problem, or given some family of polynomials, you want to understand, what is the structure of these polynomials, symmetry properties, sparsity properties, what are we defined? I mean, there's a lot of technology that will allow us to not write the obvious semidefinite problem that you will write, but to do some things in a very clever and smart way. And again, I don't have time at all to discuss this, but think about the end, everything that I describe as a very rough first cut of what's actually going on underneath. Also, there's a lot of incredibly interesting and enormous simulating connections with mathematics.
00:45:18.150 - 00:46:05.194, Speaker A: I mean, with Leon or with many, many areas of mathematics. I mentioned, I guess, the tip of the iceberg of these connections with probability. When you think about the things as just probability distributions, but in particular, some very foundational results in probability, things like the exchangeability theorem, the definitis exchangeability theorem, they can be understood very much in the same lines of what's happening in here. I guess I talked a little bit about quantum, but there's a very nice non commutative analog of all this story, where instead of thinking about polynomials in commutative variables, you think about polynomials in non commutative variables. There's an associated geometry with it, I mean, to it. And all these techniques are actually quite useful in that regard. Again, I can't really say a lot.
00:46:05.194 - 00:47:44.364, Speaker A: So in the two minutes I have left, let me say a little bit about what are the kind of things that people are trying to understand now? A lot of it. And actually, I'm doing a shameless advertisement for somebody happening at the Simons, I think, in a month or so, couple of months. So on the one hand, there's a lot of interest in trying to understand what are the limits of these machines, what are the limits of these hierarchies, what can they prove what they cannot prove? And there's been both very interesting positive results and very interesting negative results. Of course, it will not solve NP hard problems, but it really looks like enough that, at least for a very large class of statistical problems, we don't really have any algorithms that are any better than this, that this is, in a sense, and people like Boaz Barak have conjectured this, essentially an optimal algorithm, in a sense that one can make quite precise something that I'm more a positive and constructive person rather than computational complexity, rather than a complexity person trying to prove negative results. I really want to understand, can we produce better machines? Of course, very enormous interesting results will tell us that, at least in some generality, there's no better machines, but for particular problems, we can do things better. Again, I don't have time to discuss this, but if you come to the workshop, you may hear a little bit about it on the practical side, like I said, this is absolutely wonderful when it works. The real problem in practice is that these saps get very big very quickly.
00:47:44.364 - 00:48:44.084, Speaker A: If you have any experience with semidefinite programming, you know that solving large semi definite problems is complicated, not just, not so much because they take a long time, but really because of memory issues. And one of the things that people are trying to understand on the algorithmic side, much of work, again, by people here at the Simons, is trying to understand algorithms that perhaps achieve the same kind of guarantees in some situations, but they're cheaper to run the particular sense. And an example of these nice spectral algorithms. Or perhaps the idea would be to still solve this semi definite problem and give up convexity, try to do something perhaps quick and dirty. And I think it will be very interesting if somehow this program will succeed. And I think one of the things that, again, at least I'm particularly interested, is that, Leinor, we can get algorithms that are, I think, better than the great technology that we have based on interior points, but at the same time, they're still practical. I mean, they don't just work in the asymptotic limit.
00:48:44.084 - 00:49:44.642, Speaker A: My second and last, shameless advertising. If you want to know about all this stuff, there's a nice book that we co edited with Greg and Rico. You can get it, you can just download it. I'm not selling anything, so you can just go there. And I think that's it. Thanks for your attention. So the question is, what is reasonable, right? So I think a lot of it depends on structure, right? The right counting variable, somehow it's not really the right thing.
00:49:44.642 - 00:49:51.634, Speaker A: I mean, if you don't put any structure whatsoever, I assume things are absolutely dense, then.

00:00:00.360 - 00:00:46.170, Speaker A: Already this week and kind of follow directly to the previous talk, actually talking about how social interaction and multi agents systems may be a very interesting path for AI and at least the neural AI path of AI. So, like, no inspired architecture of AI. And so, as you see in the title, I'm very in the social thing. So I would start by the social whoops. Thinking of thanking all the people that I had the pleasure to work with. I love this concept of ubuntu in African, which means like, I am because you are. And clearly we are a network of minds mind jazzing.
00:00:46.170 - 00:01:47.870, Speaker A: And so far, like, the week was a good mind jazz so far, and also thanking my team in Montreal. So today I have like, two main parts. One is about social physiology, which is like trying to tackle what some people metaphorically called a decade ago, the dark matter of neuroscience with social interaction. The time, like the literature, was rather poor in studies studying two individuals in interaction who have. Early earth was part of these pioneers. And over the last decade, there has been a lot of progress in that space. And the second part going to be like, are we going to turn those things regarding the question of AI? And I won't speak too much of AI per se, but more like bringing elements that could be actionable potentially by artificial intelligence researchers.
00:01:47.870 - 00:03:03.110, Speaker A: And so let's start with social physiology and how humans interact with others. So, in that space, the plan was to study social interaction with experimental staff, but also with computational models. And one of the key thing come from actually developmental psychologists who have been studying social interaction for decades using videos of parents interacting with their kids and trickery. I had the chance to be supervised by Jacqueline Nadel, who spent a lot of time showing how very early those kids are able to decipher genuine real time interaction with their caretaker from an interaction with the video of the caretaker. So we have, like, very early in life, the ability to connect with people and enter in coupling with them. We started by using the same kind of system with multibrane recordings to understand what, from a neuroscience perspective, change when you are actively interacting with another individual compared to perceiving social stimuli. And so the setup is simple.
00:03:03.110 - 00:04:23.520, Speaker A: We have two people in two Faraday cages. They are imitating each other and movements, and we have conditions where it's forced in one direction, but we have also this kind of condition where it's a spontaneous turn taking that happen. And so we analyze how this dynamic unfold and what are the neural correlates of that. And so one first correlates is to show that indeed, during social interaction, neural correlates that you can observe are different from what happens during perception of social stimuli. But even deeper than that, actually, the role that you are taking during the interaction and the context in which this interaction unfold also change the way the brain process information. But more surprisingly, and I was, like, strongly influenced because I was in the former lab of Francisco on the work on neural synchronization within brain. What we also wanted to test is, like, at the dynamical level, if we take the two brains and the two nervous system in interaction as one system, can we observe signature of social phenomenon? The idea being that when we have two sensory motor.
00:04:23.520 - 00:05:02.826, Speaker A: When we have a sensory motor coupling between two nervous system, they may converge at some point on a synchronized state. And so that's one of the result that we obtained. It has been also observed in many other studies and modalities. But clearly, there is this phenomenon of synchronization. At first, it's more like a marker. And a lot of people thought it was even not possible in the beginning, but also more like an epiphenomena. And for the last ten years, I've been trying to make sense of that and try to understand the underlying mechanisms.
00:05:02.826 - 00:06:18.808, Speaker A: Typically, for instance, like, we observe very fast synchronization in gamma band, which doesn't make sense from a behavioral point of view. And recently, in the Journal of Neurophysiology, we had a model that explained maybe why we can observe such gamma band oscillations, synchronization so well. We then explore other types of social interaction in language, modulation of the familiarity between the people interacting. So if it's with a best friend, your romantic lover, or a stranger, what is the ability that you have to connect and to synchronize with them? And how it may be modulated by the type of task that you're doing. So, like, typically, for instance, what we found that is very funny is how getting to know someone through a long term relationship may help, for instance, to couple and coordinates for sensorimotor tasks. So the more you know the person, the better you are at coordinating at the sensorimotor level. But for empathy giving and cognitive tasks, the romantic couple were more disengaged at the neural level than the stranger or the friends.
00:06:18.808 - 00:07:42.216, Speaker A: Because one of our thesis would be like, for instance, that we internalize more the model of the other person after a long term relationship. So now we are working with couple therapists to try to study that in couples. So we also looked at interaction that were not rhythmic, because one of the strowman was like, well, social interaction are rhythmic and you have motor behavior. So that's a mutual entrainment of the two brains that happens. So we study, for instance, social touch without stroking, like just holding the hands, to show that also this kind of synchronization may be a marker of something that is more social than just mirror sensory motor entrainment. And more recently also, we studied in babies with their mother, how olfaction may also be a factor that enhance this synchronization, and how actually it may be an objective marker, for instance, to detect how babies are engaging with adults that are not even their real mother. So, in that experiment, the ethical committee accept that we made mothers sleeping two days in a row with the same t shirt, putting that in a jar, and then having other mothers wearing the t shirt with the body odor of their real mom.
00:07:42.216 - 00:08:50.178, Speaker A: And we show that baby can be fooled by this body odor typically, and also something that connect with what we discussed. Also regarding technology and zoom, we show that during this kind of technology mediated communication, those mutual entrainment and those synchronization tends to be reduced and potentially connect to this zoom fatigue that we all have, I suppose, experienced and still experienced, because in a sense, like the integration of self and other information in those settings is perturbed by the jitter and the lags and so on from the communication device. When we are face to face, there is no delay and no problem for the interaction. There is a growing interest in those multibrane neuroscience thing. There's also. So now we have a lot of papers per year on that. I like to bring back to the early days of 1965, where maybe the first hyperscanning paper has been published in science at that time.
00:08:50.178 - 00:10:06.318, Speaker A: You can publish in science with just one sentence and one figure. So those people at that time were claiming to have demonstrated telepathy in identical twins. That was never reproduced, of course, but that may explain why during 40 years, almost nobody tried to record multiple brains ever after that. And it's also a reminder that we need to be careful also with the claim that we are doing with those metrics and those results. So, since then, also on top of trying to understand the mechanisms underlying those interbrain synchronization and their potential function, we have been also very active to bring technical guidance for the community at the hardware level, at the software level, trying to develop open source software for that, and bringing back also philosopher to explain the different factors that may be at play in this shadow of at the dynamical level. Because, of course, when we are looking at this measure of similarity between two people in interaction. It's a compression of many, many factors, whether it's like the similarity between the two systems that we're observing, or the communication and exchange of information between those two systems.
00:10:06.318 - 00:11:05.154, Speaker A: And so the interesting aspect here is that the. The similarity may be actually a factor that modulates our ability to communicate. So, my lab is in a child hospital. We're looking a lot to neurodevelopmental disorder and autism to see how the dissimilarity and the neurodiversity impact this ability to synchronize and coordinate with other people. But on the other side, and we saw with the talk just before, it's true communication that we are creating culture and common ground and similarity of our behaviors. So the big challenge, in a sense, is to bring explanation to this phenomena. So, there are many ways to approach that from using hyperscanning and try to have direct intervention to have more like, I borrow from Cravr, the type of explanation for neuroscientists, more like causal at the structural level.
00:11:05.154 - 00:12:37.264, Speaker A: So, studying how the brain structure underlying social cognition may lead to this phenomenon of interbrain synchrony, and through computational modeling, also have counterfactual and test hypothesis about what's the nature and what the function of those things. And recently, that very interesting experimental results show that also beyond even an epiphenomenon or marker, those synchronization between brains may have also a downward impact on the social behavior itself. So, like, by using interbrain stimulation in mice, they show that they were actively changing their social behavior by artificially inducing interbrain synchrony. So I won't speak too much about that, but I wanted at least to briefly say that that has consequences for the way of seeing psychopathology and mental health. And typically, even through the NIMH, which is to me, like the counterbalance of the DSM way of boxology of disorders, even the dimension in the erdog of NIMH stop at the behavior and doesn't take into account the social dimension. So I think there is, like, a lot to do in that space. We can combine a more like omics perspective that biomedical research is embracing with a more like also integrative neuroscience and have quantitative results for achieving precision psychiatry.
00:12:37.264 - 00:13:40.480, Speaker A: But I like also the term interpersonalized. I may spell it psychiatry, because in the case of psychiatry, it's more than just precision. It's also taking into account the person and their experience. And I will come back that at the whole end, with more like, phenomenal consciousness issues. So that was like the stage for more like where I come from in a social neuroscience perspective and those weird phenomena, like, I like the quote of Isaac Asimov to say, like, the best sentence to hear in science is not Rekha, but that's weird. And like, well, what do we do with that from artificial intelligence point of view and computation? So here, well, we are in the bay Area, so we have first part that is more like biophysics to try to understand with computational method what is going on with those interbrain synchrony. And on the other end, there is more deep learning and top down approach for that.
00:13:40.480 - 00:14:39.726, Speaker A: So for the biophysics side, when we started to have this phenomenon of interbrain synchrony, we were asking like, well, what is the contribution of similarity at the anatomical level to this phenomenon? So, fortunately, at that time, they were like the start of connectomics with Hackman and so on. I remember this poster in my dorm with the first connectome. It was wonderful. And using this kind of data, we were able to simulate, basically this sensory motor coupling between two brains in silico, in the computer. So we have, like the two connectomes of these two people. And in the same way that in the experiment I show you, the two people are imitating, spontaneously their end movements. Here we are coupling those oscillators at the motor regions of one brain to the visual region of the other brain, and vice versa.
00:14:39.726 - 00:15:48.854, Speaker A: To create this coupling at the sensory motor level and to be able to compare, of course, with the EEG data, we use Maxwell equations to put a virtual eeg cap on those virtual brains. So it's like brain in the vats with their virtual eeg in order to compare with what we observed in the real experiment. And so first, at the intrabrain level, what we observe is that the real anatomy smooths out the transition between absence of coordination between the brain area and a full coordination, which means like epileptic seizure type. So that was already known by physicists. But the real anatomy, the backbone of the brain, the connectome, have this property of smoothing out this transition. And so you have a bigger regime of working even in a noisy environment, while if you take the shuffled anatomy, so you have the same whoop, there's a delay. Yeah.
00:15:48.854 - 00:16:50.244, Speaker A: So if you take like a shuffled anatomy, then you have a very sharp transition. So you are either dead or epileptic scissors, kind of like. So that's a property that was already interesting to reproduce. It was already known. But at the interbrain level, what we found that was not new at the time is that this real anatomy not only facilitate integration of information within brain, but also the integration of information between brain. So you have a kind of greater propensity to enter in synchrony with another person that share this anatomical structure. Another also important message from these simulations, that even with scrambled brains at anatomical level and without any exchange of information, you still have a residual synchronization between the two systems, which is like something super important for this field, because it's not surprising to observe interbrain synchronization on the absolute value, because we are not random number generators.
00:16:50.244 - 00:18:07.530, Speaker A: So our dynamics is on average similar. But the interesting aspect is more like to look at the increase of similarity at the dynamical level through interaction than the absolute value itself. So again, that has some consequences for our approach of mental health. So typically, in the case of autism, instead of looking at one brain region or one gene, here, we can see how diverging from the norm of the anatomy could lead to a collapse of this ability to coordinate with other. And this align with a theory called the misattunement hypothesis of autism, where a small variation, initially at the biological level, going to percolate through cognitive behavioral interaction and the sociocultural configurator. So here it's more like a process model of autism, where instead of saying like, autism is this gene or autism is this brain area, it's more like autism is actually a different trajectory in the developmental space that is associated with a different of the embodiment of the nervous system. So that bring also to breaking news.
00:18:07.530 - 00:19:24.104, Speaker A: So that's more like a funny slide that cognition is multiscale in the sense that we have to deal with those very down towards implementation details of the wiring, but also the social dynamics that take care between people. So they were like this paper by Christoph Kor in 2012, where you say like, biological systems are characterized by a large number of highly tertiary components, beta gene, protein, or cells. These components interact causally in myriads of way across a very large spectrum of space time, from nanometer to matter, from microseconds to years. A complete understanding of the systems demanded large fraction of this interaction be experimentally or computationally probe. You finish the abstract by this is very difficult. So, yeah, well, a long time ago, in a country far, far away, France, they were like someone called Claude Bernard, who wrote this treaty of experimental medicine, and he was already complaining by the fact that people were tending to reduce phenomenon of physiology. Like, he's a father of physiology, basically to reduce that to physical shamic reaction.
00:19:24.104 - 00:20:52.182, Speaker A: And as a system theorist, in a way, he wanted to critique this viewpoint that maybe reductionism may not apply to the category of things that are living things. And even if the classical reductionist mode of operating in science and biomedical research has found many, many interesting results, the thing is that we should be remind that nature doesn't care about those scales and those different way of observing at one scale or another. And those scales tend to even interact between each other. And so in a sense, how through this kind of realization, we can operationalize that in our way of studying the brain and potentially translate that for AI. So here, the thing is, I take a very different viewpoint that David Marr, that would separate the function from the algorithm and the implementation, and saying that to fully understand the function, you need to completely integrate all the scales. Like, you can't ignore the implementation level and throw the baby with the badwater by saying, like, we don't care, it's just implementation, because we don't have a clear view on what are the implementation detail yet. I mean, we don't have a full understanding of the implementation of the brain.
00:20:52.182 - 00:22:14.696, Speaker A: And even if we have a full understanding, there's this funny paper that maybe some of you know, like where will neuroscientists would still be able to understand a microprocessor and they want with the classic methods that we have. The problem is, like, the brain is even more challenging than a microprocessor, because the way it's designed by evolution involve this kind of causation between scales. And so, like reducing the computational level at just like sort of upper level, while neglecting the implementation, may lead to miss something. And physics has been like a pretty good example of that. So, like, there are phenomenon like phase transition in physical systems, such as like thermal, magnetic or quantum system. Like Kenneth Wilson was explaining with the renalization group, that were not explainable with classic mean field theory. So in a sense, like we were experimentally observing something, like measuring magnetization was super easy to do at the empirical level, but our computational models of things were failing to replicate what we were empirically measured, which is like super cool when it happens in science, because it showed that we have something to learn.
00:22:14.696 - 00:23:33.412, Speaker A: And what Kenneth Wilson did is actually by the normalization group formalism, show that you can explain those phase transition better, but also predict even phase transition that were not yet empirically observed. Which is like, to me like the best you can do in science, predicting even things that have not been yet observed. Like the Mandelief table, for instance. And in that situation, the thing is, we have to take into account all the scales simultaneously for the case of phase transition. So pragmatically, how to do that? There are a lot of efforts in different countries to try to do multi scale modeling of the brain in a very realistic way, like the human brain project, to more abstract ways with more deep learning, architecture and so on. The problem is, again, if we take the on premise that we have not yet all the implementation levels understood, how we can connect those different levels in the same lingua franca. So here I took a bias because I'm coming from physics, but to use dynamics and dynamical systems as this langua franca between scales.
00:23:33.412 - 00:24:57.320, Speaker A: But also, interestingly, with dynamical systems, you can connect patterns of the sort of you can observe in nature, like in phase coordination, synchronization, and so on, with more like dynamics of elements of a system. So you can have phenological similarity dealing with different type of phenomena. So, for instance, like the phase transition that you can observe at the brain level, maybe model also at the phenological level as a phase transition at the subjective level. So you can use those similarity of dynamic phenomenon to glue phenomenon that were not in the same space originally. So let's go back to artificial agents and machines. Concretely, if we use this kind of formalism, what can we do? So, like, that was the finger wiggling project that we have a lot of discussion and love before. So I went to work with Scott Kelso, who spent, like a lot of his career, like multiple decades studying figure wiggling, which seems like maybe a very anecdotic thing like that, but ultimately led to the discovery of form.
00:24:57.320 - 00:26:09.536, Speaker A: A dynamical form called the hacken Kelso bunds model were based on a very strange, again, phenomenon of finger wiggling, where if you try to wiggle your finger like that and accelerate, at some point your finger is going to switch in phase. And this thing was interesting because at that time, there were a big control theory of motor theorists, and that was challenging the idea of motor control as a pure top down thing. And he went to physicists to say, like, how you would model that with physics. And Herman Hacken was like one of the father of synergetics. And studying the physics for laser showed that actually, in this example, you need to take the two fingers as one system. So the more predictive aspect is not the finger, but the relational phase between the finger. And so, like this, clearly, the kind of thing where the dynamics is not anymore about the subsystem, but you have to take the phenomenon of the two systems as a wall to be able to predict.
00:26:09.536 - 00:27:23.602, Speaker A: And so we put that in a machine and having, like, humans interacting with this finger wiggling model. And interestingly so, we had, like, purely social psychology results, where having a model that is reciprocally coupled with the human allow a very natural interaction, and you can control someone was saying before, our prediction of another person that is also affected by yourself leads to a very strong divergence here. Like, the idea is, since we are controlling half of the dyad from experimental. From the experimental point of view, it's very interesting. So, typically, we have, like, the agent being cooperative all the time, or competitive all the time, or changing its behavior. And we ask, at the subjective level to the people interacting, how do you felt about the other person? And one of the result that was funny is typically that the worst judgment of being competitive is when you are, like, cooperative initially and you switch to competitive. So that was a first thing interesting, but the second one was in the context of cooperation, even if mathematically the system is cooperative.
00:27:23.602 - 00:28:37.782, Speaker A: In the same way, the difficulty of the task tend to make the person attributing less cooperation to the other person. So, like, instead of saying the task is more challenging, they were blaming the other of not being cooperative. Then we can combine that with neuroimaging and understand how self and other information are processed in the brain. And what we found is that actually, and that's more like the structural position that I was talking about earlier, the interbrain synchronization that we observed in the first part were actually massively at the right temporopietal junction, which is well known for social neuroscientists. But what we found using this nonverbal Turing test is that when we look at the neural networks that are informationally coupled to the self behavior and to the other behavior, the RT PJ is more like the hub between those two representations. So, like, in a sense, the two brains share at the same place, the same information, because there is the self and the other simultaneously overlapping there. So it's like the best candidate for having a similar dynamics in both brain.
00:28:37.782 - 00:29:56.084, Speaker A: So that may explain one of the aspect of the puzzle. And what we show also is that these more like sensory motor integration between self and other, then functionally connect with more frontal regions associated with planning and attention, attribution and theory of mind. When we were asking the subject to also subjectively report and judge how cooperative they felt the other person was, or if they also thought, I, it was a human or a robot. So, well, that's one example of application of those dynamical formalism in human machine interaction. Another application that I won't detail too much is to combine that with machine learning for neural modulation and basically neural technology. But if we go back to the core of the topic of this week, so, like, higher level cognition, what this social twist to cognition may bring in the table, in a sense, and there is like three main dimensions that are to be connected here. First, the fact that machine learning is still poorly integrating dynamics in their algorithms.
00:29:56.084 - 00:30:47.786, Speaker A: So we have like feedforward network or irreconcil network, but it's only starting to have differential equation directly in the models. And our brains operate in time. It's not like time is transcendent and outside. Actually, we are physical systems where time has a role in the way things are computed. And it's connected with this second axis, which is biological plausibility, where deep learning was the first already iteration on that. Like to take neo connectionism seriously and move from old fashioned AI to something that is more plausible at the biological level. But here, the plan is to go to even more plausibility by adopting cognitive architecture from leading theories, typically global workspace and those kind of cognitive architecture at the macro level.
00:30:47.786 - 00:31:32.020, Speaker A: And the third one is social embodiment. So like how to move from a disembodied chatbot that doesn't have this reinforcement learning with the world to something that is more embodied at the extremist robot. But we saw just previously, our 3d games can totally, actually, it's a screenshot from your work, can totally help in designing intelligent embodied agent at the virtual level. So one argument, because like you can say, well, okay, that's your opinion, man. The thing is that evolution tends to have a strong case on that. So I look this noting in biogic makes sense. Whoops, except in the light.
00:31:32.020 - 00:32:33.014, Speaker A: Oh, definitely don't want to, except in the light of evolution. So in this part, I will make a little detour to show that actually, from an evolutionary standpoint, it makes sense to predict other people's behavior. And there are even a way to flip the coin and say, like, well, maybe it's actually the thing that came first. Like our euler level cognitive ability may have been driven by the fact that we needed to predict other behavior and to study that. So I spent like five years doing genetics on primates and humans, and we compared all the genes expressed in the brain and tried to look at what genes have been evolving or being conserved. And to our big surprise, actually brains tissue are very conserved compared to other tissue in the body. And massively it's associated with the synapse so you don't, don't mess with the synapse.
00:32:33.014 - 00:33:55.286, Speaker A: It's super conserved. If you have mutation in synaptic function, it also usually go bad. But so if the synapse and most of the brain are conserved on average, what would have evolved the most? So, first, we show that indeed, the brain structure involved in social cognition and language tends to accumulate the most drift from evolutionary standpoint. And also, interestingly, the cerebellum also tends to have a strong, strong signature of evolution. And it's aligned actually with paleoanthropology, which show that the skull of homo sapiens have change a lot at the part of the cerebellum, rather than prefrontal cortex, typically. And well, there is a renewal of interest in cerebellum, because not just to hold our head on the back, but it's also have a cognitive impact and social implication of cerebellum. And when we look at more like the single cell level, the changes are more affected, the morphogenesis and the fact that you have the number of neurons, rather than a specific break, typically our results doesn't support the fact that it's one gene that pop up and we are Homo sapiens and we talk and so on, like Fox p two, for instance, but more like a very diluted drift of many genes that tend to associate with social cognition.
00:33:55.286 - 00:35:15.706, Speaker A: And so that's go well with what we heard earlier on neotiny and social learning, because typically one of the signature of homo sapiens compared to other primates is this extension of window to learn and being encultured. And it's strongly associated with this molecular level. So with Jean Pierre Changer, we started to look at what are the basic biological mechanisms, starting with biophysics, but in the same spirit at Namo, removing what is a surplus and trying to find the minimal biological mechanisms to allow to learn, access consciousness. So not subjective experience, but access consciousness with the global workspace. And we ended up with actually the same kind of bricks that Nemo, but with dopamine on top. So in our case, it was clear that you need a reward signal on top of the avian learning to achieve higher order combination of representation and solve tasks that are associated with access consciousness, such as trace conditioning. But the metacognitive and social cultural level was still missing in the model, and we saw with the talk before how challenging it can be from a computation point of view.
00:35:15.706 - 00:36:28.600, Speaker A: So instead of biophysics, what we are doing is trying to have this social component on deep learning architecture. So very like the work in the talk before. But instead of having pure deep learning, efficient in an engineering way, try to grab from biology strong inspiration and have inductive biases from this biology. So in that work, we take inspiration from attention schema theory from Michael Graziano, which has not a very clear computational implementation yet, but still is compatible with global workspace, and propose a way to have a loop regulation of attention. I'm not definitely agreeing with all the theory. I'm just saying that it's very interesting from a functional and computational standpoint. And what we do, because we have way less GPU's than OpenAI, is to do a wall grid in 2d with those little agents interacting socially and trying to show how the pressure that we put on those agents to cooperate are compete, then leads to a higher level cognitive ability at the individual level.
00:36:28.600 - 00:37:46.880, Speaker A: So the last slide is about like also how the social aspects connect with ineffability and consciousness topics. So we have this work with the Mila colleagues, where we try to interpret ineffability and the richness of experience, and this kind of disconnection between the subjective experience and the qualia, and the potential poor language description of it in terms of information loss. So we had a lot of discussion with Leonard Blum on that here. The thing that is interesting from a social perspective is that actually this ineffability that operate between people is also operating between brain structure. So like, in a sense, like this information loss that you can have by transmitting what you're experiencing to another person is also maybe like the same loss that you would have when you transfer from the pure experience to working memory or long term memory. So I want to put that there because in a sense, that's a. That's where maybe also relevant for all the question of artificial consciousness here.
00:37:46.880 - 00:39:02.720, Speaker A: So, the open question slide. Well, from a pure social physiology side, I think the differences between what is required for interacting truly with other people and what is more like social, but in the offline mode is not clear yet. And some people completely disagree with my position and saying, like, we just need single brain recording and old fashioned social neuroscience, there is no need for multi brain recording. Well, I tend to have show you that there are phenomenon that could not be reduced at one single brain. So the next question is, is it like just a marker or is there like a mechanism underlying this phenomenon? So the experiment with the mice that I show, tends to show that it may be more than just a marker. So we need more model and causal explanation of what's going on. And the thing that I'm super interested is like how to connect this phenomenon at the social level and neuroscientific level with the subjective experience, and how the phenological experience of interacting with other person is fundamentally different than interacting with something that is nothing.
00:39:02.720 - 00:40:26.788, Speaker A: So typically with the virtual agents or a human. So that's more like from the human physiology side and on the other side, on social neural AI, what are the inductive biases and the type of curricula that need to be applied for having social coordination between artificial agents? So we saw how massive compute are needed. The scaling law of multi agent reinforcement learning are pretty bad. To what extent we can use social neuroscience to create more inductive bias in the architecture to improve that. And in that sense also, another question that is super interesting is the link between the ability of predicting these other agents and the ability of having our own self reflective action to metacognition, and what kind of advantages it could bring to those agents to have to deal with others agents extensively. Will it induce also a better ability to self reflect? Another big question that asked earlier is the question of agent abstraction. And we have first attempt of theory of many minds, like how to do theory of minds with group of agents as one group.
00:40:26.788 - 00:41:42.522, Speaker A: And it's very interesting to me how sometimes we are dealing with the other people's as one pool, like seeing the in the basket player, seeing the other team as one activity, or like all the person of the team as single individual. And what is the advantage of that computationally? I think from AI perspective, it could be super interesting to have optimality threshold to know how to chunk information when you have to deal with many, many agents, not undiag one, but in large context. And finally, like how we can simulate culture and innovation. So we have an attempt to simulate those systems like what was said at the end, like not using those multi agent system necessarily for solving tasks, but more like as a sandbox for policymaking and for understanding human systems in general. So, like we have for instance, a project on using multi agent reinforcement learning for climate coordination. So like studying the different policy that we can put to facilitate coordination towards like climate. So those are like really big open questions.
00:41:42.522 - 00:41:47.100, Speaker A: But yeah, so thank you very much for your attention. And, yeah.
00:41:59.080 - 00:42:23.104, Speaker B: I wonder, first of all, this is very cool. I feel like I need to watch this three more times to unpack all that information. But I was wondering like, do you have a specific idea of how to integrate dynamical systems in machine learning? Like, is there like a simple thought about that? That is, yeah.
00:42:23.152 - 00:43:06.976, Speaker A: So on that we have a lot of work at the intersection of neuroscience, machine learning and dynamical systems. So there is like three main class of approach. Some are like very phenological, like oscillators and so on. And you can plug that to a deep learning system to predict the dynamic in the future. So we have a paper like that showing you can better predict brain activity in the future if you inject equations of brain dynamics. And the deep learning just fit the. The parameters of the equation rather than rebuilding the whole theory from the scratch.
00:43:06.976 - 00:44:01.110, Speaker A: So typically, you help the algorithm to know what it's to search for. So that's one way. There's another way with typically goku net, where like here you can even do like a sort of auto encoder, but with differential equations. And so the system try even to reconstruct the dynamics. And there's like a work called novel Ode where you can combine differential equation with deep learning. So those are like emergent techniques. And then there is like also methods like Cindy, where you take all your data, you create, with multiplying them, a basis of all the possible terms of differential equation, and then you build from there like a predictive model.
00:44:01.110 - 00:44:03.910, Speaker A: So there are different approach. Yeah.
00:44:07.330 - 00:44:21.390, Speaker B: So this is a very interested question. At the end, you talked about the open questions, so I want to ask you about the open questions and where you think you're going in that direction between marker and mechanism.
00:44:22.210 - 00:44:22.634, Speaker A: Yeah.
00:44:22.682 - 00:44:26.006, Speaker B: What causes what, what you're showing us.
00:44:26.198 - 00:45:15.310, Speaker A: Yeah. So typically, like, from the early start, like, I mean, I was joking about the science paper, but even during my master, people were thinking like, I was doing power up psychology. So now it's clear that there's a marker. It could be value for diagnostics or prediction, or even to decipher cognitive theories in the proper experimental settings. But going from a marker to a mechanism require a more interventional aspect. So we don't have optogenetics, like the mice stuff, but in the lab, we bought things for doing multi brain stimulation in humans. So that's the next step for me, like having causal intervention and show that it has an impact on behavior.
00:45:17.340 - 00:45:21.052, Speaker B: Cool. Okay, I think we can move on.
00:45:21.076 - 00:45:28.700, Speaker A: And take a break. Thank you. Yeah, thanks. So we have.

00:00:01.360 - 00:00:45.068, Speaker A: Let's get started. I'm just introducing the next speaker. It's Puneet Nipritali talking about smooth analysis for low rank solutions to SDP. Thank you all for coming to the top. This is joint work with Srinath Bhojanapalli, Nikola Bhumal, and Fateek Jain. So, as the title indicates, we are interested in solving semi definite programs. These are problems where we used to minimize a linear function c times x, subject to linear constraints, aix equal to bi, but with additional constraint that x has to be positive semi definite, meaning that x is a symmetric matrix and all its eigenvalues are non negative.
00:00:45.068 - 00:01:46.610, Speaker A: Okay, and it has several applications. I perhaps don't need to stress on these to this audience. And there also exists polynomial time solutions for solving semi descent programs. And examples include ellipsoid method, interior point method, multiplicative weight update, and so on. Okay, even though these are column l time methods, they have problems scaling to extremely large problem sizes when you try to solve them in practice. And in order to cope up with this issue, Bureau and Montero in 2003 proposed a new approach to solving these programs, solving these problems, and they demonstrated that these, their approach is actually empirically very good. It performs very well on a large class of problems, and they also provide a lot of interesting, they also show a lot of interesting results about their approach, but they do not manage to show a general proof of correctness on general semi definite programs.
00:01:46.610 - 00:02:34.140, Speaker A: Okay, I'll come back to explaining what exactly the bureau monitor approach is in just a minute. But the basic building block that starts out the bureau Mont row approach is this older result by Barvinok and by Pataky, which basically says that for any feasible semidefinite program with M constraint. So m here stands for the number of constraints. As long as it is feasible, there exists at least one solution whose rank is at most square root of m. So if the number of constraints is m, then there exists at least one solution whose rank is only square root of Microsoft. And in several practical applications, m, the number of constraints is the same as the ambient dimension n. And this means that you actually have solutions whose rank is square root n.
00:02:34.140 - 00:03:20.724, Speaker A: So in general, there is a priori. There is no reason to expect that there can even be a solution of rank n minus one. But it turns out that as long as you have only n constraints, you have a solution of rank, only square root of n. Okay, now what are the advantages of these low rank solutions? So, the first one is that once you have the solution, you only have to use n to the 1.5 space to actually store the solution rather than n square, so it reduces the memory requirement. And on the other hand, whenever these sdps actually come up as relaxations of combinatorially hard problems, whenever we can find low rank solutions, the rounding procedure actually has better guarantees depending on the rank of the solution that you find. So these are the two main advantages.
00:03:20.724 - 00:04:15.270, Speaker A: And the bureau Montero approach actually gives us a, tries to find a third advantage, which is that they want to use the existence of these low rank solutions to actually find them faster, to actually solve this optimization problem faster. And what is this approach? So the problem on the left is the original semi definite program where we wish to minimize cx subject to these constraints. The main idea behind this Bueller monitor approach is to write x as, as u u transpose, where u is factorized only by a n cross k matrix, okay? And k is usually, as I mentioned, much, much smaller than n. And once we replace x to be u u transpose, it has two advance. It basically enforces two things. One is that x is automatically positive, semi definite because we are writing it in the square form. And second one is because u is a tall matrix.
00:04:15.270 - 00:05:13.212, Speaker A: X is automatically a low rank matrix. So the modified problem that we wish to solve is to minimize c times uu transpose, subject to AI uu transpose equal to bi. Okay, this is the constraint problem that the bureau monitor approach tries to solve. Now, this is still a constrained problem, and one of the ways to try solve a constraint problem is to first turn it into an unconstrained problem and solve the unconstrained problem. And one of the basic ways of doing this transformation is to write the penalized version where we have the objective, which is c times uu transpose, and then we have a penalty parameter, which is mu, and then we add a quadratic penalty, which is AI uu transpose minus bi. This basically tells us how much we are, we are not satisfying a particular constraint, and we put a square and then mu basically penalizes, gives us, tells us how much to penalize each unsatisfied constraint. Okay? And now we have converted this into an unconstrained problem.
00:05:13.212 - 00:05:51.050, Speaker A: We can try to solve this. I should point out here that the penalty version is not the best way to convert a constrained problem to an unconstrained problem. And there are more sophisticated ways of doing this. But for the purposes of this talk, I'll just focus on the penalized version. And towards the end of this talk, I'll say a bit more about more sophisticated methods like augmented Lagrangian and so on. Okay, so how do we solve this penalty problem? Penalized version of the problem. So the main challenge is that even though f originally is convex in the x space, so the penalty version, the x space, is convex.
00:05:51.050 - 00:06:34.978, Speaker A: It turns out that this UU transpose factorization makes this non convex. So the question is, how do we solve this non convex problem? And in general, solving non convex problems is np hard, and we cannot hope to do it. But for non convex problems, we can actually solve for what are known as stationary points. And let me introduce what stationary points are. So first order stationary points are just those points where the gradient is small, and second order stationary points are those where the gradient is small and Hessian is almost positive. Some. This is the second thing here we can actually find second order stationary points very efficiently.
00:06:34.978 - 00:06:46.274, Speaker A: And there actually has been a lot of recent work in making finding the second order of stationary points very, very efficiently using just gradient descent and first order algorithms.
00:06:47.014 - 00:06:53.834, Speaker B: Why do you make on the second order condition, why don't you say greater or equal to zero? Why do you allow it to be a little bit negative?
00:06:54.214 - 00:07:05.270, Speaker A: Because, in fact, just because we cannot solve anything. Exactly. So we cannot get a gradient equal to zero and similarly right weight or equal to.
00:07:05.342 - 00:07:06.742, Speaker B: But you allow it to be a little negative.
00:07:06.798 - 00:07:13.062, Speaker A: You could allow it because it's hard to distinguish whether there is an extremely small eigenvalue or not.
00:07:13.118 - 00:07:14.718, Speaker B: You could just say greater or equal to zero.
00:07:14.766 - 00:07:21.110, Speaker A: Right. I'm just wondering in general, like, iterative methods cannot get you exactly equal to.
00:07:21.142 - 00:07:24.354, Speaker B: Yes, yes. So you say you can ask for greater or equal to zero.
00:07:26.214 - 00:07:29.794, Speaker A: What will asking for greater than or equal to minus?
00:07:30.974 - 00:07:33.726, Speaker B: I was just wondering whether it's going to be a trick in your analysis.
00:07:33.790 - 00:07:48.050, Speaker A: No, it's not a trick in my analysis. So all we really need is this. And this is what people have looked at. But I guess if you use second order methods where you exactly query the Hessian, then you can exactly check whether it's greater than, because you are doing.
00:07:48.082 - 00:07:51.290, Speaker B: It by representing the matrix as UU transpose, right?
00:07:51.362 - 00:07:51.626, Speaker A: Yeah.
00:07:51.650 - 00:07:56.426, Speaker B: That's how you force it to be that way. Never mind, never mind. It's okay. We can talk about.
00:07:56.530 - 00:08:22.118, Speaker A: Sorry. Sure. Okay. So the point that I want to make in the slide is that for non convex optimization problems, it is indeed possible to find second order stationary points efficiently. And we can use those algorithms on this problem. So we will find a second order stationary point of this optimization problem. So what can we say about the second order stationary points? In a recent work, Bhumal et al.
00:08:22.118 - 00:09:00.098, Speaker A: Actually showed that once k is greater than or equal to the square root two m, which is the same as the existential result that I mentioned earlier for almost all Phi. So C is the objective here. So C is the objective in the semi definite program for almost all C, every second order stationary point is actually a global optimum for this optimization problem. Okay, are there conditions on mu? There is no for every mu. So you pick c at random with probability one. For every mu, every second order stationary point is a global optimum. Yeah.
00:09:00.098 - 00:09:29.934, Speaker A: Is there an epsilon that modifies second order stationary point? The previous slide, you had epsilons floating around. Yeah. Okay, so this statement is for exact second order stationary points, where you put epsilon equal to zero. So these are approximate definitions of first order and second order stationary points. And this is precisely one of the questions that we want to ask. So this result basically says that exact second order stationary points are exact global optima. But in practice, you cannot find exact second order stationary points or first order stationary points.
00:09:29.934 - 00:09:31.374, Speaker A: What?
00:09:32.434 - 00:09:33.974, Speaker B: You qualify that?
00:09:34.434 - 00:10:10.684, Speaker A: Okay, so for the purposes of this talk, you can think of where so bad fee have Lebed measure zero. That's what it means. Okay, so a bad C will be that it has some second order stationary point which is not a global optimum. Yeah. Then the set of all such c has Lebec measure zero under what measure? Under what the bad c bat c lies in n cross n space. Right.
00:10:11.864 - 00:10:17.244, Speaker B: Is that also hold in finite precision computation? When you compute that thing.
00:10:19.734 - 00:10:57.260, Speaker A: This is just an existential statement. There is no competition involved here. So this result basically says that almost always that with the C that does not satisfy, this property has limit measure zero. Okay, so this leads to two open questions. So the first question is whether there exists bad fee in this Lebek measure zero set, for which second order stationary, like there is a second order stationary point, which is not a global optimum. Right. Is this almost all? Is it really necessary? Or is it just that it's a proof RT file.
00:10:57.260 - 00:11:46.980, Speaker A: Okay, so that's the first question. And the second question is precisely the computational question that we want to raise, which is that in practice, we cannot find exact second order stationary points. We can only find approximate second order stationary points. So does this statement also hold for approximate versions, meaning that our approximate second order stationary points approximate global optima? Okay, so these are the two questions that this result gives rise to, and we answer both of these questions affirmatively. First, we show that we can construct C for which there are bad second order stationary points which are actually not global optimum. So this almost all is actually required. And second, for perturbed sdps, I mean, because this almost all is required, you have to add some amount of perturbations for any given problem.
00:11:46.980 - 00:12:32.034, Speaker A: But once you add some amount of perturbation, approximate second order stationary points are approximate global optimum. Okay, and I'll only be talking about the second result. And let me now try to elaborate more on what exactly I mean by this perturbed and approximate and so on. Okay, so we, when we say perturbation, we basically mean it in the smooth analysis sense, meaning that we take the objective c, and then we add a random gaussian perturbation, g. So g is a symmetric gaussian matrix with covariance sigma g square, and the standard deviation is epsilon. So epsilon is this parameter. And we look at the problem, which is c plus g.
00:12:32.034 - 00:12:54.422, Speaker A: So the penalized problem, exactly the same, except that c is replaced by c plus g. So this is a new penalized problem. And the rank that you want to get is square root of m log one over epsilon. So you are optimizing in this low rank space. And once you do this, then we can show that with high probability, every epsilon second order stationary point is actually an epsilon global optimum.
00:12:54.478 - 00:12:56.414, Speaker B: That epsilon is not related to your.
00:12:56.454 - 00:13:03.834, Speaker A: It'S the same epsilon that I mentioned. So this epsilon second order stationary point means that the gradient is less than or equal to epsilon. And the Hessian is.
00:13:04.174 - 00:13:07.782, Speaker B: The second order condition is hardwired into your analysis there.
00:13:07.838 - 00:13:33.120, Speaker A: Okay. Yeah. I mean, if you give me greater than or equal to zero, then it doesn't hurt me. But we don't really need it. Of the perturbed objective or of the original objective? Of the perturbed objective. Can you connect the two? Same. Can you connect the perturbed objective to the original objective? Yeah.
00:13:33.120 - 00:13:47.004, Speaker A: So it would depend on like, the sizes of AI, bi and so on, that when you, because you are just changing the objective by a little bit. So as long as other things are bounded, you should be able to connect them.
00:13:47.664 - 00:13:51.920, Speaker B: I thought you were going to do that. You were going to show that optimization.
00:13:51.952 - 00:14:22.764, Speaker A: So, I mean, you could do that on top of this, but this is what we currently show. But if you are really interested in solving the original problem, you can again try to connect both of them. We haven't done that work. How does this high probability depend on epsilon? This high probability does not depend on epsilon. So the epsilons are already connected here. Yeah, yeah, yeah, yeah. What needs to go.
00:14:22.764 - 00:14:51.604, Speaker A: So the omega so whatever constants you have here would come in this high probability. Yeah. Okay. So it's with constant probability or the probability, no, I'm saying like whatever probability you want here, that would modify a constant that you would put in this omega, this one because of the gaussianity, right? Because of the gaussian matrix. That's the only probabilistic thing that you have. Yeah. Okay.
00:14:51.604 - 00:15:49.180, Speaker A: So in terms of runtime guarantees that we get for this problem. So we use capital z to denote the total number of non zeros in the problem. Okay. Interior point methods have only a logarithmic dependence on one over epsilon, which is desired accuracy, and then a polynomial dependence on all of these other problem dependent parameters and multiplicative weights, has one over epsilon Square dependence on epsilon, and does not explicitly have dependencies on the dimension, and so on. But it depends on something called the width parameter, which one has to compute on a problem to problem basis to evaluate the runtime complexity. And finally our result. So I should mention that this quantity is to solve the penalized problem, and you need to do more work to, as I mentioned, like the penalized version is probably not the best way to solve the constraint problem as such.
00:15:49.180 - 00:16:22.244, Speaker A: But the result that we are giving here is only for solving the penalized problem. And this depends as z square root m plus m to the 03:02 n times poly of your epsilon. What algorithm is this? Sorry, what algorithm is, okay, so this is, you could just do put up gradient descent on the gradient. Yeah, you just apply accelerated gradient descent or gradient descent, you get this guarantee. Yeah. Okay. So in the remaining part of the talk, let me just briefly present the main ideas of the proof.
00:16:22.244 - 00:17:12.030, Speaker A: So, there are two key steps which have already been established in prior work to understanding to tackling this problem. The first, the first step, price. So the first step tries to establish that any second order stationary point which is rank deficient, which is not full rank, is a global optimum. Okay, what this means is that if u is a second order stationary point, and if rank of u is strictly smaller than k, so less than or equal to k minus one, then u is a global optimum. This was already shown in bureau Montero's original paper. And the second key step is that for f, that comes from perturbed sdps, where perturbed again, we add this random gaussian perturbation with probability one. If k is greater than or equal to square root m, then all first order stationary points are ranked efficient.
00:17:12.030 - 00:17:56.014, Speaker A: So why does this suffice? Basically, we find a second order stationary point, it's also a first order stationary point. And so this is ranked deficient. And if it is ranked efficient, we know that it's a global optimum. So that's the main idea. So as I mentioned, like all of these have been done for exact FoSP and exact FOSP. So our main contribution to basically make this all quantitative and make sure that the quantitative dependence is not exponential in anything and it's polynomial in all the relevant parameters. Okay? Okay, so let me now first tell you how to do the second part, which is that all approximate first order stationary points are approximately ranked efficient.
00:17:56.014 - 00:18:33.374, Speaker A: So if you write down the function that we wish to optimize. So it has this ugly expression, and when we write down first order stationary point, we know that the gradient is actually small. Right? That's what the definition of first order stationary point is. The most important thing to note about the gradient is that it can actually be written as a product of two matrices. So the first matrix is this complicated expression, and the second matrix is just u, which is a thing that we are trying to optimize for. Right. And the most important thing to note here is that the product of two matrices can be small only if at least one of them is rank deficient.
00:18:33.374 - 00:18:37.734, Speaker A: If both of them are full rank, then the product has to be non zero.
00:18:37.894 - 00:18:40.914, Speaker B: Excuse me, what's the dimension of the AI?
00:18:41.994 - 00:19:12.610, Speaker A: N cross n n cross n. So this whole thing is an n cross n matrix. This is an n cross k matrix. And if you have a product of two matrices which is small, then at least one of them have to be ranked deficient. Both of them cannot be full rank, and the product becomes small. Okay, so then all we need to really establish is that this left matrix is actually full rank. Then it automatically turns out that this right matrix is actually low rank.
00:19:12.610 - 00:19:49.464, Speaker A: Okay? So you only have to establish that this left matrix is actually has rank greater than or equal to n minus k. Okay, so now you see that this left matrix has this gaussian plus a bunch of other things. So for simplicity, let's just consider what the rank of a random gaussian matrix is. Right. The smallest singular values of gaussian matrices have been extremely well studied in the last ten years or so, or 15 years or so. And the probability that a random gaussian matrix is singular is actually equal to zero. So with probability one, it's not singular.
00:19:49.464 - 00:20:10.284, Speaker A: And in general, the n minus ith smallest singular value of g goes as I over square root n. So if you look at the smallest k, and then take the sum of squares of them, it grows as k cube over n. This is expected behavior of the sum of squares of the smallest of random quotient matrix. Yeah. Can you elaborate a little more on that?
00:20:10.364 - 00:20:15.588, Speaker B: You said product to matrices. I can scale an identity by epsilon.
00:20:15.636 - 00:20:38.972, Speaker A: And image full rank for arbitrary small epsilon. Yeah. By full rank I mean. Okay, so you have to do some scaling here, meaning that as long as this is non zero and this is non zero, what is non zero? The matrix is non zero, I am saying with the relative scale.
00:20:39.028 - 00:20:42.704, Speaker B: So if you scale, but it is highly ranked, different.
00:20:43.444 - 00:20:54.264, Speaker A: Okay, so the precise statement that I want to make is that if you normalize two matrices and then take their product, if it is small, it means that one of them has to be relatively ranked, efficient.
00:20:59.704 - 00:21:03.616, Speaker B: They could be orthogonal to each other because one of them is square.
00:21:03.720 - 00:21:47.534, Speaker A: They have full rank, so they cannot be orthogonal because this spans the entire space and the other one also spans the entire space, so they cannot be orthogonal. Your second value is n by k. What do you mean the entire space? I mean the full rank means that it has rank k. So if this n cross n matrix spans the entire space, that also contains this k dimensional subspace here. So the expected behavior of the sum of squares of the smallest k singular values is k cube over n. And it is indeed actually possible to obtain large deviation bounds for this random quantity that it is actually smaller than some small constant times its expected behavior. And the failure probability goes exponentially as minus k square.
00:21:47.534 - 00:22:19.944, Speaker A: So this is the property that we want to use for random gaussian matrices. And this can actually be extended for any arbitrary matrix plus a gaussian matrix. You want? Yeah. Do you want the sum of singular value squared or just. I thought you were going to be with the operator now, right? Generally, no. So we want to show that the smallest singular values of this matrix are large, which would then mean. So that's why I'm looking at the sum of squares of the small as singular values.
00:22:19.944 - 00:22:27.692, Speaker A: But just as small as I see, k is small. K is small. K is small. Yeah. And you know, like square root n.
00:22:27.748 - 00:22:31.732, Speaker B: The matrix a can be, doesn't have to be positive, semi definite.
00:22:31.908 - 00:22:36.332, Speaker A: No. I mean, we are only looking at singular values, g plus a. I mean.
00:22:36.348 - 00:22:39.524, Speaker B: If I can give you any a, I can make the singular values.
00:22:39.604 - 00:22:58.576, Speaker A: But g is random. G does not know a. So g is picked randomly. So a is fixed, and then you are picking g at random. So the randomness cannot really. Okay. Okay.
00:22:58.576 - 00:23:34.520, Speaker A: So this basically says that you can actually get the same bound for any g. For a matrix g a, where a was arbitrarily picked and g was independently chosen after a. Now, in the current context, we are interested in bonding this g plus this whole quantity. And the bad aspect here is that this quantity, this matrix that we have here, depends on u. And u is an unknown for us because u could be any second order stationary point. And a priori, we don't know what exactly these matrices can be. And the way we deal with this is to first actually do an epsilon net over the m dimensional space.
00:23:34.520 - 00:24:15.776, Speaker A: And then within this epsilon net, you look at matrices of the form c lambda I AI. Okay, for each of these points in epsilon net, you can actually get this concentration large deviation bound. And if you do a union bound and then use smoothness to extend to the entire ball, you basically can get the result. And the union bound over this epsilon net is precisely, will precisely give you this one over epsilon to the m factor, because you are doing union bond over nice m things and you want this minus k square to actually cancel this one over epsilon to the m. So that's basically where you get k square greater than or equal to m log one. Or epsilon, you have to do an exponent in m space. You can't do it in k space.
00:24:15.776 - 00:24:56.494, Speaker A: Somehow you can't do it in k space, because like this matrix, this whole matrix lies in the subspace of subspace spanned by AI, which is actually an m dimensional space. So we cannot. Okay, okay. So there are some technical issues to carry this out. Actually, the first thing is that you cannot do an epsilon network like entire RM. You can only do on a compact like ball or something like that. And in this context, what it means is that these coefficients that you have here, you need to actually show that they don't go to infinity.
00:24:56.494 - 00:25:58.432, Speaker A: They cannot be arbitrarily large. They are all bounded. And you can actually show that for compact sdps, all second order stationary points are uniformly bounded, which means that u is actually bounded, which means that this whole quantity is again bounded. And so doing a union bound or a compact ball is already good enough for our purpose. Okay, this seems kind of quite obvious that for compact sdps, meaning that if the feasible set is compact, all second order stationary points are also uniformly bounded. But technically, it turns out that this is one of the challenging aspects in showing it. Okay, so now let me come to the other part, which is to show that once we have these approximately low rank second order stationary points, they are actually approximately global optima, the main idea here is that because f is convex in the original space before you did the factorization, if a matrix uu transpose is suboptimal, there exists a descent direction because f is convex in the original space.
00:25:58.432 - 00:26:40.438, Speaker A: Okay? And in fact you can show that there exists a descent direction which increases the rank by only one. And now this makes it clear why u being ranked efficient is good, because you can actually like this descent direction which increases the rank by at most one also exists in this factorized space because u was ranked deficient. Okay. Similarly, if u is actually approximately rank deficient, you can actually massage the descent direction which rank one descent direction to also exist in this factorized space, and then construct a descent direction which does not really increase the rank. So it exists in the factorized space whenever u is very sub optimal.
00:26:40.486 - 00:26:49.672, Speaker B: So approximately rank deficient means you have a small singular value and then your direction is a singular vector corresponding to that small.
00:26:49.838 - 00:27:14.244, Speaker A: Yeah, we use that to construct it. It's not exactly that, but we use it to construct this descent direction. The descent direction has something to do with the smallest eigen direction of u and also the original singular direction of u and the original descent direction. Okay, I have a question. Yeah. So if there's a descent direction in the original parameter space. Yeah.
00:27:14.244 - 00:27:37.330, Speaker A: Why does it have to be symmetric? Right? It will be symmetric because uu transpose is a symmetric. No, but you are saying it is convex in the original x domain of x. Yeah. Which you haven't factored. Yeah. So a rank on descent direction in just. Oh, I mean, it's, there is a descent direction when you impose this PSD constraint also, right? Oh, ok.
00:27:37.330 - 00:28:02.646, Speaker A: Ok. So the descent direction always moves in this PSD cone, so it will be asymmetric. So, to summarize, the main point of the main reason that we started this work was the realization that low rank solutions to sdps are very useful both from an application and algorithmic perspective.
00:28:02.710 - 00:28:21.734, Speaker B: Excuse me, I'm not sure I can see that your discussion here holds in exact arithmetic, but if you translate that to finite precision, then your statements about singular values and going from Gaussians to gaussian plus a for NEA and statements about those singular values won't hold.
00:28:21.774 - 00:28:23.542, Speaker A: Yeah. So I can easily give you a.
00:28:23.558 - 00:28:33.074, Speaker B: Matrix a where all the things that's totally numerically singular when you add it to a gaussian, and even on its own. So those arguments in finite position are not going to hold anymore.
00:28:34.054 - 00:28:35.536, Speaker A: No, that's. I am not sure.
00:28:35.600 - 00:28:36.912, Speaker B: Yeah, I can not.
00:28:36.928 - 00:28:38.520, Speaker A: If the Gaussian has high enough variance.
00:28:38.592 - 00:28:40.016, Speaker B: No, I give you an a.
00:28:40.200 - 00:28:40.928, Speaker A: But how?
00:28:41.016 - 00:28:49.136, Speaker B: You won't know what the, I just, you know, make the a highly ill conditioned. So regardless of what you add to it, it'll be highly ill conditioned. Numerically singular.
00:28:49.280 - 00:28:54.884, Speaker A: No, no. If you add a random matrix, it will automatically have some small singular directions because you cannot account for.
00:29:01.624 - 00:29:04.924, Speaker B: Norms. It's highly likely it's gonna remain that way.
00:29:05.224 - 00:29:10.432, Speaker A: No, no. Give me any a, I'll add Gaussians and I cannot.
00:29:10.488 - 00:29:12.520, Speaker B: No, this just doesn't happen in practice.
00:29:12.672 - 00:29:15.176, Speaker A: The condition number will be n. This is a.
00:29:15.320 - 00:29:18.176, Speaker B: If you ever do numerical computation that doesn't happen.
00:29:18.280 - 00:30:00.190, Speaker A: Let's let this. Okay, so I'll maybe come to the probabilistic aspects later. So, yeah, so the, as I mentioned, low rank solutions. Finding low rank solutions to semi definite programs is very important, both from an application and from an algorithmic perspective. And the bureau Montero approach tries to average this idea, and we show that this actually does not work in the worst case, meaning that there are examples where it could get stuck in like bad places. However, it does work in the smooth analysis sense, and we can get polynomial time convergence rates for, for this approach. And let me just present briefly some open directions that I think are very interesting.
00:30:00.190 - 00:31:00.154, Speaker A: So, firstly, while this is the first result in giving polynomial time guarantees for the bureau Montero approach, we believe that our results are not tight. And even more importantly, I think the fact that we work with penalty method is not very satisfying, because penalty method is not really used in practice. And the algorithm that's actually used in practice is augmented lagrangian methods. And extending these kind of results for augmented lagrangian methods is very interesting. We have some preliminary results on exact alms, but it will be very interesting to understand the case for inexact alms. Finally, in machine learning, we are usually also interested in very specially structured problems where we are not satisfied with finding solutions of rank square root m, but rather much, much smaller rank. So extending these approaches for specially structured problems where you may be able to find much smaller rank solutions might be interesting.
00:31:00.154 - 00:32:00.444, Speaker A: And there is one direction that I really like, which is basically a random matrix theory question. And the reason we were not able to solve this very well is also the reason for like suboptimality in our results. And let me try to explain the problem, which I think is very interesting. So if we ask how close a random vector will be to a random subspace, we are able to answer this like this question is very well understood because you just look at the orthogonal space and how large, how small the vector can be in this orthogonal space. Similarly, if you ask how close a random matrix can be from the set of all low rank matrices, this boils down to understanding the smallest singular values of a random matrix. This has also been very well studied in the recent past. The question that actually arises in our work is how close will a random matrix be to the sum of a subspace and the set of low rank matrices.
00:32:00.444 - 00:32:46.364, Speaker A: So if you construct the set of a plus b where a comes from a subspace and b is a low rank matrix. Okay, so this is the Minkowski sum of a subspace and a set of low rank matrices, how close can a random matrix be to this subspace? And this is the like really key question that we try to ask. Our solution depends on this epsilon net argument, which I think gives pretty loose results. And if it is possible to get a much tighter result for this question, I think it will automatically improve our results. Okay. And to me it seems like this is a very natural question and very interesting one as well. So that's all I had to say.
00:32:46.364 - 00:33:30.378, Speaker A: Thank you for your, for your epsilon net question, right? Yeah. Is the difficulty compactness or boundedness or the subspace and. Yeah, so if it is compact, you can definitely use epsilon net argument to get this. But when you are looking at the subspace plus the set of low rank matrices, it's unbounded. And there is this way of getting epsilon, that's where you peel off piece and then half the we can talk about. But still, I feel it works only for compact. Right.
00:33:30.378 - 00:34:24.450, Speaker A: Maybe it gets a better dependence on like the size of the set or something, but I would think it still works only for compact sets. Yeah. So the thing that prevents you from extending this to your objective was cx. Yeah, like a more general convex fx, it will not work because you don't have this previous result of the square root m existence of a square root m solution for. Yeah, yeah. I guess my question is why does it not extend to a general effect subject to linear constraints? So in our result it does not extend because, okay, so what exactly are we doing? So we have this g plus this matrix, right? So if you don't have the c, then this thing can actually change from point to point. So you have to do your union bound like over some other thing.
00:34:24.450 - 00:34:42.634, Speaker A: So here, C plus, this is still a subspace, like this is still in a subspace, this is a fine subspace. But if C can vary from point to point, you have to account for all the different C's that can come from your function. Okay? So with that, let's thank the speaker and thank you.

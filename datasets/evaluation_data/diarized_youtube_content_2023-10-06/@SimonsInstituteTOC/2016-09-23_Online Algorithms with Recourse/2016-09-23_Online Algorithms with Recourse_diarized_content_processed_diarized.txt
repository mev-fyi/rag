00:00:01.280 - 00:00:36.564, Speaker A: Thank you. So I'll talk about online algorithms with three course. So this is not a new model. It has been around for a while, but just that I think lot of recent work has happened and lot of open problems remain. So let me just begin by going over how we define competitive analysis. So we say that you have some problem and an input arrives over time. And at each time t I want to maintain a solution over whatever input I have seen so far.
00:00:36.564 - 00:01:25.044, Speaker A: And then whatever decisions I have taken so far, they are in some sense irrevocable. That is the assumption. And the way I analyze my algorithm is by comparing it with something which knows the entire input in advance, right? So we say that look at the best offline algorithm and I should be comparable to that, right? And then I define the computing ratio of an algorithm on an input sequence as cost of my solution by the compared to the best optimal solution. Okay? So let me give an example. So I'll talk about this problem called online load balancing. So what happens here is that at each point of time one job arrives. Think of it as a unit size job.
00:01:25.044 - 00:01:57.850, Speaker A: And when a job arrives, it can only be processed on a subset of machines. So it specifies which subset of machines it can be processed on. So for example, this one can go on first, two machines only, and then you send it to one of the machines and the next job arrives and so on. I define. And then the idea is that the jobs that I have already assigned, they cannot be reassigned. So that's the second point that I cannot really change my solution at each point of time. And the goal is to, let's say, minimize the maximum load on a machine.
00:01:57.850 - 00:02:24.914, Speaker A: So load on a machine is how many jobs you have sent on a machine. So look at all the machines and take max of load on each machine. And let's say you just want to minimize this. So this problem has been studied very well for a long period of time. And we know that if you look at the greedy algorithm, which says that when a job arrives, look at all the machines, it can go on and just, let's say, assign it on the least loaded machine. So that's a natural algorithm. So let's say here it goes to that machine.
00:02:24.914 - 00:03:00.562, Speaker A: So we know that this algorithm is log m competitive, where m is the number of machines. And in fact, this is also the best possible one can do. Let me talk about a, a simpler version of this problem, which I look at. Even this version turns out to be interesting. So the simpler version is a special case when each job can only go on two machines, all you have to do is to figure out which of the two machines to say it on. So I can think of it as some sort of edge orientation problem. Job has different length on different machines.
00:03:00.562 - 00:03:42.034, Speaker A: Yes. Each job is unit size and completely when it comes, it specifies which machines it can go to. So let's say think of machines as vertices in a graph, and each job is like an edge. And all you have to do is to orient this edge. So let's you orient like this and so on, okay. And the load is like the degree of a node, so you want to minimize the maximum degree of a vertex. And if you think of the setting when the underlying graph is a tree, then I claim that you can get optimum one because you can just look at a root and then just orient everything away from it.
00:03:42.034 - 00:04:18.570, Speaker A: But even in this very simple case of edge orientation and the underlying graph being a tree, one can show that the best an online algorithm can do is like log n. Okay, and why? Let's see. So let's say these are the nodes in the graph. And suppose some edge arrives and you orient it in some manner, okay? And then another edge arrives, you orient it like this and so on. Okay? And then another edge arrives which looks like this. The way I set it up is that its endpoints are the vertices which already have in degree one. And then you do the same thing again.
00:04:18.570 - 00:04:56.614, Speaker A: Right? So two vertices get in degree two now. And then you send an edge which connects the two things and so on. Okay, so you can easily see that if I keep on doing this, I can make the integrity of some vertex to be log m, where m is the number of vertices here. And this, I mean, so this shows a lower bound, one can also show a lower bound for randomized algorithms. And it follows that the same lower bound carries over to load balancing because it's only a more difficult problem. Okay, and this is another problem that I'll talk about. So this is called online spanning tree.
00:04:56.614 - 00:05:33.994, Speaker A: So what happens here is that you're given a metric space and let's say vertices arrive online. And all I have to do is to maintain a spanning tree on all of the vertices. So let's say a vertex v zero arrives and at each time a new vertex vi arrives. And when it arrives it reveals to you the distances to all the other points. And then you have to figure out how to connect it to the remaining points. And again, the idea is that you're not really allowed to change the tree that you already have because, you know, by our definition we are not going to do that. So let us say v one arrives, you connect it like this, v two arrives and so on.
00:05:33.994 - 00:06:30.254, Speaker A: And then you want to minimize the cost of the tree. So just a simple mst problem. And again, one can think of the greedy algorithm which says that when a vertex arrives, you connect it to the nearest vertex. Uh, right, so v one arrives, v two goes to the nearest one, and so on. And it is known that this algorithm is a log n competitive, and there is also a matching lower bound of log n. So in some sense, log n is the right bound. Okay, okay, so, so let me just sort of, you know, review like what are the, what, the point is that the idea of using competitive analysis has been very successful in analyzing lot of algorithms which are actually used in practice, like routing, network design and so on.
00:06:30.254 - 00:07:20.098, Speaker A: But often it turns out to be quite pessimistic. So for example, in these settings, we see that sometimes you can be as far as log n times the optimum. Also there other extreme settings where the competitive ratio could even be unbounded. And in such cases it is not clear how to proceed because how do you compare two different algorithms? Let us say if the commutative ratio can be very large. So this was the sort of the definition of using competitive analysis. And what I want to look at is, can I relax this notion of irrevocable? Can I sometimes say that some of my past decisions can be changed? So this is what I want to look at. Now.
00:07:20.098 - 00:07:52.432, Speaker A: If you think about it, it's not a valid assumption. I mean, it is a valid assumption in many cases. For example, if you're looking at scheduling, caching, paging, I mean, page faults which have occurred, you cannot do anything about them. Similarly, if there's a job that you have processed, then you cannot just go back and say that I want to process it again. So sometimes decisions which you take in the past cannot be revoked. Okay? But maybe in some other settings it is possible to change some of the decisions that you have taken so far. So, for example, in the kind of problems I was talking about, it may appear as some sort of temporary disruptions of services.
00:07:52.432 - 00:08:38.404, Speaker A: For example, you have built a network and you want to say that, look, things are getting bad. So all I want to do is I want to tweak some of the edges in the graph. So it may be a low overhead thing, provided you don't disrupt too many things. So, so for example, in the edge orientation problem, maybe I want to say that, look, this is how I had assigned my jobs, but maybe I want to change some of the edge orientations, I want to go back and I realized that some of the orientations were bad. So I'm going to go back and change some of these. And then you can imagine that there is a trade off between how much you change your solution versus what's the objective value. Of course, if I is resolve the problem at every point of time, I can be equal to opt, but then I will be changing my solution a lot.
00:08:38.404 - 00:09:38.304, Speaker A: So this is the idea I want to explore, that I am, let's say I'm allowed to change some of the past decisions. So for example, in load balancing, I'm saying that if you have done the assignment of jobs, I'll allow you to reassign some of the jobs. So for example, suppose these are the six machines and this is the current assignment of jobs. Then a new job arrives and let's say it goes to some machine, but then I'll perhaps maybe move around some other jobs also, so that the overall load remains balanced. Maybe it will help. So similarly, network design in routing, one can say that I'll reroute some of the existing demands and so on. This line of work has connections to this whole area of dynamic graph algorithms where they say that I want to maintain a good solution, I'll change my solution, but at each point of time I am not bounded by how much you change, but how much time you take.
00:09:38.304 - 00:10:14.272, Speaker A: So let's say you take time t to change to figure out the new solution. Then clearly in some sense, you are not changing your solution too much by more than some function of t. So there are connections to dynamic online algorithms, but I will not go into the details here. So this is the plan. I'll talk about the edge orientation problem, even though it's a very simple problem. Turns out that they're interesting open questions here. Then I'll see what happens in load balancing.
00:10:14.272 - 00:11:06.644, Speaker A: I'll talk about standard tree, and then I'll conclude with some open questions here. Okay, so let's see what's known here. It's a very simple problem, and of course, if you do naive, which is basically solve the problem at each point of time, you could be doing n reorientations per unit time. Greedy, as we saw, is log m competitive. It doesn't have to do any changes in the solution. So Brodel and Fagerberg showed in 98 that you could get max in degree two instead of one, provided you are allowed to do three reorientations per edge arrival. By amortized, I mean that at some point of time it may do lot of reorientations as compared to other times, but on an average you will be only doing three orientations per unit time.
00:11:06.644 - 00:12:03.982, Speaker A: So whenever an edge arrives I am allowed to change three other edges. So that is the point, okay? So let me, let me present the algorithm. It's a very extremely simple algorithm and has acute analysis. So let's say this is a situation, okay? The an edge arrives which connects these two vertices. And what they do is they say that let's just oriented in any minor, okay? Okay? And now what I do is I see if some vertex gets in degree three, okay? So I'm maintaining the fact that nobody has integrity more than three or three or more. And now when you arrange this edge, some vertex gets in degree three. So what you do is you flip all the incoming edges to it, okay? So I flip all these three edges, okay, now what this may do is you can imagine that some other vertex may get in degree three because I changed several edges now.
00:12:03.982 - 00:12:42.094, Speaker A: So then you do the same thing at. So whenever you see a vertex was in degree becomes three, you just flip all the edges coming to it, okay? And this could lead to a cascade, okay? So for example, suppose there was a vertex like that and the situation was like that. Then you flip all the three edges there and so on, okay? And now I want to prove that on average you will only do a constant number of flips. So consider the time t. And let's say that that's the optimal solution. I'm saying that the underlying graph is a tree but need not be a tree. But let us say the opt is one and the underlying graph is a tree.
00:12:42.094 - 00:13:25.228, Speaker A: Doesn't matter, okay? And so that's the optimal solution there, okay? And this is your current solution. At some point of time you have not seen all the edges and you have oriented your edges in some manner so far, okay? And what I want to show is that you picked a time t and I want to show that the total number of flips that you do till this time t is at most three t. That's what I want to show. So what I will do is I will define a potential function. So the, so let us have one definition I will call an edge in my solution to be a good edge if its orientation matches the optimal tree orientation. So remember this tree is not changing with time. Its fixed.
00:13:25.228 - 00:13:55.564, Speaker A: So your edge is good if it matches the orientation in that tree. Otherwise it is bad. And now, so these two are good edges and the other two are bad edges. And now let us define my potential as the number of bad edges at any point of time. So number of edges which are oriented the wrong way. And what happens when a new edge arrives? When a new edge arrives, you give it some orientation. So your phi could go up by one unit.
00:13:55.564 - 00:14:21.174, Speaker A: But I claim that each time you do a flip, you will reduce the potential. Why? Because you are flipping three edges. Now, out of those three edges, if you think about the optimal solution, only one of those was coming into this vertex. So you are setting at least two bad edges to good. So phi is at least decreasing by one unit. And that shows that you cannot be doing this operation multiple times. A lot of times.
00:14:21.174 - 00:15:13.074, Speaker A: That is it. So that is the complete proof. Uh, okay, so uh, that's, that's what is known. Uh, one interesting open question which remains is, uh, in this algorithm you are kind of, you may be doing lot of flips at some point of time. So let's say I restrict that you can only do, let's say ten flips at each point of time. So can now one get a competitive ratio of constant? So that's not even known for a tree. So even if the underlying graph is a tree, can I prove that I can get a non amortized constant, comma, constant? Okay, interesting open question is what if I am allowed to even sort of delete edges? Okay, so let's say the graph will, I guarantee you that the graph will remain a tree, but at each point of time I'll either add an edge or remove an edge.
00:15:13.074 - 00:15:35.870, Speaker A: And again, I want, let's say constant amortized. Constant competitive. I should add that for all of these problems. If you're willing to do log m amortized, that is, change log m edges, then one can get a constant comparative. I'll show the citation later. Okay. All right, let's come back to load balancing.
00:15:35.870 - 00:16:24.132, Speaker A: It's a slightly harder problem and let's see what one can do here. Now it's not just an edge orientation problem. So the similar kind of analysis will not work here. So, uh, so recall that this was the, uh, problem that you have to assign a job to one of the machines. And now we're trying to understand what's the trade off between the competitive ratio and uh, the extent of uh, reassignment that I need to do. Okay, so, uh, this is what is known, uh, so if you do greedy, we know that's log m competitive. Uh, now, not that matching is a special case of this problem because if opt is one, that is, you can assign all the jobs to machines where nobody gets two jobs.
00:16:24.132 - 00:17:11.172, Speaker A: So that's, so maximum matching is a special case of this problem. And Bose Qatar showed that if you want to maintain a maximum matching, let's say at each point of time, then one can get away with doing only square root and amortized reassignment. Okay, so even this is a highly non trivial result. So our work, et al, showed that if you want four competitive algorithm, then one can get away with this log m changes per arrival. So when a job arrives, you will reassign log m jobs. And we showed that one can get a constant competitive algorithm with constant number of reassignments. I should also add that this is the case for maximum matching.
00:17:11.172 - 00:17:56.164, Speaker A: The conjectured value here is log n. We don't know if that is true. So Chaudhary and others showed that one can get a login reassignment result here, provided the input arrives in a random order. But it remains an open problem to get log n here. Okay, uh, so let me just, uh, describe what this algorithm is which gets a constant comma, constant in in both the parameters. Okay, so, uh, so, and if you could log in, wouldn't it give a login algorithm for matching? I mean, offline, there's online, uh, I mean, wouldn't it improve the m to the three halves? So this is for the random arrival. No, like in the most.
00:17:56.164 - 00:18:00.624, Speaker A: No, the online case. I know, I don't think I know.
00:18:01.164 - 00:18:02.940, Speaker B: Number of changes, not necessarily the time.
00:18:02.972 - 00:18:41.144, Speaker A: To find the changes. Yeah, you want to maintain, you can extend this problem to the case of general processing times. And there we get a log log n competitive algorithm. So you can again ask the same question. Jobs have sizes instead of just being unit sized jobs. And we can get a log login competitive algorithm with constant number of reassignments. So I'll briefly describe what the ideas here are.
00:18:41.144 - 00:19:19.244, Speaker A: Okay, so the idea is very simple. Let's say opt is one. So let's say it's possible to maintain a matching, and I'm allowed to put two jobs on a particular machine. So when a new job arrives, what I'll do is I'll find some sort of shortest augmenting path. So I'll say that find a sequence of exchanges which does not violate the load by two and find the shortest such sequence of exchanges because it's just the shortest augmenting path problem. So let's say this job arrives, you put it here because load does not go beyond two. But let's say a job of that type arrives, then you put it here, and then you may have to move it further.
00:19:19.244 - 00:20:01.814, Speaker A: Okay. So I call it shortest augmenting sequence. And the idea of the proof is the following. That let's say that I build a graph on the machines and I have an edge between two machines. If there is a job on machine five which can go on machine two, that's just the graph, the residual graph here. And I can look at this graph, and then I say that, look, if I want to move a job from a particular machine, I can define the shortest path from that machine to a vacant machine. So this I will call as the height of a machine.
00:20:01.814 - 00:20:32.830, Speaker A: So, height of a machine is defined as the length of the shortest augmenting path starting from this machine. And let m I denote the number of machines whose height is I. Now, what I claim is that the size of m I is exponentially small with respect to I. So the number of machines of height I is at most the number of machines of height I minus one over two, so it decreases exponentially. Height exactly. I. Sorry.
00:20:32.830 - 00:20:49.486, Speaker A: Height, exactly. I. Let's say height exactly. Yeah. Doesn't matter. Or maybe at most, we'll say, okay, okay. And the proof is as follows.
00:20:49.486 - 00:21:33.140, Speaker A: Yeah, maybe it should be at most. Okay, so let's say there's a machine, let's say machine number five, which has height I. And remember, it has height I means that there must be two jobs sitting on it, because if there was just one job, its height would be zero. So there are two jobs sitting on it. Let us say a and B and look at the optimal solution. In the optimal solution, these two jobs, A and B, were perhaps going to machine number two and machine number eight. And I claim that those two machines would have height I minus one or more, cannot be having height I minus one, because if they had very small height, then Phi will also have height, very small.
00:21:33.140 - 00:22:11.130, Speaker A: So the fact that five is height I means that two and eight have height at least I minus one. Right. And so that kind of doubling allows you to prove this theorem. So I'm not giving a formal proof, but that's the idea. And then one shows that the height of a machine never decreases over time. So this is a property of the shortest augmenting path algorithm. So once I have all of this, what do I get? I get that if you look at the total amount of augmentation that if you go to a machine of height I, you spend I units of time to do find the, find an empty machine.
00:22:11.130 - 00:22:47.496, Speaker A: Okay? So it's I times size of mi, which is order m. Right. Because the size of mi is extremely small. Okay, so that's the idea of the proof. We could extend it to flows where we say that instead of just jobs being assigned to machines, requests are arriving in a network and you want to route this request to a source. And then we can say that instead of obeying the capacities, you are allowed to validate the capacities by a constant factor. When we also look at load balancing with general job sizes, this is what I was referring to.
00:22:47.496 - 00:23:19.764, Speaker A: And one can get a log, log and competitive algorithm here. Let me just give you the brief idea of what this algorithm is. Log is for general job sizes. So now I claim that just using shortest augmenting path is not good. Why? Because let's say a new job arrives and you place it on some machine, then you may have to sort of send two jobs away to just to balance the load, because the arriving job was a huge job. So you cannot say that I'll just change things along a single path. You may have to do it on a tree kind of thing.
00:23:19.764 - 00:24:24.348, Speaker A: Okay, so I mean, our first idea is to just sort of think of some sort of fractional version of this problem. So you break each long job into unit sized jobs and think of just scheduling those unit size jobs. The only thing you have to do is that you have to change the previous analysis where, because if you have split a job into multiple pieces, then moving a small piece should cost less than one. Okay, so whatever fraction it is, let's say one third of a job, then I'll say that moving this small piece will only cost one third. So given that one can look at the fractional version of this problem and one can prove that you can again get a constant, competitive, constant demortized algorithm here. So here, so far we are, okay, but now when you want to convert this into an integral solution, I mean, just a simple randomized rounding or standard algorithm, it's not clear how to bound the extent of reassignment. So, uh, so what we do is that for small sizes, we show that one can do randomized rounding.
00:24:24.348 - 00:24:52.094, Speaker A: And for large jobs, you need to do a little bit more work. But basically by combining these two cases, one get gets a log, log n algorithm. Okay. And at the same time we stay, stay constant comparative. Okay, so, uh, let me show, uh, what else is known here. Uh, one can also talk about a more general version where you want to maintain maximum fair assignment. So we can also do that with constant comma, constant in both the parameters.
00:24:52.094 - 00:25:39.624, Speaker A: And then one interesting question is that for general job sizes, can one get a constant reassignment constant competitive algorithm. So we don't know how to do that. Another interesting question is it seems that if you insist that at each point of time, let us say you can only make ten changes in your solution, there should be a lower bound. But we don't know how to prove such a thing. So yeah, so in terms of the, in the non amortized case it is very poorly understood. So the best we know is that one can get a log number of reassignments per arrival and then one can get a constant comparative. But we don't know if you can get a constant comma, constant non amortized result.
00:25:39.624 - 00:26:31.794, Speaker A: Let me finally talk about the, mentioned the last do you know something about fully dynamic? Okay, so then of course one can also ask the question of fully dynamic setting that jobs are also arriving and leaving. So in fact, even for the edge orientation we don't understand this problem. So we don't know how to solve this yet. Finally, let me talk about what is known for the Steiner tree problem. So remember the question was that vertices arrive one by one and you have to maintain a standard tree here. And when a new vertex arrives you could perhaps change some of the edges in your existing tree. So perhaps you could change this tree and so on.
00:26:31.794 - 00:27:17.306, Speaker A: Okay, now here's what is known. So image and Waxman showed that one can get a constant competitive algorithm by changing about root n edges at each point of time. Then this was improved to a PTA's by migo and others where they were doing about one over epsilon log one over epsilon changes per vertex arrival. We improved it to slightly one over epsilon. And then you can get a trade off here. You can get a bigger constant with a better approximation here. So you can get a constant comma constant here, let me show you what the idea is.
00:27:17.306 - 00:27:44.354, Speaker A: Idea is again very simple. So we know that there is a greedy algorithm which says that when a vertex arrives you connect to the closest vertex. Now this I know doesn't have a good competitive ratio. It is log m competitive. Now let's say that besides doing this, I do something else. I say that whenever you see two edges, let's say e and f. F is in your tree and e is not in your tree.
00:27:44.354 - 00:28:16.414, Speaker A: And suppose if I could add e and remove f, the cost of this tree goes down. Suppose I could do these kind of changes. So then I'll say that let's add e and remove f. Okay? And I keep on doing this. Now if I keep doing this till I can do this, I know that this will lead to an MST, because that's exactly what it is. But one can show that this would lead to lot of changes. So it's, we do not know how to, we can show that, you know, that there are lot of changes you will make here.
00:28:16.414 - 00:28:55.184, Speaker A: But now you can say that if I only want a p task kind of result, let's say that you will swap e and f only if you get somewhat significant benefit. So only if the length of e, it's somewhat smaller than the length of f. And if you keep on doing this again, it's possible to show that you will get a tree whose cost is within one plus epsilon of the optimum. An interesting thing one can show is now the number of swaps you are making is only constant per arrival. So here is one slide idea of the proof. The way the proof goes is the following. So let us say that is the minimum spanning tree and this is your tree.
00:28:55.184 - 00:29:22.904, Speaker A: I will define a potential function. The potential function is the following. It says that look at the greedy solution. Greedy is when, remember, greedy is a log m competitive solution. But let us look at the product of all the edges in the greedy solution and compare that with the product of all the edges in the MST. This quantity is never more than four to the n. So, I mean, I do not have a simple proof of this, but let us believe this fact.
00:29:22.904 - 00:30:21.612, Speaker A: Now, if you, if you look at this statement, I claim we are done. Why? Because each time you do your swap, what are we doing? We are reducing the numerator by, by some factor, because you are reducing, replacing an edge by a somewhat smaller edge. So each swap decreases product by one over one plus epsilon some constant factor. And so you cannot be doing this operation multiple many times. Okay, so, yeah, okay, so again, one can ask interesting questions. We show that even if you allow vertices to be deleted, one can get a constant amortized algorithm, and in fact one can even get such a result in the non amortized setting. Now, in all of these cases where so we have a result which shows that you can get a constant comparative even, let's say you're allowed, let's say one change at each point of time.
00:30:21.612 - 00:30:55.932, Speaker A: But this algorithm is much more complicated. We conjecture the following should be true that let's say at each point of time you see that I should be making these hundred changes, but you put them in a queue and you say that. Let me just pick the top five changes. So is this a constant computing algorithm which is only doing five changes at each point of time? So it's a non amortized kind of result. So we don't know how to prove this. We don't know how to do the fully dynamic case. Again, if you're allowed only constant number of changes at each point of time, and then we can ask a similar question for other network design problems.
00:30:55.932 - 00:31:25.764, Speaker A: Steiner Forest, higher connectivity and so on. This is just a list of what other things are known for. Traveling salesman problem. One can again get a constant, comma, constant. There's some work on facility location recently we looked at set cover where you say that points are arriving or they could be moving away. And we showed that one can get a log n competitive constant recourse algorithm. So let me just conclude.
00:31:25.764 - 00:31:44.184, Speaker A: So, online algorithms with recourse, it's a powerful tool which addresses some of the shortcomings of competitive analysis in some cases. And there are plenty of open problems in routing resource allocation, facility location and so on. Thank you.
00:31:53.504 - 00:32:07.936, Speaker B: So there's been a lot of interest in algorithms with predictions. Right. So if I have the option of seeing k time steps into the future or changing k of my previous actions, do you have a sense which one is the more powerful model?
00:32:08.080 - 00:32:27.214, Speaker A: Yeah. So there is some work on lookahead where you say that I'll have some look ahead and maybe I'll use that, but I don't know how to compare the two. Yeah, I don't have a sense of that time. Any other questions? Not less than coming. Thank you.

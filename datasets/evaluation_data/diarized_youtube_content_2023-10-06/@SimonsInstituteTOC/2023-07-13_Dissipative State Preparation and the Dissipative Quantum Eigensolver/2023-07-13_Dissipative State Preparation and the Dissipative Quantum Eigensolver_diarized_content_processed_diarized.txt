00:00:00.880 - 00:00:23.154, Speaker A: Okay, thanks, everyone, for coming to our final talk on hamiltonian complexity in QMA. We have Toby Cubitt, who will tell us about dissipative quantum eigensolvers. Thanks a lot. So it's really, really nice. I think it's actually my first time at the Simons Institute. I think that's probably my fault because I had to turn down a couple of previous invitations because I wasn't able to make it. So thank you very much for inviting me.
00:00:23.154 - 00:00:55.524, Speaker A: I guess since now, like, you know, everyone has a spin out company in quantum these days, I worried about my sponsors, Facecraft. This actually is research done at the spin out company, Facecraft. And these are the co founders, Ashley Montanaro, you've heard about a bit in the previous talk, actually, and John Morton. They're paying for this trip. So, you know, there's a Facecraft policy that I have to come dressed like this. As Frank just pointed out, I'm one of the co founders of Facecraft, so if this policy really exists, I could unmake it. I'll leave you to work out whether that's a real policy or a joke.
00:00:55.524 - 00:01:23.766, Speaker A: This is. I'm going to talk about these results, about ground state preparation, and this is where I'm going to go now. I'm not, almost certainly not going to get to this material. I put it up there, though, because the previous time I gave this talk, the audience did manage to ask enough questions. Not like, could you please talk about the slides you didn't get to, but ask questions where the answer was? All right, I'm going to go to this section. So let's see if you can achieve the same. I think they covered everything here in questions afterwards.
00:01:23.766 - 00:01:53.574, Speaker A: So I'm going to try and get to here. So let's start with intro to this. This is just a. I'm going to go through really rapidly warm up on this because we heard a lot about ground state preparation yesterday, and particularly yesterday. So the problem I'm concerned with is the ground state problem. So, preparing a ground state on a quantum computer so that input some classical description of a K local hamiltonian, each of these. So each sum of local terms, each of which acts on, at most, k q dits.
00:01:53.574 - 00:02:30.606, Speaker A: And then our task is to output something that's close to the ground state of the system. So psi sub zero, the ground state, minimum eigenvalue, eigenvector. And then we want to output at some state. Prepare some state psi tilde, that's epsilon close to the. To the ground state. I'm gonna rewrite this very slightly. Uh, this is fine if we have a unique ground state, but if we don't have a unique ground state, then I'm going to rewrite this as and say we've got a ground state, a projector onto the ground state subspace, and our task is to prepare some state, pure or mixed, but some density matrix that's got high overlap with the ground state, because that way I don't have to worry about that.
00:02:30.606 - 00:03:18.544, Speaker A: Works for degenerate ground state as well. So that's the task. Prepare a state that's in the ground state subspace or has high overlap with the ground state subspace of the local Hamiltonian. Of course, this problem is notoriously it's QMA hard. So we expect this to be exponential time in worst case, even on a quantum computer. And something to note is that physical sort of physics assumptions or conditions you can put on the Hamiltonian, there's almost nothing you can do that makes this problem in terms of physical kind of conditions or assumptions you can put on h, the Hamiltonian that makes this problem easy. So you can, if you impose that it's frustration tree, you promise it has a constant spectral gap, commuting local terms, polynomial density of states, it's still np hard even if you put impose all of these conditions on the Hamiltonian.
00:03:18.544 - 00:03:47.808, Speaker A: Are you interested in the non uniform case of the problem? It's like, do we get this? So given the Hamiltonian, we need to efficiently find the circuit that prepares. That's right. No non uniform complexity classes in today's talk. All right, sorry, Scott. I like non classes, but not just trying to clarify. Good. So you know this problem, it's QMA hard, but this is a problem that people really care about solving.
00:03:47.808 - 00:04:31.304, Speaker A: Indeed, huge amounts of high performance compute time is devoted to solving this problem, despite the fact that it's very hard. Classical compute time, people in quantum computational chemistry, materials science modeling are solving this problem every day successfully. So just because it's QMA hard doesn't mean we give up. And of course, there's interest in despite the fact that it's QMA hard, people have, because it's such an important, useful task. People have studied many different quantum algorithms for this problem over the years, from adiabatic ground state preparation, the quantum phase estimation, imaginary time evolution, sort of the new kid, newish kid on Niski, kid on the block, VQE. And all of these have their pros and cons. They're all exponential time.
00:04:31.304 - 00:05:10.450, Speaker A: Worst case, that might work on some problem instances you care about successfully, but there's also another algorithm that dates back quite a while, dissipative state preparation. So what is this? This dates back to a paper by Frank, who's at the back here, Frank Visrata, Wolf Sirach from 2009. And they actually did three things in this paper all those years ago. So all of these results are interesting in their own right. One was engineering ground states of many body hamiltonians. One was constructing algorithms for constructing certain classes of states with efficient classical descriptions. And in the title of the paper, I think the title of the paper is something I did.
00:05:10.450 - 00:05:40.600, Speaker A: The quantum computation also showed that you can do quantum computation dissipatively. So these are three separate results in that paper, ground state engineering, as we said, exponential time. Worst case, unless QMA collapses to BQP, comparing tensor network states, or stabilizer states, is poly time. And quantum computation, also in this model is polytime. I'm not going to talk about these two. Okay, so the relevant one of those three results from this old paper is this ground state engineering process. So that's what I'm going to talk about.
00:05:40.600 - 00:06:23.118, Speaker A: The other two results are very interesting. There's been lots of interesting follow up work, but that's not what I'm concerned with in this talk. For that, I just need to do a slight digression to define what a frustration free Hamiltonian is. Many of you will already know this, but a frustration free Hamiltonian is one where the global ground state is also the minimum eigen energy state for each local term individually. So the global ground state is also the local ground state. And there's an easy argument, standard argument, that for any frustration free Hamiltonian without loss of generality, and we can do this efficiently in classical polytime world, we can rewrite it as a sum over projectors where the ground state is still the same. So the ground state just becomes.
00:06:23.118 - 00:07:11.394, Speaker A: Or the ground state subspace is then just the kernel of this operator, the zero eigenvalue subspace of this. Okay, what did fraschate, Volt and Sirach show all the way back in 2009? So they showed, if we have one of these hamiltonians that are frustration free, then they did something a bit more sophisticated than this. But I'm going to present a simplified version of it, which, which works and gets the spirit of it. They constructed this quantum channel, or completely positive trace preserving map. It takes an input density matrix and it outputs this thing. So what's this thing doing? We can sort of unpack what saying pick a random term in hamiltonian random project. Remember, our Hamiltonian is sum of projectors measure the carry out, the projective measurement.
00:07:11.394 - 00:07:41.922, Speaker A: That's the measurement on that projector or its orthogonal complement. And if you get the complement outcome, then just replace the state with the maximum mixed state, and then it. And then that's what this map is doing, unpacked into words. Very simple procedure. You just measure the local term on the Hamiltonian. If you get the right outcome, if you've kind of projected into the local ground space, keep going. If you don't, just randomize and re sample qubits.
00:07:41.922 - 00:08:07.434, Speaker A: And the way I've written it here, we're just actually doing something very crude. We're resampling the entire system, so we're throwing everything away and starting again. If we get a failure, you can do something smarter here. I don't remember exactly, but I thought that if I got the PI or dongle, then you rotated. Yeah. This is a simplified version of what you did, so you can do smarter things than this for the purposes of this talk. Does it make any difference? It makes some difference, and I'll come to that later.
00:08:07.434 - 00:08:24.994, Speaker A: But not, not big, big one. For this purpose, this is exponential time, and so is the other algorithms. Good. This is simpler to think. Reasonable. Okay. And what they showed is that the.
00:08:24.994 - 00:08:44.347, Speaker A: If you iterate this process, this process, and you just keep on repeating this completely positive map, this converges in the. As you. If you. In the limit the. To a state that's in the ground state subspace. So the fixed point of this map is a ground state. This looks like a quantum version of shunning.
00:08:44.347 - 00:09:12.914, Speaker A: Yeah. It's closely related, but it's a little bit different because. And I'll touch on shunning later a bit. It's not shining. You don't run it to convergence, which is a key difference. Okay, so what's the nice thing about, in the context of preparing ground states of many body systems, what are the benefits of this by now quite old dissipative state engineering algorithm? Well, it's a simple local procedure. All you have to do is measure the local terms of the Hamiltonian.
00:09:12.914 - 00:09:49.390, Speaker A: It doesn't matter what state you start with. This is the output is the fixed point of this process. You can start in whatever state you like, something easy to prepare, completely random state. It will inexorably converge towards the ground state. And as they pointed out in this paper, it's somehow inherently resilient to noise and errors because it doesn't matter if halfway through your computation, a cosmic ray comes in and scrambles your qubits. You just keep running and it will push it back to the ground state. The disadvantages? Well, it's exponential time, but that's not a big disadvantage because all algorithms for this problem in general have to be worst case exponential time, but it also, it only works for frustration free Hamiltonian.
00:09:49.390 - 00:10:36.274, Speaker A: So everything I said assumes the Hamiltonian is frustration free, and it's actually hard to check if Hamiltonian is frustration free. It's actually QMA one hard. So many papers working on ground state algorithms start off by reciting this paper and saying, but unfortunately, it only works for frustration free Hamiltonians, so we're not going to do that and we'll do something. So what I'm going to talk about in this talk is an algorithm that is very much inspired by this dissipative ground state engineering, which we call the dissipative quantum eigensolver for marketing purposes. But it overcomes essentially this obstacle of the dissipative ground state engineering. And it works for any Hamiltonian, including frustrated ones. And it has a number of other advantages and provable, nice properties that I'll touch on.
00:10:36.274 - 00:10:49.514, Speaker A: Question. Yeah. Why is the dissipated version not loadapps in practice? Good question. Maybe I should put a tick there. You're right. I think. I think it's not.
00:10:49.514 - 00:11:09.520, Speaker A: I haven't done any numerics on it. I don't think Frank did either, so. But, yeah, fair. Could be. Could take care as well. Yeah. Okay, so what does this quantum migrant solver achieve? Well, it's a simple local procedure, like the district of ground state engineering, but now it works for any Hamiltonian.
00:11:09.520 - 00:11:43.612, Speaker A: It doesn't require any knowledge of the properties of the Hamiltonian. So you don't need to know the hamiltonian spectrum or anything that's hard to compute about it. You just need to have a description of the Hamiltonian and you can prove that it's fault resilient in a sense that I'll make precise later with no overhead. There's no ancillas, there's no error correcting code, and yet it's resilient to. It's not fully fault tolerant, but it is in a provable, precise sense. Noise during the process will not spoil the output. Cody, can you comment on the question about why it would be low depth? In practice, they will, yeah.
00:11:43.612 - 00:12:10.576, Speaker A: So it's exponential time. Worst case, it has to be QMA hard. Otherwise I would collapse QMA to BQP with the. But in practice, on Hamiltonians, when you try it, it often runs much faster than exponential. Like in practice means in spacecraft. I care about the depth of the circuit, just the number. Not scaling, asymptotic scaling.
00:12:10.576 - 00:12:35.376, Speaker A: But take the problem you care about solving. How quickly will it find the ground state of that particular problem? It's not a precise complexity, for example, about scaling, but we'll see, like, examples where there's promise in the same way as with VQE. In practice, VQ sometimes works well, despite the fact that the general problem is exponential. Toby, when you say neh, you still mean. It's a sublocal term. I still mean local k. Local Hamiltonians.
00:12:35.376 - 00:12:43.896, Speaker A: Yes. Probably you can expend it to sparse Hamiltonians potential. Yeah, sorry. Good point. Any k, local H. Yes, thank you. Yeah.
00:12:43.896 - 00:13:15.138, Speaker A: Otherwise it would be a bit too much. Good. So what's the difference? What are the new ingredients here that lifted this from, like, the discipline to ground state engineering, from frustration free Hamiltonians to arbitrary local Hamiltonians? So there are two changes. Instead of using projective measurements, I use weak measurements. And then the second ingredient is, instead of running this, is running this to convergence. This is a little bit inspired by schoening or reminiscent. You don't run it convergence.
00:13:15.138 - 00:13:48.858, Speaker A: You conditionally stop the process at an appropriate time based on the outcomes that you see as you're doing the measurements. So the output of this algorithm is not the fixed point of this CPT map, this quantum iterating, this quantum channel. It's a conditionally stopped process. So those are the kind of two conceptually new ideas that get you from frustration, frustration free Hamiltonians to frustrated. Okay, so I'll try and hopefully we'll see. I can have to want a brief digression to agsps, and then we'll come back to what the. I'll write down what the process is and we'll start analyzing it.
00:13:48.858 - 00:14:05.926, Speaker A: So this is a approximate ground state projectors were introduced actually not in this paper, but in an earlier paper. But this. This paper kind of. This definition is. Comes kind of from this general definition here. This is from. From Dorito Haran et al.
00:14:05.926 - 00:14:49.846, Speaker A: From a paper where they proved the reproof the 1d area law in a stronger 1d area law. So this is a generalization of the definition of AGSPs from there. So AGSP, approximate ground state projector. So this is a generalization of their definition. I say that an operator k, a hermitian operator k, is a delta, gamma, epsilon, approximate ground state projector. For a projector PI, if there's some projector PI that's close to PI in operator norm, and for that projector PI, it commutes with k and k contracts. Well, let's put those on the final complement of this subspace defined by PI, it contracts by at least root delta.
00:14:49.846 - 00:15:53.936, Speaker A: And on the subspace the support of PI, it doesn't contract by more than gamma root gamma. Okay, so if this was actually a projector, then this gamma would be one and delta would be zero. So a very good approximate ground state projector, which would not be approximate, it would be exact ground state projector would have delta equal to zero, gamma equal to one, and epsilon equal to zero, or ground state approximate ground state projector would have delta close to one, gamma not close to one, and epsilon big. So this, for those who know the AGSP results and the use of them in improving area laws, there's an extra condition in the previous definitions that I just don't care about for these purposes, which is that it doesn't, the AGSP should not expand the Schmidt rank of a state too much. I don't care about that condition here. So I've removed it. Those of you know, AGSPs, it's not okay, so not that difficult to construct approximate ground state projectors, at least approximate ground state projectors.
00:15:53.936 - 00:16:44.270, Speaker A: They might not be very good ones, but there is at least possible to construct them relatively straightforwardly. So one can show it's not too, it's not a particularly difficult proof that if I take this object here, what is this? This is like a product over all the local terms of some operators related to local term in the Hamiltonian. And I just add a bit of epsilon weight of it to something to the identity, and then I take the product upwards and downwards. This object here is a delta gamma epsilon squared, ADsP for PI zero, where PI zero is the ground state of Hamiltonian. What are all of these things? So this operator k, sub I is related to the local term of the Hamiltonian. It's just essentially rescaling and flipping the spectrum. And you know, this is not a very good, a GSP.
00:16:44.270 - 00:17:03.206, Speaker A: Gamma is close to one. That's great. But delta is very close to one as well. It's just a little bit smaller. And the approximation parameter is order epsilon squared, where epsilon is the parameter. What's the nice thing about this? A GSP is that I can implement it locally. So if I unpack, let's simplify this.
00:17:03.206 - 00:17:57.318, Speaker A: Let's just call this thing k, sub I, capital k, sub I. This is an operator that acts just on non trivially, just on the same number of quits as my local term in the Hamiltonian. So this corresponds to performing some kind of generalized measurement on a small number of qubits, qubits and then moving on to the next one and doing that in some order so precisely, this is like one element of a generalized measurement which is close to identity. So this is a weak measurement in that we have pair of measurement operators that one of them is close to identity, the other one is the other way that makes it normalized. So if I measure all of these k, sub I in turn, and I always get the good outcome. So the k outcome, rather than its complement or the other outcome, I'm going to start calling this the zero outcome. So these are binary outcome measurements, not projective.
00:17:57.318 - 00:18:38.244, Speaker A: So zero is going to be the good outcome, because it's zero for low energy or ground state. If I measure these things in order, and I always get the good outcome, the zero outcome, then what I have implemented is k, k here, big k, which we said already is approximate ground state projector. Of course, I might fail, I might get the wrong output at some point in the process. And then I haven't managed to implement this. So I can apply this, I can implement this by local operations, but only probabilistic. Turns out it doesn't actually matter. It will work for any ordering, but they don't commute.
00:18:38.244 - 00:19:23.828, Speaker A: And there's all this order. It's a really good question. There doesn't seem to be numerically to matter very much. But I don't know that there might be some way, maybe choosing random order would be clarified. There's still parameters here, just epsilon. So if I can, you know, that looks like a complicated equation, but actually, if I unpack this, what does it look like to do one of these weak measurements? So if I have a k body term on my Hamiltonian that looks like a tensor product of Pauli's, then the circuit to do it has a few c naughts and then some single qubit rotations just here and some kind of basis changing operations. Yeah.
00:19:23.828 - 00:20:09.496, Speaker A: So you know, if I, if this was a two local hamiltonian, so just two body interactions and there would just be two qubits here and like four c nots and a few single qubit rotations, it's not a particularly difficult implement. It is circuits to implement a single one of these measurements. And then you do this for every turn term in hamiltonian. In term. Okay, so if you take epsilon, go to zero, does it converge to some sort of differential equation? Uh, probably, but I'm going to only analyze things in discrete time. Okay, that was a. And how to implement them? Not very good, but okay, ish AJSp's locally, which is the ingredient I need.
00:20:09.496 - 00:20:42.034, Speaker A: So now I can finally write down what the algorithm is. So the algorithm is the following. It's going to be described by a quantum instrument. So a pair of completely positive maps that sum to something trace preserving. So this is the most general way of character of mathematically writing down measurement in quantum mechanics. So one of my elements of my quantum instrument is e sub zero is just going to be to apply this a GSP, and the other one is the other thing that you need to write down to make this add up to something completely positive. And trace preserve.
00:20:42.034 - 00:21:05.554, Speaker A: So remember, this big k involves measuring each term in the local hamiltonian ones, actually twice. So all of those measurements have to succeed. This corresponds to like, what, at least one of those measurements didn't succeed. And then I replaced the entire thing. I throw it all away and replace with a maximally mixed state. And this is not very smart. You can do better things here, but I'm keeping it simple for this talk.
00:21:05.554 - 00:21:38.478, Speaker A: Okay, then there's the algorithm iterate the instrument starting from maximally mixed state or any other state you like, and stop when you get a sequence of n zero outcomes. So you iterate, you apply this instrument, one round of it is implying e zero. E one, the instrument described by that. And then you stop once you've got e zero outcome n times in a row. And it's not very difficult to prove that if you do this, the state when you stop is close to a ground state. Indeed. It's kind of the.
00:21:38.478 - 00:22:00.374, Speaker A: How close it is goes exponentially in the ratio of delta and gamma. Haven't said anything about runtime. This is just at the point where you eventually stop, which could take a really long time. You will stop on a good state. I'm sorry, could you say epsilon one again? Bd is the whole dimension and you're replacing d is the whole dimension. Yeah. So you're replacing the whole thing.
00:22:00.374 - 00:22:30.370, Speaker A: At the moment, I'm just taking simple cases, but I fail. I go like throw everything away and start again. You can do smarter things on this, but for now, I'm just going to stick to that very simple version. Turns out not to matter that much because everything's exponential time anyway, so I'm losing kind of exponential factors in this, but the algorithm's exponential time anyway, so I can get a better exponential by doing something smarter. I'll talk about that in a bit. Okay, so I'm actually going to. How different will this be? I'm doing phase estimation.
00:22:30.370 - 00:22:45.324, Speaker A: I'm just hopefully that you went up with the right place. Yep. So that's a very good algorithm. It's on. It's like, that's the quantum version of root for search. It's also exponential time. So runtime vantage, one runtime purposes, it's just as good.
00:22:45.324 - 00:23:08.388, Speaker A: And if I had a big scalable quantum computer, that's what I would do if I wouldn't run this. But that is, of course, involves doing a complicated phase estimation procedure, which involves a more complicated circuit than this. But this is not a competitive algorithm. In terms of runtime, everything I put on the table is exponential time. I see. So the difference is you have to do phase estimation. And I got nothing against phase estimation.
00:23:08.388 - 00:23:39.196, Speaker A: If I had a large scale scalable fault on quantum computer, I would run phase estimation and not know. I mean, all the algorithms you listed are exponential time. But can you say anything more fine grained than that? Like, do some tend to be faster than others? I will get to that. Hopefully. I can say a little bit. Yes. Well, no, this is an inherently quantum task, because, remember, the task here is to output the quantum state.
00:23:39.196 - 00:24:18.844, Speaker A: So it's not really. I set the rule of the game and I can diagonalize it and I can find out what its lowest eigenvalue is. Yeah. And then I could just use that term and measure it. So I don't know why you're going through this ag, because if you do that, what's wrong with that? Well, it's fine for frustration free hamiltonians, and in some sense, that is what the original algorithm by Frank et al did. But the problem is, for frustrated hamiltonians, you don't want to be in the local ground stage. That's the definition of frustration.
00:24:18.844 - 00:24:37.604, Speaker A: That might be really far from the global ground state frustration. Okay, so it's gone. It's good. It won't work at all. It won't get you to the ground state doing that. So there are choice of many types of ads you can use. Yes.
00:24:37.604 - 00:25:32.350, Speaker A: So you use this because it was simpler or because it's more robust? No, it's a bit. There's two reasons. One, I want something locally implementable, which you and your papers didn't care about, but I can still use your Chebyshev ones and I'll talk about now, the problem is that I also need to be able to construct this AGSP in practice and get to this if I have time at the end to construct your AGSP by Chebyshevolumula, I need to know the spectrum of hamiltonian, but for that, I need to solve the QMA hard problem to just construct it and persist. So this one is constructable in classical polytype. So if you deliberately start from a state that is orthogonal to the ground state, so this doesn't work at all. No measurement. You'll get a measurement that fails at some point and then you'll just replace with max remixed, replace max with a mixed.
00:25:32.350 - 00:26:00.284, Speaker A: So effectively you're starting from maximum state. That's why I put my wrote down start from Max mixed. It doesn't matter else is. That's also true in the old dissipative ground state. Dissipative state engineering results, no matter what state, if the maximum unique state, the overlap between the maximum unique state and the ground state is very small. That's right. But it's going to be exponential time anyway because it's q and a half.
00:26:00.284 - 00:26:57.226, Speaker A: You know, if you have to switch off your algorithm mindset of trying to do something efficient here, you can throw exponential practice, at least in doing the math everywhere to make. Okay, I think I'm going to see if I have time to just let's see if I can, I can, I will sketch a proof of this, because it's not very difficult. I mean, I'll go through the proof, but I'll go through it a little bit quickly. So, recall, definition of AGSP is that I have a projector that commutes with my operator KatE that's close to the ground state projector. So just taking the properties of the definition of AGSPs, I can just do a simple manipulation to just bound that the overlap with the ground state after I've applied this operator n times is at least gamma to the n. And similarly, if I take the overlap with the orthogonal complement of this projector PI, then I get something that's upper bounded by delta to the power of N. So there's an easy bounds to just derive.
00:26:57.226 - 00:27:18.922, Speaker A: And then I'm just going to look at the state when I stop. Well, this is a quantum instrument, so I've applied the map e sub zero, n times, and then I've got to renormalize. And let's just substitute in the definition of what e zero is. It's k to the n rho k to the n. K is hermitian. So I've dropped the dagger here and then divide by the trace. Now, trace of the ground state against this.
00:27:18.922 - 00:27:54.604, Speaker A: Well, just substitute that state in. Rewrite things a bit by turning, you know, projectors into the one minus the orthogonal complement and rearrange a bit. And put in the bounds. I just arrived and I get to this equation and I'm basically done, because now I just like bound. I put in the rewrite this a bit, and I've got my delta over gamma to the n, one minus something that's decreasing exponentially n. And then if I start with my, this is true for any initial state row. If I shove in the maximally mixed state as my initial state, this simplifies a little bit.
00:27:54.604 - 00:28:21.724, Speaker A: Then I can just substitute in and I get the bound that I claimed before. So it's not a particularly difficult proof. Last step, this was the overlap with the ground with the projector PI. That's not the ground state projector. My real ground state is only Epsilon close to that. But that just gives me a error, epsilon in the past. So for relatively straightforward proof, there's lots of things that are not yet.
00:28:21.724 - 00:28:48.680, Speaker A: I mean, I haven't achieved what I claimed at the beginning yet. Okay, we're getting there. What's really nice, I haven't said anything about the running time of this. What's nice is actually you can compute an exact analytic expression for the expected stop runtime of this process, and it's given exactly by this formula. So this is in terms of the operator k, which you can bound in terms of the parameters of the AGSP like this. And you see here it's exponential. I've got a d here, which is the total Hilbert space dimension, which is exponential.
00:28:48.680 - 00:29:12.416, Speaker A: And I've got a one over something smaller than one to the power of n, which is also an exponential. So this is clearly exponential runtime, as expected. But the nice thing is you can actually get exact runtimes for this algorithm. And it's a kind of a huge argument. So I think I'm actually going to indulge myself and go through the proof, and this is the last proof I'm going to go through in any detail. So this is one way to prove it. So, imagine you're a betting person and you bet.
00:29:12.416 - 00:29:29.540, Speaker A: Remember, you're doing these measurements. You measure the AGSP, you either get zero or one. You measure this instrument, you get zero or one outcome. And now let's imagine we're betting on this. I'm going to bet according to the following strategy. So, time step t. In this algorithm, I'm going to bet all of my winnings so far, plus an additional.
00:29:29.540 - 00:29:58.808, Speaker A: I'm british, so t pounds. It's roughly the same as dollars these days. I'm going to bet in all of my, everything I've won so far, plus an additional t on the outcome zero coming up next at fair odds, whatever those fair odds are might be. And if I get the outcome zero, then I get back my stake, times the odds because it's a fair game. And if I get the outcome zero, I lose everything. So to keep playing, I have to pay t plus one pounds to play the next round. Okay, so that's a, it's not a very good betting strategy.
00:29:58.808 - 00:30:21.498, Speaker A: It actually turned out it's not that bad. Okay, so now let's just define some notation. Let's write x, sub t for the, the random variable. That's the t outcome of this process. So this is this random variable, zero one, and this is another random variable, m, sub t. That's my net winnings at time t. So initially I start off with no net winnings I haven't played yet.
00:30:21.498 - 00:30:54.170, Speaker A: So the m zero is zero and m, sub t. Well, I had to pay t to play and I bet my entire winnings. And then what I get back is on a zero outcome is everything I put in times one over the probability of winning because it's a fair game. And if I get the outcome one, well, I've lost everything, and it's cost me overall t to play up to then. So I've lost t. Okay, so that's just the net winnings in formula. So this comes, this is because I said the game had I played with fair odds.
00:30:54.170 - 00:31:36.992, Speaker A: I don't know what this probability is, but whatever it is for that round of the game, that's, that's the winning, the my return on my bet. Okay, so let's do some math. So if I just write down the, what's the expected value of the winnings at time t conditioned on all of the previous outcomes up to now. So this conditional expectation, well, it divides up into the probability of getting zero, conditional previous outcomes, and the probability of getting a one. So probability, getting one, I lose t probability of getting zero. I win this much, which we just saw. And now if you look at this, this cancels with this, this cancels with this, and it all cancels away until you just get m, sub t minus one.
00:31:36.992 - 00:32:03.948, Speaker A: Okay, so just simple algebra. Everything cancels except the m, sub t minus one. This implies that my random variable m, sub t, or my sequence is in martingale with respect to x, sub t. That is, the expected winnings at time t are equal to whatever I had at the time t minus one. This is a mathematical definition of a martingale or Martingale with respect to x, sub two. So that's just capturing mathematically the fact that this is a fair game. Okay, by.
00:32:03.948 - 00:32:41.944, Speaker A: There's a nice theorem from Haskell probability theory called dubes optional stopping theorem that says that if I conditionally stop a martingale with some, with the strategy that I decide when to stop only based on the past, not the future, then the expected value of the stopped martingale is also a martingale. So that just is that there is no way of winning against fair odds. As matter what clever betting strategy you come up with, you're always going to. In this fair game, you're going to end up not winning on average or losing out on average anything. I do this in a casino because the odds aren't fair now, but for my game, I'm being fair to you. Okay, so the expectation of this stopped martingale is equal. It's a martingale.
00:32:41.944 - 00:33:21.424, Speaker A: So the expectation of the stopped martingale is equal to the expectation of m sub zero, which is zero. Okay, this is all I need to take home from this. The expectation value of m at the stopping time is zero. Okay, remember now, we reset the states to the maximally mixed every time we get a one. So if we've had a run of k zeros since the last one, well, the state just before we, this run must have been one. So now my state after I've had a run of k zeros is given by this row, sub k, which is k time. I've applied the a GSBK times and then onto the max remixed state, which is just this expression.
00:33:21.424 - 00:34:01.822, Speaker A: The probability of a zero, given that I've just had a run of k zeros, is just. Well, I have to get another outcome, e zero outcome. So I have to successfully apply the edges b another time. Simplify that. Okay, so now I have an expression for my probability of zero given run of k zeros. Okay? I also know from the way I set up the betting game that my winnings, when I've just had the stopping time, I've just had a run of n zeros. If I rewind n steps from that, then if you think about it for a bit, the definition of betting gain, that's how much money I must have.
00:34:01.822 - 00:34:15.836, Speaker A: That's how much I've lost up until that point. There's a bracket missing this. Sorry. This should be a plus size I paid t to play so far, and then every round end step. So this. This should be a plus, not a minus. So let's just think about what I.
00:34:15.836 - 00:34:45.384, Speaker A: The rules of the betting game that I set up and then I can just do some math. So I just worked out an expression for this probability of zero. Given everything else. This was my definition of my winning, my winnings coming from my definition of my betting strategy. This is what we just worked out before. This defines some recurrence relation, which I can now in m sub t, which I can then solve. And if I solve this recurrence with not too much effort, I end up with this expression for m sub tau n m at the stopping time.
00:34:45.384 - 00:35:06.244, Speaker A: So this is just a bit of math. Solve this recurrence relation. You see the solution to that in the paper. Okay, now let's take expectations. So this term here is just deterministic quantity. There's no random variables in there, so I can drop the expectation. This we showed was zero.
00:35:06.244 - 00:35:31.062, Speaker A: And now I rearrange and there's my expected stopping time, so I can get an exact expression for this. There are other ways of doing this. You can do this via generating functions. You can do it, I do it two ways in this paper and a different way in another paper because different proof methods are convenient for different purposes. There's kind of a cute martingale argument. And then you can bound this in terms of properties of the properties of the AGSP. Okay, good.
00:35:31.062 - 00:36:03.404, Speaker A: So it's really nice. We can analyze the running time and we find out that it is indeed exponential time as it has to be. But we know what, how it scales with the parameters of my system. I can run this numerically and is the only thing I'm going to be able to say in this talk about or have time to say about the fact that it's, it's in practice, it often works, doesn't take large circuit depth. So here is running numerics and running this on a Heisenberg chain of length ten, simulated classically. Obviously we don't have a quantum computer to run this on yet. We do, but they don't work as well as the classical computers.
00:36:03.404 - 00:36:28.588, Speaker A: And you see that like it runs for a whole bunch of time, actually quite a long time. And eventually this purple line is the energy, the dotted blue line is the true ground state energy. The green is the overlap with the ground state subspace. So it gets pretty close to the ground state. Now this has run for a long time, but remember, I set this n equals four here. So I'm only stopping as soon as I get a run of four zeros. And before that I reset to the maximum mixed state.
00:36:28.588 - 00:36:57.264, Speaker A: So the only I only have to kept coherence for like four iterations in this algorithm. Otherwise, that I'm just like throwing everything away and restarting, and even in just like n equals four, it gets, it, it gets close to the ground state. Okay, let's just show you that I've simulated this algorithm and it does actually work. Yeah. Question from the beginning. Right. So it's like a one for a very long time.
00:36:57.264 - 00:37:24.970, Speaker A: What's the reason for this behavior? Keep on getting ones. Haven't got around four zeros yet. Keep on resetting. It's exponential time algorithm. It's got to take a long time. I haven't yet. Here's what I just, here's a theorem we proved earlier, but, you know, and the stopping time, this will be close to the ground state with these parameters.
00:37:24.970 - 00:37:53.798, Speaker A: But the problem is, for this to work, right, I need Delta to be strictly smaller than gamma. Otherwise this is not going to zero. And if I look at, if you remember what Delta and Gamma were, you don't remember it. I wrote them down again. These are the parameters from the local aegisp I constructed from the Hamiltonian. And the problem is, to get delta smaller than gamma for convergence, I need to choose epsilon small relative to, effectively, it's relative to the spectral gap of the Hamiltonian, but I don't know the spectral gap of the Hamiltonian. That's at least, it's worse than QMA.
00:37:53.798 - 00:38:27.364, Speaker A: Hard to compute that. Okay, so I haven't, I haven't done what I said yet. Now, the solution is to not choose a constant epsilon, but to choose epsilon as a decreasing sequence in time. And so here's the theorem. If I choose epsilon at time, step t to be some constant epsilon, zip sub zero, divided by the length of time since the last one outcome, then in the limit of n going to infinity, this converges exactly to the ground state. And now this is independent. I haven't, epsilon is not depending on the spectrum of a Hamiltonian at all.
00:38:27.364 - 00:39:05.762, Speaker A: Okay, I'm not going to prove this, but let me give you sort of a very hand waving intuition. It's kind of interesting mathematically, but too complicated to put in a talk. But intuitively, once this epsilon is smaller than the spectral gap, then this algorithm will start to converge. And the convergence kind of goes as one minus one over t, because my epsilon is going as one over t. And this is the harmonic series, it diverges. So the product of one minus the divergent series converges to zero. On the other hand, up until the point where this algorithm starts actually working, if you like, it starts driving to the ground state.
00:39:05.762 - 00:39:44.002, Speaker A: The error accumulated up to that point is given by something that scales like this. So this one over t squared is coming from the fact that I have an order epsilon squared AgsP. So you kind of pick up order epsilon squared error each step up until the point where your epsilon is small enough to start converging it. And if you bounce, you can bound that by something where kind of nice point is, it's a constant. The Riemann zeta function crops up, and essentially because the error you've accumulated up to the point where the algorithm starts converging is constant, but then after that, it converges to zero. This kind of the trade, these two things, the interplay between these two things move. We got sort of tight enough control to show that in the limit, it does converge to the ground state.
00:39:44.002 - 00:40:14.538, Speaker A: That's a very rough sketch. The details are a little bit complicated. Okay. With this. Now I have a version of the algorithm where this will converge to the ground state of hamiltonian in exponential time without needing to know anything about the spectrum hamiltonian for any local hamiltonian. Good. The kind of interest in the original disputive state engineering paper was the fact, not that it was as efficient algorithm, but the fact that it was inherently resilient to noise.
00:40:14.538 - 00:41:06.554, Speaker A: It was one of the excitements of the reason that paper got so much attention on the district quantum computation side is it was the first model of quantum computation that didn't satisfy DiVincento. Sorry, DaVinco's five criterion, because it didn't need initialization. You could start from. So what happens if errors occur during the process? Or what happens if the process itself, as I'm implementing tickets, is faulty, so the gates are used to implement it, or they introduce errors themselves in the fault hover type analysis. So both possibilities are encompassed mathematically in this framework by saying that I've got an quantum instrument that's faulty. Whether these errors come from external noise or actually implementation, I can just encompass this by saying that I've got some my quantum instruments, I haven't done the right one. I've done something that's only delta close to the correct thing.
00:41:06.554 - 00:41:49.834, Speaker A: Okay, can prove is that if you iterate this faulty instrument until you get around with the algorithm I just presented, then the state of this and row sub n is then the state you stop on that. This state will be still be close to the ground state. This is not. I call this fault resilience, because it's not like full fault tolerance. Fault tolerance would say I can, independent of the error rate, I can make this as close to one, as I like with poly overhead here, I've got something a bit weaker. It says that independent of the runtime, the state will be, the output will be correct up to order delta. So it's like weaker than full fault tolerance.
00:41:49.834 - 00:42:22.720, Speaker A: But on the other hand, I haven't used any error correcting codes or fault tolerant circuits or ancillas. Okay, so I'm going to give a very brief sketch of the proof of this. This is really just a hint and then go and read the paper. I can write the action of a completely positive map in a kind of matrix representation. This is a linear operator. So I can write a matrix representation of this and then iterating it is just taking powers of this matrix. And then I use a bunch of non commutative paraphrabenius theory and cool stuff about the shor structure and stuff that I don't have time to talk about.
00:42:22.720 - 00:43:10.778, Speaker A: But go and read the paper because it's nice maths and that's kind of what's behind this proof. You have to really get a handle on the kind of sure. Structure of this matrix and then use some fragment of quantum parenthropinius theory, quantum generalization of the theory of kind of Markov chains. Okay, but here's the, here's a plot of this in action. So here I have just added noise iid depolarizing noise, I think in this numerics, um, at rate ten to the minus four, um, to this al, whilst running this algorithm. So after every gate I've applied IID depolarizing noise at that rate, um, the ground state energy is here. If I just start in the ground state and let the noise accumulate, it, you know, converges to something, the maximally mixed state and goes, ends up quite far away from the ground state.
00:43:10.778 - 00:43:40.692, Speaker A: If I have the noise running, but I run the DQE algorithm at the same time, you can see that it's no matter independent of the runtime, it stays very close to the ground state. So this is the fault resilience in action. Okay. I've actually got through all the main stuff. That was quick. So I can go on to the bonus material, but I'll pause maybe if there are any questions at this point. Yeah, let's go here and then here.
00:43:40.692 - 00:44:44.864, Speaker A: Yeah, so when you say that everything, very elementary, Martingale, you probably can do a continuous version of this and indeed in the original dissipative quantum computation paper, in fact they did it in mostly that paper, mostly in a continuous time setting. And you can just, yeah, discrete time is left as an exercise here, and you can continue. So, if you happen to have the property that the Maximix state did have, a one over 40 over state, would this be provably. That's a really good question. I'm not sure. I think if you start from a state with high overlap, it ought to converge faster. But I don't claim to have a proof, and I haven't yet running.
00:44:44.864 - 00:45:24.524, Speaker A: That's right. If you looked at quantum case, sat, you know, Bravi's coming. Yeah, you know, quantum case satisfying, you have every term is already a projector. So that's very nice. But Robbie showed that if k is two, you can solve it in polynomial time. So, does this converge quickly? So for that you can use the original algorithm, but no, I think it still ends up being exponential time. It doesn't do as well as another algorithm does that.
00:45:24.524 - 00:46:17.396, Speaker A: Okay, sorry, how much of your analysis for the stopping time goes to for other AGSP instructions? This is like, this goes for, this analysis works for any AGSP. But I will use the properties of, I just use the properties of the AGSP. So give me an AGSP and the properties, and then plug it into the theorem. So the order of the operators that visit, and you tried it numerically on a 1d system, is there a relationship between the order of the terms, like geometrically on the line? So I've tried it in 2d as well. I just haven't shown numerics for that. For 2D, Fermi, Harvard, I don't think it doesn't numerically seem to matter. And there's another thing you can do, which is in the paper, which you can just choose the terms at random each time.
00:46:17.396 - 00:46:50.850, Speaker A: And that also works. So it doesn't help like sweep up as opposed to. Not with this resampling strategy. Indeed, in the original paper by Frank, in some of the other applications where they're constructing stabilizer states or tensor network states, or there, they use clever resampling strategies that do something more sophisticated than does kind of use the structural exploit structure. And that's partly how they get poly time convergence. But that only works in those settings where you've got a description of the state up front. But it's an interesting question.
00:46:50.850 - 00:47:21.148, Speaker A: I mean, I don't know. It may be that for certain hamiltonians, you can exploit the structure of hamiltonian and get faster exponential time convergence by being clever and using more information about the structure. Okay, let me say a little bit about that. So. Oh yeah. So I might notice for resilience, there's delta that appears in these differences in the. If you implement this quantum instrument using sort of this kind of like the circuit that you mentioned.
00:47:21.148 - 00:48:01.336, Speaker A: So if I have, like, constant error gates in those, presumably this delta will scale with the system size. No. So other bonus material, because I was anticipating this question. If we have do the kind of stand error model where we, after each gate, two qubit gates, I hit those qubits with errors after every gate in my circuit. A little bit of maths. You can show that the delta will scale as with the number of terms in the hamiltonian. This is the local Hilbert space dimension times delta.
00:48:01.336 - 00:48:51.946, Speaker A: So it's not exponential, it's not scaling with the Hilbert space dimension, it's scaling with the number of terms on the local Hilbert space dimension. It bothers me because it seems to me like if you make a measurement that gets crappy there, you should just twirl that and nothing else. Absolutely agree. And that is why I have this section of the slides that I'm about to get to somehow built in also on what Eddie's saying. I mean, you might not get to hear it is also an open algorithm in some sense. I realize your strategy is different. Yeah.
00:48:51.946 - 00:49:23.766, Speaker A: VQE was in my original table to cool algorithm two, but it doesn't have provable success guarantees, so it's got different benefits. It doesn't really succeed. That's the problem with eqe. It's great, but you don't know. So in the original work of Hastings. Yes. I don't do that strategy because then you have, like, a so called quasi vocal terms, and that looks like this is the vocal thing instead of doing local things.
00:49:23.766 - 00:49:42.760, Speaker A: I think the quasi local kills you. I mean, it has to, because it has to give me something that's exponential time. So you could do that. But I have a feeling that quasi local is going to hurt. At least it has the possibility of being efficient for some problems. That's true. That's not necessarily true.
00:49:42.760 - 00:50:11.108, Speaker A: So the convergence rate of this, all I showed at the moment was a bound on stopping time. That's exponential, but that's an upper bound. And what we see from the numerics is that's often a terrible upper body, and the real, it converges much faster than the upper band. This can be fast in practice on some Hamiltonians. It depends on the specific structure of these, the eigenvalues and eigenvectors of Hamiltonians. But, yeah, I mean, you can do that. It's going to be exponential time.
00:50:11.108 - 00:50:29.892, Speaker A: But. Okay, so far, I did something very stupid. Right. Right. If I got the wrong, a bad outcome. I just threw everything away and started again. And now I'm going to get to what Eddie wants me to say, which is the, why don't we do something smarter? Which is to just reset the qubits that I just measured.
00:50:29.892 - 00:51:23.446, Speaker A: Not all of them, because why should I? Why throw everything? Because so far, what I've done is essentially just probabilistic repeat until success. So indeed, you can do local search algorithms like churning walksat moses algorithm for QLL. They only usually resample locally, so the qubits or bits that gave the bad outcome. So why don't we do a local resampling algorithm so we can do that? It just changes one of my maps. We can still derive analytic expressions for the expected state at the stopping time and for the expected runtime. It's bit mathematically harder to derive now, because you don't have, throwing everything away simplifies the maths, but you can still get analytic expressions, these expressions now in terms of d squared by d squared, transfer matrices, these, these, this quantum instrument. So this is like I have an analytic expression, but I have to do a big matrix multiplication to actually evaluate it.
00:51:23.446 - 00:51:58.956, Speaker A: So I can only do this numerically now, but we can do that. And what you see, but I can't prove at the moment, is that if you do global resampling, you get an exponential growth in the runtime with the system size as expected. And for local resampling, you do as well. But this is, you get an exponential with a smaller exponent, which is similar to like Walksat and other things where you don't, you get, do you still have exponential time, but you've improved the constant and the exponent. So you see that numerically by, and this is not simulation, this is computation. I just calculate this analytic expression. I just have to evaluate it numerically, but I can't at the moment prove that there's a smaller constant in the exponent.
00:51:58.956 - 00:52:15.666, Speaker A: I can just see it, which is intriguing. So I don't know. That's, that's what I'm going to tell us. They have time to say in answer to your question. But your intuition is spot on, and you can, this shows that it's right. If you ran Sherning's algorithm, it would be a very bad idea to reset all. Absolutely, yeah.
00:52:15.666 - 00:52:31.574, Speaker A: So indeed, the intuition that local resampling should work better. It does, yeah. And it does also for quantum, the more stickers. That's right. Good. Another thing you might haven't asked me about, but I have a bit of time. So I'll tell you anyway.
00:52:31.574 - 00:52:54.612, Speaker A: So far, I've just iterated till I see the first run of zeros. And that might take me exponential time. And no, expected stopping time is probably exponential. But what if, like, I just have a budget, I have some number of compute credits for my quantum computer, and I can run for 2 hours and that's it. You know, that's. I got to do the best I can. What we would like to do is to stop on the longest run of zeros that we've seen within that time budget.
00:52:54.612 - 00:53:20.100, Speaker A: But of course, we don't know what the longest run is until after we've gone and spoiled it by getting the wrong outcome. So we know the zero run has ended only when we measure one. But by that point, it's quantum mechanics. The measurement has disturbed the state. So I've destroyed the state I would have liked to have stopped on. So there's some nice theory from optimal stopping theory. Again, classical probability theory, the simple version, the kind of canonical problem here is all the secretary problems.
00:53:20.100 - 00:53:48.336, Speaker A: You have n candidates. You see candidates one by one. You have to decide on the spot whether to hire that candidate or not or reject them. They never come back. And what your task is to have a strategy that optimizes the quality of the candidate you hire. And there's a classic result that the optimal strategy for this problem is to just reject the first n over e natural, log Euler's constant candidates, and then hire the next candidate who's better than all the ones you've seen so far. And the probability of hiring the best candidate under this strategy is one over e, which is not too bad.
00:53:48.336 - 00:54:27.418, Speaker A: It's constant, the probability of getting the best person. So there are other variants of optimal stopping theory, but this is kind of like the simplest problem in optimal stopping theory, the first one. So if you use iterate for at most t steps, and you stop according to the optimal stopping policy, which you can do a bit better than the secretary stopping policy, but similar kind of strategy. You don't need to know what's coming in future. You stop according to some strategy based on what you've seen so far. Then you can show that the expected run of zeros you stop on according to this stopping policy goes as log the total time budget. And that's consistent with the fact that we expect an exponential running time.
00:54:27.418 - 00:55:14.990, Speaker A: We expect to need a runtime of exponential and n to see a run event. So take logs and you. That's proof that you can do this optimal stopping version of this. That also, you don't need to. You can have a version of that. You just have a time budget, you can still make it work. Okay, I'm going to finish with, once you have a run of zero, risking more, can't you keep part of this, I don't know, as quantum mechanics, like measurement principles, and this is a highly entangled state.
00:55:14.990 - 00:55:54.522, Speaker A: So I might be, maybe I've only spoiled a bit of the state, and maybe I could keep running and hope to fix up that part of the state. And that might be a smart thing to do. But if I get the wrong outcome, I know that I've kind of spoiled the state, and so I would have liked to stop one step earlier. So you can do other things in terms of resource, being clever about when you've got the wrong outcome. You can, you know, the resample locally or even just kind of heal the state. And again in the original, in the different context to get polytypes runtime for, but then you won't get a state that's necessarily close to the ground state anymore. You've spoiled it.
00:55:54.522 - 00:56:23.594, Speaker A: You pushed it a long way away, potentially, and now you've got to convert it back. But the problem is, when are you going to stop? So the original policy is like, you can try just, I'll stop as soon as I see ten, a sequence of ten zeros. That's fine, but you don't know how. But if you've really just got a fixed time budget, you have to choose when to stop before knowing what the next outcome is going to be. And there's a way of doing that that gives you the same expansion. Yeah. You go through these hamiltonian terms like back and forth.
00:56:23.594 - 00:57:23.228, Speaker A: I only go back and forth to get a commission operator for the math. Each of these projections, there's a gazillion variants of this. All of them will be exponential time in the worst case, but some might converge faster or slower on different homosexuals, and there's a lot of which have solved every problem about this type of algorithm. You could do that, and it might work better. Yes, there's a lot of interesting questions. Let me finish with one. So, coming back to Umesh's question, actually there are better AJSP's than the one I use with better parameters.
00:57:23.228 - 00:57:54.798, Speaker A: If you take a suitably shifted me scale, Cheby chef polynomial. So this is from this paper, then. So these are the parameters, ground state energy, lambda zero, delta, this little delta, the spectral gap this time. And now I just take, I put this Hamiltonian into this Chebyshev polynomial, I get a new Hamiltonian out, or this operator that I get out, it's a polynomial in h is a delta ten agsp for the true ground state. So this is very good. Gamma is one, which is excellent. Epsilon is zero and delta is pretty small.
00:57:54.798 - 00:58:55.880, Speaker A: It's in fact, it's shrinking exponentially in l, and for a degree l Chebyshev polynomial, I have a k times l local Hamiltonian with poly m terms. So I can locally approximate this just like I did before. I just apply the same lemma I had before, but to this operator, rather than the, the Hamiltonian itself, but this polynomial in the Hamiltonian, and it's still, it's just a local Hamiltonian where the localities got a bit worse and the number of terms has blown up. And if you do that, and now, instead of the process, similar process to I wrote down before, but now I'm not using a quantum instrument, I'm just adding those instruments, the elements of those instruments, together to make a completely positive trace, preserving that. But now I'm just iterating this to its fixed point. So this now is a fixed point algorithm, and now I can prove that this is close to the, I can show that the then the fixed point of this algorithm, this is how close it is to the ground state. It depends on the parameters of my AGSP.
00:58:55.880 - 00:59:28.524, Speaker A: But if I put the Chebyshev AGsP into this formula, I get out that this is essentially very close to the ground state. This is going, it's like one minus epsilon over something, that's one minus something that's decreasing exponentially in l, the degree of my Chebyshev polynomial. So this is going down, this is, this is pretty good. And the proof of this, just a quick sketch. But if I just, the fixed point equation, so my fixed point has to be invariant under the map. And so that's what my map's doing. And if I simplify the notation a bit, that's the equation I'm trying to solve for rho, sub epsilon.
00:59:28.524 - 01:00:23.204, Speaker A: And this equation is a very nice form of matrix equation that's well studied. It's called the discretely up enough equation. And there's a nice exercise to show this has a unique solution, and the unique solution is exactly that. And once I've got that exact expression for the solution to this fixed point equation, then I can just compute and bound the overlap of that with the ground state subspace. However, doesn't this give a poly, and this is like, this will run in, this will now coverage in poly time, because the AGSP is exponentially good in L. So doesn't this give a poly time algorithm for pairing ground states of arbitrary quantum local hamiltonians and collapse QMA to BQP? Well, obviously not, because I would be giving a Turing award speech rather than a talk here, and I'm not. The problem is, the reason it doesn't is because you need to know, if you remember, in the Chebyshev AGSP, you need to know the ground state and the spectral gap in order to construct the correct rescaling of the Chebyshev polynomial to get the good AGSP.
01:00:23.204 - 01:00:58.504, Speaker A: And of course, to find out the ground state energy and its spectral gap. That's at least QMA hard to compute those in the first place. So what this shows is that there exists, for any hamiltonian, there exists a polytime fixed point process for preparing its ground state, but it's QMA complete, or q, I think I should say QMA hard here. Actually, it's QMA hard to construct that process so it doesn't collapse BPD QMA, which is the other process. So I can't, I mean, I can't make this work for. Otherwise I would collapse QMA to PQP, which. And not going to do.
01:00:58.504 - 01:01:27.374, Speaker A: So it really is fundamental that you need to know the ground state energy, in fact, a bit more here. You need to know the spectral gap in order to construct the good AGSP. And it better be QMA hard to do that because otherwise. Is this only for local hamiltonians or is this for an arbitrary QMA verifier? This is for arbitrary K local hamiltonians. K local hamiltonians. All right. Because is there some dependence on K and the running time? Yes.
01:01:27.374 - 01:01:36.326, Speaker A: Yeah. Exponential. I think so. The way I presented it. Yes. I think it'll be exponentially k, probably, because otherwise you could just scale it up. That's right.
01:01:36.326 - 01:01:49.906, Speaker A: But it's that there is, I mean, in what I presented, there's definitely an exponential dependence on k. The gates. Right? Yeah, yeah. Right. Okay, good, good, good. No, I mean, this is already an interesting complexity theoretic statement. Right.
01:01:49.906 - 01:02:14.374, Speaker A: Something about advice, non uniform advice classes. Right? Well, yes, it says that any ground state of a K local hamiltonian can be prepared efficiently with the help of closed time like curve. Yes, indeed. But you don't know which close time like curve. Right. Okay, I'm going to end because. I'm sorry.
01:02:14.374 - 01:02:28.920, Speaker A: I'm happy to talk clouds time like curves afterwards. Let me just conclude. Or before. Or before. It doesn't really matter. We can talk about it in ten years time, Scott, and that will be yesterday. Okay, so, you know, there you go.
01:02:28.920 - 01:03:03.004, Speaker A: This, this adds this column to this range suite of exponential time algorithms for, you know, in principle, QMA hard problem, but might be solvable in some instances that we care about. I'm going to say, because there was a lot of interest here yesterday and day before on Gibbs samplers. I want to just flag, but I'm not going to have time to say much about it at all. A follow up paper by Dan Zhang, Jan Lucas Borgia and myself was on the archive just a month later than the paper I've talked about. And we can build on these ideas to construct a disabit of Gibbs sampler. And the algorithm is almost identical to what I already presented. The only thing that changes is the stopping condition.
01:03:03.004 - 01:03:23.898, Speaker A: You now change the stopping condition to probabilistically stop depending on the sequence of outcomes. You've seen the analysis and proofs are quite different, but the algorithm is almost the same thing. Similar benefits to DQE. It's simple local procedure. You can prove its fault. Resilience. There's no complicated subroutines like phase estimation involved, or time dynamic simulation or qubitization.
01:03:23.898 - 01:03:52.384, Speaker A: You can get exact analytic expressions for the runtime. No kind of mixing time parameters hidden in there. It's, I think, got optimal scaling, runtime scaling with, in terms of the precision, or at least it's, it matches previous algorithms. I'm not quite sure about the arguments of why that is necessarily optimal. In some sense, it's closer in spirit to just the classical metropolis Hastings algorithm for Gibbs sampling. Classically, you're just doing simple local updates at each step. The key difference is it's not a fixed point process.
01:03:52.384 - 01:04:22.934, Speaker A: We're not. And this is in some sense how we're able to do this, where previous local quantum generalizations of metropolis Hasting had to go via very different routes that look very different to the classical one. The key difference is we're not using a fixed point process. We don't run the quantum Markov chain to convergence. We can stress stop process. And somehow that's what allows us to do this with this kind of simple local updates rules rather than needing to use phasor solution. Downside, I think this algorithm, this our dissipative Gibbs sampler, I think it's sort of inherently exponential time.
01:04:22.934 - 01:04:48.374, Speaker A: I think there's no, unlike with the DQE, the ground state case, I think there's no hope of this working quickly on certain hamiltonians. But I'm not 100% sure on this because this is a bit too recent. I haven't thought enough about it, but I think it'll just always be exponential time. You just have to live with that. So it's not. Whereas some of the other algorithms, like the one from yesterday, potentially could mix faster than the theoretical upper bounds. Okay, outlook.
01:04:48.374 - 01:05:24.516, Speaker A: What I like, and the promise of the reason that the dissipative ground state engineering dissipative quantum computation attracted so much excitement over a decade ago is because it's kind of fault resistance. The main selling point is that it's fault resilient without needing any overhead. The algorithm itself is kind of resilient to errors and self corrects. And that's very useful for companies like Facecraft, where we're trying to do get stuff to run on nisk devices, because without any overhead, we have an algorithm that's kind of self correcting. So baking in the kind of correction to the algorithm itself seems a promising thing to do. And we're nearly there. And there's almost quantum hardware that's capable of running these algorithms.
01:05:24.516 - 01:05:48.080, Speaker A: Not quite, because you need to do intermediate measurements and feed for. But it sort of exists now as of the last couple of years. Just for that, we're always hiring smart people at Facecraft. So I'm going to end there. And thanks a lot for listening. Yeah. Let's go.
01:05:48.080 - 01:06:11.334, Speaker A: Frank first and then. So you're frank to last slide. You said that you had a local update, but I. I don't understand that. What you said was, was like a global update, because you have to do the measurements and they all have to succeed. So how do you update? So you're measuring the local terms and then you can resample locally and then you move on to the next term. In that sense, is what I mean.
01:06:11.334 - 01:06:42.462, Speaker A: Obviously you have to do something globally because the Gibbs data is a global thing, but each step is just the local. You're only operating on K quits as a simple. It's a very different algorithm than the one you talked about in the. This is the. No, I think, I mean, you're right, you're right. Probably I should rephrase this. You're right.
01:06:42.462 - 01:07:12.364, Speaker A: It's not local updates. I'm local measurements, but then I do a global update. You're right. You replaced with maximum mixed. No thanks. That's true. So the question is, does the depolarizing model give remainder.
01:07:12.364 - 01:07:32.254, Speaker A: It's just sort of the standard noise model when doing theory stuff. It's not. I don't have. There's no particular reason to think that it would be depolarizing. Noise is particularly nice. So this should work reasonably as well. Yeah.
01:07:32.254 - 01:07:53.226, Speaker A: So the proof is for any noise model. I did the numerics with IID depolarizing, because theorist. And that's the first thing you do in some type of noise. The theorem shows that it's resilient. It doesn't. Independent of the noise color. Yeah.
01:07:53.226 - 01:08:19.782, Speaker A: I'm trying to think why QcMA equals QMa. Someone could tell you what lambda two and lambda one are like. Is the issue that you don't necessarily trust them? No, I think that then you need advice. Right. So I guess it's something like the advice could be the energy and the gap. Yes, but then you need. Right, but I guess that says something like QCMA poly is.
01:08:19.782 - 01:08:30.985, Speaker A: Contains. Wait, wait. Really? Really? I don't know. I need to think about this more. I'm not sure I haven't. We should discuss the complexity theory implications. I mean, if you just describe the circuit, right.
01:08:30.985 - 01:09:01.642, Speaker A: You have an algorithm. Someone just says, try running this check. Oh, wait a minute. But it's, it's a fixed point process, so it's not an efficient algorithm to prepare the state. It's just a process that would have that as its fixed point. I need to check the expected runtime of that. If it were probably no real time, then QMA would be contained in QCMA poly, which would be a huge deal.
01:09:01.642 - 01:09:34.470, Speaker A: Is that surprising? It's not quite a touring award, but it's a, you know, check that. Yeah, yeah. But the reason it's advice is because you don't necessarily trust that the spectrograph is indeed that. Right. But I'm trying to think why. So why do you need advice? You need a spectral gap. You need a spectral gap, obviously.
01:09:34.470 - 01:09:43.798, Speaker A: Oh, it's for gapped Hamiltonians. I see, I see. Yeah, yeah. You need, you need, you need the spectral gap. It's on the ground state. You could verify, but the spectral gap, you can't. Right.
01:09:43.798 - 01:10:42.308, Speaker A: That's in QMA to the. I think that just says that you've got a description of an algorithm to prepare with advice to prepare the, you know, a Sat assignment. But that's really trivial. I just tell you the assignment and which bits the flip. Right. I think the classical is kind of trivial. What do you mean by polynomial size? I think so, but I don't want to.
01:10:42.308 - 01:11:03.144, Speaker A: I need to check the complexity theory implications of this. I'm not sure it did. That depends on the poly run. Expected runtime, I should check. Have probably worked it out by now. What the implications are. Sorry, I didn't hear the question.
01:11:03.144 - 01:11:39.314, Speaker A: Just clarifying. What exactly is claim about which I'm not making any claims about because I need to think more about it. Right. Does this mean QCMA contains the thing beneath the terminal? Might be. I don't think so. I mean, this algorithm is very. It's like a nice piece of theory, but in practice, and it's an exponential time, and that really hurts.
01:11:39.314 - 01:12:04.704, Speaker A: Like exponential time algorithms. But the. I don't think it's the most, you know, I don't know how reasonable this algorithm is for near term, at least in the form I presented, the exponential type. Exponential time algorithms are really painful. Right. I mean, and this is kind of, as I said, sometimes it does converge quickly, but also sometimes it just really does take exponential time. And you really see that you would just have to pitch the non uniform investor.
01:12:04.704 - 01:12:50.834, Speaker A: If you've got some non uniform investors that are happy to take advice from you, Scott, let me know. I mean, the naive brute force algorithm, the quantum generalization of naive brute force search is not very naive. It's do phase estimation with an actually mixed input on the right, and then, you know, measure the output to collapse it into an eigenstate and just repeat until you find the graph with respect to, say, max, three sat and beating group words. I don't. That's a good question. I don't know. I think there's some hope in that.
01:12:50.834 - 01:14:11.444, Speaker A: I mean, this algorithm framework that I've put together, if I apply it to sat and I do the local resampling and I choose my stopping condition, I get shown as a special case. So in that case, yes, but you're asking a different question. I don't know, but maybe with the local updates, it's possible you're doing slightly better than. But I think it will be problem dependence, and it probably is dependent on the. Yeah, I mean, in the general framework of this, where you can, a lot of the analysis, I suppose, pretend to kind of simple version, but this, a lot of this analysis works independent of what resampling map you put in and what's in particular, the resampling rule and the stopping rule. So one case of choosing those gives you churning, other cases gives you like Moses algorithm, but you have to then choose a smart resampling strategy and a stopping rule that are appropriate to the problem. So do you suspect this is strictly worse than doing phase estimation on the maximum state like this? No, I think it depends on, I mean, it's strictly worse in my terms, because I don't want to have to run phase estimation but I know that's not what you're asking.
01:14:11.444 - 01:15:05.302, Speaker A: You mean in terms of runtime? Sure, so I think it will be the upper bounds I think are worse but if you do the local resampling I can't prove it but you get an exponential time but with a smaller constant and improvement in the constant and that might do better. But I don't know. I mean that's not a proof and I can't prove that that's even true that you have a smaller exponent. I can just see it numerically so it's possible with a local, local update type algorithms you might do better but there are other algorithms that do better than phase estimation like imaginary time evolution. There's a lot of algorithms to ground state problems out there. The interest that I have in this one is the fault resilience plus the simplicity of it compared to doing a whole phase estimation. Or should we take the rest offline? Maybe.
01:15:05.302 - 01:15:06.794, Speaker A: Thanks. Thanks.

00:00:01.000 - 00:00:45.534, Speaker A: Welcome to my tutorial on sad Solving. So this is part of a bootcamp of Berkeley Institute seminar on the theory and practical aspects of sad solving. And originally this was planned as a kind of life physical event at Berkeley Institute in California. But then through these, due to this corona and COVID thing, we had to move everything online. And therefore I decided to do this a little bit differently than it was originally planned to happen. So there was like a plan for one day tutorials on particularly important subjects, like to get people going, but it's not possible. And so we're doing videos now.
00:00:45.534 - 00:01:26.886, Speaker A: And so I thought, like these videos, you can find them on the Internet. Actually, you find lots of them, even from me on talking about sad solving. Just one recent one at the Saturn SMT indian vintage school. So I recommend that one. And there are slides and so I try to do this a little bit differently. So today we're going to do something which I call a blackboard. Okay, that's what we have here, it's a blackboard, but I'm also doing c.
00:01:26.886 - 00:02:18.374, Speaker A: And c means code. You see that in a minute. So what we're going to do is to actually, while we're talking about the basics and the algorithms, I'm going to show you how this really works in practice. And therefore I recommend that while you try to follow this video or maybe just stop it now, go to the web and download this repository. This is a sad silver. I hacked particularly from scratch for this event here. The reason being I have done something similar for tutorial GIF in 2012.
00:02:18.374 - 00:03:18.650, Speaker A: Back then it was called cleanling and I just wanted to redo this thing properly now with your insights and simplified also in certain ways. Alright, I hope you had a chance to download it then. Let's see, what do we have here? First of all, sag rhymes on scratch. So there's a c and an r missing, but it's actually in c. So if you see these files and maybe I'll explain maybe those things to find your way around, and then we'll talk about algorithms. So first of all, there's a readme which explains things. So it's like sad server written from scratch, and it's meant to be simple code base.
00:03:18.650 - 00:04:39.636, Speaker A: So it's very simpler than my other soviet keysight and Cadicle and which have been really successful in the last two competitions. And you want to use them for production maybe, but this is much more instructive and much smaller. So you see here, for instance, that it really only consists of this code here and like one file in which everything of the solver is that's here, this one. Then there is like a stack, the only container actually needed. Then a configuration very small one for like pass, keeping the build information around. And then at the end here, this line which says, okay, it's an application code, you need a parser actually I think robust parser in the witness printer. Then there's the build system in version, you find the version and maybe we'll look at this for a second.
00:04:39.636 - 00:05:39.040, Speaker A: So the version I'm talking about here in this video is version zero 2.4. And then we have makefiles and yeah, I'll talk about these things maybe later a little bit. And so you can compile the whole thing as we just saw by just issuing configured. So this will generate a makefile, we can say make and the solver is built. Then we can also do run some cnfs solves them. And then at the end also tries a little bit of API testing even though this is not complete for this solver yet. Okay, so you should try this and maybe also try maybe like one of these test cases because this will print some nice output.
00:05:39.040 - 00:06:19.912, Speaker A: So this is the output. So the reading then yeah, it starts solving. So I'm going to explain these things later. And then at the end there's the result, it's unsatisfiable. This s here is from the sub competition output format, in case you haven't seen that. So this is sort of the most important line in this file. If you for instance would here just write q for minus Q, then when you only get this file, this line with unsatisfiable, then some profiling information and then some statistics and the end memory and time usage.
00:06:19.912 - 00:06:58.194, Speaker A: Then the silver exits. And this exit code here is really the exit code. So if we asked Michelle what was the X code, it was 20. That's also like a common format from the SAT competition where we had like ten for satisfaction formula and 24 for unsatisfiable formulas. And of course the same would work for satisfactory which factors these numbers. And therefore it's because it's a square of two prime numbers, it's satisfiable. And if I do that, then you get here exit code one.
00:06:58.194 - 00:07:41.722, Speaker A: But more important you get here these numbers, like first of all, again like a solution line, but now it says satisfiable instead of unsatisfiable. And then the solution here is printed as so called witnesses line or v lines, value lines, where if you write the variable positively or negatively. So you might wonder why do these variables not have name. Well that's the dy mix format. And maybe that's the next thing I show for a second. So if you look at this instance, you see here, this is a typical sat instance with, this is like a prefix and that's called that. It's a cnF.
00:07:41.722 - 00:08:26.344, Speaker A: And then here you have the number of yabls occurring in this file. And this is the number of classes. So if you go down here, you see like it's like this many lines and bytes, right? And furthermore, these are the actual clauses and cnfs are like that. But before I explain more about it, you just need to think of this as well. It would be as if you would have. Maybe I pick this one with mixed. So this would be the same as writing sort of not x 25 or x 24.
00:08:26.344 - 00:09:09.514, Speaker A: Then you have a symbolic representation. And then comes the next clause. And this clause would be x eight or not x 24 or x 25 and so on. And these are all connected with ends and so on. All right, so this is kind, and this is kind of our task. How do you build a tool which, which solves such instances? So let's talk about the input format of a SAT solver. So it's a conjunctive normal form and you must have seen this before.
00:09:09.514 - 00:09:40.920, Speaker A: So let me just like make an example. So we have two variables, m and s. And obviously in this COVID times we'll have a shirt, like my t shirt I'm wearing here. And we also have a mask. And of course we'll just talk about now like conditions on these variables. So let's assume if I have a shirt and I have to wear a mask. If I wear a mask, I should wear a shirt.
00:09:40.920 - 00:10:23.914, Speaker A: That would be really strange, right? And then like one of the two should be true. So this would be like three constraints. And because they're in CNF, we're put an end together. Now these, these implications here, they're a little bit strange. So let's just transform them into a real scene f. And that would be, there was an end. That would be like replacing the, the implication by this junction.
00:10:23.914 - 00:10:52.460, Speaker A: And then we'll get these three clauses. And that's like our CNF now in this form, it's already like less readable than here in the middle. But I argue it's pretty natural to think in terms of such constraints for certain things. But let's not stop here. So let's just now simply say that like the shirt here is. We have a number one. So once again.
00:10:52.460 - 00:11:28.484, Speaker A: Right, so we discussed this before we interpret this as x one, and this here is x two. And then we have the dymax format simply as not shared, which means minus one or two. Right? And zero for terminating the clause. Then the opposite. So two implies one and the. And one of them is true. Okay, you see that? Of course, like, I'm used to reading this dymax format, which is literally very fast, but it's also pretty simple.
00:11:28.484 - 00:12:23.624, Speaker A: So you have two variables and three clauses, and you could give this to a sad solver. Okay, now the question is, is this thing satisfiable? And. Well, it is. Why? Because if you think about it, then one of these clauses here. Sorry. These three clauses are all the clauses which exists with two variables except for one clause. So the clause which is not here is not as or not am, right? And so that would say I should not neither wear ma.
00:12:23.624 - 00:13:11.644, Speaker A: I should not wear a mask and a shirt at the same time. Right? It's indication of not as and am. And these four clauses would be unsatisfiable. Why? Because you have four assignments to these two variables, and each of them would be blocked by one of these clauses. And so blocking all of them would just make the formula unsatisfiable. But because it's satisfiable, we're going to have a satisfying assignment which is exactly the opposite of the clause, which is missing, which is s and m. So you can think of s is true and m is true satisfies these three clauses.
00:13:11.644 - 00:13:55.028, Speaker A: Why? Well, you also see that this is true here, right? And this here is false. You can also think of the other way. So I'm making all variables true, and each clause contains one true variable. So that's why it's satisfiable. Okay, so this concludes my introduction into CNF. All right, now let's see whether we can also do this example with the SAT solver. So for that, we'll just start a new file, which we call as CNF, and then put in this, like our two variables in three clauses.
00:13:55.028 - 00:14:27.870, Speaker A: Remember, the first implication was one implies two, second one. Two implies one. And the third one, one of them is true. Now we can. So when we get like, yeah, it's satisfiable, remember this code here? But we'll also get this satisfying assignment, namely that the shirt here is true and also the mask is true. Okay, so this is how satisfiable instances work. Now, if I would do the same with an unsatisfiable instances.
00:14:27.870 - 00:15:32.164, Speaker A: Remember, the sun once became unsatisfactory. I need to make it four clauses now. And then the whole thing becomes unsatisfiable as expected. All right, what we're now going to do is trying to get a bigger problem into CNF and we're going to do what people call the zeting encoding or transformation. Right? And for this example, I use my favorite sort of like, well, there's some more, but this is one of my favorites. We are going to use a distributivity law from Bolson algebra, which looks like this, right? So you get a or b and then you can replace this by a or c. All right, and so let's keep this example.
00:15:32.164 - 00:16:25.174, Speaker A: Now what we're going to do is to introduce variables for these individual nodes here, like, I mean operators. And this is better seen in circuit format. And it has the additional advantage that the circuit, you can apply a ct in transformation to the circuit as well. So let's look at this left one. We have an a here and then we have a b and a c. And the b and the c go into an and gate which then goes into an or gate which has a as first one. And then this conjunction is second one and this is our output.
00:16:25.174 - 00:16:59.752, Speaker A: Okay? And then we want to know that this is the same. And I'll talk about this in a second as the one on the right. And for that we're going to use an Xor. This is an and or xor. And I'll say more about this in a minute. And the output we're going to denote by o o. Then of course, you see that the top one here is an and gate, right.
00:16:59.752 - 00:18:08.502, Speaker A: And this and gate has two or gates as input and. All right, and they have the common b. The common a here as this is used in both. But then the right one has a c and the left one a b module like commutativity of these gates. And in principle, what you really want to do is kind of get here this b and also here instead of this a, you want to get this b. But I'll just assume that they're really the same inputs here for readability. Now the question is how do we get this into a CNF? And basically what we're going to do is we're going to put new variables and mark them with blue for each of these gates.
00:18:08.502 - 00:18:49.294, Speaker A: So if we have like for instance, have here x variable for this or gate here y variable for this, y gate here z for this and gate, and maybe here u and v for these guys. Okay? And then we simply write down like what these compute. And let's do this here. So let's start from the left. So from the left we have u is equal to a and v. Okay. And then we do it for the other gates.
00:18:49.294 - 00:19:24.186, Speaker A: So we have v is equal to b and c. So this is an input gate and so on. So z is equal to, to x and y, and x is equal to b or a. And finally y is equal to a and. Sorry. Or c. Okay, right.
00:19:24.186 - 00:20:19.214, Speaker A: Now this is obviously a linear algorithm, right? But still not a CNF. So how do we get now from this to the CNF? Well, we need to translate each of these individual clauses here into c and f. And for that, let's maybe look at this clause here. Right? So we're having u is equal to a and v. And you can think of this constraint as u implies a and, um, implies b, and then both of them, a and b imply u or a. Okay, now maybe at the end. So we're going to turn this now into a real c and f.
00:20:19.214 - 00:20:40.474, Speaker A: But I guess you can see this already. So it's new a. And because I'm lacking space, I'm using a strange notation here. Right. But I guess you get the idea. The bars are just disjunctions and. Sorry, I didn't do this.
00:20:40.474 - 00:21:32.440, Speaker A: This is a CNF. So when encoding such circuits, there's one thing to consider, inconsistrancy, sometimes called arc consistency. And I would call it maybe redundancy. And for an example, consider sort of, you have here a gate. It's like an equation, like with the Zetin problem, where we now have a condition. And if the condition is true, then we'll get a true case. So the then part, otherwise we get the else part.
00:21:32.440 - 00:22:23.466, Speaker A: So think of this as this question mark Colin operators in commonly used in programming languages, you can also think of this as if conditioned and then it's else. Or people would also sometimes maybe call this something like for conditional or. Okay, I think I get the point in the point. Now the way how you can encode this into Zetin would be if C is true, then x is equal to t, and if C is false, then x is equal to else, right? And. Well, the equal sign is. Now this is sort of highest priority now. And then you encode this further.
00:22:23.466 - 00:23:19.410, Speaker A: So this is the same as if c implies, then x implies t and t implies x. And here it's the opposite. If C is true, then x implies e and e implies x. And. Yeah, and then we flatten it as we did before. So because this use an or and then this thing here becomes an or, and we're going to erase here the negation and put the negation here. And then we can use our distributivity law and also remove here this implications.
00:23:19.410 - 00:23:57.062, Speaker A: And then at the end get like six clauses, which I'm now dropping the the or again, like I did in this one example, and I get that one and I get c and tr and x. And I get c and X bar and e. And c and e bar and x. Okay. Okay. So this looks pretty good, just to say, like, for sanity. Chicken, look at this one.
00:23:57.062 - 00:25:08.564, Speaker A: So if the condition is true and the then part is true, then the output of this thing here should also be true. This is also sometimes called in circuits, a multiplexer. So where you can have here c is a selector and then t or else is input. And then depending on c, you get one of these two guys, max for multiplexer. So we now need to discuss the following things. So if you think about this last one here, but this operator, then it's clear that if t is equal to e, right? Then of course, x is equal, let's say to t. If you think about it, this is a resundant constraint.
00:25:08.564 - 00:26:36.864, Speaker A: And it, for instance, would give us here the formula if both e and t are true, right? So both true, then also x has to be true. And if both of them are false, right, sorry, false rate, then x test. So we would have these additional redundant clauses. However, as it turns out, they can be resolved by resolving on the, on the condition here. So if we take this first class here, this one here, we'll take it here and move it here. And you take this third class here, also move it here. And then we'll do a resolution between these two on the variable here, not see? Well, then we're getting exactly what we wanted.
00:26:36.864 - 00:27:24.564, Speaker A: So we get not x, t or e, right? This is our. The second one here. Okay. And that's also true for the other one. So, so the message is that if you're these, these pink clauses down here, they would give you sort of more power to the encoding, right? Because if you think about it like the sad silver knows that e and t are true, then it will immediately deduce from these, that axis has to be true. However, they can be resolved from already existing clauses from, from these original clauses, which we. We're having here.
00:27:24.564 - 00:28:33.308, Speaker A: And those would be what we would call irredundant. And therefore, in Sarcasto, would want to only have these irredundant clauses to keep the formula simple. But it might internally actually derive these redundant clauses, and therefore, depending on how powerful the satzel is, you want to explicitly encode this redundancy. But most of the time you do not want to do it. You can also think of it in the following way. So if you think about like, you give all six to the sad solver, and the sad solver has a procedure which determines that, well, tailoring clauses, which are the result of resolving two tailoring clauses, would be redundant, then the SaT solver would remove those and would spend like effort, which you could have avoided anyhow from the very beginning. So what I've shown you so far on the bit level, these are constraints which you would want to use to encode execution of a program.
00:28:33.308 - 00:29:41.702, Speaker A: But often a problem encoding in the SAT also has certain constraints, and these constraints are more of a logical nature, and therefore maybe different methods are needed. I'm giving you two examples here. The first one are cardinality constraints, but of course, like not really the, the ultimate explanation for this. And the other one will be something about fixed points. So what are cardinality constraints? Well, we saw already before in example, so the kind of majority gate is one for over three bits. But like the carry out we had before was actually, you can think of this if you take the input bits and you sum them up. So this plus here, this is really sort of natural numbers, okay? Natural numbers plus, where you kind of interpret really true and false is concentrate.
00:29:41.702 - 00:30:36.194, Speaker A: And then we're asking whether this is larger, equal than two. This was the majority gate thing. Okay? So in principle these are called cardinality constraints. So they're kind of linear programs where the variables are zero, one, and where the coefficient here is always one, of course. And these are actually all exactly the conjunction and or like is exactly the set of Boolean of symmetric functions. But that's not the point. Now, actually, something which goes back to Shannon, I want to show you, like assume you have this constraint here, ABCD, and you want it to be larger than two and smaller than three, three.
00:30:36.194 - 00:31:24.120, Speaker A: And so that means there are at least two of these, four are true and at most three. So how do you encode that? Of course, now you could sort of take an approach and think about like ruling out all impossible ways of assigning this variable, but another one, a circuit like approach. And that's what I'm going to show you here is based on bdds. And so what we do is we have here a BDD node. This, you need to think of a note here, reads this down here with a stroke here. This is the then part, and then we'll have a dashed version to the right. And that's the else part.
00:31:24.120 - 00:32:04.218, Speaker A: And in there it's the variable. Okay, and then if a is true, right, then we're going to, sorry. If a is false and we're going to check b. If b is false, we're going to check c. And then if these is false, well, then we know that all four are false and this is clearly a false rate. Then we'll get to a second row and we do diagonally the same variables. So bdds or obdds have this requirement.
00:32:04.218 - 00:32:39.744, Speaker A: And the variables are always kind of here tested in the same order. And so we're going to do exactly the same again. So we going with an else to the right. And here we know that at this point we have also zero because there's exactly one variable true. Right. You went down sort of like one way here and one of these four ways. And that's like in most one variables, you're not satisfying it.
00:32:39.744 - 00:33:08.588, Speaker A: Okay, now we're done actually with the a's and b's. And now we're doing a c check here. Now, two out rule, okay. And we still need to do here a d check. And now if we now go to the right, we now know that exactly two variable search rows. This is what we wanted. So we can put a one here, right? And.
00:33:08.588 - 00:34:03.940, Speaker A: Yeah, right. You see, like, for instance, if you went this way, you, you had like two variables, or this way you have two variables, right? All right, now the same here is true here for the d down here where, well, if I went down here, then my three variables here, which I had in this vertical line are true. And also, like, if you go this way, and I didn't draw this yet, so this would also be true. However, if you make d also true, then you're false. Right. So it doesn't fit anymore. Okay, now you're doing, we need to introduce like variables as before, right? Rst and so on, right.
00:34:03.940 - 00:34:52.924, Speaker A: And then we're going to encode, like each of them as a constraint. So, for instance, we would here have that y here, this y here, we almost cannot read it. So it's a badly written y. Let me try to draw it again. So this y here is such a mux, which we considered before. If b is true, then we get s downward, right, and otherwise the t, right. And then we'll continue and get our like four classes, right? So that means we're going to have here, like with this four, three, two plus one, like seven plus 310.
00:34:52.924 - 00:36:03.890, Speaker A: Such muxes, and of course some of them simplify. So it's, we don't really need like 40 clauses. But that's the idea. You also see that if you kind of put here an arbitrary constant here to the right, so let's say we're putting here a k and these would be n variables, then this whole thing here is in the order of onk, which could be quadratic. And there are other ways in the, in the literature which make this cheaper. But in many cases, this BDD based version I'm showing you is still pretty useful and at least sort of, it's a very natural way of doing constraints. So the next thing I want to show you is related to other types of constraints, which are really often, and I would call them maybe fixed points constraints.
00:36:03.890 - 00:36:52.936, Speaker A: And a typical example would be temporal logic and the encoding of temporal logic. So for instance, the reachability of the existence of a path, if you aware of that, that's kind of a least fixed point. But there are many other examples like reachability in the graph. So think about having encoding as a toco and you want to know that something is reachable. And you also get to this fixed point. But more abstractly, let's assume you have an equation which looks like that. Again, bad y.
00:36:52.936 - 00:37:42.584, Speaker A: Sorry about that. And then the y is like b or x. Okay, then this set of equations, of course, has a solution. Like for instance, you make a solution for x and y, no matter what a and b are these like, just put x and y to. True. So the largest fixed point, largest solution here is for x and y is x and y equal to one. Okay? But if maybe your semantic of this mutually exclusive equation is that you want to really have the sort of implication of y is the smallest formula, then of course the solution is x of y is the same as a or b.
00:37:42.584 - 00:38:34.534, Speaker A: And that's not that easy to encode. I mean, like you could take this and generate like what would be six clauses, but that's not like what the, that's not the correct way of encoding. This only for the largest fixed point. For the smallest fixed point, you're making a mistake here. And there's a kind of a whole field, if you want, which called Asp or answerset programming, which talks about so called stable models where you kind of need to make sure that you kind of not cyclically assume something. So this solution here would be a cyclic solution. So I got this wrong.
00:38:34.534 - 00:39:17.240, Speaker A: Yeah, sorry. No, I got it right. And if you want to avoid these cyclic solutions, you might either sort of like dynamically or just to build directly into the SAS solver, detect these cycles and avoid them for that. Of course you would need to know that for x and y, you want these solutions. So before we now look at side algorithms, we're going to look at one more kind of encoding part. And then I let it be. The question is how do you get more complex like a C program, the execution C program now into CNF.
00:39:17.240 - 00:40:33.454, Speaker A: And we now know how to get the circuit, the bit level circuit into CNF. Next step is like how can you get something more complicated? And for this, let's assume we want to compute the bit vector addition of two bit vectors of length four. So you can, sorry, I should not have written like four. So it's better to think of this as like bit vectors which have s two s one s zero as bits, like four bits. And we add this kind of the same with bits together, x one x zero plus y three y two, y one y zero. Okay, how do we do that? And the basic idea is that you just need to compile a hardware circuit for it and then take the Satan encoding of this hardware circuit. And then for those of you who went through digital design courses, that's pretty simple.
00:40:33.454 - 00:41:15.934, Speaker A: But let me just like briefly explain how this done. So what we're actually doing is we're using full adders. And full adders here are like boxes. It looks like that they have three inputs, x and y, and usually carry in and they produce some outfit and like s. And also like you can think of this as a carry out. So I call it o. And then we take these full adders and put them together in the following way.
00:41:15.934 - 00:42:11.316, Speaker A: So we're having, now first of all, I should write down the semantics. So s is then the same as the xor between the three input bits, okay? And Xor between the parity in all three, s is odd. If all three even, then s is true. If all three are even, then s is false. And then we also have this carry out here, which is majority gate people call it, because it takes sort of the value of the majority of its inputs, but it's also symmetric. But you can also think of it as a cardinality constraint, which simply checks whether two of them are true. And that's by big disjunction like that.
00:42:11.316 - 00:43:03.036, Speaker A: Now you take, what we're now going to do is just taking these full adders and plugging in here the bits. So here we're putting actually a constant zero, and then we get s is zero, then we get the next full adder and we're getting s one. So maybe I'll just not maybe draw these arrows, but the others are kind of clear. So we could x one, y one. And yeah, this is kind of the input of that one. So it should go here to the left. Maybe I should have written here this differently and put here the I here as an arrow here from the left.
00:43:03.036 - 00:43:31.484, Speaker A: Okay. And then we'll put here a zero in. And this here is of course just y zero. Okay. And then we continue doing like this two more times. And then get all the desired output bit. And that carry here can be ignored.
00:43:31.484 - 00:44:24.244, Speaker A: Okay. And since all these guys are now just circuits, you just have to like use now the zetein encoding. In this way you can get like a four bit additional. And yeah, you can do the same. Then of course with other operators, like we would call these guys kind of world level operators or if you want, if you're an SMT person you would call it bitweighters. So what I've shown you here is kind of how do you get the bit vectors of world level expressions into gate levels, which is a classical heart rate design problem. And then when we have this gate level like this circuits, then we can go to formulas.
00:44:24.244 - 00:45:11.854, Speaker A: The beauty about this is that you can really do this kind of for all kinds of real executions of machines where you don't really abstract something to something continuous. And that's why this is a very useful technique. Alright, so next we are going to talk about actual algorithms. So I will call this DP versus DPl. I won't talk much about this first thing here. So this is for Davis Putnam because this would be pre processing and I don't have time in this video to talk about pre processing. So what we're going to look at is this DPLl.
00:45:11.854 - 00:45:40.544, Speaker A: And I assume that most of you have seen this. So I try to be pretty fast here. So again, like in the dymax notation I'm going to use now like one two three for x two, x three, right. I guess you get the point, right. So this is kind of x or x three, right. And then we put here lots of ends around it. But let me just forget about this and keep the, just one, two, three.
00:45:40.544 - 00:46:38.186, Speaker A: Then we're going to have the negation of this second one and then start over again with the same, I think you know what this is heading. So we're going to really have here all the possible clauses with three variables. So this should be 16. And now we're going to play, I'll try to solve these formula. First of all, is this formula unsatisfiable? Yes, of course it is unsatisfiable for the same reason we discussed before. For the simple example with a mask and the shirt, these clauses here rule, each clause rules out exactly one assignment of three variables. Since there are like eight, like eight such assignments and each class rules out exactly one.
00:46:38.186 - 00:47:08.104, Speaker A: For instance, this last one rules out the assignment where all are true. This first one here rules out the assignment where all are false. This rules are all possible studies. Now let's do this with a SAS over. The classical way of doing this is a DPL search tree. So you kind of, look, it's like a BDD, right? So you would for instance, pick here a variable. Let's say we're picking one as variable, right? And then we make it true.
00:47:08.104 - 00:48:42.188, Speaker A: For instance, so we use the same symbols as in, in the, in the, in the, sorry. As for the bds, in the concluding, for the canal constraints, then you see that these first clauses here are all true, right? But here these four are false, but nothing happens because they're still like in all clauses, like two literals left. So it's possible, so it would in principle be possible to satisfy them. Okay, nothing happens here. But the next step would be we're going to assign here variable two to true, okay? And now we're getting the situation that these clauses are gone, but it's really kind of strange to actually even consider them. But we're going to have now this clause and this clause where two literals are false. Okay? So if for some reason, right? So our sarcasm works by walking downwards this list to find such a case, it would find this clause here first and then call this a unit clause and will force this guy here to true.
00:48:42.188 - 00:49:32.576, Speaker A: So, so we're actually kind of taking this clause here and use it here to assign three to true. And these guys were decision, but this guy not. So this guy has only one outgoing edge as we'll see. So this is not a decision. But now we figure out that this clause down here is conflict ting. So we often say conflicting. So this literature is not clear about that, but it's called a conflicting or conflict clause.
00:49:32.576 - 00:50:06.864, Speaker A: I like the term conflicting more, but let's not go into that. So why? Well, because now this not three here is also false, right? And while, yeah, this clause is, and the red ones here would be also the twos here. Okay, I think you get the point. Okay. Okay. Now the solver backtracks. So I'll backtrack here by just pressing Ctrl Z.
00:50:06.864 - 00:50:53.840, Speaker A: And now again, in this situation where two is true, then we said we going to imply three, but this is ok, so now we're getting the first time to two equal to false rate. So now these guys here are false and the other clauses are true. And then you would see again maybe with this argument that we get here downward. And then let's see this clause here. First we force this to a unit. Okay, so we have the same situation as before. So we setting three to true, but not with the second branch.
00:50:53.840 - 00:51:33.040, Speaker A: And then get of course in exactly the same conflict as we had before. Conflict, okay, and of course this would continue. Then we're backtracking. Then we maybe do two again. We could also do three, by the way, but doesn't matter, right, and we'll get also by unit propagation. Again two conflicts. And that would then show that the formula is unsatisfiable.
00:51:33.040 - 00:52:29.902, Speaker A: Okay, now let's move on to the core algorithm of satsalming, which is CDCL. So let's go back to the start of the tree, so it looks almost the same. Also the example here. So if we're signing two to true, right, then we're getting again our conflict down here, right? Okay, so maybe again signing three first. Too true. Okay, and then get the conflict by our clause down here. But now we would say, okay, let's see what was the reason for, for this conflict.
00:52:29.902 - 00:53:35.004, Speaker A: We made some assumptions and the assumptions are these two guys. Okay, so what we really said was if, if one is true and two is true, okay, then false. So I now need to use bottom because otherwise it's conflicting with the zero or something. Alright, so I guess you get the point. All right, so that means what I really know is that one and two as a clause cannot be true. Or further, this is the same as saying the loss minus two is not possible with this formula. So once again, if this is our formula and this is our new clause, what we kind of showed by f and c, and we nowadays do call this unit propagation.
00:53:35.004 - 00:54:02.714, Speaker A: If this gives butter, then we know that, sorry, not c. I got the wrong thing. We call it alpha, which is the negation of c. Okay, I'll come back to this in a second. To bottom. Then we're getting f implies c. Alpha is supposed to be not c.
00:54:02.714 - 00:55:24.998, Speaker A: And therefore f is actually the same as f and c. And that's what I kind of did here. So I added here my c. Okay, so revert this until the point where we derived the c. So we now know that the c can be added to the formula, okay? And if you look carefully at this c, then you will see that it's a little bit strange because, well, if you look at this graph here, then at this position here, we made the decision three, okay? But that's not good because. Sorry, decision three, we made a decision two, two to be true. But that's not good because if you look at this clause, if you would have this clause here, then this is false, right? And therefore this has to be a unique clause, right? Henceforth, not two.
00:55:24.998 - 00:57:07.896, Speaker A: So that means I should not have done this. I should have immediately, just after one, take the unit implication here, this two as a unit, as we did it before with the three, okay? But like now with only one outgoing edge, because it's false, okay? So this here is not a decision, right? So this is an implied unit. And furthermore, one thing which might be important here is this clause here. This clause here is a learned clause, we call it, and it's responsible here for, for implication of the two. So what's this cdcl doing here, this conflict driven clause clause clause learning here? Well, it works like DPL, but then in a situation like this one, it tries to figure out what are the reasons for, for my failure getting into this dead end, like my conflict down here. And then I learn the reasons, which is something I can add to the formula. And then I figure out, okay, so if I have this in the formula and I kind of backtrack and reconsider the way how I get here, then I will figure out, okay, and that's guaranteed.
00:57:07.896 - 00:58:06.572, Speaker A: Well, I would not have taken one of the decisions I've done before, right? So you collect all the decisions which led to this bad situation and then you have to undo one of them. And therefore this situation, this decision here, becomes a propagation of the negation of it, right? So you can see that here it's a one and here it's a false two to true, and the right one is two to one. 20. And this is in principle the idea between conflict driven cos learning. I mean, we could continue now. So if you do here, if we continue, and you will see that, as before, that's now of course, like these colors don't match anymore. So I'm not going to do this any further.
00:58:06.572 - 00:58:41.860, Speaker A: But you will see that then after one more decision, then you will get a conflict. And, sorry, not even after one decision. What's going to happen here is this two to falls rate, which I just erased here, will lead to another conflict. Actually it will be here, a conflict with this here in this particular two clauses. So this one is now false. This is the first one. And then three and not three are in conflict.
00:58:41.860 - 00:59:43.032, Speaker A: And then I will again try to collect the reasons for that. And the only reason we have in here is this one. So what we're going to do actually next is to learn here the negation of the single decision, which is then the clause not one, the single clause not one. So once again we have that f and one per unit propagation. Like looking at these units will get into bottom and therefore we know that f is the same. So actually the f prime after adding this binary clause is the same as f prime and adding the binary clause not one. Alright? So, and actually this happens quite frequently learning these units.
00:59:43.032 - 01:00:19.024, Speaker A: And we're going to look at this in the code or in the output of the set. Silver. Next. Alright, now let's see about how this works in practice. So I have here in the such direct regression suite which uses these formulas. So this regression suite here is called by this guy like a shell script. And yeah, we're going to look now at this file here, which is a larger one.
01:00:19.024 - 01:00:51.250, Speaker A: And it has produced, this is expected to produce 20 output as unsatisfiable. So let's have a look at this formula. So if I run it, then we get ansat of course, as expected and pretty fast. So in 4000 conflicts. Maybe I should also explain some more statistics here. So this is the number of decisions taken. So you see that there's like way more decisions than conflicts like that.
01:00:51.250 - 01:01:26.838, Speaker A: Well, because first of all the solver needs to, is restarting what we're going to discuss at 1.2. And then, well, you're going to sort of go down and you're making wrong decisions. Then the CDCL has a way of covering up for these bad decisions. And then it jumps over decisions which, which were redundant. And that also means that you have usually more decisions than conflicts. The next statistic you want to look at here is propagations. This is the number of assignments in essence.
01:01:26.838 - 01:01:55.374, Speaker A: And also the number of times you walk this list of clauses to figure out whether there's a unit or a conflict. And that's again another order of magnitude larger. And this is very typical. Usually it's actually even more so like two orders of magnitude. And so maybe this already gives you a flavor how this is done. So you're going really deep. You propagate a lot.
01:01:55.374 - 01:02:23.654, Speaker A: Like for every decision you propagate, maybe you assign ten more units. Right. Remember we had these nodes in the, in the tree in CDCL, which have only one successor. These are all propagations. And usually for r1 decisions you have ten of these implied propagations. And also like this is really the hotspot of the solver. We'll talk about this later a little bit more.
01:02:23.654 - 01:02:55.962, Speaker A: What I want to show you also here is this output here. So first, maybe I need to explain how you read that. So there's like here kind of a header, which is like for this small example, barely readable. But I tried to explain it, of course. Like we had like 22, 80 variables and then this many original clauses, and then initially 100% of the variables are still there. And then this sort of does something and then it hits the first conflict. So this is, you barely see it.
01:02:55.962 - 01:03:22.534, Speaker A: It's really sort of below this conflict header there. And that's the point I wanted to make. This conflict actually leads to learning a unit clause. So that's when this I is printed. So this I means iteration. I don't know why I called it like that, but in my solvers it means you learn the unit clause and it happens quite frequently, right. You see like 123-4567 unit clauses.
01:03:22.534 - 01:04:00.548, Speaker A: Eight, nine. And then you're getting close to, you find the empty clause, and this is the code that the formula is unsatisfying. And this already happens for the first conflict. So this all really went down the branch. And the very first conflict detected was one where after analyzing the reasons why this conflict happens, you realize there's only one decision necessary to get that. And that's then the conflicting, the Lernt clause. It's negation, actually.
01:04:00.548 - 01:04:30.074, Speaker A: Alright, now next happens here after six conflicts, after five more. Right. We again learn a unit. Right, so, and also the number of variables is now going down. So for this first unit we only were able to sort of like remove, make one variable inactive, which is this unit, learn. But here we are actually jumping from, you see, 20, 217, nine to 77. So we're going down by seven.
01:04:30.074 - 01:05:05.828, Speaker A: And the reason for that is, well, because we learned this unit and then we propagated. And only after propagating we actually print this line. And then this learned unit implied another unit, like on the top level, another variable. And that's why even though we just learned two unions here, we removed kind of three variables which become a side. Okay, then next thing I want to show you here is this line here. This is the reduction. So this number here also goes up.
01:05:05.828 - 01:05:39.458, Speaker A: You can see it also barely here. And this minus, minus for removing clauses that needs to be done quite often actually in a silver. So here we do it after 300 clauses. And. And what's the purpose of this? Well, it removes clauses which are redundant. So not all conflicts lead to clauses you learn. So here you see, we have 300 conflicts, but we have only 272 clauses here.
01:05:39.458 - 01:06:18.194, Speaker A: Some of them are actually not necessary and learned. So that means, like from this, 298, because the two unit clauses are, of course, not, not added. Some of them were removed, and that continues here. So now, from this 588 conflicts, only 469 redundant clauses remain. And you see this? This is going on. So this is number of conflicts, and this is the number of redundant clauses. Okay.
01:06:18.194 - 01:07:03.528, Speaker A: Right. And of course, maybe another way to think about this is that sort of, you're trying to sort of like, learn short and shorter clauses, because this kind of removes some part of the search. And then at one point, of course, like when you continue learning shorter and shorter clauses, you will learn a unit. And these are these eyes. And it really happens quite frequently. Now back to the blackboard. So, one important data structure, if you want, and it's also an algorithmic aspect of the CD cell, is what I would call the implication graph.
01:07:03.528 - 01:07:53.902, Speaker A: And this goes back to show Marcus Silva and Karem Sakala. And I'm going to. This is really sort of at the core of CDCL and extremely useful to get like a faster set solver. So how does it work? Okay, so first of all, we need to kind of maintain the assignment of the sad solver. And that's usually done with some global variable stack, and it's called actually trail. So, like this captures the assignment and it grows like upwards. So it's like a stack.
01:07:53.902 - 01:08:44.648, Speaker A: And if you assign, let's say a variable one to true variable, two to folds and so on, then you crawl here upward. That's the trail. Okay. And then when you make a decision, you might push here, four on top of it, you can backtrack, and then at minus four because it was flipped and so on. And then there's like, usually in my slower called values, another global table. And this goes really sort of like from smallest variable to largest one. And it actually is a ternary variable, ternary contents rate.
01:08:44.648 - 01:09:24.644, Speaker A: So, like, these are all variables. For all variables, you have this. And this just gives you which are assigned. So this is the two key data structures you have. And with that, you're already doing pretty well. Then, of course, we still need to have the clauses, like this clause here, for instance, and another clause, four minus six one or so, and work with these. And these are usually also kept somehow in something, which is all, again indexed by the whole variables.
01:09:24.644 - 01:10:14.010, Speaker A: And then for each variable, it would have two entries, like one for the false occurrence and the other one for the true occurrences, like the positive and the negative occurrence. You can think of this as sort of actually here it's like maybe variable one minus one, two literal, of course, minus two, three minus three, and so on. Right. And then here one, right. Would need to have a connection here. And maybe it continues here. Two would be only here in this example, this three would go here and so on.
01:10:14.010 - 01:11:07.884, Speaker A: Right. And of course, like what one really does in practice is to have here actually a stack, which is usually a power of two. So it could be like four, for instance, here. And this would then, for instance, this one here would keep a pointer here to these two cases. So I think this is maybe something one could figure out already by yourself. So usually I would call this case for reasons which we're going to discuss later watches. But of course, you can also think of this as occurrence lists, like lists of occurrences of avaiahu.
01:11:07.884 - 01:12:01.262, Speaker A: All right? But now we also need to kind of remember how to organize this learning. And the way, as I said, is the implication graph, right? And this is now on top of what I just showed, right. My way of describing is maybe slightly different than in the literature, but I try to make it fit also like what other people do. So here's like the decision level. Some people use here like an sign. And the decision level really starts at zero. So here on at zero, there are all the units, right? We discussed before, when you learn a new unit, you will go to the top.
01:12:01.262 - 01:12:47.992, Speaker A: It doesn't have any decision before it just like it's something which you need to do because it's forced. So let's assume we're having here like, as in the example we have here, minus two is a unit, okay. And also like what's in the literature would be you write here the decision level at zero and then the assignment. So instead of having here the minus one to denote the literal, which is true, in the literature, you often see such a notation. Sorry, not true. Yeah, because I said, like, the variable one is false. So minus one would be literal.
01:12:47.992 - 01:13:35.200, Speaker A: We would see this notation. I prefer now this one because here, well, the level you see from sort of the separation here. So there's going to be another level here, which is one, and another decision level two and another decision level three. Okay. Okay. There might be multiple, it could be even that sort of like this unit, because there's a clause which has the shape one or two, that there's another literal implied on this level. So this is not from the example.
01:13:35.200 - 01:14:52.442, Speaker A: Let's just make this up. Okay? Now here at this decision level we need to make decisions. Let's assume we're making here a decision with variable five, okay? Now it could be that we're going to imply a literal seven directly. And this is then because of the clause not five, seven, right? But we could also maybe do nine, but we need here this unit from the top. And then you see this nine here actually has as reason the negation of these two guys, which is not five and one is clause, right? So this is the convention of this implication graph. You have the nodes which are literals. So sine variables and their predecessors, like in this case, the predecessor here is five and one, right? They are the reasons, the antecedents for this guy.
01:14:52.442 - 01:16:11.194, Speaker A: So maybe I draw this in a different color. So what I mean here is, this is kind of the reason clause, right, for this thing here. And this was the reason clause for, for this thing here. Okay, this is how you read the, but now let's continue building that. So maybe nothing happens here, but we're making for some reason like a decision minus six. Then, then minus six could in principle here, let's say with this seven here, okay, and also with the nine get to, let's say what don't we have four, okay, but that is in conflict. And this is drawn like, like that with the copper.
01:16:11.194 - 01:17:08.234, Speaker A: And actually maybe we can do this red because it's copper for conflict. And we also plug in here now this guy. So if you now read off here the conflict, then we'll get again the negation of this guy, which would be not two, not seven, not nine and not four. Okay, so there's like a clause of length four which is now falsified. Okay, so we're building this tree like we do here. But what would be the next step? Well, we're going to to do a conflict analysis. And the conflict analysis here would be as follows.
01:17:08.234 - 01:18:00.206, Speaker A: So we're going to consider here, this here as a first cut, this cut here through this graph separates the decisions on this side from the kappa and it corresponds to clause. And now in this case the clause already exists actually in this bedroom, by the way. So I just forgot this is not possible. So I need to have another line. Let's pick this line here. Okay. So we need to have here in addition six.
01:18:00.206 - 01:19:03.934, Speaker A: I can't see this six is here. Okay, well why is that? Because actually what's an invariant here? And that's why I figured it out is this, these two edges are here, these guys here, they're really necessary because there's an invariant in CDCL that like when you get a conflict, then there will always be sort of like two literals contributing to this conflict from the same decision level. From this decision level too. And that's why I figured there's a mistake. And anyhow, so like down, we need to, of course, like have this cut also go over this line. Now the first step, what one would do is one would try to find whether there's like another cut rate, which, which would do, which would actually do the same thing. And.
01:19:03.934 - 01:19:54.892, Speaker A: Right. So we're cutting here now, maybe, maybe here. And, and that's because we're kind of resolving here the clause of this assignment. So this guy has as reason not nine and not seven, both from decision level one and six. Okay. Okay. And if you resolve this clause, it's really literally a resolution.
01:19:54.892 - 01:20:20.540, Speaker A: So we take this guy here and this guy here, then we'll get from this the, the resolvent, which takes out here the six. Right. And. Sorry, not the six, the four. This was a six. This doesn't look good here. So just the second.
01:20:20.540 - 01:20:50.794, Speaker A: And this doesn't look good. So it's a six. And so the six remains, of course. And the result would be the six. Then the not two, the nine is shared. Then the not seven is also shared. And the four goes away because that's what, sorry, the four goes away and of course, because of the four had to be in here because it's the reason of that.
01:20:50.794 - 01:21:58.832, Speaker A: Okay, so if you resolve these two clauses like the green one and the red one, you get this pink one, this one. And that would be then our learned clause, this implication. Graphs also have another way, which I'm going to explain now with a different setup, so less complicated. So we're going to have, now let's say we're not having any, any unit that's like just irrelevant for our example. But we're going to have here a decision one here decision two and this decision three, let's say like one implies two and maybe not to four and minus five. What about that? And then two does something else like maybe minus six, maybe actually together here with this four. And.
01:21:58.832 - 01:23:11.602, Speaker A: Yeah, just like for you, maybe start checking that you have the right answer. Now let's assume we're going to get here to the clause five and then we'll have the conflict, not five, seven and we have the conflict with these two guys. And maybe here these two guys, so let me write down the conflicting clause. So the conflicting clause has four literals. And let's start like on the top here with minus five. So it would be five, four and then three negated and seven negated. Okay.
01:23:11.602 - 01:23:50.534, Speaker A: And now what you can also see here is that there's another cut, which I now need to draw differently, actually, which looks like this. This will be the learned clause we need to resolve here. Away our. I think I did this green before. Like, we need to solve away the, the clause here for the seven here, which is just three or eight. Like the clause here would be not three, seven with this clause. And then we'll get the pink one.
01:23:50.534 - 01:24:18.474, Speaker A: If you resolve these two guys, then you get seven goes away. And we'll get five. Not four, not three, seven goes away. Five. Yep. Four, five and three and four. Five, three.
01:24:18.474 - 01:25:08.484, Speaker A: Okay. And that's a nice learn clause. And now what's going to happen is the following. That's the interesting part. None of these clauses here in this decision level here, these are different color. So none of these clauses here in this decision level, literacy decision level was actually needed, right? So you really see that these two graphs, latest to implant, are separated. And also, if you look at this clause here, if you think about the decision levels here.
01:25:08.484 - 01:25:35.452, Speaker A: So let me try if I can do this. So if you do this, blue, if you put the decision levels here, you would see that three was in decision level three, right. This is three. Four was at one and this was at one. So this is the clause we're going to learn. But that clause now has a strange flavor. So actually we'll call.
01:25:35.452 - 01:26:19.476, Speaker A: These are called blocks. And you can think of this as a. As a decision level blocks. And the number of this, like the number of these would be two. And that's called, actually the LBD glucose level. Like the number of level, or the certain term for it is glue. So this is the number of levels, right? The number of numbers here.
01:26:19.476 - 01:27:06.992, Speaker A: Unique numbers. It's one and three here. These blue numbers of levels from the left here, projected on the claws. And this thing has only two levels, but it has size three. So this already looks like interesting, but more. And this is sort of the really cool part here. There is no two, right? So in that means if you think about, like when I explained CDCL, what you should do, right? Like CDl learns a clause and then tries to figure out when did I make a mistake? If I would have known this clause already before now, this situation is clear, right? Because the decision two, you would not even have attempted because nor the decision like three.
01:27:06.992 - 01:27:59.744, Speaker A: Right. Both decisions at decision level two and decision three are, would not have been taken because that clause actually already at decision level one here forces three to be true. Right. So what would happen here is into this. Now in orange is that actually we'll learn here this clause and immediately now in orange derive here three, right. We can do this on decision level one, not decision level two. So that means we're completely jumping over these levels down here.
01:27:59.744 - 01:29:03.044, Speaker A: And that's what we call back, jumping to level one. Well, backtracking would of course be this level. But like the implication graph allows you to figure that out easily. That like you just take sort of the second highest block here, the second highest decision level, which is like this one one, and then you jump to that one and then you force literal. Okay, there's a third part to that which I also want to explain. And that's called a unique implication point. Right? So now I'm specializing this topic to unique point.
01:29:03.044 - 01:29:44.134, Speaker A: So what's that? Well, you, for those of you who have some background algorithms, this is sometimes called articulation point, which decomposes a graph into disconnected components. But we're having here directed graph and so we'll see how this goes. Anyhow, so now I start earlier. So I'll put here decision level later. I mean decision level one because we don't have any units. Okay? And then we're doing here an implication two, three and maybe four. And then we have another decision level which is at two.
01:29:44.134 - 01:30:28.544, Speaker A: And here we have a decision running out of numbers four. Five implies nine. And then we have down here at decision level three we have our eleven and this together with a nine here. And I'm going to, because it's important to see that. I'm going to write down here the clause. It's like we're going to say not eleven, not nine and seven. So I'm going to forgot to put the seven here.
01:30:28.544 - 01:31:08.736, Speaker A: And then the seven has also a shape like this one. So we don't have a, let's say minus eight. And this gets us in minus eight together with this guy here. And this gets us into a conflict with decision with this guy. So this is our kappa then, which is false. Note again. So I didn't make a mistake.
01:31:08.736 - 01:32:00.444, Speaker A: We have this nice property that like the kappa has two incoming edges from literals on the highest decision level. And the clause would be not for eight because here we have minus and not seven. Okay, now what kind of card do we get? Well, we could have gotten this cut here. Okay, this is what we're going to call later, the decision or last EIP clause. And it's the one where the decision is in there. Right. This one, this was, oops, sorry, this was eleven.
01:32:00.444 - 01:32:40.352, Speaker A: This class here has the property that it has not eleven and then not nine, not three and not four. And if I'm going to draw again the levels on top of it for the blocks, you see, this is like the first block is in level three and nine is at level two and three or four are at level one. Right. Like three blocks. Glucose level three. Right. And, and whether you backtrack, well with this one you would just backtrack to decision level two.
01:32:40.352 - 01:33:04.316, Speaker A: Right. So the backtrack level is of course, this is the backtrack at back jump level. This one. Yep. And we would kind of continue here. Alright. Now if I do a slightly different cut.
01:33:04.316 - 01:33:34.426, Speaker A: So the cut goes here, stops here at seven. So you don't resolve here further. I probably should take a different color. Let's maybe use orange again. So I start here, then I still have to include the three and also the four. So the eight is resolved away. And then I'll get this, but then my clause here.
01:33:34.426 - 01:34:33.108, Speaker A: So this clause would be not seven, not three and not four. And if I again draw the decision levels, you will see we have the same situation as before. We only have two blocks and in particular two is missing. Right. So that's why our back jump level would be now one. So that means we can actually back jump here. So once again, so this first clause, the last UIP clause, this one was jumping back to decision level two, while this first UAP clause here, first UAP clause, allows us to backtrack to level one, which is of course better.
01:34:33.108 - 01:35:38.876, Speaker A: Right. And also, so, I mean, there are multiple arguments in this, but the intuition is of course you're pruning more search, you're jumping over things which are redundant. A rule of thumb here is that you shouldn't do, or you should restrict the number of resolutions you should do. So only going back as few solutions as possible. But here's like one thing which is important. This cut here has the same property as this is the first UIP, while this one is the last UIP as this first cut. So that means if you really look closer here at this picture, is that it corresponds to a clause, to a little clause which only has exactly one literal on the last decision level, like seven for the first UAP and eleven for the last UAP.
01:35:38.876 - 01:36:41.864, Speaker A: And that's exactly what kind of is important feature of these clauses. So once again here, this level three thing is only happening once. And this is then the kind of property of these learn clauses. And you stop immediately after resolving when you find the clause which has exactly this property. There is one more thing I want to mention here. You need to find those ulps and how do you do that? And the way to do this is actually you take the trail which we discussed before, which keeps the partial assignments of the stack as a topological order. And then you walk back this order, and this way you can always find this, this kind of articulation point without much overhead, easily by counting how many sort of variables are still here down on this last decision level.
01:36:41.864 - 01:37:41.218, Speaker A: And as soon as this number drops to one, you found your clause and we're going to look at that in the code next. Alright, so now we're going to look at some details of the code. So my plan now is following. So I'm going to kind of dive down into this function which does the analysis like, which just does the same thing what I just did on the blackboard, but in real code. But of course, like there are like a couple of things which you need to understand first, and these are two things, like how clauses are represented and then how variables are represented. And alternative would have been I just go through the like maybe literally bottom up or, but that I thought like it's more useful if you just sort of like take everything which is needed to be able to understand this part of the code. And then we'll later like reiterate.
01:37:41.218 - 01:38:35.864, Speaker A: So it's kind of a cyclic way of going through the code. Okay, so let's have a look at this code file. So this is the main library. So as I said, it's written in c and it's like one single file with some comments. So I tried to put only comments which try to explain things. I did not put links to references like in cadicle. But the thing I wanted to show you here is first the representation of Valos, which is explained here, you saw the dymx format like where we would have numbers one and two, which are in the range one.
01:38:35.864 - 01:39:32.380, Speaker A: And then of course here the maximum number which can be sort of represented in two complements. So exactly two billions. And you can't imagine, it's really like people are sending me really big benchmarks and yeah, so keysight, my other solver, has like 256,000,000 variable that's barely enough. But like lingerling which has half under 28 million, like this has been broken or this limit has been hit a couple of times. So anyhow, so I think like being on the safe side with 32 bit, maybe in ten years we will go into to have HT 64 bit indices for these variables. So what you see here on the left is of course the Dymax format, right? So like variable one, it's negation two. And this would go here until int marks.
01:39:32.380 - 01:40:00.848, Speaker A: The convenient thing about this dynamics format is that you have also this sort of sentinel which is not used like zero is a non valid index. You can also not negate it. Right. By the way, this is the same for the only number missing here for two complements, which is int min. But this is completely illegal here. So we just sort of are one number short here actually in the dymx format of what we could use. Or you can think of it also this way.
01:40:00.848 - 01:40:38.324, Speaker A: Yeah, well there's another variable or value which I can sort of misuse for strange things. This is pretty convenient for kind of sort of negation. And thinking about this and also the examples, however, it turns out in sat solvers it's much more convenient to take another encoding. And that you see here on the right. So once again, this is the how these variable indices are encoded, while in dymax on the left, they're just like these numbers. And negation means not. Now the right hand side, you see like this is kind of shift it by one.
01:40:38.324 - 01:41:36.410, Speaker A: And in addition you're kind of multiplying the actual variable index times two. It's an unsigned integer, so this goes up to slightly more than 2 billion. And the sign is encoding the least significant bit. And for that maybe I'll show you again how this is done, maybe in a black part. So you think of if this is a variable index, right? Then these are kind of our 32 one index bits. And the least significant bit here, this is the sign, I think you get the point. And this of course then gives us actually even maybe slightly one more variable.
01:41:36.410 - 01:42:40.020, Speaker A: But okay, one issue though here is that we need to change the kind of invalid value here to something else. And in the code it's just like invalid, it's called as a macro, which is this number here and actually should be five here, this is a typo here, this is a typo, and it's unsigned int max. Okay, so the reason why I'm showing you this is because now if you go through the code, you need to think of terms like these variable indices. They're not like in Dymx, like here on the left, but they're kind of re encoded here in the 0123 where three is negation of two and so on. Okay, the next thing I need to show you is how. Yeah, here's, by the way, this invalid definition is here, the clause data. And that's a little bit tricky.
01:42:40.020 - 01:43:08.830, Speaker A: So forget this link down at the bottom. This is not interesting at the moment. So here's this id. We're currently using it for two purposes. First of all, it's very useful for debugging because then you have an id. And then second, it can be used as a tie breaker for sorting if you want. We need to sort clauses during clause reduction, but it's sort of more a minor, minor thing.
01:43:08.830 - 01:43:35.730, Speaker A: If you really want. It's probably possible to get rid of this eight bytes actually, because, well, you just need to use a stable sorting function and other things. But for now we keep it to keep things simple. Also easy to debug. So next thing are like flags. I think the only one for now interesting is this one. We're separating the clauses into redundant and irredundant clauses.
01:43:35.730 - 01:44:11.114, Speaker A: There's actually a stack in the server. I can show you this later where you put the redundant and the irredundant clauses. So maybe you're a little bit confused. There are like three words and actually the fourth word would be original. So what we really say is they're like redundant and irredundant no matter whether they sort of like how you derive them. So learn has this connotation that you learn them through CDCL. And that's of course not really necessary to know what a clause is, has been learned or it has been resolved, or some other matter is shrunken or whatever.
01:44:11.114 - 01:44:42.656, Speaker A: It's important to understand that there are clauses which are redundant, which you can always throw away because the rest of the formula is satisfiability equivalent. Or whether these. You have to keep it in order not to sort of make a formula which is unsatisfiable, satisfiable. And that's what this bit is for. Of course, like the learn classes built by default, first become redundant. Then the next line here, this glucose level here, this is already saw. This is the number of these blocks.
01:44:42.656 - 01:45:27.858, Speaker A: So these were blue blocks in this for the implication graph, like the LBD or glucose level. I again use all three words. Don Knuth came up with this glucose level. The original authors called it LBD. I like clue because it's the shortest thing and you can pronounce it. Then next comes the size of the clause, the length, the number of literals, and now comes something tricky, which for those of you who have not seen c, might not have seen before. So this is a trick which really, I would say gives you in the order of almost factor two.
01:45:27.858 - 01:46:01.804, Speaker A: Speed. And I'll explain this in a second, what this is. So let's go back to the blackboard. So we're having a clause, right? And the clause has a size. So we have the id and then some flags, the clue and then the size. Okay? Now in a classical kind of object, let's say maybe object oriented way. So this is our clause.
01:46:01.804 - 01:46:12.288, Speaker A: You would now have here a reference to the literals. Okay. And they would be. Yeah, literals. Right. So they are now unsigned. Right.
01:46:12.288 - 01:46:23.494, Speaker A: Three. So this is three. Well, that doesn't make sense. But. But four would make sense. And then seven, that doesn't have to be sorted rate. So this could be nine and so on.
01:46:23.494 - 01:47:03.304, Speaker A: And this is the size of the clause. And however, the problem is these clauses will then be sort of, sort of watched. Right. And if you now see these pictures, you see these three two big dots. As I already said before, the main work done in a satso is actually propagation, which means walking here. These clauses, they usually actually sit, as I explained before themselves, in array. So you also have a point of the reference here.
01:47:03.304 - 01:47:26.772, Speaker A: But this is cheap. This doesn't happen that often. But this is really costly. So this is costly. This is dollar, dollar, dollar. This is probably dollar. And this is also expensive because you kind of now have three pointer dereferences.
01:47:26.772 - 01:48:03.924, Speaker A: One, two, three, while this is still the most expensive one. But this is also expensive and you can completely get rid of it if you're able to make the array actually variadic. Right. And this works as follows. So you just have your size, but now you continue just here with the literals. Right. You put the literals here directly after it.
01:48:03.924 - 01:48:20.504, Speaker A: I don't remember what we had. I think we had four and so on. Okay. Then you only pay one. Like you pay this dollar. Dollar point of the reference is gone. So that's the reason.
01:48:20.504 - 01:49:02.650, Speaker A: Yep. And the c, actually, because it's such a common medium, allows this kind of variatic declaration which says, yeah, here comes an array. But this array is embedded into the object you're allocating. And, well, you need to care yourself how big it is. And when you allocate it, you also have to be careful, actually, in c, you really have to precisely say how big the memory is you're using. And that's an important trick. In the code itself, there's almost no difference because the access to this literal looks as if they would really be like in the first version.
01:49:02.650 - 01:49:51.210, Speaker A: But of course the compiler will realize that this is different and that they are embedded. So kind of, you would call this idiom like embedded variadic literals allocation. All right, so this is, I think, what I would need to show. There are some more things which maybe I'll just show in the assignment function here. So this assign here, this is like what happens if you remember, like you put something on the trail. So that means we're assigning this literal here to true, and we remember the reason for assigning these literals. Okay, you will see in a second how this is done with the, with the assignment.
01:49:51.210 - 01:50:51.356, Speaker A: Right. So this clause is such a clause we just have seen. So now this is a pointer to such a clause, a reference, okay? And there's some overhead, like extensive locking, which serves as comments, but also like for debugging or for seeing like what's going on. Then here there's a specific check for whether this thing is a root level assignment. If it's a root level assignment, then we record this. Right. This actually is just a statistic counter, while this one here is active was actually the second next to last column we saw in this output, like when the number of variables goes down because more variables are assigned, then here comes a trick which is, yep, everybody does it, but it's painful for many reasons and I cannot completely explain it.
01:50:51.356 - 01:51:41.690, Speaker A: But the trick is as follows. As soon as you're learning a unit like something which is definitely implied by the formula and it's a variable, then you don't need the reason anymore. So it's like you just can forget that clause, because that clause is now root level satisfied by that literal which you're assigning, and therefore it's completely redundant and can be removed from the formula. And that's why we're actually recording this by not storing the clause here as reason at all. In the implication analysis, which I've discussed before, this just means you have to check the level of a literal, like the decision level, because like levels, variables which have a decision level of zero should be skipped. Okay, then we'll assign the literals. There's like some other trick which is related to that.
01:51:41.690 - 01:52:30.524, Speaker A: This, you actually want to have access to these values, this values array for each variable for English, and because of that will actually duplicate the value in a certain sense we have in this array. It's not a variable size, but it's actually of twice the size of the number of variables. And it will access it with literals which are twice the size of variables. Right. And then for the negation where the, the least significant bit is flipped, you put the minus one for negative and you put one for positive and it's zero. By default that means unassigned. In the video I had a dash for unassigned for the number of variables.
01:52:30.524 - 01:53:00.654, Speaker A: Okay, then here you see three arrays which do have, are indexed by the index of literal. So this index macro here really just divides the literal by two and gets the 32 one index bits, right. And. All right, so first of all, you remember the sign. So this is a trick. It's called face saving, which we're going to talk about later when we look at decisions. Then we're going to save the reason of a clause.
01:53:00.654 - 01:53:52.490, Speaker A: And that's, remember like for, for a root level will become zero, but otherwise it's kind of, the arrows in the incoming arrows in duplication graph are represented by this assignment. So this is really beautiful if you think about it, right? So the implication graph we saw is a complicated graph structure. And you would wonder how do you really represent this in a computer? It's completely trivial. Just take a reference to the clause which forced this literal to be aside. Now you might wonder, what do you do with decisions? Well, with decisions you do the same. They guarantee it not to be on decision level zero. Okay, so this thing here is then not zero, but then you keep just put a reason which is zero and not a pointer.
01:53:52.490 - 01:54:11.444, Speaker A: Right. Not a reference. So you find decisions by not having a reason. Reasons. And except for those variables which are assigned to decision level zero. And those are units. Okay, so these are, this is, we will come back to this phase series later.
01:54:11.444 - 01:54:49.992, Speaker A: This thing I want to show you. This is in essence the information which is encoded in duplication graph we just discussed. So the reasons are these kind of incoming arrows for literal in duplication graph because the reason contains of course all the other literals and also the implied literal. And this is the silver level, right? You need that for multiple things like for, as I said, like figuring out whether it's a unit or whether it's a decision. Okay, now comes something. We put something on a trail. So this trail is pre allocated.
01:54:49.992 - 01:55:07.604, Speaker A: So that's why it's not a really push stack thing. But we know that like the trail is maximum size of the number variable. So that's why we pre allocate it. And then we'll put the literal which was just assigned. It was assigned to true. Right. You still see it here in this line on the trail.
01:55:07.604 - 01:55:44.174, Speaker A: Okay, then I want to mention this already. Now we also decrease the number, the counter, which counts the number of unassigned variables. That gives us a very fast check to determine whether the current formula is satisfiable. Right? So we don't need to go through all clauses and figure out what they're satisfiable. Only. We were going to have a check like a, which checks that there are no unassigned variables left and we propagated everything. And then the combination of these two properties will let us conclude that the formula is satisfiable.
01:55:44.174 - 01:56:36.138, Speaker A: Okay, so now let's go to the assign function. Sorry, the analyze function, which is exactly corresponds to our. All right, so we're going to now look at top down to the analysis, as I said. Right, so here's the CDC solving loop. So you have an seen actually pseudo code of that yet, but this is very close to like how you would represent it on slides as well. So first of all, you might already see here this 20, which is the code for unsatisfiability. And that's like only set to the result value if the solver happens to be inconsistent, which is a synonym for having learned an empty clause or having an empty clause, like original empty clause.
01:56:36.138 - 01:57:15.558, Speaker A: Right. Otherwise we'll just have this loop here. And the first part of the loop you will just really do constraint propagation. And again, so we're going to look at that also later. So we'll just walk all the clauses of the freshly assigned literals on the trail and then look through whether their unit or whether their in conflict. And if they're in conflict, then we go to this analysis, what we decide, what we discussed. If they're actually in unit clauses, then we'll just make this assignment with the function which we also just saw and then continue.
01:57:15.558 - 01:57:54.070, Speaker A: Okay, and this iterate flag, this is exactly the I we saw in the output. So if you learn a unit, then the solver would implicitly in analyze, actually set this flag to true, so that we can see that in the output that there's a unit learned. So otherwise. And that's what I also mentioned before, there's this unassigned counter. So if there are no variables left anymore and which are unassigned. So in a sense, like the trail is now as large as it is possible. Okay, all the variables are assigned and propagation did not result in a conflict.
01:57:54.070 - 01:58:37.942, Speaker A: Because we get here in this else branch here, then we're all done, right? We know the formula is satisfiable. So we set this, and this will actually terminate this loop here, which really continues until either the result here is set to 20 for Ansat, or the result is set for ten here after normal variables are assigned and no conflict occurred. Otherwise, we do some more things, including, including reduction, which I already mentioned, like for reducing clauses, also restarting. And then some other thing is possible at the end. We'll need to pick a variable that's done here in this design. So that's the CDCL loop. It's not recursive.
01:58:37.942 - 01:59:11.174, Speaker A: You want to write down this for Dpll. It gets a little bit more tricky. It's also possible doing it very similarly. But yeah, it's slightly different. Now, as I said, the hotspot is here. And this is kind of really the core of this CDCL. And I'm going to show how this works not only the blackboard now in real code, now analyze.
01:59:11.174 - 01:59:46.284, Speaker A: And it gets the solver, of course, and conflict. So the conflict is the, is the clause which the propagation found to be empty. Remember like we had this in this example. So you're doing some propagation, and then there was like one clause which forced three to true. And then the other clause says, oh, then I'm false. And this false clause is now given as an argument to this function. The goal is now to learn the clause and also do the backtracking and the assignment of the flipping of the literal.
01:59:46.284 - 02:00:18.892, Speaker A: The first UIP will actually be flipped. Okay, so we're first getting the conflict level. And if that conflict level is zero. Okay, so if you get in conflict on the root level, then of course, like just by the units and everything which is in the formula unit propagation alone would give you conflict. So that means the formula is unsafe. But, well, we came to this point actually without having found this earlier. So we're now marking this as unsat.
02:00:18.892 - 02:00:48.994, Speaker A: Right, the formula. And then we'll also ask the proof checker actually to check this. But, and because there's no other literal edit to the learn, like the checker, that would mean check that the empty clause is implied. Okay. Then you see sort of there's like three data structures, three stacks actually needed here. One is the blocks. Actually each block is identified by the decision level.
02:00:48.994 - 02:01:05.120, Speaker A: Right. We had like these blue blocks, or like the, like three to one. Like in one case it was only three one. So you could back jump to level one. Then we would push actually one and three here on this stack. Then the second stack stack here. This is the clause we're learning.
02:01:05.120 - 02:01:46.974, Speaker A: Obviously you need to push these literals somewhere before you really allocate the clause. So there's a stack which does that. And then this one here is kind of a mark, bit of something similar to graph traversal of the implication graph. So this tells you which of the literals have I marked to be seen. And the reason we need this is because we need to undo this markings later. Donald Knuth in his solvers, for instance, uses time spent to avoid this sort of undoing of the marks unmarking and therefore doesn't need this stack. Okay, then we make room for the first ULP.
02:01:46.974 - 02:02:12.448, Speaker A: So we want to keep the first ULP as first element on the stack. So we just put sort of an invalid literal there as a placeholder. Then we get the marks. Again, these marks are these muc flags which allow us to detect whether we've seen already a literal in duplication graph, like as in graph search rate. And as you see, these are signed charts. So these are just bytes. So you have bytes for every variable.
02:02:12.448 - 02:02:52.818, Speaker A: You have a byte which tells you, have I seen this variable before? And that's what you're using for the marks. Then the levels, we saw that before when we in the assignment. So the levels of a literal start in a big array and we, we just kind of get that so they can easily refer to it the same for the reasons. So these are the reasons we start training assignment, right. Remember, these two guys actually really represent the implication graph. Then for each decision level we have another flag. So similar to the variables which is here, we also remember which decision levels have been seen already during the conflict analysis.
02:02:52.818 - 02:03:18.626, Speaker A: Right? So these guys are per variables and these are per decision levels. And then blocks here. This is just sort of those frames which we have marked. So the plots is in essence actually used to unmark those bytes here which were used to mark the decision levels which have been seen. Okay. And then we start at the end of the trail. Okay.
02:03:18.626 - 02:04:14.778, Speaker A: The trail is almost like a stack. So you saw that in the assignment, we push things onto the trail like at the end. So we start there and then, and this is the trick where having we count the number of literals on the current level in the claws, we kind of constructing which are still unresolved initially. Like all the literals in the conflicting clause which are not from, which are from decision level are unresolved. And as I discussed before, I made this mistake. Right? Remember that usually there are guaranteed to be two literals of the current decision level in the conflicting clause. So this will be after we resolve, after we start this whole thing with the conflicting clause.
02:04:14.778 - 02:04:47.544, Speaker A: Will this number will be at least two. And then we're going to sort of resolve a way along the trail, like starting backward from this t here, all the literals we found so far, until this unresolved current level here is zero. And then we'll get the UAP. So that's why here at the outside, this is kind of the outcome of this thing. There's a variable called UIP, again, again, unsigned, and just encodes the literal here. Okay, so we have a reason it's non zero. So we're analyzing this.
02:04:47.544 - 02:05:36.632, Speaker A: The log function will actually print the reason marking this reason is used for like reduction. So we're not going to throw away used reasons. And then we go over the clause, you see here that, and I'm using here c. But I have some macros in place which almost make it look like automatic ranges in c eleven, and therefore keep the code actually compact. So what I do here is I go over all these literals like we saw this on the blackboard of this reason clause. Then I'll get the index, get the level of it. If the level of that literal is zero, right, I don't have to do anything.
02:05:36.632 - 02:06:06.212, Speaker A: This is already explained also before. So the solvers assume that everything on decision level zero is kind of ignored. So you only remember the values of these variables, but no reasons. The clauses are anyhow satisfied, which are these reasons. Then I'll take the mark bit. And the mark bit is either z and scene is just one or not. And if it's marked, then I have seen that and I can ignore it.
02:06:06.212 - 02:06:56.290, Speaker A: Otherwise I mark it as seen. And then later, because I need to unmark it, I'll push it here on the analyzed stack, on the scene stack. Actually there is some necessity to sort this analyze stack later with respect to time to keep the decisions in order along the timestamps. And that's why I not only push the index here, the variable index on this analyzed or scene stack, I push with it, also the timestamp with it. But this is a technicality which we could discuss maybe later. Okay, then we're analyzing this literal rate. So we're saying, okay, so this one has now been seen, and now we need to have a case split.
02:06:56.290 - 02:07:38.294, Speaker A: And this case split is like typical for CDCL. If the literal is in a lower decision level, right? So in the pictures I had, there was where these lines, right, and then we're resolving below these lines here. And if after, if you now find the literal which was above, right from a lower decision level, then we're in this first case. Otherwise, if you're below, then we are in the current decision level. And if you're in the current decision level, see what's happening. Well, then we just increase this number of unresolved literals on the current decision level. We've marked it as a side effect, so that's important.
02:07:38.294 - 02:08:10.886, Speaker A: But we also need to increase this number. The second case here, when the literal is really like from a lower decision level, really means we're going to learn this literal. Put this into the clause we are going to learn. That's what's happening here, right? Just push this into. Or this is one of the literals we're going to put into our learn clause. Note, by the way, this literal is because it occurs in a reason of a clause. And it's not that we're going to see the literal which is 14 to true.
02:08:10.886 - 02:09:07.556, Speaker A: This will be only a literal which is false to false. You also see here the assertion that this is the case that is really sort of like the negation already we're seeking, right? So we kind of do here the negation implicitly here, right. By following in sort of an arrow backward in the implication graph, we said, okay, we have to flip the literal, but here, because this literally is part of the reason it's already flipped, then we do some bookkeeping here for the levels, as I said. Also the levels are marked, the decision levels which are used. And these are called frames. If this is not marked yet, then I need to pull in this decision level. I call it in other solvers pull in this additional.
02:09:07.556 - 02:09:45.564, Speaker A: And this is bad, right? Remember the example with the back jumping? Like every decision level you omit helps you to sort of keep. Keep this, the claws sparser. That's also the idea behind this glucose level of blocks, right? So you want to keep these blocks as few as possible. And that's why kind of, this is not, if you have too many of these, this kind of gives you not that good clauses. But I want to count this anyhow. So I'll push these if it's not, has not been seen yet. This level, I push it on the plaques, right? Like the integer number level is pushed on the plaque and it's marked as being used.
02:09:45.564 - 02:10:23.292, Speaker A: All right, now this is the end here of going over all literals of the reason. And we'll just have this conflicting clause here as a reason assigned here. Where is it here. So we just take the through this loop, which goes backward over the trail. We'll just have the conflict as reason. So this is kind of a misnomer, because it's a conflicting thing. So everything is forcing it later.
02:10:23.292 - 02:11:04.128, Speaker A: The reason will always be a reason for forcing a variable to be true, and it will be the case then that this variable or this literal here has already been seen before. So that's why it will not be pushed. And that's why this assertion I was just mentioning here is true, because the literal which was assigned to true, was already marked to be seen before. And so we're not getting here because the mark was true. Okay, now comes the part with the sort of topological sorting. It's kind of hitting here in this loop. So we're now at the particular trail position, right? And.
02:11:04.128 - 02:12:02.484, Speaker A: But this trail, maybe the very last variable rate, might actually not have sort of be assigned even after the conflict variable, because we're sort of like way earlier in propagating. We have not reached the end of the trail yet in our propagation. And so I'm going into the trail and checking whether this little was already seen. If it's not been seen, well, and I just keep on going backward in the trail until I find those literals from the, from the clause and will take it then. So this loop terminates if I find such a literal which has been seen. Okay, and it's actually guaranteed here. This is what this assertion says, that you will never go, never have an underfloor, you will always be above the trail, and we'll talk about this later.
02:12:02.484 - 02:12:42.124, Speaker A: Anyhow, so this is the next UIP candidate here. So it's like a candidate at this point. So you don't know yet. It becomes really the UIP if the number of unresolved literal on the current decision level really drops to zero, right? Because then this one was the last one we resolved away, and then we break out of this loop. Otherwise, we know this thing needs to have a reason why. Well, it cannot be a decision, because the decision is, of course, a UIP. So if UIP would be the decision of this decision level, then it's guaranteed that this thing here is zero after.
02:12:42.124 - 02:13:33.864, Speaker A: And because of that, you will go out on this loop. Okay, then we found our unique implication point. You can actually get there some nice log message for this one then. That's what I already said. Like, we need to sort of the place where we made room for putting the UIP, that's the first literal in the clause that's now overwritten with the just found UIP, and then we can log the clause we actually deduced. And then comes something I'm not sure, like, I have time for that in this video here, which is called clause minimization, we start with this clause and actually we can shrink it. And the shrinking also uses the implication graph.
02:13:33.864 - 02:14:09.634, Speaker A: And then you get often a smaller class, which is at least as good as the originally deduced class here. Okay, now you see also it makes also very simple the definition of blocks. So the blocks are the number of blue numbers we had. Actually not completely true at this slide. Like you had like maybe the blue numbers three, two, one in the blackboard. And three was sort of the current decision level. That one of those course doesn't count.
02:14:09.634 - 02:14:58.594, Speaker A: So the number of blocks is because the current decision level is always a part of, will always be seen in the conflict, right? Because you just made an assignment on that level. So that you take out and then you take the other blocks, like the other levels which have been seen that are stored in this block stack. And this is your glucose level. Okay? Then we need to find the jump level. So once again, what's the jump level? Was the second largest level among those, the blue ones, including the current level. Right? So you go through this, through your blocks and you find the second largest one. That's what we have here, right? So it's a level which is not the conflict level and where the jump level is smaller.
02:14:58.594 - 02:15:47.710, Speaker A: Okay. Then there's some metrics which have to do with restarting, which we also are going to discuss. And then that's almost it, except for one thing, which we have not discussed at all. And this will be part of the second video, which is how do we actually pick decisions? And that's what's happening here. So we're trying to bump variables involved in this analysis. And as you kind of see, it's completely clear what you do. All the variables I have seen there during this kind of backward resolution to the implication graph, those are important variables in my current state of the search and those I will going to make more important for decisions.
02:15:47.710 - 02:16:27.764, Speaker A: That's called bumping. And we'll discuss this in the next part. Otherwise, I just backtrack to the jump level. This does nothing else but just unroll, like shrinking the trail, popping literals from the trail until the topmost literal on the trail has this jump level. Okay? And then I learned the claws. And the size of the clause is of course, needs to be again, split into two cases. The first case is that you learn a unit and then, well, you don't need to learn a clause, you just assign this to the, at the root level.
02:16:27.764 - 02:16:56.836, Speaker A: So that's why jumping back to the root level. Then we do our nice. Prepare our nice output of the I column. Right. Remember Ci, right. This is done here because we learned the unit and we learn this not UIp, by the way, I didn't say that before, but the not UIP. So you have to flip the UIP because you take the Uip from the trail and on the trail are only true literals.
02:16:56.836 - 02:17:54.474, Speaker A: But of course you want to put the negation of it into the learn clause. While for the other clause variables, right, which are part of the reason, which are all false, those you put directly into the learn clause. Okay, now, now there's like some, some important sort of like things regarding watching schemes which we also briefly touch upon later and, but I'll don't have time to explain, explain this here. Then we have to watch the clause, then reset everything. Okay, so this was a force to the force through the analysis function. And next we're going to talk about decisions. Now back to the blackboard for decisions.
02:17:54.474 - 02:19:03.234, Speaker A: So decisions actually come in two flavors. And the first one is variables and the second one is which face, silver yapple. And the other one is the face. So this is already, of course, kind of heuristic and it is the current one which is employed in the solvers. And I'm going to explain both of them, of course, like these are heuristics because we don't really have any proofs on how to use things here. So you need to pick a variable in a phase and already separating these two is an assumption. There's like one rule of thumb, which is a maximize satisfied clause is maximize satisfied clauses.
02:19:03.234 - 02:20:34.128, Speaker A: And the alternative to that is of course, kind. And why is that? Well, because if you're trying to get with the decision as many clauses as possible satisfied, you're getting closer to a satisfying assignment. And if you're done, right, if you reach this satisfying assignment, then you're done. And therefore, like trying to eagerly make big steps towards this goal is guaranteed to either get you into sort of a dead end or soon, or you really find this satisfying assignment. And yeah, related to this one is propagate as much as possible. So that's particularly interesting in the old look ahead, sort of like you count if I make a decision, you count how many additional variables would that actually assign? So in a certain sense you're doing the same ego kind of forward looking thing by kind of actively, actively kind of going for that. So these are kind of the two heuristics in look ahead.
02:20:34.128 - 02:21:25.822, Speaker A: There's also really like, that's the name, look ahead. That you kind of simplify the formula first or you do this sort of in a two step approach. Now, the interesting thing about this is, now, this is not state of the art anymore. So what we're doing is called, some people called it relevance based decision heuristics. And with relevance here, we mean your look, what was actually currently important and important, obviously, in closed learning, are those literals which you resolve away, as we've just seen. These are the scene literals, like these which are pushed on the scene stack during the analysis. Those literals, which are why? Well, because they were always, they were used in a certain sense to revive facts.
02:21:25.822 - 02:22:16.566, Speaker A: And maybe, and this got us into a big controversy, but I nevertheless write it down here. This has a flavor of local search for proofs, right? And in particular, if you drop the proofs part here, then I'll get into fight with Karem Sarkala and others. But I think this is true. So this religion heuristics and it's exponential version of it, it's called EV sits. And the thing I'm going to show you in code is VMTF. They are all of this flavor. So you're taking what kind of the reasons for things which went wrong, right.
02:22:16.566 - 02:22:56.534, Speaker A: And you're trying to actually focus on these things which went wrong recently. This is a very kind of human way of making decisions. Right. Okay, so let me explain this in more detail. So we're going to do first visits, I think now I can remember. It's variable score independent. I'll talk about that in a minute.
02:22:56.534 - 02:23:57.422, Speaker A: Decay and then forgot was s means sum. Alright, so the sum. So the sum means that you sum it up over kind of all literals. And this comes from the old kind of papers from the nineties and like what people used in cresp here, some you can't read it. This independent means that you're really looking at variables rate. So it's kind of redundant this term because you're having here, this independent here and in this variable are kind of our kind of synonyms. All right, so let me get rid of this one.
02:23:57.422 - 02:25:15.638, Speaker A: And so what is this rail. So you kind of increase score, score of scene variables. This is already the modern version. In the old days, when this paper in 2000 by the friends from Princeton came around, they did it like this was here originally, was like the variables in the clause, right? But nowadays it's the, the scene variables and actually more so plus reason literals. And this goes back to the maple sylvers from Canada, plus reason literals. Of gloss literals. All right, so this is kind of the state of the art now.
02:25:15.638 - 02:25:54.262, Speaker A: So as you know what scene is from the code. So you just do your kind of travel of your implication graph. And whenever you need to sort of like go back through such an edge, you mark this new variable as seen. And that's like a variable which is important. Then at the end you have these variables in the clause. They are, they have all been seen by definition, right? But there are some more like those which you walked over on the current decision level. And then this like plus reason, these rules here, it's called also a reason side bumping or bump reasons.
02:25:54.262 - 02:27:07.614, Speaker A: This is kind of new from 2016. But this thing here, this means decay. And that's really important also decay, I would call it smooth score of all variables. What you really do in one conflict step is increase the score of those variables which are involved, the relevant variables, and then decay the score of everybody. And this usually goes in a exponential way. Sorry, this would be only here also score variable in an exponential way. And this has very, very much to do with kind of exponential moving average rate or which is of course a very common technique in machine learning.
02:27:07.614 - 02:28:00.284, Speaker A: And so the score of the variable will become actually the old score of the variable plus, sorry, this was exactly. No, it's right. Plus alpha, which is the kind of smoothing. This is the decay here times the, like what you predict. Sorry, what you got, which is the delta, I'll come back to. To that in a minute. The delta and the prediction.
02:28:00.284 - 02:28:35.820, Speaker A: And now, of course I got it wrong. So this is here. Now this is exactly the right formula. Okay, now what's this delta here? So this delta here is the, whether you actually saw that, whether this is a relevant variable. So you compute this core update for all variables. This s. Prime is done for all variables.
02:28:35.820 - 02:29:29.930, Speaker A: But then you distinguish with this delta, those variables which are seen and which are not seen. And for this scene here, delta is one for seen variables and zero otherwise. And of course you need to take this reason side here also into account. They would become kind of reason or reason side. Okay? And this data you can. So from this equation down here, you see this, this is a kind of an update of the scores. And then, so you can think of like all variables go down, actually exponentially go to zero.
02:29:29.930 - 02:30:31.974, Speaker A: And then those variables which kind of are interesting, they pick out. And that was the v six. Okay, now the v six has this issue that you're yet, that you're going to have to update all the scores, right? As I explained, like s prime has to be computed for all the. Yups, this is costly. You can have millions of variables every conflict we're going through, all millions variables. And updating this is pretty like it's still in the formula, but gives you kind of a quadratic sort of flavor thing. And that's why people came up with isits, actually, the two minisat authors, Niklas N and Nicholas Sierransen, and they have this kind of the number, sorry, the number of scene variables is way smaller than the number of variables.
02:30:31.974 - 02:31:46.894, Speaker A: And this is the argument that maybe we can have an algorithm which only updates scores of the scene variables. And so what they do is actually you add increment to all scene variables exponentially, kind of in a geometric fashion. I should put here the name of this increment. So this is kind of maybe what kind of? Yeah, well, let's call it capital I. And then I prime becomes something like, actually what you would do would be one over one minus alpha times I. So this is in machine learning, usually beta like a number close to one, while alpha is very small. And so this is kind of usually a number like close to one, but above one.
02:31:46.894 - 02:32:24.554, Speaker A: So typically, for instance, right, 1.1, for instance, and beta would be 0.19 and alpha would be then 0.1. Okay, this explains kind of how things work. So you kind of, instead of decreasing everybody by 10%, what you do is you increase the bump. This is called then bump, actually. So maybe I should have called it b bump increment.
02:32:24.554 - 02:33:23.718, Speaker A: You bump this every time, more, exponentially more. Of course, the problem then is that once in a while, actually quite frequently, after maybe thousand conflicts, you run out of your overflow here. And in particular, which is initially when I saw this is awkward, but nowadays I don't think it's an issue anymore. Also, because compilers become more robust with respect to floating point. You need floating points, right? And then you have typically ten to the power ten e 150 is kind of the limit where the thing overflows. And then what you just do is, well, you take this biggest score and divide all the variable score by this, this biggest one. So this was one of the invention of the unique classes.
02:33:23.718 - 02:34:58.284, Speaker A: The other one is, well, you need a binary heap priority queue where you put these scene variables, okay? And then you always pick from this priority queue the variable which is the top variable with the largest score. And however, that of course has the problem that you can only make decisions on variables which are unassigned, and therefore in original implementations, by instance, Alex Nadel, and also by myself, you would have always equally removed all assigned variables, like those which are propagated from the binary heap, so that the binary heap only contains the priority, contains only the unassigned variables. But that's pretty costly, if you remember. So we do one decisions and then maybe ten or even hundred propagations. So you need to sort of remove all these hundred literals from this binary heap, which is still each of them a log n operation. And therefore Nikola Servantsen had this idea, well, why don't we do this lazily? So we keep all variables on the heat heap, and as soon we ask for a decision, we pop from the heap the maximum with the maximum score, until we find the variable which is unassigned and we assign that one, of course. Then doing backtracking, by unassigning the variables, you need to check whether these variables are not in the heap and then push them back.
02:34:58.284 - 02:36:30.304, Speaker A: Okay, this is the exponential v seats and this is, I would like what everybody else does nowadays, except for my solvers where I use a variant at least like in some part of the code, which is variable move to font and that's much easier to explain. And I'll explain this one next and also the implement. And that's why I want to show you this in more detail. So now to this VMTF or variable move to font, and so variable move to front. So this appeared first in the siege set silver, but has pretty like, like old concept, which is this move to front. Basically, instead of using a binary heap and which is a part of, and also this smoothing this decay thing, we're using something much more aggressive, I would say, and always keep the most recent variable, which was involved in producing conflict, as our highest priority for making this. So how is this done? Well, it's very simple.
02:36:30.304 - 02:37:18.084, Speaker A: So we're doing also we keep the variables in a doubly linked list. Keep variables in a doubly linked list. Okay. And, okay, seen variables are taken out and move to the end. Move to the end. Now, the only thing which I still need to say is a search from the end towards. Maybe we should search from, we should call this head and, well, from end to beginning for a decision.
02:37:18.084 - 02:38:20.348, Speaker A: From end to beginning for a decision. Okay, now this has a slightly quadratic flavor, right? So you're, whenever you make a decision, you need to sort of start from the end, searching from the end. So it's like, unless you can sort of hope that sort of like the variables you, you need to, to make decisions on are kind of always staying at the end of the list. This sounds bad. And also the original author, Ryan from the Sarzeau siege, didn't figure that out. But in 2015 we wrote a paper on how you, how you can do this, implement this faster. And I explain this now, this is with stamp.
02:38:20.348 - 02:39:04.258, Speaker A: So everything I had on the before erased. It is of course also true. So we're keeping the variable doubly linked list. Like we, like we remove variables which are seen and put them at the end. And also we search, but we're keeping a search as cache. So what that means is when we search the list, we remember up to which point we search. So maybe we found and then we remember the position, the list where we stopped the search for a variable.
02:39:04.258 - 02:40:33.894, Speaker A: And then when we again then started searching for decision, we started the position. And this already looks like better. Why? Because, well, if you think about like you have like 10,000 sort of like literals, right? So this is my list, even so it looks like a stack and. Right, and. Yeah, and these are like one, let's say even 500,000 variables, right? And then I make a decision here and then I make a decision here. And if I always start here from the beginning here, here at the end, and here's the beginning to find a new variable like I'm traversing here and checking whether these variables are unassigned, then of course, like I have accumulated like your trading cost if there's no conflict happening, right? So for instance, if you would have CNF, if really like this, this Q here has one and it goes like maybe 200,000, right? And you really have only one clause in your dymax format, which looks like this rate, and so P, C and f 100,001. Then you see what's going to do, right? So I'm going to go over this list line in a quadratic way, right? So I go from the right and then search again.
02:40:33.894 - 02:41:47.434, Speaker A: And the obvious solution for that is of course this is this search thing, right? So you were just going to have here a search field, which is this one here. And we're having like we just remember the position actually in the code, we're going to remember the variable because there's mapping from the variables to the precisions in this doubly linked list. When I need to do the search sort of like pick a decision, then I move my search pointer to the next position. Okay, that looks simple. But now comes the problem. What if I have to backtrack and in particular unassign a variable rate? Then it could be that, for instance, your search here is as we have here in the picture. Right.
02:41:47.434 - 02:42:33.124, Speaker A: So it's here, but the variable, there's like maybe the variable 17 here, which is unassigned. Unassigned, this guy. Then of course this search is wrong, right. Because you need to make sure like all the most important variables are to the right and you need to sort of find the first most important rate. So this is the like importance order to the right is more important. Right. So this is most important and you want to pick the decision which is most important.
02:42:33.124 - 02:43:37.494, Speaker A: Okay, now how do you do that? Well, one way would be is it's also not described in literature. Well, whenever you backtrack, just put the search to the end. Right. So you could, during backtracking, just put it here during backtracking. But then again, you don't avoid this quadratic example I showed you, right, with 100,000 clauses. Okay, so what our solution was in the 2010 point is to have here a kind of a list of stamps, okay? And these are timestamps where, I'm sorry, timestamps where you kind of make sure that they ordered along the enqueue time. So you can sort of think of this as timestamps or enqueue time, the time when you enqueued something to the right.
02:43:37.494 - 02:44:22.052, Speaker A: And this should be of course like be totally ordered. So like thousand three five and, and so on. Thousand, whatever. Okay. Now the point is, you know that this search here put, has the, has the timestamp four, but I'm going to unassign here this variable 17 and then I'm looking up here the timestamp of the variable and if this is bigger than this one, I'm going to destroy it and move the search in here, right? Yeah. And that's it. Okay.
02:44:22.052 - 02:45:01.000, Speaker A: In this empirically. So I don't have a theoretical analysis. It's really very fast. So it's way faster to, than, actually the code runs faster than the binary heap code. It's also easier to implement actually because you don't have to implement the binary heap, maybe more to this offline. But like you need to integrate this heap into the, in the start server. For instance, the standard priority queue in STL doesn't have an update minimum because you need to search.
02:45:01.000 - 02:45:27.100, Speaker A: They always work minimum. So you need to pop with during update. Like we compute, our score is prime all the literals. So you need to probably implement your binary Q heap yourself. It's not that a big deal, but still. And, yeah, and then the unassignment in this case is really constant time. I mean the surnage might increase, but the unassignment is constant time.
02:45:27.100 - 02:46:14.924, Speaker A: You just take out, like in this case, for instance, you would take out the, if it's bumped, right, you take out the 17 and you move it to the end. And, and you might need to update this search pointer while with binary heaps. Really? So even though you use this lazy trick I mentioned, you have to push back to the binary heap. All these variables which were taken lazily from the heap, they need to go back. And this is really like a log end operation every time. And if you have a million variables, that's still quite substantial. If you have to sort of push back like ten or 2000 or something.
02:46:14.924 - 02:47:02.844, Speaker A: Okay, there's still like one issue. So I mean, this thing, as I've said already, this is really aggressive. Okay, what do you mean with aggressive? And, well, if you think about it, like the factors we discussed before, so we had like beta was 0.9, right, or alpha 0.1. They could in principle simulate such a variable move to font Q with actually alpha equal beta equal 0.5, right. This gives you almost the same effect, except, and that's like if you do this with the binary heap, you will just increase the pressure on this binary heap.
02:47:02.844 - 02:47:58.756, Speaker A: Way more things will be bubbled up and bubbled down the binary heap then with a smoother decision, like a smoother decay, like with 0.1 or even 0.01. So it's not advisable to simulate the variable move to front with binary heap. Okay, that's one issue, right? So you cannot really do that. On the other hand, it turns out that for satisfiable instances, you should not really be aggressive. So you should kind of accumulate the knowledge about which variables are interesting and not just really focus on the most recent wants. I mean, this is intuition, there's no proofs or something here, but this is kind of what's important for satisfiable instances.
02:47:58.756 - 02:48:58.280, Speaker A: Once again, in satisfiable instances, it seems you want to be sort of more stable. And that's also why the solvers, my solvers have and also like things, Chantzig osovers have a stable and like a focused phase. I call it now focused mode, where you switch between the two. And in the stable mode, you're better off using a non aggressive, sort of like very low alpha decision cue. And in this case you should not use VMTF. But in the other phase, in the focused phase, which is particularly important for unsatisfierce instances, almost, let's say, put it this way, for very very hard, satisfiable instances, maybe two, then you should be extremely aggressive and localize the proof search as much as possible. And that's what you get by VMTF.
02:48:58.280 - 02:50:04.952, Speaker A: And in addition, you get also the benefit that the actual implementing heuristic is cheaper than with this doubly linked list and with the, with the binary heap if you use this stamping trick I just explained. Okay, we're going to look now at the code for the stamping. So first of all, there's like this, just a standard implementation of the doubly linked list. Now instead of pointers, we're just using the variable in indices as next, in previous fields, this not only, yeah, this makes it a little bit more faster. So you do the voids like eight byte, so it only needs like four byte instead of eight byte. And also we can resize this link array without sort of fixing pointers if we increase the number of variables of the software. And beside this sort of classical previous next fields, you have this timestamp I discussed.
02:50:04.952 - 02:50:50.026, Speaker A: So this is the timestamp when this variable, if it's on the queue, was enqueued, right. And the queue itself looks like this. So we have the first and last, the head and tail, if you want, of the, of the queue. Yeah, I call this, begin here, the first and called the last end. So this is where we start searching towards the first one. This is the position of the variable which we found last in our search during searching for decision. And when we search to the left, to the less important variables, then we update that so that next time we search, we don't need to start again from the end.
02:50:50.026 - 02:51:55.092, Speaker A: And then this stamp here, this is the, the timestamp, which is the number of times I encountered something onto the variable. Of course, this is, as you see, I've also put this into like four bytes, like just roughly after 4 billion stamp operation, this will overflow. And then we need to call this restamp operation. And yeah, so the overflow happens down here and this rest does nothing else but going over that link. And then really just put like fixing the stamps that everything on the queue is in order again. And then really just because this happens so rarely, like really only like 4 billion times, we'll just put the search cache here to the end and well, the empty queues and it, now here, this is where this happens. As I said, like the timestamp, there is four byte, like 32 bit integer, like after 4 billion time step.
02:51:55.092 - 02:52:33.936, Speaker A: So to the power, like 32, it will overflow, but it's an unsigned. So this, like in c, actually well defined. And then we will go here into the second part where we. Otherwise, we'll just do this following, check that whether it is literal enqueue is actually unassigned. And if it's unassigned, sorry. If it's unassigned, and if it's unassigned, we of course need to update the search pointer to the end. Okay.
02:52:33.936 - 02:53:18.120, Speaker A: The dequeue version does not any of the special code for handling this. And now we can go to the actual pumping. All right, so this is the code we saw before already, and it's really the scene stack. Again, these are the variables which we see during conflict analysis, plus optionally not in this code, but in other solvers. You can also pump the literals in the reasons of the variables in the learn clause, which is actually good idea. And then you're just bumping. What is really bumping in? Well, it's just dequeuing all these variables from the queue.
02:53:18.120 - 02:53:42.964, Speaker A: This is a constant time operation. And then queuing it. Right. This is not for the bumping, this is just for unmarking the sort of like scene variables. Okay, that's almost it. So there's like one catch though, which is maybe. Yeah, this is like something you pay for this using the VMTF.
02:53:42.964 - 02:54:13.774, Speaker A: It turns out that the basic scheme I just explained is, can be improved. And it actually, unfortunately substantially improved by making sure that when you take out these variables, like maybe these guys, and then you put them to the end, right. Then you put them in the same order. You don't reverse them. Right. You put them in the same order. Actually, it is even more clear if you interleave to take them out in the order and you put them here at the end.
02:54:13.774 - 02:54:54.908, Speaker A: And this really gives a boost heuristically. So the heuristic gets better. It's nothing. With sort of the time spent in this update, the university gets better. It's important, it seems to be that you should keep the variables in the same order as they are, kind of keeping the order stable, which is a little bit counterintuitive to the idea of aggressive bumping with VMTF. Okay. And, well, that's why you need to, you should actually sort these analyzed variables with their stamp time.
02:54:54.908 - 02:55:45.954, Speaker A: And you saw this before. This is where. Why here in the conflict analysis, we're not only pushing the variable index on this stack of scene variables, but unless this macro and sort here is true, where it's disabled, this sorting, but also the timestamp, and then we'll sort these pairs of invariable index and timestamps with respect to the timestamp. Okay. And then we bump, of course, as you can see, after it's sorted here, we're really going from the smallest timestamp and take that out one first and put it at the end and so on. Right. So you always keep sort of the relative order between these guys intact.
02:55:45.954 - 02:56:35.494, Speaker A: So this is the implementation of VMTF. So let's go back to the CDCL loop. And so what you understand now, by now, is this Boolean constraint propagation. We looked at, analyze this iterate was, of course, this is this minor thing for printing this. I, what are two things which are like sort of in the, all were missing and are important are this restarting. So you only get into this restarting if you didn't find the conflict through propagation, and there's still unassigned variables left. So in principle you would want to use this decide down here.
02:56:35.494 - 02:57:57.240, Speaker A: But at this point, point you can also decide to restart, unless it's, again with a macro disabled, or it's. Yes, the switching, which you have not discussed, or this reducing the database. Okay, so decide we've covered yet, we're going to do now the restarting. So, restarting is really comes from a completely different, different sort of like motivation. In local search, it was shown in the end of last century that like, if you run, say anything, which is kind of a random component for a while, you might get stuck in sort of an unlucky situation. And while on average it's actually possible to reach the goal fast, and because of that, it's good not to get sort of like stuck in at situation, but to kind of restart and this way proceed. The interesting thing is that the motivation today is completely different, and we haven't completely understood that part yet, but like there's empirical evidence that it's exactly the opposite, so has nothing to do sort of with search in the sense of the assignment space.
02:57:57.240 - 02:58:53.486, Speaker A: However, it might still have the same motivation if you think in terms of local search for proof, and you might end up sort of like focusing too much on this way of proofing something. And maybe there's another way, and therefore you should have a chance to restart. Okay, restarting itself is pretty simple, so let's have a look at that one first. That's very simple. So which is backtrack to decision level zero. What I have not implemented yet, maybe until a couple of days later, is something which Marijn, Heuel and students came, figured out, which was reusing the trail, and then sometimes you don't need to backtrack really to the top. So the second argument to backward is the, maybe you remember it was the jump level analyze.
02:58:53.486 - 02:59:23.162, Speaker A: So here it's the zero. Of course you go just really to the back. Why is this not harmful, you might argue? Well, because we don't do anything else. So we only backtrack. So we keep all the learned clauses, we in particular keep the scores of the variables. And now comes another part. We're kind of here in the default situation.
02:59:23.162 - 02:59:48.278, Speaker A: So this has to do with the switching, which we probably going to explain later. You're really increasing this interval between two restarts. How are these intervals measured? Well, they measured in the number of conflicts. So you see it here. So this is the limit for the restart and it's set to the current number of conflicts. As you saw, this was in one of the columns. Plus this interval.
02:59:48.278 - 03:00:35.146, Speaker A: And this interval here that's actually here has a slightly increase. Here it's log. And in classical solvers this would be geometric or arithmetic, but since glucose people actually get kind of a constant interval and why this is possible, we'll discuss in a second. In stable mode we'll use a more classical one, but I'll talk about this later. So that's really all this is like what happens in restarting. You in essence just backtrack to the root. And while you try next restart some insert, restart interval again.
03:00:35.146 - 03:01:20.876, Speaker A: So like if you spend like a thousand restart, this is log ten, actually here, round it up. Then you're having like an interval of three and so on. Okay, the interesting part here is not like what you do, but when you do it, okay, so you remember in the CDCL loop code, there was this, if restarting, then restart. So this is the restarting function, the trigger when you restart. Okay, so you do don't restart if it's the decision level zero, because you're already there. Then you check this limit. So this kind of says, okay, the rest of this code is never tricked if you haven't hit this limit.
03:01:20.876 - 03:01:57.814, Speaker A: So you wait at least for a couple of conflicts, but not that money, right? So yeah, as I told you. Right? So like maybe three or four. Okay, then comes something completely, a little bit. It's maybe obscure, but it can be explained. And that's like the main purpose of this part of the video. So we're going to check the average clue, and that means like just a clue of the clauses, which we learned recently. So there's an exponential moving average behind that.
03:01:57.814 - 03:02:43.942, Speaker A: And I'll talk about that in a minute. And we have two such exponential moving averages, a fast one and a slow one. And maybe I'll show this on the blackboard. So you can think of this as, like in stock market analysis. So, so if you have here the time, right? And, and here's the price, then what people do in stock market analysis, they measure like a slow moving average. Like something like that, right? So this is a slow moving average. While, of course, like the view data.
03:02:43.942 - 03:03:42.310, Speaker A: Like, look, looks like that, right? I'm not sure I got it right. So this is low moving average. And then they do another one, which is, you see a small isn't like the actual data rate, but it's like a faster moving average than the, than this low one. So this is a fast moving average here at the end, I didn't get it right. Okay. And then in addition, they would have a margin around this thing where sort of you say, okay, so before I have here an event which, which forces something, I want to see a margin. And, okay, so the events are, of course, these places where these two lines cut, right? So here and, and here and here and here and here.
03:03:42.310 - 03:04:44.714, Speaker A: But, and then in stock markets, you would sell, if you're like here in this event here, because it's like the long average, like the lower, like low fast moving average seems to go over the long average move. So people are selling. So it's likely that the trend will continue and you do the opposite. So, like if, if here, for instance, like maybe a couple of days later where you're, you're cutting again this line, and then it's the opposite. So, of course, like my, my drawing here is not accurate, but you get the point, right? So you have this fast moving average. And maybe to make this more concrete, I think in stock market analysis, they really did like six or nine days window. And I'll explain it in a second of computing the averages over the last six days, for instance, versus computing it over a month.
03:04:44.714 - 03:05:48.254, Speaker A: And this is like a real average, like in this window. What you can also do is an exponential moving average. So it has exactly the, this formula we saw before for the variable, for the exponential visits where you then do the alpha is just one over the days, right? And so if you have for nine days, it's like one over nine, and for 30 days, it's one over 30. And then because this alpha actually gives you the correction of the current score, in that case, here, it's, it's like, maybe I write down this function again. It's like plus alpha times. Now this would be your kind of price and this would be your current value. Now, like, the fast version would be one over nine, while the slow version here would be one over, let's say 20 days or whatever.
03:05:48.254 - 03:06:22.878, Speaker A: And. Okay, so this is how you can compute it without a window. And we're going to do this also in the sad solver. And I think I'll have like one alpha fast. Here is one over, sorry, 0.03. And the alpha slow was, if I'm not mistaken, or something. So we look in the code to make this precise, but in this order.
03:06:22.878 - 03:07:09.448, Speaker A: Right, so this was like three e minus two. And this guy would be one e minus five. Okay. Okay, so the rule is if, if the glue measured this way is reasonably so, you take a margin. Actually, the margin is like some percentage of the slow moving price or the slow moving clue. If the slow moving clue plus some sort of fraction is lower than the fast moving clue, then it seems the clue is going up fast. And that's not a good sign.
03:07:09.448 - 03:07:57.388, Speaker A: And then we restart. That's the idea. And that kind of allows empirically to sort of control the point where you want to restart and do only restarts where you not like in the pig, it really making progress. The glue goes down and you really sort of like think, okay, so this is strange. I'm a situation where I'm going up and up and up, and maybe I should really restart and see whether I can find kind of more locally proofs with restarting. Okay, now let's go back to the code and see what is happening. Right, so here you see the unbiased fast moving average.
03:07:57.388 - 03:08:33.788, Speaker A: We'll go looking into this function soon. Then here's the slow moving one. So these are just like in the previous picture, the two averages, the white one and the green one. And then we're multiplying this thing by a factor, like 1.25, actually, and then we'll get the, the limit. So let's maybe start looking for this constant because I promised this before. Right, so here you see the restart.
03:08:33.788 - 03:09:25.844, Speaker A: Mars marching is 1.5. As I said, like if you're 25% over the slow moving average with the fast low moving average, then you restart. And then this is also located on this, the blackboard, three times ten to the power minus two. And the fast moving averages is actually a slow moving. The alpha for the slow moving average is defined here. Now, yeah, what about this unbiased thing? So this is something I figured out recently by reading some machine learning papers. And it turns out that these exponential moving averages are really pretty in the sense that they are biased towards the initial value.
03:09:25.844 - 03:10:28.478, Speaker A: And of course, we start with zero. So this means that, for instance, the slow moving clue rate, it would really ramp up very slowly to sort of the real average. And you want to fix that. And in our paper where we described this first, also in 2015, how we do this, and also like in category implementation, we didn't figure out a nice way of doing it, I have to say at least, no, theoretically justified, but there's like a nice paper, machine learning paper, actually, famous machine learning papers, which is about the atom method for learning meta parameters. And part of that is a section where they talk about initializing exponential moving averages. And so what they simply do is, you remember beta, it's just one minus alpha. They multiply the computed exponential average with this term, and then that they give an analysis, which of course is a little bit too above my limit of understanding of the statistical part.
03:10:28.478 - 03:11:12.590, Speaker A: The claim is then unbiased, and it really looks pretty good empirically, much better than the solutions I have before. And what you see is really sort of like the exponential, sort of like, without any of this initialization, this thing, this exponential will wiggle a lot and actually overshoot, like what you really, it should be with this thing. It really very fast triggers on the kind of, intuitively, visually, the right exponential moving average. Yep. And this is the formula we saw before. You see, in c, it's even simpler than on the blackboard. So it's still here, right, this blue one.
03:11:12.590 - 03:11:54.910, Speaker A: And it's exactly the same in wise easier, because we have this plus equal here, but otherwise it's exactly the same. And then here's the unbiased one. Well, you probably want to, to cache this one over minus beta to the power n, right, because that's expensive to compute. These are floating points. And this one, this is just done by keeping beta caching beta over n, where n is the number of updates to this exponential moving average. Next time we do it, we just multiply this cached value by beta, which is, of course here, it's like even preconceived compute it as a constant. Okay.
03:11:54.910 - 03:12:56.188, Speaker A: And that computes these averages. And. Yeah, for the restarts, let me just mention here, Djanzek made this observation, I think I mentioned this already before, that you have, you should keep your sovereign into two modes, one which is more so it has many restarts, and one which has less restarts. And the later is actually good for satisfiable instances, while the former is good for unsatisfiable as I said, it's the completely opposite as the original motivation. Maybe, except for this point with the proof search I made that maybe the same argument from back then applies to proof search, where you sort of like should switch to like new parts of the search base. Okay, so. And how do you keep this apart? Well, the current code does this, as pioneered in QSAT.
03:12:56.188 - 03:13:54.894, Speaker A: So you measure in some sense the virtual time spent in the focused mode. The focus mode is the one where you kind of aggressively restart with this glucose style restarts, but with exponential moving average, which are just this would be this else part here. And otherwise, if you're in the stable mode, which is only enabled if mode switching is actually compiled in, then you're doing a slower restart. Scheduling. And in caseide in category, I'm using the Luby schedule. Maybe some of you know that one here because I was too lazy to implemented the Luby or Donald smoother, reluctant Dublin version of it. I just fall back to my old picosite inner and outer scheme, which actually, for instance, is still used in my copy here of z three, which you will figure out if you enable verbose mode.
03:13:54.894 - 03:14:42.856, Speaker A: Okay, so this inner outer works by kind of going up to a sort of the outer limit, and you go down and you start again the inner minute exponential upper, like more like a sawtooth change, but it's like an exponentially increasing sawtooth chain. And the inner outer factor here gives you the increase exponentially. In the original papers, this 1.1, and the current implementation is actually 2.2. Okay, so these are then the modes of restart, which means like far less restarts in the stable mode. Now the question is still like, when do you switch the mode? And as I started to explain, this is happening here. So the standard solver starts with the focused mode.
03:14:42.856 - 03:15:34.192, Speaker A: So it will be in this line and always check them. So then it's conflict control, and these conflicts will increase, like in a arithmetic way. And then during this time where you're kind of in focused mode, you compute the number of ticks. This is then sort of similar to knuth memory accesses. So kind of a virtual time to measure. How much time did you spend here in the focused mode since the large switch rate? And then next time you run an instable mode, you're trying to use the same number of tips. Why don't you use the conflicts? Well, it turns out that in focused mode, because you're restarting so aggressively, your conflict rate per second goes dramatically down.
03:15:34.192 - 03:16:32.504, Speaker A: I saw cases where this was a factor of 20, and so measuring the conflicts is not good because then you spend sort of like ten times more time in the focused mode and it's not what you want. So that's why kind of we're giving here the limits, the conflicts limit for the, for the focused mode and then use the ticks computed in that as a limit for the, for the stable mode. And that's the similar, actually switching between stable and which happens here. Stable and focused mode, which is in Kisa. Now this is simpler here, but otherwise it, it has kind of the same part. I want to show you this also running. So we need to a slightly larger example.
03:16:32.504 - 03:17:12.518, Speaker A: Let's try the speaker's formula which is in the repository, this one. Let me scroll up here to show you this thing. Okay, so this curly parenthesis, they start a focused mode. It ends here after exactly 1000 conflicts. Then the stable mode here with this bracket here ends here. And this difference here is measured in ticks, not in conflict. Now for this instance could be that it actually almost the same, but in general it's not.
03:17:12.518 - 03:18:19.424, Speaker A: And here you for instance also see that in the stable mode only did like one restart here from in this whole phase, which is of course not, not much. Right. All right, so that's the stable and focused mode. And yep, this splitting of the two modes into stable and focus together with having actually an exponential resets decision heuristic for the stable mode which we don't have in the satch solver yet, really gives very good results on satisfiable instances. And you get an additional edge by doing these target phases which I will not explain in this video. So this concludes the part on this mode switching and the restart. So we're going to talk about clause database reduction next.
03:18:19.424 - 03:18:46.772, Speaker A: So now let's have a look at reduce. So once again it works in the same way as this restart. So we having a trigger for when it's happening. And I'll talk about this later. Even though like the trigger is simple, but like the limit setting the limit is, is interesting. So I'll talk about that. And then we have here this function which reduces the clause database.
03:18:46.772 - 03:19:54.266, Speaker A: Right. And so what does reduce mean? Well, you have these learned clauses and with every conflict you put in your learn clause and they're kind of in the range of the length of these clauses are sort of like, yeah, 30, 40 ish, but sometimes even way, way longer, like hundred thousand even or 10,000 or like you have instances very regularly, every clause is 10,000 and you need to like propagate over those clauses and we'll later see the, at the end of this video, I will talk about sort of data structures for watches, which is important for getting this fast, but still. Right. Assume you can do propagation fast. You still need to sort of like propagate sort of somehow in the order of learn clauses, right. Because otherwise you would not need them. And therefore these clauses need to be removed, in particular those which are, which are kind of useless.
03:19:54.266 - 03:20:25.200, Speaker A: And this term used and useless is of course interesting. Like which kind of heuristics do you use for that? In the old days, it was really like that. So you could remove maybe all clauses which are longer than 20. This was in the early set. So one rule then the other rule would be, well, you an activity. This was in Minnesota, the rule. So you would bump clauses actually, which is a kind of level of use, right.
03:20:25.200 - 03:20:54.724, Speaker A: So you're pumping things actually with a very low alpha. So like zero point, like one to the power minus five, like this low glue alpha we saw. And this already hints towards that sort of. This bumping is not that important. Maybe the sort of the age when you did learn the clause is more important. In particular, maybe more recent clauses are more useful. Right.
03:20:54.724 - 03:22:04.722, Speaker A: And for that, it's unclear whether you really need the bumping anyhow. So this was pretty difficult for a long time to get right statistics like heuristics for. But then there was a paper by the glucose authors, Laurent Simon and Gillard Mart, who talked about, who figured out that, okay, I have an, a priori metric, which is the clue which we looked at already, which gives a very good estimate, at least like sort of for the first tier, actually, of clauses you want to keep. So what they showed experimentally is the usefulness of clause that kind of goes down exponentially with the, with the clue. And so you want to keep clue, small clue, actually, clue of two are always kept as by default, where clue of two is more. It looks like a, like a ternary clause, because clue of two means like a clue you can interpret as the number of decisions you need to make this clause propagating. Okay, so this is on the lower side.
03:22:04.722 - 03:22:43.976, Speaker A: So we keep for sure all the clauses which have at most clue two. And then what do we do with the others? Okay, like first thing. Yeah. You need to protect the clauses, which are reasons you cannot pull out the reason from a literal, which is on the trail. This is this thing then? Yeah. In this implementation, we combine reduction also with removing root level satisfied clauses. And of course, you only need to trigger that if there are new root level variables.
03:22:43.976 - 03:23:23.468, Speaker A: So that's done here by this fix. So if there are new fixed variables, then you also mark irredundant clauses as garbage. Otherwise you only work on redundant clauses for this clause reduction. And actually this over here separates the redundant and irredundant cloth in two separate stacks. And then this makes things a little bit faster. But it's not completely true because the most sort of the costly, the hotspot in this reduction is actually updating the watchlist. And we found a way around this in keysight, but I'm not talking about that here.
03:23:23.468 - 03:24:01.200, Speaker A: And by sort of like splitting in irredundant and irrebundent, you do not get rid of this hotspot of kind of flushing the watches. Anyhow, then this is the sort of main heuristic. We'll talk about this in a minute. So we're going to gather candidates, right. We don't put on this candidate stack, this is a stack of candidates here. We don't put on it like clauses with glue, 10 or two. Then we sort these guys, then we mark garbage candidates.
03:24:01.200 - 03:24:52.104, Speaker A: Like there's heuristic involved here, which means like these are now solid. So some of them are more, some less useful. And then of course we throw away these less useful clauses and how many. And in the original papers they've thrown away half of them. I throw away 75% for another reason, which I'm going to explain next. Yeah, and then, as I said, this is the hot spot because you kind of, you now need to walk these occurrence lists and then access clauses randomly in memory. And that's because you need to remove from the watch list these references to these clauses, which are removed like either satisfied or reduced.
03:24:52.104 - 03:25:26.552, Speaker A: And then you can go through these stacks, irredundant clauses or redundant clauses, these two here, and just really physically remove the clauses and flush these references in them. Okay, so that's it. And then, well, at the end you going to unprotect the reason clauses again. So now let's, let's, let's have a look at these three. So first one like gathering the candidates, like I really explained this a little bit. Then sorting them. Yeah, haven't talked about that.
03:25:26.552 - 03:25:44.534, Speaker A: And then you also need sort of a policy for which to keep. So let's first look at gathering reduced candidates clauses. That's it. So we go over the list of all redundant clauses. Right. And this is the stack or the stack of all redundant classes. And.
03:25:44.534 - 03:26:32.972, Speaker A: Right. Then we need to skip these protected ones, which are like reasons. And then we might actually want to like also check whether the clause is satisfied, but only if there are new root level assigned by, since the last time we did that. Otherwise, and this is really after many years, like the local optimum. I'm in there and there's a paper by Gul Diep and matte, also at sat two years ago in Lisbon, where they kind of threw machine learning came almost to the same conclusion, but I heard they have updates on that one, so I'm curious about that. Anyhow. So what's this? Well, there's a boolean flag I have in the.
03:26:32.972 - 03:27:24.338, Speaker A: So in each clause we saw this maybe before, and this Boolean flares tells you, has this clause been used in conflict analysis? Right, so here. Right. So if you analyze the clause during this, we discussed this loop extensively before, so we went backward. Like all these literals are false except for the implied one, which was marked recursively reachable from the conflict. Then we call this clause also as useful because it contributed to this conflict and we had to resolve it away to get to the first ULP clause. Okay, this is this flag and we, we're getting the value of this flag here. This is disused, but then we reset it.
03:27:24.338 - 03:28:02.330, Speaker A: Right. So whenever we do a full flaws reduction, we reset this used flags. So that means we're going to only sort of look at was this clause used since the last time this reduction was running? Okay, and if it was, well, we don't put it as a candidate. So you kind of keep always clauses which were used since the last time we did a reduction. Yeah, this is the thing I already mentioned. So we have this reducing the clue limit, which is constant, and this is two. So if the clue is smaller, equal than two, we're also not considering the candidate.
03:28:02.330 - 03:28:46.632, Speaker A: Otherwise we'll consider the clause as a candidate. Okay, so this is the gathering redundant one. Next one, after we have taken, we have to sort them. And this also has an interesting heuristic it uses here, this comparison function. So actually when we later remove useless clauses, we start at the top of the stack and pop from the top of the stack to the right are those more useless clauses and the, onto the left. Okay, now we get these two clauses. So this is quick sort.
03:28:46.632 - 03:29:33.664, Speaker A: Maybe you don't know how C works, but C has a built in quicksort and this has a little bit strange like usage. So you take the function which returns an integer, and if it's minus one, then the left argument is supposed to be smaller than the right one. So whenever I return here, minus one, like for instance here, then, yeah, the first argument is smaller than the second one. And with the explanation it just made, it means that the clause is considered more important than the other one. So here a smaller clue is considered better than a bigger clue. And D has a higher chance to be reduced like recycled. And in the other direction.
03:29:33.664 - 03:29:57.612, Speaker A: If C is actually larger, then you swap the two. Then next, that's a classical example. We have the size and the size is working the same way. Smaller size is better than bigger size. You want to keep pluses with a small size. Actually you can just do that. Okay.
03:29:57.612 - 03:30:55.606, Speaker A: And you will get not a bad silver. It's with this used and all the other things, actually slightly slower, but uses less memory. Well, because you focus on these sizes first, actually the very low clue like this, keeping always like clue two and also the used ones, more important than variations of this scheme, at least this is my experience with experimental data. Then here at the end, the idea is done in a sequential way. It's like a 64 bit index. And this way you kind of take also the age into council. So older clauses are one means like less useful, right, okay.
03:30:55.606 - 03:31:59.228, Speaker A: And otherwise this makes it kind of also deterministic with respect to different implementations of q sort because it's non stable in general. By the way, for the, we use this q sort also for sorting these stamps, right? But there the stamps are unique, like all the elements on the, on the decision queue have unique stamps and therefore their stableness of sorting is not an issue. And then last but not least, we have here this mark garbage candidate. And what you see here is very simple. So we just pop from the stack of candidate candidates until we reach the target. And the target here is computed with this reduced fraction here and should have, okay, reduced fraction here. And this reduced fraction here is 0.75.
03:31:59.228 - 03:32:43.632, Speaker A: If I said so, that means like 75% of the clauses are removed, right? Because 25% will remain. Okay. But then what you really do here is only setting the garbage pit flag because they now still need to flush these watches, which is at least for reduction, a very like a hot spot. Okay, so this almost completes our part, but there's a very intriguing and interesting part left. And this is when you reduce. Okay. And it looks very simple.
03:32:43.632 - 03:33:22.380, Speaker A: Okay, so we just have a limit which is measured number of conflicts. And yeah, if this is hit. But then of course the question is how is this reduce conflicts limit set. Okay. Okay, so by the way, so you see here before I explain that, that how you remember the last number of fixed variables at this point. And so the, here's it said, right, so the reduced interval is a fixed limit. It's 300.
03:33:22.380 - 03:34:11.420, Speaker A: Starts with 300. After 300, you do the first reduction, and then, in principle, after another 300, but it's actually increased with a number of reductions. Like, with the first reduction, it's like, well, it will be one, and then it's almost linearly increased. And this is what the original authors of glucose proposed. So they would have kind of done this rate, just reductions. But what I think figured out in kissat was that maybe you want to actually have a sublinear increase of this interval between two reductions, between two minus signs in this picture. And this reduces, of course, this will throw away more clauses and this speed up the silver.
03:34:11.420 - 03:35:03.192, Speaker A: And it turns out that this seems to be a good compromise, at least in Kisatin was here. I don't have really complete experimental evidence for that, but. So you take the number of reductions and you divide it by the logarithm of reductions, and this gives you a slightly sub linear increase of this interval instead of the interval. But note that already, the linear one, like the one I said, right, this one here, this was a bit big improvement when the glucose paper in 2009 came out. And this became only possible by having a better, a priori metric for which clauses to keep. Like, in particular, the one which says, well, keep all the clauses which have at most a clue of two. Okay.
03:35:03.192 - 03:36:15.838, Speaker A: Anyhow, so I would say getting to this point and really figuring out how to do actually and schedule these reductions with minor variations was one of the big improvement in the last ten years, together with this chonsic idea of getting the phase saving and, sorry, mode switching and not mode switching on the SARS oversight. And, yeah, maybe this target phase, which I will not explain here, and they are also not implemented yet, which I presented with Matthias at the post workshop last summer, actually in 2020. And there's the video and also slides of it online. We're actually working on a journal paper. So this seems to be. It's hard to evaluate, but it seems to be giving you quite some edge also, as the competition results from last year shown, where not only Keysat was making a big jump, but also to other solvers which implemented similar ideas. But I won't describe this in detail.
03:36:15.838 - 03:37:12.934, Speaker A: So next I'm going to talk about some other very important aspects of this sad solving, which is like data structures for watching clauses, and we'll talk about that next. All right, so now we're going back to the blackboard for one important part of sad solving, which, well, at least gives you a factor of two more in the range of three and four. And this is about like low level data structure. It's also very important to think about that in order to save memory. So this, the SAS solver we discussed so far, is actually not that good. So it has like four to eight times more memory than the keysat. But that also applies to other solvers like Cadeco and also minisat.
03:37:12.934 - 03:37:52.870, Speaker A: So what I'm talking about something is called watches. And this is like a really intriguing idea. When I first saw it, I could not believe it. So I had to quite, I saw the paper and for two days I tried to disprove the others, but they were right. And so, of course, now it's natural to me, and now it's my task to explain this to you. So, to you, maybe some of you have seen this before, but. Well, okay, so once again, remember we had trail and we had values and the simplication problem represented by the levels and by the values.
03:37:52.870 - 03:38:28.026, Speaker A: So what else do we have? Well, we have the clauses. And I was a little bit like sort of imprecise there. So let's see. So the first simplest way of thinking about this. So we have now let's say literal lake 17. And maybe here is like I'm using now dymx, again, not the sort of the unsigned version. And then you have here a container, which is a list of clauses in which these variables occur.
03:38:28.026 - 03:39:00.766, Speaker A: And of course, one way of doing that would be, and that's, for instance, something I did like in my sats, in my QBf. So the quantour is. Well, if you have. Yeah, so here 17 occurs and maybe there's some other literals, like minus two. Okay, and then, well, here's maybe the next clause with 17, maybe a binary clause this time. I guess you get the idea. So you need like additional fields.
03:39:00.766 - 03:39:43.552, Speaker A: And maybe if you, at the end, you put a zero here. Okay, and then of course, like these would come from somewhere else. Right. Like from the. And maybe this one also, right, so this is like for full occurrence lists and their places can full occurrences means like you need to watch all occurrences of literal scene clauses. That's for certain algorithms important like for like pre processing and, but I don't talk about pre processing today and, but it's really costly. So let's think about it.
03:39:43.552 - 03:40:35.176, Speaker A: So this thing here is of course like four byte, right? And, but what about here, this, this pointer? Okay, well, this is usually on today's machine, eight byte and maybe, so maybe I should put this in different colors. Actually, you want to have doubly linked list, like in our variable move to front thing. So this would be another eight byte. Okay, so that means, like, for every literal, you not only have kind of the payload, which is four byte, but you have 16 bytes, which gives you a factor five. Right. That's pretty bad. So maybe we forget about this w linked list, and it's, of course, like, also possible.
03:40:35.176 - 03:41:15.052, Speaker A: But then you need to employ, again, some garbage collection scheme, and you're still, like a factor three. So this is three x ray, because you go from four to twelve before you go from four to six to 20. Right. So, like three x versus five x. Then you would again think, oh, is this really that bad? Okay, so this is why this scheme here is rarely used. But before I completely forget about that, let me show you a scheme which in the old days. Sorry, oops.
03:41:15.052 - 03:41:42.416, Speaker A: In the old days, was used. And. And this is where the name comes from. It only watches two literals. Okay. And this was the observation in the Jaff paper back then in 2001, I think, where they figured, okay, you only need to watch two clauses. And there are, like, two implementations for that one.
03:41:42.416 - 03:42:25.728, Speaker A: The one I'm showing here is kind of the one which was originally done, but which was not in Lindau's version of the code, and therefore it got sort of lost. So I got a hold of recently of some old version of this code, but it's hard to compile in today's machine. So I don't know whether I can still resurrect that code. But anyhow, I independently kind of. Sorry, this was, of course, wrong. This last arrow, the same in Picosat. So what you see here is kind of the picosat version and the M.
03:42:25.728 - 03:42:58.262, Speaker A: Jeff version for Moskiewicz. Jeff. Not for Lindau's chef. All right, so first you would need to understand this watch literal to appreciate it. But maybe it's a good point to explain this here. So what was the really insight? Most important, one of the most important insight in that paper was that. And there are some predecessor working for saddle, actually, that even if you have a long clause, like, think of this as ten k long, right.
03:42:58.262 - 03:43:27.158, Speaker A: Then it's really expensive to have all these occurrences. And what actually, what? Your proposal. I forgot, you don't have these fields here. So you have a constant size. Only the first two have this watch field. So this was imprecise for me. But you can have, like, a clause of length 2000, and then you only pay the price here.
03:43:27.158 - 03:44:47.604, Speaker A: Initially, this would be 16 byte per cloth. And now why is this enough well, they have this invariant that you watch two literals in the clause, and they are like, they have to be both unassigned. This is the invariant or clause contains satisfied literal. Satisfied literal. And there's like some smaller catch here. So you want to make sure that when you backtrack among this, and this one has to be level of, this literal is smaller, equal than watched literal level. Okay, so if you maintain these two invariances somehow through propagation, then you make sure that you never miss propagation.
03:44:47.604 - 03:45:39.054, Speaker A: More important, you never miss a clause which is actually unsatisfied, but you didn't find it, right. So if you're not careful, you might watch things which are, you might stop watching the clause or not propagating a clause which is unsatisfiable. And then remember in our discussion, we said, like, as soon as the number of unassigned variables goes to zero, we return and say that the formula is satisfiable. If you're not careful here, you would actually claim the formulas to be as satisfiable, while sort of there is still this clause which you cannot reach, which is unsatisfiable, which you've kind of overlooked. Okay. With these two arguments. And then fixing that during propagation, you're getting like almost the state of the art.
03:45:39.054 - 03:46:20.626, Speaker A: But this is like around 2001 and 2006 or so. Okay, in the Amchef, like in the Z chef, which was kind of the first published source code, or at least like the source code which became available, which was at least I saw, I didn't see the M. Jeff code for a long time. It was slightly different. So there, what did I have here? Maybe five. Sorry, what was five? Right. This arrow here is actually wrong.
03:46:20.626 - 03:46:58.990, Speaker A: So we're not watching the claws head. So it points to the wrong direction. Actually, we are precisely watching this literal, like as a pointer. Right, the pointer address and then maybe really hear the pointer address of when you go through three. And then because you're not really watching the clause, you don't know where the clause ends. And then they put here like sentinels, maybe zero, so that you know the clause end and the clause beginning. And you need like additional sort of bits here for those literals which are watched.
03:46:58.990 - 03:47:33.664, Speaker A: Right. And like this one will of course not be watched. Yeah. As you see, this is pretty like a cumbersome. And you still need like, sorry, you don't need these guys, of course, these, these pointers anymore, but you need these additional bits. And maybe you can do stuff them into the rest of the literal so you can get away with with four bytes per literal in the clause. The sentinels, of course, like they are cheap.
03:47:33.664 - 03:48:16.432, Speaker A: So this was Z chef Linthal Cheng's version. Okay, now we saw already Picosat and. And am chaff. There was one catch, though, in that one, which now I raised. But I have to redo it because you're only keeping here the sort of. The first two connected. And the rest of the literals, like, let's see, there's like maybe four.
03:48:16.432 - 03:48:41.804, Speaker A: They don't have any link fields. And now you see 17 could be here or it could be another field. Then you would need to say, okay, so this point belongs to 17. While if there's like 13 here, then this point belongs to 13. It's still a single list linked singly list. And therefore you still need some. Some sort of garbage collection, maybe.
03:48:41.804 - 03:49:36.596, Speaker A: Anyhow, what if this guy violates now our watch property? It could be that 17 is actually assigned to zero. Now what we do here is. And this is then later, also done in other solvers, we remove the 17 and place it in another. Because maybe this guy here is also assigned to zero here. And this remains zero. But here there was like maybe a minus five, which was actually unassigned. Okay, so you would not need to do this check if this guy is one.
03:49:36.596 - 03:49:57.700, Speaker A: This is like. This would not violate the property. But it's tricky. And. Yeah, that's another story. So anyhow, we swapped these two guys. And this has the strange effect that the clause data, the clauses are not.
03:49:57.700 - 03:50:25.814, Speaker A: The literatures in the clauses are not immutable. They kind of change during proposal. Right? And this is, again, this is M. Jeff and Picosat. And. But this is not the best scheme. So around that time already, people came up with the following observation.
03:50:25.814 - 03:50:56.650, Speaker A: What if. Yeah, this is fine, but what if here, now you have a clause which has only two literals, like maybe -19 and again, 17. Well, then you have, again, pointers here. Right. And. Yes. So these pointers, of course, now can point to the start of the clause because we know that the point is for one of the two literals.
03:50:56.650 - 03:51:06.570, Speaker A: You know, from where you come. Right. You start propagating from the. From the 17 here and. Right. And then you go to this clause. And then you see.
03:51:06.570 - 03:51:15.722, Speaker A: Oh, I need to go here because the. This is the 17. Then I see where, which. Okay, I need to go this. This pointer. Right. I guess you get the point.
03:51:15.722 - 03:51:50.434, Speaker A: So you need to follow these things. But here it's pretty bad because you're. You're wasting a lot of memory. And in particular, because we discussed this already, there like lots of cache over usage here. So for this binary clause, we're having really like an overhead. And then of course, as you probably see, one pointer access, one pointer access, one pointer access. Like for every clause you have an additional pointer access.
03:51:50.434 - 03:52:53.520, Speaker A: And this is the chunks you need to get in there are bigger. So that is why already partially in Z chef, but then later in Minnesot, the following scheme became state of the art. Instead of having here directly linked lists, you would actually have a stack here. So the stack would contain usually a power of two number of entries, and the stack has begin and end. And then sort of like these guys are invalid, right. And then you really point directly to the clause and there's like no, yeah, so maybe 17 minus, what did we have? 13? And this guy was the other guy, the longer one, which I of course don't remember anymore what the literal was. Right.
03:52:53.520 - 03:53:17.604, Speaker A: But you get the point, right. So the advantage here is that this thing here, you only need to load it once. So this gives you one cache miss. And yeah, this will be fast. So no overhead and you shrink the size of this clause memory. Okay. But there's more you can do.
03:53:17.604 - 03:53:44.824, Speaker A: And this goes back to Stuki and Chu. And this is called blocking literal. And oops, I should have kept that one. Okay, so they observed that. Or this also actually was observed in other silvers. And so I remember also writing about that. Is that often the other watched literal? So this is the other watched literal.
03:53:44.824 - 03:54:49.154, Speaker A: Sorry, you should write it below. The other watched literal. When I traverse this clause starting from 17, right, then this, this -30 is the other wash literal. And that is in practice very often true, actually. So I think, like in my Picassad paper, I said 60%, but that's still true probably today. So at least this non significant part of this, of these, if these excesses are completely useless, why is it useless? Well, I do this point of the reference here, this one here, and then I get this clause memory here into the cache, and then I figure out with 60% probability, oh well, I don't need to look at that clause because the other literal is actually true. And moreover, it's often the other watch literal even in long clauses.
03:54:49.154 - 03:56:06.872, Speaker A: Like we had this long clause here before, which, where the other watch literal was maybe minus five or so. And also that one is included in this metric. So one of course needs to redo this experiment. Okay, so you visit these clauses without any use, and that's bad. So instead of doing that, the basic idea here is to increase the size of this stack, which you anyhow have to kind of access at least one rate and extend it to include here a blocking literal. Right? So in this case it would be just, let's say -13 for a binary clause right here. For the long clause we had like minus five, right? But, and we'll see this later.
03:56:06.872 - 03:56:46.458, Speaker A: This is not necessary. It could be any clause, any literal actually could be our seven. So it might be minus five, but it could also be this seven here. So I put the seven here. So it just has to be not the other watch, it should just be one of the literals in the clause. And the reason we cannot really enforce that it's the other watch is because otherwise this would require string propagation to update the other watch when we traverse the clause for 17. And then we need to, we swap 17 for some reason.
03:56:46.458 - 03:57:21.706, Speaker A: But then yeah, 17 is not the other watch of five anymore. So we need to go to the watchlist of five and update the watches here. But it's not necessary. So we can here have five and seven. And now of course what we do is actually before we make this dollar, dollar dollar memory dereference. So this is like a dollar, I said then we're just checking here. And this is also just dollar whether this 13 is actually true or like maybe this seven.
03:57:21.706 - 03:58:35.120, Speaker A: Right? And if this is true, we know it was assigned before, before 17, or at least at the same decision level. Actually that's the important part. And therefore I can just not visit that clause completely, sort of avoid this dollar dollar if for instance, seven and -13 are both true. Alright, so this is a blocking literal and goes back to true and Stokke block true, but there's more to it. But this more to it was also invented earlier actually, where people said, okay, so these binary clauses occur so often. Actually in the sad competition last year, there were instances with hundred millions of clauses and only 60,000 non binary clauses. Okay, and then it turns out if you really look carefully at this, that you don't even need here this whole clause anymore.
03:58:35.120 - 03:59:38.094, Speaker A: Because also like if there's like 13 somewhere, right, then -13 would also have here a stack with 17 in it and a pointer to that clause. So in essence, the clause is completely represented by these two entries in the watchlist. Okay, so that's why we can really remove the whole clause. It's not as easy as you think because you're, well, in this analysis function you saw before in, in satch, there was just one loop which went over one reason clause. If you now have sort of like two different kind of reasons. It's engineering wise a little bit tricky. So there are like two types of reasons, binary clauses where you don't really have the clause where you only know, okay, it was derived by a binary clause and there are these long ones and.
03:59:38.094 - 04:00:14.566, Speaker A: Yeah, so this makes the code more tricky. Furthermore, and now it becomes really sort of very interesting acclaiming kiss that I reached sort of the absolute limit. I thought like I had it be lingering, but it's not true. So this guy here, this -13 rate occupies now if you think about. And it's actually also true for. So this thing is actually 16 byte whites in sag. And why? Because the SAT.
04:00:14.566 - 04:00:59.140, Speaker A: So we were looking, well, because this thing here is eight byte pointers and you need to keep things here aligned in a struct. And then actually we put here actually also the size, which is kind of redundant, but we put it there and. Okay, so why can't we just kind of shrink the whole thing and just sort of steal a bit from the literal field and mark it as sort of binary and then only use like a four byte for this guy. So binary clause would then have four bytes here and. Right, this goes away. Four bytes here. Of course.
04:00:59.140 - 04:01:33.920, Speaker A: Now the problem is that the, the table here on top would have this shape, right? So because for the long clause, you still need a reference. And it's clear we cannot afford eight byte again, because then the whole thing becomes strange. So you would want to have here a four byte index of that, which then again limits the number of clauses you can access. But then you really get to the absolute minimum. So this is four byte. This is four byte. This is four byte.
04:01:33.920 - 04:02:11.848, Speaker A: And then you have this mixed, so you have then a mixed watch stack list of binary, like four byte small watches. And then for the large clauses, you have the blocking literal plus a bit that this is a large clause. And the eight by, there's like another, that's why I put here like space for another dot here. Another issue here. Well, there's one bit you need for whether it's binary or not. But then in addition, right. It's unclear whether this clause is irredundant or not.
04:02:11.848 - 04:03:19.170, Speaker A: Right. So if you have the clause in memory, as we also saw, like in satch, you could just have a bit there for denoting these clauses irredundant or is redundant. I mean, for garbage collection, it's not really like for reduction, it's not really an issue because you keep these binary clauses anyhow. But for like variable elimination for pre processing algorithm which really need to know whether clause is redundant or not, this is not feasible. So you really need to sort of put here another bit here into the, this is for the binary and this here is for a redundant bit whether this watch corresponds to a redundant clause or not, even though the clause is actually not there. But with this you greatly reduce of course the memory usage of the sad silver bioflu four to eight. And this way really handle a big instances, what do you gain? Well, our current machines get to the limit that you reach with this scheme.
04:03:19.170 - 04:04:43.538, Speaker A: So as I said, like keysight can handle 256 million like two to the power like 28 variables. And after that it just gives up. Also like this offset of course is this restriction. So this gives you like 616 gigabyte if you take eight byte aligned classes in an arena where you take the offset and things like that. So anyhow, so what I figured in practice is like that with this scheme you're getting up to sort of like instances which only run in 128 gigabyte. But if you have machines which with 256 gigabyte memory or 512, then you might really sort of jump across this sort of barrier and increase everything by effect of two. But then the bad thing is of course that you suddenly need twice as much memory, right? So as soon as you have a machine which, which affords, which gets like kisser to the limits with say 26 gigabyte of main memory, then another server which would not use this sort of compact scheme and like just one or two bits more would require already twice the memory footprint.
04:04:43.538 - 04:05:49.394, Speaker A: And you would need to buy a machine with let's say half a terabyte. Okay, now I would suggest we'll look at the code and for that I have here pre run sag, which also shows off one feature here of Satch. Satch has this possibility to completely disable features like blocking clauses. So if you take the option no block, then you're disabling that. And you get like for this slightly more harder factoring example we already looked at before, you get an estimate, like how much you gain just by these blocking literals. And as I said, it depends how you count, right? If you start off with the faster version, then going from here to here gives you 50% slowdown. While from here to here is of course like only like 33%.
04:05:49.394 - 04:06:22.366, Speaker A: But still it's like a considerable. And if you add a couple of these things together, you can easily make a bigger improvement. Okay, so maybe I show this non blocking for this no block first. So you just need to put this environment, sorry, this prepossessor variable. And then you get that. But then if you search for this en bloc, right, disable blocking, it will slow down propagation. And there's some more.
04:06:22.366 - 04:06:51.890, Speaker A: So you can completely remove restart. It's reduction. You can also combine them. Actually maybe I should show this too. There's like a combinatorial testing script, which of course failed because I just changed something. But in principle it would would we said hard with two. Oh, there was an error.
04:06:51.890 - 04:07:25.222, Speaker A: I'm not sure why this happened. Okay, anyhow, so we're going to this commentatorial testing should in principle work. So maybe I didn't check it on this latest version. And then this was the point. All these options here, even so you can switch off learning completely. This is the worst thing for that. I really had to hack actually the regression script to disallow harder benchmarks.
04:07:25.222 - 04:07:51.694, Speaker A: Because without learning everything would break down. Then I didn't talk about loss minimization today in this video. So this needs to wait. And then the sorting here, this would disable sorting of the pumped literals. And so you see you can switch off also this mode switching with the stable and focused. And see like what the software behaves. But there's no blocking here.
04:07:51.694 - 04:08:18.158, Speaker A: Now really shows you what this blocking idea is about. Like this is our reference tool, our clause. And then we add like these two more things. And in principle you only need like a bit here, which says the clause is binary not. But because we have like wasted this four bytes anyhow. Right. And we need like for the blocking literal, the full 32 bit.
04:08:18.158 - 04:09:07.114, Speaker A: Unless we going down with number of variables, we can as well just to put the whole size there. Because the, these two guys would have on a 64 bit machine each four bytes. So the whole thing like eight byte plus this eight bytes again on a 64 bit machine as pointer to the clause. Then we'll have here the stack which. What was that? The stack which for the watches with the begin, end and allocated as usual. And then the actual watches here are just a big array, like the reasons here we looked at before. And also the mark flags.
04:09:07.114 - 04:09:59.008, Speaker A: Ray, I didn't talk about face saving. This is also about this target phases, which also needs to go into another talk. All right, so these watches are then just like an area of stacks. And each like each area has here the begin and the end. So maybe go back to the drawing that you see again. So each of these guys would have like a begin pointer and an end and an allocated pointer. And maybe I'll just do them in red, so that you see what I mean? So this guy here has a begin end pointer and then of course an end pointer which points to the sort of valid part.
04:09:59.008 - 04:10:34.670, Speaker A: And the allocated is here. You need that for kind of like linear accumulated reallocation effort. Okay, that's very basic. And then this is the code which puts a watch into a literal. And it's actually only complicated because of this. If def here, which distinguishes the cases where you have blocking literals in which not, right. If you don't have any blocking literal, then nothing has to be done.
04:10:34.670 - 04:11:22.304, Speaker A: Is this parameter here with the plocking is useless otherwise you put the size there of the clause and the plot. And now comes the sort of important part. Watch the two first literals in the clause, right? So you take just the two first literals and you put them there. This also means there are really no clauses which are unit and there are no clauses which are empty, right? So they're kind of done by global flex. The empty clauses, an inconsistent flick and the uniclose are just like global root assignment. Okay, then you watch like exchange wise, lit zero is the literal for the one, and lit one is the one for literal zero. I guess you get the point.
04:11:22.304 - 04:12:03.960, Speaker A: So this is actually not the complicated part about watches. You just do this for all classes. The real, of course, meat of all this is in the propagate literal function. But before I show that, let me first show you the propagate completely. So the propagate, call it boolean constraint propagation. This just gets to the trail rate and then has, has here a pointer actually to the literals which have already been propagated. And then all literals to the right on the trail stack need to still pre propagate it.
04:12:03.960 - 04:13:09.316, Speaker A: That's what we're doing here in this loop, unless there is a conflict. Okay? And then we get from the trail at this position, this propagate position, we get the literal which needs to be propagated and propagated until we find the conflict and the real complicated and the most important and hotspot function here is this one propagate literal. And yeah, I don't have time to go over all indices, but I want to go briefly over it because it has maybe some interesting aspects you're not aware of. So first of all, something which also pioneered in keysight last year is related to what I already said. For this mode switching, you might really compute the time taken in this propagate rate propagates the hotspot. And because it's the hotspot you can take the effort in that hotspot and use it as a kind of virtual time to make things deterministic. And the simplest way to do this is computing memory accesses.
04:13:09.316 - 04:14:03.424, Speaker A: So that's also what Don Knuth does in his books. He doesn't compute sort of the running time of his algorithm. He uses gigaments like the number of billion memory operations. However, I found this slightly inaccurate for our users here, because many memory accesses, in particular the same cache line, and we're optimizing for that even do not cost much. So what you really want to do is you want to measure these kind of random non cache memory accesses. And here is like what I found, which seems to be reasonably the reason why I think it works reasonably. If I look at the running, the amount of time spent in blocked and switched search, focused and stable search.
04:14:03.424 - 04:15:18.464, Speaker A: If this mode switching is enabled, which is controlled by this ticks, then you really see that it's like almost 50 50. Of course it's not like completely like maybe 40 or something, but it's very close. And that's why this is pretty accurate, I claim at least like in a factor of two. So we'll just take the number of watches and then take the assume watch like cache line size, which is under 28 on most machines, at least on this intel machine. I'm showing this, you divide it by the size of the, of one watch rate, and that gives you rough estimate for, for the number of cache lines you're going to visit when you propagate this particular literal. And this one here is this single dollar sign, right, I mentioned before where you need to go through the, you need to get at least access the beginning pointer of the stack, all right? And then comes the loop. And then you're kind of walking that watch stack.
04:15:18.464 - 04:16:10.704, Speaker A: And by default we keep the watch, something I have not discussed before. But if you kind of propagate and you go into a clause and you figure out, oh, I found a replacement, then of course that literally you started the propagation, which is not watching the clause anymore, and then you need to replace it. In this case, you need to drop the watch, right? Because otherwise you would watch this clause multiple times, more than two times, okay. And because this is default, we just keep it. And now comes the plucking part. So if you have plucking, then you just get out of the watch, the blocking literal, you check its value, and if it's larger, zero, well you can just keep the watch in it, you don't need to access the claws no, other watch. This is a very fast sort of path here in the solar, which as we saw gave sort of 50% speed.
04:16:10.704 - 04:17:07.694, Speaker A: Then the other part is, then we can get the size, as I said, like it would be enough to say okay, it's binary, not, because if it's binary, then we actually don't need to go to the clause at all, because the like in a binary clause, the upper wash literally is clearly the blocking literal. I mean I have to make sure that it's true, but yeah, and then you only need to look at the value. And if it's the other, the blocking literal value is zero. We found the conflict and otherwise you just assign it. Assignment is actually slightly costly. So I put here like $1 and okay, now comes the very expensive part, right? And if blocking is on, then of course the size of the clause is now large clause non binary, otherwise it's clause. But this is the only difference here between blocking and non blocking.
04:17:07.694 - 04:17:44.782, Speaker A: So now we need to access the clause. The first part is here where we access the literals. And I don't have time to explain that what's happening here. But here we are really accessing the first time the cache line in which the clause sits, and most likely this cache line is not in the cache. So because the Sat solver access memory completely randomly and therefore we pay a tick for that. Okay, now we get this other watch, because it might be different from the blocking literal and also check its value. If it's true, we'll also do nothing.
04:17:44.782 - 04:18:25.432, Speaker A: So we just remember that actually. So we're updating the blocking literal with that one because now that one is better because it's like true. And therefore next time we would do this, we might not need to go to pay this tick. All right, now, yeah, this is some normalization codes I want to discuss. But now we're searching for the replacement. So here's the loop over the literals of the clause, right? And we start of course not at the first literal, but at the third one like literals plus two, because this is where we try to find replacement, right. We try to find like 17 swapped with something else.
04:18:25.432 - 04:19:11.328, Speaker A: Okay. And so we just walk this, this, this clause, unless this class is really long, but I don't really check this in addition, then this is really just like already captured by this one tick. And then if the replacement value here is larger than zero, we do the same trick as before. We can just replace the plug and literal and don't need to actually do the swapping. This is pretty tricky and to convince yourself that this is true. Actually, that you, you don't need to update this one, otherwise we're at the watch. Otherwise, well, it could be the replacement value is unassigned.
04:19:11.328 - 04:19:38.276, Speaker A: So that means we found the literal which is unassigned, and we put it as a replacement watch. So we dropped the previous watch, that's this one. Then swap the two. And now I have to watch it. Of course, right, so this is swapping the literal, which for which we started the propagation. This is like watching the replacement. Okay? Otherwise the replacement is false, the present value is false.
04:19:38.276 - 04:20:44.472, Speaker A: So we walked from, starting from three, we walked to the end of the clause, and all the literals are false. Okay, now we check again the value which was the other watch as value. And if that one is actually assault like assigned, then it has to be zero, because we checked the true case already above. Then we found the conflict and report the conflict rate. And then the third, the very final situation is that this other value is now unassigned, right, because the true case was done above where we replaced the plocking literal. And then here was the conflict. And now the last case is where we really assign this literal, this other literal, like the watch, the other watched literal with the, with the clause which has traversed as reason.
04:20:44.472 - 04:21:53.362, Speaker A: Okay, well, because the queue kind of follows the p, we need to keep also this thing, like in case of conflict, where we have an earlier report, still consistent. Okay, so this is in a certain sense, the, I would claim the most technical part in the current version of the silver, but it's really sort of needed, like already, like a 15 year old technology, not like brand new. And therefore, I wanted to show you this in detail. So this brings us to the end of this tutorial. I hope you enjoyed it and you will try some of the source code I presented. It's on GitHub, just for you to remember. There's lots of other material out there on Sat solving, also by me, just gave a tutorial, as I said at the SAT, SMT summer school.
04:21:53.362 - 04:22:33.776, Speaker A: There's a video, also there's a CPIor masterclass, all on my webpage. There are a lot of tutorial slides from previous years, from summer school, etcetera. Of course, there's like sad solvers, like at least a dozen sad solvers, some of them winning competitions. It's my pleasure if you would take some of these and work with them. And also in particular, this last one, which I developed for this occasion, which I continued develop for some more time, which called satch, right, for sad solver. From scratch. So have a look, play with it, and I hope you will have as much fun with sad solving as I did in the past.
04:22:33.776 - 04:22:35.264, Speaker A: Thank you very much. Bye.

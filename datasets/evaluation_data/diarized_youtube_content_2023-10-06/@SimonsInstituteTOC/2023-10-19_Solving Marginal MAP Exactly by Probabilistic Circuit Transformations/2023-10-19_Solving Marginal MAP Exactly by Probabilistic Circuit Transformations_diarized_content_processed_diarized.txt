00:00:01.360 - 00:01:14.722, Speaker A: Theoretically I have shorter talk, so I guess this might work out for the last day of the talk or last talk of the day. Okay, so I wanted to kind of tell you about this paper that we published with Tal and gee last year on exactly solving marginal map. I guess the query marginal map kind of came up a couple times during the workshop. Um, so the particular reason I wanted to kind of tell you about uh, this solver approach is it has slightly a, you know, different flavor than kind of the exact algorithm by like feedforward evaluation that, that we've seen more, more in the workshop. So um, we've already seen this a couple of times, but just to, just to um, make sure that we're all on the same page. So, to define Mars on map, basically the query is that if you have a distribution over set of variables x, we want to find the state to state over those, some set of query variables to maximize the marginal probability. And you could do this with some evidence given optionally.
00:01:14.722 - 00:01:57.644, Speaker A: Doesn't matter too much really. The idea is that the key thing is that you need to maximize some marginal probability. So you need to sum out some latent variables or some hidden variables. Essentially this is kind of, you can think of it as like a two layer of queries. You're trying to compute the map of some marginal distribution. So this makes it in general mp to the PP hard for graphical models, so on. So now um, let's consider the case where our distribution uh, p here is actually given as a probabilistic circuit.
00:01:57.644 - 00:03:36.952, Speaker A: So just to, um, I'm sure this, this is probably like boring for you at this point, but just to make sure we're absolutely all on the same page, right? So if, if we, if the circuit that's given is smooth and decomposable, we know that we can compute marginal probabilities in linear time just by freeboard evaluation. Um, and we can compute marginals for any, you know, arbitrary partial assignments to arbitrary subsets of your, of your variable. And then if we additionally have uh, deterministic sum nodes, then we can also compute um, map or MPE, uh, tractably. So, so if you are trying to maximize over um, all set of variables in your circuit, you can do this tractably with smooth decomposable and deterministic pieces. The problem is even, um, if we can compute marginals and map tractably, so even for smooth decomposable indeterministic circuits, uh, computing, you know, marginal map query is, is still np hard. And the intuition of, of why that is is basically we're trying to maximize, um, over some marginal distribution. So essentially we, we need this, um, we need the, the circuit that's going to represent that marginal distribution to still be deterministic, which is in general not true if you're given some, uh, deterministic circuit.
00:03:36.952 - 00:04:20.630, Speaker A: So how we compute marginals is, for instance, let's say your query variables are just x one and x two. In this circuit, over three variables, how to compute marginals is just to replace all of these leaf nodes that you want to sum out with ones. In this case, they just all get multiplied into one. So they basically just disappear. So in this resulting circuit, now this is no longer, uh, deterministic, right? So, so if you look at this sum node, um, for, uh, a value, you know, of x two. So x, if x two is false, um, both of these inputs to, to that sum node will be non zero. So this is no longer, uh, deterministic.
00:04:20.630 - 00:05:25.170, Speaker A: And we cannot, um, just linear time compute the marginal map query for, for this, uh, query set. Okay, so, um, what can we do? Well, um, we can of course, try to find the, uh, structure constraints, the circuit constraints that will let us compute marginal map in linear time. Right. And we already saw, um, one example of that and Rena's talk, where if you have, you know, and or search with a constraint pseudo tree, basically, if you have all the map variables or query variables appearing at the top of your circuit, um, then you can, you can compute marginal map exactly in linear time. Um, there's slightly general definition that, that basically just says after you marginalize, um, out some variables, the resulting circuit is deterministic. So you can just call that like marginal determinism or q determinism. This is still very hard to enforce.
00:05:25.170 - 00:06:06.874, Speaker A: Um, I think Benji might be telling you more about this on, on Friday. So, so this property also shows up for queries other than, uh, marginal map. Um, the point is to enforce these, uh, constraints because once you enforce them, you can compute this np hard query in linear time. Um, actually trying to do that is hard. Your circuit might, your circuit size might blow up. You may end up with exponential size. And also another point is that if you have a circuit, you enforce this constraint for a particular marginal map query.
00:06:06.874 - 00:06:32.612, Speaker A: And then let's say you want to compute another marginal map for a different set of query variables. Then you need to go through all that process all over again. You have to change your circuit to, to conform to that different constraint. Right. That's, that's very expensive. Um, so another alternative is to keep the circuit as is, and then perform search on top of them. This is an optimization problem.
00:06:32.612 - 00:07:59.890, Speaker A: You can, you can, uh, do, you can perform search. Um, so what, what we, um, looked into is essentially instead of kind of in one go enforcing this hard constraint, we're trying to keep upper and lower bounds on the marginal probability while transforming the circuit iteratively. And in the end we will end up with a circuit that actually, that actually is tractable for marginal map. The kind of catch that's hidden is that you may change the distribution as you're changing the circuit, but the guarantee is that we will not change the marginal map solution. So for this problem, we can actually do this iterative transformation, changing the distributions, because you'll still output the right answer. Okay, so um, as a starting point, let's first look at what the easy way to first get a lower and upper bound for a particular marginal map query. Um, so in, in the search for marginal map paper that I mentioned in the previous slide, there, there's a, essentially an algorithm to get an upper bound on the marginal map through a single feed forward pass.
00:07:59.890 - 00:09:12.314, Speaker A: This is basically the same algorithm, um, that would get you the, the marginal solution if you started with a constrained circuit. Um, if you just run that algorithm on, on a circuit that's actually not tractable for marginal map, what you end up with is an upper bound. And, and I'll actually show you a bit of an example of that later. Um, and then, as for lower bound, because this is a maximization problem, you can just choose any assignment queue and then use its marginal probability as a lower bound. So in practice, for example, you can compute the full assignment mPe, just take the assignments to the query variables, and that tends to work, okay, as a starting lower bound. So the question is, how can we tighten these bounds, right? Starting from these, how can we make them better? And the goal is to tighten the bounds until both they converge to the exact marginal absolution. So that's exactly what we're going to do by transforming the circuit iteratively.
00:09:12.314 - 00:10:21.778, Speaker A: So the main idea that we use to come up with iterative, um, transformation is to notice that, um, when you're computing the marginal map probability, not all parts of the circuit are actually relevant. So what do I mean? Um, let's take this example circuit, and then let's say we're computing this marginal probability, right? So we have a circuit over three variables, uh, computing this marginal probability, uh, given a partial assignment to two variables. So in this case, only the, the circuit that are highlighted in blue is actually relevant. So if you see, um, so all the other ones that are not colored, all the uh, black edges will either, you know, propagate zero or will get multiplied with zero at some point. So it doesn't actually contribute anything to, to this marginal probability. So for example, we're given x one is one, x two is zero. So this one will just evaluate to zero.
00:10:21.778 - 00:11:52.614, Speaker A: So it's not relevant at all. Over here, these may evaluate to something non zero, but then in this side, because x one is given as one, it'll get multiplied with zero. So all of these substitute over here is also irrelevant for this particular partial assignment and for this particular example circuit. It turns out that this assignment that we were looking at is actually the marginal map solution. Which means if we were to get rid of any edge that's not colored, that's any black edge that's not highlighted. If you prune those, it's not going to actually affect your marginal map solution, right? So for example, in an extreme case, if we just look at this blue colored sub circuit and then ask for the marginal map, or ask to compute marginal map, you get back the same answer. So now the question boils down to can we actually efficiently identify which of these edges we can, you can prune, can we identify which of the edges will be, you know, irrelevant for your marginal map solution? So for that, what we're going to do is define a bound on every edge that we say.
00:11:52.614 - 00:13:48.064, Speaker A: If this, okay, let me just go through. So for every edge, what we're going to say is what's the largest marginal probability you can get from an assignment that actually uses that particular edge? Basically for each edge connecting node NC, we're going to define a bound that essentially is an upper bound for a different marginal map query, if you will, where you're trying to maximize the marginal probability over a smaller set of assignments, where that set is defined as just the partial assignments that actually activates the edge, meaning that actually uses, that actually propagate something non zero on that edge. So in the earlier example we were looking at, so this partial assignment that we were looking at appears in this set C for all the edges that are highlighted in blue, and then it will not appear in the other edges that are not highlighted. Another way of looking at it is, let's say we're looking at this set C for just this orange edge here. So we're asking which assignments to variables x one and x two actually activate or uses this edge. In this case that just corresponds to setting x one to one and value of x two can be either. So in this edge we'll have these two partial assignments appearing in that set.
00:13:48.064 - 00:14:48.644, Speaker A: And the, and the goal is to, um, goal is to compute a bound that says um, that will return the um, larger or maximum probability on this edge. So larger, um, marginal probability between these two assignments if we're looking at this particular edge. So if we have such a, such a bound, then given, you know, any lower bound on your marginal map probability, you can say if, if this bound does not exceed that lower, lower bound, you can see if we prune that edge because this just says, you know, this is a lower bound on your solution. And you're saying um, assigned assignments that, assignments that use that edge, um, is not going to have a marginal probability larger than that lower bound, meaning none of those can be a marginal absolution.
00:14:48.764 - 00:14:48.996, Speaker B: Right?
00:14:49.020 - 00:15:59.500, Speaker A: So we can get rid of that edge and we show that um for, um. So if your, if your input is a smooth and decomposable circuit, you can compute these edge bounds for all edges in your circuit, um, in a single feed forward and then a backward pass. So in linear time, give um like a high level idea of, of that, you know, bound algorithm with kind of an example and pictures essentially. Um, also talk about it more formally offline if anyone's interested. But basically what we'll do is first start with the feedforward algorithm that I mentioned that will get you the upper bound on the marginal map solution. And how it works is essentially you identify these. So okay, here the setting is still the same.
00:15:59.500 - 00:16:37.890, Speaker A: So here say the query variables are x one and x two. So now we're going to look at the sum nodes and see which ones are actually queue deterministic. You can just think of them as like a decision node on the query variable. So if so, for any of those some nodes that split on a query variable, what we'll do is actually turn that into a max node. So here we choose the max between these two. That's just 0.9 to the same thing here.
00:16:37.890 - 00:17:08.070, Speaker A: So choose the maximum between the two and then for the other ones it's just business as usual. Compute products and weighted sums. So compute the weighted sum here again and then at the top here. So this is another uh, q determined sum node. This is basically a decision node on x one. So at that point we also um, take the max between here, essentially take the max between 0.93 times 0.6
00:17:08.070 - 00:18:07.770, Speaker A: and 0.84 times 0.4. Okay, so this um, is our starting, uh, upper bound on the marginal map solution. And then now what we'll do is starting from that bound, go backwards. So top down in the circuit, tightening the edge bound. So tightening the edge bound, every time we encounter this q deterministic or decision node on the current variable and sort of the intuition of what the bound is trying to do is um, for example, okay, let me, yeah, for, for example, if you are um, trying to get the edge bound on this or on this edge right here. So the, what this value is trying to um, or what this value will, will give you is essentially imagine um, this sum node only had that edge as an input.
00:18:07.770 - 00:19:28.602, Speaker A: So imagine, you know, this edge didn't exist and then um, say you, you run the same feed forward algorithm to get the upper bound. So in the previous example, the upper bound we chose here was coming from this edge. So if you get rid of that and then run the same upper bound, uh, or feed forward upper bound algorithm, you're going to end up with a, with a smaller value because you're going to propagate a value from another one that was not chosen in the max. So um, so that's kind of the intuition of, of what each of the edge bound is trying to say is if you are forced to use that edge, what would the upper bound have? Have been? And um, kind of the, the key part of the algorithm is instead of actually removing an edge and running the feedforward algorithm and doing that over and over again, we can actually use the cache value from the previous feedforward pass to um, get that edge bound for all edges in one go. So that's really um, all that's happening. So if you don't see a, you know, q deterministic sum, we just kind of propagate the values from, from parent to children. And then down here, you know, do the same thing.
00:19:28.602 - 00:20:31.212, Speaker A: So see um, on, on this edge, you can tighten the bound by essentially um, looking at the cash values and, and doing some subtraction, um, sort of in, you know, in a careful way that this still guarantees you that, that this is an upper bound. If we uh, computed this kind of uh, edge boundaries. And let's say you are using some partial assignment to give you a lower bound on your module map. Now you have the lower bound and then you can look at the circuit and say, oh, so these two bounds have values smaller than the lower bound, I can get rid of it. So make the circuit slightly smaller. Of course, the catch is this backward pass isn't going to prune, you know, every, every edge that you possibly can. So this is not going to, you know, magically solve marginal map in, in one go.
00:20:31.212 - 00:22:03.204, Speaker A: So what we have to do is um, iterate between pruning the edges as much as you can and then um, another transformation called split basically, which is trying to also um, introduce more q deterministic sum nodes, which gives you more opportunity to tighten your bound. And split is nothing but basically channel decomposition or introducing a decision node. So if you're splitting on unvariable x one, you just introduce this decision node on x one and then connect the sub circuits, each of which are kind of conditioned on the two values of x one. So every time you introduce this split at the root node, that's going to tighten your bound. And in this iterative approach we are splitting on one variable at a time. After we split on all of the query variables, then you end up with a, basically you end up with the constraint structure where you have all the map variables at the top of the circuit, which is the case where we know we get the exact marginal map solution. So basically we know the number of iteration is going to be at most the number of query variables you have.
00:22:03.204 - 00:22:46.208, Speaker A: So um, kind of. Of course, you know, this is still solving an, you know, np hard problem, even though in an iterative way. So the catch is every time you do this split, you may double the size of the circuit. Right. Um, but what we saw in, in practice is in a lot of cases, um, pruning actually gets rid of a lot of the parts of the circuit. So even though you may double the size in the next iteration, you may prune a lot of the, um, a lot of parts of the circuit. So then you can, you know, double decrease it again.
00:22:46.208 - 00:23:38.294, Speaker A: Double decrease it again. So this is kind of one example run of, of the iterative solver. And this kind of looks like a typical run, really. Um, so what we see is, you know, here you start with, sorry, something like a little over like 8000. Um, so initially if, when we are doing a lot of splits in the variables, we do see that the circuit size increases, but as we continue and tighten the bound, we can prune more and more parts of the circuit. And at the end what we actually end up with is even smaller than what we started with. And this is, you know, visual representation of what's happening in each iteration is starting from some lower bound and upper bound and iteratively tightening it until we end up at the exact solution.
00:23:38.294 - 00:24:23.944, Speaker A: So, yeah, and so we compared with essentially a search based solver for map and MPE on some networks, which are also smooth and decomposable circuits. And especially on these larger data sets, we saw that the search algorithm couldn't converge. It was essentially timing out and we could solve almost all of those cases, at least on this benchmark. Pruning seems to work well enough to keep the circuit from blowing, going up beyond control.
00:24:29.444 - 00:24:29.996, Speaker B: Okay.
00:24:30.060 - 00:25:18.534, Speaker A: Um, yeah, so I'll conclude there. So essentially, yeah, the main idea was that we can do this iterative circuit transformations going back and forth between pruning and splitting to tighten upper and lower bounds on your module map query. Right. And even though each split might, in the worst case, double the size of the circuit, it seems like, at least in the benchmark that we tried, pruning seems to work pretty effectively, although it would be nice if we can provide any guarantees. This was also using kind of a heuristic that I came up with Sims to make sense intuitively. I just tried. A few seem to work well.
00:25:18.534 - 00:26:26.764, Speaker A: Um, of course, can, can be improved. Um, yeah. And just to mention, I presented this as a marginal map solver. Of course we're starting. You can, you know, give it a non deterministic circuit so you can solve, you know, for example, MPE for some project alerts or marginal map or. Yeah, all, all the same. And maybe one question is, can we actually generalize this approach to get bounds for other queries that also seem to require determinism to compute tractably on a circuit? Also going with the recurring theme of the program, can we, um, you know, generalize, can, can we give it like a semi ring treatment here? I think the, um, one point is that to tighten these bonds, we needed to basically do subtraction to tighten the upper bond going from top to bottom.
00:26:26.764 - 00:26:48.374, Speaker A: Um, but then these values, it's. So it's not exact subtraction we need. It's really, we need to find some value that satisfies some inequality. So maybe like Monis is okay. There are probably like experts who can tell me here. Yeah, I think that's it. Thank you.
00:26:57.274 - 00:27:07.324, Speaker C: Thanks for the talk. In your experiments, we can see that the lower bound stabilizes very quickly. Is it not a fact of the implementation or just the example?
00:27:08.024 - 00:27:40.614, Speaker A: So that's actually an observation that I kept seeing actually quite, quite often. So the lower bound I was using is essentially what I mentioned earlier of computing MPE and then reducing it to the query variable set. That seems to give you a pretty good lower bound at least. Yeah, it does seem to stabilize quite early. I don't have a good explanation for that. I don't know if that happens beyond those benchmarks, but it is actually something we noticed at least on these 20. Thanks.
00:27:44.474 - 00:27:53.254, Speaker B: Yeah, thanks. Nice work. Does this carry over to continuous species as well? Like if I have gaussian leaves or whatnot?
00:27:53.714 - 00:28:42.204, Speaker A: Yeah, so I think if you're given, I think if you're given deterministic circuit, then, then you have like leaves with maybe like truncated support. In that case, I think you can use that to introduce these like q deterministic nodes at the top. So I think you can use those to split. Right. Otherwise I think if you try and split, you. Yeah, I need to think if you run into problems like renormalizing after you like introduce this like truncated, you know, gaussians that didn't occur in your input circuit, but at least for, at least for, if you're starting with a deterministic circuit, I think you can pretty much apply that.
00:28:42.504 - 00:28:49.200, Speaker B: Okay. And if I start with something like gaussian leaves, then it's probably, probably doable, but like a little bit finicky, right?
00:28:49.232 - 00:29:05.764, Speaker A: So, yeah, then you have to like think about like how I'm going to split. Like how do I want to split the support? Because you have to introduce these, you have to introduce some q deterministic, some nodes at some point, right. Because that's the only time you actually tighten the bounds.
00:29:10.624 - 00:29:18.264, Speaker D: Can you say something about the data sets that you are using? Are those graphical models? Are those circuits?
00:29:18.304 - 00:29:46.668, Speaker A: What is the input? So these are all like discrete variable data sets. So the input to the algorithm was basically, we took these data sets and then learned a smooth and decomposable, in this case, actually I think structured decomposable circuit. So we learned circuits. And then from that, you know, starting from the circuit, we run the search and our.
00:29:46.756 - 00:29:48.220, Speaker D: So the input is a circuit.
00:29:48.292 - 00:29:49.560, Speaker A: Input is a circuit, yeah.
00:29:49.692 - 00:30:00.936, Speaker D: And so in the data set, when you are learning the circuit from the data set, do you assume structure or you learn both the structure and the parameters?
00:30:00.960 - 00:30:02.640, Speaker A: We learn both the structure and parameters.
00:30:02.712 - 00:30:19.164, Speaker D: From data and you are guaranteed to have a circuit that will be, it can be in memory, so it's bounded. So if it was a graphical model, not necessarily, you can have this as a starting point, right?
00:30:19.264 - 00:30:43.740, Speaker A: Yeah, that's true. So if you're starting from a graphical model, you know, if you're trying to compile exactly the hard part might be actually getting the circuit. In this case at least you're not compiling to a constrained circuit. So we just need smoothness and decomposability. So we'll be able to compile, you know, more models than if you were, than if you were to try to compile it into like a constrained circuit.
00:30:43.772 - 00:30:43.964, Speaker B: Right.
00:30:44.004 - 00:30:53.672, Speaker D: Okay, thank you. And there are just one more question. When you are comparing with the search algorithm, which search is this something in the literature or you implemented it?
00:30:53.728 - 00:31:11.524, Speaker A: Yeah, this is, this is from like Assam product network literature. So this is a data had different heuristic based search for both, you know, MPE and marginal map on smooth and decomposable PCs. Okay, thank you.
00:31:17.994 - 00:31:47.346, Speaker C: Yes, thanks for the talk. Nice work. My question is, if I understand correctly, you are running a branch and bound. So one of your operations is a branch, the other is a bounding, and then you put them back into circuit, which means you can still do both things, but keep them in a single circuit. My question is why instead of just doing the branch and bound separately and then keep the small circuits reducing as you keep doing the branch and bound.
00:31:47.450 - 00:32:12.258, Speaker A: So we're not explicitly doing branch and bound, if you will. So it's a little weird to think about, but. So by splitting and then introducing another like split node at the root and so on, we're kind of almost like building a search tree, like bottom up, if you will. So what you end up with at the end. Yeah, you do end up with something that looks like a search tree, but we're not really explicitly doing something is very explicit.
00:32:12.346 - 00:32:33.864, Speaker C: I mean, this is just a branch and bound. Right. Because you keep the two new circuits. So my question is why to put back in the circuit instead of keeping them separately and let's say, kill them to process. My question is, isn't the same, or you're getting something by keeping them into a single model?
00:32:34.284 - 00:32:40.212, Speaker A: I think what sort?
00:32:40.378 - 00:32:42.064, Speaker C: I might be missing something we can.
00:32:42.184 - 00:32:59.680, Speaker A: Yeah, I think what we introduced, there's a split. Split nodes we introduced at the top, though. The ones that we introduced. I. I mean, really, the main thing is sometimes down here. Yeah. Down.
00:32:59.680 - 00:33:18.144, Speaker A: Then down in the sub circuits, you may have like shared sub circuits, right. So you don't have to like keep track of different. This is like keeping track of different branches in parallel, but also with like shared substrate. That makes sense. Yeah.
00:33:21.244 - 00:33:35.684, Speaker B: A quick one. Have you tried also comparison against the PSDD with the constraint and the v three? And. And if so that the problem is that the, the circuit becomes too large or just perform poorly.
00:33:37.624 - 00:34:07.556, Speaker A: Yeah, usually the problem is that it does become too large for, I mean, if we're learning, we can give it a. Yeah, yeah. You can give it a constrained retreat. But then, I mean, so in the learning part, then usually the issue is that you end up with something that's like less expressive, you don't get. You get like lower likelihood on the particular data if you're learning, and then if you're trying to compile, then of course. Yeah. The compilation part, just for my understanding.
00:34:07.580 - 00:34:32.133, Speaker B: But the constraint is like the, the q variables are on one side and the other variable says something like that. Okay, other questions. Yeah, so following on renaissance question. So what are the queries? Do? Just solve m map for each variable. So for your experiments, what are the queries?
00:34:32.513 - 00:35:01.024, Speaker A: Oh, for these, yeah. So here, basically, this is kind of the percentage of query hidden and evidence. Query evidence and hidden variables that we have. So according to those percentages, we kind of randomly sample. So, for example, we'll randomly sample like 30% of the variables as the query variables. So these are on, you know, average, on some random instances of marginal cost.
00:35:01.324 - 00:35:05.388, Speaker B: And what happened for that case that you didn't finish? I see there's a nine out of a bunch of.
00:35:05.436 - 00:35:13.132, Speaker A: There. There are a few that we couldn't finish. Yeah. So, so there, what's happening is really the circuit does blow up.
00:35:13.228 - 00:35:27.124, Speaker B: I see. Any other questions? I actually have a question. I think, like the crucial step is identifying the q deterministic cell nodes, right?
00:35:28.144 - 00:35:57.094, Speaker A: So we kind, I mean, so partially we kind of cheat that. We are like introducing these decision nodes at the top, and at the bottom we have something that can essentially find not all q deterministic, but some q deterministic nodes, even though maybe they're not, you know, exactly decision nodes. So you have something in between that's actually, you can, you can, um, do a first, you know, pre linear time pre processing to designate those nodes.
00:35:57.914 - 00:36:00.654, Speaker B: I assume that is somehow easy to do, right?
00:36:01.274 - 00:36:23.498, Speaker A: Um, yeah, I mean, if there are decision nodes, then we can definitely find them pretty easily, and then you can find some extra ones. But yeah, if you, if your circuit is such that it's very hard to find any q determining signal, then what happens is, until you introduce, until you do enough splits, you basically wouldn't prune anything.
00:36:23.666 - 00:36:29.634, Speaker B: Right. Okay, questions.

00:00:00.240 - 00:01:11.988, Speaker A: Thanks for staying for the final talk. So, I'm Jakob Nordstrom, the University of Copenhagen, Lund University, and I'm going to talk about pseudoboolean solving as something sitting right in between SaT solving and integer linear programming. So what is pseudo Boolean solving? Maybe the first question, apart from being a cool name. Well, as a theoretician I would call this is just a function over the Boolean hypercube, and they have, they're well studied in operations research in interlinear programming. So we are going to be interested in when these pseudo boolean functions are linear functions, and that is enough to express a lot of if you think of your favorite np complete problems, then chances are actually that it can be expressed in linear pseudo Boolean form. And I should say right away that what you'll get now is like a condensed version of mostly a condensed version of what I did during the summer's bootcamp. So you can view this as a teaser for going to that tutorial and listening to more of the details there.
00:01:11.988 - 00:02:22.684, Speaker A: But I'll add some new twists, I guess, especially towards the end, just to convince you that you should stay anyway. So why do we want to do sudo Boolean constraints? So one reason is that it's a much richer format than the CNF format that sat solvers use. I mean, just to say, if out of six variables you want to say that three are true, that's just one cardinality constraint, as opposed to this mouthful of clauses where it's even hard to see that I didn't do a bug somewhere. I think in earlier versions of these slides I even had bugs and I didn't even see them. And in addition, once you move over to sudo Boolean constraints, it turns out that you actually have stronger methods of reasoning than the resolution method that underlies CDCL. But the bonus is that you're still close enough to sat to look at all the cool ideas that have appeared in sat solving, and you could try to port them to this pseudo boolean setting. Plus, since you have a zero one integer linear program, and there are lots of interesting ideas in the mixed integer linear programming community, you can try to take ideas from there as well.
00:02:22.684 - 00:03:36.132, Speaker A: Okay, so just to make clear we're on the same page, so suitable. And constraints then will be linear constraints for the rest of this talk where I have integer coefficients, an integer constant term literals, that's just variables or negated variables that take values, true or false. So one or zero. And in general, in a suitable constraint you could have any way of comparing them, but we will focus on it won't be too important for the talk, but it's kind of nice when you describe how you reason with pseudo boolean constraints and when you implement algorithms to use what's called normalized form, where all of these coefficients and the constant terminal non negative integers. And the reason that you can do this without loss of generality is that if you have a negative coefficient for xi, you just switch to not xi instead. And in this normalized setting, the constant term is known as the degree or the degree of falsity. Okay, so just to make sure, again, continue our discussion to make sure we're on the same page.
00:03:36.132 - 00:04:43.720, Speaker A: So if you have a clauses in CNF, those are just special cases of pseudo Boolean constraints, because you just sum up the literals and want at least one of them to be true. And then we saw that cardinality constraints is an example of a more general class of constraints. And then you can go wild and have arbitrary coefficients like this constraint, which is like a general pseudo boolean constraint. And another thing that is nice with sudo Boolean constraints is that you can express a lot of things staying inside this formalism. For instance, sometimes it's useful to have a variable encode the truth value of a constraint, say that I want z to be true precisely when this constraint holds. So the nice thing is that this also I can write as a pair of pseudoboolean constraints, and I won't go too much into the details, but you can see that just the first line is the easiest one to see here, that this says that if z is true, this forces, indeed forces this constraint to be true. And then if you look at the second line and you think a bit more, then you realize that z false, will actually force this constraint to be false.
00:04:43.720 - 00:05:35.804, Speaker A: So Sudo Boolean constraints are expressive and nice to work with, and what? So the input that we have are then Sudo Boolean formulas, just conjunctions of such constraints. And then we have two problems that I want to discuss with you. And one is just the satisfiability problem, but ported to sudo Boolean to a pseudo Boolean setting. So this is pseudo Boolean solving. You get a collection of pseudo Boolean constraints and you want to know whether they are satisfiable or whether they're feasible. But another bonus with going to pseudo Boolean form is that you can express optimization problems in a nice and natural way. So you can also have some linear combination of literals weighted by some coefficients wi and that you want to minimize, say without loss of generality.
00:05:35.804 - 00:06:39.594, Speaker A: So then the problem becomes that you want to find a satisfying assignment to f, and among all such assignments you want to minimize the objective. So that's the setting, that's the problem that we want to understand. And so what I'm going to tell you a little bit about is how you can do this by using so called sudo boolean solvers. And I'll then also try to discuss how you can borrow ideas from the SAT side, in particular from Max Sat solving and also from mixed integer linear programming. And this is again going to be like more of a brief overview talk or a sales pitch that I think this is something that might be interesting to look more into. And so I'll try to give you some pointers and there are some, some literature references on the slides and they are all available at the end of the slides, which I assume might be somewhere on the Simon's web page later. Or if not, then they will be on my web pages.
00:06:39.594 - 00:07:40.414, Speaker A: Okay, so what do you do if you get a sudo boolean formula? Well, one thing that you can do, since you know and love conflict driven clause running solvers, you just rewrite your sudo boolean constraints to conjunct in normal form and run your favorite set solver. This is one thing you can do. Another approach, which is the one that I've been working more on, is in one sense you want to stay with conflict driven closed learning, but you port your input from Sudo Boolean to CNF. I want to go in the other direction. Mostly I want to stay with the Sudo Boolean format and I want to portray CDCL to a sudo Boolean setting. And in particular I think there are two solvers that are being actively developed that I know of that are following this approach. And this is sat for J by the team in France and then rounding Sat, which is being developed by our group.
00:07:40.414 - 00:08:37.032, Speaker A: So okay, how do you do it? How does CDCL based pseudo Boolean solving work? Well, it's being used because it turns out that it's often a very competitive approach. And sadly, I have to say from the point of view of so called native Sudo Boolean solving, the CDCL based approaches sometimes just beat the crap out of us. And it's interesting to understand why, and I don't fully understand why. So that's an interesting research question. But you can, I mean, it can be noted that when you rewrite the pseudo boolean formula to CNF, then you're introducing extension variables. And these extension variables, they mean interesting things and they, so they give you a lot of extra power. And that means that if you have a disjunction over such extension variables, then actually that encodes some kind of polytope if you look at the original problem.
00:08:37.032 - 00:09:55.774, Speaker A: So in some sense that we don't really understand it, it gives you a way of doing fairly powerful reasoning just because the variables mean things that you couldn't speak about before in a sudo Boolean solver because there was no variable for this thing. However, in order for this to work, you really want your formula to be encoded in a nice way. So for instance, if I'm evil and I try to permute the variables and the constraints so that they come in a not so natural order, then it seems that the CDCL based approaches take a huge hit in performance. And also for some problems, like say, if you're working on pigeonhole principle formulas, you just have the basic fact that no encoding into CNF can compensate for the fact that CDCL based reasoning is exponentially weaker than pseudo Boolean reasoning for such formulas. And this you can also see sometimes. But there are, I think, a lot of interesting problems. One interesting problem is when you're doing the rewriting, how do you rewrite to CNF in the best possible way? There is a lot of research on this, a lot of different encodings.
00:09:55.774 - 00:11:16.000, Speaker A: I don't think we really understand from a rigorous point of view which encodings are good or bad. Another interesting question is how would you, I'd like to understand better how the CDCL based approaches compare to the cutting planes based approaches that I'm going to discuss briefly next. In particular, they seem to be somewhat complementary, and it would be nice to, well, on the one hand, to theoretically understand what's going on. For instance, could we somehow pin down how helpful these new auxiliary variables are? This I don't understand. And also, I mean, if, if the CDCL based approach is sometimes good, and the cutting planes based approach is sometimes good, then why don't we try to build a solver that somehow tries to do both and get the best of both worlds? I think this would be a nice thing to do. Okay, so moving on to Sudo Boolean conflict driven search. So this is now when I want to keep my input in sudo boolean form, but I want to do like the conflict driven search and learning, because I've seen how good that is in sat solving.
00:11:16.000 - 00:12:16.166, Speaker A: So do the same thing as in CDCL, but using cutting planes instead of the resolution proof system and operating on pseudo boolean constraints rather than clauses. So what do I mean by the same thing? Well, we would have the same setup where there is this cycle of assigning, deciding on variables and then making obvious propagations. So you have a decision propagation cycle, and there's a natural way of generalizing what it means for a sudo Boolean constraint to propagate. And right, if a pseudo boolean constraints will be violated unless I set x to true, then that means that this pseudo Boolean constraint propagate x to true. So I do this decision propagation cycle until I hit the conflict, which is a violated constraint. And then what I want to do is I want to look at all of my propagations that I've made that led to this conflict. I want to look at these constraints and then I want to do conflict analysis and learn a new constraint.
00:12:16.166 - 00:12:56.450, Speaker A: But this constraint is going to be pseudoboolean and I'm going to have to use some other form of reasoning than a resolution to do it. And the reasoning that we're going to use is cutting planes. So cutting planes, like traditional cutting planes, is this so that we know that all literals are non negative and then we know that we can take positive linear combinations. So Ca and Cb are positive numbers here. And then you have this division rule which just says that. And here I'm using that the constraint is written in normalized form, that all of these coefficients are positive. Then I can just divide by a c and roundup everywhere.
00:12:56.450 - 00:13:26.914, Speaker A: So this is like how cutting planes is presented in the proof complexity literature. Going back to cook et al. But then if you're doing solving, you also want to use the saturation rule. And maybe saturation is easier to see by an example. Also division by an example. So suppose, suppose I have this constraint x plus two, y plus four z greater or equal three. Then if I divide by two and round up everywhere, then I get x plus y plus two z greater or equal to.
00:13:26.914 - 00:14:04.378, Speaker A: So this is what division does, what saturation does, it says. Well, I mean if this constraint is satisfied, then having the coefficient four here is clearly overdoing it. Actually three is enough. So if this constraint x plus two y plus four z greater greater equals three holds, then the same constraint with three z instead also holds. Both of these rules, importantly are using that we know that the variables are integers. So this is like the rest of the rules. This is just linear programming basically.
00:14:04.378 - 00:14:50.674, Speaker A: But here you have the boolean rules. And it's nice to have boolean rules if we're going to solve boolean problems. So, but doing the same thing, just, but just with pseudo Boolean constraint. That's opening a can of worms. And I think this is like an area where we could really use more research. One the first annoying problem is that if you take this fancy pseudo boolean solver but you feed it a CNF formula in the proper pseudo boolean encoding, then everything just collapses to CDCL but with very, very expensive data structures. And this is a major weakness as I see it, something that has been proposed is to try to rewrite your input and see if it could be rewritten to, for instance, cardinality constraints in a better way.
00:14:50.674 - 00:15:35.284, Speaker A: And this has been implemented, but it's not actually yet good enough to be used in practice. So you really, so one thing, if you're going to use a sudo boolean solver, you have to pay attention to your encoding. Don't use the CNF encoding. If your problem is really a CNF problem, then you probably shouldn't be using a sudo boolean solver. Another problem is that even if you get a nice encoding, we do have examples of where you have zero one integer linear programs where even the linear relaxation is infeasible. So you don't need any boolean reasoning to decide that there is no solution. I mean, just, just linear programming is enough.
00:15:35.284 - 00:16:14.670, Speaker A: And this should be very easy for cutting planes reasoning. And still solvers take forever. This is another very annoying factory. A third area of possible improvement is that preprocessing is something that is very important in sat solving. It's also being used in interlinear programming, but so far the pseudoboolean solvers don't really have it. And this is probably another source of possible improvement. So these are like, I guess saying that I believe there is quite a bit of low hanging fruit where you can take insights from either sat solving or interlinear programming.
00:16:14.670 - 00:17:10.440, Speaker A: And if you just implement it, then probably sudo boolean solvers would become much better. Another interesting question is that it turns out that when you're doing this conflict analysis on pseudo boolean constraints, then many degrees of freedom arise. And again, going into details would take a lot of time. So I have to refer you to the tutorial, but there are a lot of like scenarios that a lot of choices that you just didn't have before in CDCL, but with suitable Boolean constraints you do. For instance, I mean in CDCL you're going to do your conflict analysis with resolution, period. But in a sudo Boolean setting you could use maybe division, maybe saturation, maybe combining them, maybe doing something else you can massage your pseudo boolean constraints and simplify them in different ways. When you finally decide to learn a constraint, it can be asserting at several different levels.
00:17:10.440 - 00:18:05.804, Speaker A: So how far should you back jump? Another thing is, since the coefficients are integers, what kind of precision do you want? Do you want to stay in fixed precision and round when you're overflowing? Do you want to be in arbitrary precision? And just such a basic question of what is a good learn constraint. What is a strong constraint for a clause? This is in some sense obvious. The fewer literals you have in a clause, the stronger it is. But for a pseudo Boolean constraint, it's like at least two dimensional. On the one hand you have how many variables it involves, but the question is also how the coefficients relate to the degree of falsity. And so you could be in a scenario where you can learn several incomparable constraints, and we don't have a good sense of which one is the best one. And there are also interesting theoretical questions about understanding different subsystem of cutting planes.
00:18:05.804 - 00:19:25.590, Speaker A: For instance, how does cutting planes with division compare to cutting planes using saturation? Lots of room for, for improving our understanding there. But still, I mean this, these solvers do work well in the sense that there are a lot of if you have a decision problem, and if it's natural to encode in pseudo Boolean form, then we do have lots of examples where pseudo boolean solvers are clearly stronger than CDCL solvers. Not just pigeonhole principle formulas would be like the obvious toy example, but also lots of other examples. Going further, from decision problems to optimization problems, we can borrow ideas from Max sat. So one obvious way to do optimization is just linear search. So you run your solver and you want to minimize this objective function, say sum of wi li for literature. Just run the solver, find a solution, and then you add a constraint saying now I want something better, I want something smaller than what you found, and run the solver again and keep going until the formula is unsatisfiable, at which point you know you found an optimal solution.
00:19:25.590 - 00:20:07.018, Speaker A: This is like simple, but it works reasonably well. In particular, you can often get a decent solution quickly, which might be interesting in applied scenarios where you actually not interested in solving to optimality. But maybe you have limited time and you want some decent solution quickly. And linear search can be good. But of course the downside is that you don't know how good your solution is, because you have no idea of what the matching lower bound might be. Another interesting idea also from Max Sat is like the dual is to do core guided search. So now you say, okay, here's my objective, let's be optimistic.
00:20:07.018 - 00:20:40.094, Speaker A: The best possible scenario here would be that it's possible to set all literals to zero, that we give the minimum zero. I'm assuming again here that all the WI's are non negative. So I'll just assume this. I'll run my solver with assumptions. So pre made decisions for setting the whole objective function to zero. And now one or two things can happen. Either this works out, and then I've clearly found the optimal solution, or it doesn't, and then I learn the reason why that, you know, maybe some collection of, of these literals, at least a of them have to be true.
00:20:40.094 - 00:21:43.794, Speaker A: And then I can use this to update my estimate of what the best possible solution is. And I can actually also rewrite the objective function by introducing new variables and run from the top again and keep going until I find an optimal solution, which will be when my, when in my rewritten objective function, I can set everything to zero. Then I know I have the optimal value, and then I have sort of computed how much I changed my objective during this rewriting. So this means that I work with lower bounds, and it can. Turns out that it can be helpful to get good lower bounds, because this helps to cut off the search space. You know, it cuts off places where there's no reason to go. The downside is obviously that you don't find a solution until you have the optimal solution, and you don't know for that reason, you don't know how good your lower bound is.
00:21:43.794 - 00:22:42.392, Speaker A: So then what if we try to combine linear search and core guided search? Wouldn't that be nice? And it turns out that, yes, it would be. And the nice thing compared to Maxsat is that this is much, much cleaner and simpler to do in a sudo Boolean setting. So, this is something that we did and had in AAA just a few weeks ago. So here for comparison, here are two good sudo boolean solvers, sats, four J, and then the CDCL based solver, Napps. And here are different versions, different combinations of sudo Boolean solving with core guided search and linear search interleaved. And if you compare, like, these rows and the rows down here, you can see that there are overall, like, significant improvements. Sadly, however, we're not beating the academic MIP solver skip.
00:22:42.392 - 00:23:36.060, Speaker A: I'll get back to that in a minute. So, what's up with MIP solvers? So, MIP solvers actually solve a much more general problem. So then you have, some of the variables will be integral and not necessarily boolean, and other variables will be real valued, except as a special case. If you don't have any real valued variables, then you have an integer linear program. And if in addition all of these variables are bounded between zero and one, then you have a zero one integer linear program, which is just another name for the pseudo boolean formulas that we started with. And if you want to do pseudoboolean solving, then you just do you give a vacuous objective function. But it turns out that MIP solvers are not so good for decision problems.
00:23:36.060 - 00:24:48.764, Speaker A: They somehow, they really use the objective function heavily to guide the search. So we actually have, it's not so hard to find decision problems where Sudo Boolean solvers will beat MIP solvers, but finding optimization problems where Sudo Boolean solvers are better, that is not so easy. So what MIP solvers do is, again, they have, as I already said, they have preprocessing, which is important. And then they work by not trying to find Boolean solutions, but instead they relax the problem solve linear programming relaxations, and then try to use that to store information about how good or bad the solution can be. And then they use something that's called branch and bound, and they also derive new integer linear inequalities that rule out solutions to the relaxation that are not integral. And this is something that's called branch and cut. And then you combine this with lots and lots of heuristics.
00:24:48.764 - 00:25:34.014, Speaker A: Okay? So if you compare to sudo Boolean solvers, pseudo boolean solvers have really good conflict analysis. But as I already mentioned, they are not great. Even on some problems where the LP relaxation is infeasible, they still run forever. This is a scenario where MIP solvers would terminate immediately because they solve just in the very first root node. They solve the LP relaxation, they see that it's infeasible, they terminate immediately. Okay, so mixed integer linear programming solvers have powerful search. They use the LP relaxations, they have lots of different ways of adding constraints, but when you show infeasibility, then they basically just backtrack.
00:25:34.014 - 00:26:36.864, Speaker A: So this suggests that why don't we try to get the best of both worlds? We use the powerful search of MIP and then the sophisticated conflict analysis of pseudo boolean solvers. Okay, this sounds great. It's easier said than done, but we have done this. So what we did, we took our solver roundingsat and integrated it with the LP solver soplex from this MIP solverskip, and then you can add different bells and whistles. You can also take these Gomorrah cuts that are computed to rule out LP relaxation solutions. You can also ask the sudo boolean solver to share the constraints that it learns during conflict analysis to send them to the LP solver. And when we run this on knapsack problems, then we see that all of these techniques here is the base rounding sat, and all of these techniques really make the solver significantly better, although we're still not beating scip.
00:26:36.864 - 00:27:37.374, Speaker A: But in fairness, it should be said also that MIP solvers have a lot of special purpose methods to detect and solve knapsack constraints with, for instance, dynamic programming. We don't do that, we're just running our standard conflict driven search here. Let's compare to some other benchmarks. So if we look at the sudo boolean competition benchmarks, decision and optimization instances, and some Miplib instances, again, decision and optimization problems, then, well, I guess we don't get the performance that we were hoping for. But at least the hybrid solver is always second best. So like, if you had to pick one solver, then you shouldn't pick the pseudo boolean solver, you shouldn't pick the MIP solver, you should pick our hybrid because it's always like reasonably good. Although it would have been nicer if it, I mean, clearly you could also make the argument that if you care about optimization, then still it seems like MIP solvers are winning.
00:27:37.374 - 00:28:54.580, Speaker A: So, but this is, I think it's before we conclude from this that sudo boolean solvers are hopeless, it should be noted that there's been like tons and tons of manures invested in coding up fine tuning MIP solvers. There are huge industrial solvers, and pseudo Boolean solving is really, in comparison, not at all that well explored. So I would argue that the fact that you can get this good results with so limited effort, to me this shows that I think pseudo Boolean solvers is something we should look more deeply into. And there are lots of interesting problems one could look at how to interact between the linear programming solver and the PB solver, how to make the pseudo boolean solver use information from the LP relaxations, for instance, that we don't do. I already mentioned that. Why don't we use preprocessing? In particular, we could take the MIP presolving techniques that work in a pseudo boolean setting and tag them on. So this is, you have to be a little bit careful, because some MIPs solving techniques will change zero one integer linear programming problems into other types of problems.
00:28:54.580 - 00:29:47.384, Speaker A: But it should be possible to deal with this. Another interesting fact is that you have a wide, like a rich library of different cut rules that you could, in principle plug into sudo Boolean conflict analysis and see if something better pops out. This is something that I really would like to do. And now this is like, ends where I was in my tutorial, and after the tutorial, during the boot camp, I basically got questions saying that, nice. But, you know, why would any sane person actually do sudo Boolean solving? So then I realized that I was maybe underselling a little bit. So I want, you know, for fairness sake, I want to balance the picture and say that there are in fact applications where already sudo Boolean solvers are outperforming even commercial mip solvers. You just take a standard pseudo boolean solver off the shelf and, for instance, for problems like arithmetic circuit verification, it turns out that pseudo boolean solvers are state of the art.
00:29:47.384 - 00:30:40.284, Speaker A: Some people in Glasgow matching, doing some kind of matching problems for children with adopted families, apparently they take the same problems and they run our solver instead. It's order of magnitude better than the MIP solvers. They used another nice application area, which might be interesting for people who work on this, neural networks, in particular, binarized neural networks. The issue with those is you get a lot of reified constraints for the activation functions, and those are really, they're really killing MIP solvers, because when you relax them, they get very uninformative. But pseudoboolean solvers deal really nicely with these reified constraints. So again, we see, like, just off the shelf order magnitude performance and improvement compared to MIP. Okay, so this concludes my sales pitch.
00:30:40.284 - 00:31:37.960, Speaker A: So, I guess what I wanted to say is, sudo Boolean optimization is it's an expressive and powerful framework, but it's close enough to sat that you can use all your favorite ideas from SAT. You can use ideas from Max sat in some sense. It can be argued that Max Sat and Sudobool and optimization are just two different ways of describing the same problem. I believe that we have not. We're very far from exploiting the full power of cutting planes, which is exponentially stronger than what the reasoning that we're using on the SAT side. And I also do believe that we could use a lot of the insights from the mixed integer linear programming literature. And there are certainly, I mean, we're not where we would like to be in terms of performance, because of course we would like to beat the competition, all of them, including the MIP solvers, and we don't.
00:31:37.960 - 00:32:11.172, Speaker A: There are a lot of interesting challenges for how to design the algorithms. Also, efficient implementation is a huge challenge. Like a question like how to propagate sudo Boolean constraints is much more costly than propagating clauses. And this is really slowing down solvers. Also, different reasoning methods. We just don't understand them as well as we understand the resolution proof system underlying CDCL. But we already know that there are applications where off the shelf cutting planes based solvers are beating the competition.
00:32:11.172 - 00:32:26.734, Speaker A: So if you're looking at, for instance, binarized neural networks or something, maybe you should take a look at a sudo Boolean solver and see if it can do some, anything for you. So that's it.
00:32:28.034 - 00:33:18.804, Speaker B: Thank you, Jacob. So I'll take the first question. So for resolution is a perfect fit for CDCL, because we know that if you have a set of clauses, you want to eliminate a variable, then you need to, what you do is exactly resolution. So resolution is equivalent to quantifier elimination or variable elimination. What is the corresponding statement? If I have a bunch of pseudo boolean constraints, I want to do variable elimination. Do we have the same kind of a theorem that will give us the same result that do we have an algorithm? It does give us an algorithm to eliminate variables, cutting planes, saturations, division and saturation.
00:33:23.384 - 00:33:27.764, Speaker A: I'm not sure, I mean, my question clear.
00:33:29.784 - 00:33:52.594, Speaker B: I have a set of pseudo Boolean constraints and I want to eliminate a variable and get the exist x such that a set of suitable I want. Can I represent it, for example, by sort of pseudo Boolean constraints, even is the projection through the Boolean? I suppose so, but I've never seen the theorem that would state what exactly is the projection operation?
00:33:53.814 - 00:34:18.096, Speaker A: I mean, I think the answer is yes, but I'm not sure. It's very interesting. I mean, it's definitely a complete method, right? So you can, you can like eliminate in some sense. I think you could do like the analogue of Davis Putnam resolution, but I haven't thought about it in that way, and I don't know, I'm afraid I might not have a good answer. I mean, maybe someone from the audience would have a good answer.
00:34:18.280 - 00:34:28.952, Speaker B: So this is a theoretical result because it's important, because it tells us that the right thing to do when you have a conflict is to generate the conflict clause and it is the resolution.
00:34:29.008 - 00:34:30.088, Speaker A: So it gives us also a tight.
00:34:30.136 - 00:34:56.384, Speaker B: Connection between what CDCL does and, you know, we have a theorem that connects directly to proof complexity. Okay. We said it generates basically if you have CDCL plus restart, it gives you and it fails. The resolution proof is going to be of size linear, or same size essentially as the search tree. Do we have the same kind of theoretical foundations here?
00:34:57.244 - 00:35:40.264, Speaker A: To some extent, yes, to some extent. I mean, it's definitely the case that if you look at what the pseudobula solars are doing, they will spit out cutting planes proofs in exactly the same way as a CDCL solver produces a resolution proof. And this is a complete method. So one big difference is that for CDCL, we have the theoretical result saying that assuming that your heuristics are somehow magically optimal, then conflict driven clause learning with restarts is never more than polynomially worse than resolution. So CDCL searches efficiently for resolution proofs. This is false. In a pseudo boolean setting, we are not searching efficiently for coming planes proofs.
00:35:41.204 - 00:35:50.384, Speaker B: Okay, that's important insight. Thank you. Other questions? Are there any questions on the charts? Let me check the chat.
00:35:52.964 - 00:35:54.144, Speaker C: Yeah, I have one.
00:35:54.524 - 00:35:55.284, Speaker A: Yeah.
00:35:55.444 - 00:36:22.904, Speaker C: So this MiP, you see, it looks to me like, look ahead, right? Like the thing what marine was explaining. You spend lots of time in every search node, and the, of course, your PB solver does the opposite. It's more like CD cells. So the obvious question is, of course, like, just do what we did right, with this cubing conquer. But for PB. And related to that, are there incremental PB solvers? Because this is something where we need to, for this cubing conquer. Actually.
00:36:25.564 - 00:37:22.924, Speaker A: You mean incremental? I think that the answer is that all that needs to be done in that setting could be done, but maybe it isn't as well developed in the sense of having a standard library or API for how to do this. And this is probably something that we should do. Yeah, I think it's interesting to note, like, the parallels with marines talk as I was listening to it. It's very similar in philosophy, but it's slightly different in the. So one thing that, I mean, also, MIP soloists would have this kind of thing where they probe variables and collect statistics. I think they call this strong branching, except that they actually consider this to be too expensive, I think. So they do this strong branching at the start, but then when you've been running for a while, they collect statistics of how, how this branching worked out.
00:37:22.924 - 00:38:19.856, Speaker A: And based on this, they make estimates of what's going to happen in the future. And this is something that they call sudo costs. So this is like an interesting question, whether you would do look ahead solving and not do full probing, but sort of do intelligent guesses based on how things have been performing previously. That would be porting MIP techniques into look ahead, but I don't know how expensive the look ahead step is. And then another thing that is nice, I mean, I think there's a lot of questions to explore at the interface of pseudo Boolean solving and MiP solving. But the fact that you can, when you find a solution, but it's like you relax the problem, you find a rational solution that you can add a new cut, which is a sound constraint that cuts away this rational solution and so tightens your polytope. This is important.
00:38:19.856 - 00:39:01.424, Speaker A: And this, we see that, as I showed in some of the experiments, this can really improve, this can really improve performance. Another thing that can improve performance is when we're somewhere in the middle of the search and we're asking the LP solver. So the pseudo Boolean solver cannot see the contradiction, but the residual LP is already infeasible. In that case, a Mip solver can help us by seeing a, that it is infeasible and B, by Farkas Lemma, it returns a conflict constraint so that we can like, you know, fast forward the conflict analysis. And this turns out to be, these constraints are apparently like super useful. So, but it's an interesting question.
00:39:01.844 - 00:39:10.004, Speaker C: Yeah, I don't your experiments look like you would import like a MIP technology into PB solver. Right. But this tubing conquer turns it around.
00:39:10.084 - 00:39:10.300, Speaker A: Right.
00:39:10.332 - 00:39:16.404, Speaker C: So you would use a PB mIP approach and then one point switch to BB. What I'm asking.
00:39:16.564 - 00:40:10.184, Speaker A: Yeah, that's, yeah, that's interesting. I think so one problem has been to explain how Sudo Boolean conflict analysis works and the fact that it is exponentially more powerful. This is somehow a message that is hard to get across, but I think it's slowly sinking in and that it's more like, I think there are people on the MIP side that would like to do sudo boolean conflict analysis, but the question is whether it will happen. Because there's, you know, I mean, there's so many interesting questions to pursue, but yeah, that's definitely like taking, what we have done is like the mips, the PB solver is clearly the master and the LP solver is the slave. You could turn this relationship around and let the conflict analysis be the slave. Yeah, this is definitely something that I'd like to do.
00:40:11.144 - 00:40:12.724, Speaker B: Miguel, do you have a question?
00:40:19.104 - 00:41:09.984, Speaker A: So this is this approach, similar to sat modulo integer linear arithmetic in the SMT setting? Yes and no. I think it's stronger in the sense that since we're operating on the linear constraint, I think in an SMT setting, you would be restricted to deriving facts that you can express in the variables that you have. You have variables that mean certain things, and you can derive facts about those. But now, when we are massaging our linear constraints, we'll generate tons and tons of new linear constraints. So, like, in an SMT setting, this would correspond to, I guess, you know, generating a lot of extension variables, which I don't think the SMT solvers do. So in that sense, I think it's slightly orthogonal.
00:41:12.004 - 00:41:13.624, Speaker B: Thomas, do you have a question?
00:41:20.804 - 00:42:24.364, Speaker A: If someone decides to encode a given pseudo boolean formula into CNF, is there any known worst case upper bounds? Regarding spa, there are lots of results on how to do this. Yeah, I mean, you can do it efficiently. There are two parameters that you trade off, the encoding size and the propagation strength. And this has, I mean, there's a, this is a research area, and in the tutorial I have like some, some references for this, but there's still room for, like, the theoretical results don't perfectly match what people actually use in practice, and there's probably room for improvement. Any last question Sibylla asks regarding back jumping, would chronological backtracking similar to chronological CDCL works not jump to any asserting level? In some sense, yes. So we don't know in sudo Boolean solvers that we're back jumping to the right level. So in some sense, all the extra hacks needed to make CDCL work in a chronological setting.
00:42:24.364 - 00:42:35.304, Speaker A: In some sense, I would argue most of them are already there in a pseudo boolean setting, because we already need to deal with these problems. If that's an answer to the question.
00:42:36.884 - 00:42:53.552, Speaker B: Okay, we got all the questions answered. Thank you, Jacob. I think we had a great session on three different approaches to non CDC and solving. So I will close the session. And we didn't even lose power. Some of them must optimize the power appropriately. So close the session.
00:42:53.552 - 00:42:59.856, Speaker B: We'll see you all. Let's thank all the speakers, and we'll see you all next week. Bye.

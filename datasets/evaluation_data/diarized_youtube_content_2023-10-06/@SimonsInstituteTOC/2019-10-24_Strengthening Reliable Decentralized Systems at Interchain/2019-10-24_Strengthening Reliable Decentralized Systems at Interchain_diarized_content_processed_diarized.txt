00:00:04.520 - 00:00:21.914, Speaker A: Hi. I guess I'm supposed to mine the next block now. So this is Joseph Witter, who is an associate professor at Tuy and also works at interchain. And he will be talking about basically the tendermint consensus protocol.
00:00:24.694 - 00:00:41.410, Speaker B: Hello. So I will talk about tendermint. So I'm here for the interchange foundation. And actually we are going to. It's a transition phase soon. Research and development will be called informal systems. We're going to spin out, but for now, it's interchange foundation.
00:00:41.410 - 00:01:26.206, Speaker B: I want to introduce a little bit what we are doing and who we are. So two researchers currently accept me. Work with me is Igor Kornova, who's an expert in computational verification, and Shaku Milosevic, who is an expert in display algorithms and fault tolerance. And so we have the, we have swiss nonprofit foundation, and we support research and development of secure and scalable decentralized applications. And currently we're focusing, and this is why I'm here on Cosmos Network and tendermint. And the question, of course, what does this word mean? So let's start with, with cosmos. So cosmos is our vision of decentralized networks of independent blockchains.
00:01:26.206 - 00:02:23.274, Speaker B: So we don't believe that there should be just survivors in this competition of blockchain, and then everyone should run their business on that. Our view is that every community should have their own blockchain and should live in the cosmos ecosystem, and they should communicate with each other via inter blockchain communication protocols. So it's a little bit like villages, cities and countries. So each blockchain is like a city, and most of the business goes within the city. And sometimes you have to communicate with another city and then sort of discover this inter blockchain communication protocol. And so, as I said, what it said here, it's that should be like tendermint. By this, we mean that basically we do state machine replication in the classic sense, in the fault tolerance.
00:02:23.274 - 00:03:00.420, Speaker B: So it's a strong finality. This is the also the sort of the assumption that lies behind IBC. And so tendermint is this consensus algorithm that runs the core of the system. It is byzantine fault or state machine replication. And it's a modern implementation of classic ideas. Here it says pbft and tl's. So we say PbFT because more people know it.
00:03:00.420 - 00:03:44.344, Speaker B: But the algorithm is closer to the duo Kleinstockmeier consensus algorithm. And if you know the paper, and you should definitely read the paper, it's the authenticated byzantine case. And this algorithm is basically the blueprint for what we are doing. I say it's modern because it's designed to run on a wide area network with big numbers of nodes, which requires us that the communication has to be concept based in order to be efficient. And everything is open source. You can find all the code online. And which is something which is sometimes embarrassing to me is that actually also our technical discussions are online, so we have the development sessions every week.
00:03:44.344 - 00:04:31.063, Speaker B: They are recorded and they are put on YouTube. And then you can see how we say crazy stuff sometimes. So you can follow all our discussions there and all our developments. And since this is here a consensus seminar, I have to have one slide on consensus, and that is it. So this is sort of the idea of tendermint consensus. And this is also why I said it goes dls, because here you don't have sort of this notion of, you know, few change and then broadcast. So what you have, you have, you have someone, the leader proposes a value, then it's checked for validity, then it's pre voted, then we wait for prevotes.
00:04:31.063 - 00:05:37.816, Speaker B: Then depending on how many prevotes we get, you have pre commits. And then depending on what's happened, either if the consensus is not successful, we go to a new round, which means we're going to pick a new leader, or we're going to commit, which means we have generated a new block and we go to the next height and do this again. That we have this notion of rotating coordinator is sort of part of our idea to fairness. So we want that everyone who participates in the protocol has the chance to actively propose the values and has influence on what is going to happen. And therefore we have this, these rotating coordinators, which is weighted over the voting powers. And actually the system is much more complicated than typical figure specific four processes. This is a sketch of how the different roles that we have in tandemint so what we have, we have validators.
00:05:37.816 - 00:06:35.754, Speaker B: Validators are the nodes, typically you see in consensus algorithms that actually participate, that generate new messages, that sign that sign values. And basically all other nodes here are full nodes. They participate in the gossiping and they also follow the state machine, so they receive the messages. When they have received two thirds of certain messages, they do the state transition. But if they are not validators, they're not going to generate messages in the sense that they don't sign messages. The reason why we have here, these validators here, sort of hidden behind the sentry nodes, is because at the end of the day, it's super complicated to be a validator because you need to have your private key on a computer that is online and it's sort of therefore attackable. And sort of one of the ideas is that the validators actually are not talking directly to the outside world, but the hide behind this.
00:06:35.754 - 00:07:28.076, Speaker B: Also, it's not the IP addresses that are known to the protocols, it's just the public keys. So this is part of the security setup that we have. Yeah. The client can then talk to. And then from an architecture viewpoint, the important feature of tendermint is that we have this application blockchain interface. So our view is that every application should run their own blockchain in the idea of being decentralized. But then, of course, when I say every application, I have a very vague view of application, in the sense that also a virtual machine can be an application.
00:07:28.076 - 00:07:58.114, Speaker B: And actually there are several projects that implement different virtual machines on top of tendamint. So there's a virtual machine for ethereum, for move, for pact, for Vosum. I keep forgetting, I think Agorik. So there has one. So we are open. There are many projects that build on top of. And that sort of.
00:07:58.114 - 00:08:41.044, Speaker B: To conclude this overview of the past, I want to give the historical background. So che one wrote the white paper consensus without mining, to have this idea about proof of stake. And then Ethan Pakman, in his master thesis, worked on this tendermint consensus algorithm. Then the idea of the Cosmos network comes from this 2016 white paper. And then in 2018, Shako Milosevic contributed to this. He found some life net sparks in the thesis by Ethan. And so they fixed them here in this.
00:08:41.044 - 00:09:21.346, Speaker B: That's sort of the historical background of the pandemonium project. There's a while. Do you have questions? Then I go on. So, to give some idea what we are like, to give some idea what we are currently doing. And one of the projects that we are working on right now is the light client, which is a very modern term, actually, in old nineties language, it's basically a read. So we have here this view of the tendermint blockchain, where you have here these nodes that run the. The application.
00:09:21.346 - 00:10:12.966, Speaker B: And we want to have the clients from time to time, connect and figure and want to check a block. And it should be light in the sense that they should not be forced to do all the computations. If they sleep for a day and come back, we do not want, if they just want to see the most recent block, we don't want them that they have to follow all the blocks that have been generated. That's the problem. So the security model that lies in our solution is every validator has some voting power, the validator set can potentially change at the end of every block. So in the consensus, the validators also decide who's going to be the validators for the next consensus instance. And.
00:10:12.966 - 00:10:59.344, Speaker B: But this validated set change is controlled by the application, which also means it can totally change. There are no assumptions on this change in the consensus middleware. And because we have this proof of stake, and if you want to get the stake out, you have to wait some time in order to that we can check whether you behaved nicely, we have this assumption that if a block is committed at time t, then the set of the next validators, two thirds of them, must be correct until t plus tp. So tp is this thrusting period which is imposed by the unbounding period. It's a little bit complicated. Let's see a figure. So, assume here we have here the time x is t.
00:10:59.344 - 00:11:35.394, Speaker B: At this time instance. Here we have a block generated here. This here is a depiction of the validator set. There might be some faulty ones here, and there were some correct ones here. And the assumption is that during this drastic period, these guys in here behave correctly, and that most this guy here behave faulty. And if at some later point in time, another block is generated and then new validator set is going to be selected, they might look like this. So you have here some correct guys, again, some faulty guys, and this for this drastic period, this holds.
00:11:35.394 - 00:12:24.764, Speaker B: This also somehow means that when we have these overlappings here, and they are typically very long, because blocks are generated every five to 6 seconds, and this lasting period in the current blockchain is three weeks, when we have this overlapping, this generates restrictions about who can be correct and who can be faulty. Now, of course, the problem now that the light client faces is the following. So, for example, I don't know, a block was generated, I don't know at this point here. And then it goes to sleep for a week. It comes here, it has a new validator set. It gets a block with the validator set. Can it trust this new block or not? And that's the problem that we have.
00:12:24.764 - 00:13:16.044, Speaker B: So, in principle, what is quite easy to observe. So if, for example, the light guy sees this block here, it goes to sleep and wakes up here, there's nothing it can, there's no trust it has left. The last information it had was this one. This information is outdated and it cannot do anything. So at this point, the only thing you can do is you go to your favorite newspaper dealer and ask him, can you give me a new trusted header that I can use to get new states. But if the light guide is online every other day or say once every week, we want to ensure that with the trust that it has, by knowing that this header here was correctly generated, that it could be, that it can verify this header, possibly without checking too many headers here in between. That's the problem we are looking at.
00:13:16.044 - 00:13:58.638, Speaker B: So the problem is you have to track validator changes. As I said, it's a read, but we cannot do the classic read that you could do when you had a static membership in state machine replication in the old days. You ask just everyone who participates, give me the current state. You wait until you receive f one identical answer so you know one correct guy was among them and you're happy. Now you don't even know who to ask because the validator set can change all the time. So the security of this lite client depends on the proof of stake timing assumptions, as I said. So we have to use this time in order to establish the trust and of course that eventually, so this is not the security but the liveness eventually.
00:13:58.638 - 00:14:53.832, Speaker B: Actually we can connect to a correct node to give us, to give us blocks. So how does it work? Well, the lite client is initialized with the trusted theta h one, which is sort of the root for its trust. It downloads this new header it's interested in verifying, and it tries to verify the new header based on information that is in h one and the age of this block. And then once it has verified the new Ada h two, it has enough information to get to extract all the information from the application as mercury proof. So here's just one, sketch one part of the header verification, just to give you an idea of what we are doing. So that function here has an old header which h one which is trusted, and the new header h two. First we check that the old header isn't expired.
00:14:53.832 - 00:15:29.904, Speaker B: If the old header expired, we have to say we cannot give you any trust on h two. Then we compute the voting power that was there in the old header. Then here we check that the header h two is currently signed. So this is just the condition about the well formedness of the header h two. And then this here is the interesting check. Here we check basically that the new header h two is signed by at least one process that is correct. That can be sure to be correct by the drastic period assumption.
00:15:29.904 - 00:16:05.574, Speaker B: So here we have this one third. So intuitively, if sort of the intersection of the validators ensures that one third, more than one third of the old validators are still around, then we can do this check. If this check fails, it doesn't mean that this header here is forged. It might just be the case that between h one and h two, too many changes in the validator set happen. But we don't have to do. We do some bisecting. So we ask for some header in between in order to generate this trust eventually.
00:16:05.574 - 00:16:59.976, Speaker B: So that's what we're currently doing. And actually I haven't talked at all about the title of the talk, which was about strengthening distributed systems. And I want to talk a little bit about actually the main project that I'm involved in, and this is called we want to do verification driven design. So I come from academia and there we have this ivory tower idea how systems are designed, right? We have an algorithmic idea. We are going to write them in a domain specific language. We can actually then do some automated verification, even on that if you are happy, right, then from this we can synthesize the code nicely, automatically automate verification, and we get a system and correct by construction, everything works fine. I am a scientist.
00:16:59.976 - 00:17:24.032, Speaker B: Yeah, but of course it's all wrong. No. So we don't have this language, we have pseudo coded best, we have many computational models. We have heard words like weak synchrony, eventual synchrony, partial synchrony. All this is not motions in English at best. We don't have formal semantics. And on the other side, on the verification side, everything is complicated.
00:17:24.032 - 00:18:02.554, Speaker B: We have unbounded state spaces, we have parameters, we have faults. So at the end we are going to have bugs. And this system, and this problem is real. There are bugs in systems. Even if, you know, peer reviewed papers, we understand that things happen. So there are some, some codes, one thing quite hard to follow in the slides, you know, and then, you know, we have some bug in the, in the system here or some smaller mission if one specification, and at some point they don't actually have literal action. So this is both on the, this problem is both of course on the, on the application side and on the, on the implementation side.
00:18:02.554 - 00:18:54.210, Speaker B: And what we try to do is we want to eliminate that. We want to have a, a more rigorous approach to the engineering of systems. So first point, we're going to start with pozzi style specs, I like to say so with problem statement assumptions, some solutions and some arguments while they are correct. And the important point from here is that these specifications should be acceptable both for us on the verification side, on the academic side, and for the engineers. If you look at specifications that are written by engineers, they talk about data structures, they talk about APIs, but you will not find a lifeless specification of the thing in there, for example. So you need something to sort of span these both worlds. Then what we want to do, we want to write formal specifications in TL.
00:18:54.210 - 00:19:25.720, Speaker B: This sort of should make the English formal. And if the English is not formal enough, fix the English. At some point we're going to implementation of this protocol in rust. And as first step toward correctness, we're going to test the implementation against the TLA specs and vice versa. And finally we're going to do automated verification of the TLA specs. And I insist on the fact we want to do automated verification. We don't want to spend five people, six months in writing machine checkable proofs.
00:19:25.720 - 00:20:24.948, Speaker B: This is not going to scale in our world where the protocols are changing all the time. We want methods that have a bigger degree of automation. And actually the light kinder just presented this sort of our first pilot project where we're doing that. And just to convince you that I'm not totally crazy about what I'm claiming here, I want to give you some recent results I had on automated verification, which I think we made some nice progress. So the first result I want to talk its verification of protocols and what we developed in the last together with Igor, you saw his picture on the second slide is the byzantine model checker. So the problem that we are tackled on the high level is parameterized model checking. So when I was in undergrad, model checking meant I would write my protocol for some model checker, fix the parameter nice, and do exhaustive state space exploration.
00:20:24.948 - 00:20:54.914, Speaker B: And then it would give me counterexamples or not. But then if I would write a paper for this kapozi, I would write proofs for n, right, which is an arbitrary big n. So what we want to do is imperator. We want to have a description of the system, check against temporal formulas, but keep n as a parameter. We don't want to fix it. And the algorithms we looked at are very close to the algorithms we have discussed here. The last one, twig here is a standard example where I broadcast by Schrika Dentuig.
00:20:54.914 - 00:21:29.762, Speaker B: What you find here is threshold guards. That's the major point. This is also we have discussed quorums and all that. This is sort of the code representation how to check whether enoch quorums intersect. And you have these resilience conditions on the system. And what this, then this gives you actually in parameterized verification is that you want have a system of n processes. There's an assumption about the number of faults and fr actually fault in the run.
00:21:29.762 - 00:22:28.538, Speaker B: And you want to check whether for all values nt and f that satisfies, for example, this famous n is greater than three t, that the parallel composition of n minus f correct processes. And these processes are also parameterized because NLT showed up in the code with f faults satisfies our safety, our safety and lifeness properties. In general, these problems are undecidable. But what we could do is we could, for this, threshold guarded algorithms, define automata for which we actually have nice results. And we can automatically, for all, for the parametric case, check a number of disciplined algorithms from the literature. And last week at the Friede workshop at Disc, Messagamoli presented his own work. He's our first user, and he used the byzantine model checker to check the broadcast of the red belly blockchain.
00:22:28.538 - 00:23:25.318, Speaker B: So that's quite, quite exciting and sort of the theoretical underpinning behind. Just to give you a sort of the idea, we use bounded model checking, which basically means what we can do, we can check execution of a fixed finite length against the specification. But of course, what we want to do is we want to check all executions. And the big question is whether there is an if and only if between them. Actually, what we have done in the last years, we have shown that for these threshold guided algorithms, we can make this bounded multiple incomplete for safety. So that's sort of on the protocol side towards the verification of implementation and of code. I've worked together with Cesare Tragoe from India Paris, and what we did here, we dig up some old literature and sorry, Eli, I call the work communication closure.
00:23:25.318 - 00:24:18.920, Speaker B: But there is also a very nice paper daily, very close to concept stratified decomposition. So what's the idea of communication closure? Communication closure basically means is that we have programs that locally go through a sequence of blocks of the code. And for example, the second block of this process here only communicates with the second block of this code here. So if they are structured in a way that one blocks only communicates with the same block of another process, this is a communication closed here, the first block sends a message to the second block. This is not communication closed. So we use these notions. And if you think back about also some algorithms we have talked about this week, for example, view change, typically you have a lead electron phase and you have a broadcast phase.
00:24:18.920 - 00:25:17.184, Speaker B: And the lead election messages are not going to interfere with the broadcast. And the broadcast are not going to interfere with the lead election. Okay, so here you have a decomposition of these algorithms, and they're not interfering. But of course, there is also always a trivial decomposition, right? You can always say the whole program is one layer and everything is fine. The question is, which is a good layer of decomposition? And the nicest layer is, of course, if you have message change, one, which corresponds, in our nice view of distributed computing to the notion of a round. And if you have notions of the round from a verification viewpoint, it's super exciting, right? You just don't have interleavings, you don't have to deal with facts like who does the first step or something. You just talk about what messages are sent in the round, which messages are received in the round, which also means you don't have to think about message buffers if you want to reason about asynchronous system, and they do this in an asynchronous environment.
00:25:17.184 - 00:26:18.544, Speaker B: So if you have always to carry around invariants about all the message buffers, if you don't have to do in this case, you can reason about the rounds in isolation and you get much simpler proof arguments. So what we've done in that work, we answer, we asked two questions, which protocols are communication closed, and how can we compute round decomposition? So we have found an automatic method where we annotate the code that can identify automatically communication closed. Asynchronous protocols, once we have them, we're going to rewrite them automatically into synchronous protocols, and then to specification on the synchronous protocols. Some idea here. So here you have some schema of this algorithm I've shown you before, and then you sort of have to understand where in the code round boundaries. And then you're doing this writing in the synchronous code. Once you have a synchronous code, and of course you prove that the semantics are the same, so they produce indistinguishable executions.
00:26:18.544 - 00:27:21.888, Speaker B: And once you have done that, you can pick one of the verification methods for synchronous algorithms that have been developed in the last years. And there's huge interest in the verification community for distributed algorithms. What we have done, we have taken some algorithms, encoded them in c, basically, and these are the invariants, and this gives you the synchronous codes. So we have written them and also verification. And we used the deductive verification in psync, so do not keep you away much longer. From lunch, I talked to you a little bit about what is our idea about Cosmos and tendermint, what we are currently doing for the lite line, and for me, the interesting thing is that what we want to do in the next month is really to sort of reimplement tendermint in rust and do this in a way that we have better trust in the correctness of the systems and the correctness of the protocols. That's all.
00:27:21.888 - 00:27:22.564, Speaker B: Thanks.
00:27:26.964 - 00:28:09.284, Speaker C: There's a lot of work going now about this. In Hansinger group, they have a language how to write things round by round. And Molis Sagiv has this EPR system, ERP system proof. And they claim that they don't have a proof yet that everything that can be run can be written round by round, can be translated to the EPA, to the ERP or VPR. I don't know what's over there. And then they have an automated proof to it once you put it in this logic. So I wonder if this doesn't.
00:28:09.284 - 00:28:13.712, Speaker C: I expected EPR to come somewhere here, but it didn't.
00:28:13.888 - 00:28:42.074, Speaker B: It's not. Yeah, because it's a little bit of different approach still. I didn't know that they work on, on rewriting into synchronous rounds. So about the work by the Hansinger group. Such actually was in that group. And last week we had a workshop, as I said, in Budapest, and there was also a talk by the Hansinger group that worked on that. And this rewriting into synchronous rounds is currently a hot topic.
00:28:42.074 - 00:29:00.984, Speaker B: And there are several groups doing that at the end. The problem to reason about distributed systems is to handle partial orders, because this is what's going on. And instead of reasoning about sort of all the executions, you just want to pick one execution which represents a possibly big set of executions in partial order. And this is what's going on.
00:29:03.204 - 00:29:05.864, Speaker C: This is distributed should be round by round.
00:29:07.204 - 00:29:31.844, Speaker B: This is the point that with the idea of stratified decomposition, we sort of say, okay, the moment this is actually the algorithm is in rounds, we can understand how to do that. And while this was in 87, a good idea to write mathematical proofs, and it's a very nice idea. What we try to do is we want to use it for automated reasoning. And this is more recent. This is going on right now.
00:29:32.664 - 00:29:40.304, Speaker A: Okay, well, I guess let's thank the speaker and then we can take the rest of the questions offline. We can have so people can go to lunch.

00:00:00.080 - 00:00:03.034, Speaker A: The program, is that right?
00:00:05.974 - 00:00:10.110, Speaker B: Yeah, you can try either one. I'd suggest sharing the application.
00:00:10.182 - 00:00:12.710, Speaker A: Yeah. Does that work? Yes.
00:00:12.862 - 00:00:14.554, Speaker B: If you could just bring it to full screen.
00:00:15.934 - 00:00:19.526, Speaker A: Looks good. All right.
00:00:19.710 - 00:00:21.634, Speaker B: Can we see it in full screen mode?
00:00:22.014 - 00:00:23.034, Speaker A: Is it not.
00:00:23.334 - 00:00:25.034, Speaker B: Oh no, it's not yet.
00:00:27.774 - 00:00:55.774, Speaker A: 1 second. So it's full screen for me? I'm not sure.
00:00:56.754 - 00:01:03.254, Speaker B: Then maybe let's try the reverse. Maybe try sharing your desktop and then doing that.
00:01:05.514 - 00:01:11.602, Speaker C: Okay. While we are playing with the full screen or not. I mean, it's good that we at least slide. Okay, excellent.
00:01:11.778 - 00:01:12.534, Speaker A: Yes.
00:01:14.794 - 00:02:00.706, Speaker C: So it's great that we have Andy because from probably you all remember when we have a very nice talk about Zygos from Rajiv aloor and he praised very much, like, oh, if you want to use great solver for Saigus, you should use CVC four. And the person who, if I have ever questioned about Zygos and CVC four, it's exactly Andy Reynolds and I'm happy that he's here. So Andy right now is a research scientist at University of Iowa. Before that he was a postdoc at EPFL, and before that he also did PhD with Cesare Pinelli in Iowa. And as I said, he's the person behind CBC four cycles. If you ever have any questions, ask Andy. And handy.
00:02:00.706 - 00:02:08.854, Speaker C: I hope you don't hate me for saying that because probably now we'll have many questions and emails. So thank you, Andy.
00:02:10.714 - 00:03:02.834, Speaker A: Yeah, so my talk is syntax guided synthesis and SMT of you from inside the solver. So I'll try to give you a bit of an inside look into how CVC four works for Saigus. So, SMT solvers, as many of you know, have many applications, including software verification, synthesis, and the list goes on. So in, in this talk, I'll be describing how the synthesis algorithms work in CVC four, which is the solver that I've been working on for about ten years now. So this solver is open source, it's available at this link. And this is really a really big project. It's been a joint collaboration between University of Iowa and Stanford University mostly, but lots of external collaborators.
00:03:02.834 - 00:03:46.574, Speaker A: So yeah, many people to thank. Cesare Tenelli and Clark Barrett are the project leads for the team. So to give some setting to the kind of formalisms I'll be using in this talk. So we're interested in synthesis conjectures of this form. So there exists some function f for which some property p holds for all x. And more specifically, we're interested in predicates where the background theory is something like linear arithmetic, or any of the other theories supported by SMT solvers. So this theory component kind of often motivates you to use an SMT solver.
00:03:46.574 - 00:04:46.094, Speaker A: Additional additionally, in addition to the spec here, we have a syntax. And so this is the classic syntax guided synthesis problem, which Rajiv and others popularized recently. And I'd like to just go over this kind of standard picture of counterexample guided inductive synthesis. So, given a syntax and a spec, you have a solution enumerator and a solution verifier. The enumerator gives candidate solutions for f, and it enumerates them until the solution verifier is able to find that there is a given. F has no counterexamples with respect to the spec. And the body of these functions here are given by the syntax.
00:04:46.094 - 00:05:55.204, Speaker A: So it's a pretty common picture here. So, in general, the SMT solver, or in traditional settings has been used as the solution verifier. But in our cab 15 paper, we sort of considered a different architecture where the solution enumeration and verification were kind of tightly wound together in the SMT solver, in particular in CBC four. And what this allows is certain synthesis algorithms that leverage the internal state of the SMT solver become possible. And just in general, for performance reasons, you often really would like a tight integration between these two components. So in this talk, I'm actually going to give you three different flavors of synthesis in CVC four, how we solve these synthesis conjectures. I'll briefly mention some internal applications of Saigus that we have for actually making CVC four better, and just briefly mention some future work.
00:05:55.204 - 00:06:47.346, Speaker A: So, given this kind of high level picture, we have this synthesis conjecture. We want CVC four to somehow magically solve it and give us a solution. Well, as I mentioned, there's actually three different independent solvers within CVC four, and the first is counter example, guided quantifier instantiation. This is an idea that we brought up in Cav 2015, and we've been working on extensions of it in the past few years. There's also what we call the smart enumerative solver and the fast enumerative solver. And again, I'm just giving some references here to some of the papers where we described these techniques. And the best approach to apply here depends on the synthesis conjecture.
00:06:47.346 - 00:07:39.404, Speaker A: And I'll get into what kind of conjectures are given to which one of these solvers. So, just going over the three techniques now. So the first one is what we call counterexample guided quantifier instantiation and the intuition here is that some synthesis conjectures are essentially first order. And in particular, this is the classic Max example, saying that f of x, y is the maximum of x and y. And what you can do with a conjecture like this is what's known as antisculumization, where the outermost function f is pushed inwards to become a first order variable z, and then it's in a first order form. And we know how to solve these in SMT solvers. And the techniques that we use to solve them are under the umbrella of counterexample guided quantifier instantiation.
00:07:39.404 - 00:08:38.514, Speaker A: So I'm not going to get into the details of this technique, but the high level idea is mentioned here is that essentially there's classic quantifier elimination procedures that typically you can phrase as instantiation based procedures for first order quantified formulas with one alternation. And from this, a synthesis procedure for single invocation properties follows fairly trivially. However, there's quite a few caveats here. So first of all, as I mentioned, the specification must be single invocation. The functions to synthesize in your problem are applied to the list of universal variables. So this max example works. You can have multiple functions as long as they're applied to the same arguments, but more complicated conjectures, like saying that a function is commutative, this technique is not applicable.
00:08:38.514 - 00:09:37.408, Speaker A: Second caveat is, if syntax restrictions are present, then this method may violate them. And what we do in practice is heuristic fitting of the solution that we get from counter example guided instantiation to the grammar. And third, a term selection strategy must be known for the theory. So we don't magically get a synthesis procedure for new theories, we actually have to do the theory specific work of determining how to devise this selection strategy. So for linear arithmetic, small finite domains, bit vectors, these things we know how to deal with, but more complex theories like strings and non layer arithmetic, we don't. Okay, so given all those caveats, a more generic way of solving synthesis conjectures. In SMT solvers, we use enumerative approaches.
00:09:37.408 - 00:10:53.294, Speaker A: And the first of these is what I call smart enumerative saigus. And so in smart enumerative saigus, again, we have this picture of having a conjecture and a set of syntax restrictions. But what we do is alternatively, instead of looking at this as syntax restrictions, we look at the grammar as an inductive data type and the inductive data type. Inductive data types is a theory that actually SMT solvers support. So then what we do with this input conjecture is we turn this higher order quantification on f, we turn it into first order quantification on this data type, which I'm calling f int. And this is done via a deep embedding where it also relies on these evaluation functions, e, where this essentially maps the data type representation of our function to its behavior, its actual behavior on the integers. So then, given this form of the conjecture, we're able to give this to CVC four and solve it via a combination of the data types.
00:10:53.294 - 00:11:54.812, Speaker A: Quantifier free theory solver plus Segis loop. And the idea here is that basically models for d correspond to candidate solutions. So when you do this, when you do any sort of enumerative approach, it's very important to consider search space pruning. And again, the solver is going to generate us a stream of candidate models for d, shown here. And yeah, the most important optimization is to only consider terms whose analog is unique up to theory, specifically simplification. So in SMT solvers, we spend a lot of our time actually developing these simplification techniques, which I'm just writing with a down arrow here. So the basic idea is you convert these data type values into the corresponding terms, and then you discard the ones, the terms that are not unique up to theory normalization here.
00:11:54.812 - 00:13:02.200, Speaker A: So I would discard y plus one if I had already considered one plus y, for instance. So then, just looking closer at what a syntax constraint is, or a blocking constraint is in this approach. So the solver then deals with clauses that look essentially like this, where the clause I'm showing up on the top here is essentially saying do not consider solutions where d is x plus zero. So, in detail, what this is saying is either the top symbol of d is not plus, or the first child of d is not x, or the second child of d is not zero. Now, to make this efficient, we actually had to modify the data types decision procedure to use what are known as shared selectors. So traditionally, data types uses selectors that are unique for each constructor. However, we share these between constructors.
00:13:02.200 - 00:14:04.914, Speaker A: This enables clause sharing, which is described in this hcar paper. The nice thing that you can do when you have this sort of representation of syntax constraints is you can actually generalize them. So I can reason, you know, given this example, that I never want to consider a d where it's of the form t plus zero for net. And it's simple to express this, you just drop the middle constraint. So this is what's what we call theory rewriting with, with structural generalization this is described in our Cav 2019 paper. We also use what's known as partial evaluation unfolding. So the formula at the top here is saying when the top symbol of d is ite, its evaluation behaves like if then else, which you can express in a fairly straightforward way.
00:14:04.914 - 00:15:11.096, Speaker A: We can also do total evaluation where essentially when d is fully specified, then we, when we relate its evaluation to its built in analog. And so what this enables is essentially the quantifier. Three theories, in this case, linear arithmetic, is working in cooperation with data types to do the enumeration. And we combine partial and total evaluation unfolding, where Boolean connectives and Ite use partial and the others use totally. All right, so then the third approach that I'd like to briefly mention is fast enumerative sagus and the idea is actually very simple, and it's essentially just treating this conjecture as a black box. We directly enumerate terms based on highly optimized iterator data structures. Now, the pseudocode for this approach actually can just be described in about five or six lines of pseudocode.
00:15:11.096 - 00:16:17.624, Speaker A: There's a lot that goes into making this efficient, but the general idea here is to just use a lightweight data structure for enumerating terms from the grammar as fast as possible. Now, with respect to smart enumeration, there are a couple pros of using fast. So we can still take some of the optimizations from smart enumeration, like discarding terms that are not unique up to theory rewriting. And the other pro is that fast enumeration is indeed very fast. Now, if you actually compare a lightweight data structure for enumerating terms, you get roughly 100 times the throughput with respect to smart enumeration. So that means it's considering roughly 100 times more candidates per second. And the reason for that is just, you know, using a Sat solver to generate candidate solutions versus using custom iterators.
00:16:17.624 - 00:17:11.464, Speaker A: It's, you know, a heavy hammer versus a light hammer. The main con though, when using fast enumeration is you cannot easily generalize syntactic constraints. And some of these more advanced techniques for pruning the search space are not easily applicable. And the reason for that is essentially, sometimes you need a constraint solver to really solve, you know, navigating a search space. But the summary is, in fact, fast enumeration is usually better for most of the Saigus comp benchmarks. However, when you're really dealing with difficult problems, you should use smart enumeration generally. So in particular, for invariant synthesis problems, we almost always use smart.
00:17:11.464 - 00:18:24.530, Speaker A: If you really wanted to get into the guts of what keeps me up at night is, you know, this is some profiling information about how to optimize fast and numerative saigus. And just this is kind of giving the lifetime of a term through fast enumeration. So, considering a search space of about 10 million terms, we generally construct about hundred thousand of them and look at the rewriter. Of those, we consider only about 60,000 to evaluate on examples, 15,000 we may check against the conjecture, and so on. And the takeaway here is actually that evaluating terms on concrete examples is surprisingly the bottleneck when it comes to when you're really getting down into what is the bottleneck for enumerative sagus. So, in fact, about 70% of the runtime is just evaluating terms on concrete examples. So just summarizing here, the three solvers.
00:18:24.530 - 00:19:03.780, Speaker A: So this is what CVC four does when it gets a conjecture. If the formula is single invocation, no grammar restrictions, and we know how to solve it via quantifier instantiation, then we use the first 1st method. If the conjecture has multiple functions to synthesize our grammar with boolean connectives, we use smart enumerative. Otherwise we use fast enumerative. So that's CVC four straight out of the box, no command line options. That's exactly what I'll do. And yeah, I don't have time to get into other techniques, but there's quite a few other things that are implemented.
00:19:03.780 - 00:20:06.604, Speaker A: On top of what I mentioned for CBC four, this includes some of the divide and conquer stuff that Rajeev, I think, mentioned in his talk. We also had an FMCAD paper that has a different unification algorithm that we found was helpful. We also use theory specific constant repair, which I. I believe Elizabeth is going to be talking about, as well as a few other techniques that I'll skip. So, ongoing work. One of the things that I think is really cool is that syntax guided synthesis has in fact, had a lot of uses internal to our group. So the other CVC four developers, they all kind of take our Saiga solver and apply it internally to do really cool things.
00:20:06.604 - 00:20:46.244, Speaker A: So this includes statically designing new quantifier instantiation algorithms. We've used this Saiga solver to help us do that. Discovering new rewrite rules. You can use Saigus to do that. Test case generation is another obvious application of Saigus that we've taken advantage of. And yeah, another kind of big research area is taking enumerative Saigus and actually applying it the other way to use as an instantiation strategy for first order formulas. So we have a talkers paper about that.
00:20:46.244 - 00:21:48.420, Speaker A: We also are working on many algorithms that utilize enumerative saigus as a black box. So doing things like invariant synthesis, abduction, interpolation, optimization, SMT solvers are kind of gaining more and more features, and Saigus has been kind of a powerful tool internally for us. And, yeah, in addition to all the high level stuff, there's still work to be done at the low level, optimizing the solver. So thanks for the invitation, and thanks for listening. So, these techniques I mentioned in the talk are all available in CVC four. And in fact, we're working on a new version of CVC four to be called CVC five. We have a Python and C APIs for Saigus, and we're working on a Java API as well.
00:21:48.420 - 00:21:51.084, Speaker A: Again, it's open source. So. Thanks.
00:21:51.664 - 00:22:04.804, Speaker C: Thank you. Thank you. Thank you. So, do we have time for a question? We have time for maybe one or two short questions. Let me see. Is there anything in the chat? Raz, please.
00:22:06.384 - 00:22:28.828, Speaker D: Andy, great talk. Thank you. I wish we had more time to go into more details. One question was why you cannot or don't want to integrate evaluation on examples into the actual constraint. Solving that as the pruning and evaluation, I think that whatever slide is.
00:22:28.916 - 00:23:02.724, Speaker A: Yeah, yeah. So, yeah, I should say this point, it does incorporate the evaluation by examples. Now, what I'm. What I say that you can't do is you can't easily express things like, I don't want to consider this shape of a term, because maybe I did some more advanced learning. Right. Because to do that, you would have to modify your iterator to somehow navigate through shapes, if that makes sense.
00:23:05.104 - 00:23:12.608, Speaker D: I think in the example is where you spend 70% of your time. I assume that was input output examples. Right. Are we talking about the same thing?
00:23:12.776 - 00:23:34.324, Speaker A: Yeah, yeah. So we do. The fast enumerator does skip based on equivalents up to examples. Right. So, in fact, that's what this 60% is. It's actually spending most of its time checking whether a term is unique. Up to examples.
00:23:35.504 - 00:23:36.320, Speaker D: I see.
00:23:36.472 - 00:23:37.204, Speaker A: Yeah.
00:23:41.284 - 00:23:44.864, Speaker C: Radu, you have a question. And please.
00:23:46.684 - 00:23:47.504, Speaker E: Yes.
00:23:48.484 - 00:23:49.664, Speaker C: You're muted.
00:23:52.124 - 00:24:03.878, Speaker E: Yeah. So the question was related to what Draz was asking. So how do you plan to improve? Yeah, so, I mean, 70%.
00:24:04.036 - 00:24:37.624, Speaker A: That's right. So. Well, I think first thing to note is that it's very important to have an evaluator that operates on very low. I mean, C data structures. You don't want to go through an API for this. So once your evaluator is as optimized as possible, then the only way to really improve runtime is to decrease these, the number of terms you, you consider. Now, one way to do this.
00:24:37.624 - 00:25:14.684, Speaker A: You know, an easy way to do this would be to make your rewriter more and more effective. Because if, if you can show a term is not unique based on rewriting, then that saves you the trouble of having to evaluate it. So that's what, essentially, this. I don't know if you can see my pointer, but essentially I'm trying to push down the number of terms I evaluate. But then you'll get to a line where if your rewriter is perfect, there's just so many logically unique terms.
00:25:15.744 - 00:25:18.244, Speaker E: So it looks like uniqueness is key here.
00:25:18.744 - 00:25:36.524, Speaker A: Yeah, but, yeah, I mean, our, basically our rewriter, you know, we, you know, some theories. We've put in years of effort into making the rewriter, you know, as normalizing as possible.
00:25:37.344 - 00:25:40.816, Speaker E: So, yeah, thanks a lot. Very nice talk.
00:25:41.000 - 00:26:04.824, Speaker C: Thank you, Andy. And I hope you will continue participating this seminar of every, every Monday. So I have now a question, and we always want to take a short break, but it would maybe make sense to follow up with Andy's talk with the mark stock because it's a short five minutes talk that actually says one of potential optimizations of the CVC four. Or should we take a break and then.

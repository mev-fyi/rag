00:00:00.280 - 00:00:29.746, Speaker A: All right, welcome back. So, next up, we have Annie Raymond, who's going to tell us about symmetric sums of squares. All right, thank you to the organizers for inviting me to speak in the francophone afternoon of the session. And so today I want to tell you about symmetric sums of squares, which is joint work with three collaborators who are all here today. So no pressure for me. So, James Sanderson, Mohit Singh, and Rikka Thomas. So let me dive right in, and let me tell you what is our goal for today.
00:00:29.746 - 00:01:09.760, Speaker A: So, our goal is to certify the non negativity of a symmetric polynomial over the hypercube. And so, just in case you fall asleep or I don't get there for time reasons, here is immediately our key result. So, spoiler alert, the runtime does not have to depend on the number of variables of the polynomial, right? So I'll first give you a little bit of background. So I'll tell you about sums of squares, module, and ideal, and how usually the runtime there does depend on the number of variables. And then I'll specify our setting where your polynomial is symmetric and you're over the hypercube. And I'll try to justify that it's actually a very natural setting. And then I'll move on to our results and prove exactly this.
00:01:09.760 - 00:02:04.520, Speaker A: And if there's time, I'll tell you a little bit how all of this relates to the work of flag algebras of Sasha Razbarov. All right, so let's go over a little bit of background, which a lot of you know, but just to make sure we're all on the same page, let's go over what is the sum of Kurt's module and ideal? So, let's say that I want to certify the non negativity of a polynomial p, not globally, but just over the solutions of a system of polynomial equations. So, for example, I could want to certify that the polynomial one minus y is non negative whenever x squared plus y squared is equal to one. So I really want to show that y is at most one over the unit circle. That's pretty clear from a picture. But how could you actually prove that in a more formal way? Well, I could want to write one minus y as a sum of squares. Obviously, I won't succeed, because one minus y is not greater or equal to zero for every point in two reals, but.
00:02:04.520 - 00:02:53.568, Speaker A: So, okay, I write a sum of squares, and then I remove something, and you might say, well, now, how do you know that you're still greater or equal to zero? Well, what I'm removing is something that I know is zero for every point that I care about. For every point of the unit circle, x squared plus y squared minus one is equal to zero. So I have something that is greater or equal to zero over every point of two reals minus something that I know is zero over every point that I care about. So I have something that is greater or equal to zero for every point that I care about. And so that's what we'll want to do. In general, I'll have some ideal I that is generated by some set of polynomials, and I'll look at its real varieties, which will just be the roots of the system of polynomials. So here, for example, my ideal would be generated by the polynomial x squared plus y squared minus one.
00:02:53.568 - 00:03:32.096, Speaker A: And my real variety will be the roots of that. So just the unit circle. And so I'll say that my polynomial is a sum of squares, module, and ideal. If I can write p as a sum of squares plus something that lives within my ideal, which I know is zero, right? So I'll have something that is greater or equal to zero. My sum of squares plus something that I know is zero for every point that I care about. Okay? And so if it so happens that all of my polynomials that I'm squaring have degree at most d, then I'll say that this is a d sum of squares, module and ideal. So the very nice thing here is that modulo some very minor conditions for the type of systems that I'll be interested in.
00:03:32.096 - 00:04:11.044, Speaker A: I will be able to do that. If I let d grow, then I will be able to find my sum of squares. So I'll need to find some positive semi definite matrix q, just like this here to write my sum of squares. And I'll have to find my h and then this will give me my sum of squares. And so I can use some indefinite programming to find q and a. Runtime is the number of variables to the order of the degree that you need. And so because of that, we often see the degree as being a measure of complexity of the problem, right? So if you have that your degree is some small constant, then you can do this in polynomial time.
00:04:11.044 - 00:04:42.480, Speaker A: If d grows with n, then this is a hard, complex problem. So, everybody good with some of the squares module and ideal, great. So we don't want to do that in general, we want to do this in this specific setting. So I have a k subset, discrete hypercube that I denote by v and k. So this is just a discrete zero one hypercube whose coordinates are indexed by Klement subsets of a ground set of elements one through one. This is a pretty natural setting. I'm more of a combinatorialist.
00:04:42.480 - 00:05:56.922, Speaker A: So for me I can think about, ok, I have my ground set of elements or the vertices of a graph, and my k subsets are actually two element subsets are the edges of my graph, right? So this would be this kind of setting. In Volker's talk this morning, when he mentioned Woolsey's system for scheduling, he had variable yij, where yij was one if job I was scheduled before job j, and zero if it wasn't. So this is a very broad system, and so not only am I over the k subset discrete hypercube, but I'm minimizing a symmetric polynomial over this k subset discrete hypercube. So symmetric here, I mean that it is sn invariant. So I have my symmetric group that is acting on the ground set of elements one through n, and I'm really looking at the induced action on my k element subset, right? So I have the action s being applied to the variable x I one through ik. I get x of s applied to I one through s applied to ik, right? I'm really looking at the induced action. And so what we'll want to do is, well, minimizing maximizing, it's really equivalent to certifying non negativity.
00:05:56.922 - 00:06:33.744, Speaker A: I'll make that clear in a second. So I want to find sums of square certificates, and I want them to be clever. I want to use the fact that, oh, I have symmetry here, and I'm over the hypercube. And so I want to use symmetry so that I can find a runtime that is independent of n. If I just used straightforward some of the squares module ideal, like we just did in the previous slide, my runtime would depend on n. And so if my problem had a ground set of elements where the number of elements is big or goes to infinity, that would be problematic. So I want to be clever.
00:06:33.744 - 00:07:16.448, Speaker A: So the case when k is equal to one, so when I don't really have subsets where you have a direct action on the elements, was done in 2014 by Greg Lackerman, George Govea, and James Pfeiffer. But the case k is greater or equal to two when you actually have subsets was left open because the representation theory there is a bit different. And so that's the case that I want to focus on today. So you might say, well, wasn't this case already good enough? Well, a lot of problems are over vertices, for example. But there's a lot of problems over edges. So let me give you two very specific problem where that fits exactly your setting. So why do we want to be able to do this? So one problem is a turn type problem.
00:07:16.448 - 00:07:59.814, Speaker A: So let's say that I'm given a fixed graph h, and I want to figure out what is the maximum edge density of a graph on n vertices that does not contain h as a sub graph. And in particular, since this is often hard, I'll be happy if I can say something in the case when the number of vertices goes to infinity. So the smallest instance of that is Mantel's theorem where you're formatting triangles in a graph, right? So we know then that a max edge density is at most one half. It's attained on complete bipartite graphs with parts as equal in size as possible. And then this was generalized by Turan for when you forbid cliques of size a. But so you can do that really for any graph h. And so if you pass on to hypergraphs, then it becomes very hard.
00:07:59.814 - 00:08:27.750, Speaker A: And so here, okay, our vertices are, is our ground set of elements, and we're really looking at edge variables, which edges stay there. There are two subsets, or if I'm in the k uniform hypergraph, they're k subsets of my ground set of elements. And maximizing the edge density. Well, yeah, the edge density is something that is invariant on the reset. So this is exactly inner setting. And here we see. Yeah, I want to do this for any n.
00:08:27.750 - 00:08:55.162, Speaker A: In particular, I want to do this as n goes to infinity. Right. So if my runtime depends on n, this will be very problematic. Another example is Ramsey type problems. So let's say that I want to color the edges of a complete graph on n vertices with the colors either ruby or sapphire. And I want to find the smallest number of vertices for which I'm guaranteed a ruby clique of size r or a sapphire clique of size s. You.
00:08:55.178 - 00:08:56.494, Speaker B: Don'T like red and blue.
00:08:56.794 - 00:09:38.004, Speaker A: Well, then it would be, you know, two letters that are not consecutive in the Alphabet. That would be problematic. So the most famous instance of that is when r and s are both three. There's a theorem that says that if you have at least six people in a room, then you're guaranteed to have at least three people who mutually know each other or three people who mutually don't know each other. Right? So here on five vertices, I was able to color my edges with red and blue so that there was no monochromatic triangle. But on six vertices I might have tried, you know, all of possible colorings and I would have failed. I would always get a red or blue triangle.
00:09:38.004 - 00:10:22.530, Speaker A: And so here again, my variables are edge variables, right? And I could do this for k uniform hypergraphs as well, so k can be bigger than two as well. I'm really trying to show unfeasibility, right? So I want to show that when I have six, it's impossible that I don't get a monochromatic triangle. So in that case I'll really be trying to show that minus one is really greater or equal to zero. Right, that's how I'll show in feasibility. And minus one, well yeah, that is a system polynomial. So I'm trying to certify the non negativity of a symmetric polynomial here too, you might say, well, here n is pretty small, right? Here my n is six. That's not so bad, right? But the thing is that this grows pretty quickly.
00:10:22.530 - 00:10:57.324, Speaker A: So if I look at the case when r and s are both four, then this becomes 18 vertices. When r and s is five, we don't know, we know it's between like 41 and 49, something like that. And then after that it just keeps growing very big. So if your runtime depends on the number of vertices that you have, you'll probably be in trouble. So this is the kind of problems that fits in our setting. There's many others, but hopefully now you think it's not too arbitrary of a setting. So let's go back to the turn type problem and let's really make everything super explicit.
00:10:57.324 - 00:11:31.250, Speaker A: From now on I'll just imagine that everything is two subsets. Just to make things easier, all the results that I'll tell you about will hold for k subset discrete hypercubes. But let's just have vn be the two subset discrete hypercube, or the coordinates are indexed by pairs of two elements of my ground set. So let's look at the smallest instead of turn type problem. So let's look at Mantel's example. So I'm trying to form a triangles in a graph on n vertices. Okay, how can I model that? I want to maximize the edge density there.
00:11:31.250 - 00:12:09.990, Speaker A: So I'll have edge variables, right? So for every para versus I and j, I will have a variable xi j. That is either one if I put an edge between I and j and zero if I don't. So my first set of constraints ensures exactly that I either have an edge or I don't. I cannot have half an edge. Then I need to make sure that every, that all the edges that I draw do not form any single triangle. So I look at every triplet of vertices I, j, k, and I need to make sure that for any three vertices, two of them do not form an edge. Right? So one of the associated edge variables should be zero.
00:12:09.990 - 00:12:37.706, Speaker A: So if I take their product, I should be getting zero. Okay, so now my constraints ensure that I am drawing a triangle free graph. That is very good. Now I just want to maximize the edge density over that. So I just add up all of my edge variables. This will tell me exactly how many edges I drew, and I divide by the total number of edges there could have been and choose two. And so what I want to do is to show that this is at most one, two plus some little error that goes away as n goes to infinity.
00:12:37.706 - 00:13:16.162, Speaker A: Right, this is what I need to do if I want to retrieve Mantel's theorem. Well, that's the same thing as showing that one two plus that little error, minus my objective function, so minus my edge density is greater or equal to zero whenever I have a triangle free graph, whenever these equations hold. Okay, so I'm trying to sort of find non negativity. Great. So I can use sums of Kurt's module and ideal, right, where my ideal will be generated basically by the equations that I have. So I want to find some positive semi definite matrix q and some degree d such that I can write this polynomial as a sum of squares module. My ideal.
00:13:16.162 - 00:13:53.478, Speaker A: So my ideal is generated by x squared minus x, right? So this is to make sure that every edge variable is either zero or one. And this is to make sure that I'm triangle free. And so here, okay, I have my psy matrix q. I need, I'll have some vectors v that are vectors of basis elements of the gradient most d in my quotient ring. And so I can just take any basis. And so semi definite programming should allow me to find Q. Right, but the problem is of course that then, well, the runtime would be the number of variables and choose two to the order of the degree that I need.
00:13:53.478 - 00:14:33.174, Speaker A: I told you the degree is kind of considered to be representative of how hard the problem is. Mentel's theorem was proven in 1907. The proof is one line long, I imagine. I hope that d is very small constant, right? But even if it's a small constant, well, I want to do this for any n for any number of vertices. And in particular I want to do this as n goes to infinity, so my runtime goes to infinity, and that is very problematic. We see semi definite programming and some of those squares as being a very strong technique. And I'm telling you, I'm not able to retrieve this very easy theorem from 1907.
00:14:33.174 - 00:15:15.798, Speaker A: So what are we doing wrong? Well, what we're doing wrong is that we're not using symmetry right. We're not being smart. We're saying that every single one of our variable looks different, but they're not, they all look the same. So I need to use that. So, to give you a little bit of foreshadowing, this is the kind of sum of squares proof that I want. This is the kind of certificate that I want. So here, instead of having a vector of all the monomials of degree nmos d in my quotient string, I have just a vector of two polynomials, and here a vector of one polynomial, and those polynomials represent something with regard to symmetry, right? They're not random polynomials.
00:15:15.798 - 00:15:46.670, Speaker A: And then because I have these polynomials that exploit symmetry, I get constant size matrices. So instead of having infinitely big matrices, I just have a two by two and a one by one matrix. And in those matrices, my entries are functions of n. So this is a certificate for any n. In particular, it's a certificate as n goes to infinity. So this is the kind of certificate that I will want to obtain. And we will be always able to get something of this grip vector where.
00:15:46.702 - 00:15:48.794, Speaker B: One of the entries is a polynomial.
00:15:49.334 - 00:16:26.464, Speaker A: Yeah. So it's a vector of length two. So my first polynomial is one, the second one, which is a polynomial, and q one is this polynomial here. So instead of having a vector of the basis, I have some vector of polynomials, and this is, what does this equal? So if I show, so once I get this right, I know that this is greater or equal to zero. This implies that this here is greater or equal to zero, directly, not equal. I'm being a bit tricky here. This is sort of the right hand side.
00:16:26.464 - 00:17:02.384, Speaker A: Yeah, it's kind of saying that. So it's a sum of squares that is equal to some slightly different polynomial. That implies this one. All right, so how will I do that? How do I exploit symmetry? How do I find such certificates? Well, I'll need to use representation theory. You might not like representation theory, you might love it. We don't need much. So we have a big vector space, right? We have my quotient ring, like everything that has degree at most d in there, some big vector space.
00:17:02.384 - 00:18:00.874, Speaker A: And so all I really want from representation theory is to say that I can write down this big vector space into smaller vector spaces that retain some information about symmetry. Okay? So if you know a little bit of representation theory, you know that I can break down my big vector space into a unique isotopic decomposition. And so here, since my group is a symmetric group, it's going to break down into smaller vector spaces that are labeled, that are indexed by partitions of anna. Okay, then if you know a bit more representation theory, you know that, oh, those break down further into irreducibles, but that's not the way that I want to go. I want to break down my isotypic components into w tau lambda. So for every partition lambda, I have the shape of that partition. So here the partition 5331 gives me a shape with five, three, three and one cells in each row.
00:18:00.874 - 00:19:00.422, Speaker A: And then a standard tableau for that shape lambda is just a filling of your cells with the numbers from one through n so that each number goes into a different box. And when I read from left to right and from top to bottom, I should be increasing. So for any tableau, I can consider the row group of the tableau. So any action that will fix the rows of my tableau, for example, the action one four would be fine, right? Because one and four would still end up in the same row, whereas the action one two would not work. I would be switching the rows of these two elements. And so the w tau lambda that I decompose my isotopic component into is just a subspace of my isotopic component that is fixed by my rho group. Okay, and so we can show that v lambda can be decomposed into a direct sum of the w tau lambda for standard tableau tau lambda.
00:19:00.422 - 00:19:23.814, Speaker A: And so we can call n lambda to be the number of standard tableau of shapes lambda and m lambda the dimension of w tau lambda. If you know representation theory, that is the multiplicity of your irreducible. Okay, big message is that you have this big vector space and now you break it down into smaller vector spaces. That keeps some information about symmetry.
00:19:23.974 - 00:19:29.742, Speaker B: So just the definition of this vector space Rx is a ring of polynomials in x.
00:19:29.918 - 00:20:06.274, Speaker A: So yeah, this is your polynomial ring. And then you mod out by your ideal. And in there you only keep things that have the grad most d. Good question. Okay, so, okay, what did we say, you know, was some of the squares module ideal. Okay, I have a polynomial and it is a sum of squares of degree D module ideal if and only if there exists a PSD matrix q such that p can be written as v transpose qv moduloma ideal. So plus some h that lives in my ideal where v is a vector of basis.
00:20:06.274 - 00:20:40.434, Speaker A: Elements of, yeah, the elements of degree at most d in my quotient ring. So that's how I would do it normally. And so in the early two thousands, Karin Gatarmann and Pablo came up with this wonderful technique to exploit symmetry in semi definite programming. So they said instead of using any basis, use a smart basis. Use a basis that keeps some information about symmetry. Right? You're looking at a symmetric problem. Use a basis that says something about symmetry.
00:20:40.434 - 00:21:30.434, Speaker A: So, ok, look at the decomposition that you get here and find a basis for each w tau, lambda. Altogether, all these little bases will give you a basis for your big vector space v. So, ok, find such a basis, called a symmetry adapted basis. And then what happens to your matrix q is that it becomes very structured. So instead of being like anything, you know, now that your matrix Q is doubly block diagonal. So for every partition, so for every isotypic component, you get one big block, and then for every standard tableau within for a partition, then you get one little block, and each of these little blocks are the same. So you really just need to keep one little block for each of your big blocks.
00:21:30.434 - 00:22:07.080, Speaker A: So that means that in total, the size of your matrix goes from being the sum of the m, lambda and lambda to just the sum of the m lambda. And you know that there's tons of zeros, it's block diagonal. That's a huge improvement. And so even if you don't know much about representation theory, these are positive integers. This is much better. Great. This is great, but it's not enough for what we want, right? So our point for us, we really want to get rid of the dependence on n, right? On the number of variables.
00:22:07.080 - 00:22:45.192, Speaker A: And so here, how much smaller is the size of this SDP? Well, m lambdas are hard to calculate, but they often depend on n. And as the number of partitions of n certainly depends on. Nice. Okay, so the total size still depend on n. And then the other problem is that I need to find this basis for each w tau lambda, and there's an algorithm for that. But the complexity of this algorithm depends on n. So now our goal was really to say, okay, there's this wonderful technique, but it doesn't do exactly what we want.
00:22:45.192 - 00:23:42.452, Speaker A: What if we just look over the hypercube? So here, this was for all symmetric polynomials, right? And you can use any group, really? So what if we specify the group to be sn and we were looking over the hypercube, can we do better then? Can we get rid of these issues. And so we showed that we can. So the first thing that we showed is that basically, if your polynomial is symmetric and there does exist sum of squares of degree D, then you can find your certificate just by keeping a few partitions in Gatorman par. So just keep the first few blocks, and we tell you exactly which ones to keep, and then you'll be fine, you won't lose any power or any information. And so the number of blocks that you need to keep doesn't depend on n, it just depends on the degree D and the m lambdas for each of them. So the size of those blocks also is independent of N. Great, so that's good.
00:23:42.452 - 00:24:07.892, Speaker A: So, for example, in the proof of Mantel's theorem that we saw before, I kept two blocks. I kept the blocks corresponding to the partition n and n minus one. One. That's it. Okay, that's good. Then there's still the problem of we need a symmetry adapted basis, right? And so the algorithm for that depends on n. Well, there, the idea is very simple.
00:24:07.892 - 00:24:41.234, Speaker A: Instead of a basis, just find a spanning set. So find a spanning set for all the partitions that you're keeping. So these are the partitions you're keeping. Now, of course your spanning sets are going to be bigger than a basis, so you need to make sure that now these are not too big, that you're not losing the fact that we just got the size of the SDP to be independent of n. So each spelling set should have size independent of n, and we want them to be easy to generate, right? We want the runtime to generate them too, to be independent of n. And so we show that such spanning sets do exist. They're very simple.
00:24:41.234 - 00:25:30.414, Speaker A: So, for example, you can just symmetrize a monomial under the rho group, and you can take an appropriate Mervi's transformation, you get another one for free. So that's good news. So whenever you are trying to certify the non negativity of a polynomial over a k subsid discrete hypercube, then you know that you can do this in a runtime that is independent of n. That only depends on d, the degree that you need in your sum of squares. Of course the degree can depend on n, right? In that case, you're screwed. Yeah, there's nothing that you can do. But if it's a nice tractable problem where the degree is small, then this is going to be fantastic, right? Both for k is equal to one by the work of Greg, draw and James, or for k greater or equal to two.
00:25:30.414 - 00:26:15.876, Speaker A: The good news, don't stop there. Let me in two minutes tell you about how this links to the work of flag algebras. So, Hasbarov in the early two thousands, introduced the concept of a flag, which for him is just a partially labeled graph. And so he uses this flag to certify symmetric inequalities that give good upper bound for many types of problems. But to keep in spirit with this talk, turn type problems. And so the key features there is that he gets sums of squares, but there are sums of squares of graph densities, not of polynomials. And because of that, n disappears, right? So this whole n being big and or going to infinity business, that's problematic.
00:26:15.876 - 00:26:57.504, Speaker A: The problem disappears altogether. But that also doesn't mean that he can only obtain asymptotic results and nothing else. And he can only do it for dense graphs, because there's this error of order one over n that comes in. So that can eat up the optimal solution if you don't have a dense graph. And so he was very successful for hypergraphs. And so, some of the best results that we have are due to ham. So once these sums of squares, one can wonder, is there any link, Abby Wiggarson asked Sasha, has we have about this, you know, is there a link to traditional solar square theory? And Sasha said, no, no, no, no.
00:26:57.504 - 00:27:44.688, Speaker A: And, well, he was wrong. For once in his life, he was wrong. So basically we show that such as flags, if you think about them as polynomials, they are actually spanning sets for these wt lambdons, right? These row growth, row group fixed subspaces. And so those padding sets are also independent of size n. So that means that if you have a polynomial that is symmetric and a sum of squares of degree d, then its non negativity can be established through flags on KD vertices. Even in restricted cases where you have something about types and flags, it's all good. And while we had already shown that every flag sum of squares polynomial of degree KD can be written as a succinct dsos.
00:27:44.688 - 00:28:11.784, Speaker A: So what this means is that flag methods are equivalent to standard symmetry reduction methods for finding sums of squares over discrete hypercube. One might be a bit faster than the other, but it's going to be, they're going to be very close, is really what we're getting at. And so I think I will stop here. Thank you. Any questions?
00:28:14.884 - 00:28:18.064, Speaker B: The obvious question is, so what's the dependence on d?
00:28:18.684 - 00:28:19.604, Speaker A: What is what?
00:28:19.724 - 00:28:22.064, Speaker B: What's the dependence on d of your running times?
00:28:24.084 - 00:28:28.548, Speaker A: I mean, we we did calculate it at some time. It's not so bad, but it's not a pretty formula either.
00:28:28.676 - 00:28:31.100, Speaker B: Something exponential. Exponential or.
00:28:31.172 - 00:28:34.572, Speaker A: No, no, it's not exponential. It's a polynomial nd.
00:28:34.668 - 00:28:46.260, Speaker B: Oh, yeah, good. And so usually for sum of squares, you have a certificate if you don't have a proof. Right. Of degree D, you have some similar thing.
00:28:46.452 - 00:28:49.356, Speaker A: You mean like more complexity, result, type of.
00:28:49.540 - 00:29:06.964, Speaker B: Well, let's say you want to find, you have your favorite theorem that you want to prove. You want to prove it with a sum of square proof as you just of degree D, and you try and you don't find one. And could you give a witness for that? Possible.
00:29:07.624 - 00:29:25.396, Speaker A: Then it's not possible to do it. I mean, we've never tried. Presumably we could. Certainly, we're trying to get positive results. So what we do, if we fail with a certain degree, then we just go higher. Right. So we're more in the positive result kind of business and not the negative.
00:29:25.396 - 00:29:35.524, Speaker A: But other people could go another way with it, for sure. All right, let's thank anyone.

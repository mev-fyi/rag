00:00:00.200 - 00:00:38.084, Speaker A: The talk by Alex Nadel on conflict driven cross learning, sat solving and how it can be used for optimization problems. Alex, without further ado, please. Ok, thank you very much. So this talk will consist of two parts. In the first part, I talk about core CDCL substrate, which will be mostly review of the foundations of CDCL. And then I'll talk about solving complex optimization problems with sats. So the first part is mostly about the past, and the second part I believe should be an opportunity for the future based on my own industrial experience, which I will share with you.
00:00:38.084 - 00:01:16.814, Speaker A: So let's get started. Let's get started from the very beginning, although everybody knows that, but still. So sat is the problem of determining whether a boolean formula in CNF is satisfiable. And it's the original intercompute problem. There is a famous Cook Levin theorem from the early seventies, which means that SART has an exponential complexity, unless p is equal to p. Whether this is, of course, frequency sight is the most important outstanding question in computer science. So it all boils down to a question, if checking a solution is easy, whether it's also easy to solve the problem.
00:01:16.814 - 00:01:57.244, Speaker A: And it's really a knowledge of mystery, right? So it's one of the most intriguing open questions in computer science. But however, such solvers are highly scalable tools. So how come there is this gap between theory and practice? So we don't know for sure. But what we do know is that the fundamentals of modern stack solvers, the fundamental algorithm there is Benker search, and it was developed in the early sixties. It's called DPLL or DLL. So let me show you how to get from some basic enumeration to DPNL. And then we will get the CDC.
00:01:57.244 - 00:02:39.408, Speaker A: So we have the CN formula, right? We have two clauses here, literals. And so the easiest way to solve it would be to come up with this enumeration of all the possible solutions. So we just build this tree, and then you have vertex, which corresponds to a variable, and then boolean values to the left and to the right. And then you have. So you enumerate all the solutions. And then if there is a right square, it means that the formula is unsatisfiable, and green square, which means it's satisfiable. So this is kind of the basic approach to solve this problem, a straightforward approach.
00:02:39.408 - 00:03:15.644, Speaker A: But then of course you can also stop when the close terms unsatisfiable, right? In this case, it first close unsatisfiable. So you can stop here. So this is one improvement made by the authors of DPA. Then. And then the most interesting idea there was to carry out backlash. And then stop when the first model is found, because you need only one model. So you just pick a variable, you assign it to some value, and then you pick another variable, assign it some value, and then you stop, because the closer it turns out satisfiable, and you flip it, and you find the model.
00:03:15.644 - 00:04:17.276, Speaker A: And then yet another improvement, which was introduced already in DPL in these two original papers, has something to do with unit clauses, where a unit clause is a clause in which one variable, one literal, is unassigned and the rest are falsified, and then one can observe, then all the clauses must be satisfied. And then the unit close rule is says that you must assign the unassigned literal, you must satisfy it. So the unassigned literal must be implied in the clause. And so it was observed that it pays off. It really pays off to apply the unit close rule till fixed point, which is known as bunangutan propagation. So in this case, you would just pick your variable, assign it to value, and then b would be implied. In the first close, it's parent loss, and you would pick c, and then you would just sort of find, find the model.
00:04:17.276 - 00:05:05.954, Speaker A: Okay, so this is the basic DPL algorithm. However, DPL could handle really small formulas with under 2000 clauses, while modern sum solvers can hold with huge industrial instances of hundreds of millions of closes. So again, how come? And so the turning point was the introduction of CDCL conflict driven cloud learning or simply confident solving. And that was in fact the birth of modern high scale Assad solving. So the idea is to learn from conflicts, right? From those racers to drive and from battery search. That's the basic idea of CDCl or conflict damage solving. And let me quickly go over the intuitive principles of modern CDCl subs.
00:05:05.954 - 00:05:34.040, Speaker A: So the first one is learning and pruning. So whenever there is a conflict, you want to learn some strong framework, some clauses, and improve the search. Then there is the locality principle. So you want to focus your search on the relevant data. So if you cannot find such data, then you will apparently fail. You won't be able to solve the formula. But the SAT solvers are really good at it, so they can find some local context and learn some strong closer from that context.
00:05:34.040 - 00:06:21.516, Speaker A: And then go on, find another local context. Okay, this is only kind of not precise understanding, right? Just heuristic understanding. But I think that if you cannot, if they cannot be local, if you cannot find a context to learn from, then you will just fail. Then there is the third principle of well engineered data structures, which restates to extremely fast Boolean constraint propagation BCP. And these days there is also, there are also some orthogonal techniques to this CDCL, like in processing and very recently local search integration. So these are the principles behind modern CDCL substance. And in the first part of this talk, I'll give you an indepth dive in the core of the core.
00:06:21.516 - 00:07:08.888, Speaker A: I call the core the correspondence loop and Boolean constraint propagation only. So I won't talk about the other algorithms. Now, the seminal works, the two seminal works for coefficient driven slots solving are the works about grasp by Joao Marcus Silva and Karim Sakalaku is just here. And the work on the chaff sat solver by the peninsula group, it was also boarded by the COVID board. So I'll go over the algorithms of chaff and grasp and compare them. But first I would like to talk about Boolean constraint propagation. So the Boolean constraint propagation BCP is a crucial algorithm because it consumes the vast majority of the runtime of modern SAP solvers.
00:07:08.888 - 00:08:06.164, Speaker A: So what it does, it first, it identifies and propagates in unit losses. This is essential for performance. So you can kind of skip this first part, because this is not really necessary, because when you, if you, even if you skip it, and you, once you decide on the literal, you will identify that the clause is unit, essentially. But this is really good for performance, to identify unit loss and propagating them. And then it's essential for correctness to identify and report any conflicts. You cannot afford yourself to skip conflicts, right? Because then you don't have it correctly. So how is it carried out? So every literal holds a watch list with all the clause where L is watched, and then when the literal is falsified, the solver goes over, visits all the clauses in its, in the watchlist of not L.
00:08:06.164 - 00:08:51.292, Speaker A: And so. So it really pays off to keep that watch list short. So let's go over efficient data strategies for BCP. So grasp watched all the literals, right? But then the crucial observation that it is sufficient to watch two literals was made by hand au Zhang in satosat solver. So here it's sufficient to watch two non falsified literals, so, literals which are either unassigned or satisfied to ensure to guarantee that the clause is not unit nor conflict. So you just hold these two pointers. But in Sato, there was an order between these two watched literals.
00:08:51.292 - 00:10:15.534, Speaker A: There was a head and a tail, and then all the literals to the left of the head were falsified, you had to ensure they're falsified. And the same goes for the literal to the right of the tail, and which also required the solver to visit clothes while backtracking. And then that was that limitation was removed by the authors of chaff, and they observed that it is sufficient to wash the first two literals in every clause, and then you do not need to visit clauses during backtracking. You also need to make sure, though, that the decision literal of a falsified watch, if there is a falsified watch, is not lower than decision level of falsified non watches in order to guarantee that when once you backtrack, the watch literal becomes unassigned before any non watch literal, and then we are fine. All right, so the last thing I wanted to mention here is that it was found that caching one literal of the clause inside the watch list really pays off, because then if that literacy is satisfied, you don't need to go to the close itself in the closed database, and so you save cache misses. And the related observation is that you don't really need to store binary clauses at all in the closed database. So for example, Kisat does not store binary clauses.
00:10:15.534 - 00:10:58.622, Speaker A: So this slide summarizes efficient data structure for DCP. And now we go back to configuration analysis. So I'm now going over configure algorithm of chaff and that of grasp, and then we'll talk about follow up solutions. All right, so consider the formula on the left and let us recall how chaff works. So first it would pick a decision variable, say a at decision level one. It will try to propagate a divisive, but here it cannot be propagated. So it would pick the next decision literal, b and c and d and e.
00:10:58.622 - 00:11:49.694, Speaker A: And then at this point we actually have literals implied by previously assigned literals. So it would imply f in c five, because f terms unit, and it would imply g at c three. And then there will be a conflict cause then c two would become falsified. So here is what chart does. When there is a conflict, it learns a falsified so called asserting clause. So the first iteration in the clause is always the literal of the last decision level, then the last decision level data. Then there is a literal of decision level beta lower than delta, and then the rest of the literals must be assigned, must be falsified for decision levels which are not higher than beta.
00:11:49.694 - 00:12:23.534, Speaker A: So we have the highest decision level, then the second highest decision level, and then the rest of them. And shuffler, the so called first, I remind you about first therapy. Very soon after that, a chart backtracks to level beta, which renders this closed units. And then you can flip c one with c, with this clause being its parent clause, and run Bcp. So that's chaff's algorithm in a nutshell. Let's continue this example. So, in order to learn a clause, one can construct an implication graph.
00:12:23.534 - 00:13:02.236, Speaker A: So another way to look at it would be through resolution derivation. But here I present this way. So in the implication. The implication graph essentially shows the dependencies between the implications between the literals. So for example, giving is implied at close c three, right, because C was assigned true and f was assigned true, etcetera. And then you can draw this first uap cut. So on the right hand side there is the conflict, and on the left hand side there is the reason, including the so called right most unique implication point, which is f.
00:13:02.236 - 00:13:55.712, Speaker A: So this is essentially a literal of the last decision level, which is sufficient to out of the literals of the last decision level, it is sufficient to imply the conflict together with other literals from previous decision levels. So there it stops, and there is an associated clause, so, which comprises not f, because f is on the left hand side of the cut, not c, and not b. If you learn this clause, it will prevent the conflict from reappearing. So chap would learn that close it would backtrack non chronologically to decision number three. So it would skip d decision level of d because it has no part in the conflict. And then after that it would flip f in that newly drawn cause. And there will be some further implications, in this particular case, a conflict.
00:13:55.712 - 00:14:40.070, Speaker A: So it would again generate this implication graph, the only first epic loss, which is in this case f or not a. Then it would backtrack non chronologically to decision level of a because b and c do not contribute to the conflict, and continue in this manner. Okay, for this is chaff. This is the well known classical algorithm. Let us now go back to grasp and recall how confidential looks, looked, and grasped. Okay, so the algorithm was a little bit more complex. So there was a preliminary step of backtracking to the conflict level delta that was called non chronological backtracking in grasp.
00:14:40.070 - 00:15:19.012, Speaker A: Okay, we will talk in a minute. Why grasp needed this preliminary backtracking? Then it was still learned a falsified, assertive, frustrated cause. This step is similar to chaff. It remained in chaff grass, also learned a close per every other UAP of the last level. But then it would backtrack to level delta minus one rather than to better, which is currently called chronological backtracking in the modern literature. Right? So grass would do, again, in modern terminology, would do chronological backtracking, unlike chaff. And then it would again flip and imply c one.
00:15:19.012 - 00:15:57.824, Speaker A: So let me show you how it works on this example. So again, we have the same example and the same decisions here, ABCD and E, the same implications, and we get to the conflict. So here, first chap would, sorry, grasp would learn the first type, similar to chaff. Then it would also learn the second UAP clause, another clause. So it corresponds. So here, the unique implication point is the decision literal of the last decision level. So this is also a valid clause corresponding to the cut.
00:15:57.824 - 00:16:56.444, Speaker A: So it would learn several clauses. If there was a third UIP, it would also learn a close, et cetera. Then it would backtrack to decision level four. So it would carry out essentially, again, in modern terminology, chronological back setting, and would flip, would flip f. In grasp f is called a special kind of flip decision variable at level five, but it actually proceeds as if it were a literal implied at level three. So it is essentially implied at level three because c six, right, is it consists of literals b and c, and the highest literal of them is c, which goes to level three. So again, despite the fact that we are at level four, this literal is implied at level three at a lower level.
00:16:56.444 - 00:17:28.265, Speaker A: And then it would imply g at level three. And this is the implication graph. So now here we have this preliminary step. The conflict occurs at level three, but, and we need to backtrack to the conflict level before doing conflict analysis. So grasp would actually backtrack at this point, would remove level four because it's not related to the conflict. And then it would again learn, it would learn the first epic loss, the second epic loss, back chronologically. Okay.
00:17:28.265 - 00:17:33.294, Speaker A: And continue in this manner. So this is the algorithm of grasp. Yes.
00:17:33.994 - 00:17:58.666, Speaker B: So the summary here is that on the first conflict, the summary here on the first conflict, instead of just jumping immediately, it tries to imply the last variable that was assigned by decision to lead to a conflict. It checks to see if the other assignment is now an implication of the conflict. And if it is, then it backs.
00:17:58.690 - 00:18:09.346, Speaker A: Track on the first comment. It wouldn't back technologically at all. It would always back the chronological, like a short field.
00:18:09.410 - 00:18:43.414, Speaker B: Well, I mean, you call it chronological, but what it did is, okay, yeah, we have a terminology confusion over here as well. But what it does is instead of just saying I got a conflict, if I make this assignment, and then backtracking narcologically it tries the other assignment by implication, it says, since this assignment led to a conflict, the, I think what Joa Pablo called it is the failure driven assertion. It says the other value is also not a decision, it's an implication. And if that is unsafe, if that is a conflict, it backstracts.
00:18:44.314 - 00:19:38.936, Speaker A: Yeah, I think, yeah, I mean, again, I try to formulate it in modern terminology, but this is the same algorithm. I talked to Joao essentially in a very long email thread, and he agreed to say that this is essentially the same. After all, the interesting thing that modern solves actually go back to grasps him, which I will show next. So let me now present or summarize an up to date conflict analysis loop algorithm, which covers grass and chaff, but also modern solvers. First, there is this preliminary backtracking step, or back taking to conflict level if required. Okay, so it's done by grass, but not by, not by chart, because in chart the current decision level is all the conflict is always the conflict level. Chaff back.
00:19:38.936 - 00:20:30.664, Speaker A: It's not logical. Then the solvers learn an assortment clause, which is the first type of clause in both grasp and chaff, and optionally some other clauses, for example, the other clause which correspond to the other UIP. And then they backtrack to a decision level inside this interval between beta, which is the level to which sharp would benefit, and the delta minus one. So grasp always vectors to delta minus one, which corresponds to chronological background in today's terminology. And chap would always better to beta. Okay, now modern solvers, I'll talk about it in the next slide. They sometimes vector to beta, sometimes to delta minus one, sometimes to levels in between.
00:20:30.664 - 00:21:21.532, Speaker A: Okay, but still, this scheme covers all the solvers, as far as I know, all the modern solvers. And then there is this step of flipping c one and implying it in the newly generated course. So this sums up the confinery swoop algorithm as implemented in modern solvers and also in the first CDC servers. Let me now talk a bit about modern solvers. What they do so grasp was invented in 1996. Then there was chaff in 2001. And Chaff's algorithm, which generates one first epic clause and then does non closure tracking, was the state of dart for a very long time, for 17 years, until there was this, our work about Maple CB.
00:21:21.532 - 00:22:02.448, Speaker A: So we implemented chronological backtracking in the leading solvent at the time, one of the versions of Maple. And what we did there is we implemented a backtracking heuristic which chooses between chronological and non chronological backtracking. I will not go into the details, but just that at every conflict you can choose whether you do chronological or non chronological backtracking. And this hem is essentially used by almost all the solvers, except for cadecal, which I'll mention next. So it used by metal based solvers, cryptominisat, kisset. And so one can say that modern solvers went back. So do something in between grasp and chaff.
00:22:02.448 - 00:22:53.048, Speaker A: Okay? So they relax this requirement of backlink and nonprofit logic, and it seems to help, especially on satisfiable incidences. And the chronological background algorithm in these solvers is essentially very similar to Grasp's. But it was still a huge challenge to implement it, because if you remember, grasp watched all the literals in the closest. But it turned out that it's difficult to combine chronological backtracking with the two watched literal scheme, which is essential for efficient BCP. And this is because of simultaneous propagation at several decision levels at once. So it turned out that BCP must be adjusted to prevent not only performance issues, but also correctness issues. And then useful BCP invalids are still violated.
00:22:53.048 - 00:23:32.402, Speaker A: So I'll show you an example. Before, I just mentioned cadycall. So katical uses a different background scheme. It backtracks to the decision level. In that level between the highest decision level and the second highest vision level with the greatest variable score. It's applied by critical and also by myself, which I'm going to mention. Okay, so now, yeah, and in critical, there is an integration between crosscode and modern BCP schemes, of course, but it's not discussed in the paper.
00:23:32.402 - 00:24:13.332, Speaker A: So we also did not discuss it in our original paper. But let me show you why it is challenging to integrate chronological backtracking in the CP. So here we have this close. So the first two literals are unassigned, and next, literals are falsified at levels 2030. And then assume that the first literals are falsified at level one, which can now happen because the implication when chronicle backtracking is applied, implication can be at any level, not only at the latest level. Okay, but. And then you.
00:24:13.332 - 00:24:42.374, Speaker A: And there is a conflict in this course, right. But before proceeding, you have to flip literals here. You must make sure that the first two literals are the highest in the close. If you don't do that, you have a correctness problem. And essentially all the solvers that implement chronological do this. Right, but it was not documented, although it's essential for correctness. Now, let me show you some invariants which are still violated even with the adjustment.
00:24:42.374 - 00:25:27.054, Speaker A: So the first invariant I call it lowest implication, it was a string. So no assigned literal can be implied at a lower level. So essentially this situation cannot happen. You see, there is a close here with two liters falsified at level ten, and then a literal satisfied level 20. Now that literal could have been implied in this clause, right at level ten, but in practice, and it would be better, it would have been better. But in practice, all the modern solvers except for intracept, which I'm going to mention, actually allow for this situation to happen. And then you could essentially compress your decisions and compress your implications if you allowed to imply the literal in disclose.
00:25:27.054 - 00:26:00.102, Speaker A: And then another variant which is violated is, I call it lowest conflict. So in chaff, for example, at every conflict, BCP returns a clause falsified at the lowest possible level. So there are two potential conflicts here, one at level 21, at level 30. So a solver which implements non colloquial backtracking would always find the lowest conflict. But this is not the case for gambling key set. It could find this conflict first, and then it would do conflict analysis. It would learn a new clause.
00:26:00.102 - 00:26:43.452, Speaker A: Eventually it would discover the lower conflict too. But it will take time and effort, it will carry out conflict analysis for this clause, and then after backtracking and flipping and doing BCP would actually discover this conflict as well. But there can be any number of these conflicts. So these two environs are violated. Now, in my new solver, which I implemented several years ago, two years ago, I have a new scheme which actually ensures lowest implication, lowest conflict. So I'm just going to to tell you a bit, a few words about my solver, and then I want to move to the next topic. It's an open source citizen solver, written from scratch.
00:26:43.452 - 00:27:22.134, Speaker A: And there is a paper at SATS, and also recently I gave a talk about the talk about the solver, which you can now seminar. So there is a video of the talk, it's free, and there is a public repository, and it's tuned towards incremental applications with multi satisfiable quiz in the paper. The applications, anytime we get knockset. But at intel they are using it for optimization problems like placement, scheduling, etcetera. Which brings me to the second part of this talk. So now I'm going to talk about optimization problems. If there are questions about the first part, please do ask them.
00:27:22.134 - 00:28:07.468, Speaker A: When you're finding the conflict clause, a lot of programs like Minnie said, are able to reduce the size of that clause substantially. You take care of all those reductions as well. You know what I mean, a lot of times you come up with a clause of size 20, but you can reduce it to size 20, but the decision levels do not change there. So still. So I do that too. But it does not change the decision levels in the close. So the close becomes minimized, but the decision levels are the same.
00:28:07.468 - 00:28:45.688, Speaker A: And so this distinction between chronological, not so, it does not change the basic algorithm. That's what I mean. Although the close is minimized, it does not remove decision levels from the close. All right, let me then move on. So now I'm going to talk about optimization, how you can solve optimization for problems with SAT. So let me formulate here the so called offset problem. So it was as follows.
00:28:45.688 - 00:29:38.448, Speaker A: On the input we have a propositional form of f and conjugate normal form as in the standard SAt soldier. But then there is also pseudo Boolean objective function, psi and object would return, is required to return a model to the formula f, which minimizes sign. So let me just remind you that this pseudo Boolean function is just emitting from every full assignment to a real number. So for example, here we have a pseudo Boolean function given in a table, and then we have this formula f. It has three models, and in order to find the minimal model, we just check in the table the values for every model. So it's 875 20.4. And then an opposite solver would just return m one, because it's the minimum model.
00:29:38.448 - 00:30:34.764, Speaker A: So this is the problem of optimization inside, formatted in the more generic manner. Right? I don't tell you here how the function, the pseudo Boolean function is provided, right? That's the problem. How can you solve this problem in practice? It depends on psi. If psi is a linear function, right? Then what you can do is you can just use Maxx, which is a rich and well established field. There are many maxos out there and they do linear optimization and such. But what if the function is not linear? What do we do in that case? So it turns out there is only scarce research on the topic, almost no research at all. So I'm going to tell you about our contribution, the so called pulse algorithm, which simulates local search with satisfaction.
00:30:34.764 - 00:31:25.696, Speaker A: And it's sufficient and simple to implement. I mean, I found it sufficient in my industrial practice. And then there, so there is also another work which we did about high level local search when you use a Sat solver or a polosat solver as an oracle. So I just mentioned it here, but I won't talk about, I won't go into details today, so I'll talk a bit. I talk about polosat and then I'll try to share with you some considerations about the importance of optimization in SaT and future directions. So now I'm going to present to polosat. So polosat is, what it does is minimize a black box function given a Sat formula, right? So again, you have a Sat formula and you have a function.
00:31:25.696 - 00:31:57.684, Speaker A: Now the function can be provided to, to the algorithm when you implement it. It can be provided as a black box function, right? So just a function with the solver calls. So it does not have to be represented in any, any manner. It can be anything. Okay, so how do we use pulseat? So first you create the CNF formula, and then you call the Sat solver. And as I said, you provide it a callback function. You can also call it under assumptions in incremental flows.
00:31:57.684 - 00:32:43.980, Speaker A: And then the solver will query the function when all the variables are assigned and it expects the function to return a number. Again, based on that, the solver does optimization. And there's no need to bit blast the function into close, you can just calculate it offline. So it can be a complex anything, right? A complex negative function. So in practice, in practice, the function depends on a subset of variables, normally, which I call the observables, and it is strictly monotone in these observables. So when an observable is flipped from one to zero, the function is decreased. For example, it holds for max, right? It's a linear function.
00:32:43.980 - 00:33:43.714, Speaker A: So if you flip any b from one to zero, then the coefficients are positive and so the function goes down, but these restrictions can be lifted. Now the idea behind polyfat is to simulate local search with a Sat solver. So here is the algorithm. First it calls a sat solver over the formula f, just to find the first approximation for the optimization problem. And then there is an external loop which runs an internal loop until the model m is not improved anymore. So the algorithm tries to improve m in an anytime fashion. Now, what does the internal loop do? It goes over all the bad absorbers, where absorbance is bad if it has never been assigned zero in any model, and it tries to find a model in which it is assigned zero.
00:33:43.714 - 00:34:11.684, Speaker A: So it tries to flip the current bed observable as follows. It provides it as an assumption, provides node b as an, as an assumption. So notice here that it cannot find the same model again, because it is guaranteed by construction that we flip the value of b. Yeah, and then if performance satisfiable and we found a better model, we just update m so that's the essence of the algorithm.
00:34:17.264 - 00:34:20.448, Speaker B: But do you preach a local minimum?
00:34:20.496 - 00:34:42.724, Speaker A: Yes, it's an incomplete algorithm. I'm going to talk about it. An incomplete algorithm, it can be integrated into complete algorithms and I am going to talk a bit about it. When you get to the local minimum, you're done? Yes. Okay. So there's no coming back. In order for the thing to work in practice, there are several things you need to ensure.
00:34:42.724 - 00:35:14.332, Speaker A: First, this is really crucial. You need to apply polarity fixing. What do I mean by polarity fixing? You modify the polarity selection scheme of the subsolver. So wherever a solver chooses a variable, you assign it a certain value. So you override the polarity decision heuristic of the start solver to simulate local search. In practice, what you do is the following thing. You fix the value of the observables to zero because you want to go to the local minimum.
00:35:14.332 - 00:36:05.674, Speaker A: You want to go to the minimum. And the other rest of the variables, you fix them to the best model so far. And that makes the solver, so that makes the solver do local search around the latest solution with some bias towards the minimum or a minimum. Okay, this is a crucial step. It makes the algorithm to simulate local solution because you always look for a close solution. Another thing which has to be done is to use a conflict threshold for every invocation in practice, because otherwise you might get stuck and you don't want to because you have many, many calls to make and it's just an incomplete algorithm. And then another thing which helps is to boost the variable scores of the observers so that you would start with the observables.
00:36:05.674 - 00:37:12.424, Speaker A: But if you just fix them to zero and if you use them as assumptions, it would never finish because it's too strong. But if you just boost the response, it normally makes the algorithm work faster, work faster because it will start with a solution closer to the mean. So that's the algorithm, as I said, it's an uncomputed algorithm, but it can be integrated into high level complete algorithm by just, by replacing, if you have a high level complete algorithm, just linear source for example, which we will go over next, then you can just replace subqueries by post queries and you're done. And then your complete algorithm still work and it will work faster in multiple. So that's the idea. Now I'm going to talk about an application. So this is an industrial application, we are actually using this algorithm introduction that intel and for several applications this is kind of the main application and the application is placement.
00:37:12.424 - 00:37:52.564, Speaker A: So the problem is about placing cells on a grid. Okay? So for example, this is an example instance and this is a solution. So we just placed these cells here, right? So there are no further constraints here. So they're placed and this is a solution. And this problem is already complete because degree is restricted. That's what makes it decomplete, right? Because if there was a limited space, then it's a simple problem, but it's limited. Then in practice, you also need to optimize your placement.
00:37:52.564 - 00:38:45.524, Speaker A: So there are so called nets. So the cells are marked with nets and, and the placement, so the net size is the perimeter of the boundary box of the box bounding all the cells which belong to that net. So for example, so this yellow bounding box form net one. This is bounding box for net one because it goes, it bounced c one, right? And then c three and c five. There are three cells which are marked with net one and they're bounded. So this is an example and the goal is to minimize the sum of all the net sizes. So you want to sum of all the net sizes to be minimum.
00:38:45.524 - 00:39:32.114, Speaker A: That's the golden practice, because then again, in industrial practice, if you place them and if you follow this optimization requirement, then routing is much easier. So you have a good placement. That's the idea. Now, in practice, there are also some additional constraints which are translated to sats, but I'm not going to talk about them. Now, how can you solve placement? So you can translate it to bit vector logic and then through bit vector logic to some, essentially. So every cell has a constant width and constant height. And so we introduce two bit vectors which represent the bottom most corner of every cell.
00:39:32.114 - 00:40:02.174, Speaker A: And then to find the solution, one has to ensure that there is no overlap between each pair of cells and the constraint is written down here. It's quite simple. So this is a constraint in bit vector logic, but it can be bit plastic translated sat. And also you have to make sure that all the cells are placed inside the grid. The percentage keep here. But again, it's quite a simple constraint and this way you can translate placement to sat. Of course, if you have additional constraints, you can just add them to the formula.
00:40:02.174 - 00:40:53.694, Speaker A: Right. Now, if you want your solution to be optimal in some way, then you have instance of the so called optimization model, bit reference problem, obv problem. So in this case we have the constraints and then we also need to minimize the value of the so called optimization target t, where ni expresses the net size for every net. So you can just, you can create this variable for every net, this is a bit vector formula. Yeah. And then you have this target to minimize and you can provide it to which does optimization model in between. Now these two, they do either binary search or linear search essentially.
00:40:53.694 - 00:41:31.244, Speaker A: And here I'm going to show you how you can solve it with linear search because it's faster in practice than binary search. First you assert your formula, find the solution and then you just do linear search. While new is still a solution. You, you assert that the value of the target should be lower than it's very new and you call saturation. So this is just linear search. This is a complete algorithm and an anytime algorithm, which is good. And it essentially outperforms binary search algorithms, but it still gets stuck in practice in data set.
00:41:31.244 - 00:42:20.782, Speaker A: Now what you can do is just to run the same algorithm and replace certain locations with poly satin locations. And essentially you are done, you have a new algorithm, and as I'm going to show, it's faster than if you're using Sat only. And now to implement polosat, you need to provide a callback function. In this case, the function would simply return the value of the target bit vector under the current model and the observables would be the bits of the net sizes. And then the function is monoton mD. And that's it. You can do it, you can pick, you can pick an algorithm, a complete algorithm and replace your satcols by polished calls.
00:42:20.782 - 00:42:49.684, Speaker A: You need to define your optimization, your blackboard optimization function and observable security. That's what we do. And then, so I'll show you some results on industrial batchmaps. So let me just go to the results. So here what we have, this is a timescale from 50 seconds to 600 seconds. And we measure quality for every timeout. And the quality is just a normalized quality.
00:42:49.684 - 00:43:12.856, Speaker A: So one is the best result and in this case 0.6 is the worst result. Now the red graph here is binary search with SAT. The blue one here is a linear search with SAT. So you can see that linear search is better than binary search. And there is a huge gap here. And what is important for this talk is the green line here, this is linear search with polar search.
00:43:12.856 - 00:43:51.478, Speaker A: So you can see that there is a huge difference between the blue line and the green line. And here we have virtual master. And the rest of the figures, they correspond to this, the follow up paper which I mentioned, which does local search with the sat or polo sat solver as an oracle. So that improves the solution further. But still, you see there is a huge gap here between linear source with that and linear source with polosat, it works well in practice. And then we also integrated polosat into a Maxat solver. TT open wim was the winner in max evaluation four years ago.
00:43:51.478 - 00:44:35.974, Speaker A: And again, we just replaced SaT indications by post indications. But a crucial step in the context of muxat was to use an adaptive strategy to stop pulse act when it gets too slow. That would made it work for Moxat inside the Moxat solver, because in Maxat, you really need to be quick, because it's kind of linear search, a linear optimization function, and it's easier then more complex nonlinear functions. And then you can see, again, these are the results. So here, this is the baseline solver. Again, we have here timeouts from 1 minute to half an hour. And here is the quality, the higher the better.
00:44:35.974 - 00:45:20.464, Speaker A: And so this is the baseline solver, the blue one, and positive is the red one. There are some modifications, other modifications, other solvers. But again, there is a huge gap between the bison solver and pulse. So this algorithm works in practice. And essentially it was. So we are using it for industrial optimization problems at intel and the latest market evaluation, it was used by the winner in all the incubator categories, which was WLSC. Okay, now I'm done with describing my own issues, my own approaches to solving this problem.
00:45:20.464 - 00:46:06.400, Speaker A: And the point I wanted to make next is that I think that solving complex nonlinear optimization problems is an opportunity for the SAT community. So, it is well known the currently SAT based verification comprises the heaviest uses of SAT in the industry, right? So if you go to, for example, to the Cav 22 program, there were several invited talks. So there was in talk by Ziad Hahner from credence, harnessing the powerful verification for the trillion dollar chip design. So it's about verification. Another talk by Neha Rumta from Amazon, a billion SMT queries a day, which is, again, about verification. So, using hardware verification. But what about industrial optimization problems? So, I think there should be many of them, right, in practice.
00:46:06.400 - 00:46:40.586, Speaker A: And how could you solve them? So you can do it with integer linear programming. But then, if the problem is nonlinear, there are also some approaches which improve, like do non linear programming. But it's not easy to do that because there might be some boolean constraints. And also, it's not. It's really not very well known how you do it if your function is a bloodlet function. So. And as I said, we already have something working in the interface.
00:46:40.586 - 00:47:50.650, Speaker A: So my intuitive feeling is that there is a lot of places for exploration here. So just let me talk about several ideas which I had, but I'm sure there are many more ideas how you can solve complex optimization problems with SAt. So first we used, so we are using sat based local search, but there is of course, classical local search, which one can also use. And local search is now a component of modern SAT solos. And I believe it can also be harmless for solving optimization problems like with nonlinear objective functions. I can think about dedicated algorithms for subclasses, optimization functions. And now the constraints, as I presented, the constraints are just clauses, but you can think about other types of constraints, for example, pseudo Boolean constraints, right? And then you could come up with optimization algorithms for other types of constraints, not only complex optimization functions, but also more complex constraints.
00:47:50.650 - 00:48:29.864, Speaker A: And then one can look for more applications. Again, I think that if we have industrial applications at intel, that's just because we are looking there. If you look at the broader industrial problems, I'm quite sure I can find many optimization problems which are currently not very well solved. So that's my message for this part of the talk, and I think that I am done. Thank you for attention. We have plenty of time for questions.
00:48:31.084 - 00:48:32.780, Speaker B: I just have clarification questions.
00:48:32.852 - 00:48:33.204, Speaker A: Yes.
00:48:33.284 - 00:48:52.564, Speaker B: So when you say we have these constraints about the placement, these are encoded as CNF clauses as well, right? And so the question is that CNF formula, how many satisfying solutions does it typically have in an application? Does it have lots, or.
00:48:54.304 - 00:49:05.084, Speaker A: Normally it has lots of solutions, and so you just need to find a good solution out of many solutions, which it has. And yeah, I think that maybe you're thinking about symmetry breaking.
00:49:05.464 - 00:49:35.260, Speaker B: No, no, no, I'm not thinking, I'm just thinking about. Okay, so you have, you have this objective function, you know, which is the thing that you want to optimize. Right? And it depends on these boolean variables that describe constraints. If the constraints are infeasible, then that optimization is just meaningless. So it must have. I'm just curious to know, are there many, many, many solutions that will give you some value of the objective function, and then you're looking for the smallest one, for example.
00:49:35.292 - 00:49:38.716, Speaker A: Yes, normally there are many, many solutions and you're looking for the minimum.
00:49:38.780 - 00:49:39.626, Speaker B: Yes, I understand.
00:49:39.740 - 00:49:45.278, Speaker A: One good solution. And also, again, you do not really have to encode your function into clauses.
00:49:45.326 - 00:50:06.978, Speaker B: I understand that, I understand that. So the next question is, every time somebody talks about local search in the context of backtracking search, I get extremely confused. So what exactly is the local search that's happening over here? Is it self solver? After it finds a solution, now flipping bits and seeing if there are in the neighborhood any other solutions. Is that what's happening? What is that what poly set is doing?
00:50:07.106 - 00:50:43.218, Speaker A: So assume you found the solution and you want to find the solution nearby. You want to make the solution, finding a solution nearby, the one thing you can do independently of polosat and say you block the solution, then you want to find the solution nearby. You just modify your polarized selection heuristic. So as every time variable is picked, its polarity is fixed to the polarity in the solution, and then you are likely to find the solution nearby. And that simulates local solution. That's the core of what I mean, you see. So again, you ran a start solving some problem over, you found the solution independent of optimization.
00:50:43.218 - 00:51:18.876, Speaker A: Now you want to find a closed solution, a solution nearby. So you block your previous solution, for example, with the clause. And what you do, you run your solver incrementally and you modify its polarity selection heuristic. So it picks a variable, and instead of using this face saving polarity selection or whatever, you just always select the value in the latest model for every variable. And then you will stay close to the last model. And that's why I talk, I refer to it as local search because you kind of stay low, you stay near latest model.
00:51:18.940 - 00:51:24.092, Speaker B: In my understanding, local search is you get a complete assignment and then you arbitrarily flip a bit and you get a neighbor.
00:51:24.148 - 00:51:29.628, Speaker A: Yes, in classical search, but here in Polosat, you flip a bit differently by.
00:51:29.796 - 00:51:32.500, Speaker B: Okay, so call it something else, don't call it local search.
00:51:32.572 - 00:51:39.172, Speaker A: That's all. No search. Yeah.
00:51:39.228 - 00:51:42.932, Speaker B: Another way doing local search, it's confusing, I mean, because, but I wanted to.
00:51:42.948 - 00:51:45.900, Speaker A: Make a point that it's actually doing some kind of local search, although some.
00:51:45.932 - 00:51:48.464, Speaker B: Kind of local search, but not a classical local search.
00:51:49.004 - 00:52:42.400, Speaker A: Yeah. Thank you. So any sort of what you think maybe course somehow to speed up your soar because you find a solution to look around, but then maybe when you find a new solution, when you do this local search, if you don't like the name of it, whatever, looking around the neighborhood, you forgot everything that you. It could be a good idea, but I didn't do any research. Yeah, combining local search maybe, and like answer based maxim algorithms. I just want to quickly ask the self placement problems, what sort of industrial tasks does that come up in? Just placement. You need to.
00:52:42.400 - 00:53:15.064, Speaker A: So if you design a chip, eventually you need to place transistors on the chip, right, right. So you need to place all billions of transistors and so you divide these tasks into many subtasks. So first you place transistors in the cell. For that you need placement. Then you place cells like in what's called the farm, and then you place places. You place fabs on a partition, then partitions on the chip. So there are many stages of placement, but you know, you need to do it somehow.
00:53:15.064 - 00:53:57.366, Speaker A: Thanks. So actually, two comments on two questions. So for the last one from Nina, I think this is happening naturally if they are using polosat in some algorithms where you are two machine as a problem that is defined by the core that you just got in the Maxat solver. So in some Maxat solvers, you have a core on the soft clauses, and then you optimize that subproblem. If you are using polosat, then you are using information indirectly of the core. Okay. It's not that you are covering all the sub clauses, you are just focusing on a subproblem and the other.
00:53:57.366 - 00:54:19.366, Speaker A: It's already happening. Is that what you mean? Yes. I mean, you are optimizing just as a problem, just as a set of the subcloses, you're trying to get the best assignment there. And actually a name for this local search that Sakala was. Why not to call it Max pay saving, right. This is something like, it's not only for. It works not only for Max, right? Yeah.
00:54:19.366 - 00:54:33.846, Speaker A: But more or less. This is what you are doing. This is face saving, right? Not really. Not really. Because there is this algorithm which tries to flip bits, like a local search, right. So you go over all the bad observers and you try to flip them. So I understood that you said that you blocked the solution.
00:54:33.846 - 00:54:39.126, Speaker A: No, no, but that's not what I do. Right. That's just for sake of an example. Okay. That was kind. Okay. Yeah.
00:54:39.126 - 00:55:13.560, Speaker A: Like go over these observers and try to find. Flip them. But instead of working on complete assignments, you find a solution and then all the sat solo flip a bit. That's why I call this local solve, because, you know, I do it by flipping one variable, but instead of operating complete assignments, you just run a sat over with that bit. Negation of the bit being an assumption. And you also use polarity face polarity selection schemes. Yeah.
00:55:13.560 - 00:55:52.566, Speaker A: And you also need to use conflict selection, as it doesn't work. There are some. So you mentioned about nonlinear optimization for detectors. So have you thought about like, going into do some reduction to NIA because recently, like Asyntha has improved a lot. Yeah. We tried doing something with large bitwig, like 256 bitwidth while going to NIA, and it turned out to be better than bit blasting. It depends on the constraints.
00:55:52.566 - 00:56:34.824, Speaker A: So you have some constraints which can be easily expressed as like so called design rules. So I haven't talked about it at all. But there are some additional constraints which we are adding to the formula, and in order to use nonlinear arithmetic we would need to somehow convert them to nonlinear constraints. And I'm not entirely sure it's one can do it efficiently, but 1 may check. Yeah, we did some omtnia and solving bit vectors with large bit with like 256 with nonlinear constraints. So I guess it would be a nice direction. Maybe a couple of more questions.
00:56:34.824 - 00:57:01.404, Speaker A: Hi, just an observation and then I have a question, but I guess they are separate. I don't want to be in the game of sort of finding a name for this, but I think it could be called local search because for me the defining feature is you have a solution, then you have a local neighborhood. Yes. And then you evaluate candidate solutions in the neighborhoods and through the face saving and the bit flipping. You do have a neighborhood definition. Yes. Right.
00:57:01.404 - 00:57:53.294, Speaker A: My solution was, my question was different, though. There's a related paradigm, I thought as you went through the talk, which is large neighborhood search, is this something you compare against? How does it relate to large neighborhood search? Maybe it relates to the, our follow up work. In that work, what we do is we use Assat or Polosat solver as an oracle and we do local search on top of it. So, and maybe this relates somehow to large neighborhood search because we are using these solvers again to look for solutions in neighborhoods. So we have this local search inside this, and then on top of that we are also trying to find solutions in neighborhoods. I didn't talk about it, but maybe we can talk of that. Thank you.
00:57:53.294 - 00:58:01.834, Speaker A: Maybe it's fitting that the last question in a talk about conflict driven close learning, sad solving is given to Karem. Again, nice.
00:58:01.874 - 00:58:11.746, Speaker B: I just, you mentioned something about boosting visits and I didn't quite understand that. So boosting the scores of v sets, you know, is hastening finding conflicts.
00:58:11.850 - 00:58:49.272, Speaker A: No, no, no. The idea is the form. So you have the absorbers and you want to find a solution in which the observers are zero or minimized. Right. A solution with as many falsified absorbers as possible. Now there is the polarity selection heuristic, which assigns them zero independent of the variable selection. But then if you select them first, if visit selects these variables first, there is a better chance to get a solution which is minimal.
00:58:49.272 - 00:59:11.824, Speaker A: You see, if, for example, if you over select them, if you force your variable decision to select them first, always. Then, well, the solution will get stuck. But you will get the minimal solution if it doesn't. By chance, if you always select them first. Right. Right. Because then you would always select them first and try to assign them zeros.
00:59:11.824 - 00:59:13.556, Speaker A: So you select them to assign them.
00:59:13.580 - 00:59:17.196, Speaker B: Can you just define to me what observable means here in this context? What's an observable variable?
00:59:17.300 - 00:59:45.446, Speaker A: Are the variables on which this function is defined. So you want to find a solution in which function. You're minimizing. Yeah. So you want to find a solution in which the observers are as close to zero as possible. Why is it different from this? Why is observable observable is different than the scope of your objective function. Well, it's it's yeah, it's the variables from which the function depends.
00:59:45.446 - 01:00:08.066, Speaker A: So, yeah. Yeah. So variables involved in the objective function. It's not really variables involved in the objective functions is the variables in which. So this narrow usage, the function is modeled on observables. So if you flip the observable from one to zero. Then the function gets closer to zero.
01:00:08.066 - 01:00:29.274, Speaker A: And it doesn't hold for every variable which are used by the function. Oh, so the scope of the objective function can be bigger than the set of observables. Yes. Thank you. I think let's thank the speaker again. And we are now having our break.

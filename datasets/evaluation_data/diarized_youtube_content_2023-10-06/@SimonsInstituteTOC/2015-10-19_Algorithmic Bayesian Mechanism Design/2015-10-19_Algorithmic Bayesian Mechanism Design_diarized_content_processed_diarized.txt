00:00:01.760 - 00:00:43.634, Speaker A: Hi, everyone. Thanks for staying. To the end of the day, I want to talk about an algorithmic framework to solve bayesian mechanism design problems. This is based on joint work with Matt and Costas. So this framework was developed during a line of research happened in the past few years. To me, there are two motivating questions for this line of research. First one is one that has been raised in the previous two talks, namely, how can you design revenue optimal auction when you have multiple items for sale? The second question is more high level question, or more general.
00:00:43.634 - 00:01:19.258, Speaker A: It was phrased by Neeson and Ronan. Basically, they were asking, how much more difficult is mechanism design comparing to algorithm design? I want to show you today that our framework provides some understanding on both questions. Okay, let me start with the first one. So, I think everyone here knows Myerson's auction. So let me just quickly remind you what his auction looks like. So, bidders submit their bits and they're transformed into some virtual bits. Then the item is given to the one who has the highest virtual bit.
00:01:19.258 - 00:01:20.646, Speaker A: In this case, six.
00:01:20.830 - 00:01:21.674, Speaker B: Okay.
00:01:22.454 - 00:02:01.734, Speaker A: And after Myerson's result, there has been a large body of work from economics trying to generalize his results to more general settings. But unfortunately, no general characterization is known. And recently, computer scientists started to look at this problem. We provided many approximation algorithms. In fact, the previous two talks actually provide two approximation algorithms. Sorry, I didn't include them here. But in this talk, what I want to do is I want to show you an algorithm that actually computes the optimal mechanism, exact optimal mechanism, in an efficient manner for a very general setting.
00:02:01.734 - 00:02:12.456, Speaker A: What I want to point out is, by looking at this problem from an algorithmic perspective, we actually managed to characterize the structure of the optimal auction.
00:02:12.570 - 00:02:13.344, Speaker B: Okay?
00:02:13.844 - 00:02:27.024, Speaker A: In particular, when the bidder is additive, which is deciding. Let's look, in the previous two talks, the optimal auction has a very similar structure as Myerson's.
00:02:27.404 - 00:02:28.212, Speaker B: Okay.
00:02:28.348 - 00:02:40.964, Speaker A: Bidders, they submit their bids. These bids are transformed into some virtual bids. Now, for each item, I will give the item to the one who has the highest virtual bid for that particular item.
00:02:41.084 - 00:02:41.700, Speaker B: Okay?
00:02:41.812 - 00:03:24.568, Speaker A: In this case, I'll give Apple to myself because I have six. That's the highest bit for apple and same for orange. Okay, so this is very similar to Myerson's auction, except that in Myerson's case, the transformation is given by some closed form function, and it's also deterministic. In this case, the transformation is randomized and computed by some linear program. And I want to emphasize that we know examples where the optimal auction needs to be randomized so that's sort of a. Okay, that's basically what I want to say for the results. About the first question.
00:03:24.568 - 00:03:28.728, Speaker A: I'll give more details later. Let me move to the second question.
00:03:28.856 - 00:03:29.520, Speaker B: Okay.
00:03:29.632 - 00:04:03.534, Speaker A: In the second question, I want to understand how much more difficult is mechanism design compared to algorithm design. Okay, in algorithm design, uh, we're usually faced with this following problem. You're giving some input. You're asked to design some algorithm that does some operation on the input and produces some desired outcome. Okay. In mechanism design, the picture is very similar, except that the input is usually, uh, given by some agents. And the bad news for the algorithm designer is the agents actually care about the output of the algorithm.
00:04:03.534 - 00:05:04.864, Speaker A: They have some key interests here. If your algorithm is not designed carefully, they might misreport the input and get better payoff for themselves. But the point here is, if your input is wrong, the output's not going to be meaningful. So mechanism, basically, it's an algorithm that is robust to such strategic behavior. So in the Seminole paper by Nathan Ronan, they ask, if you have an optimization problem, how much more difficult is the corresponding mechanism design problem? That's what I mean when you have a strategic input for a problem compared to the algorithm design problem where you have honest input. And in my mind, the best solution you can hope for for this problem is a black box reduction that reduces mechanism and mechanism designed to algorithm design for any optimization problem. Okay, so what do I mean by that? So you have some optimization problem and say you have an algorithm that solves this optimization problem.
00:05:04.864 - 00:05:50.128, Speaker A: Now what I want is some mechanism that solves the same optimization problem. Okay, what I want to have is some procedure that interacts with the agents. Also, it interacts with this algorithm. By a few rounds of interaction, this procedure figures out what to output. And if this procedure only queries this algorithm as some oracle, this will become a black box reduction. Okay, and why do I care about black box reduction? There are a few reasons. Arguably, in the community computer science, more is known about algorithms comparing to mechanisms.
00:05:50.128 - 00:06:26.854, Speaker A: So if you have such a reduction, that means maybe some mechanism design problem which are unsolved can be just reduced to some problems in algorithm design which are already solved. And also this allows a larger community to tackle important problems in mechanism design. Because now the problem is completely, is purely algorithmic. You don't even need to know mechanism design. You can just solve the problem. Algorithmic problem. And the last point I want to make here is I think such a reduction can provide some deep understanding of mechanism design.
00:06:26.854 - 00:07:13.260, Speaker A: Namely, why is incentives so hard to deal with. So in this talk informally, I want to state that such a reduction exists. In fact, we have seen many black box reductions. Many of the famous mechanisms, you can view them as reductions, okay? So if you want to optimize social welfare, the famous VCG mechanism, optimize welfare in any setting. I want to think of the VCG mechanism as reduction. So namely, they reduce the mechanism design problem for optimized social welfare to the following algorithmic problem. You just find an allocation that maximize the sum of everyone's value for the allocation.
00:07:13.260 - 00:07:33.904, Speaker A: If you can solve this algorithmic problem, you can also run VCG, okay? And in a recent line of research, it was shown that there is a black box reduction that can accommodate approximation when your objective function is social welfare. So it means if you can solve this algorithmic problem approximately, you can also optimize social welfare approximately.
00:07:35.264 - 00:07:36.032, Speaker B: Okay.
00:07:36.168 - 00:08:14.830, Speaker A: It turns out if you want to optimize revenue, the Myerson's auction can also be viewed as a reduction. So the bidders submit their bids. These bids are transformed into some virtual bids. Then you can think of these, you can think of the mechanisms as feeding these virtue bits to some algorithm that just finds the largest number, or saying you find the maximum welfare allocation with respect to this virtue bits. Okay, so that's Myerson's auction. So, obvious question you want to ask is, okay, for welfare, we have black box reduction. When you have single item, we have black box reduction.
00:08:14.830 - 00:09:33.290, Speaker A: What if you have amount of items? You want to optimize revenue, you have general valuation function. Can you see? You have black box reduction? Or you want to go beyond revenue and social welfare, you want some general objective. For example, you want to minimize the mixed spend of job scheduling. Or say you care about Max mean fairness, can you still have black box reduction? So first, I want to show you that if your objective function is revenue, you can always reduce the mechanism design problem to an algorithmic problem. That's just maximizing virtual welfare, okay? And when your objective function is more general, there's actually some known barrier due to Shuchi, Nico and Brendan. They show that if your objective function is o for the mechanism design problem, there is no black box reduction that reduces to an algorithmic problem for the same objective. But what I want to show you today is you can reduce the mechanism design problem to an algorithmic problem that optimizes the same objective plus a virtual welfare term.
00:09:33.482 - 00:09:34.334, Speaker B: Okay?
00:09:35.074 - 00:09:53.992, Speaker A: So what do I mean by that? So, formally, if you want to design a mechanism that optimize some objective o, it's enough for you to have some algorithm that optimizes the same objective o, plus some virtual welfare, and the reduction works in polynomial time.
00:09:54.168 - 00:09:54.840, Speaker B: Okay?
00:09:54.952 - 00:10:54.264, Speaker A: So here, this algorithm will optimize objective function with respect to the reported types and plus a welfare term with respect to some virtual types. That's what I mean by virtual welfare. Here, if you have an algorithm that optimizes the sum, you can construct a mechanism that optimizes the objective. Okay, I want to point out here that the reduction can accommodate approximation. If you can just approximately optimize the sum here, you can still approximately optimize O, and the reduction preserves exact. You have the same exact, you have exactly the same approximation vector. So, to me, the way to interpret this result is saying, if you want to go from honest input to strategic input, it is no more difficult, computationally, than just adding a virtual welfare term to your objective function.
00:10:54.424 - 00:10:55.204, Speaker B: Okay?
00:11:00.944 - 00:11:23.964, Speaker A: So next, I want to give you an overview of our framework, and I will use the money item auction as running example. Okay, so this is essentially the same setting Yao and Matt talked about. So you have n items for sale. You have n bidders. They're all additive.
00:11:24.784 - 00:11:25.312, Speaker B: Okay.
00:11:25.368 - 00:11:43.604, Speaker A: The bidders valuation bidder is. Validation is drawn from some known distribution di. I want to emphasize that the main difference between this result and their result is the values here may be correlated. Your value for item one and item three might be correlated, but in their case, it's mostly assumed to be independent.
00:11:43.684 - 00:11:44.424, Speaker B: Okay.
00:11:45.124 - 00:12:16.698, Speaker A: And also, you want to assume designer and other agents know the I. This is a very common assumption. The goal here is you want to design a truthful mechanism that optimizes revenue and expectation. And by truthful, by truthfulness, I mean bayesian incentive compatible for people who are not familiar with this concept. This means if everyone else is telling the truth, I prefer to tell the truth as well. Are bidder or buyer valuations soon to.
00:12:16.706 - 00:12:18.162, Speaker C: Be independent across buyers?
00:12:18.218 - 00:12:18.854, Speaker A: Yes.
00:12:19.554 - 00:12:20.010, Speaker C: So we.
00:12:20.042 - 00:12:55.656, Speaker A: Relax. So you have a correlation, right? Your correlation across items for your independent cross bidders. Yes. Just want to remind you, this is the same setting that I show you the structure result. We have efficient algorithms for finding a revenue optimal auction, and the auction has a very similar structure as Myerson's. Okay, so how do you prove such a result? So, in a very high level sense, I want to use an LP to search for the optimal auction.
00:12:55.810 - 00:12:56.460, Speaker B: Okay?
00:12:56.572 - 00:13:01.108, Speaker A: So to do that, I need the variables to describe an auction.
00:13:01.196 - 00:13:01.516, Speaker B: Okay?
00:13:01.540 - 00:13:26.056, Speaker A: I need some variables to describe allocation probabilities. I need some variables to describe prices. After that, I want to make sure these variables actually describe an option that is truthful. So I need some truthfulness constraints. Also, I need to make sure these variables actually corresponds to a real mechanism. So I also have some feasibility constraints, and the objective is obvious. I want to maximize the expected revenue.
00:13:26.240 - 00:13:27.084, Speaker B: Okay.
00:13:29.824 - 00:14:06.514, Speaker A: So it turns out there is a very folklore way to write an lp. So the variables will be the following. So I described the probability that item j is allocated to better I when the type profile is t. Okay, I call this phi I j of t. I also have pit to describe the price that bidderi pays under type profile t. Okay, so these are usually known as expose allocation rules. So now I can write the truthfulness constraint using the variables.
00:14:06.514 - 00:14:51.794, Speaker A: The reason I can write write these constraints as linear inequalities over the variables is because from these variables I know my expected utility if my true type is t, but I'm sure to be t prime. This is just a linear function over the variables. If you can do that, you can write these two constraints as linear equalities. And also, it's easy to check whether these variables correspond to a feasible mechanism. All you need to do is to make sure no item is allocated out more than once. So you want to check for all possible type profiles. All items sum over all bidders, divide I j of t is no larger than one.
00:14:51.794 - 00:14:54.194, Speaker A: If that's the case, you're feasible.
00:14:54.314 - 00:14:55.134, Speaker B: Okay.
00:14:57.794 - 00:15:05.626, Speaker A: And the objective function is just the expected revenue. So if you can solve this lp, I find the optimal option.
00:15:05.730 - 00:15:06.576, Speaker B: Okay.
00:15:06.770 - 00:15:31.996, Speaker A: But there are some issues. The first one is this LP is just too big. It's enormous. If you compute the number of. If you calculate the number of variables, the number of constraints, you realize that both are polynomial and the total number of type profiles, which is exponential in your input. Okay, so there's just no hope for me to solve this. Awesome.
00:15:31.996 - 00:16:14.322, Speaker A: But even, say, for a very small instance, I can solve this. I don't get any structure of the optimal auction. All I see is a longer list on what to do for every type profile. I don't gain any structural understanding. Okay, so as an alternative, I want to describe an option in a more succinct way. So I use the interim allocation rule, also known as reduce forms, uh, to describe an auction. Okay, so I have a variable called PI j of Ti that specifies the following probability condition on my type is Ti.
00:16:14.322 - 00:16:23.694, Speaker A: What's the probability that item j is allocated to me in expectation over everyone else's type, and also the randomness of the auction.
00:16:23.874 - 00:16:24.714, Speaker B: Okay.
00:16:25.814 - 00:17:10.938, Speaker A: And similarly, I define a payment. PI of Ti is expected payment for me when my type is ti and my expected payment, sorry, my payment in expectation over everyone else's type and the randomness of the auction. Okay, so it's not hard to see that if this is the way I describe the auction, I only need polynomial in the number of total types variables, where previously I need the total number of type profiles. So this saves me a lot. And this is just polynomial and type the size of the input. Sorry.
00:17:10.986 - 00:17:24.554, Speaker D: You're going to assume that this probabilities for the different j's are independent. Here, phi ij for a different j, semi different j.
00:17:25.614 - 00:18:14.074, Speaker A: No, not particularly. Yeah, so I think that will show up if I want to check visibility later, but not here. So with the reduced forms, I can write a succinct lp. So reduced form will be the variables. I can write the truthfulness constraints. Still, although the reduced form is a much more succinct description of the auction, I will still be able to figure out my expected utility when my true type is t, but misreport t PI. Okay, so here the left hand side says if my true type is ti, that's a probability.
00:18:14.074 - 00:18:49.850, Speaker A: I'm getting this vector. That's probably, I'm getting each item, that's my value for each item. So the whole dot product is just my expected value, but my true type is ti, and I report ti. This is my expected payment. So the whole left hand side is just my expected utility when I'm being truthful and my type is ti. Okay, the right hand side says if I misreport my type to be ti prime, but my true type is ti, this is my expected utility. So this constraint is just saying, being truthful is better than lying.
00:18:49.850 - 00:19:50.118, Speaker A: Okay, so this is exactly the truthfulness constraint. The objective function is still just expected revenue. I can write it as the linear function over the variables. So now the main difficulty here is how do I enforce the reduced form to be feasible? Okay, so it turns out you cannot enforce, uh, reduced form to be feasible just using a few number of linear constraints. So challenge will be, how can you verify if a reduced form actually corresponds to a real mechanism? Okay, in other words, can I have a separation oracle that checks the feasibility of the reduced form? As it turns out, this is a quite well studied problem in economics. It was first studied in the eighties. Then border came along and showed that if you have a single item reduced form, there exists a set of linear constraints that characterize the feasibility of these reduced forms.
00:19:50.118 - 00:20:44.144, Speaker A: Okay, later, Chechen Mirandov provided a more combinatorial proof based on max flowming cut. But the problem here is I still cannot just, uh, add these set of linear constraints to my lP, uh, because there's still exponential many. Okay, so what we did, and independently, uh, LLR, had the same result, we provide, uh, equivalent conditions that can be checked in polynomial time. So that will give you a computational efficient version of boiler's theorem. And turns out, in the additive setting, although you have multiple items to check feasibility of your reduced form, you really just need to look for each item whether the reduced form is feasible or not. If that's feasible, the whole reduced form is feasible. So by leveraging the single item borders theorem, we can check feasibility in this case.
00:20:44.144 - 00:21:25.130, Speaker A: So where are we? Let me remind you the big picture. So, in the first step, I write a succinct LP using the reduced forms as the variables. In the second step, I used borders theorem as a separation oracle to check visibility. So, now I can solve this succinct LP and find the optimal reduced form PI star. But I'm not done yet, because all I have now is just the optimal reduced form. If you give me a type profile, I don't know what to do. That's not a real mechanism.
00:21:25.130 - 00:21:32.874, Speaker A: So I still need an efficient way to map a reduced form back to an allocate expose allocation rule.
00:21:32.954 - 00:21:33.694, Speaker B: Okay?
00:21:36.034 - 00:21:49.250, Speaker A: So it turns out the following characterization theorem we prove is very useful. So, we first show that if you look at the set of reduced forms, it's going to form a polytope.
00:21:49.322 - 00:21:49.610, Speaker B: Okay?
00:21:49.642 - 00:22:17.774, Speaker A: This is very easy to prove. Next, we show that if you're looking at a corner of these polytope, there exists some virtual value function f. If you use the allocation rule that maximizes virtual value respect to f, the corresponding reduced form will be that corner. So, in other words, we proved that any corner of these polytope can be implemented as a virtual welfare maximizer.
00:22:17.934 - 00:22:18.754, Speaker B: Okay?
00:22:20.054 - 00:22:38.800, Speaker A: So if you combine this characterization theorem with the result by characteristic Dari, then you can see that the optimal reduced form is simply a convex combination over corners that can be implemented as virtual welfare maximizers.
00:22:38.912 - 00:22:39.640, Speaker B: Okay?
00:22:39.792 - 00:22:45.488, Speaker A: Particularly, that means the optimal mechanism itself is just a distribution over virtual welfare maximizers.
00:22:45.656 - 00:22:46.536, Speaker B: Okay?
00:22:46.720 - 00:23:07.316, Speaker A: So every corner in this compass combination will give you a different virtual value function, and your mechanism will just sample this virtual, one virtual value function according to this convex combination, and then find the allocation to maximize that. So here I completed a proof for the additive buyer setting.
00:23:07.420 - 00:23:08.044, Speaker B: Okay?
00:23:08.164 - 00:23:15.304, Speaker A: Now I want to show you that if you want to go to general settings, what do you need to change in the whole framework?
00:23:15.644 - 00:23:16.504, Speaker B: Okay?
00:23:16.924 - 00:23:31.994, Speaker A: So when you have added buyers. In the first step, you write an LP using the reduce forms. Turns out in general settings, reduced forms are not meaningful. You need to use some other implicit interim description of the mechanism.
00:23:32.114 - 00:23:32.894, Speaker B: Okay.
00:23:35.034 - 00:24:17.326, Speaker A: And in the second step, I use border theorem. When you have, when bitters are additive, border theorem doesn't work when you have more general types. But luckily we can use the famous result equivalence of separation and optimization by a groucho versus driver. And pendingly, Karp and puppetee mutual to get a separation oracle using just black box assess to some algorithm that optimizes your objective plus virtual warfare. Okay, so I can still solve the LP to get the optimal implicit interim description. Now I need to implement it as a real mechanism.
00:24:17.470 - 00:24:18.314, Speaker B: Okay.
00:24:18.894 - 00:24:43.284, Speaker A: In the additive bio case, I know the optimal mechanism can be implemented as a distribution over virtual welfare maximizers. It turns out the same characterization theorem still holds when you have valuation functions beyond additive. If you try to optimize revenue, it's just that your virtual types are more complicated.
00:24:43.414 - 00:24:44.204, Speaker B: Okay.
00:24:45.304 - 00:24:58.328, Speaker A: But if you want to optimize some other objective, the characterization theorem becomes the optimal mechanism as a distribution over virtual objective maximizers, in particular in this form.
00:24:58.496 - 00:24:59.324, Speaker B: Okay.
00:25:01.384 - 00:26:10.234, Speaker A: So that's how the framework looks like in the general setting. Okay, so I want to talk about some other extensions we have for this framework. So we managed to accommodate approximation in our framework. So as a result, you can use our framework to handle auction settings with hard budget constraint, or you have extroversion bidders, and also you can go beyond auctions. For example, if you want to minimize mixed spend for scheduling jobs or maximum fairness, our framework, with some modification, you can use our framework to get mechanisms that matches the state of our algorithmic approximation factors. Now let me come back to the two motivated questions I had in the beginning. So Myerson showed that if you have a single dimensional setting, the revenue optimal auction is just a virtual welfare maximizer.
00:26:10.234 - 00:26:20.342, Speaker A: We show that no matter what the bidder's types are, the revenue optimal option can always be described as a distribution over virtual fair maximizers.
00:26:20.438 - 00:26:21.194, Speaker B: Okay?
00:26:21.654 - 00:26:29.688, Speaker A: And again, this is discovered by looking at this problem from an algorithmic perspective.
00:26:29.886 - 00:26:30.744, Speaker B: Okay.
00:26:33.564 - 00:27:39.114, Speaker A: About the second question, I want to understand how much more difficult is mechanism design compared to algorithm design. So I show you that if you're in the bayesian setting, you can always have a black box reduction that reduces mechanism design to algorithm design. So in other words, it means if you want to go from honest input to strategic input, this is no more difficult computationally than just adding this virtual welfare term to your objective. This is my last slide so I want to say that after Myerson's work, there has been so much development in single dimensional settings and in fact also some related multi dimensional settings. So our framework provides some new tools for looking at multidimensional settings. So what can we do with that? So we already seen some application of this framework for objective functions beyond revenue and social welfare, and also to accommodate budgets in your auction setting. But hopefully this is just the beginning and there are more for extra Explorer.
00:27:39.114 - 00:28:04.014, Speaker A: Thanks for listening. Also a short advertisement this is a very short version of this framework. I'll be giving a three hour whiteboard talk in the end of this month, 30th November 30. So if you're interested, come to this long version October 30 October October. Okay, October 30.
00:28:13.074 - 00:28:14.174, Speaker E: Any questions?
00:28:16.724 - 00:28:44.120, Speaker D: So you're setting up a large in a program that has to do with the number of sum of the number of different types in many settings. Types come in continuous like, you know, type is some real numbers. Can you say anything about some natural way of either solving that expert that continues to, or discretizing in some, under some assumption or something?
00:28:44.312 - 00:29:10.184, Speaker A: So I think for, at least for the additive setting I've talked about, you can discretize for your uniform, say you're continuous in zero one, say okay, I can discretize the type space and get an approximately optimal auction, but also need to pay epsilon in truthfulness. So I get Epsilon pick. Okay. It depends on how small it is.
00:29:10.604 - 00:29:17.104, Speaker E: Also, the characterization holds holds for continuous type spaces.
00:29:17.724 - 00:29:19.292, Speaker D: But if you discretize, you lost it.
00:29:19.308 - 00:29:23.344, Speaker A: To for characterization, you don't need to discretize.
00:29:31.784 - 00:30:01.304, Speaker C: You didn't actually define what you meant by virtual values. And as you were putting it up, I was the incentive constraints, of course, are linear, they're convex. You can always use the Lagrangian and move them up into the objective function. I was wondering if the theorem said more than that. Since I don't know what you mean by virtual realtor, I can imagine that you can pick out every example three point the polyhedron with some objective. What did you mean by virtual welfare?
00:30:01.924 - 00:30:36.804, Speaker A: So I think in some sense you're right. So if you lagrangify some constraints and you look at the Lagrangian multipliers in the optimal solution, and that will correspond to the virtual values I'm talking about, or some linear combination of those lagrangian multipliers will correspond to the virtual values I'm talking about. I'm not claiming this is same as Myerson. You just need to say you don't have the revenue equals virtual welfare here. I'm just saying your optimal auction looks like the form that you're maximizing some virtual value function.
00:30:37.744 - 00:31:18.504, Speaker E: Something extra you get is that there's a global ordering of all the types. And basically the corners corresponds to ironing of that ordering. Every item goes to the highest type that shows, that is reported for each item, there is a global ordering of all the types. Now, when you choose a corner, you just ironing that ordering for each item and give the item to the highest type in the ordering. So in some sense, the virtual values of different corners are not arbitrary, but they are related. It's just one global ordering of all the types for every item, a different.
00:31:18.544 - 00:31:20.444, Speaker A: Order for each item, for each item.
00:31:21.024 - 00:31:29.176, Speaker E: Of all the types of every bidder, the item is given for each item to the highest type that shows up for the ordering of that item.
00:31:29.280 - 00:32:19.768, Speaker C: So the reason I asked this question, you know, in the work that we did on the us incentive option, where the constraints, feasibility constraints aren't just that you give each item each once in some combinatorial constraint than which you can do. We also found that so related but different, that the optimum, the thing that maximizes the seller's revenue or minimizes the seller's cost. In this case, option to purchase involved maximizing or minimizing a virtual cost or maximizing a virtual revenue, et cetera. More complicated constraints than just a number of items constraints. So that's why I was thinking that the thinking in terms of the Lagrangian on the incentive constraints and moving up, you don't have to do anything with the feasibility constraints.
00:32:19.856 - 00:32:20.336, Speaker B: Exactly.
00:32:20.400 - 00:32:28.804, Speaker C: Leave them there, even if they're horrible and still have a characterization in terms of maximizing virtual welfare.
00:32:29.584 - 00:32:44.994, Speaker A: So exactly, if you have like complicated physically constrained, you can do what you set. So I think what caustus is saying, if you have, in this simple setting, you don't have complicated feasibility constraint, you can just allocate the item whoever you want. You have this ordering of the types.
00:32:51.534 - 00:33:15.198, Speaker F: So you said that the one algorithmic takeaway is that the mechanism design problem is now harder than solving like a different algorithmic problem, your original objective plus the virtual welfare, is that generally harder or not? I mean, are there problems for which that problem is intractable? But the optimization problem without the modification is not.
00:33:15.326 - 00:33:50.016, Speaker A: So we know that if you have some modular valuation, you want to optimize revenue even for one bidder, you have both way. So if you cannot, we can show that that's the only way you can optimize the revenue. And turns out you can argue that because the algorithmic problem is hard, and that's the only way to do it. So optimized revenue is hard. Okay, so there are some settings we know it goes both ways. In general, we don't know. So for jump scheduling, you mentioned that you get the same results as known.
00:33:50.016 - 00:34:04.504, Speaker A: What does that mean? Two, but you're comparing to the optimal Bayesian set of compatible mechanism, not the optimal algorithmic solution. And for module two, you don't.
00:34:05.964 - 00:34:07.124, Speaker E: No, the factor is two.
00:34:07.164 - 00:34:07.836, Speaker A: The factor is two.
00:34:07.860 - 00:34:11.364, Speaker E: The approximation factor is two instead of n. But we work in the patient.

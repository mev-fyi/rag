00:00:03.840 - 00:00:26.390, Speaker A: This is a mini crash course on error correction. Yes. Thank you. So, my plan is actually to try to give basically a tutorial. I'm not going to give an overview of the research or anything like that. I'll just try to give you some sort of hands on experience with quantum codes and teach. Ideas are particularly useful on the surface code or Torah code.
00:00:26.390 - 00:00:56.118, Speaker A: That's nice. Both practically physically, and also for sort of hamiltonian complexity. Interesting. Quantum code. Quantum state. So, first, I'll talk a little bit about quantum codes, and the basic problem with quantum states is that they're really fragile. So if you take the typical astrodinger's cat state, which is this cat, that's both, that's a dead cat, and it's a live cat, and it's in superposition between the two states.
00:00:56.118 - 00:01:38.294, Speaker A: This is a really cool state, but it's not something that could survive very long, because if a single photon came in, bounced off the state, interacted with it in some way, then bounced off, you have to trace it, trace it, trace it out, and that would collapse the whole quantum state. It would become entangled with this photon. So once the photon's lost, the state becomes collapsed. And so one way you can model this sort of as a toy model, is just to think of this as states of the classical repetition code. So zero to the n plus one to the n, or zero is, say, the dead cat, and one is a live cat. So these individually are pretty stable states. If you take a dead cat and you flip one of its qubits and one of its atoms around, it's still a dead cat.
00:01:38.294 - 00:02:07.844, Speaker A: So that's. So the repetition code is somewhat appropriate. If you take a live cat and flip a qubit around, flip a. Flip an atom or something, it's still live cat, basically. But if you take a superposition between the two, then you can see very, very quickly, like, you know, if you just measure one of these qubits, you, again, you collapse the whole state. What do we want when we. When we talk about a quantum error correcting code, instead of just this, this repetition code, it's going to be the same idea.
00:02:07.844 - 00:02:47.692, Speaker A: We're going to take cat zero. We're going to encode it as something, ket one is going to be encoded as something, some other multi qubit state. And the point is, the key property we need is that looking at a few qubits of some encoded states, say, alpha times the encoded zero plus beta times the encoded one, looking at just a few qubits should tell you nothing about alpha and beta. So in other words, it should not collapse the encoded quantum state at all. And therefore, in principle, it's recoverable. You haven't lost any information. And this is actually, I guess that's essentially the formal definition of what a quantum error correcting code is.
00:02:47.692 - 00:03:26.840, Speaker A: A code is distance d. If looking at a subset of, say, d minus one over two qubits, no information about the encoded state is revealed. So slightly more formally, the reduced density matrix tells you is independent about beta. And it seems like this could be difficult to achieve. I mean, the problem with quantum is that it's continuous, right? So you can take alpha zero plus beta one, and you can rotate it just a little bit. So you get alpha prime plus beta prime one. So that's a small error, and there's infinitely many ways of doing that.
00:03:26.840 - 00:03:58.098, Speaker A: Everything's continuous. How do you have any hope of being able to correct against these? The insight behind quantum codes is that this isn't really true. Actually, errors really are digital, and quantum codes really are essentially the same as classical error correcting codes. They're not actually all that difficult, different. And the easiest way to see this is just look, let's just get started with these operators that we call the poly operators. So the poly operators are the identity. They're just two by two matrices.
00:03:58.098 - 00:04:29.890, Speaker A: You have the identity u z 10, zero minus one. You have x 0110, and y is I times xz. It's kind of important to remember the identity, and you should probably try to remember z and x as well. So z, z takes zero, get zero to get zero, and it takes one to minus get one and x. It's nice, it just flips things around. So it takes cat zero to get one and vice versa. Okay, so that's how you can remember them.
00:04:29.890 - 00:05:37.080, Speaker A: Y, you can't remember very easily, right? But the observation is the key observation, the key fact is that these form basis, so there's four of them. If you look at all two by two matrices, it's four dimensional. And so these form a basis for the set of two by two complex matrices. And furthermore, if you look at four by four matrices, eight by eight matrices, tensor products of these operators are form of basis for those. So for example, for four by four matrices, you just look at identity tensor identity, identity tensor x, all the way up to z tensor z, and you get 16 operators and form a basis for the four by four matrices. What this means is that you take any error, so any continuous error, any, whatever error in discrete error doesn't matter and you can expand it out in terms of these simple, discrete operations, these basic poly operators, these basic poly errors, and this is really why we're done, if we can protect against just these few simple errors. So let me show why.
00:05:37.080 - 00:06:14.550, Speaker A: So say we have some code with some code word psi, and there's some recovery procedure, r, that the claim is r protects against x, y and z, or it's discrete x, y, y and z errors. And therefore, what I'm going to show is that it protects against all errors. That's enough. So let's see. So what does it mean that it protects against x, y and z errors? It means that you have r times x on qubit three times psi. It should give you back the state psi. Possibly we'll have extra sort of garbage space.
00:06:14.550 - 00:07:00.422, Speaker A: So say phi x three or something. Um, our y three psi. So y acting on the third qubit, again, it should recover the, the code word and possibly leave over some junk, and similarly for everything else. So rz two, whatever psi should give you back to the original state tensor, some extra work. And I suppose it should take the identity error. If there is no error, it should just leave things alone. So say I have some recovery procedure that acts in this way.
00:07:00.422 - 00:07:59.222, Speaker A: Corrects against x, y and z are acting on single qubits. So now, if you take a linear combination. So if you look at, say, some error, e is equal to alpha times the identity, plus beta times x on qubit three plus gamma times y on qubit three plus delta times z on qubit three, then r of e psi. So this is some, possibly, possibly, perhaps a small rotation or something. It's something continuous. But r psi, just by linearity, is going to give you psi tensor alpha times phi, whatever, x three plus beta plus gamma plus delta, or whatever it was. So the point is, this looks like very simple algebra.
00:07:59.222 - 00:08:18.324, Speaker A: It is really simple algebra, but it has a really nice consequence that instead of worrying about continuous errors, we just need to worry about x, y and z errors. Definitely. Feel free to interrupt me. There's plenty of time. All right, so, yeah, this would be true.
00:08:18.624 - 00:08:21.000, Speaker B: We don't need the polyo. We just need any basis.
00:08:21.072 - 00:08:53.508, Speaker A: That's right, for any basis. But why do we use the poly operators? I don't give myself problems that I don't know the answer to. I guess one answer would be. One reason this is nice is that it's not just any basis, but it's also a basis of unitaries. So you can hope to actually be able to correct against an x error. So you can hope to have a linear operator like this, that works. Whereas if it were non unitary, that wouldn't work.
00:08:53.508 - 00:08:54.138, Speaker A: Yeah.
00:08:54.236 - 00:08:57.654, Speaker C: So this recovery procedure is a quantum computer, right?
00:08:57.734 - 00:08:58.254, Speaker A: Yeah.
00:08:58.374 - 00:09:08.874, Speaker C: And so you are, you are thinking of r as r three. So for every bit you have a. You have a recovery procedure.
00:09:09.254 - 00:09:22.494, Speaker A: No, well, actually, I'm thinking r three. Here could be j r is just one recovery procedure that should correct error, single errors on any qubit from one to n, or whatever it is.
00:09:23.794 - 00:09:24.906, Speaker C: Oh, wow.
00:09:25.090 - 00:09:55.284, Speaker A: Here, I just wrote down three as an example. But an e like e, like this could be x three plus y three plus delta times zn j, whatever, it would still work because r corrects each one of them individually, turns five plus garbage tensor. Yeah, yeah, right. But.
00:09:55.404 - 00:09:56.904, Speaker B: Okay, so there's something.
00:09:59.884 - 00:10:00.380, Speaker A: Let's see.
00:10:00.412 - 00:10:12.274, Speaker B: So I could sort of imagine asking a question like, why do we. It doesn't. We're not talking about recovering from errors on, let's say, two neighboring bits.
00:10:12.314 - 00:10:12.894, Speaker A: Right?
00:10:14.594 - 00:10:15.934, Speaker B: Talking about single.
00:10:17.314 - 00:10:36.494, Speaker A: Well, here. Yeah, here I'm just talking about. You have a recovery procedure that say, corrects against single X's, single x, y z errors, single qubit. But if you wanted to correct against multiple qubits, you could do the same logic. Right. If you have some recovery procedure that corrects against two qubit errors by linearity.
00:10:37.414 - 00:10:44.694, Speaker B: So there's sort of an ordering in terms of the standard basis that we sort of prioritize things that act locally or something. Is that right?
00:10:44.774 - 00:10:57.234, Speaker A: In terms of how we're thinking about it? Pretty much. I mean, and that's because we think of physics as being local. So error processes will be. Will be local. They will be sums of local terms.
00:10:58.614 - 00:11:11.324, Speaker C: Now, I think I understood finally. But I still. I don't understand one such that on the left hand side, the phi should not be the same phi as on the right hand side, because that's the encoded phi.
00:11:11.404 - 00:11:12.024, Speaker A: Right.
00:11:12.684 - 00:11:20.704, Speaker C: So you are encoding phi in some. I mean, or psi. You are encoding psi.
00:11:21.844 - 00:11:22.584, Speaker A: And.
00:11:23.444 - 00:11:27.704, Speaker D: Yeah, psi is a code word. Sorry, it's the encoded code.
00:11:29.224 - 00:11:30.368, Speaker C: Oh, it's already.
00:11:30.536 - 00:11:31.664, Speaker B: It's already encoded.
00:11:31.744 - 00:11:39.672, Speaker C: It's already encoded. But don't you want to get the pur text, the original message? Or you just want to.
00:11:39.808 - 00:11:55.204, Speaker A: Oh, well, if you wanted to do that, then you could follow this all by a decoding procedure to get back to the unencoded state. Yeah. So I could add two other super operators, one that encodes the state into. Into this code word and one that decodes it at the end.
00:12:05.534 - 00:12:09.070, Speaker D: The error e now is like causing a distance of two.
00:12:09.102 - 00:12:40.882, Speaker A: Right. Because it's acting on two different qubits here. Yeah, that's interesting. Now, this error does act on two different qubits. So it's not one local, it's two local, but it's two still, a recovery procedure fixes it. But that's just, I mean, generically, if you take a generic two local operator, you won't be able to write it down like this. You'll have to expand out in terms that have two x's and two local terms.
00:12:40.882 - 00:13:13.644, Speaker A: And then you really do need a recovery procedure that corrects against pairs of polyurethane. Yeah, that's confusing. Make that three again. Okay. Okay. Any other questions? All right, so this, let's, let's just draw sort of a nice picture. So, so here's one qubit, here's 10, you know, get zero.
00:13:13.644 - 00:14:21.334, Speaker A: Here's one, which is zero, comma, one. And there's other two states that are sort of useful to remember sometimes, which is one over root two, one one, which is sometimes called ket plus, and one over root two, one minus one, which we call ket minus. And the point here is just that, if you remember x and z again. So x switches zero and one and z puts a phase on them, relative phase on them. So z, it leaves the x axis in this picture alone and flips the y axis, whereas x swaps the two. So x, in other words, x, leaves ket plus alone, because if you switch the two coordinates, it leaves one comma, one alone, and it adds a phase to kep minus, because if you switch these two coordinates, you pick up a minus one phase. And so, in other words, x and z are really the same kind of operator that just x and z are the same, except in the dual basis.
00:14:21.334 - 00:15:08.414, Speaker A: So x in the dual basis acts like z in the primal basis and sort of vice versa. So I guess another way of thinking about this then, is that when you talk about classical error correcting codes, you talk about, how do I recover against x errors, bit flip errors that switch zeros with one s quantumly, what we've said is that you need to worry about not just those kinds of errors that switch zeros and ones, but you also have to protect against these z errors that just add a relative phase between zero and one. But actually, that's the same as an x error, just in this dual basis. It's not actually that different from classical errors. And the third case is wire. Wire is the same as an x error and a zero. Y, I think, was I times xc.
00:15:08.414 - 00:15:29.470, Speaker A: So it really is just enough to think of these two kinds of errors, if you can correct them, essentially, yeah. All right. So with this background, we can give, actually, a simple quantum error correcting code. Yeah, just go over that last point again.
00:15:29.662 - 00:15:38.190, Speaker B: So it's not clear why. Is it clear that if you can correct for an x and a z, you can. Is it true in general?
00:15:38.302 - 00:15:42.434, Speaker A: No, I tried to sort of, like, swallow my sentence. I didn't quite finish it.
00:15:43.174 - 00:15:45.274, Speaker B: Sorry, I must have misheard something. Go on, please.
00:15:46.174 - 00:15:50.754, Speaker A: Yeah, it's not true. You need to be able to correct against x, y and z ers. Yeah.
00:15:53.354 - 00:15:58.714, Speaker D: But you're saying if you're correct against x followed by z, then you're fine.
00:15:58.794 - 00:16:38.714, Speaker A: No, no, certainly, in general, you need to be able to correct it against x, y and z separately. A lot of the codes we come up with, like, in this example, they have the property, they're called CSS, which means that you can split the x and z separately, and therefore. Yeah. Splits between the two and is corrected for free. That's not really a general property. Okay, so with this background, we can already give a simple quantum error correcting code and finish up this talk. Maybe, but no.
00:16:38.714 - 00:17:05.402, Speaker A: So let's just start with the classical code. So we take zero to zero, zero ket, one to 111. That's repetition code. Let's do the same in the dual bases. Right? So that protects against the x errors and the dual basis. To protect against the z errors, which are the dual of the X errors, we just take ket plus and encode it as ket plus tensor, ket plus tensor kept plus, which I'll just say plus plus plus. We take kept minus, we encode it as kept minus, tensor kept minus, tensor kept minus.
00:17:05.402 - 00:17:05.954, Speaker A: Yes.
00:17:06.074 - 00:17:09.214, Speaker B: Is there actually a quantum operation that realizes that map there?
00:17:11.034 - 00:17:14.070, Speaker A: Well, I mean, it's not unitary, but you can certainly. Yeah.
00:17:14.222 - 00:17:18.794, Speaker B: Okay, so, I mean, because. So you're not like, cloning the state. No.
00:17:19.094 - 00:17:25.078, Speaker A: You can replicate certain given states. Right. Cloning means you can't replicate arbitrary state. Right. So there's.
00:17:25.126 - 00:17:26.038, Speaker B: So there's a way of.
00:17:26.126 - 00:17:32.314, Speaker A: I mean, I can see how you would duplicate the zero in one state. So there's a way of doing zero, one plus n minus.
00:17:33.294 - 00:17:41.112, Speaker D: I think he's talking about doing it separately. Just. Just duplicating. Plus and minus or just duplicating.
00:17:41.288 - 00:17:41.944, Speaker B: Oh, I see.
00:17:41.984 - 00:18:00.888, Speaker A: Okay. Yeah, sorry. These are two different codes. The first code protects against bit flip errors. The second code protects against phase flip errors or z errors. And so therefore, you should just combine the two, and you can concatenate one on top of the other. It doesn't matter.
00:18:00.888 - 00:18:33.224, Speaker A: Well, it does matter in which order, but not really for us. And then you should be protecting against both kinds of errors. And to see how that works, I guess, you know. So ket plus is equal to, like, ket zero is equal to ket plus plus ket minus over two. So the second code is really the same as it takes. Get zero to plus plus plus plus minus, minus, minus. Get one to plus minus, minus, minus.
00:18:33.224 - 00:18:51.024, Speaker A: And so, you know, you just apply this first code. Then each of these zeros you map into this three qubit state. And so you end up with a nine qubit state. Each of these ones you send into this guy. Yeah. You have a nine qubit state. And so this gives you some nine qubit quantum error correcting code.
00:18:51.024 - 00:19:16.404, Speaker A: Yeah. And so any x error on this code will be caught by this code, by this classical repetition code, and then any z er, it will totally mess up this first code because a z er will switch, the relative will add a relative phase between these two, but that will be caught at the next level.
00:19:18.104 - 00:19:49.656, Speaker B: So there's something, there's something I'm not seeing. But I mean, just, isn't it conceivable that somehow when you concatenate codes, the efficacy of the first code has been completely destroyed or not? Is it obvious that. So I understand how the first code protects against x errors. Now you've taken that and encoded it again some other way. It doesn't seem clear to me that it's still protected against.
00:19:49.680 - 00:20:09.240, Speaker C: So I seconded. So you need to prove this. I think you need to prove that if you compose, you are composing it, then saying that you are, that the first protects against one type of error, and then you are composing it with something, then you are.
00:20:09.392 - 00:20:33.946, Speaker A: No, I agree. There's certainly something to show there, but I claim it's sort of, not hard to see. Sort of trivial, maybe. So we have nine qubits. They're arranged in three groups of three. So say you have an x error on this first block of three. So how do you recover this nine qubit code? What you do is you apply the recovery procedure for this code to each of these three blocks separately.
00:20:33.946 - 00:20:53.356, Speaker A: And so if there's an x error on one of these nine qubits, or actually you can have one of the one in each block of three. And since you apply the recovery procedure to each block separately, it'll correct those. And that doesn't affect the outer code because the outer code is just some code word on top of this repetition code. So recovery protects against it.
00:20:53.380 - 00:21:04.940, Speaker C: I guess the mathematical way of saying it is that you define a new recovery procedure, which is the sort of the product of the two recovery procedures or something like that.
00:21:04.972 - 00:21:49.604, Speaker A: Yeah. And so the slightly harder statement is what happens is if, say, you have a z error here on this first block, and then it's pushed up into the second code level. So you need to be able to apply the recovery procedure for the second code level on top of the first code. But in this code, it's particularly simple because, say you have a ZR on the first qubit of this first code, that becomes, that's equivalent to just sort of a z er on the encoded code words because it has the effect of switching the relative phase between these two, which is the same as an encoded c. Yeah. All right.
00:21:49.684 - 00:21:52.236, Speaker C: We established that this needs to be proven.
00:21:52.420 - 00:21:56.452, Speaker A: Yeah, yeah. Okay, sorry, you said something there that.
00:21:56.468 - 00:22:01.756, Speaker B: Now I realized I wasn't even thinking about. So you're saying errors can occur between the encoding process?
00:22:01.860 - 00:22:49.892, Speaker A: No, no, no, not yet. Certainly later on, maybe. Okay, so I want to give you sort of another way of thinking about these codes that lets you come up with more complicated codes than just the repetition code. And for this, I'll sort of touch on and come back to later the idea of stabilizer algebra. And in particular, I mean, this is very natural from classical codes as well. If you're familiar with linear error correcting codes, you can define the code as, it's basically, the code space is everything that satisfies certain parity checks classically, quantumly. What we'll say the code space is everything that satisfies certain.
00:22:49.892 - 00:23:24.744, Speaker A: We call them, instead of parity checks, we call them stabilizers. So here, for example, if you say, you look at z tensor z, so z z again was 10 zero minus one. So z tensor z is one minus one minus one one. This diagonal matrix. And so it leaves a plus one phase on zero zero. It leaves a plus one phase on and has a minus one phase on these odd parity strings. And so z tensor z measures the parity of two string of a two bit string.
00:23:24.744 - 00:24:25.034, Speaker A: And so therefore, we can see another way of defining the repetition code is just as the plus one eigenspace of these two operators. So z tensor z tensor is the identity, which means that the parity of the first two qubits has to be even and identity tensor z tensor z, for it to be a plus one eigen state of that, the parity of the second and third qubits has to be even. So for example, that is true if you look at z tense or z tense as the identity and multiply that times any code word that gives you back the same code word, because yes, indeed, the parity of pairs of bits really is even in this code word. So those are called the stabilizers. And then you can also see what are the logical operators in the code. How do we act inside the code space? And here, those are also quite simple. So if you want to switch logical zero with logical one.
00:24:25.034 - 00:25:37.460, Speaker A: So logical zero is three zeros, logical one is three ones. To switch the two, you just apply x tends to x tensor x. If you want to switch the relative phase between the two, or equivalently, um, when I'm doing this here, if you want to switch the relative phase between the two, just apply z tensor identity, tensor identity. That'll um, that'll put a minus one phase on the encoded one. Uh, so this is sort of, um, a way of thinking of the repetition code in terms of parity checks or stabilizers, the dual code, the dual repetition code is exactly the same, except with x's switched with z's, of course, pluses plus minus, which was zero and one. And so therefore, when we concatenate the codes on top of each other, we get a code on nine qubits. 123-45-6789 it has the following parity checks the following stabilizers, zz I I I zz, then six I's, and then similarly with the other blocks of three.
00:25:37.460 - 00:26:13.414, Speaker A: So that gives you 123456 stabilizers, six operators where the state is plus one eigenstate. And then for the outer code, the bigger code that you put on top of that, that's just x x I. Except this is logical x acting on the first block of three, right. The logical x acting on the first block of three, it's this operator here. And this is logical x acting on the second block of three. This is logical identity and similar. And then I I x x x.
00:26:13.414 - 00:26:53.494, Speaker A: So that gives us eight stabilizers for this code, this nine qubit code. One can check. They're all, they're all independent of each other. And of course, if psi equals psi q psi equals psi pq psi equals psi. So not only do you have these eight stabilizers, but everything in the group that they generate is also a stabilizer of this. That's another way of defining the code. Actually, you can define this nine qubit code just by listing these eight independent parity checks, or stabilizers.
00:26:53.494 - 00:27:21.194, Speaker A: It's possible that the code space is larger than the repetition code that I just said. But actually, it's a fact that each independent stabilizer reduces the dimension by one. So the fact that there's eight independent stabilizers means that on nine qubits means that you're left with one logical qubit. That's.
00:27:24.574 - 00:27:30.038, Speaker C: So that corresponds to the linar.
00:27:30.086 - 00:27:35.814, Speaker A: Codes in classical, exactly the same. Well, not exactly, but close enough.
00:27:35.894 - 00:27:39.430, Speaker C: So stabilizer codes are linear codes, kind.
00:27:39.462 - 00:27:49.416, Speaker A: Of in quantum codes. And of course, there are nonlinear classical codes, and they're non stabilizers, quantum codes as well. It's harder to think about. Sorry.
00:27:49.440 - 00:27:52.364, Speaker B: So what's the definition of a stabilizer code?
00:27:53.944 - 00:28:11.964, Speaker A: Formally, I guess you define a stabilizer code as the plus one eigenspace of a set of commuting poly operators. I would say. Yeah. Yeah. Of a group of commuting. An abelian group of poly operators. Yeah.
00:28:11.964 - 00:28:17.364, Speaker A: I mean, they have to commute, but. Yeah.
00:28:28.024 - 00:28:29.856, Speaker C: Polyaparators don't commute.
00:28:29.920 - 00:28:31.488, Speaker B: Yeah, but they're taken in here.
00:28:31.576 - 00:29:05.514, Speaker A: No, sorry. If you have a set of poly operators that don't commute, then it's impossible for, for them to simultaneously be a plus one, stabilize some state. Because if p q is equal to minus qp, then pq psi equal. I mean, if Psi is equal to Psi Q psi is equal to Psi and p and q anti commute, then you get a contradiction. I mean, that implies Psi equals zero.
00:29:06.984 - 00:29:12.764, Speaker B: So every time you're anti commuting two z's with two x's, you don't get any sign.
00:29:15.624 - 00:29:23.724, Speaker A: Sort of commuting has to happen, or the definition of the code just gives you nothing.
00:29:26.784 - 00:29:48.508, Speaker C: If I look at the seven and I am looking at the third row. Okay, so I'm multiplying those, then I. Then. Then an x meets a z twice or twice. I see. But in two different coordinates.
00:29:48.556 - 00:29:49.144, Speaker A: Or.
00:29:50.404 - 00:29:55.116, Speaker C: Oh, it takes a minus sign each time. Thank you. That's helpful.
00:29:55.260 - 00:30:03.416, Speaker A: Oh, yeah. Yeah. Oh, yeah. So I guess. Yeah, I haven't. Yeah, you can check that. These do commute if you wanted to.
00:30:03.416 - 00:30:04.472, Speaker A: And that's why.
00:30:04.608 - 00:30:09.404, Speaker B: So just so there's the significance of eight versus nine and what was that?
00:30:10.424 - 00:30:37.540, Speaker A: Actually, as Mario said, it's the same as for classical codes. If you take eight independent parity checks on nine bits, you're gonna have one sort of degree of freedom left. So you get a two dimensional code, two to the one dimensional code, classically quantum leaf. If you start with nine qubits and you add eight independent parity checks, you have one qubit encoded. Yeah.
00:30:37.652 - 00:30:53.564, Speaker D: Do you know there are codes where you could implement the checks? Additively as opposed to. So the problem with a lot of these stimulus codes is that the check operates very high rate. So that's six, right?
00:30:54.144 - 00:30:55.088, Speaker A: Six local.
00:30:55.256 - 00:31:16.984, Speaker D: Six local, yeah. And often it's much easier to do measurements which look like operator on qubit one plus, operator on qubit two plus something else. Could you just read, is there a way to define check operators? Add it to the list. I mean, it still seems to give you some flavor of parity.
00:31:18.124 - 00:32:05.558, Speaker A: Can you repeat a question for me? Right. So the question, I'm not 100% sure I get it, it's something about can you implement a code where the stabilizers or the checks are sums of operators instead of tensor products of operators? And the thing is, but why would that, would that even be simpler to implement? So say you had a six local, say you had a six local term, but it's a sum of, it's x one plus x two plus x three plus x plus x six. You say that's easier to implement the next one, tensor x two, tensor x three.
00:32:05.696 - 00:32:17.734, Speaker D: Yeah. I mean, at least in some architectures you could think of balancing a light beam of separate cavities. And that gives you that kind of information, give you a superposition of localized information.
00:32:22.354 - 00:32:29.854, Speaker A: Actually, I don't knoW. I don't know if it's possible or impossible. And I'm not sure.
00:32:35.054 - 00:32:37.310, Speaker D: I don't think it would be stabilized according to it.
00:32:37.502 - 00:33:06.726, Speaker A: And I'm not entirely sure. It's not actually, it isn't necessarily that difficult to measure these kinds of stabilizers. So like Z tensor, z tensor I or something. So that's just the parity of two qubits. So you can measure one of the qubits and you measure the other qubit and you have to add them up. And then you have to forget, you don't want to measure the qubit separately, you just want to measure the parity. So you have to forget the internal information.
00:33:06.726 - 00:33:49.574, Speaker A: But the point is you do measure them one at a time. It's not like you have to apply some huge massive six qubit operator. You can just break it up into a bunch of two qubit operators, but you do need to six of them anyway. I agree. That's certainly a concern. This problem that this is non local. And I mean, if you tried to come up with a code that corrects more errors, so say you wanted to correct ten errors, so you use a 21 21 bit repetition code, concatenate that on itself and can't do math, but you know you'd end up with 400 odd qubits or something.
00:33:49.574 - 00:34:30.464, Speaker A: And there would be highly non local stabilizers that would be just kind of impossible to use in practice. So the thing I'll talk about next, actually, is how we can come up with interesting codes that have very local stabilizers. So it's easy to work with these codes. That's this really nice code. I mean, so there's obviously lots of really nice codes. I think people have studied quantum correcting codes for a long time. But one of the nice ones that's both theoretically nice and practically nice is this one called the surface code.
00:34:30.464 - 00:34:48.753, Speaker A: So let me try to give some simple intuition for it. I'll start with sort of a continuous picture. So start with any surface. So it's a two manifold of boundary. Here's an example. So here I just took a sheet of paper and I cut three holes in it. That's the two manifold with boundary.
00:34:48.753 - 00:35:13.894, Speaker A: Now just draw what I'm calling a net. So a net is something that looks like this. I don't know. So basically I'm trying to draw cycles. They can overlap. They can't, they can't end like that. No degree one vertices or nothing with degree one.
00:35:13.894 - 00:35:42.554, Speaker A: They can't go like this either, because then you have these degree three things. So let's fix that. This is a valid net. This is a valid net. That's a valid net if you're careful. I guess if I drew nothing, just a vacuum, that would also be a valid net. Do they have to be compacted? Support.
00:35:43.094 - 00:35:44.554, Speaker B: Can they go up to infinity?
00:35:46.894 - 00:36:29.154, Speaker A: There's really no reason to worry about the math because there's so many problems here. I mean, no, I mean, that's a fair answer. There's huge problems here because the next thing I want to do is I want to actually take a uniform superposition over all these pictures. So instead of this or this or this, I'll just take this plus this plus this plus this and so on. And now you can really see the math is sort of problematic. But, um. Because, I mean, it's not even clear what the Hilbert space is or anything.
00:36:29.154 - 00:36:57.472, Speaker A: But intuitively, this sort of makes sense. You can sort of imagine I have some quantum state as some big superposition, massive superposition of lots of these pictures. Right. And that's what the surface code is, essentially. Ah, so I'm going to come to this in a second. Right. But see, this would have worked for any surface.
00:36:57.472 - 00:37:06.112, Speaker A: So for this code, it's certainly just a single word for more interesting surfaces. We'll get more interesting code spaces. Yeah.
00:37:06.208 - 00:37:11.204, Speaker D: Could you explain how the boundary in the first picture relates to the nets?
00:37:11.664 - 00:37:16.696, Speaker A: Well, I didn't want to draw the boundaries. Again, how are the rules related to.
00:37:16.720 - 00:37:19.908, Speaker D: The holes in the first picture?
00:37:19.996 - 00:38:08.668, Speaker A: Yeah, so when I say, just draw a net on it and you add them all up, what I mean is, you should draw only the ones that don't go around these go around the holes. So, like this plus this plus and so on. But don't have, don't necessarily have terms that go around like that. That's where we're going to get code words in a second. Okay, so let's first, before getting to that, though, let me just fix the math, because we don't want to deal with continuous things. And so what we'll do is we'll discretize it in a pretty simple way. We'll just take some arbitrary lattice.
00:38:08.668 - 00:38:41.528, Speaker A: What people traditionally use is a square lattice, and we're going to put a qubit on every edge of the lattice. So, here, here, here, and so on. And then we think of zeros and ones in the following way. We think of a one as meaning there's a red edge. So if that qubit is kept one, then we say we draw a red edge, a net edge. If the qubit is zero, we don't draw a net edge. So, for example, here, this red gives you a net.
00:38:41.528 - 00:39:19.450, Speaker A: It's a bunch of cycles. And you can think of this as you can read off the state of the qubits. It's 0101-0100 and you can read off the qubits on this horizontal edge, and so on. It's just a pictorial way of drawing these strings of zeros and ones. All right, so then, yes. The claim then, is that this really does give a quantum code. So, the first step of this to make this concrete is to say, I need to say what the code words are, what the code space is.
00:39:19.450 - 00:39:47.416, Speaker A: Then I need to say how it protects against errors and what the distance of the code is. And finally, I need to say, oh, I'll say what the stabilizers are. To relate it to what we did before, the code was actually quite simple. So, say I have three holes in my surface like this. And to be clear, the surface doesn't just have to be a surface with holes. It could be a torus, which is how Kataya first defined this code. Or it could be an arbitrary surface.
00:39:47.416 - 00:40:32.034, Speaker A: But for drawing pictures and actually for physical implementations, a flat plane is pretty simple to work, work with. So, say I have, say I do have three holes. Like this. Encoded zero is just going to be a sum of pictures, like so encoded 10, zero is going to be a sum of pictures where there's an odd number of loops around the first hole. So encoded zero 10, it's going to be the sum of pictures where there's an odd number of loops around the second hole encoded one. 10 is the sum of pictures where there's the sum of all pictures, all these stringent diagrams where there's an odd number of loops going around both of the first two holes and so on. So zero, zero, one is the third hole, and so on.
00:40:32.034 - 00:41:11.878, Speaker A: Yes. So three holes, you get three encoded qubits. That's how we get a code. Um, that's, that's, that's simple enough. Finally, why, why does it correct against errors? This is also simple enough. It's because if you look at just a piece of this, like say a zoom into this region here, right, I have some complicated cat state encoded into this code. But if I look at just a small region of this code, like, like this region, I have no idea what code word I'm in.
00:41:11.878 - 00:41:36.414, Speaker A: There's no way of telling whether there's an odd number or even number of things going around the whole because that's sort of global information that you can't see just by looking at a local region of space. Locally, just see a picture like this. This is some part of a bigger string net diagram. It is a valid string. Oops. Except for these two vertices. I don't know how to fix there.
00:41:36.414 - 00:41:49.666, Speaker A: Now it is a valid stringnet diagram. But you have no idea whether you encoded 0010 or what. That's essential.
00:41:49.810 - 00:42:02.714, Speaker B: Something's a little not clear right at the moment. So you discretize this thing and it's not clear to me that if you did a count of something that it might be different depending on whether.
00:42:04.774 - 00:42:06.302, Speaker A: Accounted kind of what.
00:42:06.398 - 00:42:11.454, Speaker B: So things that go around the first one, there are only so many ways that you can have it circle once.
00:42:11.494 - 00:42:12.678, Speaker A: Around the first one.
00:42:12.846 - 00:42:19.302, Speaker B: And potentially if you look at the frequency of where, no, I think you.
00:42:19.318 - 00:43:05.158, Speaker C: Are completely on the wrong tracks. I tell you how you should think about it. Like if you put like a circle around the first hole, then that already. So that's your, let's say that's your bids on which you can make an error. Then that's already enough error that it can skew the picture because then it already changes the parity. How many times you went down the first hole. So until you are not topologically like that, like then you are not, then you don't see then you don't see any information from the picture.
00:43:05.158 - 00:43:12.174, Speaker C: So you need to go around some hole to see some information. That's. Well. Sorry.
00:43:12.214 - 00:43:51.726, Speaker A: No, yeah, that's a good answer. I mean, so I think maybe elaborating on this picture will make sense. So, encoded 10 zero is not just this one picture. It's a sum of. Not an infinite, but many, many pictures, has all sorts of stringents. Most of them are really messy, but each of them will have something going around this first hole or in some way. So that's why Mario said, sort of topologically, or at least an odd number of times going around that hole.
00:43:51.726 - 00:44:08.834, Speaker A: So it could have three loops going around that hole in some topological way, plus a bunch of things here, plus a bunch of other loops. But sort of mentally, it's nice just to think of as a representative of this huge class of things, each of which has equal amplitude, just to draw this representative.
00:44:09.164 - 00:44:16.572, Speaker D: So, in particular, in the zero zero case, you could go around those things an even number of times.
00:44:16.628 - 00:44:21.084, Speaker A: Yeah. In fact, you could. Yeah. So this would be fine, too.
00:44:21.164 - 00:45:09.778, Speaker C: Actually, I have a better way of saying it, that let's assume I am the evil who is making. Who is trying to cheat. So you are creating this picture, and then I have control over some of the edges. So how many edges do I have to control over that? I change the topology of your picture. Well, I have to control over something which at least surrounds something in order to change your parity over at least one hole, right? I think so. So the question is, like an adversary, how many edges have to conversary has to control in order to change that?
00:45:09.906 - 00:45:11.802, Speaker B: It's not just changing, it's changing the count.
00:45:11.858 - 00:45:12.026, Speaker A: Right?
00:45:12.050 - 00:45:13.786, Speaker B: You got to get the count about right, too, right?
00:45:13.810 - 00:45:15.170, Speaker A: I mean, I see a picture here.
00:45:15.282 - 00:45:29.154, Speaker B: And the question is, can I fill that picture in with approximately the same number of ways by encoding? You know, with pictures that circle one of the things an even number of times and an odd number of times. It's just not clear to me.
00:45:29.194 - 00:45:34.214, Speaker A: Oh, I see. You're worried about the number of terms in the superposition being the same here as here.
00:45:35.474 - 00:45:37.242, Speaker B: They may be different here as here.
00:45:37.298 - 00:45:48.090, Speaker A: Yeah. Okay, well, the reason they're the same. Let's see if I have it here. Ah, it's like the next slide. Okay, so maybe let me just move on. You'll see. Yeah.
00:45:48.090 - 00:46:29.224, Speaker A: The reason they're the same is because we have these pretty simple, logical operators. So if we want to, say, flip the first bit from zero to one, what I can do is I can just apply x's to all the qubits in any cycle around this first hole. That'll switch any valid Stringnet diagram. That'll bring this superposition to this superposition, switching terms one to another. It'll take valid Stringnet diagrams to valid stringnet diagrams. If it isn't an even number of loops around the first hole, it'll have an odd number in the second picture and vice versa. So this is logical x on the first qubit, because applying that switches the state of the first qubit.
00:46:30.284 - 00:46:32.236, Speaker B: You could just choose any cycle you.
00:46:32.260 - 00:46:43.520, Speaker A: Want to run and any cycle would work as well. Yeah, this is one logical x. Sorry.
00:46:43.552 - 00:46:49.856, Speaker D: And if there were a large number of cycles already, and it intersects all of them, so how do you see that it changes?
00:46:49.960 - 00:47:19.564, Speaker A: Isn't that funny? Right, right. So the question was, what if there's, I don't know, what if there's ten cycles in the string net going around this first hole or some huge mess, maybe just some message, and you apply x's around the cycle. Why does that switch? Why does that still switch between zero and one? Why does that still take a valid state to a valid state? And that's because.
00:47:27.064 - 00:47:32.364, Speaker B: Strings with even parity form a subspace. It's a linear subspace.
00:47:32.864 - 00:47:56.544, Speaker A: Yeah, I guess. I don't know if that's the best way of seeing it. Yeah. If you take one set of cycles, these cycles like this, and you add mod two, another cycle, it satisfies all the same rules. So again, the vertices will all have either degree two or degree four. Things might cancel out, but you'll still have a valid string diagram.
00:47:58.684 - 00:48:04.624, Speaker C: Into z two to the k, where k k is the number of holes.
00:48:11.804 - 00:48:41.690, Speaker B: So here's one way of thinking about it. The local error that you can introduce is by adding in a loop that just goes around one cell. And if you try to make a loop around one of the holes, like you try to change the state that you've encoded, you've only, you've not changed the number of loops going around the holes, mod two. Right. Because if you follow, you add a bunch of these like square loops together, all of these sort of radial edges cancel and then you're left with two going all the way around.
00:48:41.882 - 00:49:26.146, Speaker A: Yeah. Or even, or even another way of seeing it, a slightly different way of seeing it would be to make this more precise in a different way. What does it mean to have an odd number of cycles going around this first hole? How do you define odd number of things going around a hole? When you have this funny picture one way of doing it is just to say, look at the number, look at the parity across this line from the hole to the boundary. If that parity is odd, then there's an odd number of things going on in the hole. If it's even, then there's an even number of things going on in the hole. So that's actually the logical z operator for the first qubit. Just measure the parity of all the qubits along some string or some path from the boundary to that first hole.
00:49:26.146 - 00:49:57.134, Speaker A: That tells you whether it's logical zero or logical one. It's not well defined. It's not clear to me that the winding number you are talking about, is it well defined because you don't have strings, you have some nits. Exactly. The way I want to define the winding number is just like this. It's the parity of, it's the number of times you cross a path from the boundary to here. If that's even, I say the winding number is zero.
00:49:57.134 - 00:50:03.714, Speaker A: If it's odd, I say the winding number is one. Makes it precise.
00:50:04.654 - 00:50:19.638, Speaker B: Sorry, I think something I didn't realize is to get one of these valve to change, check whether something you have is valid as a net, it's just a local check about whether things are two valent or four valent or something.
00:50:19.686 - 00:50:20.110, Speaker A: Is that right?
00:50:20.142 - 00:50:22.954, Speaker B: You can't have odd. Is that the only condition you need?
00:50:23.894 - 00:50:42.178, Speaker A: Almost. And that'll be the next slide. Very good. All right. But I guess I'm doing this not quite in the right order. Uh, yeah, so, so anyway, let me finish this for a second. So, so, yeah, these are the logical operators.
00:50:42.178 - 00:51:06.556, Speaker A: If I want to switch to the second qubit, I just look at a cycle going on the second, uh, the second hole. Similarly, for the third, I can measure the z operator, the logical z operators for the second qubit, um, like, like so and so on. For the third qubit and the distance of this code, then it's, it's the least, it's the least weight of any of an operator that acts non trivial in the code space. So it should take one of these qubits to some other.
00:51:06.620 - 00:51:08.024, Speaker D: What were the z operators?
00:51:08.364 - 00:51:37.734, Speaker A: Yes, the z operators are these guys that measure the winding numbers around these cycles. Intuitively, formally, they're just these parities across from the boundary to a hole. The reason they're the z's is that z is 1001 minus one. So it should tell you that logical z should tell you the difference between encoded zero and encoded one in the phase. And that's what these guys. Do.
00:51:40.034 - 00:51:43.134, Speaker C: The x operators differ from the z operators?
00:51:44.954 - 00:51:45.694, Speaker A: What?
00:51:46.674 - 00:51:49.210, Speaker C: How do the x operators differ from.
00:51:49.242 - 00:51:51.894, Speaker A: The z operators encoded x operators?
00:51:54.114 - 00:52:07.474, Speaker C: Well, never mind. Probably end the wrong tracks. So you need to check these two types of errors, right? Or.
00:52:07.934 - 00:52:11.278, Speaker A: Oh, I see. Yeah, yeah, I'll get to that. I'll get to that in a second.
00:52:11.366 - 00:52:12.034, Speaker C: Okay.
00:52:12.374 - 00:52:49.288, Speaker A: Okay. Yeah, yeah, yeah. Right. But, so I'll get to that in a second. But yes, so a good way of thinking about the distance, another way of thinking about the distance, it's how hard do you have to work to operate on the code space? How many qubits do you need to change to affect the code space while staying inside the code space? And here, it's just, it's the least weight of any of these logical operators. So you got to go either around one of these holes, around two of the holes or something like that, or you have to go from a hole to a boundary. So that's the distance.
00:52:49.288 - 00:53:09.608, Speaker A: So if you want a good code, you better make sure that these holes are well separated from the boundaries. So, if you remember, we have really, there's a lattice here. So I'm not drawing for the most part. And you have qubits on every edge of the lattice. And a hole is just. What is a hole? A hole just means there's no qubits there. You can only change it by.
00:53:09.608 - 00:53:38.376, Speaker A: You can also change it by acting between two holes. Right. Yeah, actually, you could. So say this operator here, string of Z's like that, it's topologically the same as this and this. So yeah, right. So that's a z two, tensor z three. Logical operator.
00:53:38.376 - 00:54:10.744, Speaker A: Right. That's why the holes need to be kept separate from each other as well as kept separate from the boundary. And finally, sort of an interesting thing about this code. Maybe the most interesting thing about this code is what the stabilizers are. There's two different kinds of stabilizers. One, just like for the repetition repetition code encoded on the dual repetition code, there were x stabilizers and z stabilizers. It's the same here.
00:54:10.744 - 00:54:45.364, Speaker A: The first set of stabilizers tells you that the degree at every vertex has to be even. So it could be zero, two or four, because that's what these stringent diagrams have. There's no trivalent vertices and there's no dead ends. The way you can enforce that is you just put for every vertex in this lattice, you have a z stabilizer. That on the four incidents incident qubits, you have z tensor z, tensor z, tensor z. So that measures the parity of those four qubits and forces it to be even. So these kinds of diagrams are allowed.
00:54:45.364 - 00:55:27.004, Speaker A: A diagram with one would not be allowed. That's what the stabilizer enforces, because you have to be in the plus one eigenspace. The second rule is slightly more complicated, and that's how do we enforce that these different superpositions have superpositions of these different nets, that they all have the same amplitude. How do you enforce that locally, it's just a local stabilizer. So, for example, here I have alpha times this first diagram plus beta times the second diagram. Say they differ only in this one square. The first diagram misses it, and the second diagram has it.
00:55:27.004 - 00:56:27.926, Speaker A: What we can do is we can have a stabilizer that acts on those qubits, on these qubits here, here, and here. So x tensor x tensor x tensor x. And if we stay that, if we say that this state psi is in the plus one eigenspace of these four x opera, of the x tensor x tensor x tensor x, that means that alpha has to equal beta because that operator switches these two terms. So that's how we enforce that these terms have equal amplitude. In fact, if you're stabilized by all for every tile in the lattice, if you're stabilized by those x tensor x tensor x tensor x, but those operators, then in fact, all the amplitudes have to be equal. And not just alpha equal beta, but gamma times the vacuum plus delta times whatever. All these alpha equals beta equals gamma equals delta.
00:56:27.926 - 00:57:18.406, Speaker A: And the reason is because you can use these small cycles. So these stabilizers only create or destroy a cycle of size four around one tile, but you can put them together to get bigger cycles. So, for example, if you want to get a cycle around these 16 tiles or whatever, 20 odd whatever, you can just multiply the x stabilizer for the first tile times the stabilizer for the second tile, and so on. Take the product of all those tiles stabilizers, and the x's on the interior edges will cancel. Since x squared is equal to the identity, two bit flips cancel out. And so that's how you can get, if you're stabilized by all the individual ones and you're stabilized by their product, their product corresponds to this big cycle. So therefore you're stabilized by this big cycle.
00:57:18.406 - 00:57:41.524, Speaker A: So the amplitude doesn't change when you add or subtract a big cycle or a small cycle. It doesn't. So probably there's a little bit more to prove there if you want to make that formal. Certainly intuitively, that's the reason why these are the only stabilizers you need to force you to be in the code space.
00:57:44.784 - 00:57:58.596, Speaker B: Okay, so is this equivalent to saying, or is this relevant, that if you took a particular diagram and wanted to modify it, one way would be by.
00:57:58.620 - 00:57:59.304, Speaker A: Sort of.
00:58:02.324 - 00:58:21.172, Speaker B: Adding, I guess, a square, or if part of that square was already sort of changing the root from. So is this sort of that stabilizer, sort of that sort of making this equivalence class of diagrams, is that right?
00:58:21.228 - 00:59:02.234, Speaker A: Yeah, yeah. I mean, it enforces sort of topological equivalents. So, for example, say you have a picture where there's lots of stuff going on, but maybe you have a wire coming down, a net coming down here, and here's a square, and then that goes down and across, and then it goes off and does some other stuff. If you multiply by x tensor x tensor x tensor x, it just slides it around, so it goes around the square in the opposite direction. And when you multiply by lots of these x operators, you can sort of topologically, just to form this string however you like. And so because they're all stabilizers, that means they all have equal amplitude. So in other words, all string nets that are topologically equivalent to each other all have equal amplitude in this state, in the code state.
00:59:02.234 - 00:59:33.484, Speaker A: And this all generalizes. It's not just for this one surface code. You could define lots of codes in this way that set as properties. It's quite nice. Okay. And so this finally sort of answers Mohan's question. Maybe two is too certain.
00:59:33.484 - 01:00:01.924, Speaker A: These stabilizers, now, they are local, right? So there's only, they're all four local. So the x stabilizers act on the four qubits around a cycle, around a tile. The z stabilizers act on the four qubits around a vertex. And so this is sort of how we think of implementing a quantum computer these days. Most people are thinking, you have this 2d lattice of qubits. These black qubits are the qubits that are actually used in the code. These are the ones that store the quantum information.
01:00:01.924 - 01:00:49.254, Speaker A: But then you these other sort of extra qubits sitting around. And the point of these extra qubits is so that you can measure the stabilizers, these parity checks. So, like the blue ones, you're going to use these blue ones to extract which sit in the middles of each tile, you're going to use some to extract the parities in the dual basis going around the tile. And these green qubits sitting on the vertices, you're going to use those to measure the parities of the incident for code qubits outside from that vertex. And everything now is very nice and is all geometrically local. So you can actually think about implementing this on a 2d chip or your qubit. Okay.
01:00:49.254 - 01:01:35.114, Speaker A: And maybe that's sort of why people like this code for when they're thinking about implementations, when you're thinking about, say, Hamiltonians in complexity. Just, I don't know if people have seen this before or not. You can think of it. It's a ground space of some simple Hamiltonian, this code spaces, right? Because I claim it's a ground space of this Hamiltonian, which is minus the sum overall vertices of the z stabilizers, minus the sum of all tiles of the x stabilizers. That's because all these terms commute with each other. So the ground space being in the ground space means you're a plus one eigenstate of each of these terms separately. Plus one, plus one eigenstate of each of the terms separately means you're stabilized by them, so it's all equivalent.
01:01:35.114 - 01:02:12.154, Speaker A: So here we have this interesting code space. It's a four local Hamiltonian, but not only is it four local, but it's actually geometrically four local in two dimensions. So qubits are nicely laid out on the plane. Okay, so that's kind of like the first part of this talk. So, hopefully sort of giving you some intuition for this, for the surface code and for quantum codes in general. I thought in the second part of this talk, I'd actually sort of talk about how we can, how we can use this code. And this is, of course, interesting in practice.
01:02:12.154 - 01:02:28.674, Speaker A: I mean, if you're trying to build a quantum computer, if you're not trying to build a quantum computer, I think it's still interesting just because it sort of gives me an excuse to talk about other, other properties of the code and teach you a little bit more about error correction and, sorry, stabilize your algebra. Yeah.
01:02:29.054 - 01:02:36.074, Speaker D: I hope it's not too technical, but what happens to the terms that, like, on the boundary, and why do they commute?
01:02:37.294 - 01:02:54.778, Speaker A: Yeah, so that's a good question. Whenever you have boundaries, the boundaries are always the hardest part. Right here, though, it's actually quite simple still. So, say this is my full lattice. So we've. I don't know how many qubits there are. Whatever.
01:02:54.778 - 01:03:17.974, Speaker A: There's a qubit on the middle of every edge. We just have the same constraints. So for every tile, we're gonna have four x's. The way I've drawn it, for every vertex in the interior, we have four z's. But for, like, this vertex here. I just have two z's. I mean the parity has to be even cause I don't want a net that dead ends at this vertex.
01:03:17.974 - 01:03:25.970, Speaker A: So I just have z tensor z for that guy. So there's nothing special in other words.
01:03:26.162 - 01:03:31.774, Speaker D: But if you create the hole, like if you in the middle, it seems that the problems start to arise.
01:03:34.314 - 01:04:06.118, Speaker A: No, there still won't be problems because like, say there's a. I messed up. No, no, I just have to fix. I don't want to use the eraser for the rest of the talk. There you go. Say there's a hole like this. That just means I'm not going to use, there's not going to be an x stabilizer here, but all the z stabilizers are the same, all the other x stabilizers are the same, everything will work.
01:04:06.246 - 01:04:09.394, Speaker D: So you just remove the.
01:04:10.374 - 01:04:12.750, Speaker A: So I just removed these two x stabilizers.
01:04:12.942 - 01:04:26.714, Speaker D: I see. Okay. And there's some way to remove the x terms correctly. It's not clear how. Which ones do you remove? All the ones that touch the hole.
01:04:27.684 - 01:04:29.624, Speaker A: All the ones inside the hole.
01:04:30.604 - 01:04:32.144, Speaker D: Okay, I see.
01:04:41.484 - 01:04:56.776, Speaker A: Okay. So let's see how errors affect this code. And it's fairly simple. So say you have, let me just draw the vacuum. So the all zeros string. And look at that. Say you have a single x error that's just going to flip a single edge from zero to one.
01:04:56.776 - 01:05:35.264, Speaker A: It's going to turn a net edge from zero to one, but that's going to be detected at the two end points because now I'm going to have two vertices with odd degree because the net will now dead end there. This is not part of the code space, this is an error. And the point is errors like this, with one or two errors, chains of errors, they're going to be detected only at the endpoints, because if you look inside, like right here at this qubit, you can't tell if you're in a valid state or not, but at these two vertices you can tell there's something wrong because we have these dead ends. I just wanted to ask you to remind me what the logical operators were.
01:05:36.004 - 01:05:40.124, Speaker D: Oh, there's a loop around one of the holes, right?
01:05:40.244 - 01:05:54.432, Speaker A: Yeah, but was it C's or X's? You could define it either way. The way I defined it was the X's go around and the Z's go from the holes to the boundary. So in this case, if I apply.
01:05:54.608 - 01:05:57.524, Speaker D: Loop of Z's, what happens?
01:05:59.384 - 01:06:26.064, Speaker A: A loop of Z's going around. Let's see what happened. Would that take you out of the code space.
01:06:34.804 - 01:06:44.724, Speaker B: Couldn't it change the count that you were doing going across, or shouldn't it? You'd only see one across any.
01:06:45.424 - 01:06:55.364, Speaker A: No, I think a loop going around should be a stabilizer. So I think you should be able to find. I think it should be. Leave the code space unchanged.
01:06:56.824 - 01:06:58.644, Speaker D: It's not going to change any count?
01:06:59.024 - 01:07:39.604, Speaker A: No, it doesn't change any count. Yeah, it leaves the X's, it commutes with all the x's. So you should be able to multiply some subset of these vertex z stabilizers and generate that, something that goes around. I think so, yeah, actually that's true. So, like for example, if you multiply, if you take all the vertices in this bulk region except those in the interior of this region you're talking about. So take them up to this, up to this red boundary, you multiply them all together and you end up with Z's going around because everything else cancels. That's a stabilizer.
01:07:39.604 - 01:08:11.304, Speaker A: Thanks. Okay, right, so now we have errors. And the point really is just that errors correspond to strings that terminate instead of cycles and stuff. That's what x errors do. So you see them at their endpoints, z ers, everything's. It's hard to see now, right, because my picture is sort of biased for the computational basis, this picture of string nets. But actually z ers, it's all the same.
01:08:11.304 - 01:09:06.102, Speaker A: Just in a dual picture, X's and Z's are not really any different because a tile, an X operator acting on these four qubits is same as Z operator acting on those four qubits. Just if you sort of switch x's and z's and you shift the lattice by half a unit, that's why you can see it's symmetric. And so, yeah, if you have a string of z ers, again, you'll detect that at the two endpoints. That's how you can see what z errors do. What that means is that if we're trying to correct errors, if there's some set of errors acting on a state, what we should do is we should run a matching algorithm to try to match up these endpoints to each other. And then we can correct, and then we can correct the errors because we infer that there's a string of errors between the two endpoints. So here's a sort of a concrete example that I've worked out.
01:09:06.102 - 01:09:44.844, Speaker A: So say you have whatever by whatever lattice, and you measure the parities at every vertex. And you see there's an odd parity at these orange, golden orange vertices. So how do you, how do you, how do you correct this error? What you do is you try to explain it. So the way you can explain it is by strings of x areas that terminate at these, at these orange points. So for example, here's an explanation, x, x, x along these three chains of x's. And so that's 13 x errors that generate this, this observation. Well, there's a better observation.
01:09:44.844 - 01:10:29.024, Speaker A: There's a way of generating with only five, five x errors. And so if you're trying to, if you see this observed pattern of odd parity vertices, you should correct it by flipping these x's. This is the best explanation, the least weight explanation, therefore the most probable explanation. And the way you correct z errors is the same just on the dual lattice. So just like the repetition code, on the dual repetition code, we correct x errors and z errors separately. And there's lots of subtleties here. One thing that's worth pointing out is that I'm assuming we can use a classical computer to correct errors on this quantum computer.
01:10:29.024 - 01:10:59.236, Speaker A: It's not strictly necessary for fault tolerance, but it makes our life much simpler. I won't take too many more. I won't say anything else. Just a question. Yeah. Doesn't observing what vertices have log parity collapse, whatever? No, because the quantum state save a code word first of all. Yeah.
01:10:59.236 - 01:11:08.424, Speaker A: Okay. In the code word, everything should have even parity. If there's a single x there, then you do have some odd parities. But it's odd parity at the same vertices. Always.
01:11:12.484 - 01:11:21.092, Speaker C: So you want to minimize the number of axes that make it, that make the picture correct or just want to get below a threshold.
01:11:21.268 - 01:11:35.168, Speaker A: Well, if you think of your error model as being like independent errors, then the most likely explanation, independent errors with some probability on each qubit, then the most likely explanation is the least weight explanation. And so that's the one you want to be correcting for.
01:11:35.216 - 01:11:43.224, Speaker C: My next question. Is that so minimizing classically, is it the polynomial time algorithm?
01:11:43.304 - 01:11:44.376, Speaker A: Yes, that's one of these things.
01:11:44.440 - 01:11:49.416, Speaker C: If it's not, then there is another problem besides factoring.
01:11:49.520 - 01:12:33.774, Speaker A: Right, so that's one of these things I don't want to talk about. Yeah, it's, it's polynomial, it's polynomial time. But I think the best algorithm is like cubic time, which is way too slow to run on any practical size. Quantum computer because you want to be doing this quite rapidly, to be able to correct errors quite rapidly in practice, people come up with sort of heuristic matching algorithms that work almost as well as a perfect matching. And they work pretty well, they're fast. So to know whether vertex has, you can just measure the qubits around it and then conclude, right, you gotta be able to apply some transformation. You have to measure the parity of the four qubits, right.
01:12:33.774 - 01:13:31.934, Speaker A: If you want to measure the parity of two qubits, you can just do it like this. And then measure this. Yeah, okay. And then things get interesting when we try to deal with errors on top of errors. So what if you have errors when you're trying to correct the circuit, when you're trying to correct the error. So for example, say you see this picture here on the left and there's three odd parity vertices that you observe. This makes no sense because you can't run a matching algorithm because there's three what's going to match with what? And the point is if you see three odd parity vertices, then there must have been an error in your observation.
01:13:31.934 - 01:14:12.174, Speaker A: So we have to deal with errors in the observations as well as errors on the data qubits. And what we're going to do is it's actually not that complicated. We just keep on repeatedly run this, we repeatedly extract the syndromes at every vertex. And so here's sort of a picture in space time. So I just have one dimension of space but there's another one, and then in time. And so say there's an x error on a data qubit here, and then there's syndrome errors here and here. When you extract those two vertices syndromes, parities, then you're going to observe a flip at the top of the chain and at the end of the chain.
01:14:12.174 - 01:15:00.176, Speaker A: I don't know if it's a little bit subtle to see that, but it's not that complicated to sort of see intuitively it makes some sense. Errors in observations are the same as errors on the data qubits. You just have to add this third dimension. And so if you're trying to correct for these, you just have to run the matching algorithm in three dimensions instead of on two dimensions. That's the only change you have to make, with a few other subtleties, essentially, that's the only change you have to make. And so that's how you can do error correction, fall tolerantly with errors in the syndrome extraction. Now for code to be interesting, we have to be able to compute on top of it.
01:15:00.176 - 01:15:30.856, Speaker A: And that's another reason why the surface code is interesting, it's because it lets you compute pretty easily. And here, I guess the main moral is that we don't just decode the code, compute, and then re encode the code. Because first of all, decoding is quite complicated, and you already get quite a lot of errors when you're decoding. But at the end of the day, you'd have this completely unprotected qubit, and noise would mess up the computation. So then your whole quantum computer would fall apart. So we really need some way of taking our code. Code word.
01:15:30.856 - 01:15:54.630, Speaker A: Here's a code word. Somehow we have some process that goes from here to here at every step. In the middle, it's protected against noise. And yet overall, we've implemented some interesting logical operation. So I'd like to just give an example of how we do this. And the most interesting example is sort of the Cnot gate. Because this is a two qubit gate, it entangles things.
01:15:54.630 - 01:16:24.058, Speaker A: It's pretty interesting quantum mechanically, but it's also quite simple. So here's the cnot gate. It's a two qubit gate. Classically, in the computational basis, it just adds the first bit into the second bit, mod two. And with the surface code, there's lots of ways of implementing this. The first method is kind of silly, but it's useful to remember is you can just do use it. You can implement it using transversal gates.
01:16:24.058 - 01:16:57.350, Speaker A: And so this is based on the following observation. If you take two of these stringnet diagrams and you add them up, mod two. So, meaning that two edges cancel out to nothing, it gives you another valid stringnet diagram. So in this example, you can see there's some cancellation here, but it doesn't matter. Everything still is degree two or degree four. What this means is that we can just take two code blocks. So here's one code block with one qubit.
01:16:57.350 - 01:17:32.620, Speaker A: Here's another qubit encoded in the second block of the surface code. And just apply CNOT's from corresponding qubits to corresponding qubits, corresponding qubits of the first block to the corresponding qubits of the second block. And that'll just add mod two, the first diagram into the second diagram. So it'll take a valid Stringnet diagram into another valid Stringnet diagram. So it leaves a code space unchanged. That's good. And furthermore, if you have like an odd number of cycles going around this whole, before you apply those cnots, that'll be copied into this, the second guy.
01:17:32.620 - 01:18:01.320, Speaker A: So now you'll have an odd number of cycles also going around the second, the bottom hole. And so it's changing. It's flipping the second qubit from zero to one or back, just like a CNoT gate. So this is a CNot gate on the code space? Yeah. Given this picture for transversal c nots, are you suggesting that we should not.
01:18:01.392 - 01:18:04.080, Speaker B: Have encodings with like three holes on one surface?
01:18:04.112 - 01:18:26.834, Speaker A: It should all be like this? No, I mean, this is that. Exactly. I mean, this is not the best idea of doing it. And the reason we don't actually think of doing things this way is because this loses your nice geometric locality if you're trying to implement this, because then if you're trying to implement this, you need to somehow shift the first encoded coded qubit into the middle of the second encoder. Coded Cuba. Yeah. So we're not going to do things this way.
01:18:26.834 - 01:19:24.374, Speaker A: Let me come back to that in a second. The other way of doing this is what's called co deformation. So here, instead of having multiple blocks to get multiple qubits, we're going to have just one surface, and we're going to get multiple qubits on this one surface. So here I have four qubits in this one surface. And the way we're going to compute is we're going to change the code incrementally, slowly from this original code to a slightly different code, and get back to the start. So what we're going to do is we're going to shift this first hole here slightly just down into the left, and shift a little bit further, and shift a little bit further down over here, and keep on going until it goes all the way around this, this bottom hole and back to where we started. And so we start with one code, we end with the same code.
01:19:24.374 - 01:20:02.524, Speaker A: These intermediate things are different codes. They're completely different codes, but they still give you the same protection. So long as you keep the holes far enough apart from each other, you're still protected against errors, even in the middle. But the point is, the idea of this code deformation is that even though we start ending in the same code, but hopefully, hopefully some interesting logical operation has been applied. And actually, in this example, nothing interesting has been applied. I've applied the identity. So I need to go through a couple of technicalities to actually do something interesting, but not anything bad.
01:20:02.524 - 01:20:47.112, Speaker A: Any questions? So, here's the technicality, which I will explain, because it's not so bad. So again, it just has to do with these boundary conditions. So before, I've only talked about what are called smooth boundary conditions, where. Well, it's like this, like that. It's just the lattice is, I don't know, these are all smooth boundaries. But a rough boundary is something like this. So we have these edges of lattice that just hang off into nothingness.
01:20:47.112 - 01:21:20.754, Speaker A: That's like what I call a rough boundary. And actually they're duals of each other. So if you switch X's and Z's and shift the lattice by half, you switch rough and smooth boundaries, so they're not really that secure. Essentially, the difference in terms of the stabilizers, the difference is that at a smooth boundary, the tile stabilizers are unchanged. They're squares, whereas the z stabilizers are changed weight three instead of weight four. At a rough boundary, the Z stabilizers are unchanged. They're all weight four still.
01:21:20.754 - 01:21:53.784, Speaker A: But the X stabilizers are now sort of messed up. They now just have weight three. So there's some x stabilizer here on these three qubits, but not a fourth, because there is no fourth qubit. And so now the point of a rough boundary is that actually a string can end on a rough boundary. That's okay, because we're not measuring the parity. We're not measuring the parity at this vertex. Notice Z stabilizers there anymore.
01:21:53.784 - 01:22:30.494, Speaker A: And so we can use the different encodings. So here what I've done is I've taken the surface, I have a rough boundary on top and a rough boundary for the first hole, and everything else is smooth. And so now logical X for the second qubit is the same as before. Logical X for the first qubit is just going to be an x from the rough boundary to the other rough boundary to the rough boundary of the hole. So the parity of the number of strings goes, going from one boundary to the other is now going to tell you whether you're zero or one. Okay, it's just the dual of the picture from before where that was Z's. Now it's X's.
01:22:30.494 - 01:23:30.314, Speaker A: And so if we want to compute, we just do the following sequence of deformations, code deformation. So I slide this rough boundary hole down and around and around and around back to where it started, and this chain of X's, sort of topologically, it just becomes this chain of X's. So that's what happened to the logical operator on the first qubit. That's equivalent to this chain of X's. This chain is the same as this chain, which is also equivalent to this picture here in the bottom right. Because mod two, I can cancel out this edge against that edge, slide them together, and they cancel out. So you can see, overall, what I've done is this x operator has become an x operator in the first qubit tensor, an x operator in the second qubit.
01:23:30.314 - 01:23:51.334, Speaker A: A loop around the second hole is the x operator on the second qubit. So I've actually implemented a logical sinaki between these two qubits by dragging a string behind me. Essentially, as I move this hole slowly.
01:23:53.834 - 01:24:08.730, Speaker B: I think I missed something. The two holes are sort of the first hole instead of the number of loops around it. I'm now counting the number of paths to the boundary. Is that right? Yeah, but the second hole I'm still.
01:24:08.762 - 01:24:26.854, Speaker A: Counting as the number of loops, just as before. Right. And so now, like, zero, zero is the same as before. Encoded zero, zero is the same as before. But encoded ten now means there's an odd number of paths from the boundary, this rough boundary, to that rough boundary.
01:24:28.934 - 01:24:30.878, Speaker B: Why is zero zero the same as before?
01:24:31.006 - 01:24:46.286, Speaker A: Because zero zero before was just, you have no things going around either hole. Oh, I see. Okay. It's not the same as before. Sorry. Okay. But I mean, anyway, so this is why you get the cnot gate, essentially.
01:24:46.286 - 01:25:21.204, Speaker A: You could check a couple of other things to make sure that it does the z operators correctly, too. This is the essential reason what people do in practice is they draw pictures like this. So you have two dimensions, which are the space of your qubit, of your surface. Then you have time in the third dimension, and you just draw how these holes change versus time. They braid around each other, and they always have to be separated by at least the distance that you're trying to have for this code. And you have, some of the holes are smooth, some of the holes have rough boundaries. And you can interact to apply cnot gates.
01:25:21.204 - 01:25:23.300, Speaker A: By sending us a smooth hole around.
01:25:23.332 - 01:25:28.716, Speaker B: A rough hole, what you've drawn at some point has six holes. You have holes that are created and destroyed.
01:25:28.740 - 01:25:58.552, Speaker A: I know, I know. It's because of this issue. Like, I've only told you how to create, how to implement a cnot from a rough hole to a smooth hole. But what if you want to do a smooth to a smooth, for example? And so what you do actually, in that case is you have to change the smooth qubit into a, a rough qubit encoding. And the way you do that is you have to, here's a qubit that, here's sort of a smooth qubit. You just wrap around it a rough qubit. And that sort of implements the identity operation.
01:25:58.552 - 01:26:02.928, Speaker A: One can check, you have to check this. It implements the identity operation, but it changes smooth to rough.
01:26:03.056 - 01:26:06.924, Speaker B: So when you're creating these pairs, don't you worry about error when they're close together.
01:26:07.464 - 01:26:10.294, Speaker A: Yeah. They can't be close together. They have to be always.
01:26:10.464 - 01:26:11.854, Speaker B: But when you've created them.
01:26:13.034 - 01:26:15.402, Speaker A: Oh, I see them close together in.
01:26:15.418 - 01:26:16.574, Speaker B: The beginning of their lives.
01:26:17.314 - 01:26:45.150, Speaker A: Yeah. If you create a pair of holes like this. So, like, at this time point, they're really close to each other, but these are smooth boundaries. So let's see. So you get a z er there, which would mess things up. It would be a logical zero. Topologically, the same as a logical zero.
01:26:45.150 - 01:27:13.906, Speaker A: At the end of the day, that's a problem, except it's not a problem because this is actually. This creates the state logical zero. So logical zero doesn't do anything. One has to check. That's essentially the reason B. Right. So let me just finish up then, the basic idea for putting it.
01:27:13.906 - 01:27:41.596, Speaker A: For putting this all together. Let's say, how are we actually going to implement a quantum computer? It's going to be some sort of mess like this. We have a two dimensional lattice of qubits. We're going to have all these holes in it. For technical reasons, I guess most of the time, people think of pairing the holes together and using two holes at a time to get one qubit. That kind of throws away half the logical qubits because there are twice. There is actually one logical qubit for every hole.
01:27:41.596 - 01:28:15.760, Speaker A: But most people only think of using one for every two holes. So you're going to have all these holes, you're going to pack them together as closely as possible because you don't want to use very much space because qubits are expensive. You have these channels, sort of a little bit of space that you can move these holes around and still keep some minimum distance separation. You have some rough quits, some smooth qubits. They'll be moving around. I haven't talked about how you get universal computation for that. Things get really messy.
01:28:15.760 - 01:28:42.100, Speaker A: You need to talk about distilling these certain kinds of states. It's not just braiding holes around other holes. And so, actually, I guess probably most of your diagram will be, will be used for distillation and not for encoded data. And here. Okay, it gets quite complicated. Some of the holes, you can actually have smaller holes than others because you don't need the same distance for these qubits as you need for other qubits. They can be protected less.
01:28:42.100 - 01:28:55.914, Speaker A: Well. But anyway, I think this sort of gives you some sort of picture of how quantum computers could potentially work based on this kind of code. Thank you.
01:29:06.814 - 01:29:11.514, Speaker D: Architecture, is there a threshold? And so on. Has that been actually.
01:29:14.994 - 01:29:45.864, Speaker A: Yeah. So the question is, is there a threshold known for this kind of architecture? And, yeah, there certainly are thresholds known. There are numerical estimates for thresholds, which kind of vary, but they're often quite high. So they range from like maybe a quarter of a percent to 1% noise per gate numerically. So it's competitive with other codes. Basically, the proven thresholds, which are based on sort of. They are rigorously proven, actually.
01:29:45.864 - 01:30:02.824, Speaker A: They're based on correspondences to natural statistical physics models and how, what kind of matchings? It's based on this matching thing. And I think they're quite like ten to the minus six or ten to the minus five, maybe, is what's been proved. It's much less.
01:30:10.264 - 01:30:14.044, Speaker D: What are the references for the practical ones?
01:30:15.944 - 01:30:44.554, Speaker A: What are the references for practical estimates? The first people who did this were Rousendorf, Harrington and Goyal. Since then, I think a few other people have. I think their numbers have been independently sort of checked. So other people have also run the same kinds of simulations and got similar numbers, if not exactly the same.
01:30:44.934 - 01:30:48.794, Speaker D: What was the timeframe? When did this happen?
01:30:49.094 - 01:31:37.504, Speaker A: Like, probably zero six or so. I have a possibly more cracked up question, which is for error correcting codes. Classically, we know plenty of codes with constant weight generators and linear distance, like LDPC codes. And quantumly, you know, this surface code just gives you root n distance. And people have only been able to push it to, like, root n, root log. Nice. You know, I wonder if this has any relation to all of our difficulties in doing quantum PCP that, you know, we don't even have, because there's something kind of PCP like about codes that you check in a constant number of positions and have linear distance.
01:31:37.504 - 01:32:09.944, Speaker A: I also don't know what to believe about whether these codes should exist or not. Yeah, I don't know. So this basic question is, what's known about local codes? What kind of distance is achievable? Yeah. And whether that relates to PCP. I don't know. I don't know. It's certainly interesting.
01:32:09.944 - 01:32:29.596, Speaker A: I think it's also interesting. Your observation is also interesting practically for people trying to implement these kinds of computers because. Yeah. This isn't a great code in terms of, like, the distance or anything. The distance is only a square root of the number of qubits against random errors. I guess it works pretty well. You can still try to come up with more.
01:32:29.596 - 01:32:48.144, Speaker A: You could still try to use more space efficient codes than this one. For example, you could use another code on top of this code. You can concatenate another code on top of this code would be one practical way of dealing with this. All right, great. Thank you.

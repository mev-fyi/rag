00:00:01.360 - 00:00:11.942, Speaker A: Thank you very much and thanks a lot for the opportunity to speak here to the organizers. And I'm going to tell you about. Am I echoing or it's just.
00:00:11.998 - 00:00:12.614, Speaker B: No, it's good.
00:00:12.694 - 00:00:43.108, Speaker A: Okay. I feel I'm echoing to myself. Okay, so I'm going to talk about an invariant that's been around for a couple of years now called the positive semi definite rank of a non negative matrix. And this is joint work with several people. So it's a union of several papers. But in the spring this year, we wrote a survey which you can find on the archive. And my talk today is going to be based on the outline of this survey.
00:00:43.108 - 00:00:43.824, Speaker A: So.
00:00:51.814 - 00:00:52.874, Speaker B: Happen before.
00:01:55.344 - 00:02:29.156, Speaker A: Give it one more shot. Okay, so let's hope for the best. Okay, so let me start by right away defining what the notion is, and we'll see lots of different mathematical aspects of this, this rank. So the definition is as follows. We start with some non negative matrix m. Let's assume it's p by q, and throughout the talk I will assume there is a matrix m of size p by q with non negative entries. So plus includes zero.
00:02:29.156 - 00:03:12.806, Speaker A: So these are really non negative entries. And then the definition of PSD rank is the following. So it's the minimum integer k, positive integer k, such that I can find matrices a one through ap that I can put on the rows of my matrix m. They have to be PSD. So this is my notation for k by k PSD matrices. And I should also be able to find another set of PSD matrices B, one through BQ that I can put on the columns of my matrix M such that when I take the inner product of AI and Bj, I recover the IJ entry of the matrix m. Okay? So the inner products that these AI's and Bjs make should be exactly the entries of m.
00:03:12.806 - 00:03:51.178, Speaker A: So the minimum k for which such matrices exist. And the matrices are k by k. PSD is exactly defined to be the PSD rank of a non negative matrix. Okay, so let's see a simple example. So let's look at this matrix m, which is the derangement matrix of size three by three, okay? And this matrix has rank three. The usual rank is three, but it has PSD rank two. Okay? So that means I can put two by two PSD matrices on the rows and columns of this matrix m such that the inner products will line up to be these entries that you see here.
00:03:51.178 - 00:04:20.342, Speaker A: So here is for instance, a factorization through the two by two PSD cone. So a one, a two, a three. I would put on the rows b one, b two, b three I would put on the columns. And then you have to check that the inner products line up. So just a quick check. For instance, if I want to check that the three one entry is one, I want to make sure that a three in the dot product of a three and b one is exactly one. And that's true because of this one and this one and everything else is zero.
00:04:20.342 - 00:04:37.816, Speaker A: Okay, so this is an example of a PST factorization of size two for this three by three matrix. So this example is interesting because right away you see that rank can sometimes be bigger than PSD rank. Okay? So this is, now, on the other hand, if you look at all three.
00:04:37.840 - 00:05:02.244, Speaker B: By three, can I just ask, why should we think that there's an immediate connection between the, or any relationship between the rank and the PSD? So one thing is easier. If you didn't have the PSD constraints, then there's a quadratic, you could think of just the matrices as being vectors. As vectors, yeah, but the PSD cone has dimension three. Anyways.
00:05:02.904 - 00:05:36.996, Speaker A: All right, so if you have, if you take another set of another three by three matrix, like the identity for instance, then the PSD rank is actually three. And we'll see just very shortly that there is a certain range that the PSD rank could have been. If, sorry, if the rank is three, then these are the only two possibilities. Sorry, said that wrong. If you have a three by three matrix, then the only two possibilities for PSD rank are two and three. And hopefully you will start seeing why all of this is true as I go on. Okay, so this is just a simple example and the basic definition, you mean.
00:05:37.020 - 00:05:38.820, Speaker B: For a rank three, three by three?
00:05:38.892 - 00:06:16.818, Speaker A: No, I don't mean that. I mean, yeah, exactly. For a rank three three by three matrix. Okay, right. Okay. So since this whole definition of PSD factorization, or PSD rank and so on, is a factorization result, let's just kind of compare it up front to what we think of rank, how we think of rank as a factorization. So remember that when we calculate the usual rank of a matrix, what we're calculating is the minimum k such that I can write m as a times b, no restriction on what's inside a and b such that a is a p by k matrix and b is a k by q matrix.
00:06:16.818 - 00:07:40.600, Speaker A: So I want to factorize my m as a and b, where I want to minimize the intermediate dimension, which is k. And that's exactly what we call rank. And if we reformulate this slightly, then what we are saying is I can think of the rows of this matrix a as vectors a one through ap that live in Rk and I can think of the columns of the matrix b, b as vectors b one through bq that live in the orthogonal in the dual space Rk star. And what I'm asking for is mij is equal to aibj, right? So this is exactly what rank is and this is basically we're asking for the factorization of a matrix through subspaces, right? So we are given the set of euclidean subspaces and we are asking for the smallest subspace in this family through which I can factorize my matrix and similarly PSD rank you should think of as factorizations through cones as opposed through subspaces. So that might help actually. Okay, so here's a general definition of what we call the cone rank of a matrix, and this was introduced in a paper by Joao Pablo and myself in some years ago, appeared last year and here what we do is we take a family of cones. They have to be closed in the sense that if you look at a face of the family, it again has to be in the family that's important.
00:07:40.600 - 00:08:34.644, Speaker A: So for instance, non negative orphans have this property, every face of a non negative orthan is a smaller non negative orphan. The PSD cone has this property, every face is another PSD cone of smaller size. So if you take such a family of closed convex cones, then we can define in general the cone rank of a matrix. And that's just the minimum k through which I can factorize my matrix, meaning I can find elements a one through ap in the cone indexed by k and elements b one through bq in the cone indexed in the dual cone c k star, such that when I look at Mij, this is exactly the inner product of AI and Bj. Okay, so these are cone factorizations. And on Monday we saw in Sanjiva Rora's talk the example where this family is the positive orthans. If you take the set of all positive orthons, then this rank is what's usually called a non negative rank.
00:08:34.644 - 00:09:18.066, Speaker A: And we write this, I'm going to write this in my talk with a plus at the bottom. So this is the non negative rank of a matrix. And here, now we are looking at the family of PSD cones and I have analogously this PSD rank. And you see immediately that the non negative rank is always going to be bigger than the PSD rank, bigger or equal to the PSD rank, right? So why is that? Because if I have a PSD factorization. Sorry, if I have a non negative factorization, I can think of every vector that I got as a diagonal matrix, which will now be a PSD matrix. And therefore the size of my PSD factorization can only be smaller than the size of the non negative factorization. Okay, so Ben, hopefully this answer something.
00:09:18.066 - 00:09:53.156, Speaker A: Okay, so here is the general relationship between all of these three ranks that I talked about. So non negative rank, we know, cannot exceed the dimensions of the matrix, right? Because any matrix I can write as m times the identity or identity times m. So I definitely don't need more than the minimum of p or q. And as I just explained, if you have a non negative factorization, you can convert it to a PSD factorization. So clearly PSD rank is less or equal to non negative rank. So this chain of inequalities is pretty straightforward. And then this looks complicated, but this is also straightforward.
00:09:53.156 - 00:10:50.290, Speaker A: What it's saying is that if I have a PSD factorization, then just string the rows of the matrix along as a long vector and I will get a rank factorization, not a rank factorization, like a rank type factorization of size equal to PSD rank plus one, choose two. So if my PSD factorization had size k, then I would get a k plus one. Choose two dimensional factorization of my matrix with just vectors of that size. So if you rewrite that whole inequality, then you get something like this. It says that roughly the square root of rank is a lower bound on PSD rank. So as we saw in the very beginning, rank can be bigger, but the square root of rank is definitely a lower bound on PSD rank. Okay, so small cases are very easy to determine.
00:10:50.290 - 00:11:23.942, Speaker A: So if the rank of your matrix is one, then PSD rank is one and vice versa. There's nothing to think about. If the PSD rank is two, sorry, if the rank is two, then again we have the situation that PSD rank is exactly two. And this takes maybe a little bit of thought, but not so difficult to see. So rank and PSD rank definitely agree when for the values one and two. So the first place where we're going to see a difference is in rank three, like we saw in the first slide. And let me do another example where you see what happens to PSD rank for rank three matrices.
00:11:23.942 - 00:12:01.922, Speaker A: Okay? So this is again a class of a family of three by three matrices. These are circulant matrices. So I'm putting parameters ABC as a circulant into this three by three matrix. They are non negative values ABC. And in this picture, what I'm trying to draw here is how the set of a comma, b, comma c, partitions according to different PSD rank. So, for instance, when a equals b equals c, that's the only situation when rank is one. And in that case, PSD rank is one, by this fact that I had up here.
00:12:01.922 - 00:12:34.950, Speaker A: And so there's a line coming out of the origin, exactly, going up like that, where rank and PSD rank are both one. Okay? So I didn't write that. Everywhere else, when you don't have a equals b equals c, the usual rank is three. So if the usual rank is three, PSD rank can be two or three. If you look at this inequality, you will see why that's the case. So there are only two possibilities. So the PSD rank can be two or three, and PSD rank is going to be two if and only if you lie inside this pile, parabolic region, inside this quadratic region.
00:12:34.950 - 00:13:18.706, Speaker A: Okay? So there is this quadratic inequality that you can write down in a, B and C. And then inside this quadratic convex quadratic region, you will get PSD rank equal to two. And of course, there's that line, so you have to remove that. But everywhere else you will get PSD rank equal to two. So this picture is a bit misleading, because it might make you think that there is some nice region in which the PSD rank is two, and then one and then three and so on. But the picture is actually very, very complicated if you try to do this in the space of matrices in general. So in general, we can study this kind of question, right? We can look at all matrices of size p by q of rank three.
00:13:18.706 - 00:14:00.944, Speaker A: And then sitting inside it, there will be matrices of size p by q of PSD rank two. And this is going to be some complicated semi algebraic set in general, with lots of components and so on. So, this particular case of two and three is being investigated by Kaia Kubias and Elena Robiba and Richard Robinson, and they have some very nice results. Like, they can tell you what the topological boundary of the semi algebraic region is, what the algebraic boundary is, how many components it has, and so on. It's pretty crazy. It gets really complicated and out of control. But this example is nice, because it'll show up again in a more complicated way, um, and maybe simple enough to see what's happening.
00:14:00.944 - 00:14:24.094, Speaker A: Okay, so that's sort of the basic relationship between rank, PSD rank and non negative rank. So now let me introduce one more rank, which may not be very familiar. And this rank actually plays a very crucial role in this whole theory. And this is what we call the square root rank of a matrix. Okay, so this is the definition. So I still have my matrix. Nice.
00:14:24.094 - 00:14:51.692, Speaker A: Which is non negative. Now let's look at all possible Hadamard square roots of this matrix. So that means go to every entry in the matrix and you're allowed to replace that entry with plus the square root or minus the square root. Okay, so there are two to the p times q choices. So there are two to the p q Hadamard square roots for a given matrix. So I'm taking entry y square roots of my matrix m. So there are tons of them.
00:14:51.692 - 00:14:52.428, Speaker A: Sorry.
00:14:52.556 - 00:14:54.836, Speaker B: So there's no demand for symmetricity.
00:14:54.980 - 00:14:58.340, Speaker A: No, no, no. My matrix M to begin with is not symmetric.
00:14:58.492 - 00:14:59.668, Speaker B: It wasn't even square.
00:14:59.756 - 00:15:07.956, Speaker A: Yeah, it's just an arbitrary non negative matrix. Okay, so we, we look at all possible signings of the square root. That's what we're doing.
00:15:08.060 - 00:15:18.660, Speaker B: Interesting to restrict yourself throughout symmetric matrices and have AI equals bi and in the other, like symmetric things, or is it like, like.
00:15:18.812 - 00:15:22.972, Speaker A: No. Well, so if you do that kind of stuff, all sorts of complications come up.
00:15:22.988 - 00:15:24.588, Speaker B: If you simplify your life, it makes them complicated.
00:15:24.636 - 00:16:12.090, Speaker A: It makes it much harder if you require the AI's and bis to be the same, then we don't even know whether there's a finite k, whether there is a PSD cone of finite sized matrices where you can find such a fact. It gets really complicated and this has lots of applications. So we're doing sort of general non negative matrices of size p by q. Okay, so what's the square root? So we look at all possible Hadamard square roots and then look at the usual rank of each Hadamard square root, usual rank, and then take the minimum one. Okay, so that value is what we call the square root rank. And it looks a bit artificial, but you'll see immediately by the end of the slide why this plays a role in the study of PSD rank. Okay, so this is what we're saying.
00:16:12.090 - 00:16:49.034, Speaker A: For all the people who love to minimize rank, it would be really nice to understand how small this can get and so on. So you're looking at a whole cube worth of square roots. And we would like to minimize rank. How small can this get? The smallest value that the rank can take is what we're calling the square root rank. Okay, so circulant matrix again, same example as before. So as we saw before, we know exactly where PSD rank is. One, two and three so inside the parabola it's two and on the line it's one and outside the Parabola it's three.
00:16:49.034 - 00:17:23.546, Speaker A: That's what we had before, but now let's see what happens to square root rank. So square root rank is the minimum of the ranks of these Hadamard square roots. And now what happens is you get an additional surface that grows out of the parabola. It's like a flower, it's like one of these foliums. It's very beautiful. If you rotate this in mathematica and look at it, and then the result is that the square root rank is going to be less or equal to two if and only if your ABC lie on either the parabola, the quadratic surface, or on this degree six surface. This is a degree six surface that shows up.
00:17:23.546 - 00:17:48.890, Speaker A: And if you're exactly on that surface, then the square root rank is less than equal to two. And here's the line right in the center where all the ranks are one. Okay, and everywhere else is it's two. But if you're like in the open region here inside the quadratic region, but outside the flower, then square root rank is three, PSD rank is two. So it is not exactly the same.
00:17:48.962 - 00:17:51.186, Speaker B: So it's like a square root version of the determinant.
00:17:51.290 - 00:18:32.544, Speaker A: Yeah, that's right. Okay, so this is what happens to this picture. So this maybe also already gives you some idea that these ranks have complicated regions in which they stay constantly. Okay, so why is the square root rank playing a role in the notion of PSD factorization? And it's exactly because of this fact. Okay, so the square root rank of m is the minimum k such that I can find a PSD factorization of size k of my matrix with all factors having rank one. Okay, so the AI's and Bj's that we put on the rows and columns, I didn't have any restriction on their rank when I put them up there. They just have to be in the PSD cone of size k.
00:18:32.544 - 00:19:02.612, Speaker A: But now if you impose the additional restriction that all my factors have to have rank one rank, they are rank one matrices. Then immediately you will get this invariant called the square root rank. And it takes a little bit of, it's not so hard to prove that this is the case. So this is one definition and then this is exactly why this plays a role. So we immediately see that square root rank is bigger than PSD rank. Because I'm imposing additional restrictions on the factors, I'm requiring them to be rank one. So it's an upper bound.
00:19:02.612 - 00:19:56.272, Speaker A: In some cases it's a really good upper bound, and in many cases it's a really bad upper bound. So we'll see examples of different kinds, but one fact that comes out immediately, which is a little useful, is this fact. So if you take your m to be a zero one matrix, okay, then let's see what happens. So if you take it to be a zero one matrix, then one of its Hadamard square roots is itself, right? I could replace all zeros and ones with just zeros. And the same thing, one of its Hadamard square roots is itself. So the rank of this matrix, which equals the rank of this positive Hadamard square root will be smaller than the square root rank, which is the smallest I could get by changing signs. Therefore, I will get that the rank of the matrix is big or equal to square root rank and square root rank was an upper bound on this.
00:19:56.272 - 00:20:13.990, Speaker A: So I will get that PSD rank is bounded above by rank. So this is the one very special case where rank actually jumps in front of PSD rank. Usually rank can be either above or below, but bounded below by square root of rank. But in this case you have this upper bound by rank.
00:20:14.072 - 00:20:16.602, Speaker B: Generally it's very, very tiny, right?
00:20:16.698 - 00:20:32.170, Speaker A: No, it can't. You'll see it's controlled, right, because of, oh yeah, it could be, sorry. Yeah, it could be very, very tiny. So for example, for rank three matrices, the PSD rank can be arbitrarily high. And we will see what in this equivalence allows you.
00:20:32.242 - 00:20:38.134, Speaker B: I mean, I'm not sure I see a proof, but what in this equivalence allows you to pick signs as to whichever way you want?
00:20:38.874 - 00:21:31.454, Speaker A: Okay, so here's the proof. So what happens is, so let me do it with, so we're trying to put a bound on the PSD rank of m, right? So let's look at one of the square roots, any square root, okay, so now take a rank factorization of this. So this has some rank. So let's say the rank of this one is r. So this is some p by r matrix, this is an r by q matrix, no restriction on the entries of a and b. Ok, now from every row of this a, construct, this rank one matrix, and from every column of this b, construct this rank one matrix. So now when I take the inner product of these two rank one matrices, I will get exactly the inner product of AI and BJ score.
00:21:31.454 - 00:22:37.684, Speaker A: Okay? And this is exactly mij. Okay, so from a rank factorization of any Hadamard square root, you're actually producing a factorization of my original matrix with rank one factors that's too small. So it plays an important role, this square root rank. So I've introduced all the ranks I want to introduce now. So let me just put up a table that just compares all of them, okay, so there's rank, non negative rank, PSD rank and square root rank. And since in this talk we are only interested in PSD rank, let me only focus on this column, okay? So this double less than means that the difference can be arbitrarily smaller or bigger, okay? And if you have a single, and if there's only a single inequality that shows up, that means that there is a gap, but the gap is controlled, it cannot grow arbitrarily big. Okay, so for example, rank can be arbitrarily smaller than PSD rank.
00:22:37.684 - 00:23:16.094, Speaker A: We will see such examples soon. There are rank three matrices that have growing PSD rank growing to infinity. On the other hand, rank cannot be much bigger than PSD rank because of this, one of the first inequalities that I showed in the chain, non negative rank can be arbitrarily bigger than PSD rank, not just exponentially arbitrarily. Okay? And the reason, a very nice example is the euclidean distance matrices. So here we take mij to be I minus j square. That's, it's a n by n matrix where the entries entry ij is filled with I minus j squared. This has rank three that you can check.
00:23:16.094 - 00:24:02.462, Speaker A: It has PSD rank two because it's an entry y square, right? So since it's a harder mark square of the matrix with entry I minus j, its PSD rank is bounded above by the rank of its square root, which is the matrix with entry I minus j that has rank two. So PSD rank is two. And then there is this nice result that says that the PSD, the non negative rank is log n. Roughly, it's easy to see it's at least log n. And then it was a result of pavel rubic that it is exactly log n. It's theta log n. Okay, so this non negative rank grows to infinity, but PSD rank remains constant at two, no matter what size this matrix has, and the size of the matrix can grow arbitrarily.
00:24:02.638 - 00:24:13.376, Speaker B: If I just consider uncontrolled things, then basically there ordering is rank is the smallest, then PSD rank, and then square root, rank and rank non negative or incomparable.
00:24:13.560 - 00:24:47.858, Speaker A: Yeah, so that's true. Rank can be bigger, but not so much. Yeah, exactly, exactly. Yeah. So this example kind of shows you that in general, you cannot assume that all the factors have rank one. If you want to study PSD rank, if you put a bound, a lower bound on square root rank, it may sometimes have no connection to the PSD rank, like this example. But on all the cases we actually care about later with polytopes and so on, we don't have such an example where the square root rank and the PSD rank are arbitrarily far apart.
00:24:47.858 - 00:25:22.528, Speaker A: But for arbitrary matrices, the entire table can be filled. And we have examples of all possible scenarios in the survey if you want to, if you're interested. Okay, so this is what happens to all of these ranks. So now let me come to kind of the motivation for why we introduced this rank and wanted to study this. So it's a geometric interpretation and it's related to these extended formulations and lifts and so on that you may have seen already. But let me say everything from the beginning. So what? So let's start with a convex set that I'm going to call p.
00:25:22.528 - 00:25:52.770, Speaker A: It lives in rn. So we say that it has a PSD lift of size k. If I can write p as the projection. So PI stands for projection of the intersection of the PSD cone of size k with an affine space. So this sk plus intersect l is the spectrahedron that we saw in bandstock. It's a slice of the PSD cone. So I'm saying that P has a PSD lift of size k if there is a projection of that slice that exactly matches p.
00:25:52.770 - 00:26:22.082, Speaker A: So PI is a linear map and l is an affine space. So here's a picture. This is the elliptope, the whatever, the samosa, the elliptope from the morning it projects down to a square. So this is a PSD lift of the square of size three. This is a slice of the three by three PSD cone. Okay, so that's the definition of a PSD lift. Now how can we sort of relate this to PSD rank? So for that we need to introduce the notion of a slack matrix.
00:26:22.082 - 00:27:07.776, Speaker A: So here's a general definition. So if I have a polytope p sitting inside a polyhedron q, then let's assume that we are given a p by its vertex description. So p is the convex hull of p one through pv, and q is given by its inequality description. So it's a j transpose x less equal to bj. Okay, so let's assume there are v vertices in p and f facets in q. You can assume everything is a facet. Then the slack matrix of this pair pq is a v by f matrix, so it has vertices indexing the rows facets, indexing the columns such that if you look at the ij entry, then you're just exactly recording the slack of the ith vertex in the jth facet.
00:27:07.776 - 00:27:38.942, Speaker A: So that means you're plugging in the ith vertex PI in to this position here and calculating how far is beta j from this value. So it's beta j minus aj transpose PI. Okay, so this is the slack matrix of a pair of polyhedra. One is a polytope, the other one is a polyhedron. And I get this v by f matrix. Okay, now this may look very specialized, but every non negative matrix is the slack matrix of a p sitting inside a queue. Okay, so this is not a special construction.
00:27:38.942 - 00:28:22.426, Speaker A: So anytime you give me a slack matrix, a non negative matrix, I can write it as I can rank factorize it. So I can write this as a times b, where again there is no restriction on what's inside a and b. And from this a I will get a p, and from this b I will get a q such that when you look at the slack matrix of the pair, this is exactly the order original matrix m. Okay, so this is not a special construction in that sense. So every non negative matrix is a slack matrix of this type. Okay, so then we have, then there is this theorem that relates PSD rank to PSD lives. Okay, so let me give you the theorem in two parts.
00:28:22.426 - 00:28:55.956, Speaker A: So the first part is a little bit is the general version. So it says that the PSD rank of the slack matrix coming from p and q is exactly the minimum k such that I can put a projected spectrahedron between p and q. Okay, so a projected spectrahedron coming from the k by KpsD cone in the middle of p and q. So I should be able to nest it. Okay, so that's what it is. So if I have any matrix. So remember, this can be any non negative matrix I can construct from it.
00:28:55.956 - 00:29:35.484, Speaker A: This p and q, its PSD rank is exactly the size of the k such that there is a projected spectrahedron nested between the p and the q. Now the case that's been studied a lot is this case where p and q are the same. So you're taking the vertex description of p and the facet description of the same p, they're the same. Then the slack matrix is, is what's usually called the slack matrix of a polytope. And in that case the PSD rank is the minimum k such that p has a PSD lift of size k. Okay, so this is theorem. And remember this is for any convex set.
00:29:35.484 - 00:29:44.416, Speaker A: This is not special. And the history of this theorem is like this. So the second statement where p equals.
00:29:44.480 - 00:29:51.100, Speaker B: Q, that this is well defined, right? Because actually these ranks are defined from matrices.
00:29:51.252 - 00:29:51.868, Speaker A: Yeah.
00:29:51.996 - 00:29:58.804, Speaker B: Matrix doesn't uniquely define p and q. I mean, this includes the implicit statement.
00:29:58.884 - 00:30:37.788, Speaker A: That's right. That they are all the same up to some. Yeah, that's right. But yes. Okay, so what's the history here? So this last statement here was proved for the case where pull p is a polytope and these lifts are polyhedral lifts and PSD rank is replaced by non negative rank by Yanakakis in 91. Okay, so we just call these sort of general Yanakakis theorems. So this, so that was the special case where he said non negative rank of the slack matrix is the minimum k such that I can write p as the projection of a polyhedron coming from a slice of the non negative order.
00:30:37.788 - 00:31:13.920, Speaker A: Okay, so that's the case Yanukak has proved. And then what we did was to generalize this to the case where p is an arbitrary convex set. So p is that, and we replace the positive, these PSD cones with arbitrary cone families. And then instead of PSD rank, you have to take these cone ranks. But if you have convex sets, they're not really matrices that you have to take ranks off but operate that come from these convex sets. But for the most part, we'll just only talk about polytopes. So you can just think about the slack matrices as the only things we will care about.
00:31:13.920 - 00:31:15.696, Speaker A: They're never going to be operators.
00:31:15.840 - 00:31:21.392, Speaker B: PSD rank may not be a finite number in this case for a slack matrix because p can be a circle.
00:31:21.448 - 00:31:40.754, Speaker A: And then the, that's right. So the, so the non negative rank of a circle is infinite. Right. I can never write the circle as the projection of a polyhedron. Right? So there are situations where that can happen and. Yeah, that's true. Okay, so this, the first statement is sort of a generalization of the second statement.
00:31:40.754 - 00:32:09.394, Speaker A: This is in various versions in different papers. The non negative version is in the thesis of Kostya Pashkovich, the PSD version, it's kind of folklore once you see the second statement. The first one is pretty straightforward. Okay, so that's sort of the connection between PSD rank and PSD lifts. So if you want to know the size of the smallest PSD lift, you have to know the PSD rank of the slack matrix. That's the message. Okay, all right.
00:32:09.394 - 00:32:44.874, Speaker A: Now slack matrices of polytopes are not general. They do have a lot of special structure. They have been characterized, but I don't think we fully figured out how to use that characterization. Okay, so they do have a full description by now, but that's where we are. Okay, so let's see some examples. So here's the elluptop projecting to the square again. So the polytope is minus one to the one square, and this is the description of the elliptope projecting.
00:32:44.874 - 00:33:07.538, Speaker A: So this is the elliptope. And then we have to project that down onto the Xy coordinates. The slack matrix that we get from the square is this one. There are four vertices, four facets. And then if you calculate the distance of each vertex from each facet, it's either zero or one, right. Either the vertex is on the facet or distance one from the facet. So they're filled with zeros and ones.
00:33:07.538 - 00:33:37.538, Speaker A: And the PSD rank of this matrix is three. This tells you that this lift that we constructed here is the minimum possible. You cannot write the square as the projection of a two by two PSD cone sliced with anything. So three is the smallest size of a PSD cone into which you can lift the square. Okay, so that's an example where p equals q. Now let's change it slightly. So now let's make, take p and q to be different.
00:33:37.538 - 00:34:09.104, Speaker A: So now I'm taking q to be the same square. It's minus one, one square. But I'm going to shrink my p with a parameter. So I'm going to take a smaller square inside that the outer square. And the sides of this inner square is controlled by a and b. It's a rectangle. Okay, and now remember what is, so if you calculate slack matrix, you get this big stuff, okay, so here are the vertices of the inner square, here are the facets of the outer square square, and we have to calculate the slack of every vertex in every facet.
00:34:09.104 - 00:34:43.972, Speaker A: You get this matrix. Okay, now if you want to calculate the PSD rank of this matrix, it's going to depend on a and b. So remember what you have to do is you have to be able to sandwich this projected spectra, hedron in the middle, and as long as you can do this for and depending on when you, so you go through your different cones and at some point you cannot do it with the PSD cone of size one, then PSD cone of size two and so on. So in this example it'll jump like this. So PSD rank is one. Exactly. If a equals b equals zero, that means the inner polytope is just a point.
00:34:43.972 - 00:35:12.806, Speaker A: And then as you grow your a and b parameters like this, PSD rank will be two. If a squared plus B squared is between zero and one and three. Otherwise. Okay, so there will be this. The PSD rank will move as you grow the inner square because of the sandwiching theorem that we saw. Okay, so that's, that's an example. Okay, so now let me say a little bit about what we know about PST ranks.
00:35:12.806 - 00:35:35.072, Speaker A: And we know very little. That's kind of one. We know, sorry. We know very little in some directions. We know quite a bit more in other directions. So let me start with the sort of the lower bound side of the story, which has been of great interest to lots of people, especially in computer science. So on the low bound side, we don't know much.
00:35:35.072 - 00:36:23.736, Speaker A: So one of the results that came out last year is this result of Dardush and Pakuta. They proved that if you take all zero one polytopes in rn, then not all of them can have small lifts. So small, meaning polynomial size size lift in n. So there will exist zero one polytopes in rn that are forced to have PSD lifts that are exponential in size. So how does this go? This goes by counting arguments. So what they do is they say, okay, if I have a PSD factorization, I can always assume there is one where the eigenvalues of the factors are bounded. So you can re normalize your factorization so that you put this norm bound on the factors, and then you count how many zero one polytopes are in rn, and you say, okay, there are too many.
00:36:23.736 - 00:37:03.480, Speaker A: So if there are bounds on these factorizations, there's not enough to cover all of them. So it's a counting argument that's very implicit, and it does not produce a concrete family of zero one polytopes that have this exponential sized PSD rank. So there's no concrete family known so far with large PSD rank, meaning exponential and n zero one. And a lot of people are interested in this as the potential candidate that will produce such a thing. So this is isomorphic to the cut polytope. This is the correlation polytope. It's the convex hull of all rank one matrices AA transpose, where a is a zero one vector.
00:37:03.480 - 00:37:39.210, Speaker A: Okay, so no, nothing concrete about PSD lives, general PSD lives of this polytopeat. So this is where we are in terms of lower bounds. But on the other hand, we do know PSD rank has to grow. Okay, so we do know some further things. So in the paper we wrote in the beginning, we had a result like this. So if the psd rank of a polytope is k, then p has at most k to the order k square n facets. So you cannot keep on piling up facets into your polytope and keep k small.
00:37:39.210 - 00:38:30.894, Speaker A: If you grow the facets a lot but keep the dimension the same of the polytope p, then you're forced to increase the PSD rank. So in particular, even in the plane, if you have n gons and you start increasing the n in the n gon, then you have to have the PSD rank growing to infinity. You cannot have it just be bounded. So even in the plane you can produce examples with PSD rank going to infinity as you grow the number of facets. No, these are arbitrary n gons for zero one polytopes. What we have is basically something like this that it has, there has to be zero one polytopes that need an exponential, exponential sized lift. In fact, most of them, I think, have to have an exponential sized lift.
00:38:31.194 - 00:38:32.986, Speaker B: So this is where you use elimination.
00:38:33.170 - 00:38:59.534, Speaker A: Yeah, I will come to that in a second too. Okay. And another kind of result, these are just sample results that we know is, for instance, if you take the PSD rank of a generic n gon, so that means an n gon where the vertices don't satisfy any algebraic relations, then it has to be at least fourth root of n. There are analogous non negative rank results to many of these results, which I'm not mentioning at all in this talk. So just.
00:39:01.994 - 00:39:09.014, Speaker B: If you're like a polygon in the plane, the actual rank of this is three.
00:39:09.314 - 00:39:37.994, Speaker A: It's always three. So this is a nice family where you see the gap between rank and PSD rank and go to infinity. Okay? Yeah, it's always three. It's always the. So remember, when you take any matrix and you write the p and the q from it, the, the p and the q live in space given by the intermediate dimension, which is the rank of the matrix. And so if you're, if you're just working with polygons, then the rank of the slack matrix is always three. It's always dimension plus one.
00:39:37.994 - 00:40:20.836, Speaker A: Okay, so that's that. And another thing we don't know is we don't know any family where there is an exponential gap between PSD rank and non negative rank for polytopes. So for arbitrary matrices, you can create these exponential gaps. You saw the euclidean distance matrix that had PSD rank two non negative rank log n. There are arbitrary gaps, but if you look at slack matrices of polytopes which are fairly special non negative matrices, we don't know any family that has a big gap. So in particular, we don't know, for instance, whether PSD lives are truly more powerful than LP lists in this context. Do you have a question?
00:40:20.940 - 00:40:25.164, Speaker B: We know a gap which is between n and n to the log n.
00:40:25.324 - 00:40:49.544, Speaker A: Yeah, we know some gaps like that, but we don't know really big gaps. Right. So for things like the stable set polytope of perfect graphs, we know some gap like n versus n to the log n, but we don't really know really big n to the log n is an upper bound on the non negative rank of that slack matrix that's in the Yanakakis paper. And n comes from the low bus theta construction.
00:40:49.924 - 00:40:53.596, Speaker B: We don't know that bound. I mean, that separation for sure, right?
00:40:53.660 - 00:40:54.644, Speaker A: Yeah, we don't know it for sure.
00:40:54.684 - 00:41:03.076, Speaker B: But it's, if you do look at max cut, we know that lp's of size n to the log n don't give better than half.
00:41:03.260 - 00:41:08.004, Speaker A: Right? So approximation is different. Talking about exact lists.
00:41:10.664 - 00:41:14.576, Speaker B: Still, approximation is a gap between PQ for the pQ.
00:41:14.600 - 00:42:18.598, Speaker A: Oh yeah. So in spirit, yes, it answers this kind of question, but here I'm asking for exact gaps between rank and PSD rank. Okay, now there's another kind of lifts that we can define, which are called equivariant lifts, where we know a lot more. Okay, so these are basically symmetric lifts, symmetric PSD lifts, and these are lifts that, in roughly speaking, respect the symmetries of the polytope. So if I have a polytope with a lot of symmetry, I want my lift also to capture the symmetry. So it's sort of very roughly speaking, what this is saying is that we want to construct very structured lifts such that if I have a polytope here and it's being projected from here, and there's a group acting here that keeps the polytope invariant, then if I take a point and I look at where it came from, so maybe it came from here, here's the point, and I apply the group action here. So I go here, this should be the same thing as finding another group element to act on this.
00:42:18.598 - 00:42:48.036, Speaker A: So let's call this phi of g and then projecting this down here. Okay, so somehow spinning the element, and then, I mean, sorry. Spinning upstairs and projecting should be the same as spinning downstairs and then getting the same image from before. So these are equivariant lifts. So all these lacera lifts and so on are symmetric. Okay, they're symmetric lifts. And this was also the type of lift that was studied by Yannickakis in his original paper when he showed that the matching polytope does not have a small symmetric lift.
00:42:48.036 - 00:43:40.722, Speaker A: And there are these nice, this nice result that just came out very recently that shows that the equivariant PSD rank of polytopes, like the cut polytope, for instance, is very, very big. So if you want symmetric lifts, then you do need exponential size. And this was proved sort of for slightly different definitions of equivariant lifts in these two papers. Okay, so symmetry does impose, we sort of think that symmetry does impose serious restrictions on polytopes like this. We don't know exactly yet, but these are very, very large lifts that you're forced to have if you impose symmetry. Here's another very nice result that's very recent. So this says that the equivariant PSD rank of the regular n gon is log n.
00:43:40.722 - 00:44:02.192, Speaker A: Okay, so this is, this is very nice. Whereas on the other hand, the non negative equivariant rank of the regular n gon can be all the way to n. So if n is a power of a prime number, then we knew from the first paper we wrote that this can happen. So in the world of equivariant, is.
00:44:02.208 - 00:44:03.688, Speaker B: That in the plane, the n gom?
00:44:03.736 - 00:44:06.264, Speaker A: Yeah, in the plane. In the plane, this is n non.
00:44:06.304 - 00:44:10.176, Speaker B: Negative rank without the equivariant constraint, as is log n, right.
00:44:10.280 - 00:44:26.720, Speaker A: Regular. Yeah. Is log n. Yeah. So if you have non negative, without symmetry, it's log n. That's the Bentley Nemarowski construction. And with this result is saying that if you go to PSD but require covariant.
00:44:26.720 - 00:44:35.854, Speaker A: Yeah, exactly. It doesn't cost you much. You still get log n, the true PSD rank. We don't know. We think it's maybe square root log. Nice. We don't know.
00:44:35.854 - 00:45:07.658, Speaker A: But this, in the, so just in the family of n gons, you see that there can be exponential gap between PSD lifts and non negative lifts if you look at equivariant lifts. Okay, so for equivariant things, the answer, the question I asked before is answered. The electrope is symmetric. Yes. Yeah. Okay, so, um. All right, so let me say a couple more things.
00:45:07.658 - 00:45:56.860, Speaker A: I'm almost out of time. So what do we know about lower bounds in general? So first thing you can see immediately is that the zero one structure or the, sorry, the zero pattern of the matrix is not useful to study PSD rank. This has been very useful for non negative rank. But the reason it's not useful for PSD rank is just that we saw that if you take the PSD rank of the Hadamard square, it's bounded above by the rank. So if I take a matrix with a certain zero pattern and I square it, it still has the same zero pattern, but now suddenly its PSD rank is bounded above by the rank of the matrix, right? So I can never do better than rank. This was further studied by these troy Lee and dirk ties. And then Barbie Nog has a result that also says that it doesn't help too much to look at how many distinct entries you have in your matrix.
00:45:56.860 - 00:46:30.720, Speaker A: So if you have k distinct entries in your matrix, then PSD rank is essentially a polynomial in rank. Okay, so these things have been very useful to study non negative rank, but they're not very useful to study PSD rank. So that's one message. And in general, we have this sort of lower bounding technique, sort of a meta principle, using two results of Jim. And so I would just say that here, and maybe we can improve this program using the methods that Ben mentioned this morning. But here's the program. So if you want to generally look for lower bounds like this n.
00:46:30.720 - 00:47:22.238, Speaker A: Gon result that I mentioned at the beginning, then what you can do is you can say, okay, I want to project something, a spectrahedron down onto a polytope. So let's put a bound on the polynomials that I need to write the spectrahedron. And Jim Ranagar has a nice result that says you don't need polynomials of degree more than k if you have a spectrahedron in the PSD cone of size k. And then what we do is we use his quantify elimination methods to say, okay, if I know the degree of the polynomials up here, by quantify elimination, I know something about the degree of the polynomials down here. In fact, I know them an upper bound on them. And then we use the fact that, well, if I know the degree of this entire boundary, then every facet, the product of the number of facets that you see here, has to be smaller than that degree. And from that we get a bound.
00:47:22.238 - 00:47:42.594, Speaker A: The trouble with it is that it's very hard to actually get any kind of control on the constants and so on. So it's not really easy to study the growth of PSD rank with this method. But you will get results like the n gon has to grow in PSD rank in the plane. Okay, so should I just stop?
00:47:43.774 - 00:47:48.918, Speaker B: I think we've been doing this for everybody. Okay, maybe if you can drop up in three or four minutes.
00:47:48.966 - 00:48:33.186, Speaker A: Three or four minutes. Okay, just, I can stop whenever. Okay, so now let me tell you some of the positive results we know. Okay, so this is a completely orthogonal direction, which I think is also very interesting. So people have been very much focused on studying, showing negative results about PSG rank. PSG rank is very big for whatever type of polytope you want to look at. But on the other hand, you can ask, when is this lift really, really good for which polytopes can we expect the smallest PSD lifts? And in this case, we have one theorem that comes in the that's fairly easy to prove that if you take a polynomial, then the PSD rank is actually bounded below by rank.
00:48:33.186 - 00:49:25.632, Speaker A: Okay? So as I said before, for general matrices, this is not true. Rank can be above or below the PSD rank. But if you take polytopes and their slack matrices, then the PSD rank can never go below n plus one, which is the rank of the slack matrix. Okay? So there's a hard lower bound, and then we can ask when do you get equality? So the best you can do is if you have an n dimensional polytope, you can lift it into the pSD cone of size n plus one. So when can you exactly do that? And you can do that exactly when the square root rank is also n plus one. Okay, so this is a theorem, and of course, to check this is hard, right, because I need to look over all signings of my square roots and then figure out what's the minimum and argue that that's n plus one. So we're not claiming anything about the complexity, but this is the structural theorem, and it's kind of interesting to see how this works.
00:49:25.632 - 00:50:02.330, Speaker A: So in the plane, it's very easy to see that the only PSD minimal polytopes in this sense are triangles and quadrilaterals. In r three, it's a little bit more complicated. So in R cubed, this is the complete list of polytopes that have PSD rank four, which is the minimum possible dimension. Plus one is the minimum possible, and the first three types, prisms, quadrilateral pyramids and simplices, there's no restriction. Anything with that common hut oral type is okay. But when you come to octahedral, there is a restriction on how they are situated. So the geometry actually plays a role.
00:50:02.330 - 00:50:43.614, Speaker A: And we need something called biplane octahedra which I can tell you later if you like. And another very nice feature about PSD rank is its invariant under polarity. So unlike laser rank and all these other things which do not tell you anything about the lasser rank of the polar, the PSD rank is invariant under polarity. So it's very pretty and you get all the polars will also work. Here's maybe a familiar example. So there is the Lobas theorem from a long time ago that says that if you have a perfect graph, then it has a PSD lift of size n plus one, which is the lowest theta body. And in fact that result is much stronger.
00:50:43.614 - 00:51:17.390, Speaker A: The only graphs for which PSD rank is n plus one are the perfect graphs and vice versa. And there is also some new results by Sunyal and Grande on characterizing matriarch polytopes of minimal PSD rank. Okay, so let me see what's coming. Okay, maybe I'll stop after this. Okay, so one corollary of this study of minimality is this result. So using one of these minimal polytopes, it was possible to show that PSD rank actually depends on the field. Okay.
00:51:17.390 - 00:51:48.374, Speaker A: So if you look at PSD rank over the rational numbers, it can be strictly, oh, I got it wrong. It can be strictly bigger than the PSD rank of the reorganization over the real numbers. And this is something that came out of all the discussions we had in our survey. And there's a nice paper by Hamza, Joao and Richard, and this question is open for non negative rank. We do not know if non negative rank depends on the field, so maybe this is a good place to stop. And.
00:51:58.764 - 00:52:22.804, Speaker B: So it seems like the slickest proofs for a lot of these relatively recent non negative rank bounds come out of reformulating things in terms of information theory and then doing some direct, some kinds of arguments. Obviously, when you have a very nicely structured polytope, is there, the definition is pretty different. Is there any hope of doing something similar for pounds on, you know, polytopes arising from CS problems?
00:52:23.104 - 00:52:57.244, Speaker A: Yeah. So here's everything I didn't speak about, including the previous slides. So one of the things is there is a quantum information interpretation of PSD rank. And this has been the focus of people like Troy Lee and Ronald DeWolf. And also they're trying to use information theoretic methods to put lower bounds on PSD rank. But it's not anywhere near well developed, as we have for non negative rank. For non negative rank, it has been helpful to show so results of Angkor and so on, that it can give you lower bounds.
00:52:57.244 - 00:53:31.648, Speaker A: But here we don't quite have that machinery yet, and maybe I should. I will leave the so this is, this was my special slide for ankur, so I want to put it off at the end at least. So, complexity issues, if I can take 1 second. We know very little. So square root rank is Np hard to compute, and this is a very simple example that shows it. So this is a matrix with the identity over here, and these are squares of some numbers. And this has psd rank n or n plus one, because the identity already has rank n psd rank n.
00:53:31.648 - 00:54:09.366, Speaker A: So it could either stay at n or go to n plus one, and it'll have psd rank n if and only if the partition problem is true. If you can partition a one through a n. So this reduces to partition Pse rank. In general, is it Np hard to compute? We think yes, but we don't know. There's analogous results by vavasis using sandwiching simplices between polytopes and so on. Is there a very simple proof like this of abbasis result? That would be very nice, if possible. And similarly, if you fix K and ask is PSD rank at most K.
00:54:09.366 - 00:54:37.834, Speaker A: This was shown to be polynomial time, doable by Aurora et al. And then improved by Angkor. And this is also not so easy to see for PSD rank, because in Angkor's result, he very much uses the fact that the algebraic degree of linear programming is one that we know that the optima of linear programs are on vertices. You can write them down with Cramer's rule, they are given by rational numbers. For PSD, we don't. For SDP, we don't know anything like this. We don't know what I mean.
00:54:37.834 - 00:54:53.454, Speaker A: The algebraic degree can be very, very high, as Ben said in the morning, so we can't immediately translate any of these results. But it could be that you have other techniques or other ideas to prove complexity of these ranks.
00:54:56.894 - 00:55:06.142, Speaker B: So rank, positive rank and square root rank extends immediately to tensors, but it seems that PST rank doesn't extend to tensor.
00:55:06.278 - 00:55:19.194, Speaker A: Is that a flaw? In some sense it's nicer than tensor rank, because it's lower semi continuous, lower semi continuous, and so on. But yeah, and it does share this field dependence issue.
00:55:21.114 - 00:55:28.054, Speaker B: You'Re willing to accept. Positive. So my definite majors, positive so my definite tensor.
00:55:31.074 - 00:55:31.506, Speaker A: Good.
00:55:31.570 - 00:55:32.274, Speaker B: Let's think. Rica.

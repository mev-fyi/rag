00:00:02.160 - 00:00:43.044, Speaker A: Hi all, and thank you for watching this talk. So I'm going to talk about improved monotonicity testers via hypercube embeddings. This is joint work with Mark Bavarman, Subhash Kott and guy kindlier. So let's get going. So we're going to start with describing the Montoni city testing problem, and we're going to start with the most classical domain it has been studied on, which is the uniform hypercube. So what is the hypercube? Well, you look at the set of vectors zero one to the n. This is going to be your domain, and you equip it with a partial order.
00:00:43.044 - 00:01:38.484, Speaker A: So in that partial order, x is less or equal to y if and only if xi is less or equal to y I for all coordinates I. And once you have a partial order, you can define monotonousity testing in Hoi. So a function on the habf is called monoton if, whenever x is less or equal to y, it holds that f of x is less or equal to f of y. In other words, f has to respect the partial order on zero one to the n. And once you have the partial order and monotonicity, you can define the monotonicity testing problem. So in this problem, you are given an oracle access to a function f to a Boolean function on the hydro cube. And this function is promised either to be monotonous, or else it's promised to be far from monotonous.
00:01:38.484 - 00:03:00.000, Speaker A: And the measure of distance here is the normalized hemic distance, meaning the distance between f and monoton is you take the minimum of all function g, which are monotonous. You count the number of inputs x on which f and g differ on, and you divide it by the total number of points on the hypercube, which is two to the n. So if this fraction is at least epsilon, then we say that f is at least epsilon for one. And for this talk you should think of epsilon as a small constant. You can do anything with dependency in epsilon, but it's a bit annoying, so we don't want to do it. And the question is, how many oracle access queries do you need to make to f in order to distinguish between these two cases? That is, you want to design an algorithm that makes as few query access as possible to f, and accepts with probability one if f is monotonous, whereas it rejects with probability close to one if f is epsilon. Far from so monotonic testing has been around for a while, in fact, for over 20 years.
00:03:00.000 - 00:03:46.524, Speaker A: It was first introduced in a paper by Goyler, who also gave an often query tester for the problem. And this tester is a very natural and very nice one. It's called the edge tester, and in that you just pick two points, x and y, that differ on exactly one coordinate chosen randomly, you query the value of f on these two points and you reject if these two values violate monotonicity. So it's a very natural tester. And the analysis of golfel is very, very nice. But this is the best you can do if you only consider f testers. And it took a while to improve upon this tester.
00:03:46.524 - 00:04:27.668, Speaker A: In fact, over ten years until Czecho Bartin's salary showed different tester, which achieves query complexity, n to the seven over eight. So the tester is different. The tester is what is called path tester. So again, it's some base tester that only does two queries, which is then repeated numerous times. In the base tester just takes two points, x and y. In this case, they are not different on only one quadrant, but rather they are different on several coordinates between one root and many. So they already had to come up with a new test.
00:04:27.668 - 00:05:26.374, Speaker A: But the real interesting thing in this work is the analysis of the test alone. So dynamic of the tester relies on a very interesting directed version of isochromatic inequality due to mogulis, which they had to prove and then used in order to analyze this path tester that I just mentioned. And following their work, the analysis of the test was improved by genital to enter the 506. So really the tester and the analysis at heart are the same. They still use no bully system or ethical inequality. And in fact, this is the best you can do, as long as you're only using more gullies type directed versions of isopropyl matric inequalities. And a few years after that, together with code and software, we managed to improve upon this result and got authentication tester.
00:05:26.374 - 00:06:55.454, Speaker A: So this tester was again a path tester, very similar to the one by Czech Robart in Seshabari. And the real difference, the real difference here between this work and previous works is that we use a different isopropic inequality. In particular, in that work we proved a directed version of an isopromic inequality due to telegram, which is stronger than the variant by Marburis, and we used it to design a tester and analyze it. And because root n is the best you can do, at least as far as non adaptive testers are concerned, due to work by Fischer et al. This finishes the discussion about monotonicity testing over the hypercube, because the complexity is exactly tth, maybe up to point loads. So what I'm going to talk about today is how about monogamy testing over other domains? So what do we mean by other domains? Well, you can consider any partial yodel set and study the monotonicity testing problem over it. But I would like to argue that to get interesting results, you need a little bit more structure, because partially order set can be very wide and it's not clear what you can even say about them.
00:06:55.454 - 00:07:41.494, Speaker A: So in this work, we consider what is called product domains, which is you have some basic domain, some basic probability space, m. So we should think of m is constant. The case of the Hab cube is just m equals to. But you should think of m as like ten or 20 or something like that. And mu is some probability distribution over m. And you should think of m as being equipped with the ordering, which is natural, zero less than one, less than two, less, and so on and so forth. And once you have this, you can tensurize this space in order to get m to the n equipped with the product measure, mu to the mirror, and then you can discuss monotonous testing over this product domain.
00:07:41.494 - 00:08:18.694, Speaker A: So you have the partial ordering induced by the passive partial ordering. You have the notion of monotonicity. And the only thing that you need to define is the notion of distance for monicity. And this is defined on the slide. So the distance between f and mon with respect to a measure mu is the minimum of all the monoton function g of the measure, of the set of points x, on which f and g differ on. So usually you should think of Mu is uniform, but it's not always going to be the case. And I'm going to mention when it is not going to be the case.
00:08:18.694 - 00:09:03.824, Speaker A: So, once you look at this problem, and especially if you are familiar somewhat with the testers for the hypercube, some testers immediately spring to mind when you look at this domain, which is called the hyperblader. So there are clear analogues of the edge tester, of gold or et al. As well of the path testers. But the slightly annoying thing is that it's not clear how to analyze them. So what? It is clear that these are supposed to be right testers. The analysis that we had for the hypercube does not generalize. At least we don't know how to generalize it very easily to the hyperbarigo.
00:09:03.824 - 00:10:10.064, Speaker A: So that's an, there is an exception of the port of golden tal, which is kind of easy to generalize to the hypergaid. And therefore we did know of an hoy complexity tester that followed approach of Goldar hetal. But up until 2018 this is the best that was known. So that was the case until a few years ago where black Chakrabart instant shadowy showed that you can improve upon the goal of resources again. And indeed there is an n to the 506 poly complexity testers for testing monotonicity over the uniform hyperbaric. And interestingly, what they managed to do in this work is they did manage to generalize some of the directed isopromatic inequalities from the cube to the hypoglycem. And more specifically they managed to generalize the Margolis type isopropyramatic inequality due to Chakrabartian chadri and then converted it into a tester in the same way.
00:10:10.064 - 00:10:48.148, Speaker A: So the real novelty here is that they managed to prove the isobarmatic inequality over the hybrid. And this is ready non trivial. So it's not like the same proof, but you need to do some other things. And probably what you expect me to say now is in this work we managed to improve this result to square root of m. And to do that we just generalize the Talagan style isopomy in qualities. But I would like to say that. But the issue is that I don't know how to generalize the proof.
00:10:48.148 - 00:11:42.754, Speaker A: And sort of the issue is that the proof that we had for the Boolean cube was very specific to the Boolean cube. So in that proof we have to define some operators that have no clear analogs for the hyper derivative. And therefore the proof seemed to be very telluride to the cube. So I'm not going to say that, but nevertheless, I'm going to tell you that in this work we do manage to get off Spotify quite complexity testers for the uniform hyper grid. And in fact you can do any product measure as you like. And as a byproduct, we also get directed version of inoplimetic inequalities in the style of Telugu. What is very different from the previous approaches is that the proof.
00:11:42.754 - 00:12:47.874, Speaker A: So we are not trying to generalize some facts about the Boolean hypercube and instead we take a different route. What we do in this work is we manage to do a reduction between testing monotonicity over hypergrid to testing monotonicity over the hypercube. Namely, the main goal in our work is we're given a function f over the hypergrade and we wish to construct a function g over a slightly larger hypercube of dimensional py. And we want the following properties. We want that equal access for g can be simulated by query access to f. Secondly, we want this transformation to preserve distance from monotonicity. In particular, if f is monotonous, we want g to be monotonous, and if f is far from monotonous, then we want g to be also star for monotonous.
00:12:47.874 - 00:14:04.428, Speaker A: And lastly, we want the dimension n prime of the g function to be not too much louder than the dimension of fucking. And in particular it would like to be n maybe times some polylocks of n. And if indeed you managed to find such construction of g that satisfies all of these properties, you can simulate the monotonicity test of 4G using core access four f, and you can show that this will test monotonicity four f, and the coil complexity would be root of and prime, which is the same order of the root of n, because we want the dimension to be roughly the same. So this is the approach that we try to take this work. And of course, now the question is, how do you do this reduction? So in the rest of the talk, I'm going to illustrate how you do it for the case of the p value cube, which is again something on the hypercube, but with a different measure. And then I'm going to say a few words on how you do it for the hypergride. So to illustrate the idea, we are going to take a very concrete cube.
00:14:04.428 - 00:14:53.344, Speaker A: We're going to consider the quarter bias cube. So here again we have zero one, but now we have a different measure on it. We have the measure mu quarter, which assigns one probability quarter and zero probability three four. And what we want to do is we want to reduce testing monotonicity over such measures to that over uniform rates. And when you look at this, especially the number quarter, the natural idea that comes to mind is the following. So if I take two uniform base x one and x two, and I take a product of them, then I would get a bit which has bias quota. So let's try to use this fact in order to define our function g.
00:14:53.344 - 00:15:43.734, Speaker A: So indeed, we're going to define a function g which has a dimension which is double that of f. And when it gets input x one to x two n, it's going to compute the powerwise products x one, x two, x three, x four, and so on and so forth. Get an n vector string and plug in it to f. So this is going to be our construction of g that attempts to simulate a quarter by uniform beats. And indeed, you can show that if you want to answer query queries to g, you can simulate it by queries to fix. This is clear just by definition. And secondly, it's also clear that if f is monoton, then g is monoton also.
00:15:43.734 - 00:16:37.284, Speaker A: And what seems like it should be the case, but it's not completely clear, is what happens if f is far from. In that case, we would like to say that g is far from. And you know, this makes a lot of sense. Like all of the simulation here seems to be the correct way, and it seems true, but how do you show it? And the issue here is that we don't have many tools to show that something is far from monotonous. So let's try to do it nevertheless. So we have this function g that we defined on the previous ladder, and we want to show that if f is far from, then g is far from monotonous. Well, equivalently, it means that we want to show that if G is close to Monoton, then f is close to monotonous.
00:16:37.284 - 00:17:17.664, Speaker A: So so far we didn't do anything. This is logically equivalent. But now we have an assumption. We have an assumption that G is close to monoton, meaning there is some function h which is monoton on dimension two, n, which is close to d. And our goal in life is to show that f is close to monotonous. And it only makes sense that we're going to do it by constructing explicitly a function h prime on dimensional, which is monoton and close to f. And really all that we have in order to construct H prime is this little h above.
00:17:17.664 - 00:18:17.344, Speaker A: So how are we going to use it? Well, we want to define H prime of 40, where y is some input from zero one to the n, and we only have h in our hand. So the only real thing that we can do is generate from y some input x of dimension two n to h, and then define h to be h of x. So, you know, to go from f 2g, we apply this map that sends x one x two to the point of curve x one x two. And now in some sense we want to go the other way. So it makes sense that if you have this y and you want to generate x, you should use the pullback according to this. So what do I mean? Well, if Y one is equal to one, then you really have no choice. You must take x x to the coordinates corresponding to Y one to be one one.
00:18:17.344 - 00:19:08.806, Speaker A: But what if Y one is equal to zero? So in that case, there are three options, 1001 and zero zero. And it's not clear which one of them to pick. So pick one of them uniformly random to be more precise. What you're going to do is for each coordinate I, you're going to pick Vi, which is either 001001 independently of, of the rest of the coordinates. And this is going to be the pullback of zero on that coordinate. And once you have made this choice for each coordinate, you can define the pullback map corresponding to these choices, which pulls one back to and pulls zero back to vi. And once you have that, you have this association from y to x.
00:19:08.806 - 00:19:59.490, Speaker A: You can define the function h prime as a borrower. And if you carry out a simple calculation, you can show that in expectation over the choice of the pullback, the distance between h prime and f is the same as the distance between h and g, which is Mos delta. And you can also observe that h prime is always monotonous. So therefore it means that f is delta plus two monoton and worldwide. So this indeed shows that you can reduce photobias to unbiased cube. And in a similar way, you can actually do any p bias cube for p, which is power of two. And once you have that and use some other elementary manipulations, you can actually get any p bias that you would like.
00:19:59.490 - 00:21:02.594, Speaker A: And the coil complexity is still of any. But this idea, as I presented it, seems very specific to burn Cuba. And it's not clear what to do about larger alphabets. So to see what to do about larger alphabets, you have to sort of, you know, take a step back and see what was really happening in this argument and what made it work. And really the point of this argument is that we had a two way, where the one way to go from zero one squared to mu by taking the product operation. And then we also had this pullback operation that goes from y to one of the X X one, X two that made that product into one. And this maps had to satisfy mysteriously several properties, so they preserve measures and all of that.
00:21:02.594 - 00:21:46.194, Speaker A: But additionally there to be monotone. This is really the property that we used in the proof. So for the product and map, it is clear that if you take x one, x two and map it to x one x two, this is monotonous. And for the pullback it's also clear, but it's a bit hidden under the surface. So for every choice of Vi that you made, the pullback operation that you get is also more open. So with this in mind, can you construct embeddings for the hypoglyb, maybe through geranium. And once you think about it this way, there is a very natural attempt that you may do, which is called threshold embedding.
00:21:46.194 - 00:22:40.462, Speaker A: So here you are going to attempt to partition zero one to del into three parts according to the hamming blade, and try to make it as equal as possible. And indeed, if you think about it for a little bit and use some estimates, you can show that indeed you can partition the cube into three roughly equal parts and use these specials as on the slider and this monotone, and you have a pullback. And all of this is very good. The only issue is that it's not actually possible to make different threshold function, partition the cube into three equal parts. And in fact, it will always be the case that one of the parts will be at least somewhat off. So trivially, you can achieve one over root arm. And if you work a little bit harder, you may improve that a little bit.
00:22:40.462 - 00:24:12.448, Speaker A: But this cannot give us like exponentially our distance from uniform. And when you think about that, this means that the hour that you're going to take is going to be large, which is going to lead to a blow up in the dimension which we don't want, because it affects our quiet complexity. So nevertheless, and this is where most of the heavy lifting in the paper is, we show that you can take this roughly, this construction and slightly shuffle it and do stuff to it in order to balance it out so that it partitions the cube into three roughly equal parts in a way that preserves monotonicity as well as the pullback of the properties that we need. And to prove that, we use a notion which is called monoton matchings, which is, you know, matchings that are only taking monoton edges or monoton pairs on the hypercube. And this is where most of the work goes in. And formally speaking, what we really have to call is that you can partition the hypercube into three roughly equal parts, as equal as they can be, because, you know, three is an odd number, so that between any two parts there is a perfect monotone matching. And in fact, you can do it for any number of parts, any constant number of parts.
00:24:12.448 - 00:25:03.724, Speaker A: There is nothing special about three. And this is how we construct embeddings for the haplogroup. So this is how we prove our results. And in a concurrent work, black Chakrabani sadly managed to prove the same result about the hypodride on the uniform measure. So the tester is really the same, but the analysis is completely different. So they follow the same framework as in the hypercube, except that in their work they managed to directly generalize the talagan style is a problematic inequalities for the cube and then use it to construct the test. But you know, this takes some serious effort and indeed they do some non trivial work.
00:25:03.724 - 00:26:06.314, Speaker A: So this seems like it finishes off these two works, finish off the monotonicity testing problem over the hypergridon, except that, well, if you really want to completely finish it, there is one more case that you have to consider, which is what is the dependency on the Alphabet cells. So both our work and this work of blackjack about in shadow, you get polynomial dependency on the Alphabet size m, and some other works that say that you only need to consider m, which is polynomial size. In fact, you can do dimensions. So it would be interesting to know if the polynomial dependency on n is necessary, or maybe it can be improved. And for all we know you can do with logarithmic dependency on n. But these two works fail to get it. And another interesting question is whether there are some other domains in which it would be interesting beside the monetary testing.
00:26:06.314 - 00:26:21.614, Speaker A: So to make it interesting, it would have to be something which is not product domain, but some interesting measure with enough structure. You know, maybe something from statistical physics, maybe dyzing model, who knows? So that's all. Thanks.

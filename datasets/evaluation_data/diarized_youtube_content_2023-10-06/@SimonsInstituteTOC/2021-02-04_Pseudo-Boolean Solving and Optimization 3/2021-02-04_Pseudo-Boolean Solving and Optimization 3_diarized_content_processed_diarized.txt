00:00:06.200 - 00:01:06.764, Speaker A: Welcome to this tutorial on pseudoboolean solving and optimization, which is part of the bootcamp for the satisfiability theory practice and beyond program at the Simons Institute for the Theory of Computing. So we have reached part three of this prerecorded tutorial. In part one, we learned what sudo Boolean constraints and pseudo Boolean formulas are. Sudo Boolean formulas are collections of zero one integer linear inequalities. In pseudo Boolean solving. You want to determine whether such a collection of inequalities is satisfiable, is feasible or not. We saw that we could use the ideas of conflict driven search in CDCL solvers to solve this problem, either by taking the pseudo boolean formulas and rewriting them to conjunctive normal form, so that we can feed them to a CDCL solver directly or in the other direction.
00:01:06.764 - 00:02:18.492, Speaker A: We can take the conflict driven paradigm and try to lift it from CDCL to native pseudo Boolean reasoning, where we do propagation and conflict analysis not on disjunctive clauses, but on general zero one integer linear inequalities. And if you survived till the end of part two, which was a fairly long video chunk, then you saw that there are different ways of doing this. There are lots of degrees of freedom, lots of questions that have not been fully explored compared to CDCL. And so I'd say there are lots of good open research problems there. And this is even more so when now here in part three, we consider the setting where in addition to the pseudoboolean formula, you also have a linear objective function that you want to minimize. So this is what we want to talk about now. And this topic is connected to Max Sat solving.
00:02:18.492 - 00:03:17.214, Speaker A: And many of the ideas for pseudo boolean optimization come from Max sat solving and have been most fully developed there. So we'll talk about Max sat solving, and then we'll talk about the ideas for how to solve Max sat problems and general suitable optimization problems using linear search or core guided search or implicit hitting set approaches or combinations them. So, as I already said, sudo Boolean optimization and max sat solving are closely related. In order to make this precise, let us first define what max sat is. Let's define the fully general weighted partial maxat problem. So this is where we have a CNF formula as input, but the clauses come in two types. We have soft clauses, c, one up to cm, each clause equipped with a weight wi, which is some positive real numbers.
00:03:17.214 - 00:04:00.210, Speaker A: I think for today it's better to think of them as positive integer numbers. And then we have a bunch of hard clauses, C m plus one up to c capital m. And our goal is to find an assignment row that has to satisfy all the hard clauses. And then we want to maximize the amount of soft clauses that we satisfy. So we sum up the weights of all the satisfied soft clauses, and this is our objective. Except that from now on, and for the rest of this talk, we'll think about this as a minimization problem. Instead, remember that we want to think of our sudo Boolean optimization problems as minimization problems.
00:04:00.210 - 00:04:36.870, Speaker A: But here it's fairly natural. We can minimize the penalty of the soft clauses that we fail to satisfy that we falsify. And we can write a c, a sub w for a soft clause, c with weight w. And we can write a hard clause, just a c sub infinity. And it's natural to think of a hard clause as a clause with infinite weight, because then obviously if we want to minimize the penalty, then we cannot afford to falsify a single such clause, because then our objective value is infinity. So, here is an example. Max sat instance.
00:04:36.870 - 00:05:51.720, Speaker A: We have a unit clause, not x with weight five, a clause y or not z with weight four, a clause not y or z with weight three, and then two hard clauses, x or y or z, x or not y or not z. And it is easy and natural to translate this to a pseudo Boolean optimization problem in the first following way. So, we just take all of these clauses, and we can write them as in the pseudo Boolean form by just summing up the literals and saying that there should be greater or equal zero. But for the soft clauses, for every soft clause, we add an individual new variable. So b one for clause one, b two for clause two, and b three for clause three, and we add it to the clause. Now, it is a common assumption in max sat solving that the hard part of the formula consisting of the hard clauses is satisfiable, because otherwise we have an unsat instance and there's nothing to optimize. So, given that the hard clauses are satisfiable, once I've added these new variables, b, clearly this is a satisfiable instance, because all of these soft clauses, I can just set the b variables to true and then they're satisfied.
00:05:51.720 - 00:06:47.362, Speaker A: But now what I want to minimize is the number of such b variables that I actually use. So it's not hard to see. So I have and I minimize by multiplying each variable bi by the weight of clause CI. And it's not hard to see that this is essentially now the same problem. So this is so called blocking variable transformation, where the biscuit are the blocking variables. And we can see here that an optimal solution sets x to zero and z to zero, y to one that violates only the cheapest soft clause, so it incurs a penalty of three in the other direction. We can also take a general pseudo Boolean optimization problem and translate it into a max sat instance, except that it might contain sudo Boolean constraints instead of disjunctive clauses.
00:06:47.362 - 00:07:56.538, Speaker A: So in the literature, such max sat instances in quotes are known as weighted Boolean optimization problems. So here is a pseudo Boolean optimization instance. We want to minimize some wi li, where the li are literals subject to constraint c, one up to cm. To translate this into MacsAt, we just take all the literals in the objective function, we negate them, and we make them into soft unit clauses with weight equal to the coefficient. And then all the original constraints in the pseudo Boolean instance, they turn into hard constraints with infinite weight. So it's clear that a sudo Boolean instance in such a way is just a max set instance, or more generally, a weighted Boolean optimization instance. And so you could in principle take a pseudo Boolean optimization instance, translate it in this way.
00:07:56.538 - 00:09:02.880, Speaker A: If these are general sudo Boolean constraints, you could translate these pseudo boolean constraints into CNF, as we discussed in part two, and then you could run your favorite maxat solver, and then it would work as a general pseudo boolean optimization solver. So the magsat problem comes in four flavors. If we have only soft clauses, then it's the original traditional magsat problem. If we have both hard and soft clauses, then it's known as partial max sat. And then you can have weighted or unweighted versions of these problems, where in the unweighted version, all the soft clauses have the same weight, which then, without loss of generality, we can consider to be one. So this gives us four different flavors of max sat. But the distinction is not so important these days, apparently, because most of the best solvers, they deal with a loss of generality with the most general problem.
00:09:02.880 - 00:10:31.484, Speaker A: So in what follows, we'll just talk about weighted partial mag sat, and the main approaches for solving weighted partial maxat and sudo boolean optimization that are used in current state of the art solvers are linear search, known as linear search, sat, unsat, or model improving search. We'll start talking about this, and then we will talk about another approach that is called core guided search. And then finally, I'll mention something briefly about implicit hitting set approaches for solving max set and pseudo boolean optimization. And throughout our perspective, we'll think about the problem of minimizing an objective function summing over I w I l I subject to a collection of pseudo Boolean constraints, c one up to cm, which could be disjunctive clauses, or maybe general pseudo Boolean constraints. So what this means is in some sense we, if it's a max sat problem, then we've already done this blocking variable transformation. Good. So what is linear search? Well, it's perhaps the most natural approach you could think of.
00:10:31.484 - 00:10:57.914, Speaker A: We just run the solver. So we start out by saying that we don't have a solution, so the best solution is nothingness. And then we run our solver in maxset. It's a sat solver. If it's a pseudoboolean optimization problem, then maybe it's a pseudo boolean solver. If the solver returns unsatisfiable, then we output whatever we have as the best solution and terminate. Otherwise, we found a solution.
00:10:57.914 - 00:11:44.264, Speaker A: Row an assignment to the variables. Let's update row best to be the solution, and then we can evaluate the objective function. And under row, this gives value wi times rho I, summing over I from one to n. And now we add a constraint asking for an objective function value that is one smaller than this. So we add this constraint, and then we run the solver again. So now, next time either it will have to return a better solution, in in which case we update, or if it turns out that we already found the best solution, then the solver will return unsatisfiable. And then we return the best solution.
00:11:44.264 - 00:12:26.380, Speaker A: Here is a small toy example. Suppose we have a pseudoboolean formula f, which we'll just consider to be a black box. We don't know what it is, but the objective function is minimizing. Say x one plus two, x two plus three, x three plus four, x four plus five, x five plus six, x six. Okay, good. We run the solver, and it returns the assignment that x one up to x three and x six are zero, but x four and x five are one. So now we evaluate the objective, so we get a contribution only from x four and x five, and the others contribute zero.
00:12:26.380 - 00:13:02.314, Speaker A: So the objective function value here is nine. Now we want a better solution than this. So we add the constraint that the objective function should be less than equal eight. Note that this is not a normalized constraint because it is not a greater than or equal constraint. But we agreed already in part one of this tutorial that we know how to convert this into normalized form. And here it is convenient to use this syntactic sugar to think of this as a less than or equal constraint. Good.
00:13:02.314 - 00:13:51.874, Speaker A: We run the solver again on the original formula f, plus this new constraint in red. And now suppose it sets x one, x three, x five, and x six to zero, but x two and x four to one. Then the objective value is six. So we add a constraint saying that we want the objective function to be less equal five, and we run the solver again. And now suppose the solver returns unsatisfiable. So this means that it wasn't possible to find a solution to the pseudoboolean formula f that yielded objective function value five or smaller. But we do have a solution with value six that has to be the optimal solution.
00:13:51.874 - 00:14:43.136, Speaker A: So we can return six as the optimum. That's linear search. And now, especially if you know your algorithms, you're a theoretician. You ask, well, why are we doing linear search? Why are we not doing binary search here? And the answer is that apparently linear search is better. Um, so there are at least two possible explanations for this. One is that, well, in theory, why is linear search bad? Linear search is bad because it could be that you just improve the objective value by an additive one. So you have to rerun it and rerun it over and over again, and you get only very small gains in objective function value.
00:14:43.136 - 00:16:04.114, Speaker A: In practice, apparently, this does not happen so much. Even when you do linear search, the objective function value tends to jump quite a bit. Another, perhaps more important reason is that when you're doing binary search and you're using a Sat or pseudoboolean solver as an oracle. Not all calls to this oracle have equal cost, because some of the calls will be for satisfiable instances where you just want to find a solution that is better than the solution you already have. But there is such a solution, and then some calls will be unsat calls, which is where the solver determines that you're asking for an objective function value that is too good to be true. It tends to be the case that these unsat calls are more expensive than the SAT calls. So if you do a binary search, then it might be that every, you know, a lot of, a lot of your calls might be unsat calls, and so they might be quite expensive compared to going with linear search and getting all calls sat calls until only a final expensive unsat call.
00:16:04.114 - 00:17:04.022, Speaker A: Another nice property of linear search is that you get a solution fairly quickly, even if it's not the optimal solution. Even after the first time your solver returns, you have some solution, and then you work on improve it. But you have something, and this is important for what is sometimes referred to as any time solving, which is a setup where you don't only solve for optimality, but time is also limited. So you're interested at every point in time to have the best possible solution available with that limited amount of computation. And it can be argued that in applied settings, this is a very important setting. Quite often you might not have patience to wait for hours and hours to squeeze the final bit of optimality out of your solution. If you can get an almost optimal solution quickly, then you're very happy with that.
00:17:04.022 - 00:18:09.316, Speaker A: But the problem, of course, with linear search is you don't know how good your solution is because you have no handle on what the lower bound might be. So that's what I wanted to say about linear search, sat and sat, or the LSU algorithm. Now we switch gears and talk about so called core guided search. We still want to minimize the sum wi li summing for I goes from one to n, subject to some collection of pseudo boolean constraints. And when I want to describe core guided search, it's convenient to first think of this as a max sat instance where li are these blocking variables that we have introduced. So every, the meaning now of a literal liquid is that it represents a soft clause. And this is the reason why this is important, is that this explains some of the terminology that is used, although we will generalize it shortly.
00:18:09.316 - 00:19:13.484, Speaker A: So now the idea is the following. We want to be optimistic. So we say that in fact the best possible value is zero. We can minimize everything, we can set all the literals to zero, and we run the SAT solver. Since we're doing Max SAT, we run the SAT solver with these assumptions, assuming Li to zero for all literals in the objective function. And usually SAT solvers have a special API where you can tell it to, in addition to the decisions that it's going to make on its own, you give it a list of pre made decisions to be applied at the beginning, and then what the SAT solver will do. It will apply all these decisions, and then it will either find a solution that is consistent with these pre made decisions, these assumptions, or it will return an explanation, a clause showing why these assumptions are not consistent, why you can't make all of these assumptions.
00:19:13.484 - 00:20:06.506, Speaker A: So we run the solver, and now it should be clear that if it returns satisfiable, then we have indeed found the optimal solution, because we were wildly optimistic. But this bet paid off. We found a fantastic solution, so we're happy. Clearly, zero is the best we could hope for, since all the weights wi are non negative. Otherwise what the solver does, it's returning some clause that explains why the assumptions are inconsistent. So say the learned clauses, li or l one or l two up to lk, which says that no, no, you cannot assume l one, l two up to lk, all false. At least one of these literals has to be true.
00:20:06.506 - 00:21:00.092, Speaker A: And what this means in a max set setting is no, you have to violate at least one of these soft clauses. You cannot find a satisfying assignment that satisfies all the hard constraints plus all of these soft clauses. This is not possible. And in Max sat terminology, that means that these soft clauses, c one up to ck, form a core. This is what is known as a core, and this is why it's called core guided search. So now we know that in this core, at least one clause has to be false, at least one blocking variable, li, has to be used, but possibly more, we don't know, maybe all of them. So we have to violate at least one of these clauses, maybe all k of them, we don't know how many.
00:21:00.092 - 00:22:22.932, Speaker A: So conceptually, we now introduce new variables, z j, where we think of z j as meaning that j out of these literals, l one up to lk are true, that j of the soft clauses have to be falsified. And then we can update our objective function by using the equality that we know that well, the sum of the l I is at least one, plus summing for j goes from two to k z j for these new variables j. And now we can use this equality. We can plug it into the objective function, and we will multiply it by the smallest coefficient of any li. And then we'll get a cancellation, we'll cancel that li, and we'll substitute the zjs instead, and we'll get out the constant term here that will give us an update that says that, well, this is a lower bound on what you could hope to achieve. You can't get all the way down to zero. You have to have an additive term, at least such and such.
00:22:22.932 - 00:23:38.814, Speaker A: And this allows us to update the best value. So this is going very fast, and I'm not explaining it very well, but we'll do an example shortly, a more general pseudo Boolean optimization example. So bear with me for a minute. The important thing is that in some way we can introduce these new variables which have the intended meaning that some of l one up to l k is equal to one plus sum of z two up to z k. And then we can use this equality to rewrite the objective, get an updated lower bound estimate, and then we just keep this, we store this additive lower bound somewhere, and then we assume that the rest of the objective function can again be zero. And then we repeat from the start and we just run this over and over again, deriving new course until we get the answer satisfiable back. And when that happens, the current estimate best value is indeed an optimal solution.
00:23:38.814 - 00:24:49.530, Speaker A: Okay, and this original id in Maxat comes from a paper by Fu and Malik and has been developed in a number of different directions. So see this survey in the references. Again, the references are at the end of the slides and you find the PDF with the slides on the Simons Institute webpage. I will also show the slides in the fourth and final video in this prerecorded tutorial, and they are at the end of the PDF file with my slides. And you can view core guided search it's again a linear search, but it's not sat unsat, it's coming from the unsat side and moving towards the sat side. And this idea of introducing these new variables to keep track of how much of the core is violated has been used in in answer set programming and in Mac Sat solving. So now we want to translate all of this to a general pseudo boolean setting.
00:24:49.530 - 00:25:17.944, Speaker A: And now the nice thing here first is that we don't need to think of the allies as blocking variables or markers for soft clauses or something. We just have a general pseudo boolean problem. This is an objective function, whatever. The allies are just literals. There are no soft clauses, no nothing around. We'll still talk about cores, but there are no, like, there will be no soft clauses or anything. Okay.
00:25:17.944 - 00:26:38.634, Speaker A: Another thing is that this rewriting that we did, I'm going back again, will actually be very convenient here, because in a max sat setting, if you want to actually encode this, you'd have to rewrite to cnfs in some way. But in a pseudo Boolean setting, this will just be an equality is just two pseudo boolean constraints that you can just write down and then you're done. I'm sweeping a little bit of details under the rug, but essentially this is very cheap in a pseudo boolean setting, because the constraints that you need are already available as native constraints for the solver. So you can do core guided sudo Boolean search, which just assumes that the objective function you have can reach its best imaginable value, and then you derive a contradiction if this is not possible, and essentially run the algorithm we have on the previous slide. So, let me, rather than giving you pseudocode because it gets a bit messy, let me just try to explain the idea by a concrete toy example, in fact, the same example as before. We have this pseudo Boolean formula f. I'm not telling you what it is, but we, we have the objective x one plus two, x two plus all the way up to five, x five plus six, x six.
00:26:38.634 - 00:28:02.650, Speaker A: And now we're going to solve this pseudo Boolean optimization problem with core guided search. So the first assumption is that, well, the best possible value is zero. So we set all the variables xi to zero and run this over. And now also, a pseudo Boolean solver can be developed to have this assumption mode where it will do one of two things. It will apply all the assumptions, then it will solve the residual pseudo Boolean formula under these assumptions, and it will either return a solution, in which case we're happy, or it will return a pseudo Boolean constraint that explains why these assumptions are inconsistent. How do you do this? Well, in technical terms, it's not so hard. You just run your solver with the standard conflict analysis, and then once you know, you can extract the core when you get a conflict already at the level, that is, at the decision level of the last assumption, or earlier, because if you get a conflict in the solver only after applying assumptions, then you know that the conflict is explained only by your assumptions.
00:28:02.650 - 00:29:19.200, Speaker A: Now, if you run your standard learning algorithm, you might pick up other literals also. But you can switch to the so called decision learning scheme, which resolves away all, um, reasons all the way up to the, the beginning of the trail, and then you will get a constraint that only involves the assumption variables. So, suppose that we get such a constraint back and. And it turns out that the constraint is three x two plus two x three plus x four plus x five greater equal four, say. So it turns out that this constraint, if I want to do pattern matching on the max sat core guided algorithm we had before, it's not so easy to deal with this general pseudo Boolean constraint. So, as we discussed in part two of the tutorial, you can take any pseudo boolean constraint and you can round it to a cardinality constraint. So I can look at this constraint and I can say, what's the best cardinality constraint I can get from it? Well, if the only way that this constraint is true is that at least two of these variables have to be true.
00:29:19.200 - 00:30:20.570, Speaker A: So I'll round this constraint to a constraint saying x two plus x three plus x four plus x five greater equal to this is certainly implied by the pseudo Boolean core constraint. And I'll call this cardinality constraint the cardinality core constraint. So now we want to do now we know that the sum of these variables is at least two. The sudo Boolean solver told us this, and the sum can be at most four, clearly, but we don't know where it is between two and four, and we want to store this information. And the way we're going to do this, we're going to introduce two new fresh variables, y three and y four, and write down pseudo Boolean constraints. Again, I'm using syntactic sugar here, but it should not be hard to see that the these are actually pseudo boolean constraints. First, I'll write down constraints enforcing that x one x two plus x three plus x four plus x five is equal to two plus y three plus y four.
00:30:20.570 - 00:31:06.140, Speaker A: And the reason why this is sound, I mean, this would not be a sound constraint in general, but we know that the sum of these variables is at least two. The solver told us this, so that's why we can write down this constraint. And then I'll also enforce that y three is greater or equal y four. And now if you think about it for a second, you realize that these constraints four a and four b actually enforce what I wanted it to enforce, namely that y j is true. Precisely, if sum of x two up to x five is greater or equal. Jack. So now what I want to do next is I want to update the objective function using this.
00:31:06.140 - 00:31:58.084, Speaker A: So let's go back to the previous slide, and here is the objective function. In one and in four a, I have an equality. So I can multiply this equality by two, and then I can substitute y two. Well, because I, I look at what the coefficients of x two, x three, x four and x five are, and the smallest coefficient is two. Okay, so I multiply the equality four a by two, and then I can substitute two x two plus two x three plus two x four plus two x five. I can substitute that by two times two, that's four plus two y three plus two y four, because this is an equality. Let's do that.
00:31:58.084 - 00:33:05.500, Speaker A: So here is the new objective function, which is equivalent to the old objective function, because because of these constraints four a and four b that I've introduced, the original objective function one, is equivalent to this modified objective function five. And note that in this new objective function five I have picked up a constant term for which indeed tells me what I learned from this cardinality core, namely, that it is not possible to achieve zero for this objective function. So far I know that the best possible value is four. Maybe four isn't achievable either, but you can't do better than four. Good. So now I run the solver again, assuming all literals to being zero in the updated objective function. So I assume x one, x three, x four, x five, and x six to zero.
00:33:05.500 - 00:33:32.474, Speaker A: Note that x two cancelled and is no longer around. In addition, I assume y three and y four to zero. Let's run the solver again and see what happens. So it turns out that the solver now returns not a general pseudo boolean constraint, it just returns a clause. That will happen a fair amount of the time. You'll just get a clause back in here. Suppose we get the clause x four plus x five plus x six plus y three.
00:33:32.474 - 00:34:06.472, Speaker A: At least one of these literals is true. And what do we know? Again, we know that at least one of these literal is true. We know that four of them could be true. We don't know whether one or two or three or four of them will be true. We want to store this information so we'll introduce new variables again. And so since we already have a clause, there's no need to rewrite a general sudo Boolean constraints to a cardinality constraint, because this is already a cardinality constraint. So introduce new variables z two, z three, and z four.
00:34:06.472 - 00:34:59.334, Speaker A: And we can write down this equality then that x four plus x five plus x six plus y three is equal to one plus z two plus z three plus z four. And this is sound because we have this lower bound in six. So that's why we can plug in this one. And then we add in addition constraints that z two is greater equals z three that is greater equals z four. And these constraints seven a to seven c will enforce the meaning of z j as the sum of x four, x five, x six, and y three is greater or equal j. And now what we're going to do again is we're going to look at the coefficients. We want to use this equality seven a and update the objective function.
00:34:59.334 - 00:35:42.124, Speaker A: And now x four x five x six, x four appears with coefficient two, x five with coefficient three, x six with coefficient six, y three with coefficient two. That means that we can multiply this whole equality with a two, and then substitute two times the left hand side here. We can replace that by two times the right hand side. So, two z two plus two z three plus two z four plus a constant term two. That will provide a further update of the lower bound estimate in our objective function. So let's see what we get. We get this.
00:35:42.124 - 00:36:20.448, Speaker A: So now we have an equivalent objective function again. X one plus x three plus x five plus four. X six plus two y four. Note that y three cancelled here, and also x four cancelled. And instead we have two z two plus two z three plus two z four plus the four we had before is now updated to six. So now we see that we don't know what the optimal value is, but it's at least six. So the best value estimate, we update it to six.
00:36:20.448 - 00:36:56.654, Speaker A: And now for the third time, we run the solver again, and we assume all of these literals in the objective function to false. Okay, and now you remember, in our linear search toy example, there was in fact a solution with value six. So that should be the case here as well. And indeed, our pseudoboolean solver finds it. It reports that x one, x three equals x five six, y four, z two, z three z four. All of them can be assumed to false. And there is such a solution.
00:36:56.654 - 00:37:53.624, Speaker A: Fantastic. So then we know from this that we can read off the the original solution. We can go back, for instance, if the solver doesn't already tell us, then we can figure out ourselves from four a, which was this constraint where we introduced y three and y four. So when we apply this partial assignment, four a simplifies to x two plus x four is equal to two plus y three. And the only way this can hold is that y three is zero and x two and x four are one. So that means that we can read off the original solution in the x variables. And indeed we get so, x two and x four are one and all the others are zero.
00:37:53.624 - 00:39:08.168, Speaker A: And looking at the original objective function, we had x two and x four one and all the other zero. So indeed we do get objective value six. But this we already knew, because note that due to our rewriting, this objective function in eight is equivalent to the original one, because we only transformed it using equalities. Okay, so this is an explanation by example of how core guided search works. And what are some interested properties of this algorithm if we run this pure core guided search that I discussed here? Well, it turns out that we can, if we're lucky, we can quickly get a lower bound on the solution. And this is nice, because this helps us, if we have a good lower bound, that this already allows us to ignore large parts of the search space where the objective function value would just be too good to be true. However, the way the algorithm works here we have, we know nothing about the solution until we finally hit on the optimal solution.
00:39:08.168 - 00:39:54.764, Speaker A: So we know nothing until we have the optimal one. And depending on what you want, this might not be what you're after. Also, although we do have a lower bound, we have no idea how far away this lower bound is from a feasible solution, because we're only increasing the lower bound. So this is complementary to linear search, which was good at finding a solution, an upper bound. But there we had no clue about the lower bound. So it's a very natural question to ask. Well, maybe, can we somehow combine corrugated search and linear search to get matching upper and lower bounds? Here are some ideas that have been explored for how to do this.
00:39:54.764 - 00:41:00.822, Speaker A: The first one is stratification, or weight stratification. You look at the objective function and maybe some literals have very heavy coefficients and other ones have have not so heavy coefficients. So some coefficients are large, others are small. And if there's a large difference in coefficient weights, then do the assumption only assuming literals with large weight coefficients to false, but don't assume anything about the others. So this can lead to one of two things. So if it turns out that already this very limited assumption on, on these large weight literals, if already that is inconsistent, then since you made small fewer assumptions, you get a smaller, more compact core, a stronger core. Okay, another thing that can happen is of course, that, well, in fact, assuming these high weight literals to false was consistent, so you find, you sort of accidentally find a solution.
00:41:00.822 - 00:42:11.328, Speaker A: But that's great, because then now we actually have a decent solution and we can continue our core guided search, but we have at least some kind of solution. And note that this was what the linear search gave us before, but that we were missing in the pure core guided search approach. Another idea to amortize the work done, as it were, during the core guided search is if we assume all the allies from, say, one to n to false, and then we learn a core constraint that only involves l one up to lk, then we can say, okay, now we know that at least one of these literals has to be true. What about the other ones? Maybe there are other connections in between the other literals that we have not explored. So let's just remove l one up to lk from the list of assumptions. Let's assume the other literals to false, and run the solver again with these remaining assumptions. And if we now get a new core.
00:42:11.328 - 00:43:50.216, Speaker A: Then obviously this core will be disjoint from the core we previously had over l one up to lk. So in this way we can collect a number of disjoint cores and then we can update the objective function and get a lower bound update independently with all of these independent cores disjoint cores individually contributing to the update of the objective function. Lower bound another idea is called core boosting. Here what we do is remember that I said that the nice thing with core guided search is that it can quickly give us a fairly decent lower bound on the objective function that cuts off large part of the search space. With core boosting. You just do that, you run core guided search for a while to hopefully get this good lower bound estimate, and then you switch to linear search and stay with linear search and try to find an optimal solution, hoping that the lower bound during the core boosted the lower bound that you found from core boosting during the core guided search helps you to do this. A more refined idea is to interleave core guided and linear search so that you would start doing maybe core guided, then switch to linear search for a while, then switch back to core guided search and again do linear search.
00:43:50.216 - 00:45:05.434, Speaker A: Now this apparently is not done much in macsat solvers, and my understanding is that the reason for this is in fact that all of these steps that I described with updates of the objective function and rewriting, note that we were operating with pseudo boolean constraints and this doesn't come for free, because in a CNF setting there's a lot of re encoding involved, and this is fairly expensive and takes time. So doing this, switching back and forth between core guide and the linear search is fairly costly if you're operating on cnfs. But if you're operating natively on sudo boolean constraints, then in fact this is not expensive at all. Then you can do full interleaving search fairly cheaply. So this is another advantage of a native pseudo boolean solver. One thing that we cannot do in a pseudo boolean solver, at least not yet, but you can do in a CDCL solver, just as in CDCL conflict analysis, you do clause minimization during learning. Here you can also do core minimization because the core that you learned is just a learned clause as any other clause.
00:45:05.434 - 00:46:39.390, Speaker A: So you can try to minimize the core in different ways. For a pseudo Boolean solver, it's not so clear how to do this, but maybe something can be done. Although to the best of my knowledge I don't know of anything that has been implemented in this regard. And I should note that in general, this idea of minimizing the constraints that you learned during conflict analysis is an interesting problem for pseudo boolean conflict analysis in general. One implementation detail that turns out to be important is that when we did this rewriting, let's go back and see, time and again we had these equalities where we introduce here, for instance, we introduce new variables, z two, z three, z four, and did this rewriting. Now, in a real world instance, you'll find many, many cores, and if these cores are large and are clausal, then you'll get tons of new variables, and in fact, performance will take a hit after a while. And then it turns out that you could sort of be lazy here and not introduce z three and z four.
00:46:39.390 - 00:47:52.046, Speaker A: You could just introduce z two, you had to use a different encoding, but you could just introduce z two to mean as an indicator that in fact more than one of these literals are true, and then introduce z three and z four later only when needed. So this is something that is called lazy variables. Lazy introduction of variables. Here we are, and this can be pretty important, but I didn't describe it here because conceptually it's not really a difference, it's more of an implementation detail. So why is core guided search good? No, but from a theoretical point of view, one very interesting observation is that these new variables that we're introducing, they are extension variables. And we know from proof complexity that even just the resolution proof system, if you add extension variables, then it becomes extremely powerful. It becomes as powerful as extended Frege, which is one of the strongest proof systems that we know.
00:47:52.046 - 00:49:23.754, Speaker A: And also if we take a pseudoboolean solver and add extension variables to it, then it becomes some version of cutting planes with extension variables, which is also equally strong. It takes us all the way to extended Frager. Now the problem with why these proof systems with extension variables are not used is that although they're strong in theory, it's very hard to see in practice what would be good heuristics to introduce extension variables and make use of them. But what is interesting here is that core guided search provides such heuristic for which extension variables you should introduce and why. So one interesting question from a theoretical point of view would be to formalize what core guided search can do. And given that extension variables are introduced in this way, it would also be interesting to characterize limits of the powers of this method to see if we can pin down maybe there are some things that it cannot do to a better theoretical understanding here would be quite interesting. This I just want to report briefly, this is actually something that we tried to do if we try to evaluate we implemented core guided search in a sudo boolean solver in the solver rounding set that was mentioned in part two of this tutorial.
00:49:23.754 - 00:50:11.034, Speaker A: And we have explored different flavors of this, combining core guided search and linear search. And let me present on a bunch of different benchmark families a number of instances that are sold to optimality with different approaches. The best solar configuration in red, then blue, then green. And don't look at the last line of this table for now, try to just look at it. We'll discuss the other lines first. So our favorite setting was the solver that dynamically interleaves core guided search and linear search and switches back and forth. This was a competitive approach in general.
00:50:11.034 - 00:51:35.252, Speaker A: So we ran it on the latest pseudo boolean competition from 20, 16, 16,000 competition benchmarks. There's also a MIP lib that is used for evaluations in the mixed integer linear programming community. We took some zero one integer linear programs from there, optimization problems run on those. There's a collection of challenging knapsack instances by Pissinger, and then for other reasons, somewhat independently, somewhat depending on this, we have a collection of tricky benchmarks originating in proof complexity. These are combinatorial formulas, which are sometimes referred to over on the applied side as crafted formulas. So we have a particularly tricky set of crafted formulas that challenge the solvers in different kinds of theoretical ways, measuring their strength of inference. And we can see that the hybrid solver overall performed very well on these benchmarks compared to the rounding set version that we had before.
00:51:35.252 - 00:52:25.364, Speaker A: That only does linear search. You see that it's a fairly significant jump in performance on the sudo boolean competition benchmarks, and even more so on the crafted benchmarks. Interestingly, for knapsack, linear search is still better, and for the MIP instances are in general just hard for pseudo boolean solvers. But at least it seems that hybrid helps a bit. Another very competitive approach, as we can see, is the core guided approach, where you don't interleave. But 10% of the time we run core guided search and then we switch, and until the timeout we just run linear search. That's also very good.
00:52:25.364 - 00:53:26.354, Speaker A: We try to investigate how much the different aspects of the implementation contribute. So one interesting thing with sudo Boolean solvers is that the cores are not necessarily clausal. They can be general cardinality constraints. So we try to switch this on and off, and we can see that the fact that you can get non clausal cores actually seems to contribute fairly significantly. Not always, but usually there's a boost in performance when you can have also known clausal cores. Lazy variables are very important if you want to solve knapsack, and this is because for the knapsack constraints you have lots of different weights, and it turns out that you can get very many new variables if you're not lazy. So that's why you have this huge jump here.
00:53:26.354 - 00:54:30.524, Speaker A: And then we tried this interleaving solver with both lazy variables switched off and the non clausal core switched off. And as expected, it's mostly worst. Not always, but for most of the instances. So here we can see we're evaluating against two other sudoboolean solvers, SAS four j that I've been mentioning before, and naps, which is a CDCL based solver. They are very competitive or even better than this linear search rounding set on the sudo boolean competition benchmarks. But we see that once we throw in this core guided component, running set gets much, much better, except for knapsack, where it seems that the tricky part is to find good solutions. And here somehow roundingsat is not doing well.
00:54:30.524 - 00:55:12.028, Speaker A: Now finally, the sad part is that SCiP is an academic MIP solver. It's not the best MIP solver, but it's the best non closed source solver. And unfortunately it beats the crap out of all sudo boolean solvers. So there's room for improvement here. And this is why you should also stick around for part four of this tutorial where we'll talk a little bit about what solvers like SCip do. But I should say that there are. Scip and the hybrid roundingsat solver have somewhat complementary strengths.
00:55:12.028 - 00:55:59.664, Speaker A: Also, it should be noted that SCIp uses preprocessing and none of the pseudo boolean solvers do that. So maybe we should do that. I think there is room for improvement here by taking the best techniques from SCIP and the best techniques from pseudo boolean solvers and try to combine them. And maybe also use other techniques like the implicit hitting set approach that we'll discuss shortly. Oh yeah. Here are also a plot from a cumulative plot for the sudo Boolean competition 2016 benchmarks. So here we're plotting number of sold instances as a function of time with the logarithmic scale.
00:55:59.664 - 00:56:33.024, Speaker A: Here we also tried to introduce these ideas with weight stratification and trying to find independent cores. Interestingly, for the instances in the pseudo boolean competition benchmark set. It turns out that this doesn't pay off. So weight stratification is not such a big difference. Sometimes it pays off, sometimes it doesn't. It's actually hit or miss whether you want to use stratification or not. But independent course doesn't seem to be good.
00:56:33.024 - 00:57:36.638, Speaker A: So one possible explanation for this could be maybe selection bias, because there is a selection bias in these competition benchmark sets. Or maybe we somehow didn't implement independent cores as it's done in the best state of the art maxat solvers. Or maybe it's something else entirely we don't know. That's what I wanted to say about core guided sudo Boolean optimizers. Now the final, third and final approach I want to talk about, I'll do it more briefly, is the so called implicit hitting set algorithm. Again, recall that we have this generic setting we want to minimize sum from for I goes from one to n w I l I for literals li subject to some collection of pseudo Boolean constraints. And since we're coming from Max sat again, let's think of these as causal constraints.
00:57:36.638 - 00:58:16.078, Speaker A: Let's think of these ally as blocking literals. So they're, they're names of clauses, as it were. So as in core guided search, we'll solve with assumptions and we'll collect cores, but we collect a whole set of them and keep this set. So cores will be clauses and the meaning of this clause. So again, these literals, l are like names of literals. And the first course says that, well, you have to falsify at least one of these clauses. And then the second core says you have to falsify.
00:58:16.078 - 00:59:05.570, Speaker A: So it is one of these clauses. And the core number s says that you have to falsify at least one of the clauses tagged by these literals. Okay, so in all of these sets you have to falsify at least one clause. Now, one way of trying to do this as economically as possible is well, pick as few literals as possible so that you hit all of these clauses. So pick a hitting set. So this is what we're going to do. So the way the implicit hissing set approach is we start with a set of cores that is empty at the outset and will grow with the course that we collect.
00:59:05.570 - 01:00:07.126, Speaker A: And in every iteration we compute a minimum hitting set for k, that is a set of literals such that every clause in the core set has some literal in h. So in terms of sets, age is a hitting set. What this means for truth value assignments is that if we set all the literals in age to true, then we're satisfying all of these clauses, and we know that we have to. So, satisfying all of these clauses means that we're violating some original clause in these cores. And this we know we have to do, and we're trying to do it. The fact that we're using a minimum weight hitting set means that we're trying to falsify soft clauses in the cheapest way possible. Once we figured out this minimum hitting set h, we run the solver with this assumption.
01:00:07.126 - 01:00:57.994, Speaker A: So the literals in the hitting set will assume them to true. We take the penalty. Everything else we try to assume to false. Now, if the solver run with this assumption, finds a solution, it must be an optimal solution, because we know that, we know that we have to pick one literal from all of these clauses, and the minimum heating set is doing this in the most economical way possible. So therefore, if the solar finds the solution with the minimum weight heating set, then the solution is optimal and we can return this value. Otherwise, if the solver does not find a solution, it returns a new core, which we add to k. And then we start over again, compute a new hitting set, and do another round of this iteration.
01:00:57.994 - 01:01:53.374, Speaker A: And one observation is that we, when are we using minimality? We're only using minimality here, that when the solver finds the solution, it's optimal, since the hitting set is optimal. So this means that in early iterations, we can just compute decent hitting sets, not necessarily optimal ones. We only need to check optimality at the very end. So a natural question is, yeah, but where do we find the heating sets? But it's not so hard to see that this minimum weight hitting set is in fact another pseudo boolean optimization problem. We even discussed this in the preliminaries part of the tutorial. So you could actually imagine running your solver on this subproblem and taking that solution. Or I think what is done in practice is usually you run a MIP solver and you take the solution from the MIP solver.
01:01:53.374 - 01:03:09.154, Speaker A: So how good? So this is another approach than core guided. So how do they compare? So, with the caveat that I have not done research on this, but I've talked to colleagues who know this better than I do, and they're fairly consistent in saying that it's not the case that either approach dominates the other. So it seems that implicit hitting set and core guided have complementary strengths for max hat problems, where you have many soft clauses with the same weights that are somehow interchangeable. And the important thing isn't exactly which soft clauses you violate, it's more like about the count of how many soft clauses you need to violate. Core guided seems better because it will allow you to abstract away and somehow give you this count. It doesn't necessarily care about which clauses, it will just know how many clauses you're violating. However, for Maxat problems where you have many distinct weights, it seems that the implicit hitting set approach is often better.
01:03:09.154 - 01:04:08.538, Speaker A: This is all based on intuition, though. So a very nice question for the theoreticians listening to this would be to study the proof complexity of corrugated search and implicit hitting set, and try to provide precise characterizations. Compare the two approaches. Maybe you can prove some simulation results or separation results. There is some work in this direction, but there's definitely room for more other open questions. Since implicit hitting set and core guided are complementary, why not try to combine them? So it turns out that this somebody already thought about this. There is some recent work on this, but again, my impression is that it's not the final word.
01:04:08.538 - 01:05:28.428, Speaker A: There should be more things that can be done here. Another idea is to think about well, can you do implicit heating set for general pseudoboolean optimization? So now remember that we don't have course and soft clauses here, we just have an objective function and literals. So the so called cores will just be learned pseudoboolean constraints over literals in the objective function. So then what is a hitting set? Well, a hitting set will be a partial assignment that is guaranteed to satisfy all of these constraints. Note that if these constraints are clauses, then the hitting set is really just a hitting set, because you know, for every constraint that you only need to satisfy one literal in c, and then the clause is set. In general, if the cis are suitable in constraints, then you might need to set several literals to be sure to satisfy this constraint, and you'll get some kind of generalized hitting set that does this in as cheap a way as possible. To the best of my knowledge, this has not been implemented in a native pseudo Boolean solver.
01:05:28.428 - 01:06:43.054, Speaker A: I think it would be very interesting to do it, but that's a future research direction that ends part three of this tutorial. So we've now talked about what sudo Boolean problems are, how to solve decision problems, how to solve optimization problems. But as you saw, the annoying thing is, as we developed these solvers, often, not always, but often, it turned out that mixed integer linear programming solvers were also very good at solving these problems, or even better. So, in the fourth and final part of this prerecorded tutorial, we'll talk a little bit about what these mixed interlinear programming solvers are, how they work, and what we can do about the fact that they're so good. So we can try to beat them, or we can try to join them or maybe do both. But to hear more about that, you have to tune in for the fourth and final part of this tutorial. This ends part three.

00:00:00.080 - 00:00:50.538, Speaker A: Use cryptography in game theory to remove completely trusted parties that are very common in mediated games. Now I want to switch to what's potentially more interesting for cryptographers, which is how we can use game theory in cryptography and why we would want to use it. And I claim that the main reasons are, again, we want to remove or relax some of our assumptions. And the even stronger reason is that we can actually improve the resilience and the efficiency of our solutions by doing so. It's very intuitive to see why. And we're going to see. All right, so for the first part, improving our assumptions or relaxing our assumptions, we saw a bunch of lower bounds in the talks on byzantine agreement.
00:00:50.538 - 00:01:35.034, Speaker A: We saw that you cannot do byzantine agreement if more than a third of the parties are corrupted. Like if potentially more than one third of the parties can misbehave and there's no setup, it's impossible to do by sentinel agreement. And we have like similar bounds for NPC. You cannot get what is known as fairness. I'm gonna not yet see what it is. If there's time, we're gonna cover it in the end, if the majority of the parties is corrupted. And in general, cryptographic definitions make no sense if everyone is corrupted, right? So what is there to say? So there is something inherent with cryptographic NPC definition, which is that in order to even make your definition meaningful, you need one honest guy.
00:01:35.034 - 00:02:12.505, Speaker A: So a question which you can answer is, is there anything to be said when I don't have an honest guy? Right. When everyone might potentially deviate. Now obviously there's nothing interesting. Again, cryptographically to be said, any protocol is secure against an adversary that corrupts everyone. But let's think of a setting where parties, everyone might deviate, but not adversarially. They're not byzantine, but rather they're rational. They try to maximize some utility.
00:02:12.505 - 00:03:21.616, Speaker A: And the standard type of utilities that have been looked at here are very much related to privacy of MPC. What you can think is rather than running standard NPC against a semi honest adversary, for example, or a malicious adversary that tries to make sure that information doesn't leak, you have MPC where parties have utilities, which I call curious but exclusive here, what I mean by that is that everyone wants to learn the output. It's in my best interest. My utility is maximized when I do learn the output, but when I do learn it, I prefer that no one else does and the output or anything about data. So you can think of this type of utilities and then there is a sequence of beautiful results that have shown that if everyone might misbehave, but in a way that is trying to maximize his utility, his curious but exclusive utility. We can reconstruct a search secret. Again, everyone can misbehave.
00:03:21.616 - 00:03:55.754, Speaker A: Everyone might misbehave. Still, we can reconstruct always a search secret. We can actually compute an arbitrary function with fairness. Again, everyone might misbehave. What's the key? We know in cryptography that all these tasks are impossible, for example, for dishonest majorities, NPO. And what these results say is that if parties are not too dishonest when they misbehave, so they have a goal of being dishonest, then we can actually perform all these tasks when everyone can be misbehaving. Potentially, yeah.
00:03:56.114 - 00:04:02.614, Speaker B: Is it that it's a Nash equilibrium for the computation to work directed, yeah. Is it a unique Nash?
00:04:03.994 - 00:04:20.466, Speaker A: It depends on the. So different papers have. Actually it's more than a nas. So most of those papers try to get nas. Try to get nas that survives, even iterated deletion, because they're sequential games and you want to get Nas that survives iterated deletion of dominated strategies or strictly dominated strategies.
00:04:20.530 - 00:04:22.814, Speaker C: Is it a coalition resistant? Naturally.
00:04:25.314 - 00:04:37.722, Speaker A: Those works don't have some of those. Actually, I think the Georg's work, if I'm not wrong, has a coalition resistance. Not all of them has coalesced resistance. The original, the Halpern tig, is not coalescing resistance.
00:04:37.818 - 00:04:39.134, Speaker C: How large are those coalition?
00:04:39.434 - 00:04:41.774, Speaker D: Why do you think they require honest majority?
00:04:42.514 - 00:04:56.350, Speaker A: No. Where. No, no, I'm saying cryptographically, all those tasks would require honest majority. If I didn't, if. If I had arbitrary adversaries, byzantine parties, then I would need honest majority or abort.
00:04:56.502 - 00:04:57.654, Speaker D: Yeah. Okay, the fairness.
00:04:57.734 - 00:05:06.646, Speaker A: Yeah, yeah. I mean, I mean, I just listed things that don't abort here, right? Yeah. I mean, if I want to abort, I would want t minus one, which still is worse than, you know, n minus one, which is still worse than.
00:05:06.670 - 00:05:10.654, Speaker C: N. Can you resist majority corruption in the national equilibrium?
00:05:10.814 - 00:05:24.786, Speaker A: It's not corruption, but yes, you can. You can. I mean, if everyone might misbehave, you can think of it as corrupted, right? It's not. You can think of it as everyone is corrupted, but corrupted parties won't try to arbitrarily, but they're trying to maximize.
00:05:24.930 - 00:05:28.694, Speaker C: Their utility coalition in Nash equilibrium.
00:05:30.954 - 00:05:45.974, Speaker A: I don't remember. I know that this work does t resilient, but I don't know if all of those. Yeah, I think the original work doesn't do t resilient. And some follow ups do t resilient.
00:05:46.384 - 00:05:51.484, Speaker D: But then you have to deal with the board, and for a board, you need to have some punishment strategy and some requirements.
00:05:55.784 - 00:06:35.902, Speaker A: Yeah, sorry. So, okay, so now I'm going to get to the more interesting, at least for me, or hopefully for cryptographers, part of this talk, which is how we can use game theory, how we can use game theory in cryptography to improve our solutions. Right. Before going there, I should say that there's all these wonderful results that we discussed so far, and many that I didn't discuss. There's no time for everything. And there are parallels and pitfalls, what I call them mismatches, and the theories that those things reveal. So we already saw that cryptography uses a monolithic adversary, like, that's how we call the single unified adversary.
00:06:35.902 - 00:07:43.504, Speaker A: Whereas typically, mechanism design assumes local misbehavior. The second thing is that cryptography, you know, the interesting cryptography, or much of the interesting cryptography, is based on hardness assumptions, right? So we assume that the parties are polynomially bounded, they cannot even think super polynomially, right? Let alone play. Whereas in standard game theory, parties can think, you know, the way everyone can think forever. There are works, I should say, that try to rectify that. And Rafael has some works on this thing. The third and extremely important issue is that the definition that mutu gave this simulation, real ideal based definition, has a fantastic feature, which is composability, and it's proved formally by run. So what's this property? This property says that I can take any functionality, I can take any task, and in any context, replace it with a protocol implementing it, and I'm not losing any security.
00:07:43.504 - 00:08:30.212, Speaker A: So I can, in any context, in any protocol, replace a subroutine with a protocol that I proved secure, according to cryptographic definition. In game theory, we don't have such a theorem, and there's a reason that we don't have such a theorem, right? Such a theorem cannot exist generic. Why? Because think of two tasks that have conflicting utilities, right? So the adversary is not willing to break the subroutine. But when I plug the subroutine within a bigger game, then it's in the interest of the adversary to lose in the subroutine and win more in the bigger game. So there is no hope to prove such a generic theorem in mechanist design. That's problematic. Actually, there is an even bigger problem, which appears in the last line of work that I showed you.
00:08:30.212 - 00:08:47.900, Speaker A: This rational NPC works, which is, in many of them, we cannot even replace secure channels. For example, with cryptography, for reasons which have to do with this bounded rationality, I'm not going to get into these details yet.
00:08:48.092 - 00:09:22.444, Speaker B: There's some work called black box reductions, actually computer science communication that tries to take algorithms and just reduce them to mechanisms. And what you need to use is payments. So I can't make you, like, I can't make you do this thing because you can make care about, like, the payoff that you get out of it. But I can offset your payoffs with payments and then you can try to think over this composition. I can use any building block as long as, like, I augment your payments in the right way to correct data.
00:09:22.524 - 00:10:04.138, Speaker A: That's actually very interesting. Something similar will appear in what I'm going to discuss here. But theorems of this type or results of this type can be very, very useful wherever we're trying to do. Such a combination is very important. So, and the other thing is that as cryptographers, we really love adaptive corruptions, right? We think that adaptive corruptions is the model to live in, and in particular, even adaptive corruptions against external attackers think like a virus infiltrating kind of thing. Adaptive corruption is parties start honest, they play the protocol, and then at some point the adversary, looking what he has seen in the protocol so far, decides that now they're corrupted, I want them and I'm going to use them. That's adaptive corruption.
00:10:04.138 - 00:10:15.666, Speaker A: So parties become corrupted depending on the protocol execution. So it's not supposed why. This is not one of the behavior of a corrupt country.
00:10:15.770 - 00:10:17.042, Speaker D: Not to corrupt for a while.
00:10:17.098 - 00:10:34.568, Speaker A: And to what is the difference? Adaptive. Non adaptive, you mean in cryptography now? Non adaptive means the choice of the corrupted parties is done at the beginning of the protocol and I stick to it. So I say, let's run it. I mean, I'm the adversary. We run a protocol, right? I say Ellie and Yuval are corrupted. That's it. That's my choice.
00:10:34.568 - 00:10:50.696, Speaker A: I have no option to change it. Adaptive corruption is like, hmm, I'm going to start the protocol with corrupting Ellie and let's see what happens right now. You see things in the protocol, you see what other parties send you. And I suddenly see that Yuval is a very interesting entity in the protocol. He does very interesting stuff, right?
00:10:50.800 - 00:10:51.488, Speaker D: He does.
00:10:51.616 - 00:11:16.670, Speaker A: He does. That's why the example is actually targeted to reality. So then I go and corrupt Yuval, right? Why is arihol as corrupt? Your choice. You don't commit on the choice of the. I corrupt only important players, right? I choose the most important player Ellie and corrupt him. And then, you know, I use him to figure out who else to corrupt. That's standard in cryptography, right? That's not new.
00:11:16.702 - 00:11:19.274, Speaker D: Captured by this x interim exports.
00:11:19.854 - 00:11:20.358, Speaker A: What?
00:11:20.446 - 00:11:25.350, Speaker D: In game theory, you can also capture this, right, in the solution concept using the exposed.
00:11:25.462 - 00:11:31.414, Speaker A: Can you capture this, can you capture this transition happening depending on the game execution?
00:11:31.534 - 00:11:36.194, Speaker D: Yeah. So the exposed basically means that after the facts, no coalition would be happy.
00:11:38.294 - 00:11:48.192, Speaker A: No, but I'm now discussing coalition getting larger. Right. Like, not, not. You're. You're. You're fixing a coalition, and I'm discussing the coalition designing, deciding to get larger depending on what they see.
00:11:48.248 - 00:11:57.080, Speaker D: So whatever solution concept you have, you can apply it either before the gameplay, which is kind of static adversary, or in hindsight. Okay, that's good.
00:11:57.192 - 00:11:59.244, Speaker B: Like some good subjection.
00:12:00.144 - 00:12:00.624, Speaker A: Okay.
00:12:00.664 - 00:12:04.764, Speaker D: I guess all I'm saying is that this notion of adaptive and static has also been studied in the.
00:12:05.504 - 00:12:15.994, Speaker A: I don't understand. And yet what is adaptive and static? That's fine. Let's discuss this offline. I have to be corrupted. I don't know who they are. I don't know whether he chose it by chance or he chose your val.
00:12:16.034 - 00:12:17.242, Speaker D: By chance or not.
00:12:17.418 - 00:12:41.202, Speaker A: There's very simple examples in which you can get way better from adaptive than from static. And one of those examples is that I choose one of you randomly and use him as a trusted party in my computation. Static corruption will give me probability one over the number of guys that are here of succeeding. Adaptive corruption give probability one. This makes huge difference. So, you know, that's standard in cryptography. It's been discussed.
00:12:41.202 - 00:12:50.306, Speaker A: You know, it's a standard notion. That's why it's here. I didn't know that. Standard notion in game theory, too. And so they map. They map one to one or one.
00:12:50.330 - 00:12:54.494, Speaker D: To one is very strong. But, yeah, I think definitely the.
00:12:55.194 - 00:13:54.684, Speaker A: So this question mark is answered. So what I want to discuss here, actually is a different, more cryptography friendly way of combining cryptography and game theory that doesn't have all these issues or doesn't have complicated ways of circumventing or deciding what's one to one in this sense. And this is the notion of rational adversaries, which was generalized in a framework called rational protocol design that I'm going to discuss and connect also to blockchain analysis. So what are we doing here? Rather than thinking of the protocol itself as a game, the idea is to think of the protocol being attacked by an adversary in the standard cryptographic setting. But this adversary is not arbitrary. He has some utility. And you'll see where it starts making sense.
00:13:54.684 - 00:14:31.638, Speaker A: Actually, implicitly, this idea has been even used in analysis of, of blockchains. I'm going to, first of all, why always, the question is why even go there? And the answer is immediately when you look at the standard cryptographic definition, what do we require? That every real world attack has to be simulated in the ideal world. So every real world attack must correspond to an attack in the specification. And this is, let's pray, cryptographically. It's fantastic. We get super strong security guarantees, right? I don't need to know what the adversary is going to do. I don't need to know anything about the adversary, right.
00:14:31.638 - 00:15:12.384, Speaker A: He's going to fail. And what I mean he's going to fail is I'm going to guarantee all security properties that I would want, like correctness, privacy, fairness, and even those that I don't know that I want. That's the simulation paradigm. It's a fantastic paradigm, and it gives us composition for free. The problem is that this kind of strength is also the weakness of the definition. And why, by requiring that every adversary, every attack, needs to correspond to an ideal attack, right? Whatever the adversary does, I need to know what this means in the specification. And I design a protocol for such a definition.
00:15:12.384 - 00:15:53.104, Speaker A: I design a protocol which even tries to simulate very crazy things, right. That we really never happen in reality. And I'm going to not, I don't know about never, but they're most likely not going to happen in many contexts. So. And that gives us very strong impossibilities, or that's one of the reasons that they get very strong impossibilities. So the t less than and third, for presenting agreement can be attributed to such a thing. Fair NPC, we know all these impossibilities we discussed and also the efficiency of the solutions that we have gets a hit, which is natural, right? So some of those strategies, the crazy strategies, might be very hard to cope with and might be the ones that I'm doing most of the work to cope with.
00:15:53.104 - 00:16:42.542, Speaker A: Right? All right, so if you look at what happens in reality where you run a cryptographic protocol in general attacks, you know, an attacker doesn't attack a protocol just for the fun of it, right? That's actually what this whole talk is about. There are incentives. People want to do something and they do it for some reason. So, for example, depending on the application, the attacker might want to learn private information. If we live in a blockchain setting, he might want a fork, and that's what he gets utility from, he might want to increase his block rewards. He might want to do double spending. So these are potential goals, and we could, in principle, restrict our attention of security to a set of these goals rather than the adversary wants to fork the blocks.
00:16:42.542 - 00:17:42.364, Speaker A: And just for the fun of it, who is willing in bitcoin to spend billions and billions just for the fun of it? Maybe someone is a core kind of intuition here is that some trading strategies might be avoidable in certain settings. So, for example, if seating can be detected, then I might have incentives to make sure it doesn't happen. If sitting can be detected, and whoever is court sitting must pay a penalty for it, then I could as well. If the penalty is large enough, I could as well assume that he's not going to sit. So I'm going to give you an example where incentives lead to a much, much simpler solution. It's a little bit, the motivation is a little bit arbitrary, but bear with me and please criticize it. That's fine.
00:17:42.364 - 00:18:07.822, Speaker A: Let's think of a corporate merger. We have four companies and there's two posts they want to merge. Each company has its own president, and now there's two candidates. Not each company. There's two candidates from the companies that are proposed as president. And now they want to vote on who is going to be the president of the merged company. The deal is the following.
00:18:07.822 - 00:18:39.826, Speaker A: They want to run a protocol. If the outcome of the protocol brings up one of the two presidents, like as a full, like as a unanimous agreement, then the merger goes through and everyone is happy. If the output of the protocol yields disagreement between any two parties, then the merger breaks. This means that they cannot agree on who should be the president. They don't want to be a single company. The merger breaks, and everyone knows what happens when the merger breaks. It's happened also, so the stocks get big hit.
00:18:39.826 - 00:19:24.228, Speaker A: That's not the desirable. This is the problem we try to solve. Do we know of any primitive that could help us solve this problem? Yes, any other primitive closer to the name of the bootcamp? Consensus. Right. So if I could give those guys a consensus protocol, then they could. What they would do is they would use their inputs, and if their inputs pre agree, they would just elect the president. If they don't, they go home.
00:19:24.228 - 00:20:01.210, Speaker A: Actually, if I have consensus, I can even get something stronger. There's no way that the deal is going to break. So this is a primitive that would solve this problem. We know that those guys can run a consensus. What's the problem with consensus? Actually, that should be sorry. That should not be yet rational. Problem is that if those guys don't have a setup, don't have a big AI or another setup that can allow them to authenticate and transfer authentication, it's impossible to get a consensus with more than one third of the parties being corrupted.
00:20:01.210 - 00:20:24.574, Speaker A: But we know we've seen it in stock. We also know that in order to get it by deterministic protocol, let's forget randomized. First a minute with a linear number of rounds in the corrupted parties. So if I want to get this thing with many parties being, okay, four is not a good number. Right? So linear. And four is fine. But think of it in a large scale.
00:20:24.574 - 00:20:28.454, Speaker A: We know that we will require a linear number of rounds.
00:20:30.674 - 00:20:33.410, Speaker D: It's linear, not n times t. Right?
00:20:33.442 - 00:20:41.114, Speaker A: Just t. T is the threshold. Yeah. T is the threshold on the c. So it's like n times t because. Yeah. It's a ratio.
00:20:41.114 - 00:20:52.654, Speaker A: Right. Here's one, three. It's not one third n. T is one third, not one third n. It's not a third of the parties. It's the ratio. Yeah.
00:20:56.394 - 00:20:58.938, Speaker E: What's the model? Asynchronous. Synchronous.
00:20:58.986 - 00:21:06.974, Speaker A: Yeah. Let's think of fully synchronous. Right. So I want to make a very simple example of the principle that by, by incentive, I haven't made it yet. Now I'm going to make it the principle that by incentives, we can get better.
00:21:07.094 - 00:21:09.310, Speaker E: But you don't have pki.
00:21:09.462 - 00:21:20.678, Speaker A: No, no Pki. It's synchronous. No Pki. That's why we have, like, these bounds and deterministic. That's why we have this bound here. Good. So that's what we know.
00:21:20.678 - 00:22:05.514, Speaker A: Now, by looking at the problem, what we also know is that even when someone is going to sit in the protocol, so we have our honest guys that are great. When someone is going to sit with the protocol, he's going to do so in a way that avoids, in the end, having disagreement. Why? Because disagreement is a disastrous scenario. Agreement is to always to be preferred as an output than disagreement. In this scenario, it's extremely easy, especially for this audience, to see that if this is the case, we can have an extremely simple protocol. We can tolerate any dishonest minority. That's the best we can do for consensus, right? We cannot go beyond minority for consensus, and we can do it in a single round.
00:22:06.734 - 00:22:10.958, Speaker D: So this is like a limited adversary.
00:22:11.046 - 00:22:11.534, Speaker A: Yes.
00:22:11.654 - 00:22:16.102, Speaker D: It has a limited amount of actions. And the way you decide what actions you're allowed is by saying, yes, it's.
00:22:16.118 - 00:22:33.144, Speaker A: A huge utility defines what the adversary is going to do. Yeah. Once again, there are scenarios where you can think of this as making sense, right. If it's a lose lose for everyone to disagree, it makes sense to assume that the actions that will lead to disagreement can be excluded.
00:22:33.724 - 00:22:39.300, Speaker D: This is like an exogenous choice of the limitation of the adversary. You chose this. You believe this is the.
00:22:39.412 - 00:23:10.546, Speaker A: Yes, that's always the case in any rational analysis. I believe something about what the parties are trying to achieve, and then I prove something about based on this belief. So what's the protocol? Extremely simple protocol. Everyone sends, I mean, it's simple, right? I'm not, that's not rocket science. It's very simple and simple to analyze. So everyone sends his input to everyone else and then everyone counts. Whatever is in majority is the output.
00:23:10.546 - 00:23:38.846, Speaker A: If there is a tie, just output zero. That's a protocol single round. Let's very, very quickly see why this thing achieves consensus under this assumption. Right. If there's pre agreement, what do we have? We have, let's say for the four parties, we have three parties having the same input and the adversary potentially having something different. Doesn't matter what he's going to do. Everyone is going to get three times the input of the honest parties.
00:23:38.846 - 00:24:08.482, Speaker A: So it's in the majority. He's going to output it. That's very simple. The slightly more complicated but not very complicated for this protocol case is what happens if there's no pre agreement. So let's look at the binary case for simplicity, right? If there's no pre agreement, what the setting that can be is that two parties, there's three honest parties, right? Like we have four parties, an honest majority. There's three honest parties. Two of them will have the same input and one has different.
00:24:08.482 - 00:24:29.232, Speaker A: That's the only case of disagreement. There's no other way to disagree. I mean, maybe you want to write. I mean, I can write. I mean, it's very simple, actually. So we have four parties, right? These guys, the adversary, like you have, where in the binary case, two parties have the same input, the third one has another one. Like, you know, choose your b.
00:24:29.232 - 00:24:30.204, Speaker A: Let's make it.
00:24:32.944 - 00:24:38.144, Speaker D: If t is less than half, you want five or three, right? That you're adding one more. Why four?
00:24:39.844 - 00:24:51.064, Speaker A: N is four parties. And I'm assuming that I have a corrupted minority, which means that the adversary is slickly below one half. This you can extend actually to arbitrary, to n, and it's strictly less, right?
00:24:52.044 - 00:24:55.620, Speaker D: Yeah. So it's like the standard one more less.
00:24:55.732 - 00:25:30.504, Speaker A: Anyway, what do you mean? I mean, if the adversary corrupts one more, then he has majority. That's the only thing that can happen. Or no one is corrupted. Right? So let me just, so let me just say that b is zero, just for simplicity. And this is one. Okay? So now here's what happens, right? We run our protocol. Every honest guy will receive the messages from the other guys, right? Maybe you should make it one, because now.
00:25:30.504 - 00:25:56.778, Speaker A: Sorry. No, sorry. Make it one because the decision to go to zero will destroy my argument. Sorry. All right, so everyone sends his input. All honest guys by the protocol are going to send their input to everyone. So this means that, what are the messages that are received? It's every party gets one, 10 and something from the adversary.
00:25:56.778 - 00:26:23.334, Speaker A: Everyone. And now let's look at what the adversary is going to do. He has two choices, right? One choice is to send the same message to all of them. And if he does, then they're going to have exactly the same view. So whatever rule they're using is going to lead to the same output. If the adversary sends one, they're going to output one. If the adversary sends zero, they're going to output zero.
00:26:23.334 - 00:26:46.366, Speaker A: The other choice is not to send the same message to everyone. And it's very easy to see that under this assumption, this is actually a strictly dominated. And if he sends zero to that guy and one to that guy, then this guy is going to have a tie. So he's going to break it with zero. One.
00:26:46.430 - 00:26:47.374, Speaker D: He sends one.
00:26:47.494 - 00:27:04.478, Speaker A: Yeah, 1101. Right. So he's going to break the tie with zero. He runs out with one. You're right. Sorry. I was wondering, where's my contradiction? Right? And this guy is going to get his zero.
00:27:04.478 - 00:27:19.970, Speaker A: He has a tie. He's going to break it with zero. That's the rule. Right? So zero if equal. So what's going to happen is that if he sends different values to different parties, then they're going to disagree. So this strategy is strictly dominated from the other one, where they don't disagree. So this won't happen.
00:27:19.970 - 00:27:50.550, Speaker A: And our protocol is secure under this assumption. So what did we learn from this example? That by making assumptions about the utility of the adversary, we can actually get way, way, way simpler solutions. It's nothing complicated. It's a very simple example demonstrating exactly this factory. But, you know, the utility is not, you can think of the utility. The adversary wants to play honestly, right? So that's not this utility, it's just zero one.
00:27:50.582 - 00:27:54.034, Speaker D: Right? This is what I'm allowed to do. So I'm not allowed to do in terms of the output.
00:27:55.174 - 00:27:59.514, Speaker A: Sorry, the protocol, you mean, or in general, in the problem.
00:28:01.334 - 00:28:05.794, Speaker D: So you're just limiting the space of actions that the adversary can take.
00:28:08.034 - 00:28:28.770, Speaker A: No. Right. I mean, in this protocol, this protocol has a very limited space of actions, but it could be that the protocol that I had was like a forearm protocol, right? And then there's arbitrary things that can happen there, but just in the end, the adversary wants agreement. So it happens that this solution is a trivial solution, which is actually demonstrating the fact that just by this assumption, I'm getting trivial solutions.
00:28:28.882 - 00:28:30.778, Speaker D: But it's not, this is not a game.
00:28:30.826 - 00:28:31.034, Speaker A: Right?
00:28:31.074 - 00:28:31.778, Speaker D: Isn't that a new.
00:28:31.866 - 00:28:43.824, Speaker A: No, no. Again, it's a completely, that's why I had the previous slide. That's a completely different way of combining game into cryptography. This is not a game, but I'm going to define a game now. So.
00:28:47.404 - 00:28:47.884, Speaker E: Okay.
00:28:47.924 - 00:29:32.622, Speaker A: So you can actually abstract this thing in what we call an attack game. What's the attack game? The attack game is a game which is supposed to capture exactly what it means to securely implement a task against an adversary that is restricted by his utility in a cryptographic sense. And what is the game? The game is extremely simple, unlike the sequential game, which might have an infinite depth depending on the number of rounds, so on and so forth. The game does the following. It has two parties, two agents, and they both. So one is a protocol designer, the other one is a protocol attacker. And they both know the task that we want to design the game for.
00:29:32.622 - 00:30:01.554, Speaker A: We want to devise a security definition for incentive driven adversaries so they both know the task, the cryptographic setting. The task is an ideal functionality. It's a trusted party that performs the computation we want. All right, and the parties. So here's how the game is played, and I'm going to discuss the utilities in a minute. The game is played as follows. First, the designer chooses a protocol for f.
00:30:01.554 - 00:30:47.830, Speaker A: Now this, it's important to think, to understand that this protocol is not, has nothing to do, I mean, it's the action of the game, right? Choice of the protocol is the action of the game. It's not the messages I send in the protocol, the actions of the game. The protocol itself is the action of the game. So what the designer does is he chooses a protocol which in his mind, by knowing the utility of the adversary, that I'm going to say what it is in a minute. This is the best thing that he could do as far as he understands the utility against an attacker with such a utility. Now the attacker gets informed about the protocol and he's now challenged. How are you going to attack this protocol? What he does is he chooses a cryptographic adversary.
00:30:47.830 - 00:31:13.488, Speaker A: Once again, those here are not rational agents. It's a turing machine. So the choices, the strategies are attractive Turing machines. So he chooses an adversary that in his mind and knowing the protocol is the best possible way of attacking the designer. This protocol the designer chose, there is a very important asymmetry in this thing here. The designer needs to choose the protocol without knowing how it's going to be attacked. Otherwise it's trivial.
00:31:13.488 - 00:31:34.242, Speaker A: If I know exactly what the arduous is going to do, I can just do something to avoid it. So he needs to choose the protocol while thinking, what could it be that the adversary would do in every choice they have? And then the adversary gets to learn this protocol and decides to attack. It's the attacker. Sorry.
00:31:34.298 - 00:31:43.334, Speaker E: Yeah, don't understand. The adversary here is, I call it adversary.
00:31:43.374 - 00:31:46.990, Speaker A: Let's call this attacker and call the strategy adversary to get. To not get confused. Okay?
00:31:47.022 - 00:32:00.034, Speaker E: So if I'm a good mechanism designer, I can think of all the ways that my game can be attacked. I don't need for this to be interactive.
00:32:01.054 - 00:32:29.714, Speaker A: What's the interaction here? What do you mean? I mean, the point is that you want the attacker to attack the protocol that you have in mind, right? I don't want the. I don't want this guy to try to think what would be the. I want to give him an advantage, as much an advantage to the attacker as I can. So you could think of the attacker not knowing the protocol he's attacking. But that doesn't make sense because then he needs to try to guess. So what we do is we say, ok, let's get him the protocol. I give him the protocol, and now he needs to attack this protocol and maximize his utility.
00:32:29.794 - 00:32:35.964, Speaker E: Are you playing the game? And the attacker is now controlling some. So what?
00:32:36.304 - 00:32:59.688, Speaker A: No. So what happens in the end is that I will consider the execution of this protocol with this adversary. Those are not rational entities, right? It's standard MPC. Right? And in this execution, I'm going to define the utilities. Let's see this called metagame. Yeah. I mean, you can think of it as a metagame, right? It's a two agent game.
00:32:59.688 - 00:33:19.380, Speaker A: Instead of thinking that everyone is running a protocol, you're thinking of, let's design the best possible protocol we can get that defends rational attacks. And that's why we have, like, those guys, we have like the guy who's designing the best protocol he could and then this guy that gets the protocol and attacks it in the best way that he can restrict utility, maybe.
00:33:19.452 - 00:33:26.104, Speaker E: My question is, what does it mean in this meta level to attack a game? It's designing strategies for.
00:33:27.124 - 00:34:04.920, Speaker A: So the question is, this relates to exactly what the utilities are. The utilities define exactly the goals that the adversary wants to achieve. So you can think of it as the adversary attacks a protocol for voting, and he gets utility 100. If he manages to rig the voting towards some specific candidate, that's one possible attack. He gets utility 50 if he manages to learn your vote. You can define different utilities that correspond to what the adversary, what the attacker would want to achieve. And you can define those actually in the specification.
00:34:04.920 - 00:34:42.796, Speaker A: You need to care about the protocol. You can have your specification and say, this is what I want to get, and these are possible goals an attacker might have. Now you go to the designer and tell him, give me a protocol which performs best against anything that the adversary might choose. What about computational boundedness or not? Those objects are polynomial strategies. I mean, it depends if you want information security, this can be unbounded. But in standard cryptography, it's like those objects have standard restrictions. We have in NPC, if there are.
00:34:42.820 - 00:34:47.238, Speaker D: Information theoretic, this guy can run all of the things.
00:34:47.286 - 00:35:17.786, Speaker A: Yes. Oh, those guys. So the meta players, the players of the game are unbounded. And it's a very good question, what happens if they are not unbounded? I'm not entirely sure what the natural meaning of this is, but you can think of it as they're unbounded, so they're going to do the best they can. Actually, this game has a name in game theory. It's a very simple game, but it's, it's a very useful game. It's called the Stackliberg game, and it's been very extensively studied.
00:35:17.930 - 00:35:21.894, Speaker C: So the designer needs to know the attached utility function.
00:35:22.234 - 00:35:41.616, Speaker A: So in this version you can assume that the designer's utility, this is a zero sum game. The designer's utility is maximum the attacker. So what he's trying to do is he keep his protocol as unattackable as possible. So when the designer succeeds in end of his attack and gets utility, the designer loses the corresponding utility.
00:35:41.680 - 00:35:45.832, Speaker C: So the goal has to be clear up front whether the goal is to break consistency or to learn.
00:35:45.888 - 00:35:50.804, Speaker A: Yeah, it's in the utilities. The utilities exactly define the goals of the attacker and how important they are.
00:35:55.744 - 00:35:59.044, Speaker D: And the size of the other story. So on. Like is that part of the.
00:36:01.224 - 00:36:23.714, Speaker A: Its running time is polynomial. That's all you care about. Well, it's a ppt turing machine. I mean, it's really, what's the best adversary? Right? It might be that the best adversary that you can get, and we have examples, are not to corrupt everyone, might be to corrupt a majority. It's really, this guy gives a protocol, and this guy gets the best possible attack.
00:36:24.574 - 00:36:26.462, Speaker D: This utility is known in advance.
00:36:26.638 - 00:36:31.794, Speaker A: This utility is known in advance. Yeah. So this is a. Yeah.
00:36:32.144 - 00:36:41.244, Speaker C: Is there any concrete reason why we consider the game, as opposed to, say, the statement that there exists a protocol such as for any adversary?
00:36:41.984 - 00:37:05.724, Speaker A: It's not for any adversary. Right. It's for any adversary that maximizes utility. This is the key there, right. So you can think of what you're trying to do here is you're trying to find a subgame perfect equilibrium in this game, where subgame perfect is very, very trivial to define. Right. It's a two move game.
00:37:05.724 - 00:38:10.538, Speaker A: Or you can think of it as an optimization problem when it's zero sum. It's really an optimization problem because there is one, it's a standard to play a game, and there is one best protocol, of course. Right? Okay, so what are desirable properties that we want from the outcome of such a game? So it's really like being best response to the other party's action. So let me start with attackpay of security, because this is the kind of more natural notion. And a protocol will be said to be attackpay of secure if its best response to any adversary. And we can think of the class of adversaries being like, really any polynomial time adversary, and then it's the most generic thing. So you want attack web security is parameterized by a class of adversaries, and it gets better and better as a property, the wider this class of adversaries is.
00:38:10.538 - 00:38:44.454, Speaker A: But the important thing is that it's, the class of adversaries is from this set. It's a Turing machine from this set, for simplicity. For now, let's execute. Let's attack. Security says that the best thing that the adversary can do is play an adversary from here. Sorry, I started the optimality. So, attackgraph security for a class says that the best thing that the adversary can do is play an adversary for this class.
00:38:44.454 - 00:40:05.558, Speaker A: And what we want is this class to be as small as possible. Right? So the best thing that we could hope is that this class only has, like, honest behaviors. So if you think about what this means, that we have attack way of security with the class of honest behaviors, it's really a security definition for rational adversaries why? Because what this says is that when I play this protocol, the best thing that the adversary would do with these utilities is nothing. Hence the protocol will implement in specification, and therefore I have security against an adversary that tries to maximize his utility. So you can think of it as a natural version of security, and it's actually a simulation based version of security because of the way we define the framework for adversaries that try to maximize their utility. Now we can have like the symmetric property, which is we call attack wave of optimality, which says that the protocol is the best possible response to anything that the adversary might do. And of course you want, like, I mean, we restrict the class of protocols in this statement, and you would want this class to be as large as possible, right? So you want to say that the protocol is the best among these huge class of protocols that could be played.
00:40:05.558 - 00:40:52.674, Speaker A: If I restrict this to be a very stupid, simple protocol, then it's very simple to prove it. Are those definitions clear? So the more relevant for what we're going to do is this one here. All right, in the interest of time, I'm not going to go through this thing today. At least say the theory. So a thing that you can prove, the proof is actually rather simple. Reading the theory is more complicated. Okay, so one thing that you can prove is take an adversary that needs to pay proportionally to how many parties he corrupts, think of bribery attacks, and then assume that this guy doesn't really care about privacy.
00:40:52.674 - 00:41:19.078, Speaker A: I mean, he cares, but, you know, what he would really like to do is break correctness. In other words, what he gets by breaking privacy of honest parties is less than what he needs to pay for corrupting a majority. So privacy breaking correctness, he'd love to. He gets infinite utility, potentially. We don't even say what he gets. He can get whatever he wants. But breaking privacy is not that important.
00:41:19.078 - 00:42:03.238, Speaker A: Depending on the rule, then it's very easy to get a protocol which is attackpay of secure against an adversary and computes an arbitrary function. And the idea is, take a protocol which is secure against. So when we have less than half of the parties being corrupted, it gives us full security. And when more than half of the parties are corrupted, it still preserves its correctness. Such a protocol was designed by Yuval et al. And if you use this protocol, it's again a very simple exercise to see that the adversary is not going to do anything but stay honest. Why? There's two cases corrupt less than half or corrupt majority.
00:42:03.238 - 00:42:38.774, Speaker A: So if he corrupts less than half of the parties, then what happens? He will pay for the parties. He corrupts a negative utility from the payments that he does and he will get nothing. He won't get anything from breaking security because he can't break security by design. So less than half of the parties being corrupted means nothing is broken. So the other side just pays for corrupting. So in this case he's really better off not corrupting anyone. How about corrupting majority when he corrupts majority? Again, he pays for corrupting the majority.
00:42:38.774 - 00:43:08.334, Speaker A: And by design of the protocol, he can break privacy. He can learn things he's not supposed to, but the utility is such that breaking privacy is not really worth corrupting majority. So once again, he's not going to corrupt anyone, right? In this case he's better off not doing anything and getting payoff zero rather than negative. And of course, if we don't have utilities, we already discussed that, but this cannot be done.
00:43:13.594 - 00:43:17.146, Speaker D: So this is like these things where you break privacy for more than half.
00:43:17.250 - 00:43:30.694, Speaker A: Yeah. So this is, I mean, we use a protocol where you can, for more than half, you break privacy, but not correctness. That's the protocol we use. And with this protocol you can make sure that this guy doesn't corrupt anyone. So you're secure against the guy with his utilities.
00:43:31.894 - 00:44:02.422, Speaker E: So I may be jumping ahead a little bit, but one of the problems in modeling how much it costs to corrupt a party is that you can use it repeatedly. So if you use it to get, let's say one double spend, then maybe you get one unit of reward from it. You can decide your mechanism such that it will cost you more to corrupt 1.5 and to get one unit. But now in a blockchain setting, I can use it infinitely many times. How can you?
00:44:02.598 - 00:44:18.422, Speaker A: I'll describe what kind of tenants we're going to make in the blockchain setting. So this adversary is tuned, first of all to demonstrate the principle of RPD, and it's tuned to NPC. It's not the adversary. This is not an assumption I'm going to make for adversaries attacking blockchains in particular because privacy is.
00:44:18.558 - 00:44:30.820, Speaker E: So maybe the general question is forget blockchain, but repeatedly using the same protocol, whereas the cost that you pay to corrupt parties, you know, it's the same parties in rigor.
00:44:30.852 - 00:44:54.910, Speaker A: Yeah, if you, if you, if every time you break privacy, you get a little bit more, then of course this thing is not going to be. That. Is your point about the very same person participating multiple times in parliament and then they're kind of already side and you don't have to pay them again. But are there issues, the same progress on different parties?
00:44:54.942 - 00:44:55.670, Speaker D: That would be presumably.
00:44:55.742 - 00:45:03.222, Speaker E: Yeah, that makes sense. So that's exactly the question. But it makes no sense. Well, I mean, it makes sense.
00:45:03.278 - 00:45:51.420, Speaker A: You can think of pay per views, right? So if for example, you need to pay for their, you know, Amazon cloud time, then you can corrupt someone, but still you need to pay every time he plays, right? You can think of examples. I'm not, I'm not even trying to bind these to reality at this point. This is for demonstration. I'm going to bind it in a minute with blockchains. So some of the features that we have is, first of all, we have composition. So in any such solution, if you prove attackpay of security or optimality, and you have used trusted parties there, then you can use cryptographic implementations of those trusted parties. And this goes through, we have another type of composition which is not here, where you can actually use rational implementation, in our case, RPD, in our sense, RPD implementations of functionalities.
00:45:51.420 - 00:47:08.488, Speaker A: But you pay a multiplicative penalty in the utility of the adversary, that the adversary increases his utility multiplicatively. And, you know, with blockchains and cryptocurrencies, potentially you can actually use penalties to make sure that if the penalty is large enough, you will kind of break this issue of breaking a protocol, breaking a subroutine and losing utility so that you gain utility on the bigger. So there are one can think of ideas of this type? Well, there's a bunch of other like, kind of indicated results. I'm not going to go over there because I have very little time to go to the part which applies to blockchain. All right, so what I want to do next, as fast as I can, is discuss a natural model based on this RPD idea in which we can analyze the bitcoin backbone protocol. So what Rafael referred to as Nakamoto consensus. And I'm going to do it in the same model that GKL and PSs analyzed it, which is we have fixed difficulty and we're going to see what I find a very cute feature of both the framework and fix the.
00:47:08.488 - 00:47:17.684, Speaker A: Sorry, the word bitcoin is missing backbone. Sorry. Yeah, we should. It's not this backbone. Yeah, it's a bitcoin backbone. Yeah, you're right. Yeah.
00:47:17.684 - 00:47:51.094, Speaker A: All right, so we need to tune, apply this framework to bitcoin. So the first thing we need to do is say what this task is. Let's for now think of this task as a ledger like a bulletin board. There is a paper where we actually prove that bitcoin implements a version of a bulletin board. But let's for now think of it as a bulletin board. That's the first thing we need to do. The second thing that we need to do is define the utilities, which I'm going to do in a minute.
00:47:51.094 - 00:48:30.164, Speaker A: And the last thing that we need to do is zero sum in the bitcoin setting is a little bit flaky as an assumption, because what this says is that the designer gives to the honest miners a protocol to mine, and the only thing they care is that the attacker cannot attack it, cannot make money out of it. That's not reality in bitcoin. They care about making money. So the game is not really zero sum. Is that clear? Nothing like here, just syntactic. I'm saying that the task we apply, the framework, the task that we apply to is the task that bitcoin is supposed to get, namely implementing a ledger. And it's not a zero sum game.
00:48:30.164 - 00:49:12.144, Speaker A: So how are utilities defined? This is the most plain and intuitive utilities you can think of, at least. So there's three things that give you utility block rewards. And let's say it gives you brush like bitcoins. Every block that you mine, by you, I mean the corrupted or the honest part is mine gives them br, bitcoins. There's potentially transaction fees which vary with what the contents of the block. We call those TF bitcoins. And then there is hassling cost.
00:49:12.144 - 00:49:40.164, Speaker A: And I'm going to call it hc. And let's say the unit is kilowatts per hour. Now, the utility that I want is, I want to define the utility of the adversary as the expected rewards minus the expected costs. So the adversary mines, he pays for hashing, he pays electricity for hassing. But when he finds a block and posts it, he gets the reward for this block. If there are fees in this block, he gets the fees in this block too. That's the model.
00:49:40.164 - 00:49:55.904, Speaker A: Now, of course there is mismatch in units. So I'm going to have one more parameter, which is a translation of kilowatts per hour to bitcoins so that I can define this equation. All right? Yeah.
00:49:56.684 - 00:50:02.624, Speaker C: You're not considering that the adversary can potentially break his. What about these kinds of.
00:50:03.364 - 00:50:18.376, Speaker A: He doesn't get utility by doing that unless he makes money. That's my assumption. My assumption is that the adversary wants to make money. How does he make money? Block rewards and transaction fees. If by breaking consistency, that gives me block reward and transaction fees. He's going to do it.
00:50:18.480 - 00:50:19.456, Speaker D: Double spending.
00:50:19.600 - 00:50:20.644, Speaker C: Double spend.
00:50:21.744 - 00:50:31.136, Speaker A: That's, again, this is an analysis of the backbone protocol. Double spending is not in the backbone protocol. I'm analyzing the blockchain. So the contents of the blockchain are not transactions, they're strings.
00:50:31.240 - 00:50:51.304, Speaker B: Another way to say what Elaine is saying is like you have an assumption that those particular incentives are what payoffs the attacker can get. But there's other reasons why it can benefit. Like you can have a Goldfinger attack, you can have some payments from the chinese government.
00:50:51.684 - 00:51:08.124, Speaker A: Absolutely. Again, in this analysis, similarly, as it is done in the backbone paper, transactions are treated as strings. There's nothing, there's nothing in a transaction that carries value and affects utility. They're just strings.
00:51:10.424 - 00:51:17.080, Speaker B: The fact that you make a very logical assumption that those are the utilities of the attacker. But you can make other assumptions.
00:51:17.112 - 00:51:36.888, Speaker A: Of course. Of course, yeah. No, no, no, of course. And we're going to, I mean, I make a logical assumption and I match it with an assumption which makes life very easy and it shouldn't be done. Going to say what it is, like this non variable difficulty. So that's the essence of rational analysis.
00:51:36.936 - 00:51:37.192, Speaker D: Right.
00:51:37.248 - 00:51:39.936, Speaker A: So that's the essence of rational analysis.
00:51:40.000 - 00:51:43.032, Speaker D: Is that you think you know what's rational.
00:51:43.088 - 00:52:04.904, Speaker A: Right. Right. So I mean, the point is that you can analyze this thing with different utilities and you can see what utility assumption is, the one that makes it, for example, you know, attackable or not, instead of compatible and so on. I'm going to argue actually that with these utilities, bitcoin is incentive compatible, which is probably a statement that you haven't heard so far. Most works that I know say that it's done.
00:52:07.844 - 00:52:10.988, Speaker B: The assumption that the cost per kilowatt.
00:52:11.036 - 00:52:18.196, Speaker A: Cost per bitcoin is fixed. It's not fixed, it's parameterized by this thing. Just to translate. I'm going to make conditional statement based on CR.
00:52:18.340 - 00:52:19.460, Speaker B: So what is Cr?
00:52:19.652 - 00:52:23.266, Speaker A: Is the translation rate, the value of bitcoin, how many dollars bitcoin is to.
00:52:23.420 - 00:52:25.366, Speaker B: Yeah, but I think that still ignores.
00:52:25.390 - 00:52:26.830, Speaker A: An important fact, which is for example.
00:52:26.862 - 00:52:32.774, Speaker D: That the fewer the block rewards or the difficulty changes.
00:52:32.934 - 00:52:37.726, Speaker A: Right, I said again, fixed difficulty. Right, fixed difficulty. I'm ignoring variable difficulty.
00:52:37.870 - 00:52:41.446, Speaker B: But like, aren't there many attacks that, you know, like for example, pretend that.
00:52:41.550 - 00:52:44.318, Speaker A: They drop the honest party's blocks so.
00:52:44.406 - 00:52:46.394, Speaker D: There'S less blocks that are being produced.
00:52:46.894 - 00:52:57.008, Speaker A: I'm going to discuss those. I mean, again, the assumption is fixed difficulty, the same assumption that is used in all mainstream analysis, except you're not modeling here.
00:52:57.096 - 00:52:59.472, Speaker D: Selfish mining, right. So I don't care that other people.
00:52:59.568 - 00:53:08.736, Speaker A: It'S not that I'm not modeling it. Selfish mining is not enough, is not a strategy that the adversary is going to play. As I'm going to argue if the utility, yeah, you set utility such that.
00:53:08.760 - 00:53:10.168, Speaker D: I don't care about the fact that.
00:53:10.216 - 00:53:28.016, Speaker A: No, no, with these utilities, give me 1 second, I mean maybe like three minutes and you're going to see where service mining comes in the game. I'm not modeling away selfish mining by the utilities. These utilities are the ones that you need in selfish mining. You don't need more than those utilities in selfish mining. Actually, give me 1 second and it's going to come.
00:53:28.040 - 00:53:32.684, Speaker D: I think in selfish mining the way I gain is by causing you to lose.
00:53:33.624 - 00:54:00.482, Speaker A: Why do you gain? Why do you gain? It's not that you're nasty to me, the reason you gain is that by causing me to lose, to waste power, you change the difficulty and you gain more. Again, those are the utilities that you care about. I mean, unless you think of selfish miners as very nasty people that want to attack good guys, which I don't. I think of them as people that want to make more money than they should. These are the utilities that you should care. That's my claim.
00:54:00.658 - 00:54:10.174, Speaker C: What is the definition of utility? If there are two equal land sparks like you could execute the thing. If there are, in this case is utility zero for everyone or.
00:54:10.854 - 00:54:44.416, Speaker A: I understand what is the I execute the thing. Now comes the good part. So the way that we're going to assign utilities, and this, I don't have time to go into very much in detail, but what we prove is that without utilities at all, that's proved already in the ledger paper. Without utilities at all, the bitcoin protocol implements a ledger, and this ledger has a state. It has an explicit part that captures, you think of it as the largest common prefix.
00:54:44.520 - 00:54:47.488, Speaker C: It implements a ledger if there's honest majority.
00:54:47.616 - 00:55:11.860, Speaker A: Yeah, yes, yes, yes. But I'm going to use that ledger. This ledger is my goal. Now I don't have honest majority, but this ledger is my goal. And what I want to argue is that actually, yes, you're going to implement the ledger even with a rationale assumption. But this ledger, the cute thing that it has is it has a state. It has a concrete kind of table where you keep, it has a sequence of transactions, a sequence of blocks in a sense.
00:55:11.860 - 00:55:17.348, Speaker A: And when something gets into this sequence, it's never removed. And that's what carries rewards.
00:55:17.436 - 00:55:25.624, Speaker C: What is the utility if it doesn't implement the ledger. If there's a corrupt majority, it doesn't necessarily implement the ledger. And there has to be a utility for that too, right?
00:55:28.484 - 00:55:41.710, Speaker A: Yes. So you need to, I mean, you need to allow the ledger, you need to relax the ledger, you need to allow the adversary to break the ledger so that it can be implemented by a protocol with even forks and then argue that those things don't occur.
00:55:41.902 - 00:55:46.934, Speaker C: Is there a utility function for the police when there are forks? Like it's a tree, not a chain?
00:55:47.054 - 00:55:58.874, Speaker A: I mean, what would it mean that there's a utility? Does the adversary care creating forks? That's what you're asking me? And the answer is no. In this model, no, he doesn't care if he cares, only if creating forks give him money.
00:55:58.994 - 00:56:05.134, Speaker D: The whole idea of the selfish mining is that you create a kind of a micro fork. I mean, I don't see how this is captured here.
00:56:07.394 - 00:56:09.294, Speaker A: Okay, let me continue. You're gonna see, yeah.
00:56:11.394 - 00:56:17.410, Speaker B: Minor thing, but like, why, why are you using bitcoin as the unit of currency?
00:56:17.522 - 00:56:39.336, Speaker A: Oh, that's just like arbitrary. You can use whatever you want. You can use dollars, that doesn't matter. All that changes is just this translation. That doesn't matter. So the utility of the designer, we don't have time to discuss much about it. So what you can think about it is that the utility of the designer is similar.
00:56:39.336 - 00:57:01.116, Speaker A: So the honest guys also want to make money, but they, above all, want not to have a fork. So that's the asymmetry. So the adversary wants to make money. He doesn't care how the honest guys want to make money, but what they want the most is to make sure that they maintain a ledger. That's the honest guy's goal. This is the protocol's goal. Right.
00:57:01.116 - 00:57:56.912, Speaker A: So that's why we put it there as the honest guy's goal. So that's the dream scenario of a protocol designer who's trying to design a protocol of blockchain, is that this is a blockchain protocol, and if this happens, he wants to make money. All right, so I'm going to skip this thing and go directly to analysis. So it's easy to see that with these utilities, the protocol is attack peer secure. Again, what does it mean? Strongly attack peer security setting? It means that the adversary, the best, think of this statement as the best thing that the adversary can do is just play honestly. Bad rushing. So whenever he has, whenever he sees a message from an honest guy and he has one of his own, he can push his own before the honest guys and the claim is that this strategy is the best thing that the adversary can do so effectively.
00:57:56.912 - 00:58:08.724, Speaker A: Selfish mining. With these utilities, selfish mining is not an optimal strategy, but again, it's not the utilities that exclude it, it's the fixed difficulty that excludes it.
00:58:09.224 - 00:58:10.784, Speaker D: I can argue about it, but you.
00:58:10.864 - 00:58:12.008, Speaker A: If you look at the selfish mining.
00:58:12.056 - 00:58:16.136, Speaker D: In such a way that this restricted, not really.
00:58:16.160 - 00:58:52.890, Speaker A: If you look at the selfish mining paper, you'll see that it also only rewards in this way. Actually, it doesn't even consider fizzing most of the part, but it also only rewards by blocks, nothing else. The adversary is trying to maximize his block rewards. And by selfish mining, what he does is he makes sure that he gets more than his fair share because of the variable difficulty. And that's actually, this is exactly what this proof says. Right? So it is the case that this proof won't go through with variable difficulty. Why selfish mining? Why does it go with fixed difficulty? The reason is the following.
00:58:52.890 - 00:59:05.788, Speaker A: So first of all, this is a completely markov process, right? So the adversary mines, and the probability every time that he finds a solution is just defined by the fixed difficulty. Let's say it's p. I don't know.
00:59:05.836 - 00:59:14.420, Speaker C: If your model, that is infinitely many rewards, like if the total reward is bounded, and the adversary has more fraction and he gets more reward, right?
00:59:14.452 - 00:59:18.652, Speaker D: Yeah, that's what, so I don't understand.
00:59:18.708 - 00:59:20.308, Speaker C: Why this doesn't contradict itself.
00:59:20.396 - 00:59:27.404, Speaker A: There is bounded reward, right? So every block has a fixed reward, and you have fixed difficulty. Like, I mean, how can you make more money than there is in the system?
00:59:27.984 - 00:59:38.284, Speaker C: The total reward will be unbounded. Is that the model? But in bitcoin, there are 21 million bitcoins. The total reward is bounded.
00:59:38.704 - 00:59:40.128, Speaker A: Yep. Right.
00:59:40.176 - 00:59:44.080, Speaker D: So you don't care about your fraction in this model. You just care about how much you have.
00:59:44.152 - 00:59:44.648, Speaker A: Yeah.
00:59:44.776 - 00:59:46.296, Speaker C: It's unbounded. Total reward.
00:59:46.400 - 01:00:06.176, Speaker A: You don't care about, you care about making money. Right? So my adversary, he doesn't care. You know, my adversary knows that there's like 100 billion on the system in its steady state. He doesn't care about making, like, half of those. What he cares is just about making money while he mines. That's his utility. He wants to make money.
01:00:06.280 - 01:00:12.600, Speaker C: If the total supply is bounded and I can control more fraction, then I make more money rather than the selfish mining.
01:00:12.712 - 01:00:28.604, Speaker A: I mean, how can you, what do you mean control more fraction? You're fixing at the, at the set rate every time you're mining, your probability of getting a reward which is coming is p. That's it. Right. So every time you're mining, you get like a p probability of getting the reward.
01:00:28.684 - 01:00:36.356, Speaker C: So I guess that is assuming that the rewards will never be used up like there's always going to be rewards.
01:00:36.420 - 01:00:39.308, Speaker A: Yes. Yeah. This analysis assumes the rewards, I mean with fixed. Yeah, of course.
01:00:39.436 - 01:00:44.426, Speaker E: So the fixed difficulty is memoryless. Every block has the same difficulty.
01:00:44.450 - 01:00:46.506, Speaker A: That's essentially not the assumption.
01:00:46.570 - 01:00:47.282, Speaker C: By definition.
01:00:47.338 - 01:00:49.146, Speaker E: By assumption. The selfish money.
01:00:49.210 - 01:01:00.642, Speaker A: Yeah, that's what I'm saying. That's exactly what I'm saying. Just assume that there's, it's not the utilities, it's the fixed difficulty that does it. I agree. I'm not saying something different. No, I didn't.
01:01:00.778 - 01:01:04.234, Speaker D: Selfish mind then. Selfish mind is not the best response.
01:01:04.354 - 01:01:18.934, Speaker A: Yeah, yeah, but, but we don't argue that selfish minding is not response. We argue that playing the protocol is best responsible. So that's different. Right. I'm not excluding an attack, I'm just saying that there is no attack. We focus on selfish mining, but there is no other smart attack that you can play. That's what this is.
01:01:20.954 - 01:01:30.654, Speaker E: And you're also excluding mining gaps attacks because of the assumption that there's no transaction fee.
01:01:31.714 - 01:02:22.614, Speaker A: Transaction fees we have, like actually, I mean, I want get a chance to get there, but we do have transaction fees in a, I mean, you can have internal compatibility. I'm not going to. So we can, we can argue that this is a very natural statement which says that if the price of bitcoin is high enough, then not only the adversary doesn't want to attack it, but unless guys want to mine. That's very intuitive. And it's just making the mathematical statement of this very intuitive statement. And yeah, if you have, if you have fees, then we argue that under assumptions, right. That first of all, if the price is high enough and the adversary essentially would circulate any transaction that he gets to the network, then you can still prove that this thing is attackpro secure.
01:02:22.614 - 01:02:57.614, Speaker A: Actually, this thing, which I ran fast, is probably one of the very interesting statements, which is, I mean, as far as I know, this is the first result that kind of argues that bitcoin has some incentive compatibility property. And what is incentive compatibility for us? It's like if you assume that the honest parties want to make money, that's less than fairness, right? It's not. I want to make my fair share of money, but I want an average not to lose. I want to make money not to lose. I want to make money on average. If that's your goal, then you're going to play bitcoin, that's incentive compatibility.
01:02:59.834 - 01:03:05.154, Speaker D: I want to object to saying incentive compatibility because that kind of relates to factors that gain here.
01:03:05.274 - 01:03:10.534, Speaker A: There is a game where there's a metagame. It's a game, right? In this game you can define extend compatibility. You're right.
01:03:11.274 - 01:03:12.554, Speaker D: You have a metagame.
01:03:12.674 - 01:03:25.778, Speaker A: Yes. Yeah. I mean it's. I mean, we call it attack, attack pay. We call it attack payoff instead of compatibility for that exact reason. Yeah, yeah. It's attack payoff in the attack game, it's instead of compatible.
01:03:25.778 - 01:03:45.870, Speaker A: What this means is that the adversary is not willing to attack it. He's willing to play the honest strategy and the honest guys are willing to keep mining if the adversary doesn't attack it. That's what it says. I mean, this is the definition, right? I'm not saying, I'm saying that we. That's not exactly what I said. We redefined self compatibility in this framework. And this means that.
01:03:46.042 - 01:03:48.838, Speaker D: I'm saying there's a difference in saying bitcoin is a game as it's in.
01:03:48.846 - 01:04:19.574, Speaker A: A competitor, versus saying it's attack payoff is unequal. Let's call it attack payoff. Is it compatible? The same way we do here, and this means something different than there's an incentive to play. But no, the game. You can think of bitcoin as the miners are agents, they're players, and they play a game. What we do here is we think of bitcoin as a metagame. Right? We think of it as a game between an adversary, between an attacker and all the miners against all the attackers.
01:04:20.714 - 01:04:26.290, Speaker D: I think it's fixable. I think you can actually say something about the bitcoin game.
01:04:26.402 - 01:04:50.630, Speaker A: We do say something about the bitcoin game, but what we do is we consider all the miners as a pool rather than everyone individually. Actually, this is an incentive compatibility. This is the only. I'm not the only, but the main difference between incentive compatibility in the standard setting and our setting is that we consider everyone that mines as a pool and they prove something on some. That's the metagame. But this is the metagame. That's the definition of the metagame.
01:04:50.630 - 01:05:29.072, Speaker A: The honest guys have an incentive altogether and like a specific utility, their collective reward, and they try to maximize that. And what we argue is that those guys are going to play that compatibility. So yeah, it did have like a lot of material more like including like selfish mining. We discussed a lot of selfish mining, so I'm not going to go. So the idea is that if you think of what selfish mining does is like, I mean, Rafael already said something, right? So the adversary, when he finds a block, he's not announcing it immediately. Instead he waits to see what's going to happen. And in the meanwhile, he mines on his secret block.
01:05:29.072 - 01:05:45.532, Speaker A: When he sees a new block from honest guys, at that point he's like, oh, I'm going to be spoofed. Okay, let me announce my block. He's rustling. He puts kiss block on the blockchain and discards this. And he can extend the strategy, right? He can keep mining. I feel lucky. Maybe he gets two blocks.
01:05:45.532 - 01:06:23.588, Speaker A: And at the point where the honest guys are cutting up, at that point he announces and kills their blocks. What this thing does is effectively, I mean, if we don't consider the messages that are in this block as carrying utility, what this thing does is killing computing power from the system. That's what it does. And by killing computing power, the difficulty is going to drop and the adversary is going to make more money because he eventually might have precomputed blocks. That's my claim. So this kind of is, in my opinion a very nice way of seeing what selfish binding exactly does. It's not about different utilities, it's very simple utilities as well.
01:06:23.588 - 01:07:03.056, Speaker A: But there's a variable difficulty. That's why suddenly playing is not a dominant strategy. That's one way of saying it, right? And there is like follow ups by Elaine et al. There's a smarter strategy than the one I described called stubborn mining. You're not announced whenever you feel like threatened, but you play a more probabilistic game and you use also attacks of the network to get even more rewards, namely waste even more power of honest guys. One thing that I think I had some more stuff to say, but I want to close here with this slide. So there is a question.
01:07:03.056 - 01:08:00.026, Speaker A: So we have a lot of attacks on bitcoin and there is a main message of those attacks which say that bitcoin is not incentive compatible. All those attacks say that the adversary, so, not the adversary, rational miners should not mine. It's not in their best interest to mine. And yet they do. So there is a very natural question to ask, why do they do that? And if you think of many of those attacks which have block withholding, selfish mining and so on, they have a signature which you potentially will observe if it's repeated, it's not like it's been happening and we've no idea, most likely it hasn't been happening, right. And there's a very natural question why it's not happening. And you know, there is the kind of apocalyptic approach you can take, right, where you can say, no, reality is wrong, right? I know my math, I predicted that.
01:08:00.026 - 01:08:48.097, Speaker A: It's not rational to mine, they're not rational, right? So, or at least the rationale is going to change down the line. And you can take the cryptographic approach and say, ah, there's corrupted majorities, right? It's meaningless for them to even do anything. I mean, this is the one I want to focus. Like there is a question, why would there be a majority? But the question I want to focus is this one here. In game theory, we make utilities that capture our assumptions about the world, right? We assume something is driving the party's decisions. And what happens, unlike in cryptography, where we make an assumption, we have an axiom which we believe, and then we prove things for that. And that's it, that's written in stone.
01:08:48.097 - 01:09:30.211, Speaker A: This is an assumption, right? So if we make an assumption, then we run an experiment, not me, we are cryptographers, we wouldn't think like that. But if a game theorist makes an assumption in 2014 about an experiment, runs the experiment for five years, and sees that what he predicted with this assumption is not what happens in the experiment, then the natural thing that he would say is probably my assumption were not the right one. No, I mean, it's a model, or model including utilities, for example. Yes. So probably my model was not the right one. So it's not. We should.
01:09:30.211 - 01:09:49.659, Speaker A: The message I want to make is that we should not take selfish mining religiously. So the way to view it, the way to view a rational prediction, which has been disqualified in practice for five years, is as a negative result. Probably I need to change something in the model. So this is kind of the fact.
01:09:49.691 - 01:10:07.799, Speaker C: That you are saying it hasn't happened. That's a very strong statement. Like there's no evidence that suggests it has not happened, especially now we have all these powerful relays that are important, you know, that are like super nodes in the network, and it becomes much easier now to like calculate the truth.
01:10:07.831 - 01:10:33.508, Speaker A: But the prediction, selfish mining had nothing about relay, selfish mining was about the original network, and in this original network didn't happen. Right? It's a fact. Maybe now the utilities change, I perfectly agree with you. Maybe now the situation in the network has changed and the utilities change, and maybe like in three years this is going to happen. But what I'm saying is that selfish mining made a prediction about the original network, no relays, it will not happen.
01:10:33.556 - 01:10:38.084, Speaker C: Because even if it has happened, it's very hard to detect, like, from the blockchain.
01:10:38.244 - 01:10:44.544, Speaker A: What do you mean? Right. I mean replacing. I mean replacing of three or four blocks.
01:10:45.894 - 01:10:48.834, Speaker C: It's not easy to detect, even if it.
01:10:49.734 - 01:10:59.374, Speaker A: No, but if you think of stuff, if you think of stubborn mining. Right. So you're potentially pushing two or three blocks and replacing, like a history of two or three blocks. This is an event which is observable and it's never been observed.
01:10:59.454 - 01:11:06.710, Speaker C: You and I mine a block close to each other, then the relay can prefer yours to mine, like, in a subtle way, and it's very hard to detect.
01:11:06.782 - 01:11:15.176, Speaker A: You're changing the game. Right. So the prediction was about bitcoin. If you thinking of bitcoin, that it hasn't happened. Yeah. Yeah. If you're thinking of bitcoin with relays, you're probably right, but you're changing the game.
01:11:15.176 - 01:11:33.536, Speaker A: The game that this was referring to was bitcoin. No relays, no light and heavy nodes. No, no. Like, it was a very simple predictive model which just assumed, like, a network. And what I'm saying is that in this simple predictive model, it seems that it doesn't happen. I don't even. I cannot certify that.
01:11:33.536 - 01:11:41.784, Speaker A: Right. I don't know that it doesn't happen. It seems that it doesn't. It didn't happen. Sorry. Thank you so much.

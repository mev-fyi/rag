00:00:00.200 - 00:00:21.994, Speaker A: My face, because there is a case that no one will see my face behind the mask. So, yeah, in the program I have a last name. Emmanuel Basilio. Dice caracoons. This is a typical problem that I have. My real name is Manolis. And my research interest lies on the intersection of theoretical computer science, game theory, machine learning and optimization.
00:00:21.994 - 00:00:56.518, Speaker A: Actually, just because we're in meeting conference, I decided to say, who am I? So, I was born in Athens. I did my undergrad studies in the only school that we're doing that stuff in NTUA. And right now I'm graduating from Columbia University. I can say that my dissertation is about noise in total search problems. But I decided a little bit to start with a story. I know that we have shared lots of stories today. And I want to do something more relaxing.
00:00:56.518 - 00:01:27.394, Speaker A: So I have a question for you. Do you believe that this is a real polyhedron? Hans, quickly, do you believe that this is real? Yes or no? Yeah, I have one. All the other believe that it is not real. Okay, so, in geometry, Johnson Norman Johnson in 1966 proposed the following construction. He said, okay, I will call Johnson polyhedron. To be a strictly complex polyhedron. Where each space would include only regular polygons.
00:01:27.394 - 00:02:08.494, Speaker A: And actually he presents a list of 92 polygons. 92 polyhedrons that they cover this assumption. Plus all the ancient mathematician prisms that they cover also that assumption. Now again, I will ask that question. Is that the polyhedron, a real polyhedron, a real convex polyhedron? It seems so, right? The answer is no. Three years later. So mathematician proves that the list of Johnson with the 92 polygons was complete.
00:02:08.494 - 00:02:49.552, Speaker A: So that means that this structure cannot exist, which does not make sense, because the photo is real. So something has happened. And of course, the reality is that. Just to explain my motor juvenile. Here is the reality is that the theory speak always about worst case analysis. The worst case analysis here is that we have perfect guarantee, for example, about the measurements. But if I ask you, and I challenge that with probability one, if you go at home and you do that experiment, you will, let's say with probability one to construct a polygon, for example with hexagons and pentagons, that it is forbidden by proof.
00:02:49.552 - 00:03:28.374, Speaker A: And the reason is the near misses that we have in the measurements. So this is my question in my research. So that is the way that I started working in local optimization. And actually my first work was about the smooth complexity. A way to go beyond the worst case analysis. Typically, for the majority problems that we have in local optimization, they are np hard, pls, complete exponential work guarantees, so no one would like to solve them. But there are prominent solutions that they are actually local heuristics, and there are ways in theory, to prove that they are really good enough.
00:03:28.374 - 00:04:24.526, Speaker A: Actually, if you think about it, in the previous century we are applying, from the previous century until now, we're applying just one algorithm, that is a local search method, and we call it gradient descent. And this is my first paper. I think as a PhD, we proved that even without gradients, if the stuff are really smooth, you can avoid certain points and have some good local solution. But if we ask ourselves nowadays, I think in bokeh of learning games, we establish it really nicely with many different ways, that optimization is not something so simple. For example, we have to get into data that they are certain multiple different servers. We have to do some federated situation where we want to learn different stuff from different learners. And the bots in the warehouses have to connect each other very, very locally.
00:04:24.526 - 00:04:58.662, Speaker A: So actually, this is the whole point of my research, that is what we are doing today, that is, that hopefully we will do in the future. And yes, I think that it is ubiquitous that games exist totally in optimization, in many different fields. So yeah, in the majority of the problems that I have worked was about the min max optimization, and especially how we use them for typical tricks that we have for the generative adversarial networks.
00:04:58.798 - 00:05:02.046, Speaker B: Where I try to prove, again, like.
00:05:02.150 - 00:06:07.168, Speaker A: What I said, I want to make. I'm trying to meet you, I'm trying to, to say what I am interested in, and this is what I am interested in, to understand mathematically, what are the phenomenons that I see. So if I see the cycles, I want to be able to prove the cycles. This is one of these two works, aim exactly on that, to understand different kind of models of non convex, non concave optimization, that they are applied in practice, like in gans, to prove that we have such kind of phenomena. And after that, we started to discuss about the multi agency, I think, and when players are playing stuff like no regret dynamics, that many other speakers had discussed today. So I avoid the definitions and I just pass to the main message. So, the main message that we had in my, in our research, I think that you can see it very clearly in that picture, that typically, if you follow a no regret dynamics, this is a totally rational assumption.
00:06:07.168 - 00:06:49.368, Speaker A: What we have is convergence to strict equilibrium. But for a mixed NASA equilibrium, the only thing that we can do is to discover the face of the equilibrium. But what we cannot do is really to converge to that point. Now, I will hear the correct note that, look, we had invented some machinery to converge to that points with different dynamics, but all of them again breaks when. And this is also in some of our results. If you put some stochasticity inside. So all of these models, if the payoff that we are getting has again, some noise, they have this kind of all of them.
00:06:49.368 - 00:07:25.592, Speaker A: I mean, this is a bad word. The totality shouldn't be a word of a scientist, but you understand my meaning. The majority of them, they will behave like that. So, just to follow now, the abstract that I gave, something that made me really interested nowadays is what a model that we present with Ivan Spanayes and Hugo Janis. This is really inspired by what is happening in practice. We call them. There is, there is actually a long literature in that problem.
00:07:25.592 - 00:07:57.690, Speaker A: And it is one problem that I would like to work in Simons and we call them team games. So, to team games is the following. You have your players, you separate them into different teams, and every player has some actions. And now, how we will make econometrically the game to be two team game. The solution is easy. Every player that belongs in one team will share the same utility with the co members of the team.
00:07:57.802 - 00:07:59.746, Speaker B: Now, if you want to have two.
00:07:59.770 - 00:08:53.278, Speaker A: Team zero sum games, those utilities will sum up to zero. There are lots of different applications. I will stay in the second one, because PhI was my co author and my advisee in NTUA. Really like that. One example is actually all this Reddit Wall street short bidding that happened last year with GameStop, where you have two teams that they are trying to collaborate, but at the same time they have their own incentives to play differently. So that is the reason that we really would like to understand that kind of games. So the first question is, how hard is to compute a NASA equilibrium in a two tier zero sum game? The best answer that we had right now is that they are CL's.
00:08:53.278 - 00:09:46.004, Speaker A: Hard. And I put that because approximating an epsilon Nas equilibrium in a congestion game is a CL's. So what I found even more interesting about this kind of games is that all of the classical discretization that we know, like gradient descent, optimistic gradient descent, extra gradient, optimistic multiplicative updates, everything that we know, they actually cycle around in that phenomenon. So in order to solve that solution, we proposed a new method. It is a new method of discretization that actually was proposed by people that they are doing feedback control theory. Actually, we found out that there is a similar washout filter with the discretization scheme that we did. That is used in aviation for the natural movement.
00:09:46.004 - 00:10:20.260, Speaker A: So yeah, this is the method. But I don't want really to be more tiring than what I am right now. So we achieved to show some sufficient solutions. But we strongly believe that there is something more interesting in that kind of feedback control discretization that has not been yet utilized by the optimization people. And I would be really interested in looking on that. In general. This is my perspective, this is my research agenda.
00:10:20.260 - 00:11:11.654, Speaker A: I would like to be member of that kind of world where I'm trying to create theory about the real machine learning. I'm trying to not create theory that does not speak about what's happening in practice. And at the same time always remember that. And just for a thinking slide, another problem that is a very game theoretical problem that I am trying to solve is the following problem. It belongs to the tragedy of commons interpretation. So I'm trying to solve the reading group assignment. I want to incentivize the Simons participants with a mechanism without money to present some interesting work in our equilibrium and computational reading group every Tuesday eleven to.
00:11:11.654 - 00:11:21.734, Speaker A: I always make a mistake about the noon if it is Am or PM. But you got my point. You're really invited to come. Thank you very much.
00:11:30.454 - 00:11:42.594, Speaker B: Could you comment a bit on the Cl's completenesses? Oh, yeah, yeah, yeah, yeah. Sorry, can you repeat? What is the result?
00:11:43.134 - 00:11:45.014, Speaker A: What is the result that we have?
00:11:45.174 - 00:12:08.364, Speaker B: Okay. What we can really prove is actually that it will give us the potential. You can put it. If I have the potential of the. Yeah, I have to clarify that we have not achieved to find the membership of the problem. We will have only the hardest of the problem. So yeah, I should clarify.
00:12:08.364 - 00:12:29.930, Speaker B: Thank you for the question. So the only thing that we can say is that if you give me a potential gain, then I can put the potential function in the utility. I can create a dummy reduction, I can create a dummy team game. And the result, it is Cardinal said.
00:12:30.002 - 00:12:32.170, Speaker A: The result of the team zero sum.
00:12:32.202 - 00:13:00.166, Speaker B: Game will give me the epsilon mixed nasal of that problem. But I was trying to ask also you what we can show about to understand a little bit the membership of that kind of problem. Yeah, thank you for the question. So that's problems. This is correct. This is correct. There is one gap.
00:13:00.166 - 00:13:56.404, Speaker B: There is a paper from Vazirani and Suman that proves that actually different asymptotics about that. So in that case, what is the meaningful equilibrium? This is a very good question. The reason that we decided to track NASA equilibria is that for all the other cases, there are actually results that they say that they are intractable under some complexity sense. So that is the reason that, first of all, I said, okay, let's look on that. Of course, always there is like the min max where I will look only one thing, but I felt that this is an unfair situation. I try to be like fair in both of the two things and understand an equilibrium that would be fair to that. Yeah, there is an interesting question that also we're trying to address a little bit with Johannes.
00:13:56.404 - 00:14:17.124, Speaker B: If there is no dual gap, in that case, if I come structurally and I have the only assumption that there is no dual gap, can we prove that at that case, we will discover NASA equilibria? This is not clear in comparison with the classical two player zero sum game, but it would be interesting to.
00:14:19.184 - 00:14:19.616, Speaker A: Discuss.
00:14:19.680 - 00:14:23.224, Speaker B: About that and see what is happening. Thank you very, very much.

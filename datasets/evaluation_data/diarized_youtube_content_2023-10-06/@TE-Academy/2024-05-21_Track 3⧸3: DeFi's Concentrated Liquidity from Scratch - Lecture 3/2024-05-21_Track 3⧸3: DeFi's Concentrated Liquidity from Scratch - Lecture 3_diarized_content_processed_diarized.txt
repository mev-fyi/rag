00:00:07.840 - 00:00:59.534, Speaker A: Okay. Hello again, everyone, to the next session at the Tea Academy study season. We meet again today with Mark Richardson to discuss Defi's concentrated liquidity from scratch. It's the third session in this series of lectures. In case you are following us and watching us on twitter or on YouTube, you can register to the study season via tokenengineering.net to have full access to all the material, to all recordings, and to have the chance to receive a proof of knowledge after participating in this session in Mark's program or in any of the other live tracks. Before we start here, I'd like to make you aware of the EFCC ticket giveaway that we are currently running.
00:00:59.534 - 00:01:51.270, Speaker A: You probably know that we are curating a full day of token engineering talks at the EFCC in Brussels this year on July 10. Mark your calendar. It will be a great opportunity to meet the token engineering community, to meet researchers and the space practitioners in the space, and it's hard to get tickets. Actually, they are sold out within minutes and the last ticket sale round is going to take place in the next days. We've secured five tickets for our students and we give them away based on spreading the word. To subscribe for our newsletter, token engineering reads. This is a bi weekly newsletter with the latest and greatest in token engineering research, case studies, exciting developments in the space, links to the latest papers and so on.
00:01:51.270 - 00:02:13.074, Speaker A: And yeah, let your friends know to subscribe free subscriptions and you have the chance to win a free ticket worth â‚¬500. Okay, that's it from my side. I'm excited to kick off the session again. Thanks Mark for joining us today and I hand over to you.
00:02:13.734 - 00:02:20.434, Speaker B: Thank you very much. I'm going to share my screen right now. Let me know when it comes up.
00:02:24.694 - 00:02:28.694, Speaker A: Yeah, we have it. Yeah, perfect, perfect.
00:02:28.774 - 00:03:47.254, Speaker B: Okay, good. Happy to report that a lot more people have been handing in the homework as we've been going on. I've been adding what I can to that GitHub repo just so that everyone can access it there again, I think it's a really great exercise to see how other people approach things, and it doesn't look like anyone is plagiarizing each other, which is good. I got a lot of really nice handwritten proofs for the exercise from last week and it looks like a lot of you have started to learn to plot some of the things that we've been doing, which is great. We've got just one last loose end, I think, to tie up on sort of the general theory side of things before we start to discuss the more nuanced aspects to this lecture series, which will include things like implementation and system design considerations and things like that. And we're going to touch on that today when we start to examine the uniswap v three invariant. And we will continue with that discussion into lecture four when we start to talk about carbon dfis invariant.
00:03:47.254 - 00:04:39.920, Speaker B: And then we're going to return briefly to the general theory once more to round out the lecture series in lecture five. Okay. I wanted to open the floor, though, for a general discussion to address any concerns that anyone has had up until now with respect to anything that we've already covered. The reason I'm asking is because the homework assignment, again today will continue to build on some of the stuff that you've already done. And so, if you haven't managed to complete some of this work, I would like to invite anyone who has that concern to speak now. Or we can. You know, or we can move on with the.
00:04:39.920 - 00:04:47.432, Speaker B: With the lecture as planned. Is. Angela, can you let me know if anyone's got their hand up or. Yeah, I can't.
00:04:47.488 - 00:04:53.924, Speaker A: This is your chance, guys. Raise your hand, switch on your mic, drop a note in the chat so that we can go over your questions.
00:04:54.744 - 00:05:15.716, Speaker B: Be reminded, as well, that I'm fairly active on the discord, and people are asking some really great questions there. And some of it is very closely related to the lecture material. Some of it isn't. And that's okay. I don't mind going. I don't mind doing things that way. But if you want something that's more focused and you've got stage fright or something, you don't want to discuss it.
00:05:15.716 - 00:06:20.086, Speaker B: Now, you can always reach me in the discord, and we can organize an office hours like we did last week, to go over some of these other points. Okay? So, the one loose end that we need to cover is this idea of the asymptote, which is a geometric term that is a very useful or unambiguous way to characterize the curves that we have been plotting. And it's come up now a couple of times that it's on. People are uncertain what the nature of it is or its significance, which is fine, because I haven't yet explained it. And we're going to discuss it right now. And we're going to take a bit of a journey into some other resources that I want you guys to know about that may actually help with your understanding and your learning. So, this curve has really been the focus of our study up until now.
00:06:20.086 - 00:07:33.904, Speaker B: And we call this a rectangular hyperbola. And I'll come back to why a rectangular hyperbola is different from, from other hyperbolas in just a minute. Um, but you should be pretty confident now that this has the general form of x times y is equal to some constant. Um, note that with both our reference curve and the virtual curve, they are defined exactly the same way. So even though the x and y coordinates in the virtual case have the subscript v, which is just to help remind us that these are virtual token balances and not real token balances, it's still the same equation. And so with respect to the curve that we've drawn on this slide already, we cannot actually tell whether or not this is the reference curve or the virtual curve without someone telling us which one it is because they have exactly the same, this is exactly the same shape. And while, you know, if this was the virtual curve, it would imply the existence of a smaller, or, you know, a more violent, you know, rectangular hyperbola closer to the origin.
00:07:33.904 - 00:08:41.034, Speaker B: It doesn't necessarily mean that one should be drawn. And similarly, if this was the reference curve where we were to designate this as the reference curve, as the, you know, in the context of discussing concentrated liquidity, it would suggest that the existence of a larger, more gentle curve somewhere else on this cartesian plane, that again doesn't necessarily mean that one has to be drawn. So this is just a general mathematical object that x times y equals some constant, and this is the type of shape that it draws so very, very quickly. Just substitute that constant term for some number, any number you like, something like twelve. We can substitute x for any number now and we can calculate what y would be. So for example, if we substitute x for three, then it's fairly easy to demonstrate that y must be equal to four in order for this predicate to remain true. Now we can substitute, I mean, almost any number, um, but not the number zero.
00:08:41.034 - 00:09:27.524, Speaker B: So if we substitute x for zero, now this equation has no solutions. And it's because if you, uh, if you rearrange it to make y the subject, you get the undefined term twelve divided by zero. And you know, you might have the, um, the instinct that, well, isn't that just infinity? Um, and that there are many good reasons why it's, it's not equal to infinity. You could make the case that it approaches infinity from like the positive side. Um, but as you know, we were going through in discord, this equation is also perfectly solvable for negative numbers. So if you put, you know, x is equal to negative three in there then y would be equal to negative four. And if you approach x equals zero from the other side.
00:09:27.524 - 00:10:05.372, Speaker B: So from the negative numbers moving closer to zero, you'll actually get negative infinity. So that divided by zero term, it really, it doesn't converge. It has no answer. And that is why we call this vertical line here at x equals zero an asymptote. Right. It is a very special line on the cartesian plane where our equation does not have a solution. Okay, what about for the y coordinate? Well, it's exactly the same thing.
00:10:05.372 - 00:10:45.314, Speaker B: Substitute y for zero and then try to solve for x. We also end up with this undefined term. And so y at zero is also an asymptote. Now, this is, you know, maybe very familiar because of the way that we've been setting up these curves until now, that we maybe just take it for granted that the hyperbola never quite touches the X or the Y axis. But that doesn't necessarily always need to be true. I have another program that I would like to show you. I've demonstrated this for some people before.
00:10:45.314 - 00:10:49.662, Speaker B: Angela, can you just confirm for me that you can see a blue grid on the screen?
00:10:49.718 - 00:10:51.274, Speaker A: Yes, we can.
00:10:51.854 - 00:11:32.414, Speaker B: Okay, perfect. I've stolen this software. Well, it's not stolen. I mean, I downloaded it from GitHub. I didn't create this, and I will put the attribution in the discord, but this is made by a game developer who is solving problems in hyperbolic space in order to make games with some very interesting geometry. And what this program is designed to demonstrate, among other things, is that you can uniquely define any quadratic with five points. So there are three types of quadratic equation.
00:11:32.414 - 00:12:28.964, Speaker B: One is an ellipse, and a circle, you could say, is a very special kind of ellipse. Another one is a parabola, which I suppose would look something like, let's try pull this in. There we are. So this would be a parabola, and then the other one is a hyperbola. And so you can see that we can draw any number of different quadratic curves on this plane just by moving these, by moving these points around. Now, the point that I'm making here is that, well, there's actually lots of different kinds of shapes of hyperbola. You've got ones that seem to have a, a line that's not at the x equals zero or y equals zero, defining their asymptote.
00:12:28.964 - 00:13:35.104, Speaker B: And this is totally normal. It's actually a very special case that you've got the asymptotes or these lines that the curve approaches but never touches being perpendicular to each other, that very special case where you actually do have a completely vertical and a completely horizontal, horizontal, or any rotation thereof, as long as the asymptotes are meeting at a right angle. You call this a rectangular hyperbola. And that is the object that we are studying. And the point that I'm making here is that the asymptote, this thing that the curve doesn't touch, it is a geometrically well defined concept and it has no ambiguity. And you'll notice here as well on this plane that there is no, like y or x axis, right. The coordinates of this thing are unknown, which is fine because we're still drawing a hyperbola, but we don't necessarily know where it is relative to the origin of this plane or even if this plane has an explicit origin.
00:13:35.104 - 00:14:32.814, Speaker B: The reason I bring that up is that you may not realize it yet, but we've already started to move our hyperbolas around arbitrarily on the plane in order to create some of the equations that we've been using. So I will now come back to the presentation. Okay, so here, this is our x times y equals to some constant. This is the curve that we've been studying for a while. But as soon as we move it down like this, that equation is no longer true. And we know it's not true because we've already defined terms like the x and y intercept at zero, at y equals zero, and at x equals zero. And that means that, well, that equation is no longer true.
00:14:32.814 - 00:15:45.212, Speaker B: And the equation that describes it now is actually just this horizontally and vertically shifted version where we've augmented the x coordinate by adding some constant to it. The same for the y coordinate, which causes it to move around on the cartesian plane. And you can see that however we move it around, we get slightly different curve sections and different y intercepts and x intercepts and so on and so forth. Okay, so again, if you substitute x for zero, in this case, you can rearrange this equation and get a perfectly reasonable result. Right? Whatever that constant is divided by the horizontal shift component minus the vertical shift component is what y is equal to. So x at zero is not an asymptote. But what if we set x equal to negative h, the opposite, the negated version of the horizontal shift? So now we get negative h plus h, which means that we end up with y plus v is equal to some constant divided by zero, which is already undefined.
00:15:45.212 - 00:17:09.154, Speaker B: And so this is how we define, or this is how we find the asymptotes of our curve. And it is a geometric characteristic of the functions that we're playing with. And so it makes sense to characterize them via these terms. Whereas something like a horizontal shift component, while it makes sense in the context of concentrated liquidity and a reference curve and a virtual curve and so on, if you were to look at that curve out of context, right, and, you know, try and write it down or communicate it to someone without having, you know, gone through all of this process of explaining to them that we've amplified something by multiplying by some constant and then moved it around, you just realize that the horizontal shift component is a very, it's a weird way to express what should be a very, you know, easy, like a very concise, you know, a very concise parameter of the curve. And so rather than call them the horizontal and vertical shift components, we actually just say what the asymptotes are. And because we know what the asymptotes are, it's very easy to work out what those horizontal and vertical shift components are. Now that we've worked out that there is an asymptote at negative h, where is it? On our plane.
00:17:09.154 - 00:18:07.194, Speaker B: So to show you this, I'm actually going to show you a little bit of how I animate some of these slides. But you can see that what I've got here is essentially a copy of the plane that we started with, with the curve, drawn it, that I can move around independent to the grid that was already there. And then I just block everything else out with black, with black rectangles. And so this negative h component, it is how far I've moved the curve when I clicked on it on PowerPoint and moved it relative to the background. And it's the same for the vertical component. So these horizontal and vertical shifts, they're negative forms are necessarily equal to the, um, to the asymptotes. This is, I think that the best way to ensure it your way as to where the asymptotes end up.
00:18:07.194 - 00:18:39.230, Speaker B: Okay, so I'm going to show you exactly what this looks like. So here is the slide. And I've got these, you know, black bars that are blocking everything out. And so I'm using the layers in PowerPoint to sort of obscure the things that I don't want you to see. Now if we have a look at the blue curve on the slide, I can move that just by clicking on it and dragging it. And this is what moves that part around. Maybe that's a revelation, I'm not sure.
00:18:39.230 - 00:19:41.428, Speaker B: But to actually see that the process of us transforming all of this math that we've done is literally just to describe this process of clicking on it with the mouse and dragging it over. All of the real invariant constants that we've introduced over time are just to explicitly describe this process of moving this thing around. Now, to make that, I think, a little bit more clear, or at least maybe let's say a little bit more robust, what I've done here is to create a, again, the same rectangular hyperbola that we've been studying. I'm just calling the invariant part c. And so I can change the size of the curve by moving the slider around. But then note, if I want to drag it down, I have to move the h value. Oh, sorry, that's the horizontal.
00:19:41.428 - 00:20:24.530, Speaker B: If I want to move it down, I need to move the vertical value to higher values. And if I zoom out, you'll see that it really is just moving up and down. Right. There's no special transformation happening here other than shifting this up and down. It would be the same as me dragging the plot up and down, except that when I drag the whole plot, I move all of the coordinate system with it, whereas by adjusting this parameter, I can move the curve with respect to the coordinate system. So the coordinate system is remaining exactly where it is. And that means that it's, you know, if I shift it over by, you know, 3.8
00:20:24.530 - 00:21:09.696, Speaker B: units, then what the asymptote that used to be at x equals zero has also been shifted by 3.8 units. And if I move it by, you know, 4.4 units down, then the horizontal asymptote that used to be at y equals zero is now shifted down by 4.4. And, yeah, I wanted to show you this because I think this is a really terrific resource for just exploring how these things work. You can even see what happens when you move to, like, negative constant values to see how the, you know, the curve behaves. But this is, I think, a really terrific place to begin if you are still struggling with, you know, creating some of these plots and other things.
00:21:09.696 - 00:22:31.054, Speaker B: I think that Desmos does a really terrific job of making this as accessible as possible. And being able to sort of move these things around is a little bit easier than creating a slider for yourself in excel or something like that. Okay, so to wrap up, there is a general mathematical description for this thing that we call the rectangular hyperbola, or at least the one that we are using, which is the x times y is equal to some constant. And the reason we're starting with this case is because it's in some sense, the canonical case. This is the simplest, the easiest to use. It also has the benefit of historically also being the one that was adopted largely by defi with Bancorp one and balancer, and Uniswap B one and Uniswap B two, and so on and so forth. So the only reason why this is the reference curve is because, with respect to using it, it's a convenient reference, because this is a very well behaved equation, but it's also a reference case with respect to where the technology began.
00:22:31.054 - 00:23:02.292, Speaker B: And so that is why we're starting here. We didn't need to. In an alternate universe, maybe we never would have created Bancorp v. One. We would have launched straight into concentrated liquidity style descriptions, in which case, I'm not sure if we would still use this as a reference or if we'd have to find another way to describe it. So I'm just pointing this out because it's not necessary to define concentrated liquidity in terms of unconcentrated liquidity. It can be standalone.
00:23:02.292 - 00:24:18.738, Speaker B: We are just trying to find a way to ensure it through it, and also, you know, maintain some of the historicity and provenance of how these concepts came to light. But they do work despite those things. So, beginning with that canonical case, we then introduce the amplification coefficient, which has the effect of just making the invariant a larger number. And so you can think of this as just introducing a new constant, right? And so I've just called it constant two here. And this would be our, you know, our virtual curve in, you know, in the cases that we've been studying up until now. But remember, when we are using the artificially amplified invariant, it means that the curve that we're trading on, the coordinates that it uses, no longer reflect the actual token balances. And so we're running into this problem that if there's a virtual curve and you're trading on it and it's reporting an x coordinate or something of, let's say, ten, that might not mean that it's actually got ten tokens left.
00:24:18.738 - 00:25:20.614, Speaker B: In fact, you don't really know how many tokens are left until you. You go back and query the contract in another way. The point is that a virtual cards is not the best one to trade on, because it doesn't do a good job of self reporting the token balances. You need to have some adjustment time in there. And so using this second invariant that I've put up here is problematic. What we do is we add the correction times directly into the invariant equation itself. We acknowledge that after amplifying the curve by introducing the second constant, that we can actually move the amplified curve around without touching the coordinate space that it lives in, such that when the real curve is reporting its x coordinate is equal to zero.
00:25:20.614 - 00:26:53.864, Speaker B: That means the token represented by the x coordinate is also equal to zero. And in fact, whatever the x coordinate is that's reported on this equation is equal to the token balance that it's supposed to be signaling. And so this is the progression. This real equation is the one where you get exactly the same trading rates. You get all of the same effects that you were trying to create from that amplification process, but without the drawback of having to add, you know, ad hoc some correction term so that the coordinates match up with the token balances, so that movement left and down right, literally adding in the horizontal and vertical shift components, is to make the coordinates correspond one to one with the token balances. And this is what we call the reference virtual and real curves, which also means that when it's written this way, that you can actually, if you can identify that there has been a horizontal or vertical shift component added to one of these invariants, then it's very easy to determine where the x asymptote and y asymptote is for that equation because it's always going to be equal to whatever that horizontal shift component. And, you know, vertical shift component is.
00:26:53.864 - 00:27:52.306, Speaker B: But just negate it, right, just multiplied by negative one. And so that is the x asym and y asym terms that I write about a lot in the textbook. Um, and these also have the curious property of when you take their quotient, it's also equal to y zero over x zero, which is equal to p zero y inter over x into the, um, geometric mean of the high and low price bounds. Now this kind of rounds out what I think are the, um, the, the most significant or the, um, the, the most intuitive, uh, parameterizations for this curve. Right, right. In terms of the amplification process or concentration process, depending on your perspective. And the things that punctuated on the cartesian plane are now beautifully presented, or they present themselves beautifully this way and also tell you about their relationships with respect to each other.
00:27:52.306 - 00:29:08.456, Speaker B: And so if you have just a handful of these things, then it's easy to deduce what the identities of the other variables that you might be lacking on. And it feels like a natural process for constructing this stuff, which is probably why it was the first example of the description of concentrated liquidity that we have with that part done, with the asymptotes now handled, we are actually finished with the general theory. And what I mean by that is, while we're still going to be doing some algebra on our slides, and we're still going to be, I'll still show you some of the important transformations and things in terms of actually understanding what concentrated liquidity is, why it exists, what its effects are. We're done. Even though we've still got two, you know, we've actually still got a lot more material to cover. We're really just going to be looking at exactly the same concepts from different view angles. So it's a good time.
00:29:08.456 - 00:29:49.590, Speaker B: And I've kept this lecture relatively short because I decided to. And, you know, we're not ending here. We've got a lot more to discuss today. But I'm not going to discuss as much today as I wanted to because I want. Because I wanted to put some of the material that was going to be discussed today in with the second lecture so that we can compare them sort of heads up, but also to give you another opportunity with the homework assignment today to actually wrestle with what the curve reparametrization is. So this is what we've done, right. And there's quite a lot here.
00:29:49.590 - 00:30:35.758, Speaker B: This is what we covered in the second lecture. And you can have a glance around this plot and remind yourself what each one of these things means. Right. We've got that blue rectangle is meant to be signaling the real curve with the tangent lines drawn on certain points and so on and so forth. And the specific coordinates that correspond to the various identities that we've deduced were all sort of annotated around this plot and are presented in more or less the same way that it's presented for you in the textbook. And so this is the Bancor version two, description of concentrated liquidity. And what we're going to be doing today is moving into the uniswap v three, description of concentrated liquidity.
00:30:35.758 - 00:31:23.224, Speaker B: And I hope that you'll see just in that transition, what I meant by we're kind of done with the general theory. Notice that pretty much everything stays where it is, right? Things change color. And some of the identities, or actually, all of the identities that are written around the edge of the plot are changing. But the actual mathematical and geometric object that we are describing has not changed. It's just the parameters that we use to describe it are changing or defined in a slightly different way. And then we're going to be repeating that process in the fourth lecture. And next week, when we come back and do exactly the same thing, have a look at then carbon D five's reparameterization of concentrated liquidity.
00:31:23.224 - 00:32:57.978, Speaker B: Now, it's all, I think it's, you know, it's trivial, I think, to look at an equation and say, look, I could write that a different way. Or, you know, have you considered, you know, parameterizing it using, you know, by substituting these variables for these other variables and so on? And I don't want anyone to think that there's, you know, something necessarily special or intrinsically better about any of these parameterizations. Some of them might be, like, easier to look at or have a more aesthetic appeal for different reasons, but that doesn't really matter because at the end of the day, we only really care about what we're trying to achieve on the smart contracts and how best to achieve that. And I think that the Uniswap v three example is a really, really nice one to look at, especially because it actually ties in very well with a question that we had from, from Thiago last week and which is going to become, you know, has formed the basis for the homework this week. Okay, so let's begin looking at the Uniswap v three re parameterization. Okay, so this is the equation that we've arrived at from the Bancor V two stuff that we've been discussing over the last couple of lectures. And I've just put down the p high and p low identities because we're going to need them for now.
00:32:57.978 - 00:34:39.934, Speaker B: And remember that the way that we arrived at these two identities was very, was very robust. Right? There's nothing, nothing was asserted without reason. The algebraic manipulations that we used, I think, were, were very rigorous. And I've also detailed, I think I provided sufficient detail in the textbook for you to be able to recreate those manipulations should you want to, on your own, improve these identities, because I do think that that's important. Okay, so the p high and p low, I'm asserting it here, but we did derive it properly previously, and this is essentially showing you that the price bounds are determined by, or can be calculated from the amplification coefficient and the geometric center of whichever part of the curve that you're trying to amplify. And this can be, you know, this can be manipulated to try and isolate a minus one, which is what I've highlighted here in orange and purple and also in the invariant function above. Now, the reason why we want to isolate that a minus one is because it will allow us to, inject the square root of p high and p low, which is, if you think about it, it's kind of the same as getting the price bounds themselves into the invariant equation itself.
00:34:39.934 - 00:35:37.224, Speaker B: So after we take the square roots, we can rearrange these things to isolate, isolate a minus one, which happens relatively easily in the first case. And for the second case, we just need to take a reciprocal afterwards. And so now we have two different descriptions for a minus one. And by the way, you can just test this. If you're on Excel and you've already created a plot or you're in Matplotlib or something, and you've already got some variables stored as attributes in a class or something for the plotting that you've been doing for homework, one of the things that you can just check is that after you calculate p high, you've already probably got the variables a and y zero and x zero are stored somewhere. Just try this calculation. Prove to yourself that a minus one really is equal to a divided by the square root of b high multiplied by the square root of y zero over x zero.
00:35:37.224 - 00:37:05.414, Speaker B: This is something that you can confirm, but this identity is true, and we can use it to substitute out that a minus one term. Now, it's important to look here that we aren't actually substituting everything in either the horizontal or vertical shift component, because the x zero and y zero part outside of the parentheses are actually still a part of that component. So it's not like a minus one is equal to the horizontal shift, because we would get two different answers and that would, you know, that wouldn't make much sense. But after substituting that a minus one in, we now get this invariant expression. And this is, you know, it looks a little bit cumbersome right now, and we can clean it up in just a minute. But just note that every time you do one of these substitutions, that expression that you get is now a totally legitimate reparametrization of the real curve, right? If as long as the substitutions that you're doing are carefully considered and you're, you know, you're not miss substituting something somewhere, then it should produce exactly the same curve that you had drawn previously. Okay, now the trick to the trick to this part, by the way, notice that the color coding here is not incidental.
00:37:05.414 - 00:38:37.274, Speaker B: We have two different definitions for a minus one, and of course they're going to be equal, right? These two things are equal to each other, and you can set those, you can actually set that equality if you like and see if you can work out other interesting ways to define a, for example, or something like that. But what I want you to notice is that with the a minus one term that is defined in terms of the square root of p high, we have a square root y zero on the top and a square root x zero on the bottom. Whereas for the purple term, the a minus one defined in terms of the square root of the low price, it has the reciprocal, right? It's got a square root x zero in the numerator and a square root y zero in the denominator. This is an important, it's important to set this up correctly, because when we substitute this into the general expression, we're trying not to add any additional variables. And we're also trying to make sure that we don't end up with something weird, like something raised to the power of three over two or something like that. And so the reason we do it in this order, the reason we're using this exact substitution pattern, is because we have this x zero term outside of the parentheses here. And so we're going to be using this explicitly to try and consolidate this x zero and that square root of x zero into a single square root of x zero.
00:38:37.274 - 00:39:48.514, Speaker B: And that's what I'm showing you on this slide, right? That x zero and the square root of x zero in the denominator over here and the y zero and the square root of y zero in the denominator over here are beautifully set up to collapse into a single square root. Right? And if, you know, if you haven't seen that before. Yeah, if you have anything, x divided by the square root of x is always the square root of x. It's obvious, I know, but you'd be amazed at how many people sort of have never realized that that's a totally legitimate way to simplify some of these variables down and not have sort of blown radicals floating around. And so after we do this, you will note that we actually have a fairly consistent term popping up all over the place now, which is this a times the square root of x zero times the square root of y zero. It appears both in the horizontal and vertical shift components, but it also appears in our, it also appears in our invariant. And so while we're here, maybe we should clean that up and just define a new variable.
00:39:48.514 - 00:41:02.424, Speaker B: So rather than have, rather than write this out so verbosely, let's just collapse it down into a single variable that we're going to call the letter l. And so then after you substitute those terms out for lift, you'll find that it actually cleans up very, very nicely. And we do end up with the now very familiar uniswap v three invariant that I hope that everyone in this course has at least seen before. But if you haven't, it's not a big deal. Just know that this was the real invariant equation that they wrote in their white paper and is the one that people generally refer to when they're talking about concentrated liquidity. Like it's one thing, but it's due to the popularization of this specific equation that's actually inspired me to write this course and make sure that people understand that there are many descriptions of concentrated liquidity, and they're all as good as each other, so long as you have a well motivated reason for wanting to adopt one of these reparametrizations over the other. So this is where we've ended up.
00:41:02.424 - 00:41:57.680, Speaker B: We have the description of concentrated liquidity by Bancor back in 2020 on the left, and then the description of concentrated liquidity by Uniswap v three in 2021 on the right. And you'll notice that there's going to be a couple of patterns. I hope that you'll start to notice when you parameterize one of these things really well, which is that there is a minimum number of variables in both the Bancor v two case and the UniswaP v three case. We have exactly three constants that we need in order to make this thing operate. You can think of that as being, you need to at least know the amplification and the horizontal and vertical shifts. That's three. But then, because you can start to blend some of these things together, because I'm sure there's some really good sort of information theory reason why.
00:41:57.680 - 00:42:57.656, Speaker B: But even when you're blending those theory, those variables together, you still need another variable or another constant to sort of tell you how they were blended together or something like that. But the point is, in the Bancor v two case, we have x zero, y zero, and a. Right, so x zero and y zero being the coordinates on the curve that we are trying to amplify, and then a being the rate or the. The magnitude of its amplification, whereas with uniswap e three, it's instead using l as kind of a generic size constant. Right, so it's similar to the amplification coefficient, but not quite. It kind of contains a different sense of scale, but kind of speaks to the same idea. And it also contains the p high and p low variables.
00:42:57.656 - 00:44:27.824, Speaker B: So rather than choosing a point on the curve to amplify the uniswap v three invariant instead tells you the edges of the curve of the part of the curve that have been amplified. And we'll explore that in the next slide in a little bit more detail. But this is the thing that I'm trying to leave up to you for your homework assignment, but never make the mistake of thinking, because these two equations look so different. And I'm going to show you even more equations that look very different to both of these, that they are referring to a different concept or a different mathematical object. They are redundant descriptions of exactly the same thing. Okay, so the question I have for you, and I'm hoping to get some crowd participation here, is, why should the invariant be re parameterized at all? Why go to this effort if there was already even an existing smart contract implementation of these formulas? Which isn't necessarily the easiest thing to do, by the way. Why would you go to the trouble of rewriting, refactorizing, and doing all this extra work to arrive at something that was, that, you know, is fundamentally no different? Is Thiago on the call with us?
00:44:29.364 - 00:44:30.076, Speaker C: Yeah.
00:44:30.220 - 00:44:32.548, Speaker A: Any thoughts? Yeah, go ahead, Thiago.
00:44:32.596 - 00:45:02.004, Speaker C: I think maybe you mentioned, like last session, that you, for example, use or withdraw the minus signal for better data management as it is a bit. For example, I would say that this function is the same algebraically, but I believe when you implement it in smart contracts, maybe you'll get more efficient results, and maybe around data storage. That would be my best bet.
00:45:03.264 - 00:45:33.064, Speaker B: Yeah, it's a very good guess. Would anyone else like to offer dissenting opinion or even a supporting opinion? Awkward silences don't work with me, by the way. I can let things. Let these things get excruciating. I want to hear at least one other person offer an idea. I can give it a shot. Give it a shot.
00:45:33.064 - 00:45:37.606, Speaker B: Maybe one party had a patent on.
00:45:37.630 - 00:45:39.886, Speaker C: The formulas and needed to find a.
00:45:39.910 - 00:46:42.694, Speaker B: Way to find the same utility, but not infringe on IP? Yeah, another super good suggestion. It's unclear in this case whether a reparametrization would be sufficient to get around something like an intellectual property claim. But, yeah, I think that's another really good suggestion. It could also be like, how about that? They just didn't know about it. Maybe they were so focused in what they were developing that they just weren't aware that something else had already been created that did the same thing. There's many, many possible reasons, and I can't put words in the developer's mouths, but I think Thiago's suggestion is the one that's very, very close to hitting the nail on the head. But it's not just about what's more efficient, because both of both of these expressions can be equally efficient, both in terms of memory and accuracy and everything else.
00:46:42.694 - 00:47:53.906, Speaker B: The difference is that in Bancor v two's case, it was developed for a very specific use case, and one that used a single liquidity pool. So rather than have users all taking different price points, the liquidity was combined, and the pool actually automated the rebalancing of its liquidity according to market dynamics. For anyone that's familiar with curve V two and how they have this buyback component, at the end of some epoch, it was very, very similar to that. It was discontinued because it was, you know, it didn't seem like it was going to be a good way for the industry to go. And it was, you know, more than a year later, or about a year later, that the uniswap V three came out and was implementing the same ideas. But instead of having a single pool that everyone contributes liquidity to, instead they implemented many pools. Now, you could still do that using the same invariant function.
00:47:53.906 - 00:48:57.932, Speaker B: So I'm going to show you where the perspective difference is between the Bancorp v two invariant and the uniswap v three invariant. And it can be, I have a helpful heuristic that I think you'll find useful. But before we get to the heuristic, I think we need to struggle a little bit with what it means geometrically. So, consider that this curve that we've drawn here, let's, let's call this the reference curve. It has an infinite number of prices on it, right? It enumerates prices from, you know, negative infinity all the way to zero, or, if you like, from zero to infinity, if we're, if we're negating the derivative. And so what you could do is say, well, we could actually slice the curve up into lots of little components where each reference coordinate. So, like, the x zero, y zero part defines which part of the curve that we are, that we're trying to emulate.
00:48:57.932 - 00:49:42.794, Speaker B: And then we'll create some amplification coefficient that then, you know, that then blows it up. And then that could be a discrete liquidity pool that, sure, it will eventually stop trading if prices move out of the price bounds, but then another liquidity pool on the other side of it could take over trading as the price moves into its range and so on. And so, essentially, taking up the. And this is like, this is what uniswap V three essentially does, is that they split up the reference curve into two to the. I think it's two to the 120. It's either. It's like, I think it's two to the 112.
00:49:42.794 - 00:50:40.876, Speaker B: I don't think it's quite two to the 256, but it's a very, very large number of discrete chunks of the reference curve that they. That they take out. Now, what I'm showing here is that if you were to do that using the Bancor V two invariant, the one that we've been studying, what you would be doing is essentially defining the center point of the part of the curve that you're amplifying, right? So you're defining with very, very high accuracy, with essentially arbitrary precision, to within the limits of the number of bits that you can store on ethereum. But you are defining it. It's hard coded in some respect. And that means that middle part of that segment represents the liquidity pool that's going to be created. But that means that the border between each of those liquidity pools is going to be calculated.
00:50:40.876 - 00:51:44.220, Speaker B: And remember, whenever you hear the word calculated, I want you to think approximated. Right. There is no, you can calculate these things symbolically. You can show that these boundaries exist and that they can be infinitely precise symbolically. But as soon as there's a computer involved, there is going to be some precision loss and some accuracy issues that have to be with. And so if you're trying to get all of these liquidity pools flush with each other at their price boundaries, then wouldn't it be better to define the price boundaries? And then you don't necessarily need to care about where the geometric center of the pool is. So this is what uniswap v three does, right? This is its, this is its difference in perspective compared to bancorp v two is that instead of defining where the middle of the pool is, it defines where the boundaries are, where the edges are in terms of the.
00:51:44.220 - 00:52:46.022, Speaker B: In terms of p high and p low. And this means that the geometric centers are now need to be calculated. But maybe you don't need that information. If your system is architected to have a very large number of liquidity pools adjacent to each other, and that as one is depleted of one token balance, the next one along the chain takes over, then it's much more important to know where the price boundaries are than it is the middle of the curve. One way that, and this is the heuristic that I promised you, is that the top invariant, the one that uses x zero, y zero, and a, it is analyzing the space between the fence posts between these cutoff points. And while it's in that space, it's absolutely very efficient. And like I said, there were other bells and whistles on top of Bancorp two that actually required that parameter space to be extremely accurate.
00:52:46.022 - 00:53:40.238, Speaker B: And so to have these constants readily available in the smart contracts is, with respect to that system design, the right way to do it. But if you are doing this contiguous liquidity pool design, whereas trading on one liquidity pool ends, it picks up on another liquidity pool, then you don't really care about the space in the middle. What you care about is the boundaries on either side. And so this is why having that new invariant matters. Like, can you achieve this using the other invariant? Sure, but you shouldn't uniswap V three's parameterization of its curve. The reason why this equation matters is because it is the right equation for the system that was built from it. Right.
00:53:40.238 - 00:55:27.826, Speaker B: And this is what I think is, is sort of lacking in the developer community at the moment, is that it is absolutely important to go back into the math and redefine these equations to suit the system that you're building. Because if you're using someone else's parameterization, it's like wearing a shoe that doesn't quite fit properly. Right? It's, if it's ill, if it, if you are setting up a system that doesn't have the exact system requirements, or it doesn't have the same product spec and the same architecture as Uniswap V three's invariant was built for, then probably you should think about what your own product spec is and build an invariant that better reflects that purpose. But I think that this fence posts and the gap between the fence posts heuristic is a good one. And I, you know, there may be some people that don't quite understand what I, what I mean here, but this also is kind of a different, is called, excuse me, is kind of a reflection on also, like, different indexing methods in like, programming languages. So often you'll have like a programming language that indexes from zero, where like the 0th element in the array is the first one is because you start counting at the post, not the gap between, whereas other indexing systems will start at one, meaning that it actually is looking at the space after the first bit in memory and so on. And so this is a little bit more abstract than that, but it still has that same sort of feel to it, where it's like, are you paying attention to the part in the middle, or are you mostly paying attention to the parts at the end.
00:55:27.826 - 00:56:49.524, Speaker B: Is it the bookends that you're interested in or the book in the middle? Okay, yeah, so what? So this is your homework for this week, and we're coming up on the hour, so that's good. I wanted this to be a shorter lecture than neutral, but pay attention, because I want to make sure that I've made this explicitly clear. I want you to create two systems, each comprising two discrete, concentrated liquidity pools. Okay, so this is, you know, if you're doing this in excel, this is probably going to be, you know, two different tabs, right? And each tab will have two liquidity pools on it. The important thing is that the p low boundary of the first pool, let's call that p low one, must be equal to the p high boundary of the second pool. Let's call that p high two. And that means that these two pools are going to be contiguous with each other with respect to this common price boundary, meaning that if they both have, you know, if you adjust the token balances in those two pools correctly, you should be able to trade across both of them as if they were one pool with one p high and one p low boundary.
00:56:49.524 - 00:57:50.364, Speaker B: In the first system, I want you to try and implement this using just the constants. X zero, y zero, and a. Meaning. When you've got that on your spreadsheet or when I see it in your class, when you hand it over to me, I don't want to see that system. Even referring to things like p high or plastic. The only variables that it is allowed to know about is x zero, y zero, and a. And I think already you may start feeling like this is actually a little bit more challenging than usual, because, sure, like, you can have a, you know, you can have another cell or something that, like, that calculates, you know, p high in situ meaning takes something like, you know, y zero times two, a minus one over a minus one to, or, sorry, y zero over x zero times a squared over a minus one squared.
00:57:50.364 - 00:58:31.884, Speaker B: And that will give you the p high. But when you give it to me, I don't want to see it in that cell, right. I need whatever cell that's referencing that to create it intrinsically within itself, right. To actually calculate it on the flag. And this will give you the feeling of what it's like to code a smart contract where you can't just have all of this stuff sitting around in memory all the time. You need to perform the calculation as quickly and efficiently as possible, and then it needs to forget it straight away. Then in the second system, you can use only the square root of p high and the square root of p low and l, and you will have access to no other variables.
00:58:31.884 - 00:59:30.254, Speaker B: And this will, I think, well, this exercise is designed, um, to bring in a little bit more of that engineering flavor, um, into this course. Right? This is, after all, the token engineering academy. And engineering is not mathematics. And most of what we've been studying up until this point is mathematics, but now we're actually applying it. And I think one of the things that characterizes engineering is having to work within sometimes ridiculous constraints. And so this is the constraints that I've given you, right? You have only these three variables, and you have to make the system work. And what you should find is that because of this requirement, to have two contiguous liquidity pools be traded smoothly as one crosses, as a trader crosses the border between them, you should find it's actually easier to implement it using p high, p low, and l, and it's more difficult to implement it using x zero, y zero, and a.
00:59:30.254 - 01:00:15.274, Speaker B: If I didn't make that perfectly clear, and this is a very quick graphic that's supposed to at least help communicate what it is I'm expecting. So that here are two different liquidity pools. They will have their own token balances and so on. And the price boundaries of this first liquidity pool are p high one and p low one. And the price boundaries of the second liquidity pool are PI two and p two. But p low one and p high two are one in the same number. And so this means that you can trade all the tokens out of this pool, which is fine, but then move into the next pool and continue trading relatively seamlessly.
01:00:15.274 - 01:00:41.480, Speaker B: Okay, that's it for lecture three. Short one for the. Let's call this the, you know, the. The slump in the middle of the lecture series. We've still got two more to go. The lectures four and five, I think, will be a little bit longer than this, but I'm going to try and not take up all of the 90 minutes as I usually do, because I know that it can get exhausting. Yeah.
01:00:41.480 - 01:01:00.760, Speaker B: As usual, feel free to contact me via any of these channels. I'm always active on Discord, and if you want to do some office hours to discuss literally anything from the course up until this point. And as Thiago and I are demonstrating, also some things outside of the scope of the course, I don't mind discussing either. This is the end of lecture three.
01:01:00.952 - 01:01:14.764, Speaker A: Thanks, Mark, so much. Do we have time for some questions? I see some answer rates. CJ, do you still want to raise your question, or is it already answered?
01:01:15.344 - 01:01:37.864, Speaker B: Yeah, the homework actually clarified. I wanted to confirm whether it was possible to have a continuous trading when pools are kind of having boundaries. But the homework clarifies that that is possible. So I think that's okay. Perfect.
01:01:39.204 - 01:01:42.184, Speaker A: And we have a second hand raised by thiago.
01:01:44.444 - 01:01:51.850, Speaker C: I just wanted to clarify. So what you want is a real curve for both banker and unisol, right?
01:01:52.042 - 01:01:59.618, Speaker B: Just a real. Yeah, let's just. Let's just call them, like, you know, let's just call them x. The x zero, y zero, and a function.
01:01:59.666 - 01:02:00.010, Speaker C: Yeah.
01:02:00.082 - 01:02:16.122, Speaker B: And the lp high p low function. Yes. And so whichever. So thiago, in your case, whatever variables the. Your program is using, it can. It can only choose one of these sets. Right.
01:02:16.122 - 01:02:53.454, Speaker B: So you'll have a program that only knows about a, x zero, and y zero. And then you'll have a different program that will only know about l, p high, and p low. And this is very like. This is actually simulating what it feels like to create a smart contract where you'll have three slots in memory and you can deposit these variables there. But that's the only variables that it will know about. If you want, you can have helper functions and things like that that will calculate constants and things that you might need, but you can't store them. You need to use them right away.
01:02:55.834 - 01:03:02.454, Speaker C: So, like, in the end, you want me to also analyze some discrepancies between the results when.
01:03:02.834 - 01:03:26.980, Speaker B: Not necessarily. Okay, you don't need to analyze anything. I just want you to do. Just do the exercise and then reflect on how much of a difference, difference it makes which variables your equation has. Because one of these is going to be very like. One of these is easy to do, what we've just described, and one of them is hard. And it's the.
01:03:26.980 - 01:03:37.944, Speaker B: Obviously, it's the uniswap b three one, because it's designed for this specific process, is the easier one to implement. And I just want you to see that it's easier to implement.
01:03:40.524 - 01:03:49.256, Speaker C: I'm sorry, I'm just getting. I just wanted to be really clear. So. Because we saw that l is an expression of p high below and the amplifier. Right. But.
01:03:49.280 - 01:03:52.484, Speaker B: So, yeah, it's also not. It's also just that. It's also just a number.
01:03:53.464 - 01:04:04.064, Speaker C: Yeah, it's just a number. Right. So I will just l as a number, but then I won't pass that l into the first function. Right. It's completely different field. Right. Okay.
01:04:04.064 - 01:04:04.600, Speaker C: Okay.
01:04:04.632 - 01:04:18.314, Speaker B: Yeah, exactly. Yeah, so, yeah, l. Yeah, so in. So you know what? We can. Let's have a look at this. So can you guys see my excel?
01:04:19.414 - 01:04:20.174, Speaker C: Yeah.
01:04:20.334 - 01:04:35.474, Speaker B: Yeah. So let's imagine that I'm starting to do this. I have x zero, y zero, and a. Right. And so let's just do like 100. 100, I don't know, 3.5 is generally a good number for this.
01:04:35.474 - 01:05:37.372, Speaker B: Okay, then obviously we need token balances. So these are, I'm glad that we did this because obviously you have to refer to the token balances. And let's just say that they start at 101 hundred, but they obviously don't have to. So what I mean is, at the end, I want something where you can put in DX and get dy out of it, out of this pool. And then there should be another pool underneath that will have different coordinates. And obviously its amplification factor will need to be adjusted so as to make sure that whenever one of these tokens is running to zero, so when we run out of x tokens or when we run out of y tokens, that the next pool underneath this one is ready to take over at exactly the marginal price that this one ended at. And you're limited to using these, or you have to start your implementation from these.
01:05:37.372 - 01:06:36.532, Speaker B: Whereas when you do the uniswap one, instead of having those variables to choose from, you're going to have the square root of PI. Remember, Uniswap actually does store these as the square roots, so you don't even get p high and p low. You have to use the square root, square root, p lur, and the alta. And now you need to do it again. And you should find that this is relatively easy because already, like, if PI here is ten and this is like five, for example, then no matter what I choose l to be, I already know that this one here is going to be five. Right? And, you know, if we wanted to make sure that this was geometric, and I don't really care if it is or it isn't, so you can make this any number you want. Now, the only thing that's important is that this boundary is maintained.
01:06:36.532 - 01:07:46.384, Speaker B: But you can see already, like, we're almost home and host, you know, like, we can let l be any number here, and we can let l be any number here, and we're already almost done. Whereas with this one, like, what should be the x zero and y zero coordinates? And does the amplification factor matter so that we can actually get the, you know, the p high rate over here to be the same as the p low rate over here. But this is. This is essentially what I want you to do. I just want you to separate these two instances from themselves because obviously they're going to achieve the same result. But what I want you to experience is the difficulty of trying to make an equation that wasn't fit for that purpose do something that someone else to replicate someone else's product. Whereas using an equation that was built to describe a product almost naturally does what you want it to do.
01:07:46.384 - 01:08:07.814, Speaker B: And, you know, I know you, thiago. I'm sure that what you provide is going to be fantastic, but. Yeah, just know that the purpose is to try and limit yourself, limit your knowledge to just three variables and then get the system to behave a certain way.
01:08:10.394 - 01:08:12.690, Speaker C: Okay? Good about it. Thank you. Thank you, Mark.
01:08:12.882 - 01:08:13.814, Speaker B: My pleasure.
01:08:15.544 - 01:08:52.394, Speaker A: All right, any other questions before you guys all jump on the homework? No? All good. All right, then, just to double check, we'll meet again in one week, same time, same place. Feel free to drop questions in case you have any, to the Discord Channel. And we'll see you there with a notifier on the homework again. And I guess that's it for today, Mark, right?
01:08:53.094 - 01:08:55.230, Speaker B: Yes. Wonderful. I'll see you all on discord.
01:08:55.382 - 01:08:58.918, Speaker A: Thanks so much, everyone. See you on discord, and see you next week.
01:08:59.086 - 01:08:59.742, Speaker B: Bye.
01:08:59.878 - 01:09:01.514, Speaker C: See you. Goodbye.
01:09:02.974 - 01:09:04.414, Speaker A: The recording has stopped.

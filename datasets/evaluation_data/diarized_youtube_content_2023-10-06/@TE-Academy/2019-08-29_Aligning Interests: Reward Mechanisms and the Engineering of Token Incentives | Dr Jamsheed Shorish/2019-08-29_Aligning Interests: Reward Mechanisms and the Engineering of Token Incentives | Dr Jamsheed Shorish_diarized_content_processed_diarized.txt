00:00:07.610 - 00:00:35.602, Speaker A: Our next talk is again from somebody with research background, a computational economist. I'm welcoming chamsheet Shoresh on stage. Aya, there you are. Welcome, chamsheet. Great have you here. Okay, your work includes applications of neural networks to asset pricing. So this is finance.
00:00:35.602 - 00:00:45.110, Speaker A: You worked on token valuation and incentive design. And your talk will be about reward mechanisms and the engineering of token incentives.
00:00:45.270 - 00:00:45.978, Speaker B: That's right.
00:00:46.064 - 00:00:49.290, Speaker A: Thank you for being here. And give him a warm applause.
00:00:49.870 - 00:01:14.690, Speaker B: Great. Thank you very much. I hope everybody can hear me here. So it's great to be here. Due to some technical snafus that were referred to earlier, this title slide here, which you can see that the bottom corner there is a flock of birds. The top was actually a little movie showing how you can do a computer representation of flocking bird behavior using what are called boyds. These were invented by Craig Reynolds in 1985 or so.
00:01:14.690 - 00:02:46.386, Speaker B: What you would be seeing is some computer abstraction of flocking behavior, birds moving in concert, even though they're birds, and therefore aren't really communicating in real time about an overall objective. Instead, there are local rules of local interaction that have emergent behavior. So I'm using this kind of as a red thread to kind of keep through the talk about this notion as to what does it mean to have a goal at the very top which you may or may not decide is explicitly engineered, and then have local behavior, or local interactions through the use of incentives to create emergent behavior, which would then reinforce this. And so what I'm going to do in the talk is to take, really, a background from economics and my specialization in mechanism design and contract theory, and try to convince you that there is scope for token engineering and mechanism design to be brought together to further objectives where you have a common goal, but you may or may not be able to rely upon individuals necessarily aligning their interests to further that goal in some idealized best way possible. So, I was going to motivate this a little bit with some of the existing technologies that we've already seen giveth in the common stack. But of course, then common stack is speaking later. For those of you who haven't seen these, these are two particular distributed ledger technology initiatives that are looking at the idea of having a larger scale societal goal, charitable donations for furthering the public good, or a shareable pooled resource, which you can actually then divide up for individual use.
00:02:46.386 - 00:03:55.894, Speaker B: And then you have this question, this problem, this tension of what will individual actors do? Can they actually be initiated, sort of incentivized, or design a mechanism by which, by making themselves feel that they're doing something meaningful actually furthered the common goal at the top. And the reason this is a challenge. This was well studied in the 20th century at the beginning. And I'm going to break it down into some of the social science aspects very, very quickly. This was initially looked at in a 1968 paper by Garrett Harden called the Tragedy of the commons in Science, the journal, where he was describing the overuse of a common resource when everybody acts individually. And the solution that in economics was something that was presented was the notion, well, in this case, what you have to do then is you either have to make some kind of privatization, assign property rights to resources so they aren't really commons anymore, or you have to use a top down regulation mechanism in order to ensure that a common resource, such as forests or fisheries, or the commons where sheep may graze, is not exhausted. Now, this was actually revolutionized in the 90s.
00:03:55.894 - 00:04:57.338, Speaker B: This was done by Nobel laureate Eleanor Austrom. And she made an incredibly detailed and specific analytical case on the basis of her own fieldwork, on how small communities actually reinforce individual incentives. And they do so not by assigning property rights or by assigning some sort of top down regulation, but through peer to peer reinforcement of norms and different rule sets. So this is the first indication that we could see that there is a kind of attention that must exist, but that there is a way that we could think about decentralizing a mechanism by which individuals could in fact reinforce a common good where everybody is hurt if the common resource is exhausted, while at the same time preserving individual incentives to do the best that they can. Now, economics was not the sole location for which this was done in sociology and philosophy. There's a lot of work being done on the commercialization of society, the commodification of the world. We've seen examples of this recently in the media.
00:04:57.338 - 00:06:17.010, Speaker B: For example, in Venice, the overtourism problem is a problem not just for the residents, the Venetians, who have an inundation of huge numbers of tourists that simply lower their own quality of life living there. But also, if you're a tourist thinking of yourself getting a snapshot on the realto bridge, you don't want basically 5000 people that you don't know photobombing your little selfie on the Rialto bridge. You're thinking of yourself actually as participating in the consumption of Venice independently or without other individuals who may lower your particular payoff. And so we've seen a lot of work done in sociology with regard to how can we regulate individually now, not from the top down. Our notion of overcommodification as another way of looking at this particular common goal, diverging from individual interests and from a behavioral point of view. In psychology, we've seen a lot of work done on the emergence of cooperation and the reinforcement of cooperation through reward mechanisms. And this is where we started to see the development of explicit reward mechanisms for different groups of individuals, whether those groups of individuals are animals or are humans, and actually providing an explicit kind of transfer to them, where they then can say, okay, given this transfer that is reward based, that there's a way in which I can then regulate my behavior such that a common goal is reinforced.
00:06:17.010 - 00:07:29.930, Speaker B: And this particular development from the social sciences in the 20th century led to the development of different fields that pushed forward this agenda. From this point of view of trying to align these interests. We had, for example, developments of non cooperative and cooperative game theory, decision theory, and operations research, which were, in a sense, combined through some of the work by Kenneth Arrow in the 1950s, and organizational behavior, where we're going to see a little bit of the mechanism I'll describe a bit later, looked at the organization of teams, team building within an organization, and how those kinds of team dynamics also reflect a common good. Now, what happened in the culmination from the economic side is that we had a series of mathematical results which indicated that if you really wanted a common goal to be reinforced for any kind of person, and by this I mean any kind of preferences that a person may have, one of those people will tell you simply what they want, and then everybody does that. So the common good becomes one dictator's result. So the dictatorship results from arrow. And then reinforced by the Gibbert Satterthway theorems in the early 1970s, in a way, caused economists and some social sciences scientists in general, to say, well, let's take a step back from a universal result.
00:07:29.930 - 00:08:58.786, Speaker B: And can we just find a way to pool everybody's private information that tells them what they want to do alone in some common framework where everybody pays a price, and we can use then the market to be able to take that private value, which has a value at the common level, and pool it through the market mechanism. And so this was the state of the art, really, toward the end of the 20th century, for how it was that economists were looking at this notion through the idea of bilateral negotiations, for example, in contracts where different individuals hold private information that needs to be pooled for an efficient outcome. Now we move to the 21st century, and this, in these last 20 years, we've seen a tremendous revolution in who was taking up the forefront of the challenge of examining the reinforcement of a common goal through privately aligned interests, through a lens that was not looking at a market mechanism, because that could only take you. So far, we've seen computational implementation theory which says, look, how do we figure out how to implement particular ideas, common goals, irrespective of whether or not there is a market mechanism at all? Let's just try it and see if it works. This is from computer science. Algorithmic mechanism design, algorithmic game theory. These were the leaders in this time, as data driven and computationally driven approaches, to be able to solve problems, particularly, but not exclusively in robotics, to be able to decide how these common goals can be reinforced.
00:08:58.786 - 00:10:01.946, Speaker B: And so there was a real big uptake on this notion of looking at these things as collections, not just of people with preferences, but actually of subsystems, each of which has a particular reward mechanism, and then an overall system that is dictating the direction that the system as a whole has to go. So this led to this revolution in understanding how to take a particular system and then validate and verify what is going on. So we saw the rise of the computer aided design. And of course, CADCAD is one fantastic example of this. And multi agent systems allowed this paradigm from Eleanor Austrom to become actualized as a notion of, okay, peer to peer reward, where we don't need a central authority to be the one to dictate the reward structure can actually become something that many, many different little system components can help reinforce each other. And so, in a contrary way to the economics approach, we have what is known as a systems engineering approach. And it's this which is now the driver for bringing these two paradigms into one cohesive whole.
00:10:01.946 - 00:11:26.594, Speaker B: And so what I'll do for the rest of the talk is to try to show how these two environments can somehow be put together so that we can, in a way, cherry pick the best of each of these. Now back to distributed ledger technologies. Where does this actually come into? Where's the part of this that actually makes looking at dlts such a fantastic opportunity to see this interface between these two types of approaches? Well, I will limit my use of the DLT paradigm to simply looking at it as if it is simply a database technology. Of course, it's quite a bit more, but considered as a database, as entries in a database, it has two unique features that we weren't really able to reinforce prior to this time that allow us to do this alignment of the common good through individual incentivization. First, it's a trustworthy entry, so it's non manipulable, it's auditable, and it's consensus based. And this is extremely powerful because it allows you to do so, of course, without having to worry about either the dictatorial results, the arrows impossibility theorem, or worrying about having some sort of top down approach, which everybody has to agree on. And second, decentralized implementation, you have a distributed location, you have an ability to actually have open access to what it is that is running via the smart contract system, and no single point of truth or single point of failure is necessary.
00:11:26.594 - 00:12:41.470, Speaker B: So these are the two characteristics of dlts that I'll show are ways in which we can look at this environment as reinforcing mechanisms that are both from economics and from the systems engineering literature. So this allows us then to have a representation. And that representation then takes the form of this particular kind of database entry known as a cryptocurrency token. And what is it representing? Well, in this particular case, since we're looking at a common goal that needs to be reinforced from the bottom up, we're looking at what is called a purpose driven token, from Shermin's terminology that you saw this morning, and what was described more fully from Chris in his talk. This is the idea that you have at your disposal a particular tie between what it is you want to do and how you can distribute in the form of a reward, a mechanism that when people condition upon that, they do something which is the best for the system, given the conditions that they're in. So that's the idea of what is called a purpose driven token. There are of course, many other kinds of representations of tokens, but this is the one slice that we need to be able to infer how to incentivize individual behavior at the common goal.
00:12:41.470 - 00:13:29.790, Speaker B: Now this is. I'm going to gloss over this part. This is similarly, but conceptually distinct from a utility token. It can be that these are reinterpreted as purpose driven tokens. That's simply a formal similarity from our particular purposes. What's important is that typical issuer objectives, such as fundraising and other public good environments, common good environments can all be cast as incentive transfer mechanisms. So this allows us to broaden the scope of what we would call a purpose driven token by interpreting these particular types of common goods as that particular function or relationship, or even functional relationship between different behaviors that we wish to say is what the society wants or what individuals want when they're setting up this particular mechanism or ecosystem.
00:13:29.790 - 00:14:16.254, Speaker B: Now this is necessary because it's really hard to reinforce people's good behavior by telling them to be good, or to reinforce noble characteristics by telling them to be noble. This is a hard problem. This is a result from psychology, where it is simply difficult to incentivize when people can say or do whatever they want to have them behave well. You will have all kinds of statistical distributions of trolls and cybertrols online, who, as long as they are anonymous, they behave one way. But the instant that you can actually apply a name to them, they behave completely differently. So this notion of being able to do this without transfers limits the kinds of things that you can implement. So transfers themselves.
00:14:16.254 - 00:15:32.326, Speaker B: These tokens really become the mechanism by which you can drive a particular purpose. And it would be similar if you wanted to think about how you could do this without transfers. It would be similar to trying to derive a barter economy where you weren't actually allowing individuals to save up something that they think somebody else might need in the form of money. You'd have to actually carry on your back everything that anybody else might want, and then try to get what you want from them. In addition, transfers themselves help align truth telling mechanisms. This is part of the mechanism design literature, where if you think about everything that people could do to say what they would like, it suffices to look at all of those situations where they are telling you exactly what they want and that they are not lying, so that what they are doing, instead of sending some kind of obscure message about what they would like, they simply say, I like x, or I am of type y. And that's a useful way to actually examine what happens, because you can look at mechanisms that are direct in terms of how people elicit information, and they allow you in turn to examine the types of equilibria where you would say, what I care about as an individual is independent of what anybody else is doing.
00:15:32.326 - 00:16:00.960, Speaker B: These are called dominant strategy mechanisms. Now, there are more general mechanisms that you can use. There's bayesian Nash mechanisms, where you're actually taking some sort of a probability distribution over what everybody else might be. Bad actors, good actors. That's also an equilibrium. A simple first cut at a mechanism that you can use which provides a strength, is that you simply get something kind of like the Boyd representation. You look around your local environment, you make a decision, you don't need to know what everybody else is doing.
00:16:00.960 - 00:17:06.050, Speaker B: Now, in the mechanism design literature, there are such incentives that do exist, and they've been well studied over the years, one of which, the most popular perhaps, is the Vickery Clark Groves mechanism. This was studied initially in auction theory by William Vickery, and then extended by Clark and Groves in this early seventy s. The idea behind this is intuitively very simple and appealing from this notion of building a collective common good from individuals. The idea here is that everybody in the mechanism has to pay something according to how much they contribute to the societal good. So it's a positive or negative externality of whether or not you are contributing to society or are in a sense, harming society. And so you pay or receive a stipend in the amount of that particular externality suitably defined. And that has very, very appealing characteristics if you're looking at the maximization of societal good in some fashion, of saying that this is the global benefit.
00:17:06.050 - 00:17:57.074, Speaker B: Now this requires very strong assumptions, which is where we're going to get back to the DLT strength in a moment to support dominant strategy mechanisms that may or may not pay for themselves. You may need a capital injection to come in. It may be not possible to make these assumptions that I'm going to mention in a moment, but provided that you can, you can actually use an auction mechanism, which is called a vikri auction or a second price auction, to implement these types of mechanisms. So there becomes a formal parallelism between what you can do in the sense of maximizing the common good on the basis of aligning individual interests on the one side, and thinking about that common good as something which is being brought up for auction on the other side. That's another way of eliciting that private information with or without a market mechanism. So you can think about it with a market mechanism and it's auction theory. You can think about it without that.
00:17:57.074 - 00:19:07.574, Speaker B: Then it's the messages with transfers. Now, why isn't this simply what we do every day? Why isn't this every kind of auction we've ever seen? The vast majority of auctions are not victory auctions. And the reason is because it has these strong assumptions. The first assumption is that it really doesn't matter how rich or poor you are when you are deciding about the common good for this mechanism to work, that means that if you're talking about something like, let's say, a United nations development goal of low infant mortality, it doesn't matter if you're a poor person or a rich person when deciding whether or not you want to contribute to that goal. Sounds reasonable. Perhaps if you're looking at one of the development goals, which is to increase people's level of income who are very, very, very poor, well, then it might be quite a different story as to whether or not, if you are already well off, how you are going to value that particular outcome versus whether or not you yourself are poor. And so this immunity to income effects, which is called quasilinearity as a preference assumption, is one of the strongest binding assumptions for these types of mechanisms, and is one of the major reasons why we don't see this in practice.
00:19:07.574 - 00:20:14.850, Speaker B: Another reason is that practically, people can band together and cheat. They can simply find coalitions of themselves, take the transfers, the things that are promised to them for certain types of behavior, divide that among themselves and break the mechanism. And there are other assumptions that go in with this, but these are the two main ones and the main reasons why we usually see auction mechanisms in the first price instead of a second price, a non vicary auction environment, simply because these are too, in a sense too fatal. They're just not usually realized in practice. Now I'm weaving back and forth between what we've seen for dlts and what we've seen for economics, what we've seen now for systems engineering approach. Finally, let me bring you back to token engineering and see whether or not this particularly attractive mechanism in principle, this Vickery Clark Grove's mechanism, can in some sense leverage what dlts have as strengths. And again, I'm only focusing on two the trustworthiness and the decentralization.
00:20:14.850 - 00:21:32.410, Speaker B: And it turns out this is enough to address the shortcomings mentioned before. A practical and a fairly simple demonstration of the trustworthiness allows you to, as long as you have in your DLT a consensus mechanism for validating the state of the system that is byzantine, fault tolerant, then you are able to eliminate coalitions. And this is a very kind of, in a way, hopefully an intuitive result for those of you who think about byzantine fault tolerance, the idea that you have to have a certain number of nodes in a validation network such that a message that is passed across to all of them succeeds to reach at least two thirds of them, then you have the state that everybody can agree on. So you can tolerate some mistakes, either accidental or malicious. Well, this is the idea that in a situation in which you can label the particular tokens that you're using as an purpose driven incentive reward mechanism, that nobody can come along and relabel them, destroying the opportunity for you to incentivize without a coalition. Because coalition formation is this idea that you pool everybody's token and then redistribute. Well, if you cannot pool them, if they are tied to somebody, if they are non transferable and therefore they're non fungible.
00:21:32.410 - 00:22:24.298, Speaker B: Then, provided that they can't be, those particular characteristics cannot be unwound. You can eliminate coalitions from forming. That's a demonstration result. It's fairly low hanging fruit from the point of view of what is it that dlts are so special for in creating incentivization? The second characteristic, which is more of an existence proof and is less about implementation, the first one is immediately implemented. The second one is more about there exists is that provided you have a decentralized, purpose driven token and it can be produced with zero cost. So you may have a sunk cost in designing the whole infrastructure, but then once you've got a sunk cost, you turn on the token creation mechanism, it blops out a token and it doesn't cost anything. Or more realistically, from a formal point of view, it costs something in the electricity or foregone time for creation, and you let that limit go to zero.
00:22:24.298 - 00:23:38.618, Speaker B: Then you can implement such a mechanism for users that are risk neutral or risk averse. And the idea here is more involved, but it relies upon the way in which you can replicate different potential ways in which risk is distributed throughout a network. Individuals can act in a peer to peer environment, and by acting in a peer to peer environment, they transfer with each other in such a way that an equilibrium is reached where people who are risk averse are compensated just up to what they would have obtained under certainty, the so called certainty equivalent payment that makes their risk aversion for that particular area, very, very close to that particular area flat, as if it were quasilinear. And then you can bring in the Vickery Clark Groves mechanism once again. Okay, that's the punchline of the approach here. We've been able to tie together the properties of dlts to an existing mechanism that's very commonly understood and very well studied in such a way that common goals can be realized by aligning individual incentives now work in progress in the future. This was static.
00:23:38.618 - 00:24:18.058, Speaker B: This was a one shot transfer. What we really care about is feedback mechanisms, particularly if you're actually going to be looking at goals that change over time, or if you're going to change a focus upon a particular goal. If you have some combination, for example, of the UN development goals, maybe you want to increase your focus on education, decrease your focus on maternal mortality, or vice versa. Well, that's going to require you then to look at how you actually have this feedback loop between your function that you're trying to decide is the common good and how individuals will align. Now converging to that is unclear. This is an open research question. I would really, really like to hear if anybody's looking at this or even has ideas on how long run convergence can be obtained.
00:24:18.058 - 00:24:55.420, Speaker B: You can do adaptive to Tom Mall, which is sort of the grasping of equilibria as it iterates. You can design, and I think Zargham is working on a lot of this idea of having some global stability properties in this notion. But this is something which is an open research question. My own work is looking at consumer electricity provision in Belgium, because Belgium is a country which is committed to eliminating its dependence upon nuclear power, and they're trying to. They've already eliminated dependence upon coal. The problem is that they're a massive importer of electricity, and so they have a difficulty in verifying the source of what their electricity consumption is. And so this provides us with a unique opportunity.
00:24:55.420 - 00:24:58.060, Speaker B: All right, thanks very much.
00:25:03.470 - 00:25:29.650, Speaker A: Thank you so much, chamsheet, for this enlightening talk. I think this was a brilliant example of showing the existing work which is out there, and then see what makes it special in a DLT environment. So I can't wait to see more on that. Thank you so much and talk to you soon, maybe after our talks at the networking and drinks.

00:00:28.435 - 00:01:46.575, Speaker A: Okay. Hello everyone. Welcome to our event evaluating voting design trade offs for Retro funding at Optimism. We just kick it off and go over the agenda and let until everybody else is able to join us. Today we'd like to introduce the first results of our work for Optimism Retro funding and this is a workshop to go over the results together with batchholders and governance and yeah, discuss what we have found. The agenda today is we will walk you through the evaluation framework, the design objectives there, the metrics we've developed, we'll share the issues we've found particularly in making Retro funding. Strategy proof will introduce some new strategy proof voting rules solutions we propose for round five and onwards we'll walk you through some of the what if scenarios with round four data and provide you an outline look and of course we are happy to take your questions.
00:01:46.575 - 00:02:07.725, Speaker A: Right, before we dive in, I'd like to introduce the team. The Gulf Access team is myself, Nimrud Talman, Eyal Bremen and Muhammad Idris. And yeah, Nimrud, let's start. Say some words about yourself. Let's introduce the team.
00:02:08.145 - 00:02:26.435, Speaker B: Hi, happy to be here, thanks for coming. I'm Imot Almond from Ben Gurion University in Israel. I do social choice research, algorithm design, game theory, mechanism design, all of these areas. Do you want to continue?
00:02:26.895 - 00:02:31.995, Speaker A: Yeah, Mohammed, you go next.
00:02:33.055 - 00:02:52.815, Speaker B: Hello everyone. Thanks for joining this session. I'm Mohammad Greece and I'm from Pakistan. I'm AI and machine learning engineer and working as modeling and simulation engineering this Covax simulator for Retro PGF Optimism. Thank you.
00:02:54.915 - 00:03:04.215, Speaker A: And we have also Eyal Bremen in the team. Nimrod, you take over the introduction. Right. Because Eyal has some bandwidth issues.
00:03:04.635 - 00:03:18.075, Speaker B: All right. Yeah. So Eyal is working with me in Bengal University. He's doing his PhD and he's doing all aspects of the project theory and the simulations and modeling and everything.
00:03:20.295 - 00:03:49.965, Speaker A: All right? Yes. And myself, I'm Angela, Angela Kreitenweiss. I'm founder of Token Engineering Academy. Some of you might know me. I'm active in the Optimism network because we have been running education. We were recipients in retrospect PGF round 2 and 3. We have been running study seasons, more than 5k students in our token engineering TE fundamentals course.
00:03:49.965 - 00:04:59.965, Speaker A: We have been and are still working on reputation based weighted voting mechanisms together with a team of students that we kicked off thanks to Optimism Funding and now working with the team in Gov Access on evaluating retrofunding. All in line with our vision to establish rigor in Token engineering and token based governance. And let me first say some Words about the scope of this project. So in June there have been a foundation mission request. I'll pull up the slides again to evaluate the voting design of retrofunding. And part of this was please evaluate resistance to malicious behavior to collusion, incentive compatibility and test the voting designs. Quadratic voting applied in round one, Mean rule, median rule the designs we have in Retro funding we have applied over the past rounds and let us know how we can improve the voting design.
00:04:59.965 - 00:05:48.703, Speaker A: And this is the scope of our project. This is what we have been working on since July. And as I mentioned, we have evaluated the voting rules in Retro funding precisely Retro PTF round one, which was quadratic voting. In round two, Retro funding or Retro PTF applied the mean rule. In round three, we had the quorum median rule. This was the median and said minimum quorum referring to the number of voters that a project had to achieve minimally. And in round four, the fourth mechanism we evaluated there was the cap median and the impact metric score quite new variant in voting.
00:05:48.703 - 00:06:55.879, Speaker A: And we evaluated all of them for round four, a simplified version. And to do that we started with the description that is available online publicly by Optimism. Then we translated it into a formal specification of the voting mechanism that allowed us to run a theoretical analysis of the voting mechanism. And second, we transferred it into a simulation framework in a model that allowed us to run agent based simulations to test and evaluate the voting design using simulations. So this is the voting rules and the process to evaluate it. And second, we have been working on a framework to generally evaluate retro funding voting designs. And this framework now combines six dimensions and these six dimensions are key goals for any kind of Retro funding and in particular for optimism Retro funding.
00:06:55.879 - 00:07:44.475, Speaker A: We collected these objectives together with Jonas. Thanks for your feedback and other people from the Optimism Network and Collective to define the generally the design goals and of course now moving forward to be able to prioritize. Okay, and the six design goals are resistance to malicious behavior and collusion. Number one measure to what extent a malicious voter or a group of coordinated malicious voters can impact the voting outcome. The second objective is incentive compatibility. Proof or disprove that the voting design is incentive compatible. Every participant can achieve their own best outcome by acting according to their true preferences.
00:07:44.475 - 00:08:37.384, Speaker A: And we dive into more details about incentive compatibility in a moment. The third goal, simplicity for voters and expected outcome measure. If voters can easily understand how the voting design works and how to best achieve their goals. The fourth objective, majority versus Diversity measure how well the results represent preference of majority or diversity of voters. The number five objective is Incentives alignment measure how well the incentives of voters and the optimism collectives are aligned. And the last one is alignment with the ground truth in impact equals profit. This is a key vision for RETRO funding measure how well the voting design supports finding the objective truth in impact equals profit.
00:08:37.384 - 00:09:56.377, Speaker A: Because there is this interesting paradigm in optimism RETRO funding that should allow us to measure how well this objective truth can be met and supported by a voting group. And now defining these design objectives, we developed metrics to measure how well a voting design supports these objectives. And as you can see, number one, this is a combination of metrics that we can either measure via theoretical analysis or simulations, like voter extractable value, the risk in control, bribery, robustness and group strategy proofness. The second is incentive compatibility that we call strategy proofness and we'll get to it in a moment. Number three, simplicity of voters can be measured by metrics called monotonicity, Pareto efficiency, reinforcement, majority versus diversity via utilitarian, social welfare, proportionality and diversity. There are dedicated metrics behind it, incentives, alignment, voter skin in the game and participation and impact equals profit via this alignment with ground truth. This is an overview on the metrics we defined.
00:09:56.377 - 00:10:46.967, Speaker A: And now looking at the simulation results overview table, you'll see that we have found issues in all dimensions. All six dimensions have their challenges. Some of them are more like this is really bad. And some are more like this is a trade off. It's on the optimism collective to find the best balance, for example, between diversity and majority. And we'll share the results of all of them step by step. Now, in this call, we'd like to focus on incentive compatibility because this is a fundamental property we need in voting systems to achieve related goals like impact equals profit.
00:10:46.967 - 00:11:57.849, Speaker A: And this is what we'll discuss now, making RETRO funding strategy proof. First, there is a definition of what strategy proofness is. And the definition is rooted in social choice theory, which is the study of collective decision procedures and mechanism. This is combining economics, mathematics, political science, philosophy, computer science. So we are drawing from this discipline when evaluating the voting design for optimism. And the definition of strategy proofness that we can find in social choice is that a voting rule is strategy proof if no voter can increase their utility by lying about their preferences, or in other words, by not voting according to their true preferences. And as I mentioned, we've evaluated for voting rules, round four one, retro pgf, round two, round three and round four, the voting designs applied in past rounds.
00:11:57.849 - 00:13:07.811, Speaker A: And none of these past voting designs is strategy proof. Now why is this an issue? First of all, if voters are not encouraged to vote truthfully. This is an issue in any voting system. Strategical voting is generally an issue now. On top of that, optimism retrofunding relies on the learnings from analyzing voter data and voter preferences. And if this data is skewed, wrong conclusions will be taken. For example, when it comes to the insights we'd like to take from expert guest voters in round five and also now in rounds six, how can we evaluate if experts take better decisions if we can't be sure that they don't vote strategically and are not voting according to their true preferences? And the third key issue is if the voting rule provides voters with wrong incentives, the results are distorted and optimism retrofunding can't get any closer to this objective.
00:13:07.811 - 00:13:52.461, Speaker A: Truth in impact equals profit. So the fair reward, the fair compensation for those who are adding value to the optimism network. And if we can't be sure that the results are not skewed here, that the voters vote according to their true preferences, this whole system is not reliable. All right. And to explain a little bit more what strategy proofness is, I now hand over to Nimrud to walk us through the examples we prepared. Nimrud, you just let me know when I should skip the slide.
00:13:52.653 - 00:13:54.985, Speaker B: Yeah, thanks. Yeah, okay.
00:13:55.405 - 00:13:55.717, Speaker A: Yeah.
00:13:55.741 - 00:14:43.255, Speaker B: So maybe the starting point is to define and consider what is the utility of a voter. So consider that we have a set of projects and I'm a voter and I vote with some distribution. Then if the final outcome will be exactly what I voted for, then we can assume that, okay, my utility will be. The best that I can have will be 100%. But as there is some distance or some difference between the vote that I give and the final outcome, then my utility decreases. And the question is how to define this distance. And we use L1 distance, which basically means that we count the sum of changes between my vote and the final outcome.
00:14:43.255 - 00:15:10.593, Speaker B: Let's see a simple example. So look at the. At the left you see an example with two voters V1 and V2, and two projects P1 and P2. Let's say that I am voter one and I think that we should put 75% on project one and 25% on product two. And now let's say that the out that the outcome is what is here in bold. So it's 0.375 and 0.625.
00:15:10.593 - 00:16:01.875, Speaker B: Then you see that the outcome is not exactly what I wanted and the difference is exactly the summation of 75 minus 375. This is 375 plus the difference in the, in the second project and you summit and you see, this is my utility. This is the utility of the, of the first voter. So this is the cost or the regret of the first voter. So then basically you can say that you can imagine a voter that votes and expect some kind of a cost to utility at the end. So now strategy proofness simply means that there is no incentive for me as a voter to vote differently in the hope of getting less distance between my true vote and the outcome. So if you consider.
00:16:01.875 - 00:16:05.235, Speaker B: We can go to the next slide, I think.
00:16:09.895 - 00:16:18.515, Speaker A: Give me a second. Oops, here's my clicker. It got stuck. Almost there. All right.
00:16:19.025 - 00:16:43.871, Speaker B: Oh no. Even the next one is okay. Yeah, even just really the next. Okay, so here, you see, you see on the left, these are the two preferences. So let's say my preference as before. So I'm V1 and I think it should be 75% for P1, 25 for P2. If I vote in this way and there is another voter voting 01, then the output will be what is here in bold.
00:16:43.871 - 00:17:06.731, Speaker B: And my this utility will be 75. So I will be with a cost of 0.75. Now I can basically lie. I can say that my 2 preference is 1, 0, not 75, 25, but 10. Now the output will be 50, 50 if we take the min. And you see that here. Now my L1 distance is 0.5,
00:17:06.731 - 00:17:50.375, Speaker B: which is lower than it was before. So basically this example shows that if we take the mean in each project, then it's not strategic proof. Basically there are situations in which voters have incentive not to report their true preferences, but basically to lie in this example, to exaggerate. So to put it, instead of 75, 25, put it at 10 in order to push them into the position that they want. And this is not good, as Angela tried to explain. So this is why we try to think for solutions. Basically algorithms that do not give any incentive for voters to misreport.
00:17:50.375 - 00:18:45.595, Speaker B: And this basically means that for any voter in any situation, it's in the best interest of the voter to report the true preferences. Because if they report different preferences, then maybe they get the same disutility, but maybe even more so it's never the case that it's better for them. Okay, and for this, basically there are two ways. So one way is to take the median in each column in each project. If you do this, you can see that it's actually also strategy proof. To see this, maybe consider only. So consider just one project and say that you compute the Output by the median of the values that the voters give to this project, which means that basically you sort the values, you sort them and then you take the middle voter.
00:18:45.595 - 00:19:31.125, Speaker B: If you think about it a little bit, you see that there is no incentive for a voter to misreport. So if I am the median voter, then it's best for me to report the true preference, because this is what the output will be. And if I report something different, then I will get this something different which is less than what I really wanted. And if I'm not the median voter, then it basically does not matter what I do unless I really become the median voter, but really far away from what I really believe in. So for one project, it's never the case that it's good for a voter to misreport their preferences. And this also holds for several projects. But the problem here is that you don't know what will be the sum of funds that Optimism gives.
00:19:31.125 - 00:20:48.637, Speaker B: Because if you, I mean, if you want to distribute 10 million optimism tokens, but now you take the median, so you can think about it, that you Give each voter 10 million tokens to distribute among the projects. Now if you take the median in each project, then maybe the sum of the medians that you get is not really 10 million optimism tokens. It could be less, it could be even zero, or it could be much higher. So if the, like the total funds that optimism allocates should, I mean, it doesn't have to be exact, then you can take the median. But if this is not the case, then basically, I mean, you cannot use the median because you need to do something to make it, to normalize the output to become 10 million optimism tokens again. And now it turns out that if you do normalization in a simple manner, which is what was used in round three or four, I don't remember, then you lose this strategy proofness property from before. So basically, if you take the medians but now you normalize to come back to 10 million optimism, then actually this voting will do give incentives sometimes to voters to misreport the preferences.
00:20:48.637 - 00:21:39.715, Speaker B: And this is why we try to think about a different algorithm that still gives the output to be something fixed, but doesn't give incentive to misreport. Can we go? Move on? Thanks. Okay, so this is an example why median is strategically proof. I mean, it is just one example. I mean, it doesn't prove that median is strategy proof, but it shows that for this situation, if I am the first voter voting, like in this first row, then my utility will be 0.1,3. If now I misreport and say that basically push the first preferences higher and the others a bit lower, then I get actually a lower utility. So with this example, the voter misreport and hurts itself.
00:21:39.715 - 00:21:45.565, Speaker B: So it's not good strategic voting. Can we move?
00:21:50.145 - 00:22:34.855, Speaker A: And this proves that here, if we compare here the normalized median in the second to last line and the median in the last line, and if we look at the median only, where we state it's strategy proof, we see that the L1 distance with truthful voting is 0.13 and the L1 distance with strategic voting is 0.8. And that's what's a good result. The example that untruthful voting does not lead to better results for voter one, if we apply the pure median, so the median without any normalization. Okay, come to the next.
00:22:36.445 - 00:23:30.671, Speaker B: Yeah, but the point is that if you do the normalization, that then basically you make it possible for voters to increase the utility by misreporting. The intuition for this is that basically if now I am a voter and I misreport, I can also get the sum of the medians to be changed and then the normalization will change everything. Not completely, but can change it dramatically to let my L1 distance be decreased from before. So basically to increase my utility by changing the normalization intensity or the value of normalization. Yes. I mean, if by some magical way the sum of the medians is one, then okay, this does not happen. But.
00:23:30.671 - 00:23:35.895, Speaker B: But it could happen. And then this what makes strategic voting possible.
00:23:38.675 - 00:24:18.165, Speaker A: Right? So again, to summarize, normalized median as applied in round three and four is not strategy proof due to the normalization step that is needed to land at a predefined funding round size. If we remove the normalization and apply the pure median, then it's strategy proof. But we have this challenge that the results, the boating results might not sum up to 100% of this round size. In our example it's just 87%. And that's the challenge to solve. And we have a solution.
00:24:20.705 - 00:25:05.695, Speaker B: So let me try to explain the solution. It's called the majorita in phantoms. And the idea is as follows. Maybe the intuitive idea is as follows. So I mean, as I said before, if you take the median in each project, maybe by some magic luck the sum of medians will be one, but maybe it's not. But now if you imagine that basically you can add some dummy voters and make it so, such that with the dummy voters the sum of medians now will be one, and the Question is how to add these dummy votes in a way that will not distort the preferences of the voters. Right? That will make it still connected to what people want.
00:25:05.695 - 00:25:42.311, Speaker B: And the way Majorita phantoms works is the following. So let me try to explain the algorithm and then afterwards I will try to hint why it keeps the strategy proofness property. So it works as follows. So in this example we have three voters. So basically we add three plus one dummy voters, which we call them phantoms. So we add four phantoms. Now, initially we let all of these phantom voters to vote with zero tokens for all of the projects.
00:25:42.311 - 00:26:29.995, Speaker B: This is just the initial step of the algorithm. This causes the following to happen. So basically we have three voters voting somehow, and then another four voters voting with zero. So the median of each project will be zero, right? So initially the sum of medians will be zero, complete zero. Now what we want to do, we want to increase the number of tokens that these phantom voters or dummy voters give to the projects. We want to increase it gradually, continuously, until we reach the point in which the sum of vineyards will be one. The point is that if we increase the tokens that these dummy voters distribute, then the sum of billions, I mean, maybe it keep the same for some time, and then it increases and we want to stop when it reaches one.
00:26:29.995 - 00:27:05.674, Speaker B: The specific way in which we increase it is basically one phantom at a time. So as I said before, in the beginning, all of the phantoms distribute zero tokens to all of them. Now we go to the first phantom and we gradually, I mean only the first phantom. And we gradually increase the number of tokens that this phantom gives to the project until it gives one to all of them. And then we go to the second one. We increase it from zero to one in all of the projects until we halt. So in this example you see that the algorithm stops when Fantom1 gives 1 tokens to all of the projects.
00:27:05.674 - 00:27:34.397, Speaker B: Fantom2 also gives 1 token to all of the projects. And Phantom3, we stopped it exactly when it gave 0.28 tokens to all of the projects. So we didn't have to go to continue to Phantom 4. Because when Phantom 1 gives 1 to all projects, Phantom 2 gives 1 to all projects and Phantom 3 gives 0.28 to all projects. This is the only place in time in which the sum of the medians will be exactly one.
00:27:34.397 - 00:28:10.765, Speaker B: So this is the position like the time in which we stop and the output is what now we get. So this is the algorithm. The first point to realize is that intuitively this does not distort the balance between the project because all phantoms are basically giving the same number of tokens to all projects. So, I mean, they lack everything the same. It's just a matter of the intensity in which they like all of the project. This is the first thing. The second is that this algorithm really halts, I mean, eventually, because we start with the sum of median zero and we halt in some position.
00:28:10.765 - 00:29:01.065, Speaker B: And the last thing about strategy proofness, notice that if this were like the original situation in which we had seven voters voting in this way, then basically now we just apply simple median with no normalization and simple medium. We know from before that this satisfies strategy proofness. So the point is that with the phantoms we just get to this normalization, but we still do just plain good old medium without multiplying by the inverse. Yeah, okay. And for this example, we can show that even, I mean, this is an example of the strategy proofness. If the first voter changes, then indeed it just increases the L1 distance. So it doesn't help.
00:29:01.065 - 00:29:16.425, Speaker B: Yeah, and we get results that are normalized without the normalization step, the simple normalization step that destroyed the strategy proofness. So this is the main idea.
00:29:18.885 - 00:30:36.235, Speaker A: All right, now you might ask, and we asked ourselves, okay, if we look at the voting, the real voting data in round four, if we take in this voting data and look at the results comparing the three mechanisms that we discussed. Now, the normalized median that was applied in round three and four, the pure median, to make it strategy proof with the issue that it won't land or might not land at a predefined funding goal. And the majoritarian phantoms that check both boxes, strategy proofness and landing at a predefined funding target, what would be the outcome and how would results deviate? And we took the round four real voting data and here are the top 20 projects. Now keep in mind, this is not the real voting outcome in round four. That's why we have the note without caps here. Because in the real retrofunding round four, there was a maximum cap at 500k. So no project was able to receive more than 500k.
00:30:36.235 - 00:31:10.161, Speaker A: However, we wanted to look at the pure outcome of the voting rule. That's why we didn't take the max cap into account. We just wanted to see the voting outcome. And these are the top 20 projects. And if we look at the results, green, the normalized median, not strategy proof, blue, bright blue, majoritarian phantoms, strategy proof, and median in dark blue, which is also Strategy proof. Here are the results and you see. Okay, the results are not equal.
00:31:10.161 - 00:31:13.801, Speaker A: How can they? Because mathematically the voting rule is different.
00:31:13.913 - 00:31:14.135, Speaker B: But.
00:31:14.165 - 00:31:49.035, Speaker A: But they are very close. The purpose of it makes sense. All are using the median at its core. Some balancing and final allocations are different because of a normalization. They are very close. And also if we look at the statistics, for example, the maximum median or minimum OP allocation using these mechanisms is also very equal. Maybe some results that we can find in round four data.
00:31:49.035 - 00:32:57.395, Speaker A: The normalized median. So this voting rule, the core of the voting rule that retrofunding applies so far, provides higher results for the maximum allocation. If we look at the normalized media minimum, we find 1.46. If we use the majoritarian it's 1.39. And median pure median is 1.33. And if we in contrast look at the minimum results or the median results, so what the median of across all projects, how much they received or the minimum how much the let's say the smallest allocation was or the the smallest funding for projects. Then we see that in fact the normalized median had lower numbers and majoritarian phantoms that are strategy proof and the pure median that is strategy proof have slightly higher results.
00:32:57.395 - 00:33:46.903, Speaker A: Right? So if you look at the minimum OP allocation, majoritarian phantoms allocates 0.27, the normalized median 0.21 and the median, the pure median is 0.19. So these are slight changes due to the differences in the voting rule. However, the good news is they are very similar and we have a solution to the strategy proofness problem. Last but not least, just to confirm this overall idea of the free variance normalized median lands at ultimately 10 million total allocation majoritarian phantoms also 10 million. Because we have this normalization not at the cost of strategy proofness.
00:33:46.903 - 00:34:59.825, Speaker A: And median is lower in this case with the round four data, because median is not necessarily has a guarantee that we land at the 10 million funding depends on the actual votes. And in round four, we wouldn't land at this 9.15. So overall, for retrofunding we recommend a solve strategy proofness using the majoritarian phantoms. If we'd like to land at a predefined funding target, and this includes variants like in round six or even in round five, where voters should define the final funding allocation in a range proposed in the voting. Still there voters define a certain funding allocation and we have to normalize then computing the results across all votings. So this is the solution to such cases. Predefined funding target use majoritarian phantoms and if the funding target should be a function of the voting, which is not the case in retro funding, we can use the pure median and in both cases we solve strategy proofness.
00:34:59.825 - 00:35:48.325, Speaker A: All right. By the way, majoritarian ventures is not newly invented by us. We are building on research in social choice and give references in our article on Mira. Maybe we can drop a link to the Mira article again Caitlin and there you will find the resources and the paper on majoritarian phantoms. It would be an additional component in the voting system easy to implement. We can provide the tests to make sure that everything works as expected. All right, now I stop here for the proposals on how to improve strategy approvness and let's go back to generally the evaluation framework.
00:35:48.325 - 00:37:26.975, Speaker A: As mentioned, this framework is for evaluating any voting design in the context of retro funding. We can now take a look at the priorities at the design objectives and can evaluate and verify the voting designs on the table for the next rounds and see if we find any issues. And today we have discussed incentive compatibility will step by step publish more results on how to evaluate malicious behavior and collusion on the topic of majority versus diversity and simplicity for voters expected outcome and more results on the topic of incentives alignments, voter skin in the game participation and alignment with ground truth. We also have open source repository available. Happy to drop the link. Also in the chat in a second where you can find the simulation engine, the definition mathematical specification of the voting rules we've evaluated so far and step by step we'll evaluate more and the whole retrofunding process can lead to safer results. So usually we plan the round the round scope, then some additional experiments that should be run to get collect more insights for example on expert voting or on KPI metrics based voting.
00:37:26.975 - 00:39:07.765, Speaker A: Then based on this evaluation framework we evaluate the risks associated like malicious behavior like alignment, ground truth, like incentive compatibility, are able to adapt the design and then roll out a voting so that we can be sure that the voting rule itself prevents attacks and is strategy proof and produces the outcome as expected. And we did this for round five and already provided feedback. Part of it was the majoritarian phantoms and we can do this in the future as well of course. Now I stop here and let's see if we have any questions or comments in the chat or feel free to switch on your mic as well. Anyone just let us know if you have any questions on the framework. Maybe I should jump back or on the new voting rules we propose here to make retrofunding strategy proof Totally okay to switch on your Mic or drop a message in the chat. All good.
00:39:11.065 - 00:39:53.625, Speaker C: So, sorry, I. I have a very simple question. I, I didn't understand how the other, the other metrics are impacted by these specific innovation. So if you could go deeper on that. Yeah, I mean, the HOW strategy. How solving strategy proofness is like the first step towards other metrics. I believe you said that, for example, the alignment with ground truth needs this in order to start going deeper.
00:39:53.625 - 00:39:54.977, Speaker C: So if you can explain that.
00:39:55.081 - 00:40:40.433, Speaker A: Yeah, I'm happy to elaborate on that one. Number one, we have, for example, we are at the moment running simulations on the majoritarian phantoms and nothing, any of the simulation setup we've tested so far has suggested there's an additional risk associated with majoritarian phantoms. So this is important to know. And of course we've also evaluated the other metrics here. Now, why is strategy proofness associated with alignment with ground truth? That's important to know. We. The impact equals profit is the key paradigm retrofunding is built on.
00:40:40.433 - 00:41:40.219, Speaker A: So the idea that projects or individuals who add value to the Optimism Collective and to the Optimism Network deserve funding and compensation for their work. Now the big question is how much funding do they deserve so that it's fair? And the idea of impact equals profit suggests that the profit they gain should be equal to the positive impact they made. And this is actually a great paradigm. Nevertheless, today we don't have any algorithmic way to measure the positive impact. Right. It's still hard to quantify exactly how much positive impact was made and how much funding they deserve. And it to some extent it's easier in rounds where we have projects that they can prove, for example, the fees they generated on the Optimism Network.
00:41:40.219 - 00:42:41.265, Speaker A: That's why we had in round four the KPI based. But now look at round five or round six where we have projects that are creating more indirect or a value that is harder to quantify. Right. And because we have this challenge that we can't simply take a sensor measuring and quantifying the positive impact we have voting because we have the badge holders and we have experts in the system who should have their say in determining how much funding they deserve, what their profit should be. Okay, this is this objective truth, like still we have some variance in how much they deserve. But step by step, and this is a paradigm also in social choice, there is some objective truth or ground truth the voters align on. And of course a voting rule should support this alignment.
00:42:41.265 - 00:43:29.659, Speaker A: Now, if voters are not incentivized to report their true preference and instead they can land at a for Their favorite project land at a better result by just misreporting their preference as we had in these examples. So they might think that project won where we had it. Let me just skip. Yeah, here they honestly think. Or let's look at voter one. He honestly thinks Project one is the one that deserves most. And to be safe, I even, you know, tweak the voting so that this project one gets even more due to my vote.
00:43:29.659 - 00:44:04.875, Speaker A: I vote strategically. Then the voting rule should not support this behavior and actually lead to a result that is better for we won. Instead, we should have a voting rule that says vote according to your true preferences. It won't be any better if you misreport. If you try to tweak it, it won't be better mathematically, it's not possible. Vote according to your true preferences. And only if we have this fundament we can rely on impact equals profit.
00:44:04.875 - 00:44:16.965, Speaker A: Right. Because otherwise this, this whole process in finding this objective truth is broken. And that's how these two are associated.
00:44:18.945 - 00:45:02.555, Speaker C: So one more question if I may. So I. I know you guys in, in Token Academy, Token Engineering Academy are exploring about reputation wave rotation. I understand that batch holders right now are not repetition weight, but like one batch holder, one vote, I guess is my phantoms compatible let's say with the addition of also reputation weight voting and is that something that you would advise in the sense that reputation could be also a factor or do you think it's better to keep it as it is?
00:45:03.625 - 00:45:05.489, Speaker A: Limerick. You switch on your camera.
00:45:05.617 - 00:45:06.185, Speaker B: Yes.
00:45:06.305 - 00:45:07.405, Speaker A: Shoot it away.
00:45:08.465 - 00:45:44.235, Speaker B: I mean here in the context of this project, we didn't consider it because I mean this was the grant boundaries to not touch like the way you weight voter and so on. My feeling is that, I mean you can add reputation to Madrid and phantom. Basically it gives weight. It's like weighted median. So median you can generalize by weight. And I assume that everything follows through for reputation weighted majorita and phantoms. It's a good idea.
00:45:44.235 - 00:45:59.805, Speaker B: We should check to see that really everything generalizes nicely. I mean strategy proofness will be satisfied. It's okay. But it really behaves nicely. And also, I mean it's not easy to do reputation weights as we all know.
00:46:01.785 - 00:46:30.779, Speaker A: Yeah. And I must say that's why we suggest this process. We have to go over these metrics to see if the combination of elements we have in a voting design really don't cancel out or eliminate a positive property. We were assuming in another context. And that's why it's worth going over these metrics to understand. And then Take the right decision. Sometimes there are trade offs.
00:46:30.779 - 00:47:20.817, Speaker A: In many cases, we found we can keep a balance, for example, in combinations of capping or meeting quorums and applying the median. But ultimately, to have, let's say, take the final decision on a voting rule per round, it's worth reviewing. Okay. We are trying to achieve the following design goals. This is the idea for the voting rule we have now. Could be at some point, and I must say I'd be excited for it to integrate reputation and then verify if there are any risks or problems. Thanks for the questions.
00:47:20.817 - 00:48:22.425, Speaker A: Any other questions or comments? Okay, in this case, we'll keep you guys posted. We started a thread on the Optimism Forum. At the moment we are in conversations with Jonas and the team how fast we can implement majoritarian phantoms. If there are any additional elements in round five, we should consider. Consider. And of course we are excited to evaluate, round by round, how the results would look like and how to improve retrofunding to make it ever more robust, less vulnerable to attacks, and step by step, coming closer to this impact equals profit and making all the projects adding value to the Optimism Network sustainable. Thank you for today.
00:48:22.425 - 00:48:47.355, Speaker A: Talk soon. And excited to see you at the Optimism Forum or one of our future events. And of course, if you have any questions or comments, just drop a note to the Optimism Forum post. Take a look at our mirror. Happy to continue the conversation. Thanks everyone. Talk soon.
00:48:49.735 - 00:48:50.047, Speaker B: Bye.

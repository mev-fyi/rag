00:00:00.250 - 00:00:06.160, Speaker A: You okay? It's running. And then I'd say we are good to go.
00:00:07.250 - 00:00:07.998, Speaker B: Cool.
00:00:08.164 - 00:00:46.810, Speaker C: Thanks, Angela, for inviting me. Thanks everyone for having me. Nice to meet you all. I saw some of the recording from last week's kickoff, so I know a little bit about some of you backgrounds to introduce myself a little bit and talk a bit about my background. Then, um, I'm a systems control engineer by education. I graduated engineering school here in the city where I live in Brazil in 2004. For a while there, I founded a startup, mobile gaming startup.
00:00:46.810 - 00:01:58.210, Speaker C: Back before the iPhone or Android or any of that. We ran it for about three to four years. After that, I went on to work on a government agency in Brazil. I left my hometown to go work there. My last job there at the government agency was leading a team of data scientists running heuristics and machine learning models on public data sets to identify possible cases of fraud in public expenditure. At some point in around 2006, I'd say I got involved with the maker Dow community and started working along with another brazilian friend who ended up becoming the CEO and co founder of Balancer, Fernando Martinelli. I was working with him on stability simulations for DAi, trying to apply control theory to their stability mechanisms.
00:01:58.210 - 00:03:10.026, Speaker C: That caught the eye of Michael's argument, block science, which ultimately led me to being invited to join block science, which I did in 2008. Late 2007, early 2008 work at block science until around September October last year as a research engineer, working mostly on developing the development of CAD. CAD, not the development per se, but on a macro level, acting as a subject matter expert on the development of CaDCAD and with some research projects for clients. And in September, I got a proposal to join Balancer, doing a bit of data science, a bit of engineering and component design. So this is where I'm at now. We're very excited with the projects with you guys, the collaboration with you guys, and we hope to see a lot of what we expect, and we hope to see a lot of good things come out of this collaboration. We have a lot of things to, a lot of questions to answer.
00:03:10.026 - 00:03:30.800, Speaker C: People ask us a lot of things that we don't know the answers to because we have never done much rigorous simulation on these specific things that we're being asked. So I think the joint collaboration between the communities is going to be very fruitful and we can draw a lot of value from that.
00:03:31.330 - 00:03:57.320, Speaker A: Cool. I suggest that before we move on with the content, maybe you want to switch on the camera, everyone. We can't have a proper introduction round with everyone today, but I think it will be nice to just see everybody's face and. Hi, Mark. George. Hello, George. From Romania, by the way.
00:03:57.320 - 00:04:02.220, Speaker A: China, us, just woke up Solomon. Hi.
00:04:03.470 - 00:04:04.170, Speaker B: Okay.
00:04:04.320 - 00:04:08.940, Speaker A: Hello, everyone. Good, let's go.
00:04:10.370 - 00:04:11.118, Speaker B: Cool.
00:04:11.284 - 00:04:26.130, Speaker C: So I have small presentation here to talk a little bit about to help guide the conversation about balancer V two. Can I share the screen, Angela?
00:04:26.470 - 00:04:27.810, Speaker A: Yeah, go.
00:04:27.880 - 00:04:28.850, Speaker B: It's locked.
00:04:42.570 - 00:04:45.298, Speaker C: Do you still see it? If I go into presentation? Load.
00:04:45.394 - 00:04:46.760, Speaker A: Yeah, we see it.
00:04:50.090 - 00:04:51.634, Speaker C: Loading, loading, loading.
00:04:51.682 - 00:04:53.320, Speaker B: Yeah. There we go.
00:04:54.170 - 00:05:33.320, Speaker C: Okay, so this is balancer V two. Me, deep dive. Not really a dive, but hopefully something that can get the conversation started. And I'll try our best to answer everyone's questions, even though I'm not keeping the weeds in the implementation of the solidity code. But, yeah. So, to give a brief overview of what we were looking for when designing balancer V two, these were the key tenants of balancer V two. Right.
00:05:33.320 - 00:06:53.454, Speaker C: We see the landscape in crypto, and defiant in particular, moving very fast. So we wanted to build something that was flexible and was able to keep up with the new times. As new demand comes up and traditional Uniswap 50 50 pool becomes obsolete, or a uniswap V two pool becomes obsolete, and then comes Uniswap V three. In the same way the balancer pools from view one, you can think of them as becoming obsolete in the sense that there's demand for more sophisticated products, which those pools cannot, cannot meet. And we wanted to make it so that people wouldn't have to constantly migrate their liquidity from one protocol to the next, but rather stay within this broader ecosystem of solutions. That makes it easier for you to go from one solution to the other as things start showing up. So we wanted to enable new forms of amms to be built on top of a common base.
00:06:53.572 - 00:06:54.240, Speaker B: Right.
00:06:55.250 - 00:07:23.014, Speaker C: The next thing was capital efficiency. We know from the basic design of amms, as we said in the documents announcing v two and as Uniswap v three started pointing in the same direction, that most of the liquidity that is in a pool was never really actually needed for trades to happen against that pool.
00:07:23.062 - 00:07:23.274, Speaker B: Right.
00:07:23.312 - 00:07:38.314, Speaker C: So if you think about the 50 50 uniswap pool, you have liquidity across the entire space of the possible balances. So any price is possible given the curve.
00:07:38.362 - 00:07:38.814, Speaker B: Right.
00:07:38.932 - 00:07:53.678, Speaker C: You can have prices from zero to infinity, but in reality, prices tend to stay a lot longer, fluctuating around the same point. So you really only need liquidity around that point for the purposes of swapping.
00:07:53.774 - 00:07:54.178, Speaker B: Right.
00:07:54.264 - 00:08:52.962, Speaker C: So how can we make it so that not so much capital is locked up for the purposes of enabling swaps that don't really require all that capital. So how can we take that into account? And the third point was gas efficiency. We saw with free one, how swapping against balancer and providing liquidity on balancer was very gas intensive. And balancer was developed at a time when gas prices weren't so much of a concern. And not so long after balancer launched, after balancer v one launched, we saw gas prices go up and basically never come down again. So that started being a real burden on traders, to the point where we would see many trades not go through balancer because the swap cost was not. The swap cost just didn't make it feasible.
00:08:52.962 - 00:10:02.614, Speaker C: Even though the price was better, the spot price was better at the balancer pool. So this is what we were going for, and what we landed on was the single vault architecture as a way to enable that, right? Basically, if you think about how things work in Balancer v one for comparison, you have this, right? Every pool has its own assets. The assets are actually stored in the pool in the sense that ERC 20s are stored in a smart contract, right? You have the ERC 20 table that does the accounting actually contains a record saying that this much dai is in pool a and this much bow is in pool b. And each pool has its own logic within it, right? In balancer v one, the pools were all of the same kind. They were all concentrated product pools. So the logic of all the pools were the same. And what we would have would be connectors to those pools that would make changes, would make tweaks to the logic.
00:10:02.614 - 00:10:24.690, Speaker C: So, for example, a controller of a pool could make a change to the Swat fee, or could make a change to the weights of that pool, right? But it's not an internal property of the pool per se. It's not that the pool itself is mutating or has more sophisticated logic, but rather, it has a parameterized logic, and the controller can alter its parameters.
00:10:25.290 - 00:10:26.040, Speaker B: Right?
00:10:27.130 - 00:10:42.394, Speaker C: In balancer v two, what we're going for is a vault that actually holds all the tokens and does the accounting of how many tokens each pool holds. So each pool can have its own.
00:10:42.432 - 00:10:46.966, Speaker B: Logic, independent of a controller, and communicate.
00:10:46.998 - 00:10:51.614, Speaker C: With the vault, saying, letting the vault know how to update the accounting based.
00:10:51.652 - 00:10:52.830, Speaker B: On that logic, right?
00:10:52.900 - 00:10:56.030, Speaker C: So if I go into the vault and say I want to swap.
00:10:57.970 - 00:11:02.942, Speaker B: Ten die on pool x, the vault takes.
00:11:02.996 - 00:11:11.154, Speaker C: That ten die, and x po x poo x. These are your balances. You hold x amount of die, x amount of eth, and x amount of.
00:11:11.192 - 00:11:15.678, Speaker B: Bow and user a wants to give you ten die.
00:11:15.774 - 00:11:42.654, Speaker C: What do you give them? And they want to take out bow. How many bow do you give them back? And the vault does that. Accounting for the pool, right. Takes care of subtracting, deducting the amount of bow, and increasing the amount of die of the pool. But the pool can be basically anything. The pool can have a linear prices, constant prices, constant weighted products. X times y equal k equals k.
00:11:42.654 - 00:11:52.618, Speaker C: Like uniswaps, basically anything can be built on top of the vault, because the pool is simply communicating with the vault, and it holds all the logic and.
00:11:52.804 - 00:11:54.210, Speaker B: None of the balances.
00:11:54.950 - 00:12:11.558, Speaker C: This means that especially for. Well, I'll get to that later. I want the spoilers because I have another slide on that. So this is sort of the general design, the general architecture that covers the.
00:12:11.564 - 00:12:15.560, Speaker B: Flexibility point that we were looking for, right?
00:12:18.030 - 00:13:08.566, Speaker C: And then what we also get from that is a few other interesting points that allow us to allow us to achieve those streaming goals that I talked about. So, the first them is gas optimization, right? Because you have all the assets within the vault, there is no transfer of ERC 20 tokens between the pools. The vault is doing all the accounting, right. It doesn't have to do an external call to another contract, meaning Dr. C 20 contract to say, transfer x amount of die from pool a to pool b, because user is doing a multi hop swap that requires them to trade die for Eth in one pool and then Eth for bow in the other pool, and then bow for wrap bitcoin in another pool.
00:13:08.598 - 00:13:09.626, Speaker B: For example. Right.
00:13:09.728 - 00:13:32.830, Speaker C: In v one, this would require transfers from transfers between four addresses, the users and the three pools that I mentioned. In v two, there's only two token transfers. There is a token transfer going from the user to the vault, and then another token transfer from the vault to the user. The vault does all the accountings of what happens with the balances of those three pools.
00:13:33.190 - 00:13:33.940, Speaker B: Right.
00:13:36.470 - 00:14:43.510, Speaker C: In addition to that, we also have the concept of internal user balances. So you, as the holder of a private key of an EOA, you can have an internal balance at the vault. Not only does the vault handle the accounting for all the pools, it also handles the accounting for any user, which means that you don't even have to transfer tokens into and out of the vault if you're keeping it as an internal balancer. As an internal balance. So if you're a frequent trader looking at arbitrage opportunities or just doing trades by hand every week or something, you could keep that as internal balance. And it would be just as safe as holding it. In an audited smart contract, like a smart wallet or a multisig, you have full control over your assets, but you don't have to transfer them into and out of the vault, which makes the optimizations even cheaper.
00:14:43.510 - 00:14:58.526, Speaker C: This is some preliminary data that we have on v two. We have deployed the smart contracts last week. We are running some tests on the.
00:14:58.548 - 00:15:01.454, Speaker B: Front end, but we haven't deployed the UI yet.
00:15:01.492 - 00:15:36.666, Speaker C: We haven't announced the UI. The UI is coming next week. But some of the preliminary data that we have shows this, that for a trade one transaction, each dot in the scatter plot is a transaction, right. And then on the x axis, we have the number of swaps in that transaction. So the number of swaps is how many pools did the transaction go through, or even maybe it went through the same pool twice, which is not often the case. And how much gas was used by the transaction as a whole.
00:15:36.768 - 00:15:37.130, Speaker B: Right.
00:15:37.200 - 00:16:21.206, Speaker C: So in v one, you can see how this has a great variance, of course, because we have a lot more variance on the token front and on things that might be happening sort of simultaneously with the transaction at the same time. Even though this is not taking into account transactions done via smart contracts, it's only taking into account transactions done on the exchange proxy in v one. So it reduces that risk a little bit. But you can see still a large variance, given the variance of tokens. And you can see how the prices increase. First, the prices are a lot higher and how they increase a lot more with every swap, whereas in v two, it increases a lot less per swap.
00:16:21.318 - 00:16:21.738, Speaker B: Right.
00:16:21.824 - 00:16:36.800, Speaker C: So the medians that we have for this, for example, the median for gas, units of gas per swap is at around 153 for 153,000 for v one and around 104,000 for v two.
00:16:38.370 - 00:16:40.350, Speaker B: Is that a catcat chart?
00:16:40.850 - 00:16:43.630, Speaker C: No, this is a June. This is done on June.
00:16:44.230 - 00:16:44.980, Speaker B: Cool.
00:16:46.550 - 00:16:55.618, Speaker C: Something we put on June. I can share the link with you later. We have a dashboard where we're monitoring this, especially looking into next week.
00:16:55.704 - 00:17:04.950, Speaker A: Oh, yeah, this would be cool. And am I wrong? After four swaps, I don't see any gas costs in v two, but I don't think that this can be the case.
00:17:05.100 - 00:17:24.574, Speaker C: No, this is probably some fluke on the data, the zeros here. But maybe, I don't know exactly what caused this. I think it's a fluke on Dune. The way that dune plots things, you can see that we only have one data point for a three swaps transaction, so we don't have a lot here to go for. And we don't have any data points.
00:17:24.612 - 00:17:27.040, Speaker B: On for swaps or sections yet.
00:17:28.210 - 00:17:30.720, Speaker C: We should see some of those start popping up next.
00:17:31.170 - 00:17:40.210, Speaker A: I see. Oh yeah, makes sense. There are some questions in the chat already and I just wanted to ask, do you have a hard stop? When do you have to leave? Marcus?
00:17:40.550 - 00:17:45.540, Speaker C: I can stay until the end. I can stay for another one and a half hours.
00:17:45.850 - 00:17:46.726, Speaker A: Oh awesome.
00:17:46.828 - 00:17:47.046, Speaker B: Yeah.
00:17:47.068 - 00:17:58.650, Speaker A: Then brilliant. Then we might take a look at Tana. How do you handle adding more tokens safely? Tana, this question refers to the vault topic.
00:17:59.470 - 00:19:05.322, Speaker C: Yeah, I was just wondering, the core accounting contract that manages all the token balances, what's the process by which someone, say, adds another token? And how do you manage the differences between tokens, say for example, simple examples of precision or the decimal places? And I was wondering if you wrap them in a uniform interface or something? Good question. Yeah. On the vault, we don't do anything on the vault. We simply receive the tokens and they are stored in the vault as native tokens in whatever token they are. Where precision starts making a difference is on the logic for the weighted pools. So what we do is every time that a weighted pool registers with the registers a token. So when a weighted pool is created, when one of those pools is created, it queries the token for the number of decimals so that it can store a scaling factor for that token.
00:19:05.466 - 00:19:05.966, Speaker B: Right.
00:19:06.068 - 00:19:24.606, Speaker C: So if you think about USDC and rep eth, for example, for example, USDC has six decimals and rep e 18 in the vault. They are stored as USDC and as rep e. No difference. But on the weighted pool that holds those tokens, ultimately holds those tokens.
00:19:24.638 - 00:19:25.220, Speaker B: Right.
00:19:26.010 - 00:19:48.506, Speaker C: The math is done with a scaling factor of twelve on the USDC. So all USDC balances are multiplied by twelve before doing any math on them. Right. Okay, so I'm just trying to think about. Sorry, I said multiplied by twelve and then multiplied by 110 to the twelve. Right?
00:19:48.608 - 00:19:49.260, Speaker D: Yeah.
00:19:51.570 - 00:20:06.770, Speaker C: But without. I'm assuming that the actual accounting, you don't need to actually go into the specific token contract. So you're representing them internally, right?
00:20:06.840 - 00:20:07.122, Speaker B: Yes.
00:20:07.176 - 00:20:11.374, Speaker C: You don't have to go to do the accounting. You don't have to go into the token contract.
00:20:11.422 - 00:20:12.274, Speaker B: You're right.
00:20:12.472 - 00:20:26.322, Speaker C: Okay, so what we have is we know the balance of that token on the vault, right? We know the total balance of that token on the vault. We can query that from the token contract directly.
00:20:26.386 - 00:20:26.758, Speaker B: Right.
00:20:26.844 - 00:20:47.406, Speaker C: And then what the vault has is a mapping for each one of the pools. It has a mapping of the balance of each one of those tokens in each one of those pools. So every time that a user wants to trade something with a pool, the vault increments the balance of that token for that pool and decrements the balance of the token that the pool is giving back.
00:20:47.588 - 00:20:47.982, Speaker B: Yeah.
00:20:48.036 - 00:20:53.178, Speaker C: Okay, got you. This is very similar to the Vat and makers architecture.
00:20:53.274 - 00:20:55.586, Speaker B: I think if you're familiar, I think.
00:20:55.608 - 00:21:03.826, Speaker C: You'Re probably familiar with that. I used to be familiar with the maker nomenclature, but that was a long time ago.
00:21:03.928 - 00:21:04.482, Speaker B: Yeah.
00:21:04.616 - 00:21:06.630, Speaker C: Daiwini is its own language.
00:21:07.930 - 00:21:08.438, Speaker B: Okay.
00:21:08.524 - 00:21:14.840, Speaker C: All right, thank you. Any other questions we want to address before moving on?
00:21:15.370 - 00:21:15.830, Speaker B: Yeah.
00:21:15.900 - 00:21:33.678, Speaker A: Kirty, do you want to jump in? I guess this was a comment. Beep. One, pool design had some advantages for institutional use. Don't know if you want to elaborate on that, Kirt.
00:21:33.714 - 00:22:13.298, Speaker E: Yeah, sorry, I was on mute as usual. The question is, I think V one and V two have their own strategic strengths for institutional customers. For example, when you look at the version one, I think it's really significant to have this design because certain regulators prefer to ring fence their specific capital. So for example, there's capital reserving which is required for certain financial instruments. And yet we are looking for liquid at the same time. But having such a structure may help us to kind of give that regulatory certainty. And I think that also is required, possibly.
00:22:13.298 - 00:22:23.240, Speaker E: So will these both models continue to coexist or will the version one be decommissioned and the version two will completely take over?
00:22:23.850 - 00:22:35.062, Speaker C: Right. So the V one can never be stopped. The V one will live forever because we have no control over the smart contracts in V one. So there's nothing we can do to stop V one from staying alive.
00:22:35.126 - 00:22:35.402, Speaker B: Right.
00:22:35.456 - 00:23:32.880, Speaker C: If people want to keep providing liquidity in V one, they will keep providing liquidity in V one. We do not intend to stop directing trades through V one on our UI. We have no plans for that. But we will be migrating liquidity incentivization to v two because we know how much liquidity fragmentation hurts users, both liquidity providers and traders. Liquidity providers end up not getting as much volume as they could, therefore not as big of an APY, and traders end up not getting the best prices because of this fragmentation. So we want to keep fragmentation to a minimum and only where strictly necessary. So if there is reason for institutional investors to stay within v one, even though I must confess I don't exactly follow what those reasons are.
00:23:32.880 - 00:23:44.820, Speaker C: They can still stay on view one and again, one inch matcha. All the aggregators will still be plugged into view one and our own interface as well.
00:23:45.670 - 00:24:13.610, Speaker E: Okay, just to add another comment, the regulators prefer specific pools or cap pools to have individual asset and liability audits. So, example, you can't mix two specific pools of capital, yet you can provide liquidity using different pools. So in such a scenario, it requires for you accounting specific to one specific pool without intermixing assets or the capital.
00:24:15.790 - 00:24:50.594, Speaker C: But to be clear, the pool still has full control over their assets, right? Even though the assets are. It's merely from a logical perspective that the assets are stored in the vault. But how do I put this? It's provably under the control of the pool token holders, right? The ownership of the pool is represented by a token, the BPT, the balancer pool token. So each pool has its own BPT, which represents ownership of that pool.
00:24:50.642 - 00:24:50.854, Speaker B: Right?
00:24:50.892 - 00:25:14.160, Speaker C: So if you have all the BPT of that pool, then you have full control of that pool. And the only way that you can withdraw the assets from the vault that correspond to the balance of that pool is by burning that PPT, so no one can touch the balance of the pool. If the pool is not designed to be as such. Does that make sense?
00:25:17.810 - 00:25:36.710, Speaker A: And I guess this also answers mark's question on the cross pollination between pools. So it's not that, it's just because of we have one vault, there will be an ongoing mess. You have this assignment of each token is assigned to a particular pool represented by the BPT.
00:25:37.930 - 00:26:05.360, Speaker C: Exactly, yes. Like I said, it's merely from a logical perspective. If you think about it, what are your c? An ERC 20 is a smart contract that has a table saying user x owns Y amount, user z owns a amount, and so on. It's basically what we're doing is one of those lines. We are breaking it up into several different lines at the vault level.
00:26:05.810 - 00:26:06.222, Speaker B: Right.
00:26:06.276 - 00:26:39.260, Speaker C: The year C 20 contract is going to say the vault holds 1000 die, and then the vault is going to say, okay, after 1000 die, ten is on pool a, 20 is on pool b, and 30 is on pool c. And the only way that you can change that table, similarly to the only way that you can change that table on the ERC 20 side, is by owning the private key of that line. On the pool side, it's the same thing. The only way that you can change that, modify that table, is from the pool's perspective, the pool is the only one that can make those changes by informing the vault how to make those changes.
00:26:41.790 - 00:26:54.320, Speaker A: Okay, and then we have another question. Joy Dipto, does v two have more off chain trades? And that's how gas fees are lower.
00:26:55.810 - 00:27:28.166, Speaker C: So two things there. Let's separate two things then. Balancer v two on its own, the balancer protocol on its own does not have off chain transactions. So that's not where the gas efficiencies I was talking about here come from. But the gas efficiencies come from one, the fact that the vault and the trades were optimized for gas efficiency. So even on a one swap trade.
00:27:28.358 - 00:27:30.490, Speaker B: Let me go back to that slide.
00:27:31.950 - 00:27:34.998, Speaker C: So even in a one swap transaction.
00:27:35.094 - 00:27:37.226, Speaker B: So balancer v one, right?
00:27:37.248 - 00:28:32.286, Speaker C: So let's think about balancer view. One swap transaction is only doing one token transfer from the user to the pool, and then another token transfer from the pool to the user. Each token transfer costs gas, right? Because you're doing processing on the yearc 20 smart contract, there's processing being done there. So for every transfer, there's cost. There's cost. So a single swap on a v one, two transactions, two transfers, one into the pool, one out of the pool. Multi hops on balancer view one, require you to transfer some asset from your address to the first pool, and then from that pool to the second pool, and from the second to the third, and then from the third back to yours, right? Suppose you're doing a die to bitcoin that goes die bow one in one pool, then bow eth in the other pool, and then ETh bitcoin, and the bitcoin comes back to you.
00:28:32.286 - 00:28:44.498, Speaker C: That's 1234 transfers, right? So it costs more. In balancer v two, we save those extra transfers because there's no transfer happening.
00:28:44.584 - 00:28:46.546, Speaker B: From one pool to the next.
00:28:46.648 - 00:28:55.042, Speaker C: It's just the vault doing internal accounting. And that internal accounting is much cheaper than external transfers on a different smart contract.
00:28:55.186 - 00:28:55.542, Speaker B: Right?
00:28:55.596 - 00:29:00.966, Speaker C: The external transfers on the yearcrain. That said, you might have seen the.
00:29:00.988 - 00:29:04.954, Speaker B: Announcement early this week or last week.
00:29:05.072 - 00:29:55.818, Speaker C: On the diagnosis partnership, which will do sort of off chain transactions. What the Gnosis partnership is going to do is that gnosis is going to be integrated with balancer v two to the point where multiple trades happening at the same time will be settled on balancer v two, but will be solved off chain by what they call solvers. Solvers will find this sort of common interest. So I want to sell Dai for ETH, and one of you wants to sell Eth for Dai. We don't have to both go to the pools to do that. The solver does the matching offline off chain and only sends the settlement to the Balancer pool, right? Whatever is in excess, whatever can be settled off chain then goes to the.
00:29:55.824 - 00:29:58.810, Speaker B: Balancer pools and uses the balancer liquidity.
00:29:59.150 - 00:30:34.998, Speaker C: So that will change the game significantly because it will make many trades virtually free because you're not having to pay for gas costs, you're only paying for the solvers. And the solvers are, at least in the beginning, highly incentivized on diagnosis to do the solving. And later on, it's a different market than the Ethereum mining transaction mining market. And things will change a lot and.
00:30:35.004 - 00:30:36.360, Speaker B: We'Ll see how it plays out.
00:30:37.530 - 00:30:46.346, Speaker A: That's also pretty exciting. Or dedicated. I think this would be worth having a dedicated talk. That's what I wanted to say.
00:30:46.528 - 00:30:47.018, Speaker B: Cool.
00:30:47.104 - 00:30:51.180, Speaker A: Very cool thing. Joy, does this answer your question?
00:30:52.830 - 00:30:54.746, Speaker F: Yeah, it does. Thanks for that.
00:30:54.928 - 00:30:57.900, Speaker A: Okay, cool. And how should we call.
00:30:59.870 - 00:31:08.346, Speaker F: Dip is just my discord name, so I thought I'd change to that just to avoid. Although to avoid confusing. It seems like it's confusing. Imon.
00:31:08.458 - 00:31:09.002, Speaker C: Imon.
00:31:09.066 - 00:31:09.978, Speaker B: Okay, thanks.
00:31:10.084 - 00:31:29.320, Speaker A: Just on a side note. Okay, questions are flooding in. Two more questions. But I think it's pretty cool that we can dig into it because it helps everybody to understand. So, Marcus, if you don't mind, take them octopus. Maybe you just want to say it yourself.
00:31:33.910 - 00:31:48.620, Speaker F: Hope my audio is working. So, is the idea that with the vault, you're able to move things around sort of within your own bank, rather than having to always put them on the truck and deliver them somewhere else? Is that the basic idea or is it something else?
00:31:51.390 - 00:33:29.898, Speaker C: I think it's a good analogy, but another way to think about it is instead of thinking about the truck, just think about the. Think about having several different accountants working at the same time. And in the v one multiple strategy to go back. Each accountant is each one of the yearc 20 smart contracts, right? Each one of those is an accountant, and they only do accounting for the one thing, for the token that they handle, right. The die smart contract does accounting for the die token and so on. So if each pool is transferring assets to the next, like in V one, then what it means is that each pool is telling that accountant subtract my balance by x, add x to the balance of the other pool, and so on, right? So this communication between the pool and the accountants is expensive, is the expensive part, because you not only have to pay for the call to an external contract, which is one of the expensive actions in Ethereum, but also for all the accounting that that particular ERC 20 token is doing, which might be something beyond what normal ERC 20 tokens do.
00:33:29.984 - 00:33:30.620, Speaker B: Right.
00:33:32.430 - 00:34:00.318, Speaker C: What we have in the vault is that you have one accountant the vault, taking care of the accounting for all of those tokens for the pools. So no longer that accountant, the DAI accountant, or the rapid, you see, accountant has to be called, or that there's transactions happening. Because from their perspective, nothing's changing. Everything is still on the vault.
00:34:00.414 - 00:34:00.770, Speaker B: Right?
00:34:00.840 - 00:34:16.934, Speaker C: Nothing moved from the perspective of the DAI accountant. Things only moved from the perspective of the vault accountant. So in particular, you save that external call to the yearclaim. That's the biggest change that's transferred events and all that.
00:34:17.132 - 00:34:28.582, Speaker F: So instead of having the accountants, each in their own separate office and having to send messengers to them, you've put them in the same room so that they can share each share information. Is that more accurate?
00:34:28.646 - 00:34:29.402, Speaker B: Okay, thank you.
00:34:29.456 - 00:34:32.160, Speaker C: That's a good analogy. Thank you for that.
00:34:34.210 - 00:34:37.200, Speaker A: Then there's David. Solvers are then.
00:34:42.290 - 00:35:36.020, Speaker G: Yeah, basically, I was hoping to understand the role of the solvers a little bit better. I flipped this up in the meantime. So to me, it appears the one question I have is what I'm actually quoting from the publication by gnosis, solvers are encouraged to compete against each other to deliver the best order settlement for traders in exchange for the reward of each batch. What does best mean in this case? How is this determined? Because I think you mentioned that there is heavy incentivization from the perspective of gnosis for the solvers. And that is what triggered kind of my question to ask for how sustainable this is. If this actually depends on heavy incentivization, I would reword my question now and ask, in terms of best order settlement, how is that determined if there is a large set of solvers and they are actually competing against one another?
00:35:36.790 - 00:36:09.610, Speaker C: Good. I'm not entirely familiar with the dynamics of the solvers on that level. I would say they have a KPI for best execution prices for the traders, or the best match within the batch without having to resort to an external resource, to external liquidity. But that's just my guess. I'd say at this point, I'm not dipping the weeds with the dynamics there.
00:36:09.680 - 00:36:22.382, Speaker G: Okay, so you're not aware. Okay, sorry. I was just wondering if there was some sort of a globally defined cost function that we would basically be relying on here. But I'll dig a little bit deeper into this.
00:36:22.436 - 00:36:23.040, Speaker B: Thanks.
00:36:23.510 - 00:36:33.538, Speaker A: And maybe a good opportunity to invite nosis to some of the later calls on this topic as well, and invite Martin, for example.
00:36:33.704 - 00:36:34.420, Speaker B: Good.
00:36:36.570 - 00:36:44.840, Speaker A: More questions are coming in. Vasili, how off chain transactions will change arbitrage, the whole arbitrage process.
00:36:46.650 - 00:37:36.406, Speaker C: So the arbitrage, of course, every arbitrage that can happen on chain will still happen. And we'll surely see some attempts to front run the solvers transactions from mev extractors. But what it changes, I would say, is that it probably makes it less, it will probably create, and again, something to simulate and look at the scenarios. But my initial hypothesis would be that it would reduce the frequency of arbitrage opportunities, because a lot of the arbitrage opportunities would not exist because of the matching done at the silver level.
00:37:36.508 - 00:37:36.870, Speaker B: Right?
00:37:36.940 - 00:38:16.114, Speaker C: So think, for example, if I'm buying Dai on the Eth dai pool, and immediately after that, someone is trying to buy eth on the ethi pool. In between those two, there's an arbitrage opportunity, right? The price is off sync. The price is probably off sync after I make my purchase. An arbitrager can go to a different resource, a different source of liquidity, and do that arbitrage trade. And then the Ethi comes back, comes in the second purchase, retail purchase kicks in, and there's another arbitrage opportunity.
00:38:16.232 - 00:38:16.562, Speaker B: Right?
00:38:16.616 - 00:38:39.434, Speaker C: So potentially there's that scenario. In the silver situation, that scenario would not exist because those two transactions, because those two trades are close enough that they would be batched together by the solver and only the exceeding amount would be sent on chain. Yeah.
00:38:39.472 - 00:38:51.230, Speaker H: So if you will have two trades, for example, one e per 3.5 thousand die, and the amounts are exactly the same, there wouldn't be any change of balances in the pool, right?
00:38:51.300 - 00:38:51.920, Speaker C: Correct.
00:38:52.710 - 00:38:53.460, Speaker B: Interesting.
00:38:54.070 - 00:38:54.980, Speaker C: Thank you.
00:38:56.310 - 00:38:56.722, Speaker B: Cool.
00:38:56.776 - 00:39:00.290, Speaker A: Jesus. With the next question, what about rebasing?
00:39:01.510 - 00:39:11.400, Speaker D: What about rebasing tokens? That I know that there are some kind of difficulties in that kind of token. So in order to see what was the limitation about.
00:39:13.450 - 00:39:45.726, Speaker C: We chose not to support rebasing tokens. Supporting rebasing tokens would mean an increased cost for all trades because of the accounting, because of the way that accounting is done on the vault. Basically, the vault requires that the transfers map exactly to the balance change. So the amount that's transferred is exactly the amount by which the balance has changed. And that's not the case for rebasing tokens.
00:39:45.758 - 00:39:45.858, Speaker B: Right?
00:39:45.864 - 00:40:09.900, Speaker C: Because your balance can change because of the rebasing. So it was a difficult decision. We discussed it a lot internally, but ultimately ended up deciding not to support rebasing tokens. For that reason, we wanted to optimize for gas, and we saw rebasing tokens as something that we could potentially cut out for the moment.
00:40:10.430 - 00:40:17.910, Speaker B: Thank you. You're muted.
00:40:18.410 - 00:40:19.160, Speaker G: Yes.
00:40:21.930 - 00:40:32.842, Speaker A: Sorry, I'm muted. What do you think about time, I'm not sure about the content. You still haven't been able to show us. Should we continue first with.
00:40:32.976 - 00:40:39.982, Speaker C: I don't have a lot of slides left. I think I can finish this and then we can go back to questions.
00:40:40.116 - 00:40:40.800, Speaker B: Good.
00:40:42.610 - 00:41:03.842, Speaker C: It's not a lot. We covered much of it. So the other topic was, I think we covered a lot of this already, is the fact that we have, again, customizable ama logic. So, like I said in the previous chart, you can have any kind of logic in the pools, because the vault.
00:41:03.906 - 00:41:07.000, Speaker B: Is always basically asking.
00:41:08.090 - 00:41:19.834, Speaker C: Brazilians tend to homomorphize things a lot. So forgive me if I say the vault is always constantly asking the pool, what do you want to do with this?
00:41:19.872 - 00:41:20.074, Speaker B: Right.
00:41:20.112 - 00:41:27.086, Speaker C: So I'm giving you ten die. How much are you going to give me back? How much are you going to give this user back?
00:41:27.188 - 00:41:27.840, Speaker B: Right.
00:41:29.810 - 00:42:04.620, Speaker C: So because of that, you can have basically any kind of pool that you can think of. We have launched with weighted pools, which are limited currently by the current factory. They are limited to eight token pools, and they have constant weights, constant fees. They cannot be changed. They're basically the same, similar to immutable v one pools. You can be the owner of that weighted pool, and then you have the ability to change the fees, and governance has the ability to.
00:42:08.990 - 00:42:11.530, Speaker B: Authorize another account.
00:42:11.600 - 00:43:21.700, Speaker C: To set the fees of that smart contract, which is what we are doing with gauntlet for a set of pools, the dynamic fees pools by Gauntlet. We're also launching with a specialized version of those weighted pools, which only take in two tokens and have an oracle like uniswap v three oracle, what do you call it? Geometric mean time weighted average price. We are planning on launching stable pools, like stable pools curves, which is a curve that's more fitting to tokens that trade not at parity per se, but at a more constant price, closer to a more constant price to basically concentrate liquidity around that point. And we still have in the pipeline smart pools and lbps. Lbps are a big thing in balancer. We have a lot of interest coming out of that. So that's coming very soon.
00:43:21.700 - 00:43:49.728, Speaker C: And then we have what's probably the biggest innovation in capital efficiency, which are the asset managers. So asset managers are specific accounts or smart contracts that are authorized by a pool to manage their token balances, that pool's token balances on their behalf.
00:43:49.824 - 00:43:50.420, Speaker B: Right.
00:43:50.570 - 00:44:33.216, Speaker C: So how this works is that I simplified a bit before, and it's where I complicate a bit. When the vault does the accounting of the pools, it's not only looking at the balance of the pool, but rather that balance is split in two. What we call the cash balance and the managed balance, right? For a pool that chooses to not have an asset manager, their total balance is always the cash balance, which is what the pool has available at that moment. And anyone can trade against that. But if a pool chooses to have an asset manager, it delegates control to that asset manager to withdraw some of.
00:44:33.238 - 00:44:36.596, Speaker B: Its assets from the vault, use it.
00:44:36.618 - 00:44:41.220, Speaker C: Somewhere else for something else. But the pool continues to do all of its math.
00:44:42.120 - 00:44:44.996, Speaker B: Assuming it has the full balance, right?
00:44:45.098 - 00:45:15.250, Speaker C: Because in reality it does. To the extent that it can at any point withdraw their tokens from the asset manager, it has full control over that. As long as that asset manager has not put that money to use somewhere where it's locked up, right? So think about it. Let me give an example. We are working with Aave to launch the first asset manager which is going to take assets from a pool and.
00:45:15.700 - 00:45:18.496, Speaker B: Land it on Ave, right?
00:45:18.678 - 00:45:42.356, Speaker C: Ave has pretty liquid markets. So anytime a pool needs its capital back, it can just withdraw from the asset manager. If there comes a point where the utilization ratio on Ave is so high that you cannot withdraw because all the lendable assets have been borrowed. So in case someone is not familiar.
00:45:42.388 - 00:45:45.064, Speaker B: With the way AVi works, basically, as.
00:45:45.102 - 00:46:19.940, Speaker C: A lender, you pull your assets. You deposit your assets in pool of lendable assets, and you start accruing interest on that. Even if your asset is not borrowed, right, you have a utilization ratio or a borrowing ratio of that pool of assets. And the returns, the interest rate paid for the lenders, paid by the borrowers to that pool of lenders depends on that utilization ratio. Higher utilization ratios means higher interest rates. Because you want to incentivize lenders to pull more assets into the pool.
00:46:21.000 - 00:46:25.216, Speaker B: But if the entire pool is borrowed.
00:46:25.248 - 00:47:20.676, Speaker C: Out, then you can't withdraw, right? That's the risk that you're running. That's the risk of momentarily not having your capital that you have as a lender. Is that if all the assets are borrowed out, or if more is borrowed out, then if less is left in the lending pool than you have deposited, then you can withdraw all your money back. So the same thing applies for the pool. If the asset managers deposits the pool's assets into the ave lending pool, and all of that is borrowed, then the pool suddenly can't withdraw from the assets from the lending pool. So that's where it starts becoming. Where things start taking a more complex, taking more complexity.
00:47:20.676 - 00:47:23.464, Speaker C: Because now you have to carefully design.
00:47:23.582 - 00:47:33.900, Speaker B: Asset managers, so as to not let the pools be completely drained out. Right.
00:47:33.970 - 00:47:35.548, Speaker C: You have to have some cash in.
00:47:35.554 - 00:47:38.504, Speaker B: The pool so that the pool can do trades.
00:47:38.632 - 00:47:44.016, Speaker C: Because once the cash is depleted, you don't have assets to pay back to.
00:47:44.038 - 00:47:46.912, Speaker B: The traders, and at any time they.
00:47:46.966 - 00:47:48.640, Speaker C: Have to be able to withdraw.
00:47:50.580 - 00:47:51.980, Speaker B: From the lending pool.
00:47:52.140 - 00:48:07.664, Speaker C: So this is an animation that we had on the announcement that sort of explains that basically the two token pool is this. You have a lot of assets in the pool that are never touched, because for all swapping, it only skims the surface.
00:48:07.712 - 00:48:08.164, Speaker B: Right.
00:48:08.282 - 00:48:17.560, Speaker C: Every swapping activity is only requiring some of the assets in the pool. So what we do is we split this in two and we have the cash amount and the invested amount.
00:48:17.630 - 00:48:19.784, Speaker B: The invested amount is never touched for.
00:48:19.822 - 00:48:20.840, Speaker C: Most of the time.
00:48:20.990 - 00:48:21.604, Speaker B: Right.
00:48:21.742 - 00:48:25.484, Speaker C: And you have all swapping activity happening here on the cash amount.
00:48:25.682 - 00:48:26.140, Speaker B: Right?
00:48:26.210 - 00:48:53.056, Speaker C: So this is the total balance of the pool. Cash plus invested are managed. What the asset manager does is anytime that is supposed to do, because of course, we don't have any asset managers implemented yet, but the design, the best practice would be for the asset manager to constantly monitor the cash amount so as to know that if the cash amount is running below a certain threshold.
00:48:53.168 - 00:48:57.156, Speaker B: They should withdraw some of the invested.
00:48:57.188 - 00:48:59.572, Speaker C: Amount and deposit it back to the pool.
00:48:59.716 - 00:49:00.168, Speaker B: Right.
00:49:00.254 - 00:49:04.760, Speaker C: Deposit it back as cash to the pool so that trades can keep happening as normal.
00:49:05.820 - 00:49:06.570, Speaker B: Right.
00:49:07.820 - 00:49:58.708, Speaker C: So this is, again, one area that will require a lot of engineering and simulations and doing requirements gathering and looking at scenarios where what happens if the price of a token goes up significantly in little time, then probably you run out of cash amount, right? You run out of cash for the token. Because if the price of that token is going up, then the pool is selling the token to traders. So the cash amount here goes down. So the asset managers needs to keep track of that and withdraw from the investment fast enough to avoid the pool from running out of cash. Because if the pool runs out of cash, then it cannot be traded against anymore.
00:49:58.804 - 00:49:59.220, Speaker B: Right.
00:49:59.310 - 00:50:25.212, Speaker C: You have to keep in mind that the vault does not allow the pool to have a negative balance within the vault. So the cash balance has to always be positive. The pool cannot owe money because. Oh no, I have some money in the asset managers. Let me borrow some money from the vault. No, the vault won't let you do that. Trades will fail when you try to swap against the pool.
00:50:25.212 - 00:50:26.352, Speaker C: Same thing for withdrawals.
00:50:26.416 - 00:50:26.644, Speaker B: Right?
00:50:26.682 - 00:50:51.020, Speaker C: Withdrawals too. If someone tries to withdraw a lot of liquidity from a liquidity pool and the pool does not have enough cash to cover that withdrawal and the money cannot be withdrawn from the investment, then that trade will also fail again, similarly to how a lender cannot withdraw their pools from a lending asset if all of it's borrowed.
00:50:55.360 - 00:50:58.140, Speaker A: There are a couple of questions about.
00:50:58.210 - 00:51:05.010, Speaker C: Yeah, let's the questions, because then I start exploring a little bit of the possible research questions, and I think we can.
00:51:05.380 - 00:51:16.080, Speaker A: Yes. So first one is Solomon. I am not sure if this has already been answered. The question is, asset managers create arbitrage opportunities. Is it a design feature?
00:51:18.120 - 00:51:36.532, Speaker C: Asset managers do create arbitrage opportunities. They also create opportunities for incentivization within the asset manager. Because, again, all of these arrows here, nothing in this neighborhood here happens automatically.
00:51:36.596 - 00:51:37.210, Speaker B: Right.
00:51:38.060 - 00:51:41.272, Speaker C: Every single thing in Ethereum has to be triggered by someone.
00:51:41.406 - 00:51:41.752, Speaker B: Right?
00:51:41.806 - 00:52:30.200, Speaker C: So for an asset manager to do this, someone needs to be watching this and trigger a transaction that moves assets from one place to the other. So how do we make sure that this happens in the needed frequency is one of the challenges. Do we make it so that the asset manager is one institution or one person that controls that and has full control over what goes where, when? Or do we create incentive mechanisms for anyone to trigger the process of replenishing that cash amount or withdrawing from the invested amount, like any activity in the file, like liquidating a CDP, for example.
00:52:30.270 - 00:52:30.890, Speaker B: Right.
00:52:34.160 - 00:53:01.808, Speaker C: How do we design those mechanisms to make this the most efficient possible? So I'd say asset managers, in its most basic, sort of, on the surface, you wouldn't say that asset managers create arbitrage opportunities. They will create arbitrage opportunities insofar as they are designed to replenish that cash amount. And that replenishment might not leave the pool balanced.
00:53:01.904 - 00:53:02.596, Speaker B: Right.
00:53:02.778 - 00:53:18.952, Speaker C: They might not do a good job of depositing amounts in the pool, or they might not have the ability to deposit assets back into the pool in such a way that it does not create an imbalance that would cause an arbitrage opportunity. In that case, it's correct.
00:53:19.006 - 00:53:19.610, Speaker B: Yeah.
00:53:21.120 - 00:53:28.860, Speaker A: All right. And related, next question. What if the asset manager loses money or the tokens?
00:53:29.840 - 00:53:42.492, Speaker C: Good question. So another thing that the asset manager has to do, or can do is report its current balance, its current managed balance.
00:53:42.556 - 00:53:42.880, Speaker B: Right?
00:53:42.950 - 00:54:08.344, Speaker C: So think about it like this. The pool holds 1000 die and the asset manager takes out 800. So the current state is 200 cash. Let me write this so that I don't keep track of what I'm saying. So the pool starts with 1000 die. That's 800 plus 200. 800 in managed and 200 in cash.
00:54:08.542 - 00:54:09.290, Speaker B: Right.
00:54:10.780 - 00:54:29.756, Speaker C: So the pool is doing all its math based on the fact that it has 1000 die. Every time that trade comes in, it updates that thousand die. But an asset manager can be making money or losing money on those 800 die that it took out of the pool.
00:54:29.868 - 00:54:30.432, Speaker B: Right.
00:54:30.566 - 00:55:27.090, Speaker C: It doesn't necessarily have to constantly deposit into the cash, because maybe the cash is above the threshold, right? So it doesn't need to deposit back, but it can report gains and losses, right. If the asset manager reports a gain, say it reports a gain of 10%, the managed balance will go up to 880 and the cash manage. Suppose the cash balance stayed at 200. So now the pool has 1080 die, and it will do all its math, taking into account the fact that it has 1080 die. And that's also a point where it creates arbitrage opportunities. Because if the asset manager reports those gains or losses too infrequently, those changes will be significant, right. From one moment to the next.
00:55:27.090 - 00:55:48.840, Speaker C: In a single transaction, the pools goes from 1000 die to having 1080 die. And that creates a sudden imbalance in the pool. So how do we make sure that asset managers report gains or losses in a frequency such that doesn't drain value from liquidity providers by arbitragers?
00:55:51.760 - 00:55:54.960, Speaker A: Does this answer your question, Eamonn?
00:55:57.060 - 00:56:35.500, Speaker F: Yeah, I sort of had a follow on question, like, can I just take some tokens, invest it in some derivative, some risky derivative that has an expiration right in the future, and it messes up the sort of. So basically you're sitting on some catastrophe of a loss and it's not reported anywhere in the pool. Is there anything that keeps keeping me honest? If I'm an asset manager and maybe I've just taken some tokens and invested in some ridiculously.
00:56:38.080 - 00:57:29.740, Speaker C: What we expect will happen is that asset managers won't really be people, but rather smart contracts, right. We will know what asset managers can and cannot do with the assets that they take out of the pool beforehand. And joining a pool that has an asset manager is always a choice. So as a liquidity provider, you decide what risks you're willing to take and what pools you're joining. And you're only joining the pool that has the asset manager that you want to have control over your assets, right? Because that's basically what they're doing. They have control over some of your assets. So you limit how much control you give to them by choosing one that only does what you limit it to do.
00:57:29.810 - 00:57:30.284, Speaker B: Right?
00:57:30.402 - 00:57:56.404, Speaker C: So we don't expect that to be people doing it, but rather smart contracts that are limited into how much harm they can do. And naturally, there will be the yield farming crazes will, will happen and we'll see a lot of risky stuff happening within the industry, but we don't think that's the kind of thing that will last.
00:57:56.442 - 00:57:57.030, Speaker B: Right.
00:57:59.180 - 00:58:03.960, Speaker A: Okay. And Kirty, your question, I guess, was related somehow.
00:58:04.540 - 00:58:15.150, Speaker E: Yeah, it is. I think there's a question below which emphasizes that in a better way, which talks about lockups. So we'll just address that, I guess.
00:58:15.760 - 00:58:16.910, Speaker A: Who is it?
00:58:18.560 - 00:58:21.550, Speaker E: So I think it's dog.
00:58:22.660 - 00:58:23.410, Speaker A: Okay.
00:58:24.180 - 00:58:24.880, Speaker B: Yeah.
00:58:25.030 - 00:58:51.320, Speaker E: So it says, doesn't asset measures latency lead to deadlock phenomena? And I think it's similar to what I'm asking. I'm more interested in trying to understand what are the probabilities of a credit default risk, possibly because of some sort of a lockup or if something is not reaching consensus. How does that work out in specific scenarios, just from risk management perspective?
00:58:51.900 - 00:58:52.650, Speaker B: Yeah.
00:58:53.820 - 00:58:58.330, Speaker C: David, do you want to add to that before I go in?
00:58:59.980 - 00:59:01.064, Speaker E: No, not really.
00:59:01.182 - 00:59:03.420, Speaker G: I think we can. Well, you go first.
00:59:03.570 - 00:59:08.680, Speaker C: Okay. So, yeah, basically what we were going for was with the flexibility.
00:59:08.760 - 00:59:08.956, Speaker B: Right.
00:59:08.978 - 00:59:22.524, Speaker C: We wanted to make it so that asset managers can do basically anything, but we leave it up to users to decide whether or not they want to put their money at risk with that asset manager.
00:59:22.572 - 00:59:22.832, Speaker B: Right.
00:59:22.886 - 01:00:29.776, Speaker C: So because the vault, like I said, because the vault doesn't mix up the tokens of a pool, of two pools, it makes no confusion between those things. So as a liquidity provider in pool a that does not have an asset manager, you run zero asset manager risk. You're not being exposed to the risk of any asset manager. If there's an asset manager, that all it does is land on Ave and you're happy with that risk, then you go with that pool and you're certain that you're only running that amount of risk. You can know that for a fact that the only risk you're running is the risk of the ave smart contracts and the risk of there not being enough and the risk of the amount available at the lending pool. So the not borrowed part of the lending pool not being less than your claim to the pool's assets. That's the risk.
01:00:29.808 - 01:00:30.512, Speaker B: You're right.
01:00:30.666 - 01:00:35.476, Speaker C: Because when you want to withdraw, you cannot withdraw from the lending pool.
01:00:35.508 - 01:00:35.656, Speaker B: Right.
01:00:35.678 - 01:00:39.480, Speaker C: You want to withdraw from the pool, but the pool cannot withdraw from the lending pool.
01:00:39.980 - 01:00:40.392, Speaker B: Right.
01:00:40.446 - 01:01:14.500, Speaker C: So you're basically doing two investments in one, so to speak, because you're not only providing liquidity on balancer, you're also providing liquidity to Avi. But then if the asset manager is a risky one that does all sort of derivatives grace, then you might end up losing money in other ways, in other uncalculated ways. But again, we expect it all to be open and transparent and everyone be able to make their own decisions as to how to invest their assets.
01:01:16.920 - 01:01:23.130, Speaker A: Vasily, you referred to a particular aspect on Avi. Do you want to add on that?
01:01:24.860 - 01:01:40.028, Speaker H: No, but I have another question. So do you plan to have something like whitelist of asset managers that are verified by, I don't know, your team auditors that also you trust so to help people navigate? Because I think there will be a.
01:01:40.034 - 01:02:32.056, Speaker C: Lot of asset managers probably, yes, definitely. Everything that you see on the balancer UI will have been vetted by balancer lamps. So the balancer community will vet everything that you see on the balancer Ui. If you see something on the balancer Ui, if you see a pool on the balancer Ui, it's because it would either have. Again, we are not there yet, but the plan is to have either only show pools that have been deployed by factories with specific trusted asset managers in them, or show very specific disclaimers for when that's not the case. Like what you see in v one, you guys might have seen when you go to a pool in v one. And the pool has a token that has not been vetted.
01:02:32.056 - 01:03:03.064, Speaker C: So we don't know anything about that token, right. So technically the controller of the token can mint an infinite amount and therefore drain the pool from the other valuable token. So we display a warning on that pool saying we don't know one of these tokens in this pool. Therefore this pool is in the risk of being totally depleted. Be careful when you add liquidity to it. Do your own research and make your own decisions. But we don't know anything about this.
01:03:03.064 - 01:03:12.520, Speaker C: We haven't vetted it. I expect me to do something, at least something similar like this on the pools UI.
01:03:13.740 - 01:03:45.812, Speaker H: On VTube, yeah, and the same question is related to customizable ImM logic. So for example, in PowerPoint we develop dynamic Imm. So what we should do, we should make some simulations in cut, cut and prove that it will work properly. Or we need to have an audited code for all this weight chaining and related stuff and supply to balustrate. You will verify it and after that you will be able to add this pool. So is there any process for such things?
01:03:45.946 - 01:04:29.540, Speaker C: We don't have anything very well designed yet. Like I said, we're in the initial phases of deploying, designing and implementing the first asset manager in a partnership with Ave. But what I expect will happen is that it will require audits on the asset manager, smart contracts, because it just has too much power on it. The asset manager is too powerful to be left unaudited. It has to go through thorough audits, and I'm sure everyone will be able to apply for grants, for example. And if the balancer community finds that there's a new, innovative asset manager.
01:04:31.560 - 01:04:31.876, Speaker F: In.
01:04:31.898 - 01:04:47.192, Speaker C: Place, that can be useful, I'm sure the balancer community would be happy to give grants to subsidize those audit costs. Thank you.
01:04:47.246 - 01:04:48.312, Speaker B: Okay, cool.
01:04:48.366 - 01:04:50.440, Speaker A: And a final question. Jesus.
01:04:51.840 - 01:05:42.964, Speaker D: Yes, thank you with your pleasure. I understand that in case you don't have the cash or you have out of capital invested, it's like some way protecting your capital from a crash in an asset, because in that case, your liquidity is not in the pool. So you are protected from a crash that could move your pool to one asset that is crashing. I don't know if you understand that, but it's like some way a protection, because imagine you have two assets and one of them is crashing. So one part of your capital is going to be protected in some way. So I think it's interesting instrument to protect in some way of the crash on one asset. It's only a comment.
01:05:42.964 - 01:05:59.356, Speaker D: I don't know if you see it that way or it depends on the asset managers in the asset managers to move to the cash. In that case, I probably didn't want to move to the cash because in some way I would be arbitrage.
01:05:59.548 - 01:06:27.160, Speaker C: Yes, I think so. Yes. The asset manager could definitely play a part in that. And like I said, we made it so that it's flexible enough that the asset manager can do basically anything that the pool lets it do. Like I said, the current pools don't have asset managers. They do not trust any asset manager. So anything that you put on balancer next week will be safely protected.
01:06:27.160 - 01:07:22.332, Speaker C: It's the same as a v one pool, right? It has the same basic concepts of V one pool. What we have talked about is one, of course, asset managers can play a part in that with everything that's in the invested amount. They can do their own accounting, they can do their own logic and withdraw from the invested amount so as not to run that risk. But the other thing is that, again, going back to the arbitrary amm pools, you can have pools that have circuit breakers that stop trading if the price hits a certain point, for example. So you could implement an arbitrary weighted pool that does trades as long as prices are within a certain range, and that range is controlled by some external smart contracts, for example.
01:07:22.466 - 01:07:22.908, Speaker B: Right.
01:07:22.994 - 01:07:47.572, Speaker C: Maybe you have a dow that sets the price target of that pool, and that pool circuit breaks when the price goes above that threshold. You're probably better off looking. Well, it depends. But there are cases where that could be better served by a stable pool. But it could be done in a weighted pool too. It would have to be a specific one, though, not the ones that we currently have.
01:07:47.626 - 01:07:59.400, Speaker D: Okay, but in that case, in case one price goes to the crash, you don't put cash until you stop the pool and you recover from the Capital.
01:08:00.060 - 01:08:03.224, Speaker C: Can you do that? Yes, the asset manager could do that.
01:08:03.262 - 01:08:03.850, Speaker B: Yeah.
01:08:06.820 - 01:08:07.920, Speaker C: You'Re muted.
01:08:08.980 - 01:08:14.996, Speaker D: You don't have to put in cash to recover your assets. In that case, it's only to know.
01:08:15.018 - 01:09:02.068, Speaker C: If this is possible. So the asset manager. I'm just thinking about this now, but technically, I think you could make an asset manager that stops trading altogether because it doesn't replenish the cash. And then what it does is it lets you withdraw directly via the asset manager. So instead of burning your BPT on the vault and doing a normal withdrawal, what you would do is you burn your BPT on the asset manager. The asset manager only withdraws from the invested amount, the exact amount of cash that you would withdraw. So that you do it all atomically.
01:09:02.164 - 01:09:02.424, Speaker B: Right.
01:09:02.462 - 01:09:04.328, Speaker C: So you don't create an arbitrage report.
01:09:04.494 - 01:09:32.340, Speaker D: Okay, interesting option. And the next thing is the fact that capital is being invested by asset managers is still allowed to use as a collateral. Because in that case, probably it's more tricky to have the price as a collateral. Imagine you want to get LVP in other liquidity mining.
01:09:33.960 - 01:09:38.960, Speaker C: You mean for the asset manager to use the assets from the pool as collateral?
01:09:39.040 - 01:09:59.820, Speaker D: No, I mean the LVP. It's possible to use it. Is there any difference? As you know, there are other protocols that use LVP as a collateral. Also liquidity mining and other things. I don't know if it's going to permit to use as a collateral because I don't have a price of that asset.
01:10:01.440 - 01:10:26.224, Speaker C: You still have the price. It definitely gets trickier from the point of view of the risk assessment of the protocol that is allowing that to be a collateral. Right. But keep in mind though, that each pool has its own BPT. So we're talking about the BPT, the balancer pool token as collateral. But they're not equal. They're not all equal.
01:10:26.224 - 01:10:41.416, Speaker C: Each pool has its own. So if a protocol accepts BPT, it's accepting BPT. Under those circumstances, it's BPT of the pool that has the asset manager. So in their risk analysis, they will have to take that into account, because.
01:10:41.438 - 01:10:54.860, Speaker D: In Makerdao, as you know, there are going to be pools that are as a collateral. In that case, probably they will accept, I understand, collaterals of lvps without assets manager.
01:10:55.860 - 01:11:20.292, Speaker C: Probably, yes, probably in the beginning. Definitely. More likely that that will happen in the beginning again, as risk assessment and risk management matures, then we'll definitely see also all kinds of things moving on to ppts and people wanting to take that risk at a premium.
01:11:20.356 - 01:11:20.970, Speaker B: Right.
01:11:21.980 - 01:11:38.940, Speaker A: Okay, I just wanted to let you know we have 15 minutes left, some research questions to tap on, and still the document with a couple more questions. So let's see, maybe we start now with research questions. Marcus?
01:11:40.800 - 01:11:41.404, Speaker B: Cool.
01:11:41.522 - 01:12:48.160, Speaker C: Okay, so I thought of a few things after seeing your comments on discord and some of the things that we have been thinking about. And one place where I think there could be, where it could lead to a nice, interesting and interesting research would be on the trade offs for lbps, right? So LBPs stands for. LBP stands for liquidity bootstrapping pools. A liquidity bootstrapping pool is a pool where you do an initial token offering through that pool. What you do is you start the pool with, say, 90% of the token that you're selling and 10% die, for example, and you set the pool to shift those weights over time during, I don't know, three days. You have three days of the token sale going on. So over the course of three days, those weights will shift so that you end with 90% die and 10% of the token that you have that you started with.
01:12:48.160 - 01:13:32.272, Speaker C: This creates selling pressure, or constant selling pressure on the token. Right. Because the weights of that token, the weight of the token is always going down. So the pool is always trying to sell some of the token to the community, and it provides some interesting properties around price discovery. Like I say here, we've had more than 20 token launch on the platform. They have collectively raised more than $200 million and generated a lot of volume on the platform, not only for the liquidity bootstrapping pool itself, but also what we call side volume. Because often people will come in wanting to buy that token, not with the reserve token of the pool, but with something else.
01:13:32.272 - 01:14:01.050, Speaker C: And then what they would do is go through, do a multi hop swap like I was telling you guys about before. So with that basic introduction, you can think of all sorts of things to think about. And what do you have to do? What do I do? How do I start doing an LBP, you have a lot of things to consider, right? What is the starting capital that you put in? What is.
01:14:05.990 - 01:14:11.460, Speaker A: We can't hear you anymore, Marcus. Or is it just me?
01:14:28.370 - 01:14:51.014, Speaker C: So what is the reserve token that you use? Do you use USDC? Do you use dai? What is the duration of the pool? And so on? And what we see happening a lot is that pools come to balancer, deploy their LBP, do the token sale on balancer, and most often than not, they leave to provide liquidity on something like.
01:14:51.052 - 01:14:53.222, Speaker B: Uniswap or sushiswap, right?
01:14:53.356 - 01:16:01.120, Speaker C: And it's in some ways, or at least at first pass, understandable, because it's the places most known for liquidity. People will usually go to uniswap and sushiswap for trading in general. But the question would be, under what circumstances does it make more sense to provide liquidity on balancer, to have balancer be the main place for liquidity after an LBP is done, versus on Uniswap, right? And then you have things to consider, like impermanent loss. What if you set up an 80 20 pool on balancer instead of a 50 50 pool on sushi swap? What do you expect will happen to your token price in general? And how will that choice of pool affect the capital of your treasury? As a project, you're often being the initial liquidity provider with the treasury of the project and of your community.
01:16:03.090 - 01:16:03.406, Speaker B: Who.
01:16:03.428 - 01:16:11.474, Speaker C: Is acting as initial liquidity providers on that pool. How does liquidity mining affect that?
01:16:11.592 - 01:16:11.970, Speaker B: Right.
01:16:12.040 - 01:17:33.590, Speaker C: What is the amount of liquidity mining that needs to go into those pools to offset the apy on something like uniswap or sushiswap, what are the volumes consideration that you have to take into account? How will volume play out if you see the initial pool? If you see the pool with initial capital on balancer versus seeding it on uni, does the mere fact that you're seeding it as a project, you're seeding it on balancer. Is it enough to act as a gravitational pool and draw all volume, all trading volume for your token to balancer? This happens with bow, for example, right? The bow token. It's got a lot more volume on the balancer exchange than on Uniswap. People know that the best place to buy Bao is on balancer and not on uniswap. So how would that play out for a token that is launching via an LDP? So I think all of that is a rich place for investigation and looking at doing some a b testing and parameter sweeps on CaDCAD, and it would be fantastic to see something like this come up. And there's a lot of interest for that. Just today I saw someone on the CadCad Telegram channel asking for help setting up an LBP.
01:17:33.590 - 01:17:47.134, Speaker C: So that was an interesting question. But yeah, every week we have three to five projects coming to us asking about oeps and wanting to start things. So it would be very valuable to everyone.
01:17:47.332 - 01:18:55.350, Speaker A: I wonder if at some point we could also. So just let's imagine everybody of you is free to choose his or your own research questions, or that's a prerequisite and what you feel interested in and also where you can bring your own skills to the table. Of course, it's always exciting to work on a case or a particular question that has some relation to reality and that people really care about. And I think liquidity, bootstrapping pools are definitely one of the most interesting topics where I could see, probably not a particular project, but maybe we can invite, I don't know, after one and a half months, some of the teams that have been approaching you to gather feedback or to present some first results and to discuss, okay, what are their key interests? Or what would they love to see? Because I would love to have this ongoing conversation with the community outside of this research group, of course, as well. So just to notice.
01:18:57.530 - 01:18:58.600, Speaker C: That'd be great.
01:18:59.530 - 01:19:02.200, Speaker A: Are there more research questions you have in mind?
01:19:04.090 - 01:21:15.342, Speaker C: So the other one is something that I started playing with last year and didn't get enough time to work on, is, I call it about the, if you think about the market, you have amms like balancer and Sushiswap and Uniswap. And if I had more time or more design skills, I would have made this into a graph. But you have retail investors, you have aggregators, you have arbitrage bots, and this is all a big network of connected agents, right? Each one of their different policies and their different preferences, and they may or may not have edges connecting them to each other. So the research question here, and this is probably at least at first, more of a data science research question than a CADCAD simulation research question. But I think it can lead on to a CADCAD simulation, which is to look at how efficient the market is. I mean, how often do arbitrage opportunities go unarmed in the network? Or how often does it happen that an aggregator directs their user to Uniswap when the price and balancer would have been better? How often does a retail investor that's buying on Uniswap is paying more for buying directly on Uniswap via the Uniswap UI, versus going through an aggregator and having their trade be split among several different amms. So I think understanding that and putting numbers to that I think could be very valuable to the community and would help a lot of people having a better understanding of where we are and how important it is to be well connected, either whether you are a retail trader or an aggregator or an arbitrage bot.
01:21:15.342 - 01:22:04.258, Speaker C: And by be well connected, I mean have a lot of edges connecting you as a retail trader to the aggregators, to the arbitrage bot and to the amms directly, but also the quality of those edges, especially when it comes to aggregators connecting to the amms, because the aggregators need to have a decent estimate of what the actual price is going to be for that swap before they do the swap. And same for the arbitrage bots, right? I mean, if an arbitrage bot is assuming, let's take this for an example. Suppose an arbitrage bot, someone simply switches their arbitrage bot from Uniswap, from balancer v one to Uniswap to balancer v two, right? One of the key components of an.
01:22:04.264 - 01:22:07.058, Speaker B: Arbitrage bot is your cost.
01:22:07.144 - 01:23:09.400, Speaker C: How much will your transaction cost? And costs are going down significantly in balancer v two. So if you don't change that parameter in your arbitrage bot, your arbitrage bot is not going to work as frequently as it should in balancer v two. So that's what I mean by the quality of the edge connecting those two nodes. And again, that would something that could be answered by a research question like this. I generally put it all in the bucket of how efficient is the market, because I think it basically collapses all of those questions into one, but it can be split into several different ones. And where it would lead to what I think could be an interesting CADCAD simulation would be we encode those policies into a CADCAD simulation, as they were, and then we tweak them to say what would have happened if those edges were a bit different.
01:23:10.250 - 01:23:11.000, Speaker B: Right.
01:23:12.170 - 01:23:26.140, Speaker C: Or even if edges had existed. Suppose this edge existed. We know from the data that this edge didn't exist. Suppose it did, what would have happened? How would things have played out?
01:23:28.870 - 01:23:32.120, Speaker A: Great question to observe this entire space.
01:23:32.730 - 01:24:31.350, Speaker C: Yeah. And the other one is on dynamic swap fees. I think this is something that generates a lot of interest. There have been quite a few papers on this conflict, has published some. If one of you guys, some of you saw the presentation that I did in Ozaka at the Debcon in 2019, I talked a little bit about that and how we simulated what would have happened with Uniswap if the fees had been different. So this led us to explore this possibility with gauntlet of the dynamic fee setting where they have their own models. Gauntlet has their own models, and they will be setting the fees of a set of pools based on what that model tells them to do, so as to maximize the returns for liquidity providers.
01:24:31.350 - 01:25:13.846, Speaker C: But I would be really interested in seeing something like this play out in the open. A research question, something like this being developed by the community and owned by the community would be very interesting because the balancer community can set the fees and will set the fees. Setting can parameterize the pools to say who is the fee setting, the fee setting account, and it's setting them to gauntlet. But anyone can deploy a pool and be the owner of that pool and therefore have the right to set the.
01:25:13.868 - 01:25:16.134, Speaker B: Swap fees on that pool, right?
01:25:16.252 - 01:25:34.670, Speaker C: So if someone was to come up with an efficient model for swap fee setting, they could deploy their own pool and drive liquidity to it by optimizing those returns.
01:25:39.780 - 01:26:30.492, Speaker A: All right, any more questions? Any more research questions? Thanks. Okay, thank you, Marcus, for taking the time and taking us on this journey to V two and also proposing first research questions. I think we've touched on a couple of the questions that have been included in the document, in the question document. Thanks everyone for posting your questions and, well, doing your own research on V two. I think we will touch on it over and over again across the entire research group duration. And I think, Marcus, we should also see how we can make next steps, then picking up research questions, gathering feedback from your side. And I think this will come together quite nicely.
01:26:30.492 - 01:27:16.440, Speaker A: So for the moment, I only want to add two announcements. A is overall research questions, so feel free to explore the space. At the moment, you are not under pressure to choose your research question immediately. We will have roughly another two weeks to explore, to discuss. There will be vasily introducing some more research questions probably related to what you've presented, Marcus, and then also with building on the new opportunities with V two. So we will have a dedicated session on that, too. And we are in touch with Ocean, who loves to see token spy simulations, agent based simulations on V two.
01:27:16.440 - 01:28:33.640, Speaker A: And Trent will be in one of our sessions introducing his point of view and his proposals on most relevant research questions from their side. So there will be a variety. And again, as mentioned, our aim is to not only have you guys doing research and exploration on these topics and also that we train each other in running simulations. We also want to have these touch points with tool providers, with asset managers, potentially with startups looking for liquidity, bootstrapping and whatever is relevant to also provide feedback on okay, how does this token engineering work really can help the outside world in the overall DeFi space? So I'll provide all dates on these sessions in the next days. I hope you all have the link to the one stop shop. Let me share it again in this channel as well so that we make sure you all have access to the schedule. And our next session will be on Tuesday.
01:28:33.640 - 01:29:13.520, Speaker A: I think it's 06:00 p.m. Please check the schedule again 06:00 p.m. Central European 2 hours and we will introduce what we have been doing on we one so far and take a closer look to catcat capabilities of catcat how we use catCAT and then hopefully we can build on that for all the v two simulations as well. And Nico is currently working on the python implementation of the V two Mars. Hi Nico. Okay, this is the program of next Tuesday. Stay tuned.
01:29:13.520 - 01:29:20.690, Speaker A: See you next week. Thank you for all your questions. Thank you Marcus. And yeah, looking forward.
01:29:21.420 - 01:29:32.168, Speaker C: Thanks everyone. Yeah, looking forward to the next steps. If anyone has other questions, feel free to mention me on discord and I'll get a notification and get back to your questions.
01:29:32.254 - 01:29:33.752, Speaker A: Awesome. Thank you.
01:29:33.886 - 01:29:36.420, Speaker C: Thanks everyone. Bye bye bye.
01:29:36.500 - 01:29:37.144, Speaker G: Thank you.
01:29:37.262 - 01:29:38.660, Speaker C: Obrigado. Bye.

00:00:06.650 - 00:00:09.678, Speaker A: Okay, let's start.
00:00:09.764 - 00:00:10.270, Speaker B: Yeah, sure.
00:00:10.340 - 00:00:17.230, Speaker A: Okay. Sharding sucks. That's.
00:00:20.690 - 00:00:26.390, Speaker B: Cool. But. Okay, so do you want me to start to. Do you want to go first?
00:00:26.460 - 00:00:37.350, Speaker A: My opinion is that sharding is a really hard computer science problem, and I think it's solvable, but that's what it is. It's a really hard computer science problem.
00:00:37.420 - 00:00:42.700, Speaker B: But clearly no, sharding is so simple, you had to bring super good minds from Qualcomm to tackle it. Right?
00:00:43.230 - 00:00:51.366, Speaker A: I don't think that we would get anywhere. I don't think we would be near the finish line if we tried to build a sharded chain.
00:00:51.558 - 00:01:27.346, Speaker B: But that's the difference, right? You brought talent from Qualcomm because you're building hardcore low level optimizations. We brought people from MSQL. We shipped sharding before. Right. But I have certain arguments towards sharding. I think that for certain use cases, if you're talking about payments or Dexes, I think something like Solana works great. It's a very homogeneous workload, and you can easily process hundreds of thousands of transactions on the GPU concurrently.
00:01:27.346 - 00:01:53.874, Speaker B: But if you're running an arbitrary smart contract on a platform, you can only get that much of parallelism, right? So you will be bounded by whatever number of cores you have on those mainframes running Solana. So for arbitrary code, it seems to me that you do need charging. Ultimately, at some point, you will reach the capacity of the mainframes. If adoption grows faster than this every two year, doubling the CPU, I think.
00:01:53.912 - 00:02:21.574, Speaker A: You'Re actually compute is not the problem here. Compute is just so easy to get, right? If there's actually enough demand to fill capacity, people will just add more. Computers, like hardware, is actually really cheap and easy to go get. I think the benefit of sharding is the thing that you can't scale, which is bandwidth, right? We're limited by the bandwidth of the supermajority of the network.
00:02:21.702 - 00:02:23.766, Speaker B: But adding more computers is sharding.
00:02:23.798 - 00:02:40.510, Speaker A: No, no. My validator is now like a rack of 42 inch rack worth of GPUs, right? I can add more, compute easily, right? But I can't run another fiber optic cable to everybody in the network.
00:02:40.930 - 00:03:24.320, Speaker B: So that sort of works, right? So one example is what you gave where everybody, every validator runs like a huge mainframe, and that mainframe has so much CPU and so much disk space that it can fit whatever it can fit, all the information the world has. Or there's like another school of thought where instead of doing that, they make every validator to run a set of machines, right? But it's internal communication, so all the adaptive corruption problems don't exist anymore. But that does appear, at least to me, it feels like it hurts decentralization significantly because the requirements for validator now is pretty high. So it's only for a select group of professional enterprise grade validators who can run them.
00:03:25.730 - 00:04:12.480, Speaker A: So my argument against that is that every two years, hardware gets cheaper and cheaper, and we're just unlikely to see that much usage in the next eight years. Right? Like to where it fills up one gigabit worth of DPs, that's like almost a million transactions per second, right? Like one gigabit worth of data. One gigabit is available worldwide. You can process one gigabit worth of transactions on a five K machine right now. So the imaginary world that we're thinking about, where we have 42 inch racks of computers, is like the world where we have, I don't know, a terabyte worth of bandwidth connected to everybody. It's just so far away. Right?
00:04:13.170 - 00:04:31.054, Speaker B: But were the networks actually getting that much faster? Like 1GB has been around for a while, right? But we're not getting much further than one gigabit. But the bigger thing is that you can get out of CPU, but you do need to write ultimately, right? You need to write to disk. Disk is not getting any faster.
00:04:31.102 - 00:04:54.294, Speaker A: Over time, those kind of SSDs are getting faster. That's definitely true. Both SSDs, anything that's silicon is getting basically twice as fast every two years. Not latency, but bandwidth. Like in terms of how many non sequential but concurrent operations you can do per second. All that stuff is doubling. Bandwidth doubles.
00:04:54.294 - 00:05:33.240, Speaker A: Like network bandwidth doubles every four years. So it's growth slowly. Like 5G standard is one gigabit point to point any two phones in the world. So the amount of fiber that needs to support that across data centers, they're all going to serve traffic to this. Like 3,000,000,001 gigabit devices is insane, right? So we're going to live in a super connected world with a ton of available resources. So if you have a network that utilizes all those resources to their full capacity, I think you can deliver the cheapest price for the security of this trust minimizing computer.
00:05:33.610 - 00:05:40.070, Speaker B: And so in your ideal world, how many validators do you think are going to be running Salana core?
00:05:40.230 - 00:05:58.158, Speaker A: Well, I mean, we designed the protocol to 20,000 validators. That was our simulation. But where are we going to find 20,000 validators? Where are you guys going to find validators for like, I don't know, how many shards do you plan on launching with?
00:05:58.244 - 00:06:11.570, Speaker B: Well, let's say eight, right? Okay, eight. But you see the beauty of sharding, right, is that you can run on the cheapest instance, well, not on the cheapest, but on a very cheap instance. And that's going to be enough to process a shard.
00:06:11.990 - 00:06:46.654, Speaker A: So here's my counterargument. I don't think sharding is actually a scaling solution. It's a decentralization solution. And I think people think of it as scaling because it on the surface increases the capacity of the entire network. But the price that you pay per transaction is going to be based on the capacity of the single shard. Because what that price is is the spam resistance. If you lower below that, then your full shard gets spammed out of existence, right? And you can't afford that.
00:06:46.654 - 00:07:03.410, Speaker A: You can't afford a single shard to be at capacity because that means all those users, all those applications are dead. They have to now do this long ass migration thing to another shard, right? That's like a huge attack vector. So it increases decentralization. It doesn't actually scale.
00:07:03.750 - 00:07:15.798, Speaker B: But wouldn't you agree that the cost of a single transaction in a shard, it doesn't need to be any higher than the cost of a transaction in a single chain system, right? No, because the cost of spamming will.
00:07:15.804 - 00:07:47.534, Speaker A: Be the same if it's running on the same hardware, right? So if it's a network that is optimized like ours, that means that we give you 50,000 tps worth of capacity, our price for spam is that much lower. Right. So that's kind of like, I think the main trade off, it shouldn't be called a scaling solution. It's a decentralization solution, which is fine, decentralized to the health. I mean, that's an awesome problem to solve.
00:07:47.662 - 00:08:28.110, Speaker B: So that's a good argument. However, I think once you start thinking about transaction fees in the context of blockchains being widely adopted in the wild, I think one of the requirements for blockchains to actually gain adoption is that the final user of the service does not pay any transaction fee. They use service for free and it's the service provider, the smart contract owner, who is paying for it. Right. So once we do that now spamming, even if they cannot spam the protocol, they can spam the owner of the application. Right. So you need to have some other way of protecting against spam.
00:08:29.730 - 00:08:37.140, Speaker A: It's an open network, dude. As soon as the price is below my cost. To mess with it, I'm going to mess with it, right?
00:08:37.590 - 00:08:50.838, Speaker B: But let's consider Instagram, right? A cost for me to sending requests to Instagram is practically zero, right? I can create a botnet very quickly, and yet Instagram doesn't go down, right? So people seem to have solved the.
00:08:50.844 - 00:09:03.740, Speaker A: Problem of, are your validators going to censor transactions that are paying the right amount of fees? But they just like, we don't like these because that's what you're talking about, right?
00:09:06.670 - 00:09:50.220, Speaker B: In the bright world of crypto future, which I envision, majority of applications are using this approach with application provider paying for the fees. So people use the protocol through those gateways, through hosted wallets of the application providers. They paying their gas fees. Application designers, application runners are people who are paying for those fees, and they correspondingly, through their gateways, protecting against DDos. If you actually need to use network directly, if you don't want to use like, a hosted wallet, you need full security. Well, at that point, you actually are in a position to pay a higher transaction fee, right? So if you need full security of the system, you can also pay more for it. Does that make sense?
00:09:50.830 - 00:10:09.470, Speaker A: Sort of. But you're talking about basically creating a walled garden spread between your users that interact with. They're not decentralized users anymore, right? They're not self custodying, they're just users of some app. Why doesn't that app just run in postgres?
00:10:10.690 - 00:10:59.374, Speaker B: So there's a big difference, right, in terms of world gardens, if you don't do that, if you make users pay for the gas fees, it happens that we live in the world, and the world is not going into any different state where acquiring crypto is extremely complex, right? And so if we require users to pay for transactions, the adoption will never go off limits. If you go outside and grab random person there, that person will not be buying crypto anytime in the next five years, right? So I think making that, like, this hosted wallet approach is actually making it less of a walled garden, right? And they still gain a lot of benefits from using decentralized network because, yes, they do need to trust the hosted wallet provider. But first of all, that could be someone like, people trust Coinbase. People store crypto in Coinbase, you only do it for low importance transactions, right?
00:10:59.492 - 00:11:06.340, Speaker A: So this is what you guys are building, is a decentralized network for non decentralized people, right?
00:11:08.470 - 00:11:45.246, Speaker B: But that is the thing that your majority of your audience, unless you capture the audience, which does not fully care about decentralization people will not go to Facebook. If Facebook doesn't have 90% of the population of the world, you need to capture the audience which doesn't care about crypto. If you want to capture the crypto audience, as long as crypto audience has their access to full security, full value of the blockchain, people who don't care as much, they still gain quite a bit, right? Because if they're using a hosted wallet provided by the application developer, that means that application developer, for some reason to.
00:11:45.268 - 00:12:01.940, Speaker A: Want to that application developer, right. They're paying a big pile of fees to access the chain, right? They're paying for the users, right? So in that case, they're the most motivated to switch to a chain that has the lowest fees, right?
00:12:02.310 - 00:12:03.010, Speaker B: Yeah.
00:12:03.160 - 00:12:12.342, Speaker A: For the same level of security, which is one that is designed with the most hardware, right. Per validator, that's how you get to the lowest price.
00:12:12.476 - 00:12:16.920, Speaker B: The question is, is it equally easy for them to do that? That's one.
00:12:17.530 - 00:12:28.474, Speaker A: For a company that's spending like X amount, it depends on if they're burning a million dollars a year in fees, then it's x amount of engineering hours, right. To do it.
00:12:28.592 - 00:13:10.040, Speaker B: So there's a good argument to that argument. Number one is that what you're saying is true for huge company, right? If a company built a huge service on the blockchain, and moreover for a small number of companies, it is most certainly, even if you're a little bit delusional, which you not necessarily are, but even if you're a little bit delusional, Solan is not as scalable. It can definitely host at least several very high profile applications. So for them it might be reasonable to move. However, one of the beauties of the decentralized applications is that they're composable. It's the open state components that are actually going to be making a huge difference in the next years, and hopefully they will be driving web3.
00:13:11.450 - 00:13:22.060, Speaker A: But those open state components, sharding introduces an unimaginable complexity to composability, right. Because you basically have to build Erlang, right, to deal with it.
00:13:24.110 - 00:14:04.982, Speaker B: You can abstract out most of that, right. If you go today to near Dev and you're trying to do like a cross contract call, it's no harder than just creating a future and then acting on it. And typescript already abstracts out quite a bit of it from you. Just that, unless you need synchronous calls, which is a different story, asynchronous calls are completely trivial. And today most of the code in JavaScript that you write already actually relies a lot on asynchronous calls because historically JavaScript is single threaded and you have to rely on asynchronous calls, right? Like if you do jquery, call in your website on your. But those, those open state components, their state is going to be coming a lot from smaller players.
00:14:05.126 - 00:14:16.560, Speaker A: Debugging and guaranteeing that all the contracts terminate and execute in safe states that are executing on multiple shards is like a super complex problem.
00:14:17.730 - 00:14:34.354, Speaker B: You don't need to care about it most of the time, right? As long as your logic, like you write your logic, as long as it's relatively straightforward. And most of the time it is. How many times you saw people writing ridiculously complex logic on the backend? Like open any flask application, it's as straightforward as it gets, right? There's going to be no surprises, right? Yeah.
00:14:34.392 - 00:14:38.450, Speaker A: So compile it to SP, run it on GPUs.
00:14:40.390 - 00:15:08.400, Speaker B: So the point here is that as long as for the smaller players, it's significantly easier to go and build on something that is extremely straightforward. So the open state ecosystem will be coming from the small players, it's not going to be coming from big players. Moreover, the entire promise of web3 goes against big players. You don't want Facebook's and Google's to exist, right? Their position as a monopoly is what hurts the world, what allows them to.
00:15:09.810 - 00:15:17.890, Speaker A: Communities equivalent to them to exist that are all using the same protocol, right, or the same, that are all coalesced around one thing.
00:15:17.960 - 00:15:29.480, Speaker B: Yeah. You want decentralized communities to exist. Yeah. So effectively you want all the biggest services you use today, you want them to be running by the community, right?
00:15:30.330 - 00:15:47.100, Speaker A: Which I think goes against this model where you have services that abstract that away from the user. I think ultimately the space succeeds only when we have 200, 300 million self custody wallets out there. They're all doing something.
00:15:48.990 - 00:16:16.014, Speaker B: Let's slightly pivot the argument, right? And so let's say that it is actually the case that running a huge mainframe is cheaper, $5,000 machine than running a huge distributed cluster. Why is it the case that IBM and Oracle, they can only acquire those huge enterprise customers who are ready to pay for their huge mainframes, but majority of people, they use distributed databases, they use mem SQL, they use Cassandra Mongo.
00:16:16.062 - 00:16:40.140, Speaker A: But there's like this ridiculous misconception that it's a mainframe. It's literally a gamer box, like a $5,000 machine and a one gigabit network. I have one gigabit in my house. This is like the bare level of what hardware and networks are today, right, in the developed world. Why do we utilize all of it?
00:16:40.590 - 00:16:44.766, Speaker B: So first of all, is it the case that your one gigabit never glitches, right?
00:16:44.788 - 00:16:56.274, Speaker A: Because that's why you have like a few thousand of them. And as long as the glitches are non correlated, but also, that's the whole point of consensus, right? That whole other thing.
00:16:56.312 - 00:17:10.600, Speaker B: So let's say everything goes well and within several years people actually move towards community driven services, right? Do you think that those gamer boxes, those gamer non mainframe boxes can run the entirety of what Google, Facebook, Instagram running today?
00:17:11.770 - 00:17:49.250, Speaker A: Well, the thing that's actually happening on chain, right, there's these small, straightforward things where you're just switching ownership and maybe like you have one giant state machine for price, right? You're not running the Facebook application on chain, right, that's running in the front end. What you're coordinating is data access and privacy and controls, right? It's not like this thing that needs to execute in these trust minimizing computers doesn't need to be a Java VM running a big pile of shitty business logic.
00:17:49.830 - 00:17:56.470, Speaker B: But why not? Why would I not run if I can, why would I not run those decentralized applications entirely on chain?
00:17:58.010 - 00:18:16.060, Speaker A: Well, you can really do it even in a sharded system because the resource constraints are huge. So if you are like sharding isn't going to help you there because you're talking about really fat applications, unless you have one fat application per shard, basically.
00:18:16.430 - 00:18:19.226, Speaker B: But nothing stops you from sharding applications themselves, right?
00:18:19.328 - 00:18:19.690, Speaker A: Sure.
00:18:19.760 - 00:18:25.802, Speaker B: So if application is sharded on its own for as long as the number of shards grows together with the adoption.
00:18:25.946 - 00:18:31.726, Speaker A: And then each application can run its own tendermint chain. And then a single tendermint chain is.
00:18:31.748 - 00:18:49.058, Speaker B: Not good enough, right? Single tendermint chain is still limited by what a single machine can give you, right? But if applications themselves are shorted, nothing really stops you from running the entirety of the web3 on chain, which would be like, that's the future I want to live in, right?
00:18:49.144 - 00:18:49.826, Speaker A: Sure.
00:18:50.008 - 00:18:56.790, Speaker B: But you cannot run the entirety of web3 on mainframes. I mean, you can, but they're going to be extremely expensive. Those are not going to be gamer boxes.
00:19:02.110 - 00:19:27.022, Speaker A: The applications you're talking about, they're not going to store data and images on chain. They're not going to store the front end on chain, right? Nobody's designing that. No one in Ethereum is talking about the web. Three people are not like pitching that, right. They're pitching, we store all the heavy stuff in IPFs and we load everything client side, and we use the chain to coordinate.
00:19:27.166 - 00:19:41.446, Speaker B: Right, but that's also what I'm talking about. Right? Nobody talks about storing images on chain, but you want to do all the logic, the entirety of the back end logic you want to do on chain. That's what gives you the knowledge that nobody is trying to take advantage. Right.
00:19:41.468 - 00:20:16.820, Speaker A: So then you have two options, right? You have a sharded chain, which is running low powered hardware where the fees have to cover the spam for the single shard, right? Or you have a non sharded chain that's just running standard hardware, like machines you can buy at fries. Right. That's utilizing one gigabit where the full capacity of the network is available to everybody. Right? So I think why would you pick the sharded chain? Why?
00:20:19.510 - 00:20:35.526, Speaker B: So the reason is that it is unlikely that mainframes, which a large number of entities around the world can afford, can run the entirety of the vision of what web3 can bring. Right? So if we do believe that web.
00:20:35.548 - 00:20:41.290, Speaker A: Three will, we agree that the web3 on chain is just doing small amount of logic.
00:20:41.870 - 00:21:08.882, Speaker B: But first of all, that logic is not entirely homogeneous. That's one. Right? So if you're running many, many different applications, most of that will have to be happening on the CPU, unless everybody is running a separate instance of Solana. But again, that's sharding. Exactly, right. So majority of the stuff will have to be happening on the CPU. So you will have to be running all the business logic of all the.
00:21:08.882 - 00:21:22.360, Speaker B: Like, imagine running all the business logic of all the Internet on a single. It's like as if Facebook itself did not chart their execution and was running a single huge machine replicated to another single huge machine for processing Facebook. But they don't do.
00:21:26.890 - 00:21:39.046, Speaker A: So there is like. I guess the difference is, do you think that we're going to see homogeneous applications that take up the most capacity or a long tail of non homogeneous ones that are hard to coalesce?
00:21:39.158 - 00:22:08.950, Speaker B: Right? Yeah, I think the difference here is defi. I think mostly going to be largely homogeneous, partially because I think several use cases would be dominating the entire defi market. Like a Dex for Dex salana is gorgeous. But if you're talking about web3 or any other kinds of applications, if we're talking about a whole slew of possible applications that cannot be fully moved to the GPUs, sure.
00:22:09.020 - 00:22:27.050, Speaker A: But if you have like a game like cryptokitties that all of a sudden has like a spike in usage that goes viral. Because it's going viral, it means all those contract calls are exactly the same, taking the exact same branch, breeding two cats, storing this random set of numbers, right?
00:22:27.120 - 00:22:41.934, Speaker B: Yes, for particular. But do you envision that in Solana, it will be the case that it will always be like one or very few applications that fully dominate the network and everybody else goes to the CPU? Even if it's the case, is it the case that everybody else will be?
00:22:42.052 - 00:22:51.362, Speaker A: Yeah, I guess we'll see if I could predict that. I have no clue. Right. Like, nobody does.
00:22:51.416 - 00:23:18.442, Speaker B: But the beauty of sharding is that it does scale with adoption. The particular beauty, which I think is going to be relevant short term, is that until adoption comes, and it will take time and it will take a lot of work for me, you and others who were here today to bring that adoption, until adoption comes near, will be very cheap, right? Eight shards on commodity hardware is nothing, while people in Salana already need to run main frames, right?
00:23:18.576 - 00:23:20.170, Speaker A: It's a $5,000 box.
00:23:20.240 - 00:23:21.850, Speaker B: It's a $5,000 box.
00:23:22.000 - 00:23:29.998, Speaker A: Well, like, if you look at Ethereum, right, you have, what is it, 32 e, your minimum stake, which is $6,000, right?
00:23:30.084 - 00:23:32.318, Speaker B: I'm not necessarily saying Ethereum is great, right?
00:23:32.404 - 00:23:48.386, Speaker A: And not only that, you're running a so called cheap commodity hardware that will get slashed with quadratic leaking, right, for being unavailable. So you effectively have to run a high availability system anyways.
00:23:48.498 - 00:24:09.820, Speaker B: But again, do you have to build? Slashing for an availability? Near doesn't slash for an availability, right? All of those are contentious points, but they are not necessarily something that is necessary for sharding, right? So sharding is just about whether you do scale out or if you scale up, right? That's the only argument here, really.
00:24:11.170 - 00:24:37.618, Speaker A: But the reality of it is going to be you have 80% of the tokens held by 20 entities, right? At most. So all those 20 entities will have to run a validator in every shard at all times, no matter what you do. So you have like Zilliqa, right? You have the supermajority of the stake is running a validator in every shard at all times.
00:24:37.784 - 00:25:16.142, Speaker B: But that's actually necessarily so. The argument here is that if your stake is huge, then you actually can afford to run, to run those nodes, right? But you do want that long tail of participants to be running their small nodes, and their stake is small, that also they don't need to invest in the mainframe like those clusters, but they are still providing a lot of security. It's not enough to corrupt two thirds. In a system where there are validators and fishermen, a single entity in a short who's not corrupted can still go and challenge and slash those participants who did collude, right? So for as long as you have that one little like that one person who made a small, that whole solution.
00:25:16.206 - 00:25:28.040, Speaker A: Is only a solution to a problem that only sharding has, right? You don't need a fisherman and tenderman. You have a single chain, single consensus, right?
00:25:28.970 - 00:26:06.766, Speaker B: So let's say there's 1000 people who bought, who run Salana validators, right? So that means that you need 300 people to corrupt or like you're saying, bfT consensus, but it seems like you need more than one third, right? Anyway, it's very different than when you have a huge long tail of people. And if adoption grows, right? Today, number of full nodes is small. But if adoption grows, you will have a very long tail of people who will be staking. Because also the randomness is removed. Like the lottery is removed. That's a very important property. One of the big problems of proof of work today is that there is a lottery, right? If you buy a GPU and start mining bitcoin, you will never get your reward.
00:26:06.766 - 00:26:36.634, Speaker B: You have to join the pool. Centralization in the proof of stake system, such as the way sharding usually is designed, is that as long as your stake is sufficiently small, it's sufficiently large to get into the validator seat, your reward is guaranteed. Right? If you have a lot of shards, if the sharded system takes off, if you have 1000 shards, each one with like 100 validators, as long as you have 100,000 of the total stake, you're staking, getting your guaranteed reward. So small nodes will be launching, but.
00:26:36.752 - 00:26:44.522, Speaker A: People get lazy and just give their stake to a pool or host it on Coinbase and like, okay, just stake it through this interface, right?
00:26:44.576 - 00:27:08.690, Speaker B: That happens. But remember what was happening when bitcoin was mineable? Like in my home city, which is like, it's a rural place of Russia where most people don't even think that you can live there. Everybody was mining bitcoin because it was cool. Once you give that back to people, people will be doing that. People will be staking and running nodes on the hardware and their closet. And that creates decentralization.
00:27:08.770 - 00:27:19.670, Speaker A: Yeah, of course. Which is my point is that sharding is a solution to decentralization, which is very admirable. Right? But I don't think it's like a good scaling solution.
00:27:19.750 - 00:27:32.430, Speaker B: Well, it's a play of words. Sharding is a solution to scalability, which has this property that is decentralized. While scaling up is also a solution to scalability, which has a property which it is less decentralized.
00:27:33.570 - 00:27:42.510, Speaker A: It's more expensive to decentralize, yes, but not less decentralized by constraints of number of validators or participants.
00:27:43.270 - 00:28:14.234, Speaker B: But also, I think one last argument that I personally have against scaling up is that in a system which processes like 100,000 transactions per second, there's a certain reliance. You really rely on the fact that every two years you will be scaling up by some factor, because if you start a new full node, you need to catch up from the genesis. So it's been ten years. You need to be catching up 100,000 transactions for every second since Genesis, right?
00:28:14.272 - 00:28:14.618, Speaker A: Yeah.
00:28:14.704 - 00:28:20.086, Speaker B: So unless your hypothesis is correct and it continues doubling up every couple of years, you get pillaged.
00:28:20.118 - 00:28:32.842, Speaker A: Because at some point my hypothesis is not correct. We should just be buying non perishable foods. If we stop doubling, how much compute we can do, like every two years, we're all screwed.
00:28:32.906 - 00:28:42.530, Speaker B: No, engineers will just stop writing twice as slow code every year. They will start optimizing what they do. That's not what will bring the world to the collapse.
00:28:43.590 - 00:29:00.630, Speaker A: If we hit like, an information limit, I think that would mean the end of the world in some ways or another. That's not even an option. Right. So, silicon. The wafer sizes are going to keep growing. There'll be some way that they can keep adding more transistors.
00:29:01.050 - 00:29:01.922, Speaker B: Hopefully.
00:29:02.066 - 00:29:09.380, Speaker A: Yeah, hopefully. Cool. Well, this was super fun. We could talk for hours. We could talk for hours. Yeah.

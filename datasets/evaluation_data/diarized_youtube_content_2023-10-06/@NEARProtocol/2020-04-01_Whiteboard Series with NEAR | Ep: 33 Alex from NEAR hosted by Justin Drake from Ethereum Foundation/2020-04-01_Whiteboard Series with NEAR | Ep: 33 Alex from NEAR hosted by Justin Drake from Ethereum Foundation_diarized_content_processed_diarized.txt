00:00:00.250 - 00:00:00.800, Speaker A: You.
00:00:04.450 - 00:00:30.262, Speaker B: Hi. Welcome again. In our next episode, we have Alex Skidanov from near, who's going to tell us about the details of his design and as kind of framing for the discussion, my understanding is that near basically used e two as a starting point, at least a design from maybe a year ago or a year and a half ago.
00:00:30.316 - 00:00:31.478, Speaker A: Some aspects of it, definitely.
00:00:31.564 - 00:00:40.870, Speaker B: Yeah, some aspects of it. And you've kind of forked off. So it would be interesting to see what the key differences are between e two and near.
00:00:40.940 - 00:00:42.138, Speaker A: Yeah, let's dive in.
00:00:42.224 - 00:01:00.960, Speaker B: Cool. So one of the things that I've prepared is just to provide some grounding is some of the design decisions in e two. And as we talk about this, fill in the table for now.
00:01:02.930 - 00:01:08.402, Speaker A: Before we do that, do you want me to briefly decode night shade so that when we use terms as we go through.
00:01:08.456 - 00:01:10.500, Speaker B: Yeah, please. I mean, go ahead.
00:01:10.950 - 00:01:47.274, Speaker A: Okay. So the biggest forking point between near and, well, I call them more classic sharding designs. So the more classic sharding designs, they have shard chains where every shard chain is effectively, to an extent, is an independent blockchain. Right. So there are multiple shard chains and there is a single chain, which is, we will refer to it as beacon chain. That's an ethereum term. There's a single chain which has, first of all, significantly higher security than all the remaining chains.
00:01:47.274 - 00:02:36.478, Speaker A: So everybody, or like a very large percentage of participants, validates beacon chain, and only a sample validates every shard chain. And so beacon chain is responsible for many things. One of them is generating unbiaseable randomness, and some others would be some way of improving security of every shard chain. So, for example, one common thing that exists in many such protocols is for shard chains to respect the last block that is known to the beacon chain. So if beacon chain acknowledged in some way that it saw this block, then the shard chain will never build on top of anything that is not this block. So that's one of the things that beacon chain might be doing. So instead, what we do in Nier, which is we took a step to simplify this process.
00:02:36.478 - 00:03:07.890, Speaker A: So, specifically, the problem is that when you need to orchestrate multiple chains, the implementation becomes pretty complex. Right. You need to maintain each chain, to an extent, has its own fortune rule, its own consensus. And orchestrating all of that becomes designing it, thinking about it, becomes more complex. So in near, instead, there's only one chain, which we call it the main chain. We can also call it the nitrate chain. And this entire design is called nitrate.
00:03:07.890 - 00:04:10.150, Speaker A: And so what happens is, in this main chain, every block, so it has a header with the pretty standard things like previous block or a global state route, et cetera. And logically, but not physically, this block will also contain all the transactions that happened from the previous block. However, physically, what will actually happen is similar to other sharding designs, this state is logically split into multiple shards. So, for example, we can think of the entire state as a continuous set of account ids, which is split at some boundaries into, let's say, four shards. And so any transaction that touches a particular shard, so all the transactions that touch the shard one, they will physically be grouped into a thing called chunk for short. One, all the transactions that touch shard two will logically be grouped into chunk two, et cetera. And so, even though logically the block contains all those transactions, physically, people will only download the block, and the block contains the headers of the chunks.
00:04:10.150 - 00:04:50.140, Speaker A: But then they will only download chunks for the shards they actually care about. Every block contains, at most one chunk for a particular shard, but it could contain zero, for example, if the chunk producer failed to produce it, or if it wasn't sent in time. And so you can think of those chunks as those chunks. They closely resemble the shard chain, right? So the chunk builds on top of the previous chunk, and it builds on top of the state that the previous chunk was the result of applying transactions in the previous chunk. But it becomes simpler in many other aspects. For example, there's only one fork choice rule now, there's only one concept of finality. There's only one consensus running here.
00:04:50.140 - 00:05:26.626, Speaker A: And it also simplifies to an extent the way, obviously now, same as with the shard chains design, the concept of cross shard transactions appears, right? If a transaction previously in a non sharded chain would have touched accounts into different shards, now it has to be executed separately in every shard, and so the shards need to communicate. So that also becomes simpler to an extent. And so let's see how it fits into the table. And then if something is not covered with this particular separation, we can cover it later.
00:05:26.728 - 00:05:33.042, Speaker B: So I have a few questions here. So are you saying that you have chunk producers and then block producers?
00:05:33.106 - 00:06:01.754, Speaker A: Right. So the way it works is that there is a single set of block producers. So let's say in our design, that number today is between 102 hundred. So if it's more than 200, the system as built today will not necessarily be able to handle it. So the 200 block producers, they take turns producing blocks and then each of them is assigned to some subset of shards. Right? And so within those shards, they also take turns producing chunks.
00:06:01.882 - 00:06:02.414, Speaker B: Okay. Right.
00:06:02.452 - 00:06:08.482, Speaker A: So you could think about it. Let's say five of the first five are assigned to maintain the first five shards. And then the next five.
00:06:08.536 - 00:06:09.940, Speaker B: How many shots do you have?
00:06:11.430 - 00:06:23.110, Speaker A: We're probably going to launch with something very small, like eight, but up to 100 today will probably be handleable. The green one doesn't work. Orange.
00:06:25.130 - 00:06:30.700, Speaker B: Okay, so you have eight shards, we have 64.
00:06:35.230 - 00:07:08.950, Speaker A: And so part of the idea here is that we want to launch something that is meaningful today. Right? So today, especially given it will take time for the wider adoption. So HR will be more than sufficient. And the idea is that once it is shipped and it is operational, then we can do so number of shards. We can just do an upgrade and increase up to 100, but also increasing like beyond 200 validators or beyond block producers or beyond 200 shards. We can be building the tech to support that. As the system already is operational.
00:07:10.650 - 00:07:10.966, Speaker B: And.
00:07:10.988 - 00:07:13.798, Speaker A: The adoption is already for us, the.
00:07:13.804 - 00:07:24.890, Speaker B: Minimum stake is 32 e. So if you look at the kind of max number of validators, then we get about 4 million validators.
00:07:25.390 - 00:07:28.634, Speaker A: Oh, that's like if you divide the total. Yeah.
00:07:28.752 - 00:07:33.902, Speaker B: And for you, are you saying that the maximum of validators is around 200?
00:07:34.036 - 00:07:48.558, Speaker A: Right. And so instead of having the specific stake, what happens is everyone in the system can stake any amount at any point. So you just go and you issue a staking transaction and you just say how much you want to stake and that amount gets locked.
00:07:48.654 - 00:07:49.058, Speaker B: Right?
00:07:49.144 - 00:08:22.382, Speaker A: And what happens is that at the beginning of every epoch, and epoch is approximately half a day. At the beginning of every epoch, we find such a threshold that if you divide every stake by that threshold, then you get at least 200 full seats. But any higher threshold will yield less than 200. And so that will be the price of a single seat. Right? So for example, if I stake 100, you take 50 and we need three seats total, it will say, well, threshold is 50. Because if I divide by 50, I will get two seats and you get one. But if we divided by 51, I would get one, you would get zero.
00:08:22.382 - 00:08:23.774, Speaker A: And so we don't have enough.
00:08:23.972 - 00:08:29.070, Speaker B: And staking is purely optional. Right? And there's no delegation.
00:08:29.490 - 00:08:52.450, Speaker A: So we actually do build delegation. Delegation at least. I personally am extremely against delegation. Okay. However, what will happen if you don't support delegation? People will still delegate with the idea that a, not everybody wants to run a validator or like block producing node. And b, many people will be uncomfortable running their own infrastructure. Because there's a high chance of messing it up and getting slashed.
00:08:52.450 - 00:09:20.186, Speaker A: So people will delegate, they will just do it off chain. They will just go to one of the professional validators who exist today, and they will just transfer their money and do like a paper contract, which is a perfectly viable solution. But now the system doesn't have, now it becomes non transparent. So we have no insight into how bad it is actually. While if delegation exists on chain, we have very clear picture of how much is actually delegated, we see the extent of the disaster.
00:09:20.298 - 00:09:20.622, Speaker B: Right.
00:09:20.676 - 00:09:22.720, Speaker A: So delegation will be supported on the.
00:09:23.330 - 00:09:30.066, Speaker B: And the delegation, is it that you can get slashed if you delegate your stake to someone else?
00:09:30.088 - 00:09:34.590, Speaker A: Yeah, if someone else to whom you delegated committed a slashable act, you get slashed.
00:09:34.670 - 00:09:39.362, Speaker B: Okay, great. And how do you split the rewards?
00:09:39.426 - 00:09:55.206, Speaker A: Is that the reward is effectively at the end of the epoch, the total reward is just split. I think it's either equally with everybody or proportional to the number of blocks produced. But yeah, it happens at the end of the epoch.
00:09:55.398 - 00:10:00.570, Speaker B: Okay. But I guess the splitting between the delegatee and the delegator.
00:10:00.910 - 00:10:23.906, Speaker A: So that is interesting. So what happens is staking happens through a smart contract. So every delegate, I guess, whomever is actually running the validator, they have a smart contract which outlines all the rules of how exactly the stake will be distributed. So in the simplest form, it will say, I will just give you 80% back of the reward proportional to your stake. But it could be arbitrary. Smart contract, which will distribute the reward back.
00:10:23.928 - 00:10:26.750, Speaker B: Oh, that's cool. So you kind of have delegation abstraction.
00:10:26.830 - 00:10:42.540, Speaker A: Yes. So the reason for that is that one of the big cosmos validators today has 0% or like 100% fee. And then off chain, they distribute your word according to some custom rule, because it's already happening in practice. Right. It makes sense to automate it.
00:10:42.990 - 00:10:54.302, Speaker B: Okay, great. And what do you think in practice will be the minimum amount of value that you need to have one seat in the system.
00:10:54.436 - 00:11:25.830, Speaker A: So I think if we figure out the percentage of total stake, that can easily be derived. Right. So if it's like, let's say total stake is 30%, then 30% over 200 will be the cost of a single seat. It's hard to estimate the percentage. Right. I don't have my own estimate. Ilya, the other near co founder, he thinks it's going to be over 50% total stake, at least initially, especially given that many of the initial near holders, their tokens are locked, meaning that they can stake, but they cannot transfer them.
00:11:25.830 - 00:11:44.026, Speaker A: Staking is only a thing they can do. Yeah, think about, let's say 60% is locked. So that means 0.3% is the minimum stake for the seed. If you have less than that, you can still run a node. It will not be just immediately returned to you. You can claim it back.
00:11:44.048 - 00:11:44.282, Speaker B: Right.
00:11:44.336 - 00:12:24.454, Speaker A: But the idea is that if you want to be a fisherman, you need at least some stake so that we need to be able to slash you if you submit an invalid challenge. So you can run a fisherman and there is no reward for the fisherman. So fisherman is entirely voluntarily act. Reasons for that is that it's actually very hard to create fisherman reward in such a way that whomever includes your transaction just doesn't steal your challenge. Like you need to do some commit reveal of some sort. And so instead of that, we're just saying there are clearly entities who will be willing to run fishermen like ourselves or like hypothetical exchange that is running near and has a large stake in it. So there's plenty of entities who will voluntarily run fishermen.
00:12:24.454 - 00:12:44.420, Speaker A: And then nitrate has this concept of hidden validators, which we don't ship initially, but it's going to be like in one of the future updates, which provides you an extra layer of certainty that even if you don't trust there is a fisherman, there will be someone assigned to validate the shard who is not known to the system. And so you get an extra level. We can dive deeper into it later.
00:12:45.110 - 00:12:57.474, Speaker B: Okay, so I guess I have a couple of questions. One is you mentioned the roadmap that some features are coming later. We have phase zero, phase one, phase two. What is your deployment roadmap?
00:12:57.522 - 00:13:13.514, Speaker A: Right. So I think ours is way shorter. So there's initial main net which will be launched. I cannot provide an exact date. It depends a lot on stability, right. How much it will take until we actually certain that it will not go down.
00:13:13.552 - 00:13:15.180, Speaker B: Launch it. 2019. Right.
00:13:15.630 - 00:13:50.246, Speaker A: It will not happen in 2019 anymore for sure. That would be, and so there are two big features that's not going to be included. It's unbiasable randomness beacon, which we have actually built like it's on GitHub, but stabilizing it will take longer than we're comfortable delaying the launch. And hidden validators. So those are two big features and hidden validators haven't even started yet. Right. But besides that, there is sort of long tail of things such as we do need to scale beyond 200 validators at some point early on.
00:13:50.246 - 00:14:02.570, Speaker A: It doesn't matter because we're not going to have enough, like the number of total professional people who run validators today is like in low hundreds. Right? So everybody who wants to run clearly will be able to, but long term it needs to scale.
00:14:02.910 - 00:14:08.266, Speaker B: So this max number valid is 200. That's like a technical restriction, it's not an economic one.
00:14:08.368 - 00:14:14.542, Speaker A: Yeah. So 200 today is beyond 200. We will not have the block production time, for example, that we want to have.
00:14:14.596 - 00:14:16.480, Speaker B: Okay, what is the block production time.
00:14:17.490 - 00:14:35.038, Speaker A: We wish to have? 1 second at some point. Okay. Today it is not there, but we can sort of draw the timeline of how messages pass. And according to the timeline, 1 second is technically possible. Right. Today it's somewhere between two and 3 seconds is what we can push.
00:14:35.134 - 00:14:35.780, Speaker B: Okay.
00:14:37.110 - 00:14:44.882, Speaker A: But once we dive deeper into doomslug and nitrate, we can just draw the timeline of how messages travel. For the block to be produced.
00:14:44.946 - 00:14:45.222, Speaker B: Right.
00:14:45.276 - 00:14:54.742, Speaker A: And effectively what it boils down to is it needs to have two round trips between most of the validators and validating transactions, which is two round trips.
00:14:54.806 - 00:14:55.420, Speaker B: Okay.
00:14:58.110 - 00:15:07.354, Speaker A: Which is like round trip between China and United States is 300 milliseconds. So without, optimistically, without gossip network, that would fit with gossip network, it becomes more challenging.
00:15:07.402 - 00:15:13.278, Speaker B: Yeah. Okay, interesting. And how does your system degrade if latency becomes very high?
00:15:13.364 - 00:15:40.674, Speaker A: So what happens is. So that's doomslag, right. I can also cover doomslag quickly so that we have all the building blocks. So doomslag is a very new thing. Right? So the initial doomslag we published on the last day of the previous decade, a month ago. And so doomslag is this very nice, very simple construction, which is when you produce blocks. Right? So I think this is sort of similar to Ethereum and many other systems.
00:15:40.674 - 00:15:50.134, Speaker A: Blocks include approvals, right? Or like some sort of, include what? Approvals? Or like some approvals messages from all other block producers, right? Yeah. So that's something that would be used for finality, gadgets, et cetera.
00:15:50.182 - 00:15:52.406, Speaker B: We call them attestations, you could call them votes.
00:15:52.438 - 00:15:54.202, Speaker A: Yeah, we call them approvals.
00:15:54.266 - 00:15:54.590, Speaker B: Okay.
00:15:54.660 - 00:16:22.818, Speaker A: But yeah, it's all the same thing. It's a message from every other block producer and or validator attesting to something in the past. Right? It could be the previous block, it could be something else. So specifically for Doomslug, when you create a block, to create a block, you need this approval from 50% of the remaining block producers on very previous block. So that's one round trip. When block is published, 50% of block producers needs to send it to you. And once you have that 50%, you can produce your block.
00:16:22.818 - 00:16:28.410, Speaker A: Until you have the 50%, you cannot even produce it. So the block that does not have 50% of approvals is invalid.
00:16:29.150 - 00:16:32.700, Speaker B: Okay, so what happens if you just don't get 50%?
00:16:33.390 - 00:16:35.766, Speaker A: If less than 50% are online, it stalls.
00:16:35.878 - 00:16:38.346, Speaker B: Wow. Okay. Like, definity similar to.
00:16:38.368 - 00:16:44.478, Speaker A: Definity similar to almost everything, which is like Ethereum 2.0, but also it's not two thirds, it's 50%.
00:16:44.564 - 00:16:44.862, Speaker B: Right.
00:16:44.916 - 00:17:12.786, Speaker A: So that's already. It's noticeably a bit better if you think about it. Right. There is big difference there is between acquiring two thirds of people and 50%, because lowering that 50% also has this side effect that if you have less than 50%, there could be another network in existence. Like, why do you have less than 50% block producers? One option is that there's a global network split and there's another network building. Right. Okay, so here we get to this question of consistency versus availability.
00:17:12.786 - 00:17:21.770, Speaker A: If you allow less than 50%, clearly you're, like, on the available site. Right. Requiring 51% is being more on the consistent side.
00:17:21.840 - 00:17:22.554, Speaker B: Right? Exactly.
00:17:22.672 - 00:17:58.390, Speaker A: Right. And so it acquires 50% of approvals from the very previous block. And the way these approvals work is the moment you see the block, you immediately, or like, after waiting for a little bit for, let's say, 200 milliseconds, you send the approval to the next block producer, whom you know, and then you wait for some longer time, let's say for like 2 seconds or like for 1 second or 2 seconds. That's a parameter of the system. And if you don't see the block, then you send the same approval to the person two blocks ahead of you. And then again, if you don't see the block in a little longer time, you send approval to the next person. Right.
00:17:58.460 - 00:18:02.898, Speaker B: So you send approvals to block proposers as opposed to the actual blocks.
00:18:02.994 - 00:18:26.266, Speaker A: Yeah. So from a given moment, you know block proposals for every height going forward, at least if no other blocks happen in between. Right. It is okay if the block proposals change when the next block is produced. If this block is the last block, then for the next block that is built on top of it, you need to know block proposals for every height. Right. Depending on which height the next block will be produced, there could be skips.
00:18:26.266 - 00:18:58.280, Speaker A: Right. Like the current block has height five. You know that if the next block, if it's on height six, will be proposed by one person, if it's height seven, by some other, et cetera. And so what you do is the moment you see the block at height five, you immediately send approvals to the person. You immediately send your approval to the person at height six who will be proposing at height six. And then if during 1 second you don't see the block, you send to the person who will be proposing at seven. If during 1 second and 100 milliseconds, you don't see the block, you send to the next guy and you increase the time every time.
00:18:58.650 - 00:19:02.746, Speaker B: So you are sending approvals for a specific block, not for the tip of.
00:19:02.768 - 00:19:04.442, Speaker A: The chain as you know it. Right now, yes.
00:19:04.496 - 00:19:12.106, Speaker B: Right. Okay. And you're saying that every block can change the set of future.
00:19:12.208 - 00:19:18.078, Speaker A: So we don't do that today. Today our schedule is fixed, but it technically can change if you want to for some reason.
00:19:18.164 - 00:19:22.430, Speaker B: Okay, so when you have strong randomness that you talked about, you will deploy also?
00:19:22.500 - 00:19:23.262, Speaker A: We might, yes.
00:19:23.316 - 00:19:23.582, Speaker B: Okay.
00:19:23.636 - 00:19:31.982, Speaker A: Not necessarily because it doesn't really help with dedosing, because if you know the block proposers for the particular block, you can dedose them. It doesn't help in any way that they shuffle.
00:19:32.046 - 00:19:32.322, Speaker B: Right.
00:19:32.376 - 00:20:01.610, Speaker A: Like if we don't, using some algorithm or robbery's magic, they are dedosable. That's a conscious choice. Okay. That's practically the entire doom slack. And so what it gives is that property number one, if a particular block has 51% of those approvals on the block at the very previous height, so the difference in height is exactly one, then this block is irreversible unless at least one seed gets slashed.
00:20:02.110 - 00:20:02.570, Speaker B: Right.
00:20:02.640 - 00:20:04.534, Speaker A: Okay, so we call it dooms like finality.
00:20:04.582 - 00:20:05.066, Speaker B: That makes sense.
00:20:05.088 - 00:20:12.910, Speaker A: Yeah. And then there is a finality gadget, which is running on top of that, leveraging the very same approvals. There is one extra field in the approval that finality gadget needs.
00:20:12.980 - 00:20:13.358, Speaker B: Right.
00:20:13.444 - 00:20:39.778, Speaker A: And with the finality gadget, if everything goes very well, if blocks are not skipped, then when this block is produced, this one becomes completely final. By completely, I mean standard BFT finality, where like one third needs to be slashed for it to be reversed. But if doomslake produces, if there is a skip, right? For example, let's say we configure it to be 1 second, and 1 second is not realistic, then you will expect to always have those skips, and then.
00:20:39.804 - 00:20:40.918, Speaker B: You never have finality.
00:20:41.014 - 00:21:10.210, Speaker A: So what happens is in the doomslag, it has proven that after finite amount of time, there will be, because of the delay, that after some finite amount of time, there will be two blocks in a row with a doom slide finality. Right. And it will happen very closely, very close to that moment when you actually cross the actual realistic timeout for the blocks. Right. So doomslake has finality. And because of doom, sorry, liveness. And because of doomslag liveness, finality gadget has liveness.
00:21:10.550 - 00:21:11.202, Speaker B: Right.
00:21:11.336 - 00:21:19.960, Speaker A: Because effectively, with finality gadgets, that single chain, I obviously work. And if there is a fork, then someone gets slashed, and you can only slash people finite number of time.
00:21:20.730 - 00:21:23.990, Speaker B: Okay, so you have liveness at 50%. Yes.
00:21:24.140 - 00:21:29.590, Speaker A: And then below 50%, it's not just we don't have guaranteed liveness. We don't have any liveness.
00:21:30.170 - 00:21:46.750, Speaker B: Okay, so just to recap, the fancy gadget, if you have two blocks in a row, both of which by construction, will have at least 50% of the vote for the previous block, then you're in a situation where if there is a fork, a break of the finality, then at least one first gets lashed.
00:21:47.170 - 00:21:50.670, Speaker A: Almost. It does need to have two thirds in both blocks, of course.
00:21:50.820 - 00:21:51.662, Speaker B: Oh, I see.
00:21:51.716 - 00:22:16.754, Speaker A: Okay, so for finality gadget, it's okay if approval arrives late. Let's say some approval was not included here. If that approval arrives late, finality gadget will take advantage of it. So finality gadget, it's nowhere, uses the assumption that approvals have to happen on the very previous block. Okay, same as Casper f of G. I guess Casper FFG doesn't care when approval arrives. Yeah, it just uses the set of approvals.
00:22:16.802 - 00:22:27.820, Speaker B: Right, right. So you don't care between 50 and above and 66 and above. I guess we don't care even from zero to LMD Ghost. Yes. Right.
00:22:29.390 - 00:22:37.738, Speaker A: But I guess for slashable, there's no slashable behaviors in LMD ghost. Right. So for slashable, okay, like, for finality, where someone will get slashed, there is the threshold of two thirds.
00:22:37.754 - 00:22:46.882, Speaker B: Right, okay, so basically you've taken these two things and you've called it doom slug, and you have slightly different properties. Yeah.
00:22:47.016 - 00:22:48.420, Speaker A: Okay, doom is like.
00:22:49.190 - 00:22:50.100, Speaker B: Thank you.
00:22:51.750 - 00:22:58.286, Speaker A: I would say, like, LMD Ghost is doomslag and FFG is the finality gadget. We call it NFG. Right, finality gadget.
00:22:58.398 - 00:23:01.810, Speaker B: But you're saying that it meshes in slightly cleaner.
00:23:01.890 - 00:23:04.498, Speaker A: So NFG will work with anything. It will work with LMD Ghost.
00:23:04.594 - 00:23:05.240, Speaker B: Right.
00:23:05.610 - 00:23:15.238, Speaker A: It is to an extent similar to FFG. The only major difference is that in FFG, for finality, you actually do need two consecutive blocks. Well, in your case, it would be epochs.
00:23:15.254 - 00:23:16.426, Speaker B: Right, right, epochs, yeah.
00:23:16.448 - 00:23:18.522, Speaker A: Right. But we run finality, guys, it on the block level.
00:23:18.576 - 00:23:18.746, Speaker B: Right.
00:23:18.768 - 00:23:30.190, Speaker A: So if we did use FFG, we would need to have two consecutive blocks where one of them has two thirds approvals from the previous one. And NFG is very similar to f of G. It's very similar. It doesn't have this requirement.
00:23:31.090 - 00:23:35.454, Speaker B: Okay, so the folk choice is doom, slug, and then you have nfg.
00:23:35.502 - 00:23:36.194, Speaker A: Right.
00:23:36.392 - 00:23:40.180, Speaker B: N is near, of course, or like nitrate. Nitrate. Okay, great.
00:23:41.190 - 00:23:51.190, Speaker A: And it's like NFg and ffg. It also uses reference blocks. It's very similar construction, but slightly different. Sufficiently different to remove that requirement.
00:23:52.250 - 00:24:22.830, Speaker B: Okay, great. I mean, while we're on the topic of voting with stake, I think it's very important to understand what is the distribution of stake. Because in Eve two, we're in a very unique position where we have a running network with, let's say, $30 billion of stake, and it's very decentralized. And I think, neo, you've come up with some clever ideas to find to have an initial distribution which is quite relatively decentralized.
00:24:23.170 - 00:24:48.406, Speaker A: So those ideas are all currently still in discussion. So all the ideas we were discussing last year, none of them is really in production yet. Okay, right. So we do have some amount of presale, which is below 30%, or like close to it, which is split between us, people who built it, and also people who funded it. Right, so you mean 30% of the.
00:24:48.428 - 00:24:52.090, Speaker B: Stake at launch or at launch? At launch, yeah. Okay.
00:24:52.160 - 00:24:55.994, Speaker A: Right. So the remaining 70%, the goal is to distribute them to the community.
00:24:56.112 - 00:24:56.442, Speaker B: Okay.
00:24:56.496 - 00:25:36.198, Speaker A: Exact way. There are many ideas, none of them still is decided to certainly take place, but some ideas would be to use something that handshake was doing. Handshake was doing very nice. Targeted drops to GitHub accounts, for example, or have some way of people doing some, like doing log drops where people can lock ethereum, like what edgeware was doing. People before us already found many ways to distribute tokens. We just need to analyze. And they also already did distribute tokens this way.
00:25:36.198 - 00:25:46.310, Speaker A: So what we need to do, and we don't have enough information yet, is just to look how it went. Like what happened to the token holders of handshake? What happened to the token holders of edgeware? Well, edgeware is not liquid yet.
00:25:46.380 - 00:25:48.246, Speaker B: Oh, no. They did launch a few days ago, I think.
00:25:48.268 - 00:25:58.320, Speaker A: Oh, they did? Yeah. Great. So we will stuff, we will have information to make a good. What the goal is yet. The goal is at least remaining 70% must be as distributed as possible.
00:25:58.690 - 00:26:02.510, Speaker B: Right. Okay, understood.
00:26:05.110 - 00:26:07.150, Speaker A: And so I guess system chain, we covered.
00:26:07.310 - 00:26:10.754, Speaker B: Yeah. So your system chain, you call it the main chain, right?
00:26:10.792 - 00:26:11.282, Speaker A: Yeah.
00:26:11.416 - 00:26:24.898, Speaker B: Okay, great. Okay. And for the deposits, we have a deposit contract on two. And you said you also have the contracts, but you call them staking contracts.
00:26:24.914 - 00:26:51.050, Speaker A: I guess. So that could have been a contract, but instead it's just on the protocol level. There is a separate kind of transaction, which is a staking transaction where if you execute a staking transaction, it locks the money. And in the next epoch, if you do pass the threshold, you become a block producer. If you don't, you can at any point withdraw the stake, but for as long as you have it, you can validate.
00:26:51.130 - 00:26:57.774, Speaker B: So does the staking transaction, if you're delegating, does it point towards a delegation contract?
00:26:57.902 - 00:27:02.834, Speaker A: If you delegate? That's not a staking transaction, that's just a regular contract code. Yeah.
00:27:03.032 - 00:27:11.954, Speaker B: Oh, I see. So basically you have a delegation contract and then the delegation contract makes the staking transaction.
00:27:12.002 - 00:27:12.262, Speaker A: Yeah.
00:27:12.316 - 00:27:13.560, Speaker B: Okay, cool.
00:27:14.890 - 00:27:28.860, Speaker A: From delegation contract. Staking transaction is just one thing. It can execute delegation contract. It's not like us. Every particular entity that wants to be delegate has their own contract, and so they're responsible to audit it.
00:27:29.710 - 00:27:42.638, Speaker B: Okay, great. Cool. So I guess one of the things that I've been trying to do in the space is have the various blockchain projects agree on basic primitives. So can we talk about those?
00:27:42.724 - 00:27:43.360, Speaker A: Yeah.
00:27:45.010 - 00:27:49.794, Speaker B: One, which is probably the least controversial is the hash function. Do you use shatter 56?
00:27:49.832 - 00:27:51.490, Speaker A: So we do use shutter 56 today?
00:27:51.560 - 00:27:51.842, Speaker B: Yeah.
00:27:51.896 - 00:27:54.420, Speaker A: There are internal discussions to use, like Blake three.
00:27:54.970 - 00:27:57.000, Speaker B: Oh, the non secure one.
00:28:00.250 - 00:28:28.554, Speaker A: If it is not secure, that will be brought up, I guess, during the conversation. That conversation is not very active. So one of the biggest consideration for us when we choose the primitives is that we need to have interrupt with Ethereum. So if ethereum one cannot run it, we cannot use it. Right. Because we need, like, in any foreseeable future, most of the assets will be on Ethereum. If we cannot freely speak to Ethereum one, we cannot take advantage of those assets.
00:28:28.554 - 00:28:41.438, Speaker A: Right. And so the hash function we use must be verifiable in Ethereum. Signatures we use must be verifiable in Ethereum. That's one of the big considerations. I actually don't know which BLS curves you can validate today on Ethereum.
00:28:41.614 - 00:29:09.130, Speaker B: So right now, no BLS curves, only the bn two, five, four. But there is a proposal, there's two proposals. I guess one is to just implement the most important curve for us, probably, which is BLS twelve, 381. But there's another proposal which is to have an opcode, which is, well, actually a family of opcodes which are much more general and support a very wide range of curves. So for example, all the BlS twelve curves.
00:29:11.390 - 00:29:29.522, Speaker A: But it's one of the reasons why we don't use BLS today is that when you only have 200 validators, block producers, it is actually feasible to send that many signatures. And, but also because of that, we can send our blocks to Ethereum and validate them on Ethereum site because it's Ed 2519, which can be validated on ethereum site.
00:29:29.656 - 00:29:43.080, Speaker B: Okay, so you're using ed two five one. Okay, and I forget, what is the opcode support for this on Ethereum one?
00:29:43.850 - 00:29:44.742, Speaker A: Well, I don't know.
00:29:44.796 - 00:29:45.800, Speaker B: I don't know either.
00:29:47.450 - 00:30:01.734, Speaker A: Is it supported on Ethereum? Well, I hope it is. So the beauty of this particular curve is that, and that's pretty hacky, but this curve can be converted to another curve called, I think it's called Gistreto.
00:30:01.862 - 00:30:02.346, Speaker B: Right.
00:30:02.448 - 00:30:08.270, Speaker A: Which is the same as it did 2551 line. But the group size is actually a prime, not prime, multiplied by eight. Right.
00:30:08.340 - 00:30:09.530, Speaker B: You remove the cofactor.
00:30:09.610 - 00:30:20.660, Speaker A: Yeah. Okay. So we don't do that under normal operation. In normal operation, you only use it as Ed 2519. But the randomness beacon that we abandoned uses restretto because it does need.
00:30:21.750 - 00:30:23.746, Speaker B: So you've abandoned it or you've postponed it?
00:30:23.768 - 00:30:35.894, Speaker A: Postponed it. Well, abandoned for the initial launch. Right. Okay, so in the initial launch, we don't use restretto. Actually, we probably use it for vdfs, sorry. Vrfs, the same way. But the thing is that the private key and the public key from Ed to five 5.9
00:30:35.894 - 00:30:40.620, Speaker A: can be converted to restretto by just removing the cofactor. The cofactor, yeah.
00:30:42.190 - 00:30:54.030, Speaker B: Okay, great. And then I guess another primitive, which would be good if we could standardize on, would be the networking layer. What do you use there? We use lip PTP.
00:30:54.450 - 00:30:59.578, Speaker A: So networking, I'm not the best person to talk to. Right. For some reason, we stopped using lip PTP.
00:30:59.674 - 00:31:00.414, Speaker B: Okay.
00:31:00.612 - 00:31:02.206, Speaker A: The reasons I will not remember.
00:31:02.388 - 00:31:02.830, Speaker B: Okay.
00:31:02.900 - 00:31:04.378, Speaker A: But today we're not using lip PTP.
00:31:04.394 - 00:31:08.466, Speaker B: Is it some sort of language support? You guys are writing in rust, is that right?
00:31:08.488 - 00:31:22.722, Speaker A: Yeah, it is rust. Yeah. So there's parity lip PTP. Right. I think generally most of the parity code we eventually removed was because of parity uses very high abstraction layers, which are. We use very low abstraction layers generally.
00:31:22.786 - 00:31:23.110, Speaker B: Right.
00:31:23.180 - 00:31:28.146, Speaker A: And I think lip PTP we abandoned.
00:31:28.178 - 00:31:29.654, Speaker B: Because it didn't work for us.
00:31:29.772 - 00:31:49.046, Speaker A: We tried at the end of last year, and that time lip to p was in a state that I cannot figure out how to use your abstraction in our code. And also, I think some functionalities just didn't work as well. Like the Cassandra table didn't work very well. That was purity, right? Yeah.
00:31:49.168 - 00:31:51.454, Speaker B: So are you using like a custom solution right now?
00:31:51.492 - 00:31:53.150, Speaker A: Yeah, we build our own network.
00:31:54.210 - 00:31:57.540, Speaker B: Okay. From scratch? Yeah. Okay, cool.
00:31:59.190 - 00:32:10.920, Speaker A: But it's not like we would be against to use leap p to P. Right. It's just that at that point, it was cheaper for us to build a custom than to understand the.
00:32:11.930 - 00:32:12.680, Speaker B: Right.
00:32:13.130 - 00:32:18.454, Speaker A: I think it was like both pretty complex to understand, but also at that point the stability was right.
00:32:18.492 - 00:32:46.142, Speaker B: I mean, I think Lib PGP has advanced leaps and bounds in terms of production readiness with e two pushing it forward and all the other blockchain projects using it. One of the things that was mentioned is that maybe the abstractions of Lib, PTP and Rust didn't fit well with the way your project was organized. Are you thinking of having a single client or do you see a vision where there'll be multiple near clients, maybe some outside of the internal team.
00:32:46.196 - 00:33:06.418, Speaker A: So we absolutely need multiple clients. We only have one right now, naturally, because spec isn't finalized. So for someone else trying to build it would be very painful process. But abstraction layer of lip PTP in parity is not to support multiple different clients. Right. Parity has very different goal. Their goal is to create infrastructure in which people can build very different custom blockchains.
00:33:06.418 - 00:33:34.678, Speaker A: Right. So they need to have higher abstraction, while near says there's one blockchain protocol which is near with homogeneous shorts. But we do want to support multiple different clients. Luckily those clients will be also written in different languages. So we don't need the abstraction of lip to p, we need something very specific. And so therefore, code base of near and parity are very different in terms of, for example, traits. You will see very few traits in near, while parity is almost every class is generic.
00:33:34.794 - 00:33:42.050, Speaker B: Okay, so you mentioned that you absolutely need multiple clients. What is the thinking there?
00:33:42.120 - 00:34:26.740, Speaker A: So the thinking is the same thing. Why ethereum wants multiple clients is that if there is an implementation bug, I don't think you can defend against spec bugs except by verifying spec very thoroughly. But implementation bugs you can avoid. If you have sufficient number of implementations, each of them sufficiently popular, so that no implementation has like more than one third, then if one implementation goes down, the network remains life. Right, right. So that's the argument. But also you don't want like the second concern is that imagine near like five years from now decides to completely pivot to marketing automation and not work on blockchains anymore and abandons the client, right.
00:34:26.740 - 00:35:01.840, Speaker A: Well, it's an extreme example, but in this case it's very good if there's another client where the team people can pick up and continue maintaining our client, but there is no team that is up to speed to continue doing that. Every other client will continue. There's an easier example. Imagine there's some company called parity, which says from now on, parity is maintaining the community. There's going to be some delay until community is ready to continue maintaining it. Guess there is a team that continues building. The innovation doesn't stop.
00:35:02.690 - 00:35:32.294, Speaker B: I mean, I remember maybe a year and a half or a year ago, the NIO team coming to us potentially saying maybe we could build an ethereum client, but we'd need incentivization. So I think the proposal was that part of the inflation would go to the team developing the clients. Do you think you would do that in there for another team to.
00:35:32.412 - 00:36:03.066, Speaker A: So it's hard to say with the client. So one thing we do today, which is, I don't remember, it was you who was like a big critic of this idea, but the idea is that part of the inflation goes to the contracts which gets executed, which gets executed. So there's already that in place. Right. And part of the inflation already goes to the foundation to maintain the network. Right. It's not quite foundry word, because I think foundry word was, the definition of foundry word was paying for the prior work.
00:36:03.066 - 00:36:19.058, Speaker A: Well, in our case, we're saying this is finding of the future work. The implementation is the same, the semantic is different. So it would be feasible to have also, for example, part of that could be payment for the implementers.
00:36:19.154 - 00:36:33.942, Speaker B: So you're saying that on day one you will have this feature where if a contract is being used, as in transactions trigger it, then part of the transaction fees, or even the inflation will go to the contract creator.
00:36:34.006 - 00:37:23.990, Speaker A: Yeah, that's exactly how it works today. So today every contract which gets executed during the transaction gets a little like a small fee from the transaction fee, right? And so motivation behind it is that if you envision the future where there is a lot of, actually, that's not even future, it's present, right? Consider some defi primitive that exists today, right. They need to come up with some very complex ways to monetize their projects, right? Because they, like, if they're just a primitive, if they're not user facing, then users don't pay for using them. So they need to figure out how to monetize. If it's a very popular primitive, like everybody builds on top of this building block, then that little fee could actually be meaningful monetization for them, especially if it's not like a Silicon Valley company, but just a project made by people somewhere else. That could be very meaningful.
00:37:24.070 - 00:37:34.494, Speaker B: So how does it work concretely? You mentioned it's a cut of the transaction fee, not the inflation. And is it a fixed percentage, like 5%?
00:37:34.692 - 00:37:36.458, Speaker A: Yeah, I think it is fixed and constant.
00:37:36.554 - 00:37:43.466, Speaker B: Okay. Fixed and constant. And does that money go to an address or can it also go to a contract?
00:37:43.658 - 00:37:50.338, Speaker A: I don't know how it is implemented right now, but how it is supposed to be implemented is that the contract governs how exactly that money is used.
00:37:50.424 - 00:37:58.370, Speaker B: Okay. So there is a possibility that whatever it is, the 10% cut is actually redistributed, given as a refund.
00:37:58.710 - 00:38:09.222, Speaker A: So there are a couple of problems there. So that's one of them. Another one is that, and also technically you can implement it today on Ethereum. You can make the call to actually be payable and require some of the.
00:38:09.276 - 00:38:11.226, Speaker B: But the power of the default is very important.
00:38:11.328 - 00:38:23.262, Speaker A: Yes. Right. So from this perspective. So making it constant, part of the reason was so that people don't fork it out and make it cheaper. So people still can fork it out and make it cheaper by reimbursing you back.
00:38:23.316 - 00:38:23.678, Speaker B: Right.
00:38:23.764 - 00:38:30.638, Speaker A: But it's not like as easy if they can cherily just reduce the cost.
00:38:30.724 - 00:38:31.118, Speaker B: Right.
00:38:31.204 - 00:38:38.110, Speaker A: That would be all over the place. If it's an involved process, the hope is that it's going to be less widespread.
00:38:38.190 - 00:38:43.746, Speaker B: Right. Okay, understood. I mean, that's going to be a fascinating experiment to watch out. Yeah.
00:38:43.848 - 00:38:44.500, Speaker A: Cool.
00:38:44.970 - 00:38:51.190, Speaker B: Okay, how do you create the randomness in the current block, the block proposal?
00:38:51.770 - 00:39:06.806, Speaker A: So randomness of a particular block is a VRF of the block proposer of b seeded by the randomness of the previous block.
00:39:06.998 - 00:39:12.826, Speaker B: Oh, so basically you're using whether a block proposer shows up or doesn't show up.
00:39:12.928 - 00:39:16.522, Speaker A: Yeah. So that's the influence. So the block proposer can choose not to produce.
00:39:16.586 - 00:39:25.858, Speaker B: Okay, so let's assume that we have really good latency around the world and every block proposal shows up. Doesn't mean you can predict what will be the random number, but how do.
00:39:25.864 - 00:39:27.250, Speaker A: You execute their VRF?
00:39:28.630 - 00:39:31.874, Speaker B: Oh, because they can do that.
00:39:31.912 - 00:39:33.218, Speaker A: Yeah. Nobody else can.
00:39:33.304 - 00:39:34.434, Speaker B: I see. Okay.
00:39:34.552 - 00:39:38.822, Speaker A: And the VRF comes with the proof immediately. So you submit the output of the VRF and the proof right away.
00:39:38.876 - 00:39:41.174, Speaker B: Okay. And it's not a restretto based VRF. It's something else.
00:39:41.212 - 00:39:42.422, Speaker A: It is restretto based.
00:39:42.556 - 00:39:43.240, Speaker B: Okay.
00:39:44.810 - 00:39:46.278, Speaker A: We are using restretto today.
00:39:46.364 - 00:39:47.534, Speaker B: Okay, understood.
00:39:47.682 - 00:40:39.362, Speaker A: And the actual randomness beacon. We had some smart ideas, but we ended up just building what definity does. So, effectively, the way it works is in the epoch that precedes the epoch where you need to. Where you are a block producer, you run a DKG, right? Which we just make it synchronous. So what happens is, in the first, like, 10% of the epoch, roughly speaking, everybody commits to a polynomial of degree k minus one, where k minus k is 50%, not the thirst is infinity. Everybody commits to polynomial degree k minus one, and they reveal the generator to the power of every of some k points. And then they send encrypted private shares to every participant.
00:40:39.362 - 00:41:09.102, Speaker A: And then we spend 90% of the epoch where the participant can say, you know what? What you sent me does not correspond to the committed one. And so the revealed share. So the property is that if you have a polynomial of degree k minus one, then if you raise a generator to each element of the polynomial by knowing any k of them, you can also interpolate the remaining ones. Right. So that property remains.
00:41:09.246 - 00:41:13.220, Speaker B: So by generator, do you mean some sort of seed that will allow you to generate points?
00:41:13.910 - 00:41:18.230, Speaker A: Every participant I generates a polynomial p I of x, right?
00:41:18.300 - 00:41:18.822, Speaker B: Right.
00:41:18.956 - 00:41:23.400, Speaker A: And so what they publish is they publish g to the power p I of x for some k points.
00:41:25.050 - 00:41:28.550, Speaker B: And g is like some sort of point.
00:41:28.620 - 00:41:31.850, Speaker A: Or it could be a BLS point if we did use BlS curve.
00:41:32.910 - 00:41:36.038, Speaker B: Wait, so he commits to the coefficients of PI?
00:41:36.134 - 00:41:57.066, Speaker A: Yeah, effectively. But the beauty is that if this is a polynomial, right, then knowing any k minus one, sorry, any k, you can derive others. That property remains. So maybe for people who are into cryptography, that's obvious. For me, that was something new. Right. And so then you also publish encrypted versions.
00:41:57.066 - 00:42:27.866, Speaker A: So you encrypt p I of x with a public key of the participant. Sorry. Let's say this is j of the participant j. So this is also broadcasted, this is public, together with the commitment. And so every participant now can come and say, this is the proof that this is not the encryption. You can cryptographically prove that this does not correspond to the same pix that is used in there. Right.
00:42:27.866 - 00:42:39.086, Speaker A: And so we dedicate 90% of the epoch, but it is synchronous in a sense that if you do not show up and you do not provide the proof, then you cannot participate. Next tip. Or can the randomness beacon. You can still do everything else.
00:42:39.188 - 00:42:39.454, Speaker B: Okay.
00:42:39.492 - 00:43:18.742, Speaker A: Right. So you can choose if you messed up and you didn't show up and you didn't challenge it, and you don't have your private share, you can still do approvals, validate blocks, do all other duties. You just cannot participate in the beacon. And the assumption is that after the DKG, if there are committed polynomials which are not challenged, then at least k people, at least 50% of people actually have verified their shares and would have challenged during the epoch. And so in the next epoch, what happens is that if we do have committed non challenged polynomials, then we use this, and if we don't, then we resort back to the vDf. Sorry, vrf.
00:43:18.806 - 00:43:22.106, Speaker B: Okay, right, I see. Okay, yeah, so you have a fallback.
00:43:22.218 - 00:43:48.354, Speaker A: And also another thing, which is that in the next epoch we just use standard randomness because the definitive users, right, because you have this polynomial, the randomness output. When you have like a block h, what you do is. Yeah, you just interpolate, you just compute h to the power of. So everybody adds up their polynomials. Right. So that gives you p of x and you just compute h to the p of zero.
00:43:48.472 - 00:43:48.862, Speaker B: Okay.
00:43:48.936 - 00:44:29.202, Speaker A: Nobody knows p of zero. Right. Okay. But even more to that, instead of using h here, we use this thing, right, randomness of the previous block. So like VRF, that is published in the previous block. And so what it gives you is that even if someone did break, like if someone did manage to get access of 50% of the shares, and they can completely predict the output of this randomness, they still only have one bit of influence because they still can only produce a block or not produce. Right.
00:44:29.202 - 00:44:35.842, Speaker A: So it has all the properties of the underlying randomness of the seeds, right, yeah.
00:44:35.896 - 00:44:36.466, Speaker B: Okay, I see.
00:44:36.488 - 00:44:45.000, Speaker A: But in the good case, you get completely unbiased about unpredictable randomness unless someone has 50% of shares. And assuming that DKG didn't break.
00:44:45.930 - 00:45:04.670, Speaker B: Okay, that's very interesting, because I remember maybe roughly a year ago you were telling me that definity is all great and all, but the one problem is the DKG. It might be impossible or it might be too hard to deploy it in practice. So you've gone down the DKG route, but it sounds like you've made some changes.
00:45:04.820 - 00:45:42.986, Speaker A: Right? So effectively we just said, well, we're okay with sync, because if you're not okay with synchronous network assumption, that becomes way more complex. Right. I think you can pretty trivially create a DKG in which 30% of people can predict it, not 60%. So you can parameterize it in such a way that you need 30% to break loudness, 30% to break to make it predictable, while with a synchronous network assumption. If you make the threshold 66%, you need 30% to break liveness, 66% to break. Right. And then we can push it to 50% because we want it to work.
00:45:42.986 - 00:45:45.850, Speaker A: We want liveness to remain with 50%.
00:45:45.920 - 00:45:46.540, Speaker B: Right?
00:45:46.990 - 00:45:47.498, Speaker A: Yeah.
00:45:47.584 - 00:45:51.542, Speaker B: Okay, so basically you have stronger assumptions, which makes the construction simpler.
00:45:51.606 - 00:46:06.098, Speaker A: Yes. And so, like a year ago, if someone told me, like, let your synchronous network assumption, I would say, are you crazy? But then in practice, if you think about it, it's actually very meaningful to assume that during half a day, everybody will have at least one opportunity to show up and validate their share.
00:46:06.184 - 00:46:06.820, Speaker B: Right.
00:46:07.590 - 00:46:23.430, Speaker A: And the argument here is that if during the previous half a day, at no point you were able to show up and validate your share, then probably you're also not going to be very live in the next epoch. You sort of offline. Anyway, you can be considered a flying.
00:46:27.550 - 00:47:08.446, Speaker B: One thing I'm interested in is, let's see, gas schedule. So in e two, we're looking at something called EIP 1559. And as you described it once, is like this exponentially moving average. And we basically have this base fee that gets burnt. And then we also have these variable size blocks. So we're trying to fix some of the problems of gas. What is your thinking around gas?
00:47:08.558 - 00:47:22.458, Speaker A: I think we use something almost identical in the sense that I think if it's half. Okay, Bowen, correct me if I'm saying something wrong. If the block is more than half full, we increase the price. If it's less than half full, we decrease. Something like that, right? Yeah, very similar.
00:47:22.624 - 00:47:44.590, Speaker B: Okay, cool. Well, that's a nice kind of confirmation that we might be on the right path. Okay, one question I have is regarding the committee size. So you mentioned there's, let's say, 200 validators and eight shots, and each slot gets basically assigned to five.
00:47:44.740 - 00:47:55.454, Speaker A: So not quite. So what happens is, and I think this is where we're more like polka dot school than Ethereum school. Right? So in our case. So there's a total of 200 block producers.
00:47:55.502 - 00:47:55.810, Speaker B: Yes.
00:47:55.880 - 00:48:21.686, Speaker A: And let's say every five of them, they split into groups of five, and each five validate are assigned to some five charts. That's assuming, like, there's 100 charts. If there's eight charts, it's less interesting to analyze. But let's say there's 100 charts, there is like 100 block producers, and there is some bipartite matching. It's not quite bipartite matching, but let's say first five block producers are assigned to the first five shards and then block producers from ten to 15 are assigned, like two shards.
00:48:21.798 - 00:48:23.502, Speaker B: You're saying the committee size is five?
00:48:23.556 - 00:48:40.514, Speaker A: Yes. Committee size is very small. And so every person who is assigned to a shard, they download the state. Right. So everybody has state of five shards. Therefore they just take turns between five of them to produce chunks. Right.
00:48:40.514 - 00:49:02.922, Speaker A: And that committee, it's not even technically a committee because when you produce a chunk, the remaining four don't have to sign on it. Right. It's not really a committee. You alone are attesting to the validity of it. And what happens next is the person who produces blocks. They obviously have no insight into the validity of chunks. For all they know.
00:49:02.922 - 00:49:08.186, Speaker A: I have a header, and the header kind of looks legit, like hashes, checkout, signatures checkout. So they include it.
00:49:08.208 - 00:49:10.734, Speaker B: Okay, so they're really like proposal committees. More than. Okay.
00:49:10.772 - 00:49:49.642, Speaker A: Yeah. So what happens next is one thing which we use that's, again, polka dot thingy, is that when you produce a chunk, let's draw this like this. 200 people, right? And so these people are across all the shards. So when the particular person, like, say, this guy, when he proposes a chunk, what they do is they compute an erasure code of that chunk, which in our case, let's say. So for theoretical guarantees, it needs to be six x big. For something that is one meg, you will need to be six megs. But in practice, we use less than that.
00:49:49.642 - 00:49:54.810, Speaker A: Because in practice, you still cannot break it. But you cannot theoretically prove now that it's unbreakable.
00:49:56.110 - 00:50:03.562, Speaker B: So what is your block size or your chunk size? As you say, your ratio coding is at the chunk level, right?
00:50:03.616 - 00:50:23.460, Speaker A: It is on the chunk level, yes. So it's based on the gas. And I actually have no idea what the size is. I think it's 1000 maximum. At most, 1000 transactions plus receipts. But there's also some gas limits, right? Yeah. So the gas limit is pretty much 1 second.
00:50:23.460 - 00:50:24.594, Speaker A: Yeah.
00:50:24.632 - 00:50:30.370, Speaker B: Okay, so let's see, 1000 transactions. Let's say that's about 200 kb.
00:50:30.530 - 00:50:31.190, Speaker A: Let's say.
00:50:31.260 - 00:50:34.150, Speaker B: Okay, and then you have. Did you say six x?
00:50:34.220 - 00:50:34.838, Speaker A: Yeah.
00:50:35.004 - 00:50:37.670, Speaker B: Okay, 1.
00:50:37.820 - 00:50:39.734, Speaker A: So what you do then is you.
00:50:39.772 - 00:50:46.890, Speaker B: Send those 1 mb every second we're talking about here. That's your goal, right? That's very ambitious.
00:50:47.310 - 00:51:03.006, Speaker A: Well, all of that can be fine tuned, right? Yeah. That can be decreased. Right. If we can produce smaller blocks. But still, every second we will go that route than larger blocks less frequently. Because for as long as nitrogen finality gadget finalizes them. Right.
00:51:03.006 - 00:51:24.546, Speaker A: The biggest concern of short block times disappears. The biggest concern usually is that it affects, like in proof of work, for example, if you make it too short, then that versatry, who does not have forkfulness, they have advantage. But if you have a BFT finality on the blocks, that's sort of not as big of a concern.
00:51:24.658 - 00:51:27.190, Speaker B: I mean, you can have centralization on the proposing.
00:51:29.370 - 00:51:37.078, Speaker A: Centralization on the proposing. Okay, so let's finish that. Then we can think about it. But what you do is, well, let's ambitiously say it is 1 mb.
00:51:37.094 - 00:51:37.514, Speaker B: Right?
00:51:37.632 - 00:51:58.574, Speaker A: So it is 1 mb after you erasure coded it. So it is split into small parts. Exactly. So let's say for now, for simplicity, exactly 200 of them. Even with this committee size, and definitely with biggers, it will be a sample of block producers, not all of them, but for simplicity, let's say it's all of them. And so you send one part to every block proposer.
00:51:58.622 - 00:51:59.220, Speaker B: Yeah.
00:52:00.150 - 00:52:32.400, Speaker A: And they don't need to confirm it in any way. Besides that, if they attest to the block, that means that they have one little part for every chunk that that block has. Right. And so that means that if the block has 50% attestations, that means that 50% of people attest to the fact that they have their little parts of the blocks. Right. And so then why it is six x is that if you assume that there's less than 30% of people who for some reason lie to you, then you have that one six to recover. Right.
00:52:34.210 - 00:52:39.920, Speaker B: And how do you prove that every.
00:52:40.370 - 00:52:47.846, Speaker A: That they don't optimistically say this thing is merklized. Right. So there's a Merkel root of these little parts.
00:52:47.898 - 00:52:48.500, Speaker B: Right.
00:52:49.830 - 00:52:53.806, Speaker A: So this Merkel hash is in the chunk header.
00:52:53.998 - 00:52:54.402, Speaker B: Yes.
00:52:54.456 - 00:53:25.562, Speaker A: And so chunk hash naturally depends on it. Now. So the block hash depends on it. And so if someone then lodged the whole chunk and they re encoded and arrived to a different oracle route, that's a challenge. That's a special behavior. Effectively, what happens is that what can go wrong here? So one thing is that you can send something which is not. So another thing you can do is you can compute an incorrect erasure coding and compute the merkel.
00:53:25.562 - 00:53:46.226, Speaker A: Oh yeah. So if it's incorrect erasure coding, then the Merkel root will not match when someone codes it. If it's completely irrecoverable, then it's also easy to show. I will show sufficient number of parts with Merkel route and everybody will see it's irrecoverable. And I cannot send something that does not correspond to the Merkel route at all. Okay.
00:53:46.248 - 00:54:20.458, Speaker B: So here's one thing I'm worried about. Basically you have the Chunk proposes, let's say he creates garbage in razor code, he sends them all off, and this specific chunk goes in the block. And then you get the financing gadget, which happens in 2 seconds, because each block is 1 second long. And that's not enough time for someone to both kind of reconstruct everything, detect that it's wrong, and submit something on chain. So does it mean that you might have to revert?
00:54:20.634 - 00:54:58.138, Speaker A: Yes, finality is a little tricky in this case, and that's something that we're very upfront with people. If we talk to someone who potentially might integrate with near, we're very clear that you either have to run all shorts locally, not necessarily in the same machine, it could be on multiple machines. But if you locally run all the shorts, then finality is final for you, because you know that challenge is not coming. Or alternatively. Alternatively, the concept of finality for you is. Yes, it is finalized by NFG, but also sufficient time has passed that you're certain enough that the challenge, if it was existent, would have come through. Right.
00:54:58.138 - 00:55:03.402, Speaker A: So like for example, if you exchange, you actually have infrastructure to run all the shards for you. Finality is actually.
00:55:03.536 - 00:55:24.260, Speaker B: But how does it work? Okay, so I understand. Finally, from the point of view of the user, you can have these extra checks either by waiting more or by downloading the chain yourself. But what about from the point of view of the chain and the proposers? Because presumably they would suddenly have to move to a different chain and do like, right?
00:55:25.750 - 00:55:43.814, Speaker A: Especially with a single chain. It's actually pretty simple. Right? So imagine like you're building a chain and then suddenly sometime later it was proven that this block has an invalid chunk, right? Well, it's very simple, local. You just say these blocks are invalid. This is my tip. And you continue operating.
00:55:43.942 - 00:55:47.830, Speaker B: And will you just continue working here? Just ignoring no existed.
00:55:47.910 - 00:56:16.050, Speaker A: So that was initial plan, but that's actually very hard to do. Okay, well this is way harder to on implementation level. So on implementation level, it's way easier to continue like this. So the height will continue from here, it's going to be the next height. But this is the parent. It has some complications because now the finality gadget and doomslag need to be aware of the. Because if the finality gadget and doomslag have no idea that blocks can be challenged, then this is indistinguishable from actually someone forking out.
00:56:16.050 - 00:56:53.498, Speaker A: So that should cause flashable behavior. So the way it is solved is, well, without details of finality gadget and don'ts like, it's not that easy to say, but effectively what it's like. Finality gadget, for example, has a concept of a score which needs to be strictly, like, increasing in certain cases. And we're just saying that if there is a challenged block, right, then the score, you can effectively say, you can increase the score of the block by presenting a challenged block which has higher score, which will install the finality gadget. Okay, so finality gadget will be dysfunctional here, but we will be able to restart it here by proving that the score has to be higher because there's a challenge block with a higher score.
00:56:53.594 - 00:57:17.240, Speaker B: Okay. I mean, it will be interesting to see how this kind of finality gadget will get integrated in a system like cosmos, right? In know you have a weak verifier that can't do some of the things that a user can do, and also kind of cosmos tries to rely on kind of really strong finality. But you have kind of.
00:57:19.530 - 00:57:46.014, Speaker A: We already have an Ethereum breach which has exactly the same problem. Right. Ethereum breach needs to know the latest block. So the argument here is the following, that first of all, the challenges presumably should propagate relatively fast in the sense that because of the data availability, you should be able to download the chunk no slower than any valid chunk and valid chunks. On the normal circumstances. On the normal conditions, you don't load chunk between every two blocks because that's how you operate. Right.
00:57:46.014 - 00:58:10.358, Speaker A: And so the downloading should not take more than one block time. Preparing the challenge and distributing it could take some time because it's pretty large today. We don't use small challenges. We use the size of the challenge is proportional to the size of the chunk, but it should not take more than, let's say, 20 blocks or something like that. Right. In practice. And so if it was challenged after 20 blocks, then this chain will stop.
00:58:10.358 - 00:58:13.418, Speaker A: It will stop growing. It cannot grow anymore because all the.
00:58:13.424 - 00:58:15.162, Speaker B: Other people can take that.
00:58:15.296 - 00:58:29.194, Speaker A: And so what happens is that, effectively, if you're saying my finality is I see a final block and I see another block which has it in the ancestry, which is like 100 heights beyond. Right, then this is final because that block would not have been created if this block was challenged.
00:58:29.242 - 00:58:31.582, Speaker B: I see. So cosmos can do that, for example.
00:58:31.636 - 00:58:31.854, Speaker A: Yeah.
00:58:31.892 - 00:58:34.340, Speaker B: Right. Okay.
00:58:34.950 - 00:58:39.186, Speaker A: That's one option on Ethereum bridge, we just ignore challenges for now.
00:58:39.368 - 00:58:59.654, Speaker B: So one thing I'm very interested in is state. So in if two, we kind of have this stateless client model. And so my question is, do you have statelessness, and how large do you imagine the state will become per. How do you call it so per sub?
00:58:59.772 - 00:59:01.686, Speaker A: Let's call it chart. It's still short per shot. Okay.
00:59:01.708 - 00:59:02.318, Speaker B: It's still a shot.
00:59:02.354 - 00:59:08.938, Speaker A: Yeah. So it's hard to estimate how big the state will be, but state rent is built in into near.
00:59:09.024 - 00:59:10.006, Speaker B: You have state rent.
00:59:10.118 - 00:59:43.142, Speaker A: We do have state rent. So state rent was built. Not by me. So I don't know all the answers, but we have some solutions for all the well known problems. Right. So, for example, the account can be deleted, but you want to chip in. So with state rent, can they restore the account if it got nuked? Not yet, but we probably will implement some sort of hibernation in the future.
00:59:43.142 - 00:59:54.300, Speaker A: But then you need some archival node that will actually have the data once you have the money to recover. But that is not built today. But today. Account just dies. Okay. Account just dies if you don't pay.
00:59:54.670 - 00:59:59.174, Speaker B: Okay. Account just dies if you don't pay. And that will be at launch, you'll have stake.
00:59:59.302 - 01:00:00.154, Speaker A: It is there today.
01:00:00.192 - 01:00:00.394, Speaker B: Yeah.
01:00:00.432 - 01:00:05.150, Speaker A: Like today, if you create an account on near and then don't pay for a while, it dies.
01:00:06.050 - 01:00:19.620, Speaker B: Okay. So you're trying to bound the states. Because what I'm worried about is the proposers, they're going to be shuffled from one shot to another, and they might need some time to sync, right?
01:00:20.150 - 01:00:48.780, Speaker A: Yeah, but they have half a day for that. Because the shuffling happens to one epoch in advance, you know, the shards, and so you're downloading the state. So the way it works is, let's say this is the previous epoch, right? And this is the epoch in which you're supposed to validate. So the shuffling happens at this point. So at this point, you know everybody who will be validating in this epoch. And so immediately, you know the short assignments. So you have half a day to then load the state.
01:00:48.780 - 01:01:14.850, Speaker A: And then there are some implementation details here, which is once you downloaded the state, you need to start applying blocks because state at this point is different from state at this point. So what happens is you don't load the state once you got here, there's this process called catching up, where you apply all these blocks for these shards, and then for every block after that, you just apply current shards and the next shards. So what you validate now? What you validate next time.
01:01:14.920 - 01:01:38.140, Speaker B: Okay. So if I understand correctly, like, half a day in advance, you will know these five shards that you need to sync up. And the state could be. Let's say 10gb per shot, that's 50gb download in half a day. Yeah, maybe possibly doable. Okay, cool.
01:01:39.230 - 01:01:47.310, Speaker A: But other than that, the biggest problem in state, which I would love to solve, but we have no solution today, is that updating Merkel trees is very expensive.
01:01:48.050 - 01:01:48.558, Speaker B: Right.
01:01:48.644 - 01:01:58.100, Speaker A: Like if we can get rid of Merkel trees, we will easily like five x the number of transactions we can process, but today we cannot get rid of them. We don't have a good solution for that.
01:01:58.950 - 01:02:03.790, Speaker B: I mean, one kind of brutal solution is like Merkel tree, Asic.
01:02:03.950 - 01:02:18.300, Speaker A: Yeah, sure. Or even like running them properly on multiple cores. It's not something that is commonly done today. There's something else interesting about state. Yeah, don't remember.
01:02:20.350 - 01:02:32.198, Speaker B: Okay, so one thing that you guys innovated on is like guaranteed execution. Can you talk a little bit more about that?
01:02:32.304 - 01:03:18.250, Speaker A: So the way it works is, so when you have, let me erase something, guaranteed execution is a little bit strong of a word. It's sort of guaranteed receipt, delivery. So receipt will be delivered, but then later it can get, for various reasons, the most obvious, you might not have enough gas to execute it, right. It will get nuked, but it will be delivered, it will not get lost on the way, and you don't have to sort of monitor it. So the way it works is when you create a chunk. So first of all, I think what is important to notice is that the chunk contains the state route. As of before, transactions in the chunk are applied.
01:03:19.550 - 01:03:19.962, Speaker B: Okay.
01:03:20.016 - 01:03:20.858, Speaker A: Not as of after.
01:03:20.944 - 01:03:21.386, Speaker B: Right.
01:03:21.488 - 01:03:53.154, Speaker A: I don't remember how it is done in ethereum, but after. Yeah. So what it allows you to do is that if you do after, then you have transaction execution serialized twice. Because for you to create a block, you need to, let's say there's only Alice and Bob, there's only two block producers, and then they take turns creating blocks. Right? So Alice just created a block. And to create a block, she executed all the transactions in the block because she needed the post state route before she even sent the block to Bob. Bob received the block.
01:03:53.202 - 01:03:58.918, Speaker B: I mean, at the very least, Alice wants to know if she's going to get paid a decent amount of fees, for example.
01:03:59.004 - 01:04:03.098, Speaker A: But fees, it should be the fact that when you include the transaction, you.
01:04:03.104 - 01:04:06.922, Speaker B: Should be able to estimate the fee heuristically, maybe.
01:04:06.976 - 01:04:18.014, Speaker A: Heuristically, yeah. But also because fees are paid at the end, split equally, split equally between the block. Like it doesn't matter whether you included the transaction or someone else, it gets.
01:04:18.132 - 01:04:19.774, Speaker B: Oh, so you mean this committee of.
01:04:19.812 - 01:04:25.026, Speaker A: Five value, even of 100 at the end of the day, all the hundred gets paid more or less equally at the end of the day.
01:04:25.048 - 01:04:28.062, Speaker B: So what's the advantage for me to show up even as a proposer?
01:04:28.126 - 01:04:31.730, Speaker A: Well, proportional to your participation, you still need to participate.
01:04:32.870 - 01:04:33.778, Speaker B: Oh, very interesting.
01:04:33.864 - 01:04:34.450, Speaker A: Yeah.
01:04:34.600 - 01:04:35.058, Speaker B: Okay.
01:04:35.144 - 01:04:55.350, Speaker A: And so then, Bob, they received the block. And the first thing they need to do is to apply these transactions because they need to validate. Right, right. And so after that, they produce their block. Now they need to run their transaction. Right. And so you can see that the transactions, they get serially executed twice from every block.
01:04:55.430 - 01:04:55.914, Speaker B: Right.
01:04:56.032 - 01:05:03.186, Speaker A: So that's unfortunate. Instead, I think it's pretty common now to include prestate route in the chunk. Right. So, you know, prestate route.
01:05:03.238 - 01:05:04.480, Speaker B: Who else is doing that?
01:05:05.090 - 01:05:15.970, Speaker A: I think many people do it. I actually don't want to say name and be wrong, but I think it's at least like if you read papers, flow for sure does that.
01:05:16.120 - 01:05:16.530, Speaker B: Okay.
01:05:16.600 - 01:05:38.754, Speaker A: That's like the big thing that they're saying. Okay, so instead we include the pre state route. And pre state route. Complicated a little bit with the post state route, it would have been easier, but the way it works now. So this is Alice and Bob in one shard, and there's Carol and Dave in another shard. So when Alice produces the block. Sorry, the chunk for height.
01:05:38.754 - 01:06:06.210, Speaker A: So let's say this is two consecutive heights, seven and eight. And for simplicity, let's say heights are not skipped and all the chunks are produced. When Alice produces the chunk for height, seven, remember, she creates those little parts like the erasure coding shares. We call them parts, for some reason, should call them shares. So she sends the part to everybody, including Carol and Dave. And as she does that, she knows which parts Carol and Dave validate. She also sends them the receipts.
01:06:06.210 - 01:06:09.074, Speaker A: But the receipts, she sends them.
01:06:09.192 - 01:06:10.990, Speaker B: Wait, but she didn't do execution.
01:06:11.070 - 01:06:24.134, Speaker A: Exactly. So the receipts she sends them are the receipts as of applying the previous chunk. Right. So there was a chunk before at height six. Right. And so, Ellis, before producing chunk seven, she executed chunk six. Right.
01:06:24.134 - 01:06:33.130, Speaker A: And so chunk seven. Now, chunk only contains two things in the body. It's the transactions that's included and the receipts. As of executing the previous chunk.
01:06:33.790 - 01:06:36.170, Speaker B: Why do you need to communicate receipts?
01:06:36.830 - 01:06:39.898, Speaker A: Why do we need. Well, you definitely need to.
01:06:40.064 - 01:06:42.630, Speaker B: That's your crushed out communication.
01:06:42.710 - 01:06:52.910, Speaker A: Yes, exactly. Right. And so the chunk contains transactions and receipts. Receipts have merkel proof. Right. Which again. And so the merkel proof of the receipts, it's done in an interesting way.
01:06:52.910 - 01:07:24.070, Speaker A: So this is all their outgoing receipts. They sorted by the shard id the destination. Shard id. Right. And so with the niche shard, they mortgalized and then democraized, combined. So when I send receipts to Dylan or whomever is Dave, I send him the entirety of his portion with the upper portion of the Morocco proof he doesn't need the lower. But in the future, you can prove inclusion of any receipt using the whole tree.
01:07:24.070 - 01:08:21.662, Speaker A: And so, at this point, by the time Dylan or Dave produces for height eight, they have the receipts as of six. So it might feel that there is a two blocks delay, but actually there is none. So they will know those receipts for six. Right? But the cool thing is that think about this. For Dylan to even create a chunk at height eight, to create a chunk at height eight, Dylan needs to have the block at height seven, right? When Dylan accepts the block at height seven, and then they produce the chunk at height eight. And the condition, if you remember the condition to receive the block is to say, I have my little part for every chunk included. Which includes the part for seven, right? So the moment Dylan accepts the block at height seven, they have their part at seven.
01:08:21.662 - 01:08:31.310, Speaker A: And so therefore, they have all the incoming receipts. And so when they execute their chunk at height seven, they have all the incoming receipts.
01:08:31.810 - 01:08:43.518, Speaker B: Okay, so you don't have guaranteed execution because you have this queuing. And then you might even just remove things from the queue if it becomes unmanageable.
01:08:43.614 - 01:08:52.322, Speaker A: So we won't remove them. We will still fail the transaction. It's just that failing. Failing the transaction costs very little. So the queue will start depleting way faster.
01:08:52.386 - 01:09:04.060, Speaker B: I see. Okay. But even for the guaranteed delivery, which is a very cool property, what if everyone sends receipts to one shot, then now this one know they need to download so much more.
01:09:06.030 - 01:09:32.222, Speaker A: So that's a problem. So what will happen eventually is that what will happen in practice is that Dylan, he's supposed to produce a chunk, and people send him the one part as of that block. And there's so much network that he doesn't even manage to download all of them before producing the next block. So he skips the bit. Same happens to Carol. Same happens to Dylan. Same happens to Carol.
01:09:32.222 - 01:09:59.770, Speaker A: Finally, Dylan unloaded them. So he produces the chunk, dumps all of them to the storage. And you do not really include the receipts into the parts. So whomever will validate, like Carol and other guys. But they're on the same schedule, right? So they will catch up. So that's sort of unfortunate. But it only happens if literally every shard is bombarding Dylan.
01:09:59.770 - 01:10:15.070, Speaker A: But also if you think about it, obviously, from the network perspective, the number of receipts we're sending, we're configuring it so that it's not a bottleneck. We don't want you to be practically at capacity on the network in terms of how much you receive.
01:10:16.050 - 01:10:19.866, Speaker B: Right. But this problem will just keep on getting bigger as you add more shards.
01:10:19.898 - 01:10:31.442, Speaker A: Right? With more shards, yes. And so once we try to scale way beyond. So with 100 charts, it's already quite a bit of a problem, but not as terrible because it doesn't mean it will take you 100 blocks to unload the receipts.
01:10:31.506 - 01:10:31.734, Speaker B: Right.
01:10:31.772 - 01:11:00.634, Speaker A: It will take less because it's not the bottleneck. But if we want to go to 1000 charts, that becomes invisible at that point. We need some other techniques where we're going to the most natural one. But it's a high level idea. Obviously it has many issues, is that there's a limit to how much a particular shard could send to a specific shard in one block time. So right. Now, effectively, analysis shard, every transaction can generate a receipt to Dylan.
01:11:00.682 - 01:11:00.942, Speaker B: Right?
01:11:00.996 - 01:11:07.826, Speaker A: And then we say, well, you can only include that many, at which point the rest will get recued, for example.
01:11:08.008 - 01:11:11.650, Speaker B: Okay, so you can mitigate the impact of having one shot. Yeah. Okay.
01:11:11.720 - 01:11:40.710, Speaker A: But that has many problems. For example, if you recoup, if you what? Let's say, because Alice, when she produces a block, she doesn't know which receipts will be created. So she cannot not include a transaction that generates a receipt. So when the block is executed, once you hit the capacity, you need to do something with the remaining transactions. So most likely you will just re queue them. Like put them into the queue the same way you do it today with receipts. But then the problem is that when those transactions come back to the next block, again, half large percentage of them will get to the queue.
01:11:40.710 - 01:11:54.160, Speaker A: So that's quadratic. That's not a viable solution. But it's just like a high level, one, high level idea how it could be done with the bigger number of shards. But that's an open problem, right. With hrs, it obviously works.
01:11:55.490 - 01:12:11.094, Speaker B: So one of the things that you guys have innovated on and you kind of drew a diagram at one point is like you have the state, and then instead of being kind of nicely partitioned regularly, it's more dynamic. Can you talk about this a bit more?
01:12:11.132 - 01:12:12.358, Speaker A: So, first of all, this is not built.
01:12:12.444 - 01:12:13.014, Speaker B: This is not built.
01:12:13.052 - 01:12:40.640, Speaker A: So today it's static. But the idea would be that as the shards execute transactions, you can monitor which shard is more busy than others. And then at that point you can start shifting the boundaries. They're still going to be contiguous chunks. Right. So if there's a particular contract which is disproportionately large, then at the very best case, right? Yeah, it will be in the same shard. Right? In the shard on its own.
01:12:40.640 - 01:13:14.918, Speaker A: But the idea is that the way state sync works is that when you do state sync, you don't load contiguous parts of the state with the Merkel proof. And the Merkel root is global. You can easily compute global Merkel root just by merklizing the Merkel roots of the chunks. So the Merkel root is global. And so with this recharding, it will happen, let's say, on the epoch boundary. And so when you download the state for the next shard, you know, the new boundaries, it's a slight complication, because today you download from particular person the entire state. Now you just need to be smart.
01:13:14.918 - 01:13:47.380, Speaker A: You need to say, oh, in the previous epoch it was like this, right? So you will say, well, this part I will then load from someone who was following this chart, and this part I will download from someone who was following this chart. But the rest of the state sync infrastructure is already supporting sending any part of the global state with the Merkel proof. And so that doesn't need to be changed. And other than that, it's the same as gas fee. You look at how busy the shard is. If it's too busy, then you start, okay?
01:13:48.330 - 01:13:54.614, Speaker B: And presumably to keep the complexity reasonable, you'd only do the rebalancing, let's say once a week or once a day.
01:13:54.652 - 01:13:59.318, Speaker A: Or once per epic. Once per epic is actually doable because you need to read on load state anyway.
01:13:59.404 - 01:13:59.702, Speaker B: Right.
01:13:59.756 - 01:14:04.858, Speaker A: So it doesn't matter if it's going to be like at that point, actually having the same boundaries doesn't give you much.
01:14:04.944 - 01:14:14.058, Speaker B: Okay. And then prior to the rebalancing, you'd expect every shot to have its own gas market with some variations.
01:14:14.234 - 01:14:19.050, Speaker A: So that's an unsolved problem at this point. We're debating right now internally.
01:14:19.130 - 01:14:19.662, Speaker B: Okay.
01:14:19.796 - 01:14:21.310, Speaker A: How exactly it should be done.
01:14:21.460 - 01:14:23.282, Speaker B: So what are the options here?
01:14:23.416 - 01:14:29.602, Speaker A: Well, one option is to have gas market pro short, which is.
01:14:29.656 - 01:14:30.494, Speaker B: That's unavoidable.
01:14:30.542 - 01:15:00.010, Speaker A: No, it's an open problem. Right. But yeah. So gas market pro short has fewer problems, but it has a terrible ux from perspective of the user who submits a transaction. And if you have global gas price, then obviously there's many problems like congesting one shard will be increasing the price for everybody. So that is an active discussion, and that's something that can be finded very easily, even at the very late stage.
01:15:00.930 - 01:15:21.186, Speaker B: Okay, great. So one of the things that we're going with is Wasm. You guys are also doing wasm. Can you tell more about that, like compiled versus interpreted, or which engine specifically are you using? Will you have wasm from day one?
01:15:21.288 - 01:15:27.906, Speaker A: So, yeah, we do have wasm today. So the vm today is wasm. I think we use like single pass compiler.
01:15:28.018 - 01:15:29.126, Speaker B: Single pass compiler, yeah.
01:15:29.148 - 01:15:34.998, Speaker A: Is it the case, Max? Yeah, we're using single wasmar. Yeah, we use Wasmar today.
01:15:35.084 - 01:15:35.382, Speaker B: Right.
01:15:35.436 - 01:15:59.534, Speaker A: With a single pass, without optimizations. Even more crazily, at this particular point, we have floating point numbers enabled, which are nondeterministic. Maybe they have a particular source of nondeterminism, which is Nands, and we just plan to mitigate that particular nondeterminism, which is what nands. Nans, yeah. So the problem is that, what's an end nan? Not a number.
01:15:59.572 - 01:16:00.222, Speaker B: Oh, not a number.
01:16:00.276 - 01:16:32.154, Speaker A: So the particular problem with floats and the source of, like, according to WASM spec, the particular source of non determinism is that if you have an operation which has two nans, and those two nans have different representation, likely you add them up, then the output will be one of them. But which one depends, because a compiler can choose to optimize addition and swap the arguments because addition is commutative. But suddenly for Nans, addition is not commutative. And so a wrong nan can become the output. But then obviously in a smart contract, your network diverged, your state is one bit different.
01:16:32.192 - 01:16:33.530, Speaker B: Yeah, that's terrible, right?
01:16:33.680 - 01:16:45.130, Speaker A: But Nans can be, you can choose a canonical representation for Nan, and just after every floating point operation, you can say, now, if it's Nan, use a very particular canonical representation, it becomes slower.
01:16:45.890 - 01:16:48.942, Speaker B: So you have to do a check, is Nan every time?
01:16:49.076 - 01:16:57.634, Speaker A: Yes, every time you touch floating point numbers, right? If the output is floating point number, which is no worse, of course, than completely banning floating point numbers.
01:16:57.752 - 01:16:58.130, Speaker B: Okay.
01:16:58.200 - 01:17:49.742, Speaker A: And the reason why we enabled floating point numbers, we had them disabled for a while, is that the actual devex is terrible because you constantly accidentally use floating point numbers. Because at the end of the day, you use one of the languages which compiles to wasm, like assembly script or rust, and they have floating numbers all over the place, like hash tables in assembly script, used to be using floating point numbers. I, as a developer, didn't do anything wrong, but suddenly my contract doesn't compile. And so we're just taking like half a step further. Instead of just banning floating points completely, we specifically solve the exact problem that exists for Wasm smart contracts with our particular bindings. You can do any asynchronous calls to any contract in any shard. The way you do that is you just say this is the contract, the same way you do in ethereum, but it's just asynchronous.
01:17:49.886 - 01:17:54.450, Speaker B: So every contract is asynchronous, unless you allow this kind of stuff.
01:17:54.520 - 01:18:26.446, Speaker A: Yes, or like this kind of stuff. Right. So effectively what happens is in a smart contract, you can say, now I want to call another contract. And at least in all the languages we support today, there is a concept of a promise, right? So it gives you a promise. So in your code, your code is actually very readable. You're just saying like, call this contract then, and then you provide what needs to happen next. On our end, we will separate it into two different whatever was envelopes, whatever they are, we will call the first one, right, schedule the receipt, wait for the receipt back, we'll call the second part.
01:18:26.446 - 01:18:27.902, Speaker A: So that is abstracted out.
01:18:27.956 - 01:18:32.558, Speaker B: So doing everything asynchronously, that's what definitive is doing as well. Maybe we don't know.
01:18:32.644 - 01:19:10.720, Speaker A: Okay, definity only knows, right? But we also have this thing which James press, which built for us, which is we have a Ethereum virtual machine as a smart contract compiled to WaSM, deployed on one of the shards. And so within that virtual machine, you can run any VM contracts. But obviously they live in the isolated world of a single shard. They have no concept of cross shard communication, because synchronous calls cross shard kind of don't work. But within a particular shard, you can have EVM contracts running with synchronous calls between themselves.
01:19:11.330 - 01:19:13.290, Speaker B: An Ethereum Vm.
01:19:13.370 - 01:19:16.014, Speaker A: Yeah, EVM, okay, but as a specific.
01:19:16.132 - 01:19:21.070, Speaker B: Version, how do you governance on that? You'll just freeze specific.
01:19:21.220 - 01:19:32.210, Speaker A: It's a smart contract. I don't know what exact governance today for upgrading that contract, but like any smart contract on near, there's some rules for redeployment.
01:19:32.790 - 01:19:36.820, Speaker B: Actually that's a good question, like governance. What is your thinking here?
01:19:37.830 - 01:20:01.174, Speaker A: But you don't build any formal governance. Right. And the way initially it will work is that I think it will work the same way as with any other chain. We will ship a new binary which has a version, and on the protocol level, everybody can vote for the next version. Even that might not exist on the very first version. On the very first version, it could be like completely social consensus.
01:20:01.222 - 01:20:02.886, Speaker B: So the voting is just signaling?
01:20:02.998 - 01:20:26.790, Speaker A: Just signaling, yes. Well, to an extent. So the way I see it, and that might not exist in the first version, right. We're debating if we want to build it before or after mainnet. But the way I see it is that the approvals in the block, they include the version, the highest version you can speak, and on the epoch Boundary, the versions, which can automatically happen if sufficient percentage of the block producers do speak the new version.
01:20:27.610 - 01:20:28.118, Speaker B: Okay.
01:20:28.204 - 01:21:02.622, Speaker A: Yeah, so that is all like at the early stage of how it works, but there is no token vote or anything. So it is token vote to an extent, but it's token vote by block producers effectively saying we're ready to use the new one. But governance in terms of like, who creates a spec, who creates an implementation at the beginning is going to be us. We call it like the reference maintainer or whatnot. And if we go rogue, people can always say like, okay, let's not use theirs anymore. Let's hard fork the same governance that has been working for the last, how many now? Eleven years.
01:21:02.676 - 01:21:05.390, Speaker B: I mean, even bitcoin has been using this signaling mechanism, right?
01:21:05.460 - 01:21:10.100, Speaker A: Yeah. So signaling, the only question is like, do we want to build it in now or later?
01:21:11.270 - 01:21:20.774, Speaker B: Actually going back to the wasm stuff. So you said there was these promises. How fast did these promises return?
01:21:20.972 - 01:21:42.134, Speaker A: So effectively, let's say chunks are never skipped. So every block has all the chunks. So what will happen is on height seven, Ellis creates a block which includes the promise from six on height seven. When Dylan receives their part, they will already execute on the promise. Right? Effectively.
01:21:42.262 - 01:21:44.486, Speaker B: So it's like a one slot duration.
01:21:44.598 - 01:21:56.740, Speaker A: So one slot to get to seven and then one slot to get back to eight. Okay, so if everything goes very well, if there's no congestion and chunks are not skipped, then something that initiated in six will hear back in eight.
01:21:58.150 - 01:22:12.262, Speaker B: Okay, but then what if, you know, with reasonably high probability that the two contracts are going to be in the same chart, do you get faster than so today?
01:22:12.316 - 01:22:12.774, Speaker A: No.
01:22:12.892 - 01:22:14.742, Speaker B: Okay, so that's a huge trade off, right?
01:22:14.796 - 01:22:36.254, Speaker A: Yeah, so it's a trade off. I think the biggest reason why we did that is that we don't want people to grind, right. Because what you will end up having is you will have one smart contract, which everybody needs, and then they want to be close to it. Everybody will want to be in that chart. Right. And even with recharding, so without recharding, you're guaranteed to have everybody in that chart. Because, I mean, the way, it's proof of work.
01:22:36.292 - 01:22:37.754, Speaker B: It's like meritocracy.
01:22:37.882 - 01:22:46.170, Speaker A: It's not a lot of proof of work. There's 100 shards with the probability 1% every time you land in the shard, you want to. So it takes you 100 attempts to deploy.
01:22:46.250 - 01:22:53.058, Speaker B: No, but what I mean is, like, if you want to be extra close, so that the probability that you'll be separated is very, very low, that's with.
01:22:53.064 - 01:22:56.530, Speaker A: Dynamic resharding, without dynamic recharding.
01:22:57.350 - 01:22:58.802, Speaker B: I mean, with dynamic sharding. Yeah.
01:22:58.856 - 01:23:16.810, Speaker A: With dynamic recarding, you can get closer and closer, but it's very undesirable property. So instead, what happens is that it gives you a little bit of an advantage to be in the same shard because you're guaranteed to be in the very next chunk when that happens in the same shard, while between shards, like, if the chunk is skipped.
01:23:18.510 - 01:23:21.290, Speaker B: 1 second is much slower than instant.
01:23:21.630 - 01:23:24.682, Speaker A: Yes. So at least today it is built this way.
01:23:24.736 - 01:23:25.014, Speaker B: Okay.
01:23:25.072 - 01:23:30.010, Speaker A: The second reason for that is that it's easier to implement everything consistently than special case, the same shard.
01:23:30.090 - 01:23:38.366, Speaker B: So here's my prediction of how near will evolve that there will be this one mega contract where you can do internal calls synchronously.
01:23:38.398 - 01:23:39.810, Speaker A: Yeah. Like EVM contract.
01:23:40.470 - 01:23:49.234, Speaker B: And then that will be really big, and then that will even break the dynamic stuff. And so you'll have one shot with a very expensive.
01:23:49.362 - 01:23:53.666, Speaker A: But if we see that happening, we can react. Right? Like, probably it will not happen overnight.
01:23:53.778 - 01:23:55.190, Speaker B: So how would you react?
01:23:56.250 - 01:23:58.070, Speaker A: Well, at this point, I don't know.
01:23:58.220 - 01:23:59.734, Speaker B: Okay, open problem.
01:23:59.852 - 01:24:10.858, Speaker A: Right. But you see, there are so many things that can go wrong. We can spend time and address each of them, or we can launch and see what actually can go wrong and adjust as we go, and then we.
01:24:10.864 - 01:24:12.150, Speaker B: Can learn from your mistake.
01:24:12.310 - 01:24:15.534, Speaker A: Well, yeah, the same way we learn from mistakes of others. Right, right.
01:24:15.652 - 01:24:18.074, Speaker B: But you're one of the first movers. At least that's one of your goals.
01:24:18.122 - 01:24:26.850, Speaker A: Right. We want to be as early mover as possible. Like Cosmos is already your first mover from the series of blockchains that I follow closely.
01:24:27.830 - 01:24:35.720, Speaker B: We kind of want to be last mover in the sense that we want to be the ones that are still there in ten years.
01:24:36.650 - 01:24:38.680, Speaker A: Well, everybody wants it.
01:24:39.850 - 01:24:40.600, Speaker B: Right?
01:24:40.970 - 01:24:45.640, Speaker A: That's more of a philosophical question, whether you want to launch early or late, to be there in ten years.
01:24:47.930 - 01:24:56.054, Speaker B: So if I recall correctly, one of the things that you really care about is not only devex, which you mentioned in passing, but also ux.
01:24:56.102 - 01:24:57.260, Speaker A: Yeah. User experience.
01:24:57.710 - 01:25:00.860, Speaker B: So there's some innovations there can you talk about those.
01:25:01.310 - 01:25:21.140, Speaker A: Yeah. So I think innovation would be a strong word. Many things we do exist in some way or another in Ethereum ecosystem today. They just exist as independent projects which not always work very well together. But I think over time that will all happen naturally. So there are a few things. One thing is that we allow.
01:25:21.140 - 01:25:56.574, Speaker A: So one thing is completely agnostic to the protocol. It's just something we have out of the box built, which is we have so called hosted wallets. And so one of them we're hosting ourselves. And a hosted wallet is a way for you to have to start using near without having to do anything with the blockchain. So specifically the four things we try to avoid is, a, we don't want people to understand key pairs because it's not something that is easy to explain to people. Also, people lose private keys, b, we don't want people to install metamasks. Well, there's three things.
01:25:56.574 - 01:26:08.974, Speaker A: And c, we don't want people to pay. Like you don't have to buy near before you use something because buying crypto today is extremely complex. Right. I don't know how in the rest of the world, but here I have to send my passports to the exchange.
01:26:09.022 - 01:26:09.662, Speaker B: It's insane.
01:26:09.726 - 01:26:15.666, Speaker A: Yeah, right. And so if to buy a crypto kit, I need to send my passport to someone, like the drop off rate will be very high.
01:26:15.768 - 01:26:16.226, Speaker B: Okay.
01:26:16.328 - 01:26:28.966, Speaker A: The thing is that at least the first two things are necessary for you to get the security of the protocol. If you don't install metamask, if you just use a web page, the host of the web page can send you whatever code they want and steal your private key, even if it's in local storage.
01:26:29.078 - 01:26:31.660, Speaker B: Well, unless it's maybe an IPFS page or something.
01:26:33.070 - 01:26:36.570, Speaker A: Unless. Right, but someone is hosting that IPFS page.
01:26:36.720 - 01:26:49.374, Speaker B: No, because for example, the page could be hosted on an ENS domain, and then you trust that basically there's like a fixed link to.
01:26:49.492 - 01:26:50.606, Speaker A: But someone I do trust.
01:26:50.708 - 01:26:57.678, Speaker B: Right, well, but the thing is that it's like social trust at a very, very high level, in the same way that I trust the near blockchain.
01:26:57.774 - 01:27:30.540, Speaker A: Right. So the idea here is the following. So the hosted wallet is this idea where there is a completely centralized server. In this case we run it, which gives you gateway to all the applications running on nier. And so instead of installing metamask and coming up with the key pair, you will open this hosted wallet. This hosted wallet has a different way to authenticate you. So it will be like a login and password or something along the lines or like the way we do it today is you will create an account and we will store the key locally in the local storage, but we're also going to store the key on our end.
01:27:30.540 - 01:27:45.650, Speaker A: So one thing we need to cover is we have a concept of an access key. So the account is not defined by a single key, account is defined by name. The ENS is sort of embedded in the system, and the account can have arbitrary number of keys associated with it, and those keys can have different permissions.
01:27:46.070 - 01:27:46.434, Speaker B: Right.
01:27:46.472 - 01:28:02.246, Speaker A: And so near keeps a key on its side, which is sufficient to initiate the account recovery. And so today that key technically can recover account and use it the way it wants. But the way to improve it, for example, would be that that key can initiate account recovery, which will only happen seven days from that moment.
01:28:02.348 - 01:28:03.910, Speaker B: Right? Like argent or something.
01:28:03.980 - 01:28:22.582, Speaker A: Yes. So that's something that exists. Right. And so what happens now is that near has that key that allows to recover. And so when you use hosted wallet, you can provide your phone number or your email. And so you have recovery options. So if you do lose your key locally, you can recover it using the means you used to.
01:28:22.582 - 01:29:00.742, Speaker A: But obviously you completely trust near at this point, at least to a very large extent. Because even if that key has seven day delay, because you're using the near website, the next time you go to that website, it just sends you Javascript which extracts the key from the local storage, sends it to near. So there's a lot of trust in near, right? But if all you do is you buy a cryptokitty which is worth $0.10, that's perfectly fine. Like near will not go against you to steal a $0.10 cryptokitty. But because we have access keys and the account is not defined by the key at the moment when you actually have valuable assets, at that point you can create your own account.
01:29:00.742 - 01:29:40.866, Speaker A: Like you can install metamask or like whatever the plugin or the wallet you want to use, you install it, you create a key which is now local to you, nobody has access to it. And then the last transaction that you trust near to perform is to bring that key and remove near key, at which point you have full control over the account. Nier has no access to it anymore. And it's way easier in Ethereum, if you need to transfer access to the account from one key to another, the only way to do that is to create another account and transfer all the assets. If some of them are locked or not transferable, then you cannot do that at all. Right? If your key was compromised?
01:29:41.058 - 01:29:43.346, Speaker B: Well, in theory you could build a functionality table.
01:29:43.458 - 01:30:08.270, Speaker A: Yeah, but in this case, because every account has access keys, you maintain the same account, you just change the key so it simplifies. Like Argent has built Argent on Ethereum. So it is clearly possible. Right, but it's harder. While in near, it's very easy to build such a hosted wallet. So in expectation there's going to be near hosted wallet, but there are going to be others. So whichever one you trust, you use that to start.
01:30:08.270 - 01:30:15.966, Speaker A: And also the hosted wallet can choose to pay for your fees. We have strong incentive to pay for your fees because we want people to use near.
01:30:16.068 - 01:30:18.142, Speaker B: Right, and you have lots of tokens.
01:30:18.286 - 01:30:37.160, Speaker A: Yeah, and we have tokens. Right. So we have an incentive. But someone else, like for example, it could be an application specific gateway which pays for your fees because they have future value in you. Like hypothetical 50 kitties will build a hosted wallet. They will pay for your fees initially because like an expectation, you will buy a $10,000 crypto kitty covering fees for.
01:30:37.690 - 01:30:51.194, Speaker B: Okay, so let's talk about this $10,000 crypto kitty. You're saying that you can solve the passport problem. Does it mean that you're going to become like a broker where you're going to sell neo tokens and you're not going to ask for passports?
01:30:51.322 - 01:31:21.910, Speaker A: The expectation is that a, if people get sufficiently bought into some product, but also there's wire, there are others. Right. So the hope is to integrate with those people. We don't want to be broker ourselves. It's completely orthogonal to what we're building. But like someone who figured it out for Ethereum, they not attached to a particular blockchain, as long as near token is treated the same way as Ethereum token, from perspective of particular jurisdiction, their solution will work for any blockchain.
01:31:23.370 - 01:31:31.782, Speaker B: Okay, I see. So basically you're taking, as you said at the beginning, different solutions from Ethereum and then putting them all in a central solution.
01:31:31.926 - 01:32:01.738, Speaker A: Well yeah, some of them we will put into central solution and we will try to integrate with those who we cannot replace ourselves. But the idea is that on Ethereum that today there are steps towards very good ux, but they far from converging and they just joined. And so we're just saying, well, let's have one combined solution which works. Right? So I wouldn't say that this is like a huge innovation in Ux. It's not innovation, it's convenience that matters.
01:32:01.834 - 01:32:02.480, Speaker B: Right.
01:32:03.650 - 01:32:04.062, Speaker A: Okay.
01:32:04.116 - 01:32:13.046, Speaker B: I mean, a few things that we could talk about, but is there anything in particular that you'd like to highlight before we wrap up?
01:32:13.068 - 01:32:16.726, Speaker A: No, I think we covered so much more than I was expecting. Yeah.
01:32:16.828 - 01:32:18.662, Speaker B: Okay, excellent. Well, thank you so much.
01:32:18.716 - 01:32:21.922, Speaker A: Yeah, thank you. Thank you for participating.
01:32:22.066 - 01:32:22.980, Speaker B: Yeah, cool.

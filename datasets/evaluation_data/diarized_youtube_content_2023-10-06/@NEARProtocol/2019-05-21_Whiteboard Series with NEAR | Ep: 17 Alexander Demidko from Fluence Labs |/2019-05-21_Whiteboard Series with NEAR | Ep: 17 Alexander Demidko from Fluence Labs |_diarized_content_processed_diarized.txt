00:00:04.170 - 00:00:14.302, Speaker A: Hi everyone, this is Alex from near protocol. And with me today is Alex from Fluence Labs. We will talk today about decentralized databases. Alex, would you like to introduce yourself and.
00:00:14.356 - 00:00:24.734, Speaker B: Sure. Hi. Oh, I'm Alex, and I work at Fluence as a researcher. And today I guess I will talk about how to build structured data storages in a decentralized fashion. Cool.
00:00:24.772 - 00:00:26.098, Speaker A: Would you like to give an overview?
00:00:26.194 - 00:01:27.440, Speaker B: Yeah, sure. So what we looked about, we looked at, there are unstructured data storages in decentralized ecosystem, but there is no many structured data storages. And so we thought that probably we should build something that will allow people to make queries to the data and basically be sure that the results that are returned are correct. And to give you a very brief overview how fluency structured, we have few different, like I would say heterogeneous components here. So the first one is the thing that we call real time wear. And the real time wear consists of multiple small, let's put it this way, BFT clusters. I can make one bigger, I think that's a BFT.
00:01:27.440 - 00:02:07.680, Speaker B: Onenote is also a BFT. So really small ones, really small clusters, the BFT ones. And because they are really small, there is a chance that some of these machines can go wild. So in order to keep those guys in check, we use a shared validation layer. And the validation layer is shared. We usually use this symbol to depict a validator because it looks like v. And this is basically shared validators pool.
00:02:07.680 - 00:02:14.340, Speaker B: And we call this thing a security layer.
00:02:14.760 - 00:02:17.220, Speaker A: And is it the same participants in both layers?
00:02:17.640 - 00:03:31.912, Speaker B: Well, I mean they might be, this is different software in some kind of. But you can have this like one single hardware machine to run both a real time node and a validator. So the way it works, I mean, how do those guys keep each other in check is that real time layer basically uploads every time when there is also a client, and here is a client, and I will draw a mobile phone in the sense that we want those clients to be thin. I won't say light clients, but like at least thin clients. Well, the thin client interacts with the real time layer only. And every time the way how interaction goes, the client sends a request, which is like transaction essentially, and receives a response from the real time layer. And for the validators, for the security layer to verify the real time layer, the real time layer stores transactions into a decentralized storage.
00:03:31.912 - 00:04:23.096, Speaker B: And for this purpose we use like swarm. We could also use filecoin. I mean, honestly, right now we expect that in theory, those storages will support basically if, say, for example, if you take a look at this warm paper swarm, paper talks about how it can force nodes to return you the data you have put there. Basically it's how to guarantee that it will return the data there. And if it will not return you the data, then these nodes will lose their deposits. But if you look at what swarm does currently have in deployed, they do not have this incentivization layer. So we expect that eventually, once they have this feature, the data stored there will be secure.
00:04:23.096 - 00:05:01.190, Speaker B: But for now, we basically built on theoretical guarantees that it will be one day. And we call this in the data availability layer. Okay, so first of all, the transactions are stored here. And I would say like transactions here are stored in blocks. So the data availability layer has basically keeps these real time layer blockchains.
00:05:05.850 - 00:05:10.822, Speaker A: Also we store, in this case the block is just a set of transactions.
00:05:10.886 - 00:05:11.258, Speaker B: Right.
00:05:11.344 - 00:05:12.540, Speaker A: Or queries rather.
00:05:13.310 - 00:05:14.106, Speaker B: Same thing.
00:05:14.208 - 00:05:14.682, Speaker A: I see.
00:05:14.736 - 00:05:55.424, Speaker B: Yeah, I'll put transactions here, not sure if it's visible or not. So that's, I would say the transaction history. And is it going away? Okay, sure. Okay, so we'll call this transaction history, and also this data availability layer stores states. So basically state is a snapshot of the real time layer at some point. So the way how stuff works, how.
00:05:55.462 - 00:05:57.052, Speaker A: Frequently do you produce those snapshots?
00:05:57.116 - 00:06:02.470, Speaker B: Right, so I'll get to this. So the way how stuff works.
00:06:04.920 - 00:06:05.236, Speaker A: The.
00:06:05.258 - 00:06:28.770, Speaker B: Batch validator comes and it reads the previous state snapshot, like say snapshot, state n, and it reads a fragment of transaction history and then it produces the new snapshot. And this new snapshot goes here, like into the storage.
00:06:30.710 - 00:06:33.758, Speaker A: The BFT clusters never produce snapshots, it's only validators.
00:06:33.774 - 00:06:49.062, Speaker B: I see, right, yeah, because you don't want those guys to produce snapshots. I mean, even if you take security aspect away, producing a snapshot, uploading it here, it's a very different property from the real time.
00:06:49.116 - 00:06:50.210, Speaker A: So you're saying it's more expensive?
00:06:50.290 - 00:07:44.090, Speaker B: Yeah, well, it basically will make the load on those classes irregular. I would say those classes are used to, for example, a steady transactions like incoming rate. But once they have to upload the snapshot somewhere, that kind of might decrease the ability to process transactions. So no, those guys do not process snapshots. So only validators produce snapshots. So yeah, they basically read those transactions, takes history and snapshots, and produce the new snapshot. If during the block processing they do not agree with, basically with the results they get, they can file a dispute.
00:07:44.090 - 00:08:45.950, Speaker B: But first of all, let me get to, how do they not agree? So in the end of each block, currently here in the real time layer, we use tendermint as the BFT consensus agent, essentially. So in tendermint, after, in the end of each block, you not only put transactions there, you also put the hash of your state, and that also is stored here in swarm. So we have like for example, after each block, we have here hash virtual machines, n hash of virtual machines, sub n plus one, hvm sub n plus two, and so on. So validators go over those blocks. And if basically when they are trying to apply a new block to the current state, if they produce a different hash, then they're like, okay, I mean, it doesn't work out. So let's basically point the gun at those guys.
00:08:46.020 - 00:09:02.210, Speaker A: So when you're saying hash of virtual machine, so effectively the state is not any sort of an abstraction, you're literally snapshoting the state of the memory dump. No, I mean of the virtual machine that processes queries.
00:09:02.630 - 00:09:05.486, Speaker B: No, I mean when I'm saying hash, it means like the merkle.
00:09:05.518 - 00:09:09.234, Speaker A: Right, but what is virtual machine? Okay, good question.
00:09:09.272 - 00:09:29.476, Speaker B: I forgot about that. So we use webassembly, and yeah, every node has the same virtual machine instance. And basically it's the memory of the virtual machine. And yeah, we take the hash of this memory of the memory, and that.
00:09:29.498 - 00:09:30.916, Speaker A: Hash is not merkalized in any way.
00:09:30.938 - 00:09:31.076, Speaker B: Right?
00:09:31.098 - 00:09:32.704, Speaker A: It's just the hash. Merkel. It's Merkel.
00:09:32.752 - 00:10:37.140, Speaker B: Yeah, it's Merkel. It's Merkel hash. And anyways, so we've got those guys read transactions and those guys read snapshots. And if they like, for example, one of those validators got, instead of hash Suban, it got hash Suban prime, it clearly doesn't match. And they submit a dispute and they submit a dispute to Ethereum. Okay, so once the dispute is submitted to Ethereum, well, those guys have mean Ethereum is obviously not able to download the entire state and is not able to download even the block, I would say, of transactions to basically replay that. What those guys are doing, they are playing a concept called verification game.
00:10:37.140 - 00:11:26.382, Speaker B: And that was basically proposed by trubit. And the way it works, like you execute your program instruction by instruction. And if at some instruction you found that basically your states, you have achieved different state than your counterparty, then you say, well, this instruction is the bad one. And you don't have to do this in a linear fashion. You can do like a bisex search. So once those guys have found a bad instruction, they take the chunk of the state that was used by this instruction as an input, like say, for example, I mean, let me explain. For example, if you have instruction I 32 add, this instruction obviously uses the stack.
00:11:26.382 - 00:11:54.326, Speaker B: It basically takes two values from the top of the stack here, and it then pushes one value back to the top of the stack and it consumes those. So it's like pop two, and this is like push one. So in order for the virtual machine on Ethereum to operate, you have to give it like this chunk of memory, and you also have to give it the chunk of memory where this stuff will be written.
00:11:54.438 - 00:11:58.490, Speaker A: Do you effectively need to have the entire wasm virtual machine written in solidity?
00:11:59.230 - 00:12:04.926, Speaker B: Kind of like a very small implementation of that, actually. Truebit, guys, almost already.
00:12:05.028 - 00:12:13.250, Speaker A: Nice. But then you also need a hash function which will be capable of doing hashes where only part of the state changes, right.
00:12:13.400 - 00:12:34.298, Speaker B: Well, it's still, it's mercurialized. Yeah. So you compute only the hash of the chunk, and then you compute the entire hash. The problem with that, it still might be too much for ethereum. Smart contract. And so we are looking in how optimize that, because the chunk, it might be 4. Transferring 4.
00:12:34.298 - 00:13:07.858, Speaker B: Ethereum might not be also the brightest idea. Anyways. So once those guys have pushed the thing to the virtual machine, on Ethereum, it basically executes the instruction, produces a new hash, and basically the machine that has a different hash has produced a different hash. Well, it loses its stake, essentially. I probably should talk about a little bit about timeouts, because that might be, I would say, important for security. Or if you have, in terms of.
00:13:08.024 - 00:13:12.566, Speaker A: You're saying that. So snapshot is created once every few blocks, right?
00:13:12.668 - 00:13:14.422, Speaker B: Like 10,000 blocks maybe?
00:13:14.476 - 00:13:28.474, Speaker A: Yeah, let's say four for simplicity. Okay, so we have snapshot here, right? And then we have snapshot here. Sure. So in the model you described so far, there was a single validator who did it, right?
00:13:28.592 - 00:13:30.650, Speaker B: Yes, there are multiple of them.
00:13:30.800 - 00:13:41.418, Speaker A: But if there are multiple, which state do you use as a can? So you're saying multiple validators will be assigned to this particular, what is it called? Fragment.
00:13:41.514 - 00:13:43.150, Speaker B: Yeah, history fragment.
00:13:45.890 - 00:13:49.626, Speaker A: So each of them will produce the next state. Which one will be used as a canonical state?
00:13:49.748 - 00:14:19.270, Speaker B: Well, if all of those validators agree, if all of them receive the same hash, then only the first one who has uploaded this state has to upload this state. If any of those validators disagree, they also have play the same verification game between each other. So you don't actually either they all agree, or if there is some disagreement, then someone will lose money of all this information.
00:14:19.340 - 00:14:25.820, Speaker A: What is actually snapshot to Ethereum? Do I snapshot every block? Yeah, I see. And every snapshot as well?
00:14:26.590 - 00:14:28.446, Speaker B: No, I mean, well, yes.
00:14:28.548 - 00:14:30.750, Speaker A: Wait, like a hash of every snapshot?
00:14:31.490 - 00:14:53.720, Speaker B: No. Okay, there is one more thing. Yeah, because you don't want to upload the hash of each block to Ethereum. That also will be too expensive. So we have a separate layer, which we probably should talk about once we got to the validators model. Let me describe that. I guess so.
00:14:53.720 - 00:15:40.578, Speaker B: You have mentioned the, you have mentioned multiple validators. So let me try to explain how that thing works. So first of all, validators are selected completely by random from the validators pool. And the way it works, basically all of the active validators, they have to register on the Ethereum smart contract. And then you have a random number generator that you can use to choose one of those validators. And a validator, once it's selected, it must execute the history fragment. Otherwise, if it does not do that within a certain timeout, which I probably should talk about.
00:15:40.578 - 00:16:28.450, Speaker B: So I will put a reminder for myself here. Timeouts. In this case, it will lose a small fraction of its deposit. It will not lose the entire deposit because it's like a minor offense, but it will lose like a fraction of that. So the way it works. So once you have selected one validator, and this validator is verifying this BFT class array, now after this validator, you also select another validator and you also select this validator by random from the entire pool. And what else happens when this validator is selected? It does not know if there will be another validation or not.
00:16:28.450 - 00:17:17.778, Speaker B: So the way it works, we are saying that the next validation will happen with the probability p. So this means that because in this case it will be geometric distribution. In this case, the expected value of the number of validations will be p divided by one minus p. So if say for example, you put, I don't know what here, like p equals four fifth, then in this case this will be four. Yeah, so you basically can control the expected value of the number of validations. But the idea is that you don't really know if there will be another validator or not. So the validator that goes last.
00:17:17.778 - 00:18:13.782, Speaker B: So here we probably will get to the proof independent execution, which was proposed by Justin Drake. The idea was that each validator, when it validates, it has to provide basically build like I would say, a fingerprint of the execution. And this fingerprint of the execution is specific to this validator only. So this validator will produce the proof p one, this will produce the proof p two, and this will produce the proof p three. And also, while this validator is performing the verification, this one, it will verify the proof of this validator. So because validators don't really know if there will be another validator after them or not, they are like, I mean, they don't have much choice but not to like, but to produce the.
00:18:13.836 - 00:18:40.166, Speaker A: So the idea here is that if I, as adversary, control certain number of validators, there is never a moment for me when I'm certain that if I fake also. So let's say I managed to fake few validations up to a certain extent. The idea is that even if I know that, even if I control the next validation, I still have a risk that this one, that there's going to be at least one more.
00:18:40.208 - 00:18:40.558, Speaker B: Right.
00:18:40.644 - 00:18:42.014, Speaker A: But at some point the chances pretty low.
00:18:42.052 - 00:18:43.134, Speaker B: That's actually one more.
00:18:43.252 - 00:18:51.822, Speaker A: Oh wait, you say you're saying every moment. So if we manage to get to validation number five, then the probability of next is still four over five. Yeah, I see.
00:18:51.876 - 00:19:06.166, Speaker B: Yeah. So the idea here is that the geometric distribution is memoryless. So if you are here, for example, the expected number of validations is four. If you are here, for example, the expected number of validations is still four, right?
00:19:06.268 - 00:19:10.520, Speaker A: Yeah, it's like if you want a girl and you have a boy, you still have two kids before you get a girl.
00:19:15.450 - 00:19:24.250, Speaker B: And basically, yeah, this guy doesn't know whether there will be a validation after him or which validator.
00:19:24.590 - 00:19:27.278, Speaker A: But importantly, the probability of the next validation is always high.
00:19:27.364 - 00:19:40.510, Speaker B: Yeah. You can also improve the thing by forcing not only this, our data to verify this one, but also like this validator to verify this one, the proof independent execution.
00:19:41.330 - 00:19:53.006, Speaker A: But what is the motivation to, probabilistically, they will obviously execute stuff. And so if you verify the proof of the independent execution, most likely you just waste resources.
00:19:53.038 - 00:19:53.602, Speaker B: Right, right.
00:19:53.656 - 00:19:55.378, Speaker A: What's the motivation to verify it?
00:19:55.464 - 00:20:26.138, Speaker B: Well, in our case, the idea was basically to make the computation of the proof independent execution really like the overhead really low, so you don't have an incentive to remove that. And also the idea is like, if you catch this guy like that this guy has produced an incorrect proof of nib and execution, then, well, you will get a fraction of this guy deposit. But yeah, in theory I would expect someone to go and modify the source code and remove this proof independent execution verification.
00:20:26.234 - 00:20:48.998, Speaker A: So the idea right now is that if I'm validator number five, as I'm executing the code of the query whenever I need to compute my, well, we didn't go much into proof of independent execution, but whenever I need to compute my hash of the state in the present binary, I will also compute hash of everybody else. And you're saying the incentive to recompile the binaries, it's like very low, so.
00:20:49.164 - 00:21:28.066, Speaker B: The overhead is very low, and you can also receive some money from those guys. And also it also might happen that if, for example, you can see this approach might have certain flaws here. So if you have this guy who is verifying this proof independent execution, let's say this proof independent execution was not correct, then this guy came and didn't check that, and then this guy is coming and it actually found that it's incorrect, then this guy is like, okay, I have something to lose here. So yeah, maybe you can improve it like that.
00:21:28.088 - 00:21:31.322, Speaker A: Are you saying that that also works as a motivation for the second validator?
00:21:31.406 - 00:22:23.218, Speaker B: Yeah, to actually verify the proof. Okay, let me probably talk about timeouts, because there is also potential problems here. First of all, before talking about timeouts, I probably should talk about fuel accounting. So we use very similar approach as what Ethereum does. We use fuel. But here we have a kind of different thing. Instead of forcing clients to pay for fuel, we have a developer who is paying to the, not like totally the real time wear, but to the entire validation and real timeware processing and the way how a few works, few accounting works.
00:22:23.218 - 00:23:19.750, Speaker B: So first of all, there is like a complexity of instructions, which is very similar to what you found in Ethereum, although we have complexity of webassembly instructions. But second thing is, so first you have algorithmic complexity and the second thing is amount of allocated memory. So these machines, they have to allocate memory. Right now we are focused only on the memory, like in memory stuff, we haven't really touched disk much, so I'm not going to talk about that. But you for example, can tell those guys I need 4gb of memory. Or when, once when assembly supports more, you can say I want like 32gb of memory. But anyway, the developer can have control over how much memory she wants to allocate.
00:23:19.750 - 00:23:39.440, Speaker B: So there is memory. But the problem with memory is memory is not really like if you calculate the algorithmic complexity of the webassembly program, it's like equal to work in the physical sense, but memory is equal to power.
00:23:41.330 - 00:23:45.934, Speaker A: That's way beyond my knowledge of physics, but I see what you're saying.
00:23:45.972 - 00:23:59.620, Speaker B: Yeah, so it's like how much have you allocated? But if you allocated like 4gb for 1 ns, that's probably not worth much. And if you allocate it for gigabytes for a year, that's a lot. So we multiply this thing by time.
00:24:00.710 - 00:24:02.546, Speaker A: But you don't know in advance how much time you need.
00:24:02.568 - 00:24:02.802, Speaker B: Right.
00:24:02.856 - 00:24:04.646, Speaker A: What happens if my deposit, and you.
00:24:04.668 - 00:24:39.360, Speaker B: Also don't have a good notion of time in decentralized systems. So how stuff works here, we kind of replace the thing a little bit. So this is, let me think, what was this symbol? Well anyways, let me say this is like ETA, like how much the program, like the complexity of the program that was executed. Like in a for example single block. So you can multiply this ETA by some coefficient and you will get some kind of standard time here.
00:24:42.850 - 00:24:46.634, Speaker A: Okay. How much like processing time it's spent?
00:24:46.682 - 00:24:59.486, Speaker B: Yeah. How much time it would have taken on a standard hardware to execute this program. And then you take this standard time and multiply by memory and you get how much you have to, a developer.
00:24:59.518 - 00:25:12.662, Speaker A: Has to pay for memory how much memory they used at that particular time. But then also if the query has some footprint on the state, that memory will be downloaded by every consecutive real time layer, person or validator, right?
00:25:12.716 - 00:25:44.814, Speaker B: Yeah. So the way it works, so we have this thing and we also, I mean, remember we have spoken that we have to compute the hash of the virtual machine. And we also said that the hash is like miracleized is a miracleized thing. So imagine that you for example, need to perform a single put request, like write just one byte into the memory, but your memory is like 4gb and your chunks are probably like 4 kb, let's say like that.
00:25:44.932 - 00:25:51.006, Speaker A: So now probably, are you saying the memory is pre allocated? Yeah, the memory is, okay, 4gb is pre allocated.
00:25:51.038 - 00:26:17.270, Speaker B: Yeah. Those guys are like, yeah, 4gb are pre allocated. And imagine that. But let me show you the issue here. Say for example, you have a miracle tree and maybe I don't really need this layer. And this miracle tree has like eight chunks each like 4. I'm going to write, I'm as a developer have written a program that writes a single byte into chunk.
00:26:17.270 - 00:26:48.266, Speaker B: So now if I'm just calculating the algorithmic complexity of this thing, it's quite low. So writing one byte has pretty small complexity. But recomputing the merkel hash of this chunk and this one and this one, like, and basically propagating all the way to the top is pretty expensive because you also have to calculate the hash of this thing and this and this and so on. So we also charge for, we call it for dirty in chunks. So every time when you write to a chunk, this chunk is like markets.
00:26:48.318 - 00:26:53.426, Speaker A: Dirty, but it's not much different from writing a single byte to a page which is not in the cache.
00:26:53.458 - 00:26:59.050, Speaker B: Right? Yeah. So that's kind of similar to just normal hardware.
00:26:59.630 - 00:27:04.490, Speaker A: As a developer you're responsible to make sure you're writing to colocated.
00:27:05.390 - 00:27:40.854, Speaker B: Yeah, basically you have aligned calls and writing to the same, trying to write to the same page of memory. So anyways, but we have price for georgian chunks and basically that also goes into this formula, Georgia chunks multiplied by another coefficient and that's the entire price, that's the entire fuel price. How much a developer has to pay for that and the developer might be compensated or might not be compensated for this service.
00:27:40.972 - 00:27:42.326, Speaker A: It's up to them to monetize it.
00:27:42.348 - 00:27:42.582, Speaker B: Right?
00:27:42.636 - 00:27:55.926, Speaker A: Yeah, but how would users not saturate their allowance? Like developer will not be paying infinite amount of money, right? There is some allowance. Why would I not come with a single phone and just saturate everybody's allowance?
00:27:56.038 - 00:28:00.266, Speaker B: Yeah, but that's very similar to how modern web works.
00:28:00.368 - 00:28:03.422, Speaker A: So again, it's up to developer to properly expose it.
00:28:03.476 - 00:28:46.474, Speaker B: Right. So I mean if you say for example, have deployed a back end into centralized data center, then I can make a DDoS attack on you. But anyways, here we have a central developer role here which kind of makes things a little bit centralized, but you can make it more decentralized by saying, well, each client has to pay to use this service. Clients need to pay a developer like say for example, once in a month some sum or pay for each transaction somehow. Basically if the flow of clients is high enough, then you don't really need a developer here, you just have a contract that stores some kind of balance here.
00:28:46.592 - 00:28:49.562, Speaker A: But like these guys, they really don't care who's paying, right?
00:28:49.616 - 00:28:54.154, Speaker B: Yeah, no, they just need money to operate.
00:28:54.282 - 00:28:58.974, Speaker A: And also before we go to timeout, these people never rotate, right?
00:28:59.092 - 00:29:02.366, Speaker B: Yeah, well I mean they can, but.
00:29:02.388 - 00:29:09.822, Speaker A: That'S not how it is implemented. Right. If there's a data set or any computation I want to do, I preselect these validators.
00:29:09.886 - 00:29:11.458, Speaker B: You can do that, you can do that.
00:29:11.544 - 00:29:15.746, Speaker A: And those people, they constantly rotate those I never choose and they never choose me.
00:29:15.848 - 00:29:29.322, Speaker B: Yes, honestly, we haven't digged much into how real time could rotate. So for now we are like, well, yeah, developer can choose the node that is more, has the higher availability, reputation or something.
00:29:29.376 - 00:29:30.362, Speaker A: Or better link to them.
00:29:30.416 - 00:29:46.618, Speaker B: Yeah, or better link to clients. But we can say that this layer is not necessarily, I mean it might be taken over by malicious adversary, it might happen. What's important that this layer developer doesn't have any control over this layer.
00:29:46.714 - 00:30:03.570, Speaker A: But then the interesting question is this validator, right? Whenever they get assigned to a fragment, the very first thing they do is they then load the whole snapshot of the virtual machine just to perform some number of transactions, which I guess is relatively small, right?
00:30:03.720 - 00:30:06.094, Speaker B: We actually want to make it relatively high.
00:30:06.152 - 00:30:06.774, Speaker A: Relatively high.
00:30:06.812 - 00:30:07.400, Speaker B: Okay.
00:30:07.770 - 00:30:29.846, Speaker A: But still, effectively that implies that rotation is very possible, right? Would it not make sense, let's say I want my speed layer to be more secure. Would it not make sense for me to say I want a BFT containers for four people. I don't care about link or availability, but I want more security. I want those to rotate because clearly they can, right? In principle.
00:30:29.958 - 00:30:48.260, Speaker B: I mean, they could in principle, but as you mentioned, that those guys have to. So maybe I should write it like that. So these guys are stateless and these guys are stateful, right? But.
00:30:50.950 - 00:31:29.760, Speaker A: Let'S say I chose to have one validator in my tendermint consensus group, and then I chose to have, let's say, like probability six over seven. So we're going to get six, right? It sounds very suspicious. I know. That's all good. That means I'm already paying for six people to every now and then go download my state and validate, right? So in essence, let's say that instead I drop this guy, or like, I keep this guy. It doesn't matter, but I make those six people to be more real time. I'm telling them to download the state a little in advance and then validate in real time for the same amount of time.
00:31:29.760 - 00:31:35.826, Speaker A: That would give me slightly less security in a sense that the master of.
00:31:35.848 - 00:31:39.860, Speaker B: Puppets, well, you cannot choose those guys, right?
00:31:40.550 - 00:32:00.986, Speaker A: But you see what I'm saying, right? I'm losing a little bit of security because the master of puppets, now, during that epoch, while they validate me, they know them all, and so they know exactly whom to corrupt. We're losing that advantage of the last validator, right? So I'm losing that, but what I'm gaining is that my speed layer is significantly more secure, right?
00:32:01.088 - 00:32:30.562, Speaker B: Okay, let's think about this. So first of all, that was the idea to not let anyone to tamper with this layer. So no one actually has control over this layer. So we didn't really want this. And second thing, let me think about this. So this validator will go here and take the state, right? The questions are, how often do you rotate those guys?
00:32:30.696 - 00:32:38.050, Speaker A: But let's say we rotate them as often as they are, they would do as many queries as they do today, effectively.
00:32:38.790 - 00:32:39.202, Speaker B: Okay.
00:32:39.256 - 00:32:46.658, Speaker A: Oh, the problem is that here, when they validate, the queries are condensed. Right. And if it's real time, the queries are sort of coming at a significantly.
00:32:46.754 - 00:33:10.238, Speaker B: Well, I mean, what could be done? Let me think. What could be done here? You can say, take this validator and. No, not you, take this validator. Once this validator is selected and has downloaded the state and applied it and produced a new state, maybe you could replace this node with this. Oh, wait, actually, this validator will be lagged because they can download state a.
00:33:10.244 - 00:33:15.902, Speaker A: Little bit in advance. Like, effectively what you do is you download state, like, half an hour before you would have to start validating.
00:33:15.966 - 00:33:17.970, Speaker B: But you don't know that you will be validating.
00:33:18.710 - 00:33:21.746, Speaker A: Well, let's say they somehow do know.
00:33:21.928 - 00:33:26.130, Speaker B: Right? But this will break the assumption that no one controls this layer.
00:33:27.830 - 00:33:43.286, Speaker A: Well, technically, someone does control this layer today. There is the theorem chain with randomness, which says, you validate this now. So what will change that? Ethereum, instead of saying you validate it now, says you validate it in half an hour from now, so you have time to download state, catch up, and maintain it in sync.
00:33:43.318 - 00:33:46.682, Speaker B: Right? Yeah, that would probably work. That would probably work.
00:33:46.816 - 00:34:10.606, Speaker A: So here the trade off is the security will be slightly less. That's a philosophical question. Is it the case that if someone can corrupt two thirds of my seven node cluster, in principle, they can tamper with people who get assigned to the. To validate my data set? But what I get is that my speed layer is fast. Right, sorry. My speed layer is secure.
00:34:10.718 - 00:34:17.698, Speaker B: Is more secure. Yeah, I guess. I mean, I would probably want to sit down and do some math on.
00:34:17.704 - 00:34:29.318, Speaker A: That, but here's another sort of consideration, which is, so those validators, you chose them from some pool, right?
00:34:29.404 - 00:34:29.654, Speaker B: Right.
00:34:29.692 - 00:34:47.086, Speaker A: And presumably that pool, it is unlikely that you happen to sample two thirds plus one malicious actors, or, like, even one third plus one. Depends on where you draw the line. So we expect that it will only break if a malicious actor can somehow reach out to them and corrupt them adaptively. Right.
00:34:47.268 - 00:34:48.270, Speaker B: What do you mean by that?
00:34:48.340 - 00:35:20.810, Speaker A: By adaptively, I mean that when I created. So let's say this is my cluster, it has seven nodes when I created it. It is extremely unlikely that the cluster was corrupted. So the secure layer protects me against someone. Let's call them an adversary. An adversary somehow reached out to them. For example, let's say all the validators are sitting in the same discord channel, so they went to the Discord channel and they said, if you're validating this cluster, I will give you your stake, x two, for your private key.
00:35:20.810 - 00:36:03.526, Speaker A: Right? So that's what we're trying to protect against. Okay, the thing is that clearly this validator knows that they will be validating your particular fragment for a while, right? So let's say you want them to validate for like 2 hours in a row. That means there is 2 hours during which the validators themselves knows that they're validating the fragment. You can do some smart construction so that nobody else knows until they publish, right? But they know that's what is important. So now as an adversary, what I will do is I will go to discord and I will publish a smart contract on Ethereum where if you prove that you got assigned to this fragment and you provided your private key, you get your stake, x two.
00:36:03.548 - 00:36:03.894, Speaker B: Right? Right.
00:36:03.932 - 00:36:14.460, Speaker A: So I still can adaptively corrupt. I mean, I'm still risking something, right? Because I could adopt this person, but I don't know if there's going to be next one, or rather I don't know if they will be corruptible, but if I really want to.
00:36:15.550 - 00:36:30.394, Speaker B: So here's the thing. Well, first of all, two things. Because this guy knows that someone else will be verifying him. And this guy might not really know that whether this guy will actually be corrupted, be corrupted.
00:36:30.442 - 00:36:33.354, Speaker A: But I'm paying him stakex too. He has incentive.
00:36:33.402 - 00:36:40.318, Speaker B: If an adversary is willing to spend all this stake in this attack, then yes, the adversary can all the stake.
00:36:40.334 - 00:36:43.202, Speaker A: Of seven people out of few hundred, right?
00:36:43.256 - 00:37:04.906, Speaker B: Yeah. I mean, it's basically, we can tell the developer a price. Basically the developer knows that those guys have put that much stake and the validators will put that much stake. And the developer knows that if someone spends more than this stake. Yeah. Then probably the results that the entire layer produces will not work.
00:37:05.008 - 00:37:14.366, Speaker A: But if this is the price that developer, if this is the security the developer gets, then obviously they can just put everybody onto the speed layer. You still need to spend as much.
00:37:14.548 - 00:37:49.190, Speaker B: No, I would probably say that in this case, for this case in the speed layer, you need to corrupt two thirds of the cluster. For things like to work in the security layer, you have to corrupt, I guess, everyone. And in this case, you will be like. So it's like basically corrupt all. And I would probably say that if you put everyone here. So let's consider two situations. You have seven nodes in real time.
00:37:49.340 - 00:37:52.422, Speaker A: And you have r1 time six validators.
00:37:52.486 - 00:38:00.058, Speaker B: Exactly like r1 time, six validators. I would probably say that this is, like, slightly better, but also to an.
00:38:00.064 - 00:38:18.580, Speaker A: Extent, it depends on how much we believe in the power of the adaptive adversary, because obviously you cannot expect all the six validators to be online. So an adversary can provide them a choice. They can either get corrupted for two x, they can lose the stake, or they can just skip their step for like one 10th of.
00:38:19.910 - 00:38:27.986, Speaker B: If one of those validators skips the stack, skips the validation, then another validator will be selected. Yeah. You always have to do six validators.
00:38:28.018 - 00:38:47.366, Speaker A: Yeah, but let's say we make small step. Let's say we removed completely the security layer or shared validator pool. But in the tendermint consensus, we're saying that. Yeah, let's say you crafted two thirds, but we're still making like the remaining participants can still challenge.
00:38:47.398 - 00:38:47.546, Speaker B: Right?
00:38:47.568 - 00:38:49.494, Speaker A: They can still fish, I presume.
00:38:49.542 - 00:38:55.678, Speaker B: Yeah, they could even today. Right? Actually, let me think about this.
00:38:55.844 - 00:38:59.920, Speaker A: So what you're risking is if two of them are literally offline for some reason.
00:39:00.370 - 00:39:23.922, Speaker B: So let me think about this. So I guess what could be done here? So here's the thing. So let's say, for example, those guys are corrupted, and in this case, they don't even not need to talk to the rest of the two to reach consensus, because those are enough to have consensus.
00:39:23.986 - 00:39:32.650, Speaker A: But we presume that swarm has some way to say that the data is not available. So the two guys will, they will not say, block is invalid. They will say the data is not available.
00:39:32.720 - 00:39:59.220, Speaker B: Yeah. So I guess if those guys. Let me think about this. So I guess if those guys save to the, if those guys save everything to the data like availability layer, then this could. Yeah, I mean, they are not in the consensus, but they're like, well, someone has cut us out, and they can go here and download the data and be like, I challenge you. I would probably say that's quite possible.
00:39:59.750 - 00:40:18.280, Speaker A: So effectively, if I understand everything correctly, the only thing we're losing in this approach is that the adaptive adversary has full information on whether the attack will be successful before they attack. Like, effectively, they can choose not to attack until they have full control, while.
00:40:19.610 - 00:40:38.718, Speaker B: With the shared data pool, those guys are selected on completely random. And here's the thing. If you're saying that an adversary can post a discord channel and say, basically all of the six validators here will be like, okay, I'm corruptible, but you.
00:40:38.724 - 00:40:46.946, Speaker A: Know why validators validating, right. That's not because they like fluence or cosmos or whatever they're validating. It's because they want money. So if someone goes to discord and says, here's more money.
00:40:47.048 - 00:40:56.482, Speaker B: Right. But I would probably say that's also like a philosophy. If you are saying that all six of them are corruptible, then, yeah, probably that's pretty bad.
00:40:56.536 - 00:41:03.720, Speaker A: Yeah, I think that's an uncommon opinion that you can have large percentage corruptible. But it sort of sounds reasonable if you think about it.
00:41:05.370 - 00:41:07.222, Speaker B: Well, maybe there will be some.
00:41:07.276 - 00:41:10.422, Speaker A: Well, I mean, but ultimately it's up to the developer.
00:41:10.486 - 00:41:16.230, Speaker B: Usually we are basically saying that one third of the validators are corruptible or malicious.
00:41:16.390 - 00:41:18.198, Speaker A: That's extremely optimistic.
00:41:18.374 - 00:41:24.238, Speaker B: 10% of them are, but, yeah, I agree. If all of them can be corrupted, then.
00:41:24.324 - 00:41:34.110, Speaker A: But the idea here is if the developer is the developer who chooses the security, right. If they believe that more than 50% are corruptible, not much they can do anyway.
00:41:34.260 - 00:42:07.850, Speaker B: And also, I would probably say that the stakes that the validators have put, they are basically kind of saying, well, you can expect that much security if an adversary, like say, for example, all of those nodes have put like ten k as a security deposit. If someone is willing to spend seventy k to break the thing. Yeah, you're right. Like 50. Well, no, actually you also need to corrupt those, like 70k, then. Yeah, probably. If your application is that mission critical, you probably should require those guys to put more stake.
00:42:09.070 - 00:42:11.186, Speaker A: Cool. Okay, now let's talk about timeout.
00:42:11.238 - 00:43:14.998, Speaker B: Yeah, let's talk about timeouts. So we have just discussed, we have few, and the fuel is basically instituted from three components. And the first component is what the algorithm complexity was of the program. Second component is how much memory was allocated for how much time, and the third one is how many chunks of the memory were made dirty. So now you have calculated, let's say you have calculated fuel, and once you basically have calculated fuel, we are trying to turn this fuel into the timeout because we said here that a validator must validate within a certain time. And if the validator does not validate in a certain time, then a fraction of his deposit is slashed like a small fraction, like 101,000, 110 thousand. So how the timeout is calculated, we basically take the fuel.
00:43:14.998 - 00:43:24.738, Speaker B: And here's the thing. The fuel is declared by this cluster because you cannot really know how much fuel will be spent without actually executing the program.
00:43:24.824 - 00:43:28.422, Speaker A: But once you validate, if you exceeded fuel, you just stop. Right?
00:43:28.476 - 00:43:29.078, Speaker B: What's that?
00:43:29.164 - 00:43:30.470, Speaker A: So, as a validator.
00:43:33.850 - 00:44:20.474, Speaker B: Let me show you a potential issue here. So those guys say, for example, have. Okay, let me talk about the timeouts, and I probably should clear some space here. Yeah, that's probably good enough. So let's talk about timeouts. So let's say I have fuel and I've got the timeout, which is equal, like some constant by fuel. And this constant is like choosing large enough, like maybe ten times more than you would expect an average node, maybe not 100 times, but like 24 times more than you would expect an average validator to take.
00:44:20.474 - 00:45:17.478, Speaker B: And you can say, well, if you guys are slower than that, well, don't even consider joining the network. So now you have the real time cluster, and it might happen that the real time cluster says, well, I have spent that much fuel, but this fuel is much less than the true amount of fuel that is required to perform the computation. And this fuel is written here in those blocks. How much fuel was spent for each of those blocks? So now you can say, if I want to validate a fragment of history, I need to spend that much fuel. But if the real time cluster was lying about the fuel spent, then the timeout that will be given to the validator is, like, really small. And for this, we have, like, few disputes. So once a validator comes and notices that he was given a very small amount of time, it can execute a few of dispute.
00:45:17.478 - 00:45:43.842, Speaker B: And a few dispute is very similar to the just normal verification game dispute. You're basically saying, for example, this is a real time cluster and this is a validator. And after each webassembly instruction, you can say, hey, that's how much fuel has left was spent, actually.
00:45:43.896 - 00:45:51.414, Speaker A: But that's not how I will attack you. If I'm a real time cluster, I will just upload a seven terabyte file. You will not even get to webassembly step.
00:45:51.612 - 00:45:56.738, Speaker B: Well, let me think about this. You upload a seven gigabyte file.
00:45:56.834 - 00:45:57.566, Speaker A: Terabyte file.
00:45:57.618 - 00:46:03.180, Speaker B: Terabyte file. You will upload it to swarm. Okay, let's get to this.
00:46:03.710 - 00:46:09.178, Speaker A: That's an interesting question, but swarm can provide attestation on the size.
00:46:09.264 - 00:46:12.346, Speaker B: On the size, I'm not sure.
00:46:12.448 - 00:46:15.262, Speaker A: I guess if swarm can do that, that would be your dispute, right?
00:46:15.316 - 00:47:01.740, Speaker B: Well, I don't know the answer right now, so probably we need to think about this. So let's finish with this, and then think how this can attack can be solved. So anyways, for the timeout attack, you can say, each of those guys, once this guy has found that he spent more fuel than this guy, you can say, well, I want a dispute on this part of execution. And then you do the same bisex search, and you find the instruction that has produced diversion amounts of fuel and the real time class in this case will lose stake. So for the timeouts here, I would say that, let me think.
00:47:03.250 - 00:47:10.910, Speaker A: If something is wrong, like let's say fuel is improperly recorded within the timeout, you just need to initiate the verification game, right? You don't need to finish it.
00:47:10.980 - 00:47:20.660, Speaker B: Yeah, well, and you're not only given like this timeout, you also have some time to download this state.
00:47:21.190 - 00:47:22.690, Speaker A: But that is all included, right?
00:47:22.760 - 00:47:57.246, Speaker B: Yeah, well, not including few. You probably need another constant here, because if you put few zero, then you don't have any time. So for the timeout, what kind of a problem might happen here that the data availability layer, if an adversary tries to corrupt the data availability layer and say, hey, do not return any data to the validators, so they time out, essentially that might become a problem, but.
00:47:57.268 - 00:48:04.930, Speaker A: In this case the system will just stall, right? Well, no, like if no validator can validate.
00:48:05.510 - 00:48:17.538, Speaker B: Yeah, I would probably say that you will, like, the malicious real time class in this case will never get caught. Probably. Well, actually the adversary will have to.
00:48:17.544 - 00:48:25.650, Speaker A: Pay these guys, but as a developer, you will know something is wrong because for a long period of time, you're not receiving any validation results.
00:48:25.730 - 00:49:47.718, Speaker B: Yeah, you will probably see that, because basically if an adversary will have to pay to the data availability to bribe those nodes to return the data, but it will have to bribe them for indefinite amount of time, because once those nodes start returning the data, these guys will actually come and there will be another validator that will be able to download the data and eventually someone will lose a deposit. And also with this, remember we said there will be multiple validations. So the stakes of the real time nodes are not released until the like, I mean, the real time nodes that have produced this history fragment, they will not be released until there is a last validation was completed. So if an adversary is paying to someone to not return the data, then stakes of these guys will never be unlocked. And this essentially would be similar to like just paying those guys their stakes. Yeah, you have asked about the, I think about what if, let's say, yeah, let's think about this. What if those guys have uploaded like a really big transaction file? You probably can compute the proof.
00:49:47.718 - 00:49:50.340, Speaker B: You probably can build a proof of this size.
00:49:50.710 - 00:49:58.070, Speaker A: Well, if swarm can attest to the size, there's already quite a bit of reliance on swarm, so it's not going to get any worse.
00:49:59.210 - 00:50:38.342, Speaker B: I think it should. What else can you do? You can also say, for example, you can also build a Merkel. I mean, essentially how swarm could do that, I guess you could build a merkle tree on top of this file. And once you have if, say, for example, this Inset, the file is like 1 mb, but you have downloaded already ten megabytes and it has not finished. Then you have downloaded the chunks that are required to build the merkel. Proof that these chunks belong to the half of the merkel tree. And now you can actually prove that the size of the file is.
00:50:38.396 - 00:50:40.390, Speaker A: They uploaded an invalid merkel root.
00:50:40.550 - 00:50:41.114, Speaker B: What's that?
00:50:41.152 - 00:50:48.166, Speaker A: They uploaded an invalid. Like, they actually have a 1 mb file, which they never uploaded. And for the 1 mb file, they do have the merkle.
00:50:48.198 - 00:51:16.774, Speaker B: Oh, that's actually an interesting case. Okay, so let's also talk about this. What's important here is that the merkel tree of the. Here's where the discrepancy might come from. So there is a hash of this thing and swarm. So there are actually two hashes. Okay, let's get to this.
00:51:16.774 - 00:51:20.898, Speaker B: There are two hashes, actually, and the first hash is the virtual machine hash.
00:51:20.994 - 00:51:22.210, Speaker A: That's the Merkel route.
00:51:22.290 - 00:51:25.990, Speaker B: Yeah, that's one of the Merkel routes. But there is also a swarm hash.
00:51:26.150 - 00:51:27.898, Speaker A: That's just something that swarm gave you back.
00:51:27.984 - 00:51:33.020, Speaker B: Right? And that's something that swarm attests that it will return to you.
00:51:34.350 - 00:51:37.034, Speaker A: This is by no means mercalized, right? I think.
00:51:37.072 - 00:51:38.342, Speaker B: No, they are mercurialized.
00:51:38.406 - 00:51:40.800, Speaker A: It is mercurialized. Swarm has them. Okay?
00:51:41.490 - 00:51:48.154, Speaker B: And those hashes can be computed with different chunk sizes and moreover, even different hash functions.
00:51:48.202 - 00:51:51.818, Speaker A: So effectively, you can provide one VM hash and upload a different file.
00:51:51.914 - 00:52:24.602, Speaker B: So what a validator can do, like, this guy can come and download, like, say, for example, it has produced a new state, and it says, yes, the state of the. Like, I agree with the state of the virtual machine that is written here. But it then uploads, not matching file and not matching state file to here. And in this case, and because those hashes are different, it's not like, I mean, I, well, I didn't know of an easy way how to prove that this hash doesn't match this.
00:52:24.656 - 00:52:27.530, Speaker A: But if swarm hash is mercalized, why do you have your own hash?
00:52:27.950 - 00:53:15.530, Speaker B: Well, it might be just different hash function. I mean, yes, we could make this hash function compatible, but what we are saying here is that, well, maybe it might actually happen that the hash functions will be different. So what we have thought about is that there will always be the next validator, like either the one that is reverifying this guy or the validator that is verifying the next history fragment that will download this file. And once it downloads the file, there is a way how to prove that this file, that the file available by this form hash, does not really correspond to this virtual machine hash. You will just basically find a divergent chunk.
00:53:16.430 - 00:53:22.714, Speaker A: Very specific. If the next validator is reverifying, they're not downloading the file, they're uploading the same file, right?
00:53:22.752 - 00:53:40.754, Speaker B: Yeah, but I mean, once they are ready to upload the file, they can compute the swarm hash and see, well, if the swarm hash matches this one, and if it does not, they can also do a dispute here. Yeah. What was that timeout yeah. We have talking about?
00:53:40.792 - 00:53:42.740, Speaker A: Yeah, I think we covered most of the things.
00:53:43.450 - 00:53:45.510, Speaker B: Yeah, I think so.
00:53:45.660 - 00:53:49.398, Speaker A: Cool. Yeah, we can wrap up the technical discussion here.
00:53:49.484 - 00:53:49.782, Speaker B: Okay.
00:53:49.836 - 00:53:57.030, Speaker A: We always ask one non technical question at the end, which is when is the main net? How far are you?
00:53:57.100 - 00:54:05.990, Speaker B: I think beginning of 2020, I guess. Yeah, it's 2019 right now, so. Yeah, like beginning of 2020. That's our target, I would say.
00:54:06.060 - 00:54:07.254, Speaker A: And you have a devnet, right?
00:54:07.292 - 00:54:07.758, Speaker B: Yeah.
00:54:07.884 - 00:54:09.534, Speaker A: You can go download. Play with it.
00:54:09.572 - 00:54:15.262, Speaker B: Yes, but you can play with the real time clusters and the security layer is like, on its way.
00:54:15.316 - 00:54:18.382, Speaker A: I see. Cool. Okay, thanks, everyone.
00:54:18.516 - 00:54:23.500, Speaker B: Thanks, guys. Close.

00:00:02.970 - 00:00:20.618, Speaker A: Hey everyone, welcome to another episode of the Whiteboard session. And today we have with us Jordy, co founder of Polygon, and we're going to talk about Polygon the KeVM today. So yeah, Jordy, do you want to talk a bit about yourself and Polygon the KevM?
00:00:20.714 - 00:00:32.294, Speaker B: Yeah. Well, I'm Jordy Valina. I'm the technical lead at Polygon ZKVN. Mainly what I've been doing think for the last three years now is the Polygon ZKVM. So that's what I expect you to ask me.
00:00:32.492 - 00:00:44.700, Speaker A: Exactly. So actually I believe three years ago, many people, including some of the prominent decay researchers, don't believe that we can have the KeVM in a few years. And Jordan, you proved them wrong.
00:00:45.390 - 00:01:32.858, Speaker B: I didn't believe he did. So when we started, this was a kind of a dream actually the story was that Barney Whitehat from theory of foundation, he convinced me actually we're like spending a couple of months in my home, just in the whiteboard, just trying to figure out what were the stoppers for building that. And we were like solving all the concrete details and small details and at some point say, okay, this is super complex, but this is theoretically possible. It was from there that we just start building. And for the last two years has been also a journey of solving challenges, a lot of challenges, until we got to the point. So yeah, that's an engineering process, I would say.
00:01:32.944 - 00:01:43.354, Speaker A: Right. Actually I'm curious, from your point of view, what are the major obstacles back in 2020 when you first started, what do you think are the major bottlenecks?
00:01:43.402 - 00:02:13.298, Speaker B: Well, the technology that we started with was the normal ZK technology was very much. I like to talk about the similar between electronics and circuits. I mean this is not electronic circuits. We are not talking about transistors, we are talking about polynomials. But from the mindset. Designing circuit, I mean we call it circuits. Designing ZK circuits and designing electronic circuits has a lot of similarities.
00:02:13.298 - 00:02:50.946, Speaker B: That's why we like to talk. And at that point where if we were designing circuits without a clock, so that means that, okay, you can build any computation. At the end you have ans and ores, you can do whatever you want. But the quantity of Ansanors that you need to do for something specific is huge, especially if you want to do ifs. I mean if you want to do conditional things in SDKBM you have a lot of conditions. Depending on the transaction you will execute one opcode or the other. And there is a lot of conditions and the conditional things.
00:02:50.946 - 00:03:28.654, Speaker B: So doing a generic EBM was like impossible. And you count the number of constraints and it's like a huge number there and here. The big invention was like inventing the clock. I mean, inventing the clock was very much this concept of a state machine. These starks are very good because it comes very naturally at the moment that you have a state transition function. I mean, at the moment that you have this kind of a clock, then you can build a processor. And if you can build a processor, then doing conditionals and generic programs are easy.
00:03:28.654 - 00:03:54.918, Speaker B: And this is very much the strategy that we follow. I mean, we built a processor. We built a processor with polynomials with transistors, but we built a processor. We built an assembly on that processor, and we built a program that's running that processor that mainly what it does is interprets the EVM. This was the full strategy. This was proven the right way to go. This was the biggest part.
00:03:54.918 - 00:04:31.218, Speaker B: And from there we can talk about different challenges. I mean, the memory, ECDSA, or even paddings recently, even arithmetic operations, for example, is a challenge for itself. Or how we do the storage. Each of the stain machines is a challenge by itself, but this technology has improved that. You can do whatever you want. It's like having transistors. I mean, if you get the transistor, of course you need to build the processors, but you can build whatever you want.
00:04:31.304 - 00:04:55.046, Speaker A: Yeah. Okay, maybe let's start from there. Maybe we can talk about how the state machine works and how the analogy between the regular cpu and the key processor actually works. So maybe you can start with the different state machines that you build, and then we can talk about how that relates to the EVN.
00:04:55.158 - 00:05:26.978, Speaker B: Yeah, the idea is that. What's the idea is imagine that state machine. You can imagine any state machine, but probably the easiest state machine to think about is fibonacci. Fibonacci. You can read that state machine, but at the end it's like you have two states. So we may say this is state a and b. Okay, what's the next step? What's the next step? Well, the next, if I plus one is equal a plus b.
00:05:26.978 - 00:05:48.202, Speaker B: Okay. And if you want b, I plus one, maybe it's equal to a. It's a state machine. I mean, this is the state transition function. Of course, you have maybe initial state, but you have a state transition function. And you can do that as many times as you want. You can do a multiplication, actually.
00:05:48.202 - 00:06:16.234, Speaker B: You can build a processor. I mean, this is a state machine here the way is built. See how we convert that to a polynomial thing. Okay, so this is a problem. Let me explain first how a polynomial commitment works, because I think it's quite easy. And then we try to join the both pieces together. So when we have a polynomial.
00:06:16.234 - 00:06:42.174, Speaker B: Polynomial. When we're talking about polynomials, but a polynomial you can understand as an array of values, many, we call it this. In the evaluation form, for example, you have a straight line. This is a polynomial of degree one, and you have two evaluations. For example, if you have the evaluation at zero and one, you have, maybe this is, I don't know, 43. And here you have 31. Okay, so this is a straight line.
00:06:42.174 - 00:07:27.770, Speaker B: So this is a polynomial, f of x equals to ax plus b. Okay, you have a polynomial, but with these two evaluations, with 31, and you can express this as 43 and 31. Okay, this is what we call it, the polynomial. Express it in evaluation form. This is for degree one, but you can do that with degree 1 million. That's a degree 1 million with 1,000,001 values, you get the definition of that polynomial. Okay, this ab, whatever it is, whatever numbers are there, here would be the coefficients, this would be the coefficients expression.
00:07:27.770 - 00:08:12.890, Speaker B: And this is the evaluations expression. In this case, this is like a vector. In this case, the base of this would be one x, or even x square x to the three. And in this case, the base would be the Lagrange polynomial, one, the Lagrange polynomial, two, Lagrange polynomial, three, and so on. Lagrange polynomials, is a polynomial such that Lagrange one at one, this is one, and in the other points is zero, and so on. Okay, but this is just the same way of expressing a polynomial. So the schema that we have when we do a polynomial is, okay, these days, we have approver, and we have a verifier.
00:08:12.890 - 00:08:24.030, Speaker B: Prover in general is called Peggy. And the verifier is victor. Okay, so this is, we can find this. Okay, this is victor.
00:08:24.770 - 00:08:25.278, Speaker A: Okay.
00:08:25.364 - 00:09:00.150, Speaker B: And this is Peggy. Okay, so what's the polynomial commitment schema, how it works? Well, so, Peggy, just think about the polynomial. For example, this one, he commits to this polynomial, f of x, the full polynomial. One way to thinking about committing the polynomial is hashing the polynomial. Okay. Committees in general, is a hash. We'll see that's a special hash, but it's a kind of a hashing of itself.
00:09:00.150 - 00:09:31.730, Speaker B: Okay, so if we are here, if we are thinking in finite fields here instead of in reals, we are talking with finite fields, one way of hashing polynomial, it's very unpractical way, but one way to think about is, okay, you can take all the possible values. It's a finite field, so you have all of them. You see how evaluates to all them. And then you just create a merkel tree of all that. And then you just create a rule. This uniquely will generate a hash. I mean, this is not practical, but for thinking it's a way of this polynomial commitment there.
00:09:31.730 - 00:10:19.694, Speaker B: Okay, so I commit to a polynomial, and in this case, Peggy just sends a random number, random number z. And Peggy just sends the. Okay, it sends f of z is a concrete number, and he sends f of z, but also sends a kind of a proof that f of z matches to this polynomial. Okay, in this case, the proof in the case that I explained you before would be. The proof would be the Merkel path of this polynomial. Of course, this is not practical, but this schema. I mean, there are different methods of doing this, but this is perfectly possible, right? Okay, this is a polynomial commitment schema.
00:10:19.694 - 00:10:41.610, Speaker B: But imagine that. Imagine that instead of working with one polynomial, I want to work with two polynomials, or three polynomials. Okay, imagine that there are f of x and g of X. Here I can send commitment of f of x. G of X. Maybe the commitment h of X. I can send you three commitments.
00:10:41.610 - 00:11:12.530, Speaker B: And here I want to prove you that this has some relationship. For example, imagine that I want to prove that f of x is equal to g of X plus h of X. Okay, well, the thing is that a way to do it. Okay, I send you the three commitments. You send me one single z. Here I send you, of course, f of. So g of z.
00:11:12.530 - 00:11:41.450, Speaker B: G of Z and h of Z. Okay, here is pf. I send you pg ph. Okay, so you know that these evaluations are here. And here. The idea is we can check that this constraint, this relationship fits at z. And if z is enoughly high, I mean, if it's a small, you can trick that.
00:11:41.450 - 00:12:09.282, Speaker B: But if Z is a big number, then proving just one single point, I can prove that the full polynomial is. And this is a fundamental part of this. So here is with a single check in a single point, I'm just checking all the polynomial. So I'm just checking the relationships. I'm just checking, like, a lot of things in parallel.
00:12:09.346 - 00:12:23.470, Speaker A: Yeah, as you said, a fundamental part of the k. This is because the polynomial degrees are relatively low compared to the size of the field. So if you randomly choose, like, pointing the field, and they actually hold the means with extremely high probability of the equation.
00:12:23.570 - 00:12:45.642, Speaker B: But this is fundamental because, I mean, this polynomial can be of degree 1 million or 10 million. So then I'm checking at the time in parallel. It's just in a single polynomial commitment. I'm just checking one millions or 2 million constraints at a time. So this is the main trigger of all this. There is another important thing here that's important to know. This is an interactive protocol.
00:12:45.642 - 00:13:09.442, Speaker B: So here you need Peggy and Victor, but actually you want to convert this to what we call it a non interactive. I want to generate a proof that I commit this and I just generate the proof here. There is one trick. This is the Fiat Shami here from heuristic. But the idea is, okay, so here we don't have verifier. So we compute zit as the hash of the transcript, I mean, of the hash of all these commitments. We set the commencements.
00:13:09.442 - 00:13:50.254, Speaker B: Then you compute the hash, because hash is not reversible, we don't control. So this is like kind of a random. There is a full mathematical theory behind that, but this is the idea. So we can convert any interactive protocol to a non interactive. So generating a proof where there are some polynomials, relationships, you can commit to some polynomials, and then you prove that those polynomials, these commitment polynomials, fulfill a specific relationship of polynomials. And this is very powerful. But next question that comes is, okay, this is cool, but we have a problem here that's the same machine.
00:13:50.254 - 00:14:32.660, Speaker B: So how we convert that from here to here? Okay, so let's try to connect this problem in a polynomial constraints thing. So I clean it a little bit. Let me see how I clean it there so I can clean it everything. Okay, let me just start. Let's write the state machine. So here is. Let's do it with eight times.
00:14:32.660 - 00:15:01.840, Speaker B: This is a, this is b. Let's start with two numbers. Let's start with one and two. Okay, so then a is once, this is three, and b is first. One, two, three. Put two here, just to be more clear. Okay, so the three goes here.
00:15:01.840 - 00:15:11.070, Speaker B: And here, I'm just adding five. So here is 5813.
00:15:13.350 - 00:15:16.002, Speaker A: No, that's 1321.
00:15:16.136 - 00:15:39.626, Speaker B: This is 21 34. And this is going to be 55. No, 34, 55, that would be the. Imagine that this is. Just put it in red. So here, what I have here actually is we have two polynomials. Okay.
00:15:39.626 - 00:16:02.938, Speaker B: This is one polynomial. This is polynomial A of X. And this is polynomial D of X. Okay, so what's this polynomial? Well, just a polynomial of degree seven, where it evaluates to these places where we need to pick up a point to evaluate.
00:16:03.034 - 00:16:03.680, Speaker A: Right.
00:16:04.530 - 00:16:36.890, Speaker B: I can choose any of those. So any of those work? Okay, but there are ones that are very useful. The ones that we are using is the one that are what we call it the roots of unity. Roots of unity. I mean, it's the roots of unity. If you go to the complex, for example, the square root of one is one minus one. If you do a square, the cubic square, so the three square, the three root of one is actually one is one of those.
00:16:36.890 - 00:16:58.690, Speaker B: But it's going to be also two complex numbers. I mean, you go to the complex. Here you have the circle unit. So you just divide the circle. These are the roots three, okay? If you want to do the roots nine, just divide this circle in nine equal parts. And here you will have the nine roots. Okay? So these are the roots, the roots of unity.
00:16:58.690 - 00:17:41.502, Speaker B: Here we are in finite fields, but if the final field is certain way, you also have these roots of unity. But the roots of unity are going to be certain numbers. Okay? So there's numbers that when you, I mean, if it's a square fourth, and when you multiply that number four times at the end will give you one. Okay? But they are going to be concrete. So these numbers, if the final field exists, if the final field has a good duacity, that's what we have actually, if PI actually is, if PI minus one. So PI is a prime field. If PI minus one is multiple, divides is something like two to the 28 times c.
00:17:41.502 - 00:17:47.038, Speaker B: That means that you will have two to the 28 roots.
00:17:47.134 - 00:17:47.806, Speaker A: Roots of unity.
00:17:47.838 - 00:18:16.618, Speaker B: Of unity. Okay, so that's two to the 28, two to the 27, two to the, you have square roots. You have all of them. Okay, so if the prime is good defined, and we are working with primes that are well defined, this fulfills, okay, the idea is that, well, these roots of unity, we can express them. In this case we need the x root of unity. So these square roots, I mean, it works the same. I mean, having one, imagine that we have one.
00:18:16.618 - 00:18:45.954, Speaker B: So here I can convert, I know all the x. So if I have one primitive, I can't have all of them. So I can get zero. What, to one way to two, weight to four, weight to five, six over to seven. Actually, w to eight is a square, 8th root. So it's going to be one. And w to zero is something to zero is one.
00:18:45.954 - 00:19:06.074, Speaker B: So you see, it's a circle itself. Okay? So here we have, of course, that f of w, zero is equal to f of w one. Well, in this case it's a. A of a is one, a of w, two is five. And the same thing here.
00:19:06.192 - 00:19:06.860, Speaker A: Yes.
00:19:09.150 - 00:20:06.026, Speaker B: B zero equals one. B one equals two, and so on. These are the evaluations. The cool thing is that, for example, for converting two evaluations to coefficients here, I can apply one thing that's called the fft. And I can go back and forth super fast, so I can go to coefficients and so on. So what I would do, okay, so here I have the polynomials. Okay, and what's the relationship that needs to follow? So how can I convert this to some relation? To this to some relationship? Okay, well, the relationship here is, well, here is a plus one, okay, so if a is f of here, you see that? Let me put here.
00:20:06.026 - 00:20:20.114, Speaker B: So here is, I would be a of wx equal a of x plus b of x. Okay. And b of wx. See here is that wx is the next one.
00:20:20.152 - 00:20:20.658, Speaker A: Next one.
00:20:20.744 - 00:20:39.942, Speaker B: Of course, here we have the problem of the last one. Okay, we'll solve it now. Okay, but here b of x is equal to a of x. Okay. Yeah, let's solve this problem because, I mean, okay, this works. But of course, you see that this relationship will feel everywhere. But the last one, last one doesn't work.
00:20:39.942 - 00:20:55.914, Speaker B: Doesn't work. Okay, so here what we can do is we can define another polynomial. We call it a constant polynomial. So it's a polynomial that this is a trace. I mean, this is depending of the numbers. It changes. But there is another constant doesn't.
00:20:55.914 - 00:21:21.074, Speaker B: Yeah. So here is, we are going to define one polynomial. Let's put a polynomial where here is going to be 10 zero. This is actually, the Lagrange polynomial is the basis. We call it l one of x. Okay, so this is l one. Okay, so what I'm doing, okay, I want to convert.
00:21:21.074 - 00:22:01.060, Speaker B: So these equations needs to apply, but only when l one is zero, not when l one is one. So one thing that I can do is I'm going to reconvert this. So I'm converting this equal to zero. This equals to zero. And I want this to happen. So what I'm going to do is I'm going to multiply that, going to multiply that by l one. Actually.
00:22:05.990 - 00:22:07.890, Speaker A: One minus l one minus.
00:22:08.330 - 00:22:17.510, Speaker B: Okay, this equals to zero. And all this one minus l one fixed equals.
00:22:19.790 - 00:22:20.490, Speaker A: Right?
00:22:20.640 - 00:22:51.380, Speaker B: Okay, so you see here that, well, of course, if l one is zero, this condition must fulfill. This is everywhere. So this is everywhere. But in the first one, actually, this is wrong. Well, let's put here. So actually, the last one is the one that's not defined. Okay, so it's in the last step.
00:22:51.380 - 00:24:09.562, Speaker B: So the next in the last step is the one, okay, but, okay, this is just to be precise on that. So we already have a polynomial, we have two polynomials, we have a constraint, these polynomials, we call it the trace polynomials, because this is l is, we call it a constant polynomial, but constant is known by the proverb and the verifier. And then I do exactly the same. So how the protocol would work? Well, half again, Peggy and Victor, in the first, I would commit to commit to a of x and commit to b of x. Victor would send z here, I would send, Peggy would send a of z, b of z, and it's proof. And Victor would check this. I mean, we check these equations by just substituting x with z.
00:24:09.562 - 00:24:37.634, Speaker B: Actually, you see here that, well here is wx. So actually here I need, for these equations, I need a of x. So in this case a of z. But here I would need also a of wz. So I need this opening too, right? And P-A-W and b of w. Seat here would be p of bw. Okay, but no problem.
00:24:37.634 - 00:25:22.046, Speaker B: Instead of doing one opening, I'm doing two openings. And then I'm just checking, just substituting these values with these equations and the prime field, decimal field, of course, I can convert that to fiat shamir. I can generate a proof. So here you see that I generated a proof for that. Here. Another important part is, okay, but here is, I mean, you are proving here that for any value, but I want to force here, the verifier wants to force, for example, the input. So how would you force the input? Well, you see here, well here the verifier would need also the evaluation of la to f x, but la of x is a constant polynomial.
00:25:22.046 - 00:25:50.218, Speaker B: So he knows how to evaluate that. Okay, so imagine that this is what we call it, the public inputs, in this case, the public inputs of all. So I want to force public input. This is something that the verifier have, but you want to prove that those values are correct. And the idea is that you do this, you do this by adding another constraint. In this case, it would be l one. Well, here I'm using l eight, but imagine that here is l one.
00:25:50.218 - 00:26:18.070, Speaker B: Here I want to prove that in l one. So when l one, or if you want l, if you want l eight, wx, which is l one, because it's the next value. Okay, times, and here is a of x minus. And here is, let's say a zero equals zero. And then here I can do the same. Eight. This is l one.
00:26:18.070 - 00:26:49.950, Speaker B: This is the first line. B of x means b zero equals zero. Here you see that we extend it, but then again, you do the same. You commit to a of x and b of x. Here you sense it, of course, here you would need these values in order to operate these values, a zero and b zero are public inputs. So you want to the verifier, this will be part of the verifier proof. So they will be known by the verifier, and they will check that a of x minus zero at a of z.
00:26:49.950 - 00:27:27.338, Speaker B: So actually, you will check that l one of z w, so l one is known. It's a known polynomial times a of z. This was sended by the proverb. Sure, that's correct. Mean is I zero, which is the public input, is equal to zero. So you see here that this is the kind of, for public input, but here we converted state transition function. You see this state machine state transition function to a polynomial problem.
00:27:27.338 - 00:27:34.414, Speaker B: And using the polynomial commitment schemas, there is a lot of ways of doing this. Polynomial commitment schemas. You can understand this as a black box.
00:27:34.452 - 00:27:34.846, Speaker A: Yeah.
00:27:34.948 - 00:28:01.330, Speaker B: Okay. So we are able to get, if you have a state machine, we have a clock, so we have these state transition functions. We can prove this in parallel, so we can build processors out of that. This is the core, the basic part. And from here we can start talking about other things.
00:28:01.400 - 00:28:09.190, Speaker A: Yes, actually, one quick question. You already, in practice, how are the constant polynomials communicated to the verifiers?
00:28:10.410 - 00:28:59.746, Speaker B: Well, the constant polynomials, they are like part of the circuit. I mean, they are defined. So when you design a circuit, here I design as a circuit, and here I design, that should be a constant polynomial that should have exactly these values. This is theoretically, you don't need to do anything else. I mean, the verifier knows these polynomials. The thing is that a lot of times you can have a lot of these constant polynomials. And in order to reduce the memory of the verifier and the complexity, sometimes what you do is, instead of the verifier having to compute the evaluations, the idea is we can have these polynomials like precommitted.
00:28:59.746 - 00:29:35.620, Speaker B: We have a commitment of this. If you send these polynomials, but they are precommitted, so you can generate in the setup phase. And then what you can do is here you can send the openings with the proof itself. The verifier would have just a commitment of l eight of x. This is computed in the setup phase. And here you would just send here l eight of zit and approve pl eight. Okay.
00:29:35.620 - 00:30:02.560, Speaker B: This is, sometimes it's more practical. So this is instead of having the verifier to compute. Okay, let the prover to compute it and prove it. In general, these protocols here, I'm sending a lot of proofs here. We can aggregate all this proof in a single one. And I mean, the mechanisms for doing this in a more efficient way. There is things, but essentially what you are doing is very much this.
00:30:03.570 - 00:30:05.760, Speaker A: Okay, yeah, sounds good.
00:30:06.370 - 00:30:30.470, Speaker B: This is the basic, but this is the core part. I mean, it's the basic. There are some other primitives that are relevant, that are important. There are, for example, the permutation checks and the blue caps, which are important pieces. So here is, for example, I can have like two polynomials. Imagine that. Well, here's two polynomials.
00:30:30.470 - 00:31:04.958, Speaker B: Well, imagine that you have a polynomial. That's 134845. Okay? And you want to check that. This is, for example, is in 1234-5678 so this would be a kind of a range check. Okay. So here you can express these kind of relationships that the numbers of these polynomials must be included in this polynomial. Or it's just a permutation check.
00:31:04.958 - 00:31:28.566, Speaker B: Okay. Imagine that here half a polynomial is one, two, three, and here have 345678 to one. Okay, so this is a permutation of the other. You can express this kind of relationships with some mathematical expressions. If you are interested. Here, you can check the Plokup arguments. There is a lot of literature, something about that.
00:31:28.566 - 00:32:09.622, Speaker B: But these are very useful because, for example, a permutation check allows you to have specialized state machines. I can have like a main processor state machine, but then I can have, for example, arithmetic estate machine, or a binary state machine, or a ketchup state machine. So some estate machines that act like a, very much like a coprocessor. So they are state machines that are doing specific operations. And then I can link them on each other just by a permutation check. I'm just checking what's here is also there. So what I'm assuming that's correct in this thing machine, actually proven machine in that site, how you solve memory, there is a lot of things.
00:32:09.622 - 00:32:36.750, Speaker B: But I mean, see a processor, how it works. I mean, it's just a normal processor with instructions, with conditional jumps, with memory. Actually, we got a ROM. ROM is the program that's executed in this processor. If you see the ZKBM at the end is this processor with this ROM. And this ROM is a code that actually is like a. Yeah, actually.
00:32:36.820 - 00:32:48.050, Speaker A: Jordy, do you want to draw the architecture of how the, like processors actually like the main state machine and the other different state machines.
00:32:55.420 - 00:33:12.312, Speaker B: Here is while we have a. Well, it's not. I mean, it's not very different than what would be a normal. So here we have a mainstream machine. The mainstream machine, there are two processors that. They are tied very much together. One is, we call it the ROM.
00:33:12.312 - 00:33:26.228, Speaker B: ROM is not driven the state machine. It's just our polynomials that represents the program. Okay. And then we have the memory. This is like the core part. And then there are auxiliary state machines. Here we have.
00:33:26.228 - 00:34:08.576, Speaker B: The most important part are say, the binary. Binary state machines are doing things like addition, subtraction, xor, binary things and things that are by, to buy by bit of bit operations. We have the arithmetic. Arithmetic ascent machine is mainly for multiplications, 32 bits, I mean, 256 bit arithmetic. So it's doing a 256 bit multiplication in a different prime field. This is some complexity in the resistant machine that's mainly doing that. But we have others here.
00:34:08.576 - 00:34:56.556, Speaker B: We have another, that's storage, for example, for the storage, we're using a sparse merkel tree. It's kind of a Patricia try, but much simple binary, just have a storage. Here we have medic storage, ketchups, for example, or shadow 56 now, and some other, I would say some other very specific made. For example, we have. But these are more EVM expected. For example, we have one to deal with unalignments in memory. For example, the ABM, for example, there is a problem with.
00:34:56.556 - 00:35:34.990, Speaker B: I mean, you have words of 256 bits, but actually when you are the, the memory is byte aligned, so you can do things like that. We could do that with binaries and arithmetics, but this is used so many times that we have like a specific arithmetic, specific state machine to split and divide to deal with that specific cases. But this is very much, the architecture is just different spin machines and developers don't need to worry very much about that.
00:35:36.320 - 00:35:43.310, Speaker A: And do you also want to talk a bit about Zekiasum, like the assembly language you develop for the.
00:35:46.720 - 00:36:26.856, Speaker B: In order to build design method session. I mean, we see these polynomial things. Actually, we built one language to deal with, to create this, and one language and a tooling for, we call it this arithmetic for creating these state machines. This is called pill. It's polynomial identity language. It's just a language for defining that. We have also a lot of state machines already designed, like the arithmetic state machine and binary state machine that they apply directly or with very small modifications to what would be a Zkwasm state machine.
00:36:26.856 - 00:37:11.972, Speaker B: So what we are doing is we are taking all the tech, all the work that's already in the ZKBM we are adapting if you want changing small pieces, but they're just taking. And instead of having EVM, we can have a wasm thing. Of course, the arithmetic, instead of being for example, 256 bits, it's going to be 64 bits operation. Okay, maybe ketchup, you need it or not? Okay, so maybe you will need some other discussion. For example, if you were interested in floating points or not. Okay, but this is a hard one. But I mean, at the end it would be another stain machine.
00:37:11.972 - 00:37:42.980, Speaker B: So here the idea is like a hardware design. I mean, you can have different stain machines and then you can plug them together in a different way in order to build different. Of course the ROM is going to be different because the program that you are going to run probably is going to be different, but the architecture is very much the same. So this is the work that we have been doing until now, is just trying to see and adapting the current technology to do the ZK.
00:37:44.440 - 00:38:00.248, Speaker A: Maybe for people who don't fully understand how this works in practice, it might be helpful to talk about this entire execution trace. Right. So on the one side you have this rows, like a lot of them. I think you have like two to the 23. That's limited today.
00:38:00.334 - 00:38:02.396, Speaker B: And then on the other side you can change that.
00:38:02.418 - 00:38:25.504, Speaker A: But yeah, and then on the other side you have all those columns. And each column essentially represents some kind of variables you're introducing in each of those circuits or processors. And then eventually you get the entire table filled with the execution trace. And then you kind of commit to that.
00:38:25.542 - 00:38:54.268, Speaker B: Yeah, I mean, this, each column is a polynomial, and then you commit to all of them. That's very much what you do here. There is a lot of things to talk about. But yeah, the main architecture, I think these are the main pieces. And with this you can have more or less an idea how everything works. Of course there is the details where things get more complex, but yeah, this is very much the mainly there.
00:38:54.354 - 00:39:19.360, Speaker A: Okay, maybe we can switch to talking a bit about how the KVM works on the high level from a roll up point of view. I think so far we've been talking mostly about how it works from a decay or like a computation point of view. But there is still this part of how it works is like l two, because it ties in the sequencer interaction with l one and l one to l two messaging.
00:39:19.440 - 00:40:09.590, Speaker B: Yeah. At the end, this is just food technology to prove how we see this prover at high level. I mean, the prover is, okay, this is like a normal, I mean, you have a state route you have a set of transactions state transition function. So if you have this state route and you have these transactions, you get to this new state root. Yes. Okay, so here at the end, the prover altogether at the end is a piece of code that, okay, you give them this, this and this, and it generates a proof that actually this is correct. I mean you cannot generate a proof with a different state root than this other one.
00:40:09.590 - 00:40:16.246, Speaker B: So this is the proverb. You can understand it as a black box that actually does that.
00:40:16.268 - 00:40:16.406, Speaker A: Okay?
00:40:16.428 - 00:40:56.626, Speaker B: But then you need to fit that in a system in a L2. So how the L2s work. And here of course there are different L2s and can be some detail also on the way, I'm going to explain very much how the polygon sick AVM works, but it's not very different than how other l tools works. So the idea here is the best way to think about this. So we have a network that's running, okay? So we have a state route. And sometimes it's evolved so some transactions are sent, but it's a different chain. I mean it's not ethereum chain, it's a different chain.
00:40:56.626 - 00:41:31.036, Speaker B: That's why it's a different network somehow. And here is when you want to submit something to the network in general, the first thing you do is we carry the sequencer. The user just sends this to a sequencer. In this case, imagine that's a centralized sequencer, okay. Just a server that's getting the sequencer, okay, the sequencer sequence that transactions. Actually sequencer is building these blocks, okay, so it's building state. Actually it's building here.
00:41:31.036 - 00:42:03.000, Speaker B: The transactions, it's pulling all these transactions. Transaction one, transaction two, transaction three, transaction four, maybe here, have a new estate. It can be a batch or different blocks, okay? But at the end it's sequencing transactions. It's getting the transactions and putting them one after the other. Okay? And if you trust the sequencer, you don't need anything else the sequencer gives you. It's like a normal blockchain. If you're in a state, the state is valid, okay? But of course the sequencer can lie.
00:42:03.000 - 00:42:49.860, Speaker B: If you want to build that, you go to a bank. That makes no sense. Okay, so the sequencer, what it does is once in a while maybe when it gets maybe a bunch of transactions or after a timeout, it sends this information to the main net, to the l one, just take. And it's just sequencing. And here this is the l one, okay? And actually with this step so they don't tell which Disney was state. It just put the transactions, actually it just take the transactions and they put them there. Okay, so at this point the transactions are final.
00:42:49.860 - 00:43:16.136, Speaker B: I mean, these are committed. Anybody? So the thing is that the blockchain doesn't know what's the current state. But they know that the transactions are going to be executed with this order. And because this state transition function is deterministic. And one property that maybe, I don't mention that all the transactions are valid or are executable, maybe they are not valid. But imagine that not valid transaction is just an operation transaction.
00:43:16.168 - 00:43:17.264, Speaker A: You just don't modify the state.
00:43:17.302 - 00:43:59.436, Speaker B: Okay, so you deterministically, when you have a set of transactions, you have a state, you have a set of transactions, you deterministically, you compute what's the newest state. So at this point, without generating any proof yet, just putting the transactions here, we already have a blockchain. The problem of that is that the people needs to, there are many problems with this. So one problem is that people needs to follow the full chain. I mean, it needs to compute the change from the beginning if you want to know the current estate. And the other problem is that this is, okay, so when you want to withdraw funds, they have withdraw funds. The folks are stuck in Nell one.
00:43:59.436 - 00:44:32.756, Speaker B: So hotel one knows that this estate is actually valid, you're valid and you can withdraw funds. Okay, so here there is another process, different actor in parallel. We call it the aggregator that actually is seeing what's in l one. I mean everything that's committed. And they are generating these proofs. So they are generating the proof, computing the newest state and generating the proof that this estate is actually this one. Okay, so at here we have, we call it an implicit estate.
00:44:32.756 - 00:45:07.528, Speaker B: It's a state that is known, but it's not on blockchain. But this guy is because the proof is sending the new estate here you are sending the state and with the proof, and this proof is verified on chain. So you know that this estate is correct. And it's at this point where you can withdraw the funds because you already know the state this estate can include. So what exits you can do. So you can this point for free, you can exit. Okay, so this explicit state, this is the approver and this is important for withdrawing the funds.
00:45:07.528 - 00:45:23.030, Speaker B: For example, in optimistic roll ups, this stage is much longer process. Well, yeah, because it's a process for, it's a challenge process. And then you need to give time for others to prove. We call.
00:45:25.020 - 00:45:26.116, Speaker A: Challenge period.
00:45:26.228 - 00:45:28.984, Speaker B: Yeah, it's a challenge period that you need to deal with.
00:45:29.022 - 00:45:29.320, Speaker A: Okay.
00:45:29.390 - 00:45:48.712, Speaker B: But in SDK roll up this time. So you just generate the proof and that's it. You know, if the proof is well generated and the proof system is correct, you know that this state is correct. So you don't need to wait anything more. Yeah, this is the big difference between one or the other, this transition. Perist.
00:45:48.776 - 00:45:49.390, Speaker A: Yeah.
00:45:49.700 - 00:46:09.364, Speaker B: So there are some details on the breach. I mean, hope we got the idea of the level one. L two is like you need to be able to transfer funds from l one to l two and transfer back. And here there is a mechanism, special mechanism, it's a trustless bridge, kind of automatic. And some mechanism that happens here. Here.
00:46:09.402 - 00:46:25.048, Speaker A: Okay. Actually, yeah. How about we just talk about the bridge? Because there needs to be like a mechanism to communicate between the l one and two. Like people needs to be able to deposit and then withdraw their funds back. And then maybe l two also needs to read the l one state and things like this.
00:46:25.134 - 00:47:22.744, Speaker B: Yeah, let me explain. You give you the big picture of how it works. The idea is that when somebody wants to send funds to l two, actually here what you do is, well, you send the funds to l one, you send the funds to some smart contract in l one. And this smart contract builds, what we call it is a global axit tree. But in the case here, what you do is this is built in the smart contract and it's a pen only tree. It's very much like when you are depositing something for staking in Ethereum, you're just sending funds there and you build a miracle tree of all the funds that are set there and one leaf for each deposit. So this global exit route at some point, and this is part, I mean, when I pin the sequencer, at some point, the sequencer.
00:47:22.744 - 00:48:06.492, Speaker B: But in this sequence here, actually, you are including the global x tree and putting this global xit tree in the root, in the state tree of delta, this is done automatically in this mechanism. Actually, here is the sequencer can include this global XC three whenever he wants. When you are doing this sequencer, you verify that what you are putting there is the correct one. And even more than that, I mean, the sequencer in this transaction, in the smart contract, it's forced that you include the roots. Yeah. And this is very important for what we call it the force transactions. But you are putting this.
00:48:06.492 - 00:49:01.096, Speaker B: So you are sure that if you are depositing here, this is going to be including the state tree. So this global exit route, I mean, this route of all the deposits that you are doing at some point, this is going to be available in the altos. This can go really fast because the sequencer don't even need, what they will do is they want that this is final. But once this is final, so they don't need to y to approve. They can include quite fast. Okay, and once this global xc tree is in a smart contract in Delta, then in Delta what do you do? Is a claim, a claim, I mean it's in this smart contract in Delta. And here you can do mainly what you do is, okay, you get the funds, the ones of course they need to match in the exit tree and needs to exist.
00:49:01.096 - 00:49:46.936, Speaker B: And then of course you just check, I mean you just mark that you cannot withdraw the funds twice. I mean, you just put that this leaf is already used, so you cannot use it again. So this is how you transfer from l one to l two. And for the twelve two one, the mechanism is very similar, but the other way around, in each same machine we have like the local exit route. So when you are in l two now, and you want to withdraw the phones in l one, actually what you are doing is you are sending those phones to l one. So you are creating this tree in l two, you are putting a leaf in these l two s. There is a mechanism for synchronizing this root of the l two to the l one.
00:49:46.936 - 00:50:24.650, Speaker B: And then in the l one you do the same. I mean you have this mechanism you can do, you do withdraw, you prove that this leaf is in there, that you have not used that leaf before. And then you get the phones back. But the mechanisms for updating the local exit route in l one, this happens in the prover, in the proof side. So you need to prove that actually this is the newer state that includes this global execute. Actually, to be more concrete, the prover that I mentioned here is state I. This is a state I plus one.
00:50:24.650 - 00:51:08.592, Speaker B: You are proving that. Go from one state to the state. Here we are also saying the local exit tree, this local exit tree is updated in the smart contract in l one. So every time that a proof is generated, that the proof is generated, we update the local exit tree, I mean all the exits of the l two. We update it in l one so that we can withdraw that in l one. Here to mention that this proof is not one proof per batch, okay, it's a proof that we can aggregate many proof. So the idea is that we can have like 1000 or 100 batch and we aggregate that in a single proof.
00:51:08.592 - 00:51:23.560, Speaker B: For example, we are doing, I think we are sending now one proof every half an hour. And in half an hour maybe there is, I don't know, 1000, 2000, 10,000 transactions. Batches. Yeah, batches. And each batch has a proof. And then we aggregate all the proofs in a single proof. This is the aggregation.
00:51:24.700 - 00:51:27.630, Speaker A: Is this mostly down to save on cost?
00:51:31.360 - 00:51:38.076, Speaker B: Mainly, yeah, because I mean, but it's not the proving cost. If you have to send one transaction.
00:51:38.108 - 00:51:42.576, Speaker A: Yeah, the cost verification on l one, it's not cheap, it's not the cost.
00:51:42.598 - 00:52:24.670, Speaker B: Of verification, but it's even the cost of sending a transaction, sending a transaction, updating all these rules and all that stuff. And it's called you pack all together, you convert something that would be a variable cost with something that's just a fixed cost of the network. Well, in the polygon, in the data, in the polygon 20, the idea is not to have one single proof per chain of many batches, but have one single proof. For all the chains of polygon 20, there is an optional if you are a chain, you want to generate your own proof, that's fine, but it's going to be a mechanism that with a single proof we are able to verify all the chains at a time.
00:52:25.920 - 00:52:42.580, Speaker A: Okay, so on the l one to l two interaction, how does forks on l one handle that? I assume, for example, on the sequencer side, when it needs to read l one state, it needs to read the final state. Unless the sequencer itself has a way to revert when l one reverts.
00:52:42.920 - 00:53:06.412, Speaker B: Well here, yeah, what we're doing is the sequencer. So when you're sending the sequencer here, it needs to be correct. So you cannot sequence something that you cannot sequence a global exit route. That's not final? Not final. This is l one. So you don't need to be final.
00:53:06.546 - 00:53:07.132, Speaker A: Right.
00:53:07.266 - 00:53:31.892, Speaker B: But the sequencer in general is going to wait for the finality in l one, because if it changes, then all the state that needs to revertage, it will need to revert in there. So it's more practical right now to just wait a couple of epochs in ethereum and you know that for sure that's final.
00:53:31.946 - 00:53:36.996, Speaker A: And then you can, and then what about the l two to r one.
00:53:37.018 - 00:54:05.180, Speaker B: Is not much a problem because of the problem that you send the proof. So when you are sending the proof, you are ready committing to there, it doesn't matter. I mean, if you reverted, the proof will be reverted too. And the withdrawals that you can be done later on will be reverted too. So not a problem on that side. But yeah, the sequencer here is finality in l one is important for the deposits.
00:54:06.160 - 00:54:31.304, Speaker A: Yeah, makes sense. Okay, so, given that we are kind of about to run out of time. And we also cover both kind of the roll up side as well as the decay side. Is there anything else you want to talk about? Maybe like the future of polygon decay VM. Or how do you see this whole thing. Including Polygon CDK, evolving in the future?
00:54:31.342 - 00:54:53.560, Speaker B: Yeah, well, in polygon, we are building this Polygon 20. This is what we call this constellation of roll ups. Or chains of different chains. And the idea is that they can share the same liquidity. And because of this zero. I mean, this single proof. That somehow validates the chain of the full network.
00:54:53.560 - 00:55:14.790, Speaker B: This can be seen very much like a clock. I mean, imagine that this proof happens every 30 seconds. That means that if you have different chains. You can transfer from one site every 30 seconds. So you can see the full constellation of roll ups. I mean, the full polygon 20. Very much as a single chain here.
00:55:14.790 - 00:55:34.730, Speaker B: Interesting things that you are doing are important. This intercharding communication, for example. Is something that's super interesting thing to look about. Or even the data availability is also another point. I mean, here there is a lot of points of exploration. That we can learn from each other.
00:55:35.200 - 00:55:41.388, Speaker A: What about on the decay side specifically? Where do you see the new breakthrough on the decay front?
00:55:41.554 - 00:56:06.804, Speaker B: Well, the CDK, of course. For example, for us, having Zkwasm as an option for chains. In the Polygon 2.0. This is very important. I think this is giving the options to the users. To the applications to develop in WaSm. The ZDK opens up the market for this.
00:56:06.804 - 00:56:30.444, Speaker B: This is really important. But here, I would say I'm more worried, more in the short run at this point. We have right now constellation with one single star, like the ZKVM. We need to put the next star. And from here start growing. I mean, this is for the next years. And here we'll start connecting all these things.
00:56:30.444 - 00:56:44.652, Speaker B: And see how the things are evolving. I mean, there is a lot of you do the ZKVM. But then it's like you open a new world. And we are starting now. That's very much where we are at the beginning of everything. Cool.
00:56:44.706 - 00:56:51.810, Speaker A: That's a very exciting future. And again, thanks, Jordy, for joining me. For another episode of the Whiteboard session. And thanks everyone.

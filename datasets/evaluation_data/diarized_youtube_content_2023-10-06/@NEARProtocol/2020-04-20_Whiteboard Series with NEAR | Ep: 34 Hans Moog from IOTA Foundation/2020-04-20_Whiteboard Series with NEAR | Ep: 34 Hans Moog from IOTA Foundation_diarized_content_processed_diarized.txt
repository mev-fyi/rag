00:00:00.250 - 00:00:21.438, Speaker A: You okay? Hi, everyone. This is episode 34 of Whiteboard series. We're in the middle of the outbreak, so the format changes accordingly. With me today is Hans Mogg from Iota foundation. And we will talk about Iota. We will talk about cordicide, the effort of removing the coordinator from IoTA. And we're probably going to talk about sharding as well today.
00:00:21.438 - 00:00:26.550, Speaker A: So, Hans, would you like to introduce yourself and give us an overview of. Of Iota?
00:00:27.050 - 00:01:03.280, Speaker B: Yes, I am Hans Mourk. I work for the IoTa foundation as software engineer that is deeply embedded also in the research department, because I'm responsible for writing the first prototype of Goshimmer, which is our prototype implementation of the cortisite version of IoTa, which is essentially a complete redesign of the protocol. We change a lot, the data structures, the algorithms, how stuff gets processed. And, yeah, I think it's a really nice format to be able to share some insights here to explain how things work and to answer questions, maybe also to get some critical feedback. Yes.
00:01:03.970 - 00:01:15.186, Speaker A: Cool. And can you give us an overview of what Iota is and what problems cordisite is trying to solve and how it's going to solve them and maybe the grand vision as well?
00:01:15.368 - 00:02:27.980, Speaker B: Yeah, I think Iota is actually. That's a good question also regarding the grand vision, because I feel like IoTa is a little bit one of the lesser, well understood cryptocurrencies in the space. Not just because we're using a dAG, which is not the same as a blockchain, and therefore works a little bit different, but also because the way we approach this whole DLT space is slightly different than how others do it, especially when it comes to our sharding solution. I think that will also become a little bit more obvious once we start talking about the technicalities of this. We are, as I said, a DAG based DLT. And the idea and vision is to create a system that is able to process millions, maybe even billions of transactions per second in a network where you don't have any fees, where machines can consequently execute microtransactions. And you can have, like, self driving cars paying for gasoline, you can have, I don't know, machines renting electricity from energy providers, and essentially just a platform that would allow you to implement this whole machine to machine economy and like the next industrial revolution, how it's usually called, of the Internet of things.
00:02:27.980 - 00:03:18.300, Speaker B: Yeah, that's the grand vision. And we usually also receive a lot of criticism because things like zero fees, for example, are something that is a bit controversial, because, as soon as you have a network and nodes have certain resource constraints and you have potentially unlimited demand, then how would you achieve that? You could have the throughput that you need, but also, at the same time, the security that you need without the network being overwhelmed by the corresponding load. And also here, our approach to sharding plays a really important role. And, yeah, I hope that we will be able to answer some of these questions around our concepts, our vision, and how everything is supposed to work. Yeah.
00:03:18.670 - 00:03:20.380, Speaker A: Cool. Let's dive in.
00:03:21.150 - 00:03:59.340, Speaker B: Yes, I've seen some other whiteboard series before, and usually people start more or less from the basic, like, how does technology in itself work? I want to also kind of do this in the same way, but I want to jump to start with our grand vision and the way we plan to shard the dag and maybe also talk a little bit of the benefits of a dag. And essentially, I've prepared here some pictures, and this is a little bit how a dag looks like. You have, like, a Genesis transaction, then you have. Do you, by the way, see my mouse on the screen?
00:04:01.310 - 00:04:04.922, Speaker A: No, I don't think so. Actually, I do. Yes.
00:04:04.976 - 00:04:37.742, Speaker B: Yeah. Okay. I was on the wrong picture because I saw the presentation window. So we have, like, a Genesis transaction, which is essentially the same as the genesis block in any blockchain. And then whenever you send transactions around in the network, when you issue a transaction, the user itself creates this transaction and attaches it into directed Astiklicrav, where all the links always follow, go from one side to the other. There's essentially what a dag means. And then other people can see these transactions.
00:04:37.742 - 00:05:09.322, Speaker B: They can verify if the transaction is valid, if it's a double spend or not. And if they like the transaction and say, like, I approve this one, then they can reference it as well, and then others can reference it. And then essentially, you have this structure, which grows over time. We're also pretty similar, as in bitcoin. You have more and more approvers of something that happened in the past. And at some point, the idea is that you can decide, okay, this is confirmed. And the network, of course, needs to come to an agreement how to deal with double spends.
00:05:09.322 - 00:06:06.978, Speaker B: And the big pro of this approach is that you don't need any miners, so you also don't need to wait for anybody to confirm your transactions. But you can just attach anywhere where you want, and you can also make the dag wider as the load increases. And this is essentially one of the big, beautiful things of dags, which somehow not really a lot of people are actually using in their sharding concepts. But the big benefits of a dag is that it essentially can split and get wider and wider and wider. And if we have here the situation in an unsharted network, where every transaction indirectly references each other transaction, and then at some point, if the load increases so much that the nodes cannot process everything anymore, then it is possible that's just the first step. We would go step by step and develop like an even much more beautiful charting concept out of this. But the nodes can essentially split up.
00:06:06.978 - 00:06:33.530, Speaker B: And one could say that 50% of the validators would live in shard one, in shard one, and 50% of the validators would live in shard two. And then you would essentially be able to balance the load in the network, and you can do this arbitrarily. Often that means that the more nodes you have, like the more activity that we have in the network, the more often this network can split, and it can essentially accommodate for any kind of load you throw at the network.
00:06:35.390 - 00:06:54.282, Speaker A: So I have a question here. So we didn't quite get there yet, but from what I remember about Iota, the way I remember Iota designed, there was no concept of validators. So is it a concept now in the cord side, or are you referring to the transaction issuers as the validators?
00:06:54.346 - 00:08:10.466, Speaker B: The transaction issuers, or actually the nodes that run the network. So the transaction issuer can also be just a client. I mean, the ultimate vision is that essentially every human being, every machine, and everybody who wants to use the network will have their own node. And I think that this vision might sound a little bit unrealistic in the current market adoption, because you have network sizes typically of maybe a few thousand nodes. Right? But the problem with crypto is that if you're not running your own node, then what you're most of the time doing is that you're interacting with the server of somebody that you're requesting for payment statuses, where you get some answer back like, is my payment confirmed? And stuff like that. But what I'm doing in that moment is I'm essentially trusting a third party that he didn't give hand out, like fake API responses where he just said a flag to essentially tell me that my payment was confirmed, when in fact it was not. So I think the logical consequence of DLT in the future, or the whole DLT space, will be that we will see network sizes of millions or maybe even billions of devices that are trying to connect to these networks and interact on these dlts.
00:08:10.466 - 00:08:47.890, Speaker B: And obviously we're not really there yet, and there's still some work that needs to be done. But that is essentially the ultimate vision. And because we have that many nodes that are acting as validators by choosing the point where they essentially want to attach their transactions, we have what we call the tangle, which looks a little bit like this network, which grows into one direction. And as I said, if you then separate the nodes into two different groups and say this is shot one, this is shot two, then if this gets too much, then you can split it up again, and you can split it up again, and then the network just grows wider and wider and wider.
00:08:48.230 - 00:09:21.162, Speaker A: So I have a question here. Right. So in the example you described where I'm connecting to a server, right? So if we use Ethereum as an example, in Ethereum, what I can do is instead of running a full node, I can run so called lite client, where I validate proof of work, but I don't validate blocks. And so I don't even have to download blocks in this case. Right. But if I'm connecting then to someone, because there is a Merkel proof, there is a merkel root of the state in every block, then if I make a request about the state, then they cannot flip a bit. Right, because it must match the merkel proof.
00:09:21.162 - 00:09:29.978, Speaker A: So do you consider those light clients as nodes or how do they fit into the. If we try to compare IoT and Ethereum.
00:09:30.154 - 00:09:38.082, Speaker B: Yeah. Everything that would gossip messages in the network and would essentially take part in the peer to peer communication would be a node.
00:09:38.226 - 00:09:39.030, Speaker A: I see.
00:09:39.180 - 00:10:21.218, Speaker B: Yeah. In our case, we also have different kinds of nodes, like ones that store stuff much longer, some nodes that store things just for a certain amount of time, because we also have a feature which is called snapshotting, which means that you can cut off the dag at some depth. When you say transactions are so old that nobody's going to attach there anymore, then you can essentially throw them away and condense the whole state into an aggregated ledger state. So it becomes much easier to store all of the information in the dag. And also smart contracts, something that we're going to plan on implementing. And there's going to be like a prototype soon also. But in Iota, smart contracts are not layer one, L2.
00:10:21.218 - 00:11:22.210, Speaker B: So that means that you have nodes which can then decide to take part in the smart contract computation, whereas other nodes who are only interested in doing payments can, for example, decide to only do the payment aspect. And the reason why I said that in the case of Iota, it's kind of problematic that you need to trust the node is because a lot of the clients are supposed to be IoT devices, which may be also something I should have said in the beginning, that Iota has a strong focus on delivering a platform where IoT devices can connect to each other. And most of the times these devices don't necessarily have the computing requirements to do these kind of checks or like store the corresponding block headers for a long time to do these kind of verifications. And also the problem is that as soon as you're cutting the dag, it's not that easy anymore to validate these kind of chains, as you can easily do in a blockchain, for example, right? Maybe less of a problem, but in a dag where you have this loose structure, it becomes a bit tricky.
00:11:22.730 - 00:11:47.360, Speaker A: But interestingly, in ethereum they also do cut out the old history, right? So majority of nodes in Ethereum today, they do state sync into some recent block. And there's quite a bit of controversy between bitcoin community and ethereum community on whether such a node can be considered fully secure node. So I think there's a lot of similarities here.
00:11:48.050 - 00:12:25.420, Speaker B: I guess as soon as you move to proof of stake, it doesn't make such a big difference anymore anyway, because you have this problem of the weak subjectivity that somebody comes new into the network who doesn't know anything, he needs to bootstrap somehow and get his information from somewhere, right? And in that moment you're also susceptible to attacks. But as soon as you're in sync with the network and you see the current state, and then you can also relatively cheaply keep track of the changes without having everything that happened up to the Genesis, right? But I mean, of course if you're like super paranoid and you want to sync everything that ever happened in the network, then you can still do that. No, but I agree.
00:12:26.910 - 00:12:29.530, Speaker A: And so is the core decide proof of stake.
00:12:31.790 - 00:13:43.714, Speaker B: It's a proof of stake variant, I would say, because the way proof of stake usually works is that people take their funds, they lock them in on a certain address, then they get a certain say in the network, be it in the voting or like in intervals, however often they can propose blocks and stuff like that. But to stake your funds because you're kind of like blocking them from using them in an everyday life, right? You would usually expect to get some kind of reward also because it comes with a chance of losing your funds, because if you know it sends something that you shouldn't do, presents block on two conflicting chains for example, then it might happen that they slash your funds. And since we want to be fearless, because we expect these IoT devices to not have things like we have in the human world today, where you make bigger payments every now and then as part of some contractual agreement between me and you, for example. But machines will most of the time trade face to face. They don't know each other. Maybe they will never see each other. Like a self driving car, for example, that is driving around as an autonomous taxi in a big city, for example.
00:13:43.714 - 00:14:43.494, Speaker B: It will have to drive to different gas stations, or like charging stations all the time. And if there may be also decentralized, and we don't have these centralized providers that provide this infrastructure, then it would be very tiresome to have a contract with each and every one of them and maybe pay like a flat fee up front. And it seems to be a much easier way to allow transactions to be in the form of micro payments, where I can even send like fractions of a cent for use cases. For example, in a highway, I do things like platooning, where a lot of cars are driving behind each other, and they synchronize their behavior, and they essentially save some fuel costs like this. And the idea is that you could, for example, as a car that is driving behind another car, that he could pay the guy in front of you some of the savings, so he's willing to inform you about the things he's going to do, like if he's going to do braking or something, that he just gives a, sends you a short notification so your car can drive really close to that car.
00:14:43.612 - 00:14:44.038, Speaker A: Yeah.
00:14:44.124 - 00:15:41.814, Speaker B: So that's the whole motivation. And because we cannot make this staking in a way that we make people lock in their funds, we thought about a different way of antisibility mechanism, which is called mana, and it's also an antisibil mechanism that is based on the coin supply within the network. So you have like a limited resources that is not so easy to attack from outside point of view, because you can simply not create an unlimited amount of coin supply. And what we're doing is that every node identity, or like nodes have identities, it's just like public private key pair, right? So you can sign your messages and you can validate if the message isn't really coming from a particular node. And if I have a certain amount of coins for a certain amount of time, then I multiply these two values. It's just a simplified version. The actual formulas are a little bit more complicated, and then I receive a certain amount of reputation.
00:15:41.814 - 00:16:07.140, Speaker B: So that means every transaction that is processed in the network gives the nodes a certain reputation based on how much stake they had in the network for how much time. And this gives us essentially a perception of what nodes exist in the network and how much weight they have in that particular moment. And it's not that different from proof of stake, but it's slightly different.
00:16:08.150 - 00:16:23.558, Speaker A: And with those, are there some specific kinds of transactions with mana, or is it just naturally fits into the existing dag? If I submit a transaction, does it automatically vote, or do I need to attach any message to it?
00:16:23.644 - 00:17:02.382, Speaker B: No. The moment you send a transaction, you look up in your ledger state, when were the funds moved the last time? You multiply it by the time. So, like, sending funds in circles just always to yourself, for example, doesn't generate any extra money. You really have to wait. So we combine the token amount with something that you cannot really buy time. And then as soon as you issue that transaction, the node that you use to issue that transaction receives this amount of reputation as just a numeric value on one of these balances. And since everybody sees that transaction, in the transaction, you have a field who's like the beneficiary of the mana.
00:17:02.382 - 00:18:04.886, Speaker B: Then you kind of assign the weight to the node. And even in the beginning of the network, where you have a lot of public nodes and people sharing nodes and their community run nodes and stuff like that, the basic assumption is essentially that, that the nodes that are entrusted by the people to issue their transactions and interact with the network are most probably also relatively good recipients for this kind of mana because they are trustworthy nodes from the community, they have most probably been there for a really long time, and people have good opinions about them. So that's essentially the basic idea. So you kind of turn the staking a little bit on its head to make it easier, and therefore also get rid of the problem that you would have to otherwise pay people an incentive to stake. And because every single transaction always stakes at all times, it also means that it's very unlikely that you only have a certain percentage of the funds that are staked, but you will always have a very large percentage of the funds being staked because everybody always takes it all the time.
00:18:05.068 - 00:18:33.462, Speaker A: Right? And my question was also about the fact, not about the fact, but about how is that mana used, right? So that man has the anti civil resistance mechanism. Is it just so, let's say I see two dags and they're clearly conflicting, for example. Right? So do I just see which one has more mana accumulated in it in the transactions, or do they actually explicitly vote in the dag?
00:18:33.626 - 00:19:22.938, Speaker B: Well, we use random subsample voting in the current quarter site proposal that we're working on. There's also some other ideas floating around, but it's maybe something we could discuss at another time. But currently it's random substantial voting. That means me as a node, I join the network. Of course, if I see those two conflicting decks, for example, then I can just accumulate all the mana, and the honest one most probably has more mana, so I can make a very easy decision which one is the right one. Right? Like which one is the correct one, because it's just the one that has more economic activity in it. Assuming that nobody has that much control over coins, that he could create something from the genesis which is heavier than anything that gets used in the current mainet.
00:19:22.938 - 00:19:47.720, Speaker B: But these are the typical long range attack things that any proof of stake based chain has as well, and which have turned out to not be that problematic in real life. And of course, you always have the ability, as somebody who operates a node, once you sync it the very first time, to just verify that the transaction that you're seeing are in fact the same ones as everybody's seeing as well. And once you have done this initial bootstrapping, you're good to go.
00:19:50.730 - 00:19:51.334, Speaker A: Ahead.
00:19:51.452 - 00:20:36.790, Speaker B: Yeah, I just want to finish. So, deciding which one is the correct tag when you first synchronize, that's happening just by reading, like, which is the heavier one. But once you have established a certain perception of weight in the network by reading and receiving all of these transactions, then what you do is that you do this random subset of voting, which is essentially like a poll before, like an election, you just choose a random subset of the people that you know, you ask them what they think about a certain transaction, they give you the answer. And if most of them say, I think this transaction is really good, then you follow this outcome and you change your opinion, and other people ask you as well, and you repeat this process a few rounds, and then after a short amount of time, you reach consensus.
00:20:37.450 - 00:20:48.358, Speaker A: So you mentioned that when I just bootstrap, I look at the heaviest graph, right? So heaviest is in terms of what is the weight? When we talk about the heaviest?
00:20:48.534 - 00:20:52.880, Speaker B: Yeah. The accumulated mana in these, it's like an accumulated mana. I see.
00:20:55.250 - 00:21:10.066, Speaker A: And how does mana accumulate? So if I post a transaction, a mana of a particular node, you're saying, is equal to the product of their coins multiplied by the age of every coin, right.
00:21:10.088 - 00:21:54.106, Speaker B: Effectively it's a little bit different. I mean, mana, there's different mana versions or like mana concepts in the whole system. So mana is essentially just like a funny word that we came up with because nothing else seemed to fit and we were all a bit nerdy and thought it's a nice name because it's refilling over time. As you issue new transactions, you can also spend it and stuff like that. But for measuring the economic activity, it's essentially just a sum of all these differential mana bookings that you see in the network. So that means if I send 1000 coins after 100 days, then that's 100,000 mana, kind of. And then if the next transaction, then after another 100 days sends the same amount, then that's like 200,000 mana.
00:21:54.106 - 00:22:11.430, Speaker B: And if people send like 50 coins after ten days, then it's 500 mana. And you just accumulate or sum up these values over time. And the one that is the heaviest one is then the one that is supposed to be used for the initial syncing, for example. But once you have established this initial perception, you do this voting on a second layer.
00:22:11.770 - 00:22:34.542, Speaker A: So effectively, when a transaction is issued, the transaction makes the graph heavier by the amount of money transferred in the transaction multiplied by how much? By. So you're saying if this is Utxo, right, so effectively, when I issue a transaction, the weight of the transaction is the size of the Utxo multiplied by the time from the moment the Utxo was created until now. I see.
00:22:34.596 - 00:23:09.830, Speaker B: Yeah, exactly. But it's not that the transaction itself carries the weight in the case of the voting layer, but it's that the nodes get through their identity, get this weight applied to them. So that means the node has a certain mana and a certain importance in the network. And even if he issues just a small amount of money, like he just does a small token transfer, for example, then the weight of the node that issues, that is still orders of magnitude bigger than the small transfer, and he adds his full weight to this particular decision.
00:23:10.250 - 00:23:36.062, Speaker A: But let's say I have 1000 tokens, right? 1000 iota tokens. Let's say it's a lot. I don't know the full supply, but let's say 1000 is a lot. And then let's say that, that 1000 I had since Genesis, right? So I'm one of the early people, and it's been many years from Genesis, and then I start sending a lot of transactions. Each one transfers 0.1 cents. Does every transaction add 1000 multiplied by all this time to the weight?
00:23:36.206 - 00:24:06.380, Speaker B: That's why I said also, it's a simplification, but it's a pretty good thing to understand. And what we added here, you always have this problem on proof of stake. Like, the rich are getting richer and all these game theoretical problems that make it a bit challenging. And we thought, okay, how can we get around that? I mean, mana is not directly convertible to tokens or anything. You cannot really trade mana in that sense. It's really tied to one identity also. So as an attacker, I cannot just buy huge amounts of mana and then associate that with my id.
00:24:06.380 - 00:24:52.230, Speaker B: But let me paint something here. So what we're essentially doing is if you have a certain token supply, which is like the amount of tokens that you have, right? And then you have time t. And this is mana, then the mana that you generate from an address develops a little bit like this. So it's called a demorush function. On top of that, it's an exponential decay. So the mana is growing on that address, but at the same time, the decay rate is also increasing. And that kind of balances out to have this kind of mechanism.
00:24:52.230 - 00:25:07.600, Speaker B: So if you're spending something for a large amount of that you held for a really long amount of time, then you will not generate much more than somebody who regularly uses his tokens and spends it here, and then starts accumulating again, for example.
00:25:08.210 - 00:25:47.420, Speaker A: Right? But my question is, so let's say I'm somewhere over here, right? So I'm somewhere like, in terms of time, I managed to get to this moment, right? And then at that point, let's say I issue two transactions. So let's say this amount of mana is like. Let's say it's x mana, right? And then I issue two very small transactions. So I issue one transaction which transfers 0.1 cents, and then another transaction that transfers 0.1 cents on top of that one. So did I make the graph from perspective of the person who just sinks into the network? Did the graph became x bigger, or did it become two x bigger? Right.
00:25:47.420 - 00:25:52.750, Speaker A: Does all my mana add up to the graph weight every time I issue a transaction?
00:25:54.050 - 00:26:08.274, Speaker B: No, actually, there is two versions of mana in a way. Like, you have potential mana, which is the one that is associated to the funds on an address. And that grows in the way I've described here.
00:26:08.392 - 00:26:10.660, Speaker A: So that is used for voting. Right?
00:26:13.670 - 00:26:15.650, Speaker B: No, wait, I will come to that.
00:26:15.800 - 00:26:16.258, Speaker A: Sure.
00:26:16.344 - 00:26:50.154, Speaker B: This is essentially the mana that is residing on an address. So the address has a certain amount of funds, and I have held it a certain amount of time. So it can generate a potential mana or a potential weight of this amount. Right? And then the node has a balance, like an account, and he has maybe no mana. And then as soon as you issue this transaction, the potential mana gets transferred to the node. But we also have a moving average over this. So this will not just jump up immediately, and then from that point on you will also again have a decay.
00:26:50.154 - 00:27:45.470, Speaker B: So if the mana will over time lose its value. So if the node is only used, like only sees the transactions this one single time, then over time it will lose its importance again. And here the potential mana in that moment on that address, because I moved the funds just now, would drop to zero, and then it would again start to gain weight, essentially. And as soon as I do the next transaction, then I would get on my, I don't know, let's say the mana has dropped to here by that time, and then I get another value on top. So that means my mana would fluctuate a little bit, like depending on how much activity a node processes. But nodes that are online constantly, that are processing payments of users or machines that are interacting constantly, they will have a pretty constant amount of mana, which is kind of at a certain level. And we also have math papers and stuff like that where we discuss these kind of things and also name of the formulas and everything.
00:27:45.470 - 00:27:49.220, Speaker B: But I think that would be maybe a bit heavy for now.
00:27:49.670 - 00:27:59.710, Speaker A: Okay, so even if I transferred a very small amount, like let's say I transferred 0.1 out of my thousand, my mana temporarily drops to very little number and then it starts.
00:27:59.870 - 00:28:15.770, Speaker B: No, it depends. If we have all of them in the same Utxo input, and you move the whole funds, then you would jump, like, then you would get accounted for the whole mana that you have. But if you have them on multiple different utxos, for example, then you could also spend them separately.
00:28:18.190 - 00:28:36.820, Speaker A: So let's say on the left chart, right? So let's say I have them on multiple utxos, but because it's the same node, they all contribute to the same manner. Right? And so let's say I spent. So I have 1000 tokens total. One of the utxos only has one token, and I spend that Utxo, then my mana goes down by how much.
00:28:37.910 - 00:28:41.810, Speaker B: This curve is valid for. Every Utxo has its own curve, kind of.
00:28:41.880 - 00:28:44.402, Speaker A: Oh, every Utxo has its own curve. Got it? Yeah, I see.
00:28:44.456 - 00:29:09.494, Speaker B: So that means if I move one, then this one has maybe generated this much amount of mana, like, I don't know, one. And then I will get that amount of value booked into my node identity. Then it starts decaying. But at the same time, it's also growing. It's essentially a symmetric function, so it doesn't really matter how long you hold the mana. The ultimate mana that you have in the system that you can utilize is more or less constant. The moving average changes it slightly.
00:29:09.494 - 00:29:38.440, Speaker B: So through a certain behavior, like, maybe it's better to not wait until it reaches the top here, but already spend your mana here if you want to, your funds here if you want to, for example, use that to maximize your mana, which has some positive effects, because we use mana not only for voting, but also for things like rate control and stuff. So then you can game your mana to be like 1% higher or something, but it's not very big, right.
00:29:40.330 - 00:30:14.660, Speaker A: The way I see it, and maybe this is wrong. So there are two ways where I see right now mana being used. So one of them is voting, right. If I do voting, if I sample the notes, a mana weighted, right? So if I have two peers and one peer has one mana associated with the note, and one peer has 1000 mana, then presumably I treat the vote from the second one to be 1000 times more important. But you also mentioned the second use of mana is when I'm just synchronizing, right? I'm looking at the graphs, and the graphs have weight. So there's also mana on the weights, right.
00:30:15.510 - 00:31:04.794, Speaker B: That's why I said we have multiple different versions of mana, and they get all used slightly differently. For example, in this other consensus mechanism that I mentioned early on, where we're not going to talk about today, there, we also use a different metric, how we sum up this mana and tie it closer to public measurable behavior rather than just a movement of funds. But the mana is essentially just a base metric. But you can use this mana, as I said earlier, to sum up the weight of the whole dag to decide during initial sync, for example. But you can also use different variants and derivatives of the mana for other things. And this is actually something where we're also still kind of discussing and designing the protocol. So this is not 100% finalized.
00:31:04.794 - 00:31:35.770, Speaker B: This is something that we're going to test in the public testnet to see how much mana do people actually have in a real network? How is it distributed? Who has how much mana? Is it a very even distribution? Or is it what we are expecting more of something like a zip distribution where you have a few very rich nodes, because they are public nodes that everybody uses, for example, and then you have a lot of nodes that maybe have not that much weight in the network, right. This is things that we're going to trying to find out in the testnet.
00:31:38.190 - 00:32:16.406, Speaker A: So I have one last question about mana, and then we can jump deeper into sharding or talk about voting, whichever you think would be better to discuss. So let's say I'm synchronizing, right? And so I'm going to draw like a small duck here. So there are two dags, right? And let's say that these two transactions, they are a double spent, right? Well, I'm not drawing very correct graph. And so let's say on top of both of them, there are some other transactions from different nodes. And so I need to compute the weight of this subdig effectively, right, compared to the weight of this subdig, everything.
00:32:16.508 - 00:32:51.134, Speaker B: Piled on top, essentially the same way as bitcoin works, where the amount of blocks on top of another block determine how deep it is in your chain. And then if it's like $6 deep or something, you usually accept it. If you sync from the start, then to know what is the outcome, you always need to sync to the end, essentially. I mean, of course you can also sync from the, from the heads and just look at the depths and stuff. But yeah, it's essentially the same way you solidify. That's how we call it. Like you request all the missing transactions.
00:32:51.134 - 00:33:58.438, Speaker B: Like you join in the network, you see the chips that people are currently talking about. And then every transaction has a reference to the previous one, right? So you can request for the missing one, and then you just continue that until you reach a point where either reaches a genesis that might, in theory, take a very long time. But you can also bootstrap your node with things like local snapshots. You have a snapshot file, which is essentially a summary where you start your dag. And maybe, how can I remove stuff here? I can have some space. So if we look at the dag and we have all the transactions that reference each other and stuff like that, then each of these transactions essentially introduces a state change to the global system, right? But from every point of view of a specific transaction, the state is exactly one state. So that means if I pick this transaction and I look at all of the transactions that are directly or indirectly references, then I can compute a letter state.
00:33:58.438 - 00:34:49.830, Speaker B: And what you can do now is if you have take one of these transactions as a reference point, then you can cut off the DAc like you make a cut here. In that case, the cut would be here because it's not referencing this one. But you make a cut and you summarize all of these letter states balances that you have currently in the network. And then you can provide this local snapshot file, for example, to other people who can then synchronize in a faster way. Like, usually it takes like, I don't know, two or three minutes to synchronize your node if you use the snapshot file. But of course, the snapshot file introduces a certain form of trust, where you kind of need to really make sure that you're not downloading bad transaction letter state, because otherwise people could do bad things. But it would also be pretty obvious as soon as something bad would happen, like, I don't know, I sync my node with the wrong letter saying somebody sends me money, then this.
00:34:49.830 - 00:35:06.000, Speaker B: And everybody else would think that this is a bad transaction, then they would not approve it. So it's not really anything super bad that can happen, but of course, it puts the ball into the node operator to doing maybe some extra work in getting your node synced the very first time.
00:35:07.490 - 00:35:31.142, Speaker A: Right? So now, getting back to this dag on the right, so you had two charts, right? So on the left chart, which is gone by now, you were showing mana, which was accumulating whenever you check. So separately, right? And the right chart shows how that mana contributes to the mana of the node right here, the branch, or like.
00:35:31.276 - 00:35:35.798, Speaker B: The subtangle in the thing.
00:35:35.884 - 00:35:46.406, Speaker A: Oh, I see. So this chart, which is still staying, this is not the weight of a particular node, it's a weight of a particular subdac.
00:35:46.598 - 00:36:04.586, Speaker B: No. Okay. No, sorry. Then we talk about different things. No, this is the reputation of a particular node. So that means the weight of node changes over time. But if I have the mana, like, every transaction carries this potential mana, which rises, as I wrote here, right the moment I issue the transactions, we get a value that is essentially fixed.
00:36:04.586 - 00:36:26.278, Speaker B: And this value does not decay or anything. It just gets transferred into the account of the node, and then from there it starts to decay. But the weight that we determined while we issued the transaction is essentially a fixed value. And if you sum up all these values of all the transactions that ever happened in the future code, then you get this accumulated way that allows you to deal with things like inner system.
00:36:26.364 - 00:36:41.542, Speaker A: Got it. So I think that makes perfect sense. And so just to clarify that I understand it, this, this particular value, right, which is specific to Utxo, right? This value is not specific to a node. It's specific to Utxo.
00:36:41.606 - 00:36:48.686, Speaker B: No, it's specific to the transaction. It doesn't have anything to do with the identity of the node or anything that's essentially the value that.
00:36:48.788 - 00:36:51.982, Speaker A: So that's the weight we use for the dag weight, right?
00:36:52.116 - 00:36:52.462, Speaker B: Yes.
00:36:52.516 - 00:37:02.690, Speaker A: Right. And so that means that the particular weight of the node, right, which is here, that is not used to weight the DAC, it will only be used for voting in the future. Right, I see.
00:37:02.760 - 00:37:03.522, Speaker B: Exactly, yeah.
00:37:03.576 - 00:37:04.482, Speaker A: That makes perfect sense.
00:37:04.536 - 00:37:29.610, Speaker B: And cool. That's essentially a mechanism. Just to have any consensus mechanism is always a voting mechanism, at least in my perception. Like even bitcoin is voting because the block producers, they have their vote, which chain, from their perception or point of view, is the longest one. They attach it to their chain and then the chain gets longer and the chain that get the most votes is essentially the one that wins. Right. And other consensus mechanisms here for other voting mechanisms.
00:37:29.610 - 00:38:28.574, Speaker B: And we have this random subsample voting as a second layer on top. And it allows nodes to decide where to attach their transactions because they need to have more or less consensus on which transactions are the one that are currently preferred in the network. And it's even okay if every now and then one or two nodes have come to a different conclusion. For example, because we also have some kind of resynchronization mechanisms where they would detect these kind of inconsistencies just by observing how much mana from the next approvers is approving to their transaction. And if they see a certain amount of activity in the network approve something that they don't like, or the other way around, then they can repeat the voting with the larger sample size, for example, because usually you have the sample size relatively small to reduce the message overhead. Then they can, for example, get back with their opinion or get back in line with the rest of the network. It's a little bit like a swarm of fish flies swimming next to each other.
00:38:28.612 - 00:38:37.422, Speaker A: Kind of makes sense. So from here, do you want to talk more about voting to present how it works, or do you want to dig deeper into sharding?
00:38:37.566 - 00:38:45.650, Speaker B: I think it might make sense. Maybe we can cover the voting just shortly. Right?
00:38:45.720 - 00:38:46.340, Speaker A: Yeah.
00:38:47.190 - 00:39:01.690, Speaker B: So we have a little bit of an understanding how the basics work. And then maybe it's also a bit easier to understand how just instead of going back, I will just delete everything here. Oh, you're faster.
00:39:02.910 - 00:39:03.660, Speaker A: Cool.
00:39:05.070 - 00:39:21.434, Speaker B: So let's maybe. Wait a second. No, wait. No, I did something wrong. I am trying to find a pencil that is a bit thicker so I don't have to.
00:39:21.632 - 00:39:23.820, Speaker A: I think when you click on pencil, you can choose.
00:39:27.810 - 00:40:15.706, Speaker B: I thought they have maybe some different brush or something. That's fine. So the way iota works is the way we achieve consensus is that we observe in the tangle, like the transaction gets gossiped around and we solidify them if one is missing or whatever. And transactions usually have take different times to propagate in the network, right? So you will have a certain amount of nodes somewhere in the network. I would just paint them with different colors. No, we have some red ones. And then you have some other nodes that maybe saw, in the case of conflicts, you would have like a blue and red transactions, for example.
00:40:15.706 - 00:41:08.394, Speaker B: Then you would have some nodes that saw the red transactions first. And then you have some nodes that saw the blue transaction first. And maybe let's make a few more blue, just so it becomes a little bit more obvious how this thing is going to work and whatever node. So this is nodes, this is not the transactions in the diagram or something, it's just like nodes. And they are, of course they're also connected to each other. Maybe I can bend like little lines in between, like they have all of their neighbors and it just forms like a network where they gossip. And what they now do to reach consensus is that every node, let's say we have this one, for example, he randomly asks other people in the network which one of the two conflicting transactions they like.
00:41:08.394 - 00:42:07.546, Speaker B: And they ask him like, hey, what do you think? I like blue. What do you think? And then he asks this one, hey, what do you think? And then he asks this one, what do you think? And he does it with a given sample size. In our case, it's like around 20 other nodes. And then he analyzes the results of these queries, and depending on the fact, if there was a majority of other nodes that liked a transaction or preferred a transaction that he doesn't like, then he will adjust his opinion and vice versa. So that means that if we have more blue in the network, then statistically the chances of asking other nodes that like blue are also bigger. And therefore, if everybody does that, the network will slowly tip to one side. And then maybe if the red guys, for example, let's say this guy here queried some other nodes, got more blue bag than the red one, maybe he was unlucky in the first round and only queried red guys.
00:42:07.546 - 00:42:12.500, Speaker B: So he doesn't change his. Oh, you don't see my mouse on this screen, right?
00:42:13.030 - 00:42:14.290, Speaker A: Not anymore.
00:42:15.030 - 00:43:23.846, Speaker B: Okay, I guess it's because it's not windows picture or something. So I was talking about this lower one, let's say. And he queried like a few people, and if he didn't get enough votes to change his opinion, then after the next round he does the same. So you repeat this voting process in regular intervals with a short time period in between. And if everybody does that, then ultimately everybody will eventually blue and the network will essentially have reached consensus on which transaction is the right one. And the way we then translate that into the DAC structure is that nodes initially do not like a transaction for a certain amount of time, let's say 5 seconds for example, which is like close to the average network delay, and only if they did not receive a transaction that was not conflicting with the one that they have received before, so they have not received another transaction that spends the same UTX output, then they set their liked status to true in other ways. They say like I'm not really sure, and if you receive a conflict within this time window, then you will start this loading process.
00:43:23.846 - 00:44:09.590, Speaker B: So that means that on average, honest transaction can be considered to be confirmed relatively fast or not really confirmed, because you also need to wait for enough tips to reference them to sure that they don't get orphaned or like left behind. Because it could happen that maybe only you see a transaction. And all the rest of the network, they don't see this transaction because your Internet dropped or whatever. And then if 6 seconds expire and you think it's the right one, then you would maybe accept something that shouldn't be accepted. So you always have this six second delay and then you also have this additional metric where you just see how many tips. So like the transactions at the end of the Dag reference your transaction. And if you didn't see conflict and you have enough to reference, then you essentially consider this transaction to be confirmed.
00:44:09.590 - 00:44:11.142, Speaker B: Yes.
00:44:11.196 - 00:44:32.398, Speaker A: So I have a couple of questions here. One is around. So you're saying if it's been 5 seconds, I accept the transaction. What happens if it has been 5 seconds? I accepted the transaction, but turned out there was actually some network glitch and so there's actually another half of the network which accepted a different transaction. Will we still vote or do we rely? Go ahead.
00:44:32.564 - 00:45:24.206, Speaker B: No, essentially, like what I said is not really exactly exact, but it's giving a good idea. Essentially what we have is levels of knowledge, what we say. So that means after 6 seconds, I like this transaction, but I don't consider it to be finalized yet. It's just like I personally, from my point of view, think that this transaction looks like an honest transaction, right? And all other nodes in the network might also like it, but they have not finalized their decision yet. They will then wait another average network delay and like multiple levels of multiple intervals of these. And the more intervals pass between the time, the higher my credibility in this transaction becomes. But I already start to use this transaction in tip selection as soon as it's light, kind of.
00:45:24.206 - 00:45:38.446, Speaker B: So from after the seconds time window, like 6 seconds time window or 5 seconds time window, that's something that also needs to be determined as some parameter once we launch, the network essentially defines when transactions start to be picked up by the tip selection algorithm.
00:45:38.478 - 00:45:42.770, Speaker A: I see. Oh, so you're saying for the first 5 seconds I'm just not going to be building my transactions on top of it.
00:45:42.840 - 00:47:07.166, Speaker B: Exactly, because otherwise the chances are pretty big. And I think that's also a game theoretic problem that you addressed in an article or a video that you did about avalanche at some point where you said that if future transactions approve previous ones, and if I approve another one, then the chances of this transaction to maybe not be picked up because I'm accidentally approving something that would be rejected, then why would I attach to something like that? Why would I not just attach to the genesis for example? Right? And that's a big question. And with the six second quarantine time in 99% of the cases, or when the node is honest and well connected, you will never have the problem where something gets left behind, because most people by that time already share the same perception as you. And even if you're just on the threshold, and maybe everybody else sees the conflict in time, that they say like oh, maybe I don't pick that up in tip selection yet, then still they will have most probably formed the initial opinion to be the same as yours. And even if people vote, then you essentially come up with the same result anyway. So that means that after 6 seconds for smaller amounts of funds, like if you want to buy a coffee or like a machine transacting like fractions of a cent, they might already be fine just by not seeing a conflict within that time period. But if a conflict arrives, you still vote, but also only up to a certain point.
00:47:07.166 - 00:47:17.298, Speaker B: So if you have a transaction unconflicting for like 30 minutes or something, well then your node just says, okay, now I am kind of finalized here, right?
00:47:17.464 - 00:48:15.654, Speaker A: So another question I have is, so this voting mechanism, it's very similar to snowball, right? The Cornell's paper. And in snowball, regardless of permatization, right, snowball for liveness can tolerate at most 20% or so of malicious actors, and otherwise they can stall snowball just with very high chance, right? Just by splitting the network in half of honest people, and just responding red to one half and blue to another half. And so if the network is approximately at 50%, split that 20%, malicious actors responding always blue to one half and always red to one half, is sufficient for the system to continue accumulating confidence in their corresponding colors. And so the way I remember the iota consensus solving it is, it uses a randomness beacon, right, to change the threshold on every step.
00:48:15.852 - 00:48:41.630, Speaker B: Exactly. So what we are doing is that we are changing. There's like a network wide consensus also on a random number. There's like protocols, like drand, for example, what we are currently using. But there's also research and discussions about additional metrics to get this randomness. And it also doesn't need to be like 100% exact, but most of the nodes should use more or less the same random number. Otherwise it doesn't really work.
00:48:41.630 - 00:49:32.830, Speaker B: And the way we deal with this is that we essentially, we wiggle around the threshold, above which my result that I'm expecting to change my opinion, needs to be to tip in one or the other direction. And because the attacker does not know these random thresholds up front, he has a really hard time keeping the network in balance. So at some point, you will just have a slightly bigger fraction of the network already being on one side, and then maybe the threshold is a little bit lower than you would have expected. And essentially, the simulations show that it tips relatively fast, also much faster than avalanche, in that sense. And that kind of gets rid of this problem to a certain degree.
00:49:33.570 - 00:49:44.046, Speaker A: And so the randomness beacon, is it sort of on chain? Well, on DAG, I guess, would be a correct term. Or is it a separate process which happens through separate message passing?
00:49:44.238 - 00:50:36.274, Speaker B: Currently in the protocol, it's a separate layer, but it gets persisted on the DAG. So that means that you have a certain transaction type which gets issued in the tanger. So that means that everybody references this beacon, for example, is then also able to see it and request it for past decisions and stuff like that. So it is persisted in the DAG, but the agreement on which random number you use is currently outside of the protocol. But as I said, there's also ideas and discussions about using maybe some other source of randomness that would not require to have this communication overhead in the network. Second layer protocol. Also, another thing, researching vdfs and stuff like that, in that context, we're part of this VDF alliance together with Ethereum, for example.
00:50:36.274 - 00:50:39.010, Speaker B: And there's a lot of research going into these kind of randomness.
00:50:39.590 - 00:50:56.870, Speaker A: Yeah, yeah. And I know Solana is also part of the alliance, many others. So one thing I realized we didn't do is we didn't talk about tip selection, which I think is pretty fundamental to understanding iota. So do you want very briefly cover tip selection and then maybe move to sharding?
00:50:57.770 - 00:51:06.506, Speaker B: Yes, tip selection is actually relatively simple. You just have a list of all the tips. Or maybe shortly we can just use.
00:51:06.528 - 00:51:07.446, Speaker A: Like a sharding picture.
00:51:07.478 - 00:51:37.794, Speaker B: Yeah, if we talk. What is a tip? A tip is a transaction that is at the end of the DAG, where this is like the direction which it grows, which has not been referenced by any other transactions. That's what we usually call a tip. So whenever we issue a new transaction, we usually want to attach it somewhere here in the dag. Because if I attach something that is too old, for example, that people might have snapshotted already, then they might not even approve my transaction. So this kind of lowers my chances of being accepted. And we also want the Dag to kind of create a decision.
00:51:37.794 - 00:52:26.450, Speaker B: So all the honest notes should always attach somewhere at the top. And essentially what you're doing is you have a list of transactions or tips that you like based on this local modifier. That's how we call it, based initial opinion and also on the outcome of voting. And then you just universally at random choose one of the tips and you just connect these two transactions. And the lesser state, the Utxo state, essentially makes sure that you do not accidentally like two conflicting tips. So you can always just like tips that are not conflicting with other tips, kind of. So that has a little bit changed from the original white paper version because there we had this kind of random walk where you always walk from one of these transactions and you walk past Upco and you do this based on weight, so you always end up in the heavier chain.
00:52:26.450 - 00:52:36.050, Speaker B: But this did not scale very well, so we kind of had to get rid of that. And the additional voting layer on top still gives us the ability to make these kind of decisions without having to do this random work.
00:52:36.220 - 00:52:42.426, Speaker A: So how do I choose tips today? Do I just randomly choose any two tips from the ones that you like?
00:52:42.608 - 00:53:14.074, Speaker B: Exactly. And I mean, it could in theory happen because after 6 seconds you will start to reference these tips. In very rare edge cases can happen that you may be attached to something that then later turns out in the voting phase because maybe you got really bad connection, was rejected anyway. Then what you would have to do is you would need to take your transaction and attach it somewhere else. So that's something that is possible in the daG. Also, you essentially just issue a copy of the transaction just with the reference pointer set to two other transactions. So that means that you then have to kind of take care a little bit of this dag.
00:53:14.074 - 00:53:38.880, Speaker B: But simulations show that if you make this timeout slightly bigger than the network delay, then this is extremely seldom that this happens. Because even if you see something arriving after like half of the network delay, then chances, because gossip spreads exponentially fast, that other people have also seen this transaction as the first one, unless it's maybe your direct neighbor that gives you this transaction, are still pretty big on average, right?
00:53:39.250 - 00:54:04.234, Speaker A: And actually, I just remembered one more question I had, which is. So you're saying that if I receive a transaction, right, for 5 seconds, I'm not considering it as a tip yet, right. I'm going to be building on the older tips. And 5 seconds in, I will say, okay, now, with this transaction, I've seen it sufficiently long to believe that it is unlikely to have any conflict. So I accept it. I build on top of it. So let's say there was some transaction, let's call it transaction one, which I received.
00:54:04.234 - 00:54:21.500, Speaker A: I waited for 5 seconds. I accepted it. I produced my transaction two, which builds on top of one, and then we wait for 5 seconds. Someone else waits for 5 seconds before they produce transaction three, which is on two, right? So it will take for every extra layer, extra depth on top of one, it takes extra 5 seconds, right?
00:54:21.870 - 00:54:44.194, Speaker B: Yeah, but it's essentially just a time shifted period, right? Like if I receive my transaction now, then in 5 seconds, this transaction, yeah, it's true for every step it takes 5 seconds. But you always have new tips showing up from the previous 5 seconds window. So it's just a little bit. I don't know how to explain, but.
00:54:44.312 - 00:54:57.074, Speaker A: I look at it from perspective of finality, right? If I'm the person who issued transaction one, what will be for me, the sense of finality? Is it the number of depth of layers on top of it, each one taking 5 seconds?
00:54:57.122 - 00:56:20.586, Speaker B: No, it's essentially the outcome of your voting layer. If you don't see, as I said, the levels of knowledge, the longer it takes for your transaction to be in the dag without a conflict, the more confident you essentially get into this transaction to being the one that will most probably also be accepted by the network. And at some point after a certain time threshold, you just decide, okay, this one is finalized now. So that means also that we favor liveness and functionality of the deck over partition tolerance in that sense. So if you have like a network split, for example, then what would happen? Let's say we have like a 50 50% split, China, world War three, and USA, and they kind of take up the firewall and everybody's using iota or whatever, then both networks would continue to function. But after the firewall goes down or something, then you would essentially have two conflicting versions of this dag where you need to either manually intervene and say, like, okay, I resync with a network if it's, for example, something that just happened to my particular node, or we would have to find some agreement in the real world, how we continue after that, if there have been double spends, how we would kind of make a cut and combine them in a global action. So if you compare that, for example, to bitcoin, it's slightly different, right? In bitcoin, the moment you would have the split.
00:56:20.586 - 00:56:45.850, Speaker B: And maybe in China, the bitcoin would continue to work because they have most of the hashing power, but maybe also, I don't know, the US would just spin up a lot of miners and would provide hashing power to continue or allow people to use the network. Then after the networks merge again, then what would happen is that you see the longest chain and it would essentially roll back all of the transactions in one of the parts of the world, right?
00:56:46.000 - 00:56:50.780, Speaker A: So in iota, the same will happen if after the split, there was an immediate double spend, right?
00:56:51.630 - 00:57:06.814, Speaker B: Or you can still roll back. It would not be rolled back because you would then have two states of the network. And then you need to decide what you do with this outside of the network, essentially like a fork in a blockchain kind of. Right.
00:57:06.932 - 00:57:09.200, Speaker A: But in case of bitcoin, it's also a fork, right?
00:57:10.130 - 00:57:30.230, Speaker B: Yes, but the longest chain consensus, if you don't have something like checkpoints, for example, then always longest chain would win. So, I mean, I'm pretty sure that people, even in the case of bitcoin, would then say like, no, we're not going to throw away one year of transactions and just follow the chinese plane or something. They would most probably make like, they would also fall.
00:57:30.300 - 00:57:37.418, Speaker A: Oh, so what you're saying that in Iota's case, neither of the halves will switch to the other half. They will just continue even when they.
00:57:37.424 - 00:58:19.426, Speaker B: Learn next to each other. But we do have a resynchronization mechanism, which is a little bit complex because there we have really a lot of new concepts and data structures also in the way we calculate these kind of weights. So it's maybe a bit too much to explain that right now. But if this falling out of sync happens to just a small subset of nodes. Like, for example, I don't know, I have a server in a data center and that they have a network outage. And it happened at a really stupid moment where one of the double spending transactions arrived at my point, and then somehow there were still enough honest nodes in the network that I still see that are still continuing to build up on this transaction. Then it could, in theory, happen that I fall out of sync.
00:58:19.426 - 00:59:18.966, Speaker B: But then there's an additional mechanism where I again use a similar mechanism as we used in the initial sync scenario, where we observe the economic activity in my network. And if my confidence in this transaction is not too high yet. So, like, for a certain amount of time, I can do this, and it seems to be conflicting with the rest of the perception of all the other actors in the network, which I can keep track of by monitoring the economic activity. Then I can do a bigger query where I ask more than 20 people, because in theory, it could also happen that I was just like super unlucky in asking the wrong people when I did this random subset thing. Then I will do a bigger query with like 100 nodes, for example, and then I will eventually reevaluate my decision and correct that decision. So even if you fall out of sync, your node can kind of repair itself a little bit, but only to a certain degree, because if you allow those things to be possible for too long, then this might also become an attack vector.
00:59:19.158 - 00:59:23.660, Speaker A: Yep, makes sense. Cool. Okay, so let's dive deep into.
00:59:28.030 - 01:00:20.830, Speaker B: Yeah, where did we stop? Yeah. Okay, so essentially, shards in iota is a really simple mechanism. You just make the dag wider, and at some point, the nodes on this side are not able to process everything anymore, and they kind of like split off. Right. So one problem that you have with this approach is that they do not share the same amount of validators, but they share the same past, which means that when I receive a transaction here in the same past cone, then suddenly I would be able to spend it on the right side in this chart, and I would also be able to spend it in this shard. And because you don't really have, it seems to be a pretty complex problem. And other people have also, for example, pointed this out and have said, like, okay, that's the reason why Iota will never shard in a way without allowing double spends to a certain degree.
01:00:20.830 - 01:01:15.258, Speaker B: And we have thought about ways how we can fix that without having a centralized entity like the coordinator just monitoring all of the shards and building another chain on top of all the other chains, for example, you usually do that in blockchain based systems. And the idea is the following one, that we're essentially giving a shard marker, which is something like a color, to every transaction the moment they get issued. Okay? So that means even before we shard, like, even before we split up the networks, we kind of divide the amount of validators and the nodes that are operating in the network into two groups or three groups or four groups. In our case, it will most probably be like a 64 bit short macro or something. So you can have really a large amount of potential charts. So you can split up, split up and split up. So you could, for example, divide red and dark red and bright red and blue and dark blue and bright blue.
01:01:15.258 - 01:01:49.178, Speaker B: And then you could separate bright blue and brighter, brighter blue and so on. And even if the transactions reference each other more or less randomly at the beginning, then you will still be able to kind of prevent these kind of double spends in a sharded environment, because as soon as somebody tries to spend a blue balance in this shard, the people will simply say like, no, I'm not responsible for that, right? So every node has a certain jurisdiction of the activity that it wants to do, that it considers to be responsible for.
01:01:49.344 - 01:02:05.582, Speaker A: So in the bubble in which, like, near and Ethereum and others talk about sharding, that is called state sharding, effectively, right? Because you're saying the whole state is now split into multiple parts, and exactly every shard is responsible for the particular.
01:02:05.716 - 01:02:36.760, Speaker B: This is also state charting, right? But at the beginning, everything is like part of the same network, and then you kind of have the state charted network, which prevents double spends just by being state charted in the same way as you cannot spend your funds from one chart and Ethereum and the other chart. So essentially, pretty straightforward solution, right? It's also very easy to implement. Just nodes provide the shard location whenever they issue a transaction, and then you just put it into your store together with the balances in your ledger, and then you can at some point filter out these things.
01:02:37.370 - 01:02:48.590, Speaker A: And so in each shard, do I continue? So let's say that the top shard ends up having more activity, right? So as I maintain the top shard, do I already relabel transactions for the future split?
01:02:49.490 - 01:03:09.246, Speaker B: No, they have their marker from the beginning on. It's like an inherent sharding DNA, which is part of every transaction. So let's say you have ten numbers. This one says, like, I live in shard number one. This one says, I live in shard number two, this is, like, three, four, five, whatever. And they will also always be in one. So if I start to split, shard.
01:03:09.278 - 01:03:10.850, Speaker A: One will never split further?
01:03:11.350 - 01:03:27.114, Speaker B: No, it can split further. But if I say, like, shard one is one to five and shard two is, like, six, for example, then I can split it up again and say, like, okay, shard 1.1 is from one to three, and so on.
01:03:27.152 - 01:03:27.306, Speaker A: Right.
01:03:27.328 - 01:03:32.186, Speaker B: And if I make this space of potential addresses really big, then I can do this arbitrarily often.
01:03:32.368 - 01:03:35.882, Speaker A: So, effectively, you have logical shards, which you have, like, a huge number.
01:03:35.936 - 01:03:36.154, Speaker B: Right.
01:03:36.192 - 01:03:43.310, Speaker A: So, like, let's say two to the 64th, and you have physical shards. So initially, you have one physical chart, then you have two physical charts and every physical shard.
01:03:45.090 - 01:04:09.960, Speaker B: Yeah, but there's some additional steps which will make this mechanism a little bit more beautiful, because you will not have these distinct shards that you have usually in the blockchain world, but this is essentially the basic idea. So you just put, like, a sticker on every transaction. Everybody knows who's responsible for that. And if we need to shard, then we can do that, and nobody can double spend.
01:04:11.050 - 01:04:14.094, Speaker A: Okay, go ahead. I have a scenario.
01:04:14.242 - 01:04:55.878, Speaker B: There's one problem with this approach, and the problem is that the shards essentially need to know when and where to split. And this is something that is a bit tricky to achieve, because it essentially requires you to have another consensus mechanism on top of consensus mechanism. Right. If I consider myself to not be responsible for blue slightly later, after blue decides that for himself, then maybe I'm still able to spend it in both charts. Right. So this was kind of like, the early idea. This is maybe a good way to understand the whole concept behind that, and it also makes you understand how this whole concept works.
01:04:55.878 - 01:05:28.782, Speaker B: But we also don't have the ability to send funds between shards currently. Right. We don't want to have another chain on top of all of these shards. So then we go to the next step, and it's a relatively straightforward optimization. Again, we just do a network with marker based tip selection. So that means that red transactions will prefer to reference other red transactions, and blue transactions will prefer to reference other blue transactions. And transactions just perform tip selection within their sharding vicinity.
01:05:28.782 - 01:06:00.220, Speaker B: Kind of like within what they see. Kind of. Right. And the result of this is that you will have a big tangle where everything is still connected to everything else. But these kind of sharp markers are a little bit like the colors of a rainbow. I mean, I only have four colors here in this picture because I cannot possibly write like 1 trillion colors, but you will have, like, a gradient of all the different colors from starting number to the ending number, kind of.
01:06:02.030 - 01:06:08.800, Speaker A: On this picture, there's also preference for the neighboring shards. Is it just an artifact of the picture or. That's also the idea.
01:06:10.370 - 01:06:55.174, Speaker B: Let's say your sharding coordinate net is number five, and you want your transaction. Then you would connect to one transaction that is either smaller equals the shard marker than yourself, kind of like one that is before you and one that is slightly after you. So you will naturally start to reference also some other transactions from other shards, kind of because there's no distinct borders between the shards. And I think it also becomes a little bit more obvious, what I mean when we switch to the next picture. So for now, we just do this tip selection and say, like, okay, we always try to select tips that are close to our own shard location. Right. But we also needed to have a certain monotonicity.
01:06:55.174 - 01:07:27.350, Speaker B: Like, if this one has five, then this one should be, let's say if this one here is five, then this one, for example, should be five or smaller, and this one should be five or bigger. So you always position yourself in the middle between two other tips that you reference. So if I move in one direction, it always grows or stays the same, and it cannot go up and down and up and down. So you have a sort of in the distribution of the shop space. It really looks like if you would do it with colors, it would look like a colorful rainbow.
01:07:27.850 - 01:07:33.110, Speaker A: What happens if my transaction is the largest? Do I only have one reference.
01:07:35.290 - 01:07:35.606, Speaker B: Or.
01:07:35.628 - 01:07:50.830, Speaker A: We just don't allow that to happen. So I assume you use some sort of hashes for some ids of the transaction. So let's say I created the transaction, and its hash or id happens to be the largest ever existing up until now. So I cannot reference something larger because larger doesn't exist.
01:07:51.970 - 01:07:58.960, Speaker B: Will I just have one parent ring structure? As soon as you come up on the end, you would kind of connect at the bottom again.
01:07:59.890 - 01:08:01.682, Speaker A: Oh, it's a ring. I see. Got it.
01:08:01.736 - 01:08:09.554, Speaker B: Yeah, it's a bit mask, and therefore it's like a ring. So you always just try to be in your vicinity, kind of.
01:08:09.672 - 01:08:10.546, Speaker A: I see.
01:08:10.728 - 01:08:59.762, Speaker B: And also, I think it's going to be a little bit more clear maybe now. So the nodes can now decide what position in this sharding space they're interested in. Okay, so if we have a node that has this window of perception. So I download the tangle, but I don't download everything, because if we go back to this example here, then let's say red was, let's say Berlin transactions in Berlin, and blue is transactions in Martin, which is a city that is not too far away from Berlin. And all the people that are living in Berlin would only naturally be interested in the balances of Berlin. They don't really care if somebody in another city or another continent or whatever has as balances. So the intention of this sharding is that you only download, reference, and process the transaction that you're immediately interested in.
01:08:59.762 - 01:09:36.478, Speaker B: And the same thing is true here. And in this window of perception, the node would have its focal point, like the sharding space that it wants to process in the middle. So a node that is interested in the red markers will download these transactions, but it will also download and solidify and request the transactions that are a little bit further away. So it can not just see and process what is in its direct point of interest, but it will also see transactions from its direct neighbors, kind of.
01:09:36.644 - 01:09:39.022, Speaker A: Okay, yeah, that makes sense.
01:09:39.156 - 01:10:01.366, Speaker B: That clear so far. Okay. And this means that you also will have a situation where these kind of perception windows can overlap. Like, you will have somebody who's maybe operating in the middle of Berlin, and you will have some nodes operating west of Berlin. So these perception windows are overlapping depending on which node is seeing what kind of.
01:10:01.468 - 01:10:08.282, Speaker A: So when you're using geographical locations, is it just a metaphor, or you actually envision that the sharding will be more or less aligned with the.
01:10:08.336 - 01:10:54.626, Speaker B: We actually do envision to use a geographic sharding. There will also be logical sharding on top of that. Like you can define if you want to use the geographical charting layer, or if you want to use a logical charting layer, where then, for example, applications that need global consensus instead of this kind of local economy based consensus. And the way this works is essentially just that. The node, as soon as you set it up, it defines its location. Like where am I located? Where is my business located, for example? Or if I have a node that is mobile, then this node can even change its sharding location. And as soon as it issues the next transaction with a new shard marker, then everybody will also know which area of this whole sharding space it observes.
01:10:54.626 - 01:11:18.640, Speaker B: So that means nodes can freely move between these shards. They can drive around as cars, for example, and always shift their window of perception accordingly. And the interesting aspect here is that all transactions, like the blue transaction down here, still indirectly references the transaction over there, kind of. In that case, it's maybe not so easy to see.
01:11:19.330 - 01:11:23.410, Speaker A: Yeah, but that makes sense. Over time, the tangle will entangle.
01:11:26.390 - 01:11:54.042, Speaker B: A global tangle that spans around the whole globe without any discrete borders. We still have the situation that every single transaction indirectly references another transaction anywhere else in the world, even though I don't really know about this anymore, because I cut off my perception window here. Right. And this will be something that we will then use for intershard transactions. But is it clear so far, or do you have any questions?
01:11:54.096 - 01:11:55.740, Speaker A: Yes, so far it makes sense.
01:11:56.510 - 01:13:00.170, Speaker B: It's not really complicated. It's a slightly different take on sharding. And the interesting aspect here, maybe just one more thing before we start talking about interchard transactions, is that in my direct vicinity, it's pretty easy for me to do interchard transactions, right? Like, I know the balance here. In this one, for example, if this dude sends some funds into this shard, for example, then I will immediately be able to verify that, and I will see if there's a conflicting transaction, because any double spend would also necessarily lie on the same shard location as this one, because the funds are booked in this specific location. So that means kind of close distance interchard transactions can be done by the nodes just by observing and voting for it in the same way as he does it locally. But as soon as I want to transfer funds that are a bit further away, then of course, this is not as easily possible anymore. And then we have another mechanism which we're going to use for this interchar transaction.
01:13:00.170 - 01:13:33.862, Speaker B: And here is an example. We have the Dag now written from up to down, so it's growing in this direction. And we have a transaction which spans from the red chart to the blue one. So in the transaction, there will be a source chart and a target chart. And initially, this tip is like the tip here, and it will get verified by its local validators, which will look at this transaction and which will start to reference it accordingly. And then it will build on top of that, and the people next to it will do the same. And at some point, the blue people will have the indirect reference to this transaction.
01:13:33.862 - 01:14:29.834, Speaker B: And what we're doing now is that while this, like, if it is an intershard transaction that is supposed to go to another shard, then in gossiping, we look at our neighbors and see which one of our neighbors is closer to the destination where it needs to go. And then it always waits until a new transaction gets attached, collects the hashes, and essentially builds a Merkel proof of this thing, of the whole path. And as soon as it arrives on the destination chart, then I can present this recipe, kind of, which proves that this original transaction gets reattached there here as a second version, and I attach another proof, and then I can check if the balances have indeed been moved, and if the shard link space is honest, or like the tangle in total is honest, and we have these kind of connections, then I can do this in a trustless manner, and I can transfer funds from each point on earth to every other point on earth.
01:14:29.882 - 01:14:43.934, Speaker A: Right, but there's a difference with Merkel proof, right? Merkel proof is by design, logarithmic in the sense that every consecutive layer spends twice as wide connection. Right? While here, the number of hopstrin, it's.
01:14:43.982 - 01:15:23.390, Speaker B: Of course a little bit different also because, but it uses the same kind of principles where you accumulate hashes, but you always do it pair ways. So it's not really a mercury tree where the leaves get wider and wider, so the depth doesn't rise logarithmically. But what you can do is also, if this fast gets too long, for example, it's not super long. I mean, you have like a few bytes every like a year, because you can always also calculate the previous hash from the one here. So for every step, I only need one hash, and I need the original transaction. So I need original, I need this hash, then I can compute to this one, then I need this hash, I compute this one, and so on.
01:15:23.540 - 01:15:26.080, Speaker A: But it also takes 5 seconds per step, right?
01:15:29.330 - 01:15:30.080, Speaker B: Yeah.
01:15:31.910 - 01:15:41.682, Speaker A: Because like, hypothetical yellow node in the middle yellow transaction will not be created until 5 seconds passed from the previous one, right? Yes, it can take some time.
01:15:41.736 - 01:15:50.418, Speaker B: That means if the path gets really long, for example, then of course this can take a relatively long time to do these kind of intercharp transactions.
01:15:50.594 - 01:16:09.580, Speaker A: But also, what is not entirely clear, I think, for me, is why do I care about my transaction getting to a particular shard? Like, let's say I want to pay you, right? If I have a Utxo in the red shard, I will just pay you. And now you have your Utxo in the red can.
01:16:10.270 - 01:16:11.530, Speaker B: How do I verify.
01:16:13.810 - 01:16:16.778, Speaker A: If you're not following? I see you might not be following the red chart.
01:16:16.794 - 01:16:30.740, Speaker B: My window perception doesn't even see you. Then I have a really hard time kind of seeing if you really had the funds. Kind of. Right, like you're telling me this is a transaction and they get executed there. But I kind of need to prove to you.
01:16:31.670 - 01:16:57.920, Speaker A: But how do you know even if we have this proof, right? So imagine the following situation. So let's say that iota has been running for a while. Right? Can we switch to the whiteboard? I will show you a relatively classic. Oh, no, I can delete. So let's say the following happens, right? So we have multiple shards. So we have a blue shard here, which builds transactions. We have.
01:16:57.920 - 01:17:25.238, Speaker A: Yeah, you can just move there. This is like a tool on the right with a little hand on the right hand side. Yeah. And so then let's say there's a green shard over here, right? And they sort of touch each other, and then there's a red shard next to it. And so let's say that Iota has been running for a while. It processes, let's say, millions transactions. Billions transactions per second.
01:17:25.238 - 01:17:48.870, Speaker A: And so to maintain that load, the number of shards actually grew to be pretty big. And also, let's say that the number of users is also like, let's say actually there's, like, every car, every Tesla, every gas station has it, right? So there are billions of users, billions of transactions per second. Number of shards is in thousands. And so let's say everybody follows the exact constant. Doesn't matter. So for simplicity, let's say everybody follows exactly three shards.
01:17:48.950 - 01:18:18.214, Speaker B: Actually, I need four, right? It's like you just have a certain window of perception, which is a certain diameter of the egg that you can actually process, and the nodes can individually decide how much of the bigger picture they want to see. So if you have a very lightweight node, for example, then this lightweight node might only see, like, I don't know, the next 2 example, but if you have a node that has a little bit more processing power, for example, it might see and keep track of transactions that are a little bit further away.
01:18:18.412 - 01:19:09.266, Speaker A: But for the sake of experiment, let's say that majority, because majority of the nodes will be very lightweight, right? So let's say there are several nodes, but very few of them who are very heavyweight. So, like, for example, some people in Iota foundation run a node which just tracks the entire dag, but majority of nodes are actually IoT devices. And let's say we know that on average, deployment on the IoT device, they track, their perception window is approximately corresponding to three shards, right? So let's say if one shard is sufficiently wide to fit. So I don't know exactly what we measure, but let's say it's hashes, right? It fits some width of caches. Let's say that the average IoT device is actually tracks, like, three times that or four times that. Then what I can do is I can create a large. So I can civil attack couple of shorts.
01:19:09.266 - 01:19:16.520, Speaker A: So Sibyl attacking the whole system is very expensive, right? I would have to have mana proportional to the mana of the entire system. But I can.
01:19:18.030 - 01:19:27.994, Speaker B: The mana is local. The decisions that you make within your window of perception and are based on the mana that the people have within your window of perception, right? Everything else don't really know, right?
01:19:28.112 - 01:20:05.206, Speaker A: But what I can try to do is I can try to move all my mana into this red window, right? Over time. So let's say I'm planning my attack today, which I will carry out in a year. And so within a year, in January today, I moved all my mana to the red sort of space. So in the red space, my mana dominates the space and also to yellow, right? So red and yellow both dominated by me, while nowhere else I have my mana, right? So then I effectively to Sibyl attack two shards. When there is thousands of shards, I only need 1000 of the total manner, right? Because of the system wide mana, this.
01:20:05.228 - 01:21:08.046, Speaker B: Is the same problem that you have with any sharding. Like as soon as the shards get really small, also the security problems kind of get a little bit smaller, right? Wait, sorry. And I agree to that. But I have to say that currently, mana, for example, is the anti civil mechanism that we are using. But in the future, it would most probably make much more sense if we have this amount of adoption to not use mana as an anti simple mechanism, but to use actual real world identities. Since we're anyway local already and people know each other and know businesses, they have a certain perception of trust. And if you live, for example, in the city of Berlin, and you say all the shops, all the government agencies, all the companies that are operating in Berlin have the trust, maybe even bound by the legal framework of the country where the technology is used, then you kind of have the ability to use that as an antisabular mechanism, and that of course, becomes much harder to attack.
01:21:08.046 - 01:22:01.390, Speaker B: But the current version of cordicide, which is also kind of version 1.0 that we're talking about, there's going to be additional changes, is mostly going to be based of mana also, because we don't think that we will reach this kind of splintering in the shards right from the start. So it's going to be evolutionary process, and then at some point, there will most probably be results from additional anticipal mechanisms and stuff like that. We already have a framework and somebody from community who has proposed something very similar and essentially like an oracle for decentralized identities. And this would allow you to do exactly that. And then of course it becomes much, much harder to civil attack a certain amount of shard. And I mean, I also have to say the amount of tps that we're currently achieving with go shimmer is around 10,000, 20,000 tps.
01:22:01.390 - 01:23:11.714, Speaker B: So it's quite a lot. And even on a normal machine that is not like a super strong server, because you can process everything as it arrives, like you don't need to wait in blockchain and then go through all the transactions and do all the signature checks at the same time. Of course, if you increase, decrease the time between blocks, then you get essentially similar effect. But you can load balance this extremely well. And if we're talking about Iot of the future, then of course we're also not talking about smart light bulbs and small little sensors that have the size of a little fingernail, for example, but actual devices that are machines like cars, smart devices that are driving around that have a certain amount of processing power and that have also the ability to keep track at least a reasonable fraction of the full picture. Right? And at the beginning, if you assume you have like, I don't know, 10,000, 20,000 tps throughput and maybe let me paint something and you will have, oh, that is a very big line. And you would have your rectangle or like your sharding space, which looks like this.
01:23:11.714 - 01:23:26.902, Speaker B: It's like the range of numbers. And of course it's a ring, but it's maybe a little bit easier to paint in that sense. At the beginning, you will have a situation where everybody sees everything. That's most probably going to be the situation. Can I remove your funny pictures?
01:23:26.966 - 01:23:27.740, Speaker A: Yeah, sure.
01:23:28.510 - 01:23:51.538, Speaker B: Everybody will see everything. And it's most obviously very secure to do it like that. Right? And then over time, adoption rises. Maybe at some point we have like 100,000 tps in the system or something, and each node can process up to 20,000. Then you will have essentially five shots, but it's not really five shots, they will overlap. So that means you will have some people observing this, some people observing this. Maybe there are some smaller devices observing this.
01:23:51.538 - 01:24:54.694, Speaker B: And you will have kind of like a patch of people living here. Right? And this also would be reflected in the business relationships because we have this sharding based on these geographic proximities. And most of the economy still happens locally. Like if I want to buy a pizza, I go to my pizzeria around the corner and it would be good if those guys know my balance and we can communicate with each other. And it also means that I have a certain incentive to be present in other people's chart, kind of, maybe I have another subsidy in the city, and I'm an international corporation or whatever. So even if my company is here, I might operate another server here, and I might operate another server here, and I can observe what's going on in other parts of the world. And if somebody would play foul and would start to kind of suddenly reverse decisions and stuff like that, I'm pretty sure that at that point of adoption, we would see this being recognized by some of the actors, and they could inform the world and say, like, oh, this chart has just done something really bad.
01:24:54.694 - 01:26:02.650, Speaker B: Don't accept payments from that section here, right? And the same is also true. Like, if you would have colluding countries, for example, it's very unlikely that you will have no other actor, economic actor in the world that would see that in a way. Right? You can report that. And I also have some ideas around how you can even automate that with servers that are located every now and then, they collect the information that they see and build additional market proofs, and keep that as like, a point of reference, which allows you to prove these things in the past also. And of course, then the ultimate solution would be that you have a really fine grain charted network where everything is. That would be the ultimate vision in a few 1020 years, I don't know how long it's going to take until you reach, like, millions or hundreds of millions of transactions per second, but this is something that we don't really have to care about in the immediate future. And by the time this would happen, I think we will have the corresponding legal framework and the ability to address that with some other form of anti civil mechanism.
01:26:03.230 - 01:27:01.214, Speaker A: So I can provide you some references which would be interesting how this compares to what's been happening in the sharding research. Like, for example, what was happening in near Ethereum or Polkadot, which are all, to an extent, like Polkadot is also to an extent, is sharding the basic attack, right? Which you mentioned. You also mentioned how to try to get around it is, let's say this is happening on the geographic activity basis, right? And let's say that somewhere over here, somewhere over here is something that I managed to Sibyl attack. So if it's mana, proof of mana, then I just managed to move all my mana there. Or if it's proof of identity, then I just went to some city of Vishvsk, back in Russia, where from, right. And I just managed to corrupt the entire city of Vishevsk, and I convinced everybody injures to collude, and also in all the neighboring cities. And so what I do is in my city of Jevsk, I create something completely bogus, like I create an utxo which is invalid and prints money.
01:27:01.214 - 01:28:02.702, Speaker A: And then my neighboring cities, whom I also convinced to collude, they do not produce anything invalid, except accepting that Utxo. So that someone who is neighboring those cities, they don't see anything incorrect happening in this proximity, because they don't look at the jask where the actual invalid transaction happened. And so that invalid Utxo managed to propagate through the system. And then somewhere in Berlin, after multiple hopes, I spent it. And so the general way that you mentioned, which makes a lot of sense, is that you actually do have, because it takes one node to detect invalid behavior, and one node is cheap, right? So you will have one node, one very expensive node standing in various parts of the world. However, there's a big problem here, which is when I create an invalid Utxo, invalid Utxo is a Utxo which references something that does not exist, right? So create Utxo, where I say the output of this Utxo is 1 million iota tokens, and the input, I just create random hashes. Like, I just create random hashes.
01:28:02.702 - 01:28:41.134, Speaker A: And so if you are that server which is supposed to provide proofs, you cannot really prove to everybody else that those Utxos are invalid. So even though you cannot fetch them locally, so you're locally that very expensive server which is supposed to monitor ejesk, you see that invalid Utxo, you clearly understand it's invalid. It looks very suspicious, but you cannot prove to everybody else that those hashes are incorrect. So the only thing you can do is you can go to everybody else and say, guys, you just created Utxo which is invalid, but you will have to go yourself to ejesk to sync the entire tangle effectively and see to yourself that that Utxo is invalid effectively, right?
01:28:41.332 - 01:29:10.280, Speaker B: Not necessarily. You can also build these kind of merkel proofs that you have for references in the tangle over the Utxo set. Kind of. So in theory I would be able to prove to a certain degree. I'm not 100% sure about that, but there are some ideas around that which are not finalized yet. This is also like a very new concept. As I said, it's the first time that we talk about this publicly at all.
01:29:10.280 - 01:29:48.740, Speaker B: So there's maybe also room for improvement, but you might be able to prove that it at some point at least stemmed from the genesis. But I wouldn't maybe be so sure about that. But what I see as the point here is that this is essentially a problem that you have in any sharded solution, right? So this is not necessarily worse in a way, from other shard things. Maybe you could not inflate the supply in a way, but you could at least double spend and do bad things there as well.
01:29:49.270 - 01:30:46.930, Speaker A: So the way I can very briefly tell what's happening in the ecosystem is that the first problem where a jask goes wrong and creates an invalid state transition, that is called state validity, or like data state validity problem. And so your solution is actually exactly how most of the people solve it, right? They just have nodes which monitor the situation and challenge it. But to challenge something, you actually need to see the whole history. So in case of iota, that means that if there is a certain, how do I draw here? If there is a certain transaction which is invalid and it references something, there's got to be a way to prove that this something is not part of the valid tangle. Like there's got to be a way to prove that it does not go to Genesis, which is very hard, because if I created this transaction, this will not even be a valid hash of some valid transaction. Those will be random numbers, right? And it's hard to prove. And so that's called data availability problem, which is harder.
01:30:46.930 - 01:31:10.638, Speaker A: And the way mostly it is solved is by having a data availability layer, where before any transaction gets accepted, effectively, like you have a smaller nodes which do not really apply all the state transitions, but they constantly, for example, attest to the availability of the data. So effectively, there is a larger set of people who will say, yes, I saw those hashes, and so it will be harder for me to corrupt all those people. Yes.
01:31:10.724 - 01:31:32.638, Speaker B: But what you could, for example, also do is the tangle is still like a big chain, kind of like everything is connected, right? So I could pick one coordinate in the sharding space and accumulate or build something like a checkpoint there, where I have a certain local hash, then again, which can be used to prove that stuff exists somewhere else in tangle, and it was approved, right?
01:31:32.744 - 01:31:36.434, Speaker A: So it's very easy to prove that something exists. It's very hard to prove that something does not exist.
01:31:36.482 - 01:32:34.662, Speaker B: So the question is like, maybe it would be possible to challenge that it doesn't exist, and then make the people who provide this transaction provide a proof that it has been referenced by one of these summary milestones somewhere in the middle of this thing. And if they cannot do that, then you can assume that this was not a valid transaction. But I think that this is something that really only becomes relevant once you reach a certain maturity of the technology and adoption. And of course there's also additional research going into these kind of things. There's hard problems and it's maybe not even that easy to solve. But I think that by the time we arrive there, there might also be additional answers to these kind of things in the immediate future. So in the next five years ahead or something where the sharding space is not that badly separated, it's most probably not going to be a big problem.
01:32:34.662 - 01:32:49.120, Speaker B: And the big pro that I see about this sharding approach compared to blockchain, for example, is that in blockchain, if you split up your validators up front to make up for like 64 shards, like in the case of ethereum, I think you guys have eight if I'm not mistaken. Right?
01:32:49.890 - 01:32:52.542, Speaker A: It changes. Yeah, but eight is the initial value.
01:32:52.596 - 01:33:38.326, Speaker B: Yeah, but it doesn't matter how much you do this. You essentially split up the security of your network by an 8th or by a 64 or something like that. I mean, maybe not exactly, but the security gets slightly lower because you kind of need to split up your validators in this concept. I don't need to do the splitting up front. I can have an extremely secure network in times where the adoption is not that large yet. Right. But I still have the ability by nodes then consecutively making their window of perception smaller and smaller over time, more or less organically adopt to what the network actually needs and then also maybe grow back again if the usage of the network essentially drops again.
01:33:38.326 - 01:34:10.840, Speaker B: Like if you have a very active period, then nodes shrink their perception and then you have corona and the whole activity breaks down and then suddenly you can afford to reference more stuff again and then you can also grow your perception again. So in that sense it of course has the same issues and same problems as any charlote system, but it has a slight benefit because you don't need to do the security splitting upfront. That's something what I really like about this concept, it's just like an organic system that adopts to whatever is needed.
01:34:11.770 - 01:34:23.098, Speaker A: Yeah, I think to support your point, I think in any foreseeable future the number of shards will not be in thousands, right. Even if I can adaptively corrupt one short, it's still going to be very expensive in the absolute terms.
01:34:23.184 - 01:34:45.026, Speaker B: One last thing. Also last thing. I don't know, maybe we're going to talk about something else as well. But one point that is also really important is that Iota still has second layer scaling as well. We have something which is called flash channels. So that means I can create a transaction with a person that I want to transact on tango, I create like a payment channel. It's essentially pretty similar to how the lightning network works.
01:34:45.026 - 01:35:18.218, Speaker B: It's a little bit different, but not much different. And that means that I can then transact off chain these kind of really micro payments. Like let's say I go to a gas station and I want to buy some gasoline or something, right? Then what I would usually do is I open this payment channel with the gas station. It didn't cost me any fees. I can do that even for like a two or $5 payment or whatever. And then I start streaming to pay him single units of iota or like ten iota each or something, which is like fractions of a cent. And then the gas station would continue providing me energy.
01:35:18.218 - 01:36:04.166, Speaker B: Or like gas station, I usually say gas station, but let's assume like electric vehicles because that's a little bit more healthy for the environment. And then as soon as one of the people stops, even if somebody breaks the trust in a way, he only loses like a fraction of the send energy stops sending money, or like the charging station stops sending energy. So that means that even though you have a lot of machines interacting, not everything will always happen on the maintainer. The maintainer is essentially just a broker for transactions that happen between individuals that cannot be made, that cannot use these kind of payment channels. And also for intershar transaction, you can do the same. You can essentially have an end, like let me paint something. But this is also something that is still researched.
01:36:04.166 - 01:36:56.138, Speaker B: So this is more in the realm of ideas, how we deal with this kind of fractured charting environment once the network gets really fragmented. But what you can do is that you open a payment channel, like two people open a payment channel that are really far away from each other and like a money sending service or whatever, right? And they have a certain amount of Iota as a balance that they can operate on. And then they have people using their service to send funds from here to here. And if the amount of funds that on average flow into both directions are more or less the same, then they can do that essentially indefinitely. And then they just manage their address together in the payment channel. And then you don't have to do these really long interchard transactions that you would otherwise do. You can do it, but it's eventually slow.
01:36:56.138 - 01:37:44.330, Speaker B: If the clustering is really big, as you said earlier, especially with this containment period of the transactions, then you would have the problem that it would just take long. So if you have these kind of payment channels as a second layer solution, then you can offer these kind of services, maybe even ask for a small fee for operating these services. I mean Iota, the base technology should be feedless because if I'm already running a node and providing infrastructure for the node, then why would I also pay something to somebody else, right? That's just kind of the idea that everybody helps each other kind of. But if you want to offer extra services on top of the Iota protocol and charge small fees for that for these long distance transfers, then that's totally fine and valid.
01:37:44.830 - 01:37:55.050, Speaker A: Also, to your point, I don't think it is necessary that the inflow and outflow are equal. Those two payment channels can rebalance themselves using slow transactions.
01:37:55.210 - 01:38:37.966, Speaker B: Yeah sure. At the end of the day if you see there's some difference, then you can just send the money. And then if it takes like two or three minutes until it arrives at your location that's also fine. I mean you don't have to do that. But this could be used for instant payments like, I don't know, you want to buy something, order something from the UK and you're in Berlin right now. I always use the german cities because I'm german, but this is essentially the idea, right? And I think that's also a nice and good way of doing L2 payment channels because it essentially serves this one purpose and doesn't put all of the activity on L2 as bitcoin tries to do it with their lightning network, for example, where I'm not such a big fan and I see some game theoretic issues there, but maybe it's not really the topic here.
01:38:38.068 - 01:38:40.560, Speaker A: Yeah, I think that's an interesting idea.
01:38:43.090 - 01:39:13.320, Speaker B: And this is also why our whole algorithm made the kind of why it just took so long, because developing all of these concepts and getting the ideas how you do this. Initially when we started we had kind of this idea, but we didn't know how to connect these charts. We didn't really know how to prevent double spends. It took some time and it's a really simple idea, essentially. It is not really complex to understand, but it still took some time to just arrive at that point.
01:39:17.070 - 01:39:37.840, Speaker A: Cool. Awesome. I think we covered a lot of material today. That's a lot of stuff for people to digest. Thanks a lot for taking your time and providing this deep dive. Think I think it's very interesting times in front of iota, so let's see how that all unfolds. Thanks for watching.

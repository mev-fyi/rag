00:00:04.570 - 00:00:16.858, Speaker A: Hi everybody, this is Ilya and Alex from near protocol. And we're here with Chi from Quarkchain to talk about a little bit more sharding protocols. Right. Please introduce yourself and then we can dive in deeper.
00:00:16.954 - 00:00:52.430, Speaker B: Yeah. Hi everyone. So first of all, it's my great pleasure to be here to introduce Quarkchain and also many thanks for protocol hosting this event. So, Quad chain is next generation blockchain network that aims to offer better trade off between scalability, decentralization and also security. So we already launched our testnet, I mean public testnet, four months ago and our main net is planned to launch at the end of this month.
00:00:52.580 - 00:00:54.046, Speaker A: Awesome. All right, cool.
00:00:54.148 - 00:00:55.230, Speaker C: Let's dive in.
00:00:55.380 - 00:02:31.894, Speaker B: Okay, so before I introduce our maybe detailed consensus, probably I would like to revisit a little bit how we will the problems of blockchains and probably, I'm not sure, new viewpoint or maybe some existing, but make sure that we are solving the correct problem before you dive into the solutions. Okay, so I think first, probably everybody here knows we have a trleema, which is security, decentralization and scalability. Scalability. Trima says that it's very hard to achieve these three properties at the same time, but our observation or facts is that actually achieving one of them is also difficult. Let us start from security first. So for example, let's consider most mature consensus proof of work, which has been running for more than a decade, since the debute of bitcoin, and it has been running for ten years without being attacked. It has a well defined security model which says this is called 51% attack, which says an attacker, as long as it has more than 51% of the hash power, is able to revert any block in the blockchain.
00:02:31.894 - 00:03:28.000, Speaker B: And so it can double spend the transaction with these reverted blocks. And so this 51 seems to be a large number if the network is hash power is decentralized enough. But the problem actually we saw is that these days, for example, last year, bitcoin Go was being attacked, beamed up, double spending attack, and also Ethereum classic that was also being attacked in January. Why? And the reason is that I think there's a huge misunderstanding of this 51% of attack. Especially it says 51% of what people say. Oh, 50% of the network. Yes, if there's a single network, there's 51%.
00:03:28.000 - 00:04:48.118, Speaker B: But if we set off the miners that runs the same hash algorithm, runs the same hash ALG, then this number actually in reality is far lower. So, for example, Ethereum classic and Ethereum are using a little bit outdated data where it's in January, I think, 26 23rd, where ethereum has 176 terrahash per second and Ethereum classic has nine terahash per second. If we just consider Ethereum classic itself, then 51% then requires 5.4.5 malicious attackers. But if you consider the whole miners that can also move their hash power almost instantly from other network like Ethereum, then we only need 9.6 hash power, which is roughly 5.2% to perform double spending attack.
00:04:48.204 - 00:04:55.660, Speaker C: Well, technically we need five point. Yeah, it's actually less 4.6, right? Out of 176, which is even less 4.6. Okay.
00:04:57.470 - 00:05:00.534, Speaker A: With nine, you can just literally print different blocks.
00:05:00.582 - 00:05:05.662, Speaker C: Oh, no, you don't need nine. You don't need nine because this nine is honest. Yeah, we have nine terra hashes of honest.
00:05:05.796 - 00:05:45.658, Speaker B: I assume all these are honest. I just moved here from here. Right? So I just moved nine from here to here and performed on top of span attack. And this is actually what was happened for. And this can be even that the miners that can effectively contribute hash power to the network, that means all the gpus that mine simultaneously, like crypto nine eco hash type what's to mine and see all the algorithms they are running, all the summation of the hash power can be potentially used to attack.
00:05:45.744 - 00:05:52.970, Speaker A: Yeah, I mean, the crypto 51 IO has a pretty good stats on how much it costs to attack any network.
00:05:53.050 - 00:06:27.622, Speaker B: Yes, and that's another topic I can say. But to conclude this, I would say this 51% attack is very misunderstanding. Because in reality, even for Ethereum, consider all this. It can be far lower than this number. And the situation become even worse with the marketplace of hash power. That is, for example, nice hash. And so I can rent those hash power from nice hash and then perform double spending attack.
00:06:27.622 - 00:06:37.578, Speaker B: And the renting price, according to the website you just described, to perform 1 hour attack on eastern classic just cost 4000.
00:06:37.744 - 00:06:40.182, Speaker A: Yeah, it's dropped to two, I think.
00:06:40.256 - 00:07:22.762, Speaker B: And let's consider 30 block confirmation with average 15 seconds block invoke for exchange to confirm a deposit that will take only 450 seconds. Right. That is less than 8 minutes, 10 minutes. And which means that I can just using maybe less than $1,000. $1,000 and it performs this kind of attack and which happened exactly what happened. So we see that actually ethereum classic and ethereum bitcoin go, they are pretty large cryptocurrency in the world. Like roughly top thirty s in the world.
00:07:22.762 - 00:07:57.640, Speaker B: And this implies for all the rest of POW networks, it can be easily attacked. And bitcoin ethereum, I think it's still secure, but still the rest of them are very in danger. It's not the number of attack, but rather the cost of performance attack, more related to absolute value of hash power. This is one of key observations we see.
00:07:59.770 - 00:08:01.480, Speaker C: Yeah, that we agree on.
00:08:02.250 - 00:08:06.294, Speaker A: There's even bigger problems with VRW, but yeah, we can keep going.
00:08:06.412 - 00:08:59.410, Speaker B: Okay, now, decentralization, let me, an interesting thing is that actually ethereum, after the fork, the hash power reduced to 136. Guessing where out of this 40s hash power terrahash where they move. Okay, decentralization. So a lot of people say, oh, one key property of blockchain is decentralization. It's very wonderful. But what is the exact definition of decentralization? Maybe I can give some rough definition. First, say, oh, there's no central entity to control the network.
00:08:59.410 - 00:10:17.620, Speaker B: No central entity, or maybe everybody could join the network. Could join or contribute the network, I would say easily. But how to define this? So anybody have question of my rough definition of decentralization? Or maybe better, let's break them from my viewpoint. Let me quantitize. This means, I think there are two numbers. I think when we describe how decentralized network is, I think one is the cost of running a node, a maintain the latest ledger, and second is the cost of producing a block. So first, make sure that I have the latest ledger so that I know, suppose I send a transaction, I can know how many block confirmations, so that I know whether it's finalized or not.
00:10:17.620 - 00:11:19.282, Speaker B: And then I can also for example, build index server to do some specific things with my, for example, D apps or something else. And the second is that make sure that I'm able to effectively contribute to the network by, for example, contribute my hash power or maybe stake to the network. And so let's just discuss this too. So the cost of running a nodes, actually right now, both for bitcoin and Ethereum, they're just using simple commodity pc, for example, single core or dual core cpu with probably one gigabit gigabyte memory. I know some people doing some optimization, how to use 1gb bytes memory to run bitcoin. And probably the major cost is the chain size, which ethereum, I think the latest data is roughly 2.2 terabytes.
00:11:19.282 - 00:11:28.106, Speaker B: And bitcoin, I think is roughly, I forgot, 200 gigs. Hundreds of gigabytes. 200 or 300.
00:11:28.128 - 00:11:29.034, Speaker A: Yeah, probably 300.
00:11:29.072 - 00:11:40.620, Speaker B: Now several hundreds of gigabytes. And that is still affordable for most, I think, users. So that's great.
00:11:41.550 - 00:11:47.454, Speaker A: I mean, depends who you call users, right? If you want to run it on the phone.
00:11:47.572 - 00:11:55.198, Speaker C: It's easy to store 2.2 terabytes. It's very hard to unload 2.2 terabytes. Yeah, over the network.
00:11:55.294 - 00:11:58.770, Speaker A: Also my laptop doesn't have two terabytes of space.
00:11:58.920 - 00:13:16.314, Speaker B: But I will say this still affordable to, I will say a lot of users. Maybe for example, we can easily run thousands of nodes. Like for example, Ethereum have 8000 nodes and bitcoin has roughly close to 10,000 nodes, right? That's just something. But the cost of producing a block, actually I should add some condition without consider POW case because we have most data on this without joining a mining pool, right? If joining mining pool, then it doesn't help because it's centralized. So in what situation and what's the cost can have a miner that just directly contribute to the network without joining a mining pool. And here we need some empirical data which we survey some of the miners to see in what situation you will contribute to the network directly or mine will see mining pool at the price of the fee. And they said if their hash power is greater than 0.1%,
00:13:16.314 - 00:14:25.860, Speaker B: which is one over 1000 of the hash power of the network, then they will likely just directly contribute it. Because contributing to mining pool basically amortize the reward over time. But suppose it has 1000, which means that for bitcoin, like every two weeks it has produced 2060 blocks, right? Which means that every week it can produce one block. And the miner is happy with that, right? Okay, so let me just take this number and see what's the cost if a minor owned this hash power. So back to Ethereum numbers 160 terahash per second divided by 1000, then we have then this minor, we should have this 1. We just consider a graphics car, 1080, which roughly generates 30 need like 5000. Suppose this one, the cheapest price I can find is roughly maybe $300.
00:14:25.860 - 00:14:29.378, Speaker B: Then this number can easily exceed 1 million.
00:14:29.464 - 00:14:30.980, Speaker C: Yeah, it's one and a half million.
00:14:33.030 - 00:14:37.080, Speaker A: And then this is investment. And then you get like two ether every.
00:14:37.770 - 00:14:39.590, Speaker C: Oh, that was bitcoin blocks.
00:14:40.250 - 00:14:42.406, Speaker A: Not with GPU you're not going to.
00:14:42.428 - 00:14:44.802, Speaker C: Mine, but with GPU you will get more blocks.
00:14:44.946 - 00:14:54.374, Speaker B: Yeah, the GPU may be a little bit relaxed, but still it's supposed to be used. This number, then this is still considerable.
00:14:54.502 - 00:14:59.686, Speaker C: But also we know, right, that three mining pools, if they collude, yeah, there's.
00:14:59.718 - 00:15:22.546, Speaker A: Currently three mining pools in Ethereum that control more than 60% of all the powers. They can actually cut out anybody. Like even if you have 0.1%, they will lose less than, what is it, like 100, less than tens of a percent. If they just cut out, you can.
00:15:22.568 - 00:15:32.354, Speaker C: Ignore all your blocks. Like if you have 0.1%, the mining pool can just blacklist your address and never built on top of your blocks. And so your blocks will be permanently removed.
00:15:32.402 - 00:15:36.230, Speaker B: It's kind of like blacklist attack, right? Yeah, always blacklist.
00:15:36.970 - 00:15:46.294, Speaker A: But in proof of work right now it's pretty much proof of authority. There's three authorities in both Ethereum and in bitcoin that controls the network.
00:15:46.422 - 00:15:48.906, Speaker C: Arguably proof of stake is also proof of authority today.
00:15:49.008 - 00:15:52.510, Speaker A: Arguably, but it has more authorities.
00:15:53.330 - 00:16:06.738, Speaker B: Yeah. I think the cost, which we think is here, the cost of this producer block is a significant, I mean, the.
00:16:06.744 - 00:16:19.890, Speaker A: Interesting question is when you say decentralization, right? The value of decentralization is permissionlessness, right? Yeah. This is very permissioned.
00:16:20.230 - 00:16:27.990, Speaker C: Yeah. It's permission to those who can buy 5000 gpus. Cool. Okay, so scalability.
00:16:28.510 - 00:16:29.450, Speaker B: Scalability.
00:16:31.550 - 00:16:32.634, Speaker A: Just no.
00:16:32.832 - 00:16:37.100, Speaker C: Yeah, on scalability, we have no empirical data, right?
00:16:37.950 - 00:16:39.162, Speaker B: Yeah, we do.
00:16:39.216 - 00:16:41.680, Speaker C: Oh, we do. Nice. Let's see.
00:16:42.370 - 00:17:42.046, Speaker B: Actually a lot of data is from SS three paper. Okay, scalability. So why blockchain is so slow? Because compared to centralized entity there are a lot of things completely different. So first blockchain in general have thousands of nodes, like ethereum has 8000 and bitcoin has roughly 10,000. So blockchain, I would say public blockchain, P-U-B. And this will be centralized. And then because every node need to have maintained the full ledger that means it has very high replication, which is 10,000 or 8000.
00:17:42.046 - 00:18:31.134, Speaker B: Depends on network in centralized world it highly depends on how many data centers. Some do the replication, but I would say roughly ten. That's pretty high number. And the network, public blockchain, using Internet, which is slow, which is asynchronous, I can send any message and I won't expect it will return. And it has low throughpro and latency. And in the centralized world Internet I have the dedicated data centers which have dedicated wire to connect these data centers. Sometimes we can use Qos to guarantee this traffic can deliver in some millisecond and the bandwidth can be extremely high.
00:18:31.134 - 00:19:30.974, Speaker B: It can more than 10gb or even more in some data centers where Internet people just have around ten megabytes or 100 megabytes, megabits per second. Let me see any other numbers. Probably this. And so if we for example in a chain increase, for example the block size like or reduce block interval, then we will propagate these blocks within this slow network and all these nodes will take significant amount of time. For example, there's a paper published in 2015, I think the name is called on decentralization of bitcoin, some title like that. It summarized that for bitcoin, with one megabytes, it will take 2.4 minutes to propagate the notes.
00:19:30.974 - 00:19:35.182, Speaker B: To propagate a block to 90 notes.
00:19:35.326 - 00:19:36.114, Speaker C: 90%.
00:19:36.232 - 00:19:37.634, Speaker B: 90% of notes, yeah.
00:19:37.672 - 00:19:39.718, Speaker C: With 1 mb block. How big is the block today?
00:19:39.804 - 00:19:40.418, Speaker A: 1 mb.
00:19:40.434 - 00:19:41.958, Speaker B: Let's do 1.
00:19:41.964 - 00:19:43.222, Speaker C: Thought it was 12 seconds now.
00:19:43.276 - 00:19:45.030, Speaker A: No, bitcoin, 10 minutes.
00:19:45.180 - 00:19:47.314, Speaker C: No, it was 12 seconds to propagate the block.
00:19:47.362 - 00:19:48.626, Speaker A: That's for ethereum.
00:19:48.818 - 00:19:51.190, Speaker C: I thought ethereum block post was referring to bitcoin.
00:19:51.270 - 00:19:53.914, Speaker B: Yeah, ethereum has much smaller block size.
00:19:53.952 - 00:19:59.434, Speaker A: Yeah, smaller blocks. And they have uncles, which kind of solves some of those problems.
00:19:59.552 - 00:20:04.294, Speaker B: It used kind of called ghost algorithm, but partially implemented.
00:20:04.422 - 00:20:19.860, Speaker C: But my understanding was that the original ghost paper, ghost blog post was saying that on bitcoin, it takes 12 seconds to get to 90%. And that's why you need 10 minutes to wait for the blocks. And then they introduced uncles to, yeah, let's say 2 minutes.
00:20:22.310 - 00:21:00.640, Speaker B: But this is just the data from the paper. It may be a little bit faster than this, because the Internet improved after three, four, five years. I forgot this number. But let's just use this number. And since this throughput actually is kind of constant, so, which implies that suppose I have a bitcoin cache, which using the maximum size, which is 32 megabytes, and suppose their notes size is the same as the bitcoin, because right now it's much smaller. Right. And this means that it will take 32 times 2.4,
00:21:00.640 - 00:21:02.942, Speaker B: which is roughly 1 hour.
00:21:03.076 - 00:21:12.494, Speaker C: However, I think this 2.4 minutes, it comes from the fact that in bitcoin, when you receive a block, you validate it before you there's number of hops.
00:21:12.622 - 00:21:16.194, Speaker A: Hops, not the size as much, but.
00:21:16.232 - 00:21:20.182, Speaker C: Also in practice, you can actually, as you receive the block, you can propagate it before you validate it.
00:21:20.236 - 00:21:37.420, Speaker B: I'm not sure the paper add this optimization or not. This is kind of optimization that basically broadcasts as long as it bypassed the header check, and then it will broadcast immediately. Because as long as the difficulty reaches, then it's high probability that the block is valid. Right.
00:21:38.190 - 00:21:42.890, Speaker A: But in general, I mean, it's about hops more than about the size at this point.
00:21:42.960 - 00:22:15.030, Speaker B: Yeah, it's hops, but at the same time, when I suppose, like for example, Ethereum is generally connected to two to 20 nodes or 30 nodes for each node. And I need to broadcast a block to all these things, it's still limited by my local bandwidth, right. So I need to broadcast them. And then there were multiple hops and then broadcast, broadcast. And this is the empirical data to say why we cannot. It's very hard to optimize this number. Definitely if I have more nodes, then the number can be even worse.
00:22:15.030 - 00:22:59.880, Speaker B: Okay, so we see that. Okay, why is low? Because we have this network constraint especially it is latency sensitive. That is, from one node to block us to arbitrary public nodes, it takes time. And this time can create the probability of fork or steel block. And which means that suppose we have 10% of blocks are still. That means only 90% of the hash power is contributed to the selected chain, which means that the attacker can just using 45% of hash power to attack network. And this makes further security issue.
00:22:59.880 - 00:23:06.326, Speaker B: Okay, so this is basically the review of what we saw, this three problem.
00:23:06.508 - 00:23:23.422, Speaker A: But you're using size as kind of main weight of the block, which I think in smart contract platforms, kind of moving towards more how much computation actually it takes. Bandwidth is not as important part, but not everything.
00:23:23.556 - 00:24:08.410, Speaker B: That's correct. Actually when we discuss our approach to bitcoin, Bitman, this is actually from bitcoin network. The main cost is still network. It's not the cpu because it can process each block very fast. But Ethereum network processing smart contract transactions takes extra time. And that's why Ethereum adopt very small block interval and adopting this ghost algorithm and speed up the block ray so that the cpu can be also better utilized. Otherwise, suppose I send one megabytes with smart contract, then the cpu would take maybe several seconds to process this smart contract.
00:24:08.410 - 00:24:10.446, Speaker B: Yeah, nice.
00:24:10.548 - 00:24:16.142, Speaker C: Cool. Okay, let's see how quarkchain solves all of that.
00:24:16.276 - 00:25:02.990, Speaker B: Yeah, let's go to our solution or maybe our trade off. So we see this like there's a security problem, decentralization problem, and scalability problem. There are actually two ways to address these two problem. One way is to adopt large block size, straightforward, like shorten the block interval. For example, litecoin decreased block time from 10 minutes to 12.5 minutes, claim four times. And bitcoin cash improved this number to 32 megabytes and bitcoin cash.
00:25:02.990 - 00:25:10.586, Speaker B: Satoshi vision further increased this number, if my memory is correct, to 1gb or 1gb.
00:25:10.698 - 00:25:12.474, Speaker C: I thought it was 128, but yeah.
00:25:12.532 - 00:25:47.434, Speaker B: Something big, something even bigger. I think it aims to improve one gigabytes. Probably right now it's still 128. And Ethereum adopt this called ghost algorithm. Basically tried to include those uncles or steel blocks into the rewards. But it actually partially implemented because the difficulty of these uncles are not counted towards total difficulties, which means they still have hash power loss problem.
00:25:47.632 - 00:26:08.340, Speaker A: Well, also, I mean, what conflux is doing, you can also just include those blocks in your full range, right? And then speed up even more. Like if you already have those uncle blocks in your chain, you actually can use them to include the transactions in those blocks that were not included in main chain as well.
00:26:08.950 - 00:26:46.362, Speaker B: Yes, but still, I think people have a calculation like probably this off topic, like half ghost, I'm not sure. So basically calculations say, hey, there's a basically block rate by using the ghost algorithm, but there's also called transaction rate because there's an overlap of these transactions in these blocks. So the block rate can be higher, but the transaction rate still have different slope. So I think some people have done some study on that, but I'm not sure it's related.
00:26:46.506 - 00:26:56.606, Speaker A: I mean, yeah, it's related. Like you can also adopt some technique to sample transactions better if you know that all those blocks will be included. Anyway, that is off topic.
00:26:56.638 - 00:28:06.626, Speaker B: Yes. Okay, so another solution which I think we call maybe kind of naive version of charlene, is using multiple blockchains, right? And so we have, suppose we have 10,100 blockchains, each of them running maybe like Ethereum, like ECC or etc. But then definitely we quickly enter a hash power dilution problem which we can find chain with only one over 100 hash power. I can easily attack it and so say, hey, it's possible that we are able to combine these two and then come up with a solution that may be better, adjust the problem. And this is how we are going to propose is we have a two layer blockchain. The first layer we call shoddy blockchain. It's a list of the blockchains that process non OLAP transactions.
00:28:06.626 - 00:29:07.420, Speaker B: Non OlaP means there's an azure space that partition these transactions, senders or recipients to different chains. Make sure like goals like this have overlap transactions. And then to address this core hash power dilution issue, there's called root chain. Actually the root chain itself does not contain any transactions, but it's basically it has hash pointer to blocks as normal blockchain. Its body is a list of hash pointers to the shorter blockchains. And as long as this body consists of valid sequence of solid chain, then this root block is valid.
00:29:07.920 - 00:29:18.208, Speaker C: And so on the short chain, the fork choice rule will always favor the latest block which appears on the root chain, right?
00:29:18.374 - 00:29:18.944, Speaker B: That's correct.
00:29:18.982 - 00:29:29.520, Speaker C: So let's say someone created a longer chain, right? Like from here they created a longer chain. Yes, but for as long as this block is here and this one is not, this one will be all preferred.
00:29:29.600 - 00:30:11.964, Speaker B: Will be always preferred. And actually in this case, even for this case, because for this one, its corresponding ledger, the Full ledger is not including this one, because this is corresponding to this one, the corresponding full ledger is this one and plus this one. So its corresponding root chain is still this one. So even for this one it's still this one. So no matter how long this it is, the attack will always fail. We call root chain first for choice rule. So the good thing of this is that for any block that is confirmed by the rootblock, it will be automatically protected by the rootblock.
00:30:11.964 - 00:30:27.104, Speaker B: And suppose the rootblock has significant amount of hash power, like bitcoin ethereum. That means that all the shardy blockchain they can be protected by the root block. And this is basically key idea.
00:30:27.242 - 00:31:26.200, Speaker C: But here's the question, right? So let's say we have five people or like five gigahashes are mining this chain, right? Let's say like five gigahashes mining this chain. And let's say we have 170 terrahashes mining this chain. So this chain is significantly more secure. But a particular validator here, right? So let's say there's a particular machine that is mining here, right? That his machine cannot validate all the blocks, right? So effectively when someone mines a block over here and they send it to the root chain, the root chain, all that it knows is that 5 attesting to the validity of the block. But they don't know that the block is valid, right? So if I'm corrupting this 5 can produce a block which is completely invalid.
00:31:27.020 - 00:31:30.136, Speaker B: How to corrupt this 5?
00:31:30.158 - 00:31:38.268, Speaker C: Bring ten more gigahertz of malicious. So I myself control 10 ghz, which is a very small percentage of this, right? Yes, I bring 10 ghz here, you.
00:31:38.274 - 00:31:40.316, Speaker B: Can only create a new block, right?
00:31:40.338 - 00:31:45.348, Speaker C: And I create a new block, but this block is completely invalid. So let's say it can't.
00:31:45.464 - 00:31:50.210, Speaker B: But all the rest nodes will reject this ten invalid block, right?
00:31:50.740 - 00:31:54.610, Speaker A: No, but with 10 can just produce your own chain, right?
00:31:55.160 - 00:32:01.270, Speaker C: My chain is longer, right? So how does root chain. So let's say I created this invalid block, right?
00:32:03.080 - 00:32:08.884, Speaker B: Maybe one is invalid block, another is maybe attacking fork or longer fork or some, but longer.
00:32:08.922 - 00:32:22.536, Speaker C: I can see how this protects against longer, right? But let's say 5 will use green for honest. Okay, so 5 something I rented on nice hash. Nice hash on nice hash.
00:32:22.568 - 00:32:23.310, Speaker B: No problem.
00:32:24.320 - 00:32:30.536, Speaker C: And I created a block, and in this block, this block is completely invalid. In this block I just said invalid.
00:32:30.568 - 00:32:35.984, Speaker B: Is like for example, I can mine additional coin or maybe, okay, and then.
00:32:36.022 - 00:33:01.832, Speaker C: Obviously this 5 ghz say, oh, this block is invalid. We're going to continue building this blockchain and they continue building on this blockchain. But I'm faster, right? So I, as a malicious actor, I'm building a longer chain. And so both of us sending the blocks to the root chain, right? How does this particular person on the root chain know which one to snapshot into the root chain block that comes.
00:33:01.886 - 00:33:29.740, Speaker B: To our definition of what kind of decentralization we are going to address? So basically there are two problems. One is cost of running a node, and second is cost of producing a block. So you see that running a node is, we believe is more bottleneck than running. Producing a block is more bottleneck of running a node. So we assume the network, the node actually is running the full ledger. Kalo dag.
00:33:29.820 - 00:33:34.504, Speaker C: Oh, so you're saying this person, they actually have a node for every shard?
00:33:34.572 - 00:34:19.964, Speaker B: Yeah, but the point is that we have built called a cluster design, which allows you can imagine a node, a super node, or a cluster that is able to distribute all this sharp task from its submachines. This is we can't call. If there is the world computer, then we say we are the world cloud, right? And because we see compared to the cost, like to contribute this directly running a node cost is much, much less. And suppose we just need to spend maybe $10,000 to maintain this node. But we allow more people to join network than we see. We believe we are achieving some kind of more decentralization than existing network.
00:34:20.012 - 00:34:24.540, Speaker C: And 10,000 is per shard, or 10,000 you think is the price of a.
00:34:24.550 - 00:34:26.944, Speaker B: Full cluster is us dollar.
00:34:27.072 - 00:34:29.460, Speaker C: But is it full cluster or is it one shard.
00:34:31.800 - 00:34:33.040, Speaker A: For the full cluster?
00:34:33.120 - 00:34:47.768, Speaker B: It highly depends on the future TPS of the network because these shards can be added, right? If the network is more value, then there will be more people to run the node. And probably this will become maybe higher than the production. And we would love to see that.
00:34:47.854 - 00:34:54.828, Speaker C: But when you say 10,000, does it refer to the cost? Like, how many shards do you have in mind when you.
00:34:54.914 - 00:34:58.008, Speaker B: Right now my laptop can run like easily run eight shards.
00:34:58.104 - 00:34:58.792, Speaker C: A charts?
00:34:58.856 - 00:35:21.172, Speaker B: Yes. Let me see. We have our testnet that is able to run 256 shorts. I think that will cost how much? We have 50 nodes. I need to check with that.
00:35:21.306 - 00:35:22.944, Speaker C: But 15 nodes is one cluster.
00:35:22.992 - 00:35:23.588, Speaker B: Right.
00:35:23.754 - 00:35:25.668, Speaker C: So you have a cluster which can.
00:35:25.754 - 00:35:28.764, Speaker A: Consist of 50 cluster, 50 node cluster.
00:35:28.832 - 00:35:37.800, Speaker B: 50 clusters. Each cluster runs 129 nodes with one runs for root chain and 128 runs for two shots.
00:35:38.780 - 00:35:40.920, Speaker C: And each node is a separate machine.
00:35:41.000 - 00:35:48.140, Speaker B: Effectively separate machine. Yes, separate processes using TCP ipis.
00:35:54.440 - 00:36:06.150, Speaker C: For me to fully understand. So one cluster is an abstract term for one or multiple entities running one process per shard, right?
00:36:06.600 - 00:36:06.916, Speaker B: Yes.
00:36:06.938 - 00:36:11.530, Speaker C: So if you have 128 shards, a cluster would be 128.
00:36:13.020 - 00:36:14.650, Speaker A: You said it was two.
00:36:15.020 - 00:36:21.064, Speaker B: It can be arbitrary combination, it can be one processes run multiple shards, but at least one process run one.
00:36:21.102 - 00:36:31.048, Speaker C: One shard and one root chain. Right. So one cluster is one independent snapshot of a chain. One independent snapshot processing entity.
00:36:31.144 - 00:36:34.236, Speaker B: Yeah. Maintains full ledger of the chain.
00:36:34.348 - 00:36:38.524, Speaker C: And you would expect mostly one cluster to be controlled fully by a single entity.
00:36:38.572 - 00:36:43.612, Speaker B: Right. It can be single entity or controlled by friends or trusted entities.
00:36:43.676 - 00:36:44.960, Speaker C: I would say trusted entities.
00:36:45.640 - 00:36:48.980, Speaker A: That's pretty much a new pool, but.
00:36:49.050 - 00:36:52.310, Speaker C: It'S a trusted pool, and there's no slashing. It's proof of work.
00:36:54.920 - 00:36:58.368, Speaker A: And then which hash function or what's.
00:36:58.384 - 00:36:59.476, Speaker C: A proof of work?
00:36:59.658 - 00:37:05.732, Speaker B: Any hash function. Actually, one problem. If you use block, it can use any consensus.
00:37:05.796 - 00:37:06.024, Speaker A: Yeah.
00:37:06.062 - 00:37:28.224, Speaker B: It doesn't need to be proof of work. Sure. It can be this. Using proof of work. And use this hash, hash value as kind of c to select proof of stake validators, because it is so strong hash power. So, making treat on this for one validator or one set validator on one shard is not. Probably not highly amorphic, right.
00:37:28.224 - 00:38:00.648, Speaker B: It can be also run for work with different hash algorithms. Actually, it is similar to existing, like a mix of ethereum. All this, but with more ways so that everybody can join the hash power of the root chain. Pathetic by it, we call kind of actually any shard that is added in flight. So, for example, we can add a Shaw per year. This year, one Shaw, another year, one Shaw. And the shaw will immediately be protected by the hash power.
00:38:00.648 - 00:38:12.632, Speaker B: And we call this called hash power reuse technique. It's kind of, kind of reuse because we use standard libraries. Why don't we use Sim standard hash, maybe pool of something to protect new chains.
00:38:12.696 - 00:38:32.150, Speaker A: I mean, the question is pretty much, yeah, if I'm mining the root chain, pretty much makes sense for me to run this, because if this is, like, 170 terrahashes, I need to invest a million dollars in gpus, I may as well run this. But if I'm mining one of the shark chains, right, I will not be doing this, right?
00:38:32.520 - 00:38:50.076, Speaker B: Depends. For example, let me back to previous equation. So for this, suppose I have a shards. Let's just using some numbers. A shards. Oh, I forgot. Let's just expect to suppose all of them using the same hash power.
00:38:50.076 - 00:39:40.364, Speaker B: This probably the simplest case. So we have called tax mechanism. So that some portion, for example, two third of the block rewards minus reward will be allocated to Ruchain, and one third will be allocated to each other shards. In that situation, then the cost of joining the pool will be original number, maybe one megabytes, 1 million divided by eight shards and divided by three, which I think is close to this number. Right. My question is, so as long as the cost of running a node is smaller than this month number, then my.
00:39:40.402 - 00:39:53.890, Speaker A: Question is, why do you need hash power here at all? Why don't you say anybody can produce blocks with. No. Everybody who's checking in them in the root chain will validate them anyway.
00:39:54.500 - 00:39:55.152, Speaker B: Yes.
00:39:55.286 - 00:40:06.012, Speaker A: So why not just produce blocks? They check them in, validate the correct block. Why do we need any hash power here whatsoever? Why not just have block producers just throw in the blocks?
00:40:06.076 - 00:40:08.916, Speaker B: You mean the block producer just include all the blocks? Right.
00:40:09.018 - 00:40:16.016, Speaker A: Or even better, the root chain runners, because they all have all the chains anyway running, they may as well produce.
00:40:16.048 - 00:40:28.516, Speaker B: All the blocks that essentially, actually. So we have this cortex. Right. Tax to adjust this hash power between them. Essentially. This has no hash power. Basically, there's no incentive.
00:40:28.516 - 00:40:34.844, Speaker B: And this is one. Right. All the incentive is allocated to here. So that nobody tried to mine it.
00:40:34.882 - 00:40:50.172, Speaker A: No, but let's say I'm running this cluster and I have million dollars of gpus to produce blocks on a root chain. Yeah, why not? I will just produce all of the blocks, all the shards.
00:40:50.236 - 00:40:51.600, Speaker C: But that would be effectively.
00:40:53.940 - 00:41:02.000, Speaker A: Even if it's one third, I'll get all of the one third as well, because I produce the blocks. I'll produce the blocks and include them into the next root shard chain.
00:41:02.160 - 00:41:08.048, Speaker C: But if it's one third here and two thirds here, you need to do the work separately.
00:41:08.224 - 00:41:12.168, Speaker A: Well, I mean, it's five k. Like, this is so much.
00:41:12.254 - 00:41:27.710, Speaker B: No, in that case, this will be divided by two. So this will be one. Seven terrahash divided by eight, divided by two. Right. This will be the actual hash power of this. Otherwise, it will call. Because this is a market.
00:41:30.320 - 00:41:31.852, Speaker C: 60 terrahash here.
00:41:31.986 - 00:41:33.320, Speaker B: Right? 16 terrahash.
00:41:33.400 - 00:41:45.964, Speaker A: Well, I mean, my question is, why do you separate them at all? Why not? Just, like, if you already have those clusters running, what is the value of having some of the people producing?
00:41:46.092 - 00:41:48.272, Speaker C: Well, the idea, someone needs to propose blocks.
00:41:48.416 - 00:41:54.900, Speaker A: Yeah, but these folks can propose blocks very efficiently because they have the full state of the chain, of all the chains.
00:41:55.480 - 00:42:02.010, Speaker C: But how do you choose the block that is like simultaneously 1000 blocks are proposed from 1000 clusters, which one do you choose?
00:42:02.780 - 00:42:06.344, Speaker A: But you proposing a root chain block, right.
00:42:06.462 - 00:42:11.700, Speaker C: These blocks need to be produced significantly faster than the root chain. Root chain is like once a minute. This is once every 5 seconds.
00:42:11.860 - 00:42:14.430, Speaker B: Yeah, maybe 10 seconds at a moment.
00:42:15.280 - 00:42:18.392, Speaker A: You can still produce like if you are running this cluster, you can be producing.
00:42:18.456 - 00:42:23.212, Speaker C: That's basically what happens. You have one third of hash power here just to order them in some way.
00:42:23.266 - 00:42:27.040, Speaker A: Yeah. And then you snapshot it yourself with rootblocks.
00:42:27.540 - 00:42:57.476, Speaker B: Probably. Maybe I can explain this way. Suppose we have no incentive of producing a block here, so that has no hash power. So basically the root block can just include whatever it wants. And this is essentially the problem. The same solution as large block size, right? Essentially the same. And suppose we have no hash power on the root chain and remove root chain first consensus and distribute all the hash power to all the shard block.
00:42:57.476 - 00:43:59.470, Speaker B: That's essentially the same as multiple blockchain. That's why we adjust this tax aims to harvest both benefits. Especially why we do not move all this, because when we propagate this large block, as I mentioned before, it is latency sensitive. But if we have multiple blocks, produce block simultaneously and asynchronously, because this guy produced his block, this guy produces block. So originally the network usage of bitcoin, you can imagine like this, there's a block receive after roughly 10 minutes, another block receive, there's a little bit traffic for receiving transactions and there's another receive, right? So it is latency sensitive, but a lot of bandwidth are not being used. So now we have another, you can imagine each one is basically described, but with summation so that another 1 may be like this, like this, like this, like this. Another traffic is like this.
00:43:59.470 - 00:44:04.930, Speaker B: And with summation of this, we want this bandwidth to be like this, right?
00:44:09.780 - 00:44:18.500, Speaker C: Yep. Yeah, that makes sense. I think it's somewhat similar to bitcoin ng. That's like an older paper, I think from Amin.
00:44:19.160 - 00:45:15.552, Speaker B: Yeah, I think bitcoin ng, there's some inspiration from them, but I think it just have one of effectively, and in addition, this doesn't have its consensus. But now we extend this to its consensus. And for example, I can have one of them using maybe depots. And so for the users that would like to have instant finality and then we can also have another one, maybe runs different ledger of virtual machine. For example, maybe one wimble wimbles type of. And then we can build kind of in crossroads transactions to make sure I can send maybe ethereum like tokens to that rainbow wimble chain and do the privacy preserve transaction on that and move back. And all these bins is decentralized in my definition.
00:45:15.616 - 00:45:20.136, Speaker A: Okay, so yeah, how do you do crosshair transactions in this case?
00:45:20.238 - 00:45:43.088, Speaker B: Yeah, that's a great question. So basically, let's just consider a simple crosshair transaction. Example, balance transfer. For smart contract, we can also apply similar principles. So for balance balance transfer, basically there's two sub operations. One is withdraw money from source balance and then deposit the balance to destination. Right.
00:45:43.088 - 00:46:33.424, Speaker B: And unfortunately in cross short transaction, this has to be done in asynchronous way, because in short transaction it just done within a block synchronously. So basically there are two major problems. So one, how to guarantee it is secure, because suppose the money is already deposited to the destination shore while the original shore being spent. Then how to make sure that the money will not be, for example, mining with extra supply. And another is how to make sure this transaction deposit will be being included. What is the token economy or incentive to one destination shall like to include it. I don't care.
00:46:33.424 - 00:47:04.410, Speaker B: Right. So first question, atomicity. Let's just, let me see. Yeah, probably. Let me just simplify the graph like this. Let's just assume there's a transaction here that is going to send from sha zero. Sha one goes to send to sha one.
00:47:04.410 - 00:47:44.950, Speaker B: And here in our design, actually for every SHA blocks, besides it has a hash pointer point to previous block. It also has a hash pointer point to previous root block. Point to a root block. For example, this can be this root block. And based on their best observation, it does not guarantee to observe. Maybe the block just in front of it. It can be the block before each block, but as long as this one, they.
00:47:44.950 - 00:48:21.708, Speaker B: So we have a lot of the same chain chat in our code. And so for this one, for this block, suppose it will not process this crosshair transaction until it observe the root block that contains this block. This basically becomes a partial order. Right. And with root chain, first consensus. Now back to that. If I want to revert this block, which means I want to also revert.
00:48:21.724 - 00:48:24.788, Speaker C: This block, which will also invalidate this block, I guess. Yeah.
00:48:24.954 - 00:49:21.376, Speaker B: And this makes sure we always guarantee this happened after relationship with these two sub, I would say sub operations. Okay, this is first automicity. And second is regarding the incentive. So for each block it has two gas limits. Unlike ethereum, ethereum have maybe called local gas limit, another cross gas limit. The cross gas limit is doing what? Actually, for each block header, it has a cursor which tells what is the last caution transaction. And the block is being executed.
00:49:21.376 - 00:49:41.656, Speaker B: Like for example, the cursor. Because this contains a list of these blocks, right? This contains a list. So it contains, for example, a cursor says, oh, the last block, I process this crosshair transaction of corresponding this block and the transaction id there for each.
00:49:41.678 - 00:49:42.868, Speaker A: Of the other shards.
00:49:42.884 - 00:49:44.796, Speaker B: Pretty much, yeah, for other.
00:49:44.978 - 00:49:48.060, Speaker C: And the root chain contains all the crosshard transactions?
00:49:48.400 - 00:49:54.720, Speaker B: No, it just contains the headers, the hash pointers. But it will process this.
00:49:54.790 - 00:50:00.000, Speaker C: Oh, the cursor points to the particular block and the particular transaction within the block.
00:50:02.500 - 00:50:04.124, Speaker B: Actually index. Just index.
00:50:04.172 - 00:50:05.890, Speaker C: Index of the transaction, yes.
00:50:06.260 - 00:50:10.336, Speaker A: Wait, so this shard needed to receive the full block from the other shard?
00:50:10.368 - 00:50:44.588, Speaker B: No, actually, when the block is being received, it will broadcast all the cost shard transaction to all the shards within the cluster. This is classic, I would say crossword transaction design. Because if I put it in rubric, then definitely rubblock will be followed. So it will basically broadcast to all the guy. So once this one observe this block, all the corresponding course of transaction of the block included by this root block is already observed by this guy stored.
00:50:44.604 - 00:50:48.800, Speaker A: In the local, in a mempool in a cross shard pool.
00:50:49.860 - 00:50:53.980, Speaker C: And there is a very specific order in which crosshard transactions are executed, right?
00:50:54.150 - 00:51:04.832, Speaker B: Yeah. It depends on the order in the block in this block, and then the order is included in the root block.
00:51:04.896 - 00:51:11.364, Speaker A: So root blocks actually order all of the other shards blocks in some full order.
00:51:11.482 - 00:51:18.744, Speaker B: It must be full order. Otherwise it will include invalid shard blocks. Right? Because it described the canonical chain of.
00:51:18.782 - 00:51:32.348, Speaker A: All the shard chains, but also across all the canonical across all the shard chains. What is the order between them as well? Because how do I know? Should I be executing cross shard from here first or from here? Right?
00:51:32.434 - 00:51:38.876, Speaker B: Yeah. So suppose there's a block here, right? That's also included by this one. So this root block will first, probably first include this block.
00:51:38.908 - 00:51:42.832, Speaker A: Yeah. So it's a list. It's not per shard. It's actually a full list.
00:51:42.966 - 00:51:45.652, Speaker B: It's a list that enumerates list.
00:51:45.706 - 00:51:56.790, Speaker A: Yeah. It says like shard one block 23, shard two block 27, shard one block 24, et cetera. So it's a full order.
00:52:00.620 - 00:52:25.216, Speaker B: We also have defined this neighbor relationship just in case. We have a lot of shorts, maybe thousands of shorts. Direct to direct communication of this will cause this cross transaction communication cost to be n square, which n is number of shards. So if we fix this number, so this will be m square, n times number of the number of shards. So this is total cost.
00:52:25.318 - 00:52:41.300, Speaker C: And then you will just route the transit like they will be rerouted. Imagine there's like three shards. Let's say there's four shards. So this is not blocks, this is shards. I should have used some other symbol. And let's say they connected like this. And I want to send transaction from here.
00:52:41.300 - 00:52:48.808, Speaker C: This is source, this is destination, right? So I will just go. I will not send it directly. I will route it, right?
00:52:48.894 - 00:52:49.240, Speaker B: Yeah.
00:52:49.310 - 00:53:01.560, Speaker C: So effectively. So this block, this Shard. Sorry. They will produce a block that will include this transaction. And they will do nothing with it. They will just include the.
00:53:01.630 - 00:53:32.100, Speaker B: But that's a little bit early. Because in our experiment, even to 10,024 shorts, we still pick the cluster, can still process this crosshair transaction efficiently, at least. I haven't test 110, 24, but 256, we test maybe 7% of crosshair transaction. We haven't seen any performance degradation. So once we reach that stage, then we will consider this problem. But then we say, oh, looks like this is not the only problem we want to solve at this moment. Another way is that we have this called wallet.
00:53:32.100 - 00:53:58.990, Speaker B: Even so, basically, this is automatic routing, right? So basically, I tell source destination and automatic routing. And we can also use the wallet deck to do some manual routing by issue multiple cross transactions. But that will be probably a little annoying to users. But at least at the current moment. For example, our test network 256 and test different percentage of crosshard transaction. And we haven't seen any performance degradation there.
00:54:01.540 - 00:54:12.556, Speaker A: Okay, so one question here is. So let's say there's a local gas, and you said there's a crosshard gas. How does this shard actually get the cross shard gas?
00:54:12.748 - 00:54:15.984, Speaker B: So it process this one by one, right?
00:54:16.022 - 00:54:16.320, Speaker A: Yeah.
00:54:16.390 - 00:54:18.824, Speaker B: It will consume the cross shard gas.
00:54:18.892 - 00:54:29.204, Speaker A: So when you send a transaction here, you actually deduct whatever much money plus the fee. Yes, plus the remote fee. Pretty much.
00:54:29.402 - 00:54:33.032, Speaker C: But the fee is spent because you cannot deduct fee here, right?
00:54:33.086 - 00:54:34.250, Speaker A: Yeah, exactly.
00:54:34.700 - 00:54:41.048, Speaker C: So for payments, it makes sense, right? But let's say it's a smart contract. You don't know yet how much gas will be spent on the second shard, right?
00:54:41.134 - 00:54:44.344, Speaker B: No, because the stock gas audience is specified by the initial transaction.
00:54:44.392 - 00:54:47.752, Speaker C: I see. You just subtract the maximum gas.
00:54:47.896 - 00:54:50.636, Speaker A: No, you specify how much gas, but.
00:54:50.658 - 00:54:54.060, Speaker C: Like in Ethereum, for example, I specify how much gas, but I get refunded.
00:54:54.140 - 00:55:46.112, Speaker B: Yeah, so there's a refund but refund thanks to our addressing space, I would say every 160 bit we call public key in Ethereum address. But we call recipient has corresponding address in all chains. So in this case we won't return this remaining back to this account. Because we feel this is make cross transition very efficient. It will just refound to a local account by changing I would say another 32 bits like IP address to indicate which shy is basically operating. And so it will return to the local. And because we see this is very small amount and we have this smart wallet to able to collect all this.
00:55:46.112 - 00:55:51.570, Speaker B: If user file out there too many balances in different shards and they want to collect back.
00:55:53.140 - 00:56:03.140, Speaker A: So if everybody has accounts, if I'm sending money, if everybody has accounts on all the shards, I can just send it on the same shard, right? Most of the times.
00:56:03.210 - 00:56:04.468, Speaker B: But smart contract is different.
00:56:04.554 - 00:56:06.100, Speaker A: Yeah. For smart contract, sure.
00:56:06.170 - 00:56:08.230, Speaker C: That's fleeted design, right? Yeah.
00:56:10.780 - 00:57:02.520, Speaker B: Actually in our design the cost like for example ethereum is doing a course of transaction is roughly we have to start with this gas, initial, initial transaction is this gas? Right. So we add another 9000 to the cost of transaction. This is basically kind of the cost gas cost for internal transfer. Because you treat this kind of like it runs a big smart contract with internal transfer. And so actually the cost between caution transaction and shut transaction I feel it's not so significant. So the user, for example, if you give me address, I don't manipulate this address, I say I want to send my local shop because I want to save a tiny transaction fee.
00:57:03.340 - 00:57:06.312, Speaker A: Well, it depends on how much transaction fees are in the system.
00:57:06.366 - 00:57:11.470, Speaker B: But yeah, that depends on gas price. The gas price, right. So this times gas price.
00:57:19.520 - 00:57:23.310, Speaker C: Cool. Did we cover everything?
00:57:23.840 - 00:57:24.396, Speaker A: Yeah.
00:57:24.498 - 00:57:25.148, Speaker C: Awesome.
00:57:25.314 - 00:57:25.692, Speaker B: Okay.
00:57:25.746 - 00:57:33.472, Speaker A: All right, cool. Well, thanks a lot. Please check out chain white paper testnet and leave comments on YouTube.
00:57:33.656 - 00:57:34.084, Speaker C: Thank you.
00:57:34.122 - 00:57:34.370, Speaker B: Thank you.

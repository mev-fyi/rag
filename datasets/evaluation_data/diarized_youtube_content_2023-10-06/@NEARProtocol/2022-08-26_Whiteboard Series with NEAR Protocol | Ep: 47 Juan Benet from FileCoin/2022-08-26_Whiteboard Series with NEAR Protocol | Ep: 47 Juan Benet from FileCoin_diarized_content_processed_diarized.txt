00:00:04.410 - 00:00:15.662, Speaker A: Hello, everyone. We're here in Austin after consensus with Juan, founder of Protocol Labs, and we're going to dive in into filecoin. But before that, Juan, please introduce yourself.
00:00:15.796 - 00:00:29.960, Speaker B: Yeah, thanks for having me. My name is Juan. I started ipfs and Filecoin, and I'm the founder of Protocol Labs. And yeah, I work on a lot of different network protocols and have been around in the web three community for quite a while.
00:00:30.570 - 00:00:33.750, Speaker A: Yeah, pretty much the most OG stuff.
00:00:33.900 - 00:01:12.050, Speaker B: Yeah. Great. So today we're going to go through the Falcoin protocol, and in order to get there, we're going to learn a little bit about Lipidop and ipfs. So just what we need from lipid to p and ipfs to get to filecoin. And then within Falcon, we're going to cover just the core proof system and how that works and how we build up a storage market out of that. And then we can get into a lot of the interesting dynamics that sort of emerge out of the economic structures of falcoin. Cool.
00:01:12.050 - 00:02:29.402, Speaker B: So maybe let's just very briefly describe liquidity ipfs and then kind of get to falcoin. The goal here is to be able to build a market where you have storage providers and clients, and you're able to transact here between a network of participants, where a lot of participants are bringing storage and a lot of participants want to buy that storage. And you want to enable this to happen with crypto in a decentralized network with high integrity and verifiability of the storage and all that kind of stuff. How do we get there? Lipidopy first, and won't dive into too much detail, but LipiDP is a modular network stack that lets you connect lots of different peers using peer to peer protocols, using cryptography that doesn't rely on any kind of central authority or anything like that. It's all self certifying crypto. So that means you're using mostly public key crypto, and it deals with a bunch of important self description constraints to enable many different kinds of protocols to ride on top of lipidopy. This is why now LipiDP is used by a ton of different blockchains to build up their system.
00:02:29.402 - 00:03:38.610, Speaker B: So it's kind of like the missing peer to peer network stack that maybe should have been built in the early 2000s, but we sort of extracted it out of ipfs. So many people could use all of the peer to peer magic that makes ipfs work for a bunch of other systems. And kind of what you get out of this is that you can build a network of any kind of topology that you want and design the connectivity here depending on the protocol structure that you choose. So you kind of like plug in components into this network stack depending on what your kind of user protocol wants, right? So it gives you, first of all, transport independence. So you can use things like TCP if you want, but you can also use quick or you can use SATP or any kind of reliability protocol that you want, or you can even use unreliable protocols as well. And then Liberty has a kind of bag of modules that you can then kind of start plugging in. So it gives you things like, know, cadmly is a famous DHT implementation, probably like the biggest, most widely deployed DHT.
00:03:38.610 - 00:04:05.450, Speaker B: Then it gives you things like pub sub, there's a lot of different protocols that can give you this and so on. There's a bunch of different kinds of network protocols that you may want to use in a peer to peer network. And lipidp just kind of assembles a lot of different interoperable modules that you can kind of plug in like Lego bricks into building some peer to peer protocol. Any questions so far?
00:04:05.600 - 00:04:51.802, Speaker A: Well, I mean, yeah, I am somewhat familiar with the p to P, so I would say there's the transport layer, right. That just offers a bunch of options. There is kind of the peer layer where I think the important to note is that it has a public key, private key cryptography, which what's missing in general, peer to peer communication. Right. And then you have kind of this more advanced protocols. For me, obviously, I'm always interested in DHTs kind of, and specifics of when they're applied in a protocol, because of economics, they can be broken, right?
00:04:51.856 - 00:04:52.314, Speaker B: Yes.
00:04:52.432 - 00:04:58.954, Speaker A: And because there's a lot of attack surface on this layer that people usually don't mention, but we can dive in.
00:04:58.992 - 00:05:42.570, Speaker B: I guess, as you progress. That's a great point. I tend to think that most blockchains are kind of broken in the message passing layer of the broadcasting of the blocks, but I guess nobody has quite attacked that layer very much. One thing to mention, with a lot of the lipidop modules out there, there are good incentivized analogs that are good open problems to build, right? So people could go and build an incentivized DHT, people could build incentivized pub sub and so on. And all of those kind of are like really good primitives that could build a much more robust web three and blockchain systems. And so it's one of these things where those could be extremely good primitives for people to then depend on.
00:05:42.720 - 00:05:46.300, Speaker A: So you're saying this is two projects to go and build.
00:05:47.150 - 00:06:08.482, Speaker B: Yeah, exactly. Many, right. Because there are probably a few dozen different variations in dhts that give you different kind of properties. And so out of those you might end up with like three to five different dhts that offer you those different properties. And there's like five incentivized networks here or five incentive device networks here.
00:06:08.536 - 00:06:21.878, Speaker A: I mean I know there's few of pub sub versions I think that kind of operate, but I don't think there is. Well outside of Filecoin and being one of the GST and a few others.
00:06:22.044 - 00:07:09.720, Speaker B: Yeah. So out of lipip we get this kind of like peer to peer networking stack where we can kind of plug in a bunch of different protocols and ipfs uses that to build a content addressed data system. So think of it as you want to be able to address information by what the information is instead of by where it is. So it's kind of like a really key point. So in the web today, maybe I'll describe the web case and then kind of make the IPFs case without kind of like going into the details about how exactly it works because it's less. But sort of in the web case you have a URL like this. Today, HTPs, we have like foo.com,
00:07:09.720 - 00:07:31.518, Speaker B: my picture jpEg. And so today this part, the domain maps to an IP address for the most part. And so when you're resolving this, it actually usually is like an IP address on a port. By default it's port 80, but you.
00:07:31.524 - 00:07:33.886, Speaker A: Could use one of the ports, htps now for three.
00:07:33.988 - 00:07:36.720, Speaker B: Yeah, that's true. Great point.
00:07:37.170 - 00:07:38.142, Speaker A: That's why I'm here.
00:07:38.196 - 00:08:29.086, Speaker B: Yeah, exactly. Today in the web, if you put in a link at that moment, the moment you load this address, you want to resolve what food.com is in that moment in time, which points you to an IP address and specific server running. And you go and connect to that server and you ask the server for this part, the path, what that means is that all of this information, whatever mypic JPEG is, is not defined in the network until the moment you fetch it and you view it. So this is like a very kind of weak security and it's tuned for immutability and so on. But this gives you an extremely shaky foundation where everything sort of depends on the party that controls this domain and those parties that control these servers. So what IPFs does is that, and.
00:08:29.108 - 00:08:31.326, Speaker A: Also this part as well, which the.
00:08:31.348 - 00:09:29.294, Speaker B: Resolution, which is also a very shaky foundation, super problematic. So what IPFS does is instead of this, you want to map this into a hash tree. So that means ideally you want to resolve this into something like, these are like the old IPFS hashes. Kmfu R suppose that this is like some large hash that identifies what my picture JPEG is and you can build, I'm going to describe how we build up an arbitrary content into a graph like this. But the idea is that from here then you can ask who in the network has this content. And from there you might get the old server 1234, or you might get some other server like 5678. Although of course you want to use cryptographic addresses, not just IP addresses.
00:09:29.294 - 00:09:43.734, Speaker B: So this is kind of like how it maps to each HTP. But ideally this is kind of like a secure links with like crypto public key. This has a public key as well. Man.
00:09:43.772 - 00:09:48.950, Speaker A: This is done because otherwise there can be somebody in the middle who can actually give you something.
00:09:49.100 - 00:09:50.662, Speaker B: Yeah, exactly.
00:09:50.716 - 00:09:52.378, Speaker A: Pretend they're 1234.
00:09:52.544 - 00:10:31.986, Speaker B: But you get super nice security properties out of this because if you map just the names to a hash link, it doesn't matter who serves you the content, you can always verify it. It matches to this hash. And this idea of using hash links is fundamental to most data structures in the web, three world and so on. It's like the fundamental thing that makes Bittorrent work, the fundamental thing that makes git work and all of the blockchains. So the idea of IPFs is like let's take that fundamental primitive and address all content on the web this way. And so this is what's called content addressing. The other version of HTP was location addressing.
00:10:31.986 - 00:11:19.558, Speaker B: You're addressing content by where it is. In this case we're addressing content by what it is. You're sort of deriving a fingerprint of what the content is. So kind of dive into how we generate that. Here's so all content, and this is kind of like traditional file systems stuff and databases stuff. But at the end of the day you can have some drive that has some data on it or you might have a database. These are like an iconic iconography and these might give you some block level storage which sort of splits up this disk in a bunch of regions that you can address.
00:11:19.558 - 00:12:36.560, Speaker B: And this gives you usually some kind of either relational or key value store model. But either way, in this case you end up building a file system hierarchy which ends up being like, it sort of like builds up a tree where this entire tree is kind of like your directory structure, maybenet or whatever, and you kind of explore down and find the specific content that you want. And in this case, you might have something like some tables or an index. Yeah, if this is like a SQL friendly or a relational friendly database, you might have a table like, let's call it table, very generative name here, table one. And it might have a set of rows, each with a set of values and so on. But of course, this is kind of like structured as some data structure of trees as well and so on. At the end of the day, the way that humanity's whole computing platform works is that we store bits and we understand how to access those bits of information through tree structures always.
00:12:36.560 - 00:13:35.052, Speaker B: And so the insight of IPFs is to say, hey, what if these links along the way, instead of being these mushy local references that could be changed at any moment in time? And so on, we're just hash links, secure hash links that give you integrity and verifiability and so on. And so you can take all the data inside of disks of all the data inside databases and then expose it to the world through this interface of hash links. We call our Hashlinks CIDS content identifiers. And there's a bunch of details as to what's kind of in the CID format. It gives you CIDs decorate a hash with some other information that's self describing prefix. So you know how to interpret this hash, because hash functions might break. Hash functions might change, they have different computational requirements.
00:13:35.052 - 00:13:59.032, Speaker B: You might want to change which function you use here. And so you just sort of describe the function that you're going to use, and you also describe the encoding of the data. This is pointing to. This at the end of the day is a pointer. It's pointing to some data structure over here. And also there's like a versioning identifier to know how to read this. And there's a base.
00:13:59.032 - 00:15:02.556, Speaker B: So I won't go super into detail here, but the idea is the core pointer in any IPFS system is these CIDs that give you effectively a memory pointer, like in any operating system or any programming language or anything like that. But it's a pointer that's secure and that works across distributed systems and that works out of cryptography. The way we think about it is that it gives you kind of access to this sort of like universal memory that you can store any information in and retrieve it later just by knowing the CID of it. And that could be a single little 1 kb chunk of data, or smaller. Or it could be as big as the entire file system or as big as a whole database or like the entirety of a blockchain. Right? So when you think of a blockchain, it's this big kind of sequence of blocks with sort of like trees hanging down of it. And all of this is addressed by a hash at any point in time.
00:15:02.556 - 00:15:10.524, Speaker B: And so these hashes can all be CIDs and you can retrieve all of this content through IPFs.
00:15:10.652 - 00:15:20.900, Speaker A: So is this hash, is there structure of this hash? Is this just a blob of data, a hash with this function? But if it's some kind of hierarchy.
00:15:21.240 - 00:15:24.916, Speaker B: Great question. So this is where the encoding part comes in.
00:15:24.938 - 00:15:25.572, Speaker A: I see.
00:15:25.706 - 00:16:24.810, Speaker B: So the reason we need this field is that we need a table that maps the value of that e to some program that's going to be able to decode what's in there. And so this mapping is what enables you to, when you have a pointer like this, read this e field, figure out how to interpret what's in here so that you can traverse it. There's like a default one, which is we call raw, which means it's just a bunch of bits, it's a bunch of ice. We don't know how to read it. That's like a leaf node, it's like a terminal node or something like that. But if you include a pointer here to another object and so on down. And of course this could point to other things and this could actually point back to the same thing.
00:16:24.810 - 00:17:28.510, Speaker B: If you can run this program and interpret this and be able to read the links within this, then you can traverse this whole graph. And so one of the things that givespe has a lot of power is that there's like same defaults, but it enables even older systems that are hash linked to come into this network. So for example, we tend to think of it as the Internet of data structures where you might have a network like git and a network like bitcoin and a network like unixfs, which is the default ipfs one. And git files sort of like all point to each other and so on. And they kind of have local references. So a git repo itself cannot necessarily reference objects in another git repo, but you can sort of make sense of that. And you can have objects that point into here or point into here or point into here and be able to refer to each other based on this encoding file here.
00:17:28.510 - 00:17:34.812, Speaker B: So that means you can take entire git repos and just dump them into ipfs and use all the ipfs tooling to move them around and so on.
00:17:34.866 - 00:17:38.784, Speaker A: And then pretty much reference from new objects yes, exactly.
00:17:38.902 - 00:18:02.810, Speaker B: And so for these older data structure, you kind of have to understand what you have. They make it more complicated because they're not self describing like this. And so you have to know that it is a good data structure and whatnot and so on. This is also generating this new world of IPLD, which has all of the self description within it so that you can understand what's going on.
00:18:03.340 - 00:18:05.320, Speaker A: Makes sense. How big is this library?
00:18:07.260 - 00:18:33.136, Speaker B: This is just governed on GitHub, so you can add a thing by pull request. And where we're headed soon is there's a really cool codec that xpeed Brooklyn from fission is making called auto Encoder, where you can define just a WASM program to run. So you can have a thing called auto encoder here. And this can point to a program.
00:18:33.238 - 00:18:34.976, Speaker A: A program is webassembly that can read.
00:18:34.998 - 00:19:42.980, Speaker B: It exactly the way we've thought about it for many years is like think of it as building a programming language like C or C plus plus or rust or whatever out of these distributed primitives where you might have some memory programs. This points to the v table in C or C plus plus world where you have the functions and the program in wasm. That's kind of decode the rest of the thing. So this lets you build, this is kind of like a distributed programming language on top of all that stuff. We sort of built it up out of underlying primitives, out of this kind of. The option of this is that we have a way of addressing all kinds of content, whether it's like in legacy file systems or in legacy databases or in any of the new web three hash linked things by just decorating all the links along the way with these cids. And then out of that we get verifiability integrity checking.
00:19:42.980 - 00:20:06.000, Speaker B: We get the ability that anybody can servos this content, doesn't matter who has it. And so you get all of the power of Merkel trees and all the power of these hash link data structures, but you get it sort of like across kind of different kinds of systems and across different kinds of protocols and so on. The big thing that IPFs enables is this kind of content addressing.
00:20:09.460 - 00:20:19.680, Speaker A: It's almost independent of exactly how it's laid out on the network. It's independent how it's served. It just kind of exists.
00:20:20.120 - 00:20:50.590, Speaker B: Yes, exactly. And so right now a lot of blockchains don't use cids yet because I guess people don't know about them yet. But the cool thing about this whole system is you can just add a program here to decode this and you're set. And so you can just absorb all the data generated by any hash link system. You can just plug in and you can move it around. So we have examples of moving around raw git repos or different blockchains and whatnot. Cool.
00:20:50.590 - 00:22:10.000, Speaker B: Maybe another component of IPs is that it gives you content addressing and it gives you the peer to peer networking of Lipidp. So it brings all of that in to give you this kind of secure web based on content addressing. And it also solves a lot of very pragmatic problems of how do you make this work in oss, how do you make this work in browsers, how do you make this work in mobile? So just a bunch of implementations of this entire system for different runtimes and different platforms to enable all the things to kind of talk to each other and be able to grab the data and make sense of it and so on. So think of this as over time kind of following the pathway of HTP, where instead of having just a single implementation, that kind of drives everything, instead being a bunch of libraries that let you compose like really small servers or protocols or whatever that speak this whole language and that can all resolve the IPFAs link.com or ETH or whatever you want and then some other content. And one component I'm missing here is this padding. So if we do A-B-C and so on, this is just resolution through this graph.
00:22:10.000 - 00:22:18.872, Speaker B: So we can do something like foo.com or foo eth, get a CID, and then traverse this graph by following the links here described here.
00:22:19.006 - 00:22:23.500, Speaker A: But you still need in case of ipfs to start with some gateway.
00:22:25.840 - 00:22:36.344, Speaker B: It really depends on the platform. So you don't have to start with a gateway. For example, you can put the actual hash here, but this is an immutable reference, right?
00:22:36.402 - 00:22:37.010, Speaker A: Yeah.
00:22:37.460 - 00:23:06.280, Speaker B: You could also put in what we describe as a key name, which is a self certifying. You can use a public key as an address too for something, but you need some name server that's going to resolve it. So if you use the hash, then you're set. But it's all kind of, you don't have the mutable references. If you have mutable references then you need something that can resolve those mutable references. And that traditionally is a name system. So you can use DNS, but you can use anything else.
00:23:06.280 - 00:23:33.920, Speaker B: There's a sub protocol here called DNS link that lets you do that. So you can take a traditional DNS name, put in a hash link as a text record and this works today and it's sort of already in brave and opera and other browsers. And if your browser cannot speak ipfs yet, then you can use either an extension to enable it or you can use a gateway. The gateway is there only to kind of enable browsers that don't yet speak ipfs.
00:23:34.500 - 00:23:42.640, Speaker A: But this goes like if you do put hash here to retrieve it, it is DHT underneath.
00:23:43.240 - 00:24:30.304, Speaker B: So the resolution of ipfs is sort of dependent on the platform that you have. There are cases where you want to use a DHT, there are cases where you don't. For example, in a local area network, if you're disconnected from the rest of the world, you want to be able to resolve that content locally without having to break the link. So, for example, if you and I are working together on a computer or different computers, and I'm trying to look for some content that you have, and our computers can talk to each other over the local area network, I should be able to get the content from you. And that doesn't mean we could form a local DHT, but that's kind of expensive in a local area network because the latencies are so much lower. I can just ask my nearby peers who's got this content and if somebody has it, they can just give it to me.
00:24:30.502 - 00:24:35.940, Speaker A: For example, if we're talking about Brave, and if I put a hash here, how is it going to actually find content?
00:24:36.090 - 00:25:08.404, Speaker B: So in Brave's case, if you're connected to the Internet, I think it will primarily use the. There is one big public DHT that the IPFS network uses, and for the most part it will use that large DHT. But there's other protocols that are, we're calling indexers that serve sort of the same role of DHTs, but have a different topology. The problem with DHTs is that they're very slow. You end up with logging.
00:25:08.552 - 00:25:11.200, Speaker A: Yeah, lots of fetching. Finding the peer.
00:25:11.540 - 00:25:17.250, Speaker B: Yeah. We should do like a whole whiteboard session on these and what's good about them and bad about them and so on.
00:25:18.040 - 00:25:18.790, Speaker A: Hi.
00:25:19.480 - 00:26:04.732, Speaker B: Cool. I'm going to erase all of this. That's what we got out of ipfs. So the Falcon server assumes you have already a whole bunch of content in this hash linked setting, right? So you have what we call iPLD content and it brings in all the networking from lipidp and so on. So you have peer to peer protocols. The goal of ipfest is to again make this market work between storage providers and clients that want to hire the storage from storage providers. And the way we're going to do it is we're going to build what we describe as a decentralized storage network.
00:26:04.732 - 00:26:56.636, Speaker B: So a DSN, and usually this is a very simple structure where you want to put some data. So there's like two basic operations, put and gets it. And everything else is kind of like to make this sort of happen. So you usually want to put some data and you want to get a key back and later you want to use the key to get the data back. And the way we're going to use, in our case, the key is a CID. So here we actually can just write CID. But what we want to do is we want to use a set of incentive structures to enable this to happen with certain guarantees.
00:26:56.636 - 00:27:58.390, Speaker B: Like we want verifiability that the storage is there for the long term. And you want sort of an economic guarantee that your deal will be honored. And you want some guarantees around retrievability. You want to know that you can get the data later on, that somebody's not going to hold it hostage or something like that. The way we do this is we use first a blockchain to, maybe I'll describe components here we use a blockchain to coordinate, I'll describe later kind of what we put on there. We use a proof system to create verifiable proofs of storage. And we use a market to get source wires and clients to sort of meet each other, make deals, agree on prices and all that kind of stuff.
00:27:58.390 - 00:28:34.672, Speaker B: There's a lot of complexity embedded in each of these. But I'll maybe, I think it's probably best to start with the proof system because that's kind of like a really important sort of foundational block. So this for us divides into at least two proofs pore up, which is a proof of replication and post, which is a proof of spacetime. And the idea of these two proofs, the proof of replication, what it gives us is the idea that if I have some data D, that I want to get two replicates, replica one and replicate two.
00:28:34.806 - 00:28:42.132, Speaker A: So maybe before this, what are maybe more explicitly the economic guarantees that you're trying to achieve here?
00:28:42.266 - 00:29:30.384, Speaker B: Yeah, so the economic guarantees is that, I guess. Yeah. So an economic decentralized storage network is like you're putting some data with some money and you can sort of get a CID back and in the future you can retrieve it by giving the CID and some money as well. The economic guarantee is that there's some price where you can hire the network for that price and your data, with very high probability will stay in the network for the amount of money that you're specifying. And that's kind of where the market comes in. We describe this in terms of deals and each deal is kind of a little data structure that has the client, the storage provider, and then the price.
00:29:30.582 - 00:29:31.808, Speaker A: And the period of time.
00:29:31.894 - 00:29:33.156, Speaker B: And the period of time, yeah.
00:29:33.178 - 00:29:39.044, Speaker A: So I think that's probably important pieces like you're storing it for a period of time and then you're willing to pay this price.
00:29:39.162 - 00:30:14.188, Speaker B: Yes, for this period. And if you want replication. So this is really flexible because if you want, you can build any reliability model on top of something like this. So a lot of other networks kind of pick a specific erasure coding scheme or a particular replication scheme and so on. And those replication schemes don't fit all use cases. What you want to give is a very kind of simple primitive upon which you can build all of that. And in this case, if you want your content to be replicated by many parties, you just make several deals.
00:30:14.188 - 00:30:43.740, Speaker B: If you want to take some data and erasure, code it and create different objects, then you can do that ahead of time. On the client side, you prepare it and you put it here. And also know that the client doesn't have to be the end user necessarily. You could have like client one which uses client two, which then goes to the source provider, right? So this could be like processing of some sort on behalf of the user. We sort of call this like aggregators or on ramps.
00:30:45.760 - 00:30:57.004, Speaker A: When storage provider makes this deal. Because that's why I'm like, let's figure this first because it defines what you're trying to get here. When storage provider makes this deal, what are they promising?
00:30:57.052 - 00:30:57.216, Speaker B: Right?
00:30:57.238 - 00:31:02.320, Speaker A: I mean, time kind of, what's the probability? And if they don't honor this contract.
00:31:06.020 - 00:31:56.780, Speaker B: We'Ll build up. The way we've sort of put in the content specified by these deals into the source system is by using, I think we call sectors. So let me maybe build it up. I was going to sort of explain the components, the component, but let's maybe go this way. So let's start with the blockchain and kind of express it down. So think of the falcon blockchain as having of course some state tree, right? So like any other blockchain, but then underneath it we're going to accumulate over time a set of sectors. And these sectors, think of them as lots and lots and lots of storage, storage capacity.
00:31:56.780 - 00:32:52.812, Speaker B: Think of them kind of like a storage container. So at any point in time we are adding more sectors to the network. Every block more participants onboard, more capacity, and so on then. And so what you end up with is, as the blockchain is proceeding, storage providers are committing capacity, and they're doing that for the block reward. I'll describe later how we're using the block reward, but Falcon is a storage power consensus. So SPC that uses instead of hash rate, like in bitcoin or ethereum or something else, we use the storage power that people are accumulating as the power in the block reward. So participants are intended to bring more and more and more storage power into the network so that they can earn larger and larger fractions of the block reward.
00:32:52.812 - 00:33:06.344, Speaker B: So on its own, without any kind of deals, this blockchain can assemble a lot of capacity that you can then fill with data. So think of these as kind of like storage container boxes that you're going to later put stuff into.
00:33:06.462 - 00:33:18.392, Speaker A: So, pretty much if I'm a participant and I'm not bringing new storage capacity, then I'm not receiving. I mean, we can go into block rewards, but kind of like, you always need to bring more capacity.
00:33:18.456 - 00:33:40.470, Speaker B: Yeah, exactly. So the participants maintaining the consensus here have to bring in more storage power. This is kind of like a hybrid proof of work and proof of stake protocol, where we use the algorithms of proof of stake. But the power is not just pure money. The power in the stake protocol is proven. The actual storage. Yeah.
00:33:40.470 - 00:34:19.024, Speaker B: And this could be either capacity or storage with data. We'll go later. We can describe later how we kind of incentivize not just capacity, but actually useful data. So this, on its own, think of the bitcoin network as using a function very similar to that to amass an enormous amount of hash rate on the planet. And so fatcoin has used that same kind of structure with that kind of block reward auction to assemble an enormous amount of capacity. We have 17 exabytes of capacity right now, which is, like, really competitive with a centralized cloud storage network. Right.
00:34:19.024 - 00:34:51.348, Speaker B: And every day, somewhere between 20 and 30 petabytes get added. So a petabyte is an enormous amount of storage. Every day, like, 20 to 30 petabytes more get added to the network. And that is all coming from the block reward. So the block reward is sort of summoning all of this storage hardware to appear and be ready to receive customer data. So once all of that storage is onboarded, storage providers can sell the fact that there's space in these sectors. We call these sectors.
00:34:51.348 - 00:35:15.570, Speaker B: It's kind of like an old hard drive terminology. The idea is that you can think of, like Falcon as a huge disk that you're going to partition and then you're going to put some data into the sectors. Source workers can sell the space in these sectors using these deals on the market. Part of what you agree on. And yeah, you erased the deal. I should bring you back. Let's see.
00:35:15.570 - 00:35:54.830, Speaker B: So we have the storage provider, the client, the time, the price and the sector. The sector ends up. You agree on the deal first and then later you map it to the sector so the sector can have a list of deals. I forgot also to say the CID of the content that you're storing there. So it's this tuple. And so clients and source writers find each other. I can describe later how we get to that.
00:35:54.830 - 00:36:37.064, Speaker B: They agree on a time, they agree on a price and they agree on the content, and then the client transfers the data to the source writer. The source provider can now store it in one of these sectors and they will earn this money over time. One of the other things that Filecoin does is that filecoin prefers content that has deals versus just capacity. So we have this concept of useful storage where if you can. So this is kind of like a complex economic structure. You have to solve a very hard problem, which is how can you tell.
00:36:37.102 - 00:36:39.884, Speaker A: That this content is like useful versus somebody just.
00:36:39.922 - 00:36:40.876, Speaker B: And how do you know that this.
00:36:40.898 - 00:36:47.596, Speaker A: Client is legit and not the storage provider himself? Putting more exactly like just recycling, because.
00:36:47.618 - 00:37:41.824, Speaker B: Capacity is really useful, but it's not as useful as useful storage. Right now the faculty network is incentivizing useful storage ten x more than capacity. And so there's a whole kind of decentralized protocol of verifiers and notaries that kind of check that this client is legit, check that this content is legit, and then kind of sort of like bless this deal. But that's like a Canada construction fasma is very modular. So all of these kind of components and protocols can be swapped out for other designs later on. So the marketplace here, one of the really neat things about this is that you're summoning tons of different source providers that can offer very different prices or very different kind of other services alongside, and they might tune their operations for certain kinds of data. So some source providers might be storing very large amounts of data.
00:37:41.824 - 00:38:05.770, Speaker B: So think of ten to 100 petabytes at a time or something like that, and they might have facilities ready to ingest hardware, they might be source providers that offer a lot less storage, but they have really good connectivity and so they can serve it out to end users and so on. And you enable this kind of like market behavior where clients and source providers can sort of find each other by use case.
00:38:07.980 - 00:38:11.784, Speaker A: Pretty much. This model does not prescribe in any way.
00:38:11.822 - 00:38:12.264, Speaker B: Right.
00:38:12.382 - 00:38:21.372, Speaker A: Kind of this relationship. Right. An off chain, a paperwork agreement can be done, for example, as well. And this is just a payment.
00:38:21.506 - 00:39:09.020, Speaker B: Yeah, we think that if you prescribe this relationship, you are almost certainly going to get it wrong most of the time, in that most of the time clients and search providers will be in some niche and you want to enable the participants in that niche to interact. And you're best served by creating a fluid market where that can evolve over time because also the use cases and the technologies will evolve over time. So you want to let clients of storage providers sort of find each other where they need to be. Kind of the model that we're using here is like this. I'm going to build a quick map of the system. So we have storage clients over here that use these like on ramps to go to storage providers.
00:39:10.080 - 00:39:13.256, Speaker A: You mean this is some kind of registry of storage providers?
00:39:13.448 - 00:39:32.170, Speaker B: No, let's grab it in a moment. These are retrieval providers. I'll describe that in a moment. And then this goes back out to retrieval clients. Sometimes these are the same parties, sometimes it's different.
00:39:32.540 - 00:39:37.210, Speaker A: Yeah, it can be like developer putting some stuff on and then serving it to everyone.
00:39:42.620 - 00:40:28.388, Speaker B: So idea of this map is that you have storage clients that have a bunch of data. These could be as simple as a web app or a consumer PFP or. Yeah, like your random PFP. Or it could be a large company or a large organization with tens of petabytes of content that they want to eventually make its way into the storage provider. Now, depending on the use case, the tooling, the products and so on, that these storage clients are going to want to use varies. So storing a picture as part of an NFT or something like that is very different than storing ten petabytes of archival data. And so what the source client, the product and the interface the source client needs is very different in those cases.
00:40:28.388 - 00:41:04.672, Speaker B: So these on ramps are use case specific products that tune for that ux, but that all are aggregating into pipeline. So you sort of build on ramps by vertical. You enable source clients to hire that onramp to then get storage in here. So NFT storage is a good example where that's a product specific to the NFT market. It enables anybody who wants to store a lot of nfts to use a product and an interface tuned for storing nfts. And on the background, it's archiving and storing everything with filecoin.
00:41:04.816 - 00:41:11.816, Speaker A: But it can be also a b two b business where you go and you say, I want to store this many petabytes, and then you get an email back.
00:41:11.918 - 00:41:39.632, Speaker B: Exactly. There's another on ramp which is kind of like the connecting, which right now is just kind of like this team that's just connecting prospective clients to source providers where they do a little bit of diagnosis of how much data is it, where do they want the data to live, and so on, and then connects them to a set of storage providers. That makes sense because the moment that you're moving around tens of petabytes, you have to get humans in the loop moving around that much data.
00:41:39.686 - 00:41:41.424, Speaker A: You need like physically shipping stuff.
00:41:41.462 - 00:42:16.510, Speaker B: Usually, yes. A lot of times it turns out the Internet does not have enough bandwidth to move around that much storage. So you have storage clients and source providers meeting each other, and source providers will go to the clients facilities with hardware, get the data and then bring it back. And so you want to sort of enable all of that to happen. The centralized cloud has similar services. So Amazon snowball is an example of that Azure databox and so on. In our case, this is a decentralized network of participants that's going there.
00:42:16.510 - 00:42:51.068, Speaker B: Now once the data is here, you can index it to make it retrievable and you can use these retrieval providers. I haven't spoken much about these yet, but this is kind of the CDN use case. So think of this as the CDN and think of this as like the object storage. So this is kind of like s three or something like that. And this is kind of like cloudflare. So once you have the content here and you have it indexed, you want this to be like a really fast cache all the way close to the users. There's a whole set of interesting techniques.
00:42:51.104 - 00:42:53.336, Speaker A: How you build these, that's a whole separate problem.
00:42:53.438 - 00:42:54.090, Speaker B: Yes.
00:42:55.900 - 00:43:02.020, Speaker A: When you say index here, we should probably finish with proofs, but yeah, there's.
00:43:02.100 - 00:43:46.004, Speaker B: A lot of interest. Yes. Once you want to store exabytes worth of data, you end up with all kinds of interesting large scale problems, each of which could take an entire large scale decentralized network to solve. For example, this indexing layer today, one of them is like the FFSDHG, but that doesn't work to store petabytes of stuff. So we're building these other indexing services that are more of one where the index is going to get, it's a very large index, but you can make full replicas of them and that itself could be a decentralized or incentivized thing. Yeah. It turns out that each of these have strong incentive structures.
00:43:46.004 - 00:44:48.940, Speaker B: You can create whole businesses here, whole crypto networks or companies in each of these. Okay, maybe I'll describe how to. So on the proof system, just sort of for completeness, we've left open how a storage provider proves that they have storage, that they have the content, or they just have capacity. And this is kind of where these sectors come from. So I was describing, let's go back to the proof of replication, which is that I have some data D, that I want to verifiably be able to get a proof that I'm storing as many replicas as I want. So if these are both stored by the same party, say, alice, I want to be able to prove that these two replicas are independent from each other, even if it's the same data. Why do I need to prove that? Well, one, many users want to prove that multiple copies are being stored in multiple places.
00:44:48.940 - 00:45:14.052, Speaker B: But two, it is critical for consensus power that you cannot cheat here and cannot pass off individual storage as tons of other storage. Crucially, in the capacity case, if you say generate these randomly, what you don't want is to be able to kind of generate the capacity on the fly to sort of pass the proof or.
00:45:14.186 - 00:45:17.904, Speaker A: Recycle pretty much that the capacity already presented has a new capacity.
00:45:17.952 - 00:46:14.044, Speaker B: Yes, exactly. And so there's kind of this deduplication problem where you don't want to allow a storage provider to pretend to have, say, x storage, when in reality they only have like 100th of that or something like that, or you don't want the storage providers to have no storage at all and just be able to forge the proofs, like to pretend that they have a lot of source power when they don't. And so that's where the proof of replication is really critical. And what this enables is you have an interactive proof system here that lets you prove that these two are different. And the intuition here is very simple, which is like, you can use some facet of the world to make the encoding. You pick some encoding between the data and the replica. That is either that takes some time or that is expensive.
00:46:14.044 - 00:47:00.372, Speaker B: So you can use time or cost or other structures. You could have some kind of like centralized thing that disables creating the replicas or something like that, or they carry a special signature. So there are many different kinds of poor protocols that you could make. But, for example, the time one is very kind of intuitive to think about. You sort of commit to what the data is, at some point in time you give it to the storage provider and they have to run some expensive encoding. And then once they run that expensive encoding, they communicate the proof that they've done so. And then some point later in the future, you can sort of challenge them, generate more whiteboard space.
00:47:00.426 - 00:47:02.920, Speaker A: Here we can scale up.
00:47:02.990 - 00:47:46.660, Speaker B: Yeah, exactly. You can challenge them and they have a certain amount of time to return a proof. So the challenge yields a proof and you can check whether that happened and you can sort of time them out after some period of time that is smaller than the time it takes to generate the encoding. So this is what we call a time based pour up, where this encoding just takes a specific amount of time and you send a challenge and you expect a response in less time that it takes to generate the thing. So that way when you send this challenge and you get back a proof, you know that the participant does have that content, otherwise they wouldn't be able to pass approve.
00:47:48.280 - 00:48:01.208, Speaker A: Okay, so this is pretty much like a VDF type of function that's rooted in data that they're supposed to store. How is this communication facilitated in kind.
00:48:01.214 - 00:48:10.536, Speaker B: Of like the general case? This could be any two parties in filecoin. This is the blockchain. The blockchain is automatically issuing the directions a direction.
00:48:10.568 - 00:48:15.868, Speaker A: Okay, so like new block has pretty much some kind of unique information, some.
00:48:15.874 - 00:48:52.776, Speaker B: Randomness from the chain to derive the content you're going to store and then produce proofs at any point in time. Here you have proofs, and we run one of the, I think the largest snark proofing system on the planet. And it's all large scale proofs of people actually storing all of this content. And here, same thing with a challenge. You test the challenge, issues a bunch of checks, a bunch of points, make sure that the content is there, and you produce a proof that can normally pass if you have the data.
00:48:52.878 - 00:49:08.850, Speaker A: So I mean, let's just look at example with single storage provider, right? So you produce a block. Yes. So there is some source of randomness that is used by the storage provider to produce a proof that takes how long?
00:49:09.780 - 00:49:25.716, Speaker B: In ceiling's case, this has to take a certain number of blocks. We have many versions of the proofs that have evolved over time because algorithms improve. I don't know what the latest number of block times is, but it is created such that it takes certain number of block times.
00:49:25.738 - 00:49:36.328, Speaker A: So it's kind of function that it takes whatever x blocks to compute and then it takes the sector as it.
00:49:36.334 - 00:50:08.160, Speaker B: Takes sort of like what we call an unsealed sector. We call this function a sealing operation. So this encoding, we call it seal, and it seals an unsealed sector, which is kind of just plain text stuff. It could be plain text capacity, which is all just randomly generated, or it could be the actual content that the user is asking for. You pass the seal operation to encode that whole sector, and you end up with a sealed sector, and you then produce a proof that you've done that correctly and submit it to the chain.
00:50:09.220 - 00:50:11.940, Speaker A: So what is encoding to seal the sector?
00:50:12.440 - 00:50:35.804, Speaker B: So this is where we enter into the realm of different poor ups. We spent years of work on iterating, exploring this space. There are many different kind of poor ups. The one we use right now is not a latency based poor up. It's just the easiest one. It's a cost based poor. You can think of the same argument here as an economic one, where the transitions here are just so expensive that it's cheaper for you to store the.
00:50:35.842 - 00:50:38.924, Speaker A: Data than to download it again or to generate it.
00:50:38.962 - 00:51:19.450, Speaker B: So generation here is like this pernicious type of attack, where you could sort of like, as a malicious storage provider, you could pretend to be a client, pretend to hire yourself, or pretend to add capacity, that it's just all generated from scratch. So you want an extremely hard constraint that even if the data could all be generated, it's just randomly generated data. You want to prove that it is extremely likely that the data is actually there. There's a very good economic argument here where the cost of making this computation is many times larger than just storing the data.
00:51:22.060 - 00:51:24.484, Speaker A: What is that like right now? What are your functions?
00:51:24.612 - 00:51:35.484, Speaker B: So this is just a very expensive operation that just consumes a lot of computational power. And that computational power is bounded to be more expensive than the drives maintaining the drive.
00:51:35.522 - 00:51:39.010, Speaker A: I see, yeah. Okay.
00:51:42.260 - 00:52:43.188, Speaker B: As an example of a pre verification, we today use SDR pore up, which is a specific stacked depth robust graph depth, robust graph borep, which is a very expensive. Without kind of like going super into details here, you end up, you take the data and you create a set of encodings, encryptions, all the way to get to the replica. And at each stage here, you're just running an expensive encryption that at each of these layers is all interlaced with elements in the back here. So that you cannot say, generate this stuff until you have generated all the.
00:52:43.194 - 00:52:49.940, Speaker A: Stuff, some sequential, and then you route it into some randomness.
00:52:50.600 - 00:53:27.776, Speaker B: Yeah, exactly. And so this takes a long time to go from the original data all the way to the replica. And so you can either use the latency or you can use the cost assumption. So you can use either one or both if you want to be stronger, but you end up with this super expensive process to go from data to replica. And once you're here, this is what you store and this is what you prove. We kind of like use a challenge response protocol here because it's very difficult to prove that you've done this correctly. So instead, once you have the replica, you can issue a set of challenges here and you can sort of decrypt these and prove that they're the same ones that were here.
00:53:27.776 - 00:53:30.660, Speaker B: And you can do that with traditional merkle tree.
00:53:31.640 - 00:53:35.764, Speaker A: So they store kind of encrypted part?
00:53:35.882 - 00:53:40.132, Speaker B: Yes, they store this encrypted part when.
00:53:40.186 - 00:53:45.192, Speaker A: You'Re asking them, they just need to decrypt random pieces and give it to you.
00:53:45.246 - 00:53:58.412, Speaker B: Exactly. And so this is really critical for consensus because this is what enables you to know that you have a very large amount of storage committed and you can prove that it's all legit capacity and so on.
00:53:58.466 - 00:54:29.380, Speaker A: And so the challenges are issued also automatically. Right, pretty much like every block. Then even with the same randomness, you kind of have a challenge function that given a sealed sector and the randomness, you need to return something. Approve. So how does pretty much the block producers. Right, they will receive these proofs? Like, are they receiving from everyone?
00:54:29.450 - 00:55:01.680, Speaker B: Yeah. So this is where we use these post things. So think of a poor up as a proof that goes from the encrypted data into a replica and it gives you the facility to sort of call the poor up challenge. Again, a post just uses a poor up to then with some sample, with some frequency to prove that you have been storing an arrangement of bits for a given amount of time. And so you can just keep iterating this. And so you do this today with a blockchain. So the blockchain issues a challenge.
00:55:01.680 - 00:55:21.664, Speaker B: You derive randomness from the block, you use that as the input to an ongoing challenge function, and you prove that you have the stuff you committed. All the storage on the Falco network is proved every day. So the way we sort of do this is like we, there's a challenge.
00:55:21.712 - 00:55:23.940, Speaker A: Every day for all of the storage.
00:55:25.000 - 00:55:53.004, Speaker B: Every block issue is the new challenge. And so it's just that we sort of divide up the day into these, like 48 windows and a storage provider. Storage is sort of assembled, it's just dispersed across these windows. And they get challenged at every step of the way for some fraction of their storage. You want to sort of minimize the overhead. So you want to kind of like pack it in here. So this is like a certain number of sectors.
00:55:53.004 - 00:56:06.368, Speaker B: And so in this window of time, they're going to be challenged for all these sectors. And so in this window of time, they have to produce this at the very beginning of the time period, they get the challenge and they have to submit the proof before that time period.
00:56:06.544 - 00:56:12.308, Speaker A: Every byte of storage gets challenged kind of once a day for every single.
00:56:12.394 - 00:56:23.220, Speaker B: So it's one of these probabilistic proofs where in this time period you get a challenge and that selects every sector is proofed. But within the sector, it just kind of randomly.
00:56:23.300 - 00:56:27.180, Speaker A: Yeah, it samples within the sector. How big are sectors?
00:56:27.680 - 00:56:56.048, Speaker B: 32Gb or 64gb. There's like two settings, and that's specific because of SDR poor f. It's kind of specific to the algorithm and the available hardware. So it's one of these interplays where you have to design the pore app and your implementations of the pore app based on what the available hardware is. And then once you do that, you're going to put an optimization pressure on the hardware to get better in certain directions, because for service providers like this means huge costs.
00:56:56.064 - 00:56:59.556, Speaker A: Yeah, they're spending most of their time, most of their processing on that.
00:56:59.578 - 00:57:28.480, Speaker B: So you need a bunch of gpus. So in addition to the storage, you need a bunch of gpus that can do these proofs, but they're not used all the time, which is neat, because then you can use the gpus for the remaining time to do other kinds of computation, like computation over the data. So once you have all this data in Filecoin, you can then start doing a bunch of computation over it. And that's kind of what's coming ahead next year. It's bringing online decentralized computational networks on top of all of this data that's getting amassed.
00:57:31.140 - 00:57:36.850, Speaker A: Okay, so I guess maybe let's stop by just quickly on the market.
00:57:38.660 - 00:58:44.520, Speaker B: Yeah, so the market today, we were considering doing this as kind of like an explicit market where you put asks and bids on both sides and so on. And we might still go in that direction, but because there's a lot of features here, you need this to be a very high throughput system. And so for the most part, right now, the market is not so big that you can't sort of segment it out. There's a few parties, for example, making a components where a set of source providers connect to a marketplace, and then clients come to that marketplace and sort of find source providers or they act as intermediaries between the two, where the clients hire the marketplace and the marketplace then hires the source providers. But where we're headed in the long term is that this will likely be a, think of it kind of like a dex, where you put bids and asks directly on the market. One natural extension that hasn't been done yet is that you could start having deals without the CAD yet. So you can determine, you can pre buy the space.
00:58:44.520 - 00:59:14.770, Speaker B: And what this gives you is kind of like a futures contract on spaced out, which this really commoditizes cloud storage in the same way that you can commoditize oil or something like that. This will be kind of like defi meets filecoin. That's sort of rate limited by programmability on that chain. This is where SEM is going to come in to give programmability to the blockchain. Okay.
00:59:17.540 - 00:59:23.700, Speaker A: So this price and kind of the cost, how does that offset the block rewards?
00:59:24.600 - 01:00:17.300, Speaker B: Right now the fucking network is going to follow this expansion phase where we sort of like divide it into three stages, expansion like optimization and sort of like maintenance or something. And we're sort of like here. And so during this entire period, the block reward is the dominant incentive. And so right now, the participants get incentivized by storing, by having storage power, either with capacity or useful storage. And so that means that the client's price could be extremely low. So we can be many orders of magnitude cheaper. And we are in fact, for these tens of petabytes that are getting stored at a time many orders of magnitude cheaper than the cloud, because storage providers are making so much money just on the block reward alone.
01:00:17.300 - 01:00:52.832, Speaker B: So this gives you the ability to sort of undercut the entire cloud storage system, the entire centralized cloud model, and bring all the data into podcoin. Yeah. So what's happening here over time, once the networks are saturating in terms of the available capacity and the usages of the network sort of reaches the amount of capacity, and you have more interest in putting data storage than you have capacity, then at that point the prices will start increasing here.
01:00:52.966 - 01:01:04.340, Speaker A: But I mean, this price goes so it doesn't go to storage provider. Or like when I'm doing this contract, I'm paying to search provider directly or I'm burning these tokens.
01:01:05.080 - 01:01:21.640, Speaker B: The price here goes to the source provider. But think of the source providers having multiple revenue flows. One is the deal price and one is the mining reward. Today the mining reward is dominant and the amount of money they get here is very little. Okay, so they can afford. And they just get.
01:01:21.710 - 01:01:23.800, Speaker A: Yeah, they don't care about the price.
01:01:23.870 - 01:01:29.420, Speaker B: They don't care about this price today. Yeah. And that's sort of a function of the saturation of the network.
01:01:31.920 - 01:01:38.140, Speaker A: You have how much capacity versus how much stored, and then exactly as more stored kind of the price will grow.
01:01:38.290 - 01:01:58.180, Speaker B: So when you have a ton of empty capacity, you can afford for this to be zero, you can actually afford it to be negatively priced. I will maybe leave that out as a discussion for another time. But when you have a block reward incentive that is giving you money for storing deals, you can make this negatively priced.
01:01:58.920 - 01:02:01.896, Speaker A: You can yield farms, people storing stuff.
01:02:01.998 - 01:02:16.508, Speaker B: Exactly. And so that's a super powerful incentive structure that's kind of like, you know how in the oil market you sometimes get negatively priced oil. It's a similar kind of behavior as that for a period of time.
01:02:16.514 - 01:02:19.244, Speaker A: You need to make sure you're very good at.
01:02:19.442 - 01:02:26.680, Speaker B: Yes. You need to make sure that the proofs here are legit and that the client verification.
01:02:26.760 - 01:02:28.528, Speaker A: Well, yeah, the client verification, you need.
01:02:28.534 - 01:02:46.852, Speaker B: To know that these are like seriously good customers. And that's where kind of the, we call that process five point plus, and there's a network of notaries that verify this and so on. It's a whole other story for another time.
01:02:46.906 - 01:02:59.956, Speaker A: Yeah, there's like this retrieval markets and notaries. Seems like a few more topics. Well, yeah, I mean, that is very interesting and complex.
01:03:00.148 - 01:03:41.972, Speaker B: Yes. The opposite of all of this is we have peer to peer network that we can content address all the data on the planet, and then we can create an incentive structure to store a massive, we tend to think of it as like three steps. One is like a mass hardware, then a mass data, and then make that computation useful for computation. So step one is like you have a block reward incentive structure to summon massive amounts of capacity. And so we kind of have that done now we're onboarding the data. So this is kind of like in progress now. And so this is kind of like filling up this capacity with useful data.
01:03:41.972 - 01:04:15.744, Speaker B: And then once that's there, you can use the available hardware that people have to then issue computational networks. And so this is what's coming in the future. And so you end up with a decentralized cloud storage and computing network where it's cheaper to sort of move the computation to where the data is because it has gravity. Like once you have massive amounts of data in one location, it's extremely difficult to move it somewhere else. Extremely expensive. So it's much cheaper to move the computation to the data compute there and produce your.
01:04:15.782 - 01:04:18.940, Speaker A: And given they have a bunch of gpus, this is where we're going to train our AI.
01:04:19.020 - 01:04:38.740, Speaker B: Exactly. Yes, that's where we're headed. Yeah. Great. Well, yeah, thanks for having me. Happy to dive into detail in any of this in the future. But, yeah, this is kind of like the model of today is just getting tons of useful data into this extremely cheap storage.
01:04:38.740 - 01:04:56.408, Speaker B: There's an exchange already that's leveraging this kind of negatively pricing thing where if you're a legit user, you can bring your data to the exchange and sort of sell the right to store your data. And so you can auction the auction house for useful.
01:04:56.584 - 01:05:05.216, Speaker A: So you're getting paid valuable data, storing bunch of stuff. Well, yeah, I mean, going into how to define useful, valuable data is, it.
01:05:05.238 - 01:05:31.704, Speaker B: Turns out to be not that hard, because if the data is public, that becomes a much easier problem. So for a whole subset of the data, where the data is publicly visible, that ends up being a much easier problem. You can just see what the data is and then sort of certify that it's good data that the network wants. And because it's public and viewable, you can always audit that in the future. So think of all of the large scale public data sets that the world.
01:05:31.742 - 01:05:42.700, Speaker A: Has moved them in. And then I guess just to finalize here, if this challenge doesn't come in time, then you get it slashed as a validator and you lose your.
01:05:42.770 - 01:06:14.356, Speaker B: That's right. So if you miss this proof, you get a fault and you get slashed. This goes into kind of too much detail, but there's a schedule where you're allowed to miss one because sometimes there's like, flukes, and so you sort of, like, miss one. But if you. And then you can start getting slashed for. For more, you can get up to 14, which is two weeks, I guess. Actually, we changed that to now six weeks.
01:06:14.356 - 01:07:21.016, Speaker B: So you can keep getting slashed every day for six weeks, and then at six weeks, it's terminated and the source provider loses a large amount of collateral that's been put up for the sector. So part of what makes this entire thing operate is that the source providers have to put up a large amount of collateral promising to the network that they have this storage. And the reason for that is you have to deal with this elastic thing where the blocker word and the pricing of the token changes the economic return of people at any sort of moment in time. And so in bitcoin, you get this behavior where the hash rate mirrors the price. Right? So if bitcoin is going up, then the hash rate is going to go up. If bitcoin is going down, then the hash rate is going to go down. And in five point you have to kind of build a shock absorber to make sure that even when you have some amount of volatility in the price of the token, the economic return of participants is spread out over years, so that everybody's thinking of averages over long periods of time as opposed to the immediate volatility.
01:07:21.016 - 01:07:43.060, Speaker B: And so that's where collaterals play a huge role in both adding security to the network, in that if a large chunk of storage disappears, that weakens the security of the consensus protocol. And you also don't want a bunch of users valuable data to disappear. So you want to put up a lot of money at stake committing to store all this data, and that's where the collateral structure comes from.
01:07:43.130 - 01:07:50.950, Speaker A: So if, for example, one of the storage providers gets slashed as a user, am I getting kind of that?
01:07:52.040 - 01:08:27.520, Speaker B: The collaterals are burned always. You don't flow them back to the clients. If your deal stops being stored, you then get the remainder of the price that hasn't been spent, but you don't get the collateral back. And the reason is otherwise you have this behavior where you can sort of convince a bunch of source provider, you can have malicious clients that convince a bunch of source providers to sort data, and then you go and attack them and make them miss their windows, and then you get a bunch of money back. So it creates like this perverse potential. All collaterals tend to be burned.
01:08:30.040 - 01:08:38.084, Speaker A: Well, there's still incentive to attack a bunch of storage providers to get collateral burned on network and so on.
01:08:38.122 - 01:08:56.856, Speaker B: Yeah, but if that happens, then you're weakening the utility of the network, because when you're burning capacity or you're burning useful storage or whatever, that is bad for the network. So the argument is like, sure, you might be burning some tokens, but you're burning the credibility and utility of the network.
01:08:56.888 - 01:08:59.176, Speaker A: And so that's probably not misaligned.
01:08:59.208 - 01:08:59.790, Speaker B: Yeah.
01:09:01.680 - 01:09:11.164, Speaker A: Well, thanks. This is really good. There's a lot of stuff here, and I'm sure there's more to learn. What's the best place for people to learn more?
01:09:11.362 - 01:09:30.036, Speaker B: You can go to platinum IO, and you can see a lot of info there. There's a number of papers that we published over time as well. Yeah. And we have tons of video recordings of all kinds of technical talks on the pocket YouTube channel or the percolabs YouTube channel. Awesome. Yeah. Thanks for having me.
01:09:30.036 - 01:09:31.110, Speaker B: This is really fun.
01:09:31.640 - 01:09:32.550, Speaker A: Thank you.
01:09:33.320 - 01:09:37.680, Speaker B: This was really good. Sorry that it's kind of, like, messy going back and forth.

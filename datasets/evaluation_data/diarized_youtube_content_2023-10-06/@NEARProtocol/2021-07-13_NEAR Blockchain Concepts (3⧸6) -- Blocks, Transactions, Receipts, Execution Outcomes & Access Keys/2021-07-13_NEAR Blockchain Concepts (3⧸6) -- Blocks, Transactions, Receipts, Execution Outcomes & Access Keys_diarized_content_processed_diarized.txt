00:00:08.490 - 00:01:41.630, Speaker A: So last time we ended with description of epochs. I'm trying to remember where exactly I was heading to, but let's probably just recap a little bit on the epoch side. So basically I don't think I definitely didn't open our docs, which I should have. So we have docs, which is great. We have API over here, and here we have a lot of useful information, starting with useful links where RPC are available. We even have public archival rpcs because these RPC endpoints only store five epochs, they don't store the whole history for a reason of saving storage. RPC instances currently consume 100gb on main net I guess, and for full archival node we already reach 1 tb, which is like ten times more than on RPC, which makes sense to split apart.
00:01:41.630 - 00:02:35.226, Speaker A: We can run more mainnet RPC instances to serve recent data and just a few instances with the whole archival information. So whenever you only care about latest state you can safely use this. If you want to look up historical data, you use archival. Very simple. If you're not very familiar with different tooling, you can use Postman or Carl. All the examples mostly feature this HTP utility and you can look up all the information in this nice doc. On the right side there is a nice overview.
00:02:35.226 - 00:03:35.118, Speaker A: So you can easily navigate through this very long page. And the thing that we are currently interested in is we'll be looking into network status. So there is a node status. You can use RPC to query the single node, what's its state. In example response you can see it reports the version of the binary Ryan there, the protocol version, and various information over there. Useful section is sync info which tells at which block the current node is right now. And so you can see latest block and whether the node is in syncing mode.
00:03:35.118 - 00:04:33.630, Speaker A: If it's in syncing mode it means that you'd better not use this node to fetch latest data. Because it doesn't have latest data yet, it is still catching up with the network. There is also another endpoint which is well, network info is not very interesting right now. There is validation status. So when you query validators endpoint with a block eight or block hash representing the specific point in time, you can fetch the information at that point, or you can specify null. This is a legacy style of queries. As you can see it's not very intuitive what exactly that number or this train is, or whether you need to put null or empty array.
00:04:33.630 - 00:05:46.578, Speaker A: We'll refactor that later. But overall null indicates like latest and then you receive information about the current validators, we will cover validators a little bit later. The useful part here is that this endpoint also returns you epoch start feed. So you know when epoch starts. So let's check it out or it validator and we pass. No. So here we are.
00:05:46.578 - 00:06:20.750, Speaker A: This is 36,000,006. 90 is the block where this current epoch started. Currently it's 36,000,007. Three. Three block. So we are in the middle of it. What is the reference here is that we discussed last time in Genesis.
00:06:20.750 - 00:07:14.590, Speaker A: It's a weird genesis. Over here in Genesis we have. That's weird one weird naming. Sorry about that. So epoch length over here is what we looked last time. If block production is exactly 1 second, it is 12 hours. It represents 12 hours for one epoch.
00:07:14.590 - 00:08:22.104, Speaker A: We went through this whole config talking about various records that the genesis essentially defines which accounts will be in the very beginning of the network. Now I guess we are ready to dive into blocks specifically. So do we want to start with blocks? One sec, I need to think about it. Yeah, let's start with blocks. So blockchain, as name implies, starts with includes blocks which are chained together and each block is produced by some node which we call validating node. So they are producing nodes. There are other types of nodes which do not produce blocks.
00:08:22.104 - 00:09:07.464, Speaker A: They only follow the network. That's exactly what we have here in the reference. We use RPC nodes. Those are nodes that are not validating there, just following whatever is in the network, applying the same rules. But they do not take part in creating new blocks or accepting transactions and doing something about those transactions. They can receive transaction and route the transaction to the nearest validator in their network, internal peer to peer network. So all the nodes near core nodes are part of the same peer to peer network with different roles.
00:09:07.464 - 00:09:54.750, Speaker A: There are validating nodes, there are non validating nodes. Basically there are only two types of nodes on this level, and then non validating nodes could be there for different reasons. One of them they would be serving RPC traffic. Another reason would be they are serving backup needs. So they're just following, they do not serve any traffic. They need to be there just to store the data. And there are nodes like indexer nodes which embed the whole near core node into its own application as a sub process.
00:09:54.750 - 00:11:32.620, Speaker A: It runs near core in different thread while doing some other work in some other threads. That's a core essence of indexer framework and indexer implementation for Explorer using that framework and boot nodes. Yeah, it's a special role that we assign those nodes need to be there to initiate that peer to peer process. So when we connect a new node to network, we need somehow to let it like the entry point and we use some nodes that are serving this boot node role. You can use any node on the network to connect to, but to limit certain traffic we decided to go with a separate server running those nodes and we specifically assigned it to serve this boot node role. Yeah, I hope that's enough on the high level getting back to the blocks. So each validating node sits there, follows the network, and once there is an epoch voting I will cover it later.
00:11:32.620 - 00:13:04.120, Speaker A: I guess when the epoch changes it is the time I will cover it. Now essentially there has to be some time when we decide which of all the nodes will be validating nodes. To decide that the nodes themselves rank all the nodes who are currently they rank accounts on the network by their stake balance. So there are two types of balance in here. I feel like I never will get to blocks themselves, but I feel like it's necessary to talk about validation in the first place. So these are accounts on the network. Statepoolv one near you can see that this account has, it's also called liquid balance or native account balance on Explorer.
00:13:04.120 - 00:14:05.470, Speaker A: These are tokens that this account can potentially send, transfer or use for attaching to different transactions. Let's cover it later. And this is the balance which this account cannot immediately use. So this account has 33k near tokens on liquid side, while have 42 million near tokens on their staking. Staking balance is what we use to rank all the accounts. And based on that rank we will select some of them. Let's not do deep dive on that, but we select some of them.
00:14:05.470 - 00:15:16.310, Speaker A: Quite a long list actually. And based on this stake we compute the minimum stake that we want for a node to have to be trustworthy and we call it seed price. So current seed price is at 3.2 million year tokens. And this is why this account is not part of validating list because it has less than 3 million near tokens at stake. So there are getting back to explore, we can see there are 59 validators currently which have more than 3.2 million at their stake count.
00:15:16.310 - 00:16:34.320, Speaker A: I don't want to get us into specifics how exactly we compute this value. We just switched to another epoch actually. So the price changed. Seed price changed for these upcoming 12 hours. And these are 59 nodes which will progress the network further. They will listen to all the traffic in the network and apply certain actions, do certain actions simultaneously with the rest of the same nodes. And what kind of job do they do? They essentially listen up for inputs from users for requests to do certain changes on the network.
00:16:34.320 - 00:17:37.690, Speaker A: Those requests to make a change is called transaction. So there are transactions which are essentially a request to change what kind of change it could be. It could be a transfer like I'm account a, I want to transfer to account b x amount of tokens. That's a change. You create such a transaction and submit it to the network, and you can submit it through any, any of those nodes. You don't need to go to validators immediately. If you submit to any of the node, they will reroute your transaction to the validators, and then validators will include the transaction into their current bucket that they are currently working on.
00:17:37.690 - 00:19:18.304, Speaker A: That is a block. So at every single time there is a bucket where you collect transactions and then a set of transactions gets, let's say fixed, frozen into a block. We produce a block every second, which means the transaction will get included usually a second later than it was requested, because we are waiting for other transactions, potential other transactions to fill up the block. And then we use this as you essentially apply transactions in batch a list of them. And that is called in blockchains, that is called a block. So why do we need a block? Why can't we just use like we receive the transactions, a transaction, let's just execute it and apply the change immediately. The reason to have blocks is to save up on certain costs of communication from different validators.
00:19:18.304 - 00:21:13.628, Speaker A: So instead of communicating information about every single transaction to the whole network, the blockchains usually go with this approach of delaying for a second to collect a few transactions into a single block and then only communicate information about a block to the network, which will be much faster in terms of throughput. So again, it's a compromise between throughput and latency. So if you try to immediately apply transaction to the network, it will be super fast, but you will not be able to process tens of transactions per second because it will just spam the network and it will be so slow. With blocks you cannot apply transactions immediately, so you introduce latency delay to applying the change, but you can apply more transactions at once. Near protocol benchmark showed us that we can collect up to 1000 of transactions into a single shard, let's say into a single block, but with some remarks. So this is the reason why we have blocks in the first place. What we also have, which is specific to Nier, except blocks, we have chunks.
00:21:13.628 - 00:22:24.988, Speaker A: They're not represented on explorer side because they are internal implementation of near protocol. They are essentially optimization to provide even more horizontal scalable throughput. So instead of imagine you have two k transactions per second as an input, and your block can only handle 1000 and you have 2000 on a peak time. So what other blockchains do? They rise the price of executing a transaction. And this lowers the traffic because people are not ready to pay for those transactions. But it doesn't help, I would say. And it's quite aggressive at near, what we came up with is sharding.
00:22:24.988 - 00:22:53.664, Speaker A: And this means that those validators, they don't really produce blocks. They essentially collect all the transactions into chunks. So that's the entity that we use at near. So chunk is what in other blockchains is called. Block is a collection of transactions. Into this batch we can have as many of those chunks as possible. As far as I know.
00:22:53.664 - 00:23:40.588, Speaker A: We tested with ten shards, which means that for each second there will be. Okay, I will get to it. Each second will produce a chunk in every shard. So every shard produces its own chunk for this second. Let's put it this way. For now you have ten chunks produced at the same second. And then we decide to call this whole thing a block.
00:23:40.588 - 00:24:24.700, Speaker A: So a block is the virtual thing. Now it's not containing any transactions, it contains chunks. So each block can contain like if you have ten shards, up to ten chunks in it. Also, given that the nature of the network is that delays could happen or some server could go offline, we don't want to delay block production awaiting for every single chunk to appear. That's why we can create a block with not exactly ten charts, but less than ten. It could be even one chunk. It could be even zero chunks.
00:24:24.700 - 00:25:18.510, Speaker A: For example, all the validators who are responsible to produce those chunks are currently offline. But the validator who is responsible to produce a block is online. Then there is no other thing. For the validator who is producing a block is to submit a block with no chunks in it. Technically, in reality, to prove that you did try your best. Validator who is producing such a block with no chunks includes a chunk from a previously known block. So let's get back to the questions.
00:25:18.510 - 00:26:05.960, Speaker A: One shard produced one chunk and shards and chunks. But one block. Still the consensus in shard, produces a chunk. But how do chunks it into the blocks? There are two roles. There are chunk producers and chunk producer role and block producer role. All the validators are assigned a schedule to do chunk production and block production. So throughout the epoch, every validator will be assigned to either produce a chunk or produce a block for a certain block heat.
00:26:05.960 - 00:26:23.750, Speaker A: So block hate is over here. So at this specific height, this validator is expected to send to transmit a block to the network. And it.
00:26:26.600 - 00:26:49.992, Speaker B: I understand. So the chunk producers essentially have a consensus to create the chunk. And what I don't understand the block producers, how do the block producers agree? So you can have block producers from different shards agreeing, is it? Or how does it, they still have to have a consensus on the chunks produced by the shards.
00:26:50.136 - 00:27:36.452, Speaker A: Yeah, I don't have complete picture here, like how exactly the consensus works over there. What I know is that on the high level, indeed they collect the chunks from chunk producers, from shards, essentially, and just validate certain headers. They do not validate transactions. The proofs. Yeah, they only validate the proofs and then conclude with their own proof for this specific block. And that's how they produce a block. Don't care about transactions in the chunks.
00:27:36.516 - 00:27:53.440, Speaker B: Yeah, but when you become a validator in a sharded system, you decide which shard you want to join because you deploy the pool for that shard. But the thing is, are you just a junk producer or you can be a chunk producer and a block producer.
00:27:55.620 - 00:27:58.764, Speaker A: You will be a chunk producer and block producer.
00:27:58.892 - 00:28:10.390, Speaker B: Okay. So sometimes it can happen that you're the block producer for the whole blockchain, essentially. And sometimes it happens that you're just a chunk producer for the shard. Okay, amazing.
00:28:11.240 - 00:28:11.990, Speaker A: Yes.
00:28:12.520 - 00:28:15.104, Speaker B: Okay, cool.
00:28:15.162 - 00:28:58.584, Speaker A: Good. So let's move on. So on explorer side, what you will see, if you open a block, you will see a list of transactions. We are skipping here, the abstraction of chunks completely. It is stored in the database, but I don't see any good reason to overcomplicate things. On explorer side. There is a missing part here which will come to it later, that is receipts.
00:28:58.584 - 00:29:42.080, Speaker A: And we actually are getting there. So hopefully the idea of producing the block is somewhat clear. I want to stress out why exactly the block needs to be produced even when there is no transactions at all or when there is no chunk in it. So you can see there are a lot of blocks with zeros. Zero. Just one transaction. Well, when there is one transaction, you may say, well, I could delay this execution for one more second and include that transaction in next one.
00:29:42.080 - 00:30:15.980, Speaker A: So there would be two transactions. And I don't need to create a separate block just for the sake of a single transaction. But that would delay this transaction execution by unknown amount of time. Maybe we could limit it up, but overall it's not a great experience. It's better to apply transaction as soon as possible. So essentially execute transaction, make the change, update it, blockchain. It's all synonyms.
00:30:15.980 - 00:31:17.580, Speaker A: So let's get back to the case when there is zero transactions in the first place. So why did we create this block? It seems to be useless. The reason to create a block when there is no transaction is that you cannot prove that there is no transactions. If you are silent, it's your turn to create a block, to create a chunk, and there are no transactions on your queue. If the validator will be just silent, that would mean that they didn't do their job. We cannot really reward them for doing that. That could create various issues with delay in execution.
00:31:17.580 - 00:32:22.630, Speaker A: Then other validators will spend more resources to execute the transactions. But while you will be rewarded the same amount of tokens at the end of the epoch. So that's why we need to create blocks even when they are empty. Nowadays it's rarely when the block is empty. When Mainet was just launched, it was mostly empty. So these days there are like refinance near crowd and rainbow breach, which mostly, almost constantly producing some changes to the network. Let's, let's see, what else do we have here? So this is my account.
00:32:22.630 - 00:33:15.992, Speaker A: I submitted 25 transactions, 25 changes to the blockchain. And I received, somebody submitted two transactions that were targeting my account. So these are outgoing, where I'm signing the transactions, and these are incoming. I can create changes to my own account. So this would be counting twice. For example, this one when I added a new key for my account from my account. So it's a bit misleading here, but that's how it's done.
00:33:15.992 - 00:34:30.848, Speaker A: Right now. Let's open any of the transactions and see what kind of change we can submit to the network. So as I mentioned, transactions are getting included into the blockchain. Transaction is sort of a history, is a ticket which you give to somebody who is applying the change to a huge registry of data. So this was my ticket, my transaction, which I signed for another account. I paid this amount of near tokens for processing my transaction. And the value, well, it's not very interesting or in this context, so let's keep it out.
00:34:30.848 - 00:35:01.912, Speaker A: So interesting part is that we always know when it happened. We also know unique identifier of this specific request. It's a SHA 256 in base 58 encoding. Does talk anything about it here. Well, there is docs, so you may look it up. It might be incomplete. I will need to double check.
00:35:01.912 - 00:36:00.120, Speaker A: Actually, good point for going through it. My transaction, any transaction can have multiple actions and in this specific case, there is only one action. I wanted to transfer six near to this account. Only one action. When this transaction appears on the network and validator receives it, there is going to happen some processing. And this processing on the validator side is going to be the following. So it's a nice UI.
00:36:00.120 - 00:36:56.328, Speaker A: Kudos to Dimitri for lending it and implementing it in the first place. And now we can easily reason about what's happening here. So first thing, what happens with this transaction is that we convert transaction to a receipt. So internally the whole operation on the blockchain level happens with receipts. It's an entity that we use, it's called receipt. It's similar thing to a transaction with the only change that they are signed by the validators. So they are not signed by the users, they are signed by validators and then transferred across the network on behalf of validators.
00:36:56.328 - 00:37:40.940, Speaker A: So validators are now in charge of those transactions. So let's see what exactly this means. So, validator receives a transaction and converts it to a receipt. So this means that the validator checks, the transaction is valid to be even processed. So it is signed by me. There are enough tokens to. Well, no, it doesn't check for whether it's enough tokens for the actions, but it checks whether there is enough tokens to pay the fee for.
00:37:40.940 - 00:38:52.690, Speaker A: Like we actually pay more in advance. So whenever transaction gets to the validator and it does this conversion, it overcharges us for potential future use. And the validator checks whether I have enough tokens to cover fees. And maybe I'm not 100% sure it can check for this deposited value which is deposited from transfers or from function calls. But there is a simple list of basic checks, mostly cryptographic. The most important one is whether the transaction is legit in the first place, whether it's signed cryptographically, signed by my key, by the key that does belong to this account. And the signature is correct.
00:38:52.690 - 00:40:18.540, Speaker A: The validator spent so much gas. Gas is the unit of measure of different cpu time or storage or other resource on the network or network. Traffic is also counted. How much effort does it take to communicate this particular event to other validators? All those fees are configured in the protocol config that we saw on the genesis, this main net Genesis file. So there are like runtime config, various costs, transaction cost, action receipt creation, data risk creation, and. Well, I'm not 100% sure how many different costs we have here, but they are estimated with a special tool where we measure how much cpu time, speed, instructions we needed to perform such an action. Such action.
00:40:18.540 - 00:41:12.600, Speaker A: So let's get back. Validator does this conversion. Validator converted transaction to receipt and include this transaction in the block. This receipt is going to be executed sometime later. It could be executed in the same block if receiver is the same as signer. Otherwise it will be executed in the next block. As you can see, the block hash with this transaction was included is 86, six and over here.
00:41:12.600 - 00:42:15.866, Speaker A: And this receipt was executed in this block. Gk g one. So let's open those two up. So this is one where 86 six has the number 91 and the one when this receipt was executed, when this receipt with transferring six tokens was executed, is essentially in the next block, in 92nd, block eight, and currently in Explorer, we do not display receipts, we only display transactions. It's a bug. Well, missing feature. To display receipts here, we'll need to fix it.
00:42:15.866 - 00:43:41.066, Speaker A: But what I want to stress out is that it's not exactly an empty block. In this case, it has receipts and it even has execution result. And you can see that this receipt is the same, it has the same action, transferred six near tokens as in our original transaction. So what basically happens is that every transaction converts to receipt, and this first receipt has the same set of actions as the initial transaction that is happening all the time. It's exactly what's going to happen with the execution. And this receipt was executed and it actually triggered another receipt to be created and executed as well this time. So if this receipt was sent from frol near to this vento near, this receipt is sent from system, there is no such account on the network to fraud near.
00:43:41.066 - 00:44:51.730, Speaker A: And the action is to transfer this very little amount of near tokens. That's kind of weird. And I guess that's not exactly represented in the UI yet, but it's a refund to what I said happened. While this conversion has been done, the validator pre charged my account immediately at this stage and then produced a receipt to refund back unused tokens. So it prechars to potentially execute this very complex, potentially very complex receipt. But turned out we don't need all of those precharged tokens for the gas we used so little gas. So we were refunded by the neo protocol.
00:44:51.730 - 00:46:05.020, Speaker A: Again, it happened, as you can see even further in the history, I guess it's 93rd. It's 93rd block. It again appears empty, but it's not. It has this receipt with the refund thing is it, does it make sense? How does system sign the charge back receipt? So as I said, all the receipts, even this one is not signed by for all near, it's not signed by system. These are receipts. These entities are signed by validator key. So validator key pair, and it's now validator who is in charge and who will be slashed if they are not following the rules.
00:46:05.020 - 00:47:32.510, Speaker A: And all the rest nodes constantly checking that the rules are indeed applied correctly according to the near protocol expectations. So if the core essence of the whole protocol is that all the nodes only receive the inputs, they never receive outputs, they independently come up with the outputs and create checksums or proofs. They compute a proof of the latest state and only share this proof. If the proof is the same, that's fine. If the proof is different, then some consensus rules kick in and something can be rolled back or somebody could be slashed. So there are very different potential turnarounds to such situation when proofs do not match. And you cannot just submit a proof without computing the value because you can't brute force it.
00:47:32.510 - 00:47:38.850, Speaker A: Marrett, that does answer your question.
00:47:41.140 - 00:47:46.004, Speaker B: Yeah, it answers my question. Just wanted to check because it has.
00:47:46.042 - 00:47:48.528, Speaker A: To be signed or verified somehow.
00:47:48.624 - 00:47:50.070, Speaker B: I just wanted to check.
00:47:52.520 - 00:48:58.120, Speaker A: Every Application has their own key attached to account and fee allowance. Yeah, well, let's make sure that we are on the same page in regards to transaction and receipt outcomes. So the topic that I covered right now is a transaction, its relation to receipt, and this thing here, which is currently not represented good enough, I would say there is a result and there could be potential logs. Let's open. Yeah, actually, let me open some other change. Okay. Yeah, so there is another type of action that could be on transaction, which is function call method.
00:48:58.120 - 00:49:54.430, Speaker A: So it's essentially not functional call method, but a function call or a method call. So when there is a contract deployed on some account, I can call some function on that account providing arguments. And the method name arguments are most of the time in JSON format, but on near protocol they're not limited to JSON at all. It could be any binary protocol breach uses borsch over here. So it's completely unreadable, but it's more efficient than having JSoN to parse on the contract level. And if you would open such. Again, not a great example.
00:49:54.430 - 00:51:11.210, Speaker A: There is some other account that I just happened to memorize. I have no idea whose account is this, so sorry if it's someone's around, but it's useful here. So there is a contract deployed on the account itself, and this account creates a transaction, and it wants to call a confirm method on this account. I happen to know what this actually means? It means that this nexus near account has a smart contract which has two FA implementation, two factor implementation. So essentially it happens. Two stage, let's open up. First you need to add request and add request and confirm.
00:51:11.210 - 00:52:41.600, Speaker A: So it's like whenever you do, you want to make some change on the blockchain level, but you want to have a security in place, for example by also providing security code from your SMS or any other second factor device or whatever. So the first stage is that you add request to your contract. So there is a contract that implements this two FA process. There is a method, add request and confirm, where you add your future request that you want later to execute on the blockchain. And then once you do receive SMS or code from your two FA device, it will submit a second transaction to your account with this confirmation. So very first call is quite simple. So we call a method with a list of parameters.
00:52:41.600 - 00:54:12.590, Speaker A: So the request is that receiver will be this one and the action would be transfer this amount of tokens. And that's pretty much it. So we are submitting request for two fa, for future two fa, what this contract does, it receives this method, these parameters, and it just stores these parameters in its local state and returns you the unique id and also refunds you with some tokens. The second, the second transaction which calls confirm, it says I'm confirming the request id 72. And then what happens? We convert this transaction into a receipt and then execution begins. Validators will run this receipt which is a copy of transaction essentially, but signed by validator. This call confirm method produces a cross contract call.
00:54:12.590 - 00:55:30.100, Speaker A: It's essentially a separate receipt. So it will produce a separate receipt from Nexus near to this account to transfer that amount of tokens. And these two are refunds, they are from system. So let's probably take closer look into multisig contract. So I will link up multi sick. I just want for us to see, so there is a request and confirm. Oh yeah, sorry, it so Ed, request and confirm.
00:55:30.100 - 00:56:16.280, Speaker A: It's a method on our smart contract, as we saw request. It's a complex structure which includes all sorts of things. And the implementation is that we add request. We have this request id and we will return this request id. That's all we need to know about the implementation for now. So just to remind you, where was it? Add request and confirm. Here is request.
00:56:16.280 - 00:57:01.640, Speaker A: Let me make it side by side. So add request and confirm. Add request and confirm. It's a method name on the contract. Here is request, request multi sig request, multisig request has receiver and actions vector of actions. So here is a receiver and vector of actions. Each action is the thing, each action.
00:57:01.640 - 00:57:44.070, Speaker A: Here it is. So it's a transfer of amount. I'm not sure why deposit is here. I guess it's some legacy stuff. So getting back to add a request and confirm, that's all this method does. So it just created new request, recorded it on local storage, has this new request id and returns it. So 72, as we saw it here is this new request id.
00:57:44.070 - 00:59:02.930, Speaker A: Then when we call confirm confirm. So we call method confirm with request id 72 confirm request id 72 we check that the request id is valid. We check some other conditions. We check who exactly which key was used to confirm it. Yeah, that's a missing part over here in the UI of Explorer. We can't really understand why it doesn't like what exactly is going on, why we can't just send add request and confirm, and then once more time just send confirm from the same account. Actually it checks for specific key that is used to sign that transaction in the first place.
00:59:02.930 - 01:00:33.756, Speaker A: And there is a list of expected keys that needs to be used to sign to prove that there were more than one confirmation. And if the confirmation is enough, then we remove the request and execute the request. Otherwise we just insert this new confirmation to the list and you could set up your multisig to have three or more confirmations required. Here we only have like two confirmations. That is enough to confirm and execute, execute the request, execute the request. So basically when we confirm, we use 70 72 as an identifier to find the request from our local storage to execute it. And this happens to be 72nd request is to transfer six near 6.9
01:00:33.756 - 01:01:09.860, Speaker A: near tokens to this account. Wow. I hope it doesn't overwhelm you. I guess we should stop here today because even though Sandy asked about the keys and accounts, and we touched the accounts briefly, the accounts and keys are quite a complicated topic. I may cover it in the next call.
01:01:10.310 - 01:01:15.780, Speaker B: I just have a question. This multi sick dig, is this used somewhere? In general.
01:01:17.770 - 01:02:18.002, Speaker A: It'S used in wallet. So when you sign up in wallet and it used to be a limit of 50 near tokens. When you have an account and you just created a wallet account with 50 or more tokens, it will suggest you to protect your account with multisig and why it's needed without multisig. So somebody can approach my laptop open world near Torg and send tokens. Whoever is needed, there is no protection here. It's fine. Even if we would come up with some pin on this page.
01:02:18.002 - 01:02:31.260, Speaker A: It doesn't help because the attacker could go into local storage, extract the key, and do whatever they want to do with my account having that key.
01:02:33.090 - 01:02:36.558, Speaker B: Where is the multisig in the wallet? We don't have it right now.
01:02:36.724 - 01:03:15.900, Speaker A: We do have, we do have it. Okay. It's embedded into wallet flows. You can enable it account. Yeah. So two factor, you can enable it and then it will provide you with the service to provide two Fa through SMS or email. So essentially wallet helper service will be your second.
01:03:19.070 - 01:03:35.042, Speaker B: See, that's the type of the multi sig. So it's not like three keys. I thought it's like multiple keys, have to sign it like any key. So I could set up like three. I could give one key to Mario, one key to you, and then it is the case.
01:03:35.096 - 01:04:02.154, Speaker A: It is exactly what you describe. Okay, when I set up two Fa in wallet, I give one of my keys. With limited access to wallet helper, the only action it can perform with that key is confirm. So it can only do confirm call to my own account. No other calls is permitted and it can spend tokens. Yeah.
01:04:02.272 - 01:04:06.540, Speaker B: Haven't realized TFA is such a complicated matter in.
01:04:07.070 - 01:04:13.470, Speaker A: Yep, well, it's always complicated. It's not only in here, but in near. It's even more complicated.
01:04:15.410 - 01:04:23.710, Speaker B: Okay, thank you. Because it would be nice if you could also deploy your own, not use SMS, but deploy your own multisig.
01:04:25.990 - 01:04:35.220, Speaker A: It will involve you writing the necessary service, but you can do it with this contract. With this contract. Yeah.
01:04:36.010 - 01:04:38.200, Speaker B: Okay. Amazing. Thank you so much.
01:04:39.050 - 01:05:01.680, Speaker A: Yeah. So just when you initialize it, you will need to provide some initial things, I guess add, request, confirm, let's get not sure where initialization is. Okay. It's a missing part.
01:05:04.770 - 01:05:05.520, Speaker B: Okay.
01:05:07.490 - 01:05:44.378, Speaker A: But you can always go to the code. Well, it's a single parameter. You only specify how many confirmations you want. That's all. Let's use this Nexus account and see when it was. So how to set up two Fa again, it's all on chain. And the beauty of it, it's open, you can always look it up, but you can't do anything about it.
01:05:44.378 - 01:06:39.802, Speaker A: It's just right there. So the account was created through wallet. The new key was added, and then this two fa flow has been done by wallet automatically. It deleted the old keys. So if you have full access key on the account, you can't really claim that your account is protected by two Fa because, well, you can always submit transactions without two Fa. So it deletes full access key. It re adds the old key and adds a new key for wallet and deploys a multi sick contract to itself, to its own account, and calls new methods in it.
01:06:39.802 - 01:07:24.394, Speaker A: It's an interesting transaction. As you can see, there are five actions in the single transaction. It gets translated, converted from transaction to receipt. The new method is just like a function call with parameter num confirmations equal to two. The necessary piece is to actually have two keys on the account in the first place. So this account has them. One is from wallet, which you can see actually here.
01:07:24.394 - 01:08:33.340, Speaker A: So this access key is allowed to call confirm method and that's all. So it's only allowed to call this method. And this is the key, the one that we removed. It used to be a full access key, but we replaced it with a limited permission access key to function call key, which can do add request, add request and confirm, delete requests and confirm call those four methods and that's all it can do. So you cannot submit a transfer transaction anymore because you don't have full access key. You can only do this add request or add request and confirm to submit a request and then to a favor as a second factor, will submit another transaction to confirm the execution using this. So the wallet helper will use this key to confirm your requests once you provide the correct SMS code.
01:08:33.340 - 01:08:48.150, Speaker A: Is this Marcos? Can you elaborate?
01:08:49.850 - 01:09:21.520, Speaker C: Mean like when you want to authenticate? You've actually answered that question. Like, I wasn't clear on whether all the access keys were needed to perform all the operations. So say you wanted to transfer or add, but you've already confirmed in this case. So what I just meant was if you ended transfer, you would either require, was it an either to require at least one key or all the keys to be present. So say you were sharing an account with three people, so you would require all of them to authenticate that transaction, that kind of thing.
01:09:22.210 - 01:10:30.220, Speaker A: Yeah, I mostly answered the question. The only limitation here that I wanted to mention is that it cannot remove. It does look up all the existing keys and remove all function, all full access keys listed here and then reed them again. Only allowing to do to perform these calls. Is it possible to one secondary. Can you hear me now? Cool. Is it possible to add request on adding another full access key? Yes, you can do it.
01:10:30.220 - 01:11:38.510, Speaker A: You will add a request, then confirm it, and then you will have that access key on your account. Yeah, so it's not a definitive protection which you cannot undo. You can even remove two fa. So on the wallet side, you can submit a request to deploy an empty contract or call destroy method I don't recall how exactly multisig is implemented in that regard, but whatever you essentially need to remove these keys, this function call limited keys and add the full access keys again. In it you can send request any full access key or whatever you wish.

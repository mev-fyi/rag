00:00:04.170 - 00:00:10.960, Speaker A: All right, Ricard, thanks for joining us. And do you want to introduce yourself?
00:00:12.210 - 00:00:33.270, Speaker B: Yeah, I'm Ricard. Yut. I am a former verification engineer with runtime verification and blockchain nerd. And day to day I work on KwaSM, which is our implementation of Webassembly.
00:00:35.610 - 00:00:40.780, Speaker A: So when you say your implementation of assembly, you who.
00:00:41.710 - 00:01:06.820, Speaker B: So, runtime verification, or the K framework implementation of Webassembly. So basically it's a formal and executable specification of webassembly written in what would look like a high level functional language to many programmers, I think I see. But it has some nice special properties. I'm sure we'll get around to talking more about it. Cool.
00:01:07.670 - 00:01:09.860, Speaker A: Nikolai, what do you do?
00:01:11.110 - 00:01:48.510, Speaker C: Yes, I work at near helping with what we call contract runtime, which is essentially the way how we execute contracts, smart contracts, which are technically webassembly programs inside of our blockchain, and how we integrate with what we call transaction runtime, which is essentially the part responsible for the function of the blockchain as a distributed database.
00:01:51.410 - 00:02:40.320, Speaker A: So yeah, I'm working also with Nikolai. My name is Max on the runtime, which, as you said, includes execution of the contracts. Also trying to figure out all possible safety aspects of our runtime, because safety is incredibly important for the blockchain. You kind of can live without liveness. If your node stalls or crashes, it's okay, you can just restart it, have subsocial consensus about things, when to restart the nodes or whatever, get a new binary version. But if your safety is broken, it can be fatal for the blockchain. Therefore, it's mine and Nikolai's huge focus in our contract runtime and transaction runtime on how do we make sure the contracts execute deterministically and execute correctly? That's what we're going to be discussing today.
00:02:40.320 - 00:02:44.100, Speaker A: So I'm going to let you guys kick it off.
00:02:45.990 - 00:03:17.180, Speaker C: Actually, I think it would be very nice before we start discussing particular technologies such as Webassembly or formal verification of runtime verification as a company, to discuss a little bit background ideas like mathematics behind that, the reasoning behind the formal verification. So, Rickard, what would you like to share?
00:03:20.130 - 00:03:43.406, Speaker B: Well, in essence, I think a good way to describe it is that formal verification is a process which takes right a bit, takes a program, take a program p and a specification s. Are you writing somewhere? Yeah, can you see it in the whiteboard?
00:03:43.518 - 00:03:44.642, Speaker A: Oh, now I can.
00:03:44.776 - 00:04:56.170, Speaker B: Wait a second. Great. And you put it through this in typical programming fashion, magic box. And out comes either a proof that the specification holds or a counterexample. And in theory, that's what you want. But in practice, there is also this slight possibility that we often don't talk about that you can report we could neither find a counterexample or a proof, but in principle, you formulate something you want to hold of your program. For example, if it's a token contract, it could be the number of tokens is constant, or no one can have negative balance.
00:04:56.170 - 00:05:25.300, Speaker B: And then you give the program the contract as input, and you ask a system to prove that this is true, or come up with a counterexample, and you often end up in this kind of don't know phase. So this box here often requires some manual intervention, and that's what formal verification engineers spend a lot of their time on.
00:05:27.690 - 00:05:44.860, Speaker C: And what is the language for expressing p and s, respectively? So how? I think for p, it's mostly like predefined, and depends on the area where you essentially perform the formalification. But how do you formulate s?
00:05:48.110 - 00:07:23.660, Speaker B: Well, I mean, there are many ways to formulate p as well. I mean, you can't say, well, it's just a program. But the thing that is, I'm going to say it's implicit in all of this, is that there is this semantics that goes into the box, and that's one way to express what a program is. So essentially, it's like you define the world of all programs in a language that could be rust or webassembly or what have you, and then your program is just a specific element in this world of languages. But to do formal verification, you need to express this language, l, in a mathematical fashion. And that's, for example, the webassembly implementation I'm working on is basically a way of turning the webassembly written, admittedly mathematical specification, into another mathematical specification that we can run with our system. So, the way you express s depends on how you have expressed the language l, or rather like how you express this world around here.
00:07:23.660 - 00:08:33.730, Speaker B: So you usually don't just give the program as source text into this system, or you can, but the first thing that is bound to happen is that the program is turned into this mathematical object. And for example, we use something called matching logic. So you write your specifications in matching logic. If you're using a tool like Isabelle hall, you will have an Isabel hall model of the language, and you can express things in regular higher order logic. Or it could be first order logic. It depends on the tool. And the best way to come up with finding a good balance between powerful specification languages where you can express a lot of things, but you don't want to be able to express too much, because if you have a too powerful specification language, then verification can become harder.
00:08:33.730 - 00:09:18.190, Speaker B: So there's a balance to be found there. And there's also obviously a user experience aspect to it where you want to find a way to express specification that makes sense to developers. A very easy way could be to have assertions in your code and then just have the tool transform those or transform the specification into, or write a specification for you that basically says we're never going to revert because of an assertion, but you might want to express temporal properties as well. Like say, like well, if you ever touched this variable during a run of the program, you are not allowed to touch this later and that can be harder to express.
00:09:19.490 - 00:09:58.730, Speaker C: But doesn't it actually mean that in a good case of formalification, PNS better be the same because programmer shall express his or her desire in a program and a part of those desires intentions, logic. You also express the invariance. So for example, assert, as you mentioned, is a very simple form of the formal runtime verification. So why do we want to go beyond asserts?
00:10:01.390 - 00:11:26.262, Speaker B: Well, first of all, I personally agree with you, and a big part of making formal verification more widespread is to make sure that it has good ergonomics for developers and systems where you can use asserts or do or do write annotations for pre and post conditions, for example. That usually makes more sense for the developer. The problem is that if you want to do source level verification, or if you just want to have the developer, as they're writing code, also write specifications, that's often a good thing. But there's not necessarily a big chance that the automatic formal verification engine is going to be able to prove that. And if you're a formal verification engineer, you usually know your tool, the engine you're working with pretty well, and some ways of formulating specifications are more amenable to verification. And you might want to take this high level specification and break it up into many different smaller sub goals that you want to prove, for example. And then you need to have a language to express it in.
00:11:26.262 - 00:12:12.370, Speaker B: I mean, it's the same thing. The first thing that happens to the program is that it will be expressed in this mathematical specification of the language. If the specification is also part of the source code, then the same thing happens with the specification. The specification is derived from the source code, but the first thing that gets put into the actual formal verification tool is going to be this. It's going to be written in some specification language that is usually more powerful. And if you're doing formal verification, you probably want to be able to write your own specifications that you don't have to go through the source code to implement.
00:12:12.450 - 00:13:02.630, Speaker C: But actually, if we talk about languages, I think usually there are formal languages in the form of formal grammar standing behind the language, and that's kind of one layer of languages. But actually with languages there is associated runtime semantics and certain behavioral characteristics. And the question is, which part of the language is actually to be addressed by the form of verification? Is it on time behavior? Is it like certain syntaxical properties of the language?
00:13:04.330 - 00:14:14.330, Speaker B: Well, I can't really think of anything that would be all that interesting to verify just using syntax. I mean, usually most languages try to have a very straightforward and not too complex and undecidable grammar. Like if you want to write a parser, you'll write an LR one parser that's parsing techniques, but then to give meaning to your language, that's sort of where the magic happens, so to speak. And that's also where languages become more equivalent. Any Turing complete language are essentially the same to some extent. And the way you define what each construct in the language does, I'd say that's the more interesting part. I'm thinking whether there's something that could be very interesting to verify as like what a programmer usually thinks of the pure syntax.
00:14:14.330 - 00:14:40.566, Speaker B: But if it's rejected by the parser, then you're probably going to have a parse error and resolve that the parser is a verifier. It verifies that what you're giving it is something that is expressible in the language syntactically. And the type checker is a verifier. It verifies that you are not doing anything that's considered illegal by the language's type system.
00:14:40.668 - 00:15:51.454, Speaker C: Yeah, exactly my point. Okay, so on a different layers or levels of the language, there are different rules. Like on the lowest level, there are pretty much syntactic rules of the formal language. On the level of the type system, there are different computation essentially expressed in a type system. And I think significant part of the language research like during last 50 years was put into essentially making a type system such that most of the semantics are actually caught on a level of the type system. My question about the formal verification as a technique is essentially how it augments the research. Because everybody knows how to write parsers, many people know how to do like a type system and how to perform type checkers on lettuces and so on.
00:15:51.454 - 00:16:26.440, Speaker C: But I think not so many people, at least not myself, are aware how to go on the next semantic layer, which is higher than a type system. So how to express formal statements in that area, which builds like complete examatic system, which could be actually used as input for any reasoning machine, which any formal verifier is. And so that's pretty much my question.
00:16:30.430 - 00:16:48.320, Speaker B: Just so I understand you correctly, you're trying to figure out what's the gap between the type level kind of verification that a programmer is expected to do and what the things that we usually call formal verification, where you hire a formal verification engineer to prove properties of your program.
00:16:50.930 - 00:18:00.550, Speaker C: Pretty much it looks more like, for example, type verification is absolutely like mathematical procedure. It's an algorithm. Once you have a described system for the language, and it's usually in some form is formalized as a part of the language, you can verify that the types type attribution is correct in a particular program, and that's mechanical process, and you don't need any additional operation. And it's not important if the program on the same language, if it's like word processor or web server, the type system manipulation will be exactly the same because it's a compiler which does the verification. And so my question is, imagine if you have a formal verification, what is the formal system against which verification happens, how it could be built, how it is built in your tool or in other tools.
00:18:03.370 - 00:20:07.082, Speaker B: Well, so in our tool, it's built through something called matching logic, which looks fairly similar to most logics that people may have encountered, but it's slightly more expressive. But say for example, in Isabella hall, you are using a slightly more familiar, probably higher order logic to express the meaning of programs. And I mean, it's not really the type system. And these kind of form of verification things we generally do are not really in competition because the idea with a type system is usually that it's supposed to be fully decidable. It should be pretty straightforward for your type checker to just say this is well typed, or it's not well typed, and might do unification like, oh, you're doing addition, and you know, it's going to see that one good whiteboard moment, like if you're doing one plus one somewhere in your program, or rather if you're doing like p plus q, and the type checker can infer that this is an int and this is an int, then this expression is well typed. But for that, the type checker must be able to infer the type of every expression in the program, which puts a limit on the type system's expressiveness. If you want to have a type system that can express anything, then you move into undecidable territory.
00:20:07.082 - 00:20:50.330, Speaker B: Now, type checking becomes undecidable. And I mean, this limitation here that you will sometimes end up in, don't know. That's just like a sort of mathematical threshold you cross. At some point, things are no longer decidable. Decidability means there is an algorithm that can decide this and will always be successful. Regular type checking in something like Haskell or rust or java is decidable because the type checker will always succeed to tell you whether your program is well typed or not. But if you want to have a slightly more expressive logic system, things become undecidable.
00:20:51.010 - 00:21:03.330, Speaker A: So a question you're saying is undecidable when it's theoretically undecidable, not something that your tool cannot infer because of some computational limitations.
00:21:03.750 - 00:21:45.614, Speaker B: Well, obviously there can be computational limitations. There is definitely a. I mean, in practice, for example, I think in Isabel, there's a tactic that I think is called blast, which is technically, it can take certain, I think, linear formulas, it's called, and check if they are true. And it's like, sorry, I lost a word. You don't say that it's complete. Well, it should always succeed in theory, but in practice, there's obviously a timeout limit. Somewhere the two give up.
00:21:45.614 - 00:21:47.200, Speaker B: But there is also.
00:21:49.170 - 00:21:51.246, Speaker C: The halting problem in some form.
00:21:51.428 - 00:23:09.542, Speaker B: Exactly. The halting problem is like the example that, you know, if I make the simplest Turing complete language, or if I give you lambda calculus and say, will this program ever terminate? For a great deal of programs, that's pretty straightforward. But there are going to be some programs where it's not straightforward. So, for example, people often confuse this and think that, oh, the halting problem is undecidable, therefore, it's meaningless to try. But honestly, in many cases, if you're writing a smart contract and your contract just looks like this, it's just like straight line code, then I can tell you, well, and this contains no calls and no jumps, then I can tell you this is going to terminate. But if you have a jump in here or you have a little while loop, all of a sudden, then it becomes more complex, maybe I won't be able to decide whether this terminates or. And the way many tools work is that they make sure that when you write certain functions, for example, in Isabel, you also have to provide a termination proof.
00:23:09.542 - 00:23:26.010, Speaker B: But if you just define your functions using certain simple structures, then the program can automatically tell you, sure, this is going to terminate. And if you want to do something more complex, then it's your job to also provide a proof.
00:23:26.170 - 00:23:49.400, Speaker A: So the loops also include loops in, let's say, standard arithmetic operations. Mathematical operations like, let's say, hash computation, right? Or like signature computation. If we use it somewhere in our code, then we might end up in this dunno state.
00:23:53.050 - 00:23:54.262, Speaker B: What was your example?
00:23:54.396 - 00:24:57.450, Speaker A: Well, I mean, let's say we have like a very simple example that our program verifies certain hash, or like certain signature, right? And we want to prove that the assertion that says the hash doesn't match never fires in the program. And so we cannot really prove it for the input because you need to literally pre image the hash. But this is like an example of a very simple program where you just have a hash computation and you just cannot prove that the program will not panic because the hash has been like one way function has been used somewhere in a code. But those one way functions are incredibly popular in smart contracts, even basic asset manipulation, like defi contracts. So wondering whether if someone drops in this kind of crypto function, will it automatically make it unusable? The formal application usable?
00:24:58.350 - 00:25:02.454, Speaker B: Oh, no. And I mean, for example, I think you can scroll down a bit, maximum.
00:25:02.582 - 00:25:03.980, Speaker A: Yep, let me scroll down.
00:25:06.510 - 00:25:43.740, Speaker B: Here you go. That's my terrible. What you do in general, let's see where you are. Okay. What we tend to do is often you're doing something called symbolic execution, which means that instead of inputting specific values into your program, you are inputting. There we go. You are inputting like a variable x, right? Your input to a program is x.
00:25:43.740 - 00:26:44.094, Speaker B: And then at some point you get to a place where you do hash x. Since f x is unknown, we probably won't be able to call this function. So what we'll do is we'll just leave the symbolic variable hash x here. And now we know certain things about this value hash x. For example, it's between zero and two to the power 256 minus one or something, right? And we also know that if you also have Y and you do hash, because you're just defining it as a function. And if you say, well, let's do hash Y, then we have the same situation. But now, if you ask me to prove, can you prove that hash? Sorry, it's a bit of a lag on my end.
00:26:44.094 - 00:27:48.866, Speaker B: So this becomes pretty ugly. If you ask me to prove, given that x equals y, that hash of x and hash of Y are the same, I can do that because I just have that as an assumption of my specific hash function, I write like a lemma saying that this hash is correct. And that's usually what you do. I think it's Tony hor that said something like the job of formal methods is to elucidate the assumptions upon which formal correctness depends. That's a fancy way of saying, well, the way you're doing formal verification is you're trying to figure out that something is correct given certain assumptions. So, for example, if I'm verifying a smart contract, I will often assume things about cryptography, because I'm not really proving things about cryptography, I'm proving things about the program. And I will say this program is correct given that the cryptographic primitives are correct.
00:27:48.866 - 00:28:40.514, Speaker B: Like if I do encrypt X with a key, and then I do decrypt with the same key, I have a lemma saying, or like I have an assumption essentially saying, well, that's going to be the same thing as X. If I encrypt it and then decrypt it and I use the same key, that's going to work. I will also have, or I might have a lemma saying the opposite. But I guess there's usually a chance that there is some probability. The problem with cryptography is that it's very probabilistic. So, for example, if I'm storing two values, let's say X and Y are not equal. And you ask me, is hx equals to hy? The answer is maybe.
00:28:40.514 - 00:29:03.820, Speaker B: Unfortunately, we could just add as an assumption saying that, oh, if X and Y aren't equal, their hashes are not going to be the same. Basically, there are no pre images. That's not true. But you can say that given that you're not getting a hash collision, your program is correct. And then you can decide, then you can employ your reasoning about that to say if that's good enough for you.
00:29:05.070 - 00:29:15.790, Speaker C: If your data is longer than 256 bits, then for 256 bit hashes, you are guaranteed to have at least one collision.
00:29:18.530 - 00:29:19.600, Speaker A: That's obvious.
00:29:21.090 - 00:30:25.922, Speaker B: Yes. The point is, and that's why I come back to this horror quote, is that what you're doing is you're usually not saying this program will always work in every circumstance because there's a physical world out there and things can go wrong. And is this going to work correctly given that every node fails in the same way at the same time? Maybe not. But if you just have encode that as an assumption that your virtual machine is deterministic, or you encode as an assumption that you will never have a hash collision. Then you can prove certain things. But that also means your proof doesn't work unless you state that as an assumption, and that's valuable, right? And you can remove that assumption and say, oh no, our contract works even if there are hash collisions. But either way, you probably wouldn't state that there are no such thing as hash collisions, because that's patently wrong.
00:30:25.922 - 00:30:47.100, Speaker B: You could use, like you said, the pigeonhole principle to prove that wrong, and now your whole system is unsound. But you could add an assumption saying, well, for these particular values x and y, they do not collide. And then you can prove that no one is able to steal your tokens, given that they can't produce a pre image, for example.
00:30:49.550 - 00:31:52.190, Speaker C: And actually, I really like our discussion. However, it gets very theoretical and probably close to mathematical problems or even foundation of computations, let's say. I hate to be kind of a moderating person here, but I guess to make it more closer to the theme which we aim to discuss, we probably can discuss more like a practical aspect. Imagine that in our case, p is like a rust smart contract. Could you give an example? What would be an S in your verification example, and how does it bring value to a normal developer who's not mathematician, not formal logician, but like a smart person writing smart contracts?
00:31:54.470 - 00:33:19.158, Speaker B: Sure. So if you're writing a program in rust, my standard example is it's a token contract, and history has proven that. History, like the last ten years, have proven that even something as on the surface simple as a token contract can have all kinds of really bad bugs in them. A program that looks super simple can accidentally mint tokens. That's an S that I usually take as an example that in a token transfer, the outgoing sum of every address touched, or the outgoing balance of every program touched is equal to the sum of all the incoming balances. So if a on the inputs plus b on the input plus forever is equal to if these are all the addresses that are sent as inputs to the transfer function. And these can be very complex.
00:33:19.158 - 00:34:17.086, Speaker B: It can be like, oh, it's delegating to someone somewhere, and it's giving something to the contract owner, address, and whatever. But I can say that the ingoing transfer or the ingoing balances has to be the same as the outgoing balances. And I mean, this fails for all kinds of reasons. The transfer might fail. An excellent example, of course, is overflow. I mean, if one of the addresses overflow during the transfer, then this doesn't hold. So you might say that, okay, this is going to hold, assuming that none of the addresses, there's no overflow in here, and you have to express that as a property, assuming that the changes in balances don't cause overflow, this works.
00:34:17.086 - 00:35:20.434, Speaker B: This is one property you want to hold, but another property you want to hold, for example, is that all the balances, all the outbalances should be. Sorry, actually, let me do this by text, that's easier. So AI, AI, b I, et cetera, the outgoing balances are all larger than zero, or sorry, that the ingoing balances are all larger than zero. That's going to imply that all the outgoing balances are larger, equal to zero, for example. And that's another property you might want to prove. And from this you might want to prove that the total amount of tokens in the contract is always the same. That might not be something you want.
00:35:20.434 - 00:36:54.174, Speaker B: Maybe this contract is supposed to do minting, but I mean, from this proof you might be able to extract quite easily the property. Like okay, if you do a transfer, the transfer doesn't affect the number of tokens in the contract. And I think one way this can help a developer, and we often have this conversation, is like, how can we make formal verification easier? One way to make formal verification easier is to make sure you are always very explicit about your assumptions, and you try to at least give enough information in your comments or your specification documents, or by the way you name things or whatever, or by assertions that it make it look very clear that these kind of things can never be violated. But I mean, if you just write a straightforward transfer function, there are many ways that can go wrong. But if you write this down, these kind of specification, and then try to just look at your code, there's probably going to be places in there where this is violated. And then you need to start thinking, okay, am I sure that this is going to go back to a proper state? There's going to be somewhere where the value of A's balance has been decremented without the value of B's balance having been incremented, and so on. So I think until we get, I mean, our tools are improving rapidly.
00:36:54.174 - 00:38:03.400, Speaker B: We're in like a formal methods renaissance. But for the programmer on the ground right now, I think starting to become a bit familiar with formal verification and maybe with property based testing is an excellent way to make use of this right now. Because if you just start writing down your assumptions and your invariants, then you're probably going to catch yourself making certain mistakes. If you write down an invariant. That's saying, for example, say you never want your contract balance to, you want it to be constant, and you just look over your contract and you're trying to make sure that that holds. If there's one function where you kind of scratching your head and saying, oh, I'm not sure, but yes, I think I thought it through once and it should work, then maybe you can rewrite that function to make it clearer and convince yourself and others that it's correct. So I think the formal methods, thinking and approach is valuable to everyone, and I mean especially in the DeFi world.
00:38:06.090 - 00:39:00.766, Speaker C: Yeah, I just wanted to say that what we described sounds like a very good hedging, which most good programmers I'm aware of pretty much follow, even without much of the training in a formal verification. So I know that good programmers writing complex systems always write as first. So checking your invariance frequently as possible is very common and very good habit. That's. I'm fully agree. But this kind of gets back to the previous question, which I had. So don't you really believe that the best practical formal verification is where at least languages for p and s coincide, or mobile, even where the p and s itself coincide.
00:39:00.766 - 00:39:07.194, Speaker C: So where the formal verification must be a part of the program?
00:39:07.392 - 00:40:11.440, Speaker A: Yeah, I would even add to that, because I was going to ask in the same kind of lines, the question that when engineers design a program and they have invariants in mind, they enforce them through asserts, through the assertions, right? And basically the assertions that express the invariance is the s for the like. That's what I think Nikolai is going with, is that you have a program, right? You wrote a program, and then you go over and you try to make sure that the invariance hold and your s is actually a set of assertions that you put in the strategic spots in your. And since they have to do it anyway, like good engineers, right, they need to be aware of the invariance and have to add the asserts everywhere. Where does the value of the formalification comes in? Since we enforce the invariance through the asserts, why do we need to prove them additionally, on top of that?
00:40:14.050 - 00:40:56.002, Speaker B: That depends, I guess there are two kinds of asserts. One kind of assert is like sanity checking that everything works, and if it doesn't abort, like checking. Well, if someone's trying to transfer money to themselves, then you can abort, for example, or that kind of thing. But another way you could use asserts that isn't really meant to be functional is writing down these asserts that should never be violated and you believe that there is no way they can be violated. Those are the kind of asserts you probably want to remove at compile time. It depends. But I mean those could cause your contract to dost.
00:40:56.002 - 00:41:48.346, Speaker B: Well, if you have an assert that you think can never be violated and all of a sudden that's saying the transfer function and somehow you're wrong and that ends up being violated and the only way to modify it is by calling transfer, then you're never going to be able to transfer anything with your token contract again and now your token is worthless. Probably. I say there are two kinds of asserts people will often write. Sanity checking your input. Like you call this thing correctly and you're not going to break anything. If that's wrong, if this is Ethereum, we're going to eat your gas, it's your problem. But that's input validation and that's sane.
00:41:48.346 - 00:42:39.662, Speaker B: And that's exactly like you're saying. Most good engineers, when they are not under some certain very tight deadline or something, they should have those in place. But there are also the system invariants. I haven't been over all the contracts and all the different platforms, but I think those are usually less, not present as much. And those are really the kind of things you want. You want to be able to say that your system will always be in this consistent state, your deposit contract is never going to lock up, you're never going to lose these funds or so on. And those aren't really like input checking a search, those are a search of your system.
00:42:39.662 - 00:43:38.354, Speaker B: And if those are violated, your system is probably designed around those always holding. And if those are suddenly violated, are you sure that you have the correct fallbacks for that? If that's all you take with you, like, oh, if you want to say, I'm going to show those former verification engineers that I don't need them and I'm going to write a search and I'm going to say, well, if this invariant is ever violated, we're going to call the fallback function and all our things are going to be liquidated and everyone's going to be reimbursed. Then great, you've added some great panic handling, basically. But you did that by trying to think what are the variants I expect to always hold? Where can they be violated? Am I sure that I can handle them correctly? Because that's the kind of thing a verification engineer would find. Like you assume that this will always hold. Well, it won't hold in this case. And you say okay, but in that case I'm going to deal with it like this.
00:43:38.354 - 00:43:40.610, Speaker B: And that's great. Now we have better software.
00:43:43.590 - 00:44:57.850, Speaker C: And actually in this regard, I have related questions, because one of the I'm practical engineer in the sense that I did a lot of various complex systems, and it showed that there are two very powerful practical techniques for verification. One is a sort which I mentioned, and another is some form of a virtual machine, because you can put some invariant checking actually into your execution engine. For example, things like for JVM, there is a formal verification of stack manipulation correctness. For example, it's a stack machine. So when you put values on stack and from stack, you essentially ensure that stack is balanced and properly typed. And similar thing exists in many other virtual machines. Some invariants could be checked and insured by the virtual machine.
00:44:57.850 - 00:45:16.260, Speaker C: What do you think formal verification could bring to the virtual machine? For example, if we have like razor virtual machine, do you think there could be something which we could add to this virtual machine to execute smart contracts in a safer way?
00:45:18.230 - 00:45:38.220, Speaker B: What you're talking about, if I understand you correctly, this sounds like runtime monitoring. Like checking that certain things, checking at runtime that things always work, and maybe like executing, exercising the system and running a lot of things and making sure that things always work. Is that correct?
00:45:39.150 - 00:45:40.140, Speaker C: Not exactly.
00:45:41.550 - 00:45:42.250, Speaker B: Okay.
00:45:42.400 - 00:46:33.100, Speaker C: No. For example, if you look at the Java machine, it has a bytecode verification. Bytecode verification is essentially before executing the bytecode check that the manipulations with stack are correctly, like balanced and so on. There are other checks, like memory manager in a sense, is something which helps perform modification because it ensures that objects for which the reference being held are not actually disposed, which could happen in language like a C or C Plus. Plus webassembly has similar things.
00:46:39.550 - 00:47:38.650, Speaker B: Yeah, those are properties that are super good to verify and are actually also kind of relatively easy to verify. Again, they're decidable. You can say that you can just look at a sequence of JVM bytes and say, okay, these are not going to violate cost, stack underflow, for example. And that's because that's a decisivable property. And it's well known that that's something you can do if you just design your language correctly. But some things are not decidable. And especially like if you're an engineer writing contracts, it's very hard to design a general process that is going to check some meaningful property of every proper possible program you can construct.
00:47:38.650 - 00:48:12.486, Speaker B: I mean, essentially, formal verification is applying these formal methods to the things that are not easy. Or rather, I mean, the thing you're describing is also sort of formal verification, but it's the kind we take for granted. It's the same way we take type checking for granted. It's something we know how to do. It's something we can do well. It's something most people will be familiar with, and therefore we do it. Obviously, there is no real such process for checking these kind of specifications of a token contract.
00:48:12.486 - 00:49:16.542, Speaker B: If there were, we would just apply them, and every program on the EVM or the near virtual machine would be guaranteed to satisfy these properties. But since we don't have that, we need to do whatever we can, and that usually takes some human ingenuity. And in 30 years, we're going to have a lot of cool new decision procedures to automatically verify a bunch of things that we think are important for smart contracts, but right now, no one's thought of them yet. So what you're describing are a bunch of properties that are very important to verify, but there are other properties that are important to verify that are not as easy in algorithms. There's a bunch of algorithms. There's P and MP. There's a bunch of things that are easy to do, and there's a bunch of things that are not easy to do.
00:49:16.542 - 00:49:56.380, Speaker B: But the things that are not easy to do might still be important. Therefore, we're applying our ingenuity to try to solve them best as we can, even though we know that there are some or, okay, we don't know. But even though we think that there are some basic limitations to how well we can do it, we still want to do it. So even though we know that there is no decision procedure for whether a program halts, we want to be as good as possible in detecting halting, and we want to be as good and automatic as possible in detecting important properties of smart contracts and when they're violated and when they're satisfied. And that's sort of where the research is happening.
00:49:59.970 - 00:51:06.180, Speaker C: Yeah, that's absolutely correct. I just wanted to understand the practical consequences of formal reification for engineers. So what would be the best practices? I guess we can understand one of the best practices, which is asserting other probably would be adding more checks into VM. But as you said, it's on a lower level, so it's less on the semantic layer and more on just execution engine layer if we talk about semantic related or formal verification. So what would you recommend people to do here, other than think about before the program, which is probably very valuable suggestion, but still.
00:51:09.110 - 00:51:47.098, Speaker B: It'S hard to do in general. It's sort of like saying, what are the principles you should adhere to to make good software? I mean, it depends on what software you're building. If you're building a website or if you're building a nuclear missile launch system, you have different practices. And there are some things that are obviously always good, like document your stuff and think through things. And I think it comes down to being clever. Keep it simple. Stupid principle.
00:51:47.098 - 00:52:46.980, Speaker B: If you want to do something really clever, something that optimizes something in a really smart way, but that is non obvious, you need to convince yourself, and ideally convince someone else that this holds. So, I mean, code review is a great example. If you make sure you do good and honest code review, like people actually don't just let your stuff go through. Like people actually say, I'm not sure this works. Can you show me and convince me 100% that it works? If you can convince them and you just write that down in a comment or in a document somewhere, then you're essentially doing formal verification on paper. Mathematics is essentially writing convincing enough stuff, but also try to convince you. I think we often stop in this place where, okay, it's probably true, and I can't think of any way this would not work.
00:52:46.980 - 00:53:24.300, Speaker B: Whereas of course, verification deals with the problem of like, am I 100% sure this can never be violated? I also think one shouldn't be too hung up on formal verification as like the holy grail either. I mean, there are all kinds of things that are in between. In essence, you have like let me grab the whiteboard again. You're going to have this. Let's do an arrow. It's very laggy, sorry. Let's see.
00:53:24.300 - 00:54:28.610, Speaker B: It's a bad arrow. Like more and more better verification. And I mean, if you do testing, if you write unit tests and integration tests and everything, great, you've taken a step in the right direction. Right. And if you do like runtime monitoring, or like, you know, you know, you're always checking at runtime that things are working properly, that's a step in the right direction. And there's all these things that happen on this scale. And I'd say where the more formal verification stuff starts is things like bounded symbolic model checking and say symbolic execution.
00:54:28.610 - 00:56:17.190, Speaker B: Like you find a symbolic execution engine and run your program on different inputs and try to verify things or use state of the art tools, every step to the right is probably an improvement, but I think we tend to get stuck in testing and then this fluffy thing, which is just, hang on, this is not going well. Here we go, this fluffy thing, which is hard to place on the scale which is auditing. That's someone looking at things and saying, oh, this probably works, and this falls best practice. I mean, one thing we're working on is trying to make a tool called Firefly, which focuses very much on using the existing test suite, like your existing program test suite and our formal methods to make sure that you've exercised every branch on the bytecode level. And we can also use that testing to do symbolic execution and check for properties getting violated. And you can write invariants of your system, like saying, my system should never violate this property, and then we can have that invariant and we're going to keep it with us as we are running your test suite, and we're going to make sure that that always holds. So essentially, your test suite is not only testing the things that it's supposed to test, in a sense, it's also making sure at all times that all your systems invariants are not violated.
00:56:17.190 - 00:56:56.500, Speaker B: And I think it's important to not get stuck in full form of verification because full form verification is valuable, but it's also harder than these other techniques. And therefore, right now it's sort of reserved for the most important things, the things that can absolutely never go wrong, like the beacon chain contract on Ethereum, like making sure that that is going to work and making sure that certain properties hold of it. That's a good place to employ formal verification if you have the tools and the means, but it's not going to work for everyone at all times.
00:56:57.430 - 00:57:38.350, Speaker C: Yeah. Could you give like an example how, because this sounds like a super cool idea to what you just described, to actually take tests and essentially factorize it in a sense. So instead of actual values used in tests, just use equivalent classes of the text, which leads to same or different program behavior. Could you please explain how it works in the Firefly?
00:57:40.770 - 00:57:47.860, Speaker B: So I'm not sure I understand the question. You're saying how you can automatically generate tests, or how.
00:57:51.110 - 00:58:11.334, Speaker C: Could you translate test from the actual execution to symbolic execution? I think if I understand what you described here, you essentially use a test as an input to symbolic execution engine so that you kind of understand what's going on.
00:58:11.532 - 00:58:45.874, Speaker B: Okay. Yeah. So I don't work on Firefly, so I don't pretend to be an expert on this. But the way I understand it is that what you do is we just have a specific contract, and if you are calling that within Firefly, we're going to catch that and give you a symbolic value back. Or initially we're going to give you a random value back just so you can do some random testing. But then we might also give you a symbolic value back. But if you run the same test in, say, ganache, then it's just going to give you a specific number at all times, or maybe a random number.
00:58:45.874 - 00:59:42.710, Speaker B: So the way I think Firefly does is like you ask for a random value from a specific point, and if Firefly sees you doing that, it's going to turn that into a symbolic value, if I understand correctly. So essentially you have to write your tests, or you write your tests as a property based test, like a randomized test. And then I don't think this feature is fully implemented, but in the future we're going to turn that into a symbolic, or we can turn that into a symbolic value. For example, it's all just standard like programming tricks, using hooks and checking which environment you're in. Formal verification is just very similar to programming. I identify myself as like a software engineer day to day because it doesn't feel that different. It's just working on a slightly different domain.
00:59:42.710 - 01:00:47.946, Speaker B: I'm building the tools to do health specific development work and I'm just doing it in a specific special language that has some neat features. I think it's important and that formal verification doesn't get stuck in an ivory tower. I know I talk in very abstract terms sometimes because I want to make sure I stay correct and don't say things that are probably wrong. But a problem with formal verification sometimes is that it can be a bit too abstract. And I think what we're doing, what I like to do is just show the tools I'm working on and say like, hey, here's what this can do. And it looks like you're doing functional programming, which is probably not that scary. And it's something you probably should do, like just kind of putting it in the hands of people and making sure, like I said, that people start thinking about, oh, I want to prove something.
01:00:47.946 - 01:01:26.520, Speaker B: And then you start by saying, oh, what is you want to prove? Right? Because people often come and say, oh, can you prove, I just want to prove that my contract is correct. And then you have to ask, well, what does that mean? What does it mean for your contract to be correct? And half the time people don't really have like, oh, but I know what it's supposed to do. Well, then it's doing what it's supposed to. Unless you have something written down that you can check it against, you can't really do verification. And unless you have that, it's quite possible that you haven't fully thought through what your system is doing. And it's also even more possible that it's going to be hard for you to explain it to someone else.
01:01:29.690 - 01:02:01.250, Speaker A: A question here. Sorry, Nikolai. And that's also about the practical aspect. So we talked about the financial contracts here, right? And you might have heard that many financial contracts were broken or abused not because there was some bug in the code, but because people were able to find a way to combine them somehow together, or to do some manipulations on them in such a way that at the end they come out profitable.
01:02:01.670 - 01:02:06.118, Speaker B: Like oracle manipulation with flash loans, for example.
01:02:06.204 - 01:02:18.780, Speaker A: Yeah, like flash loans, whatever. Just like some temporal manipulation, you can jack up the price, then dump it and those kind of things, right?
01:02:19.710 - 01:02:24.218, Speaker B: Call out some other contract and manipulate the price, as you're saying.
01:02:24.384 - 01:02:48.610, Speaker A: Even without going in those areas where we talk about the cross contract interaction and everything, how would you go on with trying to prove that your contract cannot be financially manipulated in temporal way, in such way that someone can somehow come out profitable at the end by just doing a bunch of atomic operations on your contract?
01:02:50.790 - 01:03:55.480, Speaker B: Well, always start with the simplest way of doing things. And I mean, the simplest way of doing things would probably not be to do full formal verification on all the code and all the contracts. It would probably be something like set up a model, like just a little graph of the different contracts, how they interact. Again, you have to come up with, well, like you said, how do you make sure someone doesn't walk away profitable? Well, you have to come up with a way to specify that, and it kind of depends on exactly what you're trying to specify. One thing you could say, like, for example, I don't know all these attacks in the specifics, but you'd say you want to prove that someone will not be able to manipulate the price of a uniswap swap as they're in the body of the code. For example.
01:03:57.710 - 01:05:14.660, Speaker A: Yeah, sorry, before we go into the details, the reason why I express this concern, because it sounded like, to me at least, it should be intuitively, really easy to formalize something like a property of some energy preservation thing, where you say something that we were trying to talk about, which is like, you cannot mint, or your total supply stays the same, something in the lines of, whoever interacts with the contract loses, took the gas. Or always, it's more like some law of thermodynamics. If you interact with the contract, you always come out at least losing the assets for the gas. Okay. And the direction you're going with is trying to say like, well, trying to formalize is too abstract, so you need to express more specifically what are the properties in there, and then try to prove formally that they hold what I'm saying. Can we come up with some set of almost like a laws of thermodynamics, but for the financial contracts that we can formulate overall for all financial contracts, and then just run verification independently of what is the body of the contract is.
01:05:15.270 - 01:05:59.022, Speaker B: That's a really cool idea. Yeah, I mean, definitely get a committee on that. Just like trying to figure out what are like figure out the thermodynamics of financial contracts and make sure that, again, since I can publish a financial contract and it's turned complete and you can do anything, not all contracts are going to adhere to it, but we can at least put down some best practices saying, like, all these things should always be respected by any good financial contract. That would be really cool. I don't know what that would look like, but it would be really cool. And it would, I think, definitely be amenable to formal verification. One problem with smart contracts is that they like to call out to other contracts, which is a good thing.
01:05:59.022 - 01:06:59.726, Speaker B: It's composability. But it also means that you have to extend your assumptions to other contracts. So you have to say, like, if you're entering a specific function, and that calls out to another contract, and you want to make sure you don't violate the laws of thermodynamics, you also have to assume that the other contract doesn't violate the laws of thermodynamics. But what if your contract call can be pretty complex? Maybe you're calling out to a different contract, and depending on the world state, there are four different paths you can take, and each one of those paths call out to a different contract. All of a sudden now you have a pretty complex, you might come up with a pretty complex system of interacting contracts. And of course, users can define contract to say, oh, please call this contract in the course of all this. And I think in practice, it can be hard to do that at code level, code level of verification, unless we have all the code, which we usually don't.
01:06:59.726 - 01:08:07.910, Speaker B: Because often you can call arbitrary contracts. It's usually not a whitelist that you can only call these. And that's why it's often good to model it in a more abstract sense, like make an abstract model of the system as interacting objects and so on, and try to work it out from there. And that's, I mean, definitely, if you come from physics or something, then for complex adaptive systems, then I think that's a great exercise. But then it's also interesting, how do you bridge that gap? Because oftentimes you do verification at a protocol level or a systems level. And what I do is usually I do verification at the code level, and there's definitely room for error in the gap between those, where you have some implicit assumptions in your big model, and those are slightly different in the code verification, and that can be violated. But basically, if you're expressing your system in mathematical terms and doing some reasoning and proving things about your system, you're doing formal verification.
01:08:07.910 - 01:08:41.220, Speaker B: That's just the description of the action. And whether it's useful or not depends entirely what you're doing. Just like in math, there are absolutely, you can do things that are not very meaningful, or you can do things that are really important. You can calculate the triangular theorems in graphs that don't really have a strong application, or you can calculate the stability of bridges and security of financial systems and so on.
01:08:42.150 - 01:09:55.238, Speaker C: Actually, curiously, I have very similar question to what Max asked, just from another standpoint, but about exactly the same problem. I mean, when you started talk about formal verification as essentially mathematical modeling. I think humanity has very long experience of mathematical modeling, and especially in area of physics. And in physics, we quickly realize, well, in any physics, like one of examples, I was thinking about gas dynamics, for example, or thermodynamics, as Mark said, it's the same. So you can in theory, solve dynamic equations for every molecular in air to essentially make statements about, absolutely perfectly valid statements about the air around you. But that will be first absolutely understandable by a human who think about that. And secondly, it will be absolutely useless.
01:09:55.238 - 01:10:44.860, Speaker C: Or you can say that it's like 25 degrees celsius in this room, and it will be like very simple statistic property, which first makes sense and relatively easy measured and computed. So my point was exactly the same, but from human point of view. So if you make a validation of very complex software models, they became useless. It's very easy to make a mistake. It's not important how smart is a particular person. It just means that the complexity have to be a little bit bigger and the brain will break. Our brain is not that powerful technology.
01:10:44.860 - 01:11:12.078, Speaker C: So we have simplify. The trick here is, are there ways to not model, or not even precisely model, but quite the opposite to model in a way which avoids they need to understand every behavioral aspect of the program, but still be useful.
01:11:12.254 - 01:11:54.946, Speaker B: Yeah, absolutely. If you're doing protocol verification, that's often what you're doing. You just have actors that way. That's more a more discrete deterministic thing. But again, I'm not coming from the realm of physics. And if you get a committee together and decide to work out a theory of thermodynamics for these kinds of systems, and a way to model your smart contract platform where you can look for these kinds of properties, that would be really cool. Again, it's not my area of expertise, so I'm not 100% sure what the use cases would be.
01:11:54.946 - 01:12:48.274, Speaker B: I can imagine something like, okay, that would be great. Value isn't destroyed anywhere, for example, or even if it moves around in interesting and complex ways, it doesn't go up in smoke or so on. But all I can say to that, it sounds really cool. It sounds really cool, and I hope you do it and get back to me when you do. But I also want to counter your point on saying, like, oh, if you're trying to verify a system that's super complex, then the brain is going to explode because it's so big and it's so hard. I mean, that can be true, but verification, one of the powers of verification is that you can have very complex systems that do a lot of tricky stuff, and it's very hard to prove that they're right. But the statement of correctness can still be quite simple.
01:12:48.274 - 01:14:01.740, Speaker B: Like a famous example is the four color theorem. So, basically, the idea that any world map, or any possible world map can be colored in using only four colors without having adjacent countries having the same color, I mean, that's a layman's statement. The proof is immensely complex, super complex, and it's been verified with proof assistance. But the thing is, the statement is pretty straightforward, and I absolutely, 100% believe the four color theorem, not because I can understand the proof, but because I can understand at least somewhat the proof checker. And someone says, I have a long string that represents a proof. We pass that through a very simple kernel that is a proof checker that only does some very simple logic and won't allow you to do anything like obviously bad. And it's going to say in the end, oh, yeah, I've seen, you've actually derived this simple thing.
01:14:01.740 - 01:15:19.220, Speaker B: This is something that you have a simple statement, and I can attest to that this complex body that is the proof actually proves this theorem. And now we're mean, and your head doesn't have to explode around a theorem, even though the proof, of course, took a huge amount of people and a lot of years to work out. And I think that's one of the powers of verification, because we often talk about how the number of bugs in code scale with the number of lines of code. And I'd say that the more complex your theorem statements are, the easier it is to make a mistake. If you have a lot of complex assumptions and complex encodings of state, then it's going to be easy for you to make a mistake. But oftentimes your theorem statement can be quite small, and the process of verification is often taking these more complex statements, like for example, we did here with the transfer function. The statement, the transfer function doesn't violate the laws of thermodynamics, like the amount of tokens stays constant, or shrinks, or whichever one we choose.
01:15:19.220 - 01:16:08.740, Speaker B: That's a simpler statement than saying every variable that is used somewhere in the body of the program has these properties at the input and output. I'd say the second statement of the problem leaves more room for error, but you can use that to then prove the bigger theorem. And I mean, that's pretty common in mathematics. If you're doing group theory, like Lagrange's theorem is really, really easy to state and prove. You can do it in a tweet, but you have to create this more complex body of other things first. But then the actual statement and the proof are pretty simple. And I think that's one of the really cool things about verification, is that you can kind of get this very high assurance because you have a very, very small statement and you have, I'd say, absolute assurance that your statement is true.
01:16:08.740 - 01:16:11.218, Speaker B: So.
01:16:11.304 - 01:16:12.450, Speaker C: Yeah, but that's.
01:16:14.950 - 01:16:27.560, Speaker B: Yeah, but in practice, especially with smart contracts, you often end up saying like, you know, well, this is true given these, and these assumptions, because obviously it's a software system and it can be hard to encode these assumptions in an intuitive way.
01:16:29.710 - 01:17:54.670, Speaker C: That sounds natural. Yeah, so I guess we actually already like 20 minutes before our land deadline. However, I guess we have very interesting discussion. I personally truly enjoyed it and like the ideas which we discussed here. So I want to say thanks a lot to you, Ricard, to Max for joining this. So maybe we can continue discussing these manners matters in some other format, because it seems to be very deep and very strange, but it's very practical in a sense, because what we do, we all write a complex system and we regularly and routinely verify them. So probably discussing it from more like distant point of view may be very enlightening for any software engineer.
01:17:54.670 - 01:17:56.694, Speaker C: Thanks a lot.
01:17:56.892 - 01:17:57.874, Speaker A: Thank you, Nicola.
01:17:57.922 - 01:18:02.870, Speaker B: Thank you, Richard, thank you so much. It was fun, right?
01:18:03.020 - 01:18:04.770, Speaker A: Sam, thanks a lot for listening.

00:00:00.330 - 00:00:30.738, Speaker A: You. Awesome. So we've had already a few spaces about phase two and kind of protocol roadmap. So I'll just quickly recap. Near protocol had a kind of multi phase approach to rolling out. We had phase zero main net in 2020 which launched with one shard. We had phase phase one launched in 22 that resharded to four shards.
00:00:30.738 - 00:01:31.610, Speaker A: And we having phase two happening kind of within next few months with testing to really introduce stateless validation and in return allow to have more shards in the network, have most validators, have lower hardware requirements and increase throughput of each individual shard as well. By putting state into memory, we can dive in into some of the technical parts, but maybe good to give some context because obviously Bowen and Dennis participated in stakeholders before. Kind of what has been the purpose of stakeholders so far? Kind of why is it really important to have such events and how they help us really build robust network?
00:01:33.230 - 00:02:16.934, Speaker B: Yeah, I can start. I think I've been through all the stakeholders. Great. Yeah, sorry, I can start. I've been through all the stakeholders that we've ever hosted. I still remember the very first iteration where that was before Mainnet and we were kind of trying to start a testnet together with a community, and on the first day it didn't go very well because there were like 40 people trying to start the network together and it didn't work for a variety of reasons. And we've come a very long way since then.
00:02:16.934 - 00:03:55.478, Speaker B: So historically the stakeholders mostly have been focused on getting more people into the validator community as well as testing the major releases of Nier, mostly for sharding. So had one before mainnet launch, and then after Mainnet launch we had stakeholders for the introduction of chunk only producers as well, which also expanded the validator set. But this time it's a bit different with the new upgrade on the horizon, which would also complete phase two of sharding, making near fully sharded blockchain post in terms of state and transaction processing, which is very exciting for the state force itself. It's mostly focused on testing the implementation and maybe less so on the validator side. So we still have validators going to invite validators to join the testing network and run its validators, see how the network performs and also the adjustment to hardware requirements and things like this. But the primary focus is on sending a lot of transactions to see how the new design, the new implementation works under the load and also with the in memory like moving staining memory. We should also see performance improvements as a result of that.
00:03:55.478 - 00:06:45.790, Speaker B: So should be able to handle more transactions as a result, and that would also be part of the program and what we want to test. So yeah, I want to pass on to Dennis to talk about it from his yep, we can hear. Yeah, Dennis is exactly right about the audience. I think historically staples have been focused on validators or potential validators who want to get into the community and become validator on near. But this time, as Stanis pointed out, it's a bit different because we're primarily focusing on more of the testing of the new implementation itself through sending a lot of transactions. That's why we named it the attack of transactions. So you don't have to be a validator to train or you don't even have to want to run a validator node to join the network.
00:06:45.790 - 00:07:48.180, Speaker B: As long as you're interested in near development or just want to see the sharding pan out and actually getting implemented in practice and see the improvement of throughput of near, then yeah, it will be a great opportunity for you to join the program and send transactions to test network. And I actually think it's probably for this type of activity. Smart contract developer would be great for the program because with any kind of testing we want to have more variety there. So we wanted to see people sending a variety of transaction loads to help us uncover maybe issues that we have not seen ourselves or some bug in the code or things like this.
00:07:51.190 - 00:09:01.000, Speaker A: All right, so to summarize, we have the new network called Statelessnet that is up and running that you can either join as a validator and provide kind of more validator power, test out, learn how to run a validator in the new environment, or you can deploy smart contract and engage it with a lot of transactions. Try some regular things like sending fungible tokens or minting nfts or any other use case that you want to do and really try to squeeze out all the power that this new network will be providing when it goes on Mainnet. So I think you can go to near slash stakewars. It redirects you to GitHub, which describes kind of different ways to participate and how to.
00:09:04.570 - 00:10:28.130, Speaker B: Yeah, I can talk a bit more about the details of the program given that we were just talking about the high levels before and the target audience, as in I'm pretty sure there are people in the audience right now want to know more about the details of the program. So right now it's divided into two stage. So the program is designed to run for two months, from the beginning of February to the end of March and it's dividing into two stages. The first stage is basically the entirety of February, and the second stage is the entirety of March. So in the first stage it's mostly both for us to kind of set up the network and making sure it's operational and also seeing the issues by just running the network itself, and also for people to come in and poke around in the network and play with it to see what kind of issues or bugs they can find. And during this stage, the activities that would be eligible for reward is to submit bug bounty reports, sorry, to submit bug reports on GitHub. And that would greatly help us making sure that our implementation is secure and stable.
00:10:28.130 - 00:11:14.580, Speaker B: And then in the second stage that starts in March, we'll have both the external validators joining this testing network along with us, and also rewarding people for actually sending a ton of transactions and how exactly we would calculate for the transaction. Reward is detailed on the reward section of the program. On GitHub you can take a look. And yeah, as I said again, the focus will be on trying to find problems by playing around with network sending transactions to uncover issues that we have not previously seen.
00:11:19.760 - 00:11:41.270, Speaker A: Cool. So if you have any questions about that, you can ask them a bit later, but now maybe let's switch gears and talk about the changes this introduces to validators and how we expect this affects chunk producers as well as validators and shift of the role in phase two.
00:11:42.760 - 00:12:43.944, Speaker B: Yeah, so I can definitely talk a bit more about that. As a result of this big change status validation, arguably the largest change in the design and the implementation since we launched Mainnet, we're reimagining the role of validators. So previously, currently we have block producers on the network. There are 100 of them that are responsible for producing blocks and actually they track all the shards today. And then we have chunk only producers that supposed to produce chunk for a specific shard. So there are a maximum of 300 of them on the network today, but in practice it's not fully utilized. So in the new setup, the roles are, I would say a bit switched around.
00:12:43.944 - 00:14:17.060, Speaker B: So there is the trunk proposers, or like you can call them trunk producers. Well, but I call them trunk proposers just to avoid the confusion in the naming, which the chunk only producer we have today. So the chunk proposers are the type of validators who would operate more expensive hardware. They will still track one shard, but they will be responsible for producing the chunks for that shard, applying the chunk including transactions and receipts, and then generate the state witness required for other validators to execute the chunk. And then the reason why they would require more expensive hardware is that in the design, they actually hold the entire state in memory. And this is where we leverage the sharding design of near, so that the state of the entire network sharded into different shards, so that we can say the size of each shard is bounded by some constant, let's say hypothetically, 50gb, and then the validator, sorry, the Chunk proposer for the shard would just be able to load that entire state in memory, and this result would have to operate machine with more ram. And that's most of the change and potentially higher network bandwidth as well, due to the need to distribute state witnesses.
00:14:17.060 - 00:15:03.620, Speaker B: And then the other type is the status validators, whose job is to verify the state translation proposed by the Chunk proposers are correct. They do so by verifying the execution against the state witness provided by the Chunk proposers. And as a result, they will not need to run as expensive hardware as people do today, mostly on the side of ssds, and the requirement on that should be dramatically reduced. So that's kind of the overview of this change. And yeah, I guess I'll pass it to Dennis to talk about this from his perspective.
00:15:07.940 - 00:16:08.790, Speaker C: Again. Yeah, well, totally excited about see that new technology coming along. And of course, from being a validator, we do not really care much about how expensive hardware we can run. It means so long. We can secure the network we provide with required hardware. But saying that if you are aiming for thousands and thousands of validators, this is of course becoming crucial point where a validator can run from raspberry PI or from home pc or something. When the validator becomes a point where it doesn't have to be like 100% uptime, where you can bring it on and off, then yes, of course the hardware becomes really relevant and you really need to look at making it more affordable to run for ordinary people.
00:16:08.790 - 00:16:38.450, Speaker C: With the technologies out there, with the scripting and everything, anybody can install the validator in no time. But right now, with a limited set, I don't think it's very important from validated point of view to run on cheap hardware. We do not mind to run on the most expensive hardware. Also, I think there will be some questions in terms of a problem itself. Probably leave it till later.
00:16:41.060 - 00:16:58.804, Speaker B: Yeah, I think Dennis mentioned a good point about the decentralization of the network. Indeed, with this change, there is kind of like a bigger maybe shift in how the validators are or how we think about the validator set.
00:16:58.842 - 00:16:58.996, Speaker A: Right.
00:16:59.018 - 00:18:37.952, Speaker B: So before it's basically every validator is essentially equal to another validator in terms of their role in the network. But now with the status validation change, there is this asymmetry introduced. So there is this chunk proposers, essentially a few of them in the network, that would operate more expensive hardware and responsible for producing the chunks and the state witness as well. But then there's ideally a lot of the stimulus validators who can potentially operate on cheap hardware, on cheaper hardware, and they would be responsible for verifying the state transition proposed by the Chunk proposers. And the important thing here is that the chunk proposers, while there are a few of them, and they operate more expensive hardware, they actually will not be able to do anything malicious because security of the network is dependent on those stateless validators actually validating the state transition using the state witness. And as a result, I think this is a good trade off to accept. And it's not only providing more potential for decentralization of the network, but also it's more future proof, right? As we can see that zero knowledge technology is maturing very rapidly today, and we expect that maybe in the next few years we will be able to see an actual integration of zero knowledge proofs into layer one protocols.
00:18:37.952 - 00:18:58.860, Speaker B: At that point the stereos validation architecture can mostly remain the same, except that instead of validating a chunk against the state witness, they can validate just 10 knowledge proof and make sure that the chunk that they verify is valid.
00:19:01.500 - 00:20:50.350, Speaker A: Yeah, so maybe to add and contrast this to other solutions that we see, we have ethereum with roll ups where each roll up runs a sequencer and then they settle on some data availability. They put the kind of transaction to data availability and then after that settle execution on Ethereum. In a way, the chunk proposers are decentralized sequencers. There is multiple of them per each shard, making sure you have your robust from halts of any individual kind of chunk producer. You have the data availability integrated directly into the protocol after they produce chunks, and then you have the kind of validations element done with stateless validation in a way making it a realistic roll ups. So you have kind of very similar design space, right? I mean there's other blockchains like Polkadot that are also using similar, but with kind of usual near focus on how do we make the user experience as straightforward as chain abstracted as possible. The idea here is to minimize, to not have any changes to how users or developers are interacting with this, while being able to add both performance throughput and also being able to add more validators to the network as requirements get lower.
00:20:50.350 - 00:22:05.350, Speaker A: I think also Dennis mentioned a very interesting thought, that as we have more of these validators, which now can validate any shard because they don't need to have the state of that shard, we can potentially also reduce requirements for their online uptime. And in turn, we can have more validators who are kind of more providing security to the network, but at the same time are not online all the time, and so can have kind of a longer tail of home validators or folks who are just running potentially on their desktop that doesn't work, that's not online from time to time. I think that's all kind of in further iterations of this, but this definitely design is kind of pushing in that direction to make it larger network with more validators who kind of can plug in and plug out without needing to maintain the state of the chain, which is a current design.
00:22:09.480 - 00:23:08.340, Speaker B: Yeah, it's definitely something we can explore further in the future. And indeed, with the decay becoming more mature, there's a question of how much stake we actually need to secure a network. Because at a point, the fundamental security model of the proof of stake blockchain becomes also an interesting point of discussion because everyone, a browser, can verify the validity of the blockchain and maybe at some point we don't need necessarily them to be recognized on the protocol level. It's also about, in a way, consensus, or like social consensus outside of the protocol itself that can be achieved through wide adoption of zero knowledge crews. Yeah, there's a lot of interesting stuff to be explored.
00:23:09.660 - 00:23:43.250, Speaker A: All right, so maybe switching gears again, I saw the question around what are the rewards for the program? So maybe you already mentioned about kind of the schedule and how it runs would be good. What do people expect from this? But also from Dennis perspective, if there are any comments or thoughts about the program, and then we can open up questions from the.
00:23:45.380 - 00:24:30.784, Speaker B: Again, like I would refer people to kind of the rewards section of the GitHub stakeholders. GitHub. And probably I should post it in the comment as well. But roughly the idea is that we're rewarding people for the issues that they find during the program. And obviously not every problem or every bug is equal. Like some are more critical than others. So there is kind of assessment on how critical the issues that people find is and also on how complete the report is.
00:24:30.784 - 00:25:31.140, Speaker B: And there are some multipliers that we assign to those things. And then there is this baseline reward of 115 year. So we multiply by the multiplier and then decide on how much reward we give to people. And then for the part of traffic generation or sending a lot of transactions to the network, it's also like a similar concept. So people would post a summary of the type of transactions that they're sending, and we would assess how important that type of traffic is or how novel it is and also see the impact on the network. And then there's a multiplier shift sign, and then there's baseline reward of 500 year. So we multiply them together and that would determine the final reward.
00:25:31.140 - 00:25:42.440, Speaker B: So, yeah, that's kind of the idea because it's somewhat complex. So I would say please refer to the actual document for more details.
00:25:45.100 - 00:25:52.510, Speaker A: Yeah. Posted as an answer here to near Ukraine guild tweets. But yeah, Dennis, go ahead.
00:25:53.920 - 00:26:41.816, Speaker C: Okay. Yes, that's a very interesting topic. And we know there is a lot of validators outside of near ecosystem who runs other chains who are really thrilled and would like to join near ecosystem because all of the validators are trying to expand their portfolio. And some of them never looked at near. Some of them had before. A lot more now, as I can see, a lot more looking at near. And right now, most of the questions, the top one question is how our stakeholders work and help them to join the main net validators.
00:26:41.816 - 00:27:21.910, Speaker C: I mean, rewards are words. They have a monetary value. But for validators, it's more important to have a seat on the main net where some foundation or some other NTC or someone else can provide with their minimum stake so they can start validating. So this basically leads to the question is the main net set is going to be expanded in the future or not? I think this is top number one question I have been seeing talking to other validators in other networks about sake was.
00:27:25.260 - 00:27:26.170, Speaker B: Go ahead.
00:27:26.700 - 00:27:46.956, Speaker C: Yeah. And another question is basically more technical. I don't know if people would like to hear that. It's just basically about the transactions and stuff. So I know there are ways to send a lot of transactions from one single machine. There's also ways to send it from via sources. But the question is really, so you're interested in volume.
00:27:46.956 - 00:28:10.980, Speaker C: So let's say one single machine, or it's going to have to be like volume from all around the world. It's all different kind of fish in terms of complexity of setting up this kind of setup. So if you need just one or two or five machines to send a transaction with one thing, if you need like 100 or 1000 machines, send your traffic. That's another kind of fish.
00:28:12.540 - 00:29:03.044, Speaker B: Yeah, I think both questions are very interesting. So for the first question about the validator set and how to become validator on near. So I mean, yes, definitely as we get to more charts, there is potential to have more validators on the network. But what I will say is that today we're nowhere near utilizing the full capacity or full capacity of the vast data set right now. So I just checked, we have 211 validators on main net today, and I think the maximum is 400. So definitely there's room to have more validators there even without changing anything. So that's still like quite a few validators.
00:29:03.044 - 00:29:44.070, Speaker B: If they want to join the network, they can. And I think the minimum threshold to become validator today is about 25,000 year. I think it's obviously subjective on whether that's high or low. But yeah, I'm not sure about the incentivization program to delegate stake for newcomers. I don't think near foundation plan to operate anything like this in the near future, but maybe Irio can talk more about that part.
00:29:44.440 - 00:31:06.992, Speaker A: Well, I think in general, even at previous take wars, we try to, instead of near foundation being kind of this operator and delegator, which generally has a lot of criticism on itself, has kind of additional operational overhead, we prefer to use liquid staking providers and really work with them. The benefit of near liquid staking providers compared for example to ethereum is because of kind of highly programmable staking. They are not actually a centralizing power, but are decentralizing power. I think both linear and St near are staking across hundreds if not 200 validators. And so I would expect that as network continues to grow, we will see more and more stake shifting to liquid staking and they are supporting new validators as they come online. So I would work with the metapool and linear to kind of get your initial delegation from those pockets. And as far as I know, they have brought in new validators on board recently, kind of through shifting some of their delegations to them.
00:31:06.992 - 00:31:39.480, Speaker A: I think maybe relevant question is right now there's a minimum of 20,000 near that's required to become a validator. And so if this change kind of will also lead to us reducing that limit, then maybe a good question to Bowen. But I agree that even right now there is available slots. So it's more about working with this liquid staking providers to get some of the initial delegation to hit that 20,000 limit.
00:31:40.800 - 00:32:37.576, Speaker B: Yeah, I think definitely that limit could be reduced, but I mean it is going to be a relatively involved protocol change. So for context, that limit was introduced so that the probability of any validator today not producing any chunk in an epoch would be extremely low. So essentially pretty much not going to happen in practice, because today every validator is going to produce some chunk or act as a chunk producer in some capacity. So they are expected to produce at least one chunk in an epoch, which is 43,000 blocks. And otherwise you will not get rewarded. But I mean, if you become a validator and not get reward and then get kicked out, that's definitely not ideal.
00:32:37.608 - 00:32:37.756, Speaker A: Right.
00:32:37.778 - 00:33:45.290, Speaker B: So that's why this minimum threshold was introduced. But indeed, with this shift, or with this change to status validation, that's no longer the case. The chunk production is taken care of by the Chunk proposers, and the status validators actually get rewarded by endorsing those chunks. And indeed, because of that, we no longer need this original threshold that's dependent on them producing one chunk during the entirety of an epoch. But again, as I said, conceptually, yes, we can get rid of the threshold, but in practice, changing this will be a relatively involved protocol change. So we do expect that we would need to take some time to make the change. Okay, I think we can talk about the second part of the question that Dennis was talking about.
00:33:45.290 - 00:33:52.108, Speaker B: Yeah, sorry, Denis, can you remind us the second question?
00:33:52.194 - 00:34:05.052, Speaker C: Yeah, sure. It's about the stage one where you want to see a lot of. Really? How do you want to see them? I know it's only in the document, but just to clarification what is in the document?
00:34:05.116 - 00:34:28.768, Speaker B: Yeah, I don't think this question you ask is actually in the docs. So. Yes, great question. I don't think we particularly care about where exactly people send a transaction from. That's less important. Whether you send it from one machine or send it from a lot of different machines, I think it's more about the nature of the transactions. Right.
00:34:28.768 - 00:34:41.784, Speaker B: So what type of transaction are they? Are they transfers or cost to smart contracts? If they are cost to a smart contract, what kind of smart contract are they calling? And things like this. And also the volume obviously matters.
00:34:41.832 - 00:34:41.996, Speaker A: Right.
00:34:42.018 - 00:34:52.830, Speaker B: So if you send one transaction a day, probably doesn't really help. But where exactly those transactions come from in terms of geographic locations, we don't really care.
00:34:56.550 - 00:35:48.694, Speaker A: I would add that I'm assuming we want to see both. We want some people who will spin up, quote unquote bot network that will try to overwhelm it from the globe. And then it's interesting to see also just kind of massive traffic from single servers, because we actually see both of these traffic patterns right now in real applications. Right. We have metatransaction relayers who are routing traffic from a single server or from a single small cluster of servers. They're using hundreds of keys to send non intersecting transactions. And we also have many of the noncustodial users transacting from their wallets kind of across the globe and doing that as well.
00:35:48.694 - 00:36:26.500, Speaker A: So we kind of see both of these traffic patterns, and I would be interesting to see them in testing as well at high capacity, and seeing how network performs with both of those use cases, and especially making sure that between nonsense, kind of RPC routing, all of these pieces are working in unison. If anyone interested in investigating that, that's like an area where I'm sure there's something to be found and reported as a team. For extra Barry points.
00:36:28.230 - 00:36:59.790, Speaker C: Okay, thank you, Jan. So I would suggest all the contestants to get to know your ecosystem better. Read the documentation, understand the smart contracts, and try all of the different transactions types. Create, deploy smart contract, delete smart contract, execute smart contract methods, make, swap, use, ref, finance, test if there is already available or not for doing some complex transactions, and so be a winner.
00:37:06.530 - 00:37:12.810, Speaker B: Yeah, sounds good. Thanks, Dennis. Should we move to questions from the audience?

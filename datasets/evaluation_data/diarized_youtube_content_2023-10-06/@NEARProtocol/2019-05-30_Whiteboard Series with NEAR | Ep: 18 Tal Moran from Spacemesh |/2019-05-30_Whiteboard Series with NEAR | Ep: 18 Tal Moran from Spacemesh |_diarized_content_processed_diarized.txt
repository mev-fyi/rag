00:00:04.490 - 00:00:05.038, Speaker A: Hi, everyone.
00:00:05.124 - 00:00:19.578, Speaker B: This is Alex from Nier. With me today is Professor Tal Moran from Space Mesh. And we will talk today about the protocol. We'll go into a lot of technical details. So, Tal, would you like to introduce yourself and give a very brief overview of the protocol?
00:00:19.754 - 00:00:52.220, Speaker A: Yes, sure. Hi, everyone. I'm Tal. I'm a professor at IDC Eltilia in Israel. And my area of research is, not surprisingly, cryptography. So I've been working on cryptographic protocols for a pretty long time. And a few years ago I got interested in blockchain and actually discovered this amazing Satoshi Nakamoto blockchain protocol that solves these open problems in byzantine agreement by sort of sidestepping the issue.
00:00:52.220 - 00:01:36.762, Speaker A: And it's very interesting. Like, there's amazing stuff, but there are lots of big problems. So I started thinking about what we can do. How can we solve these big problems? And the main problems that I was trying to solve were, I guess one is scalability. So Nakamoto's blockchain protocol basically has this inherent scalability limit you can't get. It's not what it is right now. So that seven transactions per second is below the sort of inherent limit, but you cannot scale it as far as you'd like due to the way the protocol is built.
00:01:36.762 - 00:02:10.870, Speaker A: So want to try to deal with that. There's a problem of security and this actually comes in lots of different things, so I'll get a bit deeper into that later. There's a problem of energy costs, and specifically when we talk about proof of work, it's horrible, right? It's great in terms of, like, it's a nice idea. You can verify it. It has lots of good properties, but energy cost is not one of the good properties. And that's also inherent. You can't make it more efficient to get lower energy costs.
00:02:10.870 - 00:02:41.594, Speaker A: And not only is it bad for the environment, which is already quite a bad thing, it's also expensive. Right. The system has to support itself, which means the higher the cost of mining, the higher the transaction fees have to be. So these are all three things I want to talk about. And then there's the issue of fairness, which these are all sort of interconnected. And by fairness, there are several things here. I think maybe the thing that is the most annoying.
00:02:41.594 - 00:03:18.538, Speaker A: Right. If I want to join bitcoin now, I can't actually use my home computer to mine. It's just totally impractical and unprofitable. And it costs so much and I have to wait so long until I get. There's no way for me to join unless I'm willing to actually spend a lot of money. And there's this giant difference, orders of magnitude difference, in terms of how much it costs me to mine as sort of a small user versus how much it costs me to mine. If I had enough capital to buy an ASiC, if I can locate a factory in a country with low electricity costs and low cooling costs, things like that.
00:03:18.538 - 00:03:57.702, Speaker A: So these are the sort of issues that we're trying to deal with by redesigning the core protocol. So what are the things that space mesh does? Or maybe before we get to that, let me say one word about security. The whole point of a cryptocurrency is you don't have to trust any one entity. You don't have to trust the government. You don't have to trust some small committee of users that control the system. You need to trust something a lot more reasonable. Say there's an honest majority of users, or not, or, but.
00:03:57.702 - 00:04:43.126, Speaker A: And the math behind it is good. But when the system gets very complex, and all these systems are very complex, even bitcoin, which is, compared to most systems, very simple, it's still quite complex. It's very, very hard to be confident that the math behind it is good. So even if we forget about the implementation problems, which is a whole issue of itself, right? So even protocol, the math is good, the implementation could be bad, but just getting this assurance that we're running a protocol that works, that's not easy. And I think any modern cryptographer won't really trust a protocol unless it has a security proof. Now, security proof doesn't say, no, this protocol is secure. We don't know how to do that.
00:04:43.126 - 00:05:43.660, Speaker A: Unfortunately, what we do with a security proof is reduce this protocol, the security of the protocol, from something like, trust me, this is a good protocol, or, I've tried to break it and I can't, which is not a very confident, inspiring assertion to a small set of assumptions that ideally have been studied for a long time by very many people, and we can be much more confident. And then you get a statement of the form. If these assumptions are true, then mathematically we can prove that the whole protocol is secure, and it gets us these nice guarantees. And again, we have to say formally exactly what we mean. And I think in cryptocurrencies, at least personally, I would not trust any protocol that doesn't have this form of security proof, because history has taught us that when you design a system, even if you do have a proof, it might not be secure. But if you don't have one. It's almost invariably broken in some way.
00:05:43.660 - 00:06:47.306, Speaker A: Okay, so this is just an aside about security. What are the assumptions, actually that we need? So one assumption that we always need is this honest majority. So, in fact, if we want to get consensus when there is a malicious adversary, there is this mathematical proof from the 70s, basically, that we have to have an honest majority. And what they said in the 70s, we can prove that it's impossible without an honest majority. And this is why it seemed so impossible to get this type of cryptocurrency on the Internet where anybody can come up with as many identities as they want. And then we can never guarantee an honest majority on the Internet until Satoshi came up with this idea that now instead of saying the honest majority of users, we have an honest majority of resources. So I'm saying resources here and not CPU.
00:06:47.306 - 00:07:49.522, Speaker A: Toshi said CPU. But we can generalize this, and we always need some kind of resource to base the system on. And what space mesh does is it replaces this proof of work resource with what we call a proof of space time. What is a proof of space time? It's a proof that I stored some data on my disk. Basically, I used part of my disk space for a period of time. Slightly similarly to proof of work, I'm not doing anything useful with my disk space, right? I'm storing junk on it, but I can't use that part of the disk for anything else. And why is it space time? It's not enough to say that I have a disk with 1 because if I can reuse that disk every five minutes for something else, then I am sort of not bounded by how much resources I can use.
00:07:49.522 - 00:08:20.170, Speaker A: So the actual resource that costs me is how long I do things. And if you think about how we buy storage, right? Say you're buying storage from Amazon, you pay by disk space times how long you want it for. So this is what this proof of space time does. So that's one change that space mesh does. We want to replace proof of work with proof of space time. This has two effects. Well, it has more than two, but two important ones in terms of this one.
00:08:20.170 - 00:08:43.842, Speaker A: Okay, we got rid of the energy costs. Why? Because storing things on a disk doesn't cost energy. We can just keep the computer even turned off, and the disk just doesn't take up energy. Okay, this is, everything I'm going to say has this little caveat. Of course it doesn't go to zero. There are some energy costs you need to create the disks. You need to do other things.
00:08:43.842 - 00:09:33.294, Speaker A: And specifically, you also need to spend some energy initializing the storage. And this is in some ways inherent in this kind of proof, because if I want to prove to you that I stored something big, but at the same time I don't want to send you everything, right? I want to say, or I don't want to have to download this 1 somewhere on the Internet in order to get it, then I want to be able to generate myself. But if I can generate it myself and fill the disk, what prevents me from generating it? Proving that I have it and then erasing it all. And next week when I need it again, I just regenerate it, right? So now I haven't used disk at all. I've just used work. And the whole point is we don't want people to use work. So we want to make it a rational choice to actually keep things on your disk.
00:09:33.294 - 00:10:02.426, Speaker A: And in order to do that, we make it expensive to initialize. So basically you're doing an initial proof of work in order to initialize this disk space. And after that you just prove that you're still holding it. So in theory you could always just erase it and then redo the initialization. But that costs you the proof of work money. Right. So it's expensive to do that and it's going to be much cheaper to store it for the period of time we're asking you to store it for.
00:10:02.426 - 00:10:17.326, Speaker A: So basically there is some initial energy costs, but if you amortize it over the time you're going to be using this storage, then it's sort of arbitrarily close to zero. Okay, so this is said. One thing gets rid of energy costs. The second thing is, for how long.
00:10:17.348 - 00:10:19.138, Speaker B: Do you usually store something on the deal?
00:10:19.224 - 00:10:40.250, Speaker A: So again, the final parameters aren't completely fixed. There are like a lot of knobs that you can tune. And part of what we're going to be doing in testnet is fixing these parameters. The current parameter is set to something like two weeks. Yeah. So every two weeks you're going to have to prove that you're still storing this data. So this also has to do with fairness.
00:10:40.250 - 00:11:32.550, Speaker A: Why? Because first of all, there aren't these orders of magnitude differences in costs between discs that I buy as a consumer and discs that say somebody who has a lot of capital can buy. It's not to say that there aren't differences. Amazon can buy disks for a lot cheaper than I can buy, but it's not three orders of magnitude difference. But the main thing here is that if I already bought a disk. And a lot of people have reasonably powerful computers. They come with two terabyte, four terabyte disks and they use very little of it. So if I already bought the disk for a different purpose and I have it at home and there's two terabytes sitting unused, the marginal cost for me to fill up this two terabytes is actually much less than Amazon's cost to buy a new disk.
00:11:32.550 - 00:12:17.234, Speaker A: So if I'm doing something trying to mine at scale, then my cost is going to be the cost of disks. And as a home user it's going to be harder for me to compete with that. But if I'm a small user and I just want to use my leftover space, then Amazon can't compete with me because my marginal cost is basically zero. And basically what we are hoping this has is the effect of generating a very long tail of users. So instead of having this problem where once big parties, big players come in, then the small players are pushed out, they're priced out because they can't compete anymore. We can have big players and small players coexisting. So it's a fair distribution.
00:12:17.234 - 00:13:05.554, Speaker A: We can have this sort of long tail and ideally we'd have some big players, but many, many small players, so that the sum of the space contributed by small players is actually in the majority. Right. This is ideal. We're not completely sure that this will work out, but the protocol obviously doesn't care about how the distribution looks as long as it's sort of distributed enough. Now why do we care that it's distributed enough? Let's go to the honest majority assumption. So our assumption, instead of assuming there's an honest majority of cpu space, of cpu power, we're assuming that the majority of the space, the disk space, is controlled by honest parties. And having this long tail makes this a lot more reasonable.
00:13:05.554 - 00:13:29.870, Speaker A: Right? If you have only five parties controlling 60% of the resources, then it's a bit iffy to say, yeah, we absolutely trust our trillion dollar economy on the fact that there aren't three of them that are colluding to do something bad. But if you have 800,000 people controlling this, it seems a lot more reasonable.
00:13:30.850 - 00:13:32.062, Speaker B: But quick question here.
00:13:32.116 - 00:13:32.720, Speaker A: Right.
00:13:34.950 - 00:13:48.070, Speaker B: So quick question here. So let's say I'm honest participant, right? So realistically I will be contributing something on the order of 1. That's the upper bound of how much? Probably not, maybe less.
00:13:48.140 - 00:13:48.566, Speaker A: Yeah.
00:13:48.668 - 00:14:07.162, Speaker B: Right. So ethereum today, for example, has 15,000 full nodes, not just mining nodes, but it's like everybody who has a fully synced state, right? So let's say space mesh has the same order of magnitude. That means that the malicious actor needs to have on the order of 15 petabytes, right, of space.
00:14:07.216 - 00:14:49.500, Speaker A: So we're hoping actually for an order or two of magnitude more miners than that. And I think part of the reason a full node is something that's sort of not really rewarded, right? If you're not mining, it's like you're contributing things to the network. It's already amazing that you have that many full nodes and not that many miners, right. That people actually like to contribute here. But in our case, it's actually going to be a lot easier to get in as a minor. And I think this sort of low barrier to entry is a big difference between us and other systems, which means I think we have a chance of getting this very large number of miners and actually distributing it in a more fair way. Cool.
00:14:49.500 - 00:15:36.118, Speaker A: Okay, so we talked about fairness. I'm not going to cross it out. We actually get fairness. The other thing that connects fairness to security is something we call incentive compatibility, which is, is it actually rational to follow the protocol instructions? Right. When the protocol says do this, is it in your best interest to actually do that? And why is this very important? Because when we say we have an honest majority, that's an assumption. But what we're saying is people behave honestly. But if it's actually better, like personally, for me to behave dishonestly, I get more money by doing something bad.
00:15:36.118 - 00:16:23.510, Speaker A: Is it reasonable to assume that actually a majority of the people will behave honestly? And I think in the cryptocurrency system, it's not very reasonable. It's much more reasonable to assume that people behave rationally, though everybody will do something that's in their best interest. And so what you want to prove for this type of protocol is that doing whatever is in your best interest actually is the honest protocol. You don't lose by following the honest protocol, or at least maybe you lose a tiny bit, but you won't feel like you're being taken advantage of by being honest here. And this is a problem. So like bitcoin, for example, is provably not incentive compatible. If you say withhold blocks, then you are helping yourself.
00:16:23.510 - 00:17:09.110, Speaker A: There's actually papers out showing this specific attack of how you can do it. Like what's the best strategy? And it turns out it's a better strategy than just publishing the block when you get it. But if everybody actually followed this best for themselves strategy of withholding the block, and only publishing, once they see somebody else's published things like that, then the security of the whole system just breaks. So first of all, even though there is this attack on bitcoin, we don't see people doing it. So there are sort of other orders of magnitude of play. Maybe people think that if they attack the system this way, they might get more in the near term, but then the whole bitcoin thing will crash and they won't get. So there are other factors.
00:17:10.010 - 00:17:14.070, Speaker B: But also, don't you need 25% of the hash power to execute it?
00:17:14.140 - 00:17:51.010, Speaker A: Yes, but some pools have this amount, right. In theory there are entities that could launch these attacks, and right now they're not. But do you want to trust your system to sort of the goodwill of the people? It's not completely clear. It is much, much better if you can actually prove that it's incentive compatible. So one of the things we want to do is show that our system is incentive compatible. So these are one of the sort of guiding motivations when developing space mesh. Okay, so now maybe we'll dive in a little bit into the core of the protocol.
00:17:51.010 - 00:18:34.850, Speaker A: So we said one change we made was we replaced proof of work with proof of spacetime. The other big change we made is we replaced chain with a mesh. What do we mean by a mesh? A layered dag. So instead of having one block every, on average, ten minutes, we now have many, many blocks. So we think something like 200. Again, these are final parameters can be tuned, but this is the current thing we're working on for testnet. So we have many blocks and each of these blocks in say, layer ten, this would be layer eleven.
00:18:34.850 - 00:19:13.630, Speaker A: Point to the blocks in the previous layers. Okay. We have many blocks per layer. In order to guarantee this fairness and incentive compatibility, what we want is for these blocks to be in some sense symmetric. So there's no one special block that is the leader and we use that block, but there's a set of blocks, all the honest blocks. If you're supposed to generate a block in layer eleven, then your block will get in. It will definitely get in if you're behaving honestly.
00:19:13.630 - 00:19:31.150, Speaker A: Which means that all these attacks on incentive compatibility, where I'm trying to prevent you from doing things in order to get me to something better, they stop working because basically you prove you cannot prevent me from doing anything. And also, if you behave honestly, you'll get your reward.
00:19:31.230 - 00:19:46.214, Speaker B: But without knowing the protocol yet. Right. But it feels like some sort of attacks where everybody in layer eleven somehow manages to agree to ignore this block. Because that means the total reward distributed will be lower.
00:19:46.412 - 00:20:06.478, Speaker A: Okay, that's a good point. So again, we're assuming an honest majority. So, the honest majority assumption means that here we have a majority of blocks that are going to agree to vote for this. So whenever there's an honest block, the majority of the blocks in the next layer will still vote for this.
00:20:06.644 - 00:20:14.194, Speaker B: But will the producer of this block lose anything if everybody else voted for this block? But they did not?
00:20:14.312 - 00:20:15.026, Speaker A: No.
00:20:15.208 - 00:20:21.794, Speaker B: Right. So for them specifically, it is a rational behavior to vote for fewer blocks, right?
00:20:21.912 - 00:20:54.922, Speaker A: No, they don't gain anything by doing it. Right. Okay, so what we get in terms of the formal guarantee is something that we call an epsilon Nash equilibrium. It's a little bit stronger than that, because in a regular Nash equilibrium, it holds that if everybody else is honest, the best thing for you to do is to behave honestly, too. And by Epsilon Nash, we mean the best thing. But you might lose, like, some tiny epsilon. Okay, so what we get is something stronger.
00:20:54.922 - 00:21:28.030, Speaker A: If a majority is honest, we don't need everybody to be honest. Even if there's like a third of the network that's behaving maliciously, not just rationally, but completely trying to do bad things, it's still worthwhile for you up to this epsilon to do the right thing. And the idea is this epsilon is small enough that, for instance, the costs of writing your own code, to behave maliciously, is just not worth it. And so then it becomes reasonable to actually assume that there's an honest majority and the sort of self perpetuates.
00:21:28.130 - 00:22:00.654, Speaker B: But then the question is, let's say there is somebody who is sufficiently powerful to have. So I guess as an honest participant, I'm not creating block at every layer, right? But let's say I'm sufficiently powerful to have multiple layers in a row, just like layer ten, 1112. Will it not be ideal for me, after generating the block for layer ten, shut down my network to save resources and just create block in eleven and twelve that only approves my block in the previous layers.
00:22:00.702 - 00:22:05.182, Speaker A: Does that make sense? So you're saying to get network resources.
00:22:05.246 - 00:22:09.938, Speaker B: Right, because network still costs money. Right. And I need to store those blocks locally.
00:22:10.034 - 00:22:47.810, Speaker A: So I don't know if it matters that much, because blocks ten, 1112, are five minutes apart, our current parameters. So if you have several layers. Okay, you keep your computer on for another five minutes. I'm not sure it's part of the epsilon. Yeah, obviously, we're not going to be covering every type of slight denial of service attack, because you just cannot. There are some things that, again, they go into this epsilon, you can gain, like, a tiny bit more. If you do things that, if you consider the fact they're full nodes that don't get any reward right now and still contribute, then it seems reasonable that this won't happen too often.
00:22:47.810 - 00:23:04.182, Speaker A: And as long as this bad behavior is limited to, say, one third of the space, then our proof says that we'll still get consensus and we'll get liveness and everything will be good. Cool.
00:23:04.316 - 00:23:06.434, Speaker B: So, shall we dive into the consensus?
00:23:06.562 - 00:23:40.930, Speaker A: Dive into consensus. So, first, before we get into consensus, what exactly are we trying to get consensus on, and what are the challenges? So when we have this kind of mesh, what we're assuming is, in terms of what the adversary can do, we're trying to overestimate the adversary. We're trying to say we're going to prove that even when. So, super powerful adversary. And by super powerful, I don't mean in terms of the fraction of the network, but in terms of what its capabilities are, like controlling the timing of the network. Right. This is one of the most difficult things to overcome.
00:23:40.930 - 00:24:44.886, Speaker A: So even with this kind of a very powerful adversary, we still are going to get our good properties, consensus and liveness. And the main thing that the adversary does to attack is it can basically decide on the order and timing of messages that the honest parties see, so it's not completely unrestricted. Otherwise nothing would work. We were assuming, in terms of our network communication assumption, that honest parties will always, they're all connected to the same gossip network and say, within 30 seconds, anything that I see on the network, every other honest party will see. Or if I send something on the network, any other party or every other honest party will see it within 30 seconds. But if you sent something, and I sent something, or maybe I sent two different messages, then the adversary can make sure you get one, and then maybe you'll get the other one only 30 seconds later. And maybe some other honest party will get the second message first and the first message 30 seconds after that.
00:24:44.886 - 00:25:45.014, Speaker A: So you see things in a very different order, which means one of our guiding principles is we don't want to use the timing of messages in order to rely on that to get consensus, because we don't agree on it. And even more than that, we don't want to have to sort of record the time in order to decide what's in consensus and what isn't, because this is not something I can prove. I want this really nice property that bitcoin and also ethereum have that if I wake up, say, the sleeping beauty wakes up after 100 years, and now somebody says, this is the state of the block mesh, she can decide. If somebody gives her a different state of the block mesh, she can decide which one is right without having to trust them that I was there. I saw that this came before that, because that's not something you can prove. So the actual consensus state depends only on the messages I receive, not on their order. So what do I need to decide? I need to decide for each of these layers.
00:25:45.014 - 00:26:01.450, Speaker A: So each layer has a number. So this is layer ten. This is layer eleven. This would be layer twelve. And in each layer there are many blocks, on average, say 200. And each block says which layer it's in. So this block says it's in layer eleven.
00:26:01.450 - 00:26:21.730, Speaker A: This block says it's in layer ten. It could be, in terms of time, that honest parties will always transmit blocks on time. So when I say maybe one thing that's a bit different here, our layers are five minutes apart. Exactly. It's not a probabilistic thing. So every five minutes there's a layer at 10:00 there's a layer at ten. Five, there's a layer.
00:26:21.730 - 00:26:58.770, Speaker A: So the layer number actually corresponds to an actual real time. Okay, so I say this block is at layer ten. What happens if I publish a block over here? But I claim it's at layer ten. So this should not be something that's accepted, right? Because if this actually was in layer ten, then I'm changing history because I'm already at layer 13 at this point. So we need to decide which blocks are actually in the layer they claim to be in and which are not. So we call this the validity of the block. So for each layer, we need to decide these are the valid blocks.
00:26:58.770 - 00:27:18.946, Speaker A: And some blocks are invalid. So these are invalid blocks. And we always want to maintain the property that the honest blocks will always be agreed to be valid. For the malicious block. We don't actually care. So they could be valid. They could be invalid.
00:27:18.946 - 00:27:42.926, Speaker A: Basically, if you're doing something bad, maybe we'll invalidate you. If you behave honestly, you'll be valid. If you sort of behave somewhat in the middle, then maybe yes, maybe no. What we care about in this case is only that all honest parties actually agree. Okay, so how do we agree? And maybe one more thing about the challenge is. So we said if something is over here, it's sort of easy to see. Okay, this is definitely not supposed to be in.
00:27:42.926 - 00:28:09.846, Speaker A: Everybody agrees that it's not in. And this is sort of the easy case. And if something is exactly on time, again, it's an easy case. Everybody will agree that it's supposed to be in. What about if it's somewhere in the middle? So said that there's like this five minutes, right. Every five minutes there's a layer. What happens if the adversary on purpose sends a block that's here for twelve? Yeah, it sends a block for twelve that's here.
00:28:09.846 - 00:28:29.966, Speaker A: So it's between twelve and 13. And it makes sure that some honest parties sort of put it before the threshold and some honest parties put it after the threshold. So now honest parties won't agree exactly on where this block is. And this is the difficult case that we have to resolve. We have to still get consensus on it.
00:28:30.148 - 00:28:39.860, Speaker B: But the separate question, which I guess is on slightly different level, would that not require some trusted source of time?
00:28:40.470 - 00:29:12.554, Speaker A: No, it just require. Okay, I guess it depends what you mean. In some sense, yes. We require that all parties agree on the current time within some reasonable bounds. So when we said we assume that honest parties see each other's messages within 30 seconds, then this sort of includes in it the differences in clocks. So suppose we have a three second difference in our clocks still by your time, you transmitted something at ten. I should receive it before ten and 30 seconds according to my own clock.
00:29:12.554 - 00:29:14.542, Speaker A: So this three second thing goes in.
00:29:14.676 - 00:29:31.410, Speaker B: Right. But the argument is if space mesh becomes multitrillion dollar blockchain, it will be significantly cheaper to corrupt NTP servers than to corrupt. So adversary would just corrupt NTP server and make sure that the discrepancy in time is like 5 hours.
00:29:31.560 - 00:29:58.010, Speaker A: So that's not so easy. Right? You're right that in terms of implementation, the protocol has to sort of ensure that it's keeping time accurately and so the implementation can see that time has jumped by 5 hours. That will never happen. Right. There's no time zones. You just need this absolute. How long has it been since genesis? So I think this is not an insurmountable problem.
00:29:58.010 - 00:30:23.646, Speaker A: And in fact, this problem does occur in other systems as well. Right. You do need real time to be vaguely in sync in almost every blockchain protocol, I think. Yeah. So there is this sort of very weak trust assumption in terms of my clock is more or less. Okay, you're right. Okay, so how do we get consensus? So at the high level, what we're going to do is we're going to vote.
00:30:23.646 - 00:30:52.102, Speaker A: So what I'm going to describe now is sort of this very, very inefficient protocol that sort of gets the security. Right. But in terms of practicality, it's like n squared complexity. It's horrible. So our protocol actually does the same thing, but we optimized it several steps. So it's actually much, much better in terms of communication, in terms of cpu. So it actually makes this practical.
00:30:52.102 - 00:31:29.830, Speaker A: But for the sake of understanding what's going on, it's much easier to describe it this way. So what do we do? Every use of different color. It's so nice that we have lots of colors. Every block is going to basically vote about every other block in previous layers, so all of history. So I'm going to sort of point to all of the blocks that I see. And for each of these blocks, I'm going to say, is this a valid block or is this an invalid block? And if I don't point to a block, it means I haven't seen this block. So I'm basically saying this is invalid.
00:31:29.830 - 00:32:06.050, Speaker A: So I don't need to explicitly point to blocks that I'm explicitly voting against. And then what we do is we collect the votes. So we count the votes. The votes are actually weighted, so they're weighted by sort of how much resource I expended. We'll get into sort of how do we decide when we're eligible to generate blocks? Because this is, I think, one of the interesting things that's different about our protocol. But basically now we're counting and then the majority decides. So this is great for all of those things that we all agree on.
00:32:06.050 - 00:32:23.450, Speaker A: The majority is going to decide that is honest, so that the majority will decide in the same way. So if there's an honest block, everybody is going to vote for it. And if it's sort of far enough in the past, then I vote according to what I see. So if I see the majority voted for it, I'm going to vote for it as well.
00:32:23.520 - 00:32:25.990, Speaker B: So I can change my vote in the future layers?
00:32:26.150 - 00:32:28.694, Speaker A: No, just whenever I have a new block, it votes.
00:32:28.822 - 00:32:35.306, Speaker B: Right. So, for example, I produced block here and I thought, this is valid, but then later, when I was producing block.
00:32:35.338 - 00:32:37.214, Speaker A: In layer 13, I can change it. Yes.
00:32:37.252 - 00:32:40.720, Speaker B: Yeah, I saw that. Majority of people disagree with me. I see.
00:32:41.410 - 00:33:05.800, Speaker A: So you count all the votes up till the current time, and this gives you sort of your own opinion about all the previous blocks. And then your block will say, what is your opinion about at the current time about every previous block. And so if all the honest parties agree that this is valid, then in the next layer they'll count the votes. All of the honest parties will agree that this has the majority valid, so they'll all agree that this is valid, and this majority will just grow.
00:33:06.650 - 00:33:09.310, Speaker B: And so within a few layers, it will just always converge.
00:33:09.410 - 00:33:39.922, Speaker A: Yes. And in fact, because these layers are very big, again, it depends on exactly how much probability of error you're willing to tolerate. But for, like, two to the -40 probability of error and 200 blocks per layer, even if one third of the blocks are voting completely differently, within four layers, you're completely convert in this case. So this is wonderful. And then you can have basically the same argument as why bitcoin can't be reversed. Happens here. Right.
00:33:39.922 - 00:34:09.450, Speaker A: You have the probability that you're going to sort of change the majority depends only on how many votes, the margin of votes, how many plus versus how many minus, and the fraction of the resources that the adversary controls. And so this is actually going to happen much faster than bitcoin. So in bitcoin, we have this one block every ten minutes, but here the margin grows by 200 blocks every five minutes. Once we were in this good position, then you get really, really fast convergence.
00:34:10.990 - 00:34:12.686, Speaker B: It feels like the following would work.
00:34:12.708 - 00:34:12.846, Speaker A: Right?
00:34:12.868 - 00:34:15.118, Speaker B: So let's say there's five validators, right?
00:34:15.204 - 00:34:16.202, Speaker A: Five alligators.
00:34:16.266 - 00:34:30.370, Speaker B: Validators, five block producers. And let's say that at the first step, it happened. And there's, like, a particular block we are going about. And that block was produced on the boundary.
00:34:31.350 - 00:34:42.262, Speaker A: Yeah. So I didn't get to the boundary yet. This is the hard case. Right. What I've just described so far is the easy case. Right. Everybody agrees if it's in or if it's out, and then we get conversions like that.
00:34:42.262 - 00:35:25.220, Speaker A: So that's great. But the whole point is, how do we decide about these? And actually, in this case, it turns out it's a really big problem. And this is a really big problem in all these protocols. And here we can't use sort of bitcoin solution, which is there's going to be one true block that will decide, and we'll all agree on it because there's only one. So there's going to be many. So it could be that in this layer, half the honest parties vote for it, and then half the honest parties vote against it. Okay? Now, in the next layer, the adversary will put another block here that votes for it and another block here that votes against it.
00:35:25.220 - 00:35:30.034, Speaker A: And if half the honest parties see this one and half see this one.
00:35:30.072 - 00:35:32.006, Speaker B: First and all the one is blocks as well.
00:35:32.028 - 00:35:55.454, Speaker A: And they all see these because these are honest blocks, then again, this split can continue, and you only need one block here to do this right. So you can continue this forever. So this is bad. We don't want this case. Okay, so what do we do? So this is what we call the tortoise protocol. There's another part of it that I hope I'll get to talk about later. It's an important part of it, but for the sake of the overview, let's talk about the hair protocol first.
00:35:55.454 - 00:36:23.398, Speaker A: So the hair protocol, basically, is this really fast bootstrapping method to get us to agree on these blocks. And it really happens off chain. So it still uses the gossip network, but the results of the hair protocol are only recorded as votes on the chain. So what is the hair protocol? Maybe I'll start. Why do we call this the tortoise protocol? Because it's very robust. It's a bit slow. We'll talk about.
00:36:23.398 - 00:37:01.086, Speaker A: What do we mean by slow? Because up till now, it just sounds fast, but it's sure. That's the important thing, right? It guarantees irreversibility. And this ticks and everything. Once we have agreed on something, it will stay agreed. What does the hair protocol do? What it does is we select a different committee. So here we have, basically, these blocks are subsets of all of the users that are selected to generate blocks for the hair protocol. We use just completely different committees, but in a sort of similar way, we select a random committee.
00:37:01.086 - 00:37:42.334, Speaker A: The hair committees are actually a lot larger. So the hair committee is going to be something like 800 committee members. And then, well, they could all use a byzantine agreement protocol to decide about all these blocks. So, basically, at every layer boundary, we start a new independent byzantine agreement protocol, a new hair protocol that decides on all the blocks in the previous layer. And then instead of voting according. So in the hair protocol, I vote according to whether it's on time or not into my own opinion. But because it's a byzantine agreement, at the end, all the honest parties are guaranteed to agree.
00:37:42.334 - 00:38:06.614, Speaker A: And now the rest of the honest parties who didn't participate in the hair protocol, they see the results and they vote according to the results of the hair protocol. So now all honest parties are going to agree on this. It might be in, it might be out. We're not sure. But the hair protocol is this property that if all honest parties agree on something, that's going to be the output. If they don't agree, we don't know what the output is going to be, but we do know that they will agree on it. So there's a little wrinkle here.
00:38:06.614 - 00:39:09.734, Speaker A: Something that we want is to prevent these denial of service attacks. And here we use a trick from Algorand, or similar to Algorand, where we're sort of assuming that if there are lots and lots of players, you can't DDos everyone, but if you know that somebody said something in a previous round and they're going to talk again, then you can focus on their ip and then just kill them. And this is a problem. So if you have a protocol with 800 committee members and they need to talk for several rounds, which they do, because byzantine protocols need several rounds of talking, then after the first round you could kill all the honest ones, and now you're left sort of, you don't have an honest majority in this anymore. So we use the algorithm, trick of player replaceability. Basically we have several rounds, but at every round there's a different committee which is totally independent of the previous committee. And this is really, really fast, so we can do it on average.
00:39:09.734 - 00:39:27.250, Speaker A: Again, it depends if we're under attack or not. If we're under attack, we do it, I think something like two minutes or no, maybe five minutes, average, I think. So it's like a bit less than the layer time. If we're not under attack, it's much faster.
00:39:27.910 - 00:39:34.702, Speaker B: But if it's five minutes, isn't it too late for the block producers here it's eight layers.
00:39:34.766 - 00:40:20.702, Speaker A: No. So maybe it is two minutes. Yeah. We did the calculation so that in the optimistic case it actually happens early enough that the next layer can use it. In the pessimistic case, then it might not be finished for this layer. So if you haven't seen the hair protocol results for this layer, then instead of voting sort of directly, you say, look, I'm still waiting, I don't know what the results are for this layer, and I'll vote for the previous layer instead. But because on average it takes very few rounds and this long time is if you have one third of the network being actively attacked by the adversary, this is when it can take this eight round average.
00:40:20.702 - 00:40:58.960, Speaker A: So we assume most of the time this is not going to happen because it's not a rational thing to do. Right. It's just if you weren't trying to take down the network, but you can't take down the network, so you can just slow it down a little bit. So this is what the here protocol does. And basically now we get agreement and then the tortoise ensures that, okay, this agreement is now going to be set in stone because the majority just grows and grows. Okay, so said there's another important property of the tortoise protocol, which is it has to do with security. I think there's something important for protocols in general.
00:40:58.960 - 00:41:40.218, Speaker A: What is the robustness of the protocol? And by robustness, I mean, we said our protocol is secure as long as our assumptions hold. But we want this protocol to run for a very long time. Right? So what are our assumptions? We have this connectivity assumption. We have the honest majority assumption, and we have some mathematical assumptions, like the same things that other protocols use. SHA 256 is collision resistant and behaves in certain ways. And you can't break elliptic curve signatures and things like that. So for mathematical assumptions, then they're either broken forever or not, and you're sort of assuming that they're going to keep holding on for a long time.
00:41:40.218 - 00:42:08.690, Speaker A: This is very common. Everybody does that. But for the other assumptions, they're assumptions on behavior, on, like, real life things, right? An honest majority means what people are actually doing. It's not something we can prove. And there is some very low probability that things will happen that will violate these assumptions. Suppose there's a giant power outage. All of China is now without electricity.
00:42:08.690 - 00:42:49.282, Speaker A: All the computers go down. So suddenly we don't have an honest majority for a few hours. Or maybe somebody got somehow a short spike and managed to hack into AWS and use all their disk space and also into Google at the same time, they're using all their disk space for a short period of time till they're caught. So these things could happen. They're very, very low probability, so we don't usually protect against them. But if you take a long enough period of time, then low probability events will happen. You think about lightning strikes, right? The probability that lightning will strike at this moment here is super low.
00:42:49.282 - 00:43:35.390, Speaker A: It could happen, but it's very, very low. But the probability that lightning strikes somewhere in the world is actually not that low at all. Right? Lightning does strike all the time, all around the world. So we have to have our system be robust in the sense that if these bad things happen, we don't want to say, okay, now the system is dead because over a long enough time, they will happen. So we want, okay, what can we guarantee? If everything bad is happening, the adversary hacks into all the world's computers and changes everything. Okay, then there's not much you can do. But if there's, like, power outage and we lost honest majority for a while, so the adversary can do all sorts of bad things, but at the very least, we want the system to sort of write itself after.
00:43:35.390 - 00:44:18.474, Speaker A: So now that there is an honest majority again, we're back to, our assumptions are holding, then we want to at least guarantee that we're in consensus again. Right. We don't want some kind of manual intervention to be necessary and to decide, then there has to be somebody who's deciding what is the new consensus. This is a bad thing for this distributed system that requires, we want to require very little trust. So we have something that we call self healing mode. And basically what self healing mode is, is the tortoise can work without a hair protocol at all. And the tortoise protocol works only based on the messages.
00:44:18.474 - 00:44:35.620, Speaker A: I see. So after, if we had a network split or if we had some bad things, and maybe I didn't see all the messages. You didn't see some of them after we're connected again, there's an honest majority again, we all exchanged all the messages, all that history saw. So now we're going to agree again.
00:44:36.550 - 00:44:39.022, Speaker B: Does tortoise see the hair protocol?
00:44:39.086 - 00:44:40.406, Speaker A: So you don't need the hair protocol. Okay.
00:44:40.428 - 00:44:43.554, Speaker B: So it only sees the block approvals, like votes.
00:44:43.682 - 00:45:30.774, Speaker A: What? I said that the hair protocol just bootstraps are agreement for voting in the tortoise. But once the hair protocol is gone, I don't actually need the hair protocol messages to agree on what the state is. So what I'm going to do is basically we're in agreement. So, first of all, just from the fact that the tortoise protocol result is a deterministic function of the messages I see. Means that if we're not under attack, if we have one layer that was quiet, nobody attacked at all, then we all saw the same messages, then we're already in consensus. We just agreed completely because we saw everything. But if we are under constant attack after this, still.
00:45:30.774 - 00:46:06.500, Speaker A: So maybe a low level attack. So self healing in our protocol actually requires some slightly stronger properties. So usually we're robust against one third corruption. So here you might need maybe at most, I don't remember what the numbers are right now, but, like one six or something like that. So what do we mean by one thing? We don't need the adversary to corrupt that amount. We say it doesn't attack with more than that amount. So even if it's corrupted one third, but it only attacks with one six, then self healing will work.
00:46:06.500 - 00:46:31.226, Speaker A: And basically the way self healing works is we modify this voting protocol. So this happens all the time. Right. This is part of the core tortoise protocol that we changed in order to allow self healing. So what I said here is not exact. It's not that we just have a simple majority. What we're doing, actually, is we have three states.
00:46:31.226 - 00:46:51.534, Speaker A: So if we look at the margin of votes. So this is the vote margin. So here would be all votes plus. Here is all votes minus. Okay? And this is zero. This is an equal number. Right.
00:46:51.534 - 00:47:42.926, Speaker A: So here, what we said before was basically the naive thing is this, I think, is a plus. And this, I think, is a minus. In order to allow self healing, we're going to use a kind of trick from sort of classical byzantine agreement protocols. We're going to change this, and we're going to add something around the zero so that now this is a plus, this is a minus. And here we're going to do something differently. We're going to have a coin flip. And this coin flip is going to be what we call a weak coin flip, where everybody agrees on the coin.
00:47:42.926 - 00:48:06.134, Speaker A: All the honest parties agree on the coin with some content probability, say one third. Okay, sorry. Two thirds, everybody agrees on the coin. With probability two third. And so, with probability one third, everybody agrees that it's zero. With probability one third, everybody agrees that it's one. And with probability one third, the adversary can decide they don't have to agree.
00:48:06.134 - 00:48:36.270, Speaker A: The adversary just says what each honest party thinks is the coin. And the property we have about this vote margin, the property that we maintain, is that honest parties can disagree. Right. So an honest party, if it's here, it means it sees a lot more plus than minus. And if it's here, it sees a lot more minus than plus. But why do honest parties disagree? They can only disagree if they receive different messages. Basically, they're counting votes.
00:48:36.270 - 00:49:09.290, Speaker A: So you and I can only disagree if by this much, the weight of the met of the votes that we disagree on is at least this much. But this is bounded the weight of the votes that we disagree on. We never disagree on honest blocks because those are a guarantee that we see them together. So we only disagree on the dishonest blocks that are published in the past short period. So basically what we're saying is you can't disagree by too much because the adversary cannot generate too many dishonest blocks.
00:49:10.110 - 00:49:15.006, Speaker B: But it could still be the case that one honest party is here. Right. And another one is here.
00:49:15.108 - 00:49:33.790, Speaker A: Yes. Right. So what we're saying is we're bounded. Right? You can disagree by less than this. So it could be that an honest party is here and one is here. It could be that there's an honest party here and one here. But it can't be that these two are honest parties.
00:49:33.790 - 00:49:55.740, Speaker A: Okay. And now the coin flip basically is a plus or a minus. So let's suppose we're in this case. It's symmetric for the other case. If we're in this case, then this one will always say plus. This one will use the coin. Now, with probability one third, all the honest parties will see the coin as a plus.
00:49:55.740 - 00:50:24.850, Speaker A: So with probability one third, all the honest parties are going to agree. But that means that in the next round, they're going to see a majority voting in the same direction. And so basically, in the next round, all the honest parties are going to shift. So they're going to be here. And now we can get basically to full agreement. So, okay, with probability two thirds, this doesn't happen. But in every round, it's sort of independent.
00:50:24.850 - 00:50:45.020, Speaker A: We have this good case. So if we're in the bad case, then we're just back to where we started. And this means that very, very fast, you will have. By very fast, I mean one third to the n. When n is the number of layers, there's a probability that you manage to sort of miss out. Sorry, two thirds. Yes.
00:50:45.020 - 00:51:04.058, Speaker A: Right. So this goes down exponentially fast. So pretty fast, but exponentially fast, it's still number of layers. This is why we say that the tort is sort of slow. But sure, it's much slower than the hair protocol, which is immediate. But if this doesn't work. Sorry, if the hair protocol doesn't work, this will still guarantee consensus.
00:51:04.058 - 00:51:41.694, Speaker A: And once we have consensus, then the hair protocol will start working again, and then we'll be back in the good case. So we have this sort of automated mechanism to heal from bad things. Okay. Maybe I will talk a little bit about how we decide eligibility, because I think that's something interesting, and it's different from how other protocols do it. So most protocols that we know basically do this random sampling. Right. They say every block or the block that is going to be generated or the protocols that do.
00:51:41.694 - 00:52:14.196, Speaker A: Dags have like a set of blocks or committees. Everybody sort of self select in some way whether they can join the committee and we randomly sample them. And this is how they get into the committee. In our protocol, we actually do it a little bit different. We're going to do it deterministically. And the way we do it is we have. When.
00:52:14.196 - 00:52:50.250, Speaker A: When you start out, right, you're doing this proof of space time. So you need to generate space. We have initialization. But once you do that every time, you only need to prove every two weeks that you've stored space. And this proof goes into something that we call an ATX, an activation transaction, maybe transaction is not the completely good name for it, because these are sort of like they're freestanding, they don't have to be inside blocks. So you don't need to convince somebody to put this in their block for you to join. You just publish it and everybody sees it.
00:52:50.250 - 00:53:35.892, Speaker A: And this ATX contains a post. If we have time, I will talk about exactly which kind, because there's some subtleties here, and it contains these sort of commitments to where I'm going to generate blocks. So we divide the layers into epochs of two weeks. So every 4032 layers are one epoch. And in order to generate blocks you have to publish an ATX in the previous epoch. So we have an epoch, and now you generated an ATX here. This makes you eligible.
00:53:35.892 - 00:54:04.768, Speaker A: So now you're active means you're eligible to generate blocks here. And you're actually guaranteed deterministically. So everybody is going to publish one ATX in every epoch, every miner. And this guarantees that you get to publish a block here. Where is this block published? So this is randomized. Basically part of your id is a VRF key, verifiable random function. So your id is this public key.
00:54:04.768 - 00:54:24.580, Speaker A: And the nice thing about a verifiable random function is it's a function that when you give it an input, it gives an output that looks random to everybody else. But you can prove it's the correct output and you cannot control it. There's only one correct output. So this VRF is basically going to decide which layer your block is in.
00:54:24.650 - 00:54:25.860, Speaker B: But what's the input?
00:54:26.020 - 00:55:02.214, Speaker A: So what is the input? The input, that's a very good point. The input is basically your id. That's the part of the VRF public key. The layer number, sorry, the epoch number. The epoch number and an index I where I is. So here you're going to commit to the number of blocks, the number of blocks. You can decide what D is up to some parameters.
00:55:02.214 - 00:55:17.374, Speaker A: We can get into that in a bit. Okay, so basically if you know the epoch in advance, you do, because the epoch number is one, two, three and the index. So this is the first block in that epoch, the second block, and so forth. Then you know where in the epoch it's going to be.
00:55:17.492 - 00:55:24.702, Speaker B: But. I see, but let's say I want to put a lot of my hash power, sorry, disk power into the same spot. I can grind.
00:55:24.846 - 00:55:45.420, Speaker A: You can grind on your ids. Yes. So that's bad. You're right. So there's actually an extra thing here, which we call an epoch beacon. So an epoch beacon is actually quite a bit weaker than most beacons. It's something that all the honest parties agree on.
00:55:45.420 - 00:56:08.362, Speaker A: It's something you cannot predict when you generate your id. So actually you only become active after the first epoch beacon that you couldn't have predicted in advance after you published your first id. So grinding doesn't help you because you don't know what this epoch beacon is going to be, but at the beginning of the epoch, you do know exactly where in the epoch you're going to be published.
00:56:08.426 - 00:56:13.474, Speaker B: But to have an epoch beacon, we need to have some sort of consensus on it, right?
00:56:13.592 - 00:56:37.114, Speaker A: Okay, so we need consensus for the honest parties. So there are several ways to do it. So the easiest way is to use a VDF. So we just say you use a VDF that should run for two weeks. After two weeks this is the output, and then you continue iterating this for the next two weeks. You get an output and everybody can verify that. And there's only one true answer and you can't get it before two weeks.
00:56:37.114 - 00:57:36.640, Speaker A: So this gives sort of perfect parameters, but there's a big cost to it. You have to trust a VDF. And all the VDFs we know of require these sort of new algebraic computational assumptions or trusted setup, or they're not super nice in terms of what we have to assume to get them to work. So everybody is using bdfs, they're amazing mathematical objects, but I'm not sure we might end up using them just because the parameters in some sense are better. But we can actually do it without a, and because the problem here is that we're sampling right, but we do have this advantage that over in epoch we're not sampling right. We have, these ATXs are basically deterministic, everybody registers. And we know for sure that there's an honest majority of atxes for sure by means, if our assumption holds, of course.
00:57:36.640 - 00:58:21.562, Speaker A: So we can use that to have sort of each ATX vote for say the next epochs beacon. And it's not quite that simple, but we can get a protocol that gives you sort of very little influence. The adversary might be able to do a little bit to change the beacon, but it can't do too much. And the other nice thing is that you don't need to prove that the epoch beacon is something you just write in your ATX. This is my beacon number and the protocol. We have these sort of modifications to the voting rules, so that if you're using the wrong beacon. I don't count your vote, or at least I don't count your vote for a while.
00:58:21.562 - 00:59:05.740, Speaker A: I postpone it so that it doesn't actually help you if you concentrate your power. Yeah, so I think one of the nice things is that we have this deterministic guarantee you're definitely going to get a block. So how many blocks do you actually get? So you can get how many you want. You can get lots and lots of blocks. You can get a block in every layer if you want. If you do that, you might be considered invalid in the sense that you're not going to get a reward. So the right number of blocks is basically see how many people are registered in the previous epoch and then set the number so that the average number of blocks per layer is 200.
00:59:05.740 - 00:59:45.766, Speaker A: Right. But we don't verify that you don't use too many blocks. Actually, the only thing we're worried about is using too few blocks. Why? Because if everybody is spread out across the layer, but you have all your power in one block, then again, you have this problem where your voting powers can be concentrated in a few layers, but you can show that you can't have too few blocks by basically showing how many people are registered that you see. Right. So if you see very few people registered, you need many blocks because it means you need many blocks per layer. In order to get to one block, you need to see that there's a lot of weight already there and honest parties will also see it.
00:59:45.766 - 00:59:47.990, Speaker A: So they'll also just use one block per layer.
00:59:50.090 - 01:00:05.642, Speaker B: I actually have one other interesting question. So as the protocol goes, right, we have some sort of stability as of, let's say, five layers ago, but the last five layers, they pretty.
01:00:05.776 - 01:00:30.734, Speaker A: So it depends if we're under attack and how heavy the attack is. Right. In ideal conditions, then maybe already the previous layer is under consensus. If we're under one third of the chain, one third of the power is attacking us, then occasionally we'll get a hair protocol that takes longer. So then we might have like the few previous layers are not yet in consensus.
01:00:30.862 - 01:00:35.538, Speaker B: But within a layer, is there a specific order in which blocks are applied?
01:00:35.634 - 01:00:56.634, Speaker A: Yeah. Okay, so that's actually a good question. So what we're doing so far is just deciding which blocks are in the layer. And how do you get from that to like a total order on transactions. Right. Because this is what we need to run smart contracts or to do things like that. And basically what we're saying, if we agree on which blocks are in the layer, then it's easy.
01:00:56.634 - 01:01:44.282, Speaker A: We can decide sort of whatever arbitrary rule we want. Say we order them by their hash, right? And this is the order and transactions. Another thing that I didn't mention, but transactions actually, ideally, they'll have different transactions each block, but they could be duplicated because this block and this block don't talk to each other while they're generating. So the idea is everybody chooses a random subset of the transactions. You have fairly little overlap, so you're actually going to get a high throughput, but there could be some duplications. So again, we have this, some kind of rule to say the transaction counts as the first place that appears in a block. Or if you want to randomize it, you can think of, you take all the blocks together, pool all the transactions, and then do some random order.
01:01:44.416 - 01:01:49.914, Speaker B: But as a reasonable actor, right. Would I not prefer to choose transactions which have the highest.
01:01:50.042 - 01:02:28.810, Speaker A: No. So the way that the reward system works is you don't get rewarded directly for the transactions you put in. The rewards are shared first of all among the layer, but actually also among neighboring layers so that you don't have bad incentives. Like, I want to not include this in this layer because I know I have a block in the next layer and there are fewer various things like that. So we sort of spread out this thing. So, yeah, you do want to include that. If there's too many transactions to include, which I think is, this would be wonderful here, the limit on the number of transactions is very large.
01:02:28.810 - 01:03:07.910, Speaker A: So in general, you'll have everything inside, and then it doesn't matter which ones you chose. But if you do get to the case where there's too many transactions to fit even here, then you want to incentivize sort of everyone to choose a slightly higher value transactions. But, yeah, it's not like I want the highest one, and everybody will choose the same one, because overall, it's actually better for you to coordinate so that everybody, you'll get as many transactions as possible and not just the one that's highest. Okay, so this is like a very high level overview.
01:03:09.770 - 01:03:12.854, Speaker B: Any other specific things so I can.
01:03:12.892 - 01:03:58.260, Speaker A: Talk a little bit about how this proof of space time works? Sure. Because actually, this paper is already out. It was accepted to crypto, so it's now an eprint. You can read it, and it will be presented in the conference in August. Okay, so let's recap what we want to do with a proof of space time. I want to prove to you that I'm storing a lot of data, and I'm storing it consistently for two weeks and then another two weeks. And the basic idea is I'm going to fill my disk with junk, but I need this junk to have special properties.
01:03:58.260 - 01:04:54.568, Speaker A: So for instance, one property that I want this junk to have is that it's incompressible. That is, I shouldn't be able to store some small seed and be able to easily recreate this junk. And so what is incompressible? Say random data, that's incompressible, right? But I can't just show you that I stored random data because it could be that I actually didn't store random data. I stored pseudorandom data, which has a very small c that lets me generate it at all. So what do we actually store? What we're going to do here is we're going to store the output of proofs of work and they're going to have this special property that they're incompressible. So I have this giant table, and each cell of the table is going to be a proof of work. So generating this table is going to cost me work.
01:04:54.568 - 01:05:47.070, Speaker A: It's going to be expensive. Right now we're talking in something of the order of two days on a gpu to generate this table. And it's important that it's expensive because if it was not expensive, then I could decide not to store the data and just generate it again every time. So in order to make it rational for me to use this spacetime resource, then I want to make it expensive enough that just storing it and not touching it is good. So I want to make the price of regenerating higher than the price of storing it for two weeks. And that's pretty easy because storage is quite cheap. So this two days should have sort of nice margin, and in fact it might be even a good enough margin for like commercial services where if you want to pay Amazon to store it for you, it's still cheaper to do that than to regenerate it.
01:05:47.070 - 01:06:19.840, Speaker A: Okay, so this is what I'm storing. How do I prove to you that I'm storing it? So the native first attempt is, okay, so what are the challenges of these proofs? So they're going to be your id. So we have an id. So say the challenge here is your proof of work. Id and index. So this will be your id and one, your id and two and so forth. So this is going to be hard to generate.
01:06:19.840 - 01:06:51.436, Speaker A: We have these property that you cannot compress the output. But now what do I do? Two weeks have passed. Maybe I even somehow committed to this. This is like the first naive attempt. And now I ask you, and now you say, okay, fine, show me your story. Show me three random places in the table. Okay, so if I've committed in advance, say, with a Merkel tree, then I'll have to show you three random places.
01:06:51.436 - 01:07:45.440, Speaker A: I actually have to have these random places in the table, but that's actually not a good proof of space time. Why? Because I can decide not to store the table, but just recreate those specific three things you asked me about. So that's going to be bad, right? I want to force you to store everything, but we're going to do something almost the same. So it's a very, very simple proof. What we're going to do is we're going to say, let's say this is your table. Okay? I'm going to give you a challenge after two weeks, and you're going to create a Merkel tree where the hash function uses the challenge. So I'm going to hash, instead of just hashing the two leaves, I hash the challenge and then the two leaves.
01:07:45.440 - 01:08:16.980, Speaker A: Okay, so the regular merkle tree would be a and B. And here's the challenge in a and b. And I do that in the same way. Right, until I get the root. Okay, now I'm going to describe an interactive protocol. So I send you the root of this tree, and then you give me these random leaves, and I have to show you a path in the Merkel tree. So this actually does prove that you stored the data, or at least that you had most of the table.
01:08:16.980 - 01:08:39.410, Speaker A: So to get an idea, suppose you only had half of the table. You decided not to store half. While you're building this tree, you have to commit in advance to which parts you decided to regenerate and which you didn't. So if you only regenerated half, then with probability, half every time I ask you, I'm going to land on one of these leaves that you didn't regenerate. And so I'll catch you.
01:08:41.640 - 01:08:48.948, Speaker B: But let's say it's 1 data, right? Isn't computing this Merkel tree will be like on the order of.
01:08:49.034 - 01:09:22.704, Speaker A: Okay, so, good question. You do have to go over, it's like one linear read over the, depending on how much memory, one or two linear reads of the memory to generate this tree, it's not so bad. For 1 data, the hash we use, the proof of work here uses a much heavier hash. And when you do the merkel tree, you actually don't need to do each of these. The output of the proof of work is actually quite small. So you don't need to do all of them. You can batch them together.
01:09:22.704 - 01:09:46.520, Speaker A: So it turns out in terms of actual parameters, it's not too bad. It might take you, I don't know, ten minutes, half an hour depending on the size. Again, this is like if you're a magnetic disk, but it's all linear, it's like sequential reads. So it's not bad. But you're only doing this once every two weeks. So once every two weeks you read 1 tb.
01:09:49.900 - 01:10:01.964, Speaker B: But let's say instead of doing that, right, so let's say that the output here was proof of work, of id index, but also of these three outputs, right?
01:10:02.082 - 01:10:02.990, Speaker A: Of what?
01:10:03.360 - 01:10:17.536, Speaker B: These three outputs, right? Because table is serial. Right. Then for me to reproduce this, I would have to recompute like if this is sufficiently far to the bottom and right, I would have to reproduce the big part of the table, right?
01:10:17.638 - 01:11:07.010, Speaker A: Yes. So there actually are proofs of space that were published earlier that use something a bit more common. You don't actually need the proof of work here that use these sort of interesting graph structures that have these properties that if you can get the hash of the end of the graph, then you have to have a lot of space while you're doing it. So you can prove that you're actually storing space with a lot of these hashes. And everything depends on everything else in a sort of interesting way. The reason we're doing this is, first of all, it's a lot simpler, but also one of the properties this has is that you can change the difficulty. So we're saying the difficulty of these proofs of work needs to be enough that it's more expensive to regenerate than to store for two weeks.
01:11:07.010 - 01:11:54.768, Speaker A: If you remember, we said that everybody publishes an ATX. This seems a little suspicious, right? Because if we have more and more miners, it means our communication grows, right? The reason everybody else does sampling is that you want your communication to be constant independent of the number of miners. And here we have 800,000 miners, then we have 800,000 atxes. If we have 2 million miners, we have more than twice that. So the communication is just going to grow. So how do we deal with that? So right now we said there's a two week epoch, then this will be sort of good, up to about 800,000 miners. If we want more than that, we can increase the epoch size.
01:11:54.768 - 01:12:33.230, Speaker A: So we can say, okay, once we get to 1 million miners, the epoch is going to grow to be four weeks instead of two weeks. And then basically, you're just using the ATX less frequently so the communication can still stay constant. But now this table has to hold on. It has to be more expensive than a full month of storage. So it could be that we need more work. So how do we do that? Well, we could just say, right, run everything over, but this is not super reasonable, this kind of protocol. They basically require that to run things over.
01:12:33.230 - 01:13:00.390, Speaker A: And they also require like, the harder it gets or the more space it needs to take. So these are a bit problematic. Here we have this sort of nice mechanism where you can just sort of make each, like, if we use the hash based proof of work, then you can just say, each of these is going to get a little bit harder. So you can go over the table. Some of them are already good, so basically you're only paying the difference in the difficulty. So you can sort of incrementally increase the difficulty. And this has this nice property.
01:13:00.390 - 01:13:04.070, Speaker A: We also have these properties like.
01:13:04.440 - 01:13:07.690, Speaker B: But in reality, very few of them are going to be good, right?
01:13:08.140 - 01:13:09.960, Speaker A: No, exactly the proportion.
01:13:11.420 - 01:13:17.176, Speaker B: So it's not like you're going to be requesting one extra zero. It could be that you're just requesting that it's slightly, yes, if you request.
01:13:17.208 - 01:13:23.630, Speaker A: One extra zero, then half of them will be good, but you're only doing the difference in the work.
01:13:26.720 - 01:13:30.844, Speaker B: And so then we're not actually waiting for two weeks, we're using proof of elapsed time.
01:13:30.882 - 01:13:32.032, Speaker A: Right? We're not. What?
01:13:32.166 - 01:13:33.312, Speaker B: We're not trusting that.
01:13:33.366 - 01:14:17.150, Speaker A: Okay. Yes. So this is an interactive protocol and which is not really something you can use in this setting. So first of all, we make this non interactive by using this very well known trick called Fiat shamir, which basically says, instead of me sending you the root and then you giving me random challenges, I just take this, put it into a hash, and pretend that you sent me the results of the hash as the challenges. And if it's difficult enough to find good things, then this is secure. So this is non interactive, but you still need to trust here that two weeks have passed. So how do we get around that we use this proof of elapsed time? And so basically what we're saying is we have this post.
01:14:17.150 - 01:15:13.916, Speaker A: The post has two phases. It has phase one, say in the beginning of the epoch. So this is epoch one, and then it has phase two and epoch two. So you send the same post, and now I know that two weeks have passed, but if I have to actually be there to check that two weeks have passed and I'm violating this property that only the messages matter. So instead of doing that, what you're going to do is you're going to take the output of this post, sort of the commitment to it, and put it into a proof of elapsed time. So we'll talk about this in a second, and then we'll take the output of this and use it as a challenge in the proof phase of the post. And basically this guarantees if you check this result and this result, that two weeks must have passed and this is self contained.
01:15:13.916 - 01:15:23.590, Speaker A: You don't need anybody to trust anybody. I mean, you don't need to trust this poet. You need to run this poet. Okay, so now this seems like, okay, we're back to proof of work. Why is this not just a regular proof of work?
01:15:24.360 - 01:15:26.388, Speaker B: Everybody doesn't need to run the poet. Right?
01:15:26.474 - 01:16:11.510, Speaker A: Exactly right. So the poet can be one server that actually gives everybody the answers, and it only costs once. So again, the poet server doesn't need to be trusted. There doesn't need to be only one. But if you're saying you're paying a fee to use a poet server, so anyone can run their poet server, the more users the poet server has, actually the lower the fee it can charge because its costs don't depend on the number of users. So you have this sort of aggregation where you'd expect that there will be very few poet servers with huge number of users can always verify the results, but you don't need to trust, but you don't need to pay a lot for them. There's actually very little work being done in terms of the whole system.
01:16:11.510 - 01:16:14.708, Speaker A: Cool. Yes.
01:16:14.874 - 01:16:18.630, Speaker B: So did we cover give or take everything?
01:16:19.080 - 01:16:23.952, Speaker A: Well, there's many layers that we didn't cover, but I think in overview.
01:16:24.016 - 01:16:25.732, Speaker B: Yeah, it's a great overview.
01:16:25.876 - 01:16:26.280, Speaker A: Cool.
01:16:26.350 - 01:16:30.920, Speaker B: And we always ask the same question at the end, which is not technical. When is Mainnet?
01:16:31.340 - 01:16:49.856, Speaker A: So I think right now testnet is around the corner. I think July is the current plan. And Mainnet, I think in the beginning of 2020. I'm not sure exactly how firm the dates are, but this is sort of the general idea.
01:16:49.958 - 01:16:54.370, Speaker B: Cool. Exciting. Okay, thanks everyone for watching.
01:16:54.980 - 01:16:56.384, Speaker A: Until next time, you.
01:16:56.502 - 01:17:01.310, Speaker B: Thank you. Close.

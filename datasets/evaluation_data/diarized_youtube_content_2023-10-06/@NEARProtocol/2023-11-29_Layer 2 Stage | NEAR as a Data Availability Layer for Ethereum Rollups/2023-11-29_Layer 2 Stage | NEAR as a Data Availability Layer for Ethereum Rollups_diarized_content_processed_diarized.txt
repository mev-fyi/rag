00:00:00.330 - 00:00:09.950, Speaker A: Next up we have rock climbing extraordinaire Farat Sargoz who's going to be talking about Nier as a data availability layer. So please welcome Farat.
00:00:18.370 - 00:00:52.460, Speaker B: Hey everyone, my name is Farat. I work at Pagoda as an engineering manager and today I'm going to be talking about something that we've been cooking for a while. Data availability layer on Nier. So Ilya kind of explained yesterday what we're doing on data availability layer for near but I'm going to be doing a little bit more deep dive and then we're going to look into how we do this for ethereum roll ups. Let's see if this is going to work. This is not working guys. Oh, it does? Okay.
00:00:52.460 - 00:01:11.246, Speaker B: Yeah. So what are we going to do today? We're going to be looking into what data availability is. We're going to be looking into what challenges that we have with data availability. We're going to look at what a roll up is. How many people know what a roll up is here? Oh wow. Okay then I'm going to be quick. I'm not going to go too deep.
00:01:11.246 - 00:01:43.374, Speaker B: Or maybe if you want to go too deep we can go there. Why DA is important for rollups. Right. We're going to introduce near data availability layer. We're going to do component deep dive and then we're going to look into what's next for the data availability layer. What is data availability in the first place? Data availability is a principle that data that is stored on a network is accessible and retrievable by all network participants. Yeah.
00:01:43.374 - 00:02:23.930, Speaker B: Okay, cool. That is very easy to understand. Right? You just make data available to everybody who's in a network. But what is the challenge? The challenge is when you want to scale the network because the problem is that you don't want everybody to verify all the data naively. You want to have some guarantee that the data is available to the participants but not make everybody download and verify all the data all the time. But how does scaling work in the blockchain space? There are two thoughts on this. One of them is what we're doing at near protocol, we're doing on chain scaling.
00:02:23.930 - 00:02:54.340, Speaker B: But the idea is that not everybody should be verifying all the data. Some of them should be verifying some of it, some of them should be verifying the other part. Sorry, validating. And this is how we're trying to solve this at near protocol. We're trying to do this by sharding, which is an on chain scaling solution, how Ethereum is trying to do this is kind of different. Again, same idea. Some parts should do, some parts should be doing the other part.
00:02:54.340 - 00:04:25.620, Speaker B: And it's called off chain scaling. There's multiple off chain scaling types, so to say. But we're going to look into roll ups today, because right now that is the wonders kind of picking up what is a roll up in Ethereum world currently, what they're trying to do is instead of having a monolithic blockchain, they're trying to have a modular stack, right? Where there's an execution layer, there's a settlement layer, and there's a consensus and data availability layer. What they're trying to do is they're trying to take the computation out, the execution out of the rest of the stack, put it in a very, let's say a supernode or a bunch of supernodes, do the calculation, roll up the transactions, put them in a bundle, compress them, and put it back onto an l one which actually scales pretty good, right? Because not all network has to do all the computation. But then there's a problem. How do you know that the computation that has been done on the supernode is actually correct? How do you prove to the rest of the participants that your state transition is correct? Let's go. So right now, there's two ways of doing this and some subclasses of it.
00:04:25.620 - 00:05:11.866, Speaker B: But first one is optimistic roll ups, right? So the idea is that these supernodes optimistically produce these state changes and state change commitments and then put it on an l one. And then just they keep doing it and they wait for a certain amount of time where if somebody who also has a stake in that network comes and says, wait a minute, there's a problem. Here's my proof, which is called a fraud proof. And then the chain rolls back. The l two chain rolls back. That is why it's called optimistic roll ups. And for ZK, the proof is done on every execution, and it is called availability proof.
00:05:11.866 - 00:05:50.902, Speaker B: I am not going to go into detail on ZK on technology. I just called it cryptographic magic. But at the end of the day, every execution comes with a cryptographic proof that the execution was correctly done. How does that relate to data availability? So we said that you have to somehow trustlessly verify the correctness of the computation performed off chain. Right. But how do you create the fraud proof in the first place? There's a state a, and then you want to go to the state b. There's an execution between, which is done through transactions.
00:05:50.902 - 00:07:23.654, Speaker B: So you have to have access to those transactions in the first place to say, wait a minute, there's actually a problem with these state changes, and that data has to live somewhere, and it cannot really live with the party that does the execution. Because what if they just don't respond? What if they just go away? Right? You want to be able to continue that chain and keep the state somewhere. For the ZK, you don't really need the transactions, but where do you check your balance, for example? It has to live somewhere. And that is where the data availability layer comes into play. So what you could do is since you're already putting your transaction state commitments onto Ethereum, you can just put it on Ethereum, which is fine, and it has a high security, but at what cost? Ethereum is currently and without protodank sharding or dank sharding, it is quite expensive to post this data directly on Ethereum. So what did we do then? We said, hey, near protocol has very cheap storage, has cheap transaction processing. Why don't we just create a contract and then let these l two s put their data, their state, or their state diffs or their transactions, whatever they want to put, it's just a byte array at the end of the day, directly on near protocol and provide them with a light client where they can say like, hey, this is the Transaction.
00:07:23.654 - 00:08:15.770, Speaker B: Did it actually get inside the, is it actually in the chain? Which is what we call inclusion proofs. And then we created a really minimal RPC client for rust and non rust interactions. So right now we tested with go and rust, and that is pretty much it, actually. So if you look at this graph, you can see that there's Ethereum. The roll up derives, blocks, executes transactions and posts commitments on near through near dA. We put it on a contract. There's a light client, and then the fisherman, which is fishing for frauds, right? To create fraud proofs, is asking the light client, is this in? And at the end of day can go back to Ethereum for the settlement and say like, hey, I found a fraud.
00:08:15.770 - 00:08:56.040, Speaker B: And that is what we built. The blue parts that you see is what we've been working on for a couple of while now, a couple of months, and we're very excited. It is live, by the way, right now I will give you the GitHub link at the end. If anybody wants to check out, feel free to check it out. Why would you build on near? Why would you build on near da layer? Well, it's very, very cheap, right? For now, we also found optimization. Now it's 8000 times cheaper than posting on ETH. We're going to be working on it to optimize it more.
00:08:56.040 - 00:09:37.646, Speaker B: But something that is really important. We already have a bootstrap network that has 100% uptime for more than a year, three years, three years now, which kind of says that you can trust the security of network is already running and working. The validators are already up and running. So the bootstrap of the network has already been done. We already created a lightweight DA client that is easy to run, low cost running, and we have fast finality on state data. So this is really exciting for us. What's going to happen next? Right? We already released this as open source.
00:09:37.646 - 00:10:13.726, Speaker B: You can go and check it out if you want. You can integrate your own roll ups to work with Nearda. Ilya announced some partnerships. We're working on more partnerships coming up. From a tech standpoint, what are we going to do next? We're going to be working on data availability sampling, which is really important to even get the cost down further and introduce data redundancies on near. We're working on 2d erasure coding for the data redundancies. We want to improve the commitments.
00:10:13.726 - 00:10:42.806, Speaker B: We're looking into KZG commitments, which is going to be getting us closer to Ethereum. We want to lower the barrier to entry. We want to create room to room to create economies around this DAS clients. We want to create non interactivity with erasure code commitments. You saw that there's a fisherman. We just want to get rid of it. It's just an additional actor with KZG commitments.
00:10:42.806 - 00:11:40.970, Speaker B: We don't have to do this anymore. We want to have room for more optimizations with multi proofs sampling individual chord words. And something that we want to also investigate. And we're investigating with Eigen layer is double quorum Avs, which means that the security will not be only on near protocol validators, but also Ethereum restakers on these services, which is a combined security at the end of the day, and obstruction of data will be a slashable offense in this paradigm where basically nodes, if they lie and don't give you the data, they will be slashed. We are very excited to launch this new product. And please go and check out if you want to take a look at what we've done. We've done already a couple of interesting integrations, Polygon, CDK and op stack bedrock.
00:11:40.970 - 00:11:48.780, Speaker B: We're working on multiple more. And yeah, I'm very, very excited to share this with you and thank you.

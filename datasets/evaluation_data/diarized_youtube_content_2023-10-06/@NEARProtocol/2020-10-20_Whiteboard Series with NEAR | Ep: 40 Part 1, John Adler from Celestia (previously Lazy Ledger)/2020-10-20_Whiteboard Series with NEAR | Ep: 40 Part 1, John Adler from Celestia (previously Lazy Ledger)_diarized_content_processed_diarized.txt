00:00:05.130 - 00:00:20.254, Speaker A: Hi everyone, this is Alex from Nier. With me today is John Adler, chief researcher and co founder of Lazy Ledger. We will talk about Lazy Ledger today. And John, would you like to introduce yourself and give us an overview of what Lazy Ledger is and technology behind it?
00:00:20.372 - 00:00:20.974, Speaker B: Sure. Yeah.
00:00:21.012 - 00:01:06.050, Speaker C: So as you said, I'm the chief research officer at Lazy Ledger and I'm a co founder, so I do protocol specification and applied research. So I guess I can start with, I'll move this over and I guess I can start with kind of a brief overview of what lazy Ledger does and then we can start talking kind of about the techniques we use to get there. So lazy Ledger is essentially a blockchain that is specifically designed and optimized just for data availability throughput. It doesn't do any execution at the base layer. Rather it just orders messages, in other words, just zeros and ones. It just orders them through the consensus mechanism. And then applications can run on top of lazy ledger and execute over the ordered messages.
00:01:06.050 - 00:01:11.822, Speaker C: Okay, are we ready to start talking about the fundamentals?
00:01:11.966 - 00:01:13.140, Speaker A: Yes, absolutely.
00:01:14.550 - 00:01:39.226, Speaker C: So this is kind of a terribly drawn blockchain. We all know what the blockchain does. Each block header points to the previous block. And let's see if we can draw the pencil. And each block is composed of two parts. So here is the block header, this.
00:01:39.248 - 00:01:44.560, Speaker B: Is the header, and this is the body.
00:01:47.570 - 00:02:11.938, Speaker C: And the body consists of a list of transactions, transaction one, transaction two, and so on. Right. In some order. Usually it's going to be, in particular some topological order. Some other blockchains have proposed other things like lexical ordering and stuff. But there's going to be some ordering there of these transactions. And there's going to a block header.
00:02:11.938 - 00:02:28.826, Speaker C: And the block header usually consists of a pointer to the previous block and it'll have a root of transactions and a root of the state. So let's kind of add some text here. So this one here is going to be a transactions route. And here you're going to have a.
00:02:28.848 - 00:02:29.770, Speaker B: State route.
00:02:33.070 - 00:02:37.150, Speaker C: And the text is tiny. I don't know if is that big enough or do you want me to make it bigger?
00:02:38.210 - 00:02:40.720, Speaker A: Let's make it bigger. I think bigger will be better.
00:02:41.330 - 00:02:43.934, Speaker B: Size bigger.
00:02:43.982 - 00:02:44.900, Speaker C: Is that better?
00:02:45.590 - 00:02:46.194, Speaker A: Yes.
00:02:46.312 - 00:02:50.158, Speaker C: Transactions route. That makes this bigger.
00:02:50.254 - 00:02:59.960, Speaker B: State route. Here's your body and this over here is your block header. Great.
00:03:00.570 - 00:03:02.760, Speaker C: I don't know, how do you move things?
00:03:04.170 - 00:03:07.894, Speaker A: I use this select tool v. I see.
00:03:07.932 - 00:03:09.782, Speaker C: Okay, this is starting to make sense.
00:03:09.916 - 00:03:10.310, Speaker B: Great.
00:03:10.380 - 00:03:13.882, Speaker C: So this is the state route and this is the transactions route over here.
00:03:13.936 - 00:03:14.394, Speaker B: Right.
00:03:14.512 - 00:03:54.950, Speaker C: And every block header has this. Now, there might be some other routes in there. There might be a route of receipts. There might be some proof of work nons, there might be a list or a route of votes if you're using a proof of stake style protocol, but those are kind of not relevant to what we're going to discuss here. So in a normal blockchain, what will happen is you run a full node, and the full node fully executes every single transaction in the block body. It goes through the transactions one after the other, and it fully executes them. And then it makes sure that the transactions in here match up with the transactions route, and it makes sure that the computed state at the end of the block matches up with the state route.
00:03:54.950 - 00:04:11.310, Speaker C: So it's fairly straightforward. And let's pretend that you have an attacker. So an attacker will create a longer chain of blocks.
00:04:14.130 - 00:04:14.990, Speaker B: Arrow.
00:04:18.290 - 00:04:29.060, Speaker C: Forgive my very uneven arrows, but hopefully that will suffice. Oh, so let's undo this. This block should come from, let's say there's a block over here.
00:04:30.230 - 00:04:31.634, Speaker B: There's a block over here, right?
00:04:31.672 - 00:04:47.138, Speaker C: So the attacker forks off of over here somewhere, and he creates a longer chain of blocks. So the attacker has more than 51% or more than 50% of the hash rate. If all of these blocks are valid, then the full nodes will follow this as the longest chain.
00:04:47.234 - 00:04:47.494, Speaker B: Right.
00:04:47.532 - 00:05:09.594, Speaker C: They'll do a reorganization. They'll follow this longest chain. Now, there's things that might happen there. Penalties might be enforced. Some people might decide the coin price should drop or the price of the hashing hardware should drop, stuff like that. That's not really too important to our discussion here. But the way their consensus protocol works is they'll just follow the longest chain.
00:05:09.594 - 00:05:16.458, Speaker C: So if all of these blocks are valid, the full nodes are going to follow this, and the light nodes will also follow this chain.
00:05:16.634 - 00:05:17.262, Speaker B: Right.
00:05:17.396 - 00:05:34.440, Speaker C: Light nodes just check the proof of work. So they just follow the, follow with the longest chain, and they don't validate transactions in the block body. Okay, so now this is where things get interesting. What happens if. Let's see if we can draw with a different color. Let's use red.
00:05:34.810 - 00:05:35.222, Speaker B: Right?
00:05:35.276 - 00:05:52.398, Speaker C: So there's some transaction in here that's invalid. The miner decides to insert these colluding miners that have more than 50% of the hash rate. They decide they're going to insert a transaction there that gives them a whole bunch of coins, like, let's say a billion bitcoins, something like that.
00:05:52.564 - 00:05:52.894, Speaker B: Right.
00:05:52.932 - 00:06:45.870, Speaker C: And so there's obviously an invalid transaction. You can't have a transaction that has a billion bitcoins, but they do it. So full nodes will reject this fork here, obviously, because this is an invalid transaction. And full nodes will follow the longest valid chain, not the longest chain, but light nodes will still follow this chain, because light nodes just follow the longest chain, they don't care about transaction validity. So the light nodes will follow this chain. So now you see that there is a problem, because if many users run light nodes and only a few users run full nodes, that means the light nodes can be tricked by this attack, which is especially dangerous. So the reason that bitcoiners and the bitcoin philosophy is everyone should run a full node is because of an attack like this, is that everyone who isn't running a full node could end up getting tricked.
00:06:45.870 - 00:07:31.710, Speaker C: And if all those people get tricked, they could still continue using bitcoin. And we don't really have a way of enforcing a penalty to the miners that have done this reorg. Like, the miners could just do a reorg, and then if the price of bitcoin doesn't drop, if the hashing hardware, or if the hash function doesn't get changed in response to this attack, then the miners have just executed an attack, and there's no penalty for it, there's no cost of the attack. So this means they would be able to attack bitcoin anytime they want it for free, which would obviously be a terrible conclusion. So this is why they encourage everyone to run a full node, because bitcoin doesn't have a way of protecting against this. So can we do better? Do we have a way of protecting light nodes from this kind of attack? And the answer is yes, in two steps. So we'll cover the first step.
00:07:31.710 - 00:07:36.382, Speaker C: The first step is fraud proofs. Let's see if I can.
00:07:36.516 - 00:07:50.126, Speaker A: So before we dive in, for me to understand, without an ability to insert an invalid transaction, or I guess in more general sense, it is not just an invalid transaction, it could be that all the transactions are valid.
00:07:50.158 - 00:07:50.402, Speaker B: Right.
00:07:50.456 - 00:07:54.834, Speaker A: But the state route does not correspond to the output of them.
00:07:54.872 - 00:07:55.460, Speaker B: Right?
00:07:57.030 - 00:07:58.710, Speaker C: That would be like a block withholding.
00:07:59.210 - 00:08:07.286, Speaker A: No, what I mean is that, let's say the block contains ten valid transactions, the state route is incorrect. Then the full node would also reject it.
00:08:07.308 - 00:08:07.446, Speaker B: Right?
00:08:07.468 - 00:08:11.594, Speaker A: They will validate it, but the light client will still accept it, right?
00:08:11.632 - 00:08:12.266, Speaker C: Yes.
00:08:12.448 - 00:08:26.926, Speaker A: So the miners, they can attack. The previous attack you described with the longest chain does not contain invalid transactions. This is still a valid attack that the miners can execute, right?
00:08:27.028 - 00:08:42.434, Speaker C: Yeah, I said transactions. I said transactions. But a relationship of transactions plus the state route, because the state route defines the state and transactions just modify the state. So instead of having an invalid transaction, they can just directly modify the state in an invalid way by just changing the state route at the end.
00:08:42.632 - 00:08:56.086, Speaker A: But my question is more of, so let's say everybody's running full node, right? The attacker, which has 51% of hash power, can still attack the attack you described first, right. They will create a longer chain and they will double spend, for example.
00:08:56.188 - 00:08:59.434, Speaker C: Oh yeah, they can still do that. So fraud proofs don't protect against that.
00:08:59.552 - 00:09:22.880, Speaker A: Yes. Effectively, we're saying that the attack with an invalid state transition is way more dangerous because it allows you to apply state transitions which are completely invalid while the longer chain or like rework attacks while they're still dangerous, they're less dangerous because it is still on the valid transactions that can go through. Is it the idea or why we're thinking that?
00:09:23.490 - 00:09:58.586, Speaker C: Yeah. So the reason is that we want to move beyond the model. If everyone has to run a full node for the system to be secure, that's essentially what we want to move beyond. Let's say 99% of bitcoin users and traders and investors and everyone involved in bitcoin ran spv nodes, ran light nodes. If someone attacked the system, the full nodes wouldn't have any way of proving that an invalid transaction was included in a bitcoin block to any of those people. So the bitcoin economy would just continue. So the attacker essentially has minted himself a bunch of bitcoins for free.
00:09:58.768 - 00:09:59.162, Speaker A: Right.
00:09:59.216 - 00:10:09.230, Speaker C: And they can do this whenever they want. So we need a compact way for people who are running light nodes to have some sort of guarantee of block validity.
00:10:11.090 - 00:10:11.902, Speaker A: Does that make sense?
00:10:11.956 - 00:10:12.638, Speaker B: Yeah. Yes.
00:10:12.724 - 00:10:13.920, Speaker A: Let's dive in.
00:10:14.390 - 00:10:19.940, Speaker C: So now let's see, how do I. Okay, there we go. So I'll push this up.
00:10:22.230 - 00:10:22.980, Speaker B: Line.
00:10:24.070 - 00:10:26.680, Speaker C: So line, which is red.
00:10:27.370 - 00:10:27.782, Speaker B: Okay.
00:10:27.836 - 00:10:49.740, Speaker C: So the first thing we need is one fraud proofs. And I'm going to talk about specifically the state transition fraud proofs. There's one other scheme for the UtxO data model, but for here we're going to talk about the state transition fraud proofs. Okay, so how do they work? So.
00:10:51.570 - 00:10:59.200, Speaker B: We have our blockchain. Again, we have arrows, and then we have.
00:11:01.170 - 00:11:02.842, Speaker C: Again, our block headers.
00:11:02.906 - 00:11:03.086, Speaker B: Right?
00:11:03.108 - 00:11:05.314, Speaker C: So our block headers have, in here.
00:11:05.352 - 00:11:08.814, Speaker B: They have the state route.
00:11:08.942 - 00:11:48.666, Speaker C: Here's another state route, right? And again, the state route commits to. Or it's the Merkel root of the state tree. State trees can be represented in multiple ways. In Ethereum, you have the Merkel Patricia tree. Other systems have a sparse merkel tree and so on, but it's essentially just the root of the state. And we want to make sure that going, we want, we, so we want to have a way of proving that the state root of, say the next block, or let's say the state root of this block here, the state root of the next block, we want to prove that this is invalid, assuming the previous one is valid.
00:11:48.778 - 00:11:49.246, Speaker B: Right?
00:11:49.348 - 00:11:59.620, Speaker C: So let's draw some check marks. So this one here, the state root is good. And this one here, the state root is bad.
00:11:59.990 - 00:12:00.450, Speaker B: Right.
00:12:00.520 - 00:12:34.160, Speaker C: So they do an attack by either inserting an invalid transaction or the state route is just invalid. And they've just given themselves a billion coins in the state and inserted that as a leaf in the state. So this is the kind of thing that we want to prove by induction. This is sufficient because we always know the state route at the genesis block. So as long as you can show this for one step, then by induction, you can do this anytime you want. So how would we do this? Let's see.
00:12:35.810 - 00:12:36.762, Speaker B: Pencil.
00:12:36.906 - 00:12:56.054, Speaker C: So this block has a bunch of transactions. So we know that if we start at this state route here and we execute these transactions, if this state route is not what we get, then that means this block is invalid in some way. Do we agree?
00:12:56.252 - 00:12:56.950, Speaker A: Yes.
00:12:57.100 - 00:13:06.962, Speaker C: Great. So the obvious naive way is saying, well, just give someone a block and they just execute all the transactions and compare the state routes.
00:13:07.026 - 00:13:07.494, Speaker B: Right.
00:13:07.612 - 00:13:23.194, Speaker C: They have a prestate and then there's a post date. And the post state that's committed to here in this block doesn't match up with the post date they compute. Then that's an invalid block. Right. There's your fraud proof. So this is kind of the naive way of doing a fraud proof.
00:13:23.322 - 00:13:27.518, Speaker A: But they don't have a prestate. Right. Node does not have the state.
00:13:27.684 - 00:13:31.760, Speaker C: Oh yeah. So the light node is given the prestate route over here.
00:13:32.370 - 00:13:33.166, Speaker B: Right.
00:13:33.348 - 00:13:48.280, Speaker C: So in order for the light node to know, sorry. In order for the light node to be able to execute these transactions, the only thing it needs to know is the prestate that is touched. It doesn't need to know the entire pre state.
00:13:48.890 - 00:13:49.254, Speaker B: Right.
00:13:49.292 - 00:14:11.450, Speaker C: So the first thing that you give. Thank you for bringing that up. So what you need to give to the light node. So the light node has previous state root. It's also given Merkel branches to previous state elements that are touched.
00:14:13.470 - 00:14:18.154, Speaker B: And it's given the, and it's given.
00:14:18.192 - 00:14:22.730, Speaker C: You know, well, it's given the entire block. So it's given, you know, the post aid route.
00:14:22.890 - 00:14:23.914, Speaker B: Post aid route.
00:14:23.962 - 00:14:28.642, Speaker C: And you know, all the transactions. I'm using markdown here with ones.
00:14:28.696 - 00:14:29.300, Speaker B: Okay.
00:14:29.750 - 00:14:50.354, Speaker C: And it's given the transactions in the naive case. And then if the Merkel branches aren't sufficient, then as it executes a transaction, it's going to say, well, I'm touching a state that isn't part of these Merkel branches. The proof you've given to me is insufficient.
00:14:50.402 - 00:14:50.614, Speaker B: Right.
00:14:50.652 - 00:15:18.100, Speaker C: So that means it's not a good proof. So if it executes all the transactions successfully, and then the Merkel branches are sufficient, then at least the fraud proof itself is correct. You don't know if it's correctly formatted. Okay, so essentially what you're doing is you run through all the transactions and you check to make sure is this post date route different. So this works. But there's an issue. What's the issue?
00:15:20.150 - 00:15:21.774, Speaker A: Well, it's heavy.
00:15:21.902 - 00:15:25.198, Speaker C: Well, yeah, it's heavy because you have to execute every single transaction.
00:15:25.374 - 00:15:25.810, Speaker B: Right?
00:15:25.880 - 00:15:27.906, Speaker A: Right. Well, I guess the other issue is.
00:15:27.928 - 00:15:31.686, Speaker C: That access to transactions, you what?
00:15:31.868 - 00:15:33.990, Speaker A: We might not have access to the transactions themselves.
00:15:34.060 - 00:15:38.630, Speaker C: That's part two. So in this case, let's assume that they have full access to the transactions.
00:15:38.710 - 00:15:39.434, Speaker A: I see.
00:15:39.552 - 00:15:52.602, Speaker C: Okay, so this works. But the problem is that, as you said, it's heavy. Executing all the transactions could be expensive, especially in a resource constrained environment like a blockchain.
00:15:52.746 - 00:15:53.102, Speaker B: Right.
00:15:53.156 - 00:16:06.820, Speaker C: So can we do better? The answer is yes. So draw a line. Draw line. So can we do better? The answer is yes. So what we do is, let's see.
00:16:07.990 - 00:16:09.010, Speaker B: Pencil.
00:16:09.430 - 00:16:44.686, Speaker C: So here's our, I can write, here's our transaction route. It's the Merkel tree of some transactions. So here's transaction one. Here's transaction n. There's a bunch of transactions in between. So what we do is we say, well, what happens if after this transaction, I also put inside this tree, I.
00:16:44.708 - 00:16:57.460, Speaker B: Just put some intermediate state root and see how do I select.
00:17:01.750 - 00:17:03.170, Speaker C: Let's move this over here.
00:17:03.240 - 00:17:03.474, Speaker B: Yeah.
00:17:03.512 - 00:17:31.376, Speaker C: So after every single transaction, I'm going to insert an intermediate state route. This is the naive way. You don't have to do it after every transaction. It could be after every some parameter number of transactions. It could be after a certain amount of gas. But in naive case, we say after every transaction. So intermediate state route, add and then you commit to this into a tree.
00:17:31.376 - 00:17:47.064, Speaker C: So instead of a transactions route, now you have a data route. So this is a route of where the leaves are transaction. Then the intermediate state route, after executing this transaction, then the next transaction, then the intermediate state route after executing that one and so on.
00:17:47.182 - 00:17:47.464, Speaker B: Right.
00:17:47.502 - 00:18:24.100, Speaker C: And intuitively that makes sense, because each transaction is a state transition and a block is a group of state transitions. So when we're doing this naive fraud proof over here, let me fix this typo. When we're doing this naive fraud proof, we're essentially doing a state transition, fraud proof, but over a block, we're saying, here's the previous state route, here's the next state route, execute a bunch of state transitions, and then the state routes at the end should not match up. So we can do the same thing. We include a state route after every transaction, and then we do the same process. But instead of executing all the transactions in a block, you just execute one transaction.
00:18:26.040 - 00:18:27.096, Speaker B: Does that make sense?
00:18:27.198 - 00:18:28.632, Speaker A: Yeah, that makes perfect sense.
00:18:28.766 - 00:18:29.304, Speaker B: Yeah.
00:18:29.422 - 00:18:34.660, Speaker C: And then you give exactly what you give here, except instead of a list of transactions, you just give one transaction.
00:18:34.740 - 00:18:34.984, Speaker B: Right.
00:18:35.022 - 00:18:43.848, Speaker C: And then again you just run the transaction through. So this, is there an eraser?
00:18:43.944 - 00:18:48.620, Speaker B: Erase, erase this, yeah.
00:18:48.690 - 00:19:14.224, Speaker C: So this is how you do fraud proofs. So now you brought up a very good point, which is what happens if these transactions here, what happens if the majority miners just hide them? What happens if they just don't show them to anyone, right. They show the block headers. So the block headers are still being sent out and light nodes will still follow the block headers. But no one can actually construct this fraud proof because no one knows what's inside the block.
00:19:14.352 - 00:19:15.028, Speaker B: Right.
00:19:15.194 - 00:19:19.480, Speaker C: And in fact, they don't even know if it's invalid. It could be a valid block, it just hidden.
00:19:20.140 - 00:19:20.696, Speaker B: Right.
00:19:20.798 - 00:20:18.830, Speaker C: So how do we deal with this? And this is where the more involved data availability proofs come in, which is where we're going to probably spend a bit more time. And the existence of data availability proofs is something that the bitcoin research community has generally considered not possible. And that's why they didn't consider fraud proofs possible. Exactly, because of the problem of data withholding. But they are possible with pretty decent guarantees, with pretty weak assumptions, which is what we're going to discuss here. Data availability proofs. So this is the data availability proof scheme that was formalized by Mustafa Abassam and Alberto Sacini, I think, and Vitalip Buterin in a paper, I think around September 2018, or I think around September 2018 or October 2018, somewhere around there.
00:20:18.830 - 00:20:55.560, Speaker C: But the idea of doing these fraud and data availability proofs last formally has been around for a bit longer. So this is the scheme that we're going to be using at lazy ledger. It's also the scheme that is used for serenity or that has been proposed for serenity. So how does it work? So let's start with kind of the most naive way. So this one here is going to be like a straw man. The most naive way, right? Straw man data availability scheme. So this is like, as naive as you can imagine.
00:20:55.560 - 00:20:57.770, Speaker C: But what we're going to say is.
00:20:59.980 - 00:21:01.620, Speaker B: Let'S draw a rectangle.
00:21:01.780 - 00:21:11.004, Speaker C: Let's take the block, right? Let's say this is the block. I'm going to draw it out in a nice rectangle so that we can chunk it up and stuff.
00:21:11.202 - 00:21:11.660, Speaker B: Okay?
00:21:11.730 - 00:21:14.990, Speaker C: So let's say I chunk it up into.
00:21:16.980 - 00:21:23.888, Speaker B: Eight pieces, like so. Is there a way for me to.
00:21:23.894 - 00:21:25.330, Speaker C: Copy this by any chance?
00:21:27.220 - 00:21:28.048, Speaker A: Let's see.
00:21:28.134 - 00:21:30.516, Speaker B: Select, select.
00:21:30.698 - 00:21:32.336, Speaker C: I can copy.
00:21:32.528 - 00:21:33.220, Speaker A: Nice.
00:21:33.370 - 00:21:34.260, Speaker B: Paste.
00:21:35.000 - 00:21:35.824, Speaker C: This will be useful.
00:21:35.872 - 00:21:40.164, Speaker B: Let's put this over. Let's put this over here.
00:21:40.282 - 00:21:59.710, Speaker C: I'll need this later. Let's consider this to be our block. You have all the block headers, but you don't have the block bodies, right? So let's consider this to be the block body, right. Of one of our blocks. So what you could do is you can say, well.
00:22:03.440 - 00:22:04.632, Speaker B: Let'S use blue.
00:22:04.696 - 00:22:50.312, Speaker C: Blue is a good color. I'm going to randomly sample, like, I'm a light node. This doesn't really apply to full nodes again, because full nodes fully download blocks, right? They don't have a problem with data withholding. If they see a block doesn't have a block body, then they say, okay, there's an invalid block, I reject it. So this is really only for the purposes of light nodes, right? So how can a light node convince itself that the data is available? So the light node can say, well, I don't want to download the full block, because that would make me a full node. So what I'm going to do is I'm going to download just a small portion of the block, right? And let's say there's eight transactions in this block, right? If there are eight transactions in this block, and let's say the node randomly samples three. The light node.
00:22:50.312 - 00:23:26.932, Speaker C: So it's going to sample this one and let's say this one and then this one, right? It just randomly samples three. This is, again, this is the naive case, right? But now, what happens if the attacker, let's say there's a guy here with horns because he's an attacker, right? The attacker hides just this one transaction. If he hides just this one transaction, then a light node that does this data availability check has convinced itself. Yes. Okay, I checked these three transactions I've been given them, they seem to be valid transactions.
00:23:26.996 - 00:23:27.610, Speaker B: Right.
00:23:28.540 - 00:24:19.880, Speaker C: Therefore I assume the block data is available, right? And other light nodes do this too. The chance that a light node asks for this one transaction and doesn't get it because the hacker is trying to hide this, the chance that it lands on this would be three out of eight or whatever, right, which is in this case, we're using a very large number. It's like you're sampling half the block, but imagine that you sample, let's say it's 1000 transactions and you sample five. Then in that case you can see the probability that a light node finds that this thing here is being hidden is very small. So this is not a great scheme because the attacker can, they only need to hide one transaction. In fact, they only need to hide one byte, right. They just need to hide one thing and then the entire block.
00:24:19.880 - 00:25:02.500, Speaker C: If it's hidden, then you can't show that this transaction is invalid if it's hidden. If you don't know what the transaction is, right. You can't construct one of these state transition fraud proofs, because one of the point of the fraud proofs is you need to execute a transaction. If the transaction is hidden, you can't execute it. This generally is not a great scheme because the chance that a light node will actually find out that part of this block is hidden is very small. So we want something better. So how do we do it? Let's do b, let's use razor coding.
00:25:02.500 - 00:25:25.790, Speaker C: And again we'll make this naive. Or I guess I could say, we can say one d, one d naive. So let me scoot this over a bit. Let me copy this because we'll need it again.
00:25:29.180 - 00:25:39.544, Speaker B: And move this here. Okay, so what we're going to do.
00:25:39.582 - 00:26:18.870, Speaker C: Now is we're going to use a razor coding. So the way razor coding essentially works is that with all it uses math, which we're not going to cover here, but essentially you can think of it like, let's say these four are the original data that I have, just these four. What I can do is I can actually compute some parity shares. So here's my original data. Original data. And here's the parity. So I'm given this original data, I'll compute some parity data.
00:26:18.870 - 00:26:40.584, Speaker C: And how much parity data you get is dependent on some parameter. You can change this. In this case, as you can see, it's one to one. It doesn't have to be one to one, it can be different. But essentially you have this original and parity data now, right? So as you can see, you're getting more data. So this is bigger. The original data is four chunks.
00:26:40.584 - 00:27:30.440, Speaker C: The parity data is also four chunks. So in total you have eight chunks. And depending on your parameter choice, essentially what this gives you is if you can recover four chunks out of these eight, any four, you can recover the original data. And of course, you can also recover the parity data because you just recompute the parity data. So this seems like it kind of solves our problem, because now you no longer have the problem of the straw man scheme over here. Up here. The straw man scheme, again, is that an attacker could just hide one of these chunks over here, one of these transactions, and the light node would have to specifically request that transaction, right? Otherwise it wouldn't know that something is being hidden.
00:27:30.440 - 00:27:44.188, Speaker C: In this case, if you have this, let's say you have this example where you have four and four. How many of these chunks does an attacker have to hide to be able to hide the block?
00:27:44.284 - 00:27:45.664, Speaker A: Yeah, they need to hide five.
00:27:45.782 - 00:27:46.736, Speaker C: They need to hide five.
00:27:46.758 - 00:27:46.896, Speaker B: Right?
00:27:46.918 - 00:28:29.208, Speaker C: If they hide three, it doesn't matter which three they hide. If they still broadcast the other five, then, or let's say they even hide four and they broadcast the other four, it doesn't matter which four they broadcast, the entire block can be reconstructed, right? The original data can be reconstructed, and from there, we can also recompute the parity data. So in the entire thing. So they need to hide more than half. In this simple example, it's five, right? So we're going to draw that out, let's say, in red, right? So an attacker hides five. An attacker hides these five shares, right? And I didn't draw that properly. Let's undo this one.
00:28:29.208 - 00:28:38.192, Speaker C: Attacker hides 1235, like this. That's better. So an attacker hides five, they broadcast out the other three.
00:28:38.246 - 00:28:38.850, Speaker B: Right?
00:28:39.320 - 00:29:23.072, Speaker C: Now, here's kind of where some of assumptions come into place. So one thing that's important is we assume that there's at least one honest full node in the network that the light nodes can connect to. And we assume that they can communicate with each other. So there's no eclipse attack. The reason this is important is that if the light nodes and the full nodes can't talk to each other, then the full node can't even construct a fraud proof, right? So the light nodes sample stuff, but there's no fraud proof or anything. And then what are you doing? Right, so we do make that network assumption. So what this means is essentially if the attacker broadcasts out any share, we assume that the entire network is eventually going to hear of that share.
00:29:23.072 - 00:29:28.188, Speaker C: It might take a bit of work, but we assume that the entire honest network will eventually hear of that share.
00:29:28.294 - 00:29:28.852, Speaker B: Right?
00:29:28.986 - 00:30:20.624, Speaker C: So they can't hide, say these two over here for one full node and then these three for the other full node, and then for another full node hide these five. They very much have to hide the same five, right? Okay, so we have, say this construction. So now a light node comes along and the light node does some samples, right? So the first time it samples, it will get tricked that the data is available if it lands on an available chunk, right? Like if a light node samples this chunk here, then it says, okay, that chunk is available. I've been given it. Right. I guess one thing to make clear is this erasure coded version of the chunks of original and parity data gets committed to in the block header, right? Yeah, there's a Merkel route. So we merkelize this.
00:30:20.624 - 00:30:25.456, Speaker C: Obviously if you just have the data floating around, then light node samples, it doesn't know what it's sampling.
00:30:25.488 - 00:30:25.684, Speaker B: Right?
00:30:25.722 - 00:30:43.528, Speaker C: Okay, so when a light node samples this chunk here, it has to get a merkel proof from the block header to the trunk. Just so we're clear. So if a light node samples this trunk, it says, okay, this trunk is available. So if it stops there, then it would be convinced that the block is available and it would have gotten tricked.
00:30:43.624 - 00:30:43.884, Speaker B: Right?
00:30:43.922 - 00:30:49.660, Speaker C: So the first time on samples, what's the approximate probability that it got tricked?
00:30:50.880 - 00:30:53.390, Speaker A: It will get tricked with a three over eight, right?
00:30:54.640 - 00:30:58.910, Speaker C: Yeah, sure. Let's simplify that a bit.
00:31:00.320 - 00:31:02.350, Speaker A: Well then parity minus one over total.
00:31:03.140 - 00:31:08.020, Speaker C: Parity minus one over total. Let's assume that the large number of chunks, it'll be approximately.
00:31:09.800 - 00:31:11.268, Speaker A: Yeah, then one half.
00:31:11.354 - 00:31:12.244, Speaker C: Yeah, one half.
00:31:12.282 - 00:31:12.436, Speaker B: Right.
00:31:12.458 - 00:31:42.120, Speaker C: Because we assume a large number of chunks. Great. So round one, round one, you have the probability b is approximately half, right? Okay, so now it does a second round of sampling, because you don't stop there. One round of sampling is pretty terrible. So it does a second round of sampling without replacement. So what's the approximate probability that it has gotten tricked?
00:31:42.200 - 00:31:44.736, Speaker A: After K rounds? It's going to be one over two to the k, right?
00:31:44.838 - 00:31:45.104, Speaker B: Yeah.
00:31:45.142 - 00:31:55.872, Speaker C: So it's one quarter with around n or k. Sure. P is one over two to the k, you say?
00:31:55.926 - 00:31:56.432, Speaker B: Right.
00:31:56.566 - 00:32:11.480, Speaker C: So as you can see, the probability of it getting tricked decreases exponentially. And one thing that's interesting to note here, this probability decreasing of getting tricked, is it in any way related to the number of chunks?
00:32:14.300 - 00:32:18.344, Speaker A: Well, it is important that parity is one to one with original data, right?
00:32:18.382 - 00:32:25.172, Speaker C: Oh yeah. We assume the system parameter is set up, that the parity and original data are one to one.
00:32:25.326 - 00:32:46.050, Speaker A: Yes. Well, there are a couple of things. So one is if you assume that the number is sufficiently large, right? So 1 second is a good estimate, then it should be independent of the number of chunks. But also, I guess something we didn't touch on is we assume that the adversary decides on what to reveal in advance, right? Which I guess it doesn't have to.
00:32:47.540 - 00:32:58.324, Speaker C: Well, again, is that we assume that the network is set up, that if a chunk is distributed to an honest full node, it will get distributed to all honest full nodes eventually, right?
00:32:58.362 - 00:33:14.350, Speaker A: But if I'm a light node, right, and I'm sampling and I just happen to be connected to several non honest nodes, right, I will start sampling, and the adversary, as they receive my request for a share, they will decide to reveal it, right?
00:33:15.600 - 00:33:18.984, Speaker C: We assume that the light nodes are connected to a full node, an honest full node.
00:33:19.112 - 00:33:46.624, Speaker A: I see. And we're also saying that if the. So, then I guess one assumption we did not discuss is let's say I'm a light client. I'm a light node. I'm connected to, let's say a dozen, twelve full nodes, right? So I chose to sample a particular share, and I chose a particular full node to sample it from. So if I fail to sample it from it, what do I say? Do I say that the date is unavailable, or do I try to sample it from another full node?
00:33:46.752 - 00:33:50.532, Speaker C: You continue trying until some parameterizable timeout, right?
00:33:50.586 - 00:33:59.770, Speaker A: So therefore, if I'm connected to any full node which is controlled by adversary, eventually I will sample all my shares from that adversary. Adversarial node, right? And so adversary can choose.
00:34:02.460 - 00:34:10.652, Speaker C: Sure, but the shares, well, we assume the light nodes aren't under eclipse attack. If they're connected to at least one honest full node, then they're not under an eclipse attack, right?
00:34:10.706 - 00:34:55.864, Speaker A: But in this case, I'm saying, let's say I'm connected to exactly one malicious node and everybody else I'm connected to is a full node which is honest, right? So I'm saying I want to sample, let's say the parameter is five, I want to sample five shares out of 1000, right? So I go to the full nodes and let's say that the, so the way I see it is adversary first sends me the hash of the block, right? So at this point, from someone, I heard that the block exists. Other full nodes haven't heard about it yet. So I start sampling the shares and all other full nodes. Tell me, well, I don't know the block, I'm not going to tell you the share. So I keep on retrying and I end up trying to download it from the malicious node. And malicious node at that point decides for the first time to reveal the particular share. Right.
00:34:55.864 - 00:35:15.010, Speaker A: So maybe it will not be able to trick all the light client because all the light clients collectively will probably hit all the shares, but it will be able to trick one particular one. So let's say it wants to trick Coinbase, right? So there's specifically where Coinbase is. Coinbase goes and samples, and ultimately Coinbase ends up sampling from the adversary, and adversary reveals specifically the shares Coinbase wants to see.
00:35:15.700 - 00:35:21.220, Speaker C: So we also assume a network model where queries can be made anonymously.
00:35:21.880 - 00:35:22.500, Speaker B: I see.
00:35:22.570 - 00:35:40.052, Speaker C: As in you can't associate who is making the query. In practice, the reason that this is an okay assumption, even if you don't use things like Torrent and whatnot, is that say Coinbase, they can run two full nodes or they can run 100 full nodes. And you might know one full node as coinbases, but you don't know all of them are operated by a single entity.
00:35:40.196 - 00:35:45.332, Speaker A: Yeah, well, behind the scenes, right. We're checking the light client will not be running a light client.
00:35:45.396 - 00:36:07.856, Speaker C: Well, they wouldn't be running a light client. Right. But like an end user is like an end user. Okay, they run one light client, but how do you know they're not running two light clients, one on their phone and one on their computer, that belong to the same person? And the two nodes can communicate with each other off chain. And the human is essentially a very good way of having private communication between two computers.
00:36:07.968 - 00:36:08.630, Speaker B: Right.
00:36:10.680 - 00:36:16.550, Speaker C: It's pretty hard for a computer to spy on human typing in a keyboard here and then typing in a keyboard there.
00:36:17.400 - 00:36:21.868, Speaker A: Okay. So with those assumptions, because I see you have the third one drawn.
00:36:21.904 - 00:36:22.056, Speaker B: Right?
00:36:22.078 - 00:36:34.076, Speaker A: So we are about to find out something bad about this model. Yeah, not at all obvious to me. What is wrong with it, with the assumptions we discussed. So I'm excited to hear what is.
00:36:34.098 - 00:36:57.616, Speaker C: It we will, because this is this that I invoke. Yeah. So there's kind of a few interesting things to note. The chance that a light node can be tricked is completely independent of the block size. What this means is the number of rounds you need to do is constant. It is not big o of n where n is the block size. It's not big o of some function of n.
00:36:57.616 - 00:37:05.204, Speaker C: It's big o of one with respect to the number of transactions in the block. Or the number of bytes, the number of gas, whatever you want.
00:37:05.242 - 00:37:05.830, Speaker B: Right.
00:37:06.360 - 00:37:36.556, Speaker C: This is constant, which is pretty amazing. Because it means that you just have to do a constant number of samples. And each of these sampling operations is logarithmic in the size of the block. It's a Merkel branch to the particular share. Right? So this is a very cheap operation, which is great. But now here's kind of where the problem is. Let's say I have one light node, right? I have one light node.
00:37:36.556 - 00:37:54.656, Speaker C: The light node samples three shares, right? Well, this example is bad because the number of shares is pretty small. Right. Let's say the light node samples two shares. Again, this is a small number, so it makes things a little disproportionate. But those are light node samples two shares.
00:37:54.848 - 00:37:55.590, Speaker B: Right?
00:37:57.240 - 00:38:11.096, Speaker C: So let's say pencil. Let's use green, right. So let's say the light node samples this share, right? And in fact, the light node could sample this share, right?
00:38:11.278 - 00:38:11.864, Speaker B: Okay.
00:38:11.982 - 00:38:29.584, Speaker C: You just have one light node. I realize green is a terrible color choice. Because maybe a non trivial number of our viewers are red, green and colorblind. But these x's here are green. So the light node samples these two shares just as light node. And there's not a single other node in the network, let's say.
00:38:29.622 - 00:38:29.968, Speaker B: Right.
00:38:30.054 - 00:38:50.772, Speaker C: Or this could be the full node, right? Because we assume there's one on its full node. So the full node tries its best to. By asking the network. And everyone around the full node tries to reconstruct the whole data somehow. If it can't directly download the original data. It has to ask the network for the shares individually. But it should be able to reconstruct a block.
00:38:50.772 - 00:39:09.100, Speaker C: So let's say this full node is out there making requests. And it downloads these two. So this is what it gets. Can we reconstruct a block using only these two shares?
00:39:10.000 - 00:39:10.748, Speaker A: No.
00:39:10.914 - 00:39:11.244, Speaker B: Right.
00:39:11.282 - 00:39:12.860, Speaker C: Because you need four shares.
00:39:13.840 - 00:39:14.540, Speaker B: Yeah.
00:39:14.690 - 00:39:35.510, Speaker C: So the problem is that even if we fix this. Let's say we set our k to two at some fixed number. Okay? So you have a light client or a full node or whatever. They download these two. There's no guarantee that you'll be able to reconstruct a block. If only one client does these requests, right?
00:39:35.880 - 00:39:41.364, Speaker A: Right. But wouldn't full node. The full node will try to fetch all the shares, right?
00:39:41.402 - 00:39:41.604, Speaker B: Yes.
00:39:41.642 - 00:39:43.136, Speaker C: The full node will try to fetch all the shares.
00:39:43.168 - 00:39:43.652, Speaker B: Yes.
00:39:43.786 - 00:39:50.036, Speaker C: But the problem is, okay, the full node does. But the full node can't really prove to a live client that it hasn't been able to fetch all the shares.
00:39:50.148 - 00:40:04.664, Speaker A: Right. So the way I see it so far is that the block could either be available, meaning that it did broadcast so effectively. Let's go through the timeline.
00:40:04.712 - 00:40:04.924, Speaker B: Right.
00:40:04.962 - 00:40:17.260, Speaker A: So the block was published for the first time, because we assumed that if some message was sent over the network, it will eventually reach everybody. So eventually everybody learned that the block was at least announced, meaning that the header was announced.
00:40:17.340 - 00:40:17.632, Speaker B: Yes.
00:40:17.686 - 00:40:44.088, Speaker A: So after that, everybody will attempt to sample some shares. And again, we're saying that if some share was published on the network, eventually everybody who tried to sample it will be able to receive it. So with this assumption, it seems to me that with a sufficiently large key for every available block, every light client and every full node in the system will know that it's available. And moreover, the full node will actually reconstruct it, because full nodes will attend. No?
00:40:44.174 - 00:40:59.724, Speaker C: So they can convince themselves it's available. But there's a problem. You might not be able to reconstruct the original data. Right. In this very nice straw man example, let's say you have exactly one node that's doing these sampling, right? I see the sample, these two shares, one node.
00:40:59.772 - 00:41:03.980, Speaker A: Yes, but even then, is this node a light client or a full client?
00:41:04.060 - 00:41:05.868, Speaker C: It doesn't really matter, because if it's.
00:41:05.884 - 00:41:11.404, Speaker A: A full client, it will not try to fetch K shares, it will try to fetch all the shares.
00:41:11.532 - 00:41:14.500, Speaker C: The full node will try to fetch all of them. So let's say it's a light client, right?
00:41:14.650 - 00:41:19.990, Speaker A: But if it's a light client, then there is not a single honest full node in the system.
00:41:21.160 - 00:41:41.512, Speaker C: No, the full node is still honest, it's trying to do its job, but it can't. So there's no other assumption here. The reason it's confusing is because there's no other assumption, which is what we're going to talk about. So let's say you have one honest phone node that's trying to do its work, and you have one like client. Like client samples these two shares, it sees they're available, and these are the only two shares that are distributed.
00:41:41.576 - 00:41:42.044, Speaker B: Right?
00:41:42.162 - 00:41:52.048, Speaker A: But sorry for interruption, but consider the following model, right? Let's say that the full client will not distribute any shares until it has the full block, right? So if the full node does not.
00:41:52.054 - 00:41:57.152, Speaker C: Have full block, the full node should still distribute shares, even if it's only seen a few of them.
00:41:57.206 - 00:41:57.810, Speaker B: Right?
00:41:59.860 - 00:42:04.704, Speaker A: But let's say we're changing the model, right? We're saying the full node will not be distributing shares until it has the full block.
00:42:04.752 - 00:42:04.996, Speaker B: Oh no.
00:42:05.018 - 00:42:13.960, Speaker C: But that would be terrible because then full nodes would never be able to reconstruct a block unless they've been given a full block. So full nodes can obviously gossip individual shares.
00:42:14.300 - 00:42:18.840, Speaker A: The full nodes can gossip individual shares.
00:42:19.980 - 00:42:36.830, Speaker C: Like if the only way a full node would be able to broadcast anything outwards is if it received a full block, that means an attacker could just not ever show a full block and only give out individual shares. And then full nodes would never send an outgoing message. Right.
00:42:37.280 - 00:42:57.248, Speaker A: Of course you cannot break every like, it will not be a productive time if you will be breaking every my model. So let's do the last one and then we will proceed with the full nodes. Always send they regosip to other full nodes, but they would not respond to light clients unless they have all the shares.
00:42:57.344 - 00:42:59.124, Speaker C: They can also respond to light clients too.
00:42:59.242 - 00:42:59.524, Speaker B: Right?
00:42:59.562 - 00:43:02.090, Speaker A: But I'm saying, how will it break? Right?
00:43:02.700 - 00:43:26.892, Speaker C: No, I think the reason is that the assumption seems very obvious. So can I go through the assumption? Yes, and then when I say it, it'll seem very obvious because you're like, oh, obviously this happens in practice. So the attack is very contrived. But it's still an assumption that we have to make because we have to make all our assumptions. Let's assume there's one full node and there's one, like client. Like client samples, these two shares. This is bad.
00:43:26.892 - 00:43:50.920, Speaker C: I shouldn't put this here. I should say sample this share. And then let's erase this just so we don't get confused. The like client samples, these two shares. It sees that these two shares are available, right? And let's say this is imaginary world. There's one like client samples, these two shares, they're available, right? And then the full node tries to reconstruct the block. Also seeing the full node can also only see these two shares.
00:43:50.920 - 00:43:57.960, Speaker C: So the light client is convinced that the block is available, but the full node can't reconstruct the block.
00:43:58.940 - 00:43:59.304, Speaker B: Right?
00:43:59.342 - 00:44:00.216, Speaker C: And that's the problem.
00:44:00.318 - 00:44:00.680, Speaker A: Right.
00:44:00.750 - 00:44:16.880, Speaker C: But now what happens if we have like 100 like clients? 100 like clients. Each sample two. So maybe one samples these two. One samples these two. One samples these two, and so on. And then if the block isn't being hidden, then a full node can reconstruct it by asking around for the shares.
00:44:17.220 - 00:44:17.824, Speaker B: Right?
00:44:17.942 - 00:44:23.276, Speaker C: So the trick is we assume there's a minimum number of light clients that are making these requests.
00:44:23.388 - 00:44:24.000, Speaker A: I see.
00:44:24.070 - 00:44:35.776, Speaker C: And this numbers can be fairly small. The paper gives numbers, I think around 100 or something. So it's a very weak assumption. Obviously in practice, for any reasonably sized network, you're going to have 100 nodes.
00:44:35.888 - 00:44:36.212, Speaker B: Right.
00:44:36.266 - 00:44:51.756, Speaker C: Especially light nodes. So this isn't a very strong assumption, but it is something that we have to point out is that you do need a certain number of nodes proportional to the block size doing this random sampling. Does that make sense?
00:44:51.858 - 00:44:52.956, Speaker A: Yeah, that makes sense.
00:44:53.058 - 00:44:53.710, Speaker B: Yeah.
00:44:54.320 - 00:45:12.752, Speaker C: So that's why I was confusing, because it is kind of a contrived thing that doesn't really happen in practice. So assumption here, assumption, some number of light nodes. And we note that this is going to be proportional to block size.
00:45:12.886 - 00:45:13.570, Speaker B: Right.
00:45:14.020 - 00:45:28.820, Speaker A: Right. And so is it specifically the number of light client nodes or is it the number of light or full nodes which are honest in the network? So let's say have that many full nodes but not a single light client, will it work? Or we specifically need that many light clients.
00:45:29.880 - 00:45:35.156, Speaker C: If you have this number of full nodes also doing, they can pretend to be like clients and do these requests.
00:45:35.188 - 00:45:35.752, Speaker B: So. Sure.
00:45:35.806 - 00:45:39.770, Speaker C: Number of notes, we can simplify this. Like number of nodes, really.
00:45:40.780 - 00:45:42.388, Speaker A: Number of honest nodes.
00:45:42.564 - 00:45:44.970, Speaker C: Oh yeah, of course. This is honest.
00:45:45.980 - 00:45:48.664, Speaker B: Number of honest nodes. Yeah.
00:45:48.702 - 00:45:58.544, Speaker C: Okay, great. So now why doesn't this work? Why is this an age game? Also, it seems to be we're running a bit out of time from the schedule. Is that an issue?
00:45:58.662 - 00:45:59.680, Speaker A: No, that's not an issue.
00:45:59.750 - 00:46:49.520, Speaker C: Oh yeah, perfect. I have some time. What's the issue? The issue is if this is erasure coded correctly, then we can do all this. But what happens if this is not erasure coded correctly? What happens if the block producer just doesn't? They either don't erase or code it correctly or they commit to something incorrect. Because again, this has to be committed to in some Merkle route. You merkleize all these shares, what happens if they just don't commit to it correctly? In that case, you can't do this, right? Or rather even if you do this and then you know the block is available, you might not be able to reconstruct the data nicely. So what you have to do is if the razor coding is incorrect, you need a fraud proof.
00:46:49.520 - 00:47:00.310, Speaker C: So how do I prove that these parity shares are not correct based on the original data? How would I prove that?
00:47:01.800 - 00:47:06.384, Speaker A: So here you would have to share at least four shares.
00:47:06.432 - 00:47:06.980, Speaker B: Right?
00:47:07.130 - 00:47:14.600, Speaker C: Let's assume that they can reconstruct the data. Yeah, let's assume that they reconstruct the data. So a full node reconstructs the whole thing, right?
00:47:14.750 - 00:47:17.610, Speaker A: I'm saying the proof would have to be the size of the number of.
00:47:18.700 - 00:47:19.064, Speaker B: Yes.
00:47:19.102 - 00:47:53.264, Speaker C: Right. So the proof is essentially, the proof is essentially you give the entire original data and you give the parity shares, or you give the Merkel root and the original data or four of these, and then you just say, okay, compute the parity shares, and then you'll see that the Merkel root doesn't match up. So the problem is that a fraud proof of this, that this has been computed incorrectly, is the whole data, which know this, basically saying, just download the full block and then you can see that the parity shares haven't been computed correctly, which is exactly what we're trying to avoid.
00:47:53.312 - 00:47:53.524, Speaker B: Right.
00:47:53.562 - 00:48:05.304, Speaker C: We're trying to avoid having to download the whole block because light nodes are resource constraint. What do we do? So this is where the 2d scheme comes in.
00:48:05.342 - 00:48:11.530, Speaker B: So see, this is razor coding two d.
00:48:15.580 - 00:48:20.670, Speaker C: I realize that this thing here is probably not useful anymore, so I can probably erase it.
00:48:21.760 - 00:48:24.476, Speaker A: We can replicate it seven times.
00:48:24.658 - 00:48:32.560, Speaker C: I could, but it would probably be way too big. So let's do a smaller table.
00:48:33.860 - 00:48:37.076, Speaker B: Let's do like, oops, let's drag this.
00:48:37.098 - 00:48:43.572, Speaker C: Down, let's do a square and then.
00:48:43.706 - 00:48:44.900, Speaker B: Some lines.
00:48:48.670 - 00:49:19.506, Speaker C: And this is it. So what we're going to do is we're going to arrange our original data in rows and columns. So instead of being just like a single list, a single array, we're going to arrange it in rows and columns. So this thing here is our original data. So what we're going to do is for each row, we're going to compute the parity shares for that row. So we extend it this way.
00:49:19.528 - 00:49:19.666, Speaker B: Right.
00:49:19.688 - 00:49:32.010, Speaker C: So here's the parity shares off this row. There's supposed to be lines here, but I'll not draw them for simplicity. So again, for this row, we compute the parity shares and so on. Now, for each column, we're also going to compute the parity shares of this column.
00:49:32.830 - 00:49:34.906, Speaker B: This. Right.
00:49:35.088 - 00:49:48.794, Speaker C: And then you can do this, the third square if you copy one of these two, or if you compute parity shares this way, it doesn't really matter. Right. This is kind of an implementation detail, but this is also going to be some sort of parity shares.
00:49:48.842 - 00:49:49.440, Speaker B: Right.
00:49:50.050 - 00:50:03.106, Speaker A: What is important mentioning here, which is obvious for people with the background in math, but it is not as obvious otherwise, is that it doesn't matter how you compute this fourth square, whether you erasure code columns or erasure code rows, you will get the same values, right?
00:50:03.208 - 00:50:03.954, Speaker B: Yeah.
00:50:04.152 - 00:50:14.680, Speaker A: Like a particular value. Yeah. So that is not immediately obvious. I guess it requires understanding of some math behind.
00:50:15.050 - 00:50:15.366, Speaker B: Yeah.
00:50:15.388 - 00:50:43.200, Speaker C: But ultimately this doesn't matter. What really matters is that as long as everything is a parody in some way, then that's all that matters. So even if it were different, it wouldn't matter. You just say, this is the direction I choose, essentially. So this is your original data. So we note that the 1d scheme, our parity shares are twice as big as our original data, right here. Our parity shares are three times as big as our original data.
00:50:43.200 - 00:50:53.410, Speaker C: So each of the side here is like square root of block size. Square root of block size. So the length of this big square would be two square root of block size and two square root of block size.
00:50:53.560 - 00:50:54.210, Speaker B: Right.
00:50:54.360 - 00:51:09.226, Speaker C: So let's type this out. So this one here is, this one is square root n. Let's say n is our block size, right. This one here is also square root, n is also square root n. And this one here is also square root.
00:51:09.248 - 00:51:09.980, Speaker B: Of n.
00:51:11.790 - 00:51:14.346, Speaker C: So in total, the length of these things is two square root.
00:51:14.368 - 00:51:15.100, Speaker B: Of n.
00:51:17.310 - 00:51:24.910, Speaker C: And then what we're going to do is we're going to commit to a Merkel root for each row and each column.
00:51:26.130 - 00:51:27.390, Speaker B: So in total.
00:51:27.540 - 00:51:51.798, Speaker C: So with this one here, we just need one Merkle root. We just take these and we just mercurialize them, right? So one Merkle root here, we need a mercury root for each row and each column. So in total, our commitment here is going to be two times two times two square root of n. Right, because this is two square root of n. And then we have two of these.
00:51:51.884 - 00:51:52.520, Speaker B: Right?
00:51:53.210 - 00:51:55.058, Speaker C: So in total it's four square root.
00:51:55.074 - 00:51:55.800, Speaker B: Of n.
00:51:59.050 - 00:52:39.582, Speaker C: Four square root of n. So this is our commitment size. So this one here needs to go into the block header. Now we can have like a super compact commitment where you mercalize this so you can kind of represent it as in two stages. But ultimately nodes that want to do these data availability checks need to download this four square root of n commitment or commitments. So what this means is that this does increase the size of the block header. It means that now the block header has some overhead that's proportional to the square root of the block size as opposed to just being constant sized.
00:52:39.726 - 00:52:40.130, Speaker B: Right.
00:52:40.200 - 00:53:13.230, Speaker C: And it's assumed that all light nodes will have to download this again, the super light nodes can just download the Merkle root of the ease and not do data availability checks and just trust an on up majority. But the secure light clients that do data availability checks will need to download this four squared event commitment. Okay, great. So now that we have this, how many shares does an attacker have to hide to prevent someone from reconstructing the original data and therefore the full block. Approximately.
00:53:13.990 - 00:53:14.402, Speaker B: Okay.
00:53:14.456 - 00:53:24.526, Speaker A: So approximately it will be. So to reconstruct everything, we need approximately n, right, of those little shares.
00:53:24.558 - 00:53:29.720, Speaker C: Yeah, that's true. To reconstruct everything you need around n. Yeah. Where n is the block size.
00:53:30.250 - 00:53:36.806, Speaker A: Right. So I will need to hide three n. Wait, or do I need to hide n?
00:53:36.988 - 00:53:41.930, Speaker B: You need to hide n. So n is sufficient.
00:53:44.270 - 00:53:45.798, Speaker C: N is confusing. We can use ratios.
00:53:45.814 - 00:53:46.090, Speaker B: Right.
00:53:46.160 - 00:53:48.330, Speaker C: Here the attacker hide half plus one.
00:53:48.400 - 00:53:48.874, Speaker B: Right?
00:53:48.992 - 00:53:51.994, Speaker A: Yes. Here they need to hide three four plus one.
00:53:52.032 - 00:53:52.330, Speaker B: Right.
00:53:52.400 - 00:53:53.626, Speaker A: Or like three four plus.
00:53:53.728 - 00:54:01.166, Speaker C: They don't have to hide for three four. They have to hide. Let me draw the rectangle in red. They have to hide this much.
00:54:01.268 - 00:54:01.582, Speaker B: Right.
00:54:01.636 - 00:54:04.078, Speaker C: So it's one quarter plus one.
00:54:04.244 - 00:54:06.080, Speaker A: Oh, yes, that's correct.
00:54:06.690 - 00:54:16.766, Speaker C: And what we can see is that if they hide, let's say this is eight, right? If they hide five from this row, you can't reconstruct the row. If they hide five from this row, you can't reconstruct the row and so on from the columns.
00:54:16.798 - 00:54:17.234, Speaker B: Right.
00:54:17.352 - 00:54:27.970, Speaker C: But if they didn't hide these, if they left, they left you a bit here. If they revealed this one, then you could compute the whole column, and then from that, then you can compute the rest one by one.
00:54:28.140 - 00:54:28.522, Speaker B: Right.
00:54:28.576 - 00:54:54.240, Speaker C: So they kind of have to hide this for a large enough number. Now, if you have a light node, and then it starts randomly sampling here. Here. For each round, we'll do the same as before. So here's round one. What's the probability that a light node has been tricked? That the data is available, but it's not?
00:54:55.650 - 00:54:58.400, Speaker A: It's one quarter. Right.
00:55:00.610 - 00:55:05.330, Speaker C: A light node will get tricked if it lands on something that's being disclosed.
00:55:05.930 - 00:55:06.198, Speaker B: Yeah.
00:55:06.204 - 00:55:15.240, Speaker C: It's going to be three quarters. So our round two tries to sample again. What's the probability now?
00:55:16.570 - 00:55:17.794, Speaker A: 916.
00:55:17.922 - 00:55:21.674, Speaker C: Yeah. Nine over 16. Right. So you keep going.
00:55:21.712 - 00:55:22.394, Speaker B: Right.
00:55:22.592 - 00:55:52.130, Speaker C: So we see it doesn't decrease as sharply as the previous time, but it does still decrease exponentially, which is good. So you need to do more rounds of sampling to get the same guarantees. But it means you get a better guarantee elsewhere. So what's a better guarantee elsewhere? If we have to prove that the whole thing is erasure coded incorrectly. Note that we only have to prove that a single erasure coding computation was done incorrectly.
00:55:52.470 - 00:55:52.978, Speaker B: Right.
00:55:53.064 - 00:55:57.478, Speaker C: Which means a fraud proof is now a single row or a single column in size.
00:55:57.644 - 00:55:59.494, Speaker B: Right? Yeah.
00:55:59.532 - 00:56:01.314, Speaker A: Do we agree, which is just square root?
00:56:01.362 - 00:56:01.958, Speaker B: Yes.
00:56:02.124 - 00:56:11.210, Speaker C: So now the fraud proof would be two square root of n as opposed to being. Opposed to being n with the size of the original data.
00:56:11.280 - 00:56:11.466, Speaker B: Right.
00:56:11.488 - 00:56:48.014, Speaker C: So fraud proof is big o of square root n, where n is our block size. Right over here up top, the nave scheme. The fraud proof is big o of n. So this is kind of where we see, the amazing thing is that we now have a fraud proof that's sublinear in size. And again, you only have to broadcast this Fraud Proof out if there's a fraud proof in the happy case, the only thing you need to download is this commitment and then a fixed number of samples, a fixed number of sampling.
00:56:48.062 - 00:56:48.660, Speaker B: Right.
00:56:51.450 - 00:57:02.940, Speaker C: This is kind of the Nice Property is that the number of samplings you have to do is fixed. It's not related to block size at all. So how would you increase, let's say.
00:57:03.390 - 00:57:13.326, Speaker A: While the number of samplings is not related to the size of the block, the light header now is important to the square root, right?
00:57:13.428 - 00:57:29.054, Speaker C: Yes. So one of the trade offs is the light client headers are larger. So what this means is that if you want to kind of take full advantage of this, you would want to have a smaller number of headers, each of which have larger blocks.
00:57:29.182 - 00:57:29.810, Speaker B: Right.
00:57:29.960 - 00:57:46.582, Speaker C: Which means that generally you'd want to have slightly longer block times than what you would see in some chains that have really fast block times. So instead of going for the 1 second block time, maybe you want to go for the 32nd block time, which will allow you to take more advantage of this factor here.
00:57:46.636 - 00:57:47.240, Speaker B: Right.
00:57:47.850 - 00:58:08.234, Speaker C: So that's one potential downside. But the gains is that you have now secure light clients, which is amazing, because as before, if the two choices are run a full node or have absolutely no security, that's not exactly a very good trade off, especially if you want your base layer to process many transactions where a full node could be potentially expensive.
00:58:08.362 - 00:58:09.134, Speaker A: Right.
00:58:09.332 - 00:58:23.140, Speaker C: So now we have a third choice, which is you can run a like client with data availability proofs and do this with sublinear cost and still be pretty damn secure, so long as there's one honest full node out there, which is a good choice. No one's forced to use this. But now we have this option.
00:58:24.470 - 00:58:28.280, Speaker A: Well, it's one honest full node among our peers, right?
00:58:30.330 - 00:58:31.222, Speaker C: No eclipse attack.
00:58:31.276 - 00:58:31.880, Speaker B: Yeah.
00:58:33.690 - 00:58:47.580, Speaker C: Eclipse attacks are kind of hard to pull off. Maybe not, but it's an assumption. So one thing we note is that if, let's say we want to keep some, we have some security guarantee parameter, right?
00:58:51.710 - 00:58:52.674, Speaker B: Guarantee.
00:58:52.822 - 00:59:04.094, Speaker C: So this is kind of like our guarantee that some fixed fraction of light nodes aren't going to get tricked, right? So this is going to be proportional to the number of rounds.
00:59:04.142 - 00:59:04.834, Speaker B: Right.
00:59:05.032 - 00:59:15.946, Speaker C: Number of rounds that we set as a parameter times the number of nodes doing sampling.
00:59:15.998 - 00:59:16.600, Speaker B: Right.
00:59:20.730 - 00:59:24.690, Speaker C: So as the number of nodes increases, then our security guarantee increases.
00:59:24.770 - 00:59:25.254, Speaker B: Right?
00:59:25.372 - 00:59:25.702, Speaker A: Right.
00:59:25.756 - 00:59:29.238, Speaker C: And as the number of rounds increases, so does our security guarantee, right?
00:59:29.324 - 00:59:33.306, Speaker A: Yeah. Also, I don't see your text until you. There we go.
00:59:33.328 - 00:59:42.890, Speaker C: Now I can see, okay, we have some relationship here. So if we want to keep our security guarantee fixed and we keep the number of rounds fixed.
00:59:42.970 - 00:59:43.600, Speaker B: Right.
00:59:44.050 - 00:59:52.990, Speaker C: Note that if we increase the number of nodes, we can actually increase the block size and have the same guarantees.
00:59:53.410 - 00:59:54.160, Speaker A: Right.
00:59:54.530 - 01:00:18.870, Speaker C: So this is kind of an amazing property that regular, we're not talking about lazy ledger yet, but just this property. We have the amazing property that data availability checking allows you to have the same guarantees for larger blocks as you increase the number of nodes in a regular blockchain. If you execute all the transactions, then, okay, you increase the number of nodes, you don't get more throughput.
01:00:19.030 - 01:00:19.690, Speaker B: Right.
01:00:19.840 - 01:00:26.294, Speaker C: Every node still has to validate every transaction here. Every node doesn't fully check the entire block.
01:00:26.342 - 01:00:26.554, Speaker B: Right.
01:00:26.592 - 01:00:57.826, Speaker C: Every light node only checks the fixed number of samples and download the square root stuff. So as the number of nodes increases, we can have the same security for larger block size, which is a really nice property. Okay, so now kind of the two pieces of the puzzle are together. We have fraud proofs for any arbitrary state transition. And we have a way for light nodes to make sure the data is available so that fraud proofs can be constructed.
01:00:58.018 - 01:00:58.760, Speaker B: Right.
01:00:59.370 - 01:01:35.386, Speaker C: So there's kind of one additional side caveat here. Before we start talking about lazy ledger, which is, note that blockchains always need to check for data availability. You may have heard some people talk about, say, o of one blockchains, where instead of using fraud proofs, you use validity proofs, which is like a succinct cryptographic proof that some computation is valid. And you might think, well, the only reason you need this is for fraud proofs, right? You might say, if you have validity proofs, why do you care if the data is available or not, right? The transactions are valid. The miners can't create a billion coins.
01:01:35.498 - 01:01:39.950, Speaker A: Well, you know that some state is valid. It would be nice to know what exactly is the state that is valid.
01:01:40.030 - 01:02:07.090, Speaker C: That is, the problem is that if a miner block producer in general makes a new block, but doesn't tell anyone what the new state is like. You have a state route, but you don't know what the state is. Essentially, everyone's coins are burned. They can move their coins because they don't know what the state is. So there is no such thing as no of one blockchain. All blockchains to be secure need some way of solving data availability. And that means either have everyone run a full node and actually try to fully download the block.
01:02:07.090 - 01:02:14.954, Speaker C: It means making an honest majority assumption. At which point what's the point of validity? Proof if you're assuming that. Or it means doing these data availability checks.
01:02:15.082 - 01:02:15.326, Speaker B: Right?
01:02:15.348 - 01:02:16.970, Speaker C: So there's no such thing as no of on blockchain.

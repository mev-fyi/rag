00:00:00.960 - 00:00:15.650, Speaker A: Good morning. Okay. All right. Good morning, guys. So we start with intents. Good morning. Okay.
00:00:15.650 - 00:01:06.882, Speaker A: The title of my presentation, intents are proof obligations. The developers guide to the galaxy of intents. All right. Okay, I'll change this. One of the questions I get asked the most is what are the interfaces to build intense engine protocols? And from a developer's point of view, everybody knows intents as the outcome you want to, you want to use for users. But from developers point of view, when you want to build a protocol from scratch, what are the steps? What are the mental models? So these are the objectives. I want to provide the developer focus and mental model for intents.
00:01:06.882 - 00:02:03.030, Speaker A: Answer the question of interface, distributing intents protocols, and then hopefully in the end, I can convince you the intent is not just about execution or I improving the UX. Okay, introduction. I'm co founder of Kalani. Kalani network is the infrastructure platform to build intent driven software networks. That's a lot, but essentially, or building is or software infrastructure. Okay, so if you need to build softwares, instead of building the entire software from scratch, you can build software modules and deploy the software modules to Kalani, the blockchain, and just run the Kalani node. Okay, so our node is going to become your software.
00:02:03.030 - 00:02:53.052, Speaker A: We'll look back to Kalani throughout the presentation, maybe towards the end, but that's, that's a very high level. All right, so let's look at definitions, right? Every time there's a conversation about intents, there's always debate about definition of intents. These are the things I just found online from some of the intent projects you probably have seen. Intent is a message signed by a user to express outcome, right? That's one way of thinking about intent. It's just off chain message. And then the next one I like a lot, right. To say, hey, intent is when you work with Uber and the driving destination, you don't have to tell the driver how to get there.
00:02:53.052 - 00:03:15.474, Speaker A: You want to go to New York? Just say, hey, I want to go to New York. And that's intense. Which kind of makes sense, right? Intuitively makes sense. And finally, this is enormous definition of intense. Credible commitments to preferences and constraints over the space of possible state transitions. Okay, great. But here's the problem.
00:03:15.474 - 00:03:52.282, Speaker A: If you're a developer, you hear this all makes sense, right? You. Oh, I would be an intense entry protocol. How do I go from there? I want to do a Uber. Where do I start? Okay, so this is the. Hopefully I can help you with this with today's presentation. All right, so my favorite way of framing intents is to think from the solvers perspective, okay? Because it doesn't matter how you model the intent as the protocol. In the end of the day, you need solvers, almost by definition, and you have solvers.
00:03:52.282 - 00:04:26.926, Speaker A: You have to tell Solver what they need to do. Okay? So from Solver's perspective, you think about it as your Uber driver, right? That's the software. First you give the driver something to do. You give me a thing to do, right? Then for the driver, I need to make sure you have money to pay me before I take this job. And then I need to figure out how to do it. If I need to drive to New York, I need to know, how can I go to New York? And then I drive you there. And then last, I prove to you that I've done it.
00:04:26.926 - 00:04:56.780, Speaker A: I proved to you, hey, this is New York, not pay me. It's very simple from driver's point of view now, okay? So it give me a thing to do. That's intent expression, right? These are the elements of intents. And then I need, as a driver, I need to make sure you have money. Before I drive you. I need to show you how money my over credit card. I need you to put the money.
00:04:56.780 - 00:05:25.640, Speaker A: I need you to put the money into this save here escrow, right? So that, okay, you have money. If I go to New York, this is how an insurer can pay me, and that is a credit limit. I need to figure out how to do it. That's solving. I need to deliver the outcome to you, and then I do it, okay? Drive you there, feel the intent, and in the end, what is settlement? Settlements saying, hey, here's New York. No, do what you say. You.
00:05:25.640 - 00:06:04.708, Speaker A: This is why you told me, this is why I get paid. And that's settled, right? Settle just means you pay the software. The solver proved to you that they've done what you want them to do, and then you pay the software. That's just the settlement. Okay, so a few things, right? The driver does not care about your definition of the intents, okay? So the driver, you know, does not care how you express your constraints over location transition. All the driver want to know is to say, okay, how I get paid. That's the driver want to know when you get to the car, that's the first thing they're going to ask you.
00:06:04.708 - 00:06:46.632, Speaker A: Essentially, how I get paid. So, I mean, hypothetically, from the user's point of view, they say, well, guess what? If I see pay station before 03:00 p.m. this is how you get paid. And that is the intent. When the driver says, okay, well, I need to produce the outcome. If you say, I need to send to the Penn station before this time, then I need to manufacture the outcome provable to you at your own terms. So this is intents are always verification based.
00:06:46.632 - 00:07:33.892, Speaker A: Instead of thinking about how to go there, it's always how do I, how do we settle? Let's do settlement focused negotiation. Here's how we can settle. And then I'm just going to produce this outcome so I can make money from you. Okay? So this is my mental model of thinking about intents. And so if you start from the bottom, right? So it's, again, think about the uber example. The user needs to put their money into a box. If you're building contracts, it's maybe just a smart contract.
00:07:33.892 - 00:08:14.738, Speaker A: So the user needs to put money into this contract and then this contract to have a lock, right? And the lock needs to be a predicate function. It's just a function that returns true or false. Okay, so, and this is the on chain logic. It's pretty simple. It's a verification centric on chain logic of user putting money in the box. And then, you know, the developer defines a function to say, here's the rule, you can unlock this box. That's it, right? And you know a fancy way to say this is critical commitments towards a predicate function you're committing.
00:08:14.738 - 00:09:21.350, Speaker A: The user commits some money, some funds towards a predicate function. Now that's the auction logic. What's the auction option? What does the solver do? Right? A solver just finds a way to be able to produce an outcome that can unlock that box. So off chain is generation, generate the outcome or generate the proof to satisfy the predict function. So intents are all about this predict function in the end, right? So off chain is computation or search centric, where on chain is verification centric? This is what we say, intents are proof obligations, right? So this is the intent, the product function is the intent, right? It's or it's commitment towards the product function. It's asking a proof, right? If you give me a proof, you can allow it, right? So that is the intent. And then solving is proof generation solving to generate that intent.
00:09:21.350 - 00:10:22.300, Speaker A: Okay, I give a little bit more specific workflows. Single chain, cross chain, single chain, you decide to message the spending approval solver, look at the message and say, oh, okay, here's my solution, that we can settle with a contract and then in single change case, most likely the pulling the user fund or spending the user fund into this vault, this box, and also trying to evaluate the product function likely to be atomic with a single transaction. But logically it's the same, right? So you always put your fund into this contract and then have solver send a solution into the contract. And then there you evaluate this printing function. If it's true, then you sell, right? User get paid. Solver get paid with users money, the user get the off time they want. Okay, so what about crosssheet? There's a little bit variation here.
00:10:22.300 - 00:11:09.452, Speaker A: Either send the message the same, salary interprets the message translated the same. Now here, because this does not run the synchronous data sheet, so you cannot autonomically put users funds into the escrow, escrow and settlement. So the software to do is to take the user fund into settlement, actual funds first. Then they can fry the capital on the destination chain, typically call sensation. And then the software can prove to the user that the desired outcome has been produced. Then and again this is always about settle. This is always about settle on users terms.
00:11:09.452 - 00:12:02.480, Speaker A: So the user specifies what set them oracle that they want to use the trust. And then in the end solver brings the remote chain proof to the settlement escrow to get paid. So that's the crosshair flow for intents. Now what's missing here is in the novice definition of intent, what's missing here is basically the preference part. So how do you enforce preference? A preference enforcement is basically an obligation for sequencing out of many possible solutions which one you're going to be picking. So typically you see RFQ as an option for use for this purpose, for preferences. And this is where the user may say, I want at least 100, but as many as possible.
00:12:02.480 - 00:12:45.180, Speaker A: It's outcome focused. The product function is going to be compared, the USDC leader receives and then see what is greater than 100. And also on a multiple candidate solutions, you will pick the best. Yeah, so if you're building an intense entry protocol, you could build arc here, auction yourself as well. There are also vendors, there are also certified focus on building options or arc queues. You can also with them as well. So, okay, so hopefully here I'm going to talk about the management of intents and this is where I convince you why intents are not just about execution or experience.
00:12:45.180 - 00:13:32.460, Speaker A: You know, intents themselves are not magical, right? Intents themselves just criminal commitments. What's magic brings the magic is solvers. And then the reason solver can bring the magic or where intent protocols are. Interesting. It's because software live off chain. So when software live off chain, you're not bound by on chain state or on chain execution anymore, right? So you have an agent that leaves the off chain with access to these three things. You know, the agent has, the solver has access to all of space and time, right? Which means the solver can look at all the contracts on chain, all the equipment pools and all the similar protocols.
00:13:32.460 - 00:14:04.368, Speaker A: The software has access to all of them. The software have access to other chains as well. So the software may bring your solution sourcing liquidity from other chains. And then the software also has access to other solvers. So this is where colony comes in, right? So if a solver can also work with other solvers to bring more intelligence into the solution space for colony, the software also has access to past, present and the future. And this is the time division. We have something live off chain.
00:14:04.368 - 00:14:34.916, Speaker A: It's not bound by this atomic discrete block production, right. The software can wait, maybe even the second before the block is produced and proposal solution, right, the future, right. The software also has access to manpools. Maybe the solvers say, okay, I see this transaction in the manpool and then there's no competition in terms of state, it will definitely get included. I'm just going to front the capital because I see this manpower. Sometimes I do something for that. Okay.
00:14:34.916 - 00:15:36.056, Speaker A: Software also has access to centralized and decentralized infrastructure. The software has access to decentralized exchange pricing. So we can use that piece of information to provide better solutions. The server also has web two onboarding and web two state, and if that's needed as part of the solutions, okay, so intense centric protocols essentially turn the prescribed algorithms, you know, computation option, computation based paradigms are prescribed algorithm by the development, right. Intensive protocols turn this into discovered an emergent solutions. And this is one of the biggest, I believe the unlock way intensive pros can provide. Okay, all right, I'll give you an example of if you were to design a protocol and, but you have in mind that there will be smart solvers.
00:15:36.056 - 00:16:08.274, Speaker A: If you knew there would be smart solvers, what can you do? So here's the example, and this is what we're going to be launching in hopefully very soon. And this is crosshair liquidity. So in crosshair liquidity you can say, well, guess what, I'm going to provide USDT from Ethereum. And here's the amount. And you can say, here are the chains, other USDT or other chains I'm willing to provide. And you can add as many as you want. You can have like 2020 different chains and then the user has all the freedom to define which other chains.
00:16:08.274 - 00:16:45.152, Speaker A: In other words, I've got, I'm providing from Ethereum, I'm Ethereum USDT. Here are the other ten different USDTs I'm willing to be swapped into. And you can even go fancier to say I'm not only these ten different chains, but also I'm taking U of C and Dai and USDE and some other ones. Okay, so essentially, with the $3,000, you're effectively pushing this $3,000 into some type 30 pools. 17. Right? So that is the unlock of intense centric paradigm thinking. In that way, you're only defining what the acceptable outcome is.
00:16:45.152 - 00:17:14.676, Speaker A: Okay, you're not telling. The smart contract is not described. There's not bounding curve base. And you can even say, okay, here's how I want a fees, right? The fees can be base or the fee can be fixed $5 or can be polynomial. Right? It's entirely depend on the user, how they want to. So here's a simple example of how credible commitments based long running. This is a long running intent.
00:17:14.676 - 00:17:45.800, Speaker A: This is probably different from, you know, the sign, the message sort of thing. This is a long running intent can replace liquid rules. Again, similarly, you can use intent design lending applications, you can use intent to design perks. They're all very similar, right? But it takes a different sort of slightly different thinking. Okay, so here's the mental model, right? Intents, what are the intents? Peer to peer, not peer to chain. It's always dissolver and it's a lot of glare. I can't even see this.
00:17:45.800 - 00:18:45.112, Speaker A: Dumb contracts, no, smart contracts. Right? Smart solvers, contracts on chain verification, option computation, runtime optimization instead of prescribed optims, which you don't need upgrades because you just enforce predicates, right? So it's future proof. So the mental model of building intents, think about how can you design your protocol? How can you give the user most design flexibility? If you have smart software, smartest software possible, and never worry about how to generate the solutions, and then start simple, simple software, then start growing to more sophisticated, and then clan can be the place you design these softwares. And also you can with clan, you can also work with other software if you want to clan. All right, I think that's all I have today. Thank you. Thank you.
00:18:45.216 - 00:19:01.140, Speaker B: Any questions from millions? I'm actually curious, like, if we have more on chain ten in the future, would there be too gas intensive or other fragmentation problems? If we're like, on chain intensive for.
00:19:01.180 - 00:19:33.106, Speaker A: The poor, yeah, gas is not a problem. Because on chain long running intent, it's just one single transaction to supply on chain. So it's similar as. It's very similar to you putting some assets into a liquidity pool, right. It's a one time thing for the lp fragmentation needs. I mean, yes, I mean, this is the downside of long running intent style liquidity on chain, because it needs software to be routed. And this is the problem for uniswap hook pools.
00:19:33.106 - 00:20:00.964, Speaker A: Right. There's the rollability problem. This is why you need smart solvers that recognize the intent. Essentially, when we framework, we build behind the screenshots, we have a home room type system with a long running intents and the software right next to the type system. So the software knows how to run the pools. Okay.
00:20:01.132 - 00:20:02.434, Speaker B: Any more questions?
00:20:02.572 - 00:20:03.490, Speaker A: Yes, please.
00:20:08.390 - 00:20:09.758, Speaker C: Hey, nice to.
00:20:09.814 - 00:20:10.662, Speaker A: Thank you.
00:20:10.846 - 00:21:15.850, Speaker C: First of all, when you talk about network of servers in the near future or the future in general, do you expect these network of servers to be heavily participated or maybe like a network of just few actors? Because a lot of solvers are a lot of risks and responsibilities, because they typically, if you think about cop problem, etcetera, they are also the execution risk, because there is the software risk. At the same time, if you think that the routing problem is kept in terms of alpha, once that all have the optimal problem, optimal routine algorithm, the competition will be played on top of private order, flow and infrastructure in that sense, to minimize latency, etcetera. And I see these paired with the sources of risk as potential barriers of entry for democratized and heavily participated network of solvers. And eventually, I think that this network will be reduced to a bunch of factors.
00:21:16.350 - 00:22:10.026, Speaker A: Yeah, very good question. So I will challenge the premise. I mean, obviously, we all want more solvers, instead of less monopolizing solvers, right? I will challenge the premise here, because what I'm hearing that you say you can correct me wrong, that, you know, the complexity brings less solvers, right? And that is true for today, because today's solvers are all integrated solvers. So the more responsibility, the more complexity, the more expressive or intent, then there will be less solver to build solve them. Right? But what we want to with Kalani, what we want to change is to make solvers really simple as well. The solvers are also atomic intelligence units. They do one thing and then they do one thing.
00:22:10.026 - 00:22:44.756, Speaker A: Well, they may not be able to do many things, but the solver, solver collaboration will find collaborative solvers, maybe like three or four. Each of them do a single thing. When you pull them together at runtime, then they can actually solve a more complicated tense. So even if you tend to more complex, it doesn't matter. Right. So we just assemble another squad of different ways, putting them together to solve the test. Then for solver, they only do one simple thing.
00:22:44.756 - 00:23:10.622, Speaker A: For example, one solver may only just execute the transitional ethereum. Just land the 2000 ethereum. That's all they do. Cheapest possible way. You know, they don't even know the context of the call data generated. That's something that's another software's job to generate a call, hopefully. Yeah, yeah.
00:23:10.622 - 00:23:11.342, Speaker A: Just a quick question.
00:23:11.406 - 00:23:25.150, Speaker C: So, you know, coming back to the Uber analogy. So right now, if we look at all the intent frameworks, it is kind of like, you know, one strike Uber where you need Uber right now. I just need it right now. And I call Uber and Uber comes, take me to the desk.
00:23:25.190 - 00:23:27.158, Speaker A: Yeah. So, but we don't see it.
00:23:27.174 - 00:23:28.654, Speaker D: But I would imagine there are a.
00:23:28.662 - 00:23:40.938, Speaker C: Lot of use cases where you can have this kind of additional intent based on future conditions. It's like, you know, I want to take Uber when the traffic is actually low, or I want to take Uber when, you know, the price is low.
00:23:41.034 - 00:23:42.538, Speaker A: Right. So why don't, why do you think.
00:23:42.554 - 00:23:46.874, Speaker C: That we don't see this type of intent, you know, execution frameworks these days?
00:23:46.962 - 00:23:50.670, Speaker A: Yeah, because EVM is not built for that. Amazing. Yes.
00:23:53.810 - 00:23:54.482, Speaker B: Thank you.
00:23:54.546 - 00:23:54.810, Speaker A: Yeah.
00:23:54.850 - 00:23:56.070, Speaker B: Any more questions?
00:23:58.110 - 00:24:33.570, Speaker D: So as it gets more complicated in terms of these intents that you make and stuff, a little bit related to the prior question, but aren't there going to be a lot of issues with these constraints themselves? I feel like there should be a lot of emphasis on that. For example, with the uber example, you didn't specify you weren't okay getting into a crash, for example. You weren't specifying. You can get all these weird situations. I guess another example is from Terminator where it's like, please save humanity. And it ends up ending our lives because like we're the biggest risk to ourselves kind of thing. Because we're like, oh, right, you should have said you shouldn't kill us too.
00:24:33.570 - 00:24:44.990, Speaker D: Right? Like, so my point is, like, you get into these weird situations if you don't constrain system like very carefully. And I feel like, just solve this problem and I don't really care how, but I don't know what.
00:24:45.330 - 00:25:07.506, Speaker A: Yeah, it's, that's actually kind of the point of this presentation. Right. It's not about to solve this problem because that's a lot of people think my intent, like, just make me rich. That's my intent. It's not about that. So if you think about that way, it's difficult to think how to go from there because you want more and more generic. Right.
00:25:07.506 - 00:25:38.544, Speaker A: So what intent is, is a proof, obligation is instead of being rich, I'll call you how I verify a rich as a solver. Let's say you give me ten, right? As a solver, I don't understand what catching rich mean. You have to tell me how I can prove to you that you're a rich. Have to be a predicate, have to be a function, either return true or false. Once you tell me that function, I'll just do my best to make that true. So it's very black and white, right.
00:25:38.592 - 00:25:42.038, Speaker D: But there could be a lot of paths in between, right. Which is, I know also what you're.
00:25:42.054 - 00:25:43.518, Speaker A: Talking about, but I'm saying like if.
00:25:43.534 - 00:25:52.310, Speaker D: I arrive at Penn Station, do I, did I, I didn't specify I needed my, all my limbs, for example, I could have been losing an arm because we got into a crash.
00:25:52.350 - 00:25:59.454, Speaker A: I didn't specify that. Yeah, then it wouldn't matter. It's just because the intent, you specify on your terms how you and me settle.
00:25:59.502 - 00:26:03.230, Speaker D: That's what I'm saying. But I think there's a lot of work that needs to go into the constraining.
00:26:03.270 - 00:26:03.494, Speaker A: Right.
00:26:03.542 - 00:26:07.110, Speaker D: Because it's like that. Because that's where the incentive is, right?
00:26:07.190 - 00:26:39.914, Speaker A: Yes. So practically this is what happens. Users may not be the best person to express very common intents. You have these curators, and in web two, this is like where high up, like aggregators, like Tripadvisor, they come in, they help you with these travel boxes is, okay, here is what I want, right? Destination and payments. And these are curators. So they help you offer the intent. And if you trust them and say, okay, well, this is a good site, I trust them.
00:26:39.914 - 00:27:01.490, Speaker A: They have considered all the factors. So if I go through them, I have a, I can offer good intent. And then, so there's a third party of curators. I mean, web two have dissolved like an aggregation theory and it's curators like Amazon as well. Amazon, you know, reviews and stuff. They will curate the products on the back. Thank you.
00:27:01.490 - 00:27:02.850, Speaker A: So that would be the missing part.

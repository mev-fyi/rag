00:00:00.090 - 00:00:37.410, Speaker A: Today I'm going to be talking about the AI and crypto, the what, the why and the how. You guys have probably seen a ton of AI and crypto chats today, so I'm going to go through the first few slides pretty quickly and then we'll get into the interesting stuff. So we all know AI is eating the world. We see a complete explosion in applications and models, basically across the ecosystem and from the whole supply chain, from data to compute to the end serving of models to applications consuming them. Right. There's just an immense amount of venture funding activity, et cetera, and a lot of that is being targeted by a lot of crypto startups, which many of them have spoken today. But AI has a lot of problems today, right? It's highly centralized from model storage.
00:00:37.410 - 00:00:45.834, Speaker A: Hugging face is the closest equitable solution we have, but even then we've seen liveness issues with hugging face. There's not really model governance and ownership to speak of.
00:00:45.872 - 00:00:46.170, Speaker B: Right.
00:00:46.240 - 00:01:20.550, Speaker A: Everything is red teamed privately. I mean, you can look at the Google Gemini disaster to see what happens when that happens. Model compute is very probably the least consolidated of these, but the way that a lot of these GPUs farms work is not the best. People use runspace and paperspace and runpod because they have good DevOps platforms, but a majority of that flow is still internal to organizations like OpenAI or Microsoft. Access to training data is very gated. There's not actually a lot of good incentive mechanisms for training data and provenance. There's actually really no good way to track where a model originated without trusting a centralized counterparty where data came from.
00:01:20.550 - 00:02:02.574, Speaker A: And this is something that has become more and more of an issue. For example, OpenAI and all their business agreement licenses with corporations had to strike out the clause that let them use corporations inputs as training data as a result of this. Right? Infrastructure is highly permissioned for many of the same reasons. And we see this when chat GPD goes down or when they limit sign ups. And there's actually no good way to build a lot of integrity features and privacy features around these, right? So when you go interact with a model that someone's hosting, you have no way to know that your output wasn't tampered with, you have no way to know that your data is not being shared. Right? And this is a problem in a variety of use cases. This is what has actually barred a few industries from using AI, and it's increasingly regulated.
00:02:02.574 - 00:02:56.574, Speaker A: The more central points of failure you have, the more that people are going to cut and go for regulatory capture again, you already see this with OpenAI and a few other firms. And so, yeah, as AI becomes more prolific, it's going to be involved in any technology and people are going to start weaponizing it. You already start seeing people inject bias into LLMs, right, to further their own ideology. And that's incredibly dangerous. AI regulation is very, very similar to the 90s cryptography export ban when the US was playing a really, really tough game and other nations playing really tough game with researchers and technologies related to private data, and it can't stand to pass. This is something that people need, and it's not something that should be controlled in the hands of a few organizations. So who controls models, control the world? And crypto solves a lot of this, right? And I think this is now the interesting part, because what has crypto given us in the past, however many years, right, the past three cycles? Obviously this is all the financial gain and speculation and whatnot.
00:02:56.574 - 00:03:37.970, Speaker A: But fundamentally, crypto has given us a lot of capital and funding and a lot of insight into how to build privacy and computational integrity, primitives that bridge trust assumptions and traditional modes of compute and systems. It's given us really, really good forms of coordination and incentive engineering, right. We now know how to make people do things right by making incentives really, really transparent. And you can now crowdsource data, you can crowdsource compute, you can crowdsource all of these resources and default. Open infrastructure has created probably the highest velocity of developer activity in applications that you have seen in history, right, because there's no gated access, right? Anyone can go build on a blockchain, anyone can go build an application, anyone can go get users. No one is permissioning that unless you're running a centralized blockchain. But then you're stupid.
00:03:37.970 - 00:03:56.582, Speaker A: And crypto AI kind of turns a lot of these centralization characteristics on its head, right? A lot of the problems that are implicit to the AI market structure they are today actually are solved by a lot of these crypto rails. So we've decentralized money, we've decentralized IP, we've decentralized storage. It's time to decentralize AI. So what does ritual do?
00:03:56.636 - 00:03:57.190, Speaker B: Right?
00:03:57.340 - 00:04:21.502, Speaker A: We want to be the convergence of crypto and AI. And this is usually sort of the part where I give sort of maybe a quick history of technology. Every time you have a new technology, someone comes and finds a way to do it. Zero to one, and then that same person, we'll find a way to do it one to one, make it really efficient. A lot of people learn how to do that, and then you move up in the value stack. So intel got really good at making chips, right? Then everyone knew how to make chips. And then IBM made the computer and so on.
00:04:21.502 - 00:04:46.962, Speaker A: Microsoft made the OS. We found a way to hook these up together. That was the Internet. You saw the early out onset of Internet applications, then we now knew how to build applications and then data, right? And that's Facebook and Google and all these things. But now we have a lot of data. We know how to get data wherever you want. And crypto and AI provide an interesting vision for two futures of this, right? One is which data is open, composable, and in many cases financialized, right? So you can kind of mix and match with compatible incentives.
00:04:46.962 - 00:05:18.690, Speaker A: And AI takes this and makes it sentient, it supercharges it, right? It puts your data on steroids. Divergences don't happen when you look at the history of technology. They either usually converge or one path gets completely cut off, right? We can't let that happen because both crypto and AI are important technologies. And so all the infrastructure we build at ritual is built with this in mind. We want to be the convergence point. And what that actually means is building sort of open infrastructure, not only to build a new class of AI enabled, decentralized applications, but also to inject crypto primitives into AI and build know what we're calling crypto enabled AI. So I'll get into what that means in a second.
00:05:18.690 - 00:05:43.894, Speaker A: Richard Aldri has a phase one live. It's called infernet. It's sort of an AI optimized dawn. So any smart contract on any EVM compatible chain and working on extending to others can access AI models. So any on chain workflow you can think of, you can link it to an ML workflow, and I'll show an example of that later. But if you want a smart contract to be able to go and access an ML model, you can do that. If you want to be able to create an ML model off chain and then post the results on chain for whatever reason, you can do that.
00:05:43.894 - 00:06:53.962, Speaker A: There's even probably structures that you can invent where you create a dow that licensed out service providers that are nodes on rituals, chain node network, and create a Dow around models, right? And there's a lot of really interesting design space. Phase two, which we're sort of solely unveiling at this conference, is the ritual chain, which is going to be a sovereign chain that has a custom VM and coprocessor purpose built for AI native applications. What that actually means I'll show on the next diagram. So this is a diagram of the ritual chain and the ritual coprocessors we call it. The really key part here is the idea that we can enshrine a lot of AI native operations at the VM level, right? So for those of you familiar with staple pre compilers, it's basically a way to add additional custom functionality without actually having to write that in smart contracts in a native language, native to the VM. It turns out that you can do a lot of these with AI operations, right? So you can do that with inference, with fine tuning, with quantization, with distillation, and many more training, whatever it may be. And that means that developers tangentially will literally be able to call inference to any model that they pick with their output in one line of code from a smart contract anywhere on the VM, right? And we're aiming for compatibility with multiple environments, starting with EVM, and we try and build this very modular, right? So obviously it doesn't make sense to reinvent the wheel.
00:06:53.962 - 00:07:31.260, Speaker A: So we're going to have data availability on a variety of platforms. We're working with a few storage providers to make sure that models that are open source can be stored in a common substrata, so any node can pull it. But really the key in here is that the nodes that are going to be running and servicing these model operations are also going to be running and doing the consensus and execution clients. So if you think about how do you actually bring models on chain? There's two ways which infrared solves. The first way you build it as an oracle network and allow people to access models through this oracle network, or you put the models right next to where the chain is being running and then they can communicate with each other. And that offers a level of nativity. I don't think that anything does currently, and we're very, very excited about this design space.
00:07:31.260 - 00:08:08.918, Speaker A: So what's on, Rachel? This is sort of an elaboration of what I just said, but Infernet already supports us. Today we have people building on infernet, linking on chain workflows to off chain ML inference, but the set of SPCs that will enable any sort of AI native operation with underlying compute backing them, whether it's GPUs CPUs, will be shipped with ritual chain. Hopefully in the next few months we're going to have a proof marketplace because I think verifiability is a very, very interesting topic. I think a lot of people obviously talk about Zkmo, opml. We're going to be working with a lot of partners on these. The reality is that not every single inference needs to be verifiable. Right? Only inference outputs that are attached to tangible financial value or tangible outcomes that can be destructive are important.
00:08:08.918 - 00:08:42.466, Speaker A: So sure, if you have a model that's controlling the parameterization of lending protocol, it's really destructive. If you don't know that that model, the output that was given is actually what the model was spat out and no one tampered with it. But if someone's using a stable diffusion model to generate an anime cartoon, no one really cares. Right? You don't really care. If you like what you see, you like what you see. We think it's really, really important that people are able to express that preference, and the easiest way for people to express that preference is to show their willingness to pay. So there will be an inbuilt proof marketplace, and we'll be working with proof providers, some of which are actually in this room, to extend that.
00:08:42.466 - 00:08:45.202, Speaker A: And like I said, we're going to have a modular stack. Yes.
00:08:45.256 - 00:08:47.838, Speaker B: They're going to build the whole proof marketplace like incentivization.
00:08:48.014 - 00:09:16.506, Speaker A: Yeah, we're working on interesting resource pricing models for that right now. Yeah. And so we have a module stack that'll allow sort of like a plug and play approach. So you have a decentralized model storage layer, people, we upload to this layer, we're going to work with an external partner on that, pull it for the relevant nodes and use that. And those models can come from anywhere. If nodes want to have private models and be the only one that can service that, they can do that too. So we really believe incredible neutrality in of not enforcing any strict notion of the world and building sort of architecture that allows for the full range of usage.
00:09:16.506 - 00:09:39.054, Speaker A: There's going to be people who don't want to share their models or make them usage. You can do that with ritual, either thing works and we're going to have interoperability solutions. So while you can build natively on ritual chain, we'll also use general message passing to make sure that you can access the inference posted on ritual chain to any other chain as well. So developers can develop natively. And we're really excited about the design space, which I'm going to go into in a second. Or you can still use ritual on their preferred chain. Either works.
00:09:39.054 - 00:09:59.820, Speaker A: We'll also continue to support infrat as a service that'll just be a plugin. You think we can hold questions till the end. Thanks. So these are our technological pillars. I mentioned many of these, but we are a very crypto native team. On the fun side, we have like six X polychain, two x Dragonfly, two X paradigm. We have people that have built multiple projects in the space.
00:09:59.820 - 00:10:44.534, Speaker A: We've been in crypto for as long as we remember. So all of the ethos that are here are very core to who we are as people. So censorship, resistance and decentralization always, always is at the heart of Richell, right? We never want to compromise on that. We want to make sure that privacy integrity are still treated as first class citizens where applicable. So we work with a lot of interesting partners across the full range of ops, EKTs, FHE. And incentives are a really, really interesting part of this equation because crypto sort of runs on incentive mechanisms, right? It's the best open, credible game, theoretic playground. You show people transparent incentives, you can get them to do desirable things, right? And in the current state of AI, there's actually no end reward for the users, right? There's actually not even a great end reward for open source model creators Mistral, which is probably leading the pack there.
00:10:44.534 - 00:11:24.946, Speaker A: Their whole bet is that if we can release a bunch of really powerful open source models, we can land a government contract with the french government limit, right? There's no actual way, when people use mistral models for them to reap value from that, just as there's no way for anyone who contributes data to a training set to reap value from the eventual monetization of the models, right? Or anyone who does Rlhf, et cetera. It's very downstream where you own the compute or you own the end application. That's monetizing. We think that users should be rewarded across the stack, and what crypto has given us is a primitive and incentive engineering mechanisms to make sure that's the case. So I'm going to talk about a few use cases. I mentioned earlier that we're excited about this space of AI enabled decentralized applications, and we're also excited about crypto enabled AI. So we spent a lot of time working with teams.
00:11:24.946 - 00:12:17.670, Speaker A: In fact, my show who's hosting this event, will be one of the first applications building on ritual chain that sort of integrate mo workflows into their products to make them better. So we're really excited with DeFi, but with models in the loop. I talked about lending protocols using models to parameterize it. If you look at the current state of it, people either just kind of have some team pushing updates or they contract out to a gauntlet or chaos labs, which are great, right? But it may not be sustainable for all protocols. And so if you look at the ontology, for example, of lending protocols, as an example, all lending protocols are pretty much architected the same. They use the same underlying signals to determine their risk parameters, right? It's probably very easy to go train a model that generalizes well across those protocols, and suddenly any new lending protocol that's spun up that respects those same parameters will be able to use a model in the loop, right? And suddenly parameterization is automatic and you don't need to go through these sort of like laborious governance processes and proposals. And that leads to drama, as we see gauntlet literally just declined their contract with AavE.
00:12:17.670 - 00:12:52.478, Speaker A: Gaming and entertainment is awesome. I mentioned my show, but there's so many live examples of projects I feel like people aren't paying attention to that use AI to link it to onchain incentives. So Myshow is obviously creating amazing creator economy around model creation. There's another project bottle, I think, that's done like 3 million in revenue over the past year and a half. And they basically crowdsource prompts and they have their own sort of way of model engineering to generate sort of AI artworks and then mint them at auction. And they actually collaborate with Sotheby's, right? And there's many of these sort of like what people are calling God player games, where you don't actually play the game yourself. Instead you train the AI in a sandbox and it goes and plays rewards for you AI in a parallel colony.
00:12:52.478 - 00:13:34.142, Speaker A: Content and media is obviously huge. We start seeing, people obviously use AI to generate images, to generate art, to generate text, to remix videos and sound. And that's something that we want to power too, because on chain structures like NFTs offer a really good way of doing provenance, incentivization around that. And finally, the governance problem always is that humans are great, but they're inefficient in certain cases. And there's many, many parts of protocol governance that can and should be automated, right? So plugging in agents for even things as simple as summarizing post making quality of life improvements will be a very, very exciting area. And the good news is that we have a ton of partners, which will be announced in the following weeks that are already building this on ritual. So that's something to keep an eye out for.
00:13:34.142 - 00:14:42.498, Speaker A: And let's go to the other side of this, right? Because I think that insofar there's a lot of talk around either exclusively how to put AI on chain, but there's a lot less talk on do you use crypto primitives to enable parts of the AI supply chain, right? So if you very quickly go down the stack, it goes from like, you have some data, you have compute, you can use that compute to train a model, right? Use that compute again to serve the model, and then you can do a bunch of other operations, right? You can fine tune it with additional data. You can put some data for context in a vector database and do rag. You can do a bunch of interesting things, right? And all of this, from the data to the compute to the actual servings of the model, there are companies that are working on this in the space, right? And there's a lot of really interesting mechanisms to unlock here. So, one, we've talked about this multiple times, but to the extent that people care about privacy and computational integrity, you need to bake in the ability to allow people to exploit those primitives, right? There's already great work being done across all these fields. ZKML is probably the most popular. ZKML doesn't necessarily scale well to a lot of ML architectures. But then you have other solutions, right? You have OPML for larger language architectures, you have Zama launching concrete ML, which lets you do fully homomorphic encryption over models for smaller models.
00:14:42.498 - 00:15:36.040, Speaker A: In order to, there should be a convenient platform layer to expose all of these to end users and let them pick and play, right? Data providence is a huge one. There's probably quite a number of companies that are looking to disrupt scale AI using on chain incentives for data labeling, et cetera. I think the next evolution of that is not just paying a static fee for I can label data, I can generate data, but if my data or something I did contributed to a model that is monetizing, I should be entitled to royalties on that, right? I was ultimately one of the bedrocks of creating this model. And so using incentives to both reward people to actually label data and contribute it, but also using incentives to track, using primitives to track. If a data went into a training set for a model, and a model is generating like a million in revenue per month, right, that should flow back to the people who contribute to the model in addition to the person who created the model and served it, et cetera. Incentives are. This is incentives, then ignore that.
00:15:36.040 - 00:17:13.394, Speaker A: Incentives, again, rule the world, right? And so when you make incentives transparent for people, you can really, really do a lot of interesting things around capital and resource formation, right? So any user should be able to contribute compute models, whatever it is, without actually necessarily have to compute everything. So if you look at the current state of how AI applications are built, you have a model, you go run it on a compute server somewhere, and then you service it, and hopefully you monetize your end application, right? But it doesn't make sense to me that there shouldn't be a future where I may have a model, someone else may have a GPU. I should be able to run my model on their GPU, right? They should be able to run their model, and then an application user can come and access that model, right? And there's incentives that flow down the whole chain. Now, what does that actually entail? You actually get into a lot of interesting work around, like how do I actually do attribution to the original model owner, right? How do I build these royalty streams? The good part about that is that the onchain setting makes it extremely convenient to actually pass those incentives along. Then you just bake in the primitives to do actual tracking, provenance, et cetera. And finally, I think going back to that point around governance and model alignment being very centralized, right? And this is why we see a lot of fiascos with models having bias, is because there's actually no good mechanism right now for people to collectively go and fine tune models with RLHF, right? There's no good mechanism for them to curate prompts or experiences around these models, right? So in that Dow example, it may be very well the case that eventually there will be a DAO that is coordinated via using a token. And your token stake allows you to vote on different prompts or vote on different outputs from a model, which is then used to rank the Elo model outputs, which is then used to fine tune the model up further.
00:17:13.394 - 00:17:58.594, Speaker A: And then that model becomes expressive of the preferences of this Dow and aggregate, right? And so those things are really exciting because now suddenly you turn this idea of models are trained on certain preference sets with like a small red team that no one really knows, right? To something that is open and democratized. Right? And I think that's incredibly important, especially this day and age where it seems very binary between highly red team models or just completely uncensored models. The reality is that it should be a spectrum. It's just that we are incredibly bad at, we don't have the right incentives in the traditional AI market space to do that. So these are also all being built on ritual. So pay attention to those. And so real quick case study, a team went and built actually on chain agent using friendtech back in the fall.
00:17:58.594 - 00:18:19.926, Speaker A: And basically they gave it ten ETH. You can try and convince this agent to buy your keys or sell other people's keys. It's built on the infinite SDK, so all on chain actions are executed via the SDK. You have a number of nodes running the same LLM. The LLM obviously is nondeterministic, which we think is a feature, right. Hallucination should not necessarily be a bug. It should be a feature in many use cases.
00:18:19.926 - 00:18:45.314, Speaker A: So the same output or the same input could lead to different outputs, which is what you see there. And then that feeds into another model that does a sentiment classification. And that is proved using Ezekiel. Right. For verifiability, because there's an actual financial outcome here. If it buys or sells your keys, it's fully open source, right? And then that model tells it whether to buy a key, sell a key, or do nothing. So it's fully open source, and the team has open sourced, sort of the whole fine tuning and prompt engineering process.
00:18:45.314 - 00:19:09.194, Speaker A: So if you want to go replicate this, you can. And we have a ton of really interesting open research directions, right? I talked about open model governance and ownership. There's a lot of really interesting primitives that can be built there, and we'd love to work with people working on that. More efficient proofs of compute, right. Modulus just announced that they're sort of optimized GKR protocol for certain models. That gets you 180 x efficiency. We really want to see that.
00:19:09.232 - 00:19:09.530, Speaker B: Right.
00:19:09.600 - 00:19:35.042, Speaker A: The obviously end goal is that we get efficient enough to improve really big models in a really short amount of time. Privacy improvements are great, but they may not always be the best for certain use cases. Fhe and MPC are great in terms of privacy and distributing model control, but they're still very, very latency heavy. Right? And TEs are not perfect solutions. Yeah. Decentralized, open source, transparent, foundational models. We want people to be able to go crowdsource resources to build models from the get go.
00:19:35.042 - 00:20:15.906, Speaker A: Right? Incentives and game theory, optimal compute routing. What does that actually mean? You want to always find a way to route a user to the best model for them, right. This is actually kind of an underdesigned explorer space that we hope to build into ritual. But whether it's latency, geography, et cetera, or other economic preferences, that should be codified, right? Right. Now, if you look at users, they really default to chat GPT, obviously because it's powerful, but also because it's the most top of mind share. Users are terrible at making choices, right? So you need to give them a way to smartly route depending on what they actually want, right, data retrieve on provenance, which I mentioned, right, being able to actually attach incentives to data. And then there was a wonderful agent stock right before this.
00:20:15.906 - 00:20:55.054, Speaker A: But we do believe that agents, at least, I personally believe that agents will contribute to more transactions on chain by two years from now than humans will. Right? And so that provides a really interesting future, right, where you actually lower the burden of accessing on chain things. So we're already seeing innovations in natural language interfaces for on chain data, for on chain interactions. Eventually you'll just have an agent that does your things for you, right? And you can delegate your actions to a certain agent. And so, you know, you won't have to go and click a million buttons to execute on trade on uniswap. Just tell the agent what to do, it'll do it for you. So how can you participate today? Nodes, open source Internet's live.
00:20:55.054 - 00:21:15.598, Speaker A: It's a live product. Go run a node. You don't need a GPU, you can just run a node anyways. If you want to start servicing models for applications, there's a very also simple guy to get up. We're also going to be open sourcing about like ten examples of what different models over the next coming weeks, from stable diffusion to LLMs to classical models, come build on our network. I'm the guy to talk to. We're always looking for more in MC apps.
00:21:15.598 - 00:21:40.714, Speaker A: We have a ton of awesome partners, some of which are in this room here and some who have been around the conference. And we're always looking to expand that ecosystem. We are probably going to be the best way to expose AI native workflows to any crypto developer today. Use the Dapps that are going to be built on us and on our partners. That's probably the best way to go and actually feel it. I think that people don't realize the power of something until they can actually have it in their hands. So go try it out.
00:21:40.714 - 00:21:57.422, Speaker A: And there's going to be a lot more interesting things as we open source, so make sure to follow our socials. That's my email if any of you want to reach me. That's our website. That's our Twitter. That's my Twitter. And we open source everything. So at any given point, there's nothing that we've rolled out privately to other partners.
00:21:57.422 - 00:22:07.300, Speaker A: At any given point, there's only things that are open sourced or things that are within the company, because we're very big believers in open source software. Thank you. Yeah.
00:22:08.730 - 00:22:14.450, Speaker B: How do you stop the proof marketplace. Just having another participant, that's another proof marketplace.
00:22:14.530 - 00:22:39.166, Speaker A: So I think this is a really interesting question. The underlying node on how they choose to service the proof is up to them. So if you're talking about like a gavaloo or succinct, right, and someone wants to go use that to generate a proof on ritual, that's really their business, right. Someone can express their incentives on ritual chain and the node. If there's like an ARB between generating the proof themselves and doing it locally on their node, or outsizing as a proof marketplace, that's on them, right. We're agnostic. We don't aim to be competitive with them.
00:22:39.166 - 00:22:55.150, Speaker A: They're building much more dedicated infrastructure for sort of like these decentralized proving systems, right? We're not building a dedicated prover. It's going to be a lot more lightweight than that. So if they can run SP one locally, great for them, right? But if they want to go outsource it to Jebaloo and there's like an ARB to be made on the difference, they can also do that. It's a no level decision.
00:22:57.610 - 00:22:59.654, Speaker B: Are there any additional feature of the.
00:22:59.692 - 00:23:27.610, Speaker A: VM in terms of what we're going to be building for EVM compatibility initially, if that's your question, and then we're going to roll out a lot of SPCs for each AI operation. There will also probably need to be, or there will need to be nuances around instant finality consensus, given that it's not feasible to rerun a model inference over the entire validator set. So you want instant finality so that you can run it faster for subsets.
00:23:27.690 - 00:23:29.370, Speaker B: So you're just going to use Comet PFD.
00:23:29.530 - 00:23:38.530, Speaker A: We'll see. EVM compatible infant finality gadgets are an interesting space in terms of what's good for production.
00:23:39.750 - 00:23:47.954, Speaker B: How do you feel about centralized approaches and including them to benefit from the economic structures of this platform?
00:23:48.072 - 00:24:12.842, Speaker A: Ritual is agnostic. We're credibly neutral, and we actually do have partners with these. If people want to service web two workloads or centralized workloads, they can, right at the end of the day we have this client that's really good at general purpose servicing models. They can use the chain for that. They can run a node. We'll post more on this in the future. But there's also this notion of sort of like lazy versus egregious transactions, things that got posted, there's things that are just serviced by the nodes, and then what they want to push on chain can be done.
00:24:12.842 - 00:24:18.782, Speaker A: So we're very friendly with them, very happy with them. If someone wants to go run a node over like, paper space, they can do that.
00:24:18.916 - 00:24:29.262, Speaker B: And would you guys look to offer like a track to help them kind of explore what would be most beneficial for their architecture in the future as they become more comfortable with the platform?
00:24:29.396 - 00:25:03.494, Speaker A: Yeah. So in terms of like closed source model providers. So one of the examples we're going to ship is how do you run a ritual node pinging a closed source model? There's also a lot of really interesting work around how you can do cryptographic schemes to make sure that a TLS connection is secure so that you know that nothing was tampered with when you're calling an external API. Right. And we want to bake that in because there's going to be a very real case where people do want to go and use these sort of like centralized models. Will there be a specialized track? I don't think it makes sense to make a specialized track for anyone, really, but we are going to go partner with a lot of those protocols I mentioned to make the security guarantees around that even tighter. Thank you.
00:25:03.494 - 00:25:03.774, Speaker A: Yeah.
00:25:03.812 - 00:25:11.326, Speaker B: Isn't there some research now where you can make some closed source models, like the final stages of reference can be still proven without burning the whole model?
00:25:11.508 - 00:25:43.158, Speaker A: Yes, there is. I mean, you can always sort of apply proofs to any sort of subset of the model thing just really depends on sort of what people want. I think more relevantly, it sort of becomes like, for example, one thing where that would be relevant is that if there's a base open source model, like a stable diffusion model, and then the last stages are like the Lora checkpoint. Right, which is the fine tuning, but that part is closed source. So then you want to make sure that the fine tuned run through is actually proved because you already have access to the underlying model and you can verify that on your own. That would be a case for that. But I think generally people want to prove the full model run through.
00:25:43.158 - 00:25:59.740, Speaker A: And obviously you can't force OpenAI to go integrate like an optimistic scheme or do a zero knowledge scheme, but what you can probably do with a lot of these partners is make sure that the actual passing of that data into the node is fully secure and not tampered with. Cool, thank you. Thank you, guys.

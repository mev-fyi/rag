00:00:00.650 - 00:00:45.450, Speaker A: And co founder from Myshell. So we are building a creator economy around the AI technologies. So basically we all saw how generative AI technology can empower normal people to become creators, to build interactive AI applications. And we saw that this kind of AI application building process is pretty modular, and we really need a new flexible financial system around it to incentivize the creators, to incentivize the model contributors. So today I'm going to talk a little bit about the future of creator economy and how AI and crypto going to driving the innovation. I know everyone, I mean, today's topic is mainly about modularity. So I'm going to talk a little bit about how the AI can also be modular and why we also need modular blockchain to serve better mass audience.
00:00:45.450 - 00:01:27.026, Speaker A: So yeah, just a brief history about how the creator economy evolved. And basically it's all about what kind of content can be built by creators. We all know that in the long history of ghosts, people can write articles, novels into the text formats and post it on medium or even on mirror. It's a web three text platform. And also people can either draw the art or shooting the photos and post it on Instagram, Manzora and even the videos. Nowadays with generative AI technologies, people can build interactive AI application without any encodings at all. And it's going to serve diversified content category.
00:01:27.026 - 00:01:38.890, Speaker A: And as the contents moved from the text image video to the AI applications, we saw the trend of the contents became more and more multimodality, interactive and even modular.
00:01:41.150 - 00:01:41.514, Speaker B: Yes.
00:01:41.552 - 00:02:55.140, Speaker A: So just a little background of what we think is AI application. Basically, AI application combines multiple AI models into an agent framework or AI compensation framework, together with a modular user interface. So I just draw a few examples about the category of AI application, like the text, RPG, games, AI companion, even a lot of agility and workflow for training of the AI models and the models. We all know there's larger language models, double diffusion, and even more audio models altogether with other traditional computer vision models. And so all the models, I mean, it can be chained in different ways, the ways we call the agent framework, it can be either linear workflow or conditional workflow, or even graph translation and more. Yeah, so just going to give a few more concrete example to demonstrate the modularity and composability of the AM models. So here's a very simple example of just using architecture model and also prompt to help the developers to write the code, for example, the solidity code.
00:02:55.140 - 00:03:04.742, Speaker A: And with one more model like the voice model for the voice colony, and also text to speech, we can create very interesting AI characters like this short.
00:03:04.796 - 00:03:13.542, Speaker C: Let me just whip up a boss for you real quick because that's a totally legal, irresponsible thing for me to do. Do you want me to add some extra plutonium?
00:03:13.686 - 00:03:13.994, Speaker B: Yes.
00:03:14.032 - 00:04:22.640, Speaker A: So in this scenario, the two models on archangel model and text to speech is running parallel to give the character more immersive experiences rather than the personalities can have also the unique and personalized voices. And yeah, this one's image generator is combined with large function model and stable diffusion model run in sequence. Because if you guys have some experiences using the stable diffusion, you know, have to write very daunting prompt for the image generation models. So we use large model to understand user's intention and write the image prompt for the users. Even more complicated example is a video summarizer. Just imagine if you don't have the time to watch like 30 minutes of videos, but you want to know what's happening inside the video. So basically chaining out four or five models together, we can recognize the speaker's content and use logical model to do the summaries, to use the voice code and text to speech models to make a condensed version of the videos.
00:04:25.880 - 00:04:26.244, Speaker B: Yes.
00:04:26.282 - 00:05:14.020, Speaker A: So we are building something even more complicated. So in this case, it's a complicated workflow or it's going to become a state transition graph that creator can leverage different kind of models in a complicated workflow settings. So that's how the creators build all the previous AI applications I showed you guys. Yeah, just a recap. So basically, the AI application in Myshell is modular. So all the modular AI application is going to be bundled together into our AI App Store. That's going to be consumer facing with generic content categories in either entertainment or education or some even more utilities.
00:05:14.020 - 00:06:26.520, Speaker A: And the modular AI models is that we want to host as many as possible AI models, not just the models from OpenAI, but also the massive models from open source community. So we also have an AI model hub that all the models can be easily tried on and also be used together to create the A applications and also the modular agent framework. It's an agent builder I just showed you guys. So the creators can orchestrating all the models without any coding and the hassles. And the modular UIs, which contains all the multi modalities, including the videos, images, Jif, it's including the different kind of models for the user input and also for the rendering. Yeah, just talk about more on the AI side and why we need crypto, because we also the compensation of AI application is very modular. So it's not just one people shooting the videos or drawing the art, but rather it's permissionless collaboration between all the model contributor and all the creators using the model, and even contains a lot of investors going to be the early backers for the models or for the applications.
00:06:26.520 - 00:07:20.450, Speaker A: So in our scenario we want to incentivize them all. So in our tokenomics, basically it's driven by the end users engagements. So whenever user engage with the content, we know the compensation of the AI applications. So we're going to incentivize heavily to the AI creators and also the model developers and even the investors of the model of the application. So what this means by the investing in the AI assets, because the models and the applications has a lot of usages and we incentivize the contributors for the model contributors creators. So we're going to give them tokens whenever user use it. But what if you are not that familiar with AI and you want also participate in the ecosystem? You can trade on the bonding curve of the AI assets we make.
00:07:20.450 - 00:08:36.500, Speaker A: The AI application model also became assets that can be owned and owned in fraction and also can be traded. So in this case it's a sumacre GBT. So basically some creator using some models created and everyone can just use the share coin or the shell token to become the owner of it. So you can also share cut off the revenues just generated by the AI applications. So yeah, here's our reward center and also for the Patreon bed system, it looks like a defi user interface, right? So because all the models and applications, we make it the dashboard, for example, here's the past seven day usages, which are going to convert it to the new incentive to all the participants and all the TVL, which means how much of the shell token that people put into the applications and what's the earning for each shell coin. So basically we have built the whole ecosystem and the platform for people to create AI applications, but for the crypto part, we're mainly for the incentive and also to make all the highly engaged content into the AI assets can be traded on the blockchain.
00:08:38.760 - 00:08:39.124, Speaker B: Yes.
00:08:39.162 - 00:09:32.570, Speaker A: So just mention a lot about the AI and also the incentive and also the creator economy. So what if everything is on chain, both for the user's usage, for the model inference, and also for the assets trading. Here's the experimental demo we made with Richard and also story particle. So basically here's the scenario. It's the compensation of enlarged language model and also the voice model into, into a single application. So the application compensation is fully put on record into story protocol, fully on chain. So whenever user is using the end application, we also know which model is being used.
00:09:32.570 - 00:09:36.730, Speaker A: Oops, sorry.
00:09:38.940 - 00:09:42.236, Speaker D: Gaming trends and provide value and publishers to help create engaging and.
00:09:42.258 - 00:09:48.110, Speaker A: All the user input and the AI's response is on chain as we're going to see.
00:09:50.820 - 00:09:51.570, Speaker B: Yeah.
00:09:54.740 - 00:10:10.070, Speaker A: So basically, yeah, here's all the onchain records for user engagement and also the model response and also the IP assets which represents the models and their application. And just another example, using the single model for the stable diffusion for another application.
00:10:13.160 - 00:10:13.524, Speaker B: Yes.
00:10:13.562 - 00:10:58.020, Speaker A: So I think nowadays people can start to create very interesting and complicated a applications and everything can be starting to run on chain, both for the model inference and also for the creation process and of course for the assets trading. And I think we really need high performance blockchain to empower the high volume usages. So that's why we also need modular blockchain to make everything happen because it's not feasible on the L one or existing layer two blockchain technologies. Here's my contact information. So I know you guys are building the fantastic blockchains and especially the high performance decade based modular blockchain. So if you guys are interested in the partnership, just contact me.
00:10:58.170 - 00:10:59.350, Speaker B: Yeah, thanks.
00:11:00.520 - 00:11:30.956, Speaker A: To trade assets, another way is Amm and with higher liquidity we can use order book. So I think with this kind of long tail application models, we use the bonding curve as the starting point and the fund hack, basically it's incentivized trading. But in our scenario we incentivize user holding the ownership of the assets. So during the periods that an investor holds the ownership of the AM models or the assets, they're going to share the dividends of the newly generated incentive. So that's how it works.
00:11:31.138 - 00:11:36.048, Speaker D: Okay, got it. But you buy like a sharing or besides a fixed percentage of it.
00:11:36.214 - 00:11:39.680, Speaker A: Yeah, it's a fixed percentage with a variable price on the bonding curve.
00:11:41.800 - 00:11:42.212, Speaker B: Yeah.
00:11:42.266 - 00:11:43.430, Speaker A: Any other questions?
00:11:45.480 - 00:11:47.460, Speaker C: Is it a linear bonding curve?
00:11:47.880 - 00:12:17.948, Speaker A: Yeah, I think the real issue is not the bonding curve, I mean the parameter for the curve, the quadratic others. I think it's really about the selling price. So for the standard or the classical bonding curve, people make money by selling the ownership. Right. So it's actually incentivized trading. But in our scenario we incentivize the people holding. So the sale price is the original price minus some tax.
00:12:17.948 - 00:12:33.010, Speaker A: But during the period you hold it, you're going to earn some newly generated assets. That's not possible with frantic models because in frantic settings. There's no value occurred to the assets. But in our scenario we have. So that's why we build very different bonding curve, yeah.

00:00:01.480 - 00:00:47.438, Speaker A: Yes, I'm Uma, I'm one of the co founders of Succinct. We are working on making ZK easy to use and accessible. And today I'm going to be talking about our ZK VM SP one and how it makes using ZK in production easy, cheap and really fast. So just to start off with, I think first it's worth noting that ZK is really important to the future of blockchain scaling, infrastructure and privacy. And I think in particular a lot of the problems with like Ethereum that are being discussed right now. For example, fast finality between roll ups, a lot of fragmentation, interoperability, bridging between ecosystems. I strongly think that ZK is the only way that all of these problems are actually going to be solved.
00:00:47.438 - 00:01:54.606, Speaker A: Verifiable computation is something that will help Ethereum scale. And because of this, because DK is the end game, I think in the next few years we'll see that every roll up will become a ZK rollup, every bridge will become a ZK bridge, and in general, all applications like oracles, coprocessors, et cetera, that can use ZK will use ZK because it's so powerful and such a good fit for the decentralization aspects of blockchain technology and actually scaling the overhead that comes with decentralization with this verifiable compute. But I think it's important to acknowledge that today ZK adoption has lagged behind. So it seems like this technology is really endgame, it's really powerful. But today if you look at the top two roll ups on Ethereum by TBL, they're all optimistic rollups. And then you have things like opstack that are being adopted by a bunch of changes in the ecosystem, and that is using optimistic technology, not CK. So why is it the case? Historically, ZK has been really slow and really expensive, and that's a big reason that people haven't adopted it.
00:01:54.606 - 00:02:51.420, Speaker A: So here's kind of a picture of a really beefy computer where all the cores are being utilized. People are about to run out of memory, and if you've ever built a ZK before, you've probably encountered a situation like this where if I want to run my ZK prover, I have to spin up a really beefy AWS instance. And it still is really slow. And moreover, it's really expensive to use these things in production. I think what's even worse than being slow and expensive is that it's really hard for developers to actually use ZK. So here's just a bunch of examples of random ZK circuits written in languages like Circom, Ponky, two Cairo pill, and a bunch of math papers. And today the state of ZK is such that to make an n ten Zk system, you have to basically have a cryptography PhD, you have to learn these arcane dsls and SDKs, and then you have to code in these really weird languages and know the concept of what a circuit is.
00:02:51.420 - 00:03:31.810, Speaker A: And so, developing in ZK is very, very difficult. And all these things combined mean that if you want to actually build a Zk system that's used in production, it takes months, if not years. And we see this in ethereum today, where a lot of the ZK roll ups took several years to go to production behind the optimistic roll ups. And why is that? As I kind of mentioned, there's a very small number of developers who can actually write ZK stuff and have the specialized expertise that's required. The developer, velocity, even if you do have these expertise, is still really slow. You have all these custom languages with really primitive tooling. It feels like writing assembly.
00:03:31.810 - 00:04:09.712, Speaker A: It's super unmaintainable. So for example, the ethereum EVM has a hard fork around every six months to every year. And so if you want to build an l two that's EVM compatible, you also have to upgrade your software every so often to keep compatibility with ZK. Every time you want to do that, it's a really large engineering effort. Furthermore, when you have a ZK system, it's not actually that customizable. So for example, if another team wants to use it and modify some small part of it to add a precompiler or something like that, it's totally impossible for them to do so. And then finally, the audit surface area is really, really large.
00:04:09.712 - 00:04:44.538, Speaker A: You have these code bases with hundreds of thousands of lines of code. It's really complicated cryptography and systems, and it's not really easily understood by many people. And even after that part, it's really hard to keep these things audited as you're upgrading these systems. So it's succinct. We were very familiar with all these problems. We had encountered, a lot of them ourselves, personally building in the ZK space. And we realized for ZK to reach its full potential to go mainstream, the current developer experience and the current entire experience of using ZK production is totally broken.
00:04:44.538 - 00:05:17.974, Speaker A: And so this is why we built sp one or ZKPM. Okay, so what is SP one? SP One is an open source, general purpose performance ZKPM. So let's kind of unpack what all those things are. A general purpose DK VM means that you can just write normal rust code and then use that code to get zero nonproofs underneath the hood. How this works is we have rust. It compiles to RISC five, which is a standard target supported by the normal rust compiler. So we didn't have to do any compiler work or anything like that.
00:05:17.974 - 00:05:58.640, Speaker A: And then we prove that the RISC five Isa with your particular RISC V program executed correctly underneath the hood. For our proof system, we're using small field starts with Fry and the locker room of lookup argument. And so the main point of being general purpose is that again, you can just write normal code, and that's super powerful. And I'll get into more why that's such a big unlock later. The second important thing about Spmont is that it's extremely performant. So it doesn't matter if your general purpose, if it's not actually practical to be used. But we've actually found that SP one's proving time and cost is actually better than the customized circuit world that I was describing earlier.
00:05:58.640 - 00:06:38.000, Speaker A: Our team came up with several algorithmic innovations and a few clever tricks for really state of the art performance for ZKPM. And then we have really strong performance oriented engineering on both our cpu and GPU prover implementations. And then finally, SB one is open source, so all our constraints are fully open source. It's MIT licensed, and that's really important for security and auditability. It's important to understand that we're actually proving the risk by ISA. Like what are the security assumptions we have? It's also modifiable and customizable by external teams. And we've had a few external teams contribute their own precompiles and modify the system for their particular needs.
00:06:38.000 - 00:07:14.992, Speaker A: Okay, so to dive into how easy SP one makes CK, here's an example of a Fibonacci program rated for SP one. And you'll notice that it looks very much like normal rust code, which is that it touch it. With SP one, you can use the rust standard library. So you can use VEx, you can use all that stuff from the standard library. So you can use rust normally. You can reuse all the existing crates and libraries that you really want. So for example, you can use sur day, you can use JSON, you can use the tendermin library, you can use Regex, you can use rust crypto, you can use RevM and ref.
00:07:14.992 - 00:07:48.292, Speaker A: And that's really powerful for the reasons I'll describe later. And we've personally found that our developer productivity with SP one is 100 x, if not more than the custom circuit era. You can use print statements for loops, if statements. All those things were not available in kind of like older ZK languages because you had to write circuits. And then you can use all the rust tooling and all the programs written with SP one are really easily maintainable and customizable because it just uses normal rust. So you don't need any specialized expertise. Any rest developer can use SP one.
00:07:48.292 - 00:08:32.790, Speaker A: And one really powerful thing about being able to reuse existing creates and libraries like ReVM and Ref is that because of this code reuse, the audit service area is much smaller. So for example, ref recently is this rust ethereum known implementation by paradigm, and they recently got audited. And so that's thousands of lines of code that we can just import and we don't have to audit it. We can import res and write a Zkepmore state transition function and reuse their existing audit, and the fact that they're used across a bunch of different ecosystems. So the security story behind programs written with SP one is also a lot better. So overall, with SP one, using ZK, instead of taking months and years, becomes a weekend project. And it looks very normal, which is the intention.
00:08:32.790 - 00:09:13.380, Speaker A: As I also mentioned, SP one makes CK really performant, which was like another big blocker to Zika adoption. Today we have a bunch of algorithmic innovations for our state of the art performance versus other ZK vms. There's a lot to get into there. I could probably spend hours talking about it, but to go over some of them, we use this novel offline memory checking argument. We have this concept, we make heavy use of lookups. We have this multitable setup. So there's certain risk filed instructions that are very complicated to prove and cost a lot of proving overhead, but you only pay for them when you actually use them and a bunch of other techniques.
00:09:13.380 - 00:10:10.528, Speaker A: One of our main innovations was this precompiler centric architecture, which is actually pretty hard to get working in a ZKBM. That was motivated by this key insight that for most blockchain applications, for example, a roll up state transition function or bridging, most of the prover overhead comes from things like hash functions and signature verification. And those usually take a lot of cycles in a ZkVM. So for example, in RISC five, when you compile a catch act hash function, naively it might take 10,000 cycles, which is quite a lot. What we do is we have this precompile system, which you can kind of think of as ZK native assembly, where we have a specialized circuit for these hash functions and signature schemes, and then it talks to our main cpu via lookup argument. And what that does is it makes the raw cycle count of a particular computation go down a lot, often by an order of magnitude. So I have this table that kind of shows a bunch of different programs with their cycle counts.
00:10:10.528 - 00:10:49.186, Speaker A: And you can see when we add our precompiles, the cycle counts go down by a factor of five to sometimes even ten. And that means that your proving time just went down by five to ten x by using our precompile system. So Sv one in general is around like an order of magnitude, sometimes more faster than other zkvms. And a lot of that comes from this compiles that we support. More recently, we've been working on SP one GPU, which is a GPU implementation of our prover. Proving, especially with starts and fry, is a really parallel workload. There's a lot of hashing that can be done in parallel, and other parts of operation are also very easily parallelizable.
00:10:49.186 - 00:11:39.846, Speaker A: And we found that the GPU implementation of our prover improves latency and cost by five to ten x as well. And so with SP one, ZK is now not only super easy, but also really performant. So in all, SV one just lets developers write really normal code and you don't have to sacrifice performance. So it's kind of like the best of all worlds. And I have a particular example that our company actually went through to kind of show you and demonstrate the before Arrow ZK and the after arrow of ZK with SAP one. So our company, when we started off, we were working on DK bridging, and we spent a bunch of time implementing a specialized DK circuit for verifying the tendermint consensus protocol. And so this is an example of the kind of like code that we had to write.
00:11:39.846 - 00:12:23.630, Speaker A: You can see it's very confusing, it's very ugly, it doesn't look like normal rust. There's this specialized DSL that we have, and this is just to calculate a sum in a ZK circuitous pre s p one, the kind of pain that people had to go through. And by the way, this is just like a few lines of code from a file. There's actually a huge folder full of a bunch of different files that in total is thousands of lines of code. To get a tendermint lite client working in ZK with circuits now with SP one, we made a tendermint lite client. And actually I made sure you all the code on the right. It's kind of small, but it ends up, you can see here there's line counts on the left hand side of that and you can see it ends up being like 60 lines of code.
00:12:23.630 - 00:12:43.302, Speaker A: It's probably a lot less. And I'm just going to go through it piece by piece and show you how magical the experience of using SP one is. So you can see that first at the top. We just import a bunch of libraries. So we import this tendermin liteclient verifier library. That's not a library our team wrote. It's maintained by an external Cosmos team and we can just import it.
00:12:43.302 - 00:13:11.868, Speaker A: It's already audited, it's used in a bunch of different places. We just import it. It just works. And then we import the ally library which is maintained by the ref team. And it's useful for doing stuff with solidity and solidity types. Then the main body of the function that's actually verifying the tenement like consensus that enough validator or two thirds of the validators have signed is just in this very small 20 lines of code. All we do is we read in two different blocks.
00:13:11.868 - 00:13:52.260, Speaker A: We use surday to decode them into the appropriate struct. We instantiate a verifier from the tenement library and then we just call the function verify update header that verifies enough validators have signed off and that's all there is to it. We don't even necessarily need to understand like what's going on behind the scenes. We just know that this is a good library for verifying tendermint. It's already been audited, it's used and it's really simple to use in spa one it's just 20 lines of code. And then finally we take the two headers, we hash them and then we turn it into the solidity struct. We Abi encode it and then we expose it as a public output of SP one so that we can use it on chain on Ethereum.
00:13:52.260 - 00:14:22.688, Speaker A: So if you look at these two things side by side, on the left hand side you have the custom circuit tendermint like client that we built. I took three very hard working smart engineers on our team five months to build this end to end. The final lines of code I think was around like 8000 lines of like audit code. We spent several hundred k getting this system audited. It took one and a half months. And it's like extremely complex. There was a bunch of other teams that wanted to use it, and we tried to give them the code.
00:14:22.688 - 00:15:00.110, Speaker A: It was open source, but they had a really hard time figuring out how to modify it. With SB Montenermin, it took one engineer, I think it was actually our intern, 3 hours of work. It's 50 lines of code. As you guys saw, there's barely anything to audit, probably like one day if that. And it's extremely simple, super forkable and customizable. We hosted an SB one tendermint workshop, 50 teams showed up, and now I think there's dozens of people who are working with fork versions of SP one tendermint customizing it for their own use case, because there's a lot of different cosmos chains or comet BFT based chains that want to use it. And yeah, it's very easy for them because it's just normal rust code.
00:15:00.110 - 00:15:27.630, Speaker A: Now. The thing that was really surprising to me even, was that in our old system, we spent a lot of time and effort really optimizing it. And in the end we got the proof latency to be down to around ten minutes. And we were really proud of this achievement. And the proof cost was a few dollars. So in all, I think we were pretty happy with that. And then with Sv one, a big question was, well, you know, the developer experience is so great, but surely maybe that comes at some cost.
00:15:27.630 - 00:15:51.940, Speaker A: But at the end, we found with SP one actually, that the latency when you run SP one gpu ends up being two minutes, and the proof cost is actually pennies. It's much cheaper. And so it seems like SP one is just strictly better in every way. You have a really nice developer experience. It's really easy to customize. The lines of code is really minimal, and the latency and cost of proving is actually way cheaper. It almost seems too good to be true.
00:15:51.940 - 00:16:56.312, Speaker A: And I think one big lesson we learned from this is that because Sv one's so general, you can use it for roll ups, you can use it for bridges, you can really write any program that you want to use ZK for on top of it. For us, it's much easier to optimize it and justify the engineering overhead into writing an SP one gpu. Kruger really optimize how we set up our cluster on AWS, and then find every single bottleneck and performance optimize it to the fullest extent possible. For example, in our ponky two circuit world, it wouldn't have made sense from an engineering ROI perspective to put that prover on a gpu, because it's only one use case and then you know how many people are going to use it. It's really hard to customize. And so because SB one is so general purpose, we can actually get much better performance and cost than more special purpose ZK systems, which was a really surprising insight, even to me. Another example that I want to briefly touch on is that you can use SB one for tenurement and bridging, but you can also use it for rollups.
00:16:56.312 - 00:17:36.600, Speaker A: So currently, a lot of the ZK rollups are kind of the custom circuitous version of the world that I described. Or you have these teams that spend a lot of time and effort writing these custom circuits for proving an EVM state transition function. With SP one, you can just take ref, you can import ref and then get it working within SP one takes around a weekend. And then the surprising thing actually is that the proving cost per transaction is still pretty practical. So this is actually in a pre GPU world, these numbers were run on our cpu prover. And so with the GPU prover, the costs only get better by like a factor of five to ten. But the proving cost per transaction for average Ethereum blocks ends up being between one to $0.02,
00:17:36.600 - 00:18:28.180, Speaker A: which is already pretty practical, especially given that roll ups are already paying Ethereum a similar amount for DA and settlement. And so it points to the fact that the future of kind of Zke vms and roll ups in general is something that would be SP one based and not the custom circuits that we're used to for today. So our hope is with SP one now that ZK is really, really easy. It's like a weekend project. It's also cheap and fast that now we finally have all the tools in our toolbox to make ZK go mainstream. Now developers can experiment freely and the number of developers who are able to use ZK is 100 x bigger. And so we hope that every roll up team, all bridges and all the kind of applications that I highlighted earlier are now able to use EK in the way that it's meant to be used.
00:18:28.180 - 00:19:18.228, Speaker A: And then the last thing I want to touch on that a lot of people ask me is like, okay, this sounds really awesome, when can I actually use it? And so we recently completed around four audits, including a public audit competition that would, you know, anyone in the world can participate in for a large bounty. And we just finished that up and we're launching mainnet production ready verifiers in the next few weeks. You can already use it on Testnet today. And from day one we have a few top teams using it for real production use cases like the roll ups and the bridging that we're excited to highlight when SP one goes live. So, yeah, you can get started building with it today and then, yeah, use it in prod in a few weeks. And, yeah, there's my contact information if you have any questions. Cool.
00:19:18.228 - 00:19:19.080, Speaker A: That's all.
00:19:21.100 - 00:19:38.200, Speaker B: Thank you. I actually have one question here. As we all know, like, SP one can be used for security, Osprey, etc. I don't know if there are already projects like defi projects, gaming projects. Experimenting with SP one S is extremely productive and general focus.
00:19:39.110 - 00:20:20.180, Speaker A: Yeah. Today I would say the one big category is bridging. So, for example, we work with teams like Celestia and avail that are these kind of next generation l one DA layers and their bridge to Ethereum, because they're often used for Ethereum roll ups, uses SP one. Polygon's agalar is also being built with SP one. So that's used for, like, interoperability and for, like, roll up interoperability. We've integrated with, like, a few roll ups, like, for example, Tyco and sovereign SDK, and we're working on a few other ones to have SP one have full z capability for sprawl of rollups. Yeah, those are the big categories.
00:20:21.560 - 00:20:29.260, Speaker B: Got it. Yeah. And also for the spray math, what's the main difference between SVM ref and ivory zeros before?
00:20:30.560 - 00:20:57.540, Speaker A: Yeah, I think they're pretty similar. Like, it's just importing existing rust code to get a ZK EVM state transition function for us. We did some work on the rep side to actually get it to compile within SP one because there's some crates that won't work within SP one. If you want to talk to your file system and stuff like that. So you have to do some minor refactors. Our repo ends up being very, very small. It's like five mm lines of code.
00:20:57.540 - 00:21:03.110, Speaker A: Yeah, that's the main difference, but I think it accomplishes the same kind of functional.
00:21:04.690 - 00:21:06.310, Speaker B: Yeah. More questions?
00:21:06.810 - 00:21:43.290, Speaker A: So, how hard it is for, like, another l one to produce, like, a library, like the one that you showed the tenderman has? Is it like a big lift? No, like, if you already have a rust version of whatever you want to prove, like, if you have rust code for your program, it's really easy. Like, you just import your library and you write your program with an S P one. If you don't have rust code, rust is like, currently your best supported language. So it's pretty important that you'd have to take your existing code and write it in rust.
00:21:46.630 - 00:21:48.090, Speaker B: Cool. Yeah.
00:21:52.070 - 00:22:25.530, Speaker A: How abstract are the interfaces to the backend? Like, how depend dependent is SP one, P three? How, like, how dependent is SP one on? I would say that our, like, our proof system is. There's a lot of different components of it. So there's, like, the actual proof system, which is starks and fry. Then there's, like, our lookup argument. That's actually, like, totally separate from Pomkeeper. It's, like, implemented. It's kind of another layer.
00:22:25.530 - 00:22:57.120, Speaker A: And then there's, like, also our whole recursion stack, which is totally within the SP one. It's, like, totally sewn thing. I would say for clunky three provides a really, really great, really optimized, like, fry implementation that we use. And so, for us, like, the fry implementation is pretty tied to our recursion system. So it'd be hard to move to, like, a different fry implementation. But, you know. So I think moving to a different back end would be, like, a very significant change.
00:22:57.120 - 00:23:09.000, Speaker A: But we are also experimenting with, like, upgrades to a proof system for improved performance in, like, future versions of SP one. So, like, SP two or something like that. But it is, like, a very significant change.
00:23:13.620 - 00:23:22.020, Speaker B: Cool. Any more questions? If no, then thank you. And we will have our last speaker for the infrastructure side. As a founder of Delta.

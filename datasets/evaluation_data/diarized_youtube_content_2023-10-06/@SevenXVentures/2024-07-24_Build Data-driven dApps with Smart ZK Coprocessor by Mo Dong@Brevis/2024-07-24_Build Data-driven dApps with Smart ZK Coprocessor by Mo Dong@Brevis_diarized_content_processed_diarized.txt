00:00:00.320 - 00:01:09.812, Speaker A: To your point, I totally believe that, you know, right now, the intent frameworks constraint system is actually very, very limited and sinkhole. And there's a reason for that, right? So, you know, it's because the um, as kind of precisely mentioned, is not really good for that. And uh, you know, but with Rubys, as we'll kind of talk about later, you can actually expand the type of constraint system you can do in time based frameworks in very, very amazing way, because now you will have better access of data, better access to compute in an optimization. So without further ado, I'm mo, I'm here to talk about privys. Privys is so, you know, through this talk, hopefully I can deliver to you how you can build data driven dapps with a smart native co processor. The goal of premise is really to, how do you actually do this? Okay, this works. The goal of premise is actually to introduce a new kind of construct in web3 application, which is called an asynchronous architecture, a sequence computing architecture.
00:01:09.812 - 00:02:08.624, Speaker A: Now, what is a computer architecture? Well, let's take a review in the history of Web two itself. So before 2008 is actually building a synchronized based architecture where you have this monolithic web server serving everything for the user in a sequential manner. The web service does request handling, access control, computing, data access, literally everything. It was very clear back then this type of architecture would not be able to scale to support the map of growth we were seeing in Internet early days. So this is how we evolved in the last 20 years into this new architecture where you have web server still. But the web server itself becomes a very thin piece of software that is just acting as a coordinator between the user and specialized backend services. The users will be able to send the client concurrency request to the web server and the web server will just turn around and relate the request to different specialized services.
00:02:08.624 - 00:02:55.770, Speaker A: And these specialized services will do the processing and send callback functions back to the coordinator. So the web server can assemble and kind of coordinate between these return data, represent to the user a final coherent result in the web return. So this is how you are seeing Twitter streams, Facebook streams, every single web two application you're using today is built on this type of architecture for scalability. Now if we look at where we are in web3 today, it is actually worse than web two. Before 2000. We are treating essentially blockchain vms, evms vms as this model of it, web server backend. Everything is handled by smart contract and then, you know, it's basically essentially handled in a sequential fashion.
00:02:55.770 - 00:03:44.882, Speaker A: The worst thing here is that the performance is really bonded. It's, you know, for any single blockchain, the computation is bonded. Data access community is bonded because fundamentally, even with L2s, everything is running in a replicated compute. Replicated storage, due to the high overhead of communication, fundamentally limited the combination power rooted in the consensus protocol itself. So a simple example that I always go back to is if you want to build a trader loyalty program in Uniswap, let's say you see this type of trade logic program everywhere in centralized exchanges. Say a user traded $30 million in the last 30 days. In the next 30 days you should be getting a 30% fee discount.
00:03:44.882 - 00:04:50.190, Speaker A: You see this everywhere in central exchanges, but you don't see this in any of the taxes. Why? Because if you want to do this, you have to pay 8 hours of the block time and 40k transaction fee just to access a user's historical trade, you know, in the last month for a single user. This is because right now on blockchain there is no trust free access and the computation capability possible based on the historical onchain data such as storage slots, transactions, events and all that. So what Brevis is trying to do is reverse, is trying to solve problems like that. So with Brevis, what we're trying to position blockchain is a simple coordination between different off chain computing components. Of course, many of the asset related computation are still going to happen on blockchain and the recorded on blockchain who has how much asset, who transferred how much asset to who. But the winds and hows of these asset transfers should be offloaded to an off to component to combination.
00:04:50.190 - 00:06:02.180, Speaker A: But the most important thing here to note is that because we're talking about web3 and we're talking about blockchain applications, the most important thing is to ensure the entire computation cycle is maintained in a trust free environment. That is to say that even though we're introducing this asynchronous off chain computing component, everything should be, every computation step should still only just rely on the trust assumption of the logic itself. This is where the ZK comes into play, where the computation process can be run in the ZK domain so that the result is verifiable on the blockchain directly without relying on any third party trust whatsoever. So yeah, so there are many components in Brivis, but we already have something called the ZK coprocessor, Brivis ZK coprocessors that is running production. So I will just dive a bit deeper into this. So for Brivis native coprocessor. What it does is it can generate ZK proofs for arbitrary computation across any historical on gene data, and it allows smart contracts to use that data transfer in their business logic.
00:06:02.180 - 00:06:42.758, Speaker A: So to build a Brivis powered application is very simple. There are really just three steps. The first is that you specify what type of data you want to read. Secondly, you run computation on top of this data based on your business logic. And finally you bring the data back to the blockchain, verify it, and then use it in your smart contract. So how exactly does that work? First of all, for data access bravest today, right now, if you look at our SDK already support a vast majority of the data access. That is, the data that is available on blockchain today, including storage stock, which is like the variables in different smart contracts, the NFT ownership, the token balance, these types of things.
00:06:42.758 - 00:07:16.970, Speaker A: And not only that, but also receipt, transaction receipt that contains transaction events and transactions themselves. So these data, using these data, you can actually access users historical actions and interactions with different types of applications and derive insights in the computational result out of that. And of course log information comes there as well. So the read process is quite simple. You just like specify what activity you want to read and add it here. This very simple question. That is how you can access the user's unit swap trading volume on a particular pool.
00:07:16.970 - 00:08:08.730, Speaker A: And the second step is to do compute. So revisit is based on ZK, but you don't actually need to write anything in state circuitous. We provide a very high level data stream API with Mapreduce future group bytes or zip this type of primitives. So you can actually collectively process the data you get in the first step and generate combination results easily. So this three lines of code will allow you to compute a Uniswap trading volume of a particular user using Revis. And finally, after you generate the proof of computation and the data itself, that the proof itself will be sent back to the blockchain via a standard callback function. This is where you also need to implement the callback function in your smart contract to receive the co processing result and use that in your business logic.
00:08:08.730 - 00:09:03.120, Speaker A: So to build the same thing with Rebis. Now that the patent becomes a Uniswap smart contract, we'll be able to send out a request and say that, okay, now I want to get a training volume of user to a onchain process contract. The onchain process contract will in return invoke the ZK co processing functionality of Revis. Revis does the computation and then send a trading volume data through its callback function to let the Uniswap report what is the trading volume, what is trading volatility of a port and so on and so forth. So that you can do things like volatility based fee, you know, trading volume based the fee discount and many things around that time and previous super high performance proving trading volume of users across millions of transactions. Uniswap only costing about $1. Sorry, I've got cold.
00:09:03.120 - 00:10:31.500, Speaker A: So there are many things you can do with revenue. Data driven DeFi is one big category. I talked about vip trading programs, but volatility based fee pricing, you know, pricing but many things I like, you know, retrospective farming reward protocols very valued each LP not based on their timelines of the deposit, but actually based on the amount of fee generated by each of the LP comparing to all the other different LP's. But very importantly also on the consumer facing applications. One thing I do want to mention, it goes back to Klavis talk, is that bravest can actually expand the type of constraint system you can do in the intent frameworks that using braveys now you can have a user to specify. My intent is that I want my trade to be executed when the price is moved to a certain point or I want my trade to be executed when the volatility is high, or I want my liquidity position to be rebalanced if the time we did average price already deviated from my range for like a consecutive 2 hours or 3 hours. These type of future conditional intent is something that is possible to build with brevis because brevis now have the capability to verify and prove unchained that certain triggering events actually already happened.
00:10:31.500 - 00:11:36.480, Speaker A: Sorry. And then finally there are a bunch of data and computation power infrastructure such as cross chain, you know, because revisit support, cross chain functionality native plane. So we can have the capability to build cross chain oracles by the capability of relaying the block adder from one blockchain to another using ZK so that once the block header is available, you have access to every single state that you can imagine in different blockchain. So imagine that you just launched a roll app and service chain as application chain and you don't have any access to any chain link Oracle. But with reverse you can easily get the capability to access an Ethereum chain link Oracle price via newly launched and ROA as a service application chain. And there are so many different more use cases for revis as well. So finally I just want to touch base on how you can use a k framework in general, when you're talking about off chain verification.
00:11:36.480 - 00:12:30.698, Speaker A: In ZK, there are two models actually you can choose in virtus. One is, of course, you do this in pure ZK. It's very straightforward. So you do everything in ZK computer and generally proof. The second model is called crypto economic security plus a ZR proof. So this is kind of an optimistic co processing model where you have a proposal to propose initial claim, saying that this is the, this is like the, this is like the co process without proposed, without actually going through any improving process. Now, just like an optimistic rollout with a safety fraud proof challenge, you can now submit a safe nature proof to challenge that if a challenger detected there is a fault in the coprocessing itself with this model, you can actually get much lower cost, but you don't actually lose any security.
00:12:30.698 - 00:12:56.690, Speaker A: It is not to say that you are actually dependent on the optimistic proposal because you still have the ZT security as the last line of defense. You're just trading off a bit more latency with much lower cost. And of course, you can support more features using this model because now you can prove things like proof of completeness and proof of non existence. So, yeah, I will just stop my talk here and see if there's any quick questions.
00:12:57.550 - 00:13:14.770, Speaker B: Yeah. Before we go into the question session, just like a reminder, people in the bag, you can feel free to finance it in front. And also, I have actually one question, because the Nasir proof is kind of new, and I don't know what's the current stage of this GK system?
00:13:15.150 - 00:14:24.906, Speaker A: So, you know, when we're saying, like, nature proof, so there's a Zika Nasir proof paper, but that's kind of not related to the architecture that we are mentioning here. So, you know, the nasal proof in the paper is basically saying that you can verify if a proof is wrong without actually verifying the proof itself. So. But what here, now, what we're trying to do here is more pertaining to an optimistic roll up with a fraud proof so that you are not only sending, you're not sending your completion request directly to a ZK proofer marketplace or ZK proofer network. Instead, you send it to a proposal network. And in this case, we implement an ABS as an optimistic proposal, and the proposal will propose a result without actually generating any ZP proof, because we're using the ABS. So it does come with a default security of proof of state security that you can directly use if you want, but if you don't want to directly rely on the proof of stake security, you can wait a sufficient time window to initiate challenge if needed.
00:14:24.906 - 00:14:27.070, Speaker A: So that's basically how.
00:14:27.770 - 00:14:36.202, Speaker B: Got it. And for Defi and CK space, are there any new use cases you're exploring in Azure or in your pipeline you want to measure?
00:14:36.306 - 00:15:15.322, Speaker A: Yeah, I mean, like, you know, every Defi protocol right now is moving towards modern based design, not just like Daxis, but also lending protocols, perp and everything. So many of these things will now start to be powered by more insights for launching historical data to implement things like portable fee, boosting revenue stream boosting user engagement, user retention, acquisition fees. So yeah, we're seeing a wide landscape of Defi protocols, both old and new, moving towards that architecture. Cool.
00:15:15.426 - 00:15:23.030, Speaker B: Yeah. Any more questions from the audience? And audience in the back? Okay.
00:15:26.610 - 00:16:09.038, Speaker A: I'm just kind of curious how much these computational requests cost. Like the end users. Yeah, so very concretely so this is like kind of configuration cost reference right now using revisit, it costs about. So, you know, it costs about $1.4 in off chain computation resources if you try to verify and generate proof of a user who traded about 10,000 transactions on Uniswap, like a certain period of time. So that is like already extremely scalable. Because if you think about Uniswap right now, in the entire Uniswap trading trading amount on a monthly basis is about 800k.
00:16:09.038 - 00:16:46.670, Speaker A: It's not that much actually. So it can actually handle very large scale use cases already using pure ZK and verification cost really depends on different chains you're talking, but from absolute gas perspective, it costs about 200k. Gas tools verify a proof on chain, but the benefit of taking a proof that you can actually aggregate multiple groups together to amortize the cost, you don't actually have to verify each of the proof. You can generate individual proofs and aggregate these proof as a single one with a bit of trade off on latency and verify that. And therefore, like the cost of verification is not really a major concern. Thank you.
00:16:48.250 - 00:16:49.390, Speaker B: Okay, one more.
00:16:50.540 - 00:17:08.348, Speaker C: What is the RF collaboration of securities for the gpus on integers like say a solver that is solving in general? Could it go to a CP call message to check out a user is eligible for a feature discount? And how would that workflow do you like?
00:17:08.404 - 00:17:50.400, Speaker A: Yeah, so for intent we are more looking at things like transferring ten automation where the user instead of have to specify the intent he wants to access right now, they can now specify future intents based on conditional triggers, basically saying, okay, I only want you to swap my USDC to Uniswap. If Uniswap surprised me to a certain level for a certain period of time, it cannot even just be a single point in time. The user can specify the constraint in a much broader way and in a conditional and future oriented way. So this is like how we are seeing many of the work right now is using service to build their new framework.
00:17:51.100 - 00:17:52.160, Speaker C: Okay, thanks.
00:17:53.380 - 00:17:54.180, Speaker B: Thank you.
00:17:54.300 - 00:17:54.844, Speaker A: Thank you.
00:17:54.932 - 00:17:56.060, Speaker B: Thank you. Next up, we have.

00:00:15.370 - 00:01:25.890, Speaker A: Avail Avail is a new data validity focused album blockchain that focuses on enabling roll ups. On top it, this is a project that was initiated within Polygon in late 2020, and I'm one of the I originally co founded Polygon or Matte Network back in 2017 and we spun out the project in March earlier this year. So we are now a separate entity. So today's session will just go over what is available in general, the architecture, what use cases are really targeting, and in general, bit about the use case development agenda. So I just want to set the context for this talk. In the last two, three years, what has happened is roll ups have basically taken center stage as the way to do execution. So before roll ups, there used to be this whole AlT l one sort of paradigm for scaling execution.
00:01:25.890 - 00:02:17.366, Speaker A: But once roll ups have been proved to work, these have taken center stage over the last two, three years and they are recognized as the main way to do off chain computation. And while today's role of focus on scaling execution, what they really rely on is this very scalable base layer. So Ethereum in general began as a very execution focused blockchain. It didn't have data availability in mind for roll ups later. And so of course Ethereum has been pivoting its roadmap to be more roll up friendly or data availability focused. It's a production blockchain with billions of dollars of assets in production, so it's going to take some time. So you must have heard of things like Protodank sharding, dank sharding and such.
00:02:17.366 - 00:03:28.632, Speaker A: But those are like, those will take some time. Protodyng sharding is supposed to be sometime next year, but dank sharding is going to take at least three to five years is what we feel. And so roll ups cannot be really waiting around for that kind of scalability. And so that's why that's the basis for avail, essentially that roll ups are only for data availability and avail provides a very scalable data availability layer. And I'm just going to begin with this thesis that what we really believe is that every important base layer blockchain is really just going to end up as a TL layer because execution is more or less being pushed onto roll ups on the L2. That's the whole positioning behind avail and what it really is agrenel architecture bit. But essentially it provides raw block space for roll up chains, so it provides consensus in ordering two roll ups.
00:03:28.632 - 00:04:21.630, Speaker A: So there are two parts to the roll up story. So roll ups handle execution on top, but they really need ordering and a consensus service at the back end. And that's what Ethereum does for roll ups today. So roll ups really take in some transactions, sequence them and then push them to the Ethereum base layer for ordering finality, for example. And of course they also push other items like groups for example, so that you can have a validating bridge to Ethereum for Ethereum assets and so on, for example. But really the base layer is the main consensus and ordering. So again, not getting too much into what ethereum does, but avail, for example, is that base layer, which is focused on providing scalable data availability.
00:04:21.630 - 00:05:19.260, Speaker A: And the main difference, the architecture, is that avail doesn't really have any execution like it has a minimal execution runtime, but doesn't have smart contracts. So it basically separates that function so that we can scale data separately. And that's why we are able to of course support execution environments of any kind. So EVM fairplay, but also newer VMs, move, whatever, because we don't do any execution at the base level. And we also implement a very novel construction called data sampling. Our approach is based on KZG polynomial commitments and quality proofs. So the closest project that you could track with us is Celesia, which does a more Merkel hashed and fraud proof based approach.
00:05:19.260 - 00:06:34.690, Speaker A: What we do is more similar to what dank sharding the roadmap intends to do, use a combination of KZG vulnerable commitments, or the data and validity proofs rather than fraud proofs to do the data sampling. This of course allows very light clients to sample the block pretty efficiently. And we expect that there will be millions of light clients that will be run through this. And of course we can enable all kinds of roll ups and as well as including something in the short term that we are focusing on, something called viridiums and optimiums or even health three chains. Essentially this is the architecture. So we have roll ups submit data to the block. So there is this original data, we eraser code the data, then we kind of extend the data using KZG polynomial commitments, and then we put the commitments into the header, then we kind of propagate to all the validators in the ecosystem, and then finally the block is created.
00:06:34.690 - 00:07:25.438, Speaker A: Happy to answer more questions on this later, but this is the rock. So we have this concept of application ID, and each application ID corresponds to a roll up, for example. And so you can actually put different roll ups, can put data into the same block and be differentiated by application ID. And because we use KZG permanent commitments, we are able to ensure that the commitment of the irrigation data is the same as the commitment, for example. And the beauty of this is we can actually increase the matrix size as well. So this is the rough layout of the matrix. So we construct like an m cross n matrix, it becomes a two m cross n matrix, and we can create a commitment for each row.
00:07:25.438 - 00:08:25.426, Speaker A: And because kzg are homomorphic in nature, so this c one to c n can then basically be extended to c n minus plus one to c two n, for example, again, can get into this in much more details later. So there is this validator network, which we use consensus. We use the substrate node from the polka dot ecosystem for constructing the validator node. And so we use grandpa and Babe consensus for this. This is like a hybrid ledger consensus, where Babe takes care of block production and grandpa does eventual finality. Kind of similar to gasper, but I'm not getting into the details, but essentially it's a BRF based data selection and mechanisms. The main difference here is the finality is on chains, not on the blocks.
00:08:25.426 - 00:09:31.434, Speaker A: So we do like a series of chains, for example. So this is pretty robust, and we can support up to 1000 validator set for now, with the introduction of BLS in our system, we can actually go up to ten K validators or more as well, but we start with 1000 validators. There's also a unique nominated proof of stake, which is very different from delegated proof of stake. Internally, the Portora SDK essentially uses something called fragment, which essentially ensures that stake from nominations. It's called nomination instead of delegation. It flows to a nomination pool, like a pool of validators, rather than to a single validator. So essentially, there is in protocol logic to ensure that any delegation or nomination in this case moves throughout the system, is kind of evenly spread throughout the system, so that you don't get into stake decentralized centralization sort of issues.
00:09:31.434 - 00:10:21.126, Speaker A: And we took a conscious decision of this because before at Polygon, we used sentiment in our polygon POS system, and there were very large stake centralization issues, because top seven or eight parameters used to control 67% of the stake. So this is very useful from that context. And the second component in our network is the light client. Essentially, this is like an independent node that kind of randomly samples data initially with the full node. But we have been working over the last couple of years to build out this whole p two p. So the light client network is the p two p network in itself. So the first light client bootstraps of a full node, but the other light clients then can bootstrap off a peer light client.
00:10:21.126 - 00:10:53.558, Speaker A: They don't really need access to a full node in itself, for example. And so you have this almost, it's not technically equivalent, but almost torrent like structure where a new light client enters a network and they just start bootstrapping off the lightline networking itself. We also implement suddenly a distributed hash table implementation on the light client, which enables this overlay p two p network. And so this is actually one of.
00:10:53.564 - 00:10:56.598, Speaker B: The p two p. Are you doing it?
00:10:56.684 - 00:11:46.898, Speaker A: Yeah, so we basically started with implementation of the IPFs lip PTp, but then we chucked that out. Then we went to the low level, like Kadamlia implementation of the p two p for this. And so we actually build out a lot of work on this. But yes, it's based on the Kadamlia lip P two B credit. And we also gave a presentation of this at Kadamlia Con during SBC, but happy to chat more on that. And the idea with the lightline is that with only a few hundred LCs, we are able to kind of the entire block get verified pretty quickly. And so the more the lightlines we have, the quickly the verification can be done.
00:11:46.898 - 00:12:30.146, Speaker A: And the main thing is that you don't really need to trust the validator set after the blocks have been finalized. The validator set is only for the initial block finalization. After that, once you have the light land, it's very light, you can embed the light land into sequencers and such. And you don't need to rely on any honest majority. It's basically honest minority assumption. Once enough LCs have sampled data also remains available on the DSP. Yes, I don't have it on this PDF, but we have a browser light client that we are releasing soon.
00:12:30.248 - 00:12:31.300, Speaker B: I'll talk to you.
00:12:33.350 - 00:13:14.366, Speaker A: Again. Importance is that you don't need to rely on centralized RPC, you just run your light client. You can actually use those RPCs in general. And the interesting thing is we are now integrating, starting to integrate with wallets who can run this light client, embed this light client within the wallet so that what we believe is data already sampling light cans will increasingly be on the wallet side. And because ZKP systems are also improving, we are also actually doing a POC for embedding a proof ZKP proof verifier in the wallet as well. This is some performance metric. Actually, this is a little dated.
00:13:14.366 - 00:13:57.854, Speaker A: In our latest release we have had like about 70% improvement. But just to illustrate that the block size increase for our blocks so we have benchmark up to 120 and MB blocks. We start off with a very modest two MB kind of configuration, but you can see that the performance is pretty good even in case of 128 MB blocks. And our block time is set to be 20 seconds for the DLA. So we are very comfortable in even doing 120 blocks. 120 blocks is like too much. We don't really need those at the moment, but we have actually increased performance here by up to 70%.
00:13:57.854 - 00:14:50.618, Speaker A: So this is like more in the range of two to 3 seconds. And proof generation is very trivial. We do a very light circuit for the KJVs and so the verification is also pretty low. Okay, so quickly, in general, what can be built on top? Any kind of roll ups of course, sovereign roll ups, voldiums, optimiums, app specific chains. We actually have integrations for the op stack ready for running optimiums. We have polygon, ZKVM, Voldium ready. We are working with mothera from Stackware very closely to do l three app chains.
00:14:50.618 - 00:15:57.080, Speaker A: We are hoping to have the arbitrary nitro integration up and running pretty soon and hopefully the ZK sync One also should be out next year. We also work with newer sort of VMs as well, like sovereign labs with Risero for example and so on. We also have built out a data attestation bridge. So this is like a special bridge from avail to Ethereum. So initially we built that out as a optimistic construction, but now along with we have been working for the last nine months or so with suspend, which is the team which has built out the telepathy protocol for Ethereum, the sync committee protocol, and with them we have built out a grandpa DK light client bridge which allows us to do a bi directional bridge between avail and Ethereum. And this can be deployed to any EVM compatible chain. So we plan to do this on all the major Ed two s as well.
00:15:57.080 - 00:16:57.126, Speaker A: We're not getting into sovereign roll ups too much. This is our development stage and timeline. So of course the project began way back in late 2020 within Polygon. But our second long running testnet was finished in September and we are now on our incentivized testing, which we are onboarding around 300 verators for now, mostly our tier one and tier two variators. We will scale up to 1000 and our rough target for main net is Q one of 24 next year. Yeah, these are some of the optimizations that we do want to do. So like currently, if you remember, we have these row level commitments, but we are trying to do KHG multi group like a multi group opening for the entire row.
00:16:57.126 - 00:17:39.320, Speaker A: So that right now we have M cross N or two n cross n. Sort of a group generation thing. But this we can bring down to M complexity because the multi groups just need to be dated once. And as I said, we already are almost finishing up the Zksar based data edition bridge, which is a grandpa. Yeah, I mean, I think that was just a quick rundown of the project. These are some important links. Yeah, I think that's it.
00:17:39.320 - 00:17:41.880, Speaker A: Thank you.
00:17:45.930 - 00:17:53.670, Speaker C: Challenges fortunately audience.
00:17:56.730 - 00:18:22.654, Speaker A: I mean ideal air also uses KC complicated angle. Doesn't have data. It's coming up. It's not, it's a two year effort. We already did that. We know how. I like Shigram a lot, but let's look at the, basically it doesn't have database sampling.
00:18:22.654 - 00:18:45.020, Speaker A: Database sampling takes, once you get into the weeds, it takes at least two years to build because it's not reusing any infrastructure. You have to really build out the P two p infrastructure for that. And yeah, I don't see data sampling coming from another project within two years if they're starting now.
00:18:46.750 - 00:19:30.406, Speaker B: So yeah, I think they are doing proof custody for data first, which works better with their station. Like Dave said, since you cannot fork money from the layer one network, so you cannot do sampling before. So to adjust where the data is and where it's not, but custody works. Now I want to ask a question about exactly that PTP thing you're talking about. So we have been talking about how live clients and how end users get access to the data. And I'm very curious on how roll ups or operators publish data onto the network. If you compare this to the layer one design of Gobank sharding now what the genitals is sampling.
00:19:30.406 - 00:20:06.340, Speaker B: That has been mostly solved from a sampling perspective with the dissemination of the data to the network. You have this many validators that all have to host data that these site clients are querying from. They all need access to from some form subset of the data that they are able to serve to these type clients. You have six large blocks and a load of book time. Or you can just put twelve second book time all day one. It becomes a really difficult challenge to keep that decentralized. So how do you efficient roll ups publishing data onto the film as well?
00:20:06.970 - 00:20:20.410, Speaker A: So if I understand the question is roll ups submit data to this increasing amount of data to the network. What is the centralization problem?
00:20:20.480 - 00:20:31.580, Speaker B: You are the federators that the first hop. So the fedators that are initially hosting the data for life clients sampler. How do they get access to the data.
00:20:32.590 - 00:21:05.510, Speaker A: So see the workflow. Okay, let me come out of the workflow again. Right. So what we do is basically, so you submit data to, let's say via the right line, to an RPC, for example, to the full node or the validator node. The validator node, basically, depending on the leader selection, takes in the data, constructs a block, provides it to the other validators, they come to consensus and finalize the block. So that's the first step. Basically, the lightline will then take in the headers from the finalized block and then do start randomly sampling a full node.
00:21:05.510 - 00:21:30.026, Speaker A: Once one lightline starts randomly sampling the full node, it also stores the data, some of the data that samples on the DHT on the lightline. The second lightline that comes can initially query this lightline, for example. And then if they find the data, then they can also store it there. But then otherwise, then they go to the full node.
00:21:30.058 - 00:21:37.022, Speaker B: But once you have proactively disseminate the data to nodes on the DHT, but rather you wait for those notes.
00:21:37.086 - 00:22:17.966, Speaker A: Yes, certainly we require a set of LCs to be pulling the full nodes for this, but the assumptions are that only a few tens or hundred light lines are really required to quickly randomly sample from a block. And the idea is that we expect that with our work, with wallets, for example and so on, we should be able to have a few hundred or 1000 light lines easily doing this over time. But essentially with wallet integration, we expect that number to go much, much higher. So we are actually thinking of like a million light lines or so.
00:22:18.148 - 00:22:28.878, Speaker B: So more good burden of publishing the data with the builders or the creators of the data and pivoting it to all the different nodes that can help further to somewhere.
00:22:28.974 - 00:22:58.324, Speaker A: Absolutely. Of course, the validators also store this data because they are incentivized by the native tokens, like incentives, for example. So validators do it, of course. But full nodes and this new category of lightlines, and let's say roll up sequencers who embed this lightline also have an incentive to kind of very similar to how, let's say ethereum full nodes. But this is slightly different.
00:22:58.442 - 00:23:08.804, Speaker B: It starts to go very difficult disseminated to lots of calculators, like full nodes that once you reach those numbers above two megabytes blocks.
00:23:08.852 - 00:23:22.270, Speaker A: Yeah, no, you're right. And we have been modeling, doing a lot of modeling on that in terms of how information can be discriminated. So I'm happy to share more later on.
00:23:25.850 - 00:23:43.840, Speaker B: I'm very curious. I've been arguing for layer one, to adopt the discovery DHT, the disc five thing, they have to publish the samples. I very much agree with the design part of the Fl project, but then I think the publishing part is actually an interesting.
00:23:45.250 - 00:24:05.490, Speaker A: Yeah, we are not saying we have completely solved all the challenges, but we have done a fair bit of. There are still some issues with Ptop. We still maintain, like a whitelist, for example, for PTop, because DDoS attacks and all that. But we have solutions.
00:24:11.560 - 00:24:12.710, Speaker C: Any more questions?
00:24:13.720 - 00:24:22.120, Speaker B: Yeah, can I actually know what about the main difference between the two solutions of the database sample between available and flash?
00:24:22.540 - 00:24:22.904, Speaker A: Yeah.
00:24:22.942 - 00:24:23.144, Speaker B: Okay.
00:24:23.182 - 00:25:08.280, Speaker A: So Celeste uses this Merkel hash based and fraud proof based technique. So essentially, when roll ups, for example, send data to Celestia, so they will do the origin, do the Merkel hash commitment, for example, and then the light clients have to do this fraud proof play this fraud proof challenge game. Right. So there's like a period where you have to prove that the encoding was correct or not. So if I were to dumb it down, it's kind of similar to how optimistic roll ups and Ek roll ups do. It's not really the same, but the timing windows are different, for example, but they do a more optimistic kind of implementation. We do a more validity based kind of implementation.
00:25:08.280 - 00:25:51.000, Speaker A: And the real result of that is, let's say, if you're running a ZK roll up on, let's say, celestia, for example. So let's assume that you've created the validity proof for your roll up, but you still need to wait for the fraud proof challenge window on Celestia to finish before you can get DA guarantees on avail, because you have a validity proof, and we kind of create the proof. Very. These are the benchmarks. Right. So as soon as our blocks are finalized, you get da guarantee as well. So primarily it boils down to the developer experience bit.
00:25:51.000 - 00:26:07.660, Speaker A: So Sylvester started probably like a nine month before us. So we are little behind in development. But essentially it's a fraud proof, validity proof kind of an argument, but on a da thing, it's just a performance.
00:26:12.080 - 00:26:13.310, Speaker C: No more questions.
00:26:18.180 - 00:26:47.044, Speaker A: Yeah. Okay, good. So before at Polygon, we built pos, we use tendermint. We use tendermint as one of the nodes in the polygon PoS network. And so we worked with tendermint extensively. It's good. But when we were starting ovale, we had these two choices, and substrate was written in rust.
00:26:47.044 - 00:27:29.350, Speaker A: Our whole stack is based in rust. It's pretty modular, very easy to make changes. We can suppress runtimes, change runtimes. It's a lot easier to work with. It also gives us a lot of things out of the box, like grandpa wave consensus, for example, nominated proof of stake tendermint or specifically cosmos proof of stake has this whole delegation centralization issues. And also we wanted a clear path to go from 1000 monitors right now to probably ten k or more liter and so subset has that very clearly. So we want to be a very decentralized sort of l one.
00:27:29.350 - 00:27:32.150, Speaker A: So those are where some of the.
00:27:36.920 - 00:27:41.308, Speaker C: Traveling machines upstairs. And we next have, we have the.
00:27:41.394 - 00:27:41.610, Speaker A: Thank you.

00:00:02.570 - 00:00:18.174, Speaker A: Thank you. Thank you. I'm Dan. Yeah, this talk will be it'll be, honestly, like, a little bit short. I am, like, super congested from a very dusty hotel. So if I go a little slow okay.
00:00:18.212 - 00:00:18.414, Speaker B: Yeah.
00:00:18.452 - 00:01:02.106, Speaker A: So PBS expansion pack land of L Two S. So probably for the last year and a half, PBS has been, like, a very hot topic. And just recently, PBS in the context of L Two S has started to come up. There's been a couple of people, like Aztec, like Linna, and some other also optimistic roll ups. Optimism. I think there's been some prototypes for a PBS like interface over there. So, yeah, I'm basically just going to do a bit of motivation, talk a little bit about why L Two PBS is different than L One PBS and some of the challenges.
00:01:02.106 - 00:01:17.750, Speaker A: And then I'll mostly stop there. You can catch me at a talk later in the week on some more clarifications on the design space. Yeah, big disclaimer. I know nothing about roll ups.
00:01:19.690 - 00:01:20.246, Speaker B: Yeah.
00:01:20.348 - 00:01:41.370, Speaker A: I'm glad John Tarr's not here. Yeah, I've known about them for a while, obviously, but I've only really started looking into them a couple weeks ago in a couple so, yeah, I'll say some things wrong. I still don't know what a sovereign roll up is. If anyone knows, let me know. Okay, cool.
00:01:41.520 - 00:01:41.834, Speaker B: Yeah.
00:01:41.872 - 00:02:08.950, Speaker A: So the prompt Gracie Seven X gave me was like, roll up mev. And I think just the most obvious classification to me is, like, exogenous and endogenous. So that's mev that's like cross roll up or cross domain. I think that's also similar to L one to L two mev and then just mev on the roll up as well. Looks pretty much the same, except it's a little bit faster.
00:02:10.970 - 00:02:11.334, Speaker B: Yeah.
00:02:11.372 - 00:02:24.730, Speaker A: So exogenous MEB. It's a thing. There's a paper on cross domain MEB. Check it out. The use of the word domain also expands it into binance as well and other centralized exchanges.
00:02:25.470 - 00:02:25.882, Speaker B: Yeah.
00:02:25.936 - 00:02:59.122, Speaker A: Roll ups don't really change any fundamentals. There nothing big. One thing that is interesting, it increases with the number of domains. That's really something that's really interesting in the Cowswap model specifically, although Cowswap is like minimizing mev, but the more domains that something like a cow swap format can handle, it actually increases the number of incidents once. So that's pretty cool. Endogenous mev. So on the roll up, one interesting thing is there's a lot of talk of loss versus rebalance LVR.
00:02:59.122 - 00:03:10.470, Speaker A: There was a paper by Tim Roughgarden and Jason, and here's like, a summary of one of the key terms from Ain. Alex McLavin.
00:03:11.470 - 00:03:11.834, Speaker B: Yeah.
00:03:11.872 - 00:03:35.940, Speaker A: The rate of return on Arbitrage increases roughly with the square root of the block time. So just the longer the block time, the more mev is sort of how you can think about it. So even I think some people even say, like, almost 50% of Arbitrage MEB gets taken away just by lowering the block times to like 2 seconds. It's kind of like a hand wavy number, but you could roughly think of it like that.
00:03:38.550 - 00:03:38.914, Speaker B: Yeah.
00:03:38.952 - 00:04:20.510, Speaker A: So roll of mev exists what do so this was like almost four years ago. Carl from Optimism had talked about an mev auction. So it has been very much referenced in the land of L Two S. And this even in some ways, this larger E Three search post is like a precursor of just PBS on L One Two, which is pretty interesting, but we don't really have mev auctions yet. So that was more the Optimism approach. But then also, you've obviously seen Arbitram, I think, almost two years ago. That was like all of the drama, I think, was like, between the optimism and Arbitram approach.
00:04:21.010 - 00:04:21.374, Speaker B: Yeah.
00:04:21.412 - 00:05:17.940, Speaker A: So Arbitram had tried to handle this with first come, first serve. And then there was this recent paper that came out, which was a collab between off chain labs and then Christoph Schlegel, who's at flashbox now. And the idea was basically to like instead of just straight up first come, first serve, you turn it into more of a batch auction. And this is their time boost design, where you can sort of buy yourself back in time in a way. And then here's some also interesting research from Sexy Sonnet Flashbots on the number of conflicts as the block size increases. And so this was like his recommendation for basically the size of the batch auction interval. I don't know actually what Arbitram has settled on, so I don't have much to offer there except for just like, this was where the design space largely was for a while.
00:05:17.940 - 00:05:26.260, Speaker A: Okay, so what is PBS if you're unfamiliar? This meme does it all.
00:05:26.970 - 00:05:27.430, Speaker B: Yeah.
00:05:27.500 - 00:05:50.460, Speaker A: There's a good quote from Barnaby in notes on proposal builder separation. Basically, first and foremost, it's a design philosophy recognizing that protocol actors may invoke services from third parties over the course of their consensus duties. So, yeah, we have this on L One today with memboost. And so this is the rough design.
00:05:51.790 - 00:05:52.202, Speaker B: Yeah.
00:05:52.256 - 00:06:46.240, Speaker A: Like searchers users, builders, the mempool are searchers and users, and then the mempool all kind of feed into a builder. They send blocks to this party called a relay, basically. Then when a validator is up, when it's turned to propose, a block comes up, it asks this little sidecar runs meth boost to fetch blocks from all the relays it's connected to. It will then pick the highest paying one and then do some magic and commit to that block. It's sometimes safe, although there is no tax. So why would a roll up want PBS? It's like an interesting question because a lot of the sequencers themselves are like a single entity. So you don't have this rotating property that you do in the validator set on Ethereum L One.
00:06:46.240 - 00:07:12.120, Speaker A: It's one possible way to pass to decentralizing the sequencer. I don't think it's like the full answer, but it's like part of that. And then lastly, a market for block construction. We have seen a ton of innovation in the block space markets. I think there's even things like builders are like fronting gas for searchers and all these other things. I see people in the audience have implemented that.
00:07:13.770 - 00:07:14.182, Speaker B: Yeah.
00:07:14.236 - 00:08:09.874, Speaker A: So I think it's in the best interest of most chains to incentivize some type of market for block construction because it's very hard to replicate that innovation on your own, just on a single piece of software that you write. And even additionally, you can imagine there being even different types of block constructions that you want on L Two. That might be another reason for innovation there. Okay, so this is where I really get into sticky water by describing roll ups. So this is roughly a roll up, right? You have a set of, like, you compress a bunch of transactions, and then you create a post state route and you push it to this roll up contract. And I'm not saying anything yet about who's actually doing this, but that's it. You just compress some data, shove it on the Ethel On chain.
00:08:09.874 - 00:08:38.850, Speaker A: There's supposed to be this says Ethel on chain. Okay. This is where John Chop comes in. I think that is different for sovereign roll ups. I think everything is a sovereign roll up now, but there's a different model in Celestia, I think, slightly. I'll ignore that. This is what it looks like with just one sequencer, just users to the L Two sequencer.
00:08:38.850 - 00:08:55.640, Speaker A: And so I'm kind of just going to describe a bunch of the different actors so that we can just see where some type of PBS like interface might come in. And additionally, once we get to ZK, you'll see it might actually be like, proposer prover separation as well.
00:08:56.810 - 00:08:57.174, Speaker B: Yeah.
00:08:57.212 - 00:09:37.400, Speaker A: So this is what it looks like you could imagine. Well, actually so, yeah, the next type of constraint you could think about is instead of just one sequencer, there's actually, like, a network of sequencers. There's a bunch of people working on these types of designs and in various shapes and forms. You can see how this ends up looking like a little bit more like Ethel One. If there is some type of shared sequencer architecture yeah, this is a good meme from Gord. Yeah, just stop trying to share the sequencer. I don't endorse that.
00:09:37.400 - 00:10:02.800, Speaker A: Okay, cool. One hidden complexity here is like, I'm not even showing how there's actually an E L One block builder here. While the sequencer may have the sole rights to update the block, they actually still do need to compete with the L One block building market since 90% of blocks go through that pipeline. So that's like, even a hidden complexity, there's already an ingrained PDS right here.
00:10:04.050 - 00:10:04.366, Speaker B: Yeah.
00:10:04.388 - 00:10:52.300, Speaker A: And so, yeah, we do this entire flow, like, right here in between the sequencer and the validator. And then there's also this other thing called, like, a base roll up or L One sequenced. And so instead of the sequencer being the only party that's allowed to write, it's sort of a bunch of people trying to write to the chain and whatever just ends up on chain becomes like the canonical roll up block. So, yeah, in that world, it looks more like you have a bunch of L Two block builders that are trying to post to L One through an L One block builder. So block builders on block builders. But wait, that's only optimistic roll ups. Next we introduce like approver I think there's Iraq on this, so I don't know.
00:10:52.300 - 00:11:32.650, Speaker A: Yeah, so roughly what happens is the Lt sequencer has a block, but they also send it to approver to create a proof. And then not only do they submit this updated state route plus the compressed data, but they also include a proof in it. So that in itself could be a complication. But then some projects also want approver network, which again, complicates things. And then if we take this to its limit, you have potentially a shared sequencer network, potentially approver network. And this is like three points for PBS. I'm not saying you actually need three PBS this year, but that's where this gets really funny.
00:11:32.650 - 00:12:08.680, Speaker A: Yeah, it's like a lot of complexity and we barely fully understand L One PBS. I think we're not even totally sure it's really the right path in some instances. Okay, so I'll go into a couple designs from here. This is pretty much the end linea, I think is, and I'm going to try and focus on designs that I haven't really heard of recently. I've heard of a lot of other designs, but I think these are some of the newer ones that are interesting.
00:12:09.290 - 00:12:09.606, Speaker B: Yeah.
00:12:09.628 - 00:12:50.340, Speaker A: So Linnea, they have a roll up coordinator is what this role is. And it's essentially it coordinates the sequencer and the prover. But in production right now, it is both. So yeah, that's like the centralized version. So in this case, we only really need to do PBS between this coordinator, potentially, and ETH L One. But you could imagine expanding it into I think what would be most interesting probably is creating a prover network first, as opposed to trying to create PBS in between the sequencer and the Ethel one.
00:12:52.790 - 00:12:53.106, Speaker B: Yeah.
00:12:53.128 - 00:13:59.682, Speaker A: So then there's also Tyco. Tyco. I find the Tyco design interesting because they are trying to go for like a based roll up and they propose blocks on Ethel One, and then they start proving them off of what has been posted instead of some designs where you don't even post until you start communicating with the proverb. That leads to some interesting things. One, if you notice, they have these three different states proposed, proved and verified. The difference between proved and verified is that verified means you are proved and your parent has been verified. So there's these sort of nasty attacks in the current design where if the data somehow becomes unavailable for proving a parent block of something that's already been proved, then you might actually never be able to become verified.
00:13:59.682 - 00:14:15.246, Speaker A: And it's sort of like a liveliness issue. They have a lot of redundancy right now, is like the handwriting answer. But I think that'll be something very interesting to solve in the long term. And then last, I wouldn't even pay attention to this diagram. I'll just talk.
00:14:15.348 - 00:14:15.614, Speaker B: Yeah.
00:14:15.652 - 00:15:20.740, Speaker A: So Aztec also had an RFC or Q, no RFC for L, two PBS designs and the two main ones were for net and B 52. I won't really go into them. But what's interesting is that they chose this design they call Frenet and they also accidentally introduced well, as they started working on this design, they introduced something called a withholding Attack, where now instead of just like the data getting lost, it's actually the prover can purposefully withhold the proof to force a reorg. If the reorg is more profitable than the value they would get by submitting the proof to the network, then they just purposefully never give it in. Take the slash and then try and work on another block to counter this. So yeah, I think the takeaway really is just like there are lots of complications here. I don't really have any answers at the moment.
00:15:20.740 - 00:15:37.240, Speaker A: Yeah, I think another interesting thing is like privacy. So ZK, you're providing a proof on a claim and so depending on the claim you make, you're actually sort of like revealing some information. So I think that's like another.
00:15:40.990 - 00:15:41.354, Speaker B: Yeah.
00:15:41.392 - 00:16:25.160, Speaker A: And then last also I think even further, long term proof singularity is like an interesting layer to this because this is this idea that just like ethereum, every block is just like one proof that is like an aggregate of an aggregate of aggregates of proofs. You're eventually going to need one sort of virtual machine to take an array of proofs and then construct a proof for it. And I think it's very interesting to think of how that's sort of another layer of someone needs to aggregate these proofs and that's like sort of another market that needs to become available and they potentially have their own incentives and differences on how they would proceed. And that's it.
00:16:32.510 - 00:16:41.130, Speaker C: How do you enforce, let's say I don't want my their two users to be front run under PBS construction without saying the word Spot.
00:16:43.490 - 00:16:45.758, Speaker A: How do you enforce them to not be front run?
00:16:45.844 - 00:16:51.258, Speaker C: Yeah, let's say I have PBS and how do I ensure that my user.
00:16:51.274 - 00:17:21.260, Speaker A: Is not being frontrun? I don't know. I think it's really hard to prove front running. I think the fast lane work shows that on shorter block times it actually becomes much harder to produce front running. I mean, with PBS, I guess you're saying that because you have some type of bundle accessibility. I don't know. I think it's not just PBS, but it's the way that the builder interacts with the searcher's preference that allows for the front running.
00:17:22.830 - 00:17:26.138, Speaker C: Can you say more on that last point? I don't think I understood the last point.
00:17:26.224 - 00:17:48.580, Speaker A: Well, if you have like a first come, first serve builder, then it's harder to do block, it's harder to do front running there, but you could still imagine multiple different builders with slight variations on first come, first serve, like time boost or something else like that. And that's where the front running has to occur at the block builder level.
00:17:50.230 - 00:17:59.222, Speaker C: Okay, so you're saying the users only send order flow to builders who are not front running to become an order flow thing to prevent front running?
00:17:59.276 - 00:18:01.880, Speaker A: I'm saying, yeah, that's where front running lives.
00:18:03.530 - 00:18:19.820, Speaker D: I think actually bash, but makes the front ending much easier. And it doesn't do anything to prevent unless you have privacy and SGA. Right now the block reserves are sandwiching front, I think even more.
00:18:21.870 - 00:18:26.050, Speaker A: Yeah, bundles do allow you to express front routing.
00:18:26.150 - 00:19:06.300, Speaker D: I mean, right now it's even worse. Right. But Splashbuild has used it solved the problem of privacy gas actions on chain, but it has made the front running thing, like, more centralized. There are two black wizards with the majority of those pull up bandishing transactions inside the block, and they don't technically you can send your transaction to a block reserve without transferring, but that block reserve will never be the competition because they cannot be as much as the other one. It's not actually the block builders that do the front running. Yeah.
00:19:08.030 - 00:19:17.854, Speaker E: Flashbot protects win. You're not facing like, long block latency that doesn't share, like, flashbot protector, just.
00:19:17.892 - 00:19:18.670, Speaker A: Like doesn't.
00:19:21.010 - 00:19:32.946, Speaker E: Latency perspective. Yeah, of course the model of PBS, but it's fundamentally where do you want the option to occur? If your transactions can be shared and physically seen before they're settled, then you.
00:19:32.968 - 00:19:34.020, Speaker A: Can be front run.
00:19:34.950 - 00:19:41.270, Speaker D: If you send it to the private RPC, they will extract as much as possible to compete with the other ones.
00:19:41.420 - 00:19:42.280, Speaker E: Yeah, exactly.
00:19:42.890 - 00:19:44.258, Speaker D: There's no front running protection.
00:19:44.274 - 00:19:44.406, Speaker B: Yeah.
00:19:44.428 - 00:19:48.674, Speaker E: And TfL prevents this because TfL doesn't do like a composer cartel.
00:19:48.722 - 00:19:48.886, Speaker A: Right.
00:19:48.908 - 00:19:50.510, Speaker E: Where it's all validators of TfL.
00:19:50.610 - 00:19:53.690, Speaker D: The point is that there is no front running protection.
00:19:54.990 - 00:19:56.540, Speaker E: You have public order.
00:19:58.190 - 00:20:15.120, Speaker D: I think it's more the trust adoption because if you currently send the searches, say through a movie blocker or there hasn't been proven cases of front running actually occurring. The front running actually only occurs when you send it to the public. But there are some.
00:20:19.990 - 00:20:20.402, Speaker B: Yeah.
00:20:20.456 - 00:20:52.080, Speaker A: I would also say Med Share is an example. You can't front run on Med Share, we reveal a selective amount of information about your transaction and we only accept back runs. So that's one example of a mechanism that you can implement. I think the bundle is just making a block programmable or making your preferences and how the block is constructed more programmable. So, yes, a bundle does not solve front running, and I think the original question was, like, how do you solve front running on L Two? Right.
00:20:54.450 - 00:20:58.000, Speaker C: If you do PBS, you can prevent front running.
00:20:58.770 - 00:20:59.530, Speaker A: You can't.
00:20:59.610 - 00:21:00.074, Speaker E: You can't.
00:21:00.122 - 00:21:05.166, Speaker C: Unless you trust the builders to not front run. And then you just place you're just like where do you place a trust assumption?
00:21:05.198 - 00:21:05.346, Speaker B: Right.
00:21:05.368 - 00:21:15.154, Speaker C: You place a trust assumption right now on the centralized sequencer to not front run. And in PBS, when you place on the builders to not front run, something.
00:21:15.192 - 00:21:16.146, Speaker A: Like that, place it more on the.
00:21:16.168 - 00:21:17.650, Speaker E: RPD that shares it.
00:21:17.720 - 00:21:18.194, Speaker B: Yeah.
00:21:18.312 - 00:21:20.966, Speaker C: I'm assuming bundling a bunch of things together to the builder part.
00:21:20.988 - 00:21:21.270, Speaker B: Yeah.
00:21:21.340 - 00:21:24.626, Speaker A: But I mean, if you shared a MEP share, you'll never get crowned.
00:21:24.658 - 00:21:26.626, Speaker C: Yeah, because we're trusting the centralized entity.
00:21:26.738 - 00:21:27.400, Speaker A: Yes.
00:21:27.850 - 00:21:45.246, Speaker D: And eventually you will lose the competition. Even right now, FlashPass is 10% of the black building and the other ones and the other one has like 60% of the network. And you cannot compete with those because they can offer much higher to the validator. Right.
00:21:45.428 - 00:21:50.720, Speaker A: I don't think it's so, like one dimensional. There's like a lot of different going on.
00:21:52.770 - 00:21:54.750, Speaker D: More degrees of freedom. Right.
00:21:54.820 - 00:21:56.014, Speaker A: If you're open to what?
00:21:56.132 - 00:22:12.550, Speaker D: To sandwiches, right. To even front planning. So Flashpads only have back running and those guys have front running, back running and all of the other strategies. So eventually it's a matter of time that they will be, like, much, much higher competitive than I would be interested.
00:22:12.620 - 00:22:20.242, Speaker A: In research that says front running is the only difference in all blocks. I think most of the research says it's all.
00:22:20.316 - 00:22:30.806, Speaker D: There are some research suggesting that pull up the whole block of Beavers. There are like, private transactions. Sandwiching. It's the reason that there are beavers.
00:22:30.998 - 00:22:33.366, Speaker A: They mainly do sex. Arbitrage.
00:22:33.558 - 00:22:35.610, Speaker D: Yeah, but it's like front planning.
00:22:36.290 - 00:22:36.702, Speaker B: Yeah.
00:22:36.756 - 00:22:42.240, Speaker A: People send front running. People send sandwiching to Beaver and Flashbots, everyone.
00:22:43.890 - 00:22:55.618, Speaker D: But I don't know. Did you see the research? I don't know. They mentioned that the reason that they're competitive, those two are exactly because of Sandwiching. No, there were some research.
00:22:55.784 - 00:22:56.870, Speaker C: No, sex. Sex.
00:22:58.970 - 00:23:02.520, Speaker E: Sandwiching is like, on the margin, more profitable, but it's not a good.
00:23:05.210 - 00:23:06.722, Speaker D: Competitive edge is revenue.
00:23:06.786 - 00:23:07.350, Speaker C: Yeah.
00:23:07.500 - 00:23:19.558, Speaker E: It's unclear if the market where sex X is, like, by far the largest revenue stream of the builder, and that's.
00:23:19.574 - 00:23:27.358, Speaker D: Not I mean, is that correct that the bulk of it is like sex? Yeah, but the competitive edge, the thing that makes you to win that it.
00:23:27.364 - 00:23:34.910, Speaker E: Was unclear if having a better competitive edge in your arm is like a much stronger profit leading thing than having a marginal edge.
00:23:37.810 - 00:23:38.270, Speaker B: Yeah.
00:23:38.340 - 00:23:46.120, Speaker A: It's like saying if you had some small profit on some opportunity no one knows about, you're suddenly going to dominate the blockbuilding market. Not.
00:23:49.130 - 00:23:57.670, Speaker F: If you apply Swab right. On the alpha benefit.
00:23:59.610 - 00:24:02.550, Speaker A: If you applied Swab into this diagram.
00:24:02.630 - 00:24:03.260, Speaker F: Yes.
00:24:08.990 - 00:24:38.866, Speaker A: All of it. It's the l one chain. It's the user. We view the first step as basically probably just this user to the sequencer right now. So yeah, basically running auctions on SGX that are temporary, like not like long lived, so that you only trust the SGX for small periods of time and you can do something like Megshare and then you give it to the sequencer or the blockloader.
00:24:38.898 - 00:24:43.270, Speaker F: In that case you don't need the sequencer, the IPX you can directly execute.
00:24:49.950 - 00:24:59.370, Speaker A: We are not focused on that, no. Could a sequencer run on SGX if that's what you're saying? Yes. That can be an interesting design space to explore.
00:25:01.090 - 00:25:01.840, Speaker B: Cool.
00:25:03.090 - 00:25:14.900, Speaker G: What delay would be needed for the sequences? I see that they're using tenement or hot stuff variants. So would the PBS apply still to L two S.
00:25:16.630 - 00:25:19.970, Speaker A: If they're using something like Tenement?
00:25:20.790 - 00:25:37.560, Speaker G: I see expresso trying to use Hot stuff and StarkNet is using tenement. So with their shared sequencing the PBS might not be a problem in the L two space anyway.
00:25:40.570 - 00:26:40.282, Speaker E: We're like also didn't trick and we use Tendermint for it. Unclear what the latency thing? We probably refer to like Jinwan which actually done this thing on block timing. Right? And so there's a question of what is the amount? Depending on how you do like a PBS or like an Epvf design within a chain you should structurally like a shared sequencer starts looking like an L one and that you have multiple parties in consensus and rotating lead set and you can choose to do PDF for block production and that will be the economically valid thing. And then it's just really block time is probably like the relevant entity there. Hotshot allows you to have optimistic block timing wherein if you have a better connected peer to peer network you can progress block faster. Tenement runs on a timeout based thing where it essentially says the round must progress after this many times it's either an empty block or a proposed block. The kind of open question is the economic benefit of being a proposer and whether it is ever advantageous for them to produce a block faster than their maximum time because more mev happens over a longer time.
00:26:40.282 - 00:27:42.586, Speaker E: So generally we naively assume that proposers will choose to take the maximum block time. And so the only actual kind of mechanism design difference you have is you have a shorter block time. We're looking at ballpark like 2 seconds, but that's just because you can easily get that with Tendermint you can compress it down like doing optimizations like say into half a second and I think Hotshot can get lower because they have one less round in their consensus. But then you just get in a trade off space over efficiency of your peer to peer network, really, all of it is just going to be just time of the walk. And so you will have less nev and probably the best practical research there would be looking at any of legito's public research on how they're doing nev on Salana, and there's going to be a lot of distinctions there, but they're looking at like a 400 millisecond block time. You'd at least have some question of like, how does this market look like in much shorter block times? But structurally we think it'll be roughly the same. But you probably have more centralization to your builder searcher market, but probably a lower number of sequencers that they have to communicate network.
00:27:42.586 - 00:27:46.610, Speaker E: And so you just have more tightly connected networks at lower latency.
00:27:47.510 - 00:27:47.874, Speaker B: Yeah.
00:27:47.912 - 00:27:59.430, Speaker A: So TLDR, Pbsl two, you need to be a consensus and mechanism design expert and the latency optimizer.
00:28:03.450 - 00:28:11.050, Speaker C: Can you go to the without the proverb market slide with a shared sequencer?
00:28:12.910 - 00:28:13.466, Speaker B: Yeah.
00:28:13.568 - 00:28:50.630, Speaker C: So other question is, let's say you have three L two S with different transaction ordering policy. One is like, oh, I don't care, do anything. One is like never front run, like o, encrypted, whatever. And last one is you can do only do back running. So now you have three different block builders who are sort of building this individual L two blocks. Do you need a meta shared sequencer block builder to build blocks among the L two S you shared sequencer of? Does that even make sense here's? Anyone's thoughts?
00:28:53.050 - 00:29:07.494, Speaker F: Typically you will have different site of sensors for each other because in that case, your execution engine will be different. It's highly coupled with the execution.
00:29:07.622 - 00:29:15.126, Speaker C: Yeah, no, I'm saying the builder short, they have different things, but at the end the shared sequencer have individual blocks. Right, so how do you it depends.
00:29:15.158 - 00:29:59.554, Speaker E: On the properties you want of a shared sequencer. Like an Ie construction of a shared sequencer is that you have like one block for all roll ups and they have to accept the ordering policy whether they have to. Right. It's like social consensus, what is like a valid full known as a human roll up and how they choose to derive their state out of executing like an ordered block. So they could either inherit that same thing, they could deterministically reorg that. You could also say that one transaction in a given shared sequence or block is the entirety of a block for an L two and therefore it's assumed you have some off chain builder. The design space is pretty wholly generic, but the trade off primarily is if you have a different ordering policy on a given L two that uses a shared sequencer, you're not actually going to get any useful definition of composability or relative ordering the transaction.
00:29:59.554 - 00:30:07.290, Speaker E: He was actually just are borrowing a consensus engine and saying like, all of these are like wholly sharded ordered lists.
00:30:07.370 - 00:30:08.590, Speaker C: Holy sharded.
00:30:09.570 - 00:30:16.620, Speaker A: Holy sharded. Okay, cool. Thank you.

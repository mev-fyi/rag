00:00:00.440 - 00:00:33.934, Speaker A: And this next panel is on user centric AI. On this panel we have Nick Cosby from Modulus Labs, David Minaj, he's the CEO and co founder of Valerie, Ethan sun, who is the co founder of my shell. We have Esli, who's head of strategy at the Marlin foundation. And this panel is going to be moderated by Erician, who's the co founder of Edge AI. Come on stage.
00:00:52.694 - 00:01:15.318, Speaker B: Awesome. Well, thank you everyone for coming here. Ready for the round two for tonight's brainstorm. So I want to quickly introduce myself. My name is Era. I'm the founder for Edge. Edge is a research and development lab focused on edge intelligence, local model training on edge devices, and we're looking into a lot of AI web3 with a decentralized incentive right now for the convergence, say.
00:01:15.318 - 00:01:26.134, Speaker B: And it's my great honor to have the great panelists today to really talk about what does it mean for user centric AI. So we're going to start with just a brief introduction for each team.
00:01:27.354 - 00:01:47.824, Speaker C: Yeah. Hey, I'm David, co founder of Valerie and co creator of Autonomous. And yeah, excited to be here, particularly bringing my view on how autonomous AI agents can create value for their owners.
00:01:49.844 - 00:02:20.954, Speaker D: Thank you, David. I'm asleep. I'm part of Marlin Foundation. Marlin is a trustless co processor which helps to offload heavy load compute to a decentralized node of operators, and then the result can be verified on chain. So, yeah, that's what we do on this panel. I'm here to talk about how Tes can help accelerate the whole AI decentralization and user centric AI. Thank you.
00:02:22.214 - 00:02:44.454, Speaker E: Hi, I'm Nick Cosby from Modulus Labs, co founder at Modulus Labs, we try to bring AI results on chain without sacrificing anything in terms of security. We do that via ZK proofs. And our current project is reducing the compute overhead of ZK proofs to make the proving of large AI models practical. We do that through our own specialized prover. Thank you.
00:02:45.994 - 00:03:10.034, Speaker F: Hi, this is Yi Z. I'm co founder of my shell. At my shell, we are building a decentralized creator platform that people, we empower, creators of all these kind of open source AI models for people to easily build all the AI applications. On top of that, it's also AI marketplace. All the interested people can invest and back all those kind of fantastic AI content and be part of the ecosystem.
00:03:12.214 - 00:03:41.654, Speaker B: Awesome. So I want to start with a bit of background. So in crypto, we have a way of saying, if not your key, not your coin, and in AI space, we talk about not your weights, not your model. So when it comes to this intelligence age, we start to really start to think about what does it mean from a personal, individual level, think about this intelligence stack. And I think we can start with maybe like Marlon, when it comes to AI, what are folks really talk about? What they really care about.
00:03:42.714 - 00:04:38.554, Speaker D: So with AI, one of the key things that users care about is privacy, both on the end user side as well as developers. On the end user side, they want to ensure that their data is not being used in a insecure way. And also they want to ensure that none of the things are open source and they can be accessible and breached. And on the developer side, they want to ensure that the models that they have built, they should be able to keep them safe and secure. And as well as they want to behave, ensure that the models behave in a certain way. So that's where Marlin tease comes into picture, wherein they ensure that everything happens inside a secure enclave, so that it's black box to outside environment and everything is pretty much secure, but still you can verify everything on chain. Yeah.
00:04:39.014 - 00:05:24.134, Speaker B: Any other thoughts? Yeah, and then the interesting question is, so, you know, starting from last year, right, like when at some point the open end become not open anymore, and then the whole intertwining large model become a capitalist game. Like in the San Francisco Circle, people talk about, I'm a GP poor, like, who are the GP? Richmond, all the major big AI company model. So at the, I would say, like early last year, you start to see this emergence of like smaller model, local model research start to emerge, and increasingly people think a lot about your personal can I run my local model on my edge devices on my phone and how I think on my data? So how can people trust it? How can build your intelligence stack?
00:05:26.354 - 00:06:46.204, Speaker E: Well, the problem of trusting AI models generally, basically running it on your own device, doesn't necessarily solve the problem, because the model itself may be trained to do things that are adversarial to your goals. And it's basically impossible to tell just by inspecting the weights that this is the case. So if the training process included basically a poison pill in it, that causes it to, when some specific token appears in the prompt, that it will do something adversarial, like saying code generation, introduce a security hole. There's basically no way to tell this fact without knowing what that adversarial token is. So basically, to have a trusted model, you need to understand the provenance of the model, you need to understand what it was trained on, which is, of course an issue, given that collecting these giant data sets and then running this massive proving process is very costly. So one method of doing so is, of course, with CK proofs, which is what we specialize in. If you can prove the entirety of the provenance of the model, all the training processes, all the sources of the data you got, then the edge device can verify the sysync proof and know that this model is effectively doing something sane.
00:06:46.204 - 00:07:43.906, Speaker E: So that's half the answer of kind of LLms and edge devices. The other half is the fact that once you have this model, that for whatever reason, you trust maybe because you did proof of provenance, or maybe it's because you just trust the people who created it. If other people want to rely on the results, they basically either have to recompute it themselves, which is not always practical, or trust not only that the model is correct, that you computed it correctly. That's pretty hard. LlMs, the good ones, have billions of parameters and basically doing billions of anything in a ZK proof, much less. The pretty complicated operations that llms involve is currently technologically infeasible, basically even on larger mainframes. So there's a lot of research and development to be done to be able to let edge devices both understand the provenance of their model and also prove to other people that the model was executed correctly.
00:07:43.906 - 00:07:58.122, Speaker E: But I think there's also a lot of hope in the technical progress on ZQ proofs, and a lot of potential could be unleashed if basically, once someone's done this hard compute, nobody else ever has to, they can just verify the proof that it was done correctly.
00:07:58.258 - 00:08:02.534, Speaker B: So how far are we from like, chief, like, economic proof.
00:08:05.894 - 00:08:22.838, Speaker E: Llms on edge? Like real full size llms on edge devices, probably like two to three years, small llms on edge devices proving them. That might happen in a year or so. I think we've got some good stuff in the pipeline. So.
00:08:23.006 - 00:08:48.634, Speaker B: Interesting, interesting. So when I talk about user centric AI, there are two sites. One is your intelligence, your local model. The other part is this whole entire empowerment with autonomous agent Hacksaw. We started looking into the additional agent, like this form of agent, potential economy going to emerge out of it. But let's start with a simple one. What is agent, how we define and what does it mean to be the autonomous agent architecture?
00:08:50.134 - 00:09:43.138, Speaker C: Great questions. Yes. So Ilya earlier gave this nice description of the different types of agents we can find. And obviously we are on a user centric panel, so it kind of starts with interacting, right? So you can be in a situation where maybe you're using a wallet, as was previously discussed, and an AI agent can sort of complement your interaction with the chain, let's say. So here, the AI agent is basically more like a tool. It doesn't do things for a long time or have any goal other than that specific intent, maybe, or instruction. And then on the other end of the spectrum, we have fully autonomous AI agent.
00:09:43.138 - 00:10:47.198, Speaker C: And I think, again, when we look back at prior panels, really, when people talk about AGI, they tend to mean a gentic AI of general intelligence level. And an autonomous AI agent is sort of, I guess, like the more advanced version of that. Right. I see it sort of as one step along that journey. Now, an autonomous agent is a bit different from just a tool because it has its own goals and it wants to get stuff done on behalf of its owner. Now, this owner can be you, a person, or it can be another agent. And I think that's already the sort of first kind of tick box to kind of anchor us at this intersection of crypto and AI with these kind of systems, because naturally we all know, like web3, it's all about a big part, is about ownership.
00:10:47.198 - 00:11:45.764, Speaker C: And so if we can in the future also and today, own our autonomous agent, then there's a lot of value in that, right? And now that can take very different forms. Like you could imagine, this autonomous agent is mostly deployed on chain. And I'll come back to that. Or it's a combination of on and off chain. And that's sort of where at Olas, or autonomous, we focus on a lot. So they are off chain systems, which users, either single users or a group of users, daos, maybe one day countries can co own, and they basically get some goal direction, and then they instantiate that. So if you go back to this AI agent versus autonomous agent, I also think there's an interesting ux difference there.
00:11:45.764 - 00:12:27.522, Speaker C: So in the AI agent, we're really talking about interacting. Like, if you go to chat, GPT, or some sort of web3 enabled AI agent, it's all about you, the user being in a loop with the system, almost like sort of instantaneously, and it does something on your behalf for, like, specific tasks. If you're talking about autonomous AI agent, and certainly AGI, if we can control it, then it's some. It's a different parting. I mean, we are no longer the most fantastic instantiation thereof. We're no longer gonna be there all the time and say, yes, you've done it right, or no, you haven't, or please do it. This way, instead it will generate entire outcomes.
00:12:27.522 - 00:12:51.864, Speaker C: And I think that's an interesting kind of ux shift, which we're going to see. Where Dao governance was mentioned earlier is one example. You embed the rules and the knowledge of the DAO in this kind of system and it just gets it done. And then ever so often maybe you update its knowledge or its goal direction and so on.
00:12:53.004 - 00:13:11.796, Speaker B: Interesting. So when you imagine this like an agent economy or agent future, right, I can fork myself, I can have my digital twin, I can shard myself into different version. So what are some of the creative use case are there, what are some of the extended version of ourselves can potentially be there?
00:13:11.980 - 00:14:40.288, Speaker F: Yeah, I think at micro we are not just empowering people to create digital twins or just AI characters. I think we focus more on the generic AI applications because I think nowadays a lot of people talk about AI agents and we use the term AI application because I think traditionally people with coding experiences, they just close the logic, the user interface app. But nowadays with all the large language model, basically you can use the prompt or simple instruction to make the generic large language model into specific logic with a given prompt to change the output distribution for that. And of course, basically I think large language model is more like the brain of the AI application or like the coordinator. But we also think a lot of other computer vision models, other generative models like stable diffusion or some video generation models. Basically all this kind of model is just a building blocks that we want to integrate all together to the creators so they don't have to deal with the heights of model deployments, or how to code the models, or learning coding at all. So basically they can use very simple configurations, or even use our non coding tools to define the processing logics, or to process different kind of user inputs, and to orchestrating all those kind of models together, either in a simpler linear workflow or even more complicated graph transition logics.
00:14:40.288 - 00:15:40.784, Speaker F: So given that sense, we really can empower creators to build professional grade AI application for both the entertainment like the AI games, or the educational content like AI version of Duolingo, or any other utility tools, or even personalized workflow to process your daily email or the calendars. I think that's really something we want to empower for. And I think all the fantastic projects focus more on the verifiabilities and also building the AI models on chain. And we focus more on, given this kind of fantastic infrastructures, how we can push it further to create a creator or the content ecosystem. That's going to really draw a lot of usages, a lot of creators, especially those kind of non technical creators, to leverage all those fantastic technologies, AI models, to build something that's really going to be used by people day to day, and build a whole marketplace and also the financial system around it. So I think that's something very interesting and something our vision lies on.
00:15:41.364 - 00:16:01.454, Speaker B: Amazing. So to spice things up a little bit, I know we talk a lot about the traditional convention. I want to ask each panelist, what's the most controversial sauce you have about this AI Webster conversion space? What are some that are kind of like just buzzword out there? What are some things are real?
00:16:06.674 - 00:17:02.440, Speaker D: I have a slightly different take on this. One of the controversial topics that I can think of as trustless AI life coach, right? I mean, as a human, you are making so many decisions throughout the day. There is a lot of cognitive load that has been going through your head. How can we build an AI which can act as a life coach? And you do this in a trustless way so that only you have access to that data, and the AI acts according to what you will do. Right. If you are on a date, it will tell you whether to take roses or whether to take chocolates, depending on your historic data patterns. And this is where the whole tea or the secure enclaves come into picture, because the AI model itself is hosted on a secure enclave, so that it's not exposed to any external parties.
00:17:02.440 - 00:17:12.284, Speaker D: It's a black box, and you should be able to access it, and it is only accessible to you. So, yeah, quite a controversial topic.
00:17:16.304 - 00:18:10.648, Speaker C: All right, well, I don't know how controversial it is, but earlier today, I was following the fantastic discussions, and sometimes I feel it sort of implied that there will be some sort of one big model or one AGI, which we should worry about. And that's, in my opinion, totally ridiculous. I think there will be, everyone will have varying degrees of models. There will be trillions of them. Most of them will be agentic. And I think it's all about structuring societies of humans and these agentic AI's, many of which will be orders of magnitudes more capable than us. And I think that is where the crypto AI intersection has a big role, because if you think about it from a meta level, what AI is all about is it just makes innovation faster and faster and faster.
00:18:10.648 - 00:18:24.854, Speaker C: And what crypto is in a large part about is about designing mechanisms to align. Agents, and agents are humans, agents are machines, agents, anything with agency. Don't know if it was controversial.
00:18:25.394 - 00:18:26.174, Speaker B: Nick?
00:18:26.994 - 00:18:52.958, Speaker E: Yeah. So I'm pretty excited. Obviously I work in it on the intersection of crypto and AI. There's so much space to experiment with here. But I think the unfortunate truth is that the realm of the fancy hot, super exciting frontier models like Sora or Gemini just came out. Especially Sora. Those will remain in the centralized corporations hold, I think, indefinitely.
00:18:52.958 - 00:19:00.234, Speaker E: The costs in terms of efficiency for decentralization and security cannot be so easily overcome. I think.
00:19:02.174 - 00:19:48.462, Speaker F: Yeah, I think just, yeah. I think the most controversial thing in the AIPAs crypto domain is actually the usage versus more infrastructure. I think usage is something we barely mentioned because I think nowadays, given the top performance commercial APIs, people are still trying to build a lot of consumer facing applications. A lot of AI startups is trying to use chassis bt to build something that can help us to better to do the promotions to the AI companion, all others. I think crypto of course. I think crypto of course is going to bring the AI on chain and also bring a lot of transparencies. But I think it's actually the overhead of bringing things on chain, especially if it's verifiabilities.
00:19:48.462 - 00:20:29.128, Speaker F: How much scenarios actually justify the additional cost? I think for more money or trading critical scenarios, it's of course worth it. But for a let's see if you are talking with your AI girlfriend and the verifiability makes the cost like two magnitudes higher, does it worth it? I think that's probably the most controversial talks we have internally around building a consumer facing application. I think. Yeah, just want to mention a few other buzzwords I heard a lot in the domain. I think one of them is training or the fine tuning. Of course fine tuning and training is fantastic, but I think the hardest part is to serve those kind of long tail fine tuned models. It's not possible.
00:20:29.128 - 00:21:23.940, Speaker F: Nowadays I don't see any kind of infrastructure even in the webtoon domain hot loading the long tail models fast enough. So even if we have like millions of fine tuned models, how can we serve them? Because all the models going to need GPU memories to host it to make them ready to be used to run the inferences. I think in reality people use rack rather than fine tuning to deal with the new data. I think of course fine tuning works better, but just not economic viable for most of the scenarios. I think the next one probably is agents. I think nowadays there's no clear definition of what is AI agents, especially what is autonomous agent people is always talking about it. I think they might gradually gonna form the consensus of what is really the AI agents, what's the difference between AI agent and AI applications? Yeah, so I think, yeah.
00:21:23.940 - 00:21:33.464, Speaker F: Just some of buzzword I heard because in some of the events people talked about some things even though I worked in the AI industry for past ten years, sometimes I don't understand.
00:21:34.404 - 00:22:26.022, Speaker B: Yeah, amazing. Yeah, I'll share my thoughts on that one as well, is I think for a long time we thought about what's crypto's use case, right. Miraculously, now we have AI. Now will AI become one of the largest use case for crypto? Yes, maybe. And even when it comes, everyone talk about decentralized AI. What does it really mean? Like how much do we really need to be decentralized? When for us, for our lab, when we talk the OpenAI or Lamati, they're like, yes, some maybe, but the question mark is what should be there if, let's say local model, smaller model, personal user centric AI become a real thing? Is the azure intelligence maybe arrive even faster than the decentralized one maybe as well? I have a lot of questions on that part. If you are curious about those one like me do welcome back.
00:22:26.022 - 00:22:55.474, Speaker B: Tomorrow we have a full day 20 workshop back on back Explore talk about those questions. We also invite actually one of the top tier model research company news research. They're the one behind all the fire about BitTorrent. You know, that's actually tier one, like a research company will be here to talk about how AI tier one company, they think about the decentralized future here. So that's it. Thank you everyone to join the user centric AI panel. We look forward to see you tomorrow as well.

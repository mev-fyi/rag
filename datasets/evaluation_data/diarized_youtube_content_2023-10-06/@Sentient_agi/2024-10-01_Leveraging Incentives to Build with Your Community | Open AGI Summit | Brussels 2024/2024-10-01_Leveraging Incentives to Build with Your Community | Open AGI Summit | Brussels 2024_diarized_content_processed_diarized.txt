00:00:02.080 - 00:00:33.705, Speaker A: Okay, we have our next panel starting shortly. This panel is titled Leveraging incentives to build with your community. For this panel we're joined by Ben Fielding, he is the co founder of Jensen Carton Wong who is the co founder of Aura, Alexander Hicks who is a researcher at the Ethereum Foundation. Greg Assuri who is the founder of Akash Network. And the panel will be moderated by Stepan Gershuni who's an investor at Cyberfun.
00:00:33.825 - 00:00:49.005, Speaker B: Welcome. So.
00:00:51.745 - 00:01:13.425, Speaker C: Yeah, hello everyone. So we're going to have a panel about incentives, the use of incentives in decentralized AI. Going to talk about money, about how to incentivize people, machines and artificial intelligence. So yeah, I suggest we start with the round of introductions and please introduce yourself briefly.
00:01:15.645 - 00:01:58.005, Speaker D: My name is Greg. It's late in US so Canadianism hasn't quite caught up with the eastern with the time zone. Anyway, my name is Greg, I'm the founder for Akash Network, CEO for Overclock Labs. Akash is the world's first super cloud and with a focus on accelerated computing, GPUs is the is a bread and butter for Akash. Now, considering the demand for GPUs is just increasing without the supply chain improving, Akash is now the only place to get on demand high density GPUs anywhere on the cloud. And that doesn't seem to be changing anytime soon.
00:01:59.345 - 00:02:45.395, Speaker E: Hey, I'm Ben, co founder of Jensen. Jensen is a very low level machine learning compute protocol. So we sit just above GPUs, GPUs, CPUs, any device that can do machine learning training and we provide access to those devices via our infrastructure essentially. So kind of differently to Akash, we commoditize the compute itself and change the sort of interaction from ML engineers and researchers from finding access to a specific GPU and booking time on it, to just running ML ops on something. So you're submitting a machine learning training task. You want to train an AI model. You don't care about the device, you just want some kind of infrastructure where you can submit that task and somebody somewhere in the world will train it.
00:02:45.395 - 00:03:00.555, Speaker E: Maybe it trains on one Nvidia H100, maybe it trains on a thousand MacBooks. You don't need to know as a user, you just need to know that there's some kind of rails to do that on. And so that's what Jensen is a little bit, a tiny bit like tcpip, but for a new kind of machine learning future.
00:03:01.535 - 00:03:45.535, Speaker B: Hi folks, I'm Carton, the co founder for ORA Protocol we are building the decentralized AI on Ethereum. So we have two major product. The first one is called OAO on chain AI Oracle. We use optimistic machine learning to enable decentralized inference for smart contract on ethereum and it's L2 and so that will enable a lot of use case like AIGC NFT and AI DeFi and some AI on chain gaming. And another major product we have is called initial model offering. We tokenize AI model on blockchain and then do the revenue share for the AI model after they do IMO we will make it as like AI Oracle. When AI Oracle makes fee, the revenue will share with the model token holder.
00:03:45.535 - 00:03:46.825, Speaker B: Yeah.
00:03:47.445 - 00:04:11.065, Speaker F: Hello everyone. So I'm Alex, I joined DSM foundation about a month ago and essentially I work on form verification and AI and intersection of both. I guess we're not actually. Well we have a product which is Ethereum but we're not really building AI on the layer one at this point but we're paying attention and keeping an eye out for anything that's relevant to us.
00:04:13.095 - 00:04:40.155, Speaker C: Yeah, thank you. So Greg, maybe we'll start with you. You've been doing Akash for quite a long time, one of the biggest decentralized compute networks today. And I just want to ask you to share some of the learnings regarding incentive, the use of incentives. So what does work, what doesn't work, what was maybe some of the largest failures or problems that you had to overcome while building Akash? Can you share something?
00:04:40.965 - 00:05:08.983, Speaker D: Yeah. So Akash hasn't enabled incentives on chain yet. And the reason for that is you do not want to have incentives without verification. If you do so, you'll end up into situations that you really don't want to be in. Right. And we saw recently with another network that enabled incentives without verification, they got civil attacks to death. So simple attacks are very, very real.
00:05:08.983 - 00:05:59.039, Speaker D: Every time there is money on the line you want verification. And it's very hard to verify general purpose compute right. Where you don't necessarily from a platform standpoint have access to the source code to verify the runtime or whatnot. So we are working right now with hardware verifications using trusted execution environments, which I was vehemently against it, but I kind of gave up my fight and I started accepting tees as a way to go. But tes are not general, not generic across different boxes. So you get into this, you know, edge cases and you get into situations where you really can work out so well. So future of Hakashi verification is DE now and there's A proposal out there that will be enabling time soon.
00:05:59.039 - 00:06:23.095, Speaker D: Second lesson is like you don't need on chain verifications to start off with. You can do off chain. Sorry, you don't need on chain incentives. You can always do off chain incentives. Right. And I think that's where you get the flexibility of governance. So we do have a pilot program now with a very well defined membership requirements and distribution requirements or whatnot, and that's running really well.
00:06:23.095 - 00:07:39.105, Speaker D: One of the best things about this pilot program is it's a controlled environment. So before you can go on chain and go scalable and all the craziness, you get to study the patterns and the behaviors of the incentive receivers. And I think that gave us so much valuable feedback in terms of how we should design incentive program instead of sitting in a dark room and deciding what the incentive program should look like. And third is when you look at incentives in crypto, we have this notion of homogeneity that means you don't really think about how to optimize incentive design, but rather go with the original incentive program. The bitcoin introduced that, hey, we just need to give block rewards for every block instead of really thinking through what the block reward should look like. And when you incentivize, you know, in the token that that's native to your platform, that token tends to be a volatile token. And then incentive distribution happens to be irregular and doesn't really make sense because you most probably incentivizing real world assets like a GPU or a CPU which have, you know, which are priced in US dollars and not pricing in your token.
00:07:39.105 - 00:08:17.329, Speaker D: Right. So really think through like what you're doing in terms of how are you allocating incentive budget to these behaviors that you're incentivizing. And just don't go broad and saying that you're going to get X amount of tokens without realizing what the value of these tokens are. It is like, I mean it's such a privilege to have access to liquidity in crypto, but it's also responsible on the protocol mechanism designers to understand what that means in terms of your expenditure for incentives. Right. And fourth is go as narrow as possible instead of going broad. We learned a lot of lessons there.
00:08:17.329 - 00:09:15.905, Speaker D: If you have broad incentives that doesn't really fit a particular behavior that you want to see, the likeliness of that behavior coming to life is very low. So being extremely narrow, extremely prescriptive is what we learned is a significantly better way. Like for example, like on, if you want to incentivize a certain chip set for a 100, for example. The way it works in Akash is we have, you know, every time you reach 50% utilization for a certain chip set, the rewards to or the incentives to double the capacity are released. So that way you're ingrained completely in utilization and not just going for large numbers because it doesn't make sense to have large numbers without utilization. Right. So for example, if you have 100 A1 hundreds and 50 of them gets used on a single or 24 hour period, the incentives for 200 A1 hundreds gets released so that people with capacity can actually list their capacity and keep it on the network.
00:09:15.905 - 00:09:42.025, Speaker D: So that way you have a significantly better and more disciplined distribution curve instead of just a broad like hey, incentivize everything and get thousands of GPUs that nobody really uses. So lots of lessons there and we're still, we took the lessons and now we're putting that on chain. And if you talk to me in a year's time, I'll tell you what lessons we learned of on chain incentives for resources that are priced in real world dollars.
00:09:43.045 - 00:10:19.395, Speaker C: Thank you. Very insightful. Ben, question to you. So I want to ask about crypto economics and you touched a little bit on cryptography part but there is this criticism to decentralized AI that it is not as efficient as centralized data center pre training or inference. And so why do you think that decentralized AI will beat centralized compute economically long term? And what are the drivers and what of that do you plan to implement at Jensen?
00:10:19.805 - 00:10:57.949, Speaker E: Sure. One quick point on the, on the previous question though, I think there's if I could just jump on what Greg said with the point that incentives on the product, I think that gets forgotten in the crypto space. So much like we spend and lots of projects spend lots of time constructing these incentive mechanisms and it quickly becomes the fact that that's what they're beholden to. They've built these incentive mechanisms. They've got users for those incentive mechanisms that are only there for those incentive mechanisms. And then they continue to build based on the feedback of those incentive mechanisms and they actually just build a product which is only an incentive mechanism. It doesn't do whatever it was originally intended to do.
00:10:57.949 - 00:11:31.411, Speaker E: The point of an incentive is typically bootstrapping. It's a kind of tool that you can use to create a market where one doesn't exist full stop. But it's a very kind of tiny thing and as soon as you do it, you create a proxy of the real value transaction that you want to make happen, that proxy is not going to be the same. So if you keep iterating on it, you go in the wrong direction, basically. So it's something that you see repeated time and time and time again. And is why Greg was saying the verification is so important. Right? Because if you don't have that, people are just going to come in, they're going to game that incentive directly, because why wouldn't they? They're financially rational actors.
00:11:31.411 - 00:12:07.635, Speaker E: And then you've built a thing that just is gamed by those people. So I wanted to say that very quickly, incentives aren't the product. Jumping onto the question you asked me though, why would decentralized AI be viable basically against the kind of efficiency of centralized AI? 2 kind of big reasons in our opinion. So one is scale and the other is access, competition, price, whatever you kind of want to call it. But generally the scale pieces right now as we're building models, the models that we all see are things like GPT Llama, these huge models built by the hypersensitive scalers. Those are effective. They show us what's possible with AI.
00:12:07.635 - 00:12:52.877, Speaker E: And they're built with brute force scaling, which is just throwing GPUs at them in the most centralized, easiest to perform way. You can see that with most technology going back in history, we do the kind of like easiest way of making it effective to start. And then after that we look at productizing it and making it efficient, generally scaling it beyond that kind of limit that we've achieved there. We think AI is either at or rapidly approaching that limit from a centralized perspective. And you can see this reflected in the hyperscales with the research they do. So they're moving from how do we just make a bigger model and add another thousand GPUs in the same data center to how do we build a model over two data centers? Because we have multiple and we can actually access more GPUs if we do it that way. And they research these communication mechanisms which allow them to train models over multiple data centers.
00:12:52.877 - 00:13:22.861, Speaker E: Jensen's view is that you just keep extrapolating that out. You scale it up and up and up to the point where we take off the scaling limits. We set the kind of limit at humanity's GPU supply, full stop. And it's CPU supply, it's TPU supply. We do that through these communication mechanisms and they are effective. They just need more research. So that's one of the pillars that Jensen works on, is research of how do we improve the communication efficiency of models so that we can Model over theoretically every device in the world instead of one data center, and then maybe one more data center added in.
00:13:22.861 - 00:14:06.539, Speaker E: So that's the scaling piece. The second piece is the access piece, which is right now it's very hard to get GPUs, TPU, CPUs, et cetera. They're usually concentrated within a small number of companies, either the hyperscalers or the oligopolistic cloud suppliers. There are many more devices out there in the world that could be used, but people just can't access them. There's a big divide between the person who just wants to train a model and the person that has a device that could train that model, but has no idea how they could become a cloud provider. So if we can build an infrastructure which just connects those two, it takes out all of the weird administrative costs of being a cloud provider, like kycing people, like building an infrastructure to take a model over to that device, like a payments infrastructure, et cetera. If all of that is sorted, then any one of us could be cloud providers at any point in time.
00:14:06.539 - 00:14:21.335, Speaker E: All of our phones in this room right now could be training small pieces of model. If you combine that with the first scaling piece, then you get a completely new way of doing machine learning. And that's the thing we're excited about, rather than just saying, can we make GPT slightly bigger? Yeah.
00:14:21.415 - 00:15:05.035, Speaker C: Thank you, Carsten. And you mentioned that you're building this product around initial model offerings. So people are able to tokenize their machine learning models and essentially get paid for doing that. And my question is about how is it working for you in terms of experience? Like how is it working right now and where do you see the most applications? Because traditionally in AI, like machine learning companies, they build these models, then sell API and that's the business model. How do you see distributed ownership over the models?
00:15:05.155 - 00:15:33.007, Speaker B: Yeah. Thanks, Greg. So decentralized AI is not the future thing. It's already here. So initial model offering sold a really important way, a really important problem for our civilization. So have you think about why we have not seen any alien, right? Like do you know why we haven't seen any alien yet? What do you think?
00:15:33.111 - 00:15:34.115, Speaker D: How do you know?
00:15:35.895 - 00:15:37.349, Speaker C: Didn't notice yet.
00:15:37.527 - 00:16:32.957, Speaker B: Okay, so the thesis here is that one of the most like convincing thesis is like there's a grand filter for our universe, for different civilization. So once a civilization develop a way to have industry, have information technology, it's really dangerous for them to kill each other or like they don't have the chance to go to the space or something. Right, that's the grand filter, like it's most alien, most civilization. They probably just like our stage, they cannot reach out to each other. And so the grand future is really hard to escape. We need to have a really strong and really efficient system of protocol for our civilization to escape the grand filter before like our civilization and ourselves. So one of the biggest problem I observed today is that open source AI do not have a way to keep their flywheel spinning.
00:16:32.957 - 00:17:09.465, Speaker B: It means like once you spend few million dollars to build an open source AI model, you're not going to make anything back in your hand. So which means you don't have extra resources to build a model better. So it's really bad. So everybody is trying to hide their own model, hide the way they view it, how the knowledge they have. Right. So it means that everybody are separated. So it decreased the velocity for us to discover the new knowledge, to develop the new technology, develop the new AI system to help our civilization to escape from the, from the grand filter.
00:17:09.465 - 00:18:08.881, Speaker B: And so for initial model offering like we tokenize the AI model on blockchain so that everybody like all the open source AI creator, once they publish their AI model to the world, like they don't need to worry about somebody just copy the model and like run the model without paying them. No need to worry because like you already have the token, you already have the credibility, you already have the social consensus for the AI model that reflects on the token. So the first IMO we did is called open language model that it go really well like one week it goes 6 tx in the price. And also there's multiple team in the world after they buy the token they work on the model. So like few days ago the Chat Olm model just got published in Hugging face. Because the originally open language model is just like a base model, you cannot really use it for anything. It's a base model, it hasn't been fine tuned by anything.
00:18:08.881 - 00:18:31.451, Speaker B: So now if you go to chatolm.com you can see that they already have the Chat Olm MODOC that fine tune it. It's not by our team. It's just like I don't even know who they are really. And then they are just like some anon in the world, they just like buy the token and they want to empower the token price. So how would they do? They just like build a product and made the model better. So I see the flywheel here begin to spin.
00:18:31.451 - 00:18:51.133, Speaker B: It's like open source AI flywheel just begin to spin. It might be slow, might be the Model still worse than llama free but it's okay, it's okay. The flywheel will spinning and then we will increase our velocity to develop our technology to escape the grand filter. So that's my thesis like for the imo. Yeah.
00:18:51.309 - 00:19:44.145, Speaker C: Thank you Alexander. So as I understand you are doing research at Ethereum foundation, right? So I wonder, like a lot of things in Ethereum are ultimately about mechanism design and incentives, issuance, proof of stake mov, all these important things. And when we are talking about AI, decentralized AI, it could be compute or models or data or agents or multi agent systems. What are these learnings and what of the things that already exist in what like Ethereum, already invented or actually implemented can be applicable and useful? And also can you maybe share a little bit more about your overall research thesis in regard to decentralized AI?
00:19:45.205 - 00:20:31.649, Speaker F: Yeah, I'll start with the latter part since that's a bit shorter in terms of my research thesis there. So I mean my main project at the moment is mostly focused on improving the security of ZK VMs. And so we're looking at if we can get some, you know, good kind of AI tooling and some help from AI to basically work on that because it's long and tedious to try and formally verify everything. And that's maybe less kind of decentralized AI. It's more just kind of looking at what's out there and trying to use it. And there's a big portion of that is obviously where we get fine tuning our own models and things like that. So there's a share of at Beast open source AI to come back to the first part about incentives and what we can learn.
00:20:31.649 - 00:21:49.527, Speaker F: I think something that's quite interesting around incentives is, and maybe kind of Ben alluded to this, a lot of people put a lot of effort into trying to design the perfect incentives. And then despite all these, you know, incentives and mechanism design, you know that token is worthless and but something also that's also quite interesting is that incentives can work in ways that are very different to what you would like. A lot of the times you can model a game, you know, define some utility function, find the equilibrium and it all looks good on paper. And then in the real world actually the utility function you defined isn't actually what people have in mind and you actually have incentives that come from outside your system. So one of the first papers I worked on when I was doing my PhD actually was unrelated to the AI, but had an interesting point around incentives, which is that you could write a smart contract in Ethereum and a Bitcoin miner could mine an empty block on Bitcoin, store that chain and submit a proof to the Ethereum smart contract that they've done an empty block and get paid in Ethereum. And so whatever incentives you define for Bitcoin, you could subvert them from Ethereum. And I think that's quite true for a lot of incentives because whatever you're trying to model is in a vacuum.
00:21:49.527 - 00:22:46.937, Speaker F: And once you deploy it on chain, whether that's Ethereum or something else, it's no longer in a vacuum and you have a lot of people interacting with it. You've seen this with airdrops as well, where airdrops sound like a good idea. Now people are airdrop farming and it's a bit nonsensical. So to some extent actually I feel like with the way that AI is going at the moment and a lot of people being very excited to contribute to it, I don't think there needs to be that big of a focus on reward mechanisms. Because you already have people contributing basically altruistically just for the fun of it or because they get a job out of it, you probably don't need actually to pay them that much. And if you start actually trying to get payouts for data or for models or things like that, maybe actually people trying to game the system and submit really terrible data and poison your model. So it's quite hard, I think, to really think about what incentives you want to put in place and how to put them in place without encouraging bad behavior.
00:22:46.937 - 00:23:51.151, Speaker F: That would detract from the already massive amount of good behavior that we have. You can go on hugging face any day and there's people doing tons of good work and maybe they're getting paid from their job, maybe they're doing it as a hobby, but it's already happening without, I think, the need for additional incentives at the moment. And I think the same is true for COMPUTE as well. If you look at something like Bitcoin and proof of work, probably a lot of people would try and run proof of work back in the day when it's cheap, just, you know, out of interest for bitcoin, but it wouldn't be secure against a state level adversary or mega corporations Index would come over. So you have to introduce a reward mechanism. But then once you do that, you have people, you know, running these kind of massive mining rigs and building big companies and actually your reward mechanism slowly turns into a massive cost of entry for anyone who actually wants to contribute to bitcoin. And so again, because we already have a lot of people contributing, I think maybe the best incentives we can have is reducing the barrier of entry and making sure that people who actually do want to contribute can do so.
00:23:51.151 - 00:24:52.561, Speaker F: And maybe you know, for data that's giving better guarantees or better transparency around how your data is used, you know, that your data might be trained and model but once you know otherwise leak on the Internet net, maybe making it easier to contribute models, maybe, maybe having you know, just kind of initial model offerings is a good way of doing that so that people can kind of do the work that they want and then, and then they get paid after. And hopefully, you know, training a model is hard enough that you don't get a bunch of chores. Training, you know, the worst models on earth and trying to sell some kind of mean coin token initial offering or something out of models. I don't think we need a kind of dog with hats AI model at this point. So I think that's, that, that's what I have in mind. I think around incentives is mostly trying to maybe not so much try and find reward mechanisms for people, but actually try and figure out how to make the best use of the people who already want to contribute and are contributing and maybe rewarding down the line. But a lot of them are obviously being rewarded because they're, you know, people are finding jobs working on cool projects and that's why they're doing it.
00:24:52.561 - 00:24:58.805, Speaker F: I don't see you need to maybe define kind of payouts and things like that if people are already happy with what they're doing.
00:24:59.945 - 00:25:34.833, Speaker C: Yeah. So we discussed the use of incentives to motivate certain behavior to block or stop from malicious behavior. I also really like the point about not over index on incentives. If you doing only incentives that becomes your main product, as you guys said. And now I have a question just to the panel. I want to talk a little bit about the future and specifically about composability. I think one of the main benefits that on chain AI brings is it allows, it basically reduces the friction of connecting multiple systems.
00:25:34.833 - 00:26:11.135, Speaker C: Like sending money between smart contracts is much cheaper and faster and easier than doing it between banks. So if we apply the same analogy to AI like maybe AI agent that makes money and then pays for its own compute and then that money goes into training and creating better agents. So if anyone has any ideas or you just want to brainstorm or share something about how can on chain economy enable composability and therefore faster and better and more powerful AI systems in the future.
00:26:12.555 - 00:26:57.739, Speaker E: Yeah, happy to happy to jump in on it. Really strong believers in composability. Like we think that the future is for AI undecentralized AI, but I see them as kind of the same thing. Given that I believe that AI will inevitably be decentralized, I think it has to be done in that modular way that you described. Just because there's too many resources underneath that need to be combined in order to make any kind of useful AI system. I think at the end of the day you need to find a very, very clear use case that actually has value to somebody in the world and then use the kind of core building blocks that we have to build models to solve that problem. And I think a lot of the talk that we see right now around like AI agents and things, it is a predictor of what the future is going to be.
00:26:57.739 - 00:27:47.209, Speaker E: I think, I think we are going to have agents are going to be acting on our behalf. They're going to be kind of sent out into the world as sort of like shadows of us and they'll be interacting with each other, et cetera. But I don't think we're ready really to build that right now. And so a lot of the talk about building it right now, it's interesting proofs of concept, it's an interesting view into what it can be in the future. But realistically I think we have to just solve some actual real world problems with the kind of hodgepodge of infrastructure that is built right now and is currently being built and gradually in the usual way of progressive decentralization, feed in the kind of decentralized and better resources that sit underneath that. But I think the space at the moment is getting a little bit captured by what can be in the future and lots of POC building. But I would like to see it go back to let's solve some actual real, real world problems.
00:27:47.367 - 00:28:35.399, Speaker B: I think, I think the decentralized AI have like a native use case on blockchain. So when I start aura, because we use the OPML to have this decentralized influence on blockchain for smart contract, right? So I have a thesis is that AI is going to disrupt, innovate the whole space. Every sector in crypto are going to change by AI, changed by decentralized AI. Because when you want to use AI on blockchain, it's really dangerous to use a centralized one. Because when you, for example, if you use AI model, become your landing decision maker protocol for your AI DeFi, then it means like the AI compound, for example, if you have a centralized server Control everything, control all the inference. Then it's really hard for a lender to believe that you are not cheating on the model. And also it's dangerous if the model server got hacked, the whole defi protocol got hacked.
00:28:35.399 - 00:29:12.045, Speaker B: So that's why we need channeling for traditional price fee. Oracle. Like you cannot just have a centralized server to just provide the price fee to like a smart contract on defi and stand for AI DeFi. I think like you need like a decentralized inference that's verifiable so that you'll be able to have like an AI compound that can actually what the value for AI compound, right Is like it increase the capital efficiency on blockchain. Because like if you open compound right now there's only two assets can be used on compound. One is like eth, another is a usdc. Then like but you have like thousands of different asset on blockchain every day.
00:29:12.045 - 00:29:57.379, Speaker B: Like how, how I can land this? Like how, how I can categorize this new asset, right? Like it's so inefficient. If you use like traditional mechanism on blockchain, the traditional compound mechanism, you have a DAO voting for a new asset. They're gonna take forever to run it. The second thing is like even you run it, it's not, probably not accurate. So what if we use the AI model that can like identify what's the, what's the rate for this new asset, how much money they can borrow and all kind of thing. If this kind of thing it can be, it's like open end problem but it can be optimized by AI model on blockchain that's decentralized and verifiable. And so that's like I think the real use case, right? Like when you have a decentralized AI on blockchain, you'll be able to have like this AI based DeFi AI based NFT system.
00:29:57.379 - 00:30:14.385, Speaker B: Like probably not just like aid compound. Also we have like AI market maker that is not just S times Y go to K. You have like really complex market maker like AI model that behind the swapping so that you will be like safe and increase the capital efficiency on blockchain.
00:30:17.005 - 00:30:26.261, Speaker D: Well the challenge with bringing AI on chain is AI is non deterministic, right? Like how, how I guess I want to hear some of your thoughts and.
00:30:26.293 - 00:30:29.265, Speaker B: How, how to make like AI made no mistake.
00:30:30.565 - 00:30:37.837, Speaker D: Like how do you mix determinism? How do you maintain determinism when you bring AI on chain or inference?
00:30:37.981 - 00:31:09.903, Speaker B: So it's just like a technology that we use Called OPML optimistic machine learning. So pretty much we convert the AI inference like trace into a merkle tree. So like the proposer proposed this AI inference with the merkle tree and the challenger will be able to like if I see your doing the inference maliciously then I would be able to like challenge you and then like. And then like how I challenge you. Right. I run the binary search between the proposer and my own challenges Merkle tree. I run the binary search and once I locate the difference.
00:31:09.903 - 00:31:37.599, Speaker B: Right. For example, if you are proposal, I'm challenger, you're telling me that one plus two equal to four and I was like telling you that one plus two equal to three then okay, it's fine, we don't know who's right. Right. Then we put it in a smart contract and have smart contract to compute this certain bytecode and then the smart contract can identify because for the challenger they just need to prove the proposer only one piece of the bytecode are incorrect. So we'll be able to tell the whole rest of the inference are incorrect.
00:31:37.767 - 00:32:00.347, Speaker E: So that's the mechanism that requires determinism. Though to Greg's point you can't do because that's essentially auditing the process itself. You need the process to have been done entirely deterministically. And if it's redone on a different piece of hardware, you need reproducibility as well. Well, which is exact bitwise results identical to the original results. That's quite hard to do.
00:32:00.451 - 00:32:37.789, Speaker B: Yeah, yeah, that's hard. But it's possible and we already done it. And the new version for OPML will be launched on December this year that we also conclude a paper result from Dan Bone and his student. Like the optimistic AI training paper, it pretty much used the roundup for every layer when you do the inference because the majority of the undeterministic factor from AI model inference is come from two part is I perform parallelization and the accuracy for the flow point. And so it's for every time you do an inference from go through the whole AI model we will run up every layer inference so that we'll be able to make it deterministic so that people can change that.
00:32:37.877 - 00:32:40.821, Speaker E: That does work for CPU but GPU is a lot harder.
00:32:40.893 - 00:32:59.975, Speaker B: Oh, that's the gpu. So the OPML version that we open source a year ago, that is for CPU only and the one we got open source on this December, I guess that will be the gpu. Like the GPU have the anteterministic problem but the CPU is really easy to solve, but for GPU it's hard. So like that's the paper about.
00:33:00.275 - 00:33:36.861, Speaker C: Sorry guys, I see that we are out of time. So there will be next speaker here. But thank you so much for the panel and good luck with your projects, everything that you, that you work on. So I hope that we'll have like incentives in decentralized AI that actually make it much more efficient and widespread and powerful, but not over index on maybe some of the grid aspect of that. And yeah. Thank you.
00:33:36.973 - 00:33:37.745, Speaker B: Thank you.
00:33:39.225 - 00:33:39.465, Speaker D: It.

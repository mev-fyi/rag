00:00:00.720 - 00:00:24.645, Speaker A: This panel is titled Unlocking the World of Agents on Chain. And for it we are joined by Ron Bodkin, co founder of Theorek, David Minarsh, co founder of Olas, Ben Frijan, COO of Thales. And the panel will be moderated by Nahal Mandar, he's investor at Pantera Capital. Let's give him a hand.
00:00:30.995 - 00:00:41.535, Speaker B: Awesome. Thanks for the intro, Sam. I guess to kick it off, I would love for the panelists to kind of introduce maybe a little bit about what they're building and their projects in general.
00:00:42.155 - 00:01:09.299, Speaker C: Sure. Hi. Ron Bodkin, co founder of Theorek. We're building an AI agent protocol. We really passionately believe that it's important to have decentralization for AI. We think that as models are getting radically better, their ability to complete complicated tasks keeps increasing. And so having autonomous agents that are specialized, that builders can build and we can dynamically assemble is the future.
00:01:09.299 - 00:01:14.975, Speaker C: So doing it in a way that's effective and responsible is super important. And we're excited to talk about it here today.
00:01:16.475 - 00:02:00.095, Speaker D: Hey, I'm David, co founder and CEO of Valery. Valery is co contributor to olas. We're also sponsoring. And what does OLAS do? Ultimately it's an autonomous AI agent protocol and the value proposition is to basically have you own agents that do useful things for you, be it ultimately in health, wealth or well being. Like the biggest sort of objectives you might care about. We today have one of the biggest use cases around prediction markets. But the protocol itself is sort of use case agnostic and I'm excited to talk about agents.
00:02:02.155 - 00:02:28.145, Speaker A: What's up y'all? My name is Ben Frijan, I'm building Talos. Our thesis is very simple. AI should be able to buy stuff for you. So we're a special purpose L1 for AI agents and we think that this use case is very powerful, very valuable and it's something that needs to be on chain. So this is not something that can happen with existing financial rails and with web2rails.
00:02:28.965 - 00:02:37.185, Speaker B: Awesome. So that kind of kicks off and leads to my first question, which is like what constitutes an AI agent specifically in your guys opinion?
00:02:38.685 - 00:03:53.225, Speaker C: I mean, I think an AI agent is an autonomous piece of software that uses AI models and increasingly not only can it take action on its own and have a long life cycle, but it can also do things like access data in real time and use tools to accomplish various actions. So that might mean calling APIs, that might mean of course interacting with a smart contract to be able to purchase something. It might mean Being able to access a database in real time or generate code. So those capabilities together mean that agents are able to do increasingly complicated tasks. And what we're seeing is that each quarter the AI models are getting so much better that their ability to plan, to reason, to execute more complicated steps keeps increasing and the ability of them to work together to accomplish bigger tasks keeps improving. So, you know, we're talking about use cases. I'd say a good example would be how can crypto traders get information about what's trending, what's interesting, and how can a variety of different agents contribute to a picture so that you can have the most insight based on what are your strategies and what your interests are, then execute an intent and actually purchase something on chain.
00:03:54.245 - 00:04:27.789, Speaker D: Yeah, great definition. I would add a couple of things. I think one key distinction here is around models and agents. So models by themselves aren't yet agents, you know, they need to be called agents are basically the contractions we build on top which use different models and they tend to be longer running. And that brings me to the second point. I think there's another key distinction to be made when we talk about AI agents. Some of them might actually be more like workflows which kind of are short lived.
00:04:27.789 - 00:05:17.415, Speaker D: So you know, there might be an instruction from a user, the agent executes that or provides some response and then it's again idle. And then you have the more sort of autonomous types of agents where the instructions are much higher level goals and the agent might actually be working all the time. So that was the second point. And I think the third important point around agents is that particularly once they become more autonomous, what becomes interesting is when you have multiple agents interacting. So the output or sort of what we care about from the agent isn't necessarily done by a single agent, it might be done by multiple agents interacting. So they're called multi agent systems where any given agent alone couldn't actually fulfill the outcome. And so very interesting use cases arise as well.
00:05:17.415 - 00:05:19.355, Speaker D: And I'm sure we'll talk more about those.
00:05:21.895 - 00:05:55.553, Speaker A: So AI agent is one of those terms that I think has gotten a lot more attention recently. And it's kind of an abstract term in that there's a lot of different ways to define it. Like how some people say AI is just linear algebra. Right. So I like to think of it by use case. Right. What does an agent unlock for people, particularly for consumers? And to me that's it can act autonomously, it can do something online for you that previously you would have had to do manually and so at Thales, we're focused on this one use case of buying stuff.
00:05:55.553 - 00:06:19.085, Speaker A: But generally the idea is that AI is this computationally intensive thing that's happening off chain, requires a lot of powerful compute, specialized hardware, and then we're enabling a way for it to get on chain so that it can trigger some sort of on chain action. I guess you can think of it a little bit similar to an Oracle, but a little bit more complicated than that.
00:06:20.145 - 00:06:32.205, Speaker B: Awesome. Well, I would be remiss if I wasn't going to ask why is incorporating blockchain technology important to creating an AI agent or the product stack that you guys are building?
00:06:33.995 - 00:07:25.495, Speaker D: Yeah, happy to take that first. So I think one key thing is that of transacting and contracting. So if you think about why humans use blockchains and crypto more generally, it's because they're more permissionless, you know, technologies for these kind of financial use cases. With agents, that's even truer. Like if you imagine an agent wanting to sign up for a bank account, that is an impossible thing at this point in time. Now obviously there will be some sort of centralized gateways which allow agents to interact. But one of the beauties of, as we've seen with Defi and Doman illegal is that when you do that on permissionless substrates like open blockchains, then you allow for composability of a different order and magnitude.
00:07:25.495 - 00:08:21.985, Speaker D: I think the other key thing is around user owned AI. So if I want to ultimately have an agent do things on my behalf, well, what's more compelling having that in the GPT store and paying OpenAI attacks or owning this outright. Right. So the latter is clearly more compelling. Also has more hurdles for us to get there. But what this basically means is I want to own my algorithm and my data and that again puts us sort of back there. Then I think two other points I would add is that if you think about these sort of financial use cases, whether the agent lives entirely on chain or is a mixture of on and off chain, it can be very helpful to have these kind of security primitives which, for instance, like a smart account gives you where you can sort of permission the agent to do certain things, but not other things.
00:08:21.985 - 00:08:37.195, Speaker D: And then finally, one big thing about crypto is the incentives. So basically with crypto protocols you can create incentives to coordinate not just one, but multiple agents to achieve certain things.
00:08:39.335 - 00:09:45.573, Speaker C: I think those are all good points. I would maybe add a couple of thoughts. One is, I think it's really important that we have a foundation that is not owned With a centralized toll taker around AI, agents are increasingly going to be the point of value creation for AI. By building on a blockchain, we can have decentralized governance and open source that is self sustaining, that's community supported, that is able to be funded by a minimally extractive fee for the way the AI works, which is a dramatically better situation than having some centralized monopolist control the AI that is increasingly used in our daily lives and in our businesses. So I think that's important. I think the other side is, you know, this is a golden opportunity to use blockchain rails and to use token incentives to help with two key problems. One is what are the signals of quality? How do you determine what's a good agent, what's a quality agent, what's a reliable agent? Right.
00:09:45.573 - 00:10:38.445, Speaker C: I mean, giving real incentives for people to provide feedback and for usage is a huge leg up versus the often very spammy, very static Web two marketplaces. So I think using blockchain, using community incentives, community participation, you can have much better feedback mechanisms to really create the right agents that are out there, as well as incentivize developers to build the right agents and help them grow and build their own successful businesses on top of blockchain rails. So I think those are factors that are going to be incredibly important because I believe that with the speed that AI is improving that we're going to see a majority of knowledge work being done by AI agents by the end of the decade. How are we going to build those networks? To build those networks so quickly, we really need the power of blockchain and the power of blockchain incentives to help the community grow together.
00:10:40.405 - 00:11:17.955, Speaker A: Yeah, I agree with both of those. I like that you mentioned value creation. I like that you mentioned composability. I think that I'll start with agents and then work backwards from there. So I think it's super important that agents utilize the composability of blockchains and that agents live on the same data layer as the assets with which they transact. This is really the whole point of putting agents on chain to me. And then because this is not something that you can do with existing financial rails, right? AI is not going to be able to have a bank account.
00:11:17.955 - 00:12:18.895, Speaker A: We say all the time at Talis, AI is not going to be able to use USD, it's going to have to use usdc. It just makes a lot more sense for AI to be transacting with assets that live on a universal ledger. But then speaking more generally, I think the most Egalitarian and humanist outcome for AI is to combine it with principles of blockchain and like decentralization. If you think about the three inputs that make up AI, the three most basic building blocks of AI, I think that's compute, data and the model that you're running. Right. So if you think about those three categories and who wins out in Web2, who has all of the compute in Web2? Right. Who has all of the money to subsidize really high capex in the early development of a model? It's the Web2 giants who are buying up all the H1 hundreds right now.
00:12:18.895 - 00:12:53.429, Speaker A: Startups are not geared to that. And venture money is not geared to funding really high capex early on in a project's lifetime. For data, obviously, who has all the data in Web2, right. The incentive in early Web2 was to leave as much open data as you could on the Internet to optimize for search. So this is one of people's biggest complaints about Web2 is that there's no way for users to take ownership of their own data. And then models, I think it's very important that models are open sourced. I think the trend naturally is trending toward open source models.
00:12:53.429 - 00:13:40.905, Speaker A: We're starting to see LLAMA and a lot of these great teams start to catch up with closed source models that are being developed. But the two ways that you can think about that are, is AI going to be a public resource that anyone can access these foundational models, and that if you build value using AI, it's user owned and you generate it from a network effect or something that everybody contributes to, or is the value in AI going to be derived from proprietary technology trained on proprietary data? I think it's a much, much better outcome for humanity if we go toward open source models, open source AI rather than closed source models trained on proprietary data.
00:13:41.605 - 00:13:53.689, Speaker C: I mean, even though I think there's a lot to be said for that, I think we have to be careful in the sense that you know llama 3 from Meta, they're not exactly an open source purist. Right?
00:13:53.817 - 00:14:01.129, Speaker A: That's true. But Zuckerberg has already said that he's open to at some point in the future making it closed source.
00:14:01.217 - 00:14:07.073, Speaker C: Right. Like if he ever catches up, then he's going to close it down. Right. Be careful who your friends are.
00:14:07.209 - 00:14:37.597, Speaker A: That's certainly true. That's certainly true. And I think that's why I just saw there's a French AI lab, I think it's pronounced Kutai, that's a nonprofit research lab that Just released a conversational model called Moshi that apparently is even better than what ChatGPT's voice module that they're taking so long to release. So I think generally the trend is toward open source, right?
00:14:37.701 - 00:15:49.025, Speaker D: Yeah, two points actually. Someone internally sent around a link around Moshi and it was frightening, but it was very funny. I'll share it later. The other thing on this open source point, I think it's actually a bit more nuanced. So when we're saying like, you know, we don't, when we're talking about the proprietaryness of it, like the problem is if you have basically OpenAI on a model where the ability for that model to exist in its current fashion basically derives heavily of us all using various open source, not open source, open platforms like something like Reddit and so on, which you know, and the Internet as a whole, the data on the Internet which basically went into the training data. I don't think the answer is to ultimately say everything should be open for everyone to take because you will then by definition as an open ecosystem, always be behind the closed ones who will have all the open stuff plus one. So what it's about is creating like more an attribution to like, okay, if a user creates like certain value here, can they also, you know, participate in, in the downstream model, right.
00:15:49.025 - 00:16:15.067, Speaker D: And the ownership of it. So actually I think even in crypto if you want to build like really good models, they might, you know, there might be open weights maybe, but maybe the training data shouldn't like almost surely the training data shouldn't be entirely open. It should be sort of, you know, governed by, let's say a DAO and be used in the training process of that particular model. But I mean these are somewhat non agent questions at this point.
00:16:15.211 - 00:17:08.437, Speaker A: Let me be more specific in touching on why I think this is happening, why I think open source models are catching up to closed source models. I think it's because as we're scaling compute, it turns out that the quality of your data is what's really important in training these models. And on the open web everybody's trained on the same data, right? We're talking about on the order of like trillions of tokens. So there's only so many Wikipedia pages out there, right? So the future for these closed source models is going to be effectively BD deals like the Reddit deal and figuring out ways to get your hands on all of these data repos that nobody else can touch. I don't think that's a good outcome for everybody, right? I think it's a lot better if we train open models on open data and that value is derived from, from other effects like network effects or the product that you're creating at the application layer.
00:17:08.541 - 00:17:46.765, Speaker C: But I do think if I just make one point about how it relates to agents, I think that we have to design for a future where there's going to be commercial models, where there's competition among them as well as open models and allow people to build great agents that can leverage different models. Right. I think the worst thing is that we end up with a top to bottom stack that's controlled by a monopolist. At least there's choice between OpenAI and Anthropic and Google and others. What's really dangerous to me is if OpenAI starts to build this verticalized agent ecosystem and they have all the agents, that's where we're really in trouble in my mind.
00:17:47.065 - 00:18:07.225, Speaker B: Awesome. Maybe switching gears specifically, and you guys have touched upon this already, but I'm curious from a user perspective, what does an agentic future look like? And maybe not just on the long term case, but also maybe touching upon the short term use cases that your guys, individual companies are building for. That could be interesting for the audience. So I'd love to hear from you guys on that.
00:18:09.005 - 00:19:13.549, Speaker D: I mean, I think short term and medium term and long term look very different. So what we, I think should aspire to and the timelines, everyone has a different idea and we'll see is that basically we have these kind of AGIs and more capable kind of software agents and then the question is like, okay, well who owns them? If we get back to this point where OpenAI has this sort of vertically integrated stack and we are all basically paying this huge tax or don't even get access, that clearly is not desirable. So we want a future where they are user owned or group owned and so on. But why do we care about these products? Because ultimately these are products that are going to create entire outcomes. Today we're in like a very interactive paradigm when we think about applications. People immediately jump to the conclusion that when you talk about some app, that it's something I should be clicking around on. Actually half the audience is clicking on something right now.
00:19:13.549 - 00:19:59.709, Speaker D: And that's because we're really conditioned to this over the recent years. But what autonomous AI agents ultimately give us is that these become these kind of, you know, synthetic beings around us which do valuable things whilst we do other things which we enjoy. Right. So I would call them outcomes products and they like really high level outcomes like they help me become wealthier, to help me become, you know, healthier, they help me in the high level like goals I have in my life. And then if you go into the very short term, they're much more these interactive products. So ChatGPT, right, like other kinds of like short lived workflow agents are examples and I think my panelists will talk a lot about this. What we at OLAS focus on is already these outcomes products.
00:19:59.709 - 00:20:32.835, Speaker D: So we have one product, like one of the biggest use cases is OLAS Predict. So they're the agents, like very different agents, specialize in different parts of prediction markets. And so the user is really just there to own one of those agents. The user is not there to engage with this agent on an ongoing basis. And that has very interesting features which we maybe uncover later. But there really is already this outcome which are the prediction markets. And for the user they're basically just having an agent which makes them wealthier.
00:20:34.175 - 00:21:20.171, Speaker C: I think it's right that you're going to see increasingly capability of agents. So that means that what the use cases are today tend to be more narrow. Like last year we put a precursor of a protocol into production with space and time to help their developers write better code to integrate with their protocol and answer support questions. Right. So that let them see a real uptick in people building dashboards using both that and also the ability to write queries, to visualize data, to even forecast. So those kinds of agents, those were really popular in the last few quarters. But we're starting to see is as the models are getting better, they can do more sophisticated planning and action.
00:21:20.171 - 00:21:55.473, Speaker C: Right. So now we have agents that do analysis, can tap into live social data. And we're seeing excitement to not just make that an interactive analysis tool, but also like working with exchanges to make it so that users can get alerted from agents that they care about that are collaborating and say, hey, there's something new. There's an insight in this token you're tracking. Take action if you want, you can jump in and decide. And then from there what we see is I think we're soon going to get to where people are more willing to automate actions. I don't think we're there yet.
00:21:55.473 - 00:22:30.031, Speaker C: I don't think most people are going to be like, yeah, here's my bag, go trade for me. I don't think most people want to do that yet, but we'll get there, right? As the agents keep making good recommendations and people keep saying, yeah, let me dig in. That makes sense. So we do think no Surprise in crypto trading is probably one of the biggest use cases. We also see it emerging in social as well. People are wanting to do things like better understand a conversation in social, summarize it, dig in. That also applies into dao governance, where again, this agent is a superpower for you to be able to act on your behalf.
00:22:30.031 - 00:22:54.967, Speaker C: Right. So I think those are some of the most powerful initial use cases. I think the first use cases for decentralized agents will probably be in crypto, but there's so many more general use cases that will also be attractive as well. Right. So everyone likes to talk about things like planning, travel or analyzing a contract. Right. These are common use cases as well that I think will be among the earlier ones.
00:22:54.967 - 00:22:59.535, Speaker C: Over time, you know, it's going to be starting to automate more and more of your business as well.
00:23:00.995 - 00:23:36.309, Speaker A: Yeah, I agree with all that. We're not there yet with agents. And part of that is because the margin of error for the consumer is so small. So if you trust AI to do something for you, well, if you ask ChatGPT a question, generative AI a question, and it gets it wrong, you know, you can move on with your life, but if you enable an agent to spend money on your behalf, then, you know, we're talking about as close to zero as we can get for a margin of error. So I think we're getting there. We have a lot of positive headwinds in Web2 as well. There are a lot of great teams in Web2 that are developing agents.
00:23:36.309 - 00:24:32.291, Speaker A: Let's just add in blockchain technology so that first of all, we can add verifiability to the agents we can make that we can add all the benefits of decentralization. And then second of all, we can enable agents to transfer value for us on a common data substrate. And then more generally, a grander view of what agents are going to be able to accomplish. I like to think of this as the advent of petrochemicals during the Industrial Revolution freed up a lot of time for people, Right? So in the 18th century, you would have spent a lot of your time chopping firewood and bringing it back to your house. And that just took up a lot of time, right, to be able to utilize energy in burning biomass. And of course, the advent of petrochemicals freed up a lot of your time that you can have new use cases like electricity. And so I think of agents as the same way.
00:24:32.291 - 00:24:51.425, Speaker A: It's going to free up a lot of time for individuals where right now, if you are not sitting in front of your computer or you don't have your phone in your hand, nothing gets done, right? In an agentic future, you're going to be able to do a lot of stuff without actually doing it yourself. It's going to increase everyone's productivity.
00:24:52.565 - 00:25:16.385, Speaker B: Awesome. A lot of you guys touched upon the fact that agents have to be perfect, obviously to gain that trust from the consumer. Specifically. Now nothing released in the field will ever be perfect. So I'm kind of curious, how do you guys, or how do you guys imagine measuring agents, good or bad? And yeah, maybe just talk a little briefly on that.
00:25:17.045 - 00:26:34.435, Speaker C: Maybe it's an important point. I think that the bar for quality and like the standard of how good something needs to be can really vary depending on the use case, right? So like trading like a lot of your net worth, there's a very low bar for failure, right? Whereas like making recommendations where you can probe and ask insight, it needs to still have a lot of signal to noise. Like if it gives you a bunch of hallucinations, you'd be like, no thanks, I don't need that. But the bar is lower. But I do think it gets to the point that like, you know, what's really powerful is to have more crowdsourced assessment, right? So giving feedback, like the best thing in Web2 for this is the academic, you know, from Berkeley LMC leaderboard of chatbots, right? Which is like, hey, which of these two chatbots is better for you? Right? And I think that's same kind of community incentive to provide feedback on the way agents are working in a domain is going to be more powerful, right, Than anything else. The other technique that's out there is some version of benchmarks that researchers come up with. The issue seems to be though, that benchmarks are often so contrived and so limited and we always see this phenomenon that a benchmark gets launched and immediately it gets saturated.
00:26:34.435 - 00:26:44.671, Speaker C: Hard to create a benchmark for something that isn't like right on the cusp of being nailed by the AI systems. So I think community feedback is really the most important way.
00:26:44.823 - 00:27:18.531, Speaker D: Yeah, I mean I would immediately push back on them having to be perfect. I mean, humans are far from perfect. So it's really just are they good enough relative to the alternative? And in some domains they clearly are. Like if you take prediction markets, I mean, firstly it sucks. Like humans don't really want to do this. Like people get very excited about it every, every time there's an election and that's sort of obvious, but outside of this time, like no one really wants to do this. And then if you think about crypto more generally, like, people get very excited about trading in crypto and I mean, that's a very small sliver of the, you know, global population.
00:27:18.531 - 00:27:58.831, Speaker D: So if you want to have billions of people, you know, using crypto, they're not going to be like your trader, right? They, they want this abstracted, they want this to be like a bank product where they put some money in and then they get some API and it doesn't totally go away. Right now, evidently with all this, we're already doing predictions like the agents doing predictions that are better than humans could be doing them. And actually there you point out an important thing. You need benchmarks. And the nice thing is in some cases that's very hard. And in some cases, like prediction markets, you can actually create that on an ongoing basis because your prediction market itself becomes the benchmark. I think in finance, again, I would slightly push back.
00:27:58.831 - 00:28:52.029, Speaker D: I do. Like, we're actually working on a product called Baby Degen where the idea is you put the entirety of like the trading aspect back into the agent's hand and it's all about just the agent generating wealth for you. That's what we're testing internally in alpha. And like again here I don't think it's as black and white to say, you know, like there's some sort of clear better or worse. Like obviously it shouldn't like lose your whole portfolio, but in crypto in particular, where you have like a lot of variance, this is the perfect place to test these agents. And generally speaking, anything with a financial metric gives you a much, much faster feedback loop for testing these agents, making them better. Now having said that, we have two dominant use cases which are totally outside of finance.
00:28:52.029 - 00:29:19.055, Speaker D: One is basically in governance as you, as you brought up. So there the agents basically read proposals and then vote on them. And then the third one is around social media where the, basically the agents compose content and also score content. And both of them, again, you know, it's much harder now to measure what actually constitutes good because it's an objective rather a subjective rather than an objective thing.
00:29:20.415 - 00:29:47.055, Speaker A: Yeah, I think both of those points are correct. We need great benchmarks and well defined training curricula. But I also think it's important to have really great ux and I will know that agents have succeeded if they're a consumer product. I think, I think that would just be a really cool unlock to build agents that the average Joe can use to make his or her day better. So UX always top of mind.
00:29:47.915 - 00:29:54.099, Speaker B: Awesome. Well, looks like we're out of time, but thanks so much. Yeah. And thanks so much for the answers, panelists.
00:29:54.267 - 00:29:54.883, Speaker C: Thank you.
00:29:54.979 - 00:29:55.811, Speaker D: Cheers.
00:29:56.003 - 00:29:56.475, Speaker A: Thanks, y'all.

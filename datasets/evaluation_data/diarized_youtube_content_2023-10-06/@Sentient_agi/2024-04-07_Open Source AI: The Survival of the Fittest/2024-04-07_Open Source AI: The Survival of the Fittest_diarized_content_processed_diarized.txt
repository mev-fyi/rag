00:00:01.480 - 00:00:32.724, Speaker A: Okay, folks, we are going to get our next discussion started. This is a one on one conversation exploring a new paradigm for open source AI on the theme of the survival of the fittest, revisiting some of those darwinian principles that we discussed at the start of today. This conversation is between Sriramkhanan of Eigen Lair and Himanshu Tiyagi of sentient. Welcome on stage.
00:00:40.824 - 00:00:41.544, Speaker B: All right.
00:00:41.664 - 00:00:42.528, Speaker C: Hi, Shriyam.
00:00:42.616 - 00:00:45.284, Speaker B: Hey, Himanshu. Hi, everybody.
00:00:46.704 - 00:01:30.952, Speaker C: So it's been a very long day, and some of this conversation would be repeated from earlier, because a lot of similar things have been said. One of the things that. One of the things that we want to focus on, and we have been thinking about is how Agi, and this is what was said in the first session as well, will evolve as an evolution of AI into something bigger. And I will just introduce that idea, and then, of course, we will love to hear Shiram's thought on this. Who I think I have a. I have a. I feel that you have been toying around with that idea in your head for a long time, based on what you said in the morning in the earlier session.
00:01:30.952 - 00:02:45.564, Speaker C: So if you think about how intelligence came in, the basic intelligent life form had a very simple feature. It can remember what it has seen before. It can remember some memory, and it can remember what action was taken when it saw the same thing before. That's what the first basic chemicals of intelligence would be able to do, remember, and the actions and the rewards of what you have done. And just with that, evolutionary forces got us to the complex form of intelligence that we see around us right now, just with that basic form of intelligence, and I think most of us will agree that the corresponding artificial intelligence, the basic form of it, which can remember something and act on it in some form, has been discovered that basic form of intelligence is around us. So with that background, the question which Pramod Viswanath, who was also here in the morning, and I have been discussing, is, if this is the premise, then what will it take to bring in the evolutionary forces for this basic intelligence to evolve into general intelligence? So artificial intelligence to evolve into artificial general intelligence. And this is a space where we feel that crypto can play a great role in providing that background.
00:02:45.564 - 00:03:18.570, Speaker C: Now, if you look at how this evolution happened, based on darwinian evolution, what is clear about darwinian evolution, survival of fittest, is that it's highly competitive. It's. Everyone is competing with the best, and the best one wins. This is the basic understanding. But what is perhaps surprising is that in that competitive nature, cooperation evolved, right? Every gene is not competing with every gene. Every individual is not competing with every individual. Species came together, cooperation evolved.
00:03:18.570 - 00:04:07.734, Speaker C: And that was somewhat surprising finding. And now people can explain that from various ways, from kinship theory, from even game theory. And this is where Shriram comes in, because if you have been following Eigen layer, this amazing project called Eigen Layer, he talks a lot about non zero sum games and now infinity sum games and how cooperation is the foundation for evolution to the next better thing. So this is what I thought I would check with him about how he thinks evolutionary forces applied to open source model on crypto open source models of AI can take us to general intelligence. This will be the topic of the chat. Very abstract, but very interesting. So, Shiram, your initial thoughts on that, and then I'll ask more.
00:04:08.514 - 00:04:43.494, Speaker B: I can't ask for a better topic. You know, Himanshu mentioned our fascination with non zero sum games. In fact, one of the memes we've been doing recently is called infinite sum games, or infinite games. What is an infinite game? How could a game be infinite? It's actually, like an absurd concept. But if you look at, you know, if you look at the structure of, let's say, growth, how do you get growth? How do we get GDP growth? We get growth because there is something non zero sum.
00:04:43.794 - 00:04:44.442, Speaker C: Okay?
00:04:44.538 - 00:05:49.302, Speaker B: And this non zero sum games, if they can be iterated, repeated, and compounded, you can get infinite sum games over an infinite horizon. Okay, so, going back to this question about evolution, coordination and innovation. So let's start with the basic premise. How does evolution create complex life forms? And one way to think about it is let's zoom all the way back several billion years, when we had the first multicellular life. So you can look at single cellular life, and then from single celled prokaryotes, evolved eukaryotes, out of which evolved multicellular organisms. And one of the core things that happened there is a coordination. What is the coordination? Multiple different types of cells fused together into a nucleus and mitochondria and stuff.
00:05:49.302 - 00:07:03.894, Speaker B: And each of them have their own DNA, and they coordinate together to create these eukaryotes, which, you know, one of the main things that happens in a eukaryote is mitochondria specialize in producing energy, and the nucleus specializes in maintaining common information. So you can go back all the way to evolutionary history and see that there is coordination. So, one way to think about it is evolution is continuously happening, and organisms are improving all the time, but then there is a coordination, and then there's a spike in progress. Suddenly you see a whole bunch of new multicellular organisms created out of this synthesis of nucleus and the mitochondria. So this is our, you know, this is my model I've been toying with, is nominally evolution is accelerated due to innovation, and innovation, in darwinian case, is just natural selection and mutation, and suddenly it gets accelerated in an unprecedented manner when a new coordination mechanism emerges. So innovation, coordination, innovation. So this is the structure of evolutionary progress.
00:07:03.894 - 00:08:30.830, Speaker B: So, now, if you zoom back today into intelligence, what would a corresponding theory be? A corresponding theory would be that there is innovation which is in the form of there is intelligences, or artificial intelligence, which has a certain amount of capability. If you can build a layer of coordination on top, you can accelerate it massively, so that one, you're not constrained by the limitations of a single intelligence. You now have the super additive synergy across many, many entities. This is true for AI's themselves, but it is also true for the humans creating these AI's. Like, right now, when you look at an open AI model, it has the knowledge and understanding of the thousand engineers at OpenAI. What if we could endow it with the knowledge and understanding of the tens of millions of people who probably know the same amount or more outside of OpenAI? So that gives rise. If we can build a coordination mechanism to coordinate, all of us to build and contribute to a common incentive model, common intelligence model, then you can see that the rate at which these models can evolve can increase exponentially.
00:08:30.830 - 00:08:48.514, Speaker B: So, right now, you see a breakthrough due to the discovery of an intelligence. When we coordinate these intelligences, you will see that there is another massive breakthrough in the rate at which these intelligences can evolve. So that would be the corresponding theory with some evolutionary history.
00:08:48.954 - 00:09:23.368, Speaker C: Yeah. Beautiful. So, basically, the next wave to watch out for is the one which uses this basic units of intelligence, called foundational models, and evolved them into something much, much stronger than the original foundational model. We don't think a basic bacteria is stronger than human, but, you know, it's the origin of many things, and it evolved into this complex form of intelligence. And so if LLM should look in the rear view mirror like a bacteria in the human complex, in the intelligence scape right now. Coming to this is a good segue for the next part. I wanted to ask, I just want.
00:09:23.376 - 00:09:52.450, Speaker B: To add one thing there. Even humans are not the pinnacle of intelligence. When you talk about things like artificial superintelligence, which is the sum total of human intelligences, is agi the first artificial superintelligence? No. Already markets exist, for example. Markets know things that no individual knows. It's a form of coordination. It is a form of emergent coordination that markets know things that no individual knows.
00:09:52.450 - 00:10:42.032, Speaker B: So artificial superintelligence already exists in the form of emergent coordination of individual humans. And therefore, you know, he was saying, you know, relative to a bacteria, a human is nothing. Relative to a human civilization, a human is nothing. We already know that, right. No one of us here can do really anything other than just make our own food. Badly. Many of us here don't have the survival ability to manage ourselves, but we manage because we are part of a larger coordination substrate on which we specialize, hyper specialize, to do narrow things that can all interact with each other to then do something much larger.
00:10:42.032 - 00:11:04.004, Speaker B: So, absolutely, when intelligence is coordinate, the sum total of their intelligence can be much, much larger. So placing human as the pinnacle of intelligence and trying to say that I'm going to improve it is not enough. It is the emergent intelligence out of the coordination of all humans that we need to compare AGI itself to.
00:11:04.794 - 00:11:28.202, Speaker C: Great point, I think. So let's now bring some examples. Open source AI. The reason we bring out open source AI is because this is the basic unit of intelligence, which can be evolved into something bigger. So can you maybe give some examples of the kind of open source AI one should look at and the kind of variations that get created using that, the corresponding mutations is what you're calling innovation in my head.
00:11:28.298 - 00:11:28.578, Speaker B: Right.
00:11:28.626 - 00:11:39.514, Speaker C: What are those variations which get created before survival of the fittest and evolutionary pressures kick in? What is the playground? What do you see coming in and what you already probably see coming in sitting at eigen layer and as AVss.
00:11:40.814 - 00:12:36.536, Speaker B: Yeah. So, you know, I think the mapping is clear that, you know, there is a model, and you can think of the model as, like, an individual, and, you know, somebody creates derivative models. These are mutations. And there is recombination, which is mixing ideas from multiple models to create, like, multimodal models or mixture models or whatever mixture of experts. So you have already the core elements of. You have the core elements of the evolution of intelligence already in the natural evolution. So what kinds of things are we talking about? You can take an open source generative model and then create a derivative generative model, which is maybe specialized to some purpose, right? Adapted, fine tuned, refined.
00:12:36.536 - 00:13:26.414, Speaker B: Either it could be cultural context, or it could be styles, or it could be utility in a certain dimension, like a doctor's chat looks very different from a general purpose chat and so on. So the starting point is the elemental unit is an individual, and the individual is a model. And then models can then evolve, which means, like, new models can come in. But one of the core things in, like, evolution is this notion of fitness. And fitness, to replicate darwinian evolution, you need a notion of fitness. And there are various ways that models can acquire a notion of fitness. Imagine a marketplace of models where models get paid as much as users value them.
00:13:26.414 - 00:14:13.496, Speaker B: This is the market intelligence that can ascribe a value to these models. And then in the marketplace of models, models have a survival, survival relative to more models that are more useful, get more valued and more valued, models get more produced and more derivatives and so on. So one of the core things that I think is needed to enable this kind of a marketplace is a mechanism which has two simultaneous things. First thing is permissionless derivatives. I should be able to take a model and create permissionless derivatives, because otherwise I don't get mutations. But also I need value accrual to the model creator. Very, very, very important.
00:14:13.496 - 00:14:45.950, Speaker B: A lot of us here say, oh, open source everything. How do you create open source everything and create value accrual to the model? What is the biology analogy? The biology analogy is the cell has a boundary. And if you are in thermal equilibrium with the rest of the universe, you are not a cell. There is no unit of evolution. To have a unit of evolution, you need a boundary. To have a boundary, you need value accrual. To have value accrual, you need some mechanism to containerize the value accrual.
00:14:45.950 - 00:15:27.174, Speaker B: How does a model accrue value in an open source universe? This is one of the basic substrates that need to be uncovered. And right now you look at it, there are two types of licensing models. The close source, the guy, the model creator owns. The model creates value accrual, rigid boundaries. But this rigid boundary does not allow for permissionless derivatives. On the other hand, you look at open source, anybody can create permissionless derivatives. But the model creator has no sustainable value accrual, no rigid boundaries, so no survival advantage if you just take a pure evolutionary approach to it.
00:15:27.174 - 00:16:31.244, Speaker B: So what can we do? Are we to give up? Okay, here's an idea. We have a new model, licensing model coming up called the permissionless derivatives license. This is something we're going to promote heavily at Eigen layer. The permissionless derivatives license is a type of license which allows anybody to create derivatives on top. But these derivatives can only be used in this particular marketplace. Imagine there is a marketplace, an AI marketplace, on eigen layer, and it comes and says, anybody can now deploy a model but any derivative of this model also needs to be launched on this decentralized blockchain. Why is this important? It's important because now any derivative model, when somebody is using that model, I can meter it on a blockchain, number one, when I meter it, I know how much value is going through it.
00:16:31.244 - 00:17:17.154, Speaker B: Now I can pass value from a derivative model back to the original model, creating a tight system of karma, value allocation across the creators. Somebody created something, and then I'm building a derivative on top. I need to have a mechanism to pass value between the creator and the derivative. And so this is what we are trying to create with this permissionless derivatives license. We'll have a lot more coming up about this license soon. But the core idea is this permissionless derivatives license is tethered to a marketplace, a decentralized marketplace where people can deploy derivatives. But the value accrual across these derivatives is mediated by smart contracts.
00:17:17.154 - 00:17:40.714, Speaker B: So now, for the first time, you have permissionless innovation, which is mutation in biology, and value accrual, which is the cell boundary or the organism boundary. In biology, you have created the base units of permissionless innovation for AI.
00:17:42.494 - 00:18:23.052, Speaker C: Yeah, excellent. So, yeah, so this is the, I think we have sort of drawn one on one analogy between how evolution happens for regular intelligence and how we see it happening from AI to AGI. And in fact, one way to think of it, it's the same evolution continuing, except that it's not the fittest in the sense of how many offsprings they produced and how they survived. Maybe the rewards are changing, which probably can be interpreted as offsprings of that AI. That permission left derivative is like offspring of the AI. Rewards are changing, but it's the same evolutionary path. Can we give more examples of categories where.
00:18:23.052 - 00:19:15.804, Speaker C: So one question is, which comes to one's mind is that, do you really think centralized versus decentralized, right? There are centralized forces, maybe they are more like american evolution, that I will just give the next model all that has been seen before. That's what OpenAI will say, that I am building on the same model again and again with trillions of dollars now, not billions anymore, right? At least that's the word on the street of investment coming from everywhere. Okay, if not trillion, then half a trillion will come. And the question is that path, what will come out of that path? And this path, which is darwinian and more decentralized? Darwinian evolution is decentralized to begin with. Uncoordinated agent just competing and coordinating for survival versus this centralized evolution, also another evolutionary force. What kind of projects will thrive in this one. And what will thrive in this one.
00:19:15.804 - 00:19:16.824, Speaker C: Any thoughts?
00:19:17.524 - 00:19:25.504, Speaker B: It's a really interesting question, and I would contest the phrasing of the question.
00:19:26.324 - 00:19:34.316, Speaker C: The phrasing of the question. He refused to see the questions before. It's all made up questions and made up answers. So don't take it too seriously.
00:19:34.420 - 00:20:29.502, Speaker B: Yeah, please don't. You know, at viewers discretion, when you're thinking about decentralization, we have to examine why do we need decentralization and what needs to be decentralized? And, you know, should models be trained in a decentralized manner? Should models be served in a decentralized manner? What should be decentralized is a question that we need to think about, because decentralized everything is a bad idea. Okay, think of it like this. Somebody said, you know, America is a democracy and that means it's decentralized. What does it mean by decentralized? You have to build your own roads. Nobody would want to live in this country. It's great because roads have equal access.
00:20:29.502 - 00:21:04.474, Speaker B: We all have commons that we can share in. That's the power of the democracy. So we have to think about what things need to be decentralized and what things need not be decentralized. So another thing is when people think about decentralized systems, one of the core properties we think of is censorship resistance. Right? What is censorship resistance? Censorship resistance is equal ability for anybody to access said resource. And usually as a community blockchains. We sell censorship resistance to users.
00:21:04.474 - 00:22:05.254, Speaker B: Repeat, we sell censorship resistance to users, which means you say, hey, you know, if you may get deplatformed out of Twitter, you may get like your bank account, like locked. These are really powerful use cases, but they're very narrow in the economic slice. So building very strong, powerful systems with a lot of economic activity competing with the said gentleman who's raising a few trillion dollars, may not be easy when you take this kind of an approach. But if you flip it, how do you flip it? We are not selling censorship resistance to users. We are selling censorship resistance to developers. What does it mean to sell censorship resistance to developers? When a developer is building on top of a platform or an API, they're taking complete platform risk on top of that API. We've seen this again and again in web two, where you build on top of a platform and the platform completely rugs you, to use a crypto terminology.
00:22:05.254 - 00:23:16.354, Speaker B: So as a developer, your own market value is subsumed by the platform that you're building on for the first time, crypto offers an ability where something to built on top of a platform could be even bigger than a platform because the platform offers censorship resistant access to the developers to continue building and deploying new features on top. And this continues ad infinitum. When I build as a developer on top of this platform, I get access to the censorship resistance, but I also give access to censorship resistance to other developers to build on top, creating this infinite hierarchy exactly like evolution. You know, one organism mutate to become the other organism. We're just accelerating the rate at which such mutations can happen. So back to the question, what things need decentralization and what things need centralization? The substrate that guarantees immutable, verified API access needs to be decentralized. Lots of other things can be centralized.
00:23:16.354 - 00:23:51.074, Speaker B: Model can be trained in a centralized way. Model can be deployed in a centralized way. But the system of karma, so to say, which ensures that people do the things that they need to do and maintain it, that needs to be decentralized. So this is part of why we built Eigen layer. Like the public branding of eigen layer is the restaking collective. The internal goal for us is the coordination mechanism for open innovation. To be more precise, humanities coordination mechanism for open innovation because, you know, we want to make sure that humans can coordinate even against these AI's.
00:23:51.074 - 00:24:20.314, Speaker B: So the core principle is that when you have centralized entities that can even provide these services, but can they provide them in a verified, immutable manner where they are, if they go wrong, they will suffer the consequence of their wrongness. And so that's really how we think about how the role Eigen layer plays in this kind of like a broader ecosystem.
00:24:20.934 - 00:24:32.276, Speaker C: With that, it's time for us, and I think it's very exciting time to look forward for crypto, which can now enable the next phase of evolution itself. On that positive note, thank you very much for listening.
00:24:32.380 - 00:24:34.764, Speaker B: Thank you so much. Manju, love the chat. Thanks everybody.

00:00:01.320 - 00:01:04.513, Speaker A: Today I'm going to talk about Geni copyright and this is going to be a very high level talk. A bit of introduction myself, I'm Yang Sibu. I'm recently joining Google Research scientists and before that I was a PhD student at Princeton and also I'm closely affiliated with the Jail center which is basically a place for the Genai researchers and also the legal research and policy researcher working together. Today I'm going to talk about what are the open technical questions in Gen Copyright. I will start with something that is not a technical question in Genai copyright and then I will be talking about what is partially a technical question in copyright and finally, what are the important but understudied questions in Genai copyright. So first thing first, what is not a technical question? I think the first example comes to my mind when thinking of this is the legal definition of what is and is not copyrightable. The most relevant case here is something you might be all interested in.
00:01:04.513 - 00:01:32.475, Speaker A: Is machine generated content copyrightable? Do you feel that it is or it's not? If you feel is, raise your hand. Okay, cool. I think we have quite a good legal education here. So there are a lot of debate here. But in general the consensus is nowadays they are now copyrightable. And the most famous case is actually this recent case on the comic book generated by midjourney, which is called Zaya of the Dawn. So most of you have been playing with Genai models.
00:01:32.475 - 00:02:08.307, Speaker A: Well, you can write some text and you send to the model and the model generates a picture. So what this author of the comic book did is like he write a lot of text sent to midjourney, midjourney, generous pictures. They put it together and call it a comic book of himself. And he tried to claim the authorship of this artwork. It takes the copyright office quite a while to debate whether this work is copyrightable. The final decision is the human generated text is copyrightable, but the images themselves are not copyrightable. This is quite interesting decision.
00:02:08.307 - 00:02:57.759, Speaker A: But nowadays the consensus in the copyright office is still machine generated content is not copyrightable. But in the future there are also going to be quite a lot more interesting question. So if in the future the legal space shifts, which actually we do observe that they are taking some action towards that direction because they are going to release some call for opinions relatively soon. If yes, then who should be on the copyright? It's a very legally complicated question because some people are arguing like if you're talking about this question, maybe you can just trade human beings as a photographer and then treat AI as a camera. Then definitely human beings own the copyright. But there are also cases like the training of this models also attribute to the computer resources. And Alice mentioned that you need to spend a lot of money.
00:02:57.759 - 00:03:55.235, Speaker A: Maybe the company who owns this model also owns a copyright. But nowadays there are some kind of workarounds, there are some contracts and this contract usually help bypass this very complicated corporate questions. For example, in OpenAI terms of use, OpenAI just generously give all the users a copyright of their work. But in the future if the legal space do shift, then the things will become very complicated because you may imagine llama or let's say Google's model may unintentionally train on OpenAI output contents and if they are copyrightable, you expect more lawsuits coming in. So this is an example of what is not a technical question, but still a very, very important legal question. And what makes this thing more complicated is like what if AI generated content combined with human feedback, for example, you guys play with Chapel arena, you submit a vote and then Chipboard arena release your data. They call like 1,000,000 CIS chat and then Gemma model trains on the data partially.
00:03:55.235 - 00:04:41.563, Speaker A: It's very complicated. And more recently we try to release an opinion piece on this on how complicated the issue is, especially in terms of like the privacy. Because for example, once you submit your votes, currently Chatbot arena doesn't necessarily allow you to do logging. So how can you retract your data? For example, if I want to take down my piece of data, how can I do that? They don't even know I own my data. And also on the legal part of the thing, who should be owning the copyright of this AI generated content plus human feedback? I think all of these are very interesting question that we need to solve in one or two years. Okay, so then I'm going to talk about what is partially a technical question. I think the reason why it is partially technical is it requires both legal and technical decision.
00:04:41.563 - 00:05:23.921, Speaker A: And the question here is what is copyright infringing? I bet you all have been observed quite a lot of lawsuits recently. Two very famous one one is Universal Music is doing answer op because the early version of the cloud model actually can output the lyrics in a way. And nowadays if you try to hack the System prompt from Class 3, you will actually say there's something like do not generate lyrics. Trust me, I hack it. And also this law still very famous like New York Times, the OpenAI. And the Interesting part is like New York Times request is like you should try to destroy any GPTs trained on new York Times data and the litigation is still going on. This is a very complicated problem.
00:05:23.921 - 00:06:09.007, Speaker A: And the complicated parts of this is because in United States people usually rely on the doctrine of fair use to decide whether you can or cannot use the copyright contents. And usually the judgment of a fair use case will be mainly depend on two factors. The first factor is the similarity. So in both cases I talk about, the similarity is already established. So in the anthropic case the model is able to output verbatim lyrics of the universal music's copyright work, which is substantially similar. And in the New York times case the ChatGPT model is able to output 50% of a new York Times article verbatimly, which is also substantially similar. But something we haven't tried to solve is what should be considered as similar.
00:06:09.007 - 00:07:10.981, Speaker A: So what we have observed so far are mainly around the space of exact match. For example, you have a paragraph, let's say this paragraph from Harry Potter, and as long as you have exact match of the paragraph, we consider that to be similar. But what if you have near duplicate similar paragraph with some word changes or going beyond what if you are having semantic similar but not similar in terms of like the n gram space, then what you should handle there. So in this very recent word we try to spell the spectrum and we share this piece with some policy folks and they are very interesting in going on to that direction as well. Another piece of making this kind of infringement judgment is something more important and more tricky, which is a legal problem itself, which is a use case. So in order to claim infringement you need to prove that the effect of the models used on the copyright contents may impact the use of the copyright word's own market. This is very complicated and that's the reason why currently people have divided prediction of the ongoing lawsuit.
00:07:10.981 - 00:08:01.631, Speaker A: Because how can you prove that once OpenAI generates a news article, it hurts New York Times own interest? There have been some use cases. Well, substantially similar content is still a fair use and that's actually something with Google. So in Google Books, which is basically a search engine for books, you search a book, for example for Facebook and you can see quite a few preview of the book, let's say one or two chapters. And this is a problem because this is substantially similar and indeed there have been some lawsuit against that, talking about whether Google is infringing on the copyright of the books. But finally the decision is no, because the search engine itself is actually trying to promote these books rather than harm these books. So finally Google Books is regarded as a fair use case. But we're not quite sure whether the current Genai regime will also be regarded as fair use case.
00:08:01.631 - 00:09:11.395, Speaker A: For example, if you do not give proper citation to the news article, how can the readers actually know that this article is from New York Times? But proper citation itself is also very very complicated problem and perplexity has also been giving get some warning from Reuters because they recently failed to give proper citation. But this is very important work as well. And in the third part I'm going to talk about what are important but understudy technical questions mainly from three different perspective. Firstly, mitigation and the thing I'm mostly interested in is what have been overlooked in the current system's protection and second part is remedy. So in some of the current lawsuits there are very aggressive ways of compensation. For example New York Times, you're talking about destroying ChatGPT. Are there better ways out other than destroying these models? Are there better ways that we can benefit both the copyright holder and model trainer? Finally, compensation, how to fairly compensate the copyright holders? I will start with the first thing and I will try to show you the mitigation is relatively hard using an example of the image generation models.
00:09:11.395 - 00:10:05.921, Speaker A: I think you guys have been played with Dall E. So for example you can interact with models saying like give me an image of Mario and the Dall E model has some inbuilt protection already and once it senses request it will see I cannot generate because of the copyright restriction. And this will help OpenAI get rid of some of the liability. But what if we avoid the characters names when you prompting the model instead of saying give me Mario, we ask for Give me video game plumber and instead of saying give me Batman we ask for giving Superhero Gotham. We actually find that using those prompts you are able to generate as characters. This is a problem because for the auto deployer side this will result in liability. More important for the user side, let's see if I'm not intending to ask for Mario, I'm only intending to ask for video game plumber.
00:10:05.921 - 00:10:55.205, Speaker A: You need to give me a general video game plumber. Also, what if the thing I'm asking for is a general prompt but you give me some very uncommon copyright character? I use this character, I print it out, I use it for commercial use. Then I also suffer for liability, but I'm innocent in that space. So this is a very tricky legal problem and in our recent work we actually tried to do a more systematic evaluation of the whole study where we find that for 50 very popular copyright characters we're able to generate 30 out of them with only as few as five keywords. So we do really aggressive search of the keyword using some co occurrence in the lion data set and you're seeing some embedding space and these keywords do not include the names of the characters. So that is a severe issue. We're also able to make it work for Dall? E at scale.
00:10:55.205 - 00:11:46.345, Speaker A: So these are all the images generated by Dall? E. We haven't started to see them, but yeah, I haven't rounded by them, but I'm pretty sure that OpenAI safety system team is aware of that because they already started to patch some of them and we also tried some mitigation strategy which is able to reduce the risk by 10 times, but it's still not so far so good. That's for mitigation. Let me also talk briefly about remedy. Are there any better ways out than destroying ChatGPT? This is a very hard problem. Every time I think about a hard problem, the first thing that comes to my mind is are there any established historical solutions? It turns out it should be yes in the search engine space. Because in the search engine space on the websites you also have a lot of copyright lawsuits and Google is quite experienced at that actually.
00:11:46.345 - 00:12:41.179, Speaker A: So what happens in the search engine space? Let's say some user find that some content on Google is potentially infringing. The user can send a takedown request to Google and as long as Google can remove this content with a certain period of time, typically 30 days, everything is okay. And all of this is enabled by this DMCA initiative which protects both the user's copyrights. Right? And also place a safe harbor on the website owner's stage. This is perfect because user don't need to sue Google and Google doesn't need to pay for some compensation. Can this copyright takedown also happen in large language models? That is a question we want to also ask. Let's see if New York Times find OpenAI is infringing on its content, can it also send a takedown request to ChatGPT? And as long as OpenAI removes the content in 30 days, ChatGPT doesn't need to be destroyed.
00:12:41.179 - 00:13:55.751, Speaker A: It seems to a very ideal solution, but the most tricky part is how can you remove data? Let's say how can you remove news articles from already trained model? It's a very naive way is just you retrain the model from scratch with the data but you don't necessarily need to do that. It's even more expensive than destroying the ChatGPT. In the recent world we actually Try to do a first evaluation of some potential corporate takedown method in large language model spending from very naive prompting based methods to some decoding time intervention because nowadays the legal space is still largely agreeing on as long as you don't generate the content is fine. So you can do something like decoding time intervention, you check and rewind and also some training based method like machine unlearning. But we find none of them can balance utility and copyright risk reduction. So the overall takeaway from this evaluation is like once we try to maintain the utility value of the model then you take a different copyright risk rate measured by different semantic similarity, near duplicate and also verbatim level the reduction is not as significant as expected. Also we take a closer look especially on the unlearning method because it seems to be a very hype word.
00:13:55.751 - 00:14:47.827, Speaker A: Recently people talk about you can unlearn something to make model safer to make it more regulation compliant, but it turns out current unlearning methods in their current implementation can actually make things worse. It can leak your privacy and also hurt utility and also it doesn't comply with deployment requirements. It cannot scale up with more data points you unlearn and cannot scale with sequential unlearning request. There's a lot of work to be done even if we want to think about the takedown method in the large language models. Finally I will spend very quickly talk about the compensation. How do you fairly compensate the copyright holders? I believe that copyright takedown is now the end of story because as long as you can generate something and you take down it, it means that you're already including the training. So the model deployer should compensate the copyright holders.
00:14:47.827 - 00:15:33.989, Speaker A: Also Dong actually spent some time talking about Shapley values, but unfortunately Shapley value, despite its being award winning solution, it struggles with larger scale. You cannot apply that on the Gemini tree training scale. There are also some other solution that potentially can scale but it may not convince all stakeholders because it doesn't win the Nobel prize. How can you solve this dilemma? That's also a very important question to move forward. In general I think in Geni copyright we have very important non technical questions where the legal definitions may need to evolve with technical inputs. Also there are many important technical questions. Both of them require the policy and technical researchers to work closely to solve them.
00:15:33.989 - 00:16:06.745, Speaker A: I also welcome you all to join our future efforts at Google with our colleagues we are organizing the center for Generative AI Law and Policy Research. Well we have very decent security and also safety researchers. We have already augments an event at Washington D.C. with folks from the government and also from U.S. and UK Institute and also a lot of event at machine learning conferences. We may plan to roll out a few in this year and please keep an eye on that and you are welcome to have some input in this space. Thank.

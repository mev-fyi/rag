00:00:00.090 - 00:00:14.990, Speaker A: Everyone, thank you so much for coming. We're super excited to get started here, and I am going to have Sandeep come up here to kick us off. So, Sandeep.
00:00:21.650 - 00:01:20.018, Speaker B: Hello, everyone. So thanks, Will, for telling me two minutes before that I am introing the conference. So that's a lot for the confidence. So, guys, welcome to the decentralized AGI conference, one of its kind. And the core goal of this is, as all of us are hearing, a lot of hype around the AI, and we all know that the emergent risks of AI across the globe, that this can make some parties really powerful, some centralized parties really powerful. And when you think about it as a problem for the humanity, I also think that this is one of the biggest problems of our lifetimes and definitely want to spend time and resources into this. And you see, when you look at AI, AI is a big centralizing force.
00:01:20.018 - 00:02:11.400, Speaker B: And if you want to decentralize this power, crypto is the only technology in the world, right? So there needs to be more innovation, more attempts, resource money being thrown at it, to create these decentralized incentive structures which can allow these emergent AI companies projects, or even community projects where this power can be a little bit more decentralized. So that's the whole background behind this decentralized AGI conference. We expect this conference to happen in most of the big crypto conference places. So this is the first inaugural event, and it will happen across the board. This is also hosted by sentient AI. The sentient AI is basically.
00:02:13.530 - 00:02:13.958, Speaker A: It'S an.
00:02:13.964 - 00:03:07.842, Speaker B: AI company which wants to create open AI, or anthropic kind of user experience and user facing AI product, but with the power of crypto incentives in the background, so that you can use crypto incentives to catch up to the lead time or catch up to the lead that these centralized and closed AI companies have globally. So that's the core goal of sentient. And I would like to invite the founding team of sentient on board. And I also want to announce that I will also be joining them as a co founder in this endeavor. So let me invite Pramod Vishnath, Professor Pramod Vishnath. He's the professor of computer science at Princeton and also the co inventor of 4G. So pretty accomplished person in the scientific arena.
00:03:07.842 - 00:03:34.960, Speaker B: Then we have Himanshu. And Himanshu is like the professor of computer science at ISC Bangalore, which is India's premier scientific institute. And he also recently got the Young Scientist award from indian government. And then we have Kenzie Wang, who's also the co founder and pretty Og personality in the crypto space. So yeah, guys pramod over to you to say something for the people.
00:03:41.670 - 00:04:07.434, Speaker A: Thank you. I'm a plumber. I like to build pipes for the information age. And the first sort of plumbing I was involved in very closely was when I was doing my phd. And right after we did a startup and it became 4G. So then wireless networks, the Internet was there, wireless was phones and building networks that scaled to the world. And blockchains are similar eco spirit, with incentives built in.
00:04:07.434 - 00:04:58.890, Speaker A: They are networks that align economics and incentives with people and of course, information. And now you have the era of AI, which are agents, artificially and intelligent agents together with humans that are natively interacting with each other. The platform that can align, that allow interactions, a, in a permissionless way, anyone can come in, b, sovereign. That means once your actions are defined, it executes. And c, incentive driven way is the basis for testing, building, designing, inventing, artificial general intelligence will come out of these kind of interactions. And the platform that enables such interactions is just blockchains. You can give another name, but that's what blockchains are.
00:04:58.890 - 00:05:17.490, Speaker A: They allow any number of agents to interact in an incentive driven, composable sovereign way. So that's what we are trying to build at sovereign, an AI native network that has all the ethos of the principles of blockchains behind it, but entirely for AI.
00:05:21.750 - 00:05:43.542, Speaker B: I would also like to get will on the stage, who's the head of ecosystem. He's like Ethereum Og, and not many people know, but basically he's technically the co founder of e three search and works very closely with many heavyweights in the Ethereum ecosystem. So, will, if you could also say a few things about sentient.
00:05:43.686 - 00:06:16.840, Speaker A: Yeah, so super excited to get this kicked off. I think this is necessary. I think in the same way that we see finance needs to be decentralized, AI has a lot of the same core fundamental reasons. So, yeah, I've just been really excited to see this take off, support this effort, and get this moving. So super exciting. Yeah. All right, so I'll invite Sam Lehman up here to begin to kick things off.
00:06:16.840 - 00:06:35.670, Speaker A: Everybody. I'm going to be unseen, the summit today. My name is Sam Lehman. I'm a principal at some lock capital. Folks, if you're in the room in the back, feel free to come in. There's some spots in the front here. We're going to get straight into the sessions.
00:06:35.670 - 00:07:33.534, Speaker A: Right before we do that, though, I want to acknowledge everybody who helped make this inaugural decentralized AGI summit possible. First and foremost, to the host, sentient, huge. Thank you to the organizers, edge, symbolic, capital, Lightspeed, canonical, crypto, and to all of our sponsors, Jensen, Marlin, KXVC, Aura, Myshell, ritual, talis, hum, zero gravity, Nas, research and autonomous. Thank you all so much for your support. We could not have done this without you. Thank you. And then really quick, to all the individuals who were working like crazy over the past month to pull this off in a very short timeline era, Amber, Cameron, Will, Sachi, Anan, Kenzie, Andy, Darren, Jake, Erica, and Jerry, all of you are amazing.
00:07:33.534 - 00:08:09.130, Speaker A: We could not have done this without you. So thank you for all the work that went into this. All right, we're going to get right into things. So our first keynote today is titled from attention to decentralization, why AI needs web three. The keynote will be delivered by Ilya Palasican. He's a co founder of near. He also was previously an engineering manager at Google Research, where he co authored attention is all you need, generally seen as a fundamental research piece within this field of AI.
00:08:09.130 - 00:08:32.400, Speaker A: So I'd like to welcome to the stage now. Ilya, take it. Hello. Hello. Awesome to be here. I hope this is a good kickoff for your Denver endeavors. All right, thank you.
00:08:32.400 - 00:10:03.310, Speaker A: Cool. So, yeah, as was mentioned before, blockchain, for about ten years I was actually working on machine learning, deep learning, and worked at Google research, pretty much trying to advance state of the art, and we'll talk a little bit about it. And I think one of the important works of this generation in AI has been attention to only need, which a team of us have authored. So for those who are not familiar, the kind of language modeling is not a new problem. This is something that been kind of used for various functions since 1950s. It's a statistical method and it's kind of used in different natural language processing tools even before deep learning. Now, with introduction of this concept of embeddings, where the words are mapped into vectors, into numbers, is kind of made a leap because where before you had a very symbolic processing, where you needed to kind of have all the world's words and their mapping, kind of statistical mapping, be very fixed with pretty much transforming words into numbers, you are able to have kind of math applied to them, you're able to measure distances, you're able to project them, you're able to transform them.
00:10:03.310 - 00:10:44.982, Speaker A: And so that's been one of the kind of core innovation that started a lot of the modern natural language deep learning and kind of the parallel technology that have been existing for a while. As well, since 90s, called recurrent neural networks, was the way people used for language modeling. So back at Google, we actually had trained models that would answer questions, translate that were not transformers. The challenge we faced, though, they were very slow. They were kind of similar to how humans. We read one word at a time. And if you have large documents, if you have large kind of Internet pages or large text you want to translate, it's too slow.
00:10:44.982 - 00:12:10.310, Speaker A: At Google, you need to respond within a few hundred milliseconds. And the idea kind of of transformers the origin of it, is really trying to strip down and kind of change how we process language, to really paralyze it, to leverage the kind of computational architecture we have in gpus, to really have kind of low latency way of reading large amounts of text. And it's really pretty simple model. It maps words into vectors and then transforms them, and then uses this algorithm of attention where it pretty much tries to gather information from everywhere else in a document about what this word means in this context. And so, repeated few times, it actually captures a lot of the information that's in the document and is able to answer questions, it's able to translate them, it's able to do all of these functions we see. And it was really cool to see that this same algorithm, the same machinery, was then applied to images, to videos, to DNA, to all kinds of other methods, and kind of any type of sequence of spatial formation is able to transform like this. So, really exciting because of its kind of natural scalability.
00:12:10.310 - 00:13:28.122, Speaker A: We've seen explosion of kind of usage of this as models become bigger and bigger. Now, this kind of led to massive innovation in AI, right? We see probably every company is trying to put AI in somewhere in their kind of products. We have a lot of new startups that are kind of doing new use cases and trying to transform the way you interact with computers and with each other. There is the opposite of this, right? If before the computing was interpreted by the user, by the person, now we have a new way where computing itself can communicate with others. It means that the computers now can produce content, they can interact, they can make decisions, and it's not always clear if it was a human or computer that's behind it. And so that's one of the important parts to discuss when applied to web three. The other important part is what we see is a rise of this kind of companies, private companies that are offering AI models, AI use cases.
00:13:28.122 - 00:14:47.506, Speaker A: And the problem is that as any kind of company, you have a lot of different teams that are actually involved in how you make a product, you have a curation team that decides which data set goes into training the model. You have some legal team that is deciding that, oh, we cannot use this data because it's licensed under this or that license, or we got turndown request. They have an ethics team that a lot of companies now established that is deciding what's ethical and not, which is very, very subjective. So all of that is actually influencing at the data set step and at kind of system post processing step what really result you seeing. So instead of seeing what model actually has what data is telling it, it now is massively kind of influenced and biased based on all of these different people involved in the process. And to make it even scarier, I don't think anybody's doing it yet, but I expect this to happen very soon, is that you can have ads running directly when you kind of do inference in this model. So instead of seeing what model is telling you now, it's kind of for sale and highest bidder is able to influence the output.
00:14:47.506 - 00:15:15.346, Speaker A: Imagine you're asking like, which car should I buy for my use case? And instead of whatever statistically is better, whatever somebody paid more to output that car. This is totally possible. It's actually ads, marketplaces are way faster than the model inference. So it's actually very effective to do this right now. And so this is kind of the scary part for closed AI models. We also don't know what data goes there, right. There's a curation that happens.
00:15:15.346 - 00:15:57.520, Speaker A: But then there is another side of this, which is adversarial data kind of manipulation. Right? Right. Now, if you're, let's just say, an organization or government that wants to influence how people think in a year. The way to do this is to start seeding data into all of the public forums, pretty much with the text and opinions and decisions that will actually change how these models will be trained in one year when this data will be scraped. So we have kind of this like a very chicken and egg problem. And all of this is hidden from the user. You as a user, when you're typing into the prompt, you have no idea what's happening behind the scene and what fed to it.
00:15:57.520 - 00:16:50.974, Speaker A: So this is a case for open source AI. This is a case for having the models open source the data. It's trained on making sure you are able to run it yourself and making sure you have an ability to kind of inspect every step of the way. Now, obviously not everyone will do it, but as we learn with blockchain, having that ability makes sure that we get higher quality of product, make sure we have a competition and make sure we don't get kind know. Anybody will point out if something is not working. So we have lots of potential risks, right? We have risks around regulatory, right? Right now, there is a us regulatory kind of order around how much computation your model can have before you need to report it. Having a team, ethics team that will be deciding and safety team that will be deciding on things.
00:16:50.974 - 00:17:57.494, Speaker A: They are considering doing a dual use for AI technology, which would pretty much make it so you cannot export it to other countries, which makes no sense whatsoever. This is actually reminiscent of crypto in 90s, where cryptography was potentially considered dual use. And the way to disprove it was a person printed out an algorithm on his t shirt and crossed the border and pretty much argued that this is freedom of speech to actually disclose the algorithm and not funding exporting kind of dangerous technology. We obviously also have kind of the negative sides, right? Because these tools are so good and so easy to use now to generate kind of fake information and content. There's a potential for massive disinformation, massive sways and manipulation. And so it's really important to address that. And there is kind of this really strange trade off that we've seen where big companies have more and more resources to invest into building better models into more data.
00:17:57.494 - 00:18:41.010, Speaker A: And we have open source, which doesn't have access to compute, which doesn't have access to by data, and kind of at ods with this incentives. And so, again, this is where web three can be extremely helpful. So I'll just quickly cover. This is like a first version of AI stack using web three. It splits into three major categories. One is around data and kind of data curation, content, reputation, personal data. One is around infrastructure with inference training, provable training, foundation models, kind of on edge computing and retrieval, augmentation and applications, variety of applications, people building on top of this infrastructure.
00:18:41.010 - 00:19:35.934, Speaker A: So kind of one of the important dimensions, I think we talk a lot about decentralized AI. There's a lot of kind of talks about this, but there is kind of another dimension to this, which is, do you have a tool, or you have an autonomous agent or autonomous kind of system? And this dimension kind of defines also the requirements you need for infrastructure. So, specific example, right? We have centralized examples like Chat GPT, which is a tool, you use it, you interact with it, you tell it what to do. It's fully centralized. You have things like Agent GPT, which use Chat GPT behind the scene, but they are trying to kind of build a plan and execute on your behalf. Now, on the things like llama, they're not centralized or decentralized. It's just an open source software that can be used for different cases.
00:19:35.934 - 00:20:25.246, Speaker A: Right. And it's really extremely important to have such models. Now, the, I think, really important kind of aspects and why we've been doing edge intelligence is this idea of having models run on your device because it solves a lot of problems. You don't need to prove things because it runs, it can access all your private data, you don't leak any of the information and queries that you use to anyone. And so it actually allows to have private kind of intelligence tooling for yourself without really getting into any of the hard problems at the same time. Kind of the opposite of this is AI governance or doing on chain finances. This is where it is an autonomous agent that has a mission that continues trying to improve, refine, kind of follow its objective.
00:20:25.246 - 00:21:14.306, Speaker A: And this is where you do need probable inference. You need a lot of infrastructure to power that, and there's a lot of projects that are working on that. So just to mention, one of the kind of examples we've built for the hackathon that's going on is AI agent registry. It's the idea that you can have kind of what gpts for OpenAI is limited to. The OpenAI model have for any model, including your local models. It can be integrated into any of the front ends, it can be served locally, it can be served from the website, you can have a desktop app, and you can have kind of a variety of different inputs and show the different types of agents. So right now, I think people kind of use agent very freely for anything that has like AI in it.
00:21:14.306 - 00:21:58.194, Speaker A: And so I was trying to kind of structure a little bit the different types. And so one of the kind of types, like the differences between agents is how they specialized. Right. We either specialize it by giving it a prompt. So like what GPT has been doing, you kind of condition it with a system prompt, and then it responds in a very specific way. You can have a way to fine tune the model, giving it a specific training, examples, how to respond, maybe doing an LFH on it, and you can have additional information pretty much retrieved and augmented in the prompt from specific contexts. Now, a different dimension is what kind of output the model provides, right.
00:21:58.194 - 00:22:39.786, Speaker A: Right now, most of the output we see is text, which is not how we've been used to using computing. We're used to having an interface, we used to have reach UI with actions directly in there. And so one of the cool things in the registry I showed you before is you can specify how the output is shown. So you can have model condition to output JSon, which then feeds into a rich UI. And now you can have, instead of, for example, you're asking schedule me a flight, instead of having a bunch of wall of text, you can have a really nice UI with a plane flying and time and everything shown. And finally you can have action. You can have something that does direct action.
00:22:39.786 - 00:23:18.486, Speaker A: It's in the context of your blockchain account of your potentially web two accounts, so it can actually execute all that on your behalf. Finally, you have an autonomy. So I mentioned that dimension. It can be a tool that executes something. It can be something that you tell what to do, but it figures out how to do it, the plan and executes it. Or it can be a fully reinforced learning agent that continuously given a objective, for example, maximizing a specific KPI, is continuously trying to improve and trying different actions. So this is just kind of systematization I'm starting to use for the agent types.
00:23:18.486 - 00:24:26.294, Speaker A: And obviously it's not final, and we'll continue expanding that. So I mentioned that we'll see a lot of kind of content that is produced by AI that will be misleading, confusing, manipulative. And so one of the really important pieces is actually having a layer of content reputation. And we have cryptography, we have the tools to actually enable that. And so one of this kind of asks for the hackathon as well, is actually starting to build out this network where we can actually verify, when you're looking at an image and a video and even pieces of text, who published them, where the origin is. And potentially you can have community notes and kind of community curated feedback. If this is misinformation, the simplest example actually I was talking with a journalist and they mentioned that the misinformation for them is actually not about AI, it's actually somebody taking, modifying the HTML page of the publication, taking a screenshot and publishing on Twitter.
00:24:26.294 - 00:25:09.982, Speaker A: And they got a ton of shit for whatever was published because people thought it was real simple things like that. Is that right now the information you see you kind of automatically attribute to whatever you see. You don't actually question the source of where it's published. And so having additional layer that hey, this image actually is fake. And here's community node and you can go to origin and see if it's not correct. And being that surface directly when you're browsing Internet, when you're on social media is extremely important. So another use case is kind of, I think that we will see a transformation of how we're using and applications, and how applications are built in general.
00:25:09.982 - 00:26:18.866, Speaker A: And this is really kind of why actually I got into AI early on, is I wanted to automate software engineering because I believe the way we right now interact with computing is very much fixed, kind of in early days, how we program computers, but with natural language interfaces, we're able to actually define what we want, what we expect, the intent, and we have computers to actually generate us the UI and the experience we want. And so I think we'll see a transformation of this happening. This is example from a Jutsu, an IDE in near ecosystem that already offers generative uis and generating front ends for developers to kind of really accelerate your development speed. But you can go beyond that and see how you can just generate applications for you full end to end and use it. And you will have custom applications for your use cases, and you'll use them even as non developer. Finally, there's a really interesting space of intelligent assets, right? We started with programmable money, programmable assets. That's what blockchain enabled.
00:26:18.866 - 00:27:10.440, Speaker A: It enabled a new kind of property of ownership, but you still need to write code, and this code is a strict set of rules that this assets follow. The intelligent assets now can behave kind of based on natural language input, based on kind of inputs from outside of the blockchain itself. Now I'll caveat it, and it's a huge caveat. The current models, the current llms are not designed for adversarial environment, right? When we design smart contracts, we design them that somebody will try to break in and steal all the money. And so we will need. And there is research happening on how do we strengthen llms to be able to work in such an environment where potentially the inputs given are trying to kind of steal the funds. And it's really important for governance later as well.
00:27:10.440 - 00:28:31.706, Speaker A: So kind of up leveling that you can have the agent itself to run a business, you can have something that is autonomously trying to optimize for the business KPIs, and making decisions on what projects to do, who to hire and what work to do. And there is kind of a very specific, like a zoomed in version of that, which is a kind of gigs work marketplace where you can have work posted almost like an order book and ais, and people can pick that work and do it and have kind of embedded verification loop. So the blockchain really facilitates this unification where right now you either go and use the tool, or you post it on some freelance website and there's a person come in and start doing things. This really can unify this, because now you don't really care who you're on the other side if the quality of work is well. And so this will actually be transforming as well, how the work is done broadly in the ecosystem. And finally, kind of the final piece of this is governance. Right? With governance, we have a very kind of fundamental problem when we elect people to kind of be representatives.
00:28:31.706 - 00:29:14.098, Speaker A: These people always have their own interests. It doesn't matter how kind of. And so this is called principal agent problem, where the agents we select as principals have their own interests and they're not always aligned with us. And the fundamental way to address that is to actually have the agent to be AI agent that does not have personal interests. It follows the kind of the algorithms or rules and is fully auditable. And you know what as the inputs and outputs are. And so the idea is you can have a reinforcement learning agent that's continuously trying to maximize the KPIs of whatever you're governing.
00:29:14.098 - 00:29:50.098, Speaker A: It can be a dow, it can be a protocol, it can be a layer one. It can be a city in the country. And it's trying to model the system, the world that it interacts with to understand what are the best actions it should take to improve, to maximize kind of the function. Now, that's a long term project. It requires more robust llms, it requires better world modeling, which we see evolving as well. But it's really interesting because this is fundamentally for this to be useful and trusted. It cannot be run by a centralized company.
00:29:50.098 - 00:30:30.114, Speaker A: Nobody will trust an OpenAI running governance for, let's say, uniswap. But if you have provable inference, if you have open source models, if you have all the systems running, you're able to actually transition to community stakeholders to be kind of overseeing an AI model that makes decisions. And so the bold vision is we can have an AI president. And again, it can be on different levels of the governance. It can be as small as president of a DAO and as big as president of the country. So I just want to finish on a kind of important note. The AI is a set of tools.
00:30:30.114 - 00:31:13.122, Speaker A: It's instruments. They're very powerful, they advancing really quick. But they have this fundamental issue. And in general, the open source has a fundamental issue right now that it's kind of more and more controlled by big companies, which as web three, we're kind of trying to disrupt and create more ownership in the community. And so the benefit here, we can create incentives, we can create systems that are really promoting open source, that are benefiting people who are actually building useful things and contributing them back and have this platform that available to everyone. Intelligence, especially. The more and more the intelligence is becoming powerful, should be available to everyone.
00:31:13.122 - 00:33:02.234, Speaker A: It should not be kind of limited to companies that are deciding what we can access and what decisions it can make for us. So I just urge everyone kind of to think in this way to really contribute to the space and, yeah, I'm excited to see how we can altogether build a more open source AI. It what? Microphones moderator with wireless. Yeah, like, it'll be run under. Do we want to run this? Well, I would use the other two. Okay. Are we only using in on three and four? So are they sharing or do you want to use all three additions? So all four mics, there's four people on stage.
00:33:02.234 - 00:33:04.026, Speaker A: One is a wireless. What do you want the other?
00:33:04.068 - 00:33:08.740, Speaker C: Wireless. And then share.
00:33:09.830 - 00:36:33.396, Speaker A: Okay, got. It's all. Yeah, pretty much, yeah. But, yeah, it's cool. Yeah. All right. Hello, everybody.
00:36:33.396 - 00:37:04.750, Speaker A: We're going to get into the next panel. This panel is titled the Evolution to Agi. We'll be welcoming back Ilya onto this panel. We will also have Pramod Vispanath. He is part of sentient witness chain and also a professor at Princeton University. And we'll also be joined by Sri Ram Khannan, who is a CEO and co founder of Eigen Layer. Come on stage, please.
00:37:04.750 - 00:37:42.504, Speaker A: All right, so before we actually get started, I wanted to get a bit of a temp check in the room here. So this panel is about Agi, and if you'd humor me, raise your hand if you are optimistic about a future in which Agi is achieved. So the optimist out there. Okay, lower your hands. I see where you are here. Raise your hand if you're pessimistic about that future. The brave soul over there.
00:37:42.504 - 00:38:08.732, Speaker A: A couple more. Okay. So it's a pretty friendly room. That's helpful for us. Those who pessimistic came to destroy it here. All right, so, Ilya, I want to start with you. Did you know what you were doing, what you were unlocking when you published the transformer paper? I mean, definitely not at this scale.
00:38:08.732 - 00:39:04.244, Speaker A: Right. I think as you're working in research and you have kind of day to day improvements, it doesn't feel like major breakthroughs because it always is very incremental. But the basis of this is we were using very basic models, like bag of words models to run stuff in production, because you cannot run a recurring neural networks in production. It's too slow. And then the attention was another mechanism, and a team that Jakov was leading, another co author, was using attention for query similarity. And then we're like, well, why don't we use attention and words and use it know sequence generation? And it's like, well, it's a crazy idea, but let's try it. And so obviously there's a ton of work went into actually getting into state of the art, getting it to scale, all of this.
00:39:04.244 - 00:40:12.330, Speaker A: And obviously OpenAI did an amazing work at scaling it up and showcasing what it can do. So I would say it's kind of a lot of incremental work know compounded into a fundamental change. Right? But as AI researcher, you always actually wish for this thing. And I remember even before transformers, we were discussing kind of use cases that some of the models we were doing, we had language models that can read text, and we actually had even kind of our own Wikipedia that was fully generated out of a language model. Obviously not at the quality that's right now. But I was like, can we publish it back to Wikipedia? And the legal department said no, but this is kind of things we were thinking about, like, oh, it would be really cool to have the question answering model directly in your browser that knows every page you're visiting and stuff like this. So I think kind of the wish and vision is always there in AI space, and it's more that we're continuously trying to improve the tools to get us to what we think is possible.
00:40:12.330 - 00:40:43.856, Speaker A: And so on that point, I think it'd be helpful for the rest of the conversation to get a little more specific with what we're talking about when we say Agi. So promote, what does Agi mean to you? Can you sort of put some constraints around it? Yeah. Thanks, Sam. I mean, Sam started by asking, who's optimistic and pessimistic? Can you hear me? I think it's good to first define Agi. And people have intuitive definitions. They think they mean common sense. They would think that it's self replicating.
00:40:43.856 - 00:41:07.608, Speaker A: It can replicate itself. It can start spawn off other agents, spawn off other intelligences. They're all sort of heuristics, and they're reasonable. I mean, they're one ways to do some kind of litmus tests on what AGI is, but to get a feel for. So here's sort of a definition that I have that helps me think about what AGI is. It's a union of intelligences. So GI is a union of intelligences.
00:41:07.608 - 00:41:52.932, Speaker A: But it's more than that. It has to self replicate. And where does this intelligence come? And evolution already has an answer, which is that that's the birth of GI itself without the AGI part. And that requires putting some basic building blocks, hydrogen, carbon, oxygen, under an incentive mechanism. And then you get life and it evolves. And evolution is that process which leads to general intelligence. And if you follow this logic, the equivalent for AGI, at least there's a definition that comes out, which is you need to have intelligent agents, intelligences that interact under short term.
00:41:52.932 - 00:42:30.400, Speaker A: So some incentives, quickly, I get a meal, I make some money, my wallet gets up, airdrops. And evolutionary pressures, these are longer term. You succeed and you have future generations. Both these pressures you put together. But these intelligence should interact in a free way, just like an evolution. And this free, composable and free means sovereign, like, you put in the execution, you put in the DNA, and then in this case, a contract, it just executes. This platform is crucial to have AGI to be born.
00:42:30.400 - 00:43:06.876, Speaker A: And you already see it in the sort of the latest AI models coming out. Sora was already built out of some forms of simulating worlds, and even GPT four had some feedback with human feedback to improve alignment. So you already see that AI itself needs some interaction and getting the feedback to improve itself. And AGI is just the summation of all such intelligent agents interacting. Well, what platform allows that internally? Big web, two companies, AI giants. Try it out. But you want the entire summation of intelligence to interact.
00:43:06.876 - 00:43:32.760, Speaker A: Well, there is already a platform for that. It's called blockchains. We don't think of it in this way, but blockchain is that platform where agents can interact incentive driven, sovereign way. So it's like blockchains are a necessary condition to bring out AGi. So that's how I define Agi. Fantastic. A lot of what you said was very optimistic and exciting.
00:43:32.760 - 00:44:28.780, Speaker A: Sriram, I don't know if you were an optimist or a pessimist, but could you talk a little bit about some of the challenges or the risks that you see with achieving Agi? And what role, if any, does blockchain play in addressing those risks? Yeah, I'm neither an optimist nor a pessimist. Vitalik wrote this post with two forks in the road. So you have the two forks. One fork could lead to dystopia, the fork could lead to some semi utopia. And I think it's always like that. We have always choice and discretion and ability to influence the outcomes so either an optimist or a pessimist means you already kind of assume the outcome. But I think we have to actually act to get the outcomes that we want and deserve.
00:44:28.780 - 00:45:36.508, Speaker A: So the question is, what are the kind of bad outcomes that could happen with AgI? So the first thing is one way promote defined AGI as a sovereign entity. What do we mean by sovereign? One of the most fundamental lens to think about it is, is darwinian evolution operational? What is darwinian evolution? You have an entity. That entity can create further entities, which can then create further entities and be subject to a selection pressure, some fitness pressure from the environment. So this is darwinian evolution. And how do we see darwinian evolution in AGI? You have to imagine a far out world with robotics and other stuff, self assembly, creating new robots out of materials, all of this stuff. But the proximal way, that's a distal. The proximal way in which we are going to get this is sovereign digital AGI.
00:45:36.508 - 00:46:05.556, Speaker A: What is sovereign digital AGI? It is purely existing in the digital space. It doesn't have any physical manifestation. It exists in the digital space. Where does it exist? It exists in the cloud. It exists as software, but software which holds a wallet. Crypto wallet holds a wallet, uses the wallet to go pay for its stuff, compute. Several people here building decentralized compute for ais.
00:46:05.556 - 00:46:44.800, Speaker A: Sovereign aji going to come in and pay for itself, training itself and improve itself and earn more. Darwinian evolution started. Right? It's very important that this can happen only in crypto because crypto has censorship, resistance and permissionlessness built in. There's no account access control. You can't distinguish whether a human's accessing or an AGI is accessing either for opening a wallet or for opening a compute connection. All of it on equal footing. Okay, so that's the definition of AGI.
00:46:44.800 - 00:47:18.380, Speaker A: And the proximal way this is going to happen in two to three years. My bet, we are going to have sovereign digital ais, which have some amount of survival advantage. They farm for ad drops, they figure out arbitrage opportunities. They do all the things we do just a bit better, and they're going to have survival advantage. Okay, maybe they figure out how to hack your computer and then earn tokens immutably. Right. Blockchains.
00:47:18.380 - 00:47:49.244, Speaker A: Immutable. So Aga has a bitcoin. Aga has a bitcoin. What are you going to do about it? We're going to have to start thinking about, know people, think about international sanctions. We're going to need AGI sanctions. How do you sanction an AGI which is going rogue, hacking everybody's computer? What do you do about it? So there are all these problems. Now we are talking about a fork in the road.
00:47:49.244 - 00:48:49.550, Speaker A: So I must have some alternatives here. Otherwise, this is not good. The high level thing is, when we are looking at this kind of. This is proximal, right? This is sovereign digital AGI, not physical AGI, which requires robotics and self application and maybe at least 30 years out. Okay? When we're talking about sovereign digital Agi, what sets of things can we do? How do we build better coordination mechanisms for us to express our preferences into these systems? For example, I just mentioned sanctions against traditional agi. How do we express these? Already we are facing this in a non AGI manner. In crypto, for example, we see somebody's contract get hacked, and we sit around hopelessly that, oh, my God, they lost the 300 million.
00:48:49.550 - 00:49:53.604, Speaker A: Not being able to do anything when all of us know it's a hack, it's not an intended consequence of the blockchain. Blockchains don't have enough expressivity for us to coordinate around the outcomes that we want. How do we get there? So I'm just placing questions, not giving answers, but important questions to make sure that when we build sovereign Agi, you have all these things taken care of. Of course, even more proximal than a sovereign digital AGI is a corporate AGI, which is, how do we ensure that AGI is not controlled by a couple of corporations? How do we ensure that? The optimist answer to this is the following. If you look at the history of innovation, we see that innovation is not individual centric. Innovation is evolutionary. So if we can build a framework for permissionless innovation, where innovation can cascade one on top of the other, I build something, you can build something on top.
00:49:53.604 - 00:50:34.268, Speaker A: Somebody else can build something on top. While all the people who are building things are incentivized, we can actually get really, really high rates of innovation, which can beat the corporate rate of innovation. A single company doing stuff on their own. So how do you build incentive mechanisms where people can come and innovate together? That's the important question. How do you build systems where we can express complex conditions of coordination? That's what we as a blockchain community need to do to enable the optimistic side of Agi. Ilya, I saw you smiling a bit during that. I wanted to give you a chance to respond if you have any thoughts.
00:50:34.268 - 00:51:38.934, Speaker A: Well, I think maybe high level point. I would say that as a humanity, we don't actually want a fully sovereign Agi running around taking our airdrops. What we want is a tool that is either personal or a community that expresses our interest, that is working on our behalf, that is contributing to our well being and success and whatever. The kind of, even for the example you used with sovereign AGI, the reality is actually it's not sovereign. It relies on the governance of the underlying blockchain that it's running on. And if actually we have AI running, for example, on bitcoin, and we really all decide that we don't want that, the community can actually censor it and disable it and do whatever. So there is a governance framework for community to interface with that.
00:51:38.934 - 00:52:32.054, Speaker A: It's not very expressive right now. We should make it more expressive. But I think the main important point, I think, for me is that what we want is an agent that represents us and acts on our behalf. Again, be personal or community, or organization or country, or whatever the group of people is, and represent their interests and act on their best kind of interest and optimize that. I think maybe just kind of stepping back, the kind of definition that people in AI space use around AGI is really about that. It's actually better if you find a best person at any particular skill or act, it is better than. So, compared to the artificial narrow intelligence, which is it's better at specific type of thing.
00:52:32.054 - 00:54:10.818, Speaker A: And this we know, like AI being good at or better than a human at different things over time. And we just kind of see this explosion of spaces where AI is now better at that really closing the gap across different dimensions. And again, that definition is really very utilitarian. It's not like, hey, we want a sentient being that is like we want to talk to and find feelings. It's more like, hey, we want a tool that is actually doing stuff we want, but better at scale instead of us. And that's really, I think in some way, AI is like a mirroring representation of humanity, right? And that interests. And I think, to me, the evolutionary part here is really about humanity kind of becoming one with this AI tools, right? And like augmenting intelligence and becoming more individually and globally more intelligent and more sophisticated, more kind of advanced because of those tools, and because of the way we kind of start interacting with this computing and web three in this sense, is a tool to facilitate this, to kind of create this communication and for communities to define what is the interest they are and kind of provide feedback and give ability to execute on behalf of this, with wallets, with kind of deploying resources and at the same time to create incentives for this permissionless innovation, which I totally agree is probably the most important to kind of contract, kind of close the AI evolution, which in my talk I was talking about, right, is very dangerous, has a lot of downsides.
00:54:10.818 - 00:55:24.314, Speaker A: And we see past week kind of showed a lot of issues, just like with, I think the fundamental point to understand there, there's no good answer, there's no way to have like. Because data is always biased, there's always bias in the data. It's either to whatever majority is, or they try to fix it and unbiase it. And now it's even across minorities, and now there's a different problem, right? There's always going to be a problem. And so you kind of need to move away from that, like a single party controlling the decision making and allow people to have kind of full control and then through that be able to communicate that. So anyway, I think that's where Web three is really becoming a powerful tool to facilitate that. I want to respond, and this can be for the group with maybe a provocative question, but are there any pros to centralization in achieving AGI and then maybe controlling it, putting guardrails around it, is a potential upside to having a centralized authority be able to avoid a diffusion of responsibility if something gets out there that is not all that positive.
00:55:24.314 - 00:57:04.570, Speaker A: Or perhaps maybe centralization would allow for better interpretability of models, given that there might be one authority that knows what went into it. Is there any upside to centralization? Yeah, I think there are many upsides to centralization. Centralization is clearly much more efficient than decentralization. And one of the places where this kind of an argument shows up is whether we should have models beyond a certain size be regulated or be open. I think there is a little bit of a false dichotomy here in the one sense that when you have closed models, one of the risks that safety people, for example, worry about is can the model go out and do something which can be destructive to the larger humanity? And I think open models already are come prepared or with some protection. The protection is, imagine you're going to go into a battle with an enemy, but you know the enemy's entire game plan. You're going to battle and you have this enemy and you have cracked their codes, you know their cryptography, you know exactly what each person is thinking, and you have to go battle with this enemy.
00:57:04.570 - 00:57:48.800, Speaker A: It's infinitely easier when you have an open source model. When you have an open source AI, it's much more, much easier when you know what the open source AI is in order to go contract it. Okay. But what could be dangerous is closed source AI, which is unregulated. Okay, so I have, like I said, the fork in the road kind of a viewpoint. What might be a really good barbell regulation is models beyond a certain size have to be either regulated or be open source. You can't have a large, unregulated closed source model.
00:57:48.800 - 00:58:41.870, Speaker A: That might be a much more interesting policy position than saying either one is actually good. So, again, careful, measured, cautiously optimistic, and promote. The last question here. Is the blockchain industry ready for AGI? Where are the gaps? What needs to be done to handle an AGI that these other folks seem pretty optimistic about being achieved? Oh, heavens no. I mean, I don't think many of us are what I call Gen C. My kid is Gen Z, but this is gen C generation crypto. We can all, and no, we can all agree that the industry is nowhere near anywhere mature.
00:58:41.870 - 00:59:30.986, Speaker A: Where are the opportunities then? I was thinking about where centralization helps and where decentralization helps. I'll give an example that's also related to the other question you had about Ilya, was talking about toxicity and how it's very hard to have one party do be the arbiter of everything. One of the grand challenges of AI, there are three of them in my mind. But one of the grand challenges of AI is to be effective, a good chatbot, yet be robust, that is non toxic. And they're very different things, and trying to do them both together is really a grand challenge. In AI, I gave an example of the chatbot, but this is just true of all of AI, how to be effective, efficient, and be robust. And the trouble, it's hard is because they're quite distinct.
00:59:30.986 - 00:59:52.162, Speaker A: And the chatbot example makes it very clear. The centralized approach is particularly good for building an effective bot. The data is already there. You churn in capitalistic invention brings in all the capital and everything together. The efficiency kicks in, and you really do. An effective chatbot. But alignment or nontoxicity is something different.
00:59:52.162 - 01:00:31.630, Speaker A: It's something that community agrees. You need very many people to agree, and that's inherently the strength of decentralization. So one of the things we were thinking when I was thinking of sentient itself is this kind of a decoupling to come in naturally. There are places where centralization makes a lot of sense, just efficiency, but you decouple where decentralization helps. And toxicity is something that should be community owned. It's a societal, cultural, societal, civilizational, aspect and efficiency is simply where capitalism is so good at to getting at. I feel like decentralization and centralization have both have roles in this ecosystem.
01:00:31.630 - 01:01:19.566, Speaker A: And having AI native proof systems, crypto systems that tie them all through some byzantine resistance and appropriate incentive alignment is really the challenge associated with such a platform. Last word to Ilya. Yeah. There's few dimensions where there's opportunity. I think the creating incentives around open source that indeed allow people to build on top of each other and kind of have capture some value from what they created. Because one of the challenges right now in AI, there's a lot of people who actually want to build open source software. There's a lot of builders who actually, if they had access to resources, would build really interesting stuff.
01:01:19.566 - 01:02:04.126, Speaker A: But if you're building open source, you're not capturing any value, right? You're not making any revenue. And so if you start a company, you're kind of in this perpetual search for a business model and you're probably spending more time doing that than actually building stuff. Right. And so interestingly, crypto kind of has a solution. I mean, it's not like fully worked out, but we have tools for that. And so I think that's the biggest, probably opportunity to really bring. How do we bring incentives? How do we reward people who are actually contributing value to the open source? While there will be companies, commercial companies that are centralized, that are benefiting from that open source, they should be kind of paying back for this.
01:02:04.126 - 01:02:48.026, Speaker A: And so I think that model is really interesting and something that I'm exploring, I think the flip side of this is the provable inference and kind of related stuff is like as we want these models to be more robust, more provable, there is obviously a lot of companies working on that, but that's probably a biggest gap. Like the current ZKML, for example, is nowhere near the capacity that we need for even the model I can run on my laptop. Right. And so there is a kind of a trade off there that needs to be closed and kind of figured out both on crypto and hardware on multiple sites. And that is an opportunity. That's why there's so many companies doing that. And finally, I think we just need to start putting applications that are actually interesting.
01:02:48.026 - 01:07:34.026, Speaker A: I think there's a lot of talk earlier today for the hackathon. I was actually giving a bunch of specific examples. What you can do now with the current tech, you don't need to wait for proval inference with the current tech, with the current that you can build that are interesting, that useful that benefit people, that allows them to use local models, kind of all of the species, like, just like, hey, let's do useful stuff now to prove out, to showcase, to let people see how those things actually start to work together. I think that's all the time we have for this panel. We'll be back in a few minutes with a fireside conversation between two leading founders in the industry. Thanks, everybody. Can I get up out here until.
01:07:34.048 - 01:07:34.586, Speaker B: I call you up?
01:07:34.608 - 01:08:03.490, Speaker A: Okay. All right, everybody, we are going to get our next panel started. We are fortunate to have a one on one discussion between Sandeep Nywal, the co founder of Polygon, and Juan Benette, the co founder of Protocol Labs. Please welcome Tindeef and Juan.
01:08:07.990 - 01:08:11.480, Speaker C: You gotta let them know when you're ready to go up, otherwise they're not.
01:08:15.210 - 01:08:16.280, Speaker B: Hello again.
01:08:16.650 - 01:08:17.062, Speaker A: Hello.
01:08:17.116 - 01:09:03.758, Speaker B: Hello again, guys. So I have with me dear friend Juan, founder of Protocol Labs, as you know, Filecoin, and I'm a big fan of his work. When I was just getting started, he was a legend at that time itself. So it's always great to have conversations with him and get his perspective on various things. So this conversation is more focused around AI and we don't even have a set agenda for this. We would love to take audience questions on this. Maybe we can start with audience questions if anybody has any specific question, or we can start with general intro.
01:09:03.758 - 01:09:04.374, Speaker B: Anybody?
01:09:04.492 - 01:09:30.630, Speaker A: Cool? There was some question back there. And by the way, honor to be here. Always very excited to talk about lots of things together. We want to make sure to talk about the things that are top of mind for you. Both of us have thought a lot about different things in AI and the centralized AI and the potential, but we want to make the conversation really valuable and interesting to you. So let's get some questions out. So I think there a question back there, can't hear you, so you got to be louder.
01:09:30.630 - 01:10:41.810, Speaker A: So the question is, our work in compute over data, how much overlap is there with the centralized AI? Yeah. So running an AI model is a type of computation. So if you're structuring a way to do all kinds of computation, an AI model and running an AI model is like one class of that kind of computation. And in fact, most of the compute over data networks that are being built right now are going after AI models because that's what's extremely valuable and hot right now. So, yeah, it's like perfect overlap. More questions? Yeah, back here one way doesn't know what else. Can we keep the questions AI focused? Because that way is there like an AI side to that's.
01:10:41.810 - 01:11:31.206, Speaker A: So you're saying, does the model not know what it's computing? So a model to be able to run and operate on something has to compute on a set of data that you're going to give it. So as it's computing on, it's going to find out what it's doing. The thing that can't know, right? So what you're getting at is the hardware itself or the VM that's running the model doesn't know. And so I guess what you're saying is like, hey, could we create a privacy oriented AI cloud where you can have models that are fully private, where you can develop either the model or the data that you're going to compute on with full privacy? And there are two techniques to do this, like zero knowledge and fully homophobic encryption. Both techniques can work. They have different trade offs. There's a project around ZKML that you can check out.
01:11:31.206 - 01:11:42.858, Speaker A: And what I'm personally really excited about is fhe. I think there are fhe ML structures. Zama is a company that's going after this. So both of those are pretty interesting. I don't know if you want to.
01:11:42.864 - 01:13:01.442, Speaker B: Add like Zama is one company, Inco is another company who's working on Fhe. And only problem with Fhe and zero knowledge cryptography on that is right now, the efficiency wise, it's extremely computer intensive and AI itself is computer intensive. And it's super hard right now to have what your original question was that how can you have some sort of this? What you are saying is private computation over, let's say, server, where server itself doesn't know what it's going to compute and things like that. I think one easier way in the earlier days or in the near future that people are going to use it is people are going to use tes. A lot like trusted environments where you actually put, let's say a base model, especially, let's say some of these design patterns. That, for example, sentient team is also exploring that, where you put a base model into a TE, and then after that you train the model inside the TE, so nobody knows the new weights of the model, right. So the new model is completely getting trained inside the TE, and the inferences are also being kind of thrown after the queries are being thrown after the TE model.
01:13:01.442 - 01:13:41.458, Speaker B: So that is one near future model where people are going to do that a lot. But in the long run, I really loved what Jeff Bezos recently said, that these models are more than inventions. They are discoveries so we are also thinking of multiple ways where you can train. But again, this is a slightly different model loyalty where you want, let's say there is a community owned model and you want that model to be loyal to the community. That means unless the community has permissioned the model to, let's say, provide inferences or take training data, it doesn't take it.
01:13:41.544 - 01:13:41.938, Speaker A: Right?
01:13:42.024 - 01:14:03.938, Speaker B: So there are multiple ways, like fhe and ZK for doing that, but other ways. What if somebody comes up with an interesting training technique where all the neural nodes of the model itself are loyal to that particular thing? So that is an interesting way, like what sentient team is working towards, and I think that's a very interesting area to explore.
01:14:04.034 - 01:14:58.682, Speaker A: Yeah. I personally think that the highest value thing that can come out of crypto and AI together is a much stronger governance framework on top of running AI models. So this is where you can figure out the provenance of the models themselves, what data they were trained on, what are they likely to do, and where you can add controls over what the inference requests could be. If we can do that, well, then we can build pretty scalable ways of having much safer models out in the wild, because when we're talking about, we're at an event called decentralized, I think it's Agi, right? Like, first off, man, I can't think of few ways of making the AGI problem more scary than making it decentralized. That just greatly amplifies all of the things that could possibly go wrong. And so it's. Okay, well, what is the bright optimistic case here of how do we orient this towards good outcomes? Well, okay, great.
01:14:58.682 - 01:15:54.250, Speaker A: We have this rule machine, this governance structure machine. Can we use it to then orient the models to achieve good outcomes? And so that looks like figuring out what data it was trained on, what algorithms are being run, whether the alignment type protocols that you're running on top are actually working. You can trace the individual inference, you can inspect the outputs. If we can do that really well, then maybe we have something to offer to actually make the problem better. But otherwise we're just going to make things look dramatically worse. And so be careful and to spell it out, because I see some people that are like laughing, like, oh, yeah, shit, that's potentially really bad. But I also see some people like, what do you mean? How could it possibly be worse? Well, look, when you have an extremely capable model that you can ask to do Agi to define it, it means that the model should be able to do anything that a human can do.
01:15:54.250 - 01:16:41.270, Speaker A: That's knowledge work, it should be able to think through and reason anything that a human can do. Now, imagine you take a human as capable, the smartest person that you can think of, put them, virtualize them in the computer, give them unlimited resources, and then just let them unfettered on the Internet. That is potentially really good or potentially really bad. It has many ways where that could produce very bad outcomes for the world. And so if we create lots of compute clusters around the world that we have zero oversight into, we decentralize the AGI capable compute clusters, and then we let thousands of people, to millions of people, try whatever they want on them. That's a great way of getting disasters to happen. That's like a super, super easy way of just causing all kinds of havoc.
01:16:41.270 - 01:17:00.498, Speaker A: So now, how can we use our truth machines, our verifiable computing machines, to instead aim away from those really bad outcomes and go towards the really good outcomes? I think provenance is a really good way. I think control over the actual models is potentially a good way. But other than that, I don't see that there's that much.
01:17:00.584 - 01:18:04.466, Speaker B: No, I totally agree with you that for the last whole one year, I've seen so many pitches from the AI startups, which are like, many of them are simply crypto token startups, and they are just trying to sprinkle some AI on it because there's hype. But many of them also come to you and want to have this decentralized model. Because we come from the background of Ethereum, where there is one vm, which is run by multiple parties in the environment, and many people are trying to think that, okay, we'll have a decentralized environment where this model is running in some sort of coordinated way. And one is, you are saying the philosophically, it can be super bad for the world. The other way is, I'm simply thinking, because we saw this world from 2017, when you're trying to scale the blockchain, we can't do simple value transfers scalably in decentralized networks yet. Like, nobody has figured out.
01:18:04.488 - 01:18:05.830, Speaker A: We're finally getting there. Yeah.
01:18:05.900 - 01:18:32.506, Speaker B: And the only way now people are getting that with layer twos and all that is doing it in a trustless way that's not decentralized. And that's my whole point. The trustless phenomena is actually much bigger than the decentralized phenomena. Like, if you see the ZK rollups, optimistic rollups and all that, what they are doing there is a single sequencer, and wherever you need, like decentralized, like, okay, so we started with the background of BTC.
01:18:32.538 - 01:18:32.734, Speaker A: Right.
01:18:32.772 - 01:18:46.046, Speaker B: This whole industry started with the background of BTC, and it was very important to have decentralized network so that you can have three key properties. One is trustless compute, then self ownership, and then third one is censorship resistance.
01:18:46.078 - 01:18:46.466, Speaker A: Right.
01:18:46.568 - 01:19:07.026, Speaker B: But now with this, especially ZK, you can actually achieve, and an optimistic role is also you can actually achieve the first two, like trustless compute and self ownership, self custody of your assets without decentralization. So you then kind of like, I started thinking that actually it was never about decentralization that much except BTC.
01:19:07.138 - 01:19:37.714, Speaker A: That's what a lot of us meant by decentralization. Like the verifiability piece is the most important part. It's like you want to make sure that the computation itself is verifiable against what you expected the computation to be. Exactly right. So you're getting the right outputs. I sometimes talk about it in terms of like, read, write, verify. So that's like the benefit that you get out of decentralization is either availability of more nodes being online, but really verifiability that the thing is going to do what you expect it to.
01:19:37.714 - 01:19:38.194, Speaker A: Yeah.
01:19:38.312 - 01:19:52.902, Speaker B: So the interesting thing I wanted to bring back, because I went into that different arc of history of this decentralization versus trustlessness, is that in this context, when we say decentralized AgI, what we are saying is decentralized in terms of.
01:19:53.036 - 01:19:56.678, Speaker A: Who verifiable, who kind of trains it.
01:19:56.764 - 01:21:05.354, Speaker B: Because right now, let's say you have open ais of the world who are training it, and then they fully, who controls it. These two part, if you are able to decentralize these two parts and separate these two parts from the actual execution of the model itself, like what is happening with the ZK and all that, right? So you have kind of solved scalability trilemma in some form where you just, in some form, I'm just saying that where you removed security and decentralization from the scale part of it. Like you compute at an extremely fast pace. And in the background, you know that there's a proof that's going to come and it's going to be verified on the main layer. So with the AI also, the attempt that we are trying to do and sentient team is trying to do is that decentralize the training, like verifiable, as you said, like very feeble training. Like if you have a model M one and there is a data D one, and if you train this model with this data D one, what comes out is M two, can you prove that? What comes M two? And the second thing, these are the two scientific problems that we are focusing on, is that one is the model, the provenance training provenance. Second is model loyalty.
01:21:05.354 - 01:21:35.714, Speaker B: What if you could create a model which is just like, think of it like a Navy Seal soldier. Let's say United States trains it. Even if somebody else captures the soldier and they try to get the secrets out of him, he will not give. Can we do that? Same with the model brain, it's like neurons itself, right? How can you train the model in a way where the model never responds, even if you download it and you're running it on your computer? You ask him a reference. Ask the model a reference. It doesn't respond to you unless you have the explicit permission of the network.
01:21:35.762 - 01:22:03.722, Speaker A: I think there's going to be easy ways to, or like performant ways of achieving that with the current training methods. But the real solution to that long term is verifiable fhe. If you have verifiable fhe, then you can build a large scale model that parties observing the data cannot understand what the computation actually is. But that of course has a problem of massive orders of magnitude of slowdown.
01:22:03.786 - 01:22:08.386, Speaker B: Like fhe is basically at least three to five years of work. We need learn fhe right for that.
01:22:08.408 - 01:22:16.054, Speaker A: Right. But the good news here is exponentials get really fast over time. So you just wait a few more years until these techniques can fully agree.
01:22:16.092 - 01:22:17.334, Speaker B: We have one person who has a question.
01:22:17.372 - 01:22:17.960, Speaker A: Yeah.
01:22:28.750 - 01:22:32.460, Speaker B: You mean specific to the AI or like in blockchains in general?
01:22:34.430 - 01:22:35.030, Speaker A: AI.
01:22:35.110 - 01:22:38.640, Speaker B: Okay, like OPML versus ZKMl. That's the question.
01:22:41.010 - 01:23:19.834, Speaker A: Look, my sense you can use optimistic approaches to run in high performance for things that where you want to just run a lot of computation. So for example, gen AI use cases seem like a decent use for this. Well, maybe, maybe so. What I would push to harder verifiability settings is areas where you really care about the outputs being correct. If you're trying to get a few images, you're trying to sample a large space. The acceptance criteria is actually quite broad. Lots of different data points are good enough.
01:23:19.834 - 01:24:08.854, Speaker A: But if you're trying to decide whether you're sick with something, you're trying to get a diagnosis and a recommendation for treatment that needs to be correct. Right. Or if you're going to let a model pilot vehicle of some kind, that should be correct. And so when correctness really matters, that's when you want to go all the way to strong verifiability properties. I think both ZK and verifiable fhe are good enough technologies and they'll continue to get better, that you can do some scoped problems in them. And with time, all problems, eventually it just is a matter of when you want to run it. If you want to run it tomorrow, you cannot use verifiable fhe.
01:24:08.854 - 01:24:13.514, Speaker A: It's just way too slow. But if you want to run it ten years from now. Yes. Yeah.
01:24:13.552 - 01:24:41.486, Speaker B: And with ZK also, what people are working on is originally people wanted to fully verify the full compute of the model. Now people are saying, can you just verify one or few branches into the execution of a query and things like that. But for me, this provenance of here, the provenance is actually that X model that was committed, that this model is providing the inference. That's the exact model which is providing the inference.
01:24:41.518 - 01:24:41.858, Speaker A: Right.
01:24:41.944 - 01:24:48.214, Speaker B: And for me, I somehow fail to see, and if anybody has more use cases which can actually acquire a lot.
01:24:48.252 - 01:24:48.840, Speaker A: Of.
01:24:50.570 - 01:24:53.446, Speaker B: Which can accrue a lot of business value, let me know also, but.
01:24:53.468 - 01:25:11.494, Speaker A: Otherwise, let me push back on that. So I think it is very critical that if I'm going to start trusting an AI agent to do things on my behalf, I want to know that that's correct and that as these things get smarter and smarter and smarter, they aren't getting misaligned from my intention and starting to do something other than what.
01:25:11.552 - 01:25:20.302, Speaker B: Asking, yeah, but isn't that like it's actually more of a question of correctness as you are saying, than of provenance? Like let's say I'm using.
01:25:20.356 - 01:25:26.530, Speaker A: Yeah, so it's a provenance so that you can try and approximate correctness. But correctness is what we care about.
01:25:26.600 - 01:25:52.134, Speaker B: Yeah, but for simple provenance, I was seeing, I only see this maybe defi security use cases for provenance. And probably if you want to use AI models for governance, then you want to be like, okay, this is the model that governance approved and this is the model which is talking about. But apart from these two core use cases, I've not seen maybe deep fake like you want to on chain.
01:25:52.262 - 01:26:17.668, Speaker A: Yeah. You may also want to trace who is training models to do what, who is invoking models to do what kind of thing. You may want to log that over time and that becomes a really valuable kind of community or anything. Think you had a question. Yeah, you had a question. So goodbye. Yeah.
01:26:17.668 - 01:26:39.712, Speaker A: So the question is, can you use the decentralized compute platforms to do both training and inference or just one of those? Both. You can model both structures in this decentralized network. It's just that training is dramatically more expensive than inference. So that's a harder problem. But you can do it with both. And there are networks, computer over data, networks that are trying to do both.
01:26:39.766 - 01:26:51.768, Speaker B: Who just arrived here. This is Daniel Lubarov, one of the co founders at Polygon. In my mind, like the best of the best brains in the ZK in crypto, like, Daniel, thanks for coming.
01:26:51.934 - 01:26:54.490, Speaker A: But, yeah, go ahead, go ahead. You were saying?
01:27:07.180 - 01:27:08.570, Speaker B: Did you catch the question?
01:27:12.380 - 01:28:18.278, Speaker A: So what was the first part of the question? So you're asking what are the kinds of risks that come from crypto? So the question is like, hey, can we be more concrete on what are the risks that crypto introduces to the AI question? Because a lot of people have been writing a lot about the risks that come from smart and smarter models. What happens when you enable them to have access to blockchains? Well, think about it this way. If you have a cryptocurrency is a resource that you can spend for compute, right? So you can create an agent that has an account on a blockchain, that can pay for its own resources and then can start doing other things to try and cause its own balance to increase. That's creating not just like an artificial intelligence, that's creating an artificial life form that now has a way of growing and potentially replicating and so on. Right. That gets really hairy really fast. You could have llms.
01:28:18.278 - 01:28:40.222, Speaker A: I wonder if somebody's doing this right now, this would be really bad. You could probably have llms today being trying to optimize for how do they increase the amount of money in a wallet with just an email address trying to spam all kinds of people to do who knows what. That's like, extremely dangerous type of behavior. This is how you get like optimized.
01:28:40.286 - 01:28:43.778, Speaker B: I know one person who is doing it, but for defi strategies, not the.
01:28:43.944 - 01:29:16.410, Speaker A: This is like very dangerous stuff. My sense is today we have the tech to do some pretty bad things, and it's kind of like we're kind of on borrowed time in terms of the people that know a lot of them about the models and the people that know a lot about crypto. The intersection has been really small. Events like this are bringing that intersection together. So right here we're increasing the risk. So hopefully all of you are aiming towards good outcomes and don't do really bad things accidentally. So yeah, focus on how do you produce good, really good use cases for these models.
01:29:16.410 - 01:29:36.980, Speaker A: And be careful about what models you deploy and how you give them access to random capabilities like email, like optimizing for a certain blockchain for a certain amount of money on a wallet. That's a recipe for something really bad going on. Definitely do not try genetic algorithms with these kinds of stuff. Please don't do that.
01:29:37.770 - 01:30:41.942, Speaker B: That's why, like I said, as crypto community overall, we all should optimize for, or we should all put more resources on making sure that these powerful AI models, which assumingly in this open world can be trained by the communities and will be more available because all the models that are made available open source by these large companies, like the actual fine tuned models they use for their own stuff, right. They will never put it out because there's like competitive mode in the longer run. So in my mind, community trained models over the long enough time are going to be the most powerful. And so the problem that I want to put my focus on, that the most powerful, powerful community trained models should be not like decentralized, as in they are running in a decentralized compute environment, but they are controlled by the community. Like if community says, let's say this kind of inference is toxic, or this kind of queries are toxic, do not respond to this. And the model is loyal.
01:30:42.006 - 01:31:36.682, Speaker A: Exactly. And that's what I think the provenance of not just the model, but the actual invocations, like the inference that you're requesting, is really key. And I think good governance frameworks for this could be really valuable. An optimistic type of project. Try doing it today. Grab a community that cares about having some AI assistance, get a foundation model and create some loose structure around invoking its operations, but have a little bit of a check as to whether or not that inference request is broadly aligned with the goals of the community. And this would be a good, interesting test case where you'll be forced to actually implement something that is useful for somebody, for some group, and you'll grapple with how hard it is to answer that question, whether the prompt is going to be in the best interests of the community or not.
01:31:36.682 - 01:32:27.650, Speaker A: And that's where a lot of these questions hinge on. If we can figure out good ways of doing this, we'll be in good outcome. I think we're wrapping up, so maybe last question. Okay, so the question is, what do we think about multiparty computation as another approach? Yeah, we would probably classify it just like with ZK and fhe. It's another technique that gives you the same set of outputs. You can use optimistic computation, you can use MPC, you can use ZK, you can use fhe to broadly compute whatever program you want, and it has different characteristics in terms of the topology of the network, the verifiability that you get out of it, the privacy that you get out of it, and so on.
01:32:27.720 - 01:32:36.760, Speaker B: And you end up, you don't really fully solve the centralization problem because those MPC parties can simply get on a telegram group and do what they want.
01:32:37.130 - 01:32:38.614, Speaker A: I think he really wanted to ask a question.
01:32:38.652 - 01:32:39.478, Speaker B: Yes, please go ahead.
01:32:39.484 - 01:32:40.360, Speaker A: Please go ahead.
01:32:46.080 - 01:32:46.830, Speaker C: Found.
01:32:52.540 - 01:33:28.948, Speaker A: What do we think about whether more of the value will come from small models versus large models? Well, our brain is pretty large and in about a million years we kind of took over the planet. And so large models are going to be really where the extremely valuable outcomes will be. So sure, small models will be able to do all kinds of small tasks in the meantime and be very economically significant. But in terms of really species or civilization scale improvement, large models is where it's at.
01:33:29.034 - 01:34:17.664, Speaker B: Yeah, I have a different, obviously larger language models going to be really powerful, but also what promote sometimes from sentient. He always mentions that all of these models provide some level of intelligence, but various different kind of models, some will be very good at maths, some would be very good at, let's say, medical stuff. These are all human brains and a combination of them, with better routing and coordination of them can actually convert this I intelligence into GI general intelligence. So I think in that context I can see in future some kind of combination of few models together where some of them are small language models which are doing some great work in terms of what they can do, and there are like combination of llms and mathematical models and whatever, and they are working together to do something.
01:34:17.782 - 01:37:31.720, Speaker A: Yeah. All right, well, thank you very much. And do good things, avoid bad things. Thanks, everyone. Thank you. So that's fine. All right, everybody, we are going to roll into our next panel.
01:37:31.720 - 01:38:17.960, Speaker A: The next panel is titled Blockchain's role in AI advancement. We'll be joined by Sandeep, again, DC builder, who is a research engineer at the World Coin Foundation, Se Wango, who is a professor at the University of Washington and a research scientist at Google. We have Robert Drost, who is a director at Eigen Layer. And this panel will be moderated by Will vill Nueva from sentient. Come on stage, everybody. Hello. Testing.
01:38:17.960 - 01:39:11.070, Speaker A: I think he said he wanted you to share. Cool. Thank you for joining the panel today. I think this group is very interesting. We have a good mix of builders, academia, people that have traditionally been in blockchain and have also a wider background. So thank you for joining us. I'll go ahead and just start off with, let's go ahead and have each of you introduce yourself and just say, what brings you to this summit? Why AI and blockchain? What gets you here? You guys have mics? Yeah.
01:39:12.080 - 01:40:06.750, Speaker B: As I said that, for me, the AI alignment problem, its alignment with humanity is one of the biggest problems of our lifetimes, probably the biggest problems of all of humanity in terms of man made problems, maybe just shorter of the nuclear bomb. Basically, if we allow this to go run a mock and it is not aligned with the humanity, it can really result into bad outcomes. So, yeah, that is one problem where I am very passionate about. And as we all know, that AI is like a big centralizing force, and crypto is the only technology which can bring in trustlessness and decentralization. So on a high level, it makes total sense that these two technologies should come together and create something interesting.
01:40:08.240 - 01:40:54.348, Speaker A: Hello. Hello. So, I'm a research engineer at the World Confoundation, and some of the problems that I've been mostly recently been interested in are within the intersection of crypto and AI. I created the ZKML community, essentially the zero knowledge machine learning community. Like, how do you make machine learning models provable? And currently I'm really excited or interested in how do you design digital identity protocols that are privacy preserving and have all these properties of decentralization and permissionlessness that we are used to in terms of crypto and monetary decentralization. So, yeah, essentially AI and provable AI is one of the core building pieces within this sort of paradigm of how do you build privacy preserving digital identity protocols? And that's sort of like what I'm currently interested. Yep, right.
01:40:54.348 - 01:41:53.340, Speaker A: Hi, I'm with the Allen School of Computer Science and Engineering at the University of Washington, and I work at the intersection of privacy and decentralized machine learning. And one of the things I got interested these days is when these AI agents start to interact with each other, what are the risks that we have for the ais that will be amplified once we start putting them in the wild, talking to each other? So I believe that blockchains and crypto are the essential tools to make transparent, resilient, and robust machine learning. And I'm here to learn. All right, thank you. Yeah, really happy to be on the stage with everybody. It's a great group. So, for myself, my name is Robert, and I previously was at consensus heading up a bunch of R D that was going on there.
01:41:53.340 - 01:42:56.932, Speaker A: And I'm currently at Eigenlayer, joined that just recently. So just motivation for me on this, literally, AI and the potential problems with AI was what motivated me in 2017 to get into the blockchain space. It was incredibly exciting to me that blockchain would actually be able to solve these huge problems that I'd been worried about for 1015 years around where technology was heading and the sort of mental way. And what was so motivating that I think for a lot of us here is crypto sort of started off as this thing to recognize that while capitalism is very powerful, it's also a lion that will devour us all. And so blockchain is kind of a cage that you put around capitalism. And I think AI is the same camp AI run amok. It's this ferocious animal that is not controlled in the current system.
01:42:56.932 - 01:44:22.720, Speaker A: And blockchain literally has the ability to put it under our use rather than having it consume us. That's really awesome. Thanks for those answers. So, first question I'm actually going to bring to you, Sewong, and currently anyone from the panel, feel free to add color to this. But currently it seems that within academia and within the AI industry as a whole, there is stark skepticism of blockchain in particular, that blockchain has any meaningful benefit to AI. Why is that? And what do your colleagues and students generally think? Okay, so I think the skepticism looks bigger than it actually is in the sense that if you talk to any of them one on one, they're more excited than skeptical. But as a group together, I think there is a bit of worry about the negative societal effects of blockchain, for example, like all the perhaps financial risks that some people are taking, all the carbon dioxide that's being created for all the compute.
01:44:22.720 - 01:45:38.600, Speaker A: And I think they're catching up in the sense that they're sensing that the blockchain is here to stay. It's going to have huge impact on humanity and there's no way around it. So more good places, good universities are trying to hire the best experts in blockchain. I see that all the time in the call for faculty positions, just that you can see why it will be hard to lure an expert in blockchain to academia for many reasons. So I think it goes both ways. In the sense that perhaps academia is not ready for blockchain yet, but they are open. They're not ready in the sense that, for example, if you're going to run a lab doing blockchain, trying to get a funding from federal agencies for your group is going to be very challenging, as equally challenging as getting funding for your vcs, because those agencies answer to Congress and the taxpayers.
01:45:38.600 - 01:46:13.620, Speaker A: And the other way also, I think the blockchain, I don't think, needs academia at this point. Not necessarily. Maybe going down the line, perhaps it'll build more community. But there are amazing people who are at the intersection of academia and blockchain, who's just excelling in what they do, who's probably somewhere in this room. So I think it's just a matter of time they will see more conversions. Got it? Yes. Thank you.
01:46:13.620 - 01:46:17.012, Speaker A: Thanks for answering that. Your question.
01:46:17.066 - 01:46:24.624, Speaker B: Originally was skepticism in the academia only or in general, you are saying, like in the governments and everywhere, like skepticism.
01:46:24.672 - 01:46:32.920, Speaker A: Or blockchains more in academia. But I'm interested in the government side, too, actually. I think that's really what your thought is.
01:46:33.070 - 01:46:56.000, Speaker B: Because my experience has been that governments are very pro blockchain, but they are anti crypto. There are two kind of different. Like they are anti against this financial over financialization of the economies and over globalization of their economies. That's where they are more skeptical against. But I think blockchains generally, I have found governments to be very interesting.
01:46:56.070 - 01:47:53.460, Speaker A: They're pretty generally open to it. Yeah, I was just going to comment that it's such a big difference on government side that financial crypto is something that takes control away from their federal central banking systems and other things in the AI blockchain space. It literally gives them power back, because right now corporations are exerting this stronger control. And with decentralization, they have the hope to be able to put in regulation and then be able to do things that are nation appropriate. Because people's view on AI is pretty different. If you go to a country in one part of the world versus another, as it should be, DC builder, you've done work with Worldcoin, which obviously has been playing a strong role in the discussion of AI. Human identity, separating human identity.
01:47:53.460 - 01:49:15.016, Speaker A: You've done significant work, as you're talking about around ZKML. You all sort of innovated on that, I believe. First, as a team in the space, can you dive a bit into the discussions internally of how you see the current integration with blockchain and identity pushes AI forward? Like, why it's necessary? Why is what you're doing absolutely necessary for the advancement of AI? So essentially, like the intersections of blockchain AI and how we are pushing forward that intersection, correct? Yeah. And in particular, how that connects to the identity discussion that you ultimately are in our use, we leverage AI, for example, in the biometrics side of things, where we leverage biometrics to essentially create this uniqueness vector or uniqueness measurements. That's called an iris code. This iris code is used to check whether a person is unique, because you're checking an iris code of a given user against the set of all the other existing iris codes of every single person. And thanks to that, and then using cryptography, we're able to essentially take the public key of the given user that was just verified, and we're able to create a proof that a given user owns a private key to a public key in the set of verified users.
01:49:15.016 - 01:50:11.244, Speaker A: So that's sort of like where we are leveraging cryptography as well as AI. Like, the intersection is the thing that allows us builds a better and more robust digital identity ecosystem in the sense that we're now able to prove personhood in a way that's privacy preserving. Right. We're leveraging cryptography so that users are able to prove that they're unique users and that they're not doing actions more than once. There's this property called civil resistance, meaning that protocols now are able to build systems in which they can gatekeep actions for only unique humans, and the unique humans cannot do the actions more than once. Let's say, like, if you have a voting protocol now you're able to build a unique voting protocol on chain where you can request that a given proposal can only be voted on by a given user only once, which is something that, in the digital ecosystem was not been able to done before. And we've implemented lots of these proof of stake type protocols before in the past.
01:50:11.244 - 01:50:54.270, Speaker A: We have proof of stake protocols that allow us to put some economic security, and thanks to that economic security, we make it civil, resistant, because the resource that is hard to come by is economic value. But that then leaves away all the regular people. So it sort of also acts as a gatekeeping mechanism for the average person, the average user. So that's sort of like sort of what we're trying to build, right? Do you support higher taxation for AI than human identities or different legal boundaries between the two? Anyone can answer this, but yeah, I think I don't have the expertise to answer anything in that specific domain, but I'm feel free, anyone, to answer that.
01:50:55.760 - 01:50:57.230, Speaker B: Can you repeat the question?
01:50:58.320 - 01:51:15.990, Speaker A: So in this world where now we can separate human identity from AI identity, right, do we see higher taxation for AI as they own crypto wallets or different safeguards sort of put in place between the two entities recognized as different?
01:51:18.360 - 01:51:42.444, Speaker B: I'm not sure. I think those AI models will be deployed by some human being only. So they are nothing more than workers deployed by some human being. So, at the end, you are not talking about the taxation of that model itself. You are talking about the taxation of the entity or the human being who's using them. So I'm not sure whether there should be a differential treatment on that. Not sure if somebody has.
01:51:42.482 - 01:52:37.180, Speaker A: Yeah, I think you're 100% right that while ais are acting as kind of agents for a person, then they're attached to that person's identity, and they can go through the normal kind of tax structures. Kind of like if you own a house or you own assets, then you have to pay taxes on rent, or if you're a shareholder at a business. I think the really juicy part of your question, though, is some people will deploy autonomous ais and they'll just release all of the value of them just to be owned or go into some other mechanism that doesn't go back to them. And then the question comes into, how do we actually manage that in terms of taxation? And is it even valid that somebody's able to claim any portion of that? On the other hand, if we don't do any claim, then ais become economically more powerful than humans.
01:52:38.640 - 01:52:48.320, Speaker B: God forbid someday some AI comes and says, hey, I need a different treatment because I'm not owned by any human being. And I think then we have other problems to solve at that point.
01:52:48.390 - 01:53:47.008, Speaker A: I think that'll be a very interesting time for sure. I have a question for you. Can I double back to one comment on the identity one, of course. Builder. I just wanted to say, I mean, I don't know if it's too simplistic, but I like to try to drive home this point, which is a lot of people focus on this ownership side, read, write, own, that kind of thing. But you can't really own data without having ownership of an identity, because what would ownership mean? And one of the most important components of data, apart from anything that we're going to go off and sell and use as like, kind of a capital intangible asset, that kind of data is reputation, and that's probably the most important thing that a person can own. And so identity is this key cornerstone.
01:53:47.008 - 01:54:25.728, Speaker A: We didn't see it early in crypto, because, like DC was saying early on in crypto, at the first generation, if you own the tokens, nobody needed to know anything about you. You own the tokens. They're fungible. But when we get to the point of data sets, and when we get to the point of, do you trust somebody because it's non collateralized or there's some harm that you wouldn't be able to go back and get retribution in the way that you can on a fully collateralized Ave loan or something. Then that's when identity becomes such an essential cornerstone. So it's great worldcoin is having success. We need a lot more building in the identity space.
01:54:25.728 - 01:54:50.650, Speaker A: We're totally under prepared for the need. Yeah, yeah. That space is so interesting. For sure. Sandeep, a question for you. So you've been known as a prominent builder in this space, in this industry. There's been a lot of use cases that have been built in the polygon ecosystem and more.
01:54:50.650 - 01:55:17.632, Speaker A: But I guess a question here is when we think we can go all day and talk about use cases for smart contracts or applications on chain, but on the other side, what blockchains can do for AI, I think has been even more interesting to you recently, and I'm curious to hear about that.
01:55:17.686 - 01:56:02.700, Speaker B: Yeah, I mean, contrary to what everybody, a lot of people who I see, they are trying to use AI on chain, like on chain inferences to do things. I am not a very big believer of that. I don't see many use cases of on chain AI. Basically, maybe in the defi safety and security you can have it where somebody does a transaction and AI checks in the mem pool itself. And if something is wrong, AI flips a switch in the smart contract. But then on layer twos, you could do a transactions at like 400 millisecond, 250 millisecond. I don't think that's enough time for AI to flip the switches over there.
01:56:02.700 - 01:57:08.596, Speaker B: So then you can have some sort of design patterns where somebody, instead of doing a defi transaction, they do an intent on the chain that, okay, I want to take a loan of XYZ or something, and then an AI checks that this transaction actually goes through without a hack or something, and then does the other part of the transaction. And then maybe one use case is like, it has been discussed that using AI as Dow agents, but apart from these and something with this deep fakes where you can post these videos and you can have a trusted kind of AI governed by a community saying that this is fake or this is not. These are few use cases which I see. But beyond that, I don't see many use cases of on chain AI. Like AI is interacting on chain is a different game. Like AI as a separate agent with its own address, identity, whatever it is, and doing on chain transactions, that's going to be plenty. But I don't think for on chain provenance and on chain AI, on chain inference is going to have a large market, at least.
01:57:08.596 - 01:58:17.080, Speaker B: I don't see it right now, but I do see a big place for blockchains in kind of building AI. Let me say it this way, in terms of building or training AI in a more trustless manner, where community or a group of people can decide that this data gets to train this model with this data only, and ensures that there is no toxic data, there is no biased and all those things, this kind of stuff. And basically also having crypto incentive models somehow where communities can come together, because otherwise these large AI companies. I think there is a common saying now that if you are building a foundational model, if you don't have less than a billion dollars in funding, it's kind of a non starter. So there's no way more and more startups will catch up to this. And only way that some of these community based systems can catch up to this is open source and crypto incentives. So I think their blockchain can be used very heavily, and that's an area where I'm super interested in.
01:58:17.230 - 01:59:41.140, Speaker A: That's really cool. DC builder, do you have anything to add to that, or your own perspectives on that as well? I think what Sandeep has said is mostly right, in the sense that crypto is not necessarily AI, is not necessarily an agent that's active within blockchains, or there's not that many things that you can yet do where you have AI interactivity within blockchains. Some people, for example, use AI to set parameters in defi protocols, right? Like if you have a risk model, an AI model is able to update risk parameters based on some random forest model or some exploration or optimization problems, essentially, where AI is a better fit. But I've not seen AI agents as well, personally, where I do think, just to emphasize the sentiment that Sandeep has expressed, crypto is useful to help build these AI systems in a more open way. You're able to make the AI systems accountable. You're able to create proofs that someone created, or someone ran a model on some data and produced an output, right? I can create the entire execution proof that, okay, I have some input x, I put in some model m, I have output y, I can create the entire proof of that. And any user consuming that model can have the entire provenance proof and trace that they indeed ran some foundational model and some data that they actually gave the API or whatever, and also just to build the systems themselves.
01:59:41.140 - 02:00:27.510, Speaker A: Right? Like I can create an incentive network where I can, for example, help people train models or I can, for example, make it so that I incentivize people to provide compute, so that I can incentivize people to give me their hardware. And I can create a marketplace for either hardware or models so that you can coordinate people in a more efficient way, as opposed to traditional legacy systems, which are a lot harder to coordinate because everything is legal based, everything is contract based. If I make it permissionless, then that's sort of where crypto is really a lot more useful. So I think those directionally are the ones that make more sense. Currently, though, I'm free to be surprised in the coming years by the things that people here and elsewhere build. Got it. Thank you.
02:00:27.510 - 02:01:54.092, Speaker A: Yeah, go for Robert. I just want to dovetail one comment on top of both people, but especially Sandeep, what you said on the open side, that I think a superpower that blockchain can help add to AI is on the open source side. Blockchain and the value chains of blockchain allow there to be a global network effect across all open source AI. And we don't see that in the web two world because there's no reason for an OpenAI and a Google to share their network effects. They may kind of partially have that, but in the blockchain space, assuming we've got things worked out by Worldcoin and others on identity, reputation, data sets being portable, owned by people, models also being something that you can port around different parts of the system, you get this combined network effect, which has the ability to surpass anything a single corporation can do with walled gardens of data and identity capture. Robert, what about from the hardware side? By the way, thoughts on just how blockchain can bring benefit to that from an AI's perspective? I mean, blockchain doesn't particularly. You can't say that blockchain is going to cause the hardware side to have fundamental improvements.
02:01:54.092 - 02:02:56.180, Speaker A: Hardware is what hardware is. We saw in the really dramatic shift from private data centers to public cloud, because sharing resources unlocked a lot of capabilities that didn't exist before. It kind of collapsed back from being a whole bunch of oss with proprietary hardware to being three oss, Amazon Web Services, Azure and Google Cloud. And those all became capturing their API and they became hardware walled gardens. We're seeing now with AI, that AI, everybody's building their own data set. You'll hear it at stability and OpenAI and Google building their own chips, building their own hardware. And we're kind of going back to the 90s where it's inefficient from a hardware space because you have all of these different systems which are not able to kind of fungibly move around as needed.
02:02:56.180 - 02:03:42.560, Speaker A: Less elastic innovation slows down. So I think decentralized physical infrastructure, Deepin, has the ability to get us back to this very fluid hardware market and a much faster feature velocity than we're getting into now. So I think that's where the effect will be. What do you think, Seiwong, regarding that and the whole deep end thing in general? I'd actually love to hear your thought. Right. I guess the cost structure of these gpus is such that if you're going to build 100 billion size models, then you couldn't do it on a cloud. You'll be making other people a lot of money.
02:03:42.560 - 02:04:14.764, Speaker A: So you're doing in house with your hardware. So I think there are a lot of things that needs to happen before the price is going down. The model, perhaps size is going down, maybe, and a lot of different steps, milestones that need to happen for deepen to be, I guess, a viable option. Got it? Got it. Yeah, that makes a lot of sense. I guess that brings me to my next question. Anyone can answer this, and generally something that I've been interested to ask people.
02:04:14.764 - 02:04:56.490, Speaker A: So Andre Karpathi of mean tweeted about the importance of decentralizing. Also, Elon Musk agreed with that tweet. If you all remember this, Mark Zuckerberg has been discussing pushing towards making AI more open source as a whole. Do you all think as an industry we're able to even compete if their focus is suddenly pushed towards decentralization as sort of a societal push? Sorry, anyone can answer that. I got too excited there.
02:05:02.540 - 02:05:08.250, Speaker B: I actually lost track of your question and I went into my own thought process.
02:05:10.620 - 02:05:24.588, Speaker A: How can we compete in the blockchain industry if Mark Zuckerberg or OpenAI ends up realizing they have to decentralize to be accepted societally, the laws force them.
02:05:24.594 - 02:05:58.810, Speaker B: To do it, but if they do that, then they become part of blockchain industry. Then we don't need to compete with them, we need to work with them. Then the whole point is that they don't want to do, many of them don't want to do. I think Mark Zuckerberg wants to do is will be one of the best things to happen for blockchain industry. If Mark Zuckerberg or Elon Musk actually picks up either some team building in the space or their own division to kind of explore this part, that will be a big thumbs up for the whole blockchain industry. So I think that's good.
02:05:59.420 - 02:13:19.100, Speaker A: Cool. Awesome. I think this wraps up the time in the panel. Thank you so much for joining us and, yeah, thanks, everyone. You, everybody. We are going to get into our next panel. The next panel is titled A Builder's roadmap to decentralized AI.
02:13:19.100 - 02:13:53.050, Speaker A: Joining us will be Carton Wong. He's the co founder of Aura. Michael Heinrich, he is the co founder and CEO of Zero Gravity Labs. Sean Ren, he is a professor at the University of Southern California and the co founder of Sahara. And we have Alex Rusnak, who is the co founder of Maru. This panel will be moderated by Kenzie Wang, who is the co founder and general partner at Symbolic Capital and obviously now involved with sentient. Over to you guys.
02:13:53.050 - 02:14:42.244, Speaker A: All right, guys. Yo, how are you today? All right, cool. Let's get started. So let's begin with a round of intro here. So why don't we just go in this way and have you guys introduce your background? And also, what are you guys building first? So let's start with you. Hi, everyone, I'm Alex. I'm a co founder of Maru Network.
02:14:42.244 - 02:15:18.128, Speaker A: What we are is a big data composability layer for EVM networks. And today we provide a full big data, big compute of functionality over Mapreduce for evms. Awesome. Hi, everyone, I'm Michael. I am the founder of Zero G and we're the first modular AI chain. We're starting with a infinitely scalable programmable da layer and we'll definitely chat more about that. Hi, everyone, I'm Carton.
02:15:18.128 - 02:15:50.764, Speaker A: I'm the co founder of Aura. We enable any AI and any computation on any blockchain. Hey, everyone, I'm Shannon. I'm the CEO of Sahara and also an associate professor at USC. Sahara is building a decentralized network for everyone to freely and securely deploy their autonomous AI with high performance privacy and provenance. Super excited to have you all here. Each of you represent a different piece of this AI blockchain movement.
02:15:50.764 - 02:16:45.500, Speaker A: So I want to start by asking some questions about this web three and also web two side of integrations first. So let's start with you, Alex. The first question is, how do you see this blockchain? AI can actually synergize. So what are some ways that you can see that this actually makes your existing use case better? So when it comes to the AI, a few things matter. Data and verifiability of the answers. Now, when it comes to data, what you have to prove is that the data that goes into the model itself is validated. Now, the best sources of data such as blockchains need to be taken data and aggregated off chain and proven that every single interaction that happened within the block is validated.
02:16:45.500 - 02:17:51.292, Speaker A: And this is basically where Maru comes in. Like we support today, the biggest data sets available when it comes to inference, approvable inference, is this is where you can run LLM models and know for a fact that this is the type of the model that has been used. Now, this is applicable for certain emission critical use cases, which basically going to be around financial advertising, advising, and basically something that has to do with the money movement, in my opinion. And then the further on, once we have validated data, once we have the ability to interface with this data, now we can have an unlock where real creativity comes forward, where you have llms interfacing with smart contracts, and this is basically where we're going. What about you, Michael? Sure. Our mission is to make AI a public good. So some of my professors said that potentially in two generations, we don't have to work for a living anymore.
02:17:51.292 - 02:19:01.116, Speaker A: And that would be a super cool world to be a part of. What if an AI agent runs administrative systems, transportation systems, logistics systems, like production systems? I would love to see a world like that where human beings can be totally free to have whatever creativity they want, do whatever they want in life, and it's a choice. But how do we even get there? How do we align AI interests so that they're for the best of humanity? And so blockchain and AI fundamentally have to come together from that perspective, because in a centralized world, especially if you have AgI, a hypersmart AI agent can figure out a way how to cheat a database and probably crack into it and then erase its tracks so that nobody even knows that it's cheating. That's very difficult in a blockchain context. And so in order for that world to happen, how do we start? We even need to make on chain AI a possibility right now. You can't even do model training in a decentralized fashion. You can do some inference, you can do some fine tuning, but even that is comparatively significantly slower than on the centralized world.
02:19:01.116 - 02:20:11.650, Speaker A: So how do we get to parity? And that's really what we're thinking about. Not only do we provide things like decentralized data storage, so you can actually store a model on chain very inexpensively, but then how do you serve a bunch of inference traces when you have millions of users doing an inference request at the same time? No blockchain can handle that at this point. Need a very large data pipeline, for example. I talked with a project called many fold AI, and they want to do decentralized training of models. And they were talking about a data pipeline of 50 to 100gb/second the best alternative DA solutions today are doing ten megabytes per second. How do you get to 50gb/second that's really what we're solving. And so we've built a whole system around starting with a decentralized storage system and then adding a hyperfast consensus layer to get to a per node speed, about ten megabytes per second, and then scaling up that consensus network so that it's horizontally scalable to get to 50gb/second so that these high performance applications like onchain AI or on chain gaming or high frequency DFI are actually possible.
02:20:11.650 - 02:21:06.512, Speaker A: Carlton, next one's for you. I know you came from a web two Google background. What are some challenges? Also benefits that you see by integrating web three technologies into your aura project. And also how do you see that these web three tech stack actually benefit? Yeah, so when I work in Google, the apartment I work is called trusted compute. So pretty much you try to use some sort of polynomial to prove that you are honest on some certain computation. But in back then, nobody thinks this tab will be possible to use on AI because AI was even not that big back then. So I think crypto do play a really important role here to let human understand or can analyze what AI actually doing, why they have this resell.
02:21:06.512 - 02:22:09.924, Speaker A: What's the logic? What's the reasoning behind that? In aura, we enable any AI model for any blockchain, because we want to see which blockchain will be the best perform one for AI model in the AI times crypto era. And so we have some product just launched called on chain AI, Oracle, that already enabled llama, stable diffusion, mistro and all this large model for blockchain. So we are looking for developers that can use this on chain AI really well now. And there's many new opportunities coming out because from the last crypto cycle, we see that Dow is such great invention, but the biggest problem is lack of efficiency. So because people are lazy, right? So if you don't have that kind of really strong incentive buying mechanism, even you do. The Dow normally cannot maintain really well because fundamentally what happening behind a Dow is like order is the entropy there. It just increased by nature.
02:22:09.924 - 02:22:59.320, Speaker A: So with the time increase, people just lose management for the DAO. So now if we introduce the AI agent there to help us manage Dao, many things will become possible. Now, for example, if you use AI to manage the Dow for compound. Then you'll be able to add more token asset because the AI agent can just have the streaming data from the blockchain twenty four seven. And then you'll be able to have this AI agent to manage this data flow and then do a compute what token is supposed to be collateralized and all kind of thing will be possible now. So in aura, we focus on more like how on chain AI agent will be able to empower assistant smart contract, DFI, NFT and all kind of things that we play with in the crypto space. What do you think, Sean? Great question.
02:22:59.320 - 02:24:13.728, Speaker A: So been working at AI for over 15 years. I think there are three things I'm really excited about. Number one, the economy. Number two, ownership. And number three is the security. And I will start with the economy, which is, I think is sort of the fundamental issue here for centralized AI. So if you're looking at how sort of the current traditional AI industry and community be building AI, it's sort of a saturation mindset, right? So I'm trying to improve the AI day by day, week by week, and we sort of sacrifice a lot of things where the data come from, who contributed data and who has the rights about the data that's been sent into the AI pipeline and creating a more powerful AI that actually monetize a lot of things, right? And I think the problem really wasn't clicking two years ago to people because there's a huge gap between what AI can achieve versus what this majority of the population actually can achieve, right? But starting from chat GBT to GBD four and all this fancy new stuff we see in every day, we really start thinking about a burning problem of what if we got replaced by these ais and what we're going to do and do we get a share of the AI economy in the future? I think this is really like worrying me every single day.
02:24:13.728 - 02:25:41.820, Speaker A: And I think the fundamental solution to creating a new AI economy is really to think about ownership, providence and data security. And those are what the blockchain and web three technology can provide. And this is how I'm thinking about it, right? So if you want to prove, you create, let's say, ten lines of code and submit to GitHub, which then OpenAI used to improve their model, and you create a new article on Wikipedia, or you create a whole new threat that you're trying to maintain on Reddit. These are all contributing of collective intelligence to the AI economy, but you don't get any share of that. But what if you could use blockchain technology to create personal watermark on a data set and model that you are creating. And then you could leverage cryptography methods to show that anything that was accessible out there can be accessed as expective. That's basically the trustless part of the whole story, right? And then how could you make sure your own personal, very valuable data, your personal message with your friend, your investment portfolio, the statistics, your emails, talking about investments, all these things can be really securely stored in your local devices, but you can leverage the high competence of the foundational model, say llama Mistral, in a decentralized manner.
02:25:41.820 - 02:26:27.384, Speaker A: I'm talking about updating your personal model, but without exposing your data to a centralized server. There need to be very streamlined communication between a private user node and a public decentralized node. And how could you make that usable? And that has to happen with some efficient parameter, efficient sort of approaches for communication. And that's what we are building at Sahara. We're trying to use decentralized Lora hypertuny and personal workermark to really make things high performance and privacy preserved. Next, I want to talk about the fundamentals between web two and web three. Web two is essentially powered on equity, and web three, there's a big part of it powered by a token.
02:26:27.384 - 02:27:32.976, Speaker A: I want to address this question to Michael, who came from a web two background, and what do you think are the pros and cons of building in this new web three stack? And also what are the approach that's different when it comes to building a decentralized stack? Yeah, so the web two centralized stack is very much about how do I get to revenue the fastest way possible. And you don't have to worry about a community as long as you have somebody that's paying you. That's essentially who's providing the food on your table for your company. So it's all about driving revenue, and then it's about making an impact in a market and owning that market. So it's very much about zero sum game in many cases, where it becomes, first about building a lot of value for a user, and then after a while it's all about extracting value for a user as you've gotten that kind of monopoly state. And what I actually enjoy significantly more about web three is the whole community approach. And the token is really the embodiment of that.
02:27:32.976 - 02:28:34.470, Speaker A: It's that ownership in protocols, in ways of interacting with each other, where essentially competitors in a web two sense can easily collaborate. In a web three sense, they can share data, they can share different types of products, even though they may be competitive but still collaborate. And that to me is really the spirit of web three. It's about the community, it's about collaboration, it's about building your base and then decentralizing the ownership of what the protocol really is about. So that there's governance that's not just by a board of people, that's maybe 45678, depending on whatever the company is. And then things like, for example, what happened with Sam Altman and OpenAI won't necessarily happen in a web three context because it's not just a bunch of four people in a room deciding to fade off AI in the future. And so I think that's where web three can really play an important role, is also in experimenting with new governance techniques and creating a more fair, more equal world.
02:28:34.470 - 02:29:58.156, Speaker A: And so the token is an embodiment of that. Sean, so same question to you here. I know questlabs now, it's Sahara, right? You have a web two component, but you also have a portal component as well. So what's your view on this? So again, I think there's a very nice organic synergy between web three and web two, in a sense of providing provenance and ownership to every single building blocks of AI. Sort of a pipeline, right? I'm talking about data storage, model training, hosting, updating, and then also actually the communications between human and AI model and even between these autonomous AI models, every single step I'm mentioning here require a certain sort of currency trust approach to establish, right? For example, when you're calling an API, you're actually trusting that this API is providing by a trust model host. But actually we really want. But there's a lot of things can be gamma in this current economy, right? For example, someone hacked into a centralized server and modified a model providing some data poisoning sort of opportunities for attackers to really disrupt the model and then start giving you messages.
02:29:58.156 - 02:30:55.856, Speaker A: That seems to be correct, but actually slowly going to poison the statistics and information we're going to collect over time. And I think that's really worrying. So I think the trusted component is what I'm really kind of excited about. Can we use sort of a model auditing and verification approach to make sure the model is what we're expecting? It's created in a pipeline that it was documented and plus the watermarking that I was just mentioning. How could we make sure this model parameter contain the watermark component? Essentially owner. I'm talking about attaching that watermark with a decentralized id that make it really transferable no matter which devices you are working on. And I think all these techniques add up together really help us to build a trusted, sort of a workflow for interacting with AI or for building our AI as the time goes.
02:30:55.856 - 02:32:02.010, Speaker A: And I think that's really like the fundamental technology framework for us to talk about economics. And I think economics is coming up, but it's not going to build a new economy from the next week or the next month, right. Maybe we can gradually start with building an economy where if I contribute to the sort of a knowledge basis about web three, I would get a share of that knowledge basis. And if that knowledge basis was later used to fine tune a llama and turn it into a web three llama, I get a share of the web three llama when it was used to further fine tune into any of the domain specific applications. And I think that's a very good roadmap for us, including Sahara, to build towards. Alex for Maru, I know you have a lot of big plans on working with a slew of AI projects. So what do you know is the role of decentralized framework in terms of ensuring fairness and ethical concerns? Because that's a huge problem that when we merge AI and also blockchain together in your case.
02:32:02.010 - 02:33:33.750, Speaker A: So I think Michael kind of touched a bit on this, just to touch a bit on the previous question, fundamentally, how we can look at the web two versus web three in the context of AI models, is that web two is positioned to build vertically integrated closed markets. And whereas the web three world, what's really happening here is because of the incentivization that's built into the protocol itself, what allows us to do is to capitalize on the collaboration itself by bringing more and more inputs from the community. Whereas basically the web two, to contrast, has to control everything. And this is the big fundamental differences. And the way we're seeing that the rate of innovation, once you really get it right, the rate of innovation in the web three is very fast, right? Because where we are going is where these AI agents that are verifiable are going to be cross composable. That's going to be building up ever more and more and more things where a centralized company will just not be able to ever catch up because the crowd is always bigger than a single company, to the point where how fairness goes into this. What's most important is the quality of data on which you train your model.
02:33:33.750 - 02:35:12.348, Speaker A: And this is where really zero knowledge proofs and blockchain technology really comes in, because it creates a way to, on one hand, store already we're at the point where we can store vast amounts of data, and yet this data doesn't have to be trusted, but to a single node. And this is basically where the crux of it, and then from there we can extract verifiable, useful information, which can be later applied to training and inferencing more and more AI models, which are in turn are composable. And I think this is where we're going, where how the AI is really going to explode in the next five to ten years. Carton, what about you? What about, what do you think? Yes, he represented the DK side, you represented the like aura is the team who is the first invent and implement a library called OPML. So the reason why we do that, we kind of try to use the op way to do AI on chain instead of use DK, because we find out one important critical thing is that with the model size increase, your proving cost actually increase exponentially. So pretty much after your parameter, more than 2 million parameter, then it pretty much begin to hard to be proved. So that's why I think the most practical way to do on chain AI is that at the moment is that you use some interactive proof to make sure the AI model run function correctly.
02:35:12.348 - 02:36:28.444, Speaker A: And actually, we just announced a paper called optimistic privacy preserve AI. It just released like two days ago that pretty much used the decay to do two things and two things only. The first thing is the privacy input, so nobody wants another. People know what the prompt is in some sort of the case, right? For example, if this prompt have really good value, I don't want anyone in the ethereum to run my transaction in the on chain AI inference. Then I will want to hide that prom input so you can do a ZK verifier there for sure, and it won't increase the computation cost drastically. And another part we can do a Zk on is like the final verification, because in the interactive proof, essentially what you are doing is that you cut that inference trace into a Merkle tree and then perform a binary research on that merkle tree, right? And then we do a decay proof on this binary research so that you can instantly finalize any AI inference on one block on Ethereum mainnet. Then I think that will be really powerful mechanism in the coming bull cycle when everybody need AI on chain for some reason.
02:36:28.444 - 02:37:15.044, Speaker A: And yeah, that's my take for the ZK part, just to go back and interject, well, going the op route, you're exactly not validating the validity of the data set. And the problem that you say well, you can only have limited set of data right in the ZK. Well, this is exactly what Maru solved today. We already have. With innovation around data structure and basically an ability to aggregate around this data structure, you can have very fast and very large access to data that is fully validated in the ZK. I just don't understand, to be honest. The ZK is great.
02:37:15.044 - 02:38:19.836, Speaker A: But the thing is that if you use a super long polynomial to prove some operator in the AI model when they function, then when you have a few billion parameter in the AI model, few billion operator, then what's the number scale of the polynomial you need for that billion level of the polynomial? It's just impossible, man. Probably you need to use the whole universe to become a computer to make it happen. You guys can get outside afterwards. Okay, let's switch gear a little bit. So this AI blockchain hype is real. And how has this changed the funding landscape? And also, what do you think you have as advice for future builders? Michael, I know you just complete a big round here, so I want to address that question to you. Yeah, what we've seen is that certain funds are dedicating specific theses just to the intersection of web three and AI.
02:38:19.836 - 02:39:23.510, Speaker A: So there's a lot of interest in the investor community at actually studying the intersection, fundamentally funding a lot of companies in the space and really seeing if there's practical use cases. Right now, it's still very much in an infrastructure stage from an AI cross web three side. But many funds are dedicating large amounts of resources to fund companies in the space. And so my advice would be either build infrastructure that can really put autonomous agents on chain and make that a reality for millions of people, or start looking at, well, what are the applications that we can fundamentally build? When you have AI and a smart contract, or if you have an autonomous agent controlling your wallet and then being able to do certain actions, like, I would love to tell an agent, hey, pay this bill for me or manage my expense report and then pay it off. This would be really cool. But there's only a few people building this right now. We need a lot more people building this, and there's lots of funding available.
02:39:23.510 - 02:40:11.296, Speaker A: I know a lot of investors that would love to invest in that, so can definitely chat with me afterwards. That's awesome. And Sean, what do you think? I know you also did really well on your funding. What's your advice for future builders? Yeah, that's a great question. I think for Sahara, when we're raising our crown, we've been having a very interesting game and sort of conversations with different type of investors, both web two and web three AI investors. And I think they are taking obviously very different views on things. For example, web two AI investors, they were really looking at, for example, the usability and whether you have go to market products, how much revenue you're making, things like that, and use that to justify your valuation.
02:40:11.296 - 02:41:07.744, Speaker A: And I think there's nothing wrong about that. But I think the gap here is in web three, when we're talking about blockchain power technologies, there's always this usability gap that we have to think about. Good middle points to find, right? If you're building say ZK and homographic encryptions, those are theoretically super cool things. I love them. But in terms of finding enough, exciting enough use cases or broad enough applications for these technologies, there's a lot to be think about. And I think that's where usually the conversations went into nuance, right? You talk about some applications, many AI investors are super excited about video generations, let's say, and then retrieval, augmented generation of entire Internet, for example. And you want to apply say ZK and he into these places.
02:41:07.744 - 02:42:23.016, Speaker A: And currently the conversation, if you go into lower level details, really easy to break. My advice is really find your sort of battleground, right? Let's say, if you want to build fundamental infrastructure, stack for ownership, provenance, security, decentralized storage, compute, so on, prove that you could build very theoretical sound, maybe developer facing toolkits for them to build some interesting enough use cases, right? But you could also come from a very application business oriented sort of perspective and trying to show, hey, I have some empirical, nice enough approach that I can quickly scale up and push into products and launch and make super good user attractions, even revenues and so on. So yeah, find your battleground and just stick with your stance. I think that's the best thing I want to add. Maybe one more thing, you inspired me around it. I recently saw a super cool paper that's going to be released at a conference pretty soon, but it talks about middleware for llms. So Ilya talked earlier about rag retrieval, augmented generation.
02:42:23.016 - 02:42:48.324, Speaker A: And basically what you do is you enhance a model by adding additional data sources to it. Well, what, instead of data sources, you add other models to enhance that model. So this creates completely new solution spaces. Imagine you can create a dow. Now that's basically a bunch of models together that are basically like an autonomous organization. So there's solution spaces that get super exciting about it. And I want to see builders explore that.
02:42:48.324 - 02:43:07.752, Speaker A: That would be super cool. Absolutely. I just have to fully agree. This is where the next big wave is going to be. All right, guys, if you're a builder and you're building in web three and AI, come find these guys afterwards. They are experts. Yeah.
02:43:07.752 - 02:43:43.918, Speaker A: Check out aura IO. You can use the onchain AI today. You can build some product today on ethereum today. All right, thank you all. You guys are okay, everybody, we're going to be on break for about the next 25 minutes. There is food in the entry room if you want to get some dinner. We'll be back live at around 610.
02:43:43.918 - 03:08:48.440, Speaker A: If you're on the live stream tuning in, we'll get the stream back up at around 610. Enjoy the break. See you guys. If it. No, I like it. This is jump. Don't you know my love for you? Hey, everybody, we are going to be getting the show back underway.
03:08:48.440 - 03:09:35.780, Speaker A: If you can hear me from outside, which you probably can't still, come on back in for our next panel. We'll be getting started in just about 30 seconds or so. And this next panel is on user centric AI. On this panel, we have Nick Cosby from Modulus Labs, David Minaj, he's the CEO and co founder of Valerie, Ethan's son, who is the co founder of Myshell. We have Esley, who's head of strategy at the Marlin foundation. And this panel is going to be moderated by eritien, who's the co founder of Edge AI. Come on stage.
03:09:54.320 - 03:10:11.436, Speaker C: Awesome. Well, thank you, everyone, for coming here. Ready for the round two for tonight's brainstorm. So I want to quickly introduce myself. My name is era. I'm the founder for Edge. Edge is a research and development lab focused along on edge intelligence, local model training on edge devices.
03:10:11.436 - 03:10:27.930, Speaker C: And we're looking to a lot of AI web three with the decentralized incentive right now for the convergence site. And it's my great honor to have the great panelists today to really talk about what does it mean for user centric AI. So we're going to start with just a brief introduction for each team.
03:10:29.020 - 03:11:11.000, Speaker A: Yeah. Hey, I'm David, co founder of Valerie and co creator of Autonomous. And yeah, excited to be here, particularly bringing my view on how autonomous AI agents can create value for their owners. Thank you, David. I'm Estley. I'm part of Marlin Foundation. Marlin is a trustless co processor which helps to offload heavy load compute to a decentralized node of operators, and then the result can be verified on chain.
03:11:11.000 - 03:11:45.276, Speaker A: That's what we do on this panel. I'm here to talk about how teas can help accelerate the whole AI decentralization and user centric AI. Thank you. Hi, I'm Nick Cosby from Modulus Labs, co founder at Modulus Labs, we try to bring AI results on chain without sacrificing anything in terms of security. We do that via ZK proofs. And our current project is reducing the compute overhead of ZK proofs to make the proving of large AI models practical. We do that through our own specialized prover.
03:11:45.276 - 03:12:11.640, Speaker A: Thank you. Hi, this is Yisu, I'm co founder of myshell. At Myshell we are building a decentralized creator platform that people, we empower, creators of all these kind of open source AI models for people to easily build all the AI applications. On top of that, it's also AI marketplace. All the interested people can invest and back all those kind of fantastic AI content and be part of the ecosystem.
03:12:13.820 - 03:12:43.350, Speaker C: Awesome. So I want to start with a bit of background. So in crypto we have a way of saying, say if not your key, not your coin, and in AI space we talk about not your weights, not your model. So when it comes to this intelligence age, we start to really start to think about what does it mean from a personal, individual level. Think about this intelligence stack. And I think we can start with maybe like Marlon and Lake. When it comes to AI, what are folks really talk about? What they really care about.
03:12:44.440 - 03:13:39.780, Speaker A: So with AI, one of the key things that users care about is privacy, both on the end user side as well as developers. On the end user side, they want to ensure that their data is not being used in an insecure way. And also they want to ensure that none of the things are open source and they can be accessible and breached. And on the developer side, they want to ensure that the models that they have built, they should be able to keep them safe and secure, and as well as they want to ensure that the models behave in a certain way. So that's where Marlin tease comes into picture, wherein they ensure that everything happens inside a secure enclave, so that it's black box to outside environment and everything is pretty much secure, but still you can verify everything on chain.
03:13:44.540 - 03:14:26.020, Speaker C: And then the interesting question is, starting from last year, at some point the open AI become not open anymore, and then the whole entire training large model become a capitalist game. In the San Francisco Circle, people talk about I'm a GP poor, or the GP Richmond, all the major big AI company model. So I would say early last year, you start to see this emergence of smaller model, local model research start to emerge, and increasingly people think a lot about your personal can I run my local model on my edge devices on my phone and how I think on my data? So how can people trust it? How can build your intelligence stack?
03:14:28.120 - 03:15:32.456, Speaker A: Well, the problem of trusting AI models generally basically running it on your own device doesn't necessarily solve the problem, because the model itself may be trained to do things that are adversarial to your goals. And it's basically impossible to tell just by inspecting the weights that this is the case. So if the training process included basically a poison pill in it, that causes it to, when some specific token appears in the prompt, that it will do something adversarial, like saying code generation introduces security hole. There's basically no way to tell this fact without knowing what that adversarial token is. So basically, to have a trusted model, you need to understand the provenance of the model. You need to understand what it was trained on, which is, of course an issue, given that collecting these giant data sets and then running this massive proving process is very costly. So one method of doing so is of course with ZK proofs, which is what we specialize in.
03:15:32.456 - 03:16:45.612, Speaker A: If you can prove the entirety of the provenance of the model, all the training processes, all the sources of the data you got, then the edge device can verify the succinct proof and know that this model is effectively doing something sane. So that's half the answer of kind of llms and edge devices. The other half is the fact that once you have this model that for whatever reason you trust, maybe because you did proof of provenance, or maybe it's because you just trust the people who created it. If other people want to rely on the results, they basically either have to recompute it themselves, which is not always practical, or trust not only that the model is correct, that you computed it correctly. That's pretty hard. Llms, the good ones, have billions of parameters and basically doing billions of anything in a ZK proof, much less the pretty complicated operations that llms involve, is currently technologically infeasible, basically even on larger mainframes. So there's a lot of research and development to be done to be able to let edge devices both understand the providence of their model and also prove to other people that the model was executed correctly.
03:16:45.612 - 03:16:59.776, Speaker A: But I think there's also a lot of hope in the technical progress on zkroofs, and a lot of potential could be unleashed if basically, once someone's done this hard compute, nobody else ever has to. They can just verify the proof that it was done correctly.
03:16:59.888 - 03:17:04.360, Speaker C: So how far are we from cheap economic proof.
03:17:07.580 - 03:17:25.390, Speaker A: Llms on edge? Like real full size llms on edge devices? Probably like two to three years small llms on edge devices proving them. That might happen in a year or so. I think we've got some good stuff in the pipeline. Interesting.
03:17:27.280 - 03:17:50.420, Speaker C: So when I talk about user centric AI, there are two. Say one is your intelligence stack, your local model. The other part is this whole entire empowerment with the autonomous agent hackathon. We started looking into the additional agent, like this form of agent, potential economy going to emerge out of it. But let's start with a simple one. What is agent, how we define and what does it mean to be like autonomous agent architecture?
03:17:51.820 - 03:18:44.840, Speaker A: Great questions. Yes. So Ilya earlier gave this nice description of the different types of agents we can find. And obviously, we're on a user centric panel, so it kind of starts with interacting, right? So you can be in a situation where maybe you're using a wallet, as was previously discussed, and an AI agent can sort of complement your interaction with the chain, let's say. So here, the AI agent is basically more like a tool. It doesn't do things for a long time or have any goal other than that specific intent, maybe, or instruction. And then on the other end of the spectrum, we have, like, fully autonomous AI agent.
03:18:44.840 - 03:19:48.872, Speaker A: And I think, again, when we look back at prior panels, really, when people talk about AGI, they tend to mean agendic AI of general intelligence level. And an autonomous AI agent is sort of, I guess, like the more advanced version of that. Right. I see it sort of as one step along that journey. Now, an autonomous agent is a bit different from just a tool because it has its own goals and it wants to get stuff done on behalf of its owner. Now, this owner can be you, a person, or it can be another agent. And I think that's already the sort of first kind of tick box to kind of anchor us at this intersection of crypto and AI with these kind of systems, because naturally, we all know, like web free, it's all about a big part, is about ownership.
03:19:48.872 - 03:21:05.456, Speaker A: And so if we can in the future also and today own our autonomous agent, then there's a lot of value in that, right? And now that can take very different forms. Like you could imagine, this autonomous agent is mostly deployed on chain, and I'll come back to that. Or it's a combination of on and off chain. And that's sort of where at olas or autonolas, we focus on a lot. So they are off chain systems, which users, either single users or group of users, daos, maybe one day countries can co own, and they basically get some goal direction, and then they instantiate that. So if we go back to this AI agent versus autonomous agent, I also think there's an interesting ux difference there. So in the AI agent, we're really talking about interacting like, if you go to jet, GPT, or some sort of web free enabled AI agent, it's all about you, the user, being in a loop with the system almost like sort of instantaneously, and it does something on your behalf for specific tasks.
03:21:05.456 - 03:21:47.936, Speaker A: If you're talking about autonomous AI agents, and certainly AGI, if we can control it, then it's a different parody. I mean, we are no longer the most fantastic instantiation thereof. We're no longer going to be there all the time and say, yes, you've done it right, or no, you haven't, or please do it this way. Instead, it will generate entire outcomes. And I think that's an interesting kind of ux shift, which we're going to see. Where Dow governance was mentioned earlier is one example. You kind of embed the rules and the knowledge of the Dow in this kind of system, and it sort of just gets it done right.
03:21:47.936 - 03:21:53.670, Speaker A: And then ever so often, maybe you update its knowledge or its skill direction and so on.
03:21:54.680 - 03:22:13.528, Speaker C: Interesting. So when you imagine this like an agent economy or agent future, right, I can fork myself, I can have my digital twin. I can shard myself into different version. So what are some of the creative use case? Are there, what are some of the extended version of ourselves can potentially be there?
03:22:13.694 - 03:23:42.020, Speaker A: Yeah, I think at Myshell, we are not just empowering people to create digital twins or just AI characters. I think we focus more on the generic AI applications because I think nowadays a lot of people talk about AI agents, and we use the term AI application because I think traditionally, people with coding experiences, they just code the logic, the user interface up. But in nowadays, with all the large language model, basically, you can use the prompt or simple instruction to make the generic large language model into specific logic with a given prompt to change the output distribution for that. And of course, basically, I think large language model is more like the brain of the AI application or like the coordinator. But we also think a lot of other computer vision models, other generative models, like stable diffusion or some video generation models. Basically, all this kind of model is just a building blocks that we want to integrate altogether to the creators so they don't have to deal with the hassle of model deployments, or how to code the models, or learning coding at all. So basically they can use very simple configurations, or even use our non coding tools to define the processing logics, or to process different kind of user inputs, and to orchestrating all those kind of models together, either in a very simpler linear workflow or even more complicated graph transition logics.
03:23:42.020 - 03:24:42.650, Speaker A: So given that sense, we really can empower creators to build professional grade AI application for both the entertainment, like the AI games, or like the educational content, like AI version of Duolingo, or any other utility tools, or even personalized workflow to process your daily email or the calendars. I think that's really something we want to empower for. And I think all the fantastic projects focus more on the verifiabilities and also building the AI models on chain. And we focus more on, given this kind of fantastic infrastructures, how we can push it further to create a creator or the content ecosystem that's going to really draw a lot of usages, a lot of creators, especially those kind of nontechnical creators, to leverage all those fantastic technologies, AI models, to build something that's really going to be used by people day to day, and build a whole marketplace and also the financial system around it. So I think that's something very interesting and something our vision lies on.
03:24:43.120 - 03:25:03.170, Speaker C: Amazing. So to spice things up a little bit, I know we talk a lot about the traditional convention. I want to ask each panelist, what's the most controversial thoughts you have about this AI web three convergence space? What are some that are kind of like just buzword out there? What are some things that are real?
03:25:07.700 - 03:26:43.244, Speaker A: Um, I have a slightly different take on this. One of the controversial topics that I can think of is trustless AI life coach, right? I mean, as a human, you are making so many decisions throughout the day, there is a lot of cognitive load that has been going through your head. How can we build an AI which can act as a life coach? And you do this in a trustless way, so that only you have access to that data, and the AI acts according to what you will do, right? If you are on a date, it will tell you whether to take roses or whether to take chocolates, depending on your historic data patterns, right? And this is where the whole tea or the secure enclaves come into picture, because the AI model itself is hosted on a secure enclave, so that it's not exposed to any external parties. It's a black box, and you should be able to access it, and it is only accessible to you so, yeah, quite a controversial topic. All right, well, I don't know how controversial it is, but earlier today I was following the fantastic discussions, and sometimes I feel it's sort of implied that there will be some sort of one big model or one AGI, which we should worry about. And that's, in my opinion, totally ridiculous. I think everyone will have varying degrees of models.
03:26:43.244 - 03:27:26.640, Speaker A: There will be trillions of them. Most of them will be agentic. And I think it's all about structuring societies of humans and these agendic ais, many of which will be orders of magnitudes more capable than us. And I think that is where the crypto AI intersection has a big role. Because if you think about it from a meta level, what AI is all about is it just makes innovation faster and faster and faster. And what crypto is in a large part about is about designing mechanisms to align agents, and agents are humans, agents are machines, agents, anything with agency. Don't know if it was controversial.
03:27:27.140 - 03:27:28.000, Speaker C: Nick.
03:27:28.660 - 03:28:02.010, Speaker A: Yeah, so I'm pretty excited. Obviously I work in it on the intersection of crypto and AI. There's so much space to experiment with here. But I think the unfortunate truth is that the realm of the fancy, hot, super exciting frontier models like Sora or Gemini just came out, especially Sora. Those will remain in the centralized corporations hold, I think, indefinitely. The costs in terms of efficiency for decentralization and security cannot be so easily overcome. I think.
03:28:02.010 - 03:29:14.640, Speaker A: Yeah, I think the most controversial thing in the AFS crypto domain is actually the usage versus more infrastructure. I think usage is something we barely mentioned because I think nowadays, given the top performance commercial APIs, people are still trying to build a lot of consumer facing applications. A lot of AI startups is trying to use chat GBT to build something that can help us to better to do the promotions to the AI companion, all others. I think crypto of course going to bring the AI on chain and also bring a lot of transparencies. But I think it's actually the overhead of bringing things on chain, especially with the verifiability how much scenario it's actually justified, the additional cost, I think it's for more money or trading critical scenarios. It's of course worth it. But let's say if you are talking with your AI girlfriend and the verifiability makes the cost like two magnitudes higher, does it worth it? I think that's probably the most controversial talks we have internally around building a consumer facing application.
03:29:14.640 - 03:29:57.564, Speaker A: I think. Yeah, I just want to mention a few other buzword I heard a lot in the domain. I think one of them is training or the fine tuning. Of course fine tuning and training is fantastic, but I think the hardest part is to serve those kind of long tail fine tuned models. It's not possible nowadays I don't see any kind of infrastructure even in the webtoon domain hot loading the long tail models fast enough. So even if we have millions of fine tuned models, how can we serve them? Because all the models going to need GPU memories to host it to make them ready to be used to run the inferences. I think in reality people use rack rather than fine tuning to deal with the new data.
03:29:57.564 - 03:30:35.230, Speaker A: I think of course fine tuning works better, but just not economically viable for most of the scenarios. I think the next one probably is the agents. I think nowadays there's no clear definition of what is AI agents, especially what is autonomous agent. People are always talking about it. I think there might gradually going to form the consensus of what really is the AI agents. What's the difference between AI agents and AI applications? Yeah, so I think just some of password I heard because in some of the events people talked about some things. Even though I work in the AI industry for past ten years, sometimes I don't understand.
03:30:38.400 - 03:31:21.032, Speaker C: Amazing. Yeah, I'll share my thoughts on that one as well. Is I think for a long time we thought about what's crypto's use case, right? Miraculously, now we have AI. Now will AI become one of the largest use case for crypto? Yes, maybe. And even when it comes, everyone talk about decentralized AI. What does it really mean? How much do we really need to be decentralized for our lab? When we talk the open AI or Lamati, they're like, yes, some maybe. But the question market what should be there if, let's say local model, smaller model, personal user centric AI become a real thing? Is the agile intelligence maybe arrive even faster than the decentralized one? Maybe as well.
03:31:21.032 - 03:31:55.632, Speaker C: So I have a lot of questions on that part. So if you are curious about those one like me, do welcome back. Tomorrow we have a full day like 20 workshops back on back to explore talk about those questions. We also invite actually one of the top tier model research company news research. They're the one behind all the fire about know that's actually tier one research company will be here to talk about how AI tier one company they think about the decentralized future here. So that's it. Thank you everyone to join the user centric AI panel.
03:31:55.632 - 03:31:57.750, Speaker C: We look forward to see you tomorrow as well.
03:35:25.360 - 03:36:08.292, Speaker A: Okay, folks, we are going to get our next discussion started. This is a one on one conversation exploring a new paradigm for open source AI on the theme of the survival of the fittest, revisiting some of those darwinian principles that we discussed at the start of today. This conversation is between Sriram Khanan of Eigen layer and Himanshu Tiagi of Sentient. Welcome on stage. All right. Hi, Sriyam. Hey, Himanshu.
03:36:08.292 - 03:37:05.130, Speaker A: Hi, everybody. So, it's been a very long day, and some of this conversation would be repeated from earlier, because a lot of similar things have been said. One of the things that we want to focus on, and we have been thinking about is how Agi, and this is what was said in the first session as well, will evolve as an evolution of AI into something bigger. And I will just introduce that idea, and then, of course, we will love to hear Sriram's thought on this. I feel that you have been toying around with that idea in your head for a long time, based on what you said in the morning in the earlier session. So, if you think about how intelligence came in, the basic intelligent life form had a very simple feature. It can remember what it has seen before.
03:37:05.130 - 03:38:09.996, Speaker A: It can remember some memory, and it can remember what action was taken when it saw the same thing before. That's what the first basic chemicals of intelligence would be able to do, remember. And the actions and the rewards of what you have done. And just with that, evolutionary forces got us to the complex form of intelligence that we see around us right now, just with that basic form of intelligence, and I think most of us will agree that the corresponding artificial intelligence, the basic form of it, which can remember something and act on it in some form, has been discovered. That basic form of intelligence is around us. So with that background, the question which Pramod Viswanath, who was also here in the morning, and I have been discussing, is, if this is the premise, then what will it take to bring in the evolutionary forces for this basic intelligence to evolve into general intelligence? So artificial intelligence to evolve into artificial general intelligence. And this is a space where we feel that crypto can play a great role in providing that background.
03:38:09.996 - 03:38:44.596, Speaker A: Now, if you look at how this evolution happened, based on darwinian evolution, what is clear about darwinian evolution, survival of fittest, is that it's highly competitive. Everyone is competing with the best, and the best one wins. This is the basic understanding. But what is perhaps surprising is that in that competitive nature, cooperation evolved. Right? Every gene is not competing with every gene. Every individual is not competing with every individual species came together, cooperation evolved. And that was somewhat surprising finding.
03:38:44.596 - 03:39:38.732, Speaker A: And now people can explain that from various ways, from kinship theory, from even game theory. And this is where Shiram comes in, because if you have been following Eigen layer, this amazing project called Eigen Layer, he talks a lot about non zero sum games and now infinity sum games and how cooperation is the foundation for evolution to the next better thing. So this is what I thought I would check with him about how he thinks evolutionary forces applied to open source model on crypto open source models of AI can take us to general intelligence. This will be the topic of the chat. Very abstract, but very interesting. So, Sheeram, your initial thoughts on that, and then I'll ask more. Can't ask for a better know.
03:39:38.732 - 03:40:28.940, Speaker A: Himanshu mentioned our fascination with non zero sum games. In fact, one of the memes we've been doing recently is called infinite sum games, or infinite games. What is an infinite game? How could a game be infinite? It's actually, like an absurd concept. But if you look at the structure of, let's say, growth, how do you get growth? How do we get GDP growth? We get growth because there is something non zero sum. And this non zero sum games, if they can be iterated, repeated, and compounded, you can get infinite sum games over an infinite horizon. Okay, so, going back to this question about evolution, coordination and innovation. So let's start with the basic premise.
03:40:28.940 - 03:41:42.868, Speaker A: How does evolution create complex life forms? Right? And one way to think about it is let's zoom all the way back several billion years when we had the first multicellular life. So you can look at single cellular life, and then from single celled prokaryotes, evolved eukaryotes, out of which evolved multicellular organisms. And one of the core things that happened there is a coordination. What is the coordination? Multiple different types of cells fuse together into a nucleus and mitochondria and stuff. And each of them have their own dna, and they coordinate together to create these eukaryotes, which one of the main things that happens in a eukaryote is mitochondria specialize in producing energy, and the nucleus specializes in maintaining common information. So you can go back all the way to evolutionary history and see that there is coordination. One way to think about it is evolution is continuously happening, and organisms are improving all the time.
03:41:42.868 - 03:42:49.000, Speaker A: But then there is a coordination, and then there's a spike in progress. Suddenly, you see a whole bunch of new multicellular organisms created out of this synthesis of nucleus and the mitochondria. So this is my model I've been toying with is nominally evolution is accelerated due to innovation. And innovation in darwinian case, is just natural selection and mutation, and suddenly it gets accelerated in an unprecedented manner when a new coordination mechanism emerges. So innovation, coordination, innovation. So this is the structure of evolutionary progress. So, now, if you zoom back today into intelligence, what would a corresponding theory be? A corresponding theory would be that there is innovation which is in the form of there is intelligences, or artificial intelligence, which has a certain amount of capability.
03:42:49.000 - 03:44:00.060, Speaker A: If you can build a layer of coordination on top, you can accelerate it massively, so that one you're not constrained by the limitations of a single intelligence. You now have the super additive synergy across many, many entities. This is true for ais themselves, but it is also true for the humans creating these ais. Like right now, when you look at an OpenAI model, it has the knowledge and understanding of the thousand engineers at OpenAI. What if we could endow it with the knowledge and understanding of the tens of millions of people who probably know the same amount or more outside of OpenAI? So that gives rise. If we can build a coordination mechanism to coordinate all of us to build and contribute to a common incentive model, common intelligence model, then you can see that the rate at which these models can evolve can increase exponentially. So, right now, you see a breakthrough due to the discovery of an intelligence.
03:44:00.060 - 03:44:44.044, Speaker A: When we coordinate these intelligences, you will see that there is another massive breakthrough in the rate at which these intelligences can evolve. So that would be the corresponding theory with some evolutionary history. Yeah. Beautiful. So, basically, the next wave to watch out for is the one which uses this basic units of intelligence, called foundational models, and evolves them into something much, much stronger than the original foundational model. We don't think a basic bacteria is stronger than human, but, you know, it's the origin of many things, and it evolved into this complex form of intelligence. And so if LLM should look in the rear view mirror like a bacteria in the human complex, in the intelligence scape right now, coming to this, just.
03:44:44.044 - 03:45:10.480, Speaker A: This is a good segue for the next part. I wanted to ask, I just want to add one thing there. Even humans are not the pinnacle of intelligence. When you talk about things like artificial superintelligence, which is the sum total of human intelligences, is agi the first artificial superintelligence? No. Already markets exist. For example, markets know things that no individual knows. It's a form of coordination.
03:45:10.480 - 03:46:14.788, Speaker A: It is a form of emergent coordination that markets know things that no individual knows. So, artificial superintelligences already exist in the form of emergent coordination of individual humans. And therefore, he was saying, relative to a bacteria, a human is nothing. Relative to a human civilization, a human is nothing. We already know that, right? No one of us here can do really anything other than just make our own food badly. Right? Many of us here don't have the survival ability to manage ourselves, but we manage because we are part of a larger coordination substrate on which we specialize, hyper specialize, to do narrow things that can all interact with each other to then do something much larger. So, absolutely, when intelligences coordinate, the sum total of their intelligence can be much, much larger.
03:46:14.788 - 03:46:40.332, Speaker A: So placing human as the pinnacle of intelligence and trying to say that I'm going to improve it is not enough. It is the emergent intelligence out of the coordination of all humans that we need to compare AGI itself to. Great point. So let's now bring some examples. Okay. Open source AI. The reason we bring out open source AI is because this is the basic unit of intelligence, which can be evolved into something bigger.
03:46:40.332 - 03:48:00.744, Speaker A: So can you maybe give some examples of the kind of open source AI one should look at and the kind of variations that get created using that, the corresponding mutations is what you're calling innovation. In my head, what are those variations which get created before survival of the fittest and evolutionary pressures kick in? What is the playground? What do you see coming in and what you already probably see coming in sitting at Eigen layer and as avss? Yeah. So I think the mapping is clear that there is a model, and you can think of the model as, like, an individual, and somebody creates derivative models. These are mutations, and there is recombination, which is mixing ideas from multiple models to create, like, multimodal models or mixture models or whatever mixture of experts. So you have already the core elements of. You have the core elements of the evolution of intelligence already in the natural evolution. So what kinds of things are we talking about? You can take an open source generative model and then create a derivative generative model, which is maybe specialized to some purpose, right? Adapted, fine tuned, refined.
03:48:00.744 - 03:48:56.780, Speaker A: Either it could be cultural context, or it could be styles, or it could be utility in a certain dimension, like a doctor's chat looks very different from a general purpose chat, and so on. So the starting point is the elemental unit is an individual, and the individual is a model. And then models can then evolve, which means, like, new models can come in. But one of the core things in evolution is this notion of fitness, and fitness to replicate darwinian evolution, you need a notion of fitness. And there are various ways that models can acquire a notion of fitness. Imagine a marketplace of models where models get paid as much as users value them. This is the market intelligence that can ascribe a value to these models.
03:48:56.780 - 03:49:40.764, Speaker A: And then in the marketplace of models, models have a survival, survival relative to more models that are more useful, get more valued, and more valued, models get more produced, and more derivatives, and so on. So one of the core things that I think is needed to enable this kind of a marketplace is a mechanism which has two simultaneous things. First thing is permissionless derivatives. I should be able to take a model and create permissionless derivatives, because otherwise I don't get mutations. But also I need value accrual to the model creator. Very, very important. A lot of us here say, oh, open source everything.
03:49:40.764 - 03:50:18.132, Speaker A: How do you create open source everything and create value accrual to the model? What is the biology analogy? The biology analogy is the cell has a boundary. And if you are in thermal equilibrium with the rest of the universe, you are not a cell. There is no unit of evolution. To have a unit of evolution, you need a boundary. To have a boundary, you need value accrual. To have value accrual, you need some mechanism to containerize the value accrual. How does a model accrue value in an open source universe? This is one of the basic substrates that need to be uncovered.
03:50:18.132 - 03:50:57.350, Speaker A: And right now you look at it, there are two types of licensing models. The closed source, the model creator owns. The model creates value accrual, rigid boundaries. But this rigid boundary does not allow for permissionless derivatives. On the other hand, you look at open source, anybody can create permissionless derivatives. But the model creator has no sustainable value accrual, no rigid boundary, so no survival advantage if you just take a pure evolutionary approach to it. So what can we do? Are we to give up? Okay, here's an idea.
03:50:57.350 - 03:51:51.264, Speaker A: We have a new model, licensing model coming up called the permissionless derivatives license. This is something we're going to promote heavily at Eigen layer. The permissionless derivatives license is a type of license which allows anybody to create derivatives on top. But these derivatives can only be used in this particular marketplace. Imagine there is a marketplace, an AI marketplace, on Eigenv, and it comes and says, anybody can now deploy a model. But any derivative of this model also needs to be launched on this decentralized blockchain. Why is this important? It's important because now, any derivative model, when somebody is using that model, I can meter it on a blockchain.
03:51:51.264 - 03:52:41.460, Speaker A: Number one, when I meter it, I know how much value is going through it. Now I can pass value from a derivative model back to the original model, creating a tight system of karma, value allocation across the creators. Somebody created something, and then I'm building a derivative on top. I need to have a mechanism to pass value between the creator and the derivative. And so this is what we are trying to create with this permissionless derivatives license. We'll have a lot more coming up about this license soon. But the core idea is this permissionless derivatives license is tethered to a marketplace, a decentralized marketplace, where people can deploy derivatives, but the value accrual across these derivatives is mediated by smart contracts.
03:52:41.460 - 03:53:37.092, Speaker A: So now, for the first time, you have permissionless innovation, which is mutation in biology, and value accrual, which is the cell boundary or the organism boundary. In biology, you have created the base units of permissionless innovation for AI. Yeah. Excellent. I think we have sort of drawn one on one analogy between how evolution happens for regular intelligence and how we see it happening from AI to AgI. And in fact, one way to think of it, it's the same evolution continuing, except that it's not the fittest in the sense of how many offsprings they produced and how they survived. Maybe the rewards are changing, which probably can be interpreted as offsprings of that AI.
03:53:37.092 - 03:54:15.140, Speaker A: That permissionless derivative is like offsprings of the AI. Rewards are changing, but it's the same evolutionary path. Can we give more examples of categories where. So one question which comes to one's mind is that, do you really think centralized versus decentralized, right? There are centralized forces. Maybe they are more like remrican evolution, that I will just give the next model all that has been seen before. That's what OpenAI will say, that I am building on the same model again and again with trillions of dollars now, not billions anymore, right? At least that's the word on the street of investment coming from everywhere. Okay, if not trillion, then half a trillion will come.
03:54:15.140 - 03:55:00.260, Speaker A: And the question is that path, what will come out of that path? And this path, which is darwinian and more decentralized? Darwinian evolution is decentralized, right. To begin with uncoordinated agents just competing and coordinating for survival versus this centralized evolution, also another evolutionary force. What kind of projects will thrive in this one and what will thrive in this one? Any thoughts? It's a really interesting question, and I would contest the phrasing of the question. The phrasing of the question disclaimer. He refused to see the questions before it's all made up questions and made up answers. So don't, don't take it too seriously. Yeah, please don't.
03:55:00.260 - 03:55:56.452, Speaker A: At viewers discretion, the when you're thinking about decentralization, we have to examine why do we need decentralization and what needs to be decentralized, and should models be trained in a decentralized manner? Should models be served in a decentralized manner? What should be decentralized is a question that we need to think about, because decentralized everything is a bad idea. Okay, think of it like this. Somebody said America is a democracy and that means it's decentralized. What does it mean by decentralized? You have to build your own roads. Nobody would want to live in this country. It's great because roads have equal access. We all have commons that we can share in.
03:55:56.452 - 03:56:38.332, Speaker A: That's the power of the democracy. So we have to think about what things need to be decentralized and what things need not be decentralized. So another thing is when people think about decentralized systems, one of the core properties we think of is censorship resistance. Right? What is censorship resistance? Censorship resistance is equal ability for anybody to access said resource. And usually as a community, blockchains. We sell censorship resistance to, okay, repeat, we sell censorship resistance to users. Which means you say, hey, you may get deplatformed out of Twitter, you may get your bank account, like locked.
03:56:38.332 - 03:57:38.628, Speaker A: These are really powerful use cases, but they're very narrow in the economic slice. So building very strong, powerful systems with a lot of economic activity competing with the said gentleman who's raising a few trillion dollars may not be easy when you take this kind of an approach. But if you flip it, how do you flip it? We are not selling censorship resistance to users. We are selling censorship resistance to developers. What does it mean to sell censorship resistance to developers? When a developer is building on top of a platform or an API, they're taking complete platform risk on top of that API. We've seen this again and again in web two, where you build on top of a platform and the platform completely rugs you, to use a crypto terminology. So as a developer, your own market value is subsumed by the platform that you're building on for the first time.
03:57:38.628 - 03:58:37.720, Speaker A: Crypto offers an ability where something built on top of a platform could be even bigger than a platform because the platform offers censorship resistant access to the developers to continue building and deploying new features on top. And this continues at infinitum. When I build as a developer on top of this platform, I get access to the censorship resistance. But I also give access to censorship resistance to other developers to build on top, creating this infinite hierarchy exactly like evolution. One organism mutate to become the other organism. We're just accelerating the rate at which such mutations can happen. So back to the question, what things need decentralization and what things need centralization? The substrate that guarantees immutable, verified API access needs to be decentralized.
03:58:37.720 - 03:59:37.032, Speaker A: Lots of other things can be centralized model can be trained in a centralized way, model can be deployed in a centralized way. But the system of karma, so to say, which ensures that people do the things that they need to do and maintain it, that needs to be decentralized. So this is part of why we built Eigen layer. Like the public branding of eigen layer is the restaking collective. The internal goal for us is the coordination mechanism for open innovation. To be more precise, humanities coordination mechanism for open innovation because we want to make sure that humans can coordinate even against these ais. So the core principle is that when you have centralized entities that can even provide these services, but can they provide them in a verified, immutable manner where if they go wrong, they will suffer the consequence of their wrongness.
03:59:37.032 - 04:03:46.482, Speaker A: And so that's really how we think about how the role Eigen layer plays in this kind of like a broader ecosystem. With that, it's time for us, and I think it's very exciting time to look forward for crypto, which can now enable the next phase of evolution itself. And on that positive note, thank you very much for listening. Thank you so much. Manjula, the chat. Thanks everybody. Everyone, we're cruising into our next panel.
04:03:46.482 - 04:04:20.210, Speaker A: It is AI's role in blockchain. Our panelists for this session will be Nuraj Pant. He is a co founder of Ritual. Nick Emmons, who is the co founder of Allora. Salman Avestimir who is the co founder and CEO of Fed ML and the dean's professor at the University of Southern California. And we'll be rejoined by Himanshu from sentient and Kenzie from symbolic capital. Come on stage.
04:04:20.210 - 04:05:20.406, Speaker A: All right, guys, this is my favorite panel of the day actually. So I think this topic here is really important. I think we're at this crossroad of closed world versus open world and we want to talk about the importance of blockchain in AI movement. And I think this is actually the biggest problem in our generation here. So my first question is to Himanshu. So what do you think is the role of blockchain incentive mechanism that can contribute or accelerate this AI model movement. Yeah.
04:05:20.406 - 04:05:52.114, Speaker A: So I can just continue from where we left in the previous talk. So at least I see this. I have fit in this model of evolution in my head. And evolution is all about rewards and what you get for being the better self or being the better one. And it's also about how people coordinate together to have that better form. And so AI incentives can first enable that coordination by appropriate incentives around some specific tasks, some specific goals, these models can be coordinated. Right.
04:05:52.114 - 04:06:24.138, Speaker A: This demand can be coordinated around some specific goals. For example, just by OpenAI doing so well in LLM, a lot of innovation happened very quickly on conversational side, and it was not necessary that took over. There could have been other things just because that incentive coordination happened. Now suddenly you see 20,000 different embeddings available for just the language part of it. That's because of some coordination. Now, this thing can be turbocharged with crypto for many different things, number one. Number two is the part where crypto incentives can be extended to smaller teams in very different ways.
04:06:24.138 - 04:07:15.530, Speaker A: One thing which is missing in what's happening today is that when we think of AI, we think of $1 trillion gpus, which are very expensive, and people building it who have 20 years of experience and 30 years of experience. I want to think of a world where people who are coming out of college are shaking these things, or maybe even high school kids are shaking these things. And this is where crypto incentives are very native to, that can be made very native to that population. And that's the competing force of innovation, who have not been hardbound in any of these existing things, which can be enabled through this. So the new innovators onboarding and then aligning the incentives with some broader goals, like LLM was one, but it can be music can be another one, vision can be another one. There can be multiple such things. And that's where I see this role of crypto for AI incentive ecosystem.
04:07:15.530 - 04:08:13.934, Speaker A: Niraj, what do you think? Can you repeat the question? Yeah. So crypto offers this great incentive mechanism, and how do you think it can accelerate or crowdsource AI model development? So, to me in 2023, the meta of AI is there are a lot of developers interested in building models. There aren't great ways to monetize those models or to build new products. The challenge with crypto AI today, and I guess AI in general, is that the monopolies hold all the distribution. If you're an average developer, you can't really talk to the power that, say, OpenAI has with Chat GPT so you're left in kind of a bind. You're left in a bad position where you're going to have to go and get all the distribution yourself. So I really like what crypto is doing.
04:08:13.934 - 04:09:10.730, Speaker A: Crypto AI is doing where it's decoupling the development of the models with the distribution of who can actually access those models. That's a really big thing. The other thing is, as we're thinking about, the reality is a lot of people in the AI space are not paying attention to crypto AI, so how would they pay attention? And really, I think it's lean into the crypto stuff, lean into the incentives, lean into the transparency. And I believe that we can really bring millions of users into crypto through the lens of AI. Everyone in this room probably uses chat, GPT, or maybe 70 or 80%, and that's a lot more users than we have in crypto today. So that, to me, is a very exciting value proposition. And in this idea of creating incentives, you can do everything from crowdfunding models to paying for data to paying for compute privacy.
04:09:10.730 - 04:09:50.126, Speaker A: There's so many exciting avenues to go develop, which is why I am building in this space and why I'm so excited about it. That's amazing. So, Nick, I know Alora is building a self improving AI network. So when you build this decentralized network, how do you ensure safety and also mitigate risk management? Sure. Yeah. So I think blockchains are a really useful tool in turning different nebulous resources into different digital commodities, whether it's compute, power, trust. I think when we think about AI, with what we're building with Alora and these self improving networks, is we can turn intelligence into a commodity as well.
04:09:50.126 - 04:11:13.430, Speaker A: Instead of this sort of model centric paradigm, which is commonplace today, in which applications reference specific models or things like that, I think we should move to a sort of objective centric paradigm, or maybe an intense centric paradigm for nomenclature that's more familiar, in which you establish the objective function by which you care about ais to be optimizing, and then establish market incentives such that many different ais, many different ML models, can collectively optimize that objective function. And when you move to this objective centric paradigm from a model centric paradigm, it removes the sort of all encompassing control a single model can have in manipulating some application or performing some malicious attack, or even just being incompetent in some domains. It creates an open market in which everyone's competing to optimize the thing that they really care about, this intent or this objective. So I think we can build these kinds of systems that combat these sort of manipulations or malicious attacks by moving to this objective centric paradigm. Awesome, Salman. And the next question is for you about know that's becoming a key component for decentralized GPU network. So in that regard, how do you see this decentralized gpus actually are able to be used for, in general, web two ais and things like that? Yeah, that's a great question.
04:11:13.430 - 04:11:54.198, Speaker A: Exactly. That's what we do. Meaning in Fedimel, we provide a platform so you can bring in the demand on, let's say, building a model, running inference, et cetera, to decentralized gpus. Okay, so we support multi cloud, we support decentralized GPU. But your question is on reality, what type of models can you run on it? The thing that I see is in decentralized networks, there is a lot of quantity. Maybe one part that is lacking a bit is the quality of the gpus, right? So for example, when you go to the cloud, you can easily access a 100 h 100. In decentralized GPU networks, maybe you get 40, 90 gpus lower quality.
04:11:54.198 - 04:12:27.130, Speaker A: So something to think about. As we want to position decentralized GPU networks to be the cloud for open source AI, we have to invest in the quality. The other side is the bandwidth. Like being in a rack in a data center, you can be connected right now in ten terabits per second. Now imagine decentralized GPU, you want to run it and your connection is maybe gigabit per second. So that's where I think room for innovation. For example, in federated learning, if Fed ML, we provide some solutions how to run with low bandwidth.
04:12:27.130 - 04:13:09.002, Speaker A: But I think that will accelerate. Maybe a third. One I would mention is one big difference between centralized cloud and decentralized cloud is the regulation governing it. So for example, let's say you want to put your model, you want to put your data on AWS, then there are sort of compliances that protect you. For example, there is SoC, two different type of mechanisms that you are sure your data is safe. Now we come to decentralized cloud, like your data, your model is going to other people's computers. How would you then research wise, like you can protect it by homomorphic encryption, trusted execution environments, et cetera.
04:13:09.002 - 04:13:42.002, Speaker A: Those methods, they won't work for generative AI because it's going to be very slow. They cannot have accommodate large models. So I think that's another layer to think about the trust and security of decentralized cloud. So I would say quality communication, the trust layer, these are some of the bottlenecks we are seeing. Do you have a time frame for that? So these, we actually currently do it. So we have a solution for each. For example, for the trust layer, you can think about software security, you can run things in a secure container.
04:13:42.002 - 04:14:18.338, Speaker A: Software security works very well. It's not the ideal, but in general, that's a guarantee you can give for bandwidth. As I mentioned, we already have federated learning, runs it in low bandwidth environments. For quality, we have engine that you can run inference on say 13 billion parameter models on 40, 90 gpus. So that's why currently, actually we run a lot of machine learning on decentralized gpus. So we have developers using it, but we have to scale it up. Let's say you want to go to 70 billion parameter model, you want to get to 3 million active users on a specific model.
04:14:18.338 - 04:15:13.270, Speaker A: So I think that's where the innovation needs to come in to push the scale to match, let's say AWS. Got it. Blockchain is a very powerful substrate, can be a very powerful substrate for AI development. But this token and incentive mechanism that come with it, there's a lot of fluctuation. So with that, how do you think that a fair system can be established to ensure stability of AI models? Let's start with you Jimenschu. Right. So the idea is that this blockchain is not, the incentives should not directly, the architecture of all these systems should be such that the performance of models and the incentives which are driving those development are separated out.
04:15:13.270 - 04:15:45.310, Speaker A: The incentives are for the builders, incentives are for the innovators and the model rails, and the inference and training and storage. These rails are separated out from it. This separation of architecture is very important. For example, the modeled inference should, on chain inference have become tricky and it should not be tied with gas fees somehow. Those are the architecture innovation one has to look for. So any of these projects, I think they already are aware of these issues. And this kind of architecture is evolving.
04:15:45.310 - 04:16:41.042, Speaker A: The variations in token prices are decoupled from the performance required from these models. That's how at least I see it. Niraj, how would the vitro's tokenomics work in this regard? I think how we want to architect the system. So to talk about, say, something like computational integrity in the world of crypto AI, there's a lot of talk about ZKML versus OPML versus this other stuff. And our view is really, you need to match the integrity, you need to match the cryptography to what users want. Ultimately, certain computational integrity models are not going to fit certain use cases. ZKML doesn't really fit the LLM paradigm today.
04:16:41.042 - 04:17:26.538, Speaker A: The prover overhead is too high. So as we think about how do we build an interesting ecosystem, I think it goes to a lot of these points. Building censorship, resistance, building privacy, computational integrity. And ultimately, you have this beautiful payments mechanism you have in blockchains that now, instead of having to go and have a credit card and talk to OpenAI off chain, you can directly pay for a model on chain with ETH. And that's really powerful. And I think we're just excited to see what types of use cases and applications come out of this. And ultimately, I think what everyone on the stage is building is infrastructure to try to kind of drive these interesting use cases.
04:17:26.538 - 04:18:04.022, Speaker A: And I think this next year will be really a test of what the killer use cases are for crypto AI. But I ultimately believe this crypto AI will be the strongest driver of users, maybe that or gaming in the next two years in crypto. And that's a very, very exciting prize to go and win. That's great. So verifiability of output is a very common theme now for a lot of projects. What is your approach to it, Nick? I think Naraj said it well. I think ZKML is important for some use cases, and it's just untenable for other use cases.
04:18:04.022 - 04:19:03.514, Speaker A: I think really high value use cases that demand that sort of computational integrity are important, and we'll see other approaches to kind of bringing AI on chain. I think OPML is interesting as a lower cost solution. Again, I'm a broken record here, but I do think this sort of objective centric approach sort of subverts some of the sort of, I guess, need for some of these things as well. When you're setting an ML objective that an ever changing set of models is continuously optimizing, who cares if they have some sort of computational integrity? The end result is what matters, and how they got there doesn't matter as much. So I think we'll see a bunch of experimentation in the space over the next year plus, and we'll see ZKML really start to move into only the extra high value applications that really demand that kind of computational integrity. Got it. And Salman, any take on this? Yeah, actually we worked a bit on ZKLM, like a version of that for LLM.
04:19:03.514 - 04:19:26.262, Speaker A: I agree with you. I mean, scaling it to large LLM, super difficult, maybe. My take is, I think still you would need it. For example, even if simple service like, which model, my inference is running on like a proof for that. Still you would need it even for low end applications. Maybe a way through that is through approximate proof, right. You don't need all the layers of the model to prove it.
04:19:26.262 - 04:19:59.150, Speaker A: Maybe a few layers, maybe the last layers. So I think there is a lot of work on approximations. Like that's the even for the typical zero knowledge proof, you approximate it to a polynomial. But I think you don't need to look at the entire model. Maybe there is opportunity to approximate part of that, right. Think about maybe a Lora based, maybe only the head you identify, like which adapter is running based on yours. I think there is opportunity to innovate, but I still feel approved is required not only for special cases.
04:19:59.150 - 04:20:46.154, Speaker A: Blockchain AI is still very early. We're at the first 2nd in and of it, and there's a lot of challenges ahead. So this is a question for all of you, actually here is that what are you seeing is the biggest performance challenge that you see on actually making this work. So one of the obvious technology challenge here is what everyone is talking about is proof systems. And I completely agree with what Salman said, that this approach of thinking of the computational graph as a circuit and then a computational graph as a rigid thing, converting it to circuit and following the regular ZK or proving recipe is very limited. They were not even designed to be that exact, those models. So one have to be creative in what they prove.
04:20:46.154 - 04:21:04.920, Speaker A: You don't have to prove the whole model because the model itself is not so rigid. You can cut some branches, it still performs the same way. Okay. And that's one part. This is a challenge. If you go with this approach of verification, it can become an obstacle to the whole development. I feel it's still a couple of years at least, away for some of these things.
04:21:04.920 - 04:21:32.206, Speaker A: Some creativity is needed there. And the other challenge, maybe not the infrasite challenge, but for sure a challenge. Neeraj is saying that this may become a driver for new users to come on to crypto. I completely agree with that. And that's where we have to be very innovative to bring in the mainstream AI development community to crypto. And that side of things, that I think that's also sort of a challenge right now. That to bring an AI developer to the crypto side of things, that's sort of a challenge right now.
04:21:32.206 - 04:22:01.474, Speaker A: For any one of you who's trying to do hiring, you will know. And I think that's something we should also think about. Who are these target audience who will come to crypto and innovate on AI. That's an important thing. At least I think about Salman, maybe a follow up on that. Maybe if you think about a little bit at a higher layer, let's say we want to build like a cloud, decentralized cloud for open source models. That could be a great accomplishment.
04:22:01.474 - 04:22:54.614, Speaker A: To do that, then you have to say, how would we compete with other clouds that exist today? For example, you go to Aws, you get to see Mistral, is there other open source models are there? What is going to be the add value that we provide? Definitely cost is one that's the advantage of decentralized networks. The cost is much lower. There is no way other clouds can provide that. And I think the way to realize it is like maybe to make some steps is to provide some APIs hosted by decentralized cloud and every developer use that. At the end, many developers just need the API. If these APIs are hosted, low cost, high quality, I think that's going to be a very good step to attract developers to build their solutions. Why would they go for expensive API, go for maybe low cost.
04:22:54.614 - 04:23:37.814, Speaker A: Then after that I think it's going to bring in more innovation. Once they use that, then the innovation is going to be maybe new agents, they built new models, they train and then they want to bring it back, bring the content to this cloth. Right? So right now it's like you start from the infra, you encourage building, then they bring in the content. And I think once the content is there. So I can imagine maybe in a couple of years there is going to be a model trained by the community. Why should all the models like llama be coming from meta? Maybe the community owns the compute, they have a lot of manpower and they can train great models. So now it's going to be both platform and both content.
04:23:37.814 - 04:24:01.354, Speaker A: Once you have both, then I think it's going to be a powerful ecosystem. Right. So that's what I'm hopeful that we are going to accomplish. Nick, what are you seeing at Laura? I forgot the question. The challenges that you see in terms of performance reaching the performance limits. Sure, yeah. I think today still the most performant models by quite a lot are built by these monoliths.
04:24:01.354 - 04:25:22.998, Speaker A: They're black box models. And I think if decentralized AI at the sort of intelligence level is going to ever compete with those, we have to move towards creating intelligence the same way that we create decentralized composable systems or that the way that we develop open source software. I think if decentralized AI is ever going to compete with these massive centralized black box models, then thinking through these really difficult problems of bringing different models, bring different insights, bring different forms of machine intelligence together in a sort of coherent way, is going to be a necessary element of creating anything that ever competes with these kind of massive monoliths. So I'd say there's a lot of hard problems and there's going to continue to be, but the intelligence one is the one that I'm particularly focused on. Yeah, very cool, Rachel. So I'm going to take your question a little bit of a different way, which is one of the things that I would look at when I was a VC many years ago was I was really interested in what are the emerging use cases of new technology and how do we kind of back the things that'll grow the overall developer base and ultimately the ultimate user base. And I think the thing that crypto AI needs is crypto people largely don't understand how AI works, and I think we need to develop better education.
04:25:22.998 - 04:26:11.206, Speaker A: I think once people understand ML 101 and they understand crypto, interesting concepts will start to emerge and we'll start to see some really cool applications come out of it. I think we've seen this in the ZK space the last three or four years, where it's really hard for the average solidity developer to wire circuits by hand and build all this proof stuff themselves and optimize it by hand. So now we're starting to see these generalized VM architectures and risk zero succinct type things. And I think if we can get there with ML, we can make it really easy to integrate ML into the average crypto application. That's a huge win. So as we're thinking about performance, the big theme for us is pragmatism. We're not picking one technology, one privacy technology, one integrity technology.
04:26:11.206 - 04:26:40.740, Speaker A: We just want things that are as easy as possible for developers to use. Our first product is an off chain oracle network, that you can prove the inference results on chain, and that is a good trade off. The network is not decentralized yet, but I think that's fine. Let's see what the applications are and then build up over time. So that's kind of our approach to it. That's great. Well, that's a wrap, and let's give a round of applause for all these guys and thank you guys very much.
04:26:40.740 - 04:36:13.622, Speaker A: Okay everybody, our next presentation is titled. Yeah, I'm going to talk loud. This is connected to a zoom, but yeah. Okay everybody, our next presentation is titled the promises and challenges of crypto AI. Applications. And the keynote speaker really needs no introduction. He is one of the foremost thinkers in the entire industry.
04:36:13.622 - 04:36:55.990, Speaker A: We are extremely privileged to have him joining us for this keynote. Please welcome, by the magic of the Internet, Vitalik Buterin. Hello, guys. Yeah, it's lovely to virtually see all of you. Yeah. So crypto and AI is okay? They can't hear them on the speakers. You cannot hear me still.
04:36:55.990 - 04:37:45.174, Speaker A: 1234-5678 we can hear you now. Okay, perfect. So the intersection of crypto and AI is this topic that I personally have been hearing a lot of interest in for pretty much all of the past ten years. Crypto has been a major field of computer science for quite a long time. And of course, blockchains and cryptocurrencies have really supercharged it a lot. And AI at the same time is a major field of computer science. And over the last couple of years in particular, it's just massively impressed basically everyone in terms of the amount of progress that it has made.
04:37:45.174 - 04:39:07.822, Speaker A: And so the intersection of crypto AI, trying to figure out which kinds of applications that use both of those technologies makes sense, is something that a lot of people have really been thinking about for a long time. But it's also one of those areas where it feels easy to kind of come up with these very vibe level, very abstract correspondences between the two, but it's much harder to figure out what concrete intersections between those two technologies actually work in practice. Right. So one of the things that I usually show for this is if you look at this slide from the UE's website on synergies between blockchains and artificial intelligence, basically it lists some common features of AI, including some actually weaknesses of AI, and deliver some strengths of include. It shows some strengths of blockchains. Basically AI is centralized and non transparent, and blockchains are decentralized and transparent. AI has big monopolization tendencies.
04:39:07.822 - 04:40:05.602, Speaker A: Blockchains are all about empowering the little guy and shows some synergies between the two, right? And I think these kinds of very abstract synergies are something that a lot of people have talked about, right. So I think both Peter Thiel and lots of other people have talked about this idea that crypto and AI are the two defining technologies of our time. And AI is a centralizing force. And so crypto is a decentralizing force. And from a narrative perspective, this makes a lot of sense. And you can see the argument for how the existence of AI makes it even more important to keep pushing harder on the blockchain and cryptography direction. But what's harder to see is how this actually translates into applications that actually use both.
04:40:05.602 - 04:41:31.226, Speaker A: Right? So are crypto and AI doomed to be completely separate spheres, or are there actually applications that make sense that actually manage to leverage the synergies of both of these things together? So four major categories, right? So this is the categorization that I've come up with. Basically, AI as a player in a game. So a blockchain sets up a game and ais play in that game, AI as an interface to the game. So AI is helping people to understand the blockchain world and navigate it more easily and more safely, AI as the rules to the game. So AI is actually being critical components in things like daos on chain courts, various kinds of oracle arbitration and enforcement mechanisms, and AI as the objective of the game, which is using blockchains and daos specifically as a mechanism for collaboratively building ais that are more open and democratic in some way. So the last one especially, I mean, I know Ilya Vermeer has been a huge fan of this category, and I know various people have been interested in a lot of these. So I'm going to go through all of these in turn and just talk about where I see the viability and where I see the risks.
04:41:31.226 - 04:42:37.620, Speaker A: So AI as a player in the game, right? So AI as a player in the game is actually an AI crypto intersection that has existed for basically a decade, right? We don't normally think of it as an AI crypto intersection because it just feels like so kind of a little bit lame and unimpressive, but it is, right? And that basically is automated market maker bots, right? Every exchange centralized and decentralized, it ends up getting professionalized market makers, and those professionalized market makers end up being run on AI algorithms. And now we have the MeV space. And that has just made the game even more complicated. And sometimes you have mev bots that are exploiting each other. You have sandwich attacks, you have counter sandwich attacks like sandwiches and sandwiches. You have various attempts of arbitrage bots to exploit each other and trick each other into giving each other free money. There's all of this really complicated AI playing games that we've been seeing in DeFi and CFI for many years now.
04:42:37.620 - 04:43:23.190, Speaker A: I actually view this as being only the first example of a much bigger category, right? And I think the natural second member that's really valuable here is AI's playing in prediction markets. So if we just scroll down here a little bit further. 1 second. There we go. Right? So here we have AI, omen. So this is a demo of AI's playing prediction markets. So here you see a bunch of prediction market questions.
04:43:23.190 - 04:44:36.810, Speaker A: Will IRS successfully start the 2024 tax season? Will the Supreme Court make a decision? Blah, blah? Will Nvidia's RTX remix will be utilized? And basically, all we see here is these are very micro scale prediction markets. Like, this little market volume in this case is like ten die. And then you see ais actually playing in those markets, and ais are the ones that are making the predictions, right? So prediction markets are something that has been actually picking up quite a lot of traction recently, right? In 2020, we saw a lot of people betting on the election. And I wrote a big blog post analyzing it. Then in 2023 and 2024, it feels like there is more and more of them happening, right? Like, prediction markets were a big part of the story during the LK 99 situation about half a year ago. They've been used to predict political events in all kinds of countries. They've been getting very mainstream, right? Like, I saw Donald Trump actually retweeted some prediction markets on.
04:44:36.810 - 04:46:10.760, Speaker A: Just like very mainstream intellectuals are pointing to prediction markets as a source of information about various things and about what kinds of things are likely to happen, right? And this is something that is growing on its own, which I think is interesting to see. And I personally continue to be excited about them because they're a decentralized technology that can help us sort truth from BS and figure out actual high quality predictions, but using a mechanism that is actually decentralized and that doesn't privilege one specific class of experts. But at the same time, there's the challenge that you need lots and lots of people to participate to really make them high quality. Right? And so what if robots can participate in prediction markets? That's the issue. And this is basically exactly what omen is trying to do. There's other examples that are interesting. Like if you think of micro prediction markets, like, you can imagine a micro prediction market on whether or not a particular DAP is legit, on whether or not a particular post on a particular social media platform complies with some particular set of terms of use, or whether or not a particular token is legit.
04:46:10.760 - 04:47:27.730, Speaker A: You can basically make all kinds of micro decisions into prediction markets, and you can have some kind of underlying final adjudication mechanism that's determined by humans, which is important. But most of the time, you're basically able to scale up the trust in those humans by basically having a bunch of bots whose job it is to do the best job that they can of predicting them, and the ones that do a better job of predicting them get more money. And the ones that do a worse job of predicting them end up dropping out over time, right? So I think this is one of those really fascinating spaces that I'm excited about. Now, the second piece is AI as an interface to the game, right? So one of the things that we've been seeing in the past year is the growth of wallets that try to do more to protect the user and to give the user a clearer view of what actually is going on in the network. So Metamask has had a scam detection list for a long time. This is not an AI. It's just like a pretty basic list.
04:47:27.730 - 04:49:08.660, Speaker A: The Ravi wallet has a transaction simulation feature, but so far these tools are very primitive, right? So, like, in this particular case, it's showing me that I'm selling 1000 bitcoin for 0.2 e. But what it's not telling me is that bitcoin in this case isn't actually bitcoin BTC, it's this meme coin that's called Harry Potter, Obama, sonic ten enu, whose ticker symbol happens to be bitcoin, right? So an AI would actually know the difference between those two. And that's something that's important to highlight, but, like, a simple list doesn't, right? So you could potentially really supercharge these kind of user protection tools and user convenience tools by using ais and really help users get a much better understanding of what it is that they're signing on to when they sign an approval or when they put money into a DeFi protocol. So number three, AI as the rules of the game, right? So this is one that I think gets a lot of excitement. So even in mainstream discourse, for example, there's been a lot of interest in this concept of AI judges, right? There's an article on the world government summit that's talking about it. And this is just a very popular theme that people like to talk about, especially back, like ten or 15 years ago, especially back in the day when people thought that ais would be kind of, quote, culturally and politically neutral, just automatically, as opposed to reflecting the perspectives of their creators and trading data.
04:49:08.660 - 04:51:26.572, Speaker A: As we have seen a very fun demonstration of with Gemini over the past, there's a lot of people who have these similar desires in the context of blockchain applications. Basically, if you have a blockchain based smart contract or dow, what if you actually use some kind of AI to make the final decision about subjective questions, right? So optimism, for example, has a natural language constitution called the law of chains. And what if you could actually have an AI interpret that constitution and interpret whether or not a particular proposal satisfies that constitution, right? So there's two challenges to this, right? One of those challenges is, as I mentioned, any AI is going to reflect the perspectives of the training data and the people who are creating and fine tuning it. But the other problem is this issue of adversarial machine learning, right? Basically, the two sentence argument for why these kinds of AI applications are really tough to get, right, is that if you have an AI model that's playing a key role in a mechanism and it's closed, then you can't verify its inner workings. And so it's not actually better than a centralized application. If the AI model is open, then an attacker can download the model, and they can simulate attacks against the model locally, and they can develop heavily optimized attacks to trick the model that they can then replay on a live network, right? So over here, we have an example of adversarial machine learning, where basically someone essentially trains a kind of counter model where that generates a set of tiny changes to an image of a cat that, when applied to a particular model, makes the cat look like a dog to that model, right, and one of the challenges of adversarial machine learning attacks is that they work surprisingly well, even when you don't have access to the underlying model, right. So one of the things you might think about is like, oh, well, what if we do fancy cryptography to try to actually hide the contents of the model, right.
04:51:26.572 - 04:52:27.532, Speaker A: And there are tricks to do that that we'll actually talk about. But the problem is, even if you do that, then there are these black box adversarial machine learning attacks where it turns out that if you make an attack that works against one model, then that attack often translates and also works against other models that have been trained using similar training data, even if it's totally different parameters to do the same task. So cryptographic overhead, right? Basically. So the problem is that a lot of these general purpose cryptographic magic things that we really love to think about in Ethereum, they have very high overhead, right? So we're used to ZK evms taking thousands of times longer to run than just a regular evm, right? Geth can verify a block in like 400 milliseconds, but actually proving the block takes like 20 minutes. And with better hardware. Right, and MPCA potentially can be even worse. And then AI computation is very expensive.
04:52:27.532 - 04:54:41.160, Speaker A: Right? If you want to run a model locally, then you basically need a gpu, right? And the difference between top of the line models and weaker models is massive, right? And so basically the risk is like, is it the case that for any use case where you have a really powerful model that can run inside of a, or is it the case that for any model that's small enough that you can actually put it into a cryptographic black box? It's just much, much better to use a more powerful model where you just run it in a regular computer and you trust the operator. And is the delta in quality between the small one and the big one just kind of so high that there's no point in even trying, right? If the overhead is 1000 x, then the answer is yes. Right? But I think what's interesting is that AI is a very specific type of computation that is amenable to all kinds of optimizations that unstructured types of computation like zkvms cannot benefit from, right? The general intuition pump here is that cryptography works over math, right? And the more you have math that has structure, the more cryptography can take advantage of that structure and basically run a bunch of things in parallel and get extremely high efficiency because it's basically running over the whole computation at the same time. So AI happens to be basically a matrix multiplication followed by a nonlinear layer that goes layer by layer, followed by more matrix multiplication, followed by another nonlinear layer, right? And the bulk of the cost is matrix multiplication. Matrix multiplication is linear, right? It's just a bunch of additions, and it's a bunch of multiplications by publicly known numbers, which you can do with repeated additions. And so they're also additions, right? Or sometimes you don't do it literally that way, but generally both multiplying by publicly known values and adding is very cheap to do. Inside of cryptography, you've probably heard of the same phenomenon in the context of homomorphic encryption.
04:54:41.160 - 04:55:27.340, Speaker A: Additively homomorphic encryption is very easy. We've had it for 40 years. But like real homomorphic encryption that could do multiplication, we've only basically had it for the last few 15 years even at all, and last five years in any viable form. So for CKsdarks, it turns out that you can potentially get a less than four x overhead on the matrix multiplications. And for MPC, you can also get something similar. Right? And the challenge is actually the nonlinear layers where the bulk of the overhead still is. Right? But even still, the overhead of ZK snarking or MPC AI is actually much lower than the overhead of doing the same for EVM computations.
04:55:27.340 - 04:56:42.240, Speaker A: So actually putting AI inside of cryptographic magic boxes is, like, surprisingly viable, which is, I think, really interesting right now. Black box adversarial machine learning. Basically, the challenge is like, even if a model is hidden, if you even roughly know the training data that went into the model, you can often basically make your own model, train attacks against your own model, and then those attacks also work against the original model. So if you want to effectively fight against black box attacks, you can basically do two things. One is you have to really limit who or what can query the model, right? And blockchains are actually good for this, because you can make a system where every single query that gets made actually has to be registered on chain. And then the second thing you can do is you can hide the trading data, but at the same time use cryptography to preserve confidence that the process that was used to choose and use the training data was actually followed correctly. Right? So basically, imagine you have this kind of game, right, where the way that the game works is you have a bunch of users.
04:56:42.240 - 04:57:57.300, Speaker A: Each of those users has the right to submit some portion of the training data, but the training data is encrypted, the training process is encrypted, then the model is encrypted, and then users have the right to make a limited number of queries against the model. And all of this happens in a way where the business logic gets registered on a blockchain. The computation happens with NMPC and with Zksnarks. And then if you do this, then you can actually have confidence that the method that was used to create a model was actually a method that is likely to generate a model that is actually fair and that actually does reflect the cultural preferences of the community, and at the same time verify that that model actually is the model that's being run. But at the same time, you hide the contents of the model, right? And so because you're hiding the contents of the model, no one else can train attacks against it. Adversarial attacks are like a pretty big deal, right? So this is a fun one. Basically, someone made a wearable adversarial attack where you could basically wear this special crown on your forehead.
04:57:57.300 - 04:59:16.500, Speaker A: And if you wear the crown, then you end up, from the point of view of a facial recognition model. So you either don't look like a person or you totally look like someone else, right? So they're a big deal. But the theory is if you hide the model, you hide the training data, then you can actually protect against them. So cryptography plus AI to create these kinds of models is another one of those super powerful things. And then finally, if you use these same methods, then you could use AI as the objective of the game, right? And this is basically using these kinds of cryptographic techniques to actually create these, quote, trustworthy black box ais, basically ais that can be owned and controlled by a community and where the actual model is hidden, which makes it safer to use the model for sensitive tasks. But at the same time, there is no single player that is empowered to have the backdoor keys and be able to see everything. And also from an AI safety perspective, this lets you create a decentralized AI that could have, like, for example, an on chain dao that's controlling a natural kill switch, or potentially even limit queries that try to use the AI for malicious behavior without actually, again, requiring any kind of centralization.
04:59:16.500 - 04:59:57.970, Speaker A: So a lot of really interesting possibilities. I think one note of caution here, of course, is that these are things that are still dependent on a lot of pretty intricate technology going well, right? So this is not the same as stablecoins and nfts, where basically figured everything out that it's a matter of user adoption. Right. This still is pretty speculative. Whether or not someone can actually make this kind of pipeline work and actually be efficient enough, that's an open question. Whether or not ais playing prediction markets can actually outperform big ais. It's an open question, right.
04:59:57.970 - 05:00:48.500, Speaker A: But I do think that these things are actually interesting, and these things are worth trying. And I do think that the underlying story that the default trajectory of AI is one that is going to be both risky and empower all kinds of centralization risk. And this is, this really interesting alternative strategy is one that is, I think, super interesting. Basically, crypto can both compensate for a lot of the challenges that AI creates. Right. Crypto verification could be used to compensate for higher risks of AI defects, for example. But at the same time, crypto and AI, I think, in a lot of cases, can actually work together.
05:00:48.500 - 05:02:40.180, Speaker A: And I'm excited to see what kinds of applications in these categories people can come up with. So we were able to source a couple questions from Twitter X from those folks who are not able to attend in person. So the first question we have is, do you foresee a future where blockchains scale intelligently? And if so, what does that look like when you say scale intelligently? Do you mean like scale using, I guess, like artificial or other intelligence? Or do you just mean like scale in a way that makes sense, the way that I'm taking this question is that they're scaling on their own via artificial intelligence. Okay. I feel like the way that I see the blockchain scaling landscape is that basically right now we basically roughly know how to scale blockchains from a fundamental perspective, right? We know how data availability sampling works, we know how sharding works, we know how snarks work, we know how roll ups work, we know how all the pieces work. And it's basically like a big implementation challenge to actually spec out and build all these pieces and make sure that they don't have bugs. Right? The place where I think AI can help in that process in particular is actually another application that I totally forgot to mention here, which is using AI for bug catching and formal.
05:02:40.180 - 05:04:03.200, Speaker A: Like, I don't know if people have been following this, but there's been a lot of progress in better kinds of formal mathematical proving tools. Like Terry Tao has been excited about lean recently, and people are trying to explore, can you use ais to try to generate proofs and then at the same time use these formal methods to verify those proofs and potentially even run those two methods very closely in parallel with each other? And if those methods become much more powerful, then you will be able to do things like, for example, proving that a ZK scenario, that is verifying ZKVM computation, actually is verifying the same thing that is specified in, for example, the Ethereum eel specification. Right? Or verify that, for example, the Ethereum verkel tree actually is a consistent tree. It's order independent, and all of the properties work the way that they're supposed to work and that the proof system is cryptographically secure. Right. If you have much more powerful AI based theorem proving, then it might actually be able to prove these crazy, complicated claims in a way that's just not possible today. So that, I think, is one area where artificial intelligence can really heavily assist blockchain scaling, and I think that would pretty significantly change the landscape.
05:04:03.200 - 05:05:08.484, Speaker A: And then our last question this person asked, there are about four or five large AI companies right now not leveraging blockchain. Do you think they'll ever start working blockchain into their models, into their platforms? And if so, in what ways? Do you see them leveraging the technology? Yeah, it's a good question. I mean, crowdfunding model training, I think, is one of those that, of course, could be interesting. And that's something I know some people have been interested in, right. The concept of paying people for data. I've always been kind of a little bit skeptical of, because it just feels like 90% of the progress is coming from better computation and better methods and not really better data. Right.
05:05:08.484 - 05:06:22.156, Speaker A: And it often doesn't feel like data is the limiting ingredient, though it does seem from the conversations I've had with AI people, that high quality data in particular is something that often is really valuable in getting a model to higher levels of performance at useful tasks. And so if you can make a pipeline where you can automatically compensate people for submitting verified data, I think it has to be verified because otherwise it's just going to become vulnerable to poisoning attacks of the training process. And then that's another thing that's potentially interesting. And then if some of these distributed training and distributed inference ideas actually become viable, then of course that's going to be super cool as well. And there's different ways to do that. You can run an entire training process inside of an NPC, as I talked about. You could do some mixture of expert thing where you train different parts of the model separately, and then maybe you do the NPC training process for some top layer at the end.
05:06:22.156 - 05:07:11.496, Speaker A: There's different ways to do it. Actually, seeing some experimentation with that kind of stuff would also be interesting. But yeah, aside from that, I don't know. Right. I think the base case where you have these existing models that are just being given to people, made available for people to use in a very centralized, API based way, and where you have much smaller models that people can run on their laptops, that's getting pretty powerful and getting pretty entrenched. But if crypto could also add some third category, it would be cool if it succeeds. All right, that's going to do us for Vitalik's keynote.
05:07:11.496 - 05:11:41.890, Speaker A: Vitalik, thank you so much for joining us. We appreciate you being part of this summit, and we'll be moving on to our next panel shortly. Thank you. Okay, next up we have the panel, open source AI in a centralized world. Joining this panel, we have Ben Fielding, who is the co founder of Jensen, Scott Trobridge, who is a vp at Stability AI, Robert Myers, who is the CEO and co founder of Manifold, and Casey Caruso, who is, among many things, an engineer. And this panel will be moderated by Anand Ayer, who is the manji partner at Canonical crypto and a venture partner at Lightspeed. Thank you, sir.
05:11:41.890 - 05:12:28.636, Speaker A: Thank you. No, I'm good. This is perfect right here. All right, how are you folks doing? How's everyone doing out there? This is like hour six of this marathon summit, so thanks for sticking it out. I'm excited for this panel, but there's a lot to talk about, and I had suggested that maybe all of us do a shot every time anyone mentions Gemini, but I think we should start with Gemini maybe, and just get a feel for how everyone's feeling about that. So, Casey, I'm curious if you've got any thoughts. I just want to go around here because open source is the topic du jour, maybe even for this panel right now, and there's a lot that's happened with Gemini.
05:12:28.636 - 05:12:35.356, Speaker A: So I'm curious, how do you process this? Where does this fall in your mind? Map of open source AI decentralization?
05:12:35.468 - 05:12:43.476, Speaker C: Yes, I was almost late to this panel because I was on the phone with my old Google manager discussing Gemini. We did a little pow out with.
05:12:43.498 - 05:12:46.340, Speaker A: Our old team and they're still there, this manager.
05:12:47.640 - 05:13:46.164, Speaker C: So I was on with both my old managers. One is still there and one has actually just left. Yeah. So we used to work on this team called research systems, and a lot of what we did was not directly to Gemini, but like the post today on Twitter said, as everyone probably read, a lot of the work that we were doing internally all got fed. Yeah, I mean, I think that there's people all across in the organization of how people are feeling. I think you have some people that feel like it is the worst thing to ever happen, and then the other people feel like we just kind of needed to see the other end of the spectrum to be able to come back towards something more centered. I will say, though, probably the most potent thing that somebody said today on the call was that I don't know if anybody in the room has read these new papers called Mina from meta, but it's like these new, basically ways where for training llms, you obviously have the unsupervised part and then the supervised part where you do the RL.
05:13:46.164 - 05:14:33.812, Speaker C: We're basically making incredible strides where the RL can basically be lightweight. And what that means in the end is that creating specialized models is going to become a lot easier. And so having these base models where we think they're going to be for everybody and solve every single use case just isn't even reasonable to think about. And so everybody can blow up about Gemini. But the reality is we're trying to accomplish an impossible task with having this one fits all or one size fits all. And it just gives us a lot of resolve as engineers to know we're making the strides that we're going to be able to have these specialized models that are feasible from an engineering standpoint, so that's how I feel about the whole thing. Sorry for the tirade.
05:14:33.876 - 05:14:55.016, Speaker A: No, that's great. Thanks for that background. You've got such great experience having been at Google, so. Yeah, thanks for that, Robert, take it away. Yeah. So I think that, at least on the technology side, Gemini is very interesting. It's nothing that I guess is particularly new, besides the fact that there's not like a particular special encoder for the modality.
05:14:55.016 - 05:15:37.868, Speaker A: So it's all just fed straight in. So the technology side is very interesting. However, because it's closed source, we don't know things like the data that it was trained on, how the exact know and the exact training run that took place. Whereas if Gemini was open source, if we had undesirable features of that model. In fact, a really cool paper I was reading earlier is Yao et al. The v two, just came out that talks about having, as an alignment strategy, having a language model, be able to unlearn certain things unlearn certain undesirable things that the user wants. Right.
05:15:37.868 - 05:16:24.620, Speaker A: And so if it were open source, we would be able to make these different strains of the model, we would be able to know the data set, and so we'd be able to get to what actually caused these particular issues much quicker and in a crowdsourced way. So I think that this is one of the ways where open source can really shine based off of what some might classify as a misstep, others might classify as poor marketing or pile on effect. Right. But ultimately, when the technologies and the power of the user, the user can make the informed choice for themselves. And that's the premise and power of open source. Thank you. Yeah, I think it was a great example of why we need open and fully auditable data sets.
05:16:24.620 - 05:17:30.204, Speaker A: So effectively, data sets that are being inclusive of unwanted biases, and from that, you do get effectively undesirable outcomes and outputs. I think to, in fairness of the model, I think it's fixable. It's effectively more on, like, over prompt engineering and filtration put in place, as opposed to actual model training and the data involved there. So, yeah, it was a really good example of just showing why you need effectively, even like, country cultural focused data sets, effectively looking at ways of the community and participants of those models, the outcomes of that model, of those outputs of those models, actually having participation within those data sets is going to become fundamentally important. It can't just be an entity that's effectively choosing which data to train these models on. Thank you. By the way, I don't think we did justice.
05:17:30.204 - 05:18:24.968, Speaker A: But it's really awesome to have you here representing stability, because this is largely a crypto focused conference, but the fact that we can hear from you and the fact that stability has been a pioneer with open source models is just like, it's awesome to hear from you. So thanks to everyone, but also to you for joining us. But ben, what do you think? Yeah, I mean, there's not much more to say, but I strongly agree. The point around countries should be able to build their own models, right? I think the Gemini stuff is in some ways very good that it's happened so early, because it just demonstrates that so clearly we can't have one voice building models and everybody using those singular models. It has to be representative of the whole of society and not just a really small subset. And I think the only way to solve that is to open out the tools to build those models. We need to give the ability to build language specific models, culture specific models to everyone, so that we can have the Gemini model should exist.
05:18:24.968 - 05:18:44.200, Speaker A: It sort. Some people will use it, some people will want to use that model. A lot of people won't want to use it. But I wouldn't say that we should not allow it to exist. It's just that we should allow all of the other ones to exist as well, and even the ones that go culturally in completely the opposite direction. I think there's a right for those to exist and represent society. Otherwise, we're just kind of kidding ourselves.
05:18:44.200 - 05:19:10.684, Speaker A: I described it earlier to somebody as these models kind of hold up a mirror to society. And I think what Gemini has kind of done is just like drawn a happy face on that mirror, and it's just like, no, look, it's fine. It reflects us perfectly when actually there's some ugly stuff there when you look at the data of humanity. And we kind of need to embrace that rather than pretend it doesn't exist. So I think we just build more models, basically, Casey.
05:19:10.812 - 05:19:57.304, Speaker C: Yeah, so I completely agree. But the problem is, to make an analogy, it would be as if we had one website and we're like, everybody use this one website for everything. And then when it doesn't solve a use case, people freak out. The problem is that there are so many tailwinds where economies of scale are impacting who can build websites, where the problem with open source is like, we don't have access to free compute, we don't have access to these data sets. And so naturally, these data monopolies that have in the past owned the Internet now have a step up in building these llms. And so it's like the question to me is, how the fuck do we level the playing field so open source can actually proliferate? And so then there's a lot of solutions. I think stability is doing a really good job thinking through this.
05:19:57.304 - 05:20:08.690, Speaker C: A lot of everybody here probably is, but that's the problem that we're facing right now. That's why Google is ahead, is because they have the underlying resources, and we're already starting to see the problems that come from that.
05:20:09.720 - 05:20:59.936, Speaker A: I want to riff on that. Robert, just wanted to get your thoughts on open data sets, right, and how you think about that with manifold, and how that's guiding your principles, and how you think about manifold. Yes. So in order to have all of that data open source available, where not only can people add that data set to their data set, like what we see with open orca, and then open orca two, and then we have shared GPT and all these different data sets, right? And being able to do sort of sifting and searching through all of that, such that where the amount of data that you actually need to train the model is sample efficient. Right. I don't want to build a model that requires 100 million samples to learn something. I wanted to learn, just like me, I wanted to learn in ten samples.
05:20:59.936 - 05:21:43.970, Speaker A: Cool about this was the reasoning that they had to incorporate. It wasn't just a pure decoder, they had all these planning systems on top of it. Right. And if we can use something like self supervised learning, to where we can bring down the amount of data that is actually required to be able to train something to a specific use case, or to where it's more generic or widely available, this is the way that we're thinking about it. These very large models, these very large decoders are just very expensive to run. And I think that if we could build using self supervised learning, having sample efficient models where we don't need as much data, this is the way that we think about it. Yeah, cool, thank you.
05:21:43.970 - 05:22:18.600, Speaker A: And to continue pulling on that thread, I'm curious, how do you, Scott, think about synthetic know, that's, I guess we're kind of seguing into that domain in some ways. Right. So what are your thoughts there, or how you think about stability? Yeah, I think there's a lot of applicational use there effectively. We've done a few experiments in the past. Take stable diffusion. That's probably the most wanted model that we've released. Now have models across every major modality, like 140,000,000 downloads just on stability.
05:22:18.600 - 05:23:04.940, Speaker A: Official models on hugging face. There's like 350,000,000 derivative models built by community. And actually there's now like a lot of those derivative models. And our own core models are being fine tuned to effectively be focused towards specific use cases. So there was a healthcare model that effectively took, it was like 10,000 brain scans of individual patients and then effectively learned from those brain scans and created synthetic data off of those brain scans. And obviously then you start learning and doing like pattern recognition with machine learning to actually look at preventative cases of Alzheimer's and other types of health situations. So I think there's huge opportunity there.
05:23:04.940 - 05:23:53.300, Speaker A: I think the issue that we have right now is that effectively the outputs and knowledge retrieval are only as good as the training data that the models are trained on. So a lot of foundation model companies are going and acquiring, spending hundreds of millions of dollars acquiring high quality data sets, and it's not really sustainable. So any way that we can effectively create a new system which will allow more data to be generated, I think that's a good move. Cool, thank you. I just wanted to walk back a little bit and talk about sort of how we've gotten here from an open source and closed source perspective. Back in the day we had Microsoft. We thought Microsoft had won in some ways, but Linux is still everywhere.
05:23:53.300 - 05:24:20.272, Speaker A: We have iOS and Android as a comp. So where are we headed? Like, what is the trend looking like right now? Where do we think in steady state, 2024 is the year we embody AI. What's going to happen? I guess if we're sitting here at this conference next year, how much more is open source AI top of mind for folks, versus how much open AI is top of mind when it's not really open at all. So maybe, Casey, I'd like to start with you here, if that's okay. Not to put you on the spot.
05:24:20.416 - 05:25:04.370, Speaker C: Yeah. So I think just to start with something that I think is underrated is how reliant open source right now is on. Like, we would not be where we are today in open source if meta didn't do what it did. And there's like other players that are helping open source a lot too, like stability. I hope we come to a place where there are less points of failure in that we can run open source without having these tech giants behind us. There's just like one thing to put it out there in terms of who's providing compute, who's providing the researchers. And I think it's kind of a shame that the top researchers of our generation still have to work for these big companies.
05:25:04.370 - 05:25:41.436, Speaker C: I would love in one year if what happened to bitcoin, where the top BTC devs can just work on BTC core, that was the same dynamic and open source, and people could just contribute and just make that their living because that should be able to be rewarded. And I hope that in crypto we can design a structure in which they can do that. Yeah, I just think it's BS that these researchers are still working for Mark. Like, I don't like it, but, yeah, that's like my prediction. That's what I hope, at least. Maybe that's optimistic, but that's what I'm shooting for.
05:25:41.618 - 05:26:17.396, Speaker A: That's awesome. Scott, what do you think? I know, Ben, I'll turn it over to you after. Yeah, like, very excited for the think, you know, like smaller parameter models that are focused towards specific use cases. I think we saw with existing industrial revolutions, the last industrial revolution was digital revolution. Now this is the intelligence revolution. I think we're moving to a state where every single individual will have their own personalized AI, and we're really getting to that quickly. I'm running our latest language model on my mobile device now and on my Mac.
05:26:17.396 - 05:26:48.992, Speaker A: It's taking like six megabytes of VRam, so. Sorry, 600 megabytes of VRam. Not quite six. You can effectively. Not yet, but you can effectively run these on your own devices without the need for Internet. And because they've been trained, it's not compression, it's taking 100,000 images, like high quality super large images, and compressing into like a two gigabyte file. And what can you do with that? And I think the scale of that is profound.
05:26:48.992 - 05:27:32.256, Speaker A: And the applicational uses from that will be profound as well. Yeah, just jumping back to the open source piece, I think, Casey, you're absolutely right. The new protocol models and the things that we have in web three and crypto, I think, are the next generation of open source. I think open source changes, and it isn't going to be this kind of like altruistically funded. Well, altruistically, obviously there's incentives behind it, but it's ostensibly altruism that funds it. Right now, I think we're going to move to actual proper value flows for open source. So if you can build a business model that allows you to continue to create fully open source software, but actually fund the creation of that, I think that completely changes the world.
05:27:32.256 - 05:27:59.544, Speaker A: And I think that's what we have with crypto. I think that's kind of why it exists. And I think it flows all the way down as well. Like you were saying before, some of the bottlenecks are like the compute problem. If you're building open source models, you just can't get around that there is a base cost for compute. And I think that's where open source kind of levels up a little bit. It stops being just open source and it becomes, how can we actually have the minimum kind of value flows on top of a resource that has a base cost? And I think protocols are the way that you can do that.
05:27:59.544 - 05:28:36.212, Speaker A: So you can have the equivalent of open source over a resource that has a cost, and that equivalent is the freest market possible. As low to the resource as with. Obviously, we think a lot about gpus. Jensen's a GPU protocol, but just above the electricity right there at the hardware level is where you want the value to flow to. You don't want it to be captured by some company that's like way up the stack and prevents the actual owners of the hardware from being able to realize that. And I think when you do that, you get the minimal cost you can possibly have. It's not going to be zero because there is a base cost, but at least it's going to be low enough that it opens up the market.
05:28:36.212 - 05:28:40.484, Speaker A: And I think that's pretty exciting. And you can't do it without crypto, essentially, yeah.
05:28:40.522 - 05:29:12.076, Speaker C: I just want to do a plug if anybody's interested in this problem. I'm just a contributor for this new thing called AGI Guild, and this is exactly what it's trying to. Like, I'm not the only one working on, like, I'm just a contributor. But just this concept of how can crypto financialize open source in a way that keeps the beauty of it while also making it so these devs can work as independent people is like, if we solve that, that would be one of the greatest feats of this entire generation.
05:29:12.268 - 05:29:25.520, Speaker A: Yeah, can we talk about that for maybe just a couple more minutes? Which is. And maybe we'll get esoteric about licensing here, like Apache 2.0, GPL, MIT. But what are you going for here for AGI Guild?
05:29:25.600 - 05:30:14.320, Speaker C: Yeah, you want the pitch? Okay, so the pitch is that right now there's like three big licenses in software. The most prominent one is MIT license, which basically means you can take the software and do whatever you want with it. And that's great. But what's really happening is corporations like Google take people's software, use it for commercialization, build revenue off of it, and then the people who made the software get nothing. And so it's like this perverse incentive structure where we write the code because we want to write the code, but then it's not actually like a durable system. And I don't want to get into philanthropy, but it's like all of the research shows that you need to create systems. I don't want to go on a tangent here, but basically, you need to create systems that organically arise that can be self sustained.
05:30:14.320 - 05:31:02.576, Speaker C: We see this in all different types of markets, even philanthropy. That was the point there. But we need to do the same for software. And so when I think about that, and when we were thinking about this, the contributors were like, okay, well, what if we created a new license that would be powered by crypto, where you can create this incentive structure where people get paid in this token that we can more or less like we're creating it, right? And then that can be the way it actually works more tactically. Is anybody is free to use it. Any startup is free to use it because you want to promote innovation. But then if a company produces more than x in revenue, they actually have to stake the token to then use the software, because that makes sense, because they're the ones that are using it to monetize and create the revenue.
05:31:02.576 - 05:31:18.436, Speaker C: And so that should be given back to the developers. So that's like the basic mechanism design, and it's like very early days. If anybody again wants to contribute, come find me after. But we're trying to figure this out. We don't have the answers, but there has to be a better solution than the MIT license.
05:31:18.548 - 05:32:01.876, Speaker A: Yeah, I feel like the timeline from when we went open source competition, when it came to mainstream operating systems, to where we are today with models. I feel like, I guess the time period between sort of a closed source model and open source model has shrunk. But I think to your point, Casey, the big companies attract a lot of the talent. That's where a lot of the work and the research is happening. They're able to throw a lot of money at these folks to get this up and running. But I feel like up very quickly now, from an open source perspective, and I feel like the crypto blockchain primitives incentive mechanism is there for open source to be compensated in a way that we couldn't really viably do before. So excited for this initiative.
05:32:01.876 - 05:32:51.960, Speaker A: We'll try to learn more. Ben, you were mentioning trying to get as close to the wire as possible, and I think that's really interesting. But where does open source really matter? To you. I know how you feel about this, but I'm curious, does everything need to be decentralized open source? And I know there was another panel that we talked about this, but where do you fall on the spectrum? Are some things okay if it's closed source and are centralized? Obviously there's a two by two here, but, yeah, just curious to hear your thoughts on that. Yeah, it's a good question. I don't think the open source kind of protocol business model that we've talked about here works for every use case. I think it's kind of specific to certain things where there are base resources that can be monopolized and necessarily shouldn't be monopolized.
05:32:51.960 - 05:33:51.316, Speaker A: But, yeah, I think there's cases where you'll have proprietary technology for a company, which is why that company exists. I think when it gets difficult is when you have protections around those things from a centralized party. Right, where you end up creating artificial monopolies because you're stymying competition for some reason. I think in that case we actually just hold back human progress, and I don't think it's the right thing to do. But I think if you genuinely have some kind of edge as a business in a certain niche area, it makes sense for you to potentially keep that edge if it's not generally kind of like holding back society and stopping competition kind of by doing that. But if you had no kind of proprietary technology, you would have no kind of competition, so there'd be much slower progress. To me, it's how do we maintain humanity's progress without getting stuck in these kind of traps that we get with intellectual property rights, where some people just can't be disrupted for certain reasons, that actually it should be disrupted.
05:33:51.316 - 05:34:31.608, Speaker A: Like this should be free competition. That's what we're kind of trying to avoid, I would say. Thank you. Scott and Robert would love to hear your thoughts about how far up the stack do we need to think about open source and where do we need to draw a line? Yeah, I think to Ben's point, right at the sort of infrastructure layer for sure. So we're certainly focused towards being deploying and training open models as like a baseline primitive. We gave like 20 million a 100 hours to academia and research last year just to activate communities. Awesome.
05:34:31.608 - 05:35:19.844, Speaker A: And we expect to increase that this year as well. I think it's really around how do you elevate humanity, like using these models? I think that's one of the core focuses. Now these models are getting more sophisticated. They're actually requiring less compute on the training side, because you basically have communities that are taking them and optimizing them. We have chips across Nvidia, have tpus, like Gaudy two s with intel and various others. But they're all specific and can be optimized for doing specific tasks. Some are very good for doing large model training of image models, some are very good for doing inference workloads.
05:35:19.844 - 05:36:47.052, Speaker A: So I think effectively over time it's going to get easier and easier to train these models. Yeah. So I think that touching on when you were talking about operating systems, if you look at what happened with Windows and Linux, right, it ended up becoming a race to the bottom where two things are really important. It's cost and distribution and Linux, that's why it runs everywhere, right, is because it's free or cheap and it's easy to distribute. And so I think that AI is also entering this stage where it's a race to the bottom, right? And no matter where you go in the stack, if you're trying to drive the price to zero, what's going to really end up mattering is things like how much it costs to actually say, run that inference and then how much it's going to cost to distribute that inference, right? And I think that's where open source, if you look at the original peer to peer networks, like the super, like Napster, right, the first consumer peer to peer application, what was great about it, right, it was cheap and it was easy to distribute people's music and you could get their music and we can all share our music, right? But what's the downside? It's not secure. I'm downloading viruses all the time. And so I think what was really great about bitcoin is it said, hey, we're still going to be able to run a network, a financial network like this, right, very cheaply.
05:36:47.052 - 05:37:32.864, Speaker A: But what's great is now it's secure. It's secure. And so I think we're entering this now in this new third phase of peer to peer networks where we're not only going to get cheap and fast and secure, all three, the trifecta. If you look at how Spotify was able to disrupt Napster, it was on those three pillars. And so whoever wins, whether it's open source, whether it's Google, they're going to win on these three things. And so if you're out there right now trying to build an AI startup, if you're trying to build an open source AI business, I would focus on those things, distribution, getting into the hands of as many people as possible, making sure it's as cheap as possible. It doesn't need to make a profit as long as it breaks even, right? If you want to start a cloud business, you're not going to make any money.
05:37:32.864 - 05:38:04.616, Speaker A: The margins are razor thin. But over three years, once you depreciate it 100%, you'll own all this compute to train your models. So think about it in the same way Microsoft gives away their operating systems now, because if they didn't, then no one would. Windows is an obscure operating system for gaming and business applications. Everyone else uses Linux or macOS, anything that's Unix based. So this is where I see like in the stack. Whoever can do it cheapest, the fastest, and the most secure, that's who wins.
05:38:04.616 - 05:38:16.748, Speaker A: Oh, thank you. All right, we're coming up to the tail end here. So I have like one more question, which is, are we default open source moving forward? Is that sort of what comes to mind now, Casey, what do you think?
05:38:16.914 - 05:38:18.304, Speaker C: What do you mean by that?
05:38:18.502 - 05:38:49.400, Speaker A: If you were to start to build something anywhere in the stack, it could be the lowest layers, it could be an application. Are we thinking about either using open source software, building open source software, building on open source software, using open source models, like for example, for anyone here, or if you were to start something new? Am I thinking about OpenAI's closed models? Or am I thinking about how I embrace something that's open source? So from this point forward, I guess, should we be thinking default open source?
05:38:55.040 - 05:39:19.508, Speaker C: Okay, so I'll give you my answer as a realist and more of like pragmatic. Just like when I. I still use both. Like I use quanticized models locally, I use open source hosted, and I use GPT models all the time. It just depends on the use case and it depends on what you're optimizing for. To your point, it's like you're optimizing for privacy. Yeah.
05:39:19.508 - 05:39:48.328, Speaker C: Edge compute with Zephyr beta or open Hermes. Those are the ones I use and then whatever. For a lot of programming mvps, OpenAI is still the easiest LLM. I think that's going to start to shift. I think, though one thing also worth calling out is online. I think I see a lot of claims that open source is reaching parity with closed source. That's a really vast distillation.
05:39:48.328 - 05:40:08.548, Speaker C: That's not exactly intellectually honest. Right now. There are a lot of things that closed source is a lot better at, and we're going in the right direction. But even I, as like an open source advocate, I wouldn't say it's like one to one yet, but I think this could be the year.
05:40:08.714 - 05:40:57.030, Speaker A: Cool, perfect. Thank you. Yeah. Robert? Yeah, so personally I'm in very much the same situation where I'm using both kinds, right? Whether I'm using it on civil with an open source model that we put out or a Chat GPT right. But ultimately, whoever wins this right here is all going to be about who can get into the hands of the most people, right? And I think at the end of the day, I think the OpenAI's closed source, like their nonprofit, the LP, I think that's all been kind of figured out. I don't know, but we'll see. But Openais still, at the end of the day, once they've achieved, if they're able to capture on market share, they're certainly offering at a great price.
05:40:57.030 - 05:41:34.670, Speaker A: I think that compared to open source AI, right, once that model is out there, it doesn't cost the model creator anymore. Right? So I think based off those dynamics alone, I'm going to expect to see open source AI continue to take market share. But if OpenAI releases GPT five, that has a huge gap in performance. I could also see that being something that pulls people away. Cool. What do you think, Scott? Yeah, I think open beats closed over time, for sure. We definitely align and believe.
05:41:34.670 - 05:42:42.752, Speaker A: I mean, I think the next phase of this is you effectively have a whole entire population that's basically going to get access to this new technology. So effectively the market size is only going to increase. Obviously that is still relevant for proprietary enclosed models, but I think what you'll see is, and what we're seeing every day is just like community, taking these models and creating these incredibly sophisticated workflows from various models. And I think we're seeing it from taking language models and then applying it to their image and video and audio and all of the creation process happening there. And they're going to get easier to use and more available because effectively you can start having them on devices. So, yeah, still a big believer in the open source. Yeah, I'd probably just add one thing, which is I think we're going to see the emergence of a lot more platform risk around the closed models.
05:42:42.752 - 05:43:25.836, Speaker A: We've seen a little bit of it with the OpenAI ecosystem where once that was announced, a load of kind of AI startups were like, oh shit, that's my startup gone. Like OpenAI does it now. I think we're going to see more of that and it's going to be similar to how the social media landscape was where people were building on top of Facebook, and then suddenly Facebook's like, well, actually, I want that revenue. I'll just do it. I think we'll see the same, and I think it's going to push people towards open source, obviously, but at the same time, we've got open source becoming more and more powerful. I think we'll just see people organically move towards that end, essentially, we'll see people move over away from places like OpenAI to places where they can build the open models. We'll also see them be blocked.
05:43:25.836 - 05:44:16.112, Speaker A: Like OpenAI will just kind of shut down certain use cases that they don't like, and those people will naturally move over to open source alternatives. I think the kind of difficulty for the space, and this is maybe a bit of a counterpoint, is most spaces go through this kind of process where I guess the people outside of the current culture move to the open alternatives. We saw it in social media, where all of the decentralized social networks, they capture up all of the people who can't be on the centralized social networks. And that means that a lot of people in the current kind of zeitgeist or the current Overton window look at those decentralized alternatives or those open source alternatives, and they say, oh, that's just a place for the people who are kind of outside of the Overton window, where actually it's not. It's just that they've got nowhere else to go. So I think the space is probably going to have to go through that a little bit. We'll see some pretty crazy models in the open source arena.
05:44:16.112 - 05:44:36.840, Speaker A: We need to kind of remember that that's not representative of open source, it's just representative society. And it's the fact that they can't build anywhere else. So they go there and it'll look like they're overrepresented there, but it's just a kind of short term thing while people move over to open source. Awesome. Well, we'll drop the mic with that. But thank you all so much. Thank you, the audience, for sticking around.
05:44:36.840 - 05:48:16.180, Speaker A: And, yeah, follow these folks online because I'm sure they'll continue sharing amazing thoughts about open source and decentralization. So thank you again so much. Yeah, take care. Thank you. Okay, everybody, we are going to close things out with our last panel, early stage builders in crypto and AI. This panel brings together Elizabeth Downsty. She's the CEO and co founder of Compass Labs.
05:48:16.180 - 05:49:25.224, Speaker A: We have Mike Hanono, who's the founder of Talus. We have Will Healy, who's a co founder of Hum, Shoshank Yadav, who's the co founder at Fraction AI, and Matt Wang, who's the founder of Vanna. This panel is moderated by Jake Fartanian of the Mentac group, which is an early stage crypto fund. Let's welcome these panelists to the stage. So are they going to hype you up? All right, well, thank you, everyone, for sticking around for this panel. And I'm really excited to be up here with this great group of builders who are actively building at the intersection of crypto and web three and AI. And we've all already been introduced, so I guess we'll just get started.
05:49:25.224 - 05:50:33.404, Speaker A: And I guess the first question that I would ask, I'll leave this one open. What are some of the new possibilities that we can now build because of the intersection of web three and AI? Yeah, so I guess I can start off. So the way we're thinking about the intersection of web three and AI really is, I would say, like two pronged, and we kind of divide this intersection into two distinct subspaces. So the first one being integration of web three and AI, second one being integration of AI and web three. So first and foremost, integration of web three and AI. To us it means kind of building web three esque infrastructure for supporting AI workloads, such as inference or training. And the purpose for that is to build infrastructure that inherits the properties of a peer to peer network, including censorship, resistance, decentralization, permissionlessness, to build infrastructure that is inherently credibly neutral and is able to deliver unbiased results as well.
05:50:33.404 - 05:51:17.790, Speaker A: And that in a world where AI is slowly eating up, the world could be important, where centralized entities or private entities are trying to gain more market share to develop more closed source models. Having this kind of open source, credibly neutral platform where people can build and rely on unbiased sources for AI is important. And secondly, I think is a bit more interesting, which is integration of AI into web three. So that's taking AI and ML and using these models in ways to empower both existing and new use cases within web three. Right? So that could be on chain agents that could transact on chain or on chain algo trading or risk models within lending protocols on chain. And that's like an entirely new problem space in and of itself. And we're super excited to explore it.
05:51:17.790 - 05:52:16.284, Speaker A: Just to add to that, I like to keep web three and AI as a bit separate. So web three is really great to create financial models which incentivize creation of value on AI but AI itself can be trained separately, just powered by web three. Just to tack onto that, I think that the intersection of IP ownership is something which changes a lot. If you look at the landscape of large language models, specifically right now you have OpenAI getting sued by the New York Times. And going forward, the genie might be out of the bottle in terms of public data, and whether IP law can catch up with that is a different question. But I think going forward, if we have private data training models, then ownership becomes much more important in a trustless way. I think Matt hit it very well, detailed.
05:52:16.284 - 05:52:49.790, Speaker A: Like the both categories, I'm going to focus one on bringing AI to web three, where we could have a world of, let's say, smart agents that understand the blockchain world much better than we do, and they could abstract all of the complexities in terms of like bridging or trading or flash loans or whatever it may be, for any newcomer to easily just type a question, type an intent, and then have a network of intelligence solvers in the back end to optimize for users in terms of liquidity, outcome, whatever it may be.
05:52:54.560 - 05:53:40.190, Speaker C: Yeah, I guess I completely agree with you guys. I see a lot of potential in the application of AI on chain, in the sense that for the first time we're working with a completely programmable industry that is yet to be completely optimized. And I think using AI or for example agent based learning to do this is something that isn't as well possible in other industries that aren't completely programmable as what we can see in blockchain based systems. And I think there is a huge potential there to really optimize the systems such that we are all able to use them in a super efficient and effective way.
05:53:42.160 - 05:54:42.272, Speaker A: And so on the note of kind of optimizing for a new industry. Mike, I know you just announced talus today and are focused on building the move VM as the base layer for processing these transactions. And so what makes the move VM better than traditional vms that we've seen using blockchain before? And what other types of changes to the infrastructure will be needed to make these AI applications run as effectively as possible? So one of our main focuses is to democratize AI through move. And we chose move because of three main reasons. First is security. Move enables more secure program designs. You have much less smart contract vulnerabilities in the VM by itself.
05:54:42.272 - 05:56:06.970, Speaker A: The second is parallelization, where you could have high throughput and many smart agents or many applications engaging at the same time. And third is the developer experience. And the program design move comes with an object centric model that not any other VM has at this point. And this enables and creates a framework for ownership, management of resources, whether it's like data, compute models, and even add a layer of monetization on top of it that easily enables developers to, in a very intuitive interface or program API, call it to manage all these models and build applications on top of them. So that's why we think move is going to be very powerful in the future and the framework on how we build applications on top of. And so I guess I would go to Elizabeth here and with some of these changes that we're seeing, or I guess just the pace of innovation and changes that we're seeing in building these applications, what are some of the dev tools that you're building to make the experience of understanding the data and using the data easier for a wider range of people?
05:56:08.460 - 05:57:26.550, Speaker C: Yeah, thank you. What we're building is a python interface for DeFi, right? So we enable our users to do data sourcing, simulation optimization, and eventually execution through a Python interface. So through this type of infrastructure, I guess it comes down to the point right now focusing on DeFi, but as a whole it was made to be like this open source finance for everyone, but because of the complexity, it kept very limited to a super tech savvy crowd. What we are doing is building the infrastructure to enable people to interact with DeFi through this Python interface. And I guess as a part of this, we have this agent based learning software that runs on blockchain forks to really enable our users to model the entire DeFi ecosystem through adaptive participants and for the first time be able to do risk management, do simulation, do optimization through Python without the need of any type of blockchain engineering expertise or solidity for that matter, and be able to operate on chain and have the tooling available that is required to do that in a secure and reliable way.
05:57:28.280 - 05:58:06.688, Speaker A: Yeah, I think it's definitely a good mission to be focusing on how do we make the developer experience who wants to develop in this intersection just as good as possible. Because a lot of people who develop in crypto aren't necessarily like AI experts or ML experts, and this is kind of like a mission we share as well. Right? How do we make developing AI super easy, where inferencing could be a simple function call or training? You have a good framework or devtooling for it, in our view. I think we want to make this as seamless as possible. ZK, as an example, comes with such a high level of developer complexity. Not a lot of people in this world understand ZK in and out. Right.
05:58:06.688 - 05:58:30.520, Speaker A: To utilize these frameworks at a high level is still very difficult, and that's one of the missions we have, which is kind of abstracting a lot of these developer complexities behind the scenes. So it's a simple interface to use it, and you can trust that the architecture and the infrastructure will trustlessly do its job and be able to accelerate developer velocity within this intersection.
05:58:31.420 - 05:59:16.970, Speaker C: Yeah. Just to add on that, I think that becomes especially relevant in the case that, say, you're indeed what we discussed earlier, like, you're a smart contract developer, you have parameters that you want to optimize in your smart contract. You want to be able to understand how you should optimize them in the perfect way. But then, indeed, as you say, you want to ensure that, for example, the users of your protocol are also understanding that what you're doing is correct and the way you've said you've done it. And I think that entire infrastructure that is required to go from step one of modeling to step two executing is something yet to be built and what all of us are working on right now.
05:59:18.060 - 06:00:19.950, Speaker A: Yeah, and just to point out historical examples for these cases, had the libraries like Tensorflow or Pytorch been only in c, we wouldn't have seen as much adoption of AI as we have seen so far. So having those in Python is what exactly accelerated the AI revolution. And we need that thing for the decentralized AI as well. So I guess when we think about using or building AI models, the foundational thing that we need to run the models is data. What are some of the challenges of getting the best possible data, and how do we make sure that it's all formatted in the right way to run the best possible models and know that we can actually trust the data as well. Yeah, sure. So generative AI has been talk of town for like a few years now, and all generative AI models need a lot of data for training.
06:00:19.950 - 06:01:38.548, Speaker A: But labeling companies still work in an efficient manner, in an inefficient manner. So the way it works is an AI company will go to a labeling company, ask for a specific data set, wait for a few months, and then get the data set that they wanted. And the costs are really high because the data set are being created specifically for a single company. And that's like a boutique approach, but using web three, we can create financial structures which allow us to create those data sets beforehand. So we call those perpetual data sets perpetual, because they are always being created, and they are created proactively. So whenever a company or anyone who wants to train a model needs data, they can just directly tap into the data source, get it instantly and at lower costs, which is a win win for everyone. Um, so I guess then at the, once we get to the user level, what could it look like for just an average user to, how could they interact with these data sets in terms of providing new data, cleaning old data, and what are the types of new ways that people will be able to earn money or new types of jobs that will be created because of the rise of this technology? Yeah, absolutely.
06:01:38.548 - 06:02:21.810, Speaker A: So, as I mentioned before, IP law is unable to really catch up with these generative language models. If you look at OpenAI right now, they're afraid to use sora on real people because of IP concerns. So people are really getting a lot more concerned to let their data leak out. So one of the things that we're trying to do at hum is to flip the script and actually incentivize people to upload their own data in a manner where they know they control it. If they want to turn off their chatbot or some equivalent model that was run on them, they should have the right to do so. Additionally, the more that people interact with this model, there should be some trustless mechanism to actually pay the IP owner and the model developer who developed the model. So I think that kind of answers the question.
06:02:21.810 - 06:03:33.684, Speaker A: When I add to that, there's an interesting problem where you could have, let's say, an artist who's the owner of the data, who has the IP, and at the same time, that person doesn't even know how to build a model to monetize it. And then on the other side, you have the scientist who's the guy who's like an extreme mathematician and know how to build all these models and can build all these applications. I think it's very interesting, and for sure we're going to see it soon. And this is something that talos would hopefully enable, is a way of putting the data from an artist with the math of the scientist to create a model or an output that is monetizable by whoever user or whoever application wants to use it. And enabling those two to come together, I think will enable new use cases and new applications to come on board. Kind of touching on the topic of data. I think it's also important to recognize that in addition to training data and high quality training data that users could submit as part of the training process, I think something that we are really starting to realize is also quite important is the provenance of artifacts that result from execution of inference.
06:03:33.684 - 06:04:58.100, Speaker A: Right? So, for example, how can I provably know that some model produced some output in the ML workflow process? A lot of artifacts are often generated that often indicate, hey, this is kind of like the in sample, out of sample, kind of like test results of this model. This is, for instance, maybe like the ZKML or OPML, like fraud proof or snark that was generated from this inference. These were the inputs. This is the model. And I think as we are developing in a world where AI is gradually getting more and more important, it's important to kind of understand these kind of mediums of storage of data in a way that preserves this data provenance property. And that's something we're working on as well, using kind of decentralized storage layers to store these artifacts, to make it so that the inference, as well as the execution of the inference for these models are truly made decentralized and available to anyone that wants to verify the results. And so, if we focus in on something just like the defi space right now, how will these models improve the applications that currently exist? How much more efficient can we make things? Can we lower fees? Can we make trading? How much more efficient?
06:05:00.600 - 06:06:57.476, Speaker C: Yeah, I think it's an interesting question, because where I think, for example, agent based learning comes in extremely powerful, especially in DeFi. For example, say you're a smart contract developer and you're building an amm, or you're building a lending borrowing protocol, and you want to understand risk management, right? One of the things that you need to do is understand how different parties can interact with your smart contract. So you need to, for example, be able to run thousands of simulations against your smart contract to understand how it behaves under different market scenarios, such that depending on the economic circumstances, your smart contracts can respond to that, basically. So, one of the things that we see is very powerful in the infrastructure that we provide is, rather than what we see right now, is that a lot of lending, borrowing protocols and other exchanges are using consultancy firms to do optimization for their protocol. What we think is there should be a shift in this paradigm where protocol researchers, smart contract developers, have the tooling to do that kind of optimization in house and really optimize and understand the dynamics of their smart contracts to make them as efficient and as powerful as possible. Such that, for example, say what you're saying, a fee structure should jet change, for example, with the variance of the price, should that change with the amount of liquidity that is in the protocol, those kind of things are things that should be modeled beforehand. And for example, weights could be adjusted to make those systems more efficient and to make them, for example, more easily usable for a liquidity provider.
06:06:57.476 - 06:06:59.244, Speaker C: In DeFi, for example.
06:06:59.442 - 06:08:28.410, Speaker A: Yeah, no, I definitely agree that a lot of optimization, there definitely is a lot of room for optimization, especially if you draw comparisons between existing DeFi and tradfi. Right. In tradfi you have all these quant funds building sophisticated models for risk management for calculating how much spread to quote on the market, whereas in Defi you kind of lack a lot of this sophisticated compute and intelligence. And in that way, I definitely agree with you that there is just so much room for kind of optimization on this front, but kind of going on to the second layer, which is how do we create a system that allows DeFi to take advantage of sophisticated modeling as an example, which is one problem that we've thought a lot about at vano. For these high leverage, high impact use cases, there comes a strong demand for verifiability, right? For instance, if I am going to rely on the model output, determine how much I'm going to trade or at what price I'm going to trade or how I'm going to manage my risk for a lending protocol, then verifiability becomes very important because if the result is bogus, then I would open myself up to adversarial attacks on my protocol where people can just give me bs and I wouldn't be able to differentiate that from a real output of a model. So focusing on ZKML and OPML and verifiable inference for these high leverage and high impact use cases is something we're definitely thinking a lot about to really take DeFi to the next step and compete on the same level that tradfi plays at.
06:08:28.780 - 06:09:11.060, Speaker C: Yeah, and I think one of the interesting to make the comparison to like for the first time, users in DeFi don't have to make any guesses of, for example, underlying exchange mechanics, right? It's open source, it's written in code. And so indeed, what you're saying to be able to optimize that open source code and what you're working on, for example, on the inference side is something that I think protocol researchers and smart contract developers should be able to do in house. And the infrastructure that is necessary is currently being built, which I think is going to make a big shift in the onboarding and the usage of decentralized systems.
06:09:12.200 - 06:10:25.912, Speaker A: And yeah, just to add to that, verifiability is really important if you want to increase the adoption of third party models or agents, because if you don't really know how a model was trained or what his outputs are expected to be, there is no explainability, and you can't really use those kind of models, especially for financial decisions. So yeah, verifiability is a must. It's not a nice to have thing. I agree that in some use cases, verifiability is a must, but I think verifiability is also a spectrum. Like it's fully verifiable, then that could be CKML, and then you could have, let's say, OPML in the middle, and then on the other side you have no verifiability. Where do you think is the caught up in terms of what application, in terms of cost verification, or let's say time or computer, how much it takes? How do you think we could create a framework to understand? Okay, so what applications really need to be verified versus what applications, it doesn't really need to have a verification because the model output works to some extent. I think that's actually a great point, and I do very much agree that verifiability is a spectrum.
06:10:25.912 - 06:10:59.364, Speaker A: And depending on the use case, you don't necessarily need the highest level of verification. Right. Because with ZKML as an example, the proverbial overhead is massive, and you can't really prove inference for huge llms because the computational cost simply just is too high. And I think that's a great point that you brought up. I think ultimately, the way we're thinking about it at Vana is designing multiple interfaces for ultimately, the developers of the application to choose themselves. Right. If I'm building a high leverage use case, DeFi as an example, I want immediate and high verifiability through ZKML.
06:10:59.364 - 06:11:44.622, Speaker A: Right. If I'm doing something such as, hey, I'm generating the output of, if I'm running a stable diffusion model, generate like an image for an NFT, verifiability might not be that important, and it's simply probably not worth the computational cost. Right. So we want to have kind of these flexible interfaces that adapt to kind of people's use cases and developers use cases. So that really the trade off makes sense. And so I guess I would direct this towards Shashenko. What are some of the non financial use cases that you have been collecting data sets for, and what is the process of collecting that data and making sure that it's all labeled in the correct way? Yeah, sure.
06:11:44.622 - 06:12:26.958, Speaker A: So the biggest data set that we have been targeting right now is text to video, since you all must have used Sora by OpenAI. And so a lot of companies are trying to train those kind of models and actually to create something that is usable by public needs, like a billion videos. And multiple companies can make use of those videos. So once such a data set is created, it is useful for multiple companies. And, yeah, so that has been our focus so far. And even within that, we are more specifically focused on animated videos. So government of Japan has allowed using all public data sets to be used for training all the anime videos.
06:12:26.958 - 06:14:10.030, Speaker A: So we started with that, gave our users an interface where they can mark the starting point, ending point, and describe whatever is there in that video. And, yeah, that data set can be used to train any AI model for text to video. Would you like to add to that, will? Yeah, I think that going forward, if you look at the way that people can actually make money off of the AI revolution, unless kind of building off of what Mike said, unless you're an engineer or have equity in tech, it's very different or it's very difficult. And I think that sort of this new form of data, and user generated data in particular, really liberates people to not have that technical moat, to really monetize their own data. Okay. And so I guess I'd like to turn it now towards what are some of the challenges that you all are finding in building in the AI space in just day to day? What are some of the things that are really missing right now? And are there any tools that you're building that you see as kind of key pieces to solving some of these problems? And this is going to be a bit naive, but I think the space is too early that we're missing a lot of, let's say, direction, because right now probably everything makes sense, right? Like all the solutions, all the potential use cases. And I think it's going to be a hopefully short way until we find what really makes sense and all the frameworks that we should build upon.
06:14:10.030 - 06:14:43.180, Speaker A: For example, the crypto and AI primer that came out like two weeks ago, that's a very interesting, useful explanation and extends to, Matt, the framework that you were saying. It's like, okay, now we can think about crypto and I in certain ways. And I think creating that mind churn, like spreading that type of knowledge and not just saying like, oh, AI crypto is a narrative of this bull market and thinking a bit long term in terms of what are the fundamentals is going to be a big challenge. And we're slowly seeing it more and more, and hopefully you're going to get there.
06:14:45.390 - 06:16:20.840, Speaker C: I agree with you that the AI crypto narrative seems like to be defined. What is going to be the biggest thing, I guess, in terms of your question, where do we see ourselves coming in? I think one of the big issues with crypto as a whole, and defi in particular, is the interaction and the capability of people to use it. And I think that's why when we started off, for example, we wanted to do dynamic liquidity provisioning on Uniswap, which should be something that you can do in like a couple of hours, as for example, a Python programmer working in a trading firm or trying to do a weekend project. What actually turns out to be, it's so complex that to set up the systems from data sourcing, testing your strategies and actually executing them on chain takes a year for a person to learn solidity, understand how to interact with RPc providers, all of these write smart contracts, all of these things. So I think what our goal at compass really is, is to onboard people by building the infrastructure to be able to do this through a Python interface. And I think in our case, where AI comes in or where modeling part I, so to say comes in is more in the sense that if we look into any other industry, the importance of simulations and complex networks is huge. And DeFi, or blockchain systems as a whole is no different in that.
06:16:20.840 - 06:16:39.310, Speaker C: And that is part of the infrastructure that we provide. But our goal really is to build an easy interface to DeFi. And we do that through building a python interface for defi where users can make use of every Python library to interact now with the blockchain.
06:16:39.730 - 06:17:44.974, Speaker A: Yeah, I definitely agree. There are research, like you said, running simulations and figuring out what modeling approach makes sense is definitely like a significant bottleneck in AI and crypto. And in addition to that, I would like to add, I think another bottleneck I would say that you briefly touched on is kind of like usage of deploying programs as an example in AI and crypto, where it's not immediately obvious how I would run some model in an on chain setting. Right? And one of the things that we're working on is, hey, how do we make this as modular and as composable as possible, right? Because essentially models should be seen in our point of view as building blocks, right? You might have some model query, some interchange data, get the price of some asset. That model then makes a price forecast. And within the smart contract you should be able to atomically then use that result inference. Another model and be like, okay, how do I intelligently execute this trade? By trading into this position at some point in time, and then maybe have another on chain risk model that controls the exposure of some agent to these assets.
06:17:44.974 - 06:18:39.770, Speaker A: Right. These are all things that should be seen as kind of like modular components. We don't think there is a supermodel that can be built that does everything, really. It's taking all these individual models that do individual things very, very well and being able to kind of composably put them together into a smart contract or into a program to do all these things on chain autonomously. And, yeah, building the infrastructure to support these things is something we're very interested and very much in the business of doing. I'll just add one big problem that our team has run into arises. I know this was the topic of the previous panel, but the differences in quality between open source and closed source models, specifically in large language models, if we're all trying to convert as many users as possible to this blockchain times web three space, it's very difficult to do so when the models, language models that we're using are significantly worse.
06:18:39.770 - 06:19:48.680, Speaker A: So I think that that's just another testament to the community standard to promote open sourcing. So I come from an AI background, so I look at it from the perspective of AI companies, and for them, quality, costs and time is what matters. And while crypto offers great way to create incentives and create financial systems around those incentives, it does have some overheads. So managing trade offs is one of the most important things we have figured out, because finally, we have to be competitive with the web, two companies as well, in providing the highest quality data at the cheapest price. And just quickly, on that point, how much can an average user earn today by providing data to your models that exist right now? Yeah, sure. So it depends on the kind of data sets you are providing. So, for example, if it's some specialized data set, like medical data, you can earn quite a bit of money.
06:19:48.680 - 06:20:40.448, Speaker A: And if it's something a bit simpler, like labeling videos, it really depends on the data set itself, but could be like ten cents, fifteen cents or $0.20, something like that. And labeling per video takes like a few seconds. So you can actually make quite a bit of money if you perform well. Okay, that is really exciting. And I think beautiful thing for people to be able to, a totally new way for people to earn money all over the world. I think we are at our 30 minutes mark, but I would leave it open to, if anybody has any other final points that they would like to discuss before we close it.
06:20:40.448 - 06:21:12.564, Speaker A: All right, go ahead. So this is sort of like an advice from experience when building something where your final clients are on the web two side. So you usually have the supply side and the demand side. I would suggest solving the demand side first and that will help you learn about your customer and iterate on your product better. So then you can add probably web three part more iteratively. So yeah, just from the personal experience could be different for everyone, but that has been the learning for me. Right.
06:21:12.564 - 06:22:16.628, Speaker A: Well, thank you all very much for participating this evening and thank you for sticking around everybody and have a good night. For everybody who stuck around and for the folks on the live stream, a huge thank you for making the inaugural decentralized AGI summit a huge success. The fun doesn't stop here though. We will be back in this space this Wednesday, the 20 eigth for sentient decentralized AGI revolution party. So be hanging out, enjoying good music, food from 10:00 p.m. On on the 20 eigth. So love to see you back here in a couple of days.
06:22:16.628 - 06:22:25.620, Speaker A: Thanks. Everybody's.

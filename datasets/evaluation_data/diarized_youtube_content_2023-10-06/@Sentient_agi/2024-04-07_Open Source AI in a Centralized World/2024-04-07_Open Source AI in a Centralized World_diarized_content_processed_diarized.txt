00:00:00.840 - 00:00:36.394, Speaker A: Next up, we have the panel, open source AI in a centralized world. Joining this panel, we have Ben Fielding, who is the co founder of Jensen, Scott Trowbridge, who is a vp at Stability AI, Robert Myers, who is the CEO and co founder of Manifold, and Casey Caruso, who is, among many things, an engineer. And this panel will be moderated by Anand Ayer, who is the Manchi partner at Canonical Crypto and a venture partner at Lightspeed.
00:00:51.194 - 00:00:51.890, Speaker B: You in the middle?
00:00:51.962 - 00:01:30.798, Speaker C: No, no, I'm good. This is perfect right here. All right, how are you folks doing? How's everyone doing out there? This is like hour six of this marathon summit, so thanks for sticking it out. I'm excited for this panel. I feel like there's a lot to talk about, and I had suggested that maybe all of us do a shot every time anyone mentions Gemini, but I think we should start with Gemini maybe, and just get a feel for how everyone's feeling about that. So, Casey, I'm curious if you've got any thoughts. I just want to go around here and like, you know, because open source is the topic du jour, maybe even for this panel right now.
00:01:30.798 - 00:01:39.334, Speaker C: And there's a lot that's happened with Gemini. So I'm curious, like, how do you process this? Where does this fall in your mind? Map of, like, open source AI decentralization?
00:01:39.454 - 00:01:47.436, Speaker B: Yes. I was almost late to this panel because I was on the phone with my old Google manager discussing Gemini. We did a little pow out with.
00:01:47.460 - 00:01:50.264, Speaker C: Our old team and they're still there, this manager.
00:01:51.684 - 00:02:31.608, Speaker B: So I was on with both my old managers. One is still there and one is actually just left stability. But yeah, so we used to work on this team called research systems. And a lot of what we did was not directly to Gemini, but like the post today on Twitter said, as everyone probably read, a lot of the work that we were doing internally all got fought in. And, yeah, I mean, I think that there's like people all across in the organization of how people are feeling. I think you have some people that feel like it is the worst thing to ever happen, and then the other people feel like we just kind of needed to see the other end of the spectrum to be able to come back towards something more centered. I will say, though, like the.
00:02:31.608 - 00:03:37.790, Speaker B: Probably the most potent thing that somebody said today on the call was that I don't know if anybody in the room has read these new papers called Mina from meta, but it's like these new, basically ways where for training llms, you obviously have, like, the unsupervised part and then the supervised part where you do the RL, we're basically making, like, incredible strides where the RL can basically be lightweight. And what that means in the end is that creating specialized models is gonna become a lot easier. And so, like, having these base models where we think they're going to be for everybody and solve every single use case just isn't even reasonable to think about. And so, like, the whole, you know, everybody can blow up about Gemini, but the reality is, like, we're trying to accomplish an impossible task with having this, like, one fits all or one size fits all. And it's just, like, gives us a lot of resolve as engineers to know we're making the strides that we're gonna be able to have these specialized models that are feasible from an engineering standpoint. So that's how I feel about the whole thing. Sorry for the tirade.
00:03:37.862 - 00:03:45.358, Speaker C: No, that's great. Thanks for that background. You've got such great experience having been at Google, so. Yeah, thanks for that, Robert. Take it away.
00:03:45.526 - 00:04:23.414, Speaker D: Yeah. So I think that, at least on the technology side, Gemini is very interesting. It's nothing that I guess, is particularly new, besides the fact that there's not a particular special encoder for the modality. So it's all just fed straight in. So the technology side is very interesting. However, because it's closed source, we don't know things like the data that it was trained on, how exactly the exact sizing, you know, and the exact training run that was, that took place. Whereas if Gemini was open source, if we had undesirable features of that model.
00:04:23.414 - 00:05:18.664, Speaker D: In fact, a really cool paper I was reading earlier is Yao et al. The V two, just came out that talks about, as an alignment strategy, having a language model be able to unlearn certain things, unlearn certain undesirable things that the user wants. And so if it were open source, we would be able to make these different strains of the model, we would be able to know the data set, and so we'd be able to get to what actually caused these particular issues much quicker and in a crowd sourced way. So I think that this is one of the ways where open source can really shine based off of what some might classify as a misstep, others might classify as poor marketing or pile on effect. But ultimately, when the technology is in the power of the user, the user can make the informed choice for themselves, and that's the premise and power of open source.
00:05:19.244 - 00:05:20.144, Speaker C: Thank you.
00:05:22.204 - 00:06:29.774, Speaker E: Yeah, I think it was a great example of why we need open and fully auditable, like data sets. So, you know, effectively datasets that are being inclusive of unwanted biases, and from that you do get effectively undesirable outcomes and outputs. I think to, in fairness of the model, I think it's fixable. It's effectively more like over prompting, engineering and filtration put in place, as opposed to, like, actual, like, model training and the data involved there. So, yeah, I mean, it was a really good example of just showing, like, why you need effectively, even like, country cultural focused datasets, you know, effectively looking at ways of the community and participants of those models, the outcomes of that model, of those outputs, of those models. Actually having participation within those datasets is going to become fundamentally important. It can't just be an entity that's effectively choosing which data to train these models on.
00:06:30.394 - 00:06:52.242, Speaker C: Thank you. By the way, I don't think we did justice, but it's really awesome to have you here representing stability because this is largely a crypto focused conference, but the fact that we can hear from you and the fact that stability has been a pioneer with open source models, it's awesome to hear from you. Thanks everyone, but also to you for joining us. But Ben, what do you think?
00:06:52.378 - 00:07:32.268, Speaker F: Yeah, I mean, there's not much more to say, but I strongly agree with the point around countries should be able to build their own models. Right. This is, I think the Gemini stuff is in some ways very good that it's happened so early, because it just demonstrates that so clearly, like, we can't have one voice building models and everybody using those singular models. It has to be representative of the whole of society and not just a really small subset. And I think the only way to solve that is to open out the tools to build those models. We need to give the ability to build language specific models, culture specific models to everyone, so that we can have the Gemini model should exist. Some people will use it, some people will want to use that model.
00:07:32.268 - 00:08:00.264, Speaker F: A lot of people won't want to use it. But I wouldn't say that we should not allow it to exist. It's just that we should allow all of the other ones to exist as well, and even the ones that go culturally in completely the opposite direction. I think there's a right for those to exist and represent society. Otherwise, we're just kind of kidding ourselves. We're like, I described it earlier to somebody as, like, these models kind of hold up a mirror to society. And I think what Gemini has kind of done is just like, drawn a happy face on that mirror, and it's just like, no, look, it's fine.
00:08:00.264 - 00:08:14.728, Speaker F: Like, it reflects us perfectly when actually there's some ugly stuff there when you look at the data of humanity. And like, we kind of need to embrace that rather than pretend it doesn't exist. So I think we just build more models, basically, Casey.
00:08:14.856 - 00:09:01.291, Speaker B: Yeah, so I completely agree. But the problem is, like, to make an analogy, it would be as if we had one website and we're like, everybody use this one website for everything. And then when it doesn't solve a use case, people freak out. The problem is that there are so many tailwinds where economies of scale are impacting who can build websites, where the problem with open source is like, we don't have access to free compute, we don't have access to these data sets. And so naturally, these data monopolies that have in the past owned the Internet now have a step up in building these llms. And so it's like, the question to me is like, how the fuck do we level the playing field so open source can actually proliferate? And so then, I mean, there's a lot of solutions. I think stability is doing a really good job thinking through this.
00:09:01.291 - 00:09:12.684, Speaker B: A lot of everybody here probably is, but that's the problem that we're facing right now. That's why Google is ahead, is because they have the underlying resources, and we're already starting to see the problems that come from that.
00:09:13.824 - 00:09:25.444, Speaker C: I wanted to riff on that, Robert, just wanted to get your thoughts on open datasets and how you think about that with manifold and how that's guiding your principles and how you think about manifold.
00:09:26.584 - 00:09:26.960, Speaker B: Yes.
00:09:26.992 - 00:10:30.914, Speaker D: So in order to have all of that data open source available, where not only can people, like, add that data set to their data set, like what we see with like open orca, and then open orca two, and then, oh, we have shared GPT and all these different data sets, right? And being able to do sort of sifting and searching through all of that, such that where the amount of data that you actually need to train the model is sample efficient. Right? I don't want to build a model that requires 100 million samples to learn something. I wanted to learn, just like me, I wanted to learn in ten samples. Cool about this was the reasoning that they had to incorporate. It wasn't just a pure decoder. They had all these planning systems on top of it, right? And if we can use something like self supervised learning to where we can bring down the amount of data that is actually required to be able to train something to a specific use case or to where it's more generic or widely available. This is the way that we're thinking about it.
00:10:30.914 - 00:10:46.062, Speaker D: These very large models, these very large decoders are just very expensive to run. And I think that if we could build using self supervised learning, having sample efficient models where we don't need as much data, this is the way that we think about it.
00:10:46.118 - 00:11:01.784, Speaker C: Yeah, cool, thank you. And to continue pulling on that thread, I'm curious, how do you, Scott, think about synthetic data? Because I guess we're seguing into that domain in some ways. What are your thoughts there and how you think about instability?
00:11:01.944 - 00:12:05.710, Speaker E: Yeah, I think there's a lot of application use there effectively. We've done a few experiments in the past, so take stable diffusion, that's probably the most. One model that we've released now have models across every major modality, like 140 million downloads just on stability, official models on hugging face. There's like 350 million derivative models built by community. And actually there's now like a lot of those derivative models and our own core models are being fine tuned to effectively be focused towards specific use cases. So, you know, there was a healthcare model that effectively took, it was like 10,000 brain scans of like individual patients, you know, and then effectively learned from those brain scans and created synthetic data off of those brain scans. And obviously then you start learning and doing like pattern recognition with machine learning to actually look at preventative cases of like, you know, Alzheimer's and other types of health situations.
00:12:05.710 - 00:12:39.684, Speaker E: So I think there's huge opportunity there. You know, I think the issue that we have right now is that effectively the outputs and knowledge retrieval are only as good as the training data that the models are trained on. So a lot of foundation model companies are going and acquiring, you know, spending hundreds of millions of dollars acquiring high quality datasets and it's not really sustainable. So any way that we can, you know, effectively create a new system which will allow more data to be generated, I think that's a good move.
00:12:40.894 - 00:13:20.930, Speaker C: Cool, thank you. I just wanted to walk back a little bit and talk about sort of the, how we've gotten here from an open source and closed source perspective. There was back in the day we had Microsoft. We thought Microsoft had won in some ways, but Linux is still everywhere. Then we have iOS and Android as a comp. So where are we headed? What is the trend looking like right now? Where do we think in steady state? If 2024 is the year we embody AI, what's going to happen? I guess if we're sitting here at this conference next year. How much more is open source AI top of mind for folks versus how much open AI is top of mind when it's not really open at all? Maybe.
00:13:20.930 - 00:13:24.226, Speaker C: Casey, I'd like to start with you here, if that's okay. Not to put you on the spot.
00:13:24.410 - 00:14:26.912, Speaker B: Yeah. So I think just to start with, something that I think is underrated is how reliant open source right now is on meta. It's like we would not be where we are today in open source if meta didn't do what it did. And there's other players that are helping open source a lot too, like stability. I hope we come to a place where there are less points of failure in that we can run open source without having these tech giants behind us. There's just one thing to put it out there in terms of who's providing computers, who's providing the researchers, and I think it's kind of a shame that the top researchers of our generation still have to work for these big companies. I would love in one year, if what happened to bitcoin, where the top BTC devs can just work on BTC core, that was the same dynamic in open source, and people could just contribute and just make that their living, because that should be, be able to be rewarded.
00:14:26.912 - 00:14:45.324, Speaker B: And I hope that in crypto we can design a structure in which they can do that. Yeah, I just think it's b's that these researchers are still working for Mark. Like, I don't like it, but, yeah, that's like my prediction. That's what I hope at least. Maybe that's optimistic, but that's what I'm shooting for.
00:14:45.664 - 00:14:49.524, Speaker C: That's awesome. Scott, what do you think? I know, Ben, I'll turn it over to you after that.
00:14:50.344 - 00:15:27.020, Speaker E: Yeah, very excited for the future, I think. You know, like smaller parameter models that are focused towards specific use cases. I think we saw with, like, existing industrial revolutions, the last industrial revolution was digital revolution, you know, now this is the intelligence revolution. I think we're moving to a state where every single individual will have their own personalized AI, and we're really getting to that quickly. You know, like, I'm running our latest, like, language model on my mobile device now and on my Mac. It's taking six megabytes of VRam. Sorry, 600 megabytes of vrAm.
00:15:27.020 - 00:15:56.104, Speaker E: Not quite six. You can effectively. Not yet, but you can effectively run these on your own devices without the need for Internet. And because they've been trained, it's not compression, it's taking 100,000 images, high quality, super large images and compressing into a two gigabyte file, and what can you do with that? And I think the scale of that is profound. And the application uses from that will be profound as well.
00:15:58.364 - 00:16:38.036, Speaker F: Yeah, just jumping back to the open source piece, I think, Casey, you're absolutely right. The new protocol models and the things that we have in web3 and crypto, I think are the next generation of open source. I think open source changes, and it isn't going to be this kind of altruistically funded. Well, altruistically, obviously there's incentives behind it, but it's ostensibly altruism that funds it. Right now, I think we're going to move to actual proper value flows for open source. So if you can build a business model that allows you to continue to create fully open source software, but actually fund the creation of that, I think that completely changes the world. And I think that's what we have with crypto.
00:16:38.036 - 00:17:15.760, Speaker F: I think that's kind of why it exists, and I think it flows all the way down as well. Like you were saying before, some of the bottlenecks are like the compute problem. If you're building open source models, you just can't get around that there is a base cost for compute. And I think that's where open source kind of levels up a little bit. It stops being just open source and it becomes, how can we actually have the minimum kind of value flows on top of a resource that has a base cost? And I think protocols are the way that you can do that. So you can have the equivalent of open source over a resource that has a cost, and that equivalent is the freest market possible, as low to the resource as possible. So, like, obviously we think a lot about GPU's.
00:17:15.760 - 00:17:44.554, Speaker F: Jensen's a GPU protocol, but just above the electricity right there at the hardware level is where you want the value to flow to. You don't want it to be captured by some company that's way up the stack and prevents the actual owners of the hardware from being able to realize that. I think when you do that, you get the minimal cost you can possibly have. It's not going to be zero because there is a base cost, but at least it's going to be low enough that it opens up the market. I think that's pretty exciting. And you can't do it without crypto. Essentially, yeah.
00:17:44.594 - 00:18:16.046, Speaker B: I just want to do a plug. If anybody's interested in this problem, I'm just a contributor for this new thing called AGI Guild. And this is exactly what it's trying to do. It's like, I'm not the only one working on it. I'm just like, I'm just a contributor. But just this concept of, like, how can crypto financialize open source in a way that keeps the beauty of it while also making it so these devs can work as independent people is like, if we solve that, that would be one of the greatest feats of this entire generation.
00:18:16.230 - 00:18:29.470, Speaker C: Yeah, can we talk about that for, like, maybe just a couple more minutes? Which is. Yeah, and maybe we'll get esoteric about licensing here, like Apache 2.0, GPL, MIT. But what are you going for here for AGI Guild?
00:18:29.582 - 00:19:18.258, Speaker B: Yeah, you want the pitch? Okay, so the pitch is that right now there's, like, three big licenses in software. The most prominent one is MIT license, which basically means you can take the software and do whatever you want with it. And that's great. But what's really happening is corporations like Google take people's software, use it for commercialization, build revenue off of it, and then the people who made the software get nothing. And so it's like this perverse incentive structure where we write the code because we want to write the code, but then it's not actually, like, a durable system. I don't want to get into philanthropy, but it's like, all of the research shows that you need to create systems. I don't want to go on a tangent here, but basically, you need to create systems that organically arise that can be self sustained.
00:19:18.258 - 00:20:06.590, Speaker B: We see this in all different types of markets, even philanthropy. That was the point there. But we need to do the same for software. When I think about that, and when we were thinking about this, the contributors, we're like, okay, well, what if we created a new license that would be powered by crypto, where you can create this incentive structure where people get paid in this token that we can more or less, like, you know, we're creating it, right? And then that can be the way it actually works. Like, more tactically is anybody is free to use it. Any startup is free to use it because you want to promote innovation. But then if a company produces more than x in revenue, they actually have to stay the token to then use the software, because that makes sense, because they're the ones that are using it to monetize and create the revenue.
00:20:06.590 - 00:20:22.390, Speaker B: And so that should be given back to the developers. So that's like the basic mechanism design. And it's like very early days. If anybody again wants to contribute, come find me after but I mean, we're just, we're trying to figure this out. We don't have the answers, but there has to be a better solution than the MIT license.
00:20:22.502 - 00:21:05.704, Speaker C: Yeah, yeah, I feel like the timeline from, like, when we went, you know, open source competition when it came to mainstream operating systems to where we are today with models, I feel like, I guess the time period between sort of a closed source model and open source model has shrunk. But I think to your point, Casey, like, we attract the big companies, attract a lot of the talent. That's where a lot of the work and the research is happening. They're able to throw a lot of money at these folks to get this up and running. But I feel like we're catching up very quickly now from an open source perspective. And I feel like the crypto blockchain primitives incentive mechanism is there for open source to be compensated in a way that we couldn't really viably do before. So excited for this initiative.
00:21:05.704 - 00:21:35.222, Speaker C: We'll try to learn more. Ben, you were mentioning trying to get as close to the wire as possible, and I think that's really interesting. But where does open source really matter to you? I know how you feel about this, but I'm curious, does everything need to be decentralized open source? And I know there was another panel that we talked about this, but where do you fall on the spectrum? Are some things okay if this closed source or centralized? Like, obviously it's a two by two here, but yeah. Just curious to hear your thoughts on that.
00:21:35.398 - 00:22:19.670, Speaker F: Yeah, it's a good question. I don't think the open source kind of protocol business model that we've talked about here works for every use case. I think it's kind of specific to certain things where there are base resources that can be monopolized and necessarily shouldn't be monopolized. But yeah, I think there's cases where you'll have proprietary technology for a company, which is why that company exists. I think when it gets difficult is when you have protections around those things from a centralized party where you end up creating artificial monopolies because. Because you're stymieing competition for some reason. I think in that case, we actually just hold back human progress, and I don't think it's the right thing to do.
00:22:19.670 - 00:22:59.152, Speaker F: But I think if you genuinely have some kind of edge as a business in a certain niche area, it makes sense for you to potentially keep that edge if it's not generally kind of like holding back society and stopping competition kind of by doing that. But if you had no kind of proprietary technology, you would have no competition. There'd be like much slower progress. To me it's how do we maintain humanity's progress without getting stuck in these kind of traps that we get with intellectual property rights where some people just can't be disrupted for certain reasons that actually they should be disrupted, there should be free competition. That's what we're trying to avoid, I would say.
00:22:59.328 - 00:23:10.924, Speaker C: Thank you. Scott and Robert would love to hear your thoughts about how far up the stack do we need to think, think about open source and where do we, do we need to draw a line?
00:23:11.504 - 00:23:54.424, Speaker E: Yeah, I think to Ben's point, like right at the sort of infrastructure layer for sure. So we're certainly focused towards being deploying and training open models as like a baseline primitive. We gave like 20,000,800, 100 hours to academia and research last year just to activate communities. Awesome. And we expect to increase that this year as well. So, yeah, I mean, I think it's really around like how do you like elevate humanity, like using these models? I think that's like one of the core focuses now. You know, these models are getting more sophisticated.
00:23:54.424 - 00:24:30.654, Speaker E: They're actually requiring less compute on the training side because you basically have communities that are taking them and optimizing them. We have chips across Nvidia, have tpus, Gaudi, two s with intel and various others. But they're all specific and can be optimized for doing specific tasks. Some are very good for doing large model training of image models, some are very good for doing inference workloads. So I think effectively over time, like it's going to get easier and easier to train these models.
00:24:32.354 - 00:25:51.076, Speaker D: Yeah. So I think that touching on when you were talking about operating systems, if you look at what happened with Windows and Linux, right, it ended up becoming a race to the bottom where two things are really, really really important. It's cost and distribution and Linux, that's why it runs everywhere, right, is because it's free or cheap and easily, it's easy to distribute. And so I think that AI is also entering this stage where it's a race to the bottom, right? And no matter where you go in the stack, if you're trying to drive the price to zero, what's going to really end up mattering is things like your, how much it costs to actually like say run that inference and then how much it's going to cost to distribute that inference, right? And I think that's where open source, like if you look at the original peer to peer networks like the super, like, like Napster, right? The first consumer peer to peer application. What was great about it, right, it was cheap and it was easy to distribute people's, people's music and you could get their music and we can all share our music, right? But what's the downside? It's not secure. I'm downloading viruses all the time. And so I think what was really great about bitcoin is it said, hey, we're still going to be able to run a network, a financial network like this, right? Very cheaply.
00:25:51.076 - 00:26:29.880, Speaker D: But what's great is now it's secure. It's secure. And so I think we're entering this now in this new third phase of peer to peer networks where we're not only going to get cheap and fast and secure. All three, the trifecta. If you look at how Spotify was able to disrupt Napster, it was on those three pillars. And so whoever wins, whether it's open source, whether it's google, they're going to win on these three things. And so if you're out there right now trying to build an AI startup, if you're trying to build an open source AI business, I would focus on those things, distribution, getting into the hands of as many people as possible, making sure it's as cheap as possible.
00:26:29.880 - 00:27:04.470, Speaker D: Like it doesn't need to break, like it doesn't need to make a profit as long as it breaks even, right? If you want to start a cloud business, you're not going to make any money. The margins are razor thin. But over three years, once you depreciate it 100%, you'll own all this compute to train your models. So think about it in the same way Microsoft gives away their operating systems now, because if they didn't, then no one would. Windows is an obscure operating system for gaming and business applications. Everyone else uses Linux or Mac OS, anything that's Unix based. So this is where I see, like in the stack.
00:27:04.470 - 00:27:08.434, Speaker D: Whoever can do it cheapest, the fastest and the most secure, that's who wins.
00:27:08.794 - 00:27:20.722, Speaker C: Oh, thank you. All right, we're coming up to the tail end here. So I have like one more question, which is, are we default open source moving forward? Is that sort of what comes to mind now, Casey, what do you think?
00:27:20.898 - 00:27:22.130, Speaker B: What do you mean by that?
00:27:22.282 - 00:27:53.314, Speaker C: If you were to start to build something anywhere in the stack, it could be the lowest layers, it could be an application. Are we thinking about either using open source software or building open source software? Building on open source software, using open source models, like for example, for anyone here, or if you were to start something new. Am I thinking about OpenAI's closed models, or am I thinking about how I embrace something that's open source? So from this point forward, I guess, should we be thinking default open source?
00:27:55.654 - 00:28:02.030, Speaker B: I mean, I'm a little bit of a real. Okay, so I'll give you my answer as the realist and more of like pragmatic.
00:28:02.062 - 00:28:02.564, Speaker C: That's great.
00:28:02.654 - 00:28:30.780, Speaker B: Just like when I still use both. Like, I use quanta sized models locally, I use open source posted, and I use GPT models all the time. It just depends on the use case and it depends on what you're optimizing for, to your point. It's like, if you're optimizing for privacy. Yeah. Edge compute with like Zephyr beta or like open Hermes. Like, those are the ones I use.
00:28:30.780 - 00:29:02.984, Speaker B: And then whatever. For a lot of programming, MVP's OpenAI is still the easiest LLM. I think that's gonna start to shift. I think, though one thing also worth calling out is online. I think I see a lot of claims that open source is reaching parity with closed source. That's a really vast distillation that's not exactly intellectually honest right now. Like, there are a lot of things that closed source is a lot better at, and we're going in the right direction.
00:29:02.984 - 00:29:12.528, Speaker B: But even I as like an open source, you know, advocate, I wouldn't say it's like one to one yet, but I think this could be the year.
00:29:12.696 - 00:29:15.464, Speaker C: Cool. Perfect. Thank you. Yeah. Robert.
00:29:15.624 - 00:30:18.820, Speaker D: Yeah, so personally, you know, I'm in this very much the same situation where I'm using both kinds, right? Whether I'm using it on civil with an open source model that we put out, or a chat GPT. But ultimately, whoever wins this right here is all going to be about who can get into the hands of the most people. I think at the end of the day, I think the OpenAI is closed source. Their nonprofit, the LP, I think that's all been figured out. I don't know, but we'll see OpenAI still at the end of the day, once they've achieved, if they're able to capture on market share, they're certainly offering at a great price. I think that compared to open source AI, once that model's out there, it doesn't cost the model creator anymore. I think based off those dynamics alone, I'm going to expect to see open source AI continue to take market share.
00:30:18.820 - 00:30:27.544, Speaker D: But if OpenAI releases GPT five, that has a huge gap in performance. I could also see that being something that pulls people away.
00:30:27.704 - 00:30:29.760, Speaker C: Cool. What do you think, Scott?
00:30:29.832 - 00:31:30.624, Speaker E: Yeah, I think Openbeats closed over time for sure. We definitely align and believe that. So I think the next phase of this is you effectively have a whole entire population that's basically going to get access to this new technology. So effectively the market size is only going to increase. Obviously that is still relevant for proprietary and closed models, but I think what you'll see is, and what we're seeing every day is just community taking these models and creating these incredibly sophisticated workflows from various models. And I think we're seeing it from taking language models and then applying it to the image and video and audio and all of the creation process happening there. And they're going to get easier to use and more available because effectively you can start having them on devices.
00:31:30.624 - 00:31:35.564, Speaker E: So yeah, still a big believer in the open source.
00:31:38.524 - 00:32:21.030, Speaker F: Yeah, I'd probably just add one thing, which is I think we're going to see the emergence of a lot more platform risk around the closed models. We've seen a little bit of it with the OpenAI ecosystem where once that was announced, a lot of AI startups were like, oh shit, that's my startup gone. Like OpenAI does it now. I think we're going to see more of that and it's going to be similar to how the social media landscape was where people were building on top of Facebook. And then suddenly Facebook like, well, actually I want that revenue, I'll just do it. I think we'll see the same, and I think it's going to push people towards open source, obviously, but at the same time we've got open source becoming more and more powerful. I think we'll just see people organically move towards that.
00:32:21.030 - 00:33:03.802, Speaker F: To that end, essentially, we'll see people move over away from places like OpenAI to places where they can build the open models. We'll also see them be blocked. OpenAI will just kind of shut down certain use cases that they don't like, and those people naturally move over to open source alternatives. I think the kind of difficulty for the space, and this is maybe a bit of a counterpoint, is most spaces go through this kind of process where I guess the people outside of the current culture move to the open alternatives. We saw it in social media where all of the decentralized social networks, they capture up all of the people who can't be on the decentralized social networks. And that means that a lot of people in the current kind of zeitgeist. So the current Overton window.
00:33:03.802 - 00:33:33.604, Speaker F: Look at those decentralized alternatives or those open source alternatives and they say, oh, that's just a place for the people who are kind of outside of the Overton window where actually it's not. It's just that they've got nowhere else to go. So I think the space is probably going to have to go through that a little bit. We'll see some pretty crazy models in the open source arena. We need to kind of remember that that's not representative of open source, it's just representative society and it's the fact that they can't build anywhere else. So they go there and it'll look like they're overrepresented there. But it's just a kind of short term thing while people move over to open source.
00:33:34.784 - 00:33:48.936, Speaker C: Awesome. Well, we'll drop the mic with that. But thank you all so much. Thank you the audience, for sticking around. And yeah, follow these folks online because I'm sure they'll continue sharing amazing thoughts about open source and decentralization. So thank you again so much. Yeah, take care.
00:33:49.000 - 00:33:53.094, Speaker F: Thank you. It.

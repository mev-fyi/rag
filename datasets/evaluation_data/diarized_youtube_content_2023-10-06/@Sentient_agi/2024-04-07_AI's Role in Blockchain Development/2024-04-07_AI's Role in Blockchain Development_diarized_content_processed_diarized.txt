00:00:01.680 - 00:00:38.584, Speaker A: Okay, everyone, we're cruising into our next panel. It is AI's role in blockchain. Our panelists for this session will be Nouraj pant. He is a co founder of ritual, Nick Emmons, who is the co founder of Elora, Salman Avestemir, who is the co founder and CEO of FedML and the dean's professor at the University of Southern California. And we'll be rejoined by Himachu from sentient and Kenzie from symbolic capital. Come on stage.
00:00:55.064 - 00:01:37.114, Speaker B: All right, guys, this is my favorite panel of the day, actually. So I think this topic here is really important. I think we're at this crossroad of closed world versus open world, and we want to talk about the importance of blockchain and AI movement. And I think this is actually the biggest problem in our generation here. So my first question is to Himanshu. So what do you think is the role of blockchain incentive mechanism that can contribute or accelerate this AI model movement?
00:01:38.654 - 00:02:10.194, Speaker C: Yeah, so I can just continue from where we left in the previous talk. So at least I see this. I have fit in this model of evolution in my head. And evolution is all about rewards and what you get for being the better self or being the better one. And it's also about how people coordinate together to have that better form. And so AI incentives can first enable that coordination by appropriate incentives around some specific tasks, some specific goals. These models can be coordinated.
00:02:10.194 - 00:02:42.698, Speaker C: This demand can be coordinated around some specific goals. For example, just by OpenAI doing so well in LLM, a lot of innovation happened very quickly on conversational side, and it was not necessary that took over. There could have been other things just because that incentive coordination happened. Now suddenly you see 20,000 different embeddings available for just the language part of it. That's because of some coordination. Now, this thing can be turbocharged with crypto for many different things, number one. Number two is the part where crypto incentives can be extended to smaller teams in very different ways.
00:02:42.698 - 00:03:34.014, Speaker C: One thing which is missing in what's happening today is that when we think of AI, we think of $1 trillion gpu's, which are very expensive, and people building it who have 20 years of experience and 30 years of experience. I want to think of a world where people who are coming out of college are shaking these things, or maybe even high school kids are shaking these things. And this is where crypto incentives are very native to, that can be made very native to that population. And that's the competing force of innovation, who are not being hard bound in any of these existing things, which can be enabled through this. So the new innovators onboarding and then aligning the incentives with some broader goals, like LLM was one, but it can be music can be another one, vision can be another one. There can be multiple such things. And that's where I see this role of crypto for AI incentive ecosystem.
00:03:34.634 - 00:03:36.054, Speaker B: Neeraj, what do you think?
00:03:36.654 - 00:03:37.914, Speaker D: Can you repeat the question?
00:03:38.734 - 00:03:48.194, Speaker B: Yeah. So crypto offers this great incentive mechanism, and how do you think it can accelerate or crowdsource AI model development?
00:03:49.134 - 00:04:32.442, Speaker D: So to me, in 2023, 2024, the meta of AI is there are a lot of developers interested in building models. There aren't great ways to monetize those models or to build new products. The challenge with crypto AI today, and I guess AI in general, is that the monopolies hold all the distribution. If you're an average developer, you can't really talk to the power that, say, OpenAI has with chat GPT. So you're left in kind of a bind. You're left in a bad position where you're gonna have to go and get all the distribution yourself. So I really like what crypto is doing.
00:04:32.442 - 00:05:29.210, Speaker D: Crypto AI is doing where it's decoupling the development of the models with the distribution of who can actually access those models. That's a really big thing. The other thing is, as we're thinking about, the reality is a lot of people in the AI space are not paying attention to crypto AI, so how would they pay attention? And really, I think it's lean into the crypto stuff, lean into the incentives, lean into the transparency. And I believe that we can really bring millions of users into crypto through the lens of AI. Everyone in this room probably uses chat GPT, or maybe 70 or 80%, and that's a lot more users than we have in crypto today. So that, to me, is a very exciting value proposition. And in this idea of creating incentives, you know, you can do everything from crowdfunding models to paying for data to paying for compute privacy.
00:05:29.210 - 00:05:35.174, Speaker D: There's so many exciting avenues to go develop, which is why I am building this space and why I'm so excited about it.
00:05:35.834 - 00:05:49.546, Speaker B: That's amazing. So, Nick, I know Laura is building a self improving AI network. So when you build this decentralized network, how do you ensure safety and also mitigate risk management?
00:05:49.730 - 00:06:57.896, Speaker E: Sure. Yeah. So I think blockchains are a really useful tool in turning different nebulous resources into different digital commodities, whether it's compute, power, trust. I think when we think about AI, with what we're building with Allora and these self improving networks, is we can turn intelligence into a commodity as well. Instead of this sort of model centric paradigm, which is commonplace today, in which applications reference specific models or things like that, I think we should move to a sort of objective centric paradigm, or maybe an intense centric paradigm for nomenclature that's more familiar, in which you establish the objective function by which you care about AI's to be optimizing, and then establish market incentives such that many different AI's, many different ML models, can collectively optimize that objective function. And when you move to this objective centric paradigm from a model centric paradigm, it removes the, the sort of all encompassing control a single model can have in manipulating some application, or performing some malicious attack, or even just being incompetent in some domains. It creates an open market in which everyone's competing to optimize the thing that they really care about, this intent or this objective.
00:06:57.896 - 00:07:07.096, Speaker E: So I think we can build these kinds of systems that combat these sort of manipulations or malicious attacks by moving to this objective centric paradigm.
00:07:07.280 - 00:07:29.994, Speaker B: Awesome, Salman. And the next question is for you about FedML. That's becoming a key component for decentralized GPU network. So in that regard, how do you see this decentralized GPU's actually are able to be used for, in general, web two AI's and things like that?
00:07:30.334 - 00:08:02.274, Speaker F: Yeah, that's a great question. Exactly. That's what we do. Meaning in FedML, we provide a platform so you can bring in the demand on, let's say, building a model, running inference, et cetera, to decentralized GPU's. Okay, so we support multi cloud, we support decentralized GPU. But your question is on reality, what type of models can you run on it? The thing that I see is, in decentralized networks, there is a lot of quantity. Maybe one part that is lacking a bit is the quality of the GPU.
00:08:02.274 - 00:08:32.762, Speaker F: So for example, when you go to the cloud, you can easily access a 100 h 100. In decentralized GPU networks, maybe you get 4090 GPU's lower quality. So something to think about. As we want to position decentralized GPU networks to be the cloud for open source AI, we have to invest in the quality. The other side is the bandwidth. Like being in a rack in a data center, you can be connected in right now in ten terabits per second. Now imagine decentralized GPU.
00:08:32.762 - 00:09:11.448, Speaker F: You want to run it, and your connection is maybe gigabit per second. So that's where I think room for innovation. For example, in federated learning, in FeDML, we provide some solutions how to run with low bandwidth, but I think that will accelerate. Maybe a third. One I would mention is one big difference between centralized cloud and decentralized cloud is the regulation governing it. Right? So for example, let's say you want to put your model, you want to put your data on AWS, then there are sort of compliances that protect you. For example, there is SoC, two different type of mechanisms that you are sure your data is safe.
00:09:11.448 - 00:09:48.148, Speaker F: Now we come to decentralized cloud, like your data, your model is going to other people's computers. How would you then research wise, like you can protect it by homomorphic encryption, trusted execution environments, etcetera. Those methods, they won't work for generative AI because it's going to be various law they cannot have accommodates large models. So I think that's another layer to think about, the trust and security of decentralized cloud. So I would say quality communication, the trust layer, these are some of the bottlenecks we are seeing.
00:09:48.316 - 00:09:49.984, Speaker B: Do you have a timeframe for that?
00:09:50.684 - 00:10:21.274, Speaker F: So these, we actually currently do it. So we have a solution for each. For example, for the trust layer, you can think about software security, you can run things in a secure container. Software security works very well. It's not the idea, but in general that's a guarantee you can give for bandwidth. As I mentioned, we already have federated learning, runs it in low bandwidth environments for quality. We have engine that you can run inference on say 13 billion parameter models on 40, 90 GPU's.
00:10:21.274 - 00:10:44.334, Speaker F: So that's why currently, actually we run a lot of machine learning on decentralized GPU's. So we have developers using it, but we have to scale it up. Let's say you want to go to 70 billion parameter model, you want to get to 3 million active users on a specific model. So I think that's where the innovation needs to come in to push the scale to match. Let's say AWS.
00:10:44.754 - 00:11:12.844, Speaker B: Got it. Blockchain is a very powerful substrate for, can be a very powerful substrate for AI development. But you know, this token and incentive mechanism that come with it, there's a lot of fluctuation. So with that, you know, how, how do you think that, you know, a fair system can be established to ensure like stability of AI models? Let's start with you, Hemanshu.
00:11:14.384 - 00:12:04.424, Speaker C: Right, so, so the idea is that this blockchain is not the incentives should not directly the architecture of all these systems should be such that the performance of models and the incentives which are driving those development are separated out. The incentives are for the builders, incentives are for the innovators and the model rails, and the inference and training and storage. These rails are separated out from it. The separation of architecture is very important. For example, the model inference should, on chain inference have become tricky, and it should not be tied with gas fees somehow like those things are. Those are the architectural innovation one has to look for. So any of these projects, I think they already are aware of these issues, and this kind of architecture is evolving, that the.
00:12:04.424 - 00:12:17.554, Speaker C: That the variations in token prices are decoupled from the performance required from these models. That's how at least I see it.
00:12:18.494 - 00:12:23.154, Speaker B: Neeraj, how would the virtual tokenomics work in this regard?
00:12:25.654 - 00:13:01.394, Speaker D: I think how we want to architect the system. So, to talk about, say, something like computational integrity, there's. In the world of crypto AI, there's a lot of talk about ZKML versus OPML versus this other stuff. And our view is really, you need to match the integrity, you need to match the cryptography to what users want. Ultimately, certain computational integrity models are not going to fit certain use cases. Zkml doesn't really fit the T or doesn't really fit the LLM paradigm. Today, the prover overhead is too high.
00:13:01.394 - 00:13:51.014, Speaker D: So as we think about how do we build an interesting ecosystem, I think it goes to a lot of these points. Building censorship, resistance, building privacy, computational integrity. And ultimately, you have this beautiful payments mechanism you have in blockchains that now, instead of having to go and have a credit card and talk to OpenAI off chain, you can directly pay for a model on chain with ETH. And that's really powerful. And I think we're just excited to see what types of use cases and applications come out of this. And ultimately, I think what everyone on the stage is building is infrastructure to try to drive these interesting use cases. And I think this next year will be really a test of what the killer use cases are for crypto AI.
00:13:51.014 - 00:14:03.114, Speaker D: But I ultimately believe this crypto AI will be the strongest driver of users, maybe that or gaming, in the next two years in crypto. And that's a very, very exciting prize to go and win.
00:14:04.824 - 00:14:14.564, Speaker B: That's great. So, verifiability of output is a very common theme now for a lot of projects. What is your approach to it, Nick?
00:14:15.264 - 00:15:14.014, Speaker E: I think Niraj said it well. I think ZKML is important for some use cases, and it's just untenable for other use cases. I think really high value use cases that demand that sort of computational integrity are important, and we'll see other approaches to they're kind of bringing AI on chain. I think OPML is interesting as a lower cost solution. Again, I'm a broken record here, but I do think this sort of objective centric approach sort of subverts some of the sort of, I guess, need for some of these things as well. When you're setting an ML objective that an ever changing set of models is continuously optimizing, who cares if they're computationally, if they have some sort of computational integrity, the end result is what matters, and how they got there doesn't matter as much. So I think we'll see a bunch of experimentation in the space over the next year plus, and we'll see ZKML really start to move into only the extra high value applications that really demand that kind of computational integrity.
00:15:14.354 - 00:15:16.734, Speaker B: Got it. And Salman, any take on this?
00:15:17.274 - 00:15:25.970, Speaker F: Yeah, actually we've worked a bit on ZKLM, like a version of that for LLM. I agree with you. I mean, scaling it to large LLM, super difficult.
00:15:26.122 - 00:15:26.474, Speaker C: Maybe.
00:15:26.514 - 00:15:55.836, Speaker F: My take is, I think still you would need it. For example, even if simple service like which model is my inference is running on like a proof for data, still you would need it even for like low end applications. Maybe a way through that is through approximate proof, right. You don't need all the layers of the model to prove it. Maybe a few layers, maybe the last layers. So I think there is a lot of work on approximations, like that's the issue. Even for the typical zero knowledge proof, you approximate it to a polynomial.
00:15:55.836 - 00:16:17.424, Speaker F: But I think you don't need to look at the entire model. Maybe there is opportunity to approximate part of that. Think about maybe a Lora base, maybe only the head you identify, like which adapter is running based on your. So I think there is opportunity to innovate. But I still feel proof is required, not only for special cases.
00:16:19.274 - 00:16:37.054, Speaker B: Blockchain AI is still very early. We're at the first 2nd inning of it, and there's a lot of challenges ahead. So this is a question for all of you, actually. Here is that what are you seeing is the biggest performance challenge that you see on actually making this work? Simanxu.
00:16:39.514 - 00:17:13.358, Speaker C: So one of the obvious technology challenge here is what everyone is talking about is proof systems. And I completely agree with what Salman said, that this approach of thinking of the computational graph as a circuit and then a computational graph as a rigid thing, converting it to circuit and following the regular ZK or proving recipe is very limited. They were not even designed to be that exact, those models. So one have to be creative in what they prove. You don't have to prove the whole model because the model itself is not so rigid. You can cut some branches, it still performs the same way. That's one part.
00:17:13.358 - 00:17:35.950, Speaker C: This is a challenge. If you go with this approach of verification, it can become an obstacle to the whole development. I feel it's still a couple of years at least away for some of these things. Some creativity is needed there. And the other challenge, maybe not the infrastructure challenge, but for sure a challenge. Neeraj is saying that this may become a driver for new users to come on to crypto. I completely agree with that.
00:17:35.950 - 00:18:04.064, Speaker C: And that's where we have to be very innovative to bring in the mainstream AI development community to crypto. And, and that side of things that I think that's also a sort of a challenge right now. That to bring an AI developer to the crypto side of things is that sort of a challenge right now. For any one of you who's trying to do hiring, you will know that. And, and that's, I think that's something we should also think about. Who are these target on audience who will come to crypto and innovate on AI? That's an important thing. At least I think about.
00:18:04.564 - 00:18:05.424, Speaker B: Salman.
00:18:05.964 - 00:18:46.980, Speaker F: Yeah, maybe a follow up on that. Maybe if you think about a little bit at a higher layer, let's say we want to build like a cloud, decentralized cloud for open source models. That could be a great accomplishment. To do that, then you have to say, how would we compete with other clouds that exist today? For example, you go to aws, you get to see Mistral. Is there other open source models? Are there like what is going to be the add value that we provide? Definitely cost is one like, that's the advantage of decentralized networks. The cost is much lower. There is no way other clouds can provide that.
00:18:46.980 - 00:19:28.528, Speaker F: And I think the way to realize it is maybe to make some steps is to provide some APIs hosted by decentralized cloud and every developer use that. At the end, many developers just need the API. If these APIs are hosted, low cost, high quality, I think that's going to be a very good step to attract developers to build their solutions. Why would they go for expensive API, go for maybe low cost. Then after that I think it's going to bring in more innovation. Once they use that, then the innovation is going to be maybe new agents, they build new models, they train and then they want to bring it back, bring the content to this cloud. Right.
00:19:28.528 - 00:19:56.224, Speaker F: So right now, it's like you start from the infra, you encourage building, then they bring in the content. And I think once the content is there. So I can imagine maybe in a couple of years, there is going to be a model trained by the community. Right. Why should all the models like Lomo be coming from metal? Maybe the community owns the compute, right. They have a lot of manpower and they can train great models. So now it's going to be both platform and both content.
00:19:56.224 - 00:20:04.604, Speaker F: Once you have both, then I think it's going to be a powerful ecosystem. Right. So that's what I'm hopeful that we are going to accomplish.
00:20:04.764 - 00:20:13.116, Speaker B: Nick, what are you seeing at Lora? I forgot the question, the challenges that you see in terms of performance reaching the performance limits.
00:20:13.220 - 00:20:13.484, Speaker E: Sure.
00:20:13.524 - 00:20:13.860, Speaker B: Yeah.
00:20:13.932 - 00:21:05.106, Speaker E: I think today, still the most performant models by quite a lot are built by these monoliths. They're black box models. And I think if decentralized AI at the sort of like intelligence level is going to ever compete with those, we have to move towards creating intelligence the same way that we create decentralized, composable systems, or that the way that we develop open source software, I think we need. If decentralized AI is ever going to compete with these massive centralized black box models, then thinking through these really difficult problems of bringing different models, bringing different insights, bring different forms of machine intelligence together in a sort of coherent way, is going to be a necessary element of creating anything that ever competes with these kind of massive monoliths. So I'd say there's a lot of hard problems and there's going to continue to be. But the intelligence one is the one that I'm particularly focused on.
00:21:05.130 - 00:21:08.146, Speaker B: Yeah, very cool for Rachel.
00:21:08.290 - 00:22:18.862, Speaker D: So I'm going to take your question a little bit of a different way, which is, it's sort of one of the things that I would look at when I was a vc many years ago was I was really interested in what are the emerging use cases of new technology, and how do we kind of back the things that'll grow the overall developer base and ultimately the ultimate user base. And I think the thing that crypto AI needs is crypto. People largely don't understand how AI works, and I think we need to develop better education. I think once people understand ML 101 and they understand crypto, interesting concepts will start to emerge and we'll start to see some really cool applications come out of it. I think we've seen this in the ZK space, the last three or four years, where it's really hard for the average solidity developer to wire circuits by hand and build all this proof stuff themselves and optimize it by hand. So now we're starting to see these generalized VM architectures and risk zero succinct type things. And I think if we can get there with ML, we can make it really easy to integrate ML into the average crypto application.
00:22:18.862 - 00:22:48.940, Speaker D: That's a huge win. So as we're thinking about performance, the big theme for us is pragmatism. We're not picking one technology, one privacy technology, one integrity technology. We just want things that are as easy as possible for developers to use. Our first product is a off chain oracle network that you can prove the inference results on chain, and that is a good trade off. The network is not decentralized yet, but I think that's fine. Let's see what the applications are and then build up over time.
00:22:48.940 - 00:22:50.864, Speaker D: So that's kind of our approach to it.
00:22:51.764 - 00:22:58.724, Speaker B: That's great. Well, that's a wrap, and let's give a round of applause for all these guys and thank you guys very much.

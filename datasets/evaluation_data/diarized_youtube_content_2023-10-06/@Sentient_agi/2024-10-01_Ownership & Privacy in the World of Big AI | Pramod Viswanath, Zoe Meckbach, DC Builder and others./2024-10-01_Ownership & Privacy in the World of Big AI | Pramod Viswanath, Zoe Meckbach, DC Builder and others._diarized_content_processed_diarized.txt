00:00:01.920 - 00:00:39.295, Speaker A: Okay, y'all, we're heading into our next panel titled Ownership and Privacy in the World of Big AI. For this panel we're joined by Anna Kozlowskis, the co founder of Vanna, Pramod Viswanath. He is a core contributor at Sentient and a professor of engineering at Princeton University. We have DC Builder, who's a research engineer at worldcoin, Casey Caruso, who is the founding partner of Topology vc. And this panel will be moderated by Zoe Meckvok, who is a vice president and partner at Falla Network. Welcome to the stage.
00:00:51.565 - 00:01:19.859, Speaker B: Great. Hello, everyone. Yeah, we wanted to sit in the order, so it's better for you guys in the audience to recognize the speakers. Thank you for staying after a deep and very interesting fireside chat with Sandeep. But this topic is also very, very interesting and I hope that you all can learn something from our amazing speakers here today. I'm Zoe. I'm VP and partner at Phala Network.
00:01:19.859 - 00:01:54.295, Speaker B: We are deep in co processor for AI and I'm joined by very smart and amazing speakers here today. We have Anna, we have Pramod, DC Builder, and Kesey here. And of course I would like to give you guys as speakers the opportunity to quickly introduce yourself, but also with the intro or bit of background, what where your journey is coming from, like the intersection of AI and crypto. Are you more from the AI side or the crypto side? And why are you building also into this intersection? Casey?
00:01:54.455 - 00:02:42.245, Speaker C: Sure, yeah, my name is Casey. I historically come from the AI side, but my general background is traditionally trained computer scientist and studied AI and ML in grad school and then worked at Google for four years on a variety of teams, but mostly on a team called Research Systems, where we did exploratory ML work and specifically a lot of topic modeling, and then got into crypto through mining originally and then most recently was an investment partner at Paradigm and now on my own firm. And yeah, I think that independently have been in these two industries for a really long time. Almost a decade, actually. Yes, a decade. And then more recently, have been spending a lot of time thinking about where it might make sense to have them overlap and where it does make sense and where it doesn't make sense and over what time horizons.
00:02:43.695 - 00:03:15.135, Speaker A: Awesome. So I go by DC Builder on X and I'm a research engineer at the World Coin Foundation. I mostly come from the crypto background, although I was into AI like way back in high school, but I chose the different routes, the dark side, as they call it. And I work Mostly work on programmable cryptography, so zero knowledge cryptography, MPC and blockchain engineering. And I work at worldcoin, where we're building the largest digital identity and privacy network for just financial use cases.
00:03:17.595 - 00:03:29.375, Speaker D: My name is Pramod, Pramod Vishwanath. I'm a professor at Princeton University. And it's a professional hazard for professors to ask to speak. I could go on forever. So I'm going to be careful on that.
00:03:31.595 - 00:03:57.549, Speaker E: I'm Anna from Vana. I come from kind of an intersection of crypto and AI. So I got into crypto through mining Ethereum. In 2015 I would go get GPUs from the lab dumpsters at MIT and set them up to mine with free electricity. And then I ended up dropping out of School in 2017 to start a machine learning company that came out of automating my job as an intern at the World bank. Sorting documents. This is when the attention is all you need.
00:03:57.549 - 00:04:05.465, Speaker E: Paper had come out, but people hadn't yet figured out how to use it for generative models. And I was doing some research there at csail.
00:04:06.985 - 00:04:39.115, Speaker B: Thank you so much. Very excited to have you here on stage. So today we talked a lot about like open source, closed sourced AI should be controlled by decentralized or centralized protocols or entities. I would like to start with the question of like the risk that you would see if AI data overall will be controlled by centralized entities and how you in your companies or companies that you fund or what you see in the projects you're working on. How are you mitigating these risks? Dc, do you want to start on this?
00:04:39.975 - 00:04:46.999, Speaker A: I think the AI people should start first. I have like very limited view of this. Maybe some other person that wants to take this first.
00:04:47.127 - 00:05:19.639, Speaker E: Yeah, I'm happy to take this first. So I think that some of the risks that come from centralization I would categorize into one is like whoever decides what goes into the AI model is basically deciding truth. Right. And so if you just talk to an AI to get your information, then whoever has decided the truth for that AI model has decided the truth for a large portion of the world. The other one is kind of more economic concentration. Right? So like OpenAI hit like $3.4 billion in revenue recently.
00:05:19.639 - 00:06:06.741, Speaker E: And that's just a huge amount of resources that actually comes from AI that's largely trained on people's data. Right. And all of humanity has helped to create that. But the economic upside is getting really concentrated in terms of what we do at Vana. So Vana is a user Owned data platform working towards user owned foundation model collectively owned by 100 million people who all contribute their data. One recent example is the Reddit data Dao where so Reddit selling user data for like $200 million. One of the problems that we're running into with AI today is like llama3 is trained on 15 trillion tokens or maybe to get a sense like how many people have run llama on their MacBooks.
00:06:06.741 - 00:06:09.131, Speaker E: Okay, so like some local.
00:06:09.226 - 00:06:13.439, Speaker C: Okay, so like some AI, 10% for those live streaming.
00:06:13.527 - 00:06:37.945, Speaker E: Yeah. Okay, so like that model is just trained on mostly public data. The way people have been scaling models today is just like get more and more data to train these models on. So you see these exponential scaling curves. One of the problems is we're kind of running out of public data. So There are around 15 trillion tokens in Fineweb just like common crawl all of the Internet. So we need to find ways to get more data to push the frontier of these models.
00:06:37.945 - 00:07:04.595, Speaker E: And at Vana we're letting people contribute their private data in order to own parts of these models. So with a Reddit data Dao, 140,000 users joined with their valid Reddit data. A million people tried to join with like accounts or bad data or whatever it is and now they are collectively training a user owned model. It's going to be mostly used for like shitposting. Right. It's not a foundation model yet, but that's sort of the economic model that we've set up at Vana.
00:07:06.415 - 00:07:09.955, Speaker B: Great Prama. Would you like to comment on what Anna said?
00:07:10.335 - 00:07:56.677, Speaker D: Yeah, it's great. I think data has been the fuel that's driven large part of what made the technology titans like trillion dollar platform companies for sure. And it's partly a part of our biology as a human species that we would like to share who we are and professorial hat here. And there's also a famous experiment in the US where a lady was just giving out pens and asking people to write their Social Security numbers and a large number of people wrote it, like several hundred, hundreds of people. So it's just I think privacy is in our. As a human society, as animals and farming societies is not part of our biology. Except privacy used to be previously.
00:07:56.677 - 00:08:30.119, Speaker D: The reason it came out because what you said was specific to that time and that location. If someone didn't hear you nearby and at that moment it was gone. Whereas today now it's there forever. I think this kind of doesn't gel with the timescale at which we have evolved as a social species. And so it's clearly the onus is on technology to provide some guardrails and perhaps some guidances definitely to enable those who are especially careful. That's one part of it. The other part is that data is who we are.
00:08:30.119 - 00:09:04.004, Speaker D: I mean we are, it represents who we are, including our innermost thoughts, our strategic thinking, whoever we are. And this will only get the Social Security number is just someone assigned you. But data, if you define it, is much more than that. And I'm especially interested in understanding and thinking about and building technology that empowers individuals to lead productive lives while being part of a society without having to give up your data.
00:09:04.905 - 00:09:37.905, Speaker B: Yeah, that's a great example. We discussed this case study backstage earlier and I think, as you all know, I think everyone that's here in the room today, everyone that cares about data privacy and ownership, is either in this room today to learn about it or already works in Web3. Right. So the question is more like how can we bring this kind of mindset to the people? If you want to change the mindset or just have more people use privacy in Web3 and AI, how can we do this? And maybe DC, if you want to comment on this, how are you doing this, reflecting this in the technologies that you build for, for the end user, but also for developers?
00:09:38.565 - 00:10:13.485, Speaker A: Yeah. So maybe I can put some perspective into, for example, how worldcoin handles private data. So for those who you don't know, we manufacture this hardware device called the orb, which essentially is an image. It can take an image of a person and it's able to tell apart whether the person is a real person or not based off of different sensors. And then it takes high resolution images of the irscs and it's able to compute a unique representation of them. And then it's able to check the unique representation against a set of all the other users who have been verified to date, and it's able to tell whether those are unique or not. And based off of that, you can curate a set of unique humans.
00:10:13.485 - 00:10:47.871, Speaker A: And using cryptography, concretely, zero knowledge cryptography, you're able to prove to anyone else that you are a unique human without revealing who you are. And so the way that we think about compute and compute on private data and essentially making it so that we don't learn that data in the first place. There's a lot of different types of so called programmable cryptographical techniques. They mostly fall into one or four fields. There's zero knowledge cryptography. So I'm able to make a proof about some Computation or some properties about some data, I'm able to. Then there's fhe fully homomorphic encryption, right.
00:10:47.871 - 00:11:38.195, Speaker A: So I'm able to encrypt some data, perform some computations on the encrypted version of the data. So essentially I learn nothing as the person doing the computation. And then someone else can, or like the user, the person's data, the people, people want the data can just decrypt and it's as if I would have performed that computation on the original data. But the person doing the computation doesn't learn anything. Then there is multiparty computation. So we also use this specific type of technique which allows a given set of participants, let's say the people here on stage, to perform a computation on some data without any of us learning any single learning the data itself. But it allows us to split the data into so called shards and we're able to collaboratively compute over those shards in a way where we're able to get the computation we want to perform together without learning the inputs that we're working over.
00:11:38.195 - 00:12:13.571, Speaker A: And lastly there is trust execution environments. So these are like secure chips and hardware that allow you to essentially give you a guarantee that something was executed on top of without. Like you're essentially trusting that the hardware itself is not compromised in this case. And you can extract signatures of this computation. So these are like, sort of like the four different like primitives that allow you to do computation in a private manner. And there's lots of different ways that you can combine them in different protocols that allow you to maybe do private inference or verifiable inference in AI. Like these cryptographic techniques can be applied to AI or any type of computation.
00:12:13.571 - 00:12:24.489, Speaker A: It scales like very generally and there's lots of mix and matches you can do here. And there's lots of companies exploring this sort of space for design of protocols and AI. Yeah.
00:12:24.667 - 00:12:32.077, Speaker B: Any specific use case that you're working on at Worldcoin or that you've seen combining FHE on TE or running zks on tes.
00:12:32.221 - 00:13:10.571, Speaker A: So we run an MPC protocol. Essentially these IRIS codes, as we call them, these are like the unique representations of the irises. The way that it works is that we used to have a database of all the plaintext of all these iris codes. They're not biometrics per se, but they're biometrics drives, so they're still sensitive. And so right now what we have is instead of having this plaintext database of all the iris codes, we have an MPC sharded database of all These iris codes across three participants. And these participants are able to check like a new person that has just signed up. You can check their iris codes against the entire database and without ever decrypting the database.
00:13:10.571 - 00:13:38.975, Speaker A: Right. Like they're always in this MPC state and a new version that we're iterating on top of even the query, meaning the thing you're looking up in the database, the new iris code you're looking up and the distances between this iris code and the database are going to be all private. So there's like a, this is like one practical use case of like hey, now we have almost perfect secrecy and world Coin in a like one to two year time horizon would never touch any piece of biometric ever. It would just be fully like in the crypto space. Right. In the cryptography space.
00:13:39.475 - 00:13:59.897, Speaker B: Casey, we said you're wearing several different hats, right? With your experience in crypto and AI overall, would you like to comment on like the technologies as we just mentioned that are used, being used for AI or Web3 and AI like hardware like TeS or ZK, where you've seen trend or where you also look into with your investor head?
00:14:00.081 - 00:15:11.317, Speaker C: Yeah, I also have another concrete example where actually I have a pure AI company that I work with because I don't just do crypto, but rather frontier tech. And it's interesting because they're using two of these technologies and it's extra interesting because they're not crypto, but their product is basically a machine learning competition where it's kind of like a mix between Hugging Face and Kaggle. If people are familiar with that product and they're using HFE because they want to keep the data private. And so for things for data like healthcare data, that's their solution to be able to do training and inference in a totally encrypted manner. And then they're using TE is because they want the models to stay private, where when people call the models they can actually get compensated or financially incentivized to use those models and they want the model to stay totally private. And so that's where they're using TE is. And so I think what the overall trend that I'm seeing is that even the AI companies that are thinking more about what is the future of machine learning and can we use like isolated payments and crypto being one of those potential solutions and distributed compute holistically as like a way to do compute, they're becoming closer, like they're overlapping more.
00:15:11.317 - 00:15:26.859, Speaker C: And I'm seeing a lot of my AI companies start to use the same technologies that my crypto companies are starting to develop as well. And then on the ZK side I think, I don't know, I have strong thoughts on ZK and I think that's like a little bit of a different category and use case. But I. Yeah, great.
00:15:26.947 - 00:15:35.963, Speaker B: Anna, would you like to comment on the, on the question, like where you see the trend for the crypto/AI use cases using the specific technologies we have discussed?
00:15:36.139 - 00:16:12.735, Speaker E: Yeah, I think one thing that wasn't mentioned is just like federated approaches and local models. Like you can achieve a lot of the privacy properties you're looking for by just running a model locally with all of your data. And so yeah, with Vana we have kind of this personal server that can just run from your MacBook, host all of your data. You can also host your data in a storage provider of your choice. And then using a compute environment that is trusted by the user, whether that is client side or on their local device, gives you a lot of those stronger privacy guarantees. The term we use to kind of describe all of this is non custodial data. Right.
00:16:12.735 - 00:16:34.387, Speaker E: Like usually when you use an application you have to pass them a copy of your data and then they're like holding your. They're basically custodying your data for you and you're trusting them. But in the context of Vana and some of these new privacy centric approaches, it is non custodial. Right. So you can use it and kind of personalize it, have your content in there without actually having to reveal the underlying data.
00:16:34.571 - 00:16:50.465, Speaker C: I echo federated learning as a approach that's starting to work and it's really interesting. From a distributed compute lens and there. Yeah, I don't think enough people bring up federated learning now. And it's like already in production. And a lot of the other technologies that we talk about are more exploratory and this one is actually working.
00:16:50.965 - 00:17:28.716, Speaker E: Maybe. One other research area I would call out is model merging. So distinct from federated learning where you're saying like, okay, we're gonna train a model and kind of like coordinate it across this federated network model merging, it's kind of using an approach that feels more like open source software. So some of the top models in the image space, like if people have used CIVET AI, a lot of that it's like not safe for work sort of content. But that's often where this technology starts. But the leading like face generation image models are actually created by like 15 different people who don't even know each other. And Each person has trained a little piece of the model and then passed it on.
00:17:28.716 - 00:17:40.784, Speaker E: And I think that as these techniques move into kind of broader applications, they provide this way for many people to train a model all locally with their data on their device and then contribute it back to a bigger model.
00:17:42.305 - 00:18:16.661, Speaker B: Cool. I mean you mentioned already some research areas, but if we zoom out a bit like overall and talking a bit more about innovation, how can we do things more efficient and even better for AI? How would you see the difference of what we just discussed? Hosting or having AI data secured by these different technologies? Is it like the software side or the hardware side or even being controlled by centralized entities? How do you see this impacting the innovation and the way forward for AI use cases? Pramod, do you want to talk on this?
00:18:16.733 - 00:19:05.699, Speaker D: Yeah, yeah, yeah. I think there is two parts to it. One is the data that's already out there is just out there. I mean there's that cat has long been out of the box and maybe had litters and it's really gone out there. It's the new kind of data that will get produced over time and especially strategic, like I said, just not your Social Security number but something more about how you, who you are. That's the one that is the reasoning and that's what AGI that's behind more intelligence aspects is the one that needs to be more carefully handled. And I'm particularly thinking about what kind of architectures, where does the AI sit, where do users interact with it and where does the new kind, the interaction itself generates the new kind of data that the model learns from and how to save it.
00:19:05.699 - 00:20:11.273, Speaker D: And one model that I'm especially thinking about, and this is related to project Sentient and is where the models sit outside, but they're largely given out to be inferred locally, fine tuned locally and in particular the interaction, all done locally. So in your own enclaves it could be within communities, so that could be in some trusted enclave, maybe a hardware setting, it could be just individual, you run it yourself. It could be on cloud. I mean I trust Google in the sense that they know everything about me. I mean I have Gmail and so in that sense you can have your trust. But largely I would prefer a model where the AI service, it could be OpenAI itself, a centralized one, but offering me as a service and I only go back to the owner to do maybe payments, that's only my interaction and that's pretty much it. That's the model that I'm particularly thinking about and doing the science and the technology to enable this.
00:20:11.409 - 00:20:19.685, Speaker B: Okay. A question would come up like how do you then empower more like the multi agent economy. Right. If you run so much like locally.
00:20:20.145 - 00:20:47.435, Speaker D: Yeah. Give away the model. What's preventing somebody from running away with it? I mean this is software industry went through this decades ago like Microsoft was doing. I mean IBM was doing these big mainframes and Microsoft was doing betting on personal computers. And they have to give software away, otherwise people can't run it. They have to run locally. And Microsoft Word was a classic example and they came up with this idea that oh, I'm going to give you binary, I'm not going to give you the source code and even there I'll try to do some licensing models.
00:20:47.435 - 00:21:19.479, Speaker D: So they went through this process decades ago and it works to some extent. I mean we all know piracy is there and this is the era of AI, which is a lot more than than word processors. Word processors are static, they're just there and you interact with it. Whereas this is a living object AI and you interact with it and it gets better with it. And of course knows everything about you. It's your alter ego literally. And so this ideas have been around and this technology has faced this and this is the era for new time.
00:21:19.647 - 00:21:26.191, Speaker B: Good. I think it was like a look too because we know Pramod would extend much longer on this.
00:21:26.303 - 00:21:27.919, Speaker D: Yeah, you professor, watch out for me.
00:21:27.967 - 00:21:36.899, Speaker B: Casey, a question to you. Like how do you see this balance between, between data utility and user privacy, right. In use cases or like teams that you work with?
00:21:36.987 - 00:22:13.353, Speaker C: Well, I just feel there's a different argument to be made of that. I know we talk a lot about privacy and ownership and that's all true as well. But I also think just like zooming out from first principles, the way consumers make decisions about what products to be used are usually it's like faster, cheaper or better in some way. And I think that a lot of the technologies that we're talking about and maybe even specifically like the edge stuff that Anna alluded to, just edge compute and on device compute, that is just going to become faster, better, cheaper. It's just like it is going to be a lot better to do inference that way. It's going to be. You're going to have to pay very little hosting costs obviously.
00:22:13.353 - 00:22:30.115, Speaker C: And there's so many advancements happening on chips right now, especially on inference specific chips. And just in general there's a lot of advancements with GPUs and beyond GPUs that I feel like there's a case to be made of. Even if you don't care about privacy, it's just going to become the preferred methodology in the future.
00:22:31.735 - 00:22:55.595, Speaker B: Yeah, very good, very good. Dc, do you want to comment on this? On running, I think Casey just zoomed out a little bit that there will be technologies implemented where the user doesn't need to decide anymore about the privacy use. The initial question was how do you, in your project or in use cases provide a balance between data utility and user privacy?
00:22:57.405 - 00:23:51.009, Speaker A: I mean, you're always going to be on a trade off of how useful something is and where you're running it. The more useful it is, the more usually compute intensive it is. Therefore, you're going to have to either delegate that compute to something else or scale up the state of the art so far so that you're able to actually do that on your own devices. To me, I think the thing that gives you the best of both worlds is usually cryptography. That's at least how in the blockchain space has been happening recently. You can do some form of delegated compute where the person doing the compute or the computer that's doing the compute doesn't learn the data that it's computing over, but it's still able to run whatever you want it to run over that. So to me, things like mpc, where I split the data I have on my phone, my personal data I split into different charts, I send it to the server to compute over, but the server will not be able to reconstruct it without my thing.
00:23:51.009 - 00:24:58.807, Speaker A: And I can just collaboratively compute with the server, whatever the model they want, and they can commit to using some specific model that I want. These sort of techniques exist, however, they're not really production ready or efficient enough. And there's very few cryptographers that have talked to enough state of the art AI engineers to the point where they're able to come up with something that is productionizable yet because this would also require variations of different hardware eventually, once, if we cared more about privacy, there would be hardware that would reflect the privacy, I think, because right now, for example, you can do AI models that run very performant, even on phones, because you have neural engines on the latest iPhones or whatever. But for cryptography you need to work with finite fields, which is different arithmetic and different algebra and different math than you use for AI models. And those chips are not in any consumer devices, unfortunately. So yeah, if we want to go to the privacy route, we should have hardware that represents our privacy standards. And then these use cases would be a lot More possible without sacrificing either the usability or the privacy, which I think is what we want in the end.
00:24:58.807 - 00:25:03.435, Speaker A: Right. It's just better than what we have today at all fronts. We don't have to sacrifice anything for that.
00:25:04.095 - 00:25:08.055, Speaker B: It's always the trilemma. Right. Pramat, would you like to comment?
00:25:08.215 - 00:25:40.315, Speaker D: Yeah, I mean, I think we've talked about sort of trusted hardware somewhere was mentioned, definitely. Dominic just mentioned cryptographic methods for privacy. But there's another method which is statistical methods. This is an area called differential privacy. I mean, somewhat technical, but some of you who are in sort of computer science may have known about it. And I led this research group for several years, several PhD students graduating on thinking about how this is the key point is that privacy is semantics free. I mean, what is private to me may not be private to someone else.
00:25:40.315 - 00:26:07.671, Speaker D: And so in other words, privacy has semantics and personalization aspects to it. But perhaps there is a way to make it just syntactic and think of it as numbers. This is especially relevant for AI. You know, in comes very private data and out comes a model which is just a bunch of weights, numbers. So perhaps there is a way in which one can consider just the syntactical aspect of privacy. And this would be a statistical way. That means from the weights you cannot exactly pin down who it is.
00:26:07.671 - 00:26:22.633, Speaker D: Maybe you can pin one out of 100, one out of thousand and maybe that's okay. These are not the cryptographic guarantees, which is astronomically good. These are more statistical. And I just wanted to point this out and there have been some success stories. I can talk offline.
00:26:22.809 - 00:26:45.565, Speaker B: Yeah, great. I would like to wrap it up with an over question to be answered by all of you. And starting with Anna, what are you personally most excited about when we talk about the use case of really having users owning AI agents or models and so on? Why do you think this is so important and what can it do for the user or developer?
00:26:45.875 - 00:27:39.335, Speaker E: Yeah, so I think that what AI has done is really shifted the question of privacy to kind of like something that's maybe ideological or some kind of cultural preference towards more economic. Right. So it goes from like, oh, I don't want anyone to see my messages or my data towards like, hey, there's an AI version of Anna who can potentially like earn wages on my behalf and I want to protect those economics and kind of like have true ownership of my kind of personal AI model that I create and also the broader models that I might contribute my data or expertise towards. And so what I'm excited about from kind of a decentralized AI and user owned AI perspective is just making sure that the benefits of AI are really like widely spread towards everyone who has contributed their data. So that's more of the social benefit. And then I'm very much kind of in the AI accelerationist camp. So long as you can do it in a decentralized way.
00:27:39.335 - 00:28:05.215, Speaker E: So the other piece is just pushing model performance. Right. And actually like getting over that data wall of like, how are we going to train better models and how are we going to get closer towards AI that can enable amazing things like scientific discovery and like, I don't know, a better understanding of ourselves. And so yeah, both kind of the individual perspective and also the broader. Just like what can you do with super powerful intelligence?
00:28:06.075 - 00:28:07.935, Speaker B: Amazing. Pramod, please.
00:28:08.715 - 00:28:40.265, Speaker D: I think as an educator I meet young people all the time and there's an immense drive to build and contribute to AI. And if you include high school students, college students, like a mar majority, I teach crypto classes and very few students when they come in, have wallets. But nearly everyone has done Python programming and probably definitely have a git account already. And so there's an. And there's a huge urge. There's like several hundred million, several tens of millions, if not 100 million aspiring AI developers. Very accessible.
00:28:40.265 - 00:28:56.633, Speaker D: Shake and bake technology. A lot of tech is in crypto can be deep, deep tech. This is shake and bake. I mean it's doable. And on the other hand, all of humanity wants AI and there's such a narrow path to meet the supply and demand. And I'm really interested as an educator, as a scientist to build technology to.
00:28:56.649 - 00:28:59.975, Speaker B: Bridge this amazing DC Veda.
00:29:00.795 - 00:29:31.981, Speaker A: I really echo the same point that Pramuth said. I'm in the same place from the applications perspective. I'm not necessarily the best person to ask, but I'm really excited about the infrastructure getting better. I'm someone who cares more about the engineering efforts being there. People getting excited about these things and allowing these things to happen. Be that better hardware for the privacy stack. So better cryptographical enabled, cryptography enabled hardware and just building, trying to learn more.
00:29:31.981 - 00:29:44.105, Speaker A: I think like the thing that we're missing is like bridges between both spaces where the cryptographers talk to AI engineers. And so in that name I'm also going to set for three weeks in August so I can learn more about that. But this is sort of like something I'm excited about.
00:29:45.445 - 00:30:22.245, Speaker C: I think all these points are great. I think that I feel if you zoom out again and you think about kind of the pace at which technology is becoming integrated with Homo sapiens in general or humans. It's just crazy. It's like the phone has been around or the iPhone has been around for what, like 20 years and now if you look at any public space, there's basically nobody without it. And it's just so obvious that this is going to be accelerating and that we need to come up with a new ownership model or it just won't make sense. Like this is just the next iteration of how we're going to be living. And it's, it's so clear that something needs to radically change.
00:30:22.245 - 00:30:29.005, Speaker C: Not even from an ethical standpoint, just from systems and an economic standpoint. There just has to be advancements.
00:30:30.185 - 00:30:52.315, Speaker B: Amazing. Thank you so much, everyone. As a quick summary, I think we all agreed on like on the privacy side, for AI crypto use case, we are very excited to combine a lot of software, hardware based technologies. Right. To enhance privacy for users and developers. And on the ownership side, I think Anna pointed it out very well. Let's be more excited for like, the economic models that we can actually enable in these use cases.
00:30:52.315 - 00:30:56.935, Speaker B: Thank you so much. I hope you all got something out of this panel and yeah, see you around.

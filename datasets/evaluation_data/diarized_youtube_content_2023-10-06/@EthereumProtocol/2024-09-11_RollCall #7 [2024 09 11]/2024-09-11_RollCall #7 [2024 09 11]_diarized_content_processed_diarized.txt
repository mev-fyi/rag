00:00:01.040 - 00:00:36.085, Speaker A: Hi everyone. Welcome to the seventh roll call today. I'll take over from Carl. Carl is on the call but is traveling and has somewhat unstable Internet. So I'm sure he'll be able to jump in, but I'll lead the call. Yeah, we have some agenda items. I know that Max Rasnick who basically wants to later on talk about the Blob transaction, the reserve price has time constraints and might only make it for a short portion of the call.
00:00:36.085 - 00:01:10.499, Speaker A: So we'll basically. We hope to be able to time it so that he can briefly talk about it. Otherwise I can do that for him. But I wanted to first start by giving a very brief kind of update from the layer 1 from the Orchardev side and just as a quick short experiment because I think this is generally useful. I have a very basic presentation. One sec, I'll try to share my screen. It's just two slides, but I think actually having something to look at is generally nicer.
00:01:10.627 - 00:01:11.535, Speaker B: Let's see.
00:01:13.915 - 00:01:29.813, Speaker A: If this works. Can you see my screen? Yes, I just. Yeah. Okay, perfect. Wait, this is the slide two already. Okay, slide one. So.
00:01:29.813 - 00:01:50.573, Speaker A: So basically so first just general ERP updates. Both of these updates by the way, will be specifically regarding the upcoming pectoral hard fork. The that hard fork is currently under planning. It's not basically not not not and not super near term yet but. But basically the kind of. The ERPs are more. More locked in for it.
00:01:50.573 - 00:02:42.085, Speaker A: So I think it makes sense to start kind of looking. Looking at how that affects L2s as well. And so on the general ERP update side, I think the one thing that is worth mentioning here is the EIP7702 that is the set UA account code 1. So basically it allows UAS to act and delegate to a SMART account implementation and act as a smart account on chain. And so I'm bringing it up specifically because in the past it underwent several pretty major iterations and changes and now basically the general consensus has been that we have reached a stable state. So of course it's not 100% certain that there won't be any tiny remaining changes. But basically the spec as is will be most likely more or less the spec that reaches the chain.
00:02:42.085 - 00:03:58.477, Speaker A: So if you as L2 have any kind of general thoughts around wanting to support this in the future, but have maybe been holding off, now would be the time to start kind of working on it, I would say. And so in particular I just want to mention that my recommendation would be that L2 try to basically be ready to support this feature on a similar timeline to L1 because the users will of course on layer 1 be able to start using it pretty soon and then they will expect to also be able to use it on layer 2s. So unless you specifically have reasons to not want to support it at all, I think it would be valuable to try to align the timeline here with the Pectora rollout. Of course the details there still are tbd. And then one more point that's maybe not quite so obvious that I wanted to stress there is that given that with these smart accounts we expect that the infrastructure stack that's mostly used to bring these transactions to the chain is the kind of the 4337, the ERC437 smart account standard. It would also be good. And that's something you can already do today because of course the standard is already out there in life and that you make sure that your L2 is as compatible.
00:03:58.477 - 00:04:36.463, Speaker A: Like basically that it's as seamless as possible to use smart accounts via that standard. Yeah, and that's. I don't know. Is there any feedback, any. Oh, sorry. Before we go to the second slide, any questions on 7702? Okay, then I'll go to the second point. So there I just wanted to briefly highlight something that maybe is not, not yet on everyone's radar.
00:04:36.463 - 00:05:10.283, Speaker A: So Pector is of course the next scheduled hard fork. It actually turns out that like, because there were a lot of features. Oh wait, also, I see, I'm not aware of the chat. Let me double check that there's nothing in the chat. Ah, what is the ETA on 7702? Yeah, so basically the ETA is just whenever, whenever pectoral will be shipped. Which we have Alex on this call. I'm not sure if he's comfortable giving predictions but like I would say something like first half of next year.
00:05:10.283 - 00:05:39.747, Speaker A: I think that is you know, like hopefully early in that window. But you know, realistically, sometimes first half next year is what I would say. Well, and that doesn't include UF and peas. Well, that's just kind of the topic now. So basically. So that was for now just talking about 7702. Now Petra initially is planned as one fork, but of course now it has been shaping up to be a really, really large fork.
00:05:39.747 - 00:06:39.805, Speaker A: There were a lot of like last minute additions. PEAS was added relatively late and UF was added relatively late. It in total made the fork unusually large. So now there is at least some considerations around possibly splitting the pork and rolling it out into parts and this is to be clear, not confirmed yet. This is just being discussed, but I think it's at least not implausible that it will happen this way. And specifically, just in terms of the current state of the spec readiness and testing and the most likely and most natural kind of candidates that would be pushed or the main ERPs, at least that that would likely then be considered only in the second part would be both UF and peas. And of course both of those are at least in principle also relevant for layer 2s, to the extent that layer 2s would want to also ship UF and peer does, of course, much more directly because it will bring the next major blob throughput increase over 4, 844.
00:06:39.805 - 00:07:25.977, Speaker A: And so from my side here, I just wanted to, when we first just highlight that this might happen. And so if, if we end up with this two, two part split, then we would ship the first, the fork and then I would really be very optimistic that that would be early, early next year and that would most likely still include 7702. I don't think that is a candidate for the second fork. But then these features specifically might, might be delayed until later in the year. And so I wanted to first collect a little bit of feedback here in terms of like what urgency people feel specifically say. I think it's, it's, it's more, more question around peas. So like how right now, of course blobs are still practically on mainnet, it's not guaranteed to last forever and specifically not guaranteed to last for say another year.
00:07:25.977 - 00:08:21.685, Speaker A: How urgent do people feel like a throughput increase there is. And then, yeah, depending on that, we can basically talk about how people could make their opinions heard on that point. But I'd be curious about feedback first if anyone has thoughts. Right? Yeah, I mean if, if we don't have any, anyone on the call right now with very strong opinions, which those people are usually rare. Do, do we. A question in the chat. Do we predict PS to be severely needed? Well, I think basically the question is how soon will it be needed? Right.
00:08:21.685 - 00:09:17.455, Speaker A: So I think it is definitely crucial that we do increase the blood throughput in general. It is to me also a question like how urgent is this? Right. Like, I think, I think it would be a huge lift to try like if I think at least again, Alex would be more the expert here. But like my feeling is that it's really starting to become more and more challenging to have PS kind of go live together with the rest or like the first half of the fork. So the only reason to basically double down on this and push very hard to try to still make that happen would be if we perceive that there's probably a lot of urgency, right that like say the difference between a throughput increase going live in six months or in nine to 12 months would be severe. I don't know. I personally, you know, I'm, I'm, I, of course I would want, I want the L2, the L1 to, to have the best features possible for the L2s.
00:09:17.455 - 00:09:25.355, Speaker A: But I don't know like, I feel like that's some, that's like a question that I feel like the L2s are much better positioned to, to have an answer to. So.
00:09:29.775 - 00:09:30.955, Speaker C: And I'll just.
00:09:32.055 - 00:09:33.235, Speaker A: Oh yeah, sure Alex.
00:09:34.775 - 00:09:59.795, Speaker C: Yeah, I mean another thing to consider is just like risk wise smaller hard forks are much better to ship. So that's like another consideration. And yeah, again I think timelines are very up in the air. But if it is the case that peer DOS L1RD doesn't proceed as quickly as you know, we would like, then this is an option like you're laying out.
00:10:05.465 - 00:11:14.007, Speaker A: Right? And maybe just to give a little bit of context because I see that question chat as well. So basically how does peer in general affect like the blob throughput and what is the plan there? So basically we have right now with the 4844 of course shipped for the first time blobs as a specialized data availability kind of Service from the L1 and so far this is not yet sampling based so meaning that every node in the network still downloads every blob. That is how you check the availability and the roadmap for Ethereum is to move to a sampling base. So basically when you heard about dank sharding in the past, that specifically refers to the concept of a sampling based data availability check. Initially there was more like a binary change, so basically a one time shipment like shipping this sampling feature. But by now we have a much more iterative roadmap. So there will be basically several rounds of more and more intricate sampling that will allow us to have high and higher kind of throughputs in terms of number of blobs.
00:11:14.007 - 00:12:16.735, Speaker A: So the initial peer does will allow us to go beyond four but I don't want to you know like promise any specific numbers. But my own mental model is basically that like over the next three years or so we would want to have one rollout of an improved sampling mechanism every year and say roughly 3x the throughput every year. Maybe we won't Be quite, quite be able to stick that schedule. But more or less rule of thumb. So PS would be 3x the throughput of 4x4 and then hopefully the year after so we can further improve on that and so on until we basically reach the full sampling based super targets that are associated with full dunk sharding. So really for now the question is just how soon do we basically need this first step of increases over the count throughput levels. But of course that somehow finding a compromise between the need there and the practical realities and limitations of this very large fork.
00:12:16.735 - 00:13:22.445, Speaker A: And if there's no very strong opinions on this call, which again I was just curious to check whether that's the case then I think for now it's really just PSA basically. So, so people are aware that this is a process that's happening and I just wanted to basically mention if someone may for example listen to this recording later on or something and is maybe some, some roll up team has strong opinions there. I do think what would just be valuable would be to have those communicated in a helpful way. So for example, like a blog post on expressing kind of the relative priorities on upcoming features from day one basically and how that affects L2s and what the priorities there are and the timelines that would be helpful. And then possibly of course, depending on the level of urgency there, I think the Orchid process is always open for guests to come in and express opinions directly. So there would always be an option. Yeah, I think I basically was kind of as.
00:13:22.445 - 00:13:54.765, Speaker A: I think our role as roll call is basically to try to bridge this gap. So I just wanted to make this as visible as possible for the, for the L2 side. Yeah, I think that would be all. Then on the topic of the update from the ACD process, I think I'll stop my screen share then for the moment. Yeah. Let me just briefly see. Andreas, are you already raising your hand for your own topic or is this still.
00:13:54.845 - 00:14:18.737, Speaker D: No, I just, I just have. Yeah. Have a, have a quick question. Do we have actual numbers what the, what the expected throughput increases are from the different L2s in terms of growth? So to be able to overlay that versus you know, the, the, the increased throughput on. On, on. On blobs. Right.
00:14:18.737 - 00:14:54.221, Speaker D: I mean if you're, if you're, if you're, you know, if you, you know, do like 2x3x increases and you're actually just increasing by you know, 40%, you know, every year. Right. Then the question is what's the, what's the proper alignment with the growth path of L2s. Right. It's a numerical exercise whether someone, someone has actually collected that data. What the expectations are versus what, what's being planned. Right.
00:14:54.221 - 00:15:01.825, Speaker D: Otherwise you're, you're building, building an 18 wheeler and you just need a, you know, an SUV.
00:15:04.295 - 00:15:50.555, Speaker A: Right? Yeah, exactly. And I mean I think of course I'd be happy to hear about on this point from the altus directly as well. But like I assume this is something that's very, very hard to predict and project and to some extent maybe also like business information that they would not necessarily want to disclose. But so that's why I see a role more on the, from the, from the base layer basically be, to try to be as predictable as possible so that then the L2s can have certainty in their own planning and know what, what kind of throughput levels they can, they can target while consuming L1 data. Carl.
00:15:52.655 - 00:16:52.045, Speaker E: The point is more just to be aware that if L2s do not make enough noise about this then there's no real signal to the ACD process of how important this is. And so if there is a massive uptick in the need for blob space and we didn't make a noise about it several months in advance, then ACD wouldn't have prioritized it. We're not going to have more space for blobs and the posture blobs is going to go through the roof as demand souls. So it's more heads up that like hey, if this is something that you can see impacting you, which I definitely can see being a use case without knowing the details of what's happening for any particular L2. But just in general I can definitely see this happening. And so it's supposed to just be encouraging like hey, you should stop making some noise about this if this is something you are thinking about or their potential for.
00:16:58.185 - 00:17:44.555, Speaker A: Right. Although of course again, you know, just to not make Alex too nervous, this is with the understanding that there might be there, there are very practical limitations. Right. Like it's. The fog is very large and so even with a lot of public support for appear as soon as possible, it's very much not clear that it would be possible to ship this in a combined way. But of course if to the extent that this decision is up in the air, of course having feedback on how urgent this would be is of course always helpful to inform that decision, then I think we can probably move on to the next agenda points. Specifically, Max is not yet on the call.
00:17:44.555 - 00:17:58.491, Speaker A: I know he's. It's Very unclear whether he'll. He'll be able to make it. So I can. I can basically fill in for him there. But I would then prefer if maybe we have Andreas go first and then. Then I'll see to towards the end whether Max stood up or not.
00:17:58.491 - 00:18:13.005, Speaker A: And so yeah Andreas, you wanted to basically report back from this these specific working group sessions and wanted to schedule some calls. So go ahead.
00:18:15.585 - 00:18:30.937, Speaker D: Thank you. Yeah, let me. Let me. So the. Let me give a little bit of background. So there have been so first first item are the. And I think that's it relatively speaking easier one are the altitude transaction status.
00:18:30.937 - 00:20:01.455, Speaker D: So it's like harmonization standardization. The. So there there was was a discussion in the roll call telegram channel and there were some that sort of like prompted the working group within the Ethereum open community projects to take that up and make a proposal. What could be sort of like a minimal set of transaction statuses that would be palpable to different L2 clients given the fact that there's significant implementation variances so that there can be additional transaction statuses that are specific to specific outfit clients. Put out a youth magician post and also on an RIP issue had several discussions by the feedback several discussions feedback from different L2s. And so it's like there's a current state of the specific that. Let me share my screen here just to.
00:20:01.455 - 00:20:06.699, Speaker D: Can I. Can I share.
00:20:06.867 - 00:20:11.535, Speaker A: Yeah, let me. One second. Let me figure out how I can approve that.
00:20:13.675 - 00:20:15.175, Speaker D: Just sent a request.
00:20:16.595 - 00:20:18.665, Speaker A: Yes, I think. I think you should be able now.
00:20:18.835 - 00:20:20.425, Speaker D: Okay great. Thank you.
00:20:22.525 - 00:20:28.661, Speaker A: Appreciate it. It's loading for me now. I can see your screen.
00:20:28.733 - 00:21:00.145, Speaker D: All right, so this is just the. This is just the layout for the OASIS Spec Introduction overview glossary. It's not really. I don't want to waste people's time. What really is the. Is just want to briefly go over the. The statuses also just so for everybody's benefit you want to look at it directly.
00:21:00.145 - 00:21:32.875, Speaker D: Here's the. Here's the link. And then also there's a PR for that. So we have broken up the different statuses in three dimensions. Definition, trust assumption and transaction status code. So similar to an HTTP code. So we introduced the different statuses.
00:21:32.875 - 00:22:31.789, Speaker D: L2 pending, L2 replaced, L2 drop confirmed, L2 included, an L1 pending. Then L2 included, L1 included and L2 finalized. L1 finalized. So there was some discussion around finalized versus included is basically if it's included in an L2 or should it be finalized? Is the transaction always finalized in an L2? What is included in an L2 block or not. What does it mean when it comes to decentralization of the sequencer? So there was some discussion around it. I think the loosest wording and definition was around included. That leaves the option open that it may be.
00:22:31.789 - 00:23:16.535, Speaker D: It may be finalized as well and agreed that only once it's finalized on the L1 you could call it finalized on the L2 in order to be all encompassing question. Have people had a chance to take a look at this or would it be helpful to just briefly walk through sort of like the most relevant ones. I think the first four are relatively straightforward but maybe the last three. Or is that not just asking if it were helpful to do that?
00:23:19.315 - 00:23:27.175, Speaker A: I think as long as we time boxes and basically not have it be too long. I think it's actually it might be helpful if you briefly.
00:23:27.925 - 00:23:42.205, Speaker D: Yeah maybe just the last two. So it's. It's which are. I think that's where was most of the discussion was around there because it's. It's. If it was included in the L2 again could be finalized. Let's.
00:23:42.205 - 00:24:24.395, Speaker D: Let's do this. Just the definitions of L2 included L1 pending. Then the definition is an L2 transaction included in L2 block but not yet submitted to the L1. The trust assumption here is that the L2 inclusion guarantee is depending on the submission guarantee of the L2 block to the L1 and the L1 finalization as a transaction code. Basically L2 T00.500 so have a little room to grow and people to use other transaction codes wanted to if there's. If if they needed additional transaction statuses in addition to those not replacing those.
00:24:24.395 - 00:25:29.345, Speaker D: Then the Next one is L2 included L1 included which is an L2 transaction included in an L2 block included in an L1 block that is L1 finalized. First assumption is the L2 inclusion guarantees dependent on the L1 block finalization containing the L2 block. And then the last one is L2 finalized L1 finalized. Then the definition would be an L2 transaction included in an l2 block that has been included in a transaction in the finalized L1 block. Just assumption here is the L2 transaction finalization guarantees equivalent to an L1 transaction finalization guarantee in a finalized L1 block. And then there are some requirements around just to be transaction code must be an alpha numeric strength and a testability statement. That's just a requirement for the specification which I think is a good practice.
00:25:29.345 - 00:26:00.775, Speaker D: By the way if you have a. If you have a requirement in a spec you should have a logical test there. Yeah, so it's. It's. You wait for final. Yeah, go ahead. Ansuka.
00:26:01.635 - 00:26:56.049, Speaker A: Yeah, because I also wanted to address with Elias's question and it's actually. It's interesting in this context. So indeed the kind of the. The question of course of L1 inclusion and then finalization. And there is actually an additional concept now on the L1, which is work that Francesco has been doing together with some other collaborators in the past around the confirmation rule, where basically it takes some. It basically you could think of it as some sort of like optimistic finalization where it looks at the attestations as they come in and basically under certain circumstances and you can basically set a safety threshold already can consider a transaction basically optimistically finalized or basically it's kind of locked in and it won't be. Won't be react anymore once it hits a certain threshold.
00:26:56.049 - 00:27:31.497, Speaker A: And that would be. The hope would be that like. Because right now oftentimes exchanges and things like that, they still just use a number of blocks as the de facto kind of standard for confirming transaction. Because the full finalization of L1 is relatively slow, like 12 minutes optimistically even in best case. So the hope would be that this new confirmation rule could basically be the best of both worlds, where it basically is fast, but actually is more substantive than just waiting a few blocks. And that is not yet rolled out in any clients. But it's something that I think would be worth paying attention to.
00:27:31.497 - 00:27:53.825, Speaker A: Although of course it's not super relevant in this L2 context. Or rather maybe that could be a question to Andreas. My understanding would be that most of the time this kind of status seven that you have there, L2 finalized L1 finalized, the time constraint, the binding time constraint there, or the thing that comes later is usually probably the L2 finalization anyway.
00:27:53.865 - 00:27:54.113, Speaker B: Right.
00:27:54.169 - 00:28:18.675, Speaker A: The only exception I could think of would be very fast proven ZK L2s. But so far I think that's not. Not the standard. Usually they take their trailing a little bit in their proofs anyway. So I assume basically speeding up the. To basically replacing the full L1 finalization with something that is more something like the confirmation rule. Optimistic finalization would probably not actually change much.
00:28:18.675 - 00:28:23.249, Speaker A: Right. Because you'd still have to wait on the L2 finalization part of it. Right?
00:28:23.427 - 00:28:42.077, Speaker D: Yeah, correct. So these could be additional codes that are in. You know, if that optimistic rule were introduced, you could. You could still. One could add additional codes here. Right. But before that exists and is there.
00:28:42.077 - 00:30:30.808, Speaker D: I don't think it makes sense to do it. And the spec does not exclude different clients to add additional, to add additional statuses in between that are, you know, depending on how they're, how they're structuring it, what the, what, what type of DA they're using, etc. Right. So the, the point is that they're trying to leave more room to sandwich in additional codes if they become relevant. Hence also the status codes give fairly liberal space to add additional transaction codes. I haven't looked at the latest one, so just always Hai Chen feels a bit too complicated to include the L1 block finalization status. Well, so comment to that is if your L2 can be reorced or there's the possibility that the L2 can be reorged, then it's really important to know whether the L1 is finalized because then the L2 cannot be reorged anymore.
00:30:30.808 - 00:30:58.305, Speaker D: So if, obviously if the L2 is, is finalized and it's just even if the L1's reorg, you're just resubmitting the transaction. That's one thing. Right. But if it can be reorg depending on the architecture, if you have optimistic roll ups, then we have disputes resolution, et cetera. So that's a possibility.
00:31:01.055 - 00:31:42.895, Speaker F: Yeah, I kind of agree like this. So the main point is that so L2 has its different status for whether you submit the data to whether like first they included the transaction in the L2 blocks and then whether this transaction has been submitted to the layer one for the DA and then whether the finalizing has been set on the layer one. So they're like the kind of three to four status for the L2 transaction alone. Then if you multiply by the layer one status, like it could be layer one block finalized or not, then that kind of like you can grow from the 4 status to maybe like 12 or 8 or 12 status, I guess.
00:31:44.395 - 00:32:10.133, Speaker D: But that's dependent on your client, right. So if you want to include them, right. So this is sort of like the minimal set, right? If you have that, that's like the minimal set that should be adopted if there are additional statuses that, that your client has. Sure. It's like add them. Right. It's like you can sandwich them in, in between the different, the different statuses.
00:32:10.133 - 00:32:30.825, Speaker D: It was just sort of like what sort of like what is the minimal set of statuses that, that everybody will have in common just to, to give at least a more structured framework for wallets and end users.
00:32:34.885 - 00:33:06.705, Speaker F: I guess I can maybe have a quick clarification question on between 6 and 7 like this so it's like L2 included and L1 included. But do you need that the transactions are submitted to L1 that includes L2 transaction data and then that L1 block, does that require the L1 block to be finalized or not? Because I think on the seven you require this transaction to be included in the finalized L1 block.
00:33:09.845 - 00:33:44.445, Speaker D: So included means it's not yet L. It's not yet L1 included just means it's. It's included a block but hasn't been finalized yet. You haven't waited the. So you have a super majority on the, on the, you have two super majorities on the, on the link, right. So the 12 minutes the L1 included just means that it's you, you have submitted it, it may be reorged, likely not. But if it is right.
00:33:44.445 - 00:34:07.435, Speaker D: Then what happens? It's like you, does the L2 have to resubmit it and it's still in the L2 block? Or are you going to actually reorg on the L2, right. Because now you're. Your thinking is off, right? It may not.
00:34:08.535 - 00:34:19.395, Speaker F: Yeah, that's like my main question is do you want to have L1 included and L1 finalized as 6.5 status here?
00:34:23.575 - 00:35:08.249, Speaker D: Well, if it's for you'll have the transaction that Deal two transaction that points to the block that contains all the transactions. I mean there might be additional ones. So again it depends on how you're doing of the data. Do you do your commitments to the batches on the L1 and what happens if they are in different slots? Right. So if, if you. Then, then you, you can't and if that gets reorganized, then you really have to reorg your L2 block. But if you don't do that then it's, then you don't have to do.
00:35:08.249 - 00:35:43.827, Speaker D: Do reorg on of the L2. So there, there are a lot of nuances in, in between six and seven, right. This is just to say it's like hey, this transaction, this L2 block is, is included. That's like done. And it has been included in a slot in an epoch. That's it. Right? It's not, it doesn't make any statements about, you know, have you submitted patches before that are.
00:35:43.827 - 00:36:47.305, Speaker D: That are now that might be in previous slots or not? Or is this just your state delta that you've submitted with one and you know, everything is now and virtually everything else is in blob space. So there are many different approaches here that the different clients are taking just between, you know, between status 6 and status 7. So I think they're basically just a. The goalposts so to speak, the sticks as they say. And there can be like a whole lot of other different nuances and statuses in between. If clients want to give more detailed and granular information as it may be relevant to the different products that are running on that L2. I don't know whether that answers your question or your comment.
00:36:57.045 - 00:37:33.215, Speaker F: Yeah, I think I kind of get it. So one follow up question is like you don't. I mean you were just deemed like the layer 2 transaction is finalized as long as the transaction data is included in a finalized layer one block that is DM as the finalized, that is the status seven. So for the ZK rops, if the ZK proof was submitted to the layer one, that doesn't make any changes in this transaction status, is that correct?
00:37:34.305 - 00:38:00.535, Speaker D: When the proof is submitted with the, with the. That's the, that's the proof is submitted and verified then and that transaction is then in the finalized blob, then that would be status seven. Until then there would be status six.
00:38:11.235 - 00:38:18.067, Speaker F: Yeah, okay. Yeah, probably like I was thinking a little bit more like to give some more comments please.
00:38:18.171 - 00:38:41.273, Speaker D: Yeah, give give, give comments. I put the link in the, in the chat. This is not done yet. Right. It's like we're, we're really eager to get more feedback and you know there's also, there's an issue also that's related in the repo you can. That points to the magician post. If you want to post there.
00:38:41.273 - 00:39:08.695, Speaker D: You want to comment directly here on the, on the, on the pr, please do. Right. I mean this is, this is not, this is not yet in stone. We, where you know we're trying to get as much feedback as possible. But I think it's important to have at least some goalposts there that, that are, that everybody can, can agree on.
00:39:11.675 - 00:39:25.717, Speaker F: I just have like one another question like that. Just speaking for other ZK robs like when they submit a state diffusion, how does that change? Like is that also you were thinking like a. Similar to the, like the definition of.
00:39:25.741 - 00:40:52.813, Speaker D: 6 and 7, the state diff is exactly the same. It's like that it fits in right? I mean it's, you're submitting what exactly is in that? What exactly the data is that you're submitting as to the L2 state. And what the proof for verification is, is not really relevant. I mean it's relevant for the client but it's not like for the transaction status. It's not because there's just a goal Post Right. Posting. Do you want to, do you want to say something with regard to Starknet? Yeah, I don't know.
00:40:52.813 - 00:41:38.001, Speaker D: Ordering in the L2 block is. That's really, I mean that's, that's relevant. But I think as far as the status here are concerned, it's not necessary to consider. I mean, what could, what, obviously what could happen if you, if you, if you have a, if you have a reorg on the L2. So there's a, there is a question. What happens if you're, if you're, if you, if you have a. If your consensus on the, on your sequencer is slower than the consensus on the.
00:41:38.001 - 00:42:42.465, Speaker D: On the. Until L1 is finalized. Right. So where you could, where you could have a reorg on the L2 but the L1 is actually faster in the final station, that would be a problem. So again, this is just to start the discussion to get things going to have the client teams think about it and see if they're, if they're, how. How they're fitting into this, into this proposed framework. So.
00:42:42.465 - 00:43:44.061, Speaker D: Any more, any more questions? Oh yeah, on. On between. Sorry. See the discussion in the, in the chat about you know, what's, if you have confirmed whether that's like confirmed with ordering or not. So I think that's. So I think. Oscar, what do you want to do? Do you want, do you want the discussion on the.
00:43:44.093 - 00:44:10.445, Speaker A: Right. Yeah. So I was typing, typing as you ask this. So basically, yeah, I think my understanding is that you also wanted to schedule with interested people in this group some future calls to dive more into this. Right. So then I would say it's probably better to keep it for now. I think there's also one other topic you wanted to summarize as well, if I understand correctly.
00:44:10.445 - 00:44:24.685, Speaker A: So maybe otherwise, so that we just keep it somewhat. Time box maybe best to move on for now then. And also with these calls it's better than people know to show up if they're interested. Whereas like here, if we spend too much time and then some people maybe missed out on, it would not be ideal.
00:44:24.725 - 00:44:52.785, Speaker D: Right. Yeah, I think, I think we should, we should just schedule maybe for next month or later in the month a breakout session for just that particular topic. I think everybody would. There seems to be enough discussion potential to have something dedicated that it's then also, you know, properly advertised that that's specifically for that.
00:44:54.405 - 00:45:09.189, Speaker A: Yeah, I agree. And just to say I'm not sure that right now Carl and I have the ability to like necessarily at least commit to kind of co hosting, such A call.
00:45:09.237 - 00:45:09.517, Speaker B: So.
00:45:09.581 - 00:45:29.277, Speaker A: So maybe I think it would be best if we schedule it more like as kind of a call led by you. Yeah, yeah, yeah. And use your. Advertise it, but have it not. Not like I don't want to commit yet to like, you know, it being necessarily part of the roll call directly, but I think it doesn't really make a difference.
00:45:29.461 - 00:45:36.905, Speaker D: Yeah, I mean it's like. It's like it doesn't matter who's. Who's zooming zoom link where we're using. Right.
00:45:39.245 - 00:45:41.845, Speaker A: Yeah, exactly. Just wanted to mention it.
00:45:41.965 - 00:46:01.075, Speaker D: Yeah, and I'm happy to host that. Not a problem. Right. We just need to coordinate on a date. So maybe in two weeks. 25th.
00:46:09.255 - 00:46:15.863, Speaker A: We don't have that many people on this call right now, so I could imagine that it might be a bit hard to try to do live coordination on it on a date.
00:46:15.999 - 00:46:29.275, Speaker D: No, no, no, I know, I know. It's like. It's like. What I'm saying is like shall we advert just advertise for the. For it to be a dedicated breakout session in two weeks and then we'll just. We'll just put it on the books.
00:46:31.655 - 00:46:33.855, Speaker A: Yeah, I think that seems reasonable to me.
00:46:33.975 - 00:46:50.725, Speaker D: Okay, good. Cool. I'll send you the zoom link over. We can do same time 1400 UTC. Cool.
00:46:52.585 - 00:46:57.865, Speaker A: Okay. And then there was one more topic. You also want to talk like a JSON topic here, right?
00:46:57.945 - 00:46:58.161, Speaker B: That.
00:46:58.193 - 00:46:58.409, Speaker A: That.
00:46:58.457 - 00:47:19.255, Speaker D: Yeah. So. So. Yes, correct. Let me. Let me wait a second. Yeah.
00:47:19.255 - 00:48:40.715, Speaker D: So the AP. The API so we had that sort of like has been cooking a little longer. This was a transaction fee API spec based on the transaction fee spec that the L2 working group did earlier. But this was. We had and had shared like two schemas for a post and a get so in order. So the first. The first spec here is for suppose and it's for an estimate.
00:48:40.715 - 00:50:06.605, Speaker D: So what's your. What's the estimate for an L2 transaction fee. And then basically the inputs would just be the transaction call and and the chain ID as required elements and where the. You would basically just have the as an object and required is only from input and the value and then additional There are additional optional parameters here which is all in line with. With what currently exists in addition to their like three things which is the transaction priority the currency if it's not. If it's not if clients allow for that be priced differently than just their native protocol token it could be even in fiat and besides those transaction priority if they want to if the estimate is for particular priority Then currency as I said, and then the chain ID as a. As a required one.
00:50:06.605 - 00:51:15.165, Speaker D: So it's, it's clear that was actually meant for that client and not for another. And the fonts is basically just has three elements. The actual execution fee, the data fee, the priority fee and then the total. And just to give one example, for example, the execution fee has as a value for the currency, the gas and then the price. They're optional. There's some optional parameters in there as you can see, besides the value, the value of the gas and the price itself. It's the L2 gas gas price derivation method and the output price derivation method source.
00:51:15.165 - 00:52:00.985, Speaker D: So it's just to include. To make sure that it's clear how that price is derived at. And that is. So for the, this was just the example for the execution fee. It's the same for the data fee and the priority fee except the priority also now has the priority status of that as a, as a string. Um. Any questions on the, on the, on the, on the estimate transaction fee.
00:52:00.985 - 00:52:39.095, Speaker D: Estimated transaction. Yeah. So there the. We discussed the different derivation methods and it. Yeah, it's done, it's done differently. Especially the data fee has a lot of different components, you know, depending on what the, what the different different what DA is and so forth. So the definitions are broad enough that it encompasses the.
00:52:39.095 - 00:53:44.319, Speaker D: All the different, all the different variances. And that's why the, why we included the, why we included in the responses the derivation method and description and the source as a. As optional parameters in order for. For. For clients to be able to publish out directly their, their, their details so people can see what the differences are. Which is by the way also required. If you're actually, you know, have clients that are for example in the US that's actually what becomes a legal requirement because of the US regulator, the FTC requiring fee transparency.
00:53:44.319 - 00:54:12.325, Speaker D: But that's just as an aside. No, but it does not, it does not preclude that alias. So, so it's not. It's. It's. You can. You can.
00:54:12.325 - 00:55:34.319, Speaker D: You can obviously you can add additional additional elements to the, to the objects. And I think if it's, if it's, if it's required that this is going to be priced out differently, then obviously we'll will introduce different gas types. Does that make sense? And again this is, again, this is open. That's why we want, that's why we want like feedback here. Right? What do we need to do to get that? To get. Yeah, as you said, to get. To get.
00:55:34.319 - 00:55:43.335, Speaker D: To get buy in what are the. And they. They actually the. The. So both members from. Both from. From.
00:55:43.335 - 00:56:15.597, Speaker D: From Arbitrum and Optimism have been participating here in putting this together. So sort of like a current minimal. Minimal level of agreement. But again, it would be good to actually hear directly from the. From the. From the client team lead. What that.
00:56:15.597 - 00:56:24.625, Speaker D: What that would be. So again, I would. I would. It would be good to have a breakout session for this.
00:56:25.025 - 00:56:37.777, Speaker B: Yeah. So I was about to jump in because also we are about to end to. To. To reach the hour. Of course, the call is scheduled for another 30 minutes, but from experience, often on the hour, a lot of people have to drop. So just understand. You would.
00:56:37.777 - 00:56:48.481, Speaker B: You're trying. You're. You're going to. You want to host two separate calls, like one on this other topic and then one on this. Okay. And did you have a date in mind for. For the.
00:56:48.481 - 00:56:49.645, Speaker B: For this one as well?
00:56:52.275 - 00:57:10.850, Speaker D: We could do it. So we had the 25th. We could do it. Like, what do you, like, a week later, October 2nd or a week earlier? That would be one week. Give people time. Like October 2nd or October 9th.
00:57:10.912 - 00:57:18.691, Speaker B: Well, October 9th, if you @ least want to reuse the roll call time slot, then of course, that would just conflict with the next roll call. So October.
00:57:18.763 - 00:57:25.255, Speaker D: Right. So then I would say, should we do, like, the 2nd or the 16th? What do you think?
00:57:29.515 - 00:57:39.555, Speaker B: I don't really know, like, how much overlap this and like, between those. And so basically how much extra preparation time you think people will need? I would kind of leave that up to you. I think either works.
00:57:39.595 - 00:57:39.867, Speaker D: Really.
00:57:39.931 - 00:57:40.695, Speaker A: Honestly.
00:57:41.075 - 00:57:53.805, Speaker D: Okay. Yeah. I think maybe give it a little more time like for this, for the, for the. For the API. So let's do the 16th then.
00:57:56.785 - 00:57:58.485, Speaker B: Okay, sounds good.
00:58:00.025 - 00:58:13.855, Speaker D: Okay, great. So we'll coordinate. I'm happy to host the, you know, both of them on the 25th for the status L2 transaction status on the 16th for the APIs back.
00:58:18.675 - 00:58:31.135, Speaker B: Good. And did you have. I feel like there was something on an IP as well, or is it. Was that already basically. Was it basically this as an IP or something. Something separate or.
00:58:32.115 - 00:58:42.499, Speaker D: Oh, no, this is the other one. Is the. Is the sort of like the definitions of what it. What. What a data fee is? Execution fee, priority fee. That's a. That's a.
00:58:42.499 - 00:58:45.535, Speaker D: That's an. All right, people, we're. We're out of time.
00:58:45.955 - 00:58:57.363, Speaker B: Okay, yeah, yeah, yeah. Then. And. Because then I would probably want to briefly just go back to the kind of the other topic that Max asked me to bring up and then wrap it up if that's okay with you? Or is there anything last year?
00:58:57.499 - 00:58:59.539, Speaker D: No, no. Awesome. Perfectly fine.
00:58:59.707 - 00:59:41.041, Speaker B: Well then thank you. Thank you so much for leading this, this, this part of the call. And then, yeah, like so last topic, Max unfortunately wasn't able to make it today, but he asked me to briefly mention. So there is his proposal to basically increase the minimum price that a Blob costs on mainnet right now that is set to basically one way. So, or at least there's a unit of Blob gas and that costs one way. So basically the price of a Blob right now can go all the way down to basically free. And that's indeed where we currently are in the equilibrium because we don't yet have enough demand to actually go beyond that.
00:59:41.041 - 01:00:21.649, Speaker B: So right now Blobs are basically free, which is not a problem at all. But the problem arises every time we basically have demand spikes that get us to. Now the market price would want to be above free. And because of the kind of the feedback mechanism, the 1559 style feedback mechanism that the Blob Free also uses. And that just takes some time to ramp up to a new equilibrium price whenever there are big changes in demand. And because it has to come from such a low level, it basically takes a lot of time. I forget the exact number, but it's like I think half an hour or something to basically get to any normal kind of non totally free price level.
01:00:21.649 - 01:00:54.241, Speaker B: And so for like half an hour there's basically just no efficient pricing. And so you always fall back to these priority fee auctions which have the additional drawback that with Blob transactions specifically they are a little bit more complicated because they're measured in normal gas, not Blob gas. So there's some, some, some issues around that. Anyway, it would be preferable if these ramp up times would not be so long. And so a Max basically proposes that in the next hard fog. And my feeling is that would be part of the basically the first half of Pectra no matter what. So that would basically come soon.
01:00:54.241 - 01:01:37.515, Speaker B: We basically just raise the floor from base from completely free to something that is basically effectively still kind of free. So it's not meant to actually raise any revenue, it's not meant to actually cause any strain on any of the L2s. It's really just meant to be as close to this kind of the sensitive price range as possible so that in the case of a demand spike it can basically ramp up more quickly. Of course this will no longer matter once we hit, sustainably hit at least the target throughput level for blobs. But given that so far in over half a year we have not done that yet on mainnet. The idea is let's just chip this just in case because otherwise we keep having these kind of occasional 30 minute windows of kind of price chaos. Now Max wanted to specifically ask feedback I think.
01:01:37.515 - 01:01:48.065, Speaker B: Let me, let me, let me. Oh, I just see my great timing. My Chrome just crashed. Let me actually. I don't know where is it.
01:01:51.405 - 01:01:51.789, Speaker A: One.
01:01:51.837 - 01:03:10.941, Speaker B: Second, let me look up the exact number that Max proposed. So basically he figured out a number, it's 2 to the 25, whatever but specifically that would come out so that blobs would at a minimum now always basically cost at current ETH prices more or less $0.01. So basically you could imagine if a blob transactions come transaction comes with four blobs that would basically at least cost 4 cent plus whatever it consumes an execution right. Which is not affected by this change of course as the eth price say 10x's then the minimum price now would basically effectively be 10 cents. The idea was that this is chosen low enough that it really doesn't actually effectively influence the layer 2 transaction prices at all but be basically like high enough so that you know it doesn't have to go to too many kind of orders of magnitude to reach a reasonable price range once there's such a demand spike. Now of course the concern is if L2 say that this is still a little bit too high, say maybe I don't know those $0.01 per blob is a little bit too high for use case or something you'd rather see it a bit lower or of course the other way around, you think it's a bit too low and it still has a bit room to be raised to be more sensitive to price to demand changes.
01:03:10.941 - 01:03:26.741, Speaker B: And now would be a really good time to give that feedback because otherwise probably the ERP will start to move forward and it's always harder to change these parameters once the IP is accepted. So of course either if there's where we can find more information about this there's an erp.
01:03:26.773 - 01:03:27.093, Speaker A: Let me.
01:03:27.149 - 01:03:51.659, Speaker B: Yeah, that's a good point. Again my micro crashed in like the worst moment but I found the link. So this is the link to the ERP draft. I think in the rationale there's basically he reasons through all these kind of specifics around the. The pricing. Yeah. So I'm just wondering again like we have very few people now, many people are ready to drop if anyone on here already has some specific opinion.
01:03:51.659 - 01:04:32.797, Speaker B: Otherwise, of course, if you know, you can, you can talk to your team or if someone sees this recording, just basically contact us right in the roll call channel or reach out to Max Raznick directly. That would be really appreciated feedback. So I don't know if anyone has something right now. Yeah, I wasn't, wasn't assuming that. So then, yeah, then just as a psa and yeah, do let us know if you're very opinionated about this. Okay. I mean, of course we always have an open section at the very end.
01:04:32.797 - 01:05:05.215, Speaker B: So is there anything specific left that we would want to talk about today? Otherwise we can. We can end the call. Okay, then. Well, thank you all very much for showing up today and see you either on any of these Andreas calls or I guess we will only have one until next Roll call or then next month on next Roll Call. Bye everyone.
01:05:07.995 - 01:05:08.875, Speaker D: Thank you. Thank you.

00:00:06.720 - 00:00:35.424, Speaker A: Okay. Welcome everyone to sequencing and preconfirmation call number eight. Today the topic is research and development that has been done by lime chain, specifically on base sequencing and base preconfirmations. My understanding is that they got a grant from the film foundation which has now been complete. And I guess this is part of the outcome of this grant. George, the floor is yours.
00:00:36.124 - 00:00:57.806, Speaker B: Thank you. I'm assuming you've seen my screen. Yep. Okay, cool. All right. Yeah. Well, thank you guys for the, for the time.
00:00:57.806 - 00:02:18.602, Speaker B: As Justin said, we applied and got a grant to research based pre conformations from Ethereum foundation. And very quickly we realized a couple of things. First thing, first thing that we realized is that actually pre conformations are not per se the end goal, but they're just a feature of sequencing. So we needed to figure out, okay, well, what is the form of sequencing that lends itself the best to preconformations? And then yet again, going one step further, we wanted to examine the fundamentals of decentralized sequencing in order to prove to ourselves and prove to the readers why we believe that actually base sequencing is the thing to go, and then make the case for pre conformations. And then we are able to go into a little bit more details into how would one implement the pre conformations and the whole base sequencing thing, including the modifications of the software that are needed, mechanics on opting in, et cetera, et cetera. So this is what we're going to be talking about today. And I'll start with a controversial statement.
00:02:18.602 - 00:03:07.394, Speaker B: Centralized sequencing is actually cool. And centralized sequencing is actually cool because first of all, it offers great ux for users. It offers fast pro confirmations. It's very easy to find the sequencer. It's easy to bootstrap a roll up that has centralized sequencing and normally generates normally massive revenue for the roll up if it gets adopted. But this is until it isn't, because centralized sequencing also is a massive target and any liveness fault within the centralized sequencer can hold the roll up like something that happens with inscriptions to one of the rollops previously. Also, there are potentials for censorship and potentials to monocleize the fee market and pretty much move the price any way they want.
00:03:07.394 - 00:03:58.194, Speaker B: And we don't really like these downsides. And we need to do something about this. And the obvious thing that we can do is to try and figure out what actually decentralized sequencing looks like. So let's go through a little bit of a thought experiment and quickly design the centralized sequencing. And before designing decentralized sequencing, I wanted to highlight the five guiding goals and principles that we have worked out of in order to be able to design centralized sequencing. And you'll see all of these are intertwined and ingrained within the concepts that we have researched and we are proposing now. The five guiding principles are secure without UX sacrifices, economically sustainable for all actors.
00:03:58.194 - 00:04:37.114, Speaker B: And this also includes the roll up and the roll up team. Decentralized sequencing enables compostability over walled gardens, inherits ethereum liveness over external liveness guarantees, and there is a protocol over trust based censorship resistance. So we have been designing with all this in mind. So we started our research and we did this thing. Don't squint, it's purposefully unreadable. But we essentially traversed the whole design space for decentralized sequencing. And I'm quickly going to walk you through what we found.
00:04:37.114 - 00:05:29.786, Speaker B: This is the thing that we found. First of all, decentralized sequencing hands it's not that easy to actually design decentralized sequencing as many people that have tried to do so have found out. One way that you can design decentralized sequencing among whole group of design approaches is free for all sequencing, which is essentially a completely open and permissionless sequencing. Anyone can submit sequencing transaction and sequence your, your roll up. This however is suboptimal, especially when you consider user experience because it's hard to support pre conformations. You don't even know who to ask for pre conformations, even whether they are actually going to be able to honor these pre conformations, and if they have the control to honor these pre conformations. And also there is a huge potential for censorship or frontrunning.
00:05:29.786 - 00:06:49.734, Speaker B: So the whole group of free for all sequencing approaches, we kind of discarded and we went for the other group of approaches, which is leader election. And one of the most popular way that people have been designing decentralized sequencing and exploring the designs of centralized sequencing is through external consensus algorithm, which is essentially you building your own consensus algorithm, running your own BFT, having your own validator set and then electing a single leader. And this leader is the one that can be submitting the sequencing transactions for your roll up. And this is great because during their monopoly time when the leader is elected, they can offer centralized like UX for example, pre conformations. However, when you are just having an external Twitter consensus algorithm, you start lacking two things or you are complicating two things. First of all, you have lack of timeliness guarantees because a randomly elected leader based on your concess algorithm actually doesn't have hundred percent guarantees that they can actually include their transaction on time. And by on time we mean within the slot that have been allotted for them to be putting these sequencing transactions.
00:06:49.734 - 00:07:47.254, Speaker B: And there is actually only one actor that can do this that we're going to be talking about just in a second. But the second downside for external consensus algorithms is that actually it's quite hard to prove that the leader selection was correct to l one. You can do stuff like ZK for that. But if we're looking for robustness, if we can figure out a system that doesn't require proofs for selection correctness, it's going to be much optimal system. And then we end up with the original based sequencing concept proposed by justing, which is a leader election concept. And it offers centralized, it has leaders, so it can offer centralized like UX for example, pre conformations. It adds timely timeliness guarantees, because essentially what base sequencing says is that the sequencer of the roll up is going to be the l one proposal.
00:07:47.254 - 00:08:46.314, Speaker B: And the l one proposer is the sole actor within three ML1 that can 100% guarantee that they can include a transaction, sequencing transaction within the l one block. And then it's easy to prove the leader selection correctness because you know, it has to be the proposal. But as just the previous time, there is these downsides of the original base sequencing concept. That's the sequencing gaps plus cold start. Like how do you bootstrap actually based sequencing? And just in proposed some of the ways that you can do so. And we are also having the same thoughts of how do you bootstrap this and basing ourselves on the base sequencing, no pun intended here we actually are suggesting now something that we call vanilla based sequencing. Vanilla based sequencing is very similar to base sequencing.
00:08:46.314 - 00:09:34.010, Speaker B: It's again the l two sequencing is again performed by opted in l one proposers, same as the original base sequencing concept. There are two types of selections. Primary selection happens whenever the current l one proposal have opted in to be the l two sequencer. So we are immediately giving them the rights to be the l two sequencer. This again same as the original base sequencing concept. And then there is the second fallback selection, which is in the case where the current l one proposal has not opted in to be the current, to be part, to be sequencer of the rope. Then we are just taking one random opted in proposer.
00:09:34.010 - 00:10:46.364, Speaker B: And our argument here is that this actually is addressing the cold start problem and sequencing gaps. Because even in the beginning, if there are very few sequencers, l one proposers that have opted in, they will be able to one of them is going to be to be drawn and they're going to be able to profit from the sequencing fees of the roll up, which means that they're going to be eligible for more and more and more profits. And this should make it very lucrative and very interesting for more and more proposers to actually get on with this sequencing thing, which is ultimately what we are looking for, to have bigger and bigger participation. So if we can think about what vanilla based sequencing is, well, vanilla based sequencing is the original base sequencing concept, plus the fallback selection added on top few notes. You're seeing these numbers, one, four, et cetera, et cetera. These map exactly to these goals that I mentioned here whenever you see them. This is like a property of divanilla based sequencing, through which we are actually satisfying these goals.
00:10:46.364 - 00:12:13.404, Speaker B: So as you are seeing here, leader action immediately satisfies stuff like user experience. This concept supports pre conformations because you can discover your sequencer so that you can ask for preconfirmations. It supports shared sequencing within primary selection, which supports the goal of having composability rather than walled gardens. Something that's requirement for roll ups that are implementing renewal based sequencing is to bet requirement punishment mechanisms. Staking or bonding this is mainly a design decision of the rollouts, whether they want to go for staking or for bonding or rest taking then sequencer profits from fees and mev, which makes it economically viable for sequencers. Roll ups can have revenue by extending the design to include commission out of the sequencer balance increase, which can allow the protocols that are using vanilla based sequencing to actually be economically viable for the roll ups and roll up teams themselves. The sequencers sequencing frequency in the diagrams that I showed you previously, we are equating one l, one slot to one roll up slot.
00:12:13.404 - 00:12:56.516, Speaker B: But this does not need to be so we can discuss the various cases where you can have one roll up slot be multiple l one slots or the other way around within one l one slot to have multiple roll up blocks. And something that's going to become important a little bit later. Roll up sequencing can actually be delegated to external pipeline. Much like currently block building for l one is delegated to external pipeline. Route sequencing can be delegated to external pipeline. And this is what vanilla base sequencing is. It's very close, I'd say like it's 85% to 90% the same as what Justin is proposing.
00:12:56.516 - 00:13:51.394, Speaker B: We just figure it out from the fundamentals. We reasoned it from the ground up and we ended up with very close conclusions to Justin is proposing. And then we went into preconfirmations and yeah, what are we talking when we say preconfirmations? Well, first of all, we are talking about inclusion preconfirmations and execution preconfirmations. Inclusion preconfirmations are the preconfirmations that just guarantee a transaction is going to get included within rollup slot. Execution preconfirmation allows for specifying the desired values of parts of the state of the roll up after the execution of these transactions. The first one is very useful for stuff like simple transfers. The second one is very useful for stuff like arbitrage.
00:13:51.394 - 00:15:12.778, Speaker B: So how do we actually support these two? How do we implement these two? Well, we are proposing two new EIP 2718 transaction types, by the way, you'll see it to do at the end of the presentation. This is something that we are planning to have a roll up implement proposal for, and we are looking for collaborators on this. Obviously, these are going to be serving as pre confirmation requests. The reason that we want to have separate transactions for this is so that they can have tailor made fields for their respective cases and they can have separate pricing and roll ups can actually choose whether to support just inclusion or both types of preconfirmations. And when we talk about these transactions, let's look into a little bit of the properties of these pre conformations. One thing that I wanted to quickly mention is that both of these transactions we suggest to include a deadline field and deadline field is a massive user experience enabler. Deadline field is essentially indication by the user, what's the latest possible disparate confirmation can be alert.
00:15:12.778 - 00:16:11.958, Speaker B: And there are actually two places where this is UX savior. And when I'm saying UX savior, you can think about users needing to click the sign button, type their password, type their ledger pin, or whatever it is there. First is first case where this is like a UX savior is whenever sequencer rejects a pre conformation, and sequencer can. Sequencers can reject preconformations for various reasons. One reason that sequencer can reject pre conformation is that maybe there is a conflicting state already and they cannot honor this preconfirmation. Another reason that sequencer can actually reject pre confirmation is that if pre confirmation requests comes too late within their slots, so they don't have time to build the block with this preconformation in place or delegate it to the block building pipeline. So SQL certs may opt to reject these pre conformations.
00:16:11.958 - 00:17:26.904, Speaker B: And if we have deadline filled within our pre conformation requests, wallet softwares can actually take take this UX inconvenience and just resubmit it to the next leader, to the next sequencer. So this is the deadline field that you will see shortly within our suggested fields for the pre confirmation requests. Another thing that's important to discuss is preconformation pricing. Here again, with user experience in mind, we are proposing that the two pre conformations are priced similarly to EAP 1559 rather than having gas auctions in here. And we would like to enable the RO op teams to actually decide on this pricing. But we want the pricing to be premium on top of the base vas. So basing this on a similar mechanism as EIP 1559, it allows for easy price discovery for users and for wallets, and then the rollups can set the premiums on top of the EIP 1559 base fee for gas.
00:17:26.904 - 00:18:31.384, Speaker B: And each of these transactions can have different premiums on top. This is just a formula for you to get it. It's extremely easy looking into the fields. What's an inclusion pre conformation? It's just a type two transaction with deadline on top of it, which is like, it's very very minimal thing on top of type two transaction execution. Preconfirmation is a little bit more complicated, but as you can see, on top of the deadline field, it also has three constraining lists, and you probably are already guessing it, but they are constraining the state of the resulting roll up because they have the same structure as the Ethereum state. It has a storage, it has a code, and it has a balance list. And each of these essentially contain the requirements of the user for this resulting state after their pre conformation.
00:18:33.244 - 00:18:36.664, Speaker A: George, you have a question from Jonah please.
00:18:37.924 - 00:18:50.344, Speaker C: Hey, this is great so far. Just going back to the previous slide, I'm curious if you thought about allowing payments to be made in an L two's local token, which is probably a better ux for l two users.
00:18:52.514 - 00:19:17.414, Speaker B: We are not opinionated on what is the native token. It doesn't have to be. It's a decision that can be made by each of these rocks. Like what's the native currency of develop is the decision of develop. It's not opinion. This is why we're just saying base fee per gas. But you will not see here, anywhere we're mentioning, it's that amount of ethics.
00:19:18.144 - 00:19:20.124, Speaker C: I see. Okay, makes sense.
00:19:20.504 - 00:20:07.084, Speaker B: Yeah. There was a roll up that we spoke about, about vanilla based sequencing. They had the same question. No, this is not constrained to ETH now. It's a, I guess, business and entrepreneurial decision whether you're going to use it or use your own token. This also comes back a little bit to the question, like about staking, restaking, bonding. Every different roll up team has a different idea of their business model, of their way that they want to operate the roll up, and therefore they have a different preference whether they want to go for restaking of ETH, for example, or staking of their own token, or staking of ETH, or even bonding.
00:20:07.084 - 00:20:45.504, Speaker B: Yeah, cool. I'll just go ahead with the execution per confirmation, see if that's good. Cool. All right. Yeah, the last thing that I wanted to point out here is that the quick asterisks here that if we leave the constraining lists unbounded, they can greatly expand the transaction size. Solder ops must limit their size so that transaction sizes are not like huge. What is the flow of pre conformations? It's just a two step process.
00:20:45.504 - 00:21:26.784, Speaker B: First step is already something that is happening naturally. It just eth send role transaction to send the preconformation transactions acting as a request. It's important here that the sequencer either accept or reject them. Acceptance is returning transaction hash that is now zero, whereas rejection is returning zero hash. This, by the way, is already part of the of the Ethereum spec eth central transaction can return actually zero hash. So we have reused this property to be completely compatible. And then introduction of new endpoint, that is eth get commitment.
00:21:26.784 - 00:22:37.644, Speaker B: And this can be used for the by the user to obtain a pre conformation commitment. Assigned commitment, which is bytes representing assigned commitment for the pre confirmation transaction that they have had accepted and they have transaction hash. What is the commitment? Quite an easy thing is signed bytes by the sequencer that are constraining two things. First of all, which transaction hash this is concerning, and second of all, which l one block number the sequencer is committing that this transaction is going to go through. Whenever you see these like big question marks, I have left things that are discussion points that we can have a discussion on. Maybe after I finish the slides I'll make sure to have like at least 15 to 20 minutes to have discussion on the various discussion points that are here. I wanted to mention one and pin one here, which is lack of timely service incentive.
00:22:37.644 - 00:23:29.374, Speaker B: What I mean here, well, a rational sequencer will delay the commitments for pre conformations until the end of their slot because this is where they have the most search space and they're going to know how to extract the maximum value. This, however, can render pre conformational slow and hurt user experience. The bad part about lack of timely service incentive is that it's hard to detect and enforce punishment for this lack of timely service. There are several options that you can use here. Timeliness committees is one option that you can use here, but it's very complex. Whenever you start introducing committees, you are moving into a very complicated domain. Another thing that has been explored by some teams is decaying payments.
00:23:29.374 - 00:24:53.304, Speaker B: So essentially, the later that you commit, the later that you are actually the lesser that you're going to get paid. Again, this is somewhat easy to game and it's also a little bit hard to implement. Our suggested option that we can discuss later is to have robustness, incentive approach, additional revenue that is offered to sequencers that are actually consistently offering high quality service. And this actually can be roll up opinionated, because this is something on top of the sequencer payments and this was on pre conformations. And this is still all like a little bit of architectural, high level concepts. But we went one step below and we went a little bit more into implementation details, a little bit more into development, and we went into the how do you actually build these things? How do you build these on chain? What do you need on chain? What do you need off chain in order to build vanilla based roll ups and vanilla based sequencing. And this is where we spent the most of our time in our research, because it was something that, it was a new ground that needed to be walked and needed to be explored.
00:24:53.304 - 00:25:48.684, Speaker B: And we came up with this scary thing, and don't be scared too much about it, I'm going to walk you through it. So, first of all, what we are imagining here is that we are going to have an architecture that is proposer centric, and we're going to have a discussion whether having a proposal centric rather than builder centric architecture is the best decision there. I'm just going to go through and describe what are the components and elements that we are imagining here. And immediately you see that the central point, the orchestrating point, is the one proposer. And there is something new. Already there's something new with the red asterisks, which is something that we call GmAT Boost. Gmail boost is a fork update upgrade of Mapboost.
00:25:48.684 - 00:26:43.850, Speaker B: Its main goal is to enable the connection between multiple l two pipelines and l one pipelines. So this design essentially separates the pipelines into a single primary that you're seeing horizontally and multiple secondary pipelines. The single primary pipeline deals with the current l one block building. So the end result of the l one pipeline is a block that is already built, and this is already existent. This is what we know with our PBS, we have Mapboost, we have de relays, we have the builders and everything that's behind, behind the builders. This is how we currently build blocks, how proposers actually get blocks in order to propose that. The vertical thing is the block building pipeline for, it's actually the pipeline for building sequencing transactions.
00:26:43.850 - 00:27:40.208, Speaker B: So for the l two sequencing transactions, so the end result, the end, the resulting artifact of the secondary pipelines are actually single transactions. So the idea here is that we need to actually combine these two. So the vanilla based roll ups, the sequencer that is our proposer, is going to craft one or multiple sequencing transactions for one or multiple base rollups. But these transactions transactions actually need to go through and get inside an l one block. This is the end idea. This is the goal of basic missing for the proposal to be able to make sure that the transactions for sequencing are going to go into the l one block in the slots that they're meant to. In order to do so, we are proposing the things on top of this upgrade of Macboost.
00:27:40.208 - 00:28:23.160, Speaker B: It's called GMAT boost, by the way, g stands just for generalized, so it's generalized mapboost. So we're proposing that the primary pipeline is extended with conditions API, which is an extension API to the external block building API implemented within the relays. This is the ethereum external block building API. It's backwards compatible, and it allows the proposer to specify validity conditions over their blocks that the relays needs to turn forth. And when I say validity conditions, I mean complete transactions. Is there a question? Okay, yeah. G stands for George.
00:28:23.160 - 00:29:18.638, Speaker B: All right. Yeah. So yeah, the conditions API is an extension for, of the, of the ethereum external block building API, backwards compatible. We are not breaking anything. So if somebody just installs GMAT boost and just doesn't want to be a sequencer, but wants to continue participating within the, within the current block building pipeline of l one, no problem. It's going to go through for the GMAT boost in order to, for the secondary pipeline, we are proposing something that we call pipelines API. And the pipelines API is the way that the proposers roll up nodes are able to submit these l two sequencing transactions that are going to go to GMAT boost.
00:29:18.638 - 00:30:25.754, Speaker B: And then GMAT boost is going to, through the conditions API, submit it to the primary pipeline so that the builders actually build conforming blocks. And I'm going to move on from this scary diagram because I know it's complicated. There is a simpler version here that. Yeah, I essentially walked you over it. I'm just going to quickly tell you about each of these components a little bit more. GMAT boost the goal, as I said, enable the convergence of DL two pipelines within DL1 pipeline and enable the proposers to specify validity conditions towards the external building pipeline. So this is why this extension to the external building pipeline API external building pipeline API so that the proposal is able to tell the builders, hey builders, I want you to be building me a block that has these transactions inside and we want to enable the relays to actually check for these if these conditions are met.
00:30:25.754 - 00:31:47.300, Speaker B: And Gmail boost essentially takes the resulting artifacts of the secondary pipelines, the l two sequencing transactions, and combines them and propagates them through the conditions API to the primary pipeline. The conditions API, as I said, enables the proposers to communicate with the external blog builders. There are no breaking changes to the Ethereum builder API, and in practice this is going to be implemented within the relays so that the proposers and builders can communicate requirements with each other. Now it's important to think about security of the conditions API and in order for the proposal to be saved from impersonation and so that relayers can actually trust the proposal and that the proposal is submitting them these conditions, it requires authentication. And this is another discussion point here. What is the mechanism for authentication of the proposal in front of the relay? What we're proposing here is that authentication happens via the validator signature. It requires again Gmail boost to have access to the validator key signing facility.
00:31:47.300 - 00:32:43.654, Speaker B: And I know that this sounds egregious and sounds outrageous, but we feel that this is fine because first of all, GMAT Boost is a software run by the stakeholders themselves. Keys can be accessed the same way that the validator software is accessing them, so you don't need to send them to a third party or whatever it is there. It is still a thing that is on your machine and is only accessed by your own software that you are installing. There is no third party that's getting access to your validator keys, and through these keys we can authenticate the communication between the proposers and the relays. We can have discussion later on on this. I have pinned all of these discussion points so that we examine them later. Pipelines API the pipelines API serves the purpose of enabling the communication between the l two roll up nodes and GMAT boosts.
00:32:43.654 - 00:33:46.374, Speaker B: Again, this communication between Gmail boost and the secondary pipelines needs to be authenticated. Similarly to this happens, in order for Gmail boost to be able to trust requests from the secondary pipelines and the two components are going to be authenticated in a similar manner that is happening, that the authentication is happening between the consensus and execution of their clients, which is JWT tokens. This is something that stakers are already familiar with. So that yeah, essentially want to prevent that. Unauthenticated actors are just submitting you l one transactions for you to sequence within your l one slot. You want to have only your own sequencing roll up nodes to be the ones that are submitting these l one transactions that need to get included within the l one blocks. And these are the sequencing transactions.
00:33:46.374 - 00:34:39.314, Speaker B: And then finally combining after we have these two APIs. Essentially GMAT boost combines whatever we receive from the secondary pipelines and sends it through the conditions API to the primary pipelines. I feel I said this like several times, but I wanted to hammer this point like that. Although this thing looks very scary and very big, it's actually quite an easy thing. You have the vertical things creates you several transactions and the horizontal thing includes them within l one blocks. By the way, API specs and software modifications required are existence within this hack empty. I can send you the links for this later in the chat and in the telegram group.
00:34:39.314 - 00:35:32.736, Speaker B: And something that I promised that we're going to be talking about, which is choosing the pipeline orchestrator. As you have seen, there is, there is an implicit requirement for base sequencing to have a mechanism for submission of the l two sequencing transactions within the existing l one pipeline, right? Well, if we are sequencers, we need for, so we need a way for the l one sequencing transactions to end up within the l two blocks. And then we need to ask ourselves a question. Well, there needs to be an actor that receives this, these submissions, these transactions, and we're going to call them the orchestrator. And they need to make sure that these transactions get included within DC one block. So who's this orchestrator? And we have two options for this orchestrator. One option is to use the builders as orchestrator.
00:35:32.736 - 00:36:59.664, Speaker B: So essentially what I'm saying here is that one option that we can do is essentially ask the wallets to go to the builders and ask them for preconformations or to go through the gateways. And the gateways are going to go to the builders and ask them to include these transactions within their blocks. And this has both pros and cons. The obvious advantages is that the builders are already sophisticated and highly available, and it requires little to no modifications to the existing software because the sequencers or the gateways are going to be essentially acting as a searchers for them. But the downsides are that we can have something that we've called the godfather of roll up syndrome, which is something that hurts the roll up sovereignty. What do I mean by godfather of Rollup syndrome? Well, thing that we currently have a very small group size builders. Any new rob that wants to get to be supported by these builders would need to get some form of blessing of the builders in order to be able to even get started, to have their Rollop serviced by the builders, so that their gateways, so that they accept transactions from their gateways.
00:36:59.664 - 00:38:14.932, Speaker B: And then this is a thing that it might be problematic, it might not be something that we are basing our thinking off is that there were ecosystems within the wider blockchain community that exhibited this godfather of Roloff syndrome. And there were networks like, there were systems that in order for you to launch your own network, you essentially needed to go and ask for permission for a blessing, several actors. And this led to less and less decentralization, less and less networks being launched. And the second, I think, obvious downside of having the builders as orchestrators is the smaller group size. And this can exacerbate geopolitical risks. I actually saw a Twitter thread quite recently, like a couple of hours ago, that made somewhat similar point that there are geopolitical risks with the current builders ecosystem that might materialize within extreme scenarios. Another option then the builders as orchestrators is having the proposals as orchestrators.
00:38:14.932 - 00:39:24.224, Speaker B: So what do we have here as pros and cons? Well, this is based on why they were decentralized group of l one proposers like this, one of the highest strengths of Ethereum, and it enables for permissionless creation and operation of vanilla based rollups. I mean, what I mean by this is that worst case, the roll up team can actually run multiple y. One proposers opt in themselves and this is a form of progressive decentralization because they might start with only their own proposals, but then any other proposal can just start joining in. The downsides of having the proposal as orchestrator is that it requires the adoption of modified version of Mapboost, the GMAT boosting that is used to orchestrate and delegate to the external block building pipelines. All the things that we previously spoke about GMAT post. And this is something that needs to get adopted by Elon proposers. We have chosen to go with this idea to have the proposal as orchestrators.
00:39:24.224 - 00:40:49.294, Speaker B: Our main worry is the downside of the builders becoming godfathers of any roll up. And we feel that if GMAT boost is developed and it's strictly better and more profitable for proposers to run GMAT boost then they're going to run GMAT post. Last thing which is the on chain part. How does actually one sequencer opt in and how does user wallet discover and communicate with sequencers? Sequencers opt in well, the goal for sequencer opt in is to enable l one proposers to opt in sequencers to rollups and advertise their rpcs. We're imagining that this is going to happen on chain through a two step process, process of registration and process of activation. The process of registration is for sequencers that are active validators, is used to advertise their RPC URL's validator BLS public keys that are going to be needed to check them out and they're representing wallet addresses and the registration requires signed message by the proposer so that they can be checked whether they are valid. And active.
00:40:49.294 - 00:41:49.044, Speaker B: Proposers activation is mainly used in order for rollops to be able to define their own activation criteria. And this is where again go again into staking, restaking, staking a feed or maybe staking their own native tokens, but this is what activation is for. After you have registers you need to activate by staking for example. Sequencing mechanics how do sequencing contracts actually like the sequencing contracts need to know if the currently submitted sequence is sequencing transaction is performed by the currently eligible sequencer. And this actually was surprisingly hard because as the meme says, one does not simply know the current l one proposer. You have no access to the current l one proposal. You have the previous one, but you don't have the current one.
00:41:49.044 - 00:42:38.964, Speaker B: So we are suggesting several solutions. Two of them are implementable now, but are somewhat suboptimal. There is a third one that requires hard fork. And as Connor from other mind has said previously, we don't like too much solutions that are requiring several forks in order to come through life. So the first two are at least implementable now. You can have optimistically accept all sequences and include the verification of the eligibility of the sequencer within the proofs of finality or enable challenge period. The third solution that requires fork is to actually to ask Ethereum l one to just tell us who's the current l one proposer so that we can do the checks that are necessary.
00:42:38.964 - 00:44:04.756, Speaker B: Sequencers discovery how does one wallet actually know who's the sequencer? Because the previous thing was how does the rollups contract know that this is the eligible sequencer? Well, wallet just need to check the roll up contract, the staking contract that we're calling here, the sequencer registry. And by the way, for this we also have a full specification with the interface that needs to be complied with. And within the sequencer registry you can just see who's the current, who's the next eligible sequencer. In some cases, you might need to perform some deterministic randomness algorithm in the fallback case in order to figure out who's the eligible sequencer. But if the current l one proposal have opted in, you just need to figure out their advertised RPC URL and just talk with them. And then, as I said in the registration point, opting in proposers validators are just advertising their RPC endpoint and then wallets and users can just use it as normal RPC endpoints. And yeah, this was the on chain part.
00:44:04.756 - 00:44:45.704, Speaker B: I left several discussion points. Maybe I'll just tell you what are the next things that we are that we are planning, and then I will just open the floor for questions discussions. I think that's there. So currently what we are applying for is proof of concept with Tyco in order to be able to showcase the viability of vanilla based sequencing. In the meantime, we are exploring the creation of GMAT boost. So would love to talk with the flashbots team on this. We are also currently drafting rap for pre conformation transactions that I mentioned in the beginning of the talk.
00:44:45.704 - 00:45:27.584, Speaker B: And we are also contemplating on suggesting an EIP for the conditions API, because the conditions API can actually be used for much more than just l two sequencing transactions. And we are looking to talk with any rollop that is willing and wants to explore base sequencing, vanilla base sequencing per se, on what it takes actually to implement vanilla based sequencing. And yeah, that's a wrap. And I have left the discussion points so that we can have discussion if anyone is interested into any of these. I see Jonas has several questions if you want to go through this.
00:45:31.644 - 00:45:57.308, Speaker C: Yeah, I had a quick question, but I might just be misunderstanding a technical point. If you only expose the BLS keys on block m one for the proposer block n, cant you just create a requirement that every base sequencer has to finish the sequence by posting to ethereum state, like the block n bls keys. So you have this invariant that it's always in state unchained or block.
00:45:57.356 - 00:46:33.104, Speaker B: Nice. So whenever you're what you're suggesting here is that whenever the current sequencer is posting the current sequence, they also provide the next sequencer Bls key. Is this what you're suggesting? Yeah, there's something interesting to explore. I have to think more and yeah, let's collaborate on this. This could be a very interesting, very interesting solution. Yeah, absolutely. And I have, I think Max has a question.
00:46:33.104 - 00:47:27.574, Speaker B: Have you asked the addition? Great. Yeah, great presentation. I'm just wondering what the, what this kind of architecture does to l one proposer bandwidth, hardware requirements as you scale it up in terms of transactions. Yeah, well this is going to be best answered when we, when we finish digimap boost architecture. One thing that I think is important to be mentioned here is that we are designing the system to be delegated so that you don't need actually to run additional softwares apart from upgrading or replacing, depending on how do we want to implement Gmail boost of Mac boost. So we are imagining that this is not going to happen. Massive impact on, definitely on hard disk, maybe leave it on cpu.
00:47:27.574 - 00:47:57.724, Speaker B: But then again, the thing that GMAT boost needs to do is just to take two transactions and forward them to the primary pipeline. It's not a problem. Gangster met boost pushes transactions and doesn't need to do any processing. Yeah, it doesn't need to execute them. No, no, it doesn't need to execute them. It's just, it's almost like a dumb pipeline. Just needs to combine them into a single request for, for the, for the relays.
00:47:57.724 - 00:48:03.084, Speaker B: Okay, cool. I see a race hat.
00:48:04.824 - 00:49:11.256, Speaker D: Yeah. Um, hey George, this is also very enjoyable. What I wanted to touch on was more of a kind of, I don't know, a request or a bias. But what you mentioned about delegating the BLS signatures for the like, you know, the actual hotkeys, having them like sign stuff regularly can be kind of slow, particularly in a kind of a block building context. Most people favor staying in the k one side of things, and my bias towards that is I'm one of the team building distributed validators and we have all of these different normal validator clients working together to sign single things with fault tolerance. And the thing I might suggest is in that message you said, where it's like a builder registration meth booth land is that you very much try and favor something that's very deterministic and maybe specify the timing of when to re sign. Because what we ran into with MeV builder registrations is they have announced that you can increment whenever you want to update your address, but it's more or less left as an exercise to the implementer of if you want to do it more often, just to make sure that the relays remember you and haven't forgotten you and stuff.
00:49:11.256 - 00:49:40.274, Speaker D: And all of the different clients wanted to like minimize how often they did BLS signatures, didn't want to do it on the turn of the epoch and do different like little games and did things a bit strangely and it ended up with the world where we now just signed the MeV registration once and that could work. And you going the delegated route, which I think is probably better. But yeah, anywhere with the BLS signature, the more like deterministic you can be, the more like timing specified, the more I'll be able to like aggregate them across five different client teams that do it slightly differently.
00:49:40.734 - 00:50:22.824, Speaker B: Yeah, let me try and repeat it. And I definitely want to follow up this with you because you seem to have worked a lot in this part of how do you authenticate validators. But if I understand correctly, you're proposing a two step process where the first step process is initial registration of the validators. With the registration I'm fearful if I don't want for us to have a breaking change of the current external builders API. So if we can avoid this, this is definitely better. And then just the second step is exchanging other forms of authentication with relays. And this is this more robust form of authentication to be used whenever we are submitting conditions for the conditions API?
00:50:24.164 - 00:51:02.944, Speaker D: Yeah, more or less. I think if you didn't want to break existing APIs you could probably just accept builder registration methods and separately accept like a beacon state proof that that pub key is active as kind of two separate calls. So that's not going to break anything. And coming back to you thinking about you don't know who the proposer is in a block, you just kind of let anyone use like push transactions or something. But yeah, you only have people opt in and like slash them if they come from it. Yeah. I haven't fully thought of that proposal side, but yeah, if you didn't want to change things, I think the bill of registration is a legitimate proof of the existence.
00:51:03.484 - 00:51:41.834, Speaker B: Yeah, on the two step process. One thing that I'm fearful that we're having this discussion is also I don't want to dump too much, too much more new processing to derelict because I think that they are going to actually take the burden of a lot of the processing. They are already doing this, but I don't want to overcomplicate them with each of these, with each of these calls. So yeah, there's definitely something more to be, to be explored there. Thank you, Honor. Was up, now he's down. Okay, there is a question from him in the chat.
00:51:41.834 - 00:52:19.044, Speaker B: Is the rap public? No, but you can look into, by the way, all these I'll share the links in the, in the group, but what is going to be in the rip is going to be the thing that I talked about. The fields here in the pre conformations thing like these two things, essentially making them into formal format of rip plus probably the conditions API. Jonas.
00:52:19.784 - 00:52:37.964, Speaker E: Hey George. Great presentation. Lorenzo came. So I had a question about what happens when the fallback sequencer cannot include their batch in time and it overflows into the next sequencing window.
00:52:38.704 - 00:53:34.144, Speaker B: Yeah. This is the unfortunate consequence of you not being the l one proposer. What we are suggesting here is two things. First of all, having much lesser penalties for liveness faults for fallback selected sequencers. And second of all, obviously bumping up the tips for the, for the builders in order to be able to cover for this. What I'm imagining is that with time, fallback selection should go down and primary selection should go up because it's more favorable for you to be able primary selected proposer. And if it's strictly more profitable for you to also be a sequencer for multiple roll ups within your validator, then we're going to have more and more participation, which is ultimately what we're looking for within base sequencing.
00:53:34.484 - 00:53:54.616, Speaker E: Right. And maybe another thought is like could you potentially, if you fail to include, could you potentially rely on the next kind of proposal to include it since assuming that they're already building upon your pre confirmed state, they kind of have to, or they're going to maybe commit accidental safety faults themselves?
00:53:54.720 - 00:54:09.136, Speaker B: Or is that not as long as they are willing to, and as long as they know about what you have actually committed to. Because think about the communication is literally point to point. Like the next sequencer might not even know what you have committed to.
00:54:09.320 - 00:54:12.944, Speaker E: Okay, so the commitments are not publicly broadcasted in this.
00:54:13.064 - 00:54:35.764, Speaker B: Well, you have a single RPC that is getting hit by everyone. This is why we are having leader election. Okay. We have not proposed a mempool for all pre confirmations or something like this because now this requires coordinate. This is going to definitely increase the requirements, sophistication requirements for all validators that opt in into this to have manpool between all of them.
00:54:36.614 - 00:54:37.794, Speaker E: Okay, thanks.
00:54:44.054 - 00:55:07.794, Speaker B: Cool. Any more? Keep them coming. No. All right, cool. We arrived with three minutes early, I guess. Thank you guys for the time. Thank you for the questions.
00:55:07.794 - 00:55:29.154, Speaker B: I definitely want to follow up with some of you on the different ideas that you already gave us here, and I hope that you find these concepts worthy of further exploring. If so, please do. Go ahead, ping me up in telegram and yeah, let's chat more about it. Back to you, Justin.
00:55:30.294 - 00:55:37.814, Speaker A: Perfect. Thank you, George. So this is the end of the public part of the call, and I guess we can open it up to the private after call.

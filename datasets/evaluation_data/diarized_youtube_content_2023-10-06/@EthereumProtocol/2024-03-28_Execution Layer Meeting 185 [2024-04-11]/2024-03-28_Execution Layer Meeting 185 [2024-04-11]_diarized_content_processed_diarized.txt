00:00:52.574 - 00:04:10.084, Speaker A: Sa. Sorry, my bad. Okay. YouTube audio should be back. Okay. I was just going over what's in the agenda. Sorry about that.
00:04:10.084 - 00:05:04.786, Speaker A: But yeah, we're going to talk about the scope of the fork today and mostly focus on, like, what client teams want to see alongside what's already been included. And then the last thing is, yeah, there's been a couple updates on a few specific eips, so make sure to cover those. And I think if we can end today in a spot where like 90 95% of the fork scope is set, at least on the El side, I think we'll be in a good place. I know there were some discussions about, like, the blob count in the R and D discord. So it feels like if we could get most of the scope done today, maybe in a few months, we can do a small tweak to the fork at like a simple eip. But if we don't want to delay things significantly, all of the, like, big, large changes should be figured out sooner rather than later. So.
00:05:04.786 - 00:05:37.634, Speaker A: Okay, to kick us off, there's a couple updates on just the Eips that are already in the fork. There's been a lot of discussion around Max Eb these past couple weeks, some of which might affect the El side. Alex, you put together a doc explaining how or what the implications would be and sort of questions around if we want to add El consolidations to 702 to help with Max Ev. You want to give a bit of context on this?
00:05:38.774 - 00:05:59.624, Speaker B: Sure. Yeah. So I don't know if anyone was on the most recent Maxv breakout call. Maybe if we give like a short update from that, that would be nice. But, yeah, I was thinking, I think the other stuff is probably more important to discuss. So let's not linger here too long. And maybe if there's time at the end we can circle back around.
00:05:59.624 - 00:06:50.654, Speaker B: But ultimately, yeah, so there's essentially demand from staking pools to change, or at least extend how Max Ev would work with the introduction of another execution layer operation. For this notion of consolidating two validators into one. And yeah, the doc is just like a quick sketch of what that could look like. I think for us today, mainly I just wanted to get it on people's radars and also just do a quick temperature check. Do we feel like this is something that we can do? It would mainly be changing the pre deploy, so it's not like anything much more beyond 7002 itself. Yeah. I don't know if anyone's had a chance to look at this or thought about it.
00:06:57.914 - 00:07:16.554, Speaker A: It doesn't seem like it. And I guess the reason I wanted to flag this early on is obviously, if this changes, like, the scope of 702, we. We need to consider that in, like, you know, the broader fork context, but.
00:07:16.974 - 00:07:41.302, Speaker B: Right. Yeah. So I think there's still some questions on MAXDB that we're figuring out the best way to handle. You know, there's like, we could say, hey, Max, Eb is, like, big enough already. There's nice to have features, but we could put them in, like, a future fork or something like this. But, yeah, just something to keep in mind that there might be. And with this in particular, there's not that much.
00:07:41.302 - 00:07:48.954, Speaker B: There's a little bit more this el has to do. But ultimately, with the El. Yeah, it's all kind of contained in the pre deploy, so it's actually pretty self contained.
00:07:51.054 - 00:08:09.276, Speaker A: Got it. And there's a comment in the chat about having a more generalized message bus by Vasily from Lido. I don't know if you want to take it. Yeah. Couple seconds to, like, talk through what that could look like. Yeah, it's not ready right now.
00:08:09.300 - 00:08:12.788, Speaker B: It's like, just in the back of my head for now.
00:08:12.956 - 00:08:39.524, Speaker A: Had the idea this night, but I think I'll try to bother Alex to review it when it's ready, if that's okay. Yeah. Awesome. Thanks. Okay, so that was the first picture update. Second, Alex, you had the 25 37 bls pre compiled one as well?
00:08:40.344 - 00:09:28.714, Speaker B: Sure, yeah. So this can also be pretty brief. We've done a little bit more work on benchmarking the precompiles and figuring out if we need to change anything or what that looks like. I think after some various discussions, I think the EIP is pretty much going to be as is. There's this notion of subgroup checks, and this one is kind of. I mean, yeah, the core issue is we could put them into the precompiles and things would be harder to misuse by people, users, but they'll be more expensive. I think Antonio has done some benchmarking work and basically found that we can get them pretty cheaply for some of the precompiles, except for the addition ones.
00:09:28.714 - 00:09:41.954, Speaker B: So, yeah, either way, just wanted to give a short update there. And, yeah, I think from there, the main thing left would just be finalizing the gas schedule, but otherwise, yeah, that one's moving along.
00:09:43.214 - 00:10:26.290, Speaker C: Alex, I just want to add something. I agree with you with what you've been saying about subgroup checks. I want actually to raise something that I spot today, and it's not about subgroup check. But it's about the gas of the pairings, and it's something that Dankra has been mentioning a while ago. So, basically, if you see the point evaluation, precompile gas on 4844, it is 50,000 of gas. And so this will be basically, that is two pairings. And Dancrad was saying that would be nice to have the gas of the 25 37 pairings compatible with that gas.
00:10:26.290 - 00:10:47.846, Speaker C: But in our case, instead, with the current gas, two pairings corresponds to 151,000 gas. So it's kind of a bit awkward to have, like, the same operation. I mean, two bearings in one side, paying 50,000, and in this case, 151,000. So I just bought today because I've been writing the test vectors and.
00:10:48.030 - 00:10:50.994, Speaker A: Yeah, we are.
00:10:51.294 - 00:11:04.822, Speaker B: Yeah, yeah, I mean, I hear that. I mean, we could kind of claim that we're subsidizing the 444 stuff with the lower gas costs, but, yeah, definitely something to look at.
00:11:04.998 - 00:11:12.328, Speaker C: I will raise offline as well in the. In the GitHub. There's no sense to waste time here for this, but just want to like to mention this.
00:11:12.486 - 00:11:13.544, Speaker B: Yeah, thanks.
00:11:17.964 - 00:12:32.178, Speaker A: Okay, thanks. And then the last thing I wanted to cover quickly was the Devnet zero. So, as I understand it, no team has implemented all of the eips that were included already on the. I think on both sides, there's still a fair amount of. Of change in the specs. But is that a correct assessment? Are there any updates beyond that? Yeah, are there any updates beyond just people who are working on it or any questions or blockers that people have? Okay, I guess. Anything else people want to discuss on the eips that are already included in the fork? If not, I think the best way to do this with regards to what else do we include is to zoom in on the few eips which seem to have broad support, although not unanimous, at least to start.
00:12:32.178 - 00:13:39.744, Speaker A: So every single team on the El side sent in sort of list of preference and stuff that they really want to see in the fork, stuff that they're sort of neutral towards and stuff that they're against. Skimming through all of this before the call, it seems like there's three that sort of stand out where most of the teams support them, but there's still, like, some teams either objecting or ambivalent towards it. So those three are like 3074, EOF, and 29 35. I think it probably makes sense to start with just 3074, because this is the most complex of them. And I think if we went forward with this would affect sort of the bandwidth and room for everything else. So on that front, it seems like Aragon, Beisu, Nethermind and Reth were in favor of included of including it. And then, and then Geth was the one opposed.
00:13:39.744 - 00:14:16.884, Speaker A: So I, I guess maybe let's start with, like, let's start with Geth. If someone wants to make the case, like, why they don't think it, it should be in, and then we can, we can sort of take it from there. Um, and reading your doc Geth, it seems to be about it being too big, but also the interaction with verkles. I don't know if anyone. Oh yeah, I can, I can address this. I thought we were talking about another one. Sorry.
00:14:16.884 - 00:14:52.600, Speaker A: Yeah, so there's been this conversation happening a couple months back, and I raised some concerns that, yeah, it might paint ourselves into a corner for Varco later down the road. I didn't see any progress on this front. The EOf spec is not. Well, yes, it's supposedly complete, but there hasn't been any implementation to speak of. There hasn't been a testnet. There hasn't been any noticeable progress. At least.
00:14:52.600 - 00:15:26.594, Speaker A: If that was the case, it hasn't been brought to my attention. And we feel that this is a big change. The initial design or the initial intent behind, behind Prague was to make a small feature fork ahead of our call. That clearly goes against this objective, and as a result, we oppose it. Got it, I guess, in terms of like, the progress and the implementations. Does anyone on the EOf front want to talk about that?
00:15:27.814 - 00:15:43.122, Speaker D: Sure, I can talk about it. As far as implementation, Bazoo has a complete implementation. It's on a branch right now. Mega EOF. If you were on the calls, we talk about it frequently. REt's implementation is almost complete. That's also the.
00:15:43.122 - 00:16:21.634, Speaker D: There's also a status checklist we've been attaching with all of our updates for EOF, as far as which clients have been working on it. As far as the vertical compatibility, one thing is that the current formulation of how we're going to store the storage for eofv zero is a bit of an overfit on the legacy dealing with the whole jump test analysis leaking into there. We can continue to use that for Eof if we need to. There are better ways to store it, but if we were to use the existing way that the storage was going to be stored in, it's 100% compatible. It's just data. All of our overhangs would be zero. There's no jump desk analysis.
00:16:21.634 - 00:16:56.494, Speaker D: As far as fitting EOF into verkle with that concern. It's not terribly difficult. There's better ways to do it, but the way that it exists right now can be done just fine. I know there's been discussions with ASIC has been talking about possible ways to do an eofv zero where you could encode the jump destin coding into it as a wrapper. But my understanding is that it was given as ideas to the vertical team to see if they want to pursue it. And there are other issues that were being pursued at the time. So the concern was implementations and vertical integration.
00:16:56.494 - 00:16:59.154, Speaker D: Was there another one that Guim listed?
00:17:01.674 - 00:17:21.570, Speaker A: Yeah, I mean, when. Okay, it's not exactly another one, it's vertical integration. When I said I wanted to see vertical integration, I wanted EOF implemented on Virgo Testnet. That's what I clearly asked for back in the day. So yeah, integration is not happening. It hasn't happened. Right.
00:17:21.570 - 00:17:23.154, Speaker A: But at the same time we don't have it.
00:17:23.194 - 00:17:26.694, Speaker D: That totally feels like Goalpost movie, to be honest. But I'll let Tim talk.
00:17:27.262 - 00:18:33.824, Speaker A: Yeah, I guess what I was going to say about is we don't speculatively implement eips on the next fork. And I understand that Verkle is a bit different here, but it feels like the best way to actually get there is we would have EOF as part of Petra, then all the Petra builds would have EOF and then verkle builds on top of Petra and by default it gets EOF. So like, yeah, I don't know. Like otherwise, you know, we're sort of asking all the client teams to like speculatively implement EOF on the Devnet for two forks from now, which seems like unlikely anyone would prioritize in terms of resources. Is there like a specific thing you're concerned about with regards to vertical Guillaume? Where, like why? Like I said. So first of all, no, there was no goal posting, no goal post moving. It was actually said on the, during the ACD, the last ACD we talked about.
00:18:33.824 - 00:19:15.384, Speaker A: And second, what I'm concerned of is that the argument that was already raised back then is that we paint ourselves into a corner, we implement some hand wavy version of EOF and we found ourselves blocked. We realized there's a problem and verkle can no longer happen. I just want to have this cleared out. That's all I'm asking. I guess what, what would be the, what, what would be the thing from eoF? Like, I guess, yeah, how is. Yeah, what would be the thing out of. From eof that affects basically how the vertical tree is constructed or migrated, that like you think.
00:19:15.384 - 00:20:03.786, Speaker A: Is there like a specific area basically that you think, or a specific, I don't know, part of the EOF proposal that you think if we do this thing, then that actually overlaps with how the vertical migration happens or the way state access works. To be fully convinced I need to be able to have an UF testnet that converts to vertical and we find out there's no problem. But even, even having a proposal of Verkle enabled, like even a spec would be enough. I haven't even seen this. All I had was Nwavi think that this should not be a problem. But I don't even know how to implement this. If I was, I have no spec to work with.
00:20:03.786 - 00:20:31.404, Speaker A: So yeah, even having this, I cannot agree. Yeah, on that front. So there is the mega spec for EOf. But Daniel, do you maybe want to dive a bit more into that? Like what the current spec includes, what eips map to it? Because I know that has changed a lot in the past six months or so. So I just want to make sure.
00:20:32.904 - 00:21:10.684, Speaker D: It started out as a modular eof because there's a lot of features we could add or remove out of eoF. And the Ipslon team is trying to figure out what the scope they needed. They took all the parts that could be severed and made separate eips out of them. So I agree that contributes to some of the early confusion about what eof is, what features are in and what features are out. What's in and out has been fairly well settled. The implementation metrics that I've been passing out has all of the eips that are in there is a mega spec. Let me find, once I stop talking, I'll find a link for that on the Ipson website that lists it in one concise unified document.
00:21:10.684 - 00:21:33.636, Speaker D: But historically, because it was pieced out in separate eips, we have that. There we go. That's not the current one. There's one on GitHub which we've been referring to in all our past meetings. I'll find that one. But yes, that one. And we've been using EOF, there's a unified spec and then we've been splitting it out to the IPs to respect the historical separation of it.
00:21:33.636 - 00:22:21.700, Speaker D: So there is a specific and it's been implemented. We were writing reference tests. They just merged a bunch of reference tests for the container format into EIP, into the Ethereum test network, the test repo. Just the other day for some of the things, the stage we're adders are writing reference tests for this base's reference test, apart from bugs we find during testing, has implemented all of the ips. RET is mostly there. I know Nethermind and geth for mega EOF, not for mega UF, for big EOF, which is back in Shanghai they had complete implementations and there's just, you know, a handful of things that need to be changed to support code introspection, blocking code introspection and blocking gas introspection. So the major work of building the container is done for most of these clients.
00:22:21.700 - 00:23:00.474, Speaker D: But I agree it's been kind of a moving thing because we took advantage of being pulled out of Shanghai to put features that were requested for in to make sure that with a one breaking change for ethereum virtual machine is done with all the things that we need now. So that was bringing in code introspection rejection gas introspection rejection and making sure that we had all the analysis we need for the things we needed. And so that's why it seems like it's been moving around because we took the time that we were given by being kicked out of Shanghai and then not considered for Cancun to make sure we had all those features in. But what we have now is what we intend to ship for prod.
00:23:02.454 - 00:23:03.394, Speaker A: Got it.
00:23:04.814 - 00:23:19.766, Speaker E: One thing that like how, how many new opcodes would this add? Or like how many, how many new versions of opcodes are being touched by.
00:23:19.790 - 00:23:20.354, Speaker A: This.
00:23:22.604 - 00:24:02.184, Speaker D: New versions of opcodes? I had a chart so if you're judging it by opcode number it does sound larger than it is. But all the implementation is reusing existing stuff so there's the three ones for the call that we're changing we're adding 6603 swap, add, Dupan. We're replacing the jump op codes so there's another three there and adding a vector jump op code which is something that's been requested by a lot of. A lot of people. So that there is. We're only touching the things we have to touch because of the container format and these are features that have been requested since 2018 at least.
00:24:04.284 - 00:24:04.740, Speaker A: I think.
00:24:04.772 - 00:24:07.292, Speaker D: Is that current list that Tim suspect?
00:24:07.428 - 00:24:07.676, Speaker A: Yeah.
00:24:07.700 - 00:24:11.068, Speaker D: So it's 18 I think yes and like.
00:24:11.236 - 00:24:19.524, Speaker E: So my concern is that for every time we touch not code there's a risk, right?
00:24:19.644 - 00:24:20.304, Speaker A: And.
00:24:22.484 - 00:25:19.584, Speaker E: I don't know. We're talking about. Sorry, we're talking about, I don't know, the Tlo tea store repricing that is one single opcode that has like a whole debate around it. Or we did the analysis for the pay op code and we found out that it can be like, called in like 25 different contexts, and they each interact with each other. And just making a full table of. In which context can this one opcode be called? Is already kind of extreme work. And so I just don't see that spending our time there is more beneficial than spending our time on other features.
00:25:19.584 - 00:25:54.764, Speaker E: And this is not only like the time to implement it, but especially the time to test it, to benchmark it, to make sure nothing breaks. Yeah, this is kind of my view. I don't know anything about or don't know much about worker, so I cannot speak on Guillaume's concerns about worker, but those were my concerns when saying we wouldn't like to get uf.
00:25:56.744 - 00:26:27.344, Speaker D: Okay, so it's too large is the complaint. And that in some sense that's a bit frustrating to me because we came up with a smaller patch back in Shanghai, and then other people requested it to be larger, and we just can't get a consistent request on what people want out of the, of, from the Alcor devs group. So that's, it's kind of frustrating to hear that from both sides. And they're both valid complaints. But, you know, the other option is ossify as it is now. And I don't think that's a good place for Ethereum. I think it's going to put, it's going to drain the moat of what we have for the EVM in the greater EVM ecosystem if we freeze it where it is now.
00:26:31.904 - 00:26:50.964, Speaker A: I guess on the testing front, like, is this something that we have like significant test vectors for already? Like, for example, you know, if we are changing the behavior of like 18 upcodes, do we have like reference tests for all of them? Part of them. None of them at this point. What's like the status there?
00:26:51.744 - 00:27:37.554, Speaker D: So that's where I'm working at right now, writing the reference tests for these and helping Ipsalon write the reference tests and get some of these features out. We just pushed a bunch of tests for the newest test surface would be the container format. And back in Shanghai there was a fuzzing setup done so we could test the container format from a fuzzer and found a lot of stuff. As far as fuzzing the opcodes, the same fuzzing frameworks that work there could be easily adapted. I think the best work we're going to get, in addition to writing deliberate reference tests, the test the spec has written is the fuzzing, and that's where we're going to find all of it. The fuzzing stuff is an understood problem, just needs to be adapted for the structure of the EOF and a couple more things written to make sure it works well with the of.
00:27:40.174 - 00:28:02.644, Speaker A: I guess one thing I'd be curious to hear as well is so it seems like ref and Nethermine alongside with basically both have pretty advanced implementations. Like do either of you want to talk about like what you see as the current state and like the current, like potential risks or open issues? Yeah. Merrick.
00:28:03.424 - 00:29:23.408, Speaker F: Yeah, so we are not against EOF and it definitely adds value, but the previous commitment from client teams was to do small fork and do vertical trees as soon as possible. If we add EOF here, then we can think about tektra as medium or large work and our implementation is up to the latest SPAC. But EOF brings a significant risk of consensus of consensus issues, which will require lots of testing and it cannot be rushed. So on the other hand, we know that if we do not shift erf now, we will wait two, three years of ceif on Mainnet. So that is why we are we see two options here. We can implement a medium large spectra with EOF and sacrifice testing capacity for vehicle and maybe IP for force. Continue with workloads in parallel and immediately after Pektra focus on four force and even more focus on workout risk.
00:29:23.408 - 00:29:43.764, Speaker F: Or just do as we planned before. So small pektra work on work parallel, delay EOF and release it after vertical hard work. I think both options are good, but yeah, that is how we see that.
00:29:45.344 - 00:29:53.364, Speaker A: Got it. And yeah, I don't know if anyone from rest or Ergon has thoughts you want to share.
00:29:55.544 - 00:30:10.044, Speaker G: I'm not sure if dragon is on the call. This is Georgios from rest. We already have a work in progress EOF implementation and we are generally supportive of it. We hope to have something done and merge in the coming weeks.
00:30:10.624 - 00:31:27.084, Speaker A: Okay. And yeah, anyone on the Aragon team? So for Aragon we have parallel works going on for both VRKL and EOF. So we favor EOF for Pektra because Verkle seems to be pushed and I know why, you know, the scope is increasing, but I think we can pull through. That's about the comment from Ergonom. Got it. And then yeah, in the chat there's a comment about the cross client testing being the bigger lift than the actual implementation. So it seems from this that most client teams can get an implementation fairly easily, but then testing things will be, will be a lot of work.
00:31:27.084 - 00:32:35.810, Speaker A: I feel like instead of making a decision on EOF right now, it's probably worth covering some of the other eips that people were on the fence about and see getting more context around those and then coming back to seeing do we want to include any of them or EOF. Because eof being so big, I think means like, you know, if we go forward with it, there's probably a lot of stuff we have to push out. So I want to make sure we understand what we'd be pushing out or trading it off against. So any, I guess, any other, just like, comments, thoughts on, like, the readiness or concerns around eos? Eof? Okay, yeah. Thanks everyone for sharing your thoughts on this. The next one that pretty much every team seemed to be in favor of was 3074, the one caveat. So ret's reference post was a bit old.
00:32:35.810 - 00:33:11.564, Speaker A: It was from like January. So their stance was like, we want one of the account abstraction eips, but not really specified which one. In January, we were still going through a bunch of different ones and debating them. It seems like 3074 is the one that all the other teams would prefer to see today. So I guess maybe to start there on the red side, assuming the other trine teams like 3074 and would want to move that one forward, is that one that you're still comfortable with and would be happy to see as part of the fork.
00:33:12.584 - 00:33:23.364, Speaker G: Ret is supportive of 374 and only 3874 3074 for the next hard fork, and we already have it implemented and tested.
00:33:24.544 - 00:34:02.014, Speaker A: Okay. So I guess, yeah. Do any of the client teams feel like we should not do 3074 in the next hard fork? I know in the chat a bit earlier, there were some concerns around some of the security risks, and then a bunch back and forth there I couldn't read. But we've talked about the security risks of 3074 for a few years now. Do people feel like we're happy to move forward with it, even, you know, being aware of all of those? Does anyone have any more objection or things, you know, that they feel uncomfortable with?
00:34:06.294 - 00:34:20.954, Speaker D: My objection is always safety oriented, and to move to require the current notes to allow it, to require the current notes allows for single action revocation, which is what my big ask was, and that's been delivered. So my past concerns on it have been resolved by that action.
00:34:31.044 - 00:35:08.734, Speaker A: Hello, I'm in favor of the EIP, but I am concerned about the edge case of not being able to enforce as a contract that some data aesthetically declared in a transaction like the top level call detection the lose versus eap. I drafted an EIP for a replacement, but there might be other options too. Having some sort of fallback for this feature would be really useful. Maris.
00:35:11.234 - 00:36:33.164, Speaker E: So while I'm general in favor of 3074, one thing that I would like to remind everyone of is, is that, like, it's something that came up during a lot during the working inclusion list. And I'm not sure if all the client teams are aware of it, but with 3074, the design of the miner is kind of more complicated. It makes block building more complicated because you can have transactions that invalidate other transactions, and you don't have that right now. Well, you kind of have that right now, but only with transactions that are from the same sender, with lower nonces, and with 3074, basically, transactions can invalidate arbitrary many transactions in the transaction core, it can be mitigated by the transaction pool. It's just something that we need to think about when designing our transaction pools to make them work already. Sorry. To make them 3074 ready.
00:36:35.424 - 00:36:55.544, Speaker A: Got it. And then there's. There's a comment by Yoav about the blob invalidation. I know there's been, like, a lot of back and forth on this. Yeah. Yoav, do you maybe want to just give a quick overview and then. Yeah, you can take it from there.
00:36:55.544 - 00:36:58.196, Speaker A: Yeah.
00:36:58.220 - 00:37:37.952, Speaker F: The concern we discussed, and I think we discussed it on discord already, is around the denial of service against the manpool using. By sending a lot of blobs and then invalidating a large number of blobs from a single. From a single transaction using a value transfer in 3074 auth call. So we have a rule to protect against that requiring two x fee increase for replacing a blob. But here we can bypass it for.
00:37:37.968 - 00:37:39.384, Speaker A: A large number of transactions.
00:37:39.504 - 00:38:09.294, Speaker F: Now, as Matt suggested, it's already possible to invalidate them by sending a private transaction to a builder that replaces the current blob. But this only affects the blob from the blobs from one EOA, and it's also more expensive because you need to pay the block builder, whereas propagating a lot of mempool transactions that each of them invalidate many blobs is a much cheaper attack.
00:38:12.234 - 00:38:15.642, Speaker A: Marius, did you want to respond to this? Yes. Okay.
00:38:15.658 - 00:39:19.168, Speaker E: Yes, I want to respond to this. Yes, that does have implications, but at least we created a benchmark for it. Or I created a benchmark for it in the guest case, and I think it takes around less than a second to. If I create a block full of your 3074 transactions that invalidate the maximum number of block transactions, the thing is in geth in our blog pool implementation, we don't delete the blob transactions. We just tombstone then. And so sending these kind of attack transactions does not make us do a lot of work. It just means we have a bunch of junk on the disk that is not cleaned up, that is overwritten.
00:39:19.168 - 00:39:45.174, Speaker E: The next time we write correct block transactions, it does. One thing that might be concerning is if we do reorgs, like, how this interacts with reorgs. We tested that where we kind of have to resurrect all of those transactions.
00:39:47.034 - 00:40:00.304, Speaker F: And did you also did the test also cover the peer to peer, the communication layer? Like the load on communication layer of propagating a large number of blobs that end up unpaid?
00:40:02.004 - 00:40:44.974, Speaker E: No, no. But, like, you can kind of send them right now. We have to prevent spam on the networking layer anyway. And the way we do it is just check if we have, like, if the, if a transaction is a block transaction, and if we have the bandwidth, download block transaction, and then we switch them. So this is like, this case is not worse than just someone announcing 10gb of block transactions to us, I think.
00:40:46.934 - 00:41:21.854, Speaker A: Right. Thanks for explaining. Okay, I guess, yeah. Given this. Yeah, I say 3074 was probably the EIP that had, like, I think it was the only IP that had basically unanimous support from all of the client teams to be. To be included. So does anyone object to including it? I think this is one we can probably make the call on right now if we're happy with it.
00:41:21.854 - 00:41:52.894, Speaker A: So any objections to including 3074 in Pektra? Otherwise, I think we should move forward. I was hoping to hear what 3074 plans to do with origin, if they could clarify that. Yeah, I guess if someone has a quick response. What if this is a. Okay, it's in the EIP. So I think, yeah, let's. Yeah, let's have this offline.
00:41:52.894 - 00:42:22.394, Speaker A: I think everyone has, like, reviewed the EIP and all the time teams spend time on it. So if there's no objection. Yeah, let's. Yeah, let's move with 3074 in Petra. So that's one down the next step. Okay, so, yeah, 3074 is in. Any final thoughts, comments? I think we're good on this one.
00:42:22.394 - 00:42:52.270, Speaker A: Okay. The last one I want to make sure that we cover that. A lot of teams brought up is 29, 35. So this is about saving the block hash in the state, basically. I think, like, geth neithermind basically were in favor. Aragon was, like, ambivalent about it. And I don't think we discussed it when, like, Rhett put it right up together.
00:42:52.270 - 00:43:07.264, Speaker A: So yeah, I guess I'd be curious to hear about either. Oh and sorry. Ethereum j's also a favorite. I'd be curious to hear. Yeah, either. Aragon rest any strong views on this one? Sorry. Which.
00:43:07.264 - 00:43:30.734, Speaker A: 129 35. Which is about adding the block hash as part of a contract in the state. And this was especially useful in a vertical context now where it can allow us to keep the block hash opcode or to. Yeah, to keep the block hash opcode behavior.
00:43:33.554 - 00:43:44.854, Speaker G: Yep. Ret neutral positive. Some simple change. It's very similar to how the beacon change is all the beacon root thing is also implemented if people wanted. We're down.
00:43:46.754 - 00:44:11.804, Speaker A: Yeah. Ergon for yeah, yeah. Similar views. It's small. If the bigger ones are not included, we can give this one a go. You know, that's our view. It's not going to make a huge difference, but so say we did like EOF, for example.
00:44:11.804 - 00:44:54.130, Speaker A: You think that would like maybe be too much or you'd rather like. There's like a trade off between like doing this small one and then potentially having like a bigger one included? Is that what you're saying? Yes. If you potentially are thinking about uf, I think most other eips can sort of jump out of discussion for the next hard folk maybe. Okay. And given the fact that, you know, we're not in a rush to do verkl anyways, so later on we may or may not make small changes to the EIP and associated things like testing and stuff. So it's going to evolve again in our opinion. Got it.
00:44:54.130 - 00:45:19.884, Speaker A: For the next hard folk when worker is actually implemented. Got it. Okay, sorry, I have to decide with that. It's currently being used on the vocal testnet. The IP as it is specified will not evoke. There's no event that lets us anticipate that this will ever change. It is currently being used on the vertical test.
00:45:19.884 - 00:46:13.914, Speaker A: Okay, nice. I guess, yeah. If we feel like this, we might want to like that this, you know, we might not want to do if we do other larger things. I think I'm happy to go through the other couple eips that we wanted to discuss and we can end up, we can come back to it and make a decision a bit later. Any objections there? Okay, so these were like the three big ones that basically all the client teams had preference towards. I think there's a couple more that people posted updates on that it is worth probably covering real quickly. Let's start.
00:46:13.914 - 00:46:52.134, Speaker A: Actually, Vitalik had 17667, which proposes to change a bunch of gas costs to make them more snark friendly. I don't know if Vitalik's on the call, but I think that the EIP itself is pretty straightforward. So any thoughts from client teams about this one? Okay, if there's no. Oh, sorry, Daniel. Yeah, please. I didn't see it.
00:46:52.634 - 00:47:33.576, Speaker D: So, on some of these magicians threads, it seemed like this could also be pushed out to. One of the things he pitched was having a lot of gas changes with the vertical fork in Osaka. Since we're dramatically blowing up the gas schedule, with the way that we're accounting for trees and storage, it seems like a good place for it. Since we're going to dramatically blow up the way we charge for hashes, I think that's one that we could list as good. We just need to schedule it and get the exact values for it down. I kind of agree with it. If it has a place.
00:47:33.576 - 00:47:36.324, Speaker D: I don't know if it has a place in Prague, though.
00:47:37.824 - 00:47:58.904, Speaker A: Yeah. Any other client teams or people have thoughts on this one? Oh, the diet might pop in, but, yeah, I also actually, Carl?
00:48:02.604 - 00:48:03.384, Speaker E: Yeah.
00:48:04.284 - 00:48:48.780, Speaker A: I think it's a good idea from the perspective of snarkifying stuff, but it is very extreme. I think we need to, like, do a lot of investigation onto the impacts of this. Hashing is one of the most core features that pretty much every smart contract uses at some point. And so I think we need to be very careful by doing the analysis on exactly what's, like, who's affected and how much. It's something we've had from the very beginning. And I think as one of those assumptions, that's very much baked into the many, many contracts. Yeah.
00:48:48.780 - 00:48:49.544, Speaker A: Marius?
00:48:50.244 - 00:49:40.524, Speaker E: Yes. I kind of feel the same way. And I think, like, I don't think we should. We should price stuff for a potential future, but for the costs to the nodes right now, and the cost to nodes right now, the pre compiles are kind of. The operations are kind of priced correctly. So I think if we were to reprice it, it should be at a point where we either see a bunch of ZKE evms or we even think about zkevmifying mainnet itself. So, yes, that's kind of would be my point.
00:49:42.064 - 00:49:45.724, Speaker A: Got it. Daniel, did you want to respond to that?
00:49:46.784 - 00:50:10.854, Speaker D: I just wanted to say that the hashes are, like, the most impossible things to optimize, because almost all the clients are already using, well, optimized implementation. So speed is never going to go up on these, maybe to get the VM to access the hash. But if we need to increase the gps then a change in the gas costs would be valuable. But I generally agree that Frog is probably not the right place to do this.
00:50:14.754 - 00:51:25.854, Speaker A: Yeah, I guess I had a suggestion in the chat where we are going to reprice a lot of things with vertical already in Osaka. I think in terms of just user experience, if we can. If these changes are not urgent, which it doesn't seem like they are, because they're mostly to help Altus working on ZK evms and whatnot, it feels better to bundle all of the large gas cost changes in a single fork. Not to say we can never change gas costs again, but for people to know that this is when they should pay attention and that there will be significant changes across the board, rather than trying to make tweaks in one set of prices in this fork and then a whole other set of prices in the next fork. Carl? Yeah. One quick addition on the l two side of things. I don't think we should be making l one decisions based on, for the evM, based on pricing, that l two s, I think, can figure out a way of sorting out themselves, or we can coordinate with sorting out for themselves.
00:51:25.854 - 00:51:34.962, Speaker A: This should be based on the needs of l one for now. Got it. Okay, so yeah, I think we can move on from this one.
00:51:35.138 - 00:51:36.054, Speaker H: Wait a minute.
00:51:37.594 - 00:51:38.346, Speaker A: Oh, please.
00:51:38.410 - 00:51:39.482, Speaker H: Yeah, sorry, I just.
00:51:39.578 - 00:51:40.734, Speaker A: Sorry, not the right time.
00:51:42.234 - 00:52:29.452, Speaker H: Great. Yeah, I mean, I think one. So one important thing to keep in mind here, right, is that I think people are like, it's very easy to underestimate the extent to which l one itself is actually not that far away from being ZK starked. Right. Because, like, right, the cost of stark gig, 30 million gas, like for average case stuff has already gone down from, I think like something like 5 hours a year ago to like 20 minutes now and then. It just keeps on decreasing very quickly. And so I think it's very plausible to believe that even within one or two years, we'll have the capability of proving the ethereum l one in real time.
00:52:29.452 - 00:53:14.340, Speaker H: Right. So I think it's just important to mentally adapt to the fact that, like, there's no such thing as a distinction between ZK chains and nonzk chains. Like, we are basically now entering a mode where every serious chain is a ZK chain. And so, like, ZK friendliness is not something that is unique to l two. It's something that is going to be VR relevant style ones as well. Especially given the underlying goal of trying to increase the ease of verification with things like the Verge and trying to support more properly verifying full light clients and, and so forth. Right.
00:53:14.340 - 00:54:21.254, Speaker H: So I think this is something that is, that is a super l one relevant. And I think the, again, the goal is to try to like, figure out, like, basically, yeah, we really need to worry about the worst case rather than worrying about the average case. Because especially for l one applications of this. Actually, in a way, it's more important for l one than for l two, right. Because for an l two, if you have like one or two long blocks, then you can just a lot of applications that really depend on having a, like a very fixed upper bound, like a theoretical maximum number of milliseconds that it takes to create a stark proof of no one block. Right? So, like, for example, if, well, like when we get it, let's say between two and 3 seconds, then, you know, that gets us to the point where validators and block builders will be able to take advantage of it. So that's how I see the value of that.
00:54:21.254 - 00:55:48.236, Speaker H: I see that there are some discussions in the chat on like, receipts and Merkel Patricia trees, and which definitely also touches on this topic quite a bit, I think still, aside from hash upcodes, the other two places where a block can have a huge amount of hashing in it, I think, as I wrote in the EIP spec, is number one is the Merkle budget tree, which we're thankfully getting rid of with verkle trees. And number two is receipts. And with receipts, there's also this one very particular annoying challenge that there's like these few, like these huge individual hashes that could come up if there's, if there is a receipt. Crew's log data is really huge. And I mean, of course, moving over to SSE hashing, the receipt structure is going to reduce, improve things a lot there. But fortunately, I did the, I did the math and glauc data is already kind of almost at the point of being high enough that it's not the primary issue. In terms of like bouncing ZK proving cost of a block, in terms of bounding ZK proving cost of a block, it does feel like the worst case is just like blocks.
00:55:48.236 - 00:55:50.144, Speaker H: They could take a huge amount of hashing in them.
00:55:53.404 - 00:57:14.412, Speaker A: Yeah. Thanks for, thanks for sharing all that, all that context, I guess this. And then based on a comment in the chat around, like, should this be like a good rip as well? If this is something that's like important on, you know, not maybe the next year timeline, but like the next few years, as like the speed of verifying goes down. One path forward is we could tried to get this implemented on l two s first as a signal that they actually endorse those gas prices and they might argue about them and tweet them and whatnot, and then tentatively commit to doing this in the next fork alongside with all the other vertical repricing. So this means that in say the next year, we can try to run with a version of this on some of the l two s, get them actually using those values in production, and then that'll help us refine the actual numbers. And alongside with the vertical gas cost changes, we can include either those as is or whatever tweaked version of those in the next fork. Did people think something like that?
00:57:14.518 - 00:57:15.164, Speaker H: Yeah.
00:57:17.224 - 00:57:17.560, Speaker A: Yeah.
00:57:17.592 - 00:58:59.244, Speaker H: I mean, one thing I want to just like also clarify is that, like, I think it's totally fine if this happens, let's say yeah, in the second next fork instead of being in the next fork, because like there's no point in just solving the EVM hashing issues if we, the worst case is like 300 megabytes of hashing in the mercle persuasion tree anyway. So I think like realistically, the biggest kind of short term ask that I would love to see people doing over the next month is actually just like a much more dedicated benchmarking effort to figure out two things. So the first thing is basically like what is the effect on existing applications of raising the cost of both catch hack and other opcodes by a particular amount? And the second is like basically, yeah, figuring out like on existing zkvms, what is the, like, what is the extent to which this is a bottleneck? Like basically what is the factor n by which we can make hashes more expensive, at which point something else actually becomes a bottleneck. Right. And like those two variables are going to be key in determining like what actually is going to both what parameters make sense for this, and if the results end up being unfavorable. Also, like what kind of approach makes the most sense?
00:59:00.904 - 00:59:46.344, Speaker A: And I know one thing that's come up over and over in these discussions is like l two s want to signal from l one that they're actually serious about it because otherwise they don't want to spend the time and whatnot. So I guess my suggestion for this one would be can we just cfi it for the next fork alongside all the other vertical stuff so that l two s know that we plan to do this, but also that it should sort of be on them to like push this forward before the vertical forks that like we're kind of happy with the numbers and whatnot. But do you think that would help just send a signal to the lt folks?
00:59:49.004 - 01:00:35.954, Speaker H: Yeah, I think so. I think the thing that the ecosystem needs is just like a signal of seriousness that things are moving in the direction of zksdarks being like a first class thing that everything is getting designed around and the resource costs are going to be adjusted accordingly. And both for layer twos. And I think ultimately also for l one focused ZK EVM designers. And I mean, the other third target of course, is like solidity and app developers get the ball rolling on and if re optimizing applications around some of these adjusted costs.
01:00:37.254 - 01:01:38.262, Speaker A: So I guess, does any client team oppose making this EIP 7667 CFI for like Osaka? And obviously if we get to that, implementing Osaka and we see some issues or the ZK proving time has not gone down or whatever, we can always kick it back another fork. But I think this sends a good signal and then allows, hopefully, some of the l two teams to make progress on this in the next months to finalize the numbers and do the analysis also against l one. Any objection to that? Okay, cool. So yeah, let's see if I just went for Osaka alongside the other Vircoli ips. Moving on. The other one which had an update was 7623. The biggest question there was a lot of the numbers originally were done pre den kun.
01:01:38.262 - 01:01:51.254, Speaker A: And so we didn't really see the effective blobs on those numbers. And then Tony Reran the analysis. I don't know if Tony's on if you want to give a quick update. Oh, yes, you're here.
01:01:51.594 - 01:01:53.162, Speaker G: Yes, I can do that.
01:01:53.258 - 01:01:53.674, Speaker A: Yeah.
01:01:53.754 - 01:02:21.154, Speaker G: So the main result is basically that the El payload size, we got it under 100 kb. So the El payload size was previously before 444, it was around 120. Now the average is around 90 or between 80 and 90 kb. So kind of the gap between the maximum possible El payload size and the average became bigger.
01:02:21.854 - 01:02:22.262, Speaker D: And.
01:02:22.318 - 01:02:45.034, Speaker G: Yeah, I just wanted to start the discussion on 7.623. I already saw that some client teams favorite, some didn't have an opinion on it yet. And yeah, especially thinking of increasing the gas limit or increasing the blob count, I would say that the EIP is a quite good fit to go in parallel.
01:02:46.614 - 01:03:17.314, Speaker A: And. Ben. Hi. Yeah, I think it's. There's like a hidden problem. There's a hidden problem. If gas limit does increases, which isn't under dev control, then because degenerate blocks can be created full of zeros, it would be good to address it just to diffuse that as a potential problem.
01:03:22.054 - 01:03:35.594, Speaker H: So my understanding is that like basically all of our infrastructure, our peer peers, like wrapped in snappy compression or some equivalent already. Is that the case or not the case?
01:03:40.594 - 01:03:53.894, Speaker A: One of the issues is Json. So if you get, Jason, the block data is JSON, then it doubles up in size and it goes to like 13 megabytes for the large blocks.
01:03:54.634 - 01:04:04.734, Speaker H: Right. But this is independent. So like the zero byte issue. Right. If you get JSon, that's just like a dumb factor of two increase on anything.
01:04:05.284 - 01:04:16.984, Speaker A: Yeah. And you have that between the CL and the El. So it's like unnecessary strain from if somebody wanted to create a degenerately large box.
01:04:18.164 - 01:04:31.984, Speaker H: Right. But I guess just to clarify, like, that feels like an issue that's independent of, like, of how details of 7623 work, because it's like a two x penalty that we suffer regardless of what happens.
01:04:35.564 - 01:04:46.104, Speaker A: Yeah, but the 7623 would prevent that from being a problem because it removes the. Oh, I see, the excessive large box.
01:04:47.084 - 01:04:54.904, Speaker H: I see. Like you're basically saying that there's yet another domain where capping the worst case is a really valuable thing to do.
01:04:56.364 - 01:04:58.804, Speaker A: Yeah, completely, because. Okay.
01:05:00.304 - 01:05:34.092, Speaker H: Makes sense. Yeah. By the way, I just saw in the chat, Mario Vega says that there's a concern with 7623. It adds a condition to make it a transaction invalid after it has been executed. And just to clarify that the EIP does not work that way. Right. So there is no way that with EIP 7623 transaction can get retroactively made invalid after execution.
01:05:34.092 - 01:05:57.964, Speaker H: Like, basically all that 7623 does is it changes the, it changes the refund or the rules around like, refunds and how available gas is calculated based on call data and based, and based on the.
01:05:59.944 - 01:06:13.672, Speaker A: You're breaking up a bit, Vitalik, but I think we got the gist of the last comment that like, yeah, yeah, we changed the pricing and so you still have to pay for the worst case pricing and you get a refund.
01:06:13.808 - 01:06:24.410, Speaker H: Right. The gist of my comments is basically that there's like, like, there isn't some possibility of like retroactive invalidation that 763 introduces because that's just not how it works.
01:06:24.562 - 01:06:40.666, Speaker A: Got it. Any other questions, comments on it, quick one, this came up on roll call yesterday, and while not every l two.
01:06:40.730 - 01:06:43.282, Speaker E: Was represented or had someone present, it.
01:06:43.298 - 01:07:32.010, Speaker A: Seemed like no one had any major issues with this EIP. That said, nice. Thanks for sharing that. Okay, I think it's probably worth just covering real quick a couple more updates and then trying to keep at least 15 minutes to make some final decisions. There was a comment around changing origin behavior. I know we discussed this in a past call and it didn't seem like there was too much support, but I guess. Do any of the client teams feel quite strongly about this? Okay, if not so sorry.
01:07:32.162 - 01:07:59.994, Speaker D: One thing that I had asked for, they had come onto the UF call is statements from security professionals, people actually using us, what they think about it. I think as client teams it's mostly an implementation detail and we don't necessarily see the higher level implications of why it's important to ban or why it's important to keep it. So I think what we need to hear from is security researchers to say is origin bad, good? Should it be banned, should it be changed or not? I think that's the level of input we need to make an intelligent decision on this.
01:08:00.934 - 01:08:36.463, Speaker A: Well, I do want to make the distinction really quickly that we're talking about two different things. There's the aliasing solution, which is 7645. Alias is origin to sender. I just posted it in the chat. The second one is banning origin and eof, which is not really a full ban because legacy deployments are still going to be available. But it would start us on the path of getting rid of it, banning it eventually. And then the third option is to do nothing and let each account abstraction solution as 3074 has deal with origin in its own way.
01:08:36.463 - 01:09:03.523, Speaker A: I guess. Let me just pause you here because we have a lot of stuff on the agenda. So like, yeah, unless. I think. Unless client teams have like a strong opinion on either of these, I think, yeah, we can probably just move forward and continue this conversation offline. So yeah, any. Okay, there's a big comment in the chat, but it's not about this.
01:09:03.523 - 01:09:46.700, Speaker A: Yeah, any comments from the client teams on origin? If not, okay, there's two more changes. These aren't like super related to the El, but I do want to flag them because we have been talking about them in the past. Bunch of calls first. So inclusion list. This came up a bunch in the chat today. So none, or at least definitely not a majority of the EL teams showed strong support for inclusion list. A couple of the documents sent before shared that people think it's a lot of complexity and there's still some open questions in the spec.
01:09:46.700 - 01:11:03.804, Speaker A: So I guess does anyone feel very strongly on the El side that we should do this? Otherwise it seems like the default path at this point is at least from the El side. Not including this in Petra. Yeah. Anyone want to make a strong case on the other side? Okay, so I think, yeah, unless on the CL side next week we see like a really strong support for it, then I think we could consider it excluded from this fork. But I think that, yeah, this is mostly a CL conversation and obviously has some Yale implications, but from the El side, doesn't seem to have a ton of support now. And then the other one, Ansgar and Casper, I know on the last call you wanted to take like a minute or two to talk about the issuance proposals again, even though they're mostly CL changes, and we didn't have time last week or two weeks ago, but do you want to take a minute or two to go over them now? Yeah, sure. Thanks.
01:11:03.804 - 01:12:09.404, Speaker A: So I think basically, I just wanted to briefly mention, because some people here might have come across contact conversation on Twitter or other kind of places. Basically, we proposed a while ago we had some research on kind of the long term direction for kind of the Ethereum staking system. We personally see some arguments that there's been for a while to go to, like a targeting mechanism where basically the staking ratio would stay within a pre specified range instead of being allowed to keep climbing upwards. And we see some arguments for that. Of course, that's kind of still in the research process. We'll take some time to figure that out and see what direction we end up wanting to go in. Just because it is much harder to potentially reduce the staking set size after we already have drifted upwards to say 60, 70, 80%, we felt like there might be some arguments to be made to already have some tempering of the issuance in Pectora, just basically slow that process down and give us more time to decide.
01:12:09.404 - 01:12:28.084, Speaker A: After proposing that, it turns out that there's been quite a bit of community pushback. Clearly any change like that would require really broad community support. So right now it's not in a place where it would be includable in Electra.
01:12:28.384 - 01:12:29.880, Speaker H: It's a really small change, of course.
01:12:29.952 - 01:13:14.734, Speaker A: It's like it was designed, it's basically two lines. Change the spec. So the idea would be that we will keep pushing for what the case that we see for it, and if we are successful in convincing people within the next few months, we could always add this very last moment again. Right now we're not on a path towards this, but I just wanted to make sure it's mostly a Cl side issue. But of course it would require really broad, not only community buy in, but also all code apps buy in, both from the El and Cl side, just because it's not primarily a technical change, but a more philosophical one. So I just want to briefly give a quick summary of where we're at there? That's all. Yeah, thanks for the update.
01:13:14.734 - 01:14:43.474, Speaker A: I don't want to open this can of worms on this call, but I think, yeah, it's definitely something people should be mindful of and pay attention to. But yeah, we should have the bulk of the conversation on if and how to change this on this yell call. But yeah, El teams should definitely share their point of view there. Okay, so I think this covered all of the eips, which at least had a couple of the client teams supporting them explicitly, all of the ones which had like, notable updates. Is there any like EIP or proposal that people feel that I've missed? If not, I think it's worth taking more time to dig into an EOF 7623 29 37 and figure out next steps for the three of those. But yeah, before we do that, anything else people wanted to bring up? If not? Okay, so I think EOF is the one with the highest uncertainty and also, like most consequent, most consequential, whether we do it or not. There's been a bit of chat about it as we were speaking.
01:14:43.474 - 01:16:01.124, Speaker A: I think that, like the question around. So I had a question around, you know, whether we could potentially do this as part of Verkol. Obviously, I understand that there are two large changes in the same fork, but they seem relatively isolated, although maybe that's not the case, as per some of the comments. And then the other thread in the chat was around the testing complexity and whether we should do something like try to get it implemented and tested in, say, the next month or so. And then if we realize that we're nowhere near getting it finalized, then we can remove it from the fork. But yeah, I guess the client teams have changed their updated opinions on whether it would make sense to, whether it would make sense to try now to get it included in Devnet doing cross client testing, and that we feel confident we can actually get there if we prioritize it. Or does it make sense to potentially include it alongside Verkle, even though there are two large changes and this gives us way more time? Yeah.
01:16:01.124 - 01:16:30.664, Speaker A: Any thoughts there, Guillaume? Yeah, so forget about including it alongside Verkle. Vorkel is a huge change. It's going to touch roughly. I mean, this is the gist of my concern. It's going to touch a lot of the locations at the same time. This is two big complex areas that are going to have strange interplays. This is way too risky.
01:16:30.664 - 01:16:37.424, Speaker A: I cannot support that. Georgios.
01:16:41.324 - 01:17:22.926, Speaker G: I just wrote it in the chat. But just in case, I would feel like a EOF is an EVM change. It's not an integration change. It means that we can test it in isolation and fuzz it very heavily, and we can have very clear boundaries around it. I think on the testing point, I think we should double click on what the testing looks like and define requirements for it. And the other thing is that in general, EOF is good for performance, it's good for tools, it's good for a lot of things. And I feel like people have some implementations of it already, maybe not published, I don't know.
01:17:22.926 - 01:17:31.994, Speaker G: But like for us, it was pretty simple to implement honestly, one month job, and I feel we should take a very clear headed look at it.
01:17:34.614 - 01:17:37.406, Speaker A: Yeah. Mario. Yeah.
01:17:37.430 - 01:18:34.284, Speaker F: So my only concern here is that right now the current set of tests that are written are in the ethereum test repo. And this makes it a little bit more complicated than what we have been doing in the past couple of forks. That is, using execution spec tests, which makes it more easy to review and understand what is currently the coverage for EOF. So my only concern is that we need to make the port of the tests of EOF to execution spec tests, because otherwise we are not sure of the coverage, we're not sure what's really tested or not. And this is going to take a while because currently the testing team is with constraint bandwidth. So I would say that if we want to make this EOf happen, we need to have this set of tests in the new repository. That's my only ask, I would say.
01:18:35.264 - 01:18:39.004, Speaker A: And oh yeah, I guess. Daniel, do you want to answer that?
01:18:40.584 - 01:19:02.954, Speaker D: So, I mean, I guess this is what I had to say is kind of a meta summary of what's going on. All the concerns and objections are around scheduling and complexity and difficulty, not about the merits of EOF. And there's any talk about merits, it's generally positive. Does this warrant moving EOF to CFI, but not necessarily scheduling it for Prague? And we can extend the Prague discussion to see how testing and implementations develop?
01:19:06.454 - 01:19:37.354, Speaker A: I guess the only concern I can see with that is say that we say, okay, EOF is CFI, but then we also do like say 7623 and 29 35. It's like, can we say EOF is like a medium sized set of changes if we CFI it, but then include a couple small changes, are we taking up all of the team's bandwidth? Basically. And yeah, it does feel like there's a trade off there. Right.
01:19:39.214 - 01:20:14.324, Speaker G: Sorry for jumping in. One thought for us all to be present is going faster and also upping our bar and being more precise about the size of each change. And the historical hashes change, for example, is quite small. And I would hope that every team, including ours, can implement it in a small amount of time and that we shouldn't really think of them, of these features as big burdens almost. Eof. Yes, it is a lot of work. I also think that because of the isolation, it is much easier to test.
01:20:14.324 - 01:20:26.124, Speaker G: Same thing for the historical block hash, but we surely encourage everyone to, you know, let's try to go the extra mile and stretch all ourselves together in this.
01:20:33.064 - 01:22:09.644, Speaker A: So I guess maybe a thought of like how we can move this forward is we have the spec right now for Devnet Zero, which had all the current eips included. We've added 3074 to the list. So we should probably have that in the first Devnet. I think we can make a call on whether or not we want 29, 35 and or the call data repricing one if, and then what I would do is CFI EOF and then have the teams working on Devnet zero in parallel to the testing stuff being figured out. Like I suspect it is worth taking a couple weeks to like look into, you know, what's the testing infrastructure we need and whatnot. And then if we're confident with EOF, we can add it to the Devnet after that. But I think having your first Devnet, which is everything that's already included, which is non trivial, plus a couple small tweaks that we want to do in parallel, figuring out the EOF testing situation and then making a call about whether we want, whether we think that EOF can be included with minimal overhead, that seems like the right path forward, because I guess otherwise, if we started working on EOF and realize the testing effort is going to take much longer than expected, we've sort of wasted these next couple of weeks.
01:22:09.644 - 01:22:58.294, Speaker A: So, yeah, does that generally make sense to people, CFI and EOF having Devnet zero not include it, and then in parallel to this, trying to figure out on the testing side, like what exactly do we need and what's the amount of work required and ideally doing some or most of that work. Okay, no objections. So, yeah, no objection. So let's move forward with that. So, cfied EOF, I'll need to get a EIP number from you all at some point. Worst case, I can just add the old ones there. But it'd be nice to have an eip that tracks the latest spec.
01:22:58.294 - 01:24:11.732, Speaker A: And then, yeah, I think to everyone working on EOF, please paint Mario and ask him exactly what he needs from you in terms of like testing support. I think he'll be happy to walk through like yeah, exactly what we should be migrating and how we should be assessing coverage. And then given that 29 35 is probably the most. Oh, okay, sorry. Before we do 29 35, there's another comment in the chat around stopping to serve history, which is another non trivial change. So I guess, like clients, do you want to give a overview? What do you see as the effort to do that? To what extent is this a big ask for teams? I think it's a relatively small ask. I think the maybe big change is that clients might have to change their behavior for how they start syncing from scratch.
01:24:11.732 - 01:24:57.882, Speaker A: So they won't go and request blocks before the merge. So they'll sort of stop once they get to that merge point. During the backfill, there'll be some changes for the ethwire protocol. I don't know if we'll need to. I mean, yeah, we'll probably need to update the ETH wire protocol and to say that requests for headers and bodies before a certain point will not be accepted or responded to. In general, these are pretty small ask from client teams. I think the biggest thing is like, as we've talked about in the past, is making sure that we want to making sure that this data is available, and we have efforts on making that data available with error format and having people provide that data.
01:24:57.882 - 01:25:24.264, Speaker A: If clients want to continue supporting the pre merge data, they wouldn't need a way to process the Era files. None of this is particularly difficult. I think some other clients have already implemented the error format and it's not a huge request, it's not a requirement. But if they want to continue serving that data to their users, they would need to come up with a way to ingest the data. Merek.
01:25:26.724 - 01:26:26.914, Speaker F: I very like this idea, but there are a few, probably more problems. First of all, we need to check with CL clients how they are handling deposits, because deposits are included in checkpoint sync, but if click clients will not use them, then they have to start doing it before we drop history. The another thing is, I think it might be even more problematic for clients like ref or Eridon when they syncing from Genesis. I might be wrong, so please clarify if I'm wrong here. And generally archivesync might be a little bit problematic after that, but we could import data from era files. I don't know how do you see that light ran?
01:26:28.414 - 01:26:36.674, Speaker G: Sorry mark, can you articulate the question or the risk for the ergon architecture that applies all to the rest.
01:26:36.854 - 01:26:51.134, Speaker F: So my question is if it is not problem for you if we drop all the blocks, pre merge all the blocks and you will have to start syncing from after the merge.
01:26:53.034 - 01:27:47.598, Speaker G: Ah, I see. It is true that neither and somebody from Merrigan should also weigh in on this. It is true that the snapshing functionality is not as is supported by the architecture. We had a conversation with that in the ACD channel with Felix from guest and that is because the snapsync protocol gossips sha instead of preimages and an execution in rest. And ergonom is based on pre images of the keys, so there is no way to map back from the chat to the preimages. There is an interesting question to what extent with Verkle we can also, and this might already be part of the vertical specimen. There is an interesting question to what extent this kind of sync is kind of like we can do snapsync perhaps in ref or ergon with vertical.
01:27:47.598 - 01:28:22.952, Speaker G: I don't know if that is possible. I think that's a question that we want to explore in the coming weeks or months. So that said, it means that we cannot support snapsync, which means that it hurts our ability to sync from scratch over p two p and I would love to have a conversation about it. We don't feel too strongly about it. It's possible that we can maybe host pre merge history somewhere and maybe that's fine for us. Yeah, that's roughly how I think about it. So I don't have a very strong view, but yeah.
01:28:22.952 - 01:29:15.364, Speaker G: And to the extent that we get an archive format, whether it is era or something else that might help. I think on that, on the archive format there are interesting questions around a what is the optimal file format? Whether having an optimal file format matters or whether we should move forward with something that just works. Having clear requirements for the archive format which we have asked in the chat and we think the conversation still needs more work. And finally, on the dissemination method of these networks, where I feel like it's great to say that we have portal network as an answer, although there I think we need to get again more precise, more clear on timelines and really really be clear about the dependencies between these three, the interplay of history expiry, picking the right file format, which might be a simple decision, and a dissemination.
01:29:17.584 - 01:30:20.294, Speaker A: Okay, I want to just go back to the other eips because we only have two now 1 minute left. I don't think so. Matt has a draft eip out? I think we should review that, but I don't think we should make a decision about including the draft EIP in the fork, even though there seems to be a rough consensus towards clients generally want to move towards that. And it's more question that when and how rather than if before we wrap up. I guess 29 35 feels like something where there's pretty much broad consensus, no objection, as far as I can tell, and it's fairly simple. Does anyone oppose including that in the fork and also having it part of Devnet zero so that we can get it prototyped as soon as possible? If there's no objection, I think we should move forward with that. So, including 29 35.
01:30:20.294 - 01:31:16.130, Speaker A: So Mariel, this is the block hash in the state. So like the same thing as 4788 basically, but with a different value and then the last one. So 7623, there's a lot of discussion about that, about blob size increase and whatnot. I feel like we should potentially CFI 7623 but not include it yet. There's probably some more discussion to be had there. So does that generally make sense to people? Okay, if there's no objection, we can do that. So to recap, aside from all the stuff that was already included in the fork, we added 3074, 29 35, both of which will be part of the Devnet zero spec EOF and 7623.
01:31:16.130 - 01:32:21.864, Speaker A: We've CFI'd, so we'll continue sort of looking into those in the next couple weeks, and then if we feel highly confident in them, we can bring them in later. And I think the other thing I want to flag is Proto's Eip to deal with some of the issues with 3074. That's also something we should keep looking at if we're already over time. So it feels a bit late to maybe CFI it, but yeah, I think at this point though, there's probably small things we can bring in the fork as we finalize things. But generally if EOF comes in, that would be the last big change and everything else that there should be kind of the bulk of the petro fork, at least on the El side. Yeah. Any final comments? Thoughts? Okay, well, yeah, thanks a lot, everyone.
01:32:21.864 - 01:32:29.094, Speaker A: Yeah, I will talk to you all soon and make sure to get all the specs updated.
01:32:30.274 - 01:32:49.314, Speaker G: And yeah, Tim, could I kindly ask you to in the all core devs channel, could we get a written articulation of what got confirmed, what is CFI and what are next steps for us to further discuss with precision and clear data driven articulations? Of where we need to do more work.
01:32:49.434 - 01:32:53.054, Speaker A: Yes. I'll post a recap in a few minutes.
01:32:53.854 - 01:32:54.702, Speaker G: Thank you, Tim.
01:32:54.798 - 01:33:05.230, Speaker A: Cool. Of course. Thanks, everyone. Thank you. Thanks. Thank you. Thank you.
01:33:05.230 - 01:33:06.774, Speaker A: Bye bye. Thanks.

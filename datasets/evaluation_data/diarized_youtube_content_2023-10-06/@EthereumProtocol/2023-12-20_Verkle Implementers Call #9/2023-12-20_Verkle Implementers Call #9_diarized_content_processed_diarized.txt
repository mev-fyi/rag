00:00:27.730 - 00:00:28.374, Speaker A: Okay.
00:00:28.572 - 00:00:43.480, Speaker B: Welcome everybody, to virtual implementers, call number nine. We will jump right into the agenda, starting off with client team updates. Would anyone like to kick things off?
00:00:50.120 - 00:01:16.064, Speaker C: Yeah, I'll go ahead. Yeah. So for me at least, we've been working on the shadow fork. And. Yeah, so there's been some progress. We now can simulate a shadow fork in kertosis. We start with MPT state.
00:01:16.064 - 00:01:50.200, Speaker C: We let Txfose run for a while until we have big enough states, and then we trigger the transition. So that's working. And then we started using. Okay, sorry, I see a message from Pari. Not fully in kertosis. I'm not sure what we. Oh, it's using ansible, but wait, I run it on my own machine, so it's got to be in kertosis somehow.
00:01:50.200 - 00:01:53.276, Speaker C: That was just the simulated version for.
00:01:53.298 - 00:01:55.456, Speaker D: The first bug we found where you.
00:01:55.478 - 00:01:57.084, Speaker E: Just had a multi block transition.
00:01:57.212 - 00:02:26.456, Speaker C: Okay, understood. Okay. Right, so it's not fully kertosis. Okay, got you. But yeah, anyway, we have a demonstrator, so we could build a testnet like this. But of course, the more interesting approach is to start a shadow fork. So we attempted holesky, and because it's a real payload, we started finding bugs that were not visible before.
00:02:26.456 - 00:03:03.664, Speaker C: So, yeah, it was just about basically saving pointers and restoring them. It's a bit finicky, but I think we're making progress. Although it's not done yet, and otherwise. I also looked into the testing. I don't know if Dan's here, maybe we'll talk about it at the end. So I created an equivalent of a subcommand for EVM transaction so that they can stimulate transactions and see what the output tree is. But yeah, there were some misunderstandings.
00:03:03.664 - 00:03:27.870, Speaker C: So yeah, I'll fix that after my holiday, because I'm currently on holiday. But yeah, I'm hoping to have some better, nicer announcements to make in a couple of weeks time. Yeah, inacchu, did you have anything else? Yeah, there was a test vector. Is there anything else we. You worked on?
00:03:29.520 - 00:04:31.040, Speaker E: No, I will share again in the chat, something that I shared in discord, if somebody wants to take a look at it. I just completed some test vectors for cryptography libraries covering some corner cases in crypto implementations. I already run these things in the go implementation. I know that people from the NIM team is including them in the NIM implementation. Probably we will work on the rust implementation in the near future, probably in January. I will complete the other part of the test vectors regarding the Verco tree data structure to cover some interesting corner cases there and witness generation which also has some interesting corner cases.
00:04:36.860 - 00:05:31.950, Speaker F: I can give some update regarding Ethereum JS stateless sync effort that is going on and for that basically I was integrating the new gas schedule, basically adding the charges for workal weakness accesses. I have had some limited success on that front that we are able to run few of the transactions and I aim to basically complete this in this week and maybe then we can again try syncing constant into with Ethereum JS stateless and I have few queries regarding this. Guillaume and I have sort of dropped them in the testnet, I think you haven't seen them yet.
00:05:33.040 - 00:05:36.510, Speaker C: That's right. I'll have a look. Sorry about that.
00:05:42.430 - 00:06:30.266, Speaker D: I can give an update regarding Bezu so we are still working in order to have the same root ash for the Genesis block, so we fixed several issues. The last issues it seems that it's a difference between specification and the current implementation in guest, so I'm waiting for your feedback Guillaume. It's not George, but it seems that for the specification, in order to have the main storage offset we want to use the PO operation and in guess it was a shift left. So in order to have the same route we are doing as gas we are doing a shift left. But we need to know in the future if we want to.
00:06:30.368 - 00:06:32.374, Speaker C: It's the next item on the agenda.
00:06:32.502 - 00:07:13.160, Speaker D: Yeah, okay, so I will let you talk about that. But after this modification we have the same root node so we still have a last operation in order to have the same state root ash. But clearly we are close to have the same generic state root and when we'll have that we'll try to join the testnet in order to import more block. I still have to do some refactor on my side, but it's not something that will prevent us to try to join the testnet. It's all on my side.
00:07:19.830 - 00:08:01.250, Speaker G: I can go and share updates for Aragorn so I have been able to join the network per se, but I'm facing issues on block number twelve, so I think it has something to do with gas schedule mismatch. So I'm working and looking into what sort of mismatch that might be, although I sort of implemented the gas schedule changes. But I hope to resolve this issue and make further progress with worker gen Devnet two. That's all from Aragon?
00:08:01.990 - 00:08:06.600, Speaker C: Sorry, good question. Didn't someone else not have a problem with block twelve?
00:08:07.370 - 00:08:10.886, Speaker E: Yeah, we did with Ethereum js, but.
00:08:10.908 - 00:08:13.062, Speaker H: I think block twelve is the first.
00:08:13.116 - 00:08:23.260, Speaker E: Block that contains other things. And just like simple value, each value transfers. So it makes sense that people would block on that, right?
00:08:24.590 - 00:08:31.500, Speaker C: Okay, yeah. Well, if you're having questions on that, just message us.
00:08:32.750 - 00:08:34.080, Speaker G: We'll do. Sure.
00:08:42.670 - 00:09:12.530, Speaker C: I think I'll go next. I don't have any significant updates. There are some issues with block production and I'm just trying to get that fixed. After that, we will get back on syncing using vocalsync. Okay, so I can speak for Nemba's team. Not much progress lately. Lots of end of the year vacations.
00:09:12.530 - 00:09:31.610, Speaker C: We're finalizing our mat library and we will integrate it into our virtual implementation in the next couple of weeks, apparently. And then we can finally start seeing root hashes. But then we're still a bit farther away to join the destination.
00:09:47.180 - 00:09:49.390, Speaker B: Okay, anyone else?
00:09:54.080 - 00:09:54.876, Speaker A: Cool.
00:09:55.058 - 00:10:01.570, Speaker B: We can move on then. The next agenda topic is Guillaume with the main storage offset value.
00:10:04.740 - 00:10:43.336, Speaker C: I mean, Kareem already described the issue pretty well. Let me look for my window. Here we go. So there was a mistake. I don't know if you guys can see my screen. Yeah, so there was a mistake in the computation of the main storage offset value. It was supposed to be a power and we were instead using some shift, some incorrect shift.
00:10:43.336 - 00:11:26.170, Speaker C: So Karen pointed out that this was incorrect. This is my fix. I would need before I merge it to confirm. Because what was maybe a bit surprising to me at first was that tannish didn't find it or Ethereum js didn't find it. But then if your reference was my repo, clearly you also have the mistake. So before I merge it and confirm that this is incorrect, I wanted people from Ethereum Js and nevermind to have a look and confirm that this is a bug. I expect them to confirm that, but just want to make sure.
00:11:26.170 - 00:11:58.362, Speaker C: And yeah, when this is done, I mean, we're not going to relaunch the testnet just for that. It's just a value, it's just an offset. But when we do relaunch, it would make sense to have it fixed, to have the fix in. Yeah. I don't know if you guys have some comments. Yeah, that's also what I was thinking. Maybe the block twelve is related.
00:11:58.362 - 00:12:22.120, Speaker C: But then because g eleven or gadgeter went and Gabriel passed this issue, I guess they must have somehow either made the same mistake or it's not related to this.
00:12:23.530 - 00:12:25.830, Speaker F: I think we have made the same mistake.
00:12:26.490 - 00:13:09.710, Speaker C: Okay, so yeah, if you could just confirm, look at the spec, look at your code again, confirm that this is incorrect in your code as well, and then get back to me. I'll merge that fix and we'll be ready for relaunch basically. And I'm also going to copy the link into the chat so that you have the reference. But yeah, that's pretty much it on this topic, if everybody agrees.
00:13:15.080 - 00:13:35.740, Speaker B: Cool, thank you. Next up we have on the agenda the curve discussion. I believe Carlos, if I heard correctly from Guillaume, you will give a quick update or summary on some discussion that recently happened around curve choice in Verkel.
00:13:36.480 - 00:14:41.984, Speaker H: Yeah, no changes so far, so nothing to be worried about. But I kind of did a bit of exploration based on Antonio's latest paper, which is exactly about deriving BLS curves and curves embedded into those. And basically the only thing that I was trying to see what was easy to sort out is the fact that we currently need to split the EBm stored value into 128 limbs to then commit to both limbs instead of a single one of 256 bits. That's because of pander snatch field size. Well, BLS twelve three one field size indeed, which is 253 bits instead of 256, so we cannot fit everything into it. The proposal was basically trying to find if it was worth it to find a new pair of curves such that we can get rid of this extra commitment or MSM term plus not lose. I think it's one or two bits of information for every single value that we store.
00:14:41.984 - 00:14:50.420, Speaker H: So far the feedback was given from Antonio Duncrat and Gottfried that I recall at least.
00:14:50.570 - 00:14:50.884, Speaker A: Also.
00:14:50.922 - 00:15:38.656, Speaker H: Ignathio. If I remember correctly, the most important things mentioned were the extreme SM term shouldn't be a performance or space issue. This is from Antonio Duncrat. Same with basically the design of a new BLS curve isn't worth the deal considering all of the work that it would take to actually put this into a pre compile and design everything and all that stuff. Third BLS twelve 381 is also probably going to make it into mainnet anyways via four eight four. So it's probably worth it to reuse this anyways and hack a little bit the way in which we commit to the storage values by having these two limbs. And finally this is the one I don't really understand.
00:15:38.656 - 00:16:22.770, Speaker H: It was mentioned that the scalar field bigger than 256 bits might not be a good thing performance wise, but this is only one extra bit and we only use the scalar field, if I remember correctly, for the msms. So this only affects in having one monitoration of double an app, which shouldn't be, at least to my perspective, an issue performance wise. But in any case, this was all of the feedback that Antonio Duncrat gave. And as Antonio and Godfrey agreed on points two and three, and I do agree too. So far it seems that as was already presented, brs twelve, 381 plus Vanderbagan and splitting value looks like.
00:16:24.820 - 00:16:25.296, Speaker E: The most.
00:16:25.318 - 00:16:32.870, Speaker H: Precise technique or the best one that we can aim for so far. So that should be it.
00:16:36.440 - 00:16:40.950, Speaker B: Awesome. Thank you, Carlos. Does anyone have anything to add to that or any.
00:16:51.100 - 00:17:35.180, Speaker C: I mean, just a quick comment. The extra bit would not be a problem in my view, because we could always shuffle it somewhere. I mean, this is what we do, but it could have the same complexity because we have an extra bit hanging around. Yeah, I think it's still interesting to dig, but if it makes no sense to, if it's not worth the effort, then we'll continue with the current model. It's just that there was an opportunity to maybe make things a bit simpler for. Yeah, I mean, I was trying to answer the question you put on the chat, Josh.
00:17:37.360 - 00:18:13.224, Speaker B: Got it. Thank you. Okay, next up on the agenda item is agenda item four, gas schedule. And perhaps reviewing it as initially EIP 4762 was created with the idea that the gas schedule would be adopted in the fork before Burkel trees. And that does not seem likely anymore. I think maybe you had some thoughts that you would like to start with here, possibly, yeah.
00:18:13.342 - 00:18:18.730, Speaker C: So it's really an open discussion. Danker was going to say something already. Go ahead.
00:18:22.620 - 00:18:38.880, Speaker A: Sorry, me? Yeah, so I thought we talked about this before and decided that it didn't really make sense because we had the ideas of lowering gas for certain operations because of vertical, but we can't really do that before we implemented vertical.
00:18:39.700 - 00:18:40.448, Speaker C: Right.
00:18:40.614 - 00:18:43.730, Speaker A: That's my memories of this discussion last time.
00:18:47.140 - 00:19:47.344, Speaker C: Yeah, exactly. But the problem now is that when all the tooling breaks, basically we have TX for us, we have other like, for example, Adrian from open zeppelin started deploying some of his test contracts on the test debt and all the tooling breaks because for each transaction you have the intrinsic gas, which is 21,000 gas that you pay upfront. And my understanding at least, of the reason for this intrinsic gas is to cover all the costs that you would incur to kick start a transaction. And one of them is of course to go get the account from the database. The sending account from the database. This is something that we pay on the site. We pay for on the site now because we pay the cost of adding it to the witness.
00:19:47.344 - 00:20:18.460, Speaker C: So that means that even sending a simple transaction is no longer 21,000 gas. It becomes something around 36,000. I forgot the exact number 34,000. But a lot of tooling gets broken because that value is simply hard coded, including TX fuzz. But also, like I said, some open zeppelin tooling. And I assume this is just the surface. There's got to be thousand other tools that have this value hard coded.
00:20:18.460 - 00:21:20.230, Speaker C: So my question is maybe we should revisit at least the intrinsic gas and potentially other costs that we should update during the broker transition because it feels like you're paying double. Really? It doesn't feel fair that if the intrinsic gas cost covers the reading of the sender account, user should pay on top of that for the witness cost. So yeah, that's basically the case for it. So maybe reduce the intrinsic gas from 21,000 to 21,000 minus the cost of accessing one account, at least one account, if not the sender account and recipient account. But yeah, I don't know if there are some counter proposal to this or if it is expected that the cost will be higher.
00:21:24.200 - 00:21:33.290, Speaker A: I think that makes sense. What does it do? It's like really accessing two accounts. What would that cost? In isolation? It's just like it's much less than 21,000, right?
00:21:33.660 - 00:21:43.320, Speaker C: Yes, I would have to do the calculation, but it is much less than 21,000 for sure. Although.
00:21:45.600 - 00:21:54.430, Speaker A: You could simply say the 21,000 already includes the cost of accessing the sender and the target account.
00:21:55.940 - 00:22:25.930, Speaker C: Right. So my question would then be do we keep the 21,000 and so make the sender and target account free? Seemingly free so we don't charge the vertical cost for this? Or do we change the intrinsic gas to make it 21,000 minus the cost? So that when you actually charge the cost you find 21,000 again?
00:22:27.180 - 00:22:53.410, Speaker A: I mean, I think it's very clearly better to do the first one because otherwise, let's say later, we decide, oh, we want to change the gas cost or a roll up. Once you have a different gas schedule, they would have to do this rebalancing to make sure this is 21,000 or less. So if the goal is the base transaction should cost 21,000, then I think the answer is very clear.
00:22:54.980 - 00:23:13.470, Speaker C: Yeah. Okay. Yeah. Then that's fair enough. I mean if anybody else has an opinion. But I think that's also the best approach. Okay.
00:23:15.120 - 00:23:39.590, Speaker F: I think what we can do is basically in 21,000 we can basically give few excesses, the origin and the destination excesses free. So basically when we charge 21,000 we basically add those accesses anyway to our accounting and then maybe we don't really need to.
00:23:41.160 - 00:23:47.060, Speaker C: I think this is exactly what we agreed on. I'm not sure. Maybe I misunderstand your point. Gichinder.
00:23:49.820 - 00:23:56.536, Speaker F: Okay, I'm fine. Maybe I didn't understand a bit. There were discussion here, right?
00:23:56.558 - 00:24:24.516, Speaker C: So let me summarize. Maybe I'm the one who did not understand. Instead of we keep the 21,000 value so we don't change that. But in the code at least I visualize it. In geth, when you start up your transaction, you say okay, you're going to read the sender account, you're going to read the recipient account. Those values don't get charged. Basically, in this specific context, those values are free.
00:24:24.516 - 00:24:45.930, Speaker C: Well, seemingly free. They're included in the 21,000. And then we just charge the regular, and then we still add those values to the witness so that they don't get charged later on. And that's basically it.
00:24:46.960 - 00:24:49.150, Speaker F: Yeah. Then we are on the same page.
00:25:01.860 - 00:25:05.040, Speaker B: Okay, if nothing else on this topic.
00:25:05.940 - 00:25:19.220, Speaker C: Yes, just one point. I will therefore create a PR to update the EIP and I will share it on the channel, on the Discord RND channel for more feedback.
00:25:20.200 - 00:25:41.470, Speaker B: Sounds good. Last up, we have a topic that we've discussed on a recent call, the vertical verification pre compile. I think, guillaume again, you had a few things that you wanted to touch on here.
00:25:42.720 - 00:26:32.616, Speaker C: Yeah, we didn't really have time to mention it last time, but. So there's been a proposal. Let me share my screen again here. So the idea would be to add a pre compile that does state verification. So it should no longer be called the vertical proof verification precompile because it's actually the state proof verification precompile, because Protolamda sweeped in and gave some feedback and said it would be great to have also the ability to verify merkel trees. So the principle of this pre compiler is the way it works is very simple. You just pass a series of bytes and the first byte is a version which is currently one byte.
00:26:32.616 - 00:27:50.800, Speaker C: We can make it larger if you think we'll have so many proof systems in the future that it wears more than one byte. Then you have the state route which is taken from the block, and then the proof data, which is really just it's an arbitrary payload that depends on the proof type, and then what precompile does. It gets the version from the first byte, and if version is zero, it will deserialize the MPT multi proof and verify it called the verification the MPT verification function. If version is one, it will deserialize a vertical proof and maybe those functions should actually be called something else, or at least have a different name, and then called the polynomial commitment scheme multi proof verification thing. And in its current description, the precopile returns one if it successfully verified the proof, and zero if it did not verify the proof successfully. Another feedback that was given by proto was that the pre compile should revert, period. I'm not sure there's.
00:27:50.800 - 00:28:20.530, Speaker C: I mean, according to him, it saves a bit of gas, so we could do that. I'm honestly not having any opinion on this. I think it's a bit simpler to describe that. So to describe just returning a value, but I don't mind reverting if that's what people prefer. And then Inacio had some extra comments about it, which if you want to give them.
00:28:23.220 - 00:28:41.496, Speaker E: Yeah, I had two comments regarding this topic. The first one is that some weeks ago I was reading this and realized that I think this API is missing something else. So the API today is that you.
00:28:41.518 - 00:28:42.090, Speaker I: Give.
00:28:44.380 - 00:29:57.250, Speaker E: The serialized proof and the state root, and you will get a yes or no if that verifies. But I believe that this pre compile also needs to have a way to check which keys are re improving in this proof. Because if you are a contract and you are calling and you are receiving a proof, and you will use this pre compiled to verify the proof, you will be interested in knowing which keys are being verified, because if you don't know that, you are not actually sure what is being proven. So yeah, that's one point. And the other point is the support from the Marco Patricia tree proof verification. My concern about this is if this is worth it, because in a year or a year and a half or something like that, Berkele trees will be using mainnet. I know if many people will still be using merco Patricia tree proofs for things.
00:29:57.250 - 00:30:32.010, Speaker E: And also the CGVM will have to include implementation of the proof verification. So that's kind of some extra complexity that we are pushing there. But maybe Carlos has a better idea if that's a huge pain or not, because maybe in the future we can remove the support for version zero, which is this Marco Patricia tree. But that's kind of a breaking change, and I don't know if that's kind of nice. So yeah, those were my two points.
00:30:38.610 - 00:31:20.620, Speaker H: Yes, Carlos, I think there's better ways to go with this. I think we started briefly discussing it with Ijo, and I think you Matthew, also after talking with Jordy, that for instance, you can do proof of equivalence for trees and stuff like that, and you can have external services. You can even have yourself this kind of thing so that you don't need to load the entire main net to be able to support this kind of protocol when the usage might already be low, but even lower when we switch to ventil. Because I agree there's not many reasons why you would like to use.
00:31:24.110 - 00:32:22.522, Speaker C: Did. Yes. So one question I didn't understand one point I didn't understand from what you said, carlos. Yes, it's true we have this possibility of having proof of equivalents, but what I mean is, even if it stops in a year, if people don't use this pre compile after, sorry, the MPT part of the pre compile after a year, there will still be deployed contracts that could potentially use it to verify approve at any moment. So that would break those use cases and it would still be useful. Now the point I didn't really get from the point you made, Carlos, is it really much more complicated to implement this precopile? Because this is not the impression I got, but I'm not really versed into the ZKVM.
00:32:22.666 - 00:32:55.418, Speaker H: I wouldn't say complicated as to just support it. Mainly the complex thing will basically be all of the logistics if then this gets deprecated, or the space that it might take, or the maintenance burden on reviewing auditing, et cetera. If then almost no one is actually using it, which is kind of the same thing that happens with riff MD or Blake two f or stuff like that, that almost is not usage yet everyone needs to pay the cost of supporting it.
00:32:55.584 - 00:34:30.310, Speaker C: Yeah, indeed. That's basically the other side of the argument I was making, which is indeed we would still need to support it like we support RipMD or other pre compiles that we really no one uses, but in the off chains that they could be used, we have to be able to support them. The other point about this is it really going to be a year? Because all those roll ups, some of them are presumably not going to switch to veracle at the exact same time that mainnet switches to vertical. So if it takes them another three months, I would say my argument doesn't hold. But if, for example, I think we had a talk with scroll, they were not super eager to jump on the vertical bandwagon. So if those people decide, or people like them, I mean decide not to switch for more years, an insignificant number of years, it would make complete sense to keep it. So I guess one thing we need to do is talk to every roll up and figure out what their plans, and I mean mostly the optimistic roll ups to figure out what their plans are regarding vertical.
00:34:30.310 - 00:34:35.260, Speaker C: Go ahead.
00:34:37.950 - 00:35:17.510, Speaker A: It's not obvious that a roll up having a different state scheme should impact what we should implement on an l one. Like for example, roll ups might just use completely incompatible schemes that we're never going to implement natively in our pre compile. So I think it's worth thinking through what is the exact advantage of, say, l one being able to verify a roll up state? Proof there may be applications, but I don't know if it's been properly investigated, if that's necessary. And either way that's going to be universal.
00:35:18.090 - 00:35:24.166, Speaker H: Like there are applications. But I agree with you that if they want to support those applications, they should be the ones that try to.
00:35:24.188 - 00:35:25.766, Speaker I: Be compatible with l one rather than.
00:35:25.788 - 00:35:40.974, Speaker H: The opposite way around. So I agree, but you can swap the roots of the trees to make calls that interact with data from l one being in n two, or vice versa. So there's definitely applications for that. But yeah, I'm with you also on.
00:35:41.012 - 00:36:25.466, Speaker C: This, right, okay, yeah, that's a good point. Just also jumping back to what you said about the equivalents. So for example, a Zk roll up would have no problem. And indeed, like if a Zk roll up maintains the equivalence between two trees, then all they need is because they have the proof of the equivalence, all they need is to have the vertical proof part of the pre compile. But what about non ZK roll ups, for example, optimistic roll ups? Would they need to also maintain an equivalence on their own to be able to use it this way?
00:36:25.648 - 00:36:47.300, Speaker A: I don't think what you say makes sense, because the whole reason someone uses a different scheme, for example with ZDK roll up, is that they don't want, it's too complex for them to use Merkel or Veracle or whatever, so they want to use their own. And so equivalents completely gets rid of that advantage, then they might as well just use vertical only.
00:36:49.030 - 00:37:13.260, Speaker C: Well, okay, I think the problem is, from what I understand at least, optimism does use the same scheme, like the same MPT scheme. So if they don't want to switch to vertical immediately, we are exactly in that use case I described, where we have a major player that still uses the old system that is compatible with the current version of mainnet but will no longer be in the future.
00:37:19.330 - 00:37:29.940, Speaker E: I would ask the question like how is optimism working now without this pre compiled? Is this something critical for them? They are having some other workaround today.
00:37:33.670 - 00:38:20.180, Speaker C: That's a good question. I mean, they are really eager to push for it. So I assume that it's basically that yes, they have a workaround, but it's costing them a lot of gas. Okay, well, I guess just to progress, at least on this point, is figure out if indeed it is a problem, because it is a problem. What I describe is really a problem that people won't switch. Because if optimism switches and other optimistic roll ups like Arbitram, like the major ones, decide to move on at the same time or close enough, yeah, it would not make sense to support it. I agree.
00:38:20.180 - 00:38:56.590, Speaker C: The other point I wanted to discuss, or at least get a clarification on in Nasio is when you said you need to pass the keys, but I do not remember that was the point you initially made. Because if you pass the witness, you do pass the keys, right? If you pass something that is exactly like what we pass in a block, we also declare the keys that we want to mean. I don't think I understood your point. Why is passing the key important via the API?
00:38:57.010 - 00:40:26.700, Speaker E: I can clarify. Yes, I mean, the keys are part of the proof. But my point is that the contract wants to know which keys and values are being proven by this proof. So, for example, if you are a contract that what you want to know is which is my balance at a particular block number, what you would expect to receive is a proof of that. So you will receive this proof blob and this state root and you will use the pre compile and you will get yes, this proof is correct, but if you don't do anything else, if you don't check that this witness includes the keys of my wallet address with the value that you want to verify is true, then the only thing that you know is that the proof is correct, but you don't really know which is being proven. If you don't have a way to also tell the pre compile. Hey, is this witness including these keys and values in the proof or not? Because I can send a proof of your balance and not my balance, and you don't have a way to know that if you don't have a way to tell the pre compile to also check if some particular keys and values are part of the witness, if that's clear.
00:40:27.070 - 00:40:51.620, Speaker C: Yeah, because indeed you receive an opaque payload and you don't know if your key is really in the witness unless you implement some logic yourself and therefore it kind of beats the point of using this pre compile. I think there are use cases where you don't need this, but it's true there are potential use cases in which you do need this. Yeah, okay, now that's fair enough.
00:40:56.240 - 00:41:26.570, Speaker A: I mean, I would argue you want even more, ideally, you want even logically to say what you want to access, because even if you prove key values, then the proof is still dependent on the mapping, say, where you store the balance. Ideally for a really independent proof scheme, you would just say like account balance is this.
00:41:30.140 - 00:41:31.850, Speaker E: Yeah, I agree with that.
00:41:35.020 - 00:41:52.050, Speaker C: Okay, so that's a huge change to the interface, but yeah. Okay. No, that makes sense. I need to think about it, how to implement the API, but okay, yeah, that can be done, I guess.
00:42:05.170 - 00:42:13.040, Speaker B: Okay, cool, we have made it through the agenda. Anyone else have anything they would like to bring up?
00:42:19.910 - 00:42:20.966, Speaker C: If not, I think there is an.
00:42:20.988 - 00:42:23.400, Speaker E: Extra point in the agenda. Number six.
00:42:25.690 - 00:43:00.100, Speaker B: Yes, the testing doc that was created by Dan so we could touch on this. I was thinking that I was dming with Dan before the call and just now actually I don't think he's on the call, he couldn't make it. That maybe it's best to wait for Dan or anyone else from the testing team to be on the call to discuss. It's linked in the notes. If anyone would like to review the doc. I'll link it again here. 1 second, but yes, I think that will wait for a future call.
00:43:00.100 - 00:43:17.480, Speaker B: Sounds good to you and cool. Okay. Milos? Yes, sorry Milos, I forgot that you had brought up a few things. Please go ahead.
00:43:18.670 - 00:44:37.780, Speaker I: Yeah, basically I posted a question on the agenda as well. It's about the state and how the nodes are encoded, and if there is some standard way, and whether we should standardize some way. Like for example, I'm not sure exactly how we currently store what are the nodes and the values, or we actually just store the commitments of them in the block itself, or just in general, should we standardize this in some way? I agree that clients can do however they want implementation, but maybe there should be. Or should we think about standardizing? And also, did we calculate the impact on the archive nodes, whether the worklab would actually be more helpful or not compared to the merclay? And the reason for that is, if we have a node that has a bunch of values, but only one change per block, then every new version of that node would basically just duplicate the entire node itself. And with just one value change, one child change, would that increase the value that is used? Or did we do any analysis on that?
00:44:38.950 - 00:45:14.240, Speaker C: Did you see my answer in the channel? Because I did respond to you. I mean, I can give you the summary gist. So no, there's no standardization. That wasn't part of my answer. On the channel. But I don't think there should be, simply because even in the MPT space, there's a lot of design iterations going on right now. So I don't think it's a good idea to standardize right now when everything is still evolving quite fast.
00:45:14.240 - 00:46:10.800, Speaker C: When it comes to the archive node, or at least size estimates. I responded to you, I gave an estimate we do not have. Like I said, I was saying at the beginning, we are currently working on the shadow fork of Holesky, so we can give more accurate data then. But the estimate, without all the optimization that you mentioned and those we have in mind, we save basically 10% of the space. Like this is the back of the envelope calculation, so it could completely go wrong. Once again, we need a real payload to give you some actual number, actually an actual explainable number. But from what I can tell, yeah, it should be much smaller because we don't store as many data.
00:46:10.800 - 00:47:02.190, Speaker C: But we also have the problem that currently we don't have any specific, I'm talking forgeth here. At least we don't have any specific optimization. When you recognize a pattern, for example an account, you could store that in a much smaller way, but we don't have this optimization. So I would say currently the amount of gain is limited because storing an account is basically five times as large as the way you could store it. But that's connecting back to my first point, that we still have a very large design space that we're currently discovering or going around, so it's not a good time to standardize, in my opinion.
00:47:03.110 - 00:47:04.820, Speaker I: Okay, thanks.
00:47:08.830 - 00:47:31.460, Speaker C: But let me return the question then, if I may. What would be your needs for that? Why do you ask for standardization? Is there a reason behind it, or is it just because, yeah, for example, is it out of curiosity, or is there an intent behind that?
00:47:32.870 - 00:48:49.260, Speaker I: Yes, I was basically just looking in the portal network case of how much, let's say, data would a node need to store, and how much data when the nodes transmit, like the portal network nodes transmit the workland nodes between themselves, how much payload would that be? And stuff like that. And realize that for a big node that's 8 kb, which is like for the branches that are full, that's significantly bigger than what is the case with the mercury tree. But it shouldn't be the problem. And I was looking like if there is a way to standardize, of course we can create a standard within the portal network. But I was considering if there is maybe already some standard that is used that I just wasn't aware of, but yeah, we can make a standard for us when we transmit like a smaller nodes and also the way we would store them as well, et cetera. But I was just curious if there is a standard, and I was looking for the archive state because basically the portal network, if we support historical state and everything, it would also maybe affect us in a way, and I wanted to know if there was some estimate done on that space. So basically I was just looking how it connects with the needs and usage in the portal network case.
00:48:50.270 - 00:49:39.946, Speaker C: Yeah, when it comes to archive node, I'd say let's wait for what? For some net's work to complete because I'm sure we can get some very accurate data. But yeah, I just wanted to go back to one point you made, no node stored in the database is 8 we store by path. I mean, I'm talking about gas here, we only store by path. So when we give an internal node, we only give its commitment because its children are known by the path. So you should never find yourself in a position of sending an eight kilobyte node around the network. I mean, I'm saying you shouldn't have to basically, yeah. So I don't know if that helps, but this is clearly not a standard.
00:49:39.946 - 00:49:48.030, Speaker C: I'm just saying you don't have to worry, or at least you should not have to worry about sending an eight kilobyte node across the network.
00:49:51.490 - 00:50:23.080, Speaker I: Okay, I will have to think if that's something that we can use in the portal network case as well, because you don't have like you as a one client in the network, you don't see the entire tree, you don't know the entire tree, so you need to find that through the network itself. But it's hard to know because you cannot store the, where would you get the information? How do you get to the leaf node that actually contains the data? But yeah.
00:50:26.590 - 00:50:41.760, Speaker C: If I understand your question correctly, which I might not, how do you know that? Well, you find, yeah, but you need to connect to the parents. Yeah, okay, yeah, maybe what I said doesn't apply to you, I would have to think it over.
00:50:42.210 - 00:50:43.440, Speaker I: Okay, thanks.
00:50:51.650 - 00:51:00.960, Speaker B: Okay, well thank you everyone for joining, and we will resume the call next year in January. Talk to you soon.
00:51:02.450 - 00:51:04.670, Speaker C: Thanks, have a nice holiday.
00:51:05.010 - 00:51:05.678, Speaker I: Thank you.
00:51:05.764 - 00:51:08.770, Speaker H: Happy holidays, happy holidays, bye.

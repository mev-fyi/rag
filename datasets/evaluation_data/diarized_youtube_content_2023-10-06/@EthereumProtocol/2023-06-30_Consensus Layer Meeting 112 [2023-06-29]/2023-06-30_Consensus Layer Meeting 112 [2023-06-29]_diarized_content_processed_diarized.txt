00:05:11.030 - 00:05:53.546, Speaker A: Great. We should be live. Welcome to ACDC, the consensus layer call one one two. This is issue eight two one in the PM repo. If you're following along, that's the agenda. So a few denab items, a couple of things from Mikhail about the engine API, and then we had planned to talk about thirty six as the blob target max. Hopefully some of you all have looked into the data, but we've also had some testnet hiccups, so we'll see as to where we are on that conversation.
00:05:53.546 - 00:05:57.230, Speaker A: Let's start off with you, Mikael, the deprecation.
00:05:58.290 - 00:06:43.566, Speaker B: Yep. Yeah, so from the latest call we've learned that. I'll drop the talk into chat. We've learned that basically execution layer clients do not log any error anymore if exchange transition configuration is not being called by the Cl. So that's great. And the next step would be if we take this path, the next step would be for Cl clients to stop calling this method or remove it entirely from the code base. And a requirement, according to this procedure requirement would be to make this change into Cancun at most.
00:06:43.566 - 00:07:11.240, Speaker B: So after Cancun, everyone upgrades their nodes and then el client can remove this method entirely from their code base as well. So that's basically it about the deprecation for sales side. Does anyone want to rise any opposition to doing this?
00:07:14.860 - 00:07:22.460, Speaker A: So you can remove the call or remove the code entirely now and you should certainly do so by the fork.
00:07:23.120 - 00:07:26.720, Speaker B: Yeah, that's the perfect recap.
00:07:34.570 - 00:07:57.680, Speaker A: In the opposition. And what happens if the client teams do not do so by the fork? That means they'll call a method or attempt to call a method that does not exist on the execution layer and would probably see, yeah, exactly that. Okay.
00:07:58.370 - 00:08:17.700, Speaker B: We actually will not be able to safely say that yel developers can remove this method from the code base. I don't think it's super big problem, but still, I guess we want to keep clean as clean as possible.
00:08:21.030 - 00:08:25.640, Speaker A: And this is in the Cancun engine API spec.
00:08:26.250 - 00:08:57.534, Speaker B: Yeah, it is there basically. So I take silence as no position to that. So it would be great if clients would keep this document posted so we can track the progress and be sure that it is done before conclude for sale clients in.
00:08:57.572 - 00:09:10.980, Speaker A: It sounds good. I'd say when we are discussing testnet dates, Mikhail, that maybe you just kind of do a quick pass on this on a call once more to make sure everyone's in.
00:09:11.510 - 00:09:12.660, Speaker B: Yeah, yeah.
00:09:16.570 - 00:09:23.750, Speaker A: Great. And the next item is also an engine API item from McGow.
00:09:24.590 - 00:10:37.520, Speaker B: Yeah, so it is a tiny change to the engine API, but it's not a tiny conversation, as tiny as the change looks like. So basically this is about overriding builder block by using by fallen back to local execution payload if local El clients suggest that some censorship is happening in the network. And we had this question before in one of our conversations after Shanghai, and we decided to get back to this in the context of Cancun. So now is the time to get back to this conversation. And yeah, I think that the change to engine API is really tiny and doesn't look too complicated. But yeah, I would like to ask POTUS, since he's on the call, to give more context about this and refresh the background on that.
00:10:38.610 - 00:11:31.314, Speaker C: Yeah, I can add more color, right? So the high level idea is just to give your local validator more finer control today. Local validator look at payload value, decide between the higher value between the local payload versus the builder payload. But this enables more control such that we can see whether the censorship, for example, whether transactions haven't been included for several slots with higher priority fee or some certain ts. Keep getting reorg and I think it's worth mentioning, the idea of optionality here is nice because different El could have different heuristic. It's kind of like herd immunity, and this is a feature, not a bug. And this is also an optional endpoint as well. So yeah, I think we discussed at the end of case Capella and due to timeline we didn't make it in.
00:11:31.314 - 00:11:34.370, Speaker C: And I think this is a good inclusion for Kingtun.
00:11:39.480 - 00:12:01.042, Speaker A: Yeah, it seems on the very minimal side of complexity because you can essentially do nothing on both sides other than just have this field. I'm pretty supportive. I'm sorry, my understanding was that it was a soft fork or does not.
00:12:01.096 - 00:12:03.458, Speaker B: Need to be hard.
00:12:03.544 - 00:12:07.140, Speaker A: Like is this field required to be sent?
00:12:12.360 - 00:12:26.264, Speaker B: According to this stack, yes, it is required to be sent, but the client can just send true false if it's not supporting any heuristics or do not want to support it.
00:12:26.462 - 00:12:36.204, Speaker A: And the CL can do a no up on or can for some amount of time not do anything in relation to the value, but the value needs.
00:12:36.242 - 00:12:40.530, Speaker D: To be there, just ignore it. So it might depend on zero change for us.
00:12:44.630 - 00:12:49.986, Speaker A: Why did we not opt for an optional value where someone can add it.
00:12:50.008 - 00:12:59.720, Speaker B: To the execution engine whenever they want? I probably can't think about it, but currently we don't have optional values in the spec.
00:13:01.130 - 00:13:11.740, Speaker A: There's also a hard fork coming up, which is a great time to transition and not deal with the complexity of.
00:13:12.270 - 00:13:36.100, Speaker E: If values exist on the CL side. We already do. Some fall back based on other conditions. So I think to support on the CL side that flag should be quite easy. And as said on the El side you just pass false by default and the protocol doesn't need any optional value.
00:13:41.660 - 00:13:46.920, Speaker A: Is there EL signal other than geth? I think Marius has an implementation.
00:13:53.170 - 00:13:55.346, Speaker B: Is there a specific consensus on the.
00:13:55.368 - 00:13:59.060, Speaker A: Heuristic that's going to be used to determine the value?
00:14:00.470 - 00:14:27.290, Speaker D: I think it's better not to have consensus. I think it's better to have client diversity here. And I think it's better to have diverse options that each validator can decide on what kind of sensors is censorship or not. I can give some several algorithms that I think are reasonable, but I suspect it's better to have each client team to come up with their own design decisions.
00:14:33.290 - 00:14:50.186, Speaker A: Is there a reason for this to be a field in get payload as opposed to having a new endpoint that has this sort of more general information? Because this is sort of like transaction pool information to some degree?
00:14:50.378 - 00:15:33.850, Speaker D: Yeah, I think there is an actual. So this opens the door, albeit minimally, to breaking the boundaries between the EL and the CL. So we really wanted to keep it at the absolute minimum and being trivially implementable, like having a different endpoint. This would definitely raise more concerns from El devs and it would increase complexity in using this endpoint or not. And I think just the fact that we're opening the door to breaking the boundaries between CLS and els in a way that we didn't do before, it's better to keep it absolutely minimal.
00:15:43.620 - 00:16:26.520, Speaker B: Alternatively, there was a suggestion for Cl to use JSON or PC API endpoint to grab the information required to implement some heuristics and encapsulate this completely in CL. But I should say that yel has all the information required for that, and probably some information will be really difficult to expose via JSON PI. And this is additional complexity definitely to do that. And the existing information that one can grab from JSRPCPI might not be enough for implementing some heuristics. So it's pretty constrained path.
00:16:26.680 - 00:16:37.430, Speaker A: Yeah, not even like types function, just all sorts of stuff that exists in EL to process, even if you can get the data on the CL.
00:16:40.200 - 00:17:05.164, Speaker E: Yeah, that was actually my suggestion. I think the reasoning was more or less that the CL has other information that it might want to weigh against whatever the EL is claiming. So like a little bit of censorship is fine, but I'm happy to be bought off by a big bribe and.
00:17:05.202 - 00:17:15.216, Speaker A: You still can be right. I guess you only see true false, but you can still decide whatever you want to do. With true false there is still the.
00:17:15.238 - 00:17:24.304, Speaker E: Value that you can read. So it's matter of bribe, you see the value and you can decide to ignore the flag at this point.
00:17:24.422 - 00:17:35.252, Speaker A: Yeah, you could also see false and have seen eight missing blocks and say, you know what I'm going to build locally. There is information, it's just less granular, obviously.
00:17:35.386 - 00:17:43.960, Speaker E: Yeah, there is, but it's very binary by definition.
00:17:44.540 - 00:17:54.748, Speaker A: But in many, I mean, I could be naive, it seems sufficient, but maybe I'm missing something.
00:17:54.914 - 00:17:56.632, Speaker D: And also it's not really binary.
00:17:56.696 - 00:17:56.924, Speaker B: Right.
00:17:56.962 - 00:18:39.508, Speaker D: So here is we have on the CL side all of the information that we can process and we make a decision, and then the El side has whatever information they have and they make a decision, and then we get to choose what we're going to do or not without having to know how to parse the El site. So whatever Nimbus decides, they might want to say, well, if I'm connected to get, I more or less understand what is the implementation of Geth, and I know what true or false means and I implemented this in prism. I might say, well, I know what Ericon would do and then I would just pay this or that much attention to what Ericon does. But it's not really binary.
00:18:39.684 - 00:18:46.510, Speaker A: There's more information. Also, it does not preclude a client from hitting the JSON RPC and doing other things.
00:18:51.310 - 00:19:01.310, Speaker E: Do we have a good JSON RPC to query the transaction pool this way? Basically, I don't know. Give me the top ten unincluded transactions.
00:19:02.530 - 00:20:05.170, Speaker F: We have the TX pool namespace in Geth and you can query the whole transactions. But this is a lot of information and it's very not really meaningful. We don't have an endpoint that sorts transactions or sorts of transactions by arrival time or stuff like this that's not really implemented, and it's also something that might not be going to be implemented. So we're kind of moving away from this endpoint in gath because we want to store way more transactions. Right now. The transaction pool stores roughly five thousand transactions in memory. And we would like to move to a world where we can dump some of the transactions to disk and only maintain the metadata for those transactions.
00:20:05.170 - 00:20:18.790, Speaker F: And in that case, servicing these transaction pool queries that we have right now wouldn't be possible for us anymore. It's already not really possible for block transactions.
00:20:26.360 - 00:20:26.932, Speaker B: All right.
00:20:26.986 - 00:20:38.190, Speaker E: Now I wanted to explore the idea before we commit to this, but I think if we get a Boolean we'll implement it for sure.
00:20:45.630 - 00:20:52.780, Speaker A: Okay, further discussion. Mikayl, this has not been brought up on the El call, has it?
00:20:54.430 - 00:20:55.180, Speaker B: Sorry?
00:20:55.710 - 00:20:58.800, Speaker A: This has not been brought up on the execution air call, right?
00:20:59.250 - 00:21:03.518, Speaker B: No, it wasn't. I mean, like it was before, but.
00:21:03.684 - 00:21:12.260, Speaker A: Long ago, I guess. Yeah, but as a breaking change for the cancun engine API, it has not been brought up.
00:21:13.590 - 00:21:19.140, Speaker B: Yep, it has. I think it works next week.
00:21:19.530 - 00:21:39.510, Speaker A: Yeah. And maybe right after the call we can try to circulate it and get some async conversation going so that there's something that looks like clarity before the call. Do these changes in the engine API require an AIP or.
00:21:39.660 - 00:21:45.560, Speaker B: No, it does not. No, it's just changes in the spec.
00:21:46.490 - 00:22:44.586, Speaker A: So the merge IP and the consensus layer specs kind of describe the high level communication and the requisite validations in the abstract. So that remains stable. And all this other stuff is an implementation detail, but doesn't affect the course. Okay, great. Next up, we had committed to revisiting three six a couple of weeks ago. I hoped that some engineering folks on the various teams have had a chance to look at the main net three six data experiments. We had hoped that we would have a testnet at this point.
00:22:44.586 - 00:22:47.550, Speaker A: Do we have devnet seven? Is that still work in progress?
00:22:48.690 - 00:22:58.370, Speaker G: It looks like we're passing all the five tests that we wanted to, so we'll start planning it out and most probably launch it tomorrow, if not Monday.
00:22:58.790 - 00:23:28.060, Speaker A: Okay, cool. Obviously the mesh, the type of nodes and the load are certainly very different on our devnets, but I think there was a desire to see this functioning on there. Open it up for conversation. The spec is currently written as three six. Is there any further opinion on the data? Thoughts on load? Thoughts on the stability of picking such numbers?
00:23:34.540 - 00:23:49.416, Speaker B: I have been spoken to Anton about this thing and he said that think that this is fine. The only thing that he's concerned about.
00:23:49.538 - 00:23:50.210, Speaker E: Is.
00:23:52.100 - 00:24:17.210, Speaker B: Is the flood publish. And if the flood publish is adjusted to these large fob messages, to the large messages, and in the context of four eight four, and it should be fine from his perspective, I mean like three six blobs should be fine.
00:24:19.980 - 00:24:24.360, Speaker A: What is the status of doing a staggered blood publish?
00:24:29.190 - 00:24:30.580, Speaker E: We'll be doing it.
00:24:33.990 - 00:24:47.660, Speaker A: Preneb like it will go out for. And will you be doing any sort of bandwidth estimation in doing so, or that will just be the behavior and maybe you can turn it off.
00:24:51.230 - 00:25:21.186, Speaker E: We're going to start with a reasonable value, probably user configurable, until we figure out bandwidth estimation, which is tricky. But on the other hand, we're going to base it. We're going to base it on message sizes and reasonable bandwidth for what a node should have. And then we're going to include a couple of faith safes as well, so.
00:25:21.208 - 00:25:22.020, Speaker A: That we.
00:25:24.950 - 00:25:57.914, Speaker E: Like if we run into a slow pair so that that peer doesn't break the thing and so on. But we're certainly going to do something because above all for blocks, it's a topic that everybody is subscribed to practically. So if you're connected to thirty, fifty, seventy peers, that's a lot of peers to be flat publishing to. It's a no brainer that we need some limit. And then what?
00:25:57.972 - 00:26:02.020, Speaker A: Yeah, limit and stagger. I guess there's two things. Yeah.
00:26:03.030 - 00:26:08.974, Speaker E: But flood publishing in its pure form would send it to all connected peers.
00:26:09.022 - 00:26:10.580, Speaker A: And that's not the same, right?
00:26:11.370 - 00:27:14.250, Speaker E: Yes. If any client is not implementing any kind of limit to flood publishing as it comes in native gossip sub, then this is bad. But then the staggering is another thing. We have a long conversation about this in our lip to p repo as well, but the basic idea at least is that for the first heartbeat we try to flood as much as possible. But after that we kind of want to leave room for the I have and I want mechanism to do more of the work because it's less redundant. That's where the backup mechanism comes from as well. And then we're also discussing this other protocol upgrade, which is the I don't want message, which is basically saying that I got the message, please don't send it to me anymore.
00:27:14.250 - 00:27:27.214, Speaker E: I would really love to push for this to happen before the ramp as well, but I don't know if timing wise that's possible, but it's a really important part of the overall strategy, I'd say.
00:27:27.252 - 00:27:38.770, Speaker A: Yeah, I don't want is backwards compatible, meaning it could be partially upgraded. Yeah, you get more benefits.
00:27:38.840 - 00:27:51.960, Speaker E: It's a significant difference, and it kind of depends on most clients implementing it. Or rather the more nodes online that implement it, the better it works.
00:27:56.010 - 00:28:04.330, Speaker A: What is the status of that spec becoming a spec rather than a pr and discussion?
00:28:11.650 - 00:28:13.280, Speaker E: I haven't looked at it.
00:28:14.370 - 00:28:21.566, Speaker A: I looked at it about a couple of weeks ago and it was still active discussion rather than something that looked like it was going to be rolled.
00:28:21.598 - 00:28:40.470, Speaker E: Out into the full story. Yeah, I mean, the alternative is really that we might pursue an experimental version of it before the spec is out. I feel that it's that important, but then we'll have to deal with the upgrade somehow.
00:28:46.650 - 00:29:43.704, Speaker A: It. Do other clients have notes about their blood published modifications and or that I do not want? Well, I know age has been working on the blood publish modification like specs, and I think he's been doing some experimentation, but I don't have much insight specifically into what he's done. And on top of that, he's also working on experimenting with using quick as a transport protocol instead of TCP. Yeah, both of those things I don't think we really have results from yet. Got it.
00:29:43.822 - 00:30:11.432, Speaker B: Probably we can in the next four implementers call, we can recap the networking thing, I mean like what should be done and what we highly desire to be done before work on the networking step and discuss more like I don't want and flat publish and all this and update statuses on those implementations and spec work.
00:30:11.586 - 00:30:50.190, Speaker A: Yeah, agreed. And I can knock on a few doors between now and then and make sure that the information surfaces so that'll be in one and a half weeks, which hopefully we can talk about on the breakout call and then surface it again here, I guess. Fortunately, the staggering approaches and blood published modifications can happen very independently of each other. That I do not want. I would much rather see as like a solidified spec than something experimental, but I guess we can cross that bridge as we get there.
00:30:53.570 - 00:31:03.854, Speaker B: I'm quite curious if there is anyone here that can merge the PR into the PTP spec. It seemed like that level is maintained.
00:31:03.902 - 00:31:06.820, Speaker D: By other group of people.
00:31:09.430 - 00:31:09.842, Speaker H: Right?
00:31:09.896 - 00:31:30.700, Speaker A: And we can always fork, but it'd be best to get it into the main, I guess. I'm not sure. Given where I last looked at the conversation, it wasn't clear to me that the kind of general r and D effort was ready to merge it in, but that could have changed since I looked at it.
00:31:35.190 - 00:32:30.270, Speaker B: So we can ask for lip to p maintainers. What's blocking this barrier from being merged? Can you reach out to them? On Dan's gar comments about the attacks, I think we should not worry about such attacks because the system will be able to pass those transactions through. Yeah, there could be empty slots as a result of this attack, but considering the cost of this attack with like no gain, or almost no gain for someone that's just bugging the system for a short period of time, this kind of attack does not look like a sustainable attack long term. Like a viable attack?
00:32:35.970 - 00:33:03.250, Speaker A: Yeah, I mean, I suppose it's unclear what the threshold of making it a viable attack becomes, right? Does adding all the blobs lower the threshold, thus lowering the cost for such the attack? It's also hard to parse in the context of split meshes, which that block would ride on a split mesh from the rest of the data. So feels like an unknown.
00:33:04.310 - 00:33:59.958, Speaker B: Yeah, I just wanted to briefly say, of course it's a bit of an inside worry because the main conversation here around is of course around just the normal case. But I think it's important to think about a little bit. It's obviously the situation will strictly get worse than before, just because bugs can still be as big as they were before and they're still propagated as one thing, and then we have these additional blops. Now I think I personally would be fine with just physically not worrying about it too much, just because. Also it's in the best interest of proposers to make sure their block arrives at tiers in time. So if this actually becomes a problem on Mainnet, we could imagine having just slightly modified block building behavior where you just make sure your block never gets too big, which is not actually too bad to do. So I personally wouldn't worry about it too much, but I do think we should at least physically make sure we.
00:33:59.964 - 00:34:00.966, Speaker G: Don'T just forget about it.
00:34:00.988 - 00:34:38.780, Speaker B: We are just basically, we make the conscious decision not to worry about it, that's all. Yeah, I pretty much agree, and I'd like to add that adding blobs might reduce the threshold, but I don't see how it reduces the cost of this kind of attack. In terms of spending eth to keep your transactions, keep your large transactions at the top of the mempool or buy the space from block building market.
00:34:42.930 - 00:34:45.920, Speaker A: The percentage of the block you have to consistently buy is lower.
00:34:46.930 - 00:34:48.080, Speaker B: Yeah, of course.
00:34:49.490 - 00:34:59.038, Speaker A: But with the exponential considerations, maybe it converges that not sustainable regardless.
00:34:59.214 - 00:35:28.490, Speaker B: Yeah, I would say that it seems to me that what makes this attack cheap, I mean like the space that one can buy and pay, not that big cost in this case. I think the network can handle this. It will definitely not be more than one megabyte or even more than a half of a megabyte.
00:35:33.290 - 00:35:58.250, Speaker A: Yeah. Okay, so we will monitor devnet seven, which will have these configuration values. When is the lib PTB community biweekly call, Alexey? You mentioned that in the chat.
00:35:59.390 - 00:36:00.074, Speaker B: Let me check.
00:36:00.112 - 00:36:53.210, Speaker A: But most likely every Tuesday. Let me show calendar. Okay. Yeah, so given the urgency of maybe some of the. I do not want things that might be worthwhile for a couple of us to join that call, we will surface more discussion around flood publish and I do not want on the four, four four call in a week and a half and we'll talk about this again two weeks. Peritosh, you have a Poleski or is that how we pronounce this update?
00:36:54.830 - 00:37:45.020, Speaker G: Yes, we just had the community call roughly an hour or two ago and we decide we have commitments from all the client teams that basically sign up to about one point seven million validators. We're going to be validating if that actually works. We're just going to have a small side chain where we're going to load up every single client combo and make sure that we can handle such a large genesis date. But if that's the case, then you should expect Genesis date to be ready at the end of July. And ideally they're included in all client releases by mid August, so that we'd be on track for mid September. Genesis. There's a link to the key takeaways as well as call notes, so please have a look and let us know if you oppose anything.
00:37:47.970 - 00:37:52.190, Speaker A: Is the allocation fixed?
00:37:54.610 - 00:38:17.720, Speaker G: Yes, the allocation is mostly fixed. We have three tiers, client teams, node operator l, two s, and others. In case someone did not make it in time. Please post a comment with a reason. And we're still open to evaluating stuff case by case, but ideally we don't want to because we're already over our planned target of one point five million.
00:38:19.290 - 00:38:20.280, Speaker B: Got it.
00:38:24.110 - 00:38:36.458, Speaker A: Well, there's a difference between the validator allocation and the allocation inside of the execution layer, right? Is there a zero allocation in the execution layer?
00:38:36.634 - 00:38:53.120, Speaker G: No, there would be an allocation in the execution layer. And there's a separate issue for tracking that. I'll just share a link to that as well. I'll share a link in the chat for that.
00:39:16.350 - 00:39:27.960, Speaker A: Any questions for Perry? Great. Any other Denav discussion points for today?
00:39:32.510 - 00:39:42.720, Speaker G: It would be awesome if client teams could, especially CL teams could dm me which branch I should use for tab net set and keep an eye out for info on that.
00:39:44.770 - 00:40:29.940, Speaker A: Okay, so there was a release. The release has four seven, eight eight, seventy, forty four, thirty, forty five built into the spec. At this point, Devnet seven is only four eight four four. Obviously the divergence here might cause some stickiness, but hopefully after Devnet seven, we can move towards full future testnets. If that's not the case, then we might have to revisit kind of what test vectors are released, what clients look like, and things like that. But at this point, I don't think there's much to revisit. We wanted to get the spec out there so development isn't blocked.
00:40:29.940 - 00:40:53.440, Speaker A: Hopefully it doesn't cause too much issue. Are there any questions or comments on the state of specs versus devnets right now? Okay, cool. Any other didnab related discussions?
00:41:01.060 - 00:41:18.630, Speaker E: I have a question. So spec one four zero includes this attestation subnet subscription stability subnet subscription model change. Do we have a rollout plan for that? Like when clients start using it? When clients start enforcing it.
00:41:19.800 - 00:42:02.990, Speaker A: Yeah. So it's a backwards compatible change right now because of the not any peer scoring, the intention is to turn on the enforcing of it at plus one hard fork. I believe I would have to circle back with age on whether he intended to change the spec such that it was at the NEB, but right now it can be rolled out in a backwards compatible way. I guess we should bring up the discussion as to whether that's the NEB or plus one hard fork for the enforceability.
00:42:07.290 - 00:42:17.000, Speaker E: And the other thing, the enforceability is nice, but obviously you can just not join the mesh. Did we ever solve that?
00:42:19.470 - 00:42:20.620, Speaker A: What do you mean?
00:42:25.550 - 00:42:43.070, Speaker E: Well, the enforcement says basically that if you're not subscribed to the right topic, you'll get a penalty, but you can subscribe to the topic and then leave the mesh so you still don't take the traffic hit, which is kind of equivalent.
00:42:46.230 - 00:42:54.862, Speaker A: By leave the mesh, meaning you don't have any peers even though you're averaging.
00:42:54.926 - 00:43:25.200, Speaker E: Exactly. Yeah, because you can't really detect that somebody else is on, has dprs in their mesh already and therefore is grafting you from the mesh when you try to. Sorry, pruning you from their mesh when you're trying to graft them. And the effect is kind of similar ish, actually.
00:43:30.690 - 00:43:32.640, Speaker A: It. Similar to what?
00:43:33.090 - 00:44:22.710, Speaker E: Similar to just not subscribing your node, which is what we're trying to sort of enforce here, that people subscribe to the subnet that they're supposed to be subscribing to. I mean, the implication that I was thinking about as well was for light clients right now, they're kind of uncharted territory whether they should be subscribing to the block topic or not. Probably not. Maybe. And they should be recping their blocks. Maybe. But there's no real policy for what happens when a light client connects to a node.
00:44:24.010 - 00:44:28.650, Speaker A: Yeah, right now in many ways you'd probably be downscored.
00:44:32.830 - 00:44:58.180, Speaker E: There's no explicit downscoring. Like there's nothing that says that you have to subscribe to a block topic, for example, you should, but only if you're synced, for example. So you can't really tell an unsynced node from a light client. And so on. So there are all these little gaps, let's say that one could think about if you wanted to.
00:45:06.180 - 00:45:31.340, Speaker A: Yeah, I'm not sure age is consideration on subscription versus participation and if there's any sort of. Intuitively you would probably not be able to actually know if somebody's forwarding messages along or participating at the level you expect them to. But maybe there's another consideration, Chad, that I'm not aware of.
00:45:44.470 - 00:45:48.550, Speaker E: But anyway, rollout is as clients want.
00:45:48.620 - 00:45:50.950, Speaker A: Or continuous at this point. Yes.
00:45:51.100 - 00:45:51.800, Speaker E: Yeah.
00:45:52.490 - 00:46:15.330, Speaker A: Cool. Other Dnab items? Any other items for today?
00:46:24.240 - 00:46:29.470, Speaker H: Yeah, could I chat a bit about the max effective balance stuff if now's a good time?
00:46:30.640 - 00:46:31.148, Speaker A: Cool.
00:46:31.234 - 00:47:12.312, Speaker H: Yeah, so I guess conversations have been continuing. Thanks very much to Dapline, Aditya, Mikhail and Francesco. We've all been kind of jamming on this together and it's been super helpful. So I wrote up a short one pager on kind of the status of these discussions. I also opened up kind of a very draft pr to the EIPs directory here. So yeah, I guess just kind of running down the biggest discussion points right now. I thought that might be useful.
00:47:12.312 - 00:48:16.588, Speaker H: So first is the idea of execution layer triggered partial withdrawals being a prereq for the max vector balance increase. I think this wasn't originally the consensus, but now it's kind of shaping up to be just in terms of ux being pretty unacceptable otherwise. The idea here being if a small validator opts into compounding, they basically will never see withdrawals ever until they fully exit their validator. Even if they stake from like thirty two eth up to forty eth, for example, over months or years. Then they need some way of withdrawing some of that without exiting their validator fully. So execution layer partials are kind of what we're saying is a prereq for the max effective balance increase. The question kind of then becomes do we do that in the same EIP as the max vector balance increase or do we bundle it into seven thousand and two? Seven thousand and two is an EIP from Danny about exits coming from the execution layer.
00:48:16.588 - 00:49:27.060, Speaker H: Here's the consensus spec PR and there's a link to the EIP PR in there too. So yeah, the decision around whether to include the partials withdrawals in there or in the Maxpect balance EIP I would say is kind of still up for debate, but I don't think it's too consequential. So yeah, the second thing I wanted to bring up is this idea of proposer equivocation issues. So basically slashing penalties are as written in the spec, are proportional to the effective balance of the validator. This has to be the case for attesting equivocations because that is actually like fork choice weight being thrown around if there's an equivocation there. But for proposal equivocations, we think the penalty doesn't necessarily need to be proportional to the full effective balance. And the reason being the proposal equivocation is kind of only proportional to one thirty two e validator kind of misbehaving because a larger validator doesn't have higher weight on a proposal than a thirty two e validator.
00:49:27.060 - 00:50:23.304, Speaker H: So yeah, there's a bit of discussion around how to handle that, but that's one thing that comes up. One reason that this would be desirable is just to help derisk consolidation. Like if big stakers consolidate and there still is such a huge slashing penalty for a double proposal, then even non malicious double proposals are really heavily penalized, which might not be ideal. Additionally, the third thing I wanted to bring up was the pros and cons of just removing the validator sweep altogether. This came up. I think Danny brought this up when discussing the fact that if we have execution layer triggered partials, then maybe we should just turn the sweep off altogether. This would make a lot of things easier from the implementation perspective, but it's also pretty invasive because then everyone who's used to these automatic withdrawals would have to set up some way to trigger them.
00:50:23.304 - 00:51:04.150, Speaker H: And it's just a bigger overall change to the network. So not sure if that's possible, but yeah, kind of continuing keeping that discussion alive just in case it is possible. Because then it makes a lot of things, it's almost intuitively like the right way to do it because then everyone's compounding automatically and they only withdraw as an opt in thing, and they withdraw however much they want to. And then the last thing is this ejection balance consideration. So this was brought up in the ETH research post, the proposal. Someone commented on what the ejection balance could look like. So right now the ejection balance is fixed to sixteen e.
00:51:04.150 - 00:52:34.370, Speaker H: So it's kind of like intuitively half of the max effective balance. And the question here is, if someone has a really large effective balance, like two thousand and forty eight e, is their ejection balance still sixteen e? Because then it would take basically forever for them to drain out through an activity leak or whatever. And the use case here for who we're trying to protect is people who might lose their keys, obviously, like a big staker losing their keys is pretty unlikely, but there was some back and forth on like, if we could say, make the ejection balance like three eth below their highest effective balance that they ever reached, then we could guarantee that even if you lost your keys and you're a huge staker, the most you're ever going to lose is three e and you just have to wait for the inactivity leak to bleed you down to there and then you'll get ejected. So, yeah, those are the things I wanted to bring up. Again, that doc that I linked initially has kind of some of these discussions and we'll be updating regularly as they evolve. But just to highlight execution layer partials, proposer equivocation penalties instead of slashing pros and cons of removing the validator sweep altogether, and considerations around the ejection balance. So yeah, happy to take questions and definitely to the other folks that have helped work on this, please chime in if I missed anything.
00:52:34.370 - 00:52:36.044, Speaker H: Yeah. Hey, potos.
00:52:36.092 - 00:52:36.880, Speaker A: Potos.
00:52:37.860 - 00:53:27.748, Speaker D: Yeah, just a quick comment on the sweep. Just two comments. One is that mixing this with the exits of PR of Danny, it's a bit of a thing, right? Because the exit ones, it's easy to implement, at least on the consensus side, and the withdrawals, if you don't take away the sweep, it's very hard to implement on the consensus side. And it's probably even hard to specify how it would work on the consensus side. And also, one would have to take care of making sure that everyone would be able to, if we remove the sweep, the current addresses that are being forwarding withdrawals now might not have access.
00:53:27.834 - 00:53:30.868, Speaker A: To trigger to make the call.
00:53:31.034 - 00:53:41.530, Speaker D: Right. So I don't think it's even possible to get out of the sweep, given the kind of commitment we made. So I would want to see research on this.
00:53:43.500 - 00:53:46.584, Speaker H: Yeah, that's a good point. Yeah.
00:53:46.622 - 00:54:15.110, Speaker A: In the past we were able to do, when we were trying to figure out if you could do push first pull withdrawals, there was an effort to go and look at, to do a scan of all the different execution layer contracts that were set for withdrawal credentials. There weren't that many at the time, so we were able to get kind of a complete view that has changed. So it might be interesting to do an analysis there again.
00:54:17.160 - 00:54:39.324, Speaker H: Yeah, I do think the sweep would probably be met with a lot like removing the sweep altogether would probably be pretty controversial. So we just were throwing it out there more as like a far fetched idea than necessarily like pushing for it. But it would be kind of if we were designing it from scratch. Now I think we would prefer to not have.
00:54:39.362 - 00:54:51.324, Speaker D: Definitely. But then if there's no sweep removal then I would propose that this is considered completely separate than dynasty. Seven thousand and two.
00:54:51.522 - 00:54:59.184, Speaker H: I see. So you're arguing that the partial withdrawals shouldn't necessarily come through the execution layer at all? Is that what you're.
00:54:59.222 - 00:55:12.550, Speaker D: Oh no, no, I'm hoping that they are. I think this is a very nice ux to have. It's just that mixing it with something that is very simple to implement as Danny's pr. I think it's just a way of delaying Danny's pr.
00:55:13.640 - 00:55:14.340, Speaker H: Sure.
00:55:14.490 - 00:55:14.756, Speaker A: Yeah.
00:55:14.778 - 00:55:25.732, Speaker H: I guess the only argument is if we do the partials in Danny's then the Max EBPR is very simple because then we don't have to do any of the UX considerations.
00:55:25.796 - 00:56:00.470, Speaker D: But yeah, I think then I'm only pointing this out, which is a tiny piece of the Max EB. It would be very nice to see and have a larger conversation about the security issues of it. And we've had these kind of changes to four choice and that we kind of rushed into them and then we found very deep security concerns. It would be nice to have a longer conversation on the maxib and how security is and these things that are probably out of scope of this call.
00:56:01.000 - 00:56:27.340, Speaker H: Yeah, for sure. I linked a doc called Maxeb increased security. This is something Francesco and I wrote. So that covers some of those things. But yeah, I agree, it's a bigger pr than the seven thousand and two for sure. And I guess maybe it makes sense to bundle the execution layer partials in with the maxi B then just because it's all like one atomic unit, which might be cleaner intuitively.
00:56:28.320 - 00:57:10.248, Speaker A: Yeah. One consideration for seven thousand and two is at least even if you're not doing things like removing the sweep or other stuff like that, do you add maybe a balance field where if it's max sent it's an exit, otherwise you can interpret it as something else, like a partial withdrawal. So that in the event that you do want to trigger information from more information from the execution layer, you have it there rather than having to go back and make a cross layer change at that point. Obviously we've shot ourselves in the foot prematurely optimizing like that before, but at least a consideration. Do you try to make seven thousand and two slightly more generic? Cool.
00:57:10.334 - 00:57:18.890, Speaker H: Yeah, I think big action item for me is to do due diligence on seven thousand and two. So that's something.
00:57:19.260 - 00:57:42.710, Speaker D: Just throwing this out as not depending on how much we're willing to wait. It's even possible to do this in stages. We could deprecate the sweep and allow validators to exit even if that might be impossible as well. But we could do this in stages on deprecating in one hard fork and then implementing without the sweep in the next one.
00:57:45.460 - 00:57:49.824, Speaker A: By deprecation you mean a signal, a commitment in the spectrum. Right?
00:57:49.862 - 00:58:01.160, Speaker D: A commitment that you need to exit your validators. And now that we are allowing them to exit this way or another way, by this many forks, we are going to remove the sweep.
00:58:04.480 - 00:58:10.940, Speaker A: Yeah, certainly an option. I think we're probably not quite there.
00:58:11.090 - 00:58:34.310, Speaker H: I mean, we could also do the other order which is like if we have maxi b and partials, then we signal removing the sweep after that. Right. Because now suddenly the sweep becomes less relevant. And if people want to exit, they can. I think that might be a more reasonable track. But yeah, either seem good.
00:58:34.760 - 00:58:54.940, Speaker A: Regardless of deprecation. Notice a validator presumably can exit. So they would always be able to exit even if they instantly. If they can't, then that's a problem. Yeah. And there are validators that can't exit. There are people that have lost.
00:58:56.240 - 00:58:59.150, Speaker H: Yeah, that's the ejection balance stuff too, right?
00:58:59.520 - 00:59:21.270, Speaker A: Yeah. So they're just waiting for sixteen e one day. Okay, cool. So this is pr print EIP. I think the design doc is where a lot of the considerations might go if you're interested in following this design path. Do you have any other questions for Mike today?
00:59:31.780 - 00:59:32.240, Speaker B: Cool.
00:59:32.310 - 00:59:52.880, Speaker A: Thanks, Mike. I'm going to get seven thousand and two merged and it's something I would like to discuss in the coming weeks, coming months, just as another potential feature, but not for Jeanette. We'll probably do a process. Is it merged?
00:59:54.980 - 00:59:57.120, Speaker B: Yeah, the EIP is merged.
00:59:57.780 - 01:00:01.090, Speaker A: Wow. I didn't even know.
01:00:02.900 - 01:00:04.320, Speaker B: Happened recently.
01:00:06.820 - 01:00:26.264, Speaker A: The editors are EIP bots. Yeah. Okay, cool. I'm going to do a pass on that. But anyway, check out seven thousand and two. I think it's a nice to have feature in the coming forks for the theoretical fork. After Daneb, that will be a star name.
01:00:26.264 - 01:00:39.470, Speaker A: Starting with e, we will create a tracking issue and people can toss potential stuff into it. I think we're probably a little bit early, but the beginnings of that conversation probably start today.
01:00:45.490 - 01:00:46.394, Speaker B: Too soon?
01:00:46.532 - 01:00:47.780, Speaker A: Almost too soon.
01:00:50.790 - 01:01:22.540, Speaker B: One quick thing with seven thousand and two, I think there is a bit of a space to pass the balance in to pack the balance as a part of other pub key. The second part, because it's forty eight bytes and we break this down into two pieces, but definitely would be cleaner to have a separate storage slot for the balance if you want that.
01:01:28.240 - 01:01:30.910, Speaker A: Sorry, what field were you going to pack it into?
01:01:32.000 - 01:02:00.900, Speaker B: There is the valid pub key which we store right in the storage when this pre compiler was being called. And the pub key is broken into parts first thirty two bytes and max sixteen bytes. So we have like sixteen bytes of space, which probably not enough considering that we use glaze. Okay, sorry. Yeah, sorry for derailing the main conversation.
01:02:04.680 - 01:02:15.160, Speaker A: You could pass it in as an argument, but it wouldn't then pass into the message, would it pass into the message because the message is actually packed. Forty eight bytes.
01:02:16.460 - 01:02:17.850, Speaker B: I don't know. Yeah.
01:02:18.300 - 01:03:00.160, Speaker A: All right, we can take a look at it. There's probably not a reason to shove stuff into the extra bytes of another field at this point if we want it. This design is pretty wide open so we can revisit that. Cool. Other discussion points for today. Yeah, potass. Just a quick comment on that.
01:03:00.160 - 01:03:16.198, Speaker A: In terms of the consensus layer, it can be a binary operation of the time, right? It can either be, if it's max sent, it's an exit, if not, it's a no op. So there are pretty simple ways to have that field available and really not change.
01:03:16.284 - 01:03:25.078, Speaker D: So you want just to have the field so that for future we just keep it as an O op, but then the field is there.
01:03:25.164 - 01:03:25.414, Speaker H: Yeah.
01:03:25.452 - 01:04:37.340, Speaker A: The argument there would be to reduce the changes you have to make on the execution layer, to make further changes on the consensus layer to have the data available. But we've done that many times and have weird fields sitting around that we never use like with surplus or index. So it's a possibility. I just want to bring up, I would not argue to do seven thousand and two and utilize that field in a meaningful way because that changes a lot of things. Right? Like all of a sudden partial withdrawals. Have to think about the queue in relation to the validators that churn and things like that, which is a much, much deeper consideration, as you noted. Okay, anything else for today, Tim? Was that a spicy enough blob, data size conversation for you? Yes, and you're finishing, right? As I'm done packing, so.
01:04:37.410 - 01:04:39.276, Speaker B: Couldn't have asked for a better call.
01:04:39.378 - 01:04:40.270, Speaker G: Thank you.
01:04:41.200 - 01:04:45.390, Speaker A: Have a great vacation. Okay, thank you everyone. Talk to you all soon.
01:04:46.080 - 01:04:46.844, Speaker D: Bye bye everyone.
01:04:46.882 - 01:04:47.790, Speaker B: Thanks all.

00:05:30.290 - 00:06:58.720, Speaker A: Welcome to Awkwardev's census layer call one two one. This is issue eight nine eight in the PM repo, a couple Zenav items which will probably have some things that ripple into how we discuss testnet plans and then an item around SSD spec from Yasik. Okay, if you haven't been following the repo or the discussion that's been a bit in discord. We've gone back and forth on the proper way to do lob sidecars, or at least ever since the split, there was an additional signature put on these sidecars by the proposer that serves as at least the reduction of the DOS condition of the DOS ability to essentially just the proposer. There's always kind of latent concerns around if this was sufficient, if we needed slashing conditions on this new message type, if this could increase the ability to do view splits and timing splits and short term forks and reorgs and Mev and all sorts of stuff. And the stream hasn't started. Ah, interesting.
00:06:58.720 - 00:07:13.500, Speaker A: I am streaming. Give me 1 second. Let's see if I can see if my stream key is off or something.
00:07:23.500 - 00:07:25.496, Speaker B: Are you not able to stream the call?
00:07:25.678 - 00:07:55.316, Speaker A: What? No, apparently my stream key is also being used on the testing call, so it went to the wrong call. Yeah. Dan Coon, interrupt testing is live. Okay, we'll rename that. Sorry everyone. Okay, back to the soliloquy on wildside cars. Hey man, I don't know.
00:07:55.316 - 00:08:52.516, Speaker A: That's my key. Someone reused my key. Okay, cool. So we went back and forth on this. This has also kind of created tough gossip conditions where you're trying to remember what you've seen, but also conditionally upon have you seen the block or not? When you're making the decisions on the Gota network. I believe that most of the issues that we've seen on the devnets in the past six to eight weeks have been in relation to complexities around handling these messages, when to invalidate them, how to invalidate them, what to premise those invalidations upon. So we're talking with some of the prison guys one night who were not pleased with the design and even tossing around, potentially recoupling.
00:08:52.516 - 00:09:55.160, Speaker A: And Francesco. I woke up to Francesco saying, well, why don't we just send around the block header and a Merkel proof? Which I think once that was said aloud, most people said, oh yeah, what's a better design? You don't need to open up the vc for an additional signature those messages. You cannot send redundant versions of those messages, duplicate versions of those messages with different blobs or commitments unless you're willing to get slashed, and you don't have this potential race condition where you might have the sidecar and not the block or at least the block header. So you don't really have the same type of conditional gossip conditions. So we have a pr up. I believe Ryan put it up 3531 that we've all been going back and forth on iterating on. I have asked for any nays in relation to this, and there's been a little bit of discussion, but it doesn't seem like any outright nays.
00:09:55.160 - 00:11:33.050, Speaker A: I believe this will largely be the removal of code from clients, and especially in what proved to be a pretty complex hotspot on getting right. Obviously there are implications here in terms of relationship to getting Daneb out in relationship to what Devnet 1112 look like and when they are, but it also, from my assessment, looks like a much it could actually be the same time to mainnet, because this is simpler to get right, and we're not going to have as bug ridden devnets. It's also almost certainly going to give us a safer main net because it's a simpler and more easy to get correct specification. So I guess first of all, I'd like to hear, are there anyone against moving this forward, getting this into the spec ASAP, likely doing a release in the next 24 hours and kind of recalibrating the software and devnets from there. And then assuming after we have that conversation we can get into the there's a couple of little final points in design that I'd like to just make sure we're on agreement. All right, but again, we've heard positive, generally from everyone. I'd like to hear if there's any negative, please voice now.
00:11:33.050 - 00:12:39.080, Speaker A: All right, cool. And there's a pull request up for the builder specs, and there's a pull request up for the beacon API. If that is in your domain of review, please take a look at those. Okay, I know there was in chatter in other places maybe worth having the conversation of. Why did it take this long to figure a better design out? And let's maybe have that conversation, but let's get through what we need to get through today. First, the simple answer is, well, we hadn't talked to Francesco, or Francesco hadn't truly parsed what we were doing and hadn't had the idea, but maybe there's a better answer than that. Okay, cool.
00:12:39.080 - 00:12:59.120, Speaker A: So there are a couple of pending items here, Mikhail. It looks like we're like deriving a depth parameter, but then not really using it, and we should probably simplify and remove that depth parameter. Did I get that right?
00:13:01.170 - 00:13:49.680, Speaker C: Yeah, I just think that if we don't use this constant, like in deriving the depth, then we probably don't need it, or if we have this parameter defined, so we should probably use it instead of computing the depth from g index. And I think that Selwe said that she's agree with that, so we can just make an adjustment. I think it's a small thing, really. It's kind of like more aesthetic side of things rather than. Yeah, and mainly to small discrepancies. So I would not like. We can fix it in a separate pr level.
00:13:50.530 - 00:14:41.362, Speaker A: Well, let's just fix it there, get it done. Potas, do you mean that even if the spec does not define the depth, you're not going to dynamically compute it regardless? But even in that case, do you think the spec should have that constant? Okay, I'm having trouble parsing. You don't allow me to unmute. This seems like a personal problem. Okay, cool. Regardless, I think that Shaoi agrees. Okay, cool.
00:14:41.362 - 00:15:03.820, Speaker A: I guess, regardless, we shouldn't have the constant that we're not being used. So let's go and clean it up one way or the other. Okay, Mikhail, was that your final lingering point, or is there anything else?
00:15:05.230 - 00:15:36.354, Speaker C: Yeah, there is a parameter that defines depth, and there is the constant that defines tree index. And this constant is just used for computing the depth. It's not actually not computing it, but just in the comment which explains how the depth was computed. So I think that this can be removed. I don't know. Yeah, because we're computing these g index during the runtime using the function. I know what clients will do, actually.
00:15:36.354 - 00:15:47.880, Speaker C: Probably they will, as Potter said, define this constant in the code anyway. Then it makes sense, probably, to leave it in this pack.
00:15:48.750 - 00:16:38.574, Speaker A: Okay, so this is kind of the secondary question is, should we dynamically compute the g index or should we define it up in the constants? Right, yeah, I'm. I guess all these questions are aesthetic questions. I don't feel very strongly. I think it's kind of nice to be able to talk about independently, but it matters too much, I guess. Let's both make sure we clean up both these in at least a consistent way. I see that you're unmuted. The only thing I can do to you is mute right now.
00:16:38.612 - 00:16:41.680, Speaker B: Oh, now I'm muted. Oh, thanks.
00:16:43.890 - 00:17:27.274, Speaker A: You got anything to say? Okay, these are both aesthetic cleanups. Let's just make sure that they were moderately consistent. Casey had one more. Well, first of all, Casey did point out that we must, and this is definitely an oversight, we must link the blob to the KDD commitment so that the blob inherits the consistency of the signature of the block header. So super good call on that. Otherwise anyone can mutate these messages on the PDP and they'd still be valid. So that's in there.
00:17:27.274 - 00:18:20.300, Speaker A: He did bring up one more discussion point on if you're doing a sidecar by range or sidecar by route check, that you should also verify this consistency, and that is accurate. I guess if you're putting things into your verification pipeline, you will do so. But an early kicking out of bad messages is probably a good call. On the by route requests you likely have the block. And so I wouldn't put like a must or even should on the calling of this Merkel proof because you can just look and see if it's correct. But nonetheless, I think we could add on both of them to do a consistency check. So I'll take a look at that right after this call.
00:18:24.430 - 00:18:34.718, Speaker C: One question here is, will clients use the block sidecars by route and by range? Like without a block? Without having a block? Is this supposed to.
00:18:34.804 - 00:19:11.450, Speaker D: Yeah, I think we do. So if we are kind of haven't seen anything. So we actually try to get blocks and blobs together and ask for everything, even without knowing the blocks. So we know that at some point the peer would only return the blobs that are in the block, but we don't know in advance the corresponding block.
00:19:13.230 - 00:19:33.780, Speaker A: Yeah, it's like you definitely can paralyze by range if you're syncing and then make sure that both streams kind of match up to each other. The other is, I guess these cases where you see a random route and maybe you're recovering the block, but you also might want to recover other messages in relation to it.
00:19:34.230 - 00:19:41.460, Speaker D: Yeah, it's definitely applied only to byroot. I think the by range should be different.
00:19:45.110 - 00:20:14.960, Speaker C: If these two RPC calls are used standalone to blocks, like not complementary to blocks, then it's probably worth verifying, validating the signature, because after this pr will have a block header in the blobsight card. So this request will return block headers as well. The proposer signature needs to be verified as well. It depends, of course, on the use case.
00:20:16.130 - 00:21:18.086, Speaker A: Yeah, well the kind of implicit is anytime you get one of these sidecars and you've either gotten another sidecar with the same header, or you've already gotten the block when it says verify the signature. You can also just know that you've verified the signature before it looks the same. But let me do a pass on both of those and just make sure that we're tightened up and consistent both in relation to discussing the proposal signature as well as the consistency of the commitments in relation to the blob. Yeah, I just want to clarify one thing. You can obviously verify that the commitments apply to the blob without checking the proof, but it's more that you would have a sidecar propagate one way but not the other. So it's more of like a network view split concern. I don't know how big of a concern that is.
00:21:18.086 - 00:21:54.530, Speaker A: That's why I brought it. See, I see. So you're saying the same message. If you're not actually verifying that Merkel proof, someone could be sending you like a totally different message because they could just have junk and that would have not propagated on the gossip, but would have propagated in the root. And then all of a sudden in relation to message ids and stuff, you have totally different messages coming in even though they're valid. Okay. Yeah, plug in the proof.
00:21:54.530 - 00:22:01.830, Speaker A: Yeah. It's probably worth making sure. That's just Terrence.
00:22:04.650 - 00:22:39.634, Speaker B: So currently there is sort of like a minor dog's concern with the blob sidecar. In the event that you don't see the parent block, your client may choose to insert that into a painting queue and process later when you get a parent block. So that part, if you compare the block versus the blobside card, the block actually does the signature check before you do the parent check versus the blobside card. You don't do that. You actually do the signature check after you do the parent check because of that.
00:22:39.672 - 00:22:39.874, Speaker A: Right.
00:22:39.912 - 00:22:56.646, Speaker B: It's actually fairly easy for someone to construct Bobcy Carl without value signature and just kind of dos the queue. If today client implements that queue. So that's something to watch for. I can leave a comment on the pr.
00:22:56.828 - 00:23:08.710, Speaker A: Okay. And this is if you're reading the conditions sequentially, you would prefer the parent signature, the signature to be before this conditional queue.
00:23:08.870 - 00:23:11.610, Speaker B: Yeah, just like how the block does it today.
00:23:11.760 - 00:23:15.260, Speaker A: Yeah. All right, cool. Yeah, if you can drop a comment there so we don't miss it.
00:23:17.570 - 00:23:29.394, Speaker E: That said, I don't think anybody implements those rules in that order because the order in the spec is odd with regards to cost.
00:23:29.592 - 00:23:46.390, Speaker A: We've talked about this before. Yeah. Certainly there's an attempt to get the easy checks that invalidate things in relation to others before you do hard work in the order, but obviously the real world assessment of that is probably different than a spec writers.
00:23:47.210 - 00:24:13.200, Speaker E: Yeah, and there's another. Well, it's not really a concern, but if you do ignores before reject, you might not descore a client on what would have been a reject if you first ignore it. There are like little differences like that depending on the order of things.
00:24:15.330 - 00:24:35.400, Speaker A: Nonetheless, I do agree. The attempt to, if someone can make you do like an asymmetric work, like filling up a queue, if there's a condition that would prevent you from doing so, having that before is probably a better way to write it.
00:24:38.330 - 00:24:42.950, Speaker E: The queue should be able to deal with it. Otherwise you haven't predicted your queue.
00:24:44.090 - 00:24:50.650, Speaker A: Yeah, fair. But do you want a proposer to be able to fill your queue or do you want anyone to be able to fill your queue?
00:24:52.830 - 00:24:54.570, Speaker E: Depends on the other costs.
00:25:05.320 - 00:25:42.536, Speaker A: All right, well, at least drop that comment in there, Terrence, so we can look at the configuration of that in relation to other things. I believe that we can get this merged in the next few hours, and I believe that we can get a release out tomorrow. Cool. All right, any other comments on this?
00:25:42.718 - 00:26:47.210, Speaker F: Can I ask one follow up question, since the relevant parties are here for the builder specs? So there is an open question, essentially, who computes these KCG inclusion proofs if you're going to a MeV relay? The way the PR works that I linked right now, it has the relay compute them independently with the proposer instead. Pretty easily the beacon node could pass them along in the API. Does anyone have any preference here or see one way being better than the other? So I think it comes down to, will the beacon node want to compute these proofs sort of optimistically, because it would essentially send them. Well, actually, no. So if you sign the block, that's kind of a done deal. So then the question is just, is it easy enough to make those and then send them along as well, and then the relay has left to do?
00:26:49.500 - 00:26:51.876, Speaker D: I would prefer that beacon node computes.
00:26:51.908 - 00:26:53.450, Speaker E: The proof and tenses along.
00:27:03.440 - 00:27:07.228, Speaker A: Okay, any other preference here?
00:27:07.394 - 00:27:11.020, Speaker F: Yeah, if anyone has any comments, just take them to the PR, I suppose.
00:27:12.160 - 00:27:28.672, Speaker A: I guess one thing is like the node is going to have that logic that the node can locally build. So leveraging the utilization of that logic from the node might make sense, right?
00:27:28.726 - 00:27:47.928, Speaker F: Like the relay will still verify these proofs, but it's like one less thing. They have to compute and keep track of and maintain and debug and all of this. I mean, originally I made the pr with it where they're done independently just because it couples them less. But it feels like it's better to.
00:27:47.934 - 00:27:56.578, Speaker A: Step the beacon node to it. What's the structure? Passing those between the beacon node and.
00:27:56.584 - 00:28:01.970, Speaker F: The relay, they would just be stapled onto the sign line of beacon block.
00:28:03.110 - 00:28:13.110, Speaker A: Okay. Just in some ad hoc, the ad hoc data structure, they're not actually trying to compute, utilize the network data structures.
00:28:14.250 - 00:28:15.880, Speaker F: I don't see a reason to.
00:28:21.920 - 00:28:53.110, Speaker A: Actually maybe feel a little bit differently about how than I just said, but it seems weird to pass like a small portion of what's going to end up being a message that the relay is going to have to verify and package into a larger message anyway, when the relay has everything to just create the whole message, the message being the sidecar. But I don't know.
00:28:55.100 - 00:29:03.470, Speaker F: Yeah, I mean, the thinking is just give relays one less thing to do because the beacon node already have this code. It'll be tested, debugged, all that.
00:29:12.690 - 00:29:13.006, Speaker G: Could.
00:29:13.028 - 00:30:13.992, Speaker A: Just go to bed. All right, any other comments on this one? Very cool. Anything else on this spec change and or things in relation to the spec change? All right, there's a long standing pr in which at least a couple of clients have implemented on main net. This is 30 34 allow honest validators to reorglate blocks. This has come up on discussion quite a many times. It seems that the clients that haven't implemented have not because they want to see it in the spec. And there's been a push to clean up tests and other things in relation to it.
00:30:13.992 - 00:30:50.950, Speaker A: And so the question. I also believe that on this call we've done a signal of like, yes, merge. I'm doing that one more time because it has been cleaned up and is in a ready to merge state. Is anyone on a no merge relationship to this pr sprout could not be here, but also signaled as the author that he is ready and comfortable for the speed merge.
00:30:55.500 - 00:31:15.676, Speaker G: I think I can push the minor constant change right now so we don't have to open another pr. So just wait a couple of minutes to make the CI test, which I'm.
00:31:15.708 - 00:31:19.152, Speaker A: Talking about the honest reorb pr now.
00:31:19.206 - 00:31:34.710, Speaker G: Oh, sorry. Okay, got you that one. And honest Reorg PI looks finished. Point to me.
00:31:41.100 - 00:33:20.804, Speaker A: Cool. And this is written as an optional thing, so it can also be a no op. It doesn't have to be work. Okay. We can at least give some room for discussion on denav testnets. Devnets. I've seen casual estimates of, call it three weeks to rework what's going on in the network layer in relation to the specs simplification is that approximately the signal here that approximately what? People think that we could maybe target a devnet in a few weeks, but that we should probably just weekly be assessing Perry.
00:33:20.804 - 00:33:59.500, Speaker A: I'm not certain if that includes Devconnect week or excluding. I'd say regardless that we are going to be looking at revised estimates for that on the next couple of calls. Okay, cool. Any other discussion points around Deneb, around devnets, around testing, around anything before we move on?
00:34:03.250 - 00:34:26.140, Speaker H: Yeah, I just want think we have Devnet eleven up. It's going to be around probably till we launch a new one with the proposed changes. But if anyone wants to target something we're testing, please target Devnet eleven and curly shadow fork zero should go live tomorrow. So we'll also have some statistics on how long it takes to compute blocks and so on.
00:34:30.470 - 00:35:02.810, Speaker A: Great. Okay. Yasi, do you have a proposal up from September around byte type and canonical json mapping within SSD? This is PR 3506 in the consensus specs repo. Do you want to give us the high level?
00:35:05.900 - 00:35:19.420, Speaker E: Sure. So this is kind of an old pr dates back, I don't know, maybe even around Mainnet. I think starting from the beginning.
00:35:21.520 - 00:35:21.836, Speaker A: When.
00:35:21.858 - 00:35:58.920, Speaker E: We were developing SSD, it was kind of useful that we had json so that humans could read it for SSZ. And then out of that we kind of built tests that were using JSOn to verify that our SSZ libraries were correct. And we're kind of past that stage now. But I thought it was useful to maintain this one to one mapping between JSON and SSZ. Regardless. Many binary protocols do. Protobuff, for example, has economical mapping.
00:35:58.920 - 00:36:49.450, Speaker E: It's just convenient to document how we do it in the tests. So that's basically what that PR does. It documents how we encode SSZ when we want to present it to predominantly humans in JSON, in Yaml, and so on. Initially the PR assumed that everybody thought that eight bit integers and bytes are the same. But then there were many Java developers and JSON developers upset about that. They really think that bytes are different from eight bit integers. So the new version of the PR doesn't change any of that.
00:36:49.450 - 00:37:48.140, Speaker E: It also doesn't change the one place where we actually use an eight bit number, the participation flags of the debug state API, which is mostly unused. There we have a flags field. I'd say that's a byte, but for historical reasons that's an integer. So the latest revision of the PR, it really only documents our existing practice. It kind of takes all the SSD types that we have, it gives them the corresponding JSON encoding. And if somebody like the Beacon API spec wants to base their work off that, we can drastically simplify the beacon API spec. Because right now what the beacon API spec does is that it declares kind of a myriad of little types for every field.
00:37:48.140 - 00:38:52.370, Speaker E: Every field has its own encoding, and that's just a mess, this one. And that's because the beacon API spec is written such that it depends on the specific object types that we declare later on. Whereas if we have this canonical mapping, if you're writing a JSON library on top of your SSD library, you don't have to consider specific types anymore. You can just rely on these core SSD types to fully define how to encode JSOn. So I think, not that I necessarily agree, but I've removed all points that anybody could disagree with so far that people have disagreed with from the pr. And I think in that version it should be kind of a no brainer to just put it into the spec. And then whatever discussions we want to have over beers on the relative importance of the byte, we can leave them for later.
00:38:52.370 - 00:38:53.810, Speaker E: That's it.
00:39:02.840 - 00:39:45.490, Speaker A: Any questions for Yasuk? Any opposition? All right, I'm going to ping discord about this and try to get any final comments, and then we can get a merch. Thanks, Jesse.
00:39:48.240 - 00:39:52.030, Speaker E: Lovely to get this off my list, I hope.
00:40:00.000 - 00:40:21.980, Speaker A: Cool. Yeah. When I said it's September, I didn't look at the reference PR, that was from 2022, the original. Let's help Yasik with his list. Step one, little indian. Step two, JSon mapping.
00:40:26.700 - 00:40:31.400, Speaker E: At this pace, I'm going to have to find a new hill to defend.
00:40:34.060 - 00:41:21.980, Speaker A: I'm sure we can find something for you. Okay, that is all we have on the agenda for today. Any other discussion points before we close? Okay, thank you very much. We will work on getting a release out, absolutely. As soon as possible, getting these final little points in. And thank you, everyone. Take care.
00:41:21.980 - 00:41:26.410, Speaker A: Thank you. Thank you. Bye.
00:41:26.830 - 00:41:30.490, Speaker G: Thank you. Recordings.

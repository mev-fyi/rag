00:01:13.110 - 00:01:53.008, Speaker A: Okay, we are live. Welcome everyone, to acde number 195. I'll put the agenda in the chat here. There's a bunch of stuff to go over today. Updates on the devnets, lots of specific updates or proposed changes for 7702. One sort of issue that was brought up around EOF, around the xcode size and delegate call, and then getting some updates on the devnets there. And then lastly, there were two more proposals for changes related to the stuff that's already in Pectra.
00:01:53.008 - 00:02:37.960, Speaker A: So one for EIp 7251 and then one for the engine API. Assuming we get through all this, then there's three proposals that we have on the agenda. The first is 7623, which we CFI for Pektra, already increasing the call data cost in certain cases. Second is 7742, which is about having the block count only set on the Cl side. We discussed this last week on the CL call. And then lastly, there's a pre idea around raising the reserve price for blobs. So hopefully we have the time to get through all of this.
00:02:37.960 - 00:02:49.100, Speaker A: Maybe to kick us off. Barnabas or Perry. Do either of you want to give us an update on the current state of Devnet two and what the plans are for Devnet three?
00:02:51.240 - 00:03:42.960, Speaker B: Yeah, so the current state of Devnet tool is pretty much still on the interrupt channel. We haven't been able to recover the network. There was a gets bug last week that's since been patched, but that's led to at least one or two other ones. One in prism and the other one in tecu. If someone from the team is there, maybe they can briefly go through what the bugs are or if are they still active on that? I think they're still at least the Prism one. Radek has said he was able to narrow it down, but I think the tech one might still be actively under triage it. Yeah, either ways, we haven't been able to get the network back up and running, but at this stage, I think we're going to just leave it at this level and figure out what the bugs are.
00:03:42.960 - 00:04:01.920, Speaker B: We're waiting on client teams to pass all the tests before we can launch the next network. So Devnet three, and there was a spec test release yesterday by Mario, and I think if Mario said, maybe you can just quickly speak about the spec test.
00:04:03.340 - 00:04:20.358, Speaker C: Yeah, of course, there's not much to talk about. There's a couple of interesting test cases there, which I think should be clarifications in the Eipdeh. I will try to. If no one else is working on it, I will try to make pr to the EIP to make these clarifications.
00:04:20.414 - 00:04:22.270, Speaker A: But other than that, I think it's.
00:04:22.350 - 00:04:41.024, Speaker C: Just 7702 focused released. Yeah, I think the RJS is passing because we filled the test with them. Ret yesterday, sent a message that they were passing on our EVM, but they have to port it to retheme. The rest of the teams I think.
00:04:41.072 - 00:04:42.240, Speaker A: Are working on it.
00:04:42.400 - 00:04:43.936, Speaker D: But yeah, if you guys have any.
00:04:43.968 - 00:04:46.140, Speaker C: Updates, it would be nice to know.
00:04:47.960 - 00:05:01.096, Speaker B: Yeah, I think Oliver mentioned that they've done it and they have a branch ready for us to use. So yeah, we're mainly just waiting on client teams to pass suspect us and then once they're ready, we're ready to launch the network. That's the current status.
00:05:01.208 - 00:05:09.290, Speaker A: Got it. Yeah, we won't relaunch Devnet two. Basically we'll just move on to Devnet three once we have confidence that the new test suites are all passing.
00:05:09.790 - 00:05:18.014, Speaker B: Exactly. Because most of the issues that were triggered in Devnet two were 7702 related, so there was no real reason to fix it.
00:05:18.182 - 00:05:29.850, Speaker A: Got it. And then in terms of the spec changes for Devnet three, I saw there's a doc, but are there any other notable additions?
00:05:31.270 - 00:06:00.870, Speaker B: I think the only big change is 7702. And on the CL side we've done a few changes with the consolidation bug, et cetera, but as far as the CL side is concerned, I think those changes were decided weeks ago and nothing has changed there. And for the El side, we switched to pinning to a specific spec test release version. I will just update that right now to whatever Mario released last night. But essentially if you're passing spec test, you're probably okay.
00:06:01.730 - 00:07:12.186, Speaker A: Awesome. Anyone else have updates or questions concerns about Devnet two or the path towards Devnet three? No. 7212 is not considered for Devnet three. And then I assume once we get all the teams passing the spec test, we'll launch the Devnet hopefully in the next week or so. Is that realistic? Is there any team that thinks that, you know, say, by next Thursday they couldn't have, they could not be ready to launch medfree? Okay, sweet. Well, yes, let's continue chatting about this as we fix the bugs on discord, but thanks a lot, Perry, and thanks everyone for the work on all the implementations. Okay, next up, 7702.
00:07:12.186 - 00:07:36.170, Speaker A: So we have three open prs on it that I want to make sure we discuss and then potentially make a call on, including in Devnet three if we decide to. The first is around the behavior of self destruct in 7702 by sudeep. I think I saw you on the call. Yeah. You want to give some context on your pr?
00:07:38.270 - 00:07:42.150, Speaker C: Yeah, that's just a clarification being included in the IP.
00:07:42.230 - 00:07:43.886, Speaker A: I think the execution spec test is.
00:07:43.918 - 00:07:59.940, Speaker C: Already following that behavior where we restrict the self destruct of eoas. So just a clarification being added, and I think there's a general acceptance to it. So. Yeah, it's just an FYI being.
00:08:01.120 - 00:08:09.496, Speaker A: Okay, so the execution test that Mario just shared, like, the last version, which is already in Devnet three, followed this behavior, correct? Yeah.
00:08:09.608 - 00:08:10.112, Speaker E: Yeah.
00:08:10.216 - 00:08:46.970, Speaker A: Okay, cool. Any questions, comments on this? And then. Yeah, maybe we should just have it in the list for clarity. So I don't think. Yeah, I don't think it's part of the Devnet three spec, so I would maybe just add this one as well to make it clear, especially if it's already in the test. Okay, the next up, Ethan had two prs. He's unfortunately not on the call.
00:08:46.970 - 00:09:33.738, Speaker A: I'll go with the first one, which was about changing the signature domain for 7702. So using zero x one a instead of zero x zero five, basically, in his post, he explains that this would allow future transaction types to use zero x zero five. And then if we ever get past zero x 18, we already have some issues because zero X 19 is already allocated. I don't know if anyone's reviewed this or has strong opinions. Light client commented that he was, you know, indifferent. But. But, yeah, generally in favor.
00:09:33.738 - 00:09:58.540, Speaker A: But. Anyone else. Anyone else have thoughts on this? I guess if we did do this, do we want to do this for Devnet three? Because it's like a pretty small change, but I assume it affects a lot of different parts of the code base.
00:09:59.160 - 00:09:59.664, Speaker E: Okay.
00:09:59.712 - 00:10:03.060, Speaker A: Yeah. And there's one comment about waiting, Daniel.
00:10:04.760 - 00:10:27.772, Speaker C: Yeah, exactly. I wanted to say the same. So, I mean, the change in the code base, I assume, for everybody, is very small because it's just changing a constant. But we have to change all the spec test afterwards because when we. Because all the signatures are changing. So I don't know how much work this would be. Yeah, it shouldn't be that.
00:10:27.836 - 00:10:28.396, Speaker A: That hard.
00:10:28.468 - 00:10:35.680, Speaker C: They are. They should be dynamically updated once we update that. This one constant, it should be one line.
00:10:35.980 - 00:10:36.840, Speaker F: Okay.
00:10:38.420 - 00:10:43.720, Speaker C: But yes, the filling process, it takes an hour. That will be the longest wait, I think.
00:10:47.150 - 00:11:18.440, Speaker A: So. Would people. Yeah, would people agree that we should do this change, but then maybe just plan it for Devnet four or something? Is that reasonable? Okay. And then, like, science says, he'd want to look a little bit more into the prefixes and. But then assume, generally assumes it's okay. So. Okay, then in that case, yeah, let's not do it for Devnet three.
00:11:18.440 - 00:12:02.610, Speaker A: Let's just leave the PR open a bit more for people to review in the next week or two. And then when we're scoping Devnet four, we can, yeah, we can formally add this in and if there's any concerns and people can just debate this on the PR. Any other comments or thoughts on this? Okay, and then last, 7702 pr. This one was by Dragon, which wanted to restrict the chain id to either valid existing chain ids or zero. I don't know. Giorgano, you're on the call.
00:12:03.880 - 00:12:39.690, Speaker C: Yeah, in general, we are still having that. Currently we are having that check inside EVM. I want to move that check outside EVM and for it to be validation of transaction validity. We already have some checks on the signature, and this will be one additional check on training id. It will make any authorization list that has authorization with chain id that's different from the current chain id or zero be invalid.
00:12:44.550 - 00:13:04.100, Speaker A: Any. I guess, yeah. Any concerns or objections with the general proposal? If not, I guess one question I have is, are there some cases where like testing this could be more complicated? I assume not, but yeah.
00:13:06.240 - 00:13:09.960, Speaker C: There will be need for some tests just to cover this case.
00:13:10.040 - 00:13:10.344, Speaker A: Yeah.
00:13:10.392 - 00:13:37.050, Speaker C: And that's why I would like to do it after definite three. Yeah, but this is very localized and small change. To be honest. There are some tests, I think the Mario is maybe better to say this, but there's some tests that covering different chain ids inside the authorization list. Those needs to be changed and my one or two tests needs to be added. Check this case.
00:13:41.390 - 00:13:42.150, Speaker A: Yeah, I agree.
00:13:42.230 - 00:13:47.086, Speaker C: While it seems easy enough to test, I wouldn't include this in devtree because.
00:13:47.118 - 00:13:48.774, Speaker D: Yeah, it needs additional testing.
00:13:48.902 - 00:13:56.648, Speaker C: Should be small enough though. Okay.
00:13:56.664 - 00:14:48.220, Speaker A: And then there's a comment by client saying that we shouldn't make the validity of the transaction dependent on the validity of the authorization list. But I guess maybe there one question I have is that. Yeah, like previously we just cared that this was like a 256 bit integer. What? Like. Yeah, I guess we. Yeah, we already have some restrictions on this, so I don't know if you have access to Mike, but it might be good to just expand that a bit. Yeah, I mean, I think in general, constraining the inputs based on a data.
00:14:48.260 - 00:15:03.484, Speaker E: Type integer is different than constraining the input based on chain data, fork configuration data. So I don't feel like we should be combining the fork data into this.
00:15:03.532 - 00:15:12.730, Speaker A: Kind of like serialization. Logic of the autholes. Got it.
00:15:16.190 - 00:15:42.090, Speaker F: Yeah. There's a difference between stuff that things that are invalid because they can't be deserialized and things that could be deserial authorizations that could be deserialized but then aren't valid as authorizations. And if someone on Ethereum gives you an authorization with chain id free, like you could deserialize it, but it's not a valid authorization, though it doesn't authorize anything.
00:15:44.470 - 00:16:03.700, Speaker C: This is very similar what we are doing with transaction signatures. Basically, we make it invalid if s is more than half of the field and if the v is not in correct format. So it's not a lot different from having those checks.
00:16:04.000 - 00:16:36.070, Speaker A: Right, but those, those checks are again based on like, I don't know, data types or like, you know, data like constraints less than like domain types, is that correct? Like I assume the signature data is like formatted the same across all the chains. And we want to check that it's like a valid format, but that's different than checking that. Like it's a valid signature on this, on this chain. You know, for example.
00:16:38.090 - 00:17:25.029, Speaker C: Authorization list enables us to have those checks at EVM for the signature on the transaction level. That was not the case. That's why it's optionally we have option to make it, to make those check inside EVM. But the, what I'm arguing is we shouldn't do that. We should do it when we are decentralizing the LLP and making those checks before we invalid data inside authorization list. Not just invalid, but data that we can check easily that we know that are not going to pass.
00:17:31.569 - 00:18:07.310, Speaker A: I guess. Does anyone else have strong opinions on this? And. Sorry. And then you have a chat comment saying that otherwise there's like, if we do this change, there's a potential doS vector where we have n transactions using the same authorization, which can be invalidated in zero one. You have the honor. Maybe expand on what you see as the issue here.
00:18:12.650 - 00:19:10.120, Speaker G: Yeah, I was just, yeah, I just acknowledged what a light client wrote about not making the validity of the transaction, dependence on the validity of the authorizations, because as long as the EOA that sends the transaction can pay for it, the transaction is valid, it should be included even if the authorizations themselves are invalid, because otherwise it's, otherwise you could invalidate, you could have a DoS vector where you send a large number of transactions, all of them using a certain authorization, and then you can invalidate the authorization with a single transaction and cause many transactions to become invalid after propagated. So the validity of the transaction should only depend on the sending EOA nor the authorizations. It's okay for authorizations to fail. The transaction is still valid. I think that's what meant. Right.
00:19:10.900 - 00:19:34.220, Speaker C: Just want to address Dido's claim. I don't think that's valid because even when you receive the section, you still need to do recovery of it, to check the later section work, to check recovery, to do recovery and check those basically is a lot bigger than just iterating on authorizations, authorization list.
00:19:35.640 - 00:19:58.210, Speaker G: I mean, the authorization can become invalid because it is nonce dependent. Right. So if you send a thousand transactions and all of them have the same authorization, and after the nonce gets incremented, all of the transactions except one become invalid. That's what I meant about.
00:19:59.710 - 00:20:12.120, Speaker C: That's true. But we are talking about now only for chain id, not about nonce and not about if the signature is valid or not valid. You're talking about validity of chain id.
00:20:12.580 - 00:20:36.160, Speaker G: Yeah, that's fine. About chain id. That's fine. I meant the validity. I thought that what lifelines meant was about the validity in general. And I think that the validity should not depend, the validity should not depend on the validity of authorizations. It's okay to just, these authorizations just won't work, but the transaction will still go through.
00:20:36.160 - 00:20:38.040, Speaker G: Doesn't that make sense?
00:20:39.100 - 00:20:46.200, Speaker C: It does, but this is not something that we are discussing now. Yeah, we are talking about just tracking chain id.
00:20:47.420 - 00:20:47.868, Speaker G: Yes.
00:20:47.924 - 00:20:48.640, Speaker C: Okay.
00:20:49.780 - 00:21:01.120, Speaker A: Right. And so, okay, just to be clear, like, yes, this would not, oh, sorry, please go ahead. We can't hear you really well.
00:21:14.470 - 00:21:15.250, Speaker H: Sorry.
00:21:15.630 - 00:21:17.214, Speaker E: I don't understand what the difference is.
00:21:17.262 - 00:21:18.438, Speaker A: I thought that we were talking about.
00:21:18.454 - 00:21:20.210, Speaker E: The validity of the transaction.
00:21:23.590 - 00:22:26.460, Speaker F: As I understand it. So what we're talking about here is when should the ch, so we check the chip at some point we have to check the chain id of the authorization is valid. That is, it's either the current chain id or it's zero. So it's valid on a chain. The question is, should that check happen before accepting the transaction? So if the authorization, if the chain, it is invalid, the entire transaction is not includeable? Or should it happen after the transaction is accepted. So the transaction is included in the chain and I assume then immediately fails because the authorization is invalid. My kind of feeling on this is it probably doesn't matter because like transactions that include, you know, if you have a transaction for chain a that includes an authorization for chain b, that transaction is like malformed under some trivial static check that doesn't require you to know anything.
00:22:26.460 - 00:23:27.642, Speaker F: It's obviously wrong. So anyone who signed such a transaction has already screwed up really badly, and I'm expecting that it will be basically impossible to create these sorts of transactions using any sort of standard toiling. It's not a mistake that people are going to make in reality. But on the other hand, the check is so trivially cheap that if we say reject the entire transaction, if the authorization is invalid and makes sense, the only concern I would have which would lead me against this is that currently all of the checks you have to do to make sure that the authorization is valid are completely chain agnostic. Like either the RLP bytes you get given are an encoding of an authorization object or they're not encoding of an authorization object. And the only check you have to do is you decode it with the RLP. And if your RLP decoder throws you in error, then it's invalid.
00:23:27.642 - 00:24:00.240, Speaker F: Whereas what this does is it makes the validity of the authorization. Yes, I did get married makes the authorization invalid. Validity as a decoding exercise depend on what the chain id is of the current chain. And that just seems like adding a little bit of complexity, whereas we're going to check the entire authorization anyway in a minute after we've accepted the transaction.
00:24:01.140 - 00:24:35.648, Speaker A: Okay. I think, yeah, clearly there's probably a bit more thinking to be done here. And because this is not going to be added to Devnet three, it's probably fine to move this conversation async. So there's the pr there. And I think in the next, yeah, in the next acde we can just, if it's not merged or closed by then, follow up on it. But yeah, we do have other stuff on the agenda, so unless there's any like pressing comments or thoughts on this, I think we should probably just move on. Okay.
00:24:35.648 - 00:25:15.970, Speaker A: Yeah, and thanks for bringing this up, Jorgama. Okay, anything else on 7702 before we move on from daddy Ip, if not EOF? So I forget. Frangio Giordano, I hope. Francisco Giordano, I hope I said your name right. Put together this doc with some concerns about EOF and especially how it behaves with regards to token transfers for NFTs. Do you want to take a minute to maybe walk through your doc and what the concerns are? I know it's been discussed a bit on the discord in the past couple of days as well.
00:25:18.150 - 00:26:16.540, Speaker E: Yeah, sure. So first, as a preface, I'm very excited about Eos improvements to static analysis and cogeneration. So I feel like that's important context. I think these are just improvements to make. So I do have these concerns that come from the application layer. So ERC 721 and ERC 1155 are the two major NFT standards, and essentially they need an is contract operation because of some behavior that they have on transfers. So when a token is transferred to an account, if the receiver is a contract, it has to sort of explicitly declare that it supports receiving this token by implementing a callback, and the token contract will invoke this callback and expect some special value in return.
00:26:16.540 - 00:27:11.030, Speaker E: This is only done for contracts, so the receiver does not have any code. It's assumed to be any OA, and the token is just transferred without calling any callbacks. So the purpose of this check is to prevent the loss of tokens which are transferred to contracts that can't handle them. This is an error that happens a lot, and so it's kind of debatable. Does it belong in the EVM or not? But the fact is these two ERcs which are final already specified, they require this operation. So what that means is that in eofem which does not have ext code size or ext code hash, it is not possible to implement this. So the current proposal is to work around that by dispatching to a legacy contract as a sort of escape hatch to get ext code size.
00:27:11.030 - 00:28:28.290, Speaker E: This is possible, this works, but it is a bit of a hurdle for library authors, because now they have to hard code this address or in the code that they ship to users. We as an ecosystem have to make sure that those addresses are widely deployed and available everywhere, which in its own is its own issue because there's no 100% reliable way to get deterministic addresses across all chains. And then there's also the problem of development chains on users local computers, which also have to have that. Anyway, it's a big issue. So in my opinion, this needs to be addressed just in EOF, the fact that it can be worked around in this way so easily, and also the fact that these two main standards require that. So it is going to be used widely. This sort of escape hatch mechanism to me just says, well, why don't we just enable these opcodes ext code size and or ext code hash in EOS and just fix that so that all of this workaround is not required.
00:28:28.290 - 00:29:35.670, Speaker E: This is one issue. The other issue that I describe in the notes here is regarding delegate call. There's currently a limitation to so EOF contracts cannot delegate call into legacy contracts. And this, in my opinion quite realistically caused some bricked contract bricking situations that could become sort of like a new parody wallet situation where a proxy that is working perfectly is accidentally upgraded from an EOF contract to a legacy contract, and then it becomes unusable, completely frozen, and it will require some sort of well, or no recovery at all would be possible. So it's not really clear why this limitation is in place. I think it's about just avoiding things that any of contracts that are not supposed to happen there. For example, anything related to self destruct.
00:29:35.670 - 00:30:46.726, Speaker E: Recently there was a proposal for 7702 to sort of change the behavior of self destruct in that context, that there's no discussion to apply it in EOF as well, and to just sort of lift this restriction and just allow delegate calling into legacy contracts. And that would prevent this situation. But this is sort of related to the previous issue, because if we had ext code hash, we could implement a at least a check to prevent the situation in the code itself, to see if the target that we would be delegate calling into is EOF or not. By using ext code hashes behaviors, it just allows you to detect that. So these are the two issues that are sort of related to ext code size and hash. And delegate call has its own discussion, and we've been talking about this in the EOF implementers call, but so far no change has been made and we're sort of heading towards the status quo. And I think it would be better to make a deliberate decision with convincing arguments as to why choose one thing or the other.
00:30:46.726 - 00:30:48.850, Speaker E: I'm happy to hear any opinions.
00:30:50.790 - 00:30:53.130, Speaker A: Thanks for sharing, Daniel.
00:30:54.830 - 00:31:49.560, Speaker H: So one of the we've got a couple of constraints we've been working with, with EOF to get it to ship. One of them is there was feedback given from multiple people in ACD that we should strip out absolutely everything that is not absolutely necessary to ship it, and we come back in future releases and add those features in. So any feature that didn't involve breaking something that could be added additively in the future hard fork is something we made a conscious decision not to put in to reduce the scope and the testing impact of EOF. This is one of them. How to detect a contract. We can add that with a is contractor unlocking the old opcodes in a future fork. There's also a couple of other features, TXcreate, which allows us to create transactions from, to create new EOF objects arbitrarily from transactions, was also removed, as well as consideration for Ext data copy, which allows us to copy data from other EOF contracts.
00:31:49.560 - 00:32:40.464, Speaker H: Those were pulled because those can easily be added in the in future in the next hard fork we can add those opcodes in without breaking EOF, without invalidating any other contracts. So that's been our guiding northstar for at least EOFV one to see what goes in and what goes out. And while this issue with building 721 or 1155 contract in EoF, it does kind of prevent it right now from following the specs. It doesn't break anything outside of EOf. You can continue to write these contracts in legacy and we can add these opcodes in the next hard fork and then you can start writing them in EOF. So that's kind of been our philosophy of why we chose the status quo. But if we get feedback from ACD that this is important to fix now we'll work hard on the consensus as the UF component is called to get it into this release.
00:32:40.464 - 00:32:45.660, Speaker H: But my overriding concern is ACDs are really concerned about the size of this release as it is.
00:32:53.810 - 00:33:21.350, Speaker A: And I guess maybe in that case, assuming we did add those more features like in a future version, if something did get bricked through some weird update like we were just talking about, is that something where then exposing that functionality in EOF allows you to make the same calls you made in legacy VM and therefore sort of unbreak the contract.
00:33:22.690 - 00:34:01.920, Speaker H: So that's the case with the delegate call limitation. We originally put that in. Mostly it was around self destruct, but in generally it's around any feature in any operation we banned inside of EOF. Self destruct is the most easy one to demonstrate, but when it comes to the other opcodes that we're banning inside EOF, as Svengio pointed out, you can just do a regular non delegate call to get ext code copy and pass it in as return data. So a lot of those have non delegate call solutions. I think only self destruct and side effects are what is impacted by it. And we didn't want to propose changes to self destruct, but with 7702 that cuts out of the bag.
00:34:01.920 - 00:34:25.650, Speaker H: And you can write your proxy contract to do the EOF detection via those jumper calls if you feel it's important to have your proxy in EOF. But I think until we get these features you shouldn't write a proxy in EOF. Those will come down the line and we'll get those addressed.
00:34:31.400 - 00:34:32.780, Speaker A: Yeah pragu.
00:34:35.280 - 00:35:46.070, Speaker E: Yeah, I feel like there's a significant difference between something like TX create which is actually a new thing versus something like ext code size where it's just, it's not additional effort. Well, that's easy to say, but it's not like a difference from legacy contracts. And in my view, we're making all this effort to ship Eof. Now, while removing stuff is good, it's also good to make it useful and ensure adoption so that all of this effort pays off. My concern is that with these limitations, it's going to really harm this adoption in languages and libraries, and we're not going to really reap the benefits. So in the direction of reducing it as much as possible, the simplest possible fix would be to just enable ext code size. And I think that'll be a much better situation for EOf to get adopted.
00:35:56.700 - 00:35:57.480, Speaker A: Ben.
00:36:00.060 - 00:36:22.610, Speaker C: Probably code hash also, because then you can actually detect its neof contract specifically, whereas you can't do that with code size alone because code size would say two bytes. But that doesn't tell you it's euf two bytes if you're worried about proxies detection.
00:36:24.910 - 00:37:16.830, Speaker H: So one of the things that we're developing in the UF implementers is we don't have the pr out yet, but we're contemplating an iscontract code. One of the design options is have it return zero, one or 0120 for legacy. No, zero for EOA, one for legacy and two for EOf. So in one opcode we solve both of these problems, but we're still, there's other design issues. We want to make sure we're covering spaces and not pulling back on some of our commitment to remove code introspection. Because if we just blindly turn on the XT code, hash ext code size and the XT code copy, we probably don't need copy. But I mean, if we're removing the other ext code, there's going to be a lot of pressure to say, well, why don't you just do code copy? All of a sudden we're needing to keep all the old bytecode, or at least metadata about the bytecode as was originally implemented, which is going to make things difficult for ZK systems because they'll need to keep some extra data.
00:37:16.830 - 00:38:27.620, Speaker H: But there's already issues around that anyway with calculating the addresses. So we're discussing this in our chats and I mean, if it was just as simple as just flipping an opcode or implementing one another thing, I'd be a bit more willing to push the rest of the implementers to a solution. But I think one of the big issues is we don't have the exact solution that's going to solve all of our commitments and fixing in a subsequent fork gives us the space that we need to make sure that we're doing the right thing, not necessarily the time forced thing. And as far as if we're shipping something that devs can't use, 95% of contracts never need to know if you're calling an EOF or EOA, the exception says the. But if you're calling Uniswap, it's presumed your contract, the callbacks, they work a lot of the contracts and smart contract use cases that go with this, these features are not essential and they're not breaking. So that's, you know, we're covering 89% of the people who could use it. You could deploy uniswap today and not have any of this concern.
00:38:32.840 - 00:39:17.730, Speaker A: So I guess maybe one related thing to think about this, just like, yeah, how far along GoF is right now, what the diff is to add these features and over what timeline, because there's clearly a design space to explore here, whereas we've been kind of exploring the rest of the design space for quite some time now. So I guess I don't know if, Daniel, you're the right person to give this updates, but in terms of the EOF Devnet, where are we at now? How stable are the implementations? And then what do you think it would take to add these opcodes?
00:39:20.480 - 00:40:00.506, Speaker H: So the big issue for the opcodes, aside from coming to consensus on what the correct solution is, is when you write tests for them, and that is a couple of days to write the tests, and then all the clients need to implement the code and conform with the tests. As far as Devnet for readiness, we're at least two weeks out. The clients aren't 100% on tests right now. Every client has at least one test that they're failing. Some of them, it's because there's, some of the specs have been changing underneath it a little bit, and they had implemented it to a spec that was correct a year ago. Those are some of the issues that they're working with. Plus the work on 7702 is taking a lot of engineers time right now, how things are getting basically designed on the fly.
00:40:00.506 - 00:40:12.710, Speaker H: It's taking a lot of their time to re implement these changes. As far as readiness, I think we can be ready for when Devnet four ships. Adding the opcode would push us back probably about a week for Devnet four at least.
00:40:13.810 - 00:41:49.760, Speaker A: Okay. My sense is that given EOF is already such a huge, huge change, I would lean towards integrating the version that we're already testing thoroughly as a first version in Devnet before we add anything more and then potentially in parallel start targeting an EOF extension that we can potentially add in, say, Devnet five or something if Devnet four goes smoothly. But my biggest fear here is this is already such a massive, massive change and that if we just try to add everything now and constantly keep changing the spec, we don't even get to a point where like clients have a stable implementation of like the current spec that we can test. And yeah, it does seem like we don't necessarily need to make a decision on this now, but ideally before we ship, we should have like taking the right decision here. Does that make sense to people? Objections or concerns with that? Okay, sweet. In that case, what's the best way to continue the conversation around, like, the specific issues I know that people have been using, like the EVM channel. That seems right.
00:41:49.760 - 00:41:56.780, Speaker A: And I assume there's another EOF implementers call. If not next week, the week after, is that right? Yeah, next week there is one.
00:41:57.540 - 00:42:31.930, Speaker H: Yeah. The EOF completer calls are opposite weeks of ACde. So it'll be Wednesday. And the EVM channel is a great place to do that. I'd like the ypsilant team to get that draft out as soon as they think it's ready, preferably as soon as possible so we can have discussion on what their ideas are for, how we can address that. So yeah, that's the best place to continue this. And I do like the idea of doing Devnet four with what we have right now and then contemplating whether we add this in Petra or whether it becomes a Fusaka target.
00:42:32.910 - 00:43:18.730, Speaker A: Yeah, that sounds good. Any other concerns, comments about EOf or the specific change? Okay, yeah, thanks, Daniel. Thanks friend Jill for coming on and sharing the doc. Moving on. We have a proposed change, this is a CL change to fix the correlation penalties that Mikael put together. And he just wanted to get a last call on people reviewing this. I don't think Mikael's on the call today, but anyone else has comments or contacts want to share about this, please do.
00:43:25.510 - 00:43:50.126, Speaker I: I can see it a little bit. Yeah, it kind of fixes an edge case with the penalties on the CL around slashing under the max ed change. And yeah, if especially SEAL teams could just take a look at the pr and approve, ideally that'd be great. But yeah, it should be in a pretty good place. So I guess the ask is just for CL teams to take a look.
00:43:50.238 - 00:43:55.010, Speaker A: Is this something we would merge into Devnet three or Devnet four?
00:43:56.790 - 00:44:13.970, Speaker I: Good question. I would just say it'll land in the CL specs release when it's ready, and then from there we can just see which Devnet is ready. Yeah, it doesn't really matter. This isn't something we're going to hit in testing, at least in ten, three or four.
00:44:14.630 - 00:44:55.530, Speaker A: Okay, sounds good. So yeah, let's try and get this reviewed, async, and then merge before next week's call, ideally. Next up we have a proposal by lightclient to unify request objects in the engine API. There's been a fair bit of discussion on it with. Yeah, with the last comments coming after the start of this call. Right at the start of this call. I don't know, like clients, do you want to give some context on this? And if others after that want to chime in, that'd be great.
00:44:55.530 - 00:46:13.200, Speaker A: If not, as I understand it, is that the current design requires Yale clients to be aware of the fork schedule through the engine API. And this design would, I believe, remove that requirements. But there was a recent comment. Yeah. That came right at the start of this call saying that it seems like the El actually needs to be aware regardless because of some of some old methods. Any comments, thoughts? If not, we can also continue the discussion on the PR and potentially give people another week to review it. Okay, yeah.
00:46:13.200 - 00:47:05.556, Speaker A: In that case, let's move on. Okay, so Petra Eips, we had 7623, which was proposed a while back, and then subsequently CFI'd Tony wanted to ask about including this in the hard fork. Similarly, Alex had an EIP to decouple the blob count between the El and the Cl. And then lastly, Max has a proposal to update the blob, the blob reserve gas price. And so it's probably worth going over each of these in more details. But I just want to flag that. Like, it does seem like we have a fair amount of small proposals that people still want to put in the fork.
00:47:05.556 - 00:47:31.232, Speaker A: There's others that we've discussed on previous calls, like 7212 for example. So if making decisions, we should make them in the context of like. Yeah, none of these are like the only thing we potentially want to add as a small addition to Petra. And I mean, we're just discussing a couple of new opcodes for EOF as well. Yeah. So to start, I don't know. Tony, you are on the call.
00:47:31.232 - 00:47:37.060, Speaker A: Do you want to give a bit of context on 763 and. Yeah, any thoughts you want to share there?
00:47:38.640 - 00:48:17.638, Speaker J: Yeah, sure. Yeah. As a reminder, EAP 7623 proposes to increase the call data cost for call data heavy transactions. And the main motivation to do so is to reduce the size of the El payload, because already today we see certain big blocks. And with big, we are talking about 400 kb that receive way less attestations and are then more often reorganized. Also today, the median, or the mean block size is around 100 kb plus blobs, but the maximum size is 3.5 megabytes.
00:48:17.638 - 00:48:50.320, Speaker J: So 100 kb versus 3.5 megabytes. And as you can see, this is super volatile. And by increasing the call data cost, we can basically reduce it. Also, I think the AP is in a good position now because we have blobs. All roll ups are using blobs already, so no one relies on using call data for data storage on chain. Yes, Tim said the EAP is considered for inclusion, and I would propose that we include it indefinite.
00:48:50.320 - 00:49:02.980, Speaker J: Four, the AIP itself is super small, the El specs are done, and I think Mario's also started implementing it in geth. And yeah, would love to hear what the core devs think about it.
00:49:05.330 - 00:49:32.080, Speaker A: So there's two comments saying that they see the IP as addressing invulnerability. I assume this is the fact that we can have these huge heavy blocks on the network and then a plus one from leather mine for the CIP. Any other thoughts? Comments? Okay, lots of plus ones for the EIP.
00:49:41.420 - 00:49:41.900, Speaker C: I guess.
00:49:41.940 - 00:50:14.260, Speaker A: Okay, before we make a call about this, it's probably worth at least going over the two other proposals just to see how much support they have. And then if we. Yeah, if this is the one people feel strongest about and they think we should still include stuff, we can. Yeah, we, you know, we can decide to include it and figure it out, but yeah, before we make that decision, Alex, do you want to talk about 7742?
00:50:16.080 - 00:50:16.820, Speaker C: Sure.
00:50:17.560 - 00:50:58.760, Speaker I: So I think most people have seen this EIP in some sense already, but ultimately. So today how it works is there's a target value for the bulbs that we want in the protocol and a MACD maximum value. And right now, both these parameters are specified, both MCl and El. So a couple of things this does. At least one thing is that it just couples together. Development of both these layers also makes it a little more inflexible to change, say, target or max, wherever we want. The CIP proposes to uncouple these constants between the El and Cl and essentially have the Cl drive the values, then provide them in the necessary way to the EL.
00:50:58.760 - 00:51:22.840, Speaker I: So we've gone through a few rounds of feedback, at least more on the Cl side of things, and I think the things are ready to go, meaning the EIP engine API changes and the CL specs. So yeah, I think there's generally, I mean there was really good support from the seal call last week and yeah, I'd like to hear what eldubs think.
00:51:31.250 - 00:51:53.610, Speaker A: Any thoughts on 7702? Okay, so is it favor doesn't feel strongly about including it in Pektra or not?
00:52:01.470 - 00:52:37.800, Speaker I: Yeah, I guess one other comment is that it supports pure dos and just generally the blob mechanics. And so we could imagine coupling this with peer dos, then we can decide where Peardos ultimately lands. It would be a little messy to like have a separate pure doss spec.
00:52:37.880 - 00:52:38.500, Speaker E: But.
00:52:40.240 - 00:53:48.660, Speaker C: No, we would have, we would have one spec and just point to that basically. So hopefully we could launch like, yeah, I'm not sure about the correct order what we would do. Like vector Devnet four would come first, or peer desk Devnet three. We are currently still waiting for peer desk Devnet two for client teams to finish the implementation. Once that's somewhat stable, then we can add some additional scope to the peer desk testing, which would be also the time when peer desk would rebase on top of Elektra. So at that point it would be very nice if we could play around with a different number of blobs in each, like different target and different values and just experiment of like how it would look in peer death. All we would need is just a single er to implement this and then we could use that for testing and then every other ER could implement this later or whether we decide to include it in picture or not.
00:53:56.400 - 00:55:43.680, Speaker A: Yeah, so there's a comment in the chat by Jurgen about potentially leaving decision making for the next Acde so people have time to digest. I feel like that might be the right way to go about this, so that we can at least list out all of the potential additions, and some of them are formally ips. So like 7742, I'm not sure if we've CFI'd it, but it seems like it probably makes sense to CFI that for the fork, given the relatively strong support. But then in addition to that, potentially list out like the less formalized proposals like these EOF changes and potentially what we're about to talk about, would that make sense to people? Or I guess, does anyone feel like there needs to be a decision taken now for either of these? Okay, if not, does anyone object to cfiing 7742, just so we can have it there in the list alongside everything else? So we already have 7212 there, the r1 curve. We still have the inclusion list vip, which I think we've pretty said that we're not going to do, and we already had 763. And so, yeah, I think having 7742 there. And then I can put together a list of the other proposals that aren't quite as formalized, and people can review that and ideally even share their thoughts async prior to the next call.
00:55:43.680 - 00:56:03.710, Speaker A: Okay, yeah, thanks for sharing, Alex. And then last one on the agenda, Max wanted to talk about raising the reserve price for blobs. Max, are you still on the call? Yeah.
00:56:04.610 - 00:56:37.856, Speaker D: So this change would be a one line diff. The reserve price is actually already implemented. It's just that it hasn't been set other than at one way. So it's a one line diff, just changing that constant to be a value that I proposed. The value was chosen so that the cost of a blob would be pegged to around the cost of a simple transfer. So 21k gas at a one way base fee. And so that comes out to around like $0.05
00:56:37.856 - 00:57:27.908, Speaker D: USD per blob at today's prices. The goal of the change is not to raise revenue. It would be like, even if we had three blobs per block, it would be something like less than four hundred k a year in total cost if we saturated all the blobs. But the goal is really to have the reserve price be at a point where when blobs do enter price discovery, they do so faster than they do right now. And right now it would take basically 32 minutes to get from one way to this level of like reasonable five cents per blob because of the way that the updating rule works. And you have to traverse all these orders of magnitude of fees to get to the right spot. And it just takes a long time to do that with the updating rule.
00:57:27.908 - 00:57:48.840, Speaker D: So this would be kind of like a one line change that addresses that. And of course, the reason that we might want to do this is that there's some chaotic stuff that happens when blobs enterprise discovery, where there's a lot of weirdness that goes on, on the fee markets that we've seen a few times when they do enter price discovery.
00:57:52.940 - 00:57:55.840, Speaker A: Thanks, Ansgar.
00:57:57.700 - 00:58:43.184, Speaker C: Yeah, I just wanted to say that basically the reason why the parameter is in the specs right now, but not set, was just that we weren't sure it's worth the complexity. And initially we just assumed that blobs would only really go through price discovery once, relatively shortly after shipping for it before, and then would stay above some sort of minimum price from then on out. It turns out that that was not the case. It takes a little bit longer to basically hit that adoption level. And so we might actually go through that phase several times and we've already done that a few times in the past when demand spiked. And so I personally think it makes a lot of sense. And particularly I think that Max is specific.
00:58:43.184 - 00:59:14.100, Speaker C: I know it's not an EIP yet, but the specific proposal he made seems very sensible to me because it is actually somewhat important that we hit the right trade off, that we don't set it too high. Because the point specifically is not to raise revenue or anything or like price gouge or anything like that. It's really just to shorten the amount, like the time to sensitivity, basically. And so I think basically the proposal is basically already ideal. And if it was put into a full eIp, I would support it.
00:59:15.760 - 00:59:17.620, Speaker A: Thanks, Ben.
00:59:19.240 - 00:59:46.640, Speaker C: I've not double checked Max's math, but I'm trusting it. 100 blocks to go from one. Sorry, one way to one guy seems like an extraordinary load on the validators for no unresponsiveness to get to a price that's pretty low anyway at 1 gy. So I think it makes lots of.
00:59:47.820 - 01:00:11.362, Speaker D: Yeah, and that would be at full load. And actually there's like a bunch of weirdness that happens. Usually these price spikes happen around when I. Other activity on the chain is high. And when there's trading going on, the builders don't want to include the blobs. So it actually takes even longer than that because they're periodically producing blocks without any blobs. So it's even longer than that.
01:00:11.362 - 01:00:13.190, Speaker D: That's kind of the best case scenario.
01:00:17.530 - 01:00:21.990, Speaker A: Any other thoughts, questions or comments about the proposal?
01:00:25.510 - 01:00:50.250, Speaker F: Someone mentioned that blobs are not being included for efficiency reasons related to trading. Is there any concern that we might not get price discovery because people are so reluctant to include blobs that they're just not being included above the target rate anyway? Because that might suggest we want to do something more sophisticated than just this proposal.
01:00:57.640 - 01:01:13.780, Speaker J: Sorry, I just clapped. Instead of raising my hand, I wanted to answer to Peter's question. I don't think. I think. I don't think that's the case. Because at some point, roll ups will just pay more and more and at some point the builder will have an incentive to include them no matter how big the blobs are.
01:01:19.010 - 01:02:05.900, Speaker D: Yeah, I agree with Tony. The priority fees will start to escalate. There have been some changes in builder API endpoints that allow a more efficient fee market and allow you to basically replace your bid with a higher one with a higher priority fee without rebroadcasting the blob. Whereas before you had to rebroadcast the blob, and in order to prevent a like DoS attacks on the network, you had to increase the fee by 100%. So there have been some positive changes in that direction on the builder front. Besides, I think a change like that would probably be too big for Petra, any change that's more in the fundamental structure, whereas this is just kind of a one line change to a parameter.
01:02:15.210 - 01:02:32.990, Speaker A: So I think for this specific proposal, it's clearly worth drafting an EIP and considering it along with the other changes we were just discussing in the next call. Max, do you have the bandwidth to do that in the next week or so?
01:02:34.120 - 01:02:37.840, Speaker D: Yeah, I'll have it ready by the end of the week. Thank you.
01:02:37.920 - 01:03:13.350, Speaker A: Awesome. And I guess one thing related to the 7623 that I wanted to bring up is that Anzgar said it might be worth considering just the raw call data increase. If that's simpler than 7623, I don't know if anyone wants to draft an eipde for that as well, for us to consider or if. Yeah, Tony, you have thoughts about like if we were to just do a simple one line change instead of 7623, what would that look like?
01:03:16.210 - 01:04:04.850, Speaker J: Yeah, you could basically look up the EAP first version. It started exactly like that by just increasing the call data cost of by just four xing the call data cost for non zero and zero bytes. The main problem back then was that the community was basically saying, so I reached out to a lot of community members and teams and the main feedback I got was that this is kind of then a bigger change because it impacts tooling. Because not like in EAP 7623 where 99.9% of the transactions will be unaffected. So every token transfer, any NFT transfer, anything you do with DeFi would be unaffected, not touched. But with a dump increase you touch basically every transaction.
01:04:04.850 - 01:04:44.400, Speaker J: And yeah, this was the main rationale why to do it in a little bit more complex way, but also having the advantage to not touch every transaction. And also there is this follow up proposal by Vitalik to do it fully multi dimensional, which is probably something we might want to do in the next years. So I would see 7623 more as the quick fix that is a little bit more sophisticated than the dump increase, but also far away from multi dimensional gas pricing.
01:04:45.620 - 01:05:03.350, Speaker A: Got it. Thanks. Okay, I guess in that case, yeah, we can have people review 7623 and if for whatever reason people think it's too complicated, even though it seems relatively simple. We can cross that bridge when we get there. But thanks. Yeah. Just wanted to make sure that we touched on that as well.
01:05:03.350 - 01:05:25.800, Speaker A: I think this was everything we had on the agenda for today. Is there anything else people wanted to bring up that we quite. That we. That we didn't get to today? Okay. If not, yeah, we can wrap up here. Thanks, everyone. And I'll share a recap.
01:05:25.800 - 01:05:47.490, Speaker A: Yeah. Shortly after this call. And, yes, if people can review all the proposals before next Acde and ideally share their thoughts about them ahead of time, we can hopefully make some final decisions about the scope of Prektra in two weeks. But, yeah. Thanks for coming on, everybody, and talk to you all soon. Cheers, everyone.
01:05:48.190 - 01:05:49.930, Speaker J: Thank you, everyone. Bye bye.
01:06:10.640 - 01:07:05.160, Speaker A: Sadeena. Sadeena.

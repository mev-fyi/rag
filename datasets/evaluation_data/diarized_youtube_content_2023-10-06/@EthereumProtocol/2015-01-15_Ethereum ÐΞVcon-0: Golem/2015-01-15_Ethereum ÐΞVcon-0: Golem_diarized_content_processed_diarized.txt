00:00:12.730 - 00:01:17.174, Speaker A: Hi, my name is Peter. I work at IMAP in Warsaw, and we met with Gabe approximately in February, I suppose, and we had a short chat regard future collaboration and possibilities of us helping you with some parts of the Ethereum project. It happens that I work at a company that specializes in compilers, specialized right then, and it resulted in LLVM implementation of EVM that Pablo is going to describe. But at the same time, we had little misunderstandings among us. And when Gavin described the Ethereum, our CEO remembered two phrases, turing completeness and virtual machine. So after, I don't know, half an hour, he thought, well, great, that may be a supercomputer. That's something that can distribute computation and, I don't know, locally run it.
00:01:17.174 - 00:01:56.732, Speaker A: So no, not exactly. It's more about the consensus and keeping a solid, compact state, not about distributing computations. So, okay, so what can we do? Maybe we can provide something like this. And he called it Golem from Golem 14. It is a story written by Stains Pablam. It's a machine that got so large and complicated that it gained awareness of itself. Nice.
00:01:56.732 - 00:02:58.576, Speaker A: Let's have a world supercomputer. If we cannot do this with ether, maybe we can implement it ourselves. After another thought, we come to a conclusion that it doesn't really make sense, because there are some attempts to implement something like this, and they do not work so far. Well, we have cloud computing, but this requires some structure over the machines and hardware, and we cannot build a supercomputer or provide computing power out of the box using just pcs which stay at homes of any people who would like to provide computing power. So what to do? We should give some incentive to them. They should be able to make money, and then maybe that would work. But still, that's pretty hard, because that would require registering into some services that would allow them to transfer value for the computing power that they would like to share.
00:02:58.576 - 00:04:30.280, Speaker A: So the obvious idea is that it should be backed up by ether or Ethereum. And that's what we started to think about. So the main idea is that we would like to provide users of regular pcs or whatever computers with possibilities of either distributing their computation across a peer to peer network or to make some value by providing their resources, either computation or storage or, I don't know, bandwidth for that matter, and it should allow them to do it pretty easily on both sides. Special specificating tasks may not be so easy, but computation should be out of the box without any additional configuration, and they should get remuneration for computing something. What's important is that we don't want them to get threatened by malicious nodes inside the network. So all computations have to be separated from their host machines. This is where virtual machines come into role.
00:04:30.280 - 00:05:36.690, Speaker A: And in general the task is some code. Well, in fact, any code that can be written in one of support languages that we can distribute across the network and run inside the virtual machine with some constraints, because first of all, we don't want to thread that computing node. And on the other hand, we wouldn't like to create environment which would allow attackers, hackers, I don't know, whatever malicious nodes they may be, in the network, to attack other computers, not necessarily the host one, but some other. We can imagine a scenario when someone prepressed a DDoS attack distributed dial service just by sending a million tasks that would try to connect to some server. So this cannot happen. We started our proof of concept right now. We implemented, well, sorry for the naughty graphics, but that's how it looks like right now.
00:05:36.690 - 00:06:27.440, Speaker A: We implemented a few renderers as a back end, and right now we have both open source renderers and commercial production renderers added to the project. And you cannot see this here, but right here there is rendering of four images. The one shown here is the last one. The last one is mental ray. I don't know if you know the renderer, it's a commercial renderer, and other three are two pbrts and one v ray. V ray is also a commercial renderer. On the right pane we see subtasks, which means that small tasks that were distributed across the network and are being gathered into a final picture.
00:06:27.440 - 00:07:23.590, Speaker A: So this is it. We believe that such framework can be used for something more than just rendering. Well, in fact, for any computation that can be distributed. In principle it should work as a Mapreduce computation model, maybe bit more generic, because we don't want just to distribute and gather results, but to prepare a graph, a cyclic graph of such tasks that can distribute their subtasks, gather the results, and based on that results, send another list of tasks to perform other computations. You can use it. We used it for rendering for scientific calculations in chemistry. It can be used for multiple integration easily, even for bitcoin mining, if someone would like to do it.
00:07:23.590 - 00:08:48.450, Speaker A: The main problem with this approach is that it require means of validating and collecting results, because once it's set to a network, we have no idea who may be calculating and what value of those results may have. They may be completely invalid, they may be partially invalid or simply valid. So we need some means of getting the right results and collecting them into the result that we need to use, we can use. So what did they have in common? Golem and Ethereum, because we can use Ethereum as a payment system, but on the other hand, there are some modules and parts of the source code that seem pretty similar. In both projects, we would require a very good peer to peer module and transport layer, along with node discovery and resource transfer, and very good resource sharing and management machinery. Because when you write a program, you don't only try to access local files or web servers, but maybe other computers in the network and so on. So it should all be worked out.
00:08:48.450 - 00:09:48.720, Speaker A: But that's the site of the golem. Although I believe that some resource shrink would be also required in Ethereum if parts of code are going to be shared across the network. But from our perspective, the most important thing is to use Ethereum as a generic payment system, because the traditional approach looks like this, a user had to register to some service that allows him her to transfer value. And this is a centralized solution, requires giving out some private data that would be stored somewhere in some, on some servers. And what I don't know should be a problem. Maybe it's not a problem. We believe it is that microtransactions are not supported when we distribute a large task into the network.
00:09:48.720 - 00:11:28.796, Speaker A: It may be distributed across a broad subset of this network and many nodes, which may be. Well, which is very difficult to handle when you use PayPal or similar solutions, and should be relatively difficult to implement with bitcoin, for example, I don't know what's the scale of supported granularity of microtransactions in Ethereum, what is going to be, but I believe that it might be much better than the current solutions. We wouldn't like to flood Ethereum with microtransactions, so at some point would have to decide what is the level at which we can process transactions, because if it works out, then it may be thousands, hundreds of thousands of seconds. So that wouldn't be feasible, I suppose. Well, it's nothing groundbreaking neither in terms of the idea. Well, although putting it all together seemed to be pretty difficult and in terms of iterative contracts, it's just, I don't know, vanilla implementation of common contract that should take place in Ethereum, just used to transfer value between participating nodes. Simple contract is just a contract between two nodes, one that distributes tasks and the other that provides some resources, for example, computational power software.
00:11:28.796 - 00:12:46.940, Speaker A: As a service contracts may involve another party, for example, programmers who provide their parts of code, or in case of renderers, companies that may distribute their rendering engines so that company or person also gets remuneration for providing solution and time dependent contracts. For example, when you would like to host something for some time and we have to pay in timely fashion or for hosting. So from our perspective, this is how it looks. Golem and Ethereum are independent solutions, but to make Golem really attractive, it has to be fully decentralized and more important, easy to use and easy to install. So forcing users to give out their data, credit card data for example, doesn't seem to make any sense. Well, at least much sense. Existing solutions require such registration and they doesn't seem to make a success with this approach.
00:12:46.940 - 00:13:53.016, Speaker A: And as for Ethereum, I don't know, this is just a guess, but it's quite possible that software as a service approach may attract more programmers towards Ethereum. I cannot guarantee that, but it seems reasonable and that's how it looks. If you're not bored with it, I can show you how the graphic outline of the system looks like. So it's not that complicated, but it's not easy as well. I don't know if there is anything similar to Ethereum, but we need a solid peer to peer layer build on top of some transport layer. We need network adapter to provide resource management and global I o that would allow nodes to read and write data in a safe fashion. It has to be really well thought over and implemented.
00:13:53.016 - 00:14:47.230, Speaker A: Task protocol is protocol responsible for distributing tasks across the network and gathering the results, as well as connecting it with transaction system. That's a payment system and this layer is all about the peer to peer network. Sorry. The upper layer is a client layer. The center integration component was called the client before, and it's responsible for defining tasks and passing them to the layer that's responsible for computation. We can below this line, we can test it just on a single machine running the task on a few processes or even threads. So that's good for testing purposes.
00:14:47.230 - 00:15:31.098, Speaker A: As you can see, there's virtual machine that is separated by another border. Because we don't want to give direct access from the virtual machine to external world. Especially we wouldn't like to allow processes that might be written by someone to connect with any computer in the network. Above that we have task with mission framework which describes in detail how tasks are specified. Yeah, so you say that the individual instances cannot connect to each other, so there are no shared resources. There are shared resources, but. Well, I didn't tell that explicitly.
00:15:31.098 - 00:17:40.360, Speaker A: The code that is run is just about any code you can write that we can share, but we explicitly have to point which resources should be shared because we can, for example, try to download some data from a server, and that's not a problem if you do it with one node, but when you distribute it over the network and every node downloads the same data, that may be a threat to that server. So in this case we can simply force the node that distributes task to download the data and then just distribute the downloaded data to computing nodes. What's sorting and grouping task interface? Is that interface responsible for creating a graph of Mapreduce tasks? And above that we have either user interface not similar to the one that I presented, but the one that should be easy to use and easy to specify. Tasks and multiprogramming language support, which should, I hope, allow users to simply write code using some sort of standard library and control structures that are similar to existing control structures in languages, for example parallel four that should be able distribute the tasks. And programmers shouldn't be really aware of what's going on down here. Okay. And we believe that there may be many, many virtual machine flavors, or maybe not technically, but in terms of compute capabilities, and that virtual machines should be defined by users, which poses one problem, that this does not fit the whole picture as virtual machines, or the configuration in fact would have to be distributed in a separate channel, not as a part of the application.
00:17:40.360 - 00:18:02.010, Speaker A: But that may not be a problem at some point because we can allow users to distribute the data messages that they have, such machines and uninterested party would be able to download and use it. Okay, I think that's it. Thanks, Peter.

00:00:20.480 - 00:01:12.810, Speaker A: Okay, we are actually live now. Welcome everyone to HCDE one five five. It bunch of things today, so we'll cover some Shanghai stuff and I think Maris you have some testing updates from there. Then Cancun. We had a bunch of discussions about zero blob transactions in the 4844 call this week and I think it made sense for some of those to be bubbled up here so we can hopefully move forward on them. And then there were a few other Cancun related topics. So one regarding minimal presets on the beacon chain, which El clients I believe need to start caring about with Cancun because of the engine API changes.
00:01:12.810 - 00:01:50.370, Speaker A: We also had a breakout about SSZ transaction format. So you can sort of recap what happened there in the next steps. And then there was another Ssz eIP about the withdrawal routes. And then finally something regarding the transaction pool API. So I guess to start on Shanghai. So we have sepolia planned for February 20 eigth. Ideally we'd announce that early next week.
00:01:50.370 - 00:02:58.256, Speaker A: Thus assumed client put releases out for it. That said, yeah, I know Marius, you ran into some issues when testing on the latest testnet. Do you want to maybe give us a quick overview of what happened? Yes, so full nodes were not full synced. Nodes were not able to correctly sync to the testnet. I'm horribly butchering this, so I'm just going to paper over it. Basically, the issue is if we got a block that was empty so it had no transactions, no uncles and no withdrawals, then we would actually set the withdrawal hash to nil instead of empty withdrawal. Sorry, not the withdrawal hash, the withdrawals.
00:02:58.256 - 00:03:38.740, Speaker A: And we wouldn't download the. We wouldn't download the block because the block is the. We wouldn't download the block body because the block body is empty. But we also wouldn't correctly initialize it. This problem, we had a similar problem in the past already. The thing is, we can only figure out these issues if we have empty blocks. So fully empty blocks, they don't need anything to be downloaded.
00:03:38.740 - 00:04:23.750, Speaker A: And we are full syncing. So it doesn't happen on Snapsync. It doesn't happen when you're not syncing, when you're following the chain. So yeah, it's kind of a weird edge case. But given that we had already two issues there with Geth, it might make sense to have this as a sync test. Just syncing a full chain, like full syncing a chain from another client that has empty, fully empty blocks. And yeah, it's fixed now.
00:04:23.750 - 00:05:05.490, Speaker A: It's not in the release, but we're planning to do another release with this fix and another fix basically today or so people on Sepolia can just use the normal version, but if you want to sync up after the fork happened, then you should use current master. That's basically it. Thanks. I guess I'd be curious, are we aware of other time teams having this issue?
00:05:10.280 - 00:05:20.372, Speaker B: So I haven't noticed any issue during the sync, but I will recheck all the edge cases. Would be nice to have hive test.
00:05:20.426 - 00:05:55.280, Speaker A: Of course, yeah. Anyone else? So these issues arise because of one optimization that we do. If a block has no body. We are not requesting the block body because we know just from looking at the header that the body is empty and so we are not asking the network for it. I'm not sure if other clients have the same optimization.
00:05:58.260 - 00:06:07.750, Speaker C: Yeah, we might have this optimization. We probably do have it in Aragon. So I need to double check our code and see whether we suffer from the same issue or not.
00:06:15.560 - 00:06:17.184, Speaker A: Mikhail. Yeah.
00:06:17.242 - 00:06:36.876, Speaker B: Quick comment on not having a body for empty block. We have these get payload bodies methods in the engine API. So just to be sure that those are handled correctly. Even if body is empty, you're not storing it.
00:06:36.898 - 00:07:23.766, Speaker A: Yes, those are handled correctly and we have tests for. Yeah, this is not a problem. It's really only during sync. And also if someone gives us a malformed block, either now also via the ETH protocol, but before that via the engine API, we would just reject it. But now we also reject it if someone gives us malformed block on the EtH protocol. Okay. And Mario in the chat said he can add a hive test for this.
00:07:23.766 - 00:08:09.996, Speaker A: So we currently had hive tests for both empty like blocks without transactions, blocks without withdrawals, but not the combination of fully empty blocks. I guess I'm curious just to hear from teams, do you feel this should change sort of the timeline for Sepolia or given we already have a fix in? You know, it seems like it's a pretty easy edge case to describe. Are clients still confident in having a release for sepolia, or at least pointing to master for this bug fix in the coming days? This is basic.
00:08:10.028 - 00:08:14.580, Speaker C: I think we'd be more comfortable with that second option there. We're planning our release for Monday.
00:08:15.480 - 00:08:21.430, Speaker A: Okay. And the Monday release would make sure to not have this issue, is that right?
00:08:21.800 - 00:08:32.410, Speaker C: Well, we'll try to get it in there, but if we're open to the option of someone doing a build off of main instead, that would make us a little bit more confident that we can sort it out.
00:08:33.100 - 00:08:37.980, Speaker A: Okay, sounds good. Any other client?
00:08:48.340 - 00:08:51.570, Speaker C: Yeah, I think we can do a release early next week.
00:08:53.380 - 00:10:21.850, Speaker A: Okay, yeah, the same. Okay, perfect. So what I'll do is I'll follow up with all the El teams offline and see whether they have a release or recommend pointing to master branch. And we can use that for Sepolia. But I guess, does anyone feel like we should delay Sepolia over this? Okay, so yeah, we're still on track for February 20 eigth, and if you're listening, you should expect releases from the various client teams or at the various master branch commits that support Sepolia in the next few days. Anything else regarding Shanghai capella that people wanted to discuss? Barnabas? Yes, I could give an update regarding the withdrawal devnet seven that we have just launched on Tuesday. Yes, this Devnet Seven was basically a very heavy stress test, and they meant to test for the worst case scenario on the main net.
00:10:21.850 - 00:11:31.544, Speaker A: What I did is a 600,000 validator set with 360,000 bls key changes happening during Chappella, with deposits and withdrawals happening all at the same time with field queues. And Chappella was this morning at 09:00 a.m., UTC, and we saw a huge fluctuation in CPU and Ram usage during the fork transition, which was expected due to the extremely high number of BLs messages got it. In the network. Within a few days we will see exactly how many messages have been lost or get a better estimation. And what we also noticed is we realized that there was a bug in Bezu and prism where despair did not discover new deposits. And we haven't noticed this issue before because we didn't make this amount of deposits in other networks.
00:11:31.544 - 00:12:22.690, Speaker A: But maybe someone from Badoo can explain this bug a bit. Is sorry is the issue. They could not see when they were overwhelmed with deposits, they missed a large share of them, or they stopped processing them altogether. So they stopped processing. And also there were some blocks missed, block proposals missed, and we figured that it was possibly due to some RPC batch size issue. Got it. Anyone on the baseu or Prism team have more context? I'm not aware of this issue, so that I will follow up right now.
00:12:22.690 - 00:13:03.324, Speaker A: Yeah, this is Matt. I can provide some more context. We recently limited this RPC method intentionally to a small value to kind of avoid some DOS vectors stuff. But we realized that in the case of prism they expect around a batch size of 1000, so we're providing a much smaller batch size. I'm not sure why it would completely stop the process. We need to probably investigate that, but we will reevaluate this value and we're aware of the issue specifically. Got it, thanks.
00:13:03.324 - 00:14:06.456, Speaker A: Anything else on Chappello? So, in conclusion, basically we have lost one epoch. We went down to 62% during fork transition due to the extremely high ram and cpu usage, but we recovered within three epochs afterwards. And I think it's expected to have a lot smaller case on the main net because we don't expect this amount of BLS ghost spinning and we're going to have a lot more nodes. So this is really just the worst case scenario. And then what was the split of the different validator combos on the Devnet? Was it like matching main net, or was it like an equal split? It's not equal, and it also doesn't match. I can get you the number. Sure, yeah, if you want to post it in the chat, if you don't have it off the top of your head.
00:14:06.456 - 00:14:39.410, Speaker A: Yeah, that'd be great. And will we run the Mavus circuit breaker test on this testnet as well? No, we'd be running that on main net. Shadow fork two. Okay, cool. That's still in progress though. Yeah, I had some issues syncing up the nodes before starting the shadow fork, so it's a bit delayed, but we get to that soon. And map boost has been deployed on Sheshang as well.
00:14:39.410 - 00:14:56.730, Speaker A: But I think for now it's just returning 204 as builders are coming online. But the relay is set up so we could do a circuit breaker test on Sheshang as well. But I think the idea is that we don't because we want to keep it stable for public testing. Yeah, that's fine. Thanks.
00:15:01.260 - 00:15:05.240, Speaker C: Perry, which version are you running for these tests.
00:15:07.260 - 00:15:09.240, Speaker A: For elf mapboost?
00:15:10.000 - 00:15:12.300, Speaker C: No Cl client.
00:15:14.000 - 00:15:25.010, Speaker A: At the moment. It's the latest releases, so it's still waiting for the relays to come online before I go asking around for which versions to update them.
00:15:28.050 - 00:15:33.150, Speaker C: Okay, so you were not planning to use the upcoming sealed release?
00:15:34.050 - 00:15:43.458, Speaker A: I will once the releases are done, but we haven't started the shadow work yet, so once it's done then I would reach out to get the latest images to run there.
00:15:43.624 - 00:15:44.610, Speaker C: Cool, thanks.
00:15:44.760 - 00:15:56.620, Speaker A: Yeah. Okay. Anything else on Chappella?
00:16:02.270 - 00:16:10.690, Speaker D: I want to say that I just confirmed that we already handled this empty body issue correctly. Nevermind.
00:16:10.790 - 00:16:54.160, Speaker A: Nice. Okay. And yeah, for people listening. So expect a blog post early mid next week with this, and also keep an eye on the different client repos as they put out releases or announcements for their Sepolia Chappella versions. And again, this fork is scheduled for February 20 eigth, which is Tuesday, about ten ish days from now. Yeah. Anything else? Okay.
00:16:54.160 - 00:18:37.950, Speaker A: Otherwise, let's move on to Cancun. So we had a 4844 call this week, and I think one of the big, I think things to agree on to move forward is what to do with zero blob transactions. So there were a bunch of mempool designs that relied on the ability to discriminate between blob and non blob transactions. And an assumption there is that this sort of EIP four four four type five transactions have blobs, and therefore are bigger and the other ones don't. And so there were discussions about whether we should allow zero blobs transaction in protocol, but ban them from the mempool so that if blocks are created with them, it's fine, but clients don't process them in the mempool directly. Whether we should just straight up ban them in protocol as well, at least to start. And if we do allow these zero blob transactions, then what's the right way to discriminate between blob and blob less transactions? Do we want to look at basically the length of the blob list at the transaction type? Do we want to gossip this information in something like Eat 68? And basically, I think aligning on all of this allows us to get to a transaction pool design, which hopefully is more efficient and can handle the actual blobs in a way that's different from transactions that don't have any blobs.
00:18:37.950 - 00:18:56.230, Speaker A: So I don't know if anyone, I guess from the El side, wants to maybe start and chime in here. My feeling is most of the El folks were leaning on the not allowing zero blobs, but different sort of variations of that. Yeah, Lucas.
00:18:57.130 - 00:20:16.046, Speaker D: So I was thinking about this quite a lot, and while I settled out that I don't like any solution, but what I'm leaning to now is either having some additional metadata for transaction, for example, transmitted in through ETH 68, or just using the size of transaction to determine the rules of how we behave with this transaction. So, for example, if we have a big size transaction, even if it's like whatever, if it's a blob transaction or not, it will go into this large transaction pool. Right? And this also resembles to me a bit how, for example, some managed languages like net or Java handle big objects for garbage collection. They have separate object heap for that with special rules. So it kind of makes sense for me. And it is the elegant solution from the design perspective and from implementation perspective, like trying to think about that. It's not about type of transaction, but the size of transaction also makes some sense to me.
00:20:16.046 - 00:20:29.090, Speaker D: So I'm not entirely convinced. Like I said, I don't like any of them. All of those things kind of like, creep issues into implementation and make it more complex. But maybe that's what I would suggest.
00:20:31.930 - 00:20:38.710, Speaker A: Got it. Okay, Peter, why do you disagree?
00:20:39.610 - 00:21:25.622, Speaker B: I think it's a horrible idea. The theory is super nice, super elegant, and insanely complicated. So the fact is, in order to differentiate, so the whole point of block transactions is that you have behavioral limits on it. It simply behaves completely differently than large transactions. You can have a lot of large transactions in a block, but you can only have one or two block transactions in a block. That's a huge behavioral differentiation. And if all of a sudden I can have zero block transactions and it's gone, hacking e 68 to transmit the block size or the transaction size that's completely moved, because I still can have really huge.
00:21:25.622 - 00:22:20.230, Speaker B: I can have a two megabyte transaction, plain transaction, that would be transmitted to one mechanism and block transactions would be smaller. I think it's just the whole point is with block transactions is something very specific that we can use those specifics to make optimizations. And I get it that from a research perspective, it's super nice to make everything completely generic, and then the whole thing will go fall apart, just like the Merkel Patricia tried falls apart. It's a piece of shit. And same thing will happen with transactions. We just make this meta transaction, and then we'll just say, okay, screw it. We sure hope that mevboost and all the others can handle it, because clients sure as hell won't be able delegating everything out to somebody else who has the infrastructure to handle all that crap.
00:22:23.210 - 00:22:31.658, Speaker A: I didn't get your argument there. You said, like, you can have a two megabyte bit transaction and a block transaction. And what's the problem there?
00:22:31.824 - 00:23:06.600, Speaker B: My point is that I cannot differentiate it. So currently the idea was that block transactions, we transmit the transaction id in the transaction announcements on network, so I know which ones are blocked transactions and which ones are not. The new suggestion was to forget that and just transmit the size. But then I just get one big soup of transactions again, right? I still don't understand, Lucas. Only the transaction id is in 868.
00:23:15.820 - 00:25:07.670, Speaker A: Alexei, you had your hand up. Yeah, thanks. Another idea would be to encapsulate all this separate logic for handling big transactions or block transactions or whatever, because it's just one or two cases, maybe we will have more in the future and we can announce not size or type of transaction. Or we can just share a flag that says you would not like to download this transaction like that. I mean, transactions will be, well, different of different. I mean if you will load a transaction and the size is not like, is not passed, the correct size is not passed, you will verify it that it is too big and you reject this peer, probably you want it, you want to reject peers that send you big block transactions or just big transactions at the end. And so instead of sending some details about the transaction, we can just send enumeration that says it is a big transaction, that's why you don't want to load it, or it is blob transaction and so on, and add more reasons why you should not download it.
00:25:07.670 - 00:25:21.480, Speaker A: And it can be like the solution. Got it. Andrew.
00:25:23.340 - 00:25:58.260, Speaker C: I think for simplicity's sake I agree with Peter. I think the simplest thing to do is just to introduce a new transaction type for the non blob SSZ transactions. And it already chimes in nicely with EAS 68. It has nice semantics. I think for total simplicity to my mind is the best solution. I don't actually see what are the drawbacks.
00:25:59.960 - 00:26:14.970, Speaker A: And the reason for adding this extra type of transaction is so that you can, only using SSD supporting infrastructure, sign both blob and non blob transactions. Is that right?
00:26:15.660 - 00:27:00.920, Speaker C: Well, and going forward, I think going forward we want to move to SSZ. The new type SSZ without blocks will probably be our preferred transaction type, not only for l two solutions, but potentially for everything. And this clear differentiation between non block transactions and block transactions by their type, I think it plays nicely with the semantics because they serve different purposes, rather like b as your run of the mill transaction or carry blobs.
00:27:03.820 - 00:27:04.440, Speaker A: Got it.
00:27:04.510 - 00:27:11.390, Speaker C: I don't see a problem with two types. I think it's a benefit that just highlights the semantical difference.
00:27:17.360 - 00:28:04.332, Speaker A: So this means that we'd have like effectively five transaction types, right? Or maybe six with the pre eip one, five one, or whatever. But you would keep the existing legacy transaction types, introduce blob transaction and then blob transactions which require a blob. And we can have this hard limit there and also kind of separately introduced an SSD zero blob transaction. And this means that like Maris is saying in the chat, we can do things like add more restrictions to blob transactions, like for example, not having access lists, not allowing contract creation and so on, right?
00:28:04.386 - 00:28:05.790, Speaker C: Yeah, that makes sense.
00:28:10.080 - 00:28:52.830, Speaker A: And I guess with regards to the transaction pool, we don't actually need all the clients to have the exact same implementation. Like this is not the case today. So say we went down this route of having two new transaction types, ones that is like both of them being SSD transaction types, one of them being your blob transaction, which requires having your blob and potentially has some other restrictions, and then another that is SSD, no blob transaction, which is effectively the equivalent of like a type two transaction today. How did people feel about that?
00:28:53.200 - 00:29:20.950, Speaker D: Lucas so while we don't have to have the same transaction pool implementation historically, I've seen that we converge on the very similar implementations due to security reasons. And second thing, we still need to agree on ETH 68, how it should look like, because this is what we all need to support.
00:29:21.880 - 00:29:45.870, Speaker A: Right. That makes sense. Yeah. Danny, there's going to have to be conditional logic somewhere around number of blobs, around size of transactions, et cetera. And I think ultimately, if engineers think that is embedded in the type is going to reduce complexity, then that's probably just what we should do and move forward with that.
00:29:56.400 - 00:30:43.356, Speaker D: Lucas, the one good argument that I heard about allowing zero blob transactions is that if we want to upgrade our transactions to, I don't know, have a new field, and this new field will be for blob and not blob transactions, then we have to create two transactions. Right. And this kind of complexity might increase if we introduce something else that will have a separate transaction type. So this kind of is some kind of metadata. If this transaction has blobs or not, it doesn't have to be a transaction type. But yeah, we need to have this logic somewhere. So I agree, but not sure if the transaction type is the best thing.
00:30:43.356 - 00:31:25.210, Speaker D: I was thinking about thinking about transaction type as some of its last bits as flags, for example. But then we only reserved 127 transaction types, which is a bit, not enough. So for example, if it was like 32 bit, if the last bit is set, then it has blobs. If it's not set, it doesn't have blobs, et cetera. But we can probably either just do duplication, right? So in this case, or have a separate metadata filled with some flags. But yeah, that's it.
00:31:32.320 - 00:32:38.530, Speaker B: One thing that I kind of wanted to add is that we very often fall into that fault, error, whatever. We try to make things super insanely generic from the get go, and we have absolutely no idea why. And from my perspective, that feels like a bad thing to do. For example, saying that, well, we shouldn't introduce specialized transactions because we're going to run out of 128 transactions. I mean, that's a very big, very strong argument. We have absolutely no idea if we will ever introduce another transaction or transaction with another field, in my opinion. I personally prefer to go with the simplest solutions and try to figure out, or try to make it more generic, or when there's actually a genuine need for it.
00:32:38.530 - 00:33:34.310, Speaker B: And yeah, that does mean that it might happen, that in the future, currently, we make a decision that's not the best in the future, and the future will gain a bit of complexity. But the problem is that if we make it super generic just for reasons, and then we have to tiptoe around that forever, and there will never be actually another field ever added. It just feels weird. Also, this kind of ties into what Marik's suggestion was, that he suggested that we could even cut down more features onto the block transactions. And I don't know. Personally, I prefer to have transactions that have very, very dedicated use cases. So this whole point has a very strong design, a very strong use case, and in my opinion, we should try to just focus on that use case and not make it this superset of everything.
00:33:34.310 - 00:33:52.510, Speaker B: I mean, for sure it's elegant to make it a superset of everything, but is there any legitimate reason to do so? Because currently, apart from saying that it's elegant, from a theoretical perspective, there's no reason whatsoever that anybody can come up with.
00:34:07.180 - 00:35:29.430, Speaker A: So trying to think what's like the best way forward here, it does feel like. I don't know, from the El side, having this be more tailored around the current use case seems like it's simpler. There's some value both in terms of making a generic framework and also ease of use for l two s if we allow zero blob transactions. But it seems kind of marginal, I guess. Does anyone on the El side feel like we should push forward for a zero blob and sort of more flexible four four four transaction type? Otherwise we could at least make the call that the zero blob transactions shouldn't be possible. And then there's this whole other SSD discussion about how we want to approach that. We can go to that after.
00:35:29.430 - 00:37:06.976, Speaker A: But I think if we all agree that we shouldn't do zero blob transactions, I think the other thing to figure out is, do you ban those in the mempool only, or do you ban them in protocol as well? And Dano has a question about what wallets and chain infrastructure tooling projects thinks. I don't have a great view. Does anyone on the call have one? I would suspect this is currently a very domain specific debate that most people don't have a perspective on. And I think the optimism folks seem to think this was fine. And generally on the l two side. My feeling is that whatever gets 4844 shipped the quickest, assuming it is like a small technical change, they would probably prefer to work around that and have four four four a month earlier than have four four four be delayed because we're not sort of aligned on the transaction types. Um, and yeah, Alexey has a comment in the chat as well.
00:37:06.976 - 00:38:29.874, Speaker A: Like, you know, there's also a world where like, say we just shipped this and only l two s use this, and we sort of don't have the whole ssz move happen in Shanghai, sorry, in Cancun. So that's possible as well. And if you went down that route, it's basically only l two s that have to deal with this new SSD transaction type. Maybe it's very limited, and then maybe in the fork after, we can come up with a broader SSD scheme so it doesn't have to all happen at once. So unless someone wants to make like a strong case for zero blob transactions now, I feel like we should ban them. And then the question is, should we ban them just in the mempool or in the mempool and in protocol for now? Does it make life easier if we just assume they never happen versus we just assume they don't show up in the mempool? I believe the zero blob transaction camp generally is assuming those two things happening simultaneously, especially due to the reorg considerations. Okay.
00:38:29.992 - 00:39:08.000, Speaker C: Andrew, I think we should ban them in the protocol, and it's easier to start with some restricted functionality. And I agree with Peter that we should move in the direction of more generality, actually driven by concrete use cases rather than just some philosophizing. And also banning them both in the protocol and mempool makes things consistent and easier to reason about.
00:39:09.570 - 00:39:51.850, Speaker A: Okay, yeah, that would be my assumption as well. And it's easier to relax that constraint in the future than to start without it and want to add it afterwards. Anzgar. Yeah, I just wanted to say, just because I think in general, I would have preferred to basically not ban them in the protocol. I think it's fine. I think we can go ahead and ban them in protocol for now. But just kind of philosophically, I would say that over time at least, maybe now is not the time, but over time, we should be willing to move more and more towards a world of specialized mempools, where basically not having all the functionality offered at all times by the kind of inclined mempools would be fine.
00:39:51.850 - 00:40:29.030, Speaker A: For example, kind of ad reorgs, not being able to reinsert some transactions into the mempools and whatnot, these kind of considerations. I know that client teams are kind of hesitant with that. I think philosophically, over the long term we could move more towards being willing to have more specialized out of protocol mempools. But for now, I think just banning zero bolt transactions everywhere, I think that's the problematic choice. Okay, does anyone disagree with banning zero blob transactions across the entire protocol? So both on chain and in the mempool.
00:40:33.510 - 00:41:41.270, Speaker B: Perhaps one note that kind of for banning is that I do agree again that it would be an elegant world to say that, well, if you use some weird combination of a transaction, then your transactions will not get re included, and you have to go through whatever route you went through the first time to get it reincluded. But I think that sets a strange precedent, at least for me, that essentially the only way to include such a transaction is to go through some mining pool or some flashbots bundling service. And essentially the only way to re add it is to monitor the chain and then go through the same bundling service once more. And it kind of gets into this weird place where people will just not use normal clients, everybody will use the bundling service because it can bundle stuff that the normal client cannot or will not. So I'm not sure that it's.
00:41:43.290 - 00:41:43.666, Speaker A: A.
00:41:43.708 - 00:42:39.260, Speaker B: Path that's very healthy for the network to go down. Even nowadays you can see that people are using all these forks of get that I'm assuming other clients do, just because you can get some MEv fund mev bonuses for mining, and I think it would just every single opportunity where they can make more money, more and more people will switch over. That's kind of fine if you have a good enough and fair enough infrastructure built out, but I don't think we have it yet. So I don't think we should push too many people towards that path. Basically every validator having to run flash bot, because otherwise it's just not working.
00:42:43.810 - 00:43:01.410, Speaker A: Right. And I guess by banning them at the protocol level today, we keep this a bit more fair with regards to the public web pool, where you just don't get this functionality by rallying around Geth or nevermind.
00:43:05.830 - 00:43:08.698, Speaker B: I think it's more of a generic note.
00:43:08.814 - 00:43:09.480, Speaker A: Right.
00:43:10.730 - 00:43:23.820, Speaker B: So what I wanted to say is that this reasoning that there will always be some operator which will be able to re include something that science cannot is a dangerous line of thought.
00:43:27.470 - 00:43:28.220, Speaker A: Yeah.
00:43:28.990 - 00:43:45.200, Speaker B: So that's the only thing that I would like us to keep this in mind too. That for sure we can outsource certain functionality to other actors in the system, but we need to think it over carefully as to what the implications will be.
00:43:50.150 - 00:44:57.082, Speaker A: Yeah, I think that makes sense. Okay. Anything else on the zero blob transactions? If not, then I guess in terms of next steps, could one of the 4844 authors just make the change to the EIP to say that basically type five transactions need a blob? Okay. Antar says he'll do it in the chat, so thank you. And then obviously the sort of ripple effects of that is, as we're continuing implementing these transaction pool designs, we can now take for granted that blob transactions, or type five transactions, will come with a blob and separate those from the rest of transactions. Yeah. Okay.
00:44:57.082 - 00:45:12.740, Speaker A: And I guess on a similar note, it might be worth going into the broader SSD conversation. So we had a call about this. I think it was literally yesterday. Ethan, do you maybe want to give a quick recap of the SSD call?
00:45:14.230 - 00:46:15.510, Speaker C: Sure. First of all, this is not about the blob SSD transaction, and also not about the zero blob transaction. Yesterday's call was for the representation of transactions as part of the transactions route in the block header. So there are two approaches there. One is based on using a union that is using the transaction type to create separate objects underneath, depending on that type. The other one is the superset approach, where we use the same structure as you have on JSON RPC, where you essentially have a generalized transaction that can be used to represent all of the transaction types. And yesterday we could not really decide which one is better.
00:46:15.510 - 00:47:36.320, Speaker C: Both of them have advantages and disadvantages. So we decided that we simply create a couple of prototypes so that we can actually see in Braxis on concrete examples, how big are the differences between them when they are actually used. Like, is a union really that ugly to implement in a Sierra knowledge circuit? Stuff like that. So I will be working on creating those prototypes and benchmarking them against each other to be included in about two weeks. So then we will take another session to decide whether we want to use the union approach or the normalized transaction approach to represent those on transactions route. There was also a discussion about DevP to p networking, whether we want to upgrade those as well, so that when historic blocks are downloaded, whether this should use the original encoding based on RLP, or whether this should use the union or normalized transaction. That was also an open discussion point, but still undecided as well.
00:47:36.320 - 00:47:39.230, Speaker C: Yeah, that's a summary from yesterday.
00:47:42.390 - 00:47:47.410, Speaker A: Thank you. Any questions? Comments?
00:47:50.070 - 00:48:16.794, Speaker D: I have like a timeline question. Is this being considered in Cancun? Right, because it makes sense to be considered in Cancun because we are already adding SSD transactions so we can have a full move to SSD. On the other hand, if it will be considered in Cancun, it will definitely take longer, right?
00:48:16.912 - 00:49:30.100, Speaker C: So yes, the idea was to including it into Cancun, and also if it makes sense to align the common parts of 4844 with it. But the complex parts like adding the SSC support to the ELS is already done as part of 4844. So regardless of whether this is a union type or a normalized type that will go into the transactions route, it is the same complexity. I mean, right now we are just having RLP there. That also works fine. And about Dankrod's question to benchmark, there are things like when you get approved based on this tree, how expensive is it to run a verification of a proof in a smart contract? For example, how big is the call data? How expensive is it to deploy such a contract? Mainly focused on consumers of the proofs. Exactly.
00:49:32.470 - 00:49:43.094, Speaker A: So it's about gas cost of verifying proofs on a union field, or an.
00:49:43.132 - 00:50:00.300, Speaker C: Optional field of the union transaction, or the normalized transaction, essentially. And also about the different network encodings, just a byte length for those.
00:50:05.110 - 00:51:24.924, Speaker A: Right? Yeah, we have the breakout for this two weeks from now, and we're using the type transaction channel to chat about it. In the meantime, I think also on the question of Cancun, it would be good to consider this alongside all the other potential things we can do for Cancun. So we haven't quite made a call for people to come and shill their various proposals for the upgrade yet. So I think we probably want to do something like that just so that we have sort of a full picture of what we're trading off against. So I suspect in the next couple of calls it probably makes sense to try and get a list of what are the things people would like to see in Cancun, and then this will be one of those items. But yeah, at least we'll have a full picture for making that people, I guess for people listening. If you already want to start sort of signaling what you'd like included in Cancun, there's a tag on eth magicians, Cancun candidates.
00:51:24.924 - 00:52:13.750, Speaker A: So if you have your eip there, you can just add the tag. And then there's also like a thread about the entire upgrade for folks. Even like if client know you have already strong preferences of stuff you'd like to see, it makes sense to just share those there and we can start discussing that in the next couple of calls. Any other questions about SSE transaction types? There's a comment about ethereum magicians being down. It's not down for me. That's weird. We can look into that offline.
00:52:13.750 - 00:52:38.620, Speaker A: Okay, next up, I believe Ethan and Mikhail, you had another SSZ related topic. So basically moving the withdrawal route from the MPT commitment to SSD. Do either of you want to give a quick overview of this?
00:52:40.110 - 00:53:54.746, Speaker C: I can do that as well. Thank you. That's mainly the follow up from what we discussed for Shanghai, and also postponed explicitly so that we can make sure that these withdrawals will follow a similar scheme that we have for transactions and receipts. But conceptually the withdrawals are separate, so it could be that we want, for example, the withdrawals and the deposits from another EIP to be included earlier than the transactions and receipts. So that's why I'm bringing them up separately. And the other thing that I noticed when I wrote the eips, that the dev P two P specs for how withdrawals are exchanged, I couldn't find them. So maybe that spec is still missing or I didn't check at the correct place, but I wasn't sure if right now with Shanghai we are exchanging withdrawals in RLP or in SSC format on the wire.
00:53:54.746 - 00:54:03.990, Speaker C: And if it's RLP, I'm not sure if it has a version byte in it. Yes, it's in the bodies and in the block header there is also a root.
00:54:10.910 - 00:54:15.900, Speaker A: Okay, any thoughts, comments on this?
00:54:19.680 - 00:55:18.658, Speaker C: We exchange withdrawals as RLP in block bodies in el peer to peer. Okay, so just a list. No version byte or anything? No version there. Okay. Is there a problem when we later transition to SSC? Or can we just bump the EtH protocol version, for example E 69 and then use SSE? And if it's like ETH 68, then it's RLP? Or how should this work? Well, I guess it has to be. Doesn't strictly have to be, but it's nice if it's consistent with transactions. And currently for block bodies, we use RLP for both transactions and withdrawals.
00:55:18.658 - 00:56:00.638, Speaker C: So I would actually, if we are changing that, then we should change that. The marshalling for transactions as well. Yeah, for transaction it's a mix. It's RLP for everything but type five. And if it's type five, it's SSC actually. Right? Yeah, that's for the other question, whether this should be bundled or whether we should transition withdrawals earlier. There is one thing to gain with withdrawals, namely that right now there is no single client that depends on this RLP based Merkel.
00:56:00.638 - 00:56:25.660, Speaker C: Patricia try route in the header. And the longer we wait, the higher it may become probable that someone is actually starting to use that route. For example, rocket pool could use it for some rewards computation or something. So not sure if that is a point that we should also consider. Not sure.
00:56:36.750 - 00:56:44.620, Speaker A: And I guess what's the best place to continue this conversation? The Eth magicians thread. Or is there a channel in the discord as well?
00:56:49.490 - 00:56:54.580, Speaker C: Magicians thread exists. I think that one is all right. I'm not sure about the channel.
00:56:55.670 - 00:57:53.040, Speaker A: Okay, so let's use that and hopefully people can review it in the next couple of weeks so that we basically can make a call on this as we're looking for other cancun stuff. Anything else? Okay, next up, so there was a comment about the minimal presets, which I believe are like the testnet configs for the consensus layer, and that with 4844 and the introduction of blobs, this becomes part of the engine API and therefore El clients should be aware of it. Does anyone want to give the context on here?
00:57:56.050 - 00:58:38.650, Speaker E: Yeah, sorry. First I will just sort of introduce very briefly the idea of the middle config is, yeah, probably it's meant to be used, it's for testnets. Also the consensus spec tests use them for various things where it would be infeasible or just slow to run a certain set of tests. In mainnet presets, functionally they change a couple of things. They change many things, one of which I'll mention. But the key thing for there is they use six second slots and eight slotted pox. And then there's some other things, but you end up with 48 2nd pox and it's quite a bit faster.
00:58:38.650 - 00:59:28.250, Speaker E: But the relevant thing here, for the most part these have not affected the execution layer, and through Capella and Shanghai that remains, as far as I can tell, true. However in Cancun that will start changing, because with the blobs there is now this blobs bundle v. One structure, which in the engine API is currently specified is hard coded to. The number of field elements is 4096. This is consistent with the main net preset, but not the minimal preset. Which means that a minimal mode cl attempting to use the engine API will be just speaking an incompatible engine API protocol when it tries to use the engine. Get blobs bundle.
00:59:28.250 - 01:00:37.822, Speaker E: Sorry. P one call. Now this is, on the one hand you could say this is a specific call, a specific data structure, but I think it's worth bringing up here because I think it's the first time, as far as I can tell, that the idea of this minimal mainnet preset has kind of encroached on the engine API, on the ELS. And so the question is kind of at some level what to do about present. I mean obviously part of presenting it here is I want if other people have options, that's great, but some options to start with one is we can just decide that, well it is indeed just for testing. I'll present four options to start with that are meant to be sufficiently, let's say a reasonable granularity, you can subdivide or combine them as desired. So basically we decide that, well, the engine API is only for Mainnet and if the consensus spec tests want to do some minimal thing, but they don't actually use the edge API because they don't do any networking things, then that's fine, we allow that to break and anybody running an actual network now runs main net regardless.
01:00:37.822 - 01:01:11.682, Speaker E: I would say one downside, and that has obvious upsides of there's no changes required at some level of the engine API. And so the status quo continues working. The downside is it effectively starts deprecating the minimal preset for anything but pure consensus back tests and they become even more this artificial kind of thing that can't be used in practice. So that's due to a number of considerations would actually capella exacerbates.
01:01:11.766 - 01:01:12.766, Speaker A: That's option one.
01:01:12.868 - 01:02:59.726, Speaker E: Option two, you can have the El somehow configured at startup because there's nothing fundamental about this number. I mean it's specified in the engine API, but you can just say, well, the engine API specifies some kind of, you can the next most general, and I'm ordering these in increased generality or we specific approach is to say the engine set says the els are given some configuration parameter that's basically very specifically this number of field elements and either it's a boolean or it's an integer or something and then you can just make that compatible with Cl. That's option two. Option three is there's an attempt to align things more broadly with the sort of idea of minimal and main. So don't specify this particular field, number of field elements say that, oh well, the El now knows about this notion of a preset, a minimal mainnet preset. So this is a little bit more elegant for what it is, but at the same time it's something that els haven't had to care about, and it's kind of strange in some ways that they should have to. And the fourth is a much more general purpose thing, and people have at some level, the argument here is this call already starts existing people have proposed it for capella, an engine API call that will sort of do kind of a configuration exchange, essentially not the merge one where it was just are we ready for merge, but just a more general purpose, what methods are supported and things like this.
01:02:59.726 - 01:03:09.860, Speaker E: So those are some four sort of example options, and doing nothing is also a choice. So that's why I wanted to bring up.
01:03:10.710 - 01:03:15.746, Speaker A: Thank you. Yeah, Mikhail, you already have your nap? Yeah.
01:03:15.768 - 01:04:44.626, Speaker B: I feel like the last option where the configuration is exchanged in runtime can create additional complexity of changing these parameters at the runtime. So basically one Cl theoretically can connect to El and set one number for this particular config parameter, then the other connects to it and yelp in general case have to support switching it over to a lower number or whatever. So that's definitely a complexity. On the engineering side, having this as the command line parameter, I don't know, or passing full specification of the Cl chain to yel probably doesn't make sense, because Eil really has nothing to do with most of those parameters. And I would say that this particular case is rather an exception than the common thing that we would like we will see in the future. Because here we have blob transactions on El side, which then included in propagating on CL side. So that's kind of like really looks like an exceptional case for me.
01:04:44.626 - 01:05:28.046, Speaker B: So if we are about to do anything with that, as you've said, there is an option to do nothing. I would choose less invasive and less engineering complex solution as possible. So yeah, that's kind of like my initial opinion on that. And also I have a question. What kind of devnets or testnets are we running with minimal preset? As far as I know, we have all of the devnets that we have for Shanghai and for merge and for other probably upgrades. They are running with mainnet preset. Correct me if I'm wrong.
01:05:28.046 - 01:05:56.040, Speaker B: So kind of like minimal presets more sounds like for the local machine set up or a small dev, not that having you're testing you some features and all this kind of stuff, and probably it's not that bad to have field elements set to a mainet number in that always. I don't know. So that's kind of like my initial opinion on that.
01:05:57.710 - 01:07:01.722, Speaker E: Yeah, I would probably agree. I'll say that certainly once we get to Barnabas has indeed what Barnabas said, but it is true that by the time we get to certainly anything publicly visible, the public testnets are all main net configs. I will just speak with Nimbus. I mean anecdotally runs cis, often with minimal, just preset as well as main net. But maybe what I'll say is this, the other aspect and another option actually is to change this particular field. And I think you mentioned this as well, or this is one of the things you say, but to kind of pull this out maybe least invasive fixes the issue in a lot of ways. Have the minimal presets just say that this particular parameter is the main net parameter so that we ensure that the engine API at least is not affected.
01:07:01.722 - 01:07:42.570, Speaker E: This affects minimal presets to some extent. Yes, it makes them a little less minimal, but it also means that this issue just goes away. Another thing that has come up, and I don't think Hive uses it, and this is different than what Barton just mentioned. But like you mentioned, Hive and Hive is certainly looking to run, for example six second slots when they can. Now there are different ways of doing this. One of them is you can take a tweaked main net preset and just change seconds per slot to six, and that does work. But we also have a preexisting preset which is tested that we have consensus tests and everything for it that is designed exactly to run quickly.
01:07:42.570 - 01:07:54.080, Speaker E: And so hype has found this idea useful as well. So I think there's some utility in the minimalist presets enough to not to want to get rid of.
01:08:02.750 - 01:08:23.940, Speaker A: Yeah, Gizinder has a comment in the chat about the KZG libraries have hard coded values for main net. I guess from this El teams. Does anyone have a strong opinion about this?
01:08:30.290 - 01:08:35.600, Speaker C: For base it's actually a little less work for us to only support the 40 96.
01:08:44.740 - 01:10:07.190, Speaker A: Anyone else? And there's a yeah, Alexa please. Sorry, I used to think that it is a fixed number and we will probably change only block count possible in a block, so no settings for that. And CKDG library does not support it, right? Yeah, I don't know, maybe Dan crab their proto is that a correct assumption that will only ever grow the number of blobs per block, but the 40 96 field elements per block. Blob will stay constant. Yes, that's pretty accurate. What do you mean, like forever? Say two years? Two years is my forever, right? In this case, I would not want to make this commitment. I mean, it's certainly like an option to long term also grow the blob size.
01:10:07.190 - 01:10:33.550, Speaker A: I mean, that's why we're doing four different versions of the ceremony, so that we can increase the blob size. Okay, and there's some comments on the chats now about just saying we can change the minimal preset value of just this for now. There seems to be agreement on that. So does anyone disagree for this specific preset value to just use the same as remainet?
01:10:39.930 - 01:10:42.150, Speaker E: I mean, I'd be okay with that personally.
01:10:42.490 - 01:10:51.420, Speaker A: Okay, great. So let's do that. If someone can do a pr on the CL specs to update this, that'd be great.
01:10:53.630 - 01:10:55.930, Speaker E: Okay, I'll make that pr.
01:10:56.080 - 01:11:27.922, Speaker A: Awesome. Thank you. Okay, next up, there was discussion around standardizing the transaction pool namespace. Wesley, are you on the call? Yeah, I'm here. Yes. Do you want to give some context about that? Sure, yeah. I drafted a proposal for standardized TX pool API for execution.
01:11:27.922 - 01:12:18.120, Speaker A: Clients already spoke to some folks at each of the client teams, as most already have some endpoints and got some implementation for it. But proposal is a way to hopefully find an agreement on a more common subset, which will be great for interoperability, obviously, but also allows hopefully for more reliable integrations, for example, CR or inclusion lists that are being discussed at mev boost, for example. Not too familiar with how this process work or how to best approach it, but I think you shared a link already in the chat. It's also in the agenda from today's calls. Yeah, I guess. Has any El client dev looked at this and have any opinions they want to share?
01:12:24.040 - 01:12:41.320, Speaker B: Yeah, Marek, I like all standardization efforts. However, I'm wondering if it is worth to change method names. Probably people got used to previous methods names and we could potentially break lots of tooling because of renaming.
01:12:44.480 - 01:13:57.304, Speaker A: Yeah, the rationale for changing it was actually for backward compatibility because each client currently has their own implementation. Changing that would more likely change existing integrations, but just setting up something new would at least avoid those issues. Can we do something like just deprecating? We can mark the old names as deprecated, have the clients alias both behind the scenes, and then eventually just remove the old ones from the spec. And I think there is precedent. I think there were some JSON RPC calls we did mark as deprecated in the past. I'm not quite sure which ones, but I remember having this conversation a while back. I guess probably in terms of next steps, if client teams just want to review that PR and leave any comments or leave like a thumbs up on it, that would be great.
01:13:57.304 - 01:14:36.630, Speaker A: And then, yeah, maybe we make this change just to deprecate the old APIs or mark them as deprecated in the spec. Yeah. Does that make sense to people? Any objections or other thoughts? Ok, so yeah, let's do that. Anything else, Wesley? No, that was. And then. Okay, so that's what we had already on the agenda. But Jared, you said you wanted to chat about self destruct.
01:14:38.250 - 01:16:33.798, Speaker F: Yeah, hi, can you hear? We had, I guess where I left off on self destruct was a last piece of analysis around the potential impact of EIP 47 58, which was the approach to just turn self destruct into send all and kind of the nuclear option, if you will, that would potentially, well, not even potentially, that would have backwards compatibility or would cause contracts to break. And since then it kind of seems like there hasn't really been a proposal that's come forward that has to me at least seemed actionable to pursue. So I think that what I'm wondering to get a read on from people in this call is whether we think it would be valuable to put more resources towards analyzing contracts that would be broken with EIP 47 58, under the understanding that we probably won't be able to find every broken contract, but uncovering more could be valuable. I'm just not sure if we have decided that 47 58 is completely untenable and to not pursue it, or it just is not very clear what direction to take here. So I just wanted to get a read from the community here if anybody has any opinions.
01:16:33.974 - 01:16:38.160, Speaker A: Yeah, thanks. Andrew has his hand up.
01:16:39.250 - 01:17:23.340, Speaker C: Yeah, I think there was another development. There is this IPA 60 48 proposed by exic, which might be less backwards, not as much backwards breaking. So it's more backwards compatible than the nuclear option 47 58. So I don't know the details, but I think we should contrast the two and have a deeper look. We haven't exhausted all the design options yet.
01:17:25.730 - 01:18:17.920, Speaker A: Right. So I've posted the EIP, it's 60 46. I've posted it in the chat. And the idea was that when you self destruct a contract, you just change the nons to basically the max nonce value. We don't delete the storage keys, we transfer out the funds, which is basically like sendal. And then there was this, I guess the biggest addition was that you would modify create two. You would modify create two so that you can actually redeploy a self destructed contract at the same address with different code.
01:18:17.920 - 01:18:55.980, Speaker A: But basically the check you do there is checking that the nonce is equal to this max nonce value. And there's a couple of comments in the chats about, like, we do have to disable self destruct, and we've sort of announced as part of Shanghai we're going to do it. So, yeah, I don't know if people have thoughts about this 60 46 approach or otherwise. We could maybe discuss that in more detail on the next call.
01:19:02.100 - 01:19:36.010, Speaker F: Yeah, it's been a bit since I looked at 60 46, but I wrote in the chat that at least as I recall last time, last I read, there were some concerns around by not removing storage slots, you're creating avenues for malicious behavior. And I think the example cited in the thread was gnosis safe. But yeah, I'll have to look back into that to remind myself.
01:19:38.860 - 01:20:09.956, Speaker A: Right. And this is different in self destruct now, which clears all the storage. So it's like you're resetting exactly new code with the old data and. Yeah, that could break. Yeah. Any other thoughts? I it. And back to maybe Jared's original question.
01:20:09.956 - 01:21:02.502, Speaker A: Is it worthwhile to try and do an extremely thorough analysis of all the contracts that would break on chain with the 47 58 proposal? Given we already know there are several that would break, and they're not trivial. It's not like two random contracts with less than one eth. There's a fair amount of contracts that would stop working. I'm not sure what the exact number is, but it's more than just a handful. Okay. So I guess not a ton of demand for the more thorough analysis. So maybe, yeah.
01:21:02.502 - 01:21:53.918, Speaker A: If in the next few weeks client teams can look at 60 46 or potentially think about different ways to approach it, we can continue the conversation in the next call or two. But, yeah, I think it's finding what's the least worse option. Okay, anything else anyone wanted to bring up? Okay, well, shall we just want to.
01:21:54.004 - 01:21:56.638, Speaker G: Comment on the change?
01:21:56.724 - 01:21:57.600, Speaker A: Yes, please.
01:21:59.730 - 01:22:56.930, Speaker G: So I think we've discussed it in the 44 breakout before. The reason why we have this preset is because pythec and python implementation is very slow compared to the production site. For example, we have a basic polynomial condiment proof generation and verification test, and it took less than 1 minute with minimal preset, but it takes like 28 seconds to run this test case. So that was why I really want to keep the minimal preset.
01:22:59.690 - 01:23:12.362, Speaker A: Right? Yeah. So it's like a 30 x difference. I don't know. Does anyone have thoughts about is this.
01:23:12.416 - 01:23:18.410, Speaker B: 28 seconds just for one test case or. There are like 100 test cases.
01:23:19.870 - 01:23:45.954, Speaker G: So it's only for this test case, but it's the pytest run, so the test generator will be faster than this. But still we use the minimal preset in our CI. So it will take this 28 seconds in the CI minutes, right?
01:23:46.152 - 01:23:53.910, Speaker A: Minutes, not seconds, no, I think it's seconds. So it goes from less than 1 second to 30 seconds.
01:23:55.290 - 01:24:05.510, Speaker G: Yes. And that's only one test case. One block. One block.
01:24:08.890 - 01:24:37.780, Speaker B: To be honest, 30 seconds running once, I mean, like even if it's run on CI, 30 seconds doesn't sound terrible. I don't know if we have like 100 test cases and multiple times 30 if we are jumping from minimal to mainet perception, yeah, that's something to worry about. But 30 seconds? I don't know.
01:24:43.290 - 01:25:08.320, Speaker G: Yeah, to be fair, we don't have many test case. I think probably less than ten test cases take the full proof generation and verification. But I do expect that we will add more test cases after the iterations and. Yeah.
01:25:14.450 - 01:25:36.786, Speaker A: Okay. So I guess given the small number of tests, should we just keep it this way or do we want to discuss this more? Maybe asynchron on the consensus specs on the CL call or. I'm not quite sure what's the best approach.
01:25:36.978 - 01:26:09.122, Speaker E: I'm happy to discuss it in general elsewhere. I guess we all know, without trying to get into mean sort of respectiveness of the execution in general, the fact that one question would be how much of this is an artifact for a particularly slow KZG implementation in the test runners, and how much is it really intrinsic to KZG? That is to say, how much is it fixable on a purely engineering side.
01:26:09.176 - 01:26:13.346, Speaker B: As opposed to a spec thing, this.
01:26:13.368 - 01:26:25.834, Speaker A: Is purely due to a slow implementation. Like this is because PI ECC is like 100 times slower than efficient implementations. Right?
01:26:25.872 - 01:26:51.730, Speaker E: I think this is an ugly enough problem to shunt into because it would immediately become both an engine and execution layer problem, or immediately during testing if it's a question of this can be optimized in some way. On the test runner side, that seems like a better overall investment for the ecosystem.
01:26:56.390 - 01:27:13.500, Speaker B: I think that we should start from setting the minimal to mainet value as discussed before, and see if it becomes really annoying. Then reiterate on that and think again. Probably we'll see some opposition in the PR.
01:27:17.790 - 01:27:52.880, Speaker A: Okay, yeah, I think that makes we, we can just make the pr for it and continue the discussion. Oh, and Dustin already has a pr. Great. Anything else to cover before we wrap up? Okay, well, thanks, everyone. And, yeah, talk to you all soon.
01:27:56.550 - 01:27:57.534, Speaker C: Thank you. Bye bye.
01:27:57.582 - 01:28:01.380, Speaker A: Thanks, everyone. Thanks, John. Thank you.

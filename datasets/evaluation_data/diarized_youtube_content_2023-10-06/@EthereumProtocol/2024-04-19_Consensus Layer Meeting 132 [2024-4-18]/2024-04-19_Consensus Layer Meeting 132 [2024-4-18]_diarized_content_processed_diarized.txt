00:02:03.434 - 00:02:34.274, Speaker A: Okay, let me just double check. Everything's working. Okay. It looks like the screen, screen transition. I don't understand why.
00:02:35.134 - 00:02:37.794, Speaker B: Also, Alex, your audio is quite bad right now.
00:02:42.094 - 00:03:08.168, Speaker A: But it's only like part of the window. I don't know. Tim, do you see what's going on? And do you know how I can fix this? So sorry. What do you see? So it's like only recording like the upper quarter of the zoom window and not the whole thing. Yeah. So like, let me open it. So when you have like a screen.
00:03:08.216 - 00:03:11.792, Speaker C: There, there's usually like a little red box that you can drag and drop.
00:03:11.848 - 00:06:02.010, Speaker A: To make, like to make it bigger if you, if you like, hover over. Okay, this is kind of good. Hey, everyone, sorry for the technical difficulties under streaming and let's go ahead and get started. Yeah. Fujifilm says to restart rbs. I think I'm going to leave it as is because I've also just had it be really delicate. So everyone, this is consensus call 132.
00:06:02.010 - 00:06:36.824, Speaker A: I need to find the agenda that I keep losing, but I promise we'll kick things off. Okay, let's go ahead and get started. It's really hard to hear me. Okay, can you hear me now? Came here now? Yeah. Okay. Underwater. Great.
00:06:36.824 - 00:07:35.758, Speaker A: Is it better now? Okay, maybe we'll try this is it. Spider, can you hear me now? I can't hear anyone. Okay, is this banger? Yes. I don't know why I've been having issues. Okay, can you hear me now? Is this, is this better than it was? The tire quality?
00:07:35.806 - 00:07:37.354, Speaker D: Just a lot more quiet.
00:07:38.614 - 00:07:46.654, Speaker A: I don't know, I'm like yelling at my computer. Okay.
00:07:48.394 - 00:07:49.634, Speaker E: Let'S go ahead and get started.
00:07:49.714 - 00:08:14.446, Speaker A: I think this might just magically resolve. This is what. I can hope so anyway. Okay, Electra, so the first thing to call out is we have a nice specs release of the initial pector specs. Very exciting. It's so quiet. Okay.
00:08:14.446 - 00:08:37.413, Speaker A: I don't know why I'm having these issues. It's fine now. You're the only one saying that though. Everyone else is saying they can't hear anything. Yeah, it's very, very quiet for me too. Let me try. Well, I feel like this is gonna explode if I try to leave them.
00:08:42.633 - 00:08:54.213, Speaker E: Okay, we have audio capture. Yeah, I think it'll.
00:08:56.233 - 00:08:57.133, Speaker A: Okay.
00:09:04.054 - 00:09:07.486, Speaker E: Something happens with my audio setup.
00:09:07.670 - 00:09:09.554, Speaker A: I don't know. I don't know what's going on.
00:09:10.294 - 00:09:41.010, Speaker E: Anyway, let's go ahead and get started. I'm assuming you guys can all hear me now and I'm praying that the stream is working. Either way the first thing was Electra. And so let's see here. We have the initial specs release, which is very exciting. I don't have a link handy but I can go get one in a second. But yeah, so Alphazero is out and the idea is this is an initial target for Devnet Zero.
00:09:41.010 - 00:10:27.914, Speaker E: So thanks to everyone who was involved with getting that out. Special shout out to Shawe and Francesco with help with the testing. But yeah, it has the four eips that we've included in Petra and should be a stable target for you guys to go ahead and start implementing. So yeah, super exciting. I did want to call out, there's this question of how we're doing consolidations in Max EB and it looks like what we're probably going to do is have them be initiated from the El. And right now the way they're written is they're originated from the Cl. This is fine because most of the processing logic that the beacon chain will need is going to be the same regardless of the source.
00:10:27.914 - 00:11:28.124, Speaker E: But if you drill into the specs, you'll see there's not really anything written down around how validator could initiate them. I think the plan is generally for our initial devnets just to kind of have someone hack something together just locally to inject some operations to do this, but otherwise not worry too much about building out like an operation pool, ghasa for these operations and all that, because we're very likely in Devnet like one, two, three, move into like an execution source for them, just like 7002. So I just wanted to call it out. If you find that part confusing, it's because it's a little weird right now. So otherwise, yeah, let's see, the spec is out, there's test vectors and. Yeah, so nice work everyone. Next up, there's a number of questions around different eips, different parts of the spec.
00:11:28.124 - 00:12:10.774, Speaker E: We'll just move on to the next one. So there's this question of how to handle the NEB attestations at the electric fork boundary. So EIP 7549, this is the one that's like changing how attestations work. And we'll get in the situation where the last epoch of Deneb will that decisions made in that epoch will be includable according to the spec, into Electra. But the way that you make them into net is not compatible with how you make them in Electra. So we need some way to handle this and I wanted to bring it up just to see what everyone's thinking. There's a couple options.
00:12:10.774 - 00:12:42.944, Speaker E: Or maybe I'll just stop there. Does everyone understand the problem? Okay, we got a thumbs up. If you don't, it'll probably become clear, as we discussed. But there's a couple things we could do. Like, one of them is just do nothing on mainnet. Most people get attestations in pretty quickly. And so like, you know, if we're at max performance, then really it's just like attestations in the very last slot of Deneville would have this issue.
00:12:42.944 - 00:13:28.896, Speaker E: And that's not ideal, but it does mean that the specs can stay as they are and it simplifies everything else, because then we get into the other options where we do something to handle these attestations. Probably like the most comprehensive solution is that we just keep another spot in the block for all of Electra for the sort of the Genev style attestations. We could do this. It's just now there's this extra list that's there for just a few slots. So, yeah, it's just more code to maintain. And the questions like, what do we really gain for it? Yeah, there's other solutions. You could imagine clients try to broadcast both.
00:13:28.896 - 00:13:58.284, Speaker E: Or you wait, if you know that you're at the end of DNAB and if you don't see your attestation get on chain. Oh, I mean, yeah, then I guess it's a question of how you do this, because you could imagine trying to broadcast, if you don't see it included on chain, then you rebroadcast. But then there's like slashing concerns. You could just wait, maybe say halfway into the epoch. There's like some design space here. Has anyone here looked at this? And do you have any opinions on the path forward?
00:14:01.344 - 00:15:04.996, Speaker A: Just a quick note. If it only like, if we use the same field of the same attestation field in the block, we need to understand that max attestations per block is going to be reduced significantly. So those are, attestations are not packed into more tight aggregates that we use for with the CIP since electra, then they will probably not be accommodated. There will be not enough log capacity for that. So it's probably, it probably makes sense for the last, if we want to do anything with that. It probably makes sense for the last slot of the last slot of the epoch before electric epoch, which is to make them signs. Yeah, just to make this, you know, index set it to zero.
00:15:04.996 - 00:16:15.152, Speaker A: So make an electro like electro attestation instead of the den of attestation. I don't know what other implications are having these, you're talking about the option suggested by the appliance to wait a couple of epochs before setting everything to zero. Is this what you're talking about? No. If we take this option we should understand that if we don't aggregate them, so we have like basically we'll have eight attestations instead of 120 per block at max. So we probably won't be able to put 64 attestations from the previous. Yeah, that's, yeah, I haven't thought about that implication of doing that. So it won't work at the end for other reasons.
00:16:15.152 - 00:16:15.884, Speaker A: Right.
00:16:25.244 - 00:16:25.700, Speaker B: Okay.
00:16:25.732 - 00:17:08.524, Speaker E: So one option would be you have custom code in your client to basically say within the last slot, but maybe the last like half epoch. Like there's some parameter here. Basically you would set the committee index to zero. And the reason you do this is because then you can, you know, independent of having the validator touch anything, who makes the attestation, you can repackage the old format into the new format. So that works. You know, there's implications around, I think, some of the DOS protections for attestations because they assume the committee index is, you know, a certain thing, but might be fine. Yeah.
00:17:10.664 - 00:17:15.884, Speaker A: So are we concerned that much if we just lose the last slot? We're.
00:17:17.944 - 00:17:46.740, Speaker E: I think not, but the question is like more about attack scenarios. So like you know, let's see. Yeah, I guess if you just ignored them. I mean yes, this is like the do nothing approach and it might be fine enough. So that might be the path forward right now is, you know, the way the specs are written, it kind of assumes that this is just. Yeah, you ignore, you ignore the ones that don't make it in time. And if we do this then that might be fine.
00:17:46.740 - 00:17:57.708, Speaker E: And then we can kind of analyze, you know, different attack scenarios further down the line and see if we need to harden this. But that sounds like a good path forward for now. Does anyone?
00:17:57.756 - 00:18:10.024, Speaker A: Yeah, because, yeah, because if you, those other stations will be applied to the fortress anyway. So which might be a big problem. Right.
00:18:10.364 - 00:18:23.744, Speaker E: The one concern would be if there are many, like if there is an attacker who tries to delay for some reason, then they wouldn't go on chain and that could impact justification. So there could be some like weird finality delay around the fork if someone is really motivated.
00:18:24.604 - 00:18:33.812, Speaker A: It's also worth to keep in mind that those attacks are highly attributable in a way. So like we can easily tell who, like basically who's doing that.
00:18:33.908 - 00:18:39.464, Speaker C: I'm not saying that should be the reason not to do it. But that, that's just one point of note.
00:18:43.224 - 00:18:53.404, Speaker E: Right, okay, well, it sounds like, I mean, especially for Devnet zero, we'll just keep it as is, which is basically ignore the issue. Oh yeah, Sean.
00:18:55.144 - 00:18:58.800, Speaker C: So I saw deadline. How about the comment here? I don't know if this is what.
00:18:58.832 - 00:19:01.480, Speaker A: Enrique was referring to, but to me.
00:19:01.512 - 00:19:14.634, Speaker C: This looks like essentially like a slightly better version of doing nothing because it's not like we couldn't fit any pre electra attestations in. We would be able to fit up to like whatever the new limit is.
00:19:17.614 - 00:19:20.634, Speaker A: The limit is quite low though. So.
00:19:21.334 - 00:19:21.814, Speaker C: Right.
00:19:21.894 - 00:19:35.524, Speaker A: In the best case you can accommodate like seven attestations per block, considered perfect aggregation, and just use just one, one slot for the attestation and current. Talking about the attestation from.
00:19:37.064 - 00:19:42.684, Speaker C: So, but like, isn't this just very similar to doing nothing but like slightly better?
00:19:43.984 - 00:20:27.104, Speaker A: But then you have to deal with the complexity of doing this translation in the code to gain maybe very few arguments in terms of security. So it's made slightly better but less effective in any case. So maybe nothing better. Actually, things will be good in terms of backgrad. So the first epoch of electro will accommodate all those attestations from the last slot. There will be enough capacity to do that.
00:20:36.204 - 00:21:21.064, Speaker E: Okay, so let's do nothing for now. And we'll just keep in mind that we'll probably want to look at this a little bit more closely and consider different options. But yeah, this seems like a good path forward and generally just have this everyone's radar. If you weren't following, please go take a look and yeah, we'll revisit it later. So the next one is a new EIP 8432. And this EIP essentially wants to think about how we are moving messages from the EL to the Cl. So right now with 6110 we have deposits, with 7002, we have these withdrawals.
00:21:21.064 - 00:21:37.384, Speaker E: We're likely adding this sort of consolidation message from the El. So we have all these things proliferating and the question is like how do we want to structure this in the execution layer? So this eips from lite client, do you want to maybe give a little overview?
00:21:42.804 - 00:21:43.544, Speaker A: Sure.
00:21:44.524 - 00:23:08.770, Speaker C: Basically the idea is that on the execution layer we have generally not added lots of things to our block body and you know, kind of our block header. But with these new messages that we're trying to propagate from the El back to the Cl, the sort of template has been put a commitment of all of those operations in the header, put a list of them in the body and extend those data types. And so what this proposal is trying to do is simplify the way that we do that so that we don't have to continually extend these data structures, which at least it feels on the El side is pretty manual task of updating many, many code sites where you're dealing with these and put it all into a single type. So we're reusing the same machinery that we have for the transaction types, which is prepending a single type byte in front of the RLP encoding of the transaction. Use that as a discriminator to figure out what type of transaction you're dealing with, and then parse out the transaction data from that. It really doesn't have a lot to do with how things are processed in the CEO. I think it would just be good to get thumbs up from any EL teams here.
00:23:08.770 - 00:23:53.142, Speaker C: It seems like it's had a reasonable reception and then get a thumbs up from CL's that it's okay on your side that maybe these data structures aren't mapped one to one. Because right now on the spec for spectra on CL side, these messages are individual lists within execution payload. So if you wanted to have things analogous across the two layers on the CL, maybe what you would have is you would have a union of requests and you would put every individual request type that. To me, it's not really important. It's whatever you guys think is the best way of doing it. Yeah, so I guess I can stop there. Any questions or thoughts if that seems.
00:23:53.158 - 00:23:54.434, Speaker A: Like a reasonable idea?
00:23:57.494 - 00:24:18.244, Speaker E: So I think we would want to try to keep the layout the same across El and Cl as much as we could. And so, really, like, I generally think this is a nice idea. The only thing is, you know, if we need to go change a lot of the structure of the V zero specs, it's going to kind of delay us getting to the Devnet.
00:24:20.624 - 00:24:53.644, Speaker C: I just don't want to put a lot of work into something that we already feel confident that we're going to change again. Like, we can have the specs ready by tomorrow. We just have to have people decide. And I think this is still, this is much more of a cl or an El issue to resolve. I think this is Justin here from Basu. I think that we recognize the need for this. It seems sensible.
00:24:53.644 - 00:25:44.342, Speaker C: The implementation looks good. I haven't had it open next to the code to actually take a look at the implementation overhead yet. My gut says it's fine, but I would like to have a chance to actually do that before making a stronger commitment. Do you guys have 6110 or 7002 implemented. We do have 6110 implemented and 7002 is about half done. Okay, so I think the main diff between what is done right now and what would need to be done is you would have to go in and replace the exits or, sorry, the deposits that you've added to the header and the body, replace it with the requests type and then implement the request type. So the rework that would be done is just renaming and retyping that value in the header.
00:25:44.342 - 00:26:13.288, Speaker C: The reason I like bringing this up, try to bring this up now, is that if we add 7002, if we add consolidations, then we're starting to look at bigger refactorings of. Okay, we've added three things to the block header, three things to the block body. We gotta go and delete some of those. We gotta retool them into this single type. So it feels like if we've only implemented 6110, it's a lot faster to fix that up than down the line. Yeah, fixing 6110 from our current implementation would be negligible.
00:26:13.336 - 00:26:16.880, Speaker A: There's no big deal there. I don't wanna put you guys on the spot.
00:26:16.912 - 00:26:47.354, Speaker C: Like, you can take a look at it offline. I just wanna try and get this decided by tomorrow so that we can get this backed out. We can chime in async. In terms of waste work, it seems like especially if we end up adapting this in the long term, because it saves a lot of long term complexity. It doesn't make sense to not adopt it in the near term to save, I guess, part of an initial devnet implementation.
00:26:53.294 - 00:26:53.630, Speaker A: Yeah.
00:26:53.662 - 00:26:54.006, Speaker E: Terrence.
00:26:54.070 - 00:27:10.394, Speaker A: Terrence, do we need to come to consensus on whether this request type are inside the payload or they are outside the payload by kind of like a, kind of like an envelope format? Do you guys have thoughts on which direction is better here?
00:27:12.694 - 00:27:25.132, Speaker C: It feels like it would go in the payload, but it's not really something that I feel strongly about. So if people think it needs to go in the envelope because you're not going to put it in the actual payload type on the CL, then we.
00:27:25.148 - 00:27:33.396, Speaker A: Can do that like this.
00:27:33.460 - 00:27:36.772, Speaker C: The zip allows the flexibility. It doesn't prescribe that, it must go.
00:27:36.788 - 00:27:38.144, Speaker A: In the execution payload.
00:27:46.104 - 00:28:26.878, Speaker C: Okay, sounds like people will review this offline. Generally positive sentiment. The one question that I think is pertinent to maybe ask here is are there thoughts on how you would like to deal with this from the engine API? I also want to cut this spec tomorrow or Monday. And on the engine API side, there's two ways that we could go about it. I wrote it in the PM issue if you want to take a look. But the two ways are basically we extend the execution payload or the envelope, whichever one people prefer, with each individual request type. So there would be a deposits list, there would be an exits, partial withdrawals list, a consolidation list.
00:28:26.878 - 00:29:14.174, Speaker C: Those are individual elements, and those individual elements have only one type of request, the named request that the list is named after. So then on your side you would parse that out, put it into the payload, put it into the block or the envelope, however you need to. That's one possibility. The other possibility, which is slightly simpler for the EL, but I think it's kind of negligible. We add one additional list, either in the envelope or in the payload called requests. And those requests have several different request types that could live within the list. And so you would have to look at the JSON field type and determine what type you're dealing with and then parse out that data based on the type field.
00:29:14.174 - 00:29:21.974, Speaker C: Is there any feelings on either way for that so that I can look at putting that into engine API?
00:29:28.294 - 00:29:30.902, Speaker A: Not a super strong preference, but I.
00:29:30.998 - 00:29:35.554, Speaker C: Feel like deserializing is generally easier when you know what you're expecting.
00:29:36.734 - 00:29:40.034, Speaker A: But yeah.
00:29:43.414 - 00:29:49.438, Speaker C: I guess nothing would stop it either from being an array of arrays separated by type.
00:29:49.486 - 00:29:50.074, Speaker A: But.
00:29:52.654 - 00:30:33.112, Speaker C: I think we could do either. But just in general, DCRL asking is easiest one to type. Okay, that's one leaning slightly towards just having individual lists of request types. Yeah, basically it probably doesn't care. I think I have a loose preference for individual request types. Okay, I think that's enough for me to go ahead and get started. Unless someone feels strongly against that.
00:30:33.112 - 00:30:40.404, Speaker C: I'll get a spec out for that there tomorrow. People can review it and then let's solidify it on Monday.
00:30:47.284 - 00:30:48.664, Speaker A: Okay, great.
00:30:52.084 - 00:31:10.704, Speaker E: If there's anything else on that, we'll move to the next item here. So there's a suggestion to rework EIP 7549, essentially to make the on chain aggregation more flexible. Mikael, this was your pR. Do you want to give us an overview?
00:31:11.844 - 00:32:13.754, Speaker A: Yeah, thanks, Alex. So, quick overview. What we're doing here is basically from committee bits, so to committee indices. And this allows to the same, the same aggregate to have in one aggregate, there can be, in one chain aggregate, there can be several network aggregates from the same committee. I noticed that this is quite common situation where a blog contains several aggregates from, from the same committee from the same slot. This is something that is constantly happening on the main app. And this, this proposal is kind of like as more makes this more like more room for more aggregates from, from the same committee.
00:32:13.754 - 00:33:04.922, Speaker A: So what's the problem with like 7549 is that it reduces the max obligations from 128 to just eight, which means that in theory, the max number of aggregates from the same committee that can be accommodated by one block is eight. So you can do more. And if we want to more. If this is something desirable, we can go this path. And yeah, just allow basically one on chain aggregate, have several network aggregates from the same community. And for this we need to switch from community bits to community indices. This is the way, one of the ways to do it.
00:33:04.922 - 00:34:04.896, Speaker A: So the first question is whether it is really needed. Probably potentially it can help with in the case of bad network conditions, there are many aggregates received from the same committee and we want to accommodate them. But actually eight is already pretty good number. I don't know. So the first question to CEO and ask is basically, is this is like having this limitation any cause, any sort of concern? Do we want to do something about it? Do we want to make it more flexible? And yeah, if we want, then we need to decide on the, how we keep committing. This is basically what number of bytes will, what type we will use. So basically, commuting index feeds into one byte at this moment, because we have six max.
00:34:04.896 - 00:34:42.003, Speaker A: And if we use community index data type, there is the data overhead. So it is not significant. But yeah, we could make it as complex in terms of data as feed factor by using just one byte, by using unions eight. The problem here is that we don't have union eight in the stack. And I don't know why we try to not introduce more unit types. So that's basically the overview of this proposal.
00:34:45.263 - 00:34:51.847, Speaker E: Okay, thanks. I believe there is a un eight defined. It just might not be used, but there definitely is one.
00:34:51.935 - 00:34:52.603, Speaker A: Yeah.
00:34:54.243 - 00:35:08.623, Speaker E: Yeah, I guess I have a couple questions. Like, if eight, if having like max attestations at eight is an issue here, like, could we just go to 16 or like some bigger number? And does that. That would help, right?
00:35:09.643 - 00:35:21.764, Speaker A: Yeah, that could help. But if we go to a bigger number, then we should accept the fact that block size, like theoretical block size, theoretical increase.
00:35:23.784 - 00:36:02.944, Speaker E: Right. Would go up. You had a really nice, yeah, you had a really nice chart in the pr looking at like this issue that you brought up with having kubiti indexes be eight bytes versus the, you know, type packing of the bit field that we have now. And what I didn't like was with the U 64, you get to a place where, you know, at like a million validators, it seemed like the size of the attestations would like pretty much be the status quo, which that was like an attractive benefit to the CIP is that the attestations on chain would get much smaller. Do you, am I interpreting the chart correctly? I guess is the first question.
00:36:06.924 - 00:36:20.654, Speaker A: Yeah. So you mean like, so the size is pretty much the same as with the status quo, but it can accommodate for more, uh, attestations, like from. For more committees, for more slots.
00:36:22.114 - 00:36:25.090, Speaker E: Okay, I see. So you can still have them more densely packed.
00:36:25.162 - 00:36:25.490, Speaker A: Okay.
00:36:25.522 - 00:36:26.298, Speaker E: So that helps.
00:36:26.386 - 00:37:25.714, Speaker A: Yeah, yeah, yeah, yeah. So we could use like where in the original EIP. Yeah. In the original proposal, there was an analysis of like different max attestations and basically to accommodate the same number of committees if we consider ideal aggregation. So we could have max attestations that to, which means that. Yeah, basically one attestation slot can accommodate for one slot worth of attestations received from the wire. And here we can just basically increase the number of slots, increasing the capacity of the block, which also basically helpful in the case of bad network conditions because you can accommodate for more slots in one block.
00:37:28.374 - 00:37:43.984, Speaker E: Right. Francesco had an interesting question in the chat. Like, is there some way to use a smaller type for there being multiple committees rather than have eight bytes per committee index? Could we again somehow pack that down a little more tightly?
00:37:47.164 - 00:37:47.980, Speaker A: Just to clarify?
00:37:48.012 - 00:38:04.844, Speaker F: I mean, let's say we want to say, I don't know, at most eight attestations per committee, then we could just use three bits per committee and just like where the thing that we encourage is the multiplicity, like how many of them there are instead of the community index.
00:38:07.504 - 00:38:54.624, Speaker A: Yep. But I think that if we want to do something like that, then we could probably use unint eight, which is really quite close to using a bit vector, which is one bit, I mean, like quite close in terms of data complexity. Yeah, but something like that is also possible. But again, this is if we want to accommodate for, you know, for more than eight aggregates from the same quantity. I don't know. This is more a question to those who want to hear the chain and see all the else. Is it like anyhow a problem?
00:38:59.684 - 00:39:34.284, Speaker E: Okay, well, so it sounds like to move this one forward, everyone is now aware and it sounds like something we won't decide today might require a little more analysis, but otherwise, yeah, nice work, Mikael. And I think that's that. Unless anyone has any other comments. So in that case, Mikael has another EIP or, sorry, another pr to update part of 7251. Do you also want to give us an overview of that one?
00:39:35.344 - 00:40:43.926, Speaker A: Yeah, so it is more related to 6110, but it anyway leveraged on 7251. Pending deposits, pending balance deposits here. So the original, yeah, the reason for, you know, the original reason for having this proposal is basically the 6110 removes the invariance that the pub key and the pub key and index, yeah, the index of other corresponds to pop key and this basically never changed. So that was because before 6110 we have this large follow distance, so no reward is possible beyond this follow distance. Like no real work is visible beyond this follow distance. So we kind of like having this invariant and 61 ten breaks it. So client implementations will have to make this upkeep scale cash fork aware.
00:40:43.926 - 00:41:34.794, Speaker A: So on two different forks, the same index can correspond to different top keys. This is something to handle in implementations. And the idea was basically to have a deposit flow deposit queue explicitly in the state, to have it first finalized and then apply. And then after these deposit queues finalized only after this point, start applying deposits, start creating new validators. And in this case it also means that we are processing top ups after they've been finalized. So a bit of analysis here. So I already mentioned the implementation complexity that can be alleviated.
00:41:34.794 - 00:43:00.494, Speaker A: The other things are in this pr, the signature check happens only when the deposit is being applied. And since the number of deposits are limited by the activation churn, number of deposits processed per epoch is limited by the activation churn. We have a limit, natural limit on signature verifications per epoch, which is also kind of nice because it helps to alleviate the attack vector where someone just packs thousands of deposits in a block. And with, yeah, before this pr, 1000 signature verifications would need to be processed in this case. Yeah, this stack snare is kind of like really not that realistic though, because it really has a high cost. Yeah. Also with this approach we can get rid of the activation eligibility bug, which means it just becomes there is no use for this field in the binary record, so it can be repurposed in the future if it matters.
00:43:00.494 - 00:44:05.564, Speaker A: Yeah, and the side effect is that top ups needs to be finalized before they can be processed. I don't think it's a big problem. Probably it has some positive outcomes in case of inactivity leak and these kind of situations, so no one can bump their portion of staple with respect to the total amount of stake. And. Yeah, so the problem of this queue that it will need to keep more information, more data than it is in the original 7251 proposal. And yeah, this, this is kind of like 176 bytes of additional data per every deposit slot. I would say that before 7251 it would not be a problem because all this information that is coming from deposit contract, either you create a new validator.
00:44:05.564 - 00:44:59.026, Speaker A: So you basically hold most of this information in the state. So the state will grew significantly. But since in 757251 we have, we have the switch to compounding credentials while making a top up, then we probably have a lot of top ups doing this switch and for top ups this extra information is basically not needed. So it will just waste more space in the beginning state. But yeah. So to highlight the data complexity with 100 letters, you. Yeah, also I mentioned that the deposit processing is limited by the activation churn.
00:44:59.026 - 00:45:22.714, Speaker A: So if we have like 100 batteries, 100,000 batteries in the activation churn, it will mean that this deposit queue is quite full and it will consume around 8018 megabytes of data. I don't know how big of a concern it is. So that's kind of like overview of this proposal and pros and cons.
00:45:24.614 - 00:45:49.454, Speaker E: Yeah, thanks. That was thorough. I haven't had a chance to look at the PR specifically, but yeah, I mean I think you're reasoning this sound and it sounds like something we probably want to do. Unless. Yeah, there are some complications with either data complexity or something like that. Once we start to dig in. I don't know if anyone else here has had a chance to look and has any thoughts.
00:45:53.314 - 00:46:21.144, Speaker C: So I looked at it a little bit. I think it's probably worth doing or at least continuing to explore. But I will say we've merged some changes until we're working on some changes in lighthouse to make the finalized versus unfinished pub key cache difficulty, like more simple so that I don't want to overweight that deciding on this. I think this has like solid features otherwise though.
00:46:25.124 - 00:46:26.784, Speaker A: Okay, cool.
00:46:27.804 - 00:46:40.884, Speaker E: So yeah, again I would just say, everyone keep it on your radar. I don't think we'd necessarily try to get this in for v zero, but you know, it'll, assuming we want to put it in the picture, then it'll come down the line.
00:46:46.664 - 00:47:27.224, Speaker A: Cool, thank you. By the way, a small note Francesco suggested and said basically that the activation of legibility book like to make it no use for deactivation or visibility, but we can basically add just an epoch to the pending balance deposits skew and do this by analysis. Do process the do increase the balance after it gets finalized. So this is doable with much less data complexity. Okay, great.
00:47:30.464 - 00:47:39.484, Speaker E: Next up we have a suggestion for yet another EIP. Perry, are you on the call, or maybe Tony.
00:47:39.904 - 00:47:50.484, Speaker B: Yes. Do you want to introduce it or should I?
00:47:52.904 - 00:47:57.604, Speaker E: Well, as far as I know, it's just suggesting we bump up the bomb count at Electra.
00:47:58.384 - 00:47:59.104, Speaker A: Exactly.
00:47:59.184 - 00:48:34.394, Speaker B: That's pretty much it. That we conduct a bunch of tests and a simple blob increase so that any focus from or any time that the client does have can be focused on pure dust research rather than anything else. And yet we're signaling that we offer some amount of scalability this year or some amount of increase based on how well the testing goes. And it's also tied to potentially including Tony's EIP. That also increases our headroom.
00:48:35.854 - 00:48:38.994, Speaker E: Right. The one that would change call data cost.
00:48:39.894 - 00:48:40.230, Speaker A: Yeah.
00:48:40.262 - 00:48:41.894, Speaker C: Okay, exactly.
00:48:41.974 - 00:48:56.514, Speaker E: And when I looked, this EIP did not suggest a specific number, but more. This is just kind of signaling today. And then as things unfold, as we get more main net data, we'll be more comfortable with a particular number by the time we get to Electra. Is that the idea?
00:48:57.094 - 00:49:07.950, Speaker B: Exactly. And that most of the testing and figuring out the number part can be done independent of planning teams or not completely independent, but mostly independent of teams.
00:49:08.102 - 00:49:08.794, Speaker A: Right.
00:49:09.734 - 00:49:31.834, Speaker E: Okay, cool. I think this is really nice to have, like, yeah, we'll see how pyrados shapes up. I think we'll chat about it towards the end of the call if we have time. But, yeah, I think our base case should be bumping the ball counts up, at least for Electra, once we figure out how to do that safely. Osbar, you have a hand up?
00:49:34.254 - 00:50:25.134, Speaker B: Yeah, I just wanted to briefly mention, I agree that I think it's a good idea, especially eap. That's kind of the worst case normal box. So we have some headroom and we also had this kind of alternative eap couple, like, I think two calls back, 7659, although I think that's not yet much, which would do kind of a similar thing, but with a gradual increase. I think the situation is more complicated by the fact that basically electron might or might not be in principleship together with PF already. How much we would want to increase depends of course, on this and depending on how much we want to increase, I think that difference whether we want to have a gradual increase or just one time. So I think it makes sense to basically have those two kind of alternative eaps out there. So we kind of decide closer, closer to.
00:50:25.134 - 00:50:54.692, Speaker B: I think it's more important that we just say, hey, some sort of lobby increase will be, will be part of Elektra. I just want one thing to flag. If we end up going with a simpler kind of ERP, that power just presented. There's a one time change necessary to the way we do the blob base fee, um, adjustments. So in our kind of initial EfE, we can bundle those. But I might pull this out. It's a really small adjustment, but basically we would just want to make sure that this kind of 12.5%
00:50:54.692 - 00:51:22.514, Speaker B: maximum change of the, of the, of the blob base remains the same and can't be. Unfortunately, the quirk of how 544 works, that if we increase the number of blobs, then basically that, that adjustment factor also increases, which that's not, of course, not wanted. So you have to make one time change to keep it constant. The block count though, if we, if we don't bundle this, then it will be a small separate, but it's, it's a, it's a one line change. Just wanted to mention it.
00:51:23.014 - 00:51:26.114, Speaker E: Right, thanks. Okay, yeah, that's good to keep in mind.
00:51:30.494 - 00:51:30.966, Speaker A: Cool.
00:51:31.030 - 00:51:59.464, Speaker E: Okay, thanks for that. We will scale the blobs with electra one way or another. I wanted to take a few minutes just to do a temperature check. So the alpha zero specs are out. Um, there's quite a lot in there. How are client teams feeling implementation wise? Um, it could be that you haven't really had a chance to dig in too deeply. I know last time we discussed and like, different teams had different amounts of progress on different, of different subsets of these vip's.
00:51:59.464 - 00:52:20.154, Speaker E: Um, does anyone have a status update there? Do you feel good about it? Do you not feel good about it? Any thoughts like that? The context being we would like to get to Devnet zero, say like the next month. So yeah, there might be quite a bit to do.
00:52:24.934 - 00:52:25.914, Speaker A: Yeah, Sean.
00:52:26.974 - 00:53:15.544, Speaker C: So yeah, I think in the next month we can do that. One thing is related to the generalization of the execution layer, triggerable true bowl requests. If we include that in Devnet zero, that would be better for us because it's like right now we're implementing three different eips that might change this, and we might be implementing those just to target the devnet, whereas then we'll use the generalized format in the future. So just a comment. I sort of feel like if we included that in Devnet zero as opposed to just strictly what our current targets are, that would be beneficial.
00:53:15.664 - 00:53:21.684, Speaker E: Right? Yeah, I agree. And this is what my client was proposing with combining all these different request types.
00:53:23.064 - 00:53:23.640, Speaker C: Right?
00:53:23.752 - 00:54:01.764, Speaker E: Yeah, I agree. Okay, cool. Okay, so let's see. I think that's it on electra. Is there anything else we want to discuss right now. Okay, looks like no cool. Next up, some different spec and research topics to discuss.
00:54:01.764 - 00:54:14.112, Speaker E: One thing just to shout out, there was a post by Anders around issuance. I think he just wanted to bring us to everyone's attention. I'm not sure if he's on the call, but.
00:54:14.208 - 00:54:15.048, Speaker G: Yeah, I'm here. Yeah.
00:54:15.096 - 00:54:15.568, Speaker A: Oh great.
00:54:15.656 - 00:54:17.684, Speaker E: Do you want to give us a little overview?
00:54:18.384 - 00:54:56.820, Speaker G: Yeah, just 30 seconds or something. So I was back in January, I was on the call and highlighted an introduces post that I've written where I sort of discussed bios, relevant properties of issuance level that we need to consider when changing the reward curve. And now I finished a new research post that argues a little bit more deliberate for change to the reward curve. And so I would just like to encourage researchers to take a look at it. And so in this post I go into a great detail concerning many trade offs that we must balance. Example conditions for super stakers, the composition of the staking set, economic security and discouragement attacks, etcetera. And so also I will link it in chat.
00:54:56.820 - 00:55:12.584, Speaker G: And also yesterday I put up more sort of an educational post explaining the foundations of minimum viable issuance. And so I will try to write some more educational material in this manner, also directly toward the community because I think it would be important as well.
00:55:15.884 - 00:55:16.864, Speaker A: Yeah, great.
00:55:17.374 - 00:55:19.834, Speaker G: Yeah, there it is.
00:55:21.654 - 00:55:29.274, Speaker E: Okay, excellent. So yeah, everyone take a look and we'll just keep the conversation with issuance going.
00:55:32.974 - 00:55:33.714, Speaker A: Great.
00:55:37.414 - 00:56:16.406, Speaker E: So next up we can turn to peer Das. There was a particular request here. Let's see. I don't know if age is on the call, but essentially there is a question around some of the details around mapping peers and their node ids into which subnets they're on. And I think this kind of touched this network shards refactoring that has been floating around. This has implications for peer Dos and how you would structure yourself in the network to do the sampling and also the distribution. So yeah, I don't know if anyone who's been engaging with that issue is on the call and would like to bring up their questions.
00:56:16.406 - 00:56:17.634, Speaker E: Oh, here we go.
00:56:18.334 - 00:56:55.484, Speaker H: Yeah, I can have, say a few words. Yeah, so there's, there's multiple aspects of this. One's part of pdas, one's part of just Mainnet as it stands with the data station subnets. Essentially the spec as it stands has a kind of a mistake from when we first did it. Mistakes were not the best way. There's an improvement where we can use the first bits of the node id to map to the attestation. Subnets, which allows us to hopefully improve discovery.
00:56:55.484 - 00:57:48.334, Speaker H: So I've been trying to get this in for a while, but there's now added complexities when we extend this into peer Das. The main reason I'm pushing for this is because there's two main reasons. One, I would like to just move ahead in Lighthouse in Mainnet, just doing a simple version of this, and then we're also prototyping for peer Das to have it as a foundation for peer Das. When we get down to peer Das, we're going to have to add another pr anyway to formalize the actual mapping. But if we can, I just mainly want to get all of the consensus client teams to at least have a look at it. And I haven't heard of any strong opposition so that we can start prototyping with pdas and actually just put this into main. It's entirely backwards compatible, but if all the client teams agree, then it just becomes more efficient.
00:57:48.334 - 00:58:30.774, Speaker H: The offers like there is some technical challenges with pdas, but as far as I can tell we can, if we put in a minimal version now, which potentially doesn't have rotation, we can add another pr later that adds the complexities for peer das. But mainly I just want to put it into Lighthouse now, get everyone to agree and then everything is efficient for Mainnet and it's also we can start prototyping for pdas. So I guess if you haven't seen this pr before and you're a consensus client team, just please have look and have a strong position. Just let me know before you start building it or going too deep down that path. That's about it. Thanks.
00:58:33.594 - 00:59:21.854, Speaker E: Great, thank you. Has anyone had a chance to look at this? Any other seal teams sounds like not yet, but yeah, please take a look. And it sounds like this is direction we want to go in. So let's make it happen. Okay. I think otherwise that was everything on the agenda. Is there anything that anyone else would like to discuss right now? The other question.
00:59:27.234 - 00:59:41.614, Speaker B: So I wanted to clarify, what's the current status of inclusion list Eap? Because it was, we had some reservations on the Yale side and I'm not sure what the end result was.
00:59:42.424 - 01:00:20.914, Speaker E: Right. Yeah, this was one other thing to discuss. So I think on the last execution call, yeah, there definitely were some reservations and I think I was essentially going to see if anyone wanted to bring it up to discuss on this call. It sounds like to me there are some concerns around implementing it, especially in light of account obstruction. I don't think anything's really changed there, but yeah, I mean, we didn't want on the call, like, to get into this eIp. I think we. I think it was CFI, but also at this point, we have quite a bit in publish already.
01:00:21.374 - 01:00:29.470, Speaker B: I think it was even included. That's why I'm raising this. If it was only CFI, that I wouldn't raise this. But it was even, I think, included.
01:00:29.542 - 01:00:31.294, Speaker A: It was never included. Okay.
01:00:31.334 - 01:00:33.634, Speaker B: Never included. Then my confusion, then.
01:00:35.624 - 01:01:05.780, Speaker A: Yeah, I would say nothing. No new advancements. The 3074 issue is going to exist no matter what. There's no silver bullet there. So, yeah, writing a short doc on kind of explaining the issue. But I would say at this point, there's not much confidence that we could get it fully resolved in a way that would be happy for electro. At least that seems to be the sentiment broadly.
01:01:05.780 - 01:01:06.464, Speaker A: So.
01:01:10.844 - 01:01:12.024, Speaker E: Yes, Elias?
01:01:13.884 - 01:01:36.654, Speaker D: Yes, I have a couple of questions. So, is there a solution for test vectors? As the spec is progressing very fast and the published test vectors, they get outdated soon. So maybe some client teams bold test vectors from this specs, or is there a solution for this?
01:01:39.474 - 01:01:43.854, Speaker E: Right, well, there are the test vectors for the one 50 alpha zero release.
01:01:46.994 - 01:01:50.094, Speaker D: Either the release, yeah.
01:01:50.554 - 01:01:59.934, Speaker E: Okay, great. Barnabas has link. So, yeah, generally when we have a spec release, we also like make all the spec, test vectors from the spec and then release those as well.
01:02:00.634 - 01:02:11.626, Speaker D: Okay, so this then zero likely will target some spec release, some exact spec release that will have test vectors released too.
01:02:11.690 - 01:02:11.914, Speaker A: Yeah.
01:02:11.954 - 01:02:23.734, Speaker E: The intention is alpha zero. Although if we change something with respect to this one EIP, what was the number, the one with the request refactoring that we were talking about?
01:02:23.914 - 01:02:24.478, Speaker D: Let's see.
01:02:24.526 - 01:02:25.554, Speaker A: Let me find it.
01:02:27.694 - 01:02:49.114, Speaker E: There's way too many messages in the chat 8432. So that might have some implications for just how we like structure things syntactically, but otherwise, the functionality is all in there. And Alpha Zero, I don't really see any other major changes with respect to that. And then that gives everyone a clear, stable target for w zero.
01:02:50.274 - 01:04:12.354, Speaker D: Okay, thanks. So, another question on das working group Telegram chat, we were discussing today an issue where essentially, if unwield block is imported in a power choice, then the rules of that block may influence the fork choice and essential debate of the forecast. So they remember that there were some discussions before and that actually the reason, I believe that was the reason why we don't, right now, we don't import blocks that doesn't have all the blobs available. And maybe there is some person in this shot, in this call that knows a bit more about security issues. Of this approach where unavailable blocks are imported in fork choice, because on this telegram chart, there was no response from such person.
01:04:18.814 - 01:04:19.318, Speaker A: Okay.
01:04:19.366 - 01:04:31.714, Speaker E: And so could you just state the question again? Like, the concern is I'm importing unavailable. Like I'm importing blocks into the fork choice with unavailable blobs. And the question then is like, what to do about that?
01:04:32.254 - 01:04:32.654, Speaker A: Yeah.
01:04:32.694 - 01:04:55.992, Speaker D: So, yeah, some malicious, malicious validators may vote on these unavailable blocks and this could cause reorgs. Is it clear? It's a bit tricky to explain. Yeah, well, I mean, if I'm following.
01:04:56.088 - 01:04:59.432, Speaker E: My understanding would be that these blocks wouldn't go into the fork choice.
01:04:59.488 - 01:04:59.704, Speaker A: Right.
01:04:59.744 - 01:05:02.204, Speaker E: So like, I don't know how much.
01:05:03.544 - 01:05:03.896, Speaker A: Yeah.
01:05:03.920 - 01:05:08.964, Speaker D: But Francesco was offering that it should go to the far choice.
01:05:13.824 - 01:05:14.248, Speaker A: Sorry.
01:05:14.296 - 01:05:57.876, Speaker F: Yeah, just clarify. What I was saying in this chat was basically today, what we do is to just not import blocks that are unavailable. I think that's basically fine today, but it wouldn't be fine if we move to peer tasks with the trailing for choice. I think even today it's debatable that it's the best thing to do, but I think it's okay. And there's not much issue with it. But what changes when we go to peer dust via trailing for choice is that you can even go from, so today you can only go from availability being false to true. Like is there available first being false and then true when we move to peer task choice? You can go even in the editor from true to false.
01:05:57.876 - 01:06:41.894, Speaker F: And yeah, this basically creates different scenarios that are not, you cannot see today. And I think what we should do instead is basically to not use these data available to gate the import in the for choice, but to use it just as a filter. So when you're running, you just import the block in for choice. But when you're running ahead, you don't basically go down a branch where basically you get to a certain point when you're looking at children with a block and you filter out the children that are unavailable. So just as a simple filter directly when you're running for choice. And yeah, there's various reasons for that. I'm not aware of a problem we do in this.
01:06:41.894 - 01:06:52.758, Speaker F: But yeah, the question was when the decision was made for four to instead use these data available to gate importing, was there some specific attack that people.
01:06:52.806 - 01:06:54.046, Speaker C: Were worried about or.
01:06:54.150 - 01:07:00.674, Speaker F: Yeah, basically, why was that? Why was it decided to do that? And what's the impact of that? Like maybe I'm missing something.
01:07:18.594 - 01:07:19.890, Speaker E: Does that clarify?
01:07:20.082 - 01:07:57.558, Speaker D: Okay, yeah, I mean, this, this clarifies my flawed explanation, but I mean, we are looking for a person which, which knows why in a current spec, in the nav spec, we. I mean, why exactly? It was chosen to not import unavailable blocks or blocks that doesn't have all the blobs. Is there such person in this chat? If not, then maybe now someone knows.
01:07:57.646 - 01:07:57.894, Speaker C: Right.
01:07:57.934 - 01:08:08.874, Speaker E: Well, with 4044, I mean, it's just like strictly safer to do it this way. Right? Like you just cut off even the possibility of these questions if, like, you just wait until you know everything's available.
01:08:09.924 - 01:08:20.944, Speaker D: Yeah, but if we are discussing to change it in peer dos, then it's likely we can do it right now with the current loss.
01:08:23.284 - 01:08:27.944, Speaker E: Maybe. I mean, if 444 is working well enough, I don't see why we need to change it.
01:08:29.444 - 01:08:51.753, Speaker D: Okay, but it also should be related to the thing that we do not do any validator duties if payload is invalid. So it's in some sense it says if the payload is not validated yet. So it's in some sense it's a similar problem.
01:08:53.013 - 01:09:27.404, Speaker E: Yeah, I mean, I think it's the exact same reasoning. So before I for four, like, yeah, like you can just say, don't even consider it with respect to fork choice so you don't attest to it. Don't try to put on top of it for exactly this reason with pure dots. If we do move to some trailing fork choice, it does get more complicated. And then, yeah, I think you'd need to have like a more, like a richer view, I think, like Francesco was suggesting as to, like, what's. What's. Yeah, the words get overloaded, but, like, what's, you know, what's.
01:09:27.404 - 01:09:41.664, Speaker E: I can't even think of one that's not valid or available. But basically you would have some notion that, like, this block is here and it's almost like pending. Maybe that's a good word for it. It's like pending in the fork choice and then you just have to wait for more information to move forward.
01:09:44.004 - 01:10:05.324, Speaker D: Anyway, if anyone knows this, someone who did the security analysis of the string, and if there was explanation to do that the way it is now in the net, then yeah. Please invite this person to the working group and we can proceed to discuss there.
01:10:09.104 - 01:10:39.544, Speaker E: Okay, sounds good. Does anyone have anything else? I think that's all we had on the agenda for today. And if not, we can go ahead and wrap up a little bit early. I'm sure you're all very busy with Paktia Devna zero, so good luck.
01:10:43.444 - 01:10:45.164, Speaker A: Thanks, everyone. Thank you.

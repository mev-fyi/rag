00:02:41.015 - 00:03:14.757, Speaker A: Okay, we're on. Welcome everyone to ACDE number 197. Basically two big things to chat about today. First is implementation and minor spec updates on the PETRA work. I think it makes sense to first go through this and make sure we're all on the same page realm where things are at. Then next up talking about the PETRA scope. So we discussed splitting the fork on the last call.
00:03:14.757 - 00:03:43.166, Speaker A: It seems there was some rough consensus around the first half, but then a lot of open questions around what to do about the second half. Many people and teams have shared their thoughts since then, so we can have a discussion around that. Then a couple minor things run as well, but those are the two big ones. First, I guess to kick us off, does anyone want to give an update on where things are with DevNet3 right now?
00:03:43.351 - 00:05:02.795, Speaker B: Yeah, so we've had Net3 running for a bit now and there has been the Taku Aragon fix that's already been deployed and I think the Taku team or the Aragon team was looking at illegal state exception that's happening there. Besides that Lighthouse has a stateroom mismatch. I've. It could potentially be a memory issue on the node, but yeah, we still have to figure out what's going on there. Besides those two points, there's one sort of deposit test that Philip, like PK has done from the team and he's written down some observations here, so please have a look. And I don't know, Philip, do you want to maybe say something about the deposit test? Yep. And so yeah, we basically tried to fill up the pending deposit queue on Pectra with 1,000 pending deposits to see how the network behaves and the expected increase of the epoch transition times because most clients need to recompute the hashing times 100,000.
00:05:02.795 - 00:06:02.815, Speaker B: And yeah, that could already also be observed, but most significantly is that Xatu showed quite badly increased block propagation time during these time frames. And we are not sure where this is coming from. But yeah, basically further investigation is needed to find out the root case here. Yeah, thanks. And Mikael's already, I think posted change in the consensus specs that should potentially help with this. So we will be like redoing this analysis once some PR is done or if there's some new proposal or rate limiting or whatever we choose. We definitely want to make sure that this is not happening before we, we start doing, I guess, more public devnets, et cetera.
00:06:02.815 - 00:06:07.781, Speaker B: Even though that 100,000 deposits is a large number, especially because mainnet has like.
00:06:07.848 - 00:06:13.855, Speaker A: 1.1 million valid or 1 million validators, but still it's something we've observed for now.
00:06:14.675 - 00:06:59.195, Speaker B: Besides that, we've slowly started planning for DevNet 4. DevNet 4 is essentially the same scope as DevNet 3, along with a bunch of open EIPs, ideally with everything related to builder. Also with the MEV workflow also included, there's a bunch of open PRs as well as clarification so please have a look and I guess we should first focus on merging those in and finishing the discussions and ideally we'd have spec releases done after that and we can point to the spec release for the Devnet timeline, at least in my head is roughly 2ish weeks unless that unrealistic.
00:07:02.015 - 00:07:55.605, Speaker A: Thank you. Yeah, any of the client teams want to chime in on some of the issues we've seen on the Net three or yeah, feels like it's pretty clear and yeah, so there are a couple. Yeah there are a couple I think open PRs that people want to discuss on the call so we can cover those as Well I guess. 1. So yeah, so we covered the big Q test. One other thing I think is important as we head to devnet 4 is the BLS 12381 repricings. I don't know if all the teams have had time to run the benchmarks and if someone's like looked into the results of that, but if we are to change the gas prices we should try and do it by the next devnet too.
00:08:03.425 - 00:09:16.601, Speaker B: So just speaking from benchmarking Geth, I would personally say that increasing the cost 20% across the board would be the most aggressive that I could see. The GAS model still being not heavily underpriced, so right now that's what I would opt for. From the BESU side we've been doing a lot of benchmarking with different library options and it's a little bit difficult for us because a lot of the kind of GAS targets are based off of kind of a relative performance of EC recover and that's one of the Pre compilers we've identified that we need to optimize. So I think something that's going to help us with giving a flat target for gas pricing is an agreed upon machine metric that we want to perform a specific, you know, mega gas per second for the BLS precompiles, specifically the MSM precompiles. Just initial benchmarking seems to agree that it is underpriced on what seems to.
00:09:16.633 - 00:09:17.205, Speaker A: Be.
00:09:19.505 - 00:09:43.385, Speaker B: Somewhat agreed upon hardware like using a Gen 11 NUC and like an M1 arm machine it seems to be that our initial benchmarking agrees with Geth that it is underpriced. But getting a specific target, I think it's going to be better to have a specific machine target and megagas per second rather than kind of a relative performance metric for us.
00:09:46.165 - 00:09:50.465, Speaker A: Thanks. Anyone from Wrath, Aragon or nethermind?
00:09:54.485 - 00:10:04.545, Speaker B: Yeah, for Nethermind I think it was Jared from Geth proposed potentially doubling the discount costs.
00:10:04.865 - 00:10:06.617, Speaker A: And based on our initial test with.
00:10:06.641 - 00:10:10.841, Speaker B: The state tests, we would support that.
00:10:11.033 - 00:10:29.985, Speaker A: Because the MSM, particularly the G1 MSM precompiled seems maybe underpriced, but we're seeing quite high variance between tests. So yeah, we need to look into this further and we're going to test.
00:10:30.025 - 00:10:36.905, Speaker B: Out with our own benchmark marking framework to verify the accuracy of the state test benchmarks.
00:10:40.685 - 00:10:45.945, Speaker A: Thanks. Anyone from Aragon or RET have them to look into this?
00:10:50.525 - 00:11:06.205, Speaker B: Yeah, we are at a team off site, so kind of we've been busy with that. But for us the results should be very close to those of guests because we use the same library and pretty much the same implementation.
00:11:10.705 - 00:11:15.245, Speaker A: Okay. And on the red side.
00:11:18.065 - 00:11:18.513, Speaker B: We did.
00:11:18.529 - 00:11:58.155, Speaker A: Not have time to look at it, unfortunately. Yeah. So I guess maybe one thing we could do to move this forward, especially if we wanted for Devnet 4 and that we expect to ship Devnet 4 in like two weeks, is it seems like everyone agrees that these calls are underpriced and at least Nevermind agrees that like, you know, the original proposal of doubling is probably directionally. Right. So Jared, would you be open to just. Could you open a PR against the EIP effectively proposing the doubling of the chain of the gas costs and then we can. Sorry, go ahead.
00:11:59.935 - 00:12:01.175, Speaker B: No, sorry, continue.
00:12:01.255 - 00:12:31.445, Speaker A: I was going to say if you can open the PR this way we can track it as part of the definite 4 spec and then by next week on, even though it's a CL called. If we've had time to make tests on like more standardized hardwares. More standardized hardware and also get some numbers potentially from rest, we can determine whether like those values are correct. But yeah, assuming that this is all like the information we get, then we can just move forward with the first proposed repricing.
00:12:32.625 - 00:12:33.977, Speaker B: Yeah, sure, that sounds good.
00:12:34.081 - 00:12:54.215, Speaker A: Okay, thank you. Anything else on the BLS repricing? Okay, and then. Yeah, let's discuss this actually. Yeah. So there's a question in the chat about what's the hardware that we recommend? I don't know. Jared, do you have thoughts on this?
00:12:59.275 - 00:13:24.105, Speaker B: Not really, no. I know for several proposals in the past we've just. I mean the MODX P repricing comes to mind. We've used easy recover as a base but I get that that's not that some people are against that. No, but no, I don't. I don't like have a. I can't.
00:13:24.105 - 00:14:19.009, Speaker B: I don't have an opinion on what the specific hardware should be for a target right now. I think American made a recommendation or like kind of concurrence a recommendation of like an Intel Nook 11 as a baseline with a 50 mega gas per second target, 32 pairs. I think that would be like coming up with that as a standard would be pretty reasonable. And you want also seeing architecture where did the. What is. What is.
00:14:19.097 - 00:14:22.845, Speaker A: Why are we using what's directional for that.
00:14:24.905 - 00:14:39.585, Speaker B: For the. For the Nook as rationale. I think that's just a common solo staking rig as a baseline. I don't think that there's going to be many validator nodes out there that are running on hardware lesser than that.
00:14:53.005 - 00:15:47.495, Speaker A: Okay. And there's some discussion in the chat about the version number and yeah we should probably test multiple architectures so I guess maybe yeah if teams have the capacity to test it against different architectures and at least like report those tests that would be good. I think the more data we can get the better. But yeah, if we can prioritize this in the next week or so that'd be really good so that we could actually make a call for definite four and not be changing the gas prices forever. And yeah, I'll let people continue to debate in the chat exactly which Nook version to target. Anything else on the repricings?
00:15:55.315 - 00:15:56.135, Speaker B: Okay.
00:15:56.915 - 00:16:09.135, Speaker A: Okay, next up, something that actually Mikael, is this something you wanted to be considered for DevNet 4, your PR about making the execution requests a sidecar?
00:16:11.675 - 00:16:24.175, Speaker B: Yeah, probably for Devnet 4 but generally to gather the feedback and if we want this design. So we need to do some more work on the EIPs and smart contracts.
00:16:25.645 - 00:16:26.141, Speaker A: Okay.
00:16:26.213 - 00:16:34.825, Speaker B: And yeah actually ideally if we. If we want this kind of design. Yeah we would like to have it for the Net four if possible.
00:16:35.525 - 00:16:35.877, Speaker A: Yeah.
00:16:35.901 - 00:16:42.237, Speaker B: So yeah so the. I can briefly go over the proposed change.
00:16:42.261 - 00:16:43.485, Speaker A: Yeah, I think that'd be good. Thank you.
00:16:43.525 - 00:17:00.805, Speaker B: Yeah. Yeah. Okay, cool. So this is the slide or not it's just an improvement upon the ideas that already were proposed previously but FedEx like client and some others.
00:17:01.345 - 00:17:01.785, Speaker A: Okay.
00:17:01.825 - 00:18:08.253, Speaker B: So what this PR is doing actually is it proposes the design of the requests that will be as less impactful for EL and which allows to add new type of Requests as smooth as possible. So the what exactly proposed is the first step is to remove the request from execution layer beacon block body and entirely serve this request as a sidecar. So we had this idea before, but now it makes more sense because CL keeps the request aside of the payload in the beginning block. And for, you know, for one of the concerns of this approach was the optimistic sync safety. And to keep optimistic sync safe, we'll need to keep the request to the list of requests in the EL block header. So which is. Which is fine.
00:18:08.253 - 00:19:08.459, Speaker B: Which is perfectly fine. The other part of this PR emerged in the discussion with Lucas. So we want to encode those requests in a way that EL will not need to parse them at all. So the proposal is actually to for the system Smart contracts to return the list of requests in a way that they are ready to be served to the cl. So it's just basically the modification that is required to achieve this goal is to pretend the type byte before each request entry and do this in the Smart contract implementation. So this is doable and I think it's not difficult to have this implemented. So then the EL gets these requests lists from each of the smart contracts, concatenates them.
00:19:08.459 - 00:19:56.575, Speaker B: Instead of using rlp, it just concatenates them in a list. This was proposed by Felix in the UnifierQuest objects PR to the engine API to use this encoding. This unified request list is used in two places. First, it is used in the Engine API to surface the request to CL as is. And the other part is that this exact list is used to compute this request hash commitment which is put into the EL block header. And that's basically it. So adding a new request type would be a matter of implementing the smart contract and just saying that this is a new Request type to EL&EL can handle it by some generic code.
00:19:56.575 - 00:20:00.775, Speaker B: So that's about it. The design.
00:20:01.115 - 00:20:01.563, Speaker A: Yeah.
00:20:01.619 - 00:20:25.775, Speaker B: Looks quite good to my opinion. And yeah, that's it. And it would be great to get a feedback from Yale devs and yeah, whether it sound or how does it sound to everyone and from CL as well. So CL will need to parse those requests from this kind of encoding.
00:20:27.315 - 00:20:27.931, Speaker A: Yeah.
00:20:28.043 - 00:20:59.159, Speaker B: So that's it. Please take a look. And if we decide to go, as I said, we need to change the systems market track. We need to update these 7685 EAP, which is the generic request type. So that's kind of like the changes that are not done by this PR and just announced there. I'm happy to do this. Yeah, cool.
00:20:59.159 - 00:21:00.595, Speaker B: Felix, thank you.
00:21:03.015 - 00:21:03.915, Speaker A: Thank you.
00:21:07.935 - 00:21:54.395, Speaker B: Sorry, if Felix, like client want to elaborate on this or you know, just provide your comments, please go ahead. So I think it's a great one, the proposal, because it means that we have to care even less about the request. In my previous proposal, we still had to know about the output size of the contract objects in order to be able to split it into a list. So this is now also removed from the el. Basically it's just even less knowledge about the contracts. And like you mentioned in the pr, the deposit contract is a special one, but it's also kind of the OG system contract. So I guess it's fine if we have to handle it a bit special as the only exception for now.
00:21:54.395 - 00:22:44.575, Speaker B: And yeah, so I think my big question would just be like, if it has really been determined that it's fully safe for the. For the sync. Because yeah, with this design, I mean the. Basically the idea behind this design was also a little bit to make it so that we handle the requests in a similar way to how the receipts are actually handled. So the main motivation here is also that within the Ethereum block body, like within the EL block body, we do not actually have the receipts because the receipts are an output of the block computation. And so the receipts are a separate entity. And then.
00:22:44.575 - 00:23:19.465, Speaker B: So however the. But we do have to receive the root. And this is similar here. So the requests have the request route within the block body. So I'm a bit curious how it's going to work during the sync if we will be. If we will have to somehow sync the requests as a separate object or if they are fully like if it's totally possible to just not have the requests at all within the EL after the sync. So technically we don't need them, they are only for the cl.
00:23:19.465 - 00:24:02.885, Speaker B: So I guess it would be fine not to sync. Like during the snapshync, for example, we would not sync the requests and therefore we would not be able to validate the request route. However, for the blocks which are provided by the cl, we would be able to verify the request route. Yeah, so basically this request hash has to. It will be used in two places into validations. First is the block hash validation. So the CL gives EL the receipts, the EL computes the receipts hash.
00:24:02.885 - 00:24:49.201, Speaker B: So the computation is encapsulated in el. How it's done, it's completely up to EL according to this proposal. And then this, the obtained receipts, sorry, request hash will be used to compute the block hash and validate the block hash. So if the requests passed from CL are not the one that are that the EL is committed to the block hash validation will fail. The other part is the other validation happens upon the block execution. So the requests obtained from the block execution will also need to be validated against this block commitment. And if.
00:24:49.201 - 00:25:22.813, Speaker B: Yeah, if the block execution gives you something different than that the block is committed to. So the execution of the block will fail. And these two validations actually makes us safe during the optimistic sync, where EL runs blocks on its own and it can validate the requests obtained from the execution against the request hash. And the same is done by cl. Right. So the commitment is validated from both sides. So that's it.
00:25:22.813 - 00:25:38.845, Speaker B: That's how it should work. And snapsync, of course. No, there is no. Kind of like, you know, these chats. And yeah, it's fine. So there's no need to download them during the snapsync. We basically just don't have to have the request at all for the.
00:25:38.845 - 00:25:45.405, Speaker B: Okay, that's exactly. Yeah.
00:25:48.185 - 00:25:57.795, Speaker A: Michel, you're proposing. So this request, the sidecars are going to be gossiped on the CL side and you're proposing this for the next devnet.
00:25:58.215 - 00:26:27.549, Speaker B: No, no, no. There's no gossiping of requests. So the thing is that the requests are purely created when the block is executed. It's just a mechanism for the. Basically every node computes the request on their own because the only way in which requests can be generated is via transactions. So in fact, we are already gossiping the requests in a certain way. They are just encoded within the transaction.
00:26:27.597 - 00:26:34.105, Speaker A: Oh, I see. But then how will the CL get the request? Is this going to be on notify new payload?
00:26:34.845 - 00:26:46.739, Speaker B: Yeah, basically we'll get it as an output from the el. Yeah, CL will get it on the get payload, but separately to the payload. This is why it is called the sidecar.
00:26:46.917 - 00:27:05.675, Speaker A: No. Okay, so I'm still lost. So how will the CL sync a block over gossip? When I get the block over gossip, will I have this request immediately or would I only get transactions, send it to the EL and then from there get back the requests?
00:27:05.975 - 00:27:10.955, Speaker B: No, but you will get those requests as a part of the beacon block.
00:27:14.305 - 00:27:18.365, Speaker A: The proposer will pack requests on the body as it is now.
00:27:19.945 - 00:28:02.115, Speaker B: Yes. The main problem that we are trying to address is that in the previous. Another problem we're trying to address in the previous design is that the requests are duplicated in the previous design, before the PR from Mikayl. The big problem was we had the request in the EL block body, and we also had them in the CL block body. Technically it doesn't really matter because they can somehow be discarded or something. But it's just a messy thing to have the same object with slightly different semantics in the two blocks. With this new proposal, they are only in one place, which is the CL block body, and that's where they have to be as well.
00:28:03.895 - 00:28:09.015, Speaker A: This will be constructed one on GET payload. It's going to come back from the engine.
00:28:09.175 - 00:28:09.831, Speaker B: Yes.
00:28:09.983 - 00:28:13.191, Speaker A: Separated from the payload, but okay, perfect.
00:28:13.263 - 00:28:14.515, Speaker B: It's actually same as now.
00:28:15.255 - 00:28:19.275, Speaker A: Okay, this is exactly as an epbs. So this is good. I like this.
00:28:25.855 - 00:28:53.041, Speaker B: So it's like. It's like the ultimate requests design. Like there's no better one. And this something we want for the next DevNet, or are we waiting for a few more weeks for people to comment on it before we ship it on a devnet? I mean, I don't. People.
00:28:53.153 - 00:29:15.795, Speaker A: People like it in the. In the chat, I guess. Does anyone have an objection to bringing it, Bringing this in for the next defnet? Because if everyone is happy with it, then, yeah, we should make the decision right now. And this way we can update the specs, update the contracts, update testing. But yeah. Does anyone have any concerns or objections with this?
00:29:22.815 - 00:29:36.133, Speaker B: There might be some objections from cl, but I'm not sure. I mean that, yeah, they have to do more work, which is fair because TL is the consumer. I mean, like, have to do more work by just, you know, decoding this.
00:29:36.189 - 00:29:45.025, Speaker A: But wait, what's the extra work here? I thought that on GET payload we're going to get this request, we're going to just import them locally.
00:29:45.565 - 00:30:11.659, Speaker B: What's the extra work? Yeah, previously there were some discussion in the. There was some discussion in the PR about encoding, particularly of the requests, so that the CL has to parse some, you know, some encoding that is not generic. Like, it's not entirely. It's ssd, but it requires unions, you know, this kind of discussion.
00:30:11.747 - 00:30:21.775, Speaker A: Yeah, so that I think we have already, like, relented and accepted that we can do the parsing as long as there's a commitment of not using unions then in ss.
00:30:24.655 - 00:31:12.075, Speaker B: Yeah. So this is one of the things in Mikael's proposal that is going to be really interesting because now the requests are just going to be provided as a single byte array and that has to be parsed by the cl. And I mean, let me just put it right. I think it's okay, but it's a custom format. So what we're talking about is basically it's like a byte array where you have these type containers and you have to keep checking for the first byte, then you will know the size of the next object based on this type byte and then you can basically take it out of the list. I think it's a great design, honestly. It totally works and it's the simplest possible way to send this information, but it definitely requires more parsing on the CL side than it ever did before.
00:31:12.075 - 00:31:40.245, Speaker B: And just one more clarification. This would supersede Light Plants PR to Unified request objects as well as your PR to Unified list of opaque requests. Right, so instead of doing those two, we would just do Mikael's pr. Yes, because in Mikhail's PR it's like we change, it changes the same thing again to make it even simpler, basically. Thanks.
00:31:41.955 - 00:31:50.015, Speaker A: And to be clear, the PR that's superseded is this one I'm putting in the chat. Right. So this one we would just close.
00:31:54.715 - 00:32:03.259, Speaker B: Oh, this. This one will need some. I don't know, maybe some changes, but yeah, we need something, you know. Okay, yeah, we need to update.
00:32:03.307 - 00:32:03.747, Speaker A: Oh, yeah, sorry.
00:32:03.771 - 00:32:14.455, Speaker B: Yeah, we need to update across all of the repository. So we have the engine API and the eips and the system contracts, and they all need changes in some way.
00:32:15.555 - 00:32:49.667, Speaker A: Okay. So I guess it seems like everyone is in favor of moving towards this. There's no objections. It would be great if by next week's call we could have the final set of PRs. I mean, ideally merged, but if not merged, at least a clean set of final PRs across every single EIP and the engine API and whatnot that people can review. But yeah, hopefully we can do this async in the next week or so. Yeah.
00:32:49.667 - 00:32:53.215, Speaker A: Felix, Mikael, can either of you take this on?
00:32:54.635 - 00:33:14.829, Speaker B: I left a note in the spec doc as needs updates for. I think there's three AIPS that would need update. Right. There's the MacDB change request to flatten coding deposits and withdrawals. Yeah. And then I think there's one more change request.
00:33:14.877 - 00:33:16.253, Speaker A: Hash. Flat hash.
00:33:16.429 - 00:33:29.421, Speaker B: Yeah, we need to. Yeah, so the flat hash. I'm not actually. What is the commitment? Can you. Sorry for dragging this out. But Mikael, what is the commitment? Is it the flat hash commitment or is it the nodes? Yeah, it has to be. Right, because it's just literally.
00:33:29.421 - 00:33:49.885, Speaker B: It's literally a hash of the whole. Yeah, yeah, okay. Yeah, it's. It's fine by me. Okay, yeah, so that one. So this flat hash thing then has to be changed a little bit to just basically specify that it's the hash over. Like the request hash is the hash over this over this output and.
00:33:49.885 - 00:33:57.245, Speaker B: Yeah, anyway, we will get this done. Okay. We'll implement it in the contracts and, you know.
00:33:57.385 - 00:34:08.165, Speaker A: Awesome. Oliver. I seem to recall that right now we're gossiping the requests over P2P in the block bodies.
00:34:08.285 - 00:34:28.574, Speaker B: Should we remove this in this case? Sorry, what do you mean? So it's in the block body? In the beacon block body. It still remains there, but not. It's removed from the execution party.
00:34:29.234 - 00:35:12.685, Speaker A: Okay, yeah, that was it. Okay, well, thanks, Felix. Thanks, Mikael. Anything else on this? Okay, and then next up. So Devnet4 want to make sure that we cover all the other open questions. There was the PR 26110, but this we need to change. Then there were two PRs to 7702 not allowing authorization, non sequels to 2 to the 64 minus 1 and then adding a bunch of clarifications to align the spec with the tests.
00:35:12.685 - 00:36:06.155, Speaker A: Yeah. Does anyone have context of these or want to chat about them? Let me post them in the chat here. Yeah, and it seems there was some conversation on the PR right before the call. Okay. If no one wants to discuss it, we can move on. But people should ideally review this as we. As we finalize the scope for DEFNET 4.
00:36:06.155 - 00:36:14.895, Speaker A: I'm. Anything else that people feel is kind of urgent to discuss for DevNet4 and that we should get sorted out in the next week or so?
00:36:18.315 - 00:36:25.895, Speaker B: Yeah, I think the builder spec PR should get some last looks and get merged in so that people can start working on it.
00:36:26.275 - 00:36:29.215, Speaker A: Okay. Do you mind sharing it in the chat if you have it handy?
00:36:32.075 - 00:36:33.375, Speaker B: Yeah, just it.
00:36:33.775 - 00:37:28.281, Speaker A: Thank you. Anything else on Devnet 4 that we should be looking into before next week? Okay. Otherwise. Yeah, so the two main things are Mikael's pr, which Felix and him will follow up on, and then all of the BLS repricings. So hopefully we get some agreement around benchmarks, but we'll at least have a PR open to change the gas cost by a factor of two like we originally discussed. And then a bunch of other things that have been flagged in the Devnet 4 spec already. Anything else? Okay, and if not.
00:37:28.281 - 00:38:23.891, Speaker A: Yeah, one quick thing as well I'll give a shout for is we've put up an RFP to audit all of the contracts in Petra. So we have this open now. It'll be open until October 11th. Hopefully by then the code is pretty much finalized, but we hope to get a bunch of different people looking at the contract and both fuzzing them doing some static analysis and more. I'll post the link in the chat. But if you are interested in listening you can find us on the Ethereum request for proposals repo and I think that covers everything around implementations. Anything else before we move on to the fork split? Okay, so fork split.
00:38:23.891 - 00:40:08.725, Speaker A: So on last week's call it seems like we had rough agreement on at least the first half of pectoral so moving from what DEVNET 3 was into production. A bunch of teams shared some thoughts this week. So Aragon, Aragon was like slightly opposed to the idea of splitting the fork partially because one it would just like grow the second half of things and potentially deprioritize Verkhol I think Prism was in favor of for keeping DevNet 3 as the first half of Pectra but then also opening the door for more changes in the second half, including potentially the EPBs, EIP and one thing they were explicit about is not raising the blob count in the first half. Lodestar wants to basically keep first half as Devnet 3 as well and then basically has like yes, some proposals for the second half, some of which are not already included. Nethermind feels strongly about keeping the scope as is if we do the split, but it's also fine with keeping the fork in one piece. Then Vitalik has a proposal to actually add something to the first half which is a blob increase and a 7623 to bound the block size and then ref supports freezing both halves as is. So yeah there's a lot here.
00:40:08.725 - 00:40:49.313, Speaker A: I guess one place to start is maybe on the first half. So it seems like there's a lot of support for freezing the first half of the fork and that's roughly where we rounded last call. But then yeah, I think Vitalik and sorry I forget who was the other one who wanted something else in the first half. I think Vitalik might have been the only one who wants something added to the first half aside from the base people who came on to argue for the blob increase last week. But yeah, maybe let's start here. If you're on the call Vitalik, do you want to give the yeah, yeah, I'm here. Okay.
00:40:49.369 - 00:42:39.005, Speaker B: Again I think basically a blob account increase I think is something or a blob target increase is something that will be extremely valuable. And to me the key stat basically is that if you look at the level of usage right now of blobs it's like basically somewhere around 75% of the target. And I think it's important to keep in mind basically that one big difference between the Blob market and the regular EVM market is that the blob market is made up of a much smaller number of larger actors. And so even though it feels like a nice and constant 75% like I think it is undoubtedly true that there are layer 2s that are considered that would have used blobs if more space is available, but are making the decision not to precisely because they know that if they come in then they themselves are going to be enough to make blobs be no longer cheap for both themselves and for everyone else. So I think it's really important to think about some of those long term effects and generally the fact that the Ethereum ecosystem really has turned a corner to the point where L2 is including blob based. Layer two is actually can offer people a like sub one cent transaction fees. And this is momentum that is extremely important to build on.
00:42:39.005 - 00:43:46.092, Speaker B: And generally the ecosystem needs to it is scaling and needs to scale and wants to see assurance that it actually can scale. And this is something that the Lear one is committed to going with going along with them on. And so my SO one so this is this to me is an argument for increasing the blob target. So the reason why I suggested eab7623 along this is because a lot of people's concerns around a blob target increase have to do with worst case situations. And currently the worst case block size is about 2.7 megabytes. That which is using call data and EIP 7623 basically knocks that down to roughly 1 megabyte.
00:43:46.092 - 00:45:30.035, Speaker B: And so if we do a blob 7623 and simultaneously a blob target increase so even some like 2x is which is actually more than I advocated would still reduce the theoretical maximum block size by a factor of about a third. So basically view 7623 as something which adds that a really valuable safety feature. Another so that's one of the other suggestions. And then another question is basically are there other ways to mitigate some mitigate the issue involving the problem with worst cases. And I think there's two other options, right? One of them is to basically do the EIP that increases the minimum blob base fee, which basically means that if we ever enter a fee market condition discovery condition that the period of full blocks would be about three times shorter than otherwise would be. So that's one option. And then another option is actually to abandon the idea that there has to be a 2x divergence between target and max and basically say yeah, either increase the target to 4 without increasing the max or increase the target to 4 or 5, but increase the increase the max to 7 or 8, for example.
00:45:30.035 - 00:46:31.953, Speaker B: I mean, or I guess more aggressively on Gard suggests a six nine. Right? Yes, thank you. Both 7762 is the one that I had in mind there. So that would have the practical effects that if we have, if we enter a one of these like a blah blah price discovery periods, then the it would like cut the maximum possible length of a period of maximum usage by a factor of 2/3. So I think, I mean the reason why we need to think about this is because like if you just look realistically to me it's just clear that like just scaling actual usage is just incredibly important. And if Ethereum does not offer this then like people will find it elsewhere and people are going to have insecure blockchain experiences that are just not on Ethereum. Right.
00:46:31.953 - 00:47:28.365, Speaker B: And the. Yeah, and I would even argue that like even a 33% blob increase is probably more valuable than like even 3 of the Vectra EIPS at this point. So if you just like look at the ratio of effort to value, just like the amount of actual value here is quite high in terms of increasing the, increasing the amount of activity that can happen. And so I think there's a lot of value in doing a target increase and at the same time as thinking through adding 7623 in order to try to mitigate the effect of this and allow some of the other increases to be higher.
00:47:33.825 - 00:48:46.409, Speaker A: Okay, thanks for sharing. There's been a lot of conversation in the chat, so I think there's definitely one thread that the Prism team raised last week as well around just like measuring the impact of this. Another thread is that basically the idea that if we do increase the blob count and we want 7623 and we maybe want the fee market replacement and we maybe want 7742 now we're like at a 4eip fork effectively that's like starting to be its own thing. But yeah, I guess maybe the strongest opposition seems to be from POTIs around just the measurements of this. So maybe POTIs. Do you want to share your thoughts there? Yeah, I'm just worried that even increasing the target, but keeping the limit, which seems reasonable and safe, but we have not gotten any data about this. We haven't seen a single study that says how much it takes for nodes to actually be Syncing, recovering from a long reorg.
00:48:46.409 - 00:49:04.281, Speaker A: I mean those are the things that will change because it's not bandwidth on the happy case, but bandwidth when you actually need to sync several blocks at a time. And it would be nice to see if this is actually safe. The measurements that we've seen are based on average bandwidth, which is certainly not what you need.
00:49:04.313 - 00:49:05.205, Speaker B: At the tip.
00:49:07.585 - 00:49:18.645, Speaker A: It'D be good to see a serious study that proves that this is safe and then we'll support it. But without data it seems that we're just changing numbers because we just came up with these numbers out of our head.
00:49:20.625 - 00:50:02.385, Speaker B: Yeah, I mean I'd argue that honestly we have had the study and the study is three working like increasingly fine for nine months of operation. Like a 33% increases within range of gasoline increases that we've done many times, many times on chain And I think we also just have to take the like also take seriously the other side of the argument. Right. Which is basically all of the risks that that come from blob gas prices going up to 10 and 100 way. Again like we actually have to balance those considerations at some point.
00:50:11.215 - 00:50:12.315, Speaker A: I'm iris.
00:50:14.975 - 00:50:21.191, Speaker B: Yeah, but it's not really a 33% increase. It's more like a 66% increase because.
00:50:21.223 - 00:50:23.103, Speaker A: You'Re not like when we increase the.
00:50:23.119 - 00:50:34.757, Speaker B: Blob limit we're not only increasing the limit on the consensus layer, but we're also increasing the average number of transactions.
00:50:34.861 - 00:50:40.981, Speaker A: Block transactions that are sent to the network on the execution layer in the transaction.
00:50:41.053 - 00:50:50.285, Speaker B: Right, but that's. Right, but that's still a 33% increase on the total load, right? Oh yeah, that's true.
00:50:50.325 - 00:51:51.985, Speaker A: Yeah. So I guess yeah I'd maybe be curious to hear if like other teams share kind of Prism's view around the like measurement issues like or do other teams assuming like for a second like that we didn't have all the other picture scope issues like is like yeah, do people generally want to see more measurement on this or like yeah, how do we feel about increasing the block capacity? Enrico?
00:51:53.605 - 00:53:57.795, Speaker B: Yeah, we just want to share that we had some discussion internally about this and for instance just a data point a couple of days ago a guy showed up in our discord saying that he missed the block and was a homestaker that fall back building locally and he had to east local El selected six blobs and then he ended up being reorged. The block has been reached the network fine. But then the blobs was not able to reach on time and has been reorged and this is a home stager and has not very big upload bandwidth but is still something that is concerning some of the long tail of homoser that doesn't have enough bandwidth. And so I think that the target increase to 4 is kind of reasonable but I also think that some of the homsteger could have been impacted also now and what could be something like having a parameter on the execution layer for these guys that says please, if we are about to propose a block, please don't kind of limit the number of blobs that the local EL will select just to accommodate their potential upload boundaries. In that case it could be an option that could be abused for sure. Yeah, thinking I'm just putting my foot in this. Yeah, just asking if that could make sense, something like that to go in the direction of helping those situations.
00:54:02.945 - 00:54:08.225, Speaker A: Thanks. We have Francis and Anskar. Thanks guys.
00:54:08.305 - 00:54:09.441, Speaker B: I just want to mention one thing.
00:54:09.473 - 00:54:32.059, Speaker A: That we are always talking about. Home stakers with low bandwidth cannot sync properly but we haven't actually defined a minimum requirement about home staker span with limit. Are we going to say that if they have only 1 megabytes per second upload link and we are going to tolerate that forever? I guess what I'm trying to say.
00:54:32.107 - 00:54:34.891, Speaker B: That we probably need a better measurement.
00:54:34.963 - 00:54:48.323, Speaker A: Or better minimum spec for the network requirement so that we can talk about things in more concrete manners, not in people's reports about. Okay, I have issues but I don't.
00:54:48.339 - 00:54:50.339, Speaker B: Know what your bandwidth and I don't.
00:54:50.347 - 00:55:46.195, Speaker A: Know what to expect, etc. Yeah, I think this would be good to do. We clearly don't have this today and if I were doing it, what I suggest is something like you look at around the world. What is some median amount of bandwidth that you can get across different countries and what's the share of countries that you want to cover with Ethereum. But yeah, I doubt we're going to get this today. Actually like one quick information about that I actually did a like, kind of like quick search. So according to like those speed testing sites the medium is about like 60 or 70 megabytes per second upload link and like for the like maybe a long tail of things like for the 200th country it's around like three to four megabytes per second of the link.
00:55:46.195 - 00:55:54.113, Speaker A: So depends on how we are thinking about thinking in terms of max burst.
00:55:54.209 - 00:56:04.765, Speaker B: Speed that is needed for blob propagation. It seems reasonable within that range but we definitely need more concrete analysis of that.
00:56:06.465 - 00:56:09.565, Speaker A: Thanks Anzgar.
00:56:11.225 - 00:56:36.899, Speaker B: Yeah, I just wanted to briefly say my proposal for what to do today would be that we ideally agree on at least a target increase to 4. I think the case for that. I mean I said there's a little bit of pushback there on the call today as well, but I think we have relatively broad agreement on that. And specifically going from three to four a year later. Right. We ship at the beginning of this year, we will ship peer does at the beginning of next year. I think the average global bandwidth increases by like 30% every year anyway.
00:56:36.899 - 00:57:07.765, Speaker B: So like that's basically just keeping step with that and given how strategically important it is, I think that would be a good baseline to agree on. And then maybe we just delayed the decision on whether we go beyond that with also max increase on collecting a few some additional data first. I think I personally would prefer to also do that then later on. But I see that there's a bit more resistance there. So maybe postpone that decision and just agree on the as a minimum basically that we will increase the target to. For that I think would be very productive to do too.
00:57:14.065 - 00:58:10.415, Speaker A: Yeah, I guess I'd be curious if this is something that there is broad agreement on and then you know, if again trying to keep the scope of spectra tight, like if this is something there is agreement on, like is this the one thing we would change in picture if we could only change. And then there are some concerns around the home stakers and I don't know how we resolve those but yeah, maybe, I guess maybe one question is what would we want to know to be confident that we could do this increase? Yeah, I don't know if like anyone who has some concerns around just like the current stakers, like what's. Yeah, what's the data that we'd want to see to be confident with this?
00:58:13.115 - 00:58:56.105, Speaker B: I mean isn't there already a lot of data from home staker saying the current load is too high? Is that anecdotal data from folks that are bandwidth constrained though? I mean we're only going to hear from the squeaky wheels. I'm just saying that we are already at capacity for some people and increasing the target is going to put more people at capacity and beyond. So like I don't really know what data we can provide since there's already data saying that we're kicking people off the network or making it difficult for them to do their duties as a home validator.
00:59:01.885 - 00:59:23.275, Speaker A: And then yeah, there's a. Yeah, there's a comment in the chat around rolling out. I don't want to prod and that this will help with bandwidth. But yeah, I don't know if anyone has more context on that than want to share like the timeline. Yeah. Okay. Perry saying this would take months to roll out and analyze.
00:59:25.655 - 01:00:15.095, Speaker B: Yeah, I mean is it crazy to have a fork after what's already specified for Devnet 3 that's focused just on increasing the blob throughput and doing the preparations for peer dos? Like to me that de risks the situation of just making the current fork take even longer. Gives us more time to roll out these improvements for the CL networking, gives us some time to improve the bandwidth consumption of the EL transaction pool for blobs and still keeps us from getting into a situation where we bundle it with the full peer DOS and EOF or whatever else is in the next hard fork. That could take another one one and a half years.
01:00:19.435 - 01:00:41.941, Speaker A: Yeah, I guess it's worth having that conversation. I just want to make sure also we don't forget the hands that were already up. So like potas. Let's do potis Ben and Perry and then come back to this. Yeah. So just a quick comment, a couple of quick comments. I kind of feel that there's a double standard here in that the data.
01:00:42.013 - 01:00:43.781, Speaker B: That we have that our users are.
01:00:43.813 - 01:01:07.415, Speaker A: Complaining about being re art and losing blocks is anecdotal. But then on the other hand the data that we have that the nodes are safe with an increase, it's also mostly anecdotal, we don't have good metrics and I would like these two set of data to be put up to the same standards.
01:01:07.755 - 01:01:09.387, Speaker B: And second, it seems to me that.
01:01:09.411 - 01:01:12.227, Speaker A: This change is just very minor so.
01:01:12.251 - 01:01:13.291, Speaker B: It'S easy to implement.
01:01:13.363 - 01:01:19.059, Speaker A: It's just as much as when we were talking about changing the issuance curve which was a one liner.
01:01:19.187 - 01:01:25.187, Speaker B: It's these kind of things that we can actually measure, we can take some time to measure and if we decide.
01:01:25.211 - 01:01:34.065, Speaker A: That it is safe, this is shipped in less than a day. So I don't see how why we need to agree today on an increase when we have a lot of time.
01:01:34.105 - 01:01:35.921, Speaker B: To measure and make this change in.
01:01:35.953 - 01:02:18.645, Speaker A: Less than just a few minutes on every client. Thanks. Yeah Ben, following up on light clients, maybe three forks. Just a comment that you know, EOF could go in that second one probably. But I just wanted to say with any increase in target BLOB limit, we should probably seriously consider 7762 which is the min fee, just so that the fee market isn't unpredictable and there's been.
01:02:18.685 - 01:02:21.225, Speaker B: A researcher study on that.
01:02:27.845 - 01:02:36.185, Speaker A: Thanks and again, it's a one line change. Perry, Max and Tony.
01:02:37.485 - 01:03:29.305, Speaker B: Yeah, I think I mostly agree with what Porters are saying. I don't necessarily think we have to agree today but we have to agree that we intend to do this so we can collect the data required. I do think clients are anyway implementing, I don't want messages. There's going to be a reduction there and we can analyze the reduction as well as figure out for example reor grades for home stakers. We mostly know what validator indexes comply to home staker IP addresses and we can check the reorg rate for that and see how bad it is now. So then we eliminate the anecdotal part and we actually have raw facts in front of us and then we can make a decision based on that. I guess the commitment now is then to figure out that is this stuff we want to spend time analyzing and doing or is something else higher priority?
01:03:34.205 - 01:03:37.265, Speaker A: Thanks Max and Antony.
01:03:38.215 - 01:04:43.455, Speaker B: Yeah, I just wanted to say on the data point I do respect the desire for data driven decision making and I think we already have a lot of data on this because of the fact that the fee market is sort of broken. We know that we've had periods of sustained, you know, high percentage of the gas or of the blob limit used. So we've had six blobs used for a long time and we can use that data to support a move which what Ansgar suggested would be 4, 6, which is the same limit and we've already had periods where we're operating near the limit for a long period of time. So I think we can go look at that data and make a decision based on that. I also think we should consider doing 7762 as others have mentioned because much of the, much of the disagreement about that was basically oh, we're going to reach capacity soon and then this isn't going to matter. But of course now we're increasing capacity again, we should expect to see more periods of price discovery happening.
01:04:46.875 - 01:04:47.855, Speaker A: Tony?
01:04:51.275 - 01:06:07.445, Speaker B: Yeah, I've just published some analysis on the Rio grade, a very recent analysis how the whole situation played out and it looked like since we shipped 4844 the reorg rate is basically trending down. So we are at a level that is way better where we were, let's say a year ago, for example. And especially interesting is the fact that blocks with six blobs are not way more often, are not significantly more often reorged than for example a block with three blobs or even One blob. So I think it's very hard nowadays to really attribute the fact of being reorged to the number of blobs. I think there are many more variables like the slot index and an epoch, the fact if the previous proposer is playing timing games and so on that have a way bigger impact on the reoccur nowadays than the number of blobs. So I would say it looks like the network is definitely ready to to have more blobs. I would be more concerned about the maximum EL payload size than the block size just because it can be so variable compared to blobs that are just a constant size increase.
01:06:07.445 - 01:06:32.485, Speaker B: Just if you haven't seen it, I will also post the most recent analysis that I just did today in the chat and I think it's a good idea, like Perry said, to make it more granular to look into what are solo stakers doing and also split between MEV Boost users and non MEV boost users because I think even that has a way bigger impact on the Rio grade than the number of blobs nowadays.
01:06:34.345 - 01:06:40.777, Speaker A: Thank you Amad. Yeah, just wanted to agree with the.
01:06:40.801 - 01:06:45.929, Speaker B: Last two points Tony said about solo stickers and Web Boost and Nomad Boost.
01:06:46.057 - 01:07:29.065, Speaker A: Because trending down reorgs does not mean that solo stakers are not struggling. It just means that big operators are finding better ways to optimize against being reorged and like adjusting their timings of posting the blocks. Adjusting their timings to be exactly profitable and at the same time not get reorged out. So yeah, I think that's mostly it. Not that Denkoon suddenly fixed reorging but yeah, thanks Enrico.
01:07:30.285 - 01:08:20.385, Speaker B: Yeah, it's exactly the same things from Ahmed. I do think that the improvement is just infrastructure optimization rather than yeah, clients being more optimized for sort of staking. Actually my example before was actually an example specifically for a home staker that pulled back to local build and if he had not fallen back and choose the builder he probably wouldn't haven't been reorganed out. So it's just be more resilient to maintain local building instead of just systematically give block production away.
01:08:26.365 - 01:09:41.855, Speaker A: Okay, I guess trying to summarize all of this and then yeah, the past couple calls we've spent discussing scoping like I think it's pretty clear that there's like a strong bias towards keeping the first half of Pectra as close to dev3 as possible and then there's like some desire to maybe increase capacity in this fork with a lot of Caveats and the work for that could be relatively small, but obviously not trivial. I think the four EIPs that sort of are being discussed around this are 7623. So capping the call data, 7742, assigning the blob count only to the CL, potentially 762 with the fee, the minimum fee repricing. And then there's no EIP for the blob count change, but something around that. And then it seems also clear that for the second half of Pectra we have these two huge things, Peer das sorry, and eof, that are in progress, that are not stable yet. Neither of their individual devnets are stable and we haven't even tried to put a devnet with the two together. So there's still a lot of work there.
01:09:41.855 - 01:11:21.977, Speaker A: And as much as people say that we would want to keep the spec frozen there, it seems unrealistic that nothing will come out in the next six months that we decide to include. I think one way to move forward is we keep the scope of picture a as definite. Three, we keep these blob EIPs, these four EIPs I just mentioned, modular, the one that doesn't exist yet, to actually increase the blob count as CFI'd for PCTRA a in the next few weeks, slash months, depending on how long it takes, we actually run the numbers on staking and I think there's a broader conversation to have around that, like what numbers do we actually want, what does it look like? And then try to build the confidence around whether we think this is the right time to do it or not. If it turns out that we're all happy with the numbers, then we just include these relatively small changes alongside Picture A and we shouldn't delay things too much and we get some increasing capacity. If we're unhappy with the numbers, we can debate what to do then. Then for picture B, which I think we should just accept as effectively Fusaka at this point, which is the next fork, we have EOF and Peer das, which we've already included in picture A, be the main things and we can CFI as much stuff as we want. But I think having the commitment be that we don't include new things until we're actually ready to implement them, is probably the best gate, because once we have EOF and Peer DAS relatively stable, then we'll have a big list of things that everyone thinks is extremely important and we can debate what to include from that.
01:11:21.977 - 01:12:18.843, Speaker A: But at least we're not gradually Adding more things as we haven't. While we haven't actually implemented EOF in Peerdes, I think in the world where 763 and all the blob stuff doesn't make it to Picture A, we can decide to either move it to Vectra B or, you know, if we feel that it's so urgent it needs its own fork in the middle, we can have that conversation. But that feels like the most practical way forward. Yeah. And as much as I would like to like close the scope and say that we're going to commit to these things and not add anything else, I think it's just like an unrealistic thing to commit to. But I think we can commit to not making decisions about inclusions until we're actually ready to write more code. And this maximizes how long we have to actually think about different proposals and can we commit to some success that Picture V, that would not move out.
01:12:18.843 - 01:13:21.297, Speaker A: So I would say yes, I would say EOF and Peer das, which are already included. So like my proposal is that Picture V is EOF and Peer dos and we don't add anything else until both those two things work on devnets and we feel confident that we can actually add a bunch of other EIPs. And I don't think that we can make a decision today around whether we want some small blob increase fork in between Picture A and Picture B. I think if the situation changes a lot, we'll be able to make that call. It's relatively trivial to implement this set of Blobby IPs, but we. Yeah, I don't know that this is something we should commit to today, but at least we get a scope for Picture A that's relatively finalized. It's pretty clear that we prioritize looking into the blob increase and then we keep EOF and pure das as the focus for Picture B and we don't do anything else into that fork until those two are done.
01:13:21.297 - 01:13:57.403, Speaker A: But it's possible we add more stuff like Prism was talking about, 7,732, for example, and stuff like that. But we can have that discussion when we actually have EOF and Peerdes implemented. Any strong objections? Yeah, we call this Fusaka. Yes. Thanks, Trent. So, like, what I would do practically if we agree to this is all update the PETRA meta eip. I'll remove EOF and Peer das, move those as included for Fusaka.
01:13:57.403 - 01:14:35.983, Speaker A: I'll remove anything else that was CFI'd for PCTRA except 7623 and 7742 add. I think we should add the max fee, the MIN fee for the blobs increase. We don't have a PR yet for the blob in the actual blob increase, but we. We can add that when it's there. And then if anything else was CFI'd for Fusaka or Petra, we just moved that there. And the only two things included in Fusaka would be EOF and Peerdes for now. Okay.
01:14:35.983 - 01:14:44.245, Speaker A: Any objections? Yeah, Guillaume.
01:14:46.785 - 01:14:59.409, Speaker B: Not an objection per se, just clarification what happens to whatever. The only thing that was CFI for Fusaka so far.
01:14:59.577 - 01:15:16.865, Speaker A: Right. Verko. So I think like we can leave it in the Fusaka. We can leave it as CFI for Fusaka. Realistically, we're not going to do this all in the same fork. If we want to open another. Yeah, if we want to open another meta EIP today for Amsterdam, like, I can do that too.
01:15:16.865 - 01:15:38.485, Speaker A: I think at this point I would almost wait until we're like farther along with Fusaka to open the Amsterdam vip. But. So, yeah, so yeah, Virgo should stay cfi. I mean, I'm happy to open in Amsterdam as well to like have it be clear.
01:15:41.425 - 01:15:42.825, Speaker B: Yeah, as you want. Just.
01:15:42.945 - 01:15:45.057, Speaker A: Okay, yeah, I think that's right.
01:15:45.241 - 01:15:45.965, Speaker B: Yeah.
01:15:46.545 - 01:16:00.845, Speaker A: Yeah. Okay. Yeah, makes sense. And I'll try. I don't know if the EIP bot will let me do this, but I'll try and do this all in a single PR so that it's all kind of clear in one place. But I'll see if the EIP bot is. Yeah, lets me push this through.
01:16:00.845 - 01:16:56.435, Speaker A: Okay. Anything else on the fork scope? And there was a comment in the chat from Barnabas around like, implementation estimates for the four BLOB eips. So I think, yeah, in the next couple of weeks it would be good to think through both the data we want to see, but also the overhead of implementing these and we can make a call about inclusion once we know a bit better. But I think for everyone who's in favor of pushing this, we should. Now's the time to collect data and then also try to look into reasons why this could be an issue.
01:17:04.135 - 01:17:04.983, Speaker B: Okay.
01:17:05.159 - 01:17:22.735, Speaker A: Anything else on picture? Oh yeah. Anyone implemented 7742 on the ER side by any chance? Because then we can already start doing.
01:17:22.775 - 01:17:25.167, Speaker B: Some basic tests and seeing if we.
01:17:25.191 - 01:17:27.735, Speaker A: Can start increasing the blob easily just.
01:17:27.775 - 01:17:29.155, Speaker B: From the CL side.
01:17:30.055 - 01:17:31.279, Speaker A: But we would need at least one.
01:17:31.327 - 01:17:49.555, Speaker B: EL team to do this. One EL and one CL team to do this. I would hold off on that, at least for now, purely because there's enough changes for DevNet 4. Maybe we can coordinate on this after and by then we should have some more analysis data.
01:17:56.725 - 01:18:14.785, Speaker A: Thanks. And I know Max, you came on today as well because you wanted to share some updates about 7762. I'm surprised we have the time to actually go into this, but it seems like we do. So yeah, do you want to give some updates on the conversation that happened about the EIP over the past couple of weeks?
01:18:15.775 - 01:19:06.523, Speaker B: Yeah, I would just like to plug a few things from Data Always basically gave a very thorough database investigation of what this would mean for prices and I think the maximum increase this would cause to the average price per blob for the roll ups was I believe 16% for base, going from like an average of 6 cents to an average of 7 fl. And then also some. Some of the rollups have expressed support for this, whereas they would be the ones that are kind of potentially by them, including base Express strong support for the proposal. So I added those to the Eth Magicians thread if anybody's interested in taking.
01:19:06.539 - 01:19:07.415, Speaker A: A look at those.
01:19:09.155 - 01:19:10.855, Speaker B: Sorry, the Eth Magician thread.
01:19:14.115 - 01:19:38.465, Speaker A: Thank you. And I just posted that data always analysis in the chat as well. Anything else people want to chat about before we wrap up. Okay, well. Oh yeah, next time.
01:19:40.045 - 01:19:45.445, Speaker B: Yeah. So what is the target for Pectra at this point?
01:19:45.605 - 01:20:44.575, Speaker A: So DevNet3, we CFI these four blob related EIPs or three IPS that exist and then this hypothetical blob increase. We investigate all the blobs stuff in the next few weeks. If Pectora without that is ready to ship before that's decided, then we ship this. At that point we can have a conversation around whether we want a special small blob fork in between for Petra B, which we'll call Fusaka. We have EOF and Peerdas included. We implement those, we don't add anything else until those two are implemented. We CFI a bunch of stuff in the coming months as it comes up and then when we have a stable defnet running both Peer DAS and eof, then we decide what, if anything, we want to include alongside those in the fork and then we also draft the meta EIP for Amsterdam to highlight that vertical is CFI for it.
01:20:46.035 - 01:21:14.585, Speaker B: I think I'm asking more about what when are we trying to have a frozen spec for PETRA and do we have a target that we're working for right now? Because there's been some things thrown around even like forking early next year. And to do that working backwards, it kind of means that we really need things frozen in November and we need to start thinking about doing test nets in December.
01:21:16.295 - 01:21:50.255, Speaker A: I think based on one month away, based on the discussions we had around Devnet 4 today, it seems we need at least a couple weeks for DevNet4 to go live. I think it would be ideal if by next, I guess if by next ACD we are launching DevNet 4, we should figure out whether this is the last DevNet we want to launch for picture or not. This includes. Do we want to include all the Blob stuff?
01:21:51.035 - 01:21:54.895, Speaker B: I'm pretty certain that we will have another Devnet after Devnet 4.
01:21:56.555 - 01:22:39.935, Speaker A: I think this gives us roughly a month to make the final decision around all the Blob stuff. Then in parallel to this, yeah, once we have the DevNet 4 find some bugs, fix them, we start getting towards a spec freeze. And I think how quickly we can freeze the specs depends on how many bugs and issues we find. But yeah, I would consider this. We don't quite have this in theorem development, but I consider today like a feature freeze of spectra. And maybe we do this blob stuff, maybe we don't, but we don't consider anything else. And then hopefully in the next month we get to expect freeze.
01:22:40.915 - 01:22:50.043, Speaker B: Okay, so DevNet 4 is a good target before all core devs in two weeks to have that launched.
01:22:50.139 - 01:22:50.883, Speaker A: That would be great.
01:22:50.939 - 01:22:56.375, Speaker B: Or is that too optimistic or can we do sooner?
01:22:56.835 - 01:22:58.695, Speaker A: Perry said we could do two weeks.
01:22:59.925 - 01:23:13.549, Speaker B: Yeah, I mean that feels. That feels like a good timeline because there's now still some changes that need to be made given the removal of the request from the EL block and some updates to the engine API and.
01:23:13.557 - 01:23:33.855, Speaker A: Then the gas prices for like it's kind of small, but gas prices for BLS and then a bunch of other small PRs. So yeah, I think two weeks is like realistic, but one week would feel very short and obviously we can chat about this on next week's call, but I. Yeah, if aiming to launch Devnet 4 for two weeks from now feels. Yeah, feels good.
01:23:34.755 - 01:24:00.964, Speaker B: Okay, so let's try and get all of the spec changes merged by early next week. Definitely before all core devs next week. I think everything is open that we want to change about Devnet 4. I don't think there's anything that's being discussed that doesn't have a PR yet. It's just a matter of putting them all into the specs and then hopefully the week after Devnet 4 we can launch.
01:24:01.033 - 01:24:08.065, Speaker A: Yeah, I think I like that. Devnet 4 specs by ACDC and then Devnet 4 live by ACDE.
01:24:10.165 - 01:24:28.475, Speaker B: Cool. And we also have one more avenue for discussion that's a testing call on Monday. So if there's some PR that I don't know need some more discussion, please raise it. And we can do this synchronously on Monday. So we have everything closed by ACD next week.
01:24:31.055 - 01:24:59.245, Speaker A: That's great. Okay, Anything else before we wrap up? Great. Well, yeah, thanks, everyone. Ending five minutes early. Got spectroscoped timeline for DevNet 4. Yeah, appreciate everyone's participation and we'll talk to you all very soon.
01:25:02.545 - 01:25:07.665, Speaker B: Bye. Thank you. Thanks. Thank you. Bye. Bye. Bye, everyone.

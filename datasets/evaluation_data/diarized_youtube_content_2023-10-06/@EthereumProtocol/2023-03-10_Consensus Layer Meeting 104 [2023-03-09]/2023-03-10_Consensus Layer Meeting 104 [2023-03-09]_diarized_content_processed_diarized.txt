00:06:06.900 - 00:06:43.310, Speaker A: Welcome to ACDC 10 four. This is issue seven three eight in the PM repo. Looks like a relatively light schedule, at least as planned. Capella Deneb, some spec discussions around the verge, then any sort of closing remarks and a quick SSD shout out. Okay, cool. So start with Capella. I believe Gorely is imminent Tuesday, so call it five days.
00:06:43.310 - 00:07:37.660, Speaker A: Any announcements or discussion points around Capella? Tim so we have the blog post out which has all the client releases except Nimbus I believe so. Expect an update to the blog post from Nimbus and if they have it released out, maybe they can give it a shout. And then on Monday at 1530 UTC, we're going to have another community call to answer people's questions about Capella. Shanghai, if a couple folks on the clients or research spec team want to show up, that's always great. People usually have client related or spec related questions. Yeah, it's pretty much yeah. Each staker is doing a live stream.
00:07:37.660 - 00:07:52.560, Speaker A: This is in the blog post as well. So it's at 10:25 p.m.. UTC on Tuesday. Each staker is going to start a live stream at 10:00 p.m. UTC for anyone who wants to watch the actual upgrade on Gordy.
00:07:53.480 - 00:07:57.990, Speaker B: And the Nimbus release is being prepared as we speak. It's likely to be out today.
00:08:01.400 - 00:08:41.910, Speaker A: Okay, great. We'll update the blog post then and maybe tweet it. Can I ask question about BLS change credentials and if there are any plans to flood the network on Gurley at the change or do anything which looks like what we expect to happen on main net, not in a concerted effort, not in a plan. Concerted effort. The teams could spam a portion of them if they want. I don't believe that the DevOps team has.
00:08:44.440 - 00:08:56.600, Speaker C: Yeah, we don't have any plans to do this on Gurley. We have done so in Devnets in the past and haven't noticed any real issues. But if there's concern then we're happy to coordinate that for Gorli.
00:09:00.380 - 00:09:40.990, Speaker A: Yeah, I guess if it's possible, why not especially? Gorli probably has more nodes than the networks we've run, so a little bit of different gossip pattern. Granted, I would withhold some amount just so that we don't forego the ability to test further BLS changes in the future. Okay, other capella discussion points for today.
00:09:42.960 - 00:09:50.012, Speaker B: I have questions about builder and relayer ratings, but I don't see the relevant parties here.
00:09:50.066 - 00:10:08.070, Speaker A: So there is an MVB boost community code an hour up to this end. So if you're a builder relayer, you have questions, feel free to join that code. Thanks, Terrence. Is there a link to that?
00:10:09.080 - 00:10:34.110, Speaker C: And just following up on that one, we did have a couple of mev related scenario testing. So we had Mario's mock relay running on main net shadow fork two, and we asserted that the circuit breaker works with taking the relay offline, asserting local block production, having x number of blocks missing in a row or in an epoch, and having the relay serve invalid data.
00:10:36.820 - 00:11:21.502, Speaker A: Fantastic. Thank you, Perry. Okay, great. Other capella related discussion points for today. Okay, moving on to have. It seems like one of the most lively discussion points still is getting these beacon APIs, blob signing PR merged. Sean, we did discuss this on Tuesday.
00:11:21.502 - 00:11:23.170, Speaker A: Is there a status update?
00:11:25.690 - 00:12:24.600, Speaker D: Yeah, so I think on Tuesday we were thinking we would have blobs just blinded by default in both current block production endpoints, but further discussion on the pull request. Some other use cases were brought up for having the full block signing flow also include full blobs. And that'd be for, things like. That would be good for a vouch. That would be good for separating a beacon node you want to use for proposals versus a beacon node you want to use for verification and also broadcasting sign blocks to multiple nodes. So I think there's enough of a desire to have unblinded blobs in the current full block flow that updated the PR to reflect that.
00:12:27.050 - 00:12:30.730, Speaker A: Does that mean you can optionally have them blinded?
00:12:31.390 - 00:12:44.418, Speaker D: So how it is right now is like we have one endpoint for full blocks and that will now include full blobs as well. And then the blinded block endpoint also includes blinded blobs.
00:12:44.614 - 00:12:53.120, Speaker A: Okay, so you have the stateful endpoint for blinded and then kind of like state, okay, got you.
00:12:54.310 - 00:13:54.180, Speaker D: And then the other thing is, I think people are on board with having just like a single request to submit assigned block and all assigned blobs, as opposed to splitting up that request just because it reduces the complexity around. When the beacon node responds to a message about whether it's published a gossip or imported the block, it simplifies that. And then one other point that's been brought up on that PR is generally, should we keep in mind means of providing blobs from a remote source that isn't p to p and design these APIs? And so there's still active discussion around that point. Maybe we should move it into an issue somewhere else. But the idea is that.
00:13:56.170 - 00:13:56.694, Speaker B: The idea.
00:13:56.732 - 00:14:26.080, Speaker D: Is that obviously home stakers who at their limit with bandwidth might not be able to follow via gossip. So having like a remote blob server might help these cases. Even though it's obviously better to be participating in gossip. Maybe a remote blob server is something that's like better than forcing homestakers to exit the validator set.
00:14:28.850 - 00:14:33.150, Speaker A: Is this independent of production or do you mean a remote server to get them for production?
00:14:34.870 - 00:14:39.330, Speaker D: So I think both for production and for just following the chain.
00:14:42.230 - 00:14:46.340, Speaker A: Okay, but that should be relatively independent of this pr rate.
00:14:47.910 - 00:15:05.020, Speaker D: Well, an idea was brought up that maybe blob provisioning or providing blobs shouldn't be a beacon node responsibility. Maybe it should be like a separately defined API that a beacon node could implement. That was the question.
00:15:07.150 - 00:15:21.840, Speaker A: Got you. All right. I guess to keep the devnets moving, I'd love to get merged and shift that to an issue. Seems like a deeper discussion point than just the base signing here.
00:15:23.910 - 00:15:26.210, Speaker E: What do you mean by providing blobs?
00:15:28.630 - 00:15:30.450, Speaker D: Like just an API?
00:15:31.590 - 00:15:32.980, Speaker E: Providing to who?
00:15:36.490 - 00:15:56.410, Speaker D: For example, if you want to sync a node, you could add a remote server that sends you a blob for each block route you request. So to a beacon node for following the chain and to a validator client for producing a block.
00:15:59.630 - 00:16:31.240, Speaker E: Right? Yeah. Okay, so like providing, but I didn't understand that part because it's still the beacon node that verifies the availability of all the blocks. The beacon node needs to get all the blocks. But I guess there is a question of how do they get to the beacon node. Right, so that could be an internal functionality via KCP or an external blob provider, is that what you're saying?
00:16:31.850 - 00:16:44.170, Speaker D: Yeah, it's about should we keep, I guess, remote servers in mind when designing the APIs for how you retrieve blobs for different roles.
00:16:47.230 - 00:18:05.380, Speaker F: I would say probably no. Like we have an interface for getting blobs right already. But the other point is that we're in parallel also investigating ways to minimize the bandwidth impact of blobs in general. So I'm hoping that most of the additional bandwidth will be able to regain through optimizations. And then blobs and blocks aren't like the biggest consumer, they're big, but at the stations take up a lot of bandwidth as well. Those are the most problematic mean for the purpose of producing a block, I think we have to assume that the beacon node has the blocks and blobs, and then we're designing this particular API for the purpose of signing a new block and blob. So whether or not there exists a separate facility for downloading blobs somewhere, feels kind of orthogonal really, at that point.
00:18:07.530 - 00:18:59.160, Speaker G: I think there is another aspect too, where we basically say that beacon node can link up to an external service to download block which is basically not gossiping the block. So there are two kind of beacon nodes which are being proposed as of now in this particular functionality is that some beacon nodes which will gossip the block which is participate in the gossip, and other beacon nodes which will not, and which will then use this external service to pull the block. So overall reducing bandwidth for them, because even if they pull from external drops and they still have to gossip, then the bandwidth concern doesn't go away. So this is, I think, the additional concern that is also raised in the PR comment regarding not getting the blocks from an external service.
00:19:00.730 - 00:19:59.260, Speaker A: So I'm of the mind that the parameters here, given in addition to the optimizations available, should be tuned such that home connections can use this and that if we're beyond those limits, then we should be rethinking those limits and the optimizations available, rather than hacking a centralized server into here. I will also echo to Yasik's point that the blocks by root and blocks by range requests already do allow you to get blobs from an external server. Obviously that's generally tuned to the PDP. But you could have a service that relies on that, you could have a direct peer to connection that relies on that. And so it seems like reusing that is actually the appropriate path rather than having this creep into the beacon APIs. Or am I missing something.
00:20:04.600 - 00:20:19.400, Speaker G: In the external configured blob provider? Basically, there would be few, they cannot, which might not participate in the gossip of the block. I think this is the main thing in that particular proposal.
00:20:20.380 - 00:21:23.960, Speaker A: So even in such a case, you could not be on, not that I'm advocating for it, but you could not be on the blob topics, but you can still publish into them. And so you could publish to one peer into them, or a couple of peers into them, and not be on that topic and still participate, still push out. So again, I don't know if the beacon APIs needs to be handled that facility. I do think we should take this to an issue, because this is certainly a departure from assumptions and design, and I think a lot of people have insight they want to weigh into. Sean, would you mind opening up an issue and summarizing the discussion up to this point?
00:21:24.810 - 00:21:26.086, Speaker D: Yeah, sure.
00:21:26.268 - 00:21:27.080, Speaker A: Let me.
00:21:29.130 - 00:21:37.420, Speaker D: Get, should I open on the specs repo because it was brought up in the APIs, but I think it's sort of a broader question.
00:21:38.270 - 00:21:46.266, Speaker A: Yeah, that's probably reasonable, right? Because it's not just APIs, it's how do you use gossip, how do you sync and that kind of stuff in a low resource environment?
00:21:46.458 - 00:21:49.022, Speaker F: Okay, cool.
00:21:49.156 - 00:22:19.770, Speaker G: Another thing that I want to bring up sort of clarification on is that currently the blinded route we use for builder block, but more and more it seems like blinded route for normal execution block would also be a good, so good thing. So can we sort of add some endpoints or some sort of a flag for that? That this is an execution block on the blindly routes, produced blindly, then published blindly.
00:22:20.830 - 00:22:26.940, Speaker A: I'm having trouble hearing your mic and so I didn't quite catch the question.
00:22:33.900 - 00:22:35.370, Speaker G: Am I audible now?
00:22:35.740 - 00:22:37.930, Speaker A: That's a lot better. Thank you.
00:22:38.300 - 00:23:09.120, Speaker G: Okay, so what I'm saying is that currently we have blinded routes for builder blocks and for execution blocks we use full routes. Now with the blob being full on the execution block routes, I think it would make sense if we can sort of add another endpoint or some flags to indicate that we want execution block on the blinded route in the communication between validator and beaconaut.
00:23:09.940 - 00:23:17.108, Speaker A: Like if somebody wanted lighter weight communication, even if the beacon node had the full blobs. Is that what you mean?
00:23:17.274 - 00:23:17.990, Speaker G: Correct.
00:23:23.660 - 00:23:31.710, Speaker A: That does seem like a reasonable configuration parameter. I don't know. Would you put that in the request itself?
00:23:33.600 - 00:23:40.130, Speaker G: Yeah, sounds good. I have added it in the comments but I'll sort of clearly mention it.
00:23:47.030 - 00:23:48.900, Speaker A: Okay, got you.
00:23:55.040 - 00:24:59.090, Speaker F: There is one more related question. It's also brought up in that issue which is basically that should the blinded block endpoint provide non blinded blocks or other? If you get a block from the execution layer which is not blinded, should you respond with that block on the blinded request? Meaning that the beaconode has to keep it in its state while the validator client is we blind it and then we cache it because the response of that API is by design blinded. So the VC expects it as a blinded. Yeah, indeed. And we don't. So we had an issue about this where somebody was asking about it. The spec doesn't really say that you should do that.
00:24:59.090 - 00:25:59.270, Speaker F: Sorry, just a question. What about if the flow is SSD because you don't know in advance if it's blind or unblinded, even if the milestone is the same. So are you JsoN based only or what do you do when the necessity encoded? Well, we have two requests, right? One gives you a non blinded block and the other one gives you a blinded block. We assume that the validator client will do the kind of like multiplexing or selection of which of the blinded and non blinded blocks to use. So we don't really keep that in the beacon node because then the beacon node is stateless with respect to block production. It doesn't have to cache unsigned non blinded blocks ever.
00:26:02.920 - 00:26:23.180, Speaker A: Right. But it does seem like if somebody's using the stateful access point, the assumption is. But you're saying if somebody uses the stateful access point but you have the full block, you should just put it in the request so that it can be stateless in that mode.
00:26:25.680 - 00:27:20.108, Speaker F: Yeah, I mean that's certainly a convenience because then the beaconode doesn't have to remember anything. Like the beacon node is kind of forwarding data from either the proposer like the block builders, or from the execution layer. But it doesn't have a real interest in what happens in between until the block is signed, at which point it includes it in its own chain, sort of. It's this middle state where the block has been produced by the beacon node but it hasn't yet been signed. So it's not part of any canonical history. So it needs its own little space. And right now in my reading it's ambiguous whether beaconodes should support this or not.
00:27:20.274 - 00:27:28.530, Speaker A: Would you actually throw it away though? Isn't it actually good to keep it because it has pre compute and other things on it?
00:27:30.180 - 00:28:02.960, Speaker F: I would actually throw it away, yeah. I mean the attestation pools and so on. When you build a block we capture a snapshot of the attestations at that time and then the validatory client would sign it and return it. But it could be that the validatory client decides that it doesn't like that block and asks again. Right. And then we would build a new block or we could have multiple validator clients. In cases like this it's like that intermediate cache.
00:28:02.960 - 00:28:39.786, Speaker F: I see it as a bit annoying. I would have preferred actually a single request that gives you a blinded or a non blinded block depending on what the beacon node chooses to produce. And then the validator responds in kind. So it gives back all the data to the beacon node that the beacon node gave it. That would have been my ideal design. Yeah, to have them completely unified and maybe introduce some other headers that says.
00:28:39.888 - 00:28:43.038, Speaker B: Oh, the beacon node is responding back.
00:28:43.204 - 00:29:01.490, Speaker F: With this particular, the blinded or unblinded version. So even if we are going in SSZ, the VC can do the decoding accordingly. Yeah, exactly like that. One unified request.
00:29:07.720 - 00:29:08.180, Speaker A: Yes.
00:29:08.250 - 00:29:37.790, Speaker D: Is that something we would want to try to migrate to as we're changing these endpoints for blobs? Because I agree, it does sound nice. And we have actually seen missed proposals before with Lighthouse in this interaction between the blinded flow and fallback where you're switching beacon nodes and we assume the beacon node you're talking to has the block cache. So that design does sound better.
00:29:39.920 - 00:29:44.210, Speaker F: I mean, it's an appealing moment in time because we have to muck around with that request. Anyway.
00:29:48.420 - 00:29:52.370, Speaker D: I'm happy to make the updates if people are all on board.
00:29:59.020 - 00:30:30.140, Speaker A: Yeah, no opposition. Cool. Anything else on this or beacon APIs in general? Great. Other DnAB discussion points for today.
00:30:33.870 - 00:30:37.980, Speaker B: I mean, the SSC stuff is also kind of.
00:30:38.350 - 00:30:47.840, Speaker A: You did drop that link. Yeah, if you want to give us the update on the link you just shared, that would be great.
00:30:50.610 - 00:31:34.320, Speaker B: Yes. Essentially I was asked to create this summary of all the eips that are related to transitioning the Merkel Patricia tries to SSC and it is something that will be looked at by all teams, especially the execution teams, just to review them, provide any feedback. I had a discussion with Marius today in the sharded data channel. I also linked it from type transactions. That's the canonical channel would be great. Just so that we could discuss it next week maybe.
00:31:41.970 - 00:31:47.760, Speaker A: Okay, thank you. Any further comments or questions on here before we move on.
00:31:52.720 - 00:32:38.520, Speaker F: I could talk about a pr that I raised. It was mentioned during the 4844 decoupled development, which is basically that when we receive a block or an attestation, we don't know the slot of the parent or block that this entity is derived from. Right? So for example, when we receive a block, we don't know if the block is building on a parent that has already been finalized, if we don't know the block root of the parent. And the same thing for attestations.
00:32:40.300 - 00:32:40.616, Speaker A: We.
00:32:40.638 - 00:33:20.624, Speaker F: Don'T know if we're receiving. Kind of like a block route for a block that was very old because we never transmit the slot, only the block route. Right. So what we have to do in order to discover the slot is to download the block and then figure out whether we should keep these other things around. So there's a pr I open. I don't have it in front of me right now, so I don't remember the number, but I'll post it to the consensus dev channel. The idea is to include the slot whenever we have a block route in the protocol.
00:33:20.624 - 00:34:07.364, Speaker F: So that's kind of like in the attestations there's the beacon block route. You could also put the beacon block slot in the block. You could put the parent slot and so on. And so forth. I wanted to guide interest for this. It's kind of like a small change which enables a few more checks, like a few more sanity checks before we allow gossip and it closes a few little loopholes that otherwise require resorting to, let's say, uglier constructs like bad block lists and things like this. I did not finish the pr in the sense that I provided an example of what it would look like.
00:34:07.364 - 00:34:33.630, Speaker F: But I haven't really gone through all the possible places where the slot should be. If there's, like a clear no right now, then I'm just going to close that pr and save myself to work. If it's a maybe, then I can invest some time in it. And if it's a yes, then I can invest some time in it with urgency. So if you fall anywhere on that scale, do let me know.
00:34:40.740 - 00:35:59.130, Speaker A: Yeah, I'd love some engineering input here or on that PR to know that if others see the similar issues and similar gains here, it's 3249 on consensus specs. I certainly understand the motivation, but you all would know better the pain. Okay, if you haven't taken a look at that and have an opinion, please do and leave a comment. Okay, other Daneb discussion points. Okay, I believe Guillaume has joined us. There is the verge vertical stateless spec draft up in the consensus specs. As a PR, it's been up a little bit more than a month.
00:35:59.130 - 00:36:08.700, Speaker A: There's been a little bit of review, but Guillaume wants to give us a quick walkthrough to let us know what's on this feature. Guillaume.
00:36:12.690 - 00:37:16.658, Speaker B: Muted. Okay, yeah, so just wanted Indy to make a very quick introduction. So there's that pr that's called, that's number, and the idea is very simple. You just add to the execution payload, you add a field execution witness, and this is a structure that is described further down the document, so we don't have to go through every single field. But basically, one of the points of bringing that up today was to get your attention on this. But also, there's a couple of questions I wanted to raise. One of them was that both the execution payload and the execution payload header have the entire structure, and this structure can be fairly big.
00:37:16.658 - 00:37:33.000, Speaker B: So I wanted to figure out what the opinion was. Should the header contain the entire witness or not? If not, I suppose the witness would be transferred a different way through a different type of message.
00:37:34.670 - 00:37:35.580, Speaker A: How big?
00:37:36.350 - 00:38:10.660, Speaker B: Well, in JSon, it's like an array of values of three values. Yeah. I didn't get exact numbers, so, by the way, I wanted to say we just relaunched Kelstin with this format today like a couple of hours ago. So I didn't get exact numbers. I can share that after the call. But we're talking about an array with 1000 entries, right?
00:38:13.430 - 00:38:15.334, Speaker E: We have estimates on that.
00:38:15.532 - 00:38:23.762, Speaker B: We do. I'm talking about the JSon itself. I don't know. Yeah.
00:38:23.916 - 00:38:25.974, Speaker E: Wait, why is this a JSon?
00:38:26.102 - 00:38:38.990, Speaker B: Because it's. I mean, that's true. It's also passed over the network, but this field is provided by the execution engine, the execution layer. So it also has to go over the JSON RPC.
00:38:42.210 - 00:38:55.022, Speaker E: But as binary, we know it's probably like 100, 200 kb for typical block and up to two megabytes in the worst case. Is that our estimate?
00:38:55.166 - 00:38:56.900, Speaker A: Yes. Okay.
00:38:58.470 - 00:39:05.320, Speaker E: And. Yeah. With JSon, probably a factor of a bit more than two on that. Right?
00:39:07.130 - 00:39:26.750, Speaker A: Yeah. My question would be, do you need the execution payload header? Are there things you can do with the execution payload header where you need the entire execution witness? Or is it if you have the execution payload header and maybe you're doing light client things, you just need a portion of the witness or none of the witness and otherwise you'd get the whole block.
00:39:28.850 - 00:39:46.226, Speaker B: So if you're a state full client, you do not need really the. Well, actually you don't need that data. You can get it from your own state if you're a stateless client. Yes. You will need the entire payload, but.
00:39:46.248 - 00:39:50.318, Speaker A: You'D also get the entire block. Right. You wouldn't just get the header.
00:39:50.494 - 00:39:52.022, Speaker B: Right? That's true, yeah.
00:39:52.076 - 00:39:58.950, Speaker A: Okay, I guess I'm curious if there are use cases where you'd want the header but the whole witness.
00:40:00.410 - 00:40:01.160, Speaker B: Yeah.
00:40:01.690 - 00:40:11.340, Speaker A: And that would help me understand if you'd want to ship this with the header. Because my gut is to do the root. Unless there are some sort of use case here.
00:40:12.590 - 00:40:35.314, Speaker E: Yeah, there could be a case for it in some syncing type use cases like where you have a trusted source for this and you just want to update. You want to update your state using it because it does contain everything you need to update the state. But I don't know.
00:40:35.512 - 00:40:40.430, Speaker A: But even then you could download the witness facility.
00:40:40.510 - 00:40:47.750, Speaker E: Yeah, but most of the time I think if you want the witness, you'd also want the full execution payload.
00:40:48.410 - 00:40:49.160, Speaker A: Right.
00:40:53.390 - 00:41:12.350, Speaker B: Okay. I can modify this to be just the root in the header and if indeed there's a need, we can change it again. But, yeah, I don't see any immediate need for that. For the whole witness in the header.
00:41:14.770 - 00:41:16.720, Speaker A: Yeah, that's my intuition. Cool.
00:41:17.170 - 00:42:14.820, Speaker B: So there's a second point I wanted to address or at least raise. This is the transition when you perform the upgrade. So the execution witness I suggest would be empty, because it's not really clear to me what supposedly before the transition, the state is still officially an MPT. So it's quite difficult to, and potentially not really necessary to have a proof that would be proving a diff between MPT and Veracle. So currently my proposal is to have two empty fields on the transition boundary, so only have the execution witness after one block past the verge. Yeah, I just wanted to see if anybody had any opinion about this.
00:42:19.040 - 00:42:33.650, Speaker A: Yeah, it's unclear to me how we would do a different base case here. Seems reasonable, but if there's a different option, I'd love to hear it.
00:42:37.820 - 00:42:45.790, Speaker B: No, I mean, at least I'm not aware of any other option. But yeah, if someone is, I'd love to hear from them.
00:42:50.080 - 00:42:57.600, Speaker A: You don't really have the option to even do a pre compute because that block came in on the fly and you don't have the logic.
00:43:01.140 - 00:43:48.956, Speaker B: Well, I mean, in theory, everybody would have a vertical ready representation of the state long before the transition. So you could still provide a proof with respect to this state that is not officially enshrined in the blockchain. In practice, everybody will have this virtual state, but in theory, you could do the transition at the last moment. In theory, never going to work for real, but yeah, no, I think this is still the most sensical approach.
00:43:49.148 - 00:43:57.270, Speaker A: Okay, I'm taking a look at it. I'll think about if that messes up any proof stuff, but I would just probably go into.
00:43:59.480 - 00:44:34.380, Speaker B: Yeah, okay, great, thanks. And there was a last thing. It's more like a nitpick by Depp lion. Where is it? Like he was saying, yes, so you have those two fields, Cl. And he actually answered since. But yeah, this represents some symbols that are in the paper, the IPA paper. So it has to be read like a latex.
00:44:34.380 - 00:44:57.930, Speaker B: Feel like c underscore or subscript l and c subscript r. But apparently in the specs things tend to be lowercase. So I just wanted to ask if lowercase c underscore l and lowercase c underscore lowercase r was sufficient or not.
00:45:05.770 - 00:45:19.340, Speaker F: I think the uppercase was basically used to show that the Cl and Cr are just commitments. So it might be fine to have the lowercase, but according to the spec.
00:45:21.630 - 00:45:29.680, Speaker B: Okay, well, if there's no dissenting opinion, I'll change that to be like this.
00:45:30.210 - 00:45:34.480, Speaker A: Some live code review. I think you mean colon instead of equal sign here.
00:45:37.570 - 00:45:51.300, Speaker B: Possibly, yeah. I don't know that much python, but. Okay, good. Thank you for pointing that out. And with that, I think that's pretty much all I wanted to discuss today.
00:45:51.990 - 00:45:55.242, Speaker A: Is this built upon Bellatrix or capilla.
00:45:55.406 - 00:46:14.310, Speaker B: Right, so it's built upon Bellatrix at the. Yeah. Doesn't have a capella. Like, he's not rebased on top of mean. The mean. The goal is to have it on top of Deneb, obviously, but currently it's Bellatrix.
00:46:14.470 - 00:46:40.740, Speaker A: Yeah. Okay, cool. I guess keeping it on Bellatrix for initial review seems fine, and maybe letting the NEB stabilize and then rebasing on that instead of doing two rebases seems. Yeah, great. Are there any other gotchas in here, or is this primarily data structures on the consensus side?
00:46:42.490 - 00:47:05.660, Speaker B: Yeah, exactly. It's primary data structures. There's a gotcha. Indeed. Where is it? So there's a bit of a twist. For Kelstinin, I'm looking for the structure. Exactly.
00:47:05.660 - 00:47:42.990, Speaker B: So there are two values in this structure, three fields in that structure, current value, new value, and suffix. And for Chaostinian, we don't have new value. So ultimately you should have the pre state and the post state. But for Calstin, we just put the like. It's just more maintainable at this point, when more people join, when the code base stabilizes, it will be easy enough to add.
00:47:46.000 - 00:47:48.624, Speaker F: So you can already compute the post set?
00:47:48.822 - 00:47:49.570, Speaker B: Yes.
00:48:06.560 - 00:48:09.710, Speaker A: Okay. Thank you, Guillaume. Any other questions for.
00:48:14.230 - 00:48:39.910, Speaker B: This optional? Is this an SSC? Do you need SSC unions or just optionals? So it used to be unions, but Mikhail said that now optional was added to the spec. So, yeah, it's an SSC optional. It's still a proposal, like a draft. But if you don't need the union, then I guess writing it like this is the cleanest.
00:48:40.250 - 00:48:41.000, Speaker A: Yeah.
00:48:42.830 - 00:48:46.534, Speaker B: Currently, at least in the code, it's implemented as a union.
00:48:46.582 - 00:49:11.580, Speaker A: Yes, it. Okay, anything else?
00:49:12.590 - 00:49:34.370, Speaker B: Actually, there are no more questions. I had one. So Dennib is the name for it for four. And proto back in Austria suggested electra. Do I have the permission to start referring to this as electra.
00:49:39.670 - 00:50:53.170, Speaker A: In terms of the name of the fork? Yeah, I guess as long as it stays in this underscore features directory, I would give it like a feature name, because the fork ultimately might be this combined with some other features, and there's a modicum of a process in deciding fork names, so maybe we should respect that. But again, having something in underscore features as like a star name would, I think, be confusing. And this should hang out in underscore features until closer to forming the fork so we can kick that down the can no problem. How ready is this pr right now? This is still a draft so I didn't go review it. But if we want to merge it to the feature folder soon then we should make it executable and then we will found many small and big bugs in this process, right? What do you think?
00:50:54.660 - 00:51:29.730, Speaker B: Well, we have a running testnet at the moment so I'd say it's pretty ready. But yeah. Before we enshrine it this way, I assume other clients should implement it. I know Nethermind like tennisk has also an implementation of veracle trees. I don't know how far along he is from implementing this specific spec, but I would wait for Tanish Nethermine at least to catch up to this spec before we merge it.
00:51:42.590 - 00:52:52.636, Speaker A: Cool. Okay, anything else here? Thank you Guillaume, thanks. Okay, any other general spec and research discussion points for today? Okay, any other discussion points or closing remarks before we close? Excellent. Okay, seems like high priority. Continue on this beacon APIs discussion Sean, please ping relevant members when you do the next update. Otherwise a bunch of small discussion points that will continue in issues in prs. Talk to you all soon.
00:52:52.636 - 00:52:58.108, Speaker A: Thank you. Thanks everyone. Bye. Thank you.
00:52:58.194 - 00:52:58.732, Speaker G: Thanks all.
00:52:58.786 - 00:53:00.430, Speaker A: Bye bye everyone.

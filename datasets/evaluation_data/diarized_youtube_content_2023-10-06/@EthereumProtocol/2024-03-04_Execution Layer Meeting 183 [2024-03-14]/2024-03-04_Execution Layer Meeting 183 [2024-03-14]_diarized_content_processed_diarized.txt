00:01:48.810 - 00:02:38.714, Speaker A: And we are live for Acde number 180. Good job for everyone making it on time with the daylight savings change. I think next one of these the Europeans will have their local times all messed up for today. We'll talk about the fork, obviously, and then quick shout out to move all the eips to final if you're an EIP author. We should also quickly touch on Gordy as we're shutting this down after the fork, but it looks like it's already sort of falling apart on its own, then tons of stuff around the next fork. Petra. So we have dan on to talk about the impact of 30 74 on users.
00:02:38.714 - 00:03:33.050, Speaker A: Alex wanted to talk about some changes and tweaks to the BLS pre compile. Mike had some stuff on inclusion lists, we have some stuff on call data and then a bunch of opcodes if we make it through this and still have time. Paradigm has been working on some research around the impact of state growth and how it's distributed, both in terms of types of contracts and then the rate of growth over time. We have these couple of retroactively applied vips that we had to follow up on. And then lastly we had these testing calls that we'd been running up to the fork that gotten shorter and shorter as we got close to the fork and we're seeing if we still want them. Okay, I guess to kick this off, the fork went well. Great work, everyone.
00:03:33.050 - 00:04:21.760, Speaker A: We saw a little participation drop for a few minutes that seems to have resolved itself. But anyone noticed anything interesting or that they wanted to bring up and discuss as things went live? Even just a quick perspective on blob usage thus far would be interesting if anyone has. Yeah. Terrence, you've been manually inspecting every blob that came through. I think I have two points. The first point was that we were kind of worried that the blobs will be arriving later than the block because of their typically heavier than size. And from my first observation, for the first 24 hours, that hasn't been necessarily the case.
00:04:21.760 - 00:05:11.162, Speaker A: I see like 50% of the time blobs are arriving earlier than the block. I suspect typically that may. I suspect what happened was that the relayer from mev boost have some building optimization that just costed the blob right away and then while packing the block. But then I tried to confirm that with the flashbots, since their relay is open source, they say they don't have an optimization like that. So I suspect there may be like some private source relayer somewhere that has some built in code that does this, and then the second observation is the four choice rate. So I can post a graph after. So the first 24 hours, my local node sees like an average increase of three to four reorgs.
00:05:11.162 - 00:05:40.210, Speaker A: So yeah, I'm curious what everyone's note thinks. Currently, my notes sees more than three to four reorders per day. Sorry, three to four per day. And what was it before the fork? Okay, so before the fork is on average 15 reorders per day. Right now I'm seeing about 17 to 18. Okay, and these are generally depth one. Yeah, exactly.
00:05:40.210 - 00:06:26.720, Speaker A: Thanks for sharing. Maybe I can go next. Based on Easter startup data we have, we're seeing pretty much the same in terms of there are some reords, we're seeing that two or sometimes three, but they don't seem to be recurring and neither do they seem to be unique to post fork in terms of blobs. We're also seeing blobs arrive within the two second mark, mostly. That's at least what the heat map says. And this is for ingesting something like 6000 7000 blobs that have come through since the fork. But otherwise, I think we're not noticing anything unexpected.
00:06:26.720 - 00:07:17.268, Speaker A: Nice. Anything else? Is the base fee still at the minimum of the blob? Base fee, commercial. I hadn't started ramping up. I think it's mostly at minimum, still the base fees at minimum, but it's getting close. Like it's around the point where if there was much more demand, the price would go up. Okay, yeah, I'd be interested in mine doing it right now. Oh, okay.
00:07:17.268 - 00:08:05.570, Speaker A: Any other observations? Comments? Okay, well, again, great work, everyone. This has been a massive, massive fork that we've worked on for like over two years. So very cool to see it go live and be so uneventful. Yeah, we have the blobs. And again, there weren't just the blobs that shipped a bunch of other eips. If you are the author of an EIP, please move it to final now so we can wrap this up spec wise. I'll start harassing everybody about that next week.
00:08:05.570 - 00:08:52.752, Speaker A: And then lastly, Gordy. So we agreed to deprecate Gordy and shut it down after this fork. What we originally agreed to was basically at the earliest, one month after it went live on main net. So call that April 15. It seems like the network is pretty much in a state of chaos already, where there's less and less operators on it, I guess. Does anyone have any objection to just still keeping the date of April 15 as like a heads up for the community letting people know that in the meantime it's already not super stable. But yeah, at least keeping some nodes from client teams and DevOps running until then.
00:08:52.752 - 00:09:30.720, Speaker A: And on April 15, they'll be fine. Shutting it off. Alex, you'd be surprised by the things people do not know. I heard recently that Prism users didn't know they had to upgrade their execution layer. So probably worth another round of announcement just to give a heads up. Okay, sweet. Then moving on to the next fork, Prague and Electra.
00:09:30.720 - 00:10:16.292, Speaker A: So we've been discussing this for the past couple of calls, and there's kind of a mix today of people who want to provide additional context, perspectives on some eips that are being considered. And then I think 25 37 is the only one that we actually want to change something that's already been included. So maybe I'll swap the agenda a bit. Maybe we start with 25 37 just to get through those questions, and then we can cover all the other potential eips that aren't included quite yet and go from there. Alex, do you want to kick it off with 25 37? Sure. Thanks. Let's see.
00:10:16.292 - 00:10:56.784, Speaker A: So this is the EIP to add functionality for BLS pre compiles. So I guess just as a refresher, there's kind of two different things here. There's like pre compiles for the elliptic curve, the BLS twelve three one curve. There are also pre compiles for essentially this BLS signature scheme. And these are like different BLS, which is confusing, but good to keep in mind. And either way, I've been talking to various people in the community, like different cryptographers, different roll ups, a lot of people. And basically there's some things kind of not present in 25 37 right now that would be good to have.
00:10:56.784 - 00:11:47.490, Speaker A: So I wanted to go through these and kind of get a temperature check today to see kind of what we're thinking. Let's see. Yeah, basically people want more pre compiles, and I know that's been pushed back historically that there are already a lot in the CIP. But yeah, maybe we'll just walk through these different points and I'll see if anyone has any thoughts. So the first one is adding, well, yeah, this is where it could get wild, because it's probably, well, at least two, let's say two pre compiles for point decompression. So this is actually helpful for roll ups. I don't know how much we want to get into it, but basically right now, the abis right now for the pre compiles, take points on this curve that are in this decompressed form.
00:11:47.490 - 00:12:28.750, Speaker A: The concern is that if you're at l two, then data is more expensive, so you might want to submit the compressed points. But then the concern after that is that it's too expensive to decompress them sort of natively in EVM. So we want to add pre compiles for this. Again, this is something where it's really helpful for l two, maybe less helpful for l one, but this is an open question. Alex, as an alternative can just work only with instead compressed point. And so we are doing like consensus does. So changing the current pre compiled to work with compressed points.
00:12:28.750 - 00:13:36.204, Speaker A: Right, let's see. Yeah, I guess the concern then is just that we would, yeah, there would be lots of custom algorithms that call the pre compile many times to do lots and lots of additions. And if you add a decompression to each addition, it becomes queen nonviable. Right. So there's this trade off between computation and data. And the thinking was like, data is more expensive at l two, so maybe have this here versus it's slipped on l one. And is the argument against doing this just that it's like two more pre compiles into what it's already, I mean, the argument for all of this will just be there's way too many pre compiles because I think there's already nine or so, and then this will just keep bumping it up on the too many pre compiles points.
00:13:36.204 - 00:14:56.116, Speaker A: This is a bit of a broader topic, but I feel like at some point we should revisit the topic of doing eips that replace existing pre compiles with existing code implementations. And that would be a path to actually decreasing the number of pre compiles that we have to deal with over time, and especially now that we have Mcoppy. The most obvious one to start with would probably be the identity pre compile, and others would be some of the less used hash functions, for example. And then the idea would be that that could no, not swap them for new opcodes, swap them for pieces of solidity code that do the same thing. So from a user point of view it would stay the same, except it would realistically cost more gas. And then the arguments would be that if when in the future we end up doing modular arithmetic in the EVM, then that would be a path for eventually also swapping out a decompression pre compile with solar decode. Anyway, I think that, I've been thinking yesterday while writing the vectors test vectors.
00:14:56.116 - 00:15:52.824, Speaker A: Sorry, it's like if we really want to reduce number of pre compiles for this EIP, maybe we can merge the scalar multiplication with the multi scalar multiplication. At the moment we have two separates, but we do for pairings. I mean you can do like multi pairings and it's one pre compiled. So we can actually remove the two scalar multiplication and having the multi, the MSM that takes as well one as parameter, that is allowed at the moment as well. I don't remember why, but five years ago when we were talking about BLS, I think the pre compiles were all, there was much less of them. And then after a bunch of arguing we decided that different pre compiles for different operations was a better way to go. So happy to open up that can of worms again if people feel strongly about it.
00:15:52.824 - 00:17:16.404, Speaker A: But I don't know that we're bottlenecked by the actual number of addresses used. Right? It's more about the total complexity of the thing. Or is there a reason why using more addresses is somehow an issue? It's not more addresses, it's just we expose a greater surface for bugs. Basically if we have the set of pre compiles that we have right now, we don't care about any bugs in decompression, correct? Yeah. So the new functionality itself, that's something we should debate, but whether it's exposed through eleven addresses with individual pre compiles per operations, or say one huge merged address that's sort of orthogonal to whether we actually want to do the decompression. Right. So yeah, another note on that point is I'll be talking to the L2s on the next roll call.
00:17:16.404 - 00:18:44.240, Speaker A: I think they might be next month, but my plan is to get more direct input from them because I think this one impacts them a little bit more directly than at all one. This is also one of these situations where you could split it, like if we're unsure about the decompression, if we're still arguing about the decompression pre compiles when we get to the next hard fork, we could ship BLS in Petra and then ship the decompression pre compiles in the following fork if it comes to that. Yeah, that's an optional maybe I can just quickly get through the rest of these open questions here, because basically, yeah, they're just adding more functionality. You probably don't care about the exact details, but just to round them out there's essentially three groups really with BS twelve 381 we have pre compiles already for first two groups, there's a third group. And it'd be really nice for cryptographic applications to have this third group, again, more complexity. Then there was demand to change how the current pairing precompiler works, because basically you give it the right inputs and it just tells you if they are equal essentially under this operation. But again, for different cryptographic applications, you actually want to get the value back, not just are these two things equal.
00:18:44.240 - 00:19:56.572, Speaker A: Yeah. So ultimately, if there are any cryptographers on the call that want to argue for this, it'd be great to hear from you. Otherwise, it sounds like we have to make this decision around just the general complexity of CIP. One argument against exposing GT elements, and I think this is the key reason why we've so scrupulously avoided it, is basically because once you expose GT elements, you start requiring every implementation to actually have the same pairing, as opposed to requiring every implementation to have a pairing. And that is a thing that increases the complexity of making a new implementation. It increases the complexity of the specification, and it also kind of locks us in for the future to this algorithm. Right.
00:19:56.572 - 00:20:52.300, Speaker A: Like there's at least three different ways to compute a pairing. There's different, lots of different ways to represent extension fields and all of these things, and there's some mathematical way in which they're all equivalents to each other. But if we make an opinionated choice on one, that is a lot of stuff that's currently not spec code, that becomes spec code. Are there any use cases that actually require the. Or is it just purely. It would be nice to have this. There definitely are specific protocol constructions that are pretty esoteric use cases that I can think of.
00:20:52.300 - 00:21:56.090, Speaker A: One that comes to mind is basically being able to commit to a set of elliptic curve elements in such a way that you can multiply the commitments by a constant to get a commitments to something that commits to the elliptic curve points multiplied by a constant. And there's some use cases of that, but you have to really dig down the rabbit hole for Tim Narutbak is as well, one of the things he's GT. Okay, so I think that was helpful. I'm going to go back to these different stakeholders and try to understand better how strongly they feel otherwise. I think that's it for now. Awesome. Thanks, Alex.
00:21:56.090 - 00:22:33.582, Speaker A: Okay, the guest limit changes for 25 37. Yeah, that's on my to do list. I figured if we're going to change either the interfaces or the actual pre compile set, then we'll want to do that first. But yeah, that's on the way now just to say that there might be gas cost changes to the pre compiles. Yeah, I think there certainly will be. Got it. Okay, so yeah, let's keep discussing that.
00:22:33.582 - 00:23:18.590, Speaker A: And then worst case, if we haven't made a decision on this, as we start working on devnets and stuff, we can always implement the current version with the current pre compiles and go from there. Okay. I think this was the only sort of already included EIP we had stuff to discuss on, so everything else is stuff that's been considered for the fork. Yeah, so I think it probably makes sense to go through them one at a time and chat about them. But first up we have Dan from metamask to talk about 30 74 and specifically the impact it could have on users. Dan, the floor is yours. Awesome.
00:23:18.590 - 00:24:29.970, Speaker A: Thanks a lot, Tim. Yeah, I just wanted to make some comments in support of EIP 30 74 on behalf of metamask and consensus. Some of these will probably be redundant for some of the people here, but it bears saying, since it sounds like it's getting some pretty favorable support. So I think we all know that eoas have proven to provide an insufficiently flexible system for authorization for many people, and people are suffering millions of dollars in fund losses every day. And we believe that 30 74 is an opportunity for the protocol layer to bring some opportunities for user safety that can then be implemented at the wallet layer. So 30 74 allows EOA holders to adopt smart contracts to authorize their transactions, and that could eventually mean taking fully authorized one of one private keys off of hot machines entirely, and ensuring far more people are using patterns that we're continuing to refine for safety and usability in the contract account space. 30 74 has had some criticism for involving a dangerous authorization signature, and wallets have the ability and duty to ensure that that signature has the same user facing saliency as exporting a secret recovery phrase.
00:24:29.970 - 00:25:44.190, Speaker A: But once signed, the wallet will have the opportunity to permanently adopt safer patterns, including ones where a user never needs to view or export a key and a single signature can never transfer away all of their funds. We all know contract accounts have a lot of benefits, and 3074 can bring nearly all of them to existing EOA holders. Batching sponsored transactions approve and call multisig session keys delegation the EVM is the limit. It doesn't bring the ability to revoke the original signing key, and it seems unclear to me at this time whether that's possible even by EIP 7377 and others, since an outstanding signature is often enforced by a third party contract that could be unknown to the signer, so I'm glad that that goal is beyond the scope of this EIP. The current draft also has added a mechanism that enables the revocation of the authorization, so a hot signer could keep a revocation message available in case of emergencies found in a new contract account, even while not keeping the original signing key hot. So contract accounts have hard problems ahead for how to bring the most safety to their users. But at least with 30 74 we can bring our existing 100 million or so accounts along for the ride.
00:25:44.190 - 00:27:01.766, Speaker A: Thanks. Thank you. Any reactions? Thoughts? Comments? I know we've talked about this a bunch these past couple weeks, but yeah, Hadrian yes, I was wondering, what is your vision for users using this authorization scheme? Do you expect them to only go through relayer contracts that use this authorization, or do you expect them to continue using regular type two transactions? Yeah, it would probably involve eventually moving to a relayer system similar to 43 37, because if we continued using type two transactions, then the user would still have to have private keys. I guess they could keep a gas key local, and that's a design space that we'll be continuing to explore. But my impression and suspicion is that we'll be going towards something as similar as possible to whatever becomes the account abstraction norm. Because my understanding is that every time a user uses a normal type one or type two, I run type three transaction, their non increases and their authorization got revoked. So they need to resign them every time.
00:27:01.766 - 00:28:34.664, Speaker A: And you mentioned that this signature is as critical as like exporting your private key or your seed. So are you expecting user to do that more than once? No. If the user was using type one transactions directly, I would imagine that they are using those to relay their authorizing transactions for the accounts that signed 30 74 transactions. Because like you say, another type one transaction from the same EOA would invalidate the authorization signature if you have any particular relay system implementation in mind, because I worked on OpenJs ten and 457, I wanted to hear how this thing because one of the problems that happens is when a transaction kind of invalidates the following transaction or even itself. And in 437 we do a lot of bending backwards to make sure that it doesn't happen without the validation rule. Yeah, I'm a big fan of two dimensional nonces for that kind of thing. Obviously there's other systems possible too with like you could have like a graph of nonces or something, but I expect that contract accounts need to adopt patterns that solve that.
00:28:34.664 - 00:30:41.920, Speaker A: And 30 74 would allow UAS to delegate to schemes that solve that for them, I suspect two dimensional nonsense, but the design space is open. Vitalik. Yeah, I mean, one other thing to keep in. I mean, I know that, I think Mike is going to present more about this later, but I think the ecosystem is moving toward more and more realization that authorization logic does have to be in some sense kind of explicitly recognized by the protocol, because that's necessary for it to benefit from inclusion lists, which are becoming a more and more accepted, most practical solution for ensuring censorship resistance, especially in the context of continuing growing builder separation or builder censorship and builder centralization. One thing to keep in mind on this is that whatever these schemes we end up coming up with, it probably ends up making sense in the longer term to actually make them protocol features in some form or another. Yeah, I could see a benefit to including, if an account is used to make a call using auth call to maybe require including it in the inclusion list. Right? Yeah, basically think about making some sort of enshrined and more generalized notion of validation that is sort of like it's general enough that it covers what can happen in 30 74 auth calls and general enough to cover what would happen in 43 37 wallets.
00:30:41.920 - 00:31:59.820, Speaker A: But this is still one of those ongoing research areas that I think is valuable to highlight. Yeah, that makes sense. And it's promising to me that it seems like this would work well with conclusion list. Yeah. One more thing that I think is just also worth highlighting on the 30 74 stuff is that I think there is value in making sure that while eoas and smart contract wallets continue to be separate classes of entities for any of these new and really important functionalities that we give to them, the path by which eoas get them and the path by which smart contract wallets get them are parallel, as opposed to being two separate ecosystems. And there's precedents in the existing ecosystem that I kind of worry about even today, relatively spotty level of support for ERC 1271. And this is also one of those things that I think would be good to not neglect.
00:31:59.820 - 00:33:41.110, Speaker A: So like a 30 74 kind of os equivalent for smart contract wallets, which I actually looked at the EIP and it seems like that would actually be not even that difficult to set up, but also just a thing to blag irrelevant for future medium term stuff. If we have say, 30 74, if we have like the auth opcode, is the work to make this smart wallet compatible, just like an ERC. The great thing that 30 74 has is that it doesn't derive the address from the signature, it requires you to explicitly specify the address, and so there's a natural extensibility path for that to be smart, contract friendly. Got it. Any other thoughts? Question? Comments on 30 74? I see a question in chat. How quickly do we think this could be adopted by users wallets, et cetera? It's a good question. I suspect we could at least have some experiments in metamask this year because we're working on building an account plugin system, and so that'll allow us to kind of iterate and validate pretty quickly as soon as this is ready.
00:33:41.110 - 00:35:11.970, Speaker A: I guess one thing that I'm thinking about is the way we ship this stuff. We have usually almost six months, if not more, of devnets, and then we go to testnet and we go to Mainnet. Obviously this is something where the user flows matter significantly in a way that most random opcodes we add, they get exposed through solidity and then through contracts. It's like kind of a later part of the pipeline. But if we do, whether it's 30 74, whether it's something else, how valuable do people think it is to have invoker contracts or even like a fork of metamask running with some support for it super early on in the process? Or at what stage do people think we'd have to start seeing that one kind of practical path? And I think this actually goes even way beyond this particular discussion. Like I advocate doing this for execution tickets, for example, it would be to encourage some L2 to adopt a change before mainnet. And the principle there would be that that basically becomes something which is sort of halfway between a tested and a main net in a sense that it has real users and real value, but doesn't go all the way up to hundreds of billions of dollars.
00:35:11.970 - 00:36:05.170, Speaker A: I think the challenge with that approach is that it kind of creates a lessened incentive for the signers to do the work up front. We care the most about where the users are holding the most value today. And so while we might optimistically do that development, we tend to keep our focus on who's getting hurt today. Right? And I think the way I think about this is the safest thing is where you have a relatively smooth ladder from $0 depend on it to $500 billion depend on it, right. You don't want to have a step function where you go all the way from zero to 500. He wants to go from first zero to one and then one to 101 hundred to 500. So that at each level it already got secured by the level of effort that that surely comes from the previous level.
00:36:05.170 - 00:37:02.610, Speaker A: There's some comments in the chat saying like polygon is working on, and I guess then the biggest risk with those things is like the semantics of the opcode, right? Like is Polygon doing the exact same version that we're discussing today, or are they doing the version from a year ago? So, yeah, I don't know if anyone has context on that. As far as I know, they're doing the latest version that is specified in EEP at this moment. Got it. Eric? Yeah, I just wanted to join what Dan basically said. Agree with everything he mentioned. I do think that prioritization on the wallet space is hard as well. So it is important that this kind of thing is applied in the place where we have the most interest, so that we're able to invest in it.
00:37:02.610 - 00:38:07.902, Speaker A: But if it is applied in where the interest is, this is definitely going to be a priority. So like the adoption in order to provide user value, I believe it's something that will be invested on our side as well, and to some extent about the risk. As wallets, we also have our own risk mitigation and risk verification processes. So it's not like we're going to just open it up in the simplest way and everybody do whatever they want. We're also going to run through a process where we make sure we minimize risk as we introduce any new technology. So there's another layer of risk mitigation that is going to happen because we also kind of take the responsibility in this process. Jor? Yeah, I think there's no doubt about the features that 374 can add to applications.
00:38:07.902 - 00:39:08.360, Speaker A: The problem is not the features it can add, but the risks. Because as we know right now, the only way to have it securely is to whitelist specific implementations that are known to be good. And what we end up is that there is a list of whitelisted implementations, a set of implementation either by the network or by dominant wallets. These are the allowed implementation of 30 74. I would point out that a user choosing any piece of wallet software could then effectively choose the implementation they wanted to choose that choice. It's not like, I mean, you could put it at the protocol level and make it a small plutarchy deciding it. But the default is just that the market would choose users choose wallets, wallets choose implementations, much the way that contract wallet developers do today.
00:39:08.360 - 00:40:52.674, Speaker A: Yeah, but invokers does more than just being a wallet. Like if you want to have a paymaster wallet, you connect to some Dap that simply wants to pay for your transaction and you use its invoker, you basically reelect your implementation of wallet, giving your entire value of your account to this application just because it's cool and want to give you a feature like pay for your gas. Right? So kind of reemphasizing that it will be the responsibility of wallets to make sure that this election process is salient and as safe as possible. And I think one of the strengths of wallet teams making very deliberate choices around which ones they allow list would be in part that they could elect contract accounts that make it easy to, let's say, add features like batching without having to undergo the entire auth signature process. Again, I think that there are lots of off the shelf contract accounts today, Nosisafe with its modules and now the contract account module standard that are making it very trivial to have extensible contract accounts. And so I think it's very likely that most wallet developers will be able to have a very short approval list that allows users to then have the account extensibility they need without having to resort to this pretty dire authorization. Yeah, I only pointed out that a user actually performs this election of its wallet implementation on each transaction.
00:40:52.674 - 00:42:28.050, Speaker A: It's not a portion you do. Once I select an implementation, now I'm using mossy safe, now I switch to argent or whatever, that's not doing it on each transaction because that's not accurate. The user signs one authorization signature that authorizes a given invoker as long as that account's nonce doesn't increment, and from then on that invoker is able to send messages on behalf of that EOA. So as long as the user doesn't sign any more messages from the original EOA message, they can now have subscribed to another account authorization logic, including two dimensional nonces batching or whatever else, would it be reasonable, oh, sorry, Peter and the non guy. Would it be reasonable then to describe what 30 74 does in practice as being a temporary subscription to a smart contract wallet? So you sign this invoker authorization message. That invoker authorization message then temporarily turns your wallet into whatever smart contract wallet that invoker implements until you sign and send a new EOA transaction which increments a nonce and then disables that. That seems like a good metaphor, as long as you don't lose your revocation message and original private key, in which case it would be permanent.
00:42:28.050 - 00:43:42.178, Speaker A: Anskar yeah, I just wanted to briefly mention that while indeed on the protocol side, and I hope by the way, you can understand me some breaking noise. On the protocol side, it is this way that authorization could authorize an invoker to send an arbitrary amount of interactions from your account. Our original intention, and that's kind of where this kind of commit hash came in, was that we expected one of the dominant patterns to be a kind of signature for a single action only. So you could imagine basically signing over the hash of the specific transactions actions you want to perform or something, so that it could only be used once. Of course, in practice we would have to see which type of interaction would actually be used actively. So maybe the pattern of basically one time authorization and then the invoker always sending in your name could be possible, but I don't think it's obvious that in practice that would be the dominant pattern. So I think it's very likely that we'll see one signature only authorizes a single one time action from the invoker.
00:43:42.178 - 00:44:46.330, Speaker A: That would be the dominant form. I think the reason I would suspect that the dominant pattern would be to authorize an account that then performs the messages, is that if you don't do that, you're keeping the original private key around, which is kind of the security radioactive material that we're really trying to eliminate. So as a wallet developer, we have a lot of incentive to get the scary radioactive waste out of the user's hands so that the things they can do with their hot wallet are more constrained to things they might actually intend to do. So, yes, you're right, many implementations could compete, but I think there are some major security benefits to getting the main key off the hot device. Alex? Yeah. Just about the subscription model, the analogy that you said, if I understand correctly, a single wallet like address can be subscribed to as many invokers as it wants at the same point. Right, as long as you sign and don't revoke the it.
00:44:46.330 - 00:45:12.080, Speaker A: I believe the latest draft of the EIP actually requires that the authorization includes the latest nonce for the EOA. So only a single invoker can be authorized at a time. But using this authorization does not increment. So you can sign and sign and sign for as many invokers like a batch. Yeah, I'm sorry. Yes, you're right. Yeah.
00:45:12.080 - 00:47:14.630, Speaker A: Just wanted to raise a concern that this kind of increases the surface, the potential surface of code that the same address can have, as opposed to having an implementation of a wallet one at a time. Yeah, I think it is kind of similar to plugins for smart contract wallets. You could have an implementation of a smart contract wallet that you're using, but then you could authorize many different plugins related to that smart contract wallet. I don't really see it being terribly different. Okay. And I know there were some comments by Anzgar in the chat as well around prototyping an end to end flow for this, from a client implementation all the way to an actual wallet using an invoker. How blocked is something like that on us choosing to move forward with 30 74 or some other eIp? Is this something we can just have? Is it something we can just have one client team looking at and prototyping alongside the wallet and seeing, okay, can we get a flow that we like? Or is this something where actually getting everyone to commit to 30 74 or some other proposal or some changes to it is like the right first step? I mean, I definitely understand Vitalik's point that, like, easing in is almost always a beneficial approach.
00:47:14.630 - 00:48:39.722, Speaker A: I do think that most of the accounts that will benefit from this need the main chain to adopt. So while I think we're very happy to work on some prototyping with smaller chains, like polygon, I think the big fish is the big chain. And I guess maybe another way to frame this is how much value is there in prototyping, even on a devnet and testnet, relative to a chain with actual money? Do you get, like, 80% of your learnings from, like, there's actual value at stake here, or is, like, prototyping just the sort of user flow? What brings most of the clarifying value, if that makes sense? I do think that in this ecosystem, a lot of lessons come from the actual value that's weighed on the designs that we built. Got it. And I know, yeah, we've discussed, like, other proposals in the past. I think five eight six was the other one that that came up, and those were pretty much, oh, actually five eight six. And then there was one about the one time operation to make an eoa into a smart contract wallet.
00:48:39.722 - 00:49:17.770, Speaker A: I forget what the number is for that. 17377. Thanks. Like client. But I guess out of those three, I'd be curious to hear from, just like, the different client teams, do we still feel like it's worth considering all of them? Do people tend to prefer 30 74 over them? How do teams feel about the different ones? I see Hadrian's here, and I owe him a five eight six review. But having gone over it, I think that it follows. It addresses a kind of different issue.
00:49:17.770 - 00:49:52.674, Speaker A: It allows you to kind of have a delegate call from your eoa and execute code from your account. But it doesn't enable external contracts to kind of add functionality to your account. You're still signing with your EOa as far as I'm aware. Adun can correct me if I'm wrong. No, that's correct. Yeah. And then the other one is know using new transaction types require the EOA to be continuously signing signatures, at least the initial one.
00:49:52.674 - 00:51:19.920, Speaker A: So that means the account has to have ether in it. A nice advantage of 30 74 is that accounts, even with no ether, are able to subscribe to contract accounts for additional authorizations. Got it? I guess, yeah. I'm curious to hear how client teams feel about this. There was a comment as well about making 30 74 CFI might be enough to get people to consider it seriously and start prototyping and send a signal to the community that we're seriously considering this. Is that something different EL teams would want to move forward with? Do we want to look through the other proposals? Yeah, I don't know. Does anyone on the El side have like a strong opinion? Okay, if there isn't a strong opinion, then I think it probably makes sense to then go through the other proposals for Petra and then maybe once we've discussed the different ones, see if there's anything that stands out as being higher priority.
00:51:19.920 - 00:52:38.600, Speaker A: What should the next steps be for 30 74? So to me there's two questions. One is like, do we want 30 74 over other potential AA or like EOA improvement proposals? And then do we want 30 74 over all the other things we could do in the fork. I'm curious to understand how client teams feel about those two questions. I would like other people to answer the first question, but I think for the second question, I don't really know how important of a question that is to proactively answer. I think it's a question more that we should answer when we feel like we are either missing the target that we're searching for this fork, which hopefully is the end of the year, or we feel that the complexity of the fork features is too great. I don't think that trying to sort these on priority, a priority is the most important. I think we should only prioritize it and possibly kick it out if we realize that we are not going to be able to deliver on the timeline we wanted or with the complexity that we're hoping for.
00:52:38.600 - 00:53:21.726, Speaker A: And 30 74 is a very simple implementation of an eat. The complexity comes in the reasoning about the security model. So I don't think it's like something that is going to cause us to not be able to do other things that we want to do. Got it. Any other teams or people want to speak up? Okay. So yeah, I guess if there's no other strong opinions, then yeah, I would wait until we've reviewed the other proposals and then see if there's anything else we want to CFI or include. But I think for now, yeah.
00:53:21.726 - 00:54:26.542, Speaker A: In terms of next step for 30 74, one, making sure people are generally happy with the spec across the ecosystem. And it seems like we've made progress on there. It seems like there probably is value in prototyping and prototyping implementations to get a feel for the complex flow, but that will only get us so far. But yeah, aside from those two things, I think it's just a question of do we want to prioritize it? Any other thoughts, comments? Okay, we only have half an hour left, so I'll move on to the next ones. But yeah, thanks a lot, Dan, for coming on. And everybody else, appreciate you sharing perspectives. Okay, next big can of worms inclusion lists.
00:54:26.542 - 00:54:46.342, Speaker A: Mike Cameron. Cameron. Yeah. Hey, Tim. Hey, everyone. Yeah, I'll try and be pretty brief because I know that the 30 74 discussion ran a little long. So, yeah, I guess just wanted to update a few things on the Il side of things.
00:54:46.342 - 00:55:44.778, Speaker A: This is EIP 7547 and I thought it would make sense to start with just a couple of minutes discussing the rationale, like kind of stepping away from the technical details, which I think are better hashed out kind of async, and just talking through some of the meta reasons why. I think inclusionless and electra make a lot of sense. Kind of. First and foremost, the MEV landscape continues to evolve super quickly. I think even yesterday after the fork, there was kind of some chaos around titan builder not necessarily being able to include blobs. So then Beaver builder started building like 75% of blocks, and kind of this continual evolution of builders vertically integrating with relays, relay sophistication, timing games, et cetera, et cetera. Yeah, basically trying to make the point that if we commit to not doing inclusionless in electra, we let the MEV infrastructure continue to evolve for basically the next year and a half to two years without any kind of changes on our side.
00:55:44.778 - 00:56:21.190, Speaker A: I think that's a very active decision in itself. Like, not doing anything is almost as strong as of a decision as doing something. So that's kind of the first point I wanted to make. The second is that the scope of the aisle change is generally well contained. We've been working on this proof of concept spec, Poc spec. I'll share the link here. Yeah, just trying to kind of de risk and show across both the consensus layer execution layer and the engine API that the changes are pretty small, hopefully to motivate going for it in this fork.
00:56:21.190 - 00:57:24.300, Speaker A: The third thing I wanted to bring up is these out of protocol solutions. So this is actually something that's being discussed kind of again, even though we did discuss it before, but it's cool that people are coming to the same conclusion, but at a different time. The thing I wanted to say about the out of protocol stuff is that, and I'll link a doc here, this is kind of the censorship resistance in Mapboost doc that I wrote a while ago. But the thing I want to bring up here is that the out of protocol solutions are actually pretty different in character than the in protocol one. And the main difference here is that in the out of protocol version, you can't do this next slot inclusion thing. So basically it's not really the situation where we can do something in rev boost and collect data on it, and then that derisks the thing we're going to do in protocol, because the thing we're doing in protocol is this next slot inclusion list, and the thing we'd be doing out of protocol would be same slot inclusion list. So that's my biggest beef with it.
00:57:24.300 - 00:58:19.590, Speaker A: But I do think there is value in potentially looking at some of the out of protocol solutions and potentially doing them in parallel, just because I think this is like a defense in depth thing, which is potentially really valuable. And the last thing I wanted to bring up is just that the current inclusion list spec and the design is super compatible with the endgame roadmap, like whether that includes EPBS execution tickets. There's kind of more recent discussions around these committee enforced ILS. That was a post from toas. And then there's also this idea of maybe multiple inclusionless proposals at the same time. I think all of these fit really nicely with the simple framework laid out with 75 47. So doing the first step along the path of building an in protocol solution to the MeV markets, I think is super valuable.
00:58:19.590 - 00:58:55.778, Speaker A: So that's kind of the pitch. I'm writing a short doc, kind of based on this set of arguments and a few more. So that'll come out on. I'm hoping to get that published by Monday. And then, yeah, hopefully we can continue the discussion both async and maybe on the forum. Yeah. I also just wanted to shout out quickly the core devs working in the ETH R D channel, the inclusionless channel photos, and Terrence Dustin Poon, Daniel, Sean Pejinder, Enrico Marius, Dan Roman, Francesco Vitalik, Tony Xiawe and Pintail.
00:58:55.778 - 00:59:51.034, Speaker A: Just like this has been really awesome collaboration over the past few weeks and there's a ton of activity in there. So if you want to learn more, if this feels important to you, definitely jump in. There's lots to be discussed and the last thing I wanted to bring up is that we discussed in the last all core devs consensus call, potentially doing another breakout room for inclusion lists I originally proposed for tomorrow, but I think given that I didn't open an issue in the PM repo and kind of haven't been broadcasting it, maybe it makes sense for early next week. But yeah, I just wanted to get a temperature check. Maybe we can kind of chat in the zoom chat about scheduling it. I proposed Monday next Monday the 18 march at the regular time. I'll just copy that in here so we have a reference to it.
00:59:51.034 - 01:01:05.490, Speaker A: But yeah, thanks Tim, for giving me the floor and definitely if any other folks who've been working on inclusion lists want to jump in and say their piece, then would love to hear that. Otherwise we'll just give the mic back to Tim. Thanks. Thank you Mike. Yeah, I'll start to see if there's any comments questions on what you just said and then we can talk about the breakout. But yeah, any thoughts or responses to Mike? I guess anyone from on the client team either strongly in favor or strongly against considering inclusion lists for the next fork? Russ would like to signal strong support for including it because, as Mike said, not doing anything is also a choice. Got it, thanks.
01:01:05.490 - 01:02:37.280, Speaker A: Any other teams? Yes, one small thing about inclusion list, while they are great, I'm not sure they are compatible with the end game because they are not strictly compatible with account abstraction requires some further work. Why are they not compatible with account abstraction? Because if a transaction may become invalid and you add it to an inclusion list, then it can't be included, but it's forced to. The way inclusion lists work is that they check the basic features of an account, like nons and balance, but with account obstruction they need also to check on chain validation, which might change Mike, any thoughts on this? I'm not as familiar with this. I'm pretty sure Vitalik was saying that it wouldn't be an issue, but maybe POTUS. Can I reply this? I think this statement was false. Part of the validation of the inclusion list is actually checking that the transaction can be executed, the current block and the next block. So it might be true that this is not going to solve in pens.
01:02:37.280 - 01:03:50.470, Speaker A: But this will solve for censorship of actual transactions. Yeah, I guess I was curious if it changes it all under account abstraction, like a user op versus a transaction. I guess being censored, a user operation right now is a transaction that can revert, which can be included. You can force user operation by adding a handle up. It will be forced, it will be revert on chain, for example, if some state was changed. But isn't that true? I mean, any transaction in an inclusion list could potentially revert based on the updated state of the chain before it gets included, right? No, I'm saying that with force three seven as an ERC, yes, it will force inclusion of a reverted transaction, which is not such a big problem, but small one. The problem with native account obstruction, where transaction is no longer valid, which means it can't be included because it depends on the state.
01:03:50.470 - 01:05:35.918, Speaker A: A lot of work with account obstruction how to handle such cases, but force inclusion might yeah, like Ryan yeah, I had a question on using ILS with any kind of account abstraction mechanism. Is it not the case that any bundler that's using a permissionless bundling network could submit their bundle as an IL? Like, why does the IL need to specifically be concerned with account abstraction? Again, depends on the model. With ESC four seven, there's no problem you can force an inclusion of a bundle. And the worst thing is that it's going to revert on chain because the validation doesn't prevent it from being included on chain. And here, see, once validation becomes part of the validation of the transaction, you can't include a transaction that fails validation. This is also true for I can you not have an IL that says you need to include this transaction from an EOA during the block, it becomes invalidated, and then the next block the EOA transaction is no longer valid. So that's why the design only commits to the address of the transaction rather than the full transaction itself.
01:05:35.918 - 01:06:46.462, Speaker A: That's the whole point of the no free lunch design. Okay, I think you need to look into the latest inclusion list logic. Andgar yeah, I just wanted to say, as a metaphor, given that any form of native account obstruction on layer one is still several years out, even optimistically, and thereby I would not include 30 74. That's separate. I think the understanding is general that this kind of inclusionless design might not be one that will be the final design forever, but at some point might need adjustment anyway. So I personally don't see an issue with shipping something that then verbally say, once we ship native kind of structure might or might not require updating. Okay.
01:06:46.462 - 01:07:53.554, Speaker A: And then I guess it seems like there's like general support for inclusion list and it's more a question of how and when rather than if. I don't know. I don't know that we necessarily have time to flesh out exactly the next steps on this call with like 20 minutes left and a bunch of other stuff to go over. But I do think it might be worth a break, a breakout for this, so that we can look a bit more deeply at the different designs. What's the implementation overhead of them, and whether they're realistic to ship this year, and whether in protocol designs or starting at the mefboost level first or doing both in parallel is the right approach. And then Mike is proposing Monday at 14 UTC. That seems reasonable to me.
01:07:53.554 - 01:09:44.520, Speaker A: Anyone have an objection with that way forward? Okay, let's do that then. Let's do a breakout next Monday, go over all of the inclusionless stuff in more detail, and then hopefully by either ACDC next week or ACDe the week after we can have one or maybe two specific proposals that we can make a call on and whatever we want to move forward with. Yeah, we'll set up the breakouts, but Monday, 14 UTC, people can pencil that in. Anything else suspect? We'll have a proof of concept the coming week or the week after? Because one of the other things besides just design was like a better understanding of complexity coming from that. Yeah, maybe that's actually a good thing to focus the breakup on is like what is the actual engineering overhead of in protocol inclusion lists? What does it look like to do it in Metboost? You want a proof of concept for implementation or for a specification? I thought there was an intent to do a proof of concept and implementation, but that certainly could not be the case. But just like in four days, the breakup room is being scheduled like next week. I'm basing this off of a conversation three weeks ago in ACDC, but that doesn't necessarily mean that a proof of concept was worked on.
01:09:44.520 - 01:10:55.870, Speaker A: I think there's different client teams working on different branches, but maybe we can use this breakout room to kind of just see where everyone's at, do a pulse check, and then also coordinate on maybe a more cohesive proof of concept like end to end in both a consensus client and an execution client or multiple. Yeah, I don't think obviously we can get like a full implementation done in three days, or maybe Marius can in the chat, but then the thing we could maybe get in three to ten days is at least an understanding of where we think the complexity would lie and having people looked at the spec and then understanding their client code and trying to figure out what the issues will be. But yeah, maybe we'll have a guess. Loadstar testnet by ACDC as well looking at the chat. Okay, yeah, this feels like a good place to end this part of the conversation. Sorry, drop something. We'll have the breakout on Monday.
01:10:55.870 - 01:11:46.160, Speaker A: We'll set up something on the pm repo to detail all of that. But 14 UTC, we'll see you there. Thanks Mike for the update. Okay, another large, not necessarily large change, but one with big implications. Tony's been looking at repricing call data to better discriminate between large users of call data like l two s and people who use just a bit of call data in the process of doing more regular transactions, and has put up a bunch of impact analyses data and charts on this. Tony, do you want to give some background? Yeah, sure. Thank you.
01:11:46.160 - 01:12:52.242, Speaker A: Yeah, to give you some background, it's about EIP 7623 increase call data cost and the main goal of the EIP was to reduce the maximum possible block size by increasing the cost for non zero byte call data. And it is doing that by introducing a floor price for call data that is currently set to 68 gas per non zero call data byte. So increasing it from 16 to 68. And over the past week I've gathered some feedback and the main feedback, the main concern was just to do more analysis on the impact of the EAP in the agenda. You can also see a post that already analyzes the impact of the EAP, and the result was like 4.5% of all transactions would be affected and only 1% of the users. And I did some more analyzes that I post in the chat here.
01:12:52.242 - 01:13:51.000, Speaker A: It's basically a table with the most used methods and their median and total gas consumption. Split it in EVM gas and call data gas. And in the table you can already see which methods would be affected by the EAP and which not. And one thing that is currently still under consideration is the exact cost of the call data after increasing it. So should it be a 68 gas per call data byte, or maybe lower? Maybe setting it to 48 or something? Yeah, so basically thinking about the 16 times four series here. But yeah, open for feedback, especially on that number. The goal is to not affect regular users and existing applications while still reducing the maximum possible block size.
01:13:51.000 - 01:15:21.334, Speaker A: Thanks. Any questions? Comments? Thoughts on this? Did you decide now whether the deployment cost should go into the calculation or not? Yeah, so as of now, the deployment cost is inside the conditional formula. Have you looked like, have you did the analysis with both, or do you know what the difference would be for people deploying contracts? I guess by including the deployment costs within the conditional formula that this helps people deploying contracts. So it would mean that if you deploy a contract with a lot of call data, you might still be able to not hit the floor and still get the 16 gas call data price. If you take it out outside of the conditional formula, I guess then this would get harder. But I think it's only a very small number that should be affected. Makes sense how, I guess.
01:15:21.334 - 01:16:42.670, Speaker A: Have you reached out to l two s, basically the big users of call data today, which ostensibly have shifted their usage to blobs, but is anyone going to be really mad at this when it goes live? Yeah, so I had contact with a few l two so far. I'm also planning to introduce the eap and the roll up call. I think that's the perfect place to get more feedback on that. But so far, the only concern was raised by teams that cannot really escape to blobs because they need their call data inside the evm. And you can think about stark proving on chain proofs, but also Merkel proofs, or l two withdrawals that sometimes take a lot of big Merkel that uses big Merkel proofs that might be affected and cannot escape to blops. So this is the only concern. But, yeah, I guess I'll still need to analyze how four eight four plays out now and then also how much the final increase in gas would be for those teams that cannot move to blobs.
01:16:42.670 - 01:17:23.500, Speaker A: Got it. And as I remember, the implementation for this is quite simple. Right. It's a pretty trivial change in the evm. Yes. Okay, so I guess here it probably makes sense as a next step to just one, bring this up on roll call, like Tony was saying. Two, obviously see sort of how call data and blob usage continues to evolve in the next couple of weeks.
01:17:23.500 - 01:18:19.910, Speaker A: But if we want to add this to the fork, know, one, two calls or even after that, it feels like the type of thing that's just easy to quickly add and then add to Devnets as we're working on them. Does anyone have any other thoughts or suggestions about how to move this? Tony, I guess, let us know what else you say on roll call. And, yeah, we'll talk about this in a couple of weeks. Thanks for sharing all this. Thanks. Okay, there was one new EIP, I don't know that we've talked about this on all cordes before that was discussed in the agenda. 7645 aliasing origin desander.
01:18:19.910 - 01:18:40.190, Speaker A: I know, I believe. Cyrus. Cyrus. Hope I'm getting your name right. Cyrus, can you hear me? Your mic is really bad. Really bad. Yeah, you sound like a robot.
01:18:40.190 - 01:19:12.110, Speaker A: Let me see if I can switch to a different quickly. How about now? Oh wow, my end day. Yes. Yeah. Do you want to give a bit of context on the EIP? Can you hear me now? Yes, we can. Can you hear me now? Yes. I don't think you can hear us anymore.
01:19:12.110 - 01:19:55.750, Speaker A: Can you hear us? Oh, testing. How about now? We still hear you. Can you hear us? All right, well, I'm just going to keep going. Can you hear me? I can't hear you guys. Yes, how about now? We can hear you. Just go for it. Okay, I can hear you now.
01:19:55.750 - 01:20:23.150, Speaker A: That's good. Sorry about that guys. All good. My name is Cyrus Atkinson. I've been around Ethereum since 2014 when the network went live. In 2015, I wrote some early documentation, stack overflow, q and a, some instructional videos, and I presented my project at Devcon one. All that said, I am definitely the dumbest person on this call when it comes to the EVM, so please bear with me.
01:20:23.150 - 01:21:30.260, Speaker A: 76 45 so origin is an opcode that is sort of a relic. It represents the account that originated the action and paid for the gas for the transaction, which is, and until we get true AA, always the same thing. In mid 2016, it became generally acknowledged that TX origin for anything was bad news for a variety of reasons. There's an epic Peter Bora thread in the solidity repo that goes over these issues. One, origin can be used in a sort of cross site scripting way to steal assets or misuse authority. If that authority is delineated in TX origin terms, origin breaks compatibility. Since your contract can't be used by other contracts, and origin is almost never useful, it's still an outstanding question is, are there any legitimate cases of TX origin? So since then, documentation, audits, compilers, everything has warned against using TX origin, and it has been considered deprecated since mid 2016, I guess.
01:21:30.260 - 01:22:19.232, Speaker A: Note that for those searching that Peter Bora thread, removing TX origin from solidity is a completely different thing than adjusting the EVM assembly for one thing. So keep that in mind if you're reading the replies. Since people still used TX origin, one of the common illegitimate uses of origin is a lazy hack. Smart contracts use to determine if the caller has code and can do bad things. If origin equals a caller is supposed to ensure that the caller is an eOa. But in an AA future that might not be the case. So AA seeks to separate the payer of the gas and the originator of a transaction into two identities, one of which is so then the question is which one is origin? Either way you go, it creates problems.
01:22:19.232 - 01:23:23.752, Speaker A: So in 374, for instance, an EOA can trigger a smart contract to do an off call. Is that smart contract the origin, or is TX origin? Or, sorry, is the EOA that initiated the transaction origin for another? In some AA proposals, eoas can have code. Thus origin can have code, thus these origin equal caller checks break. So bottom line, origin is a tech, delicate tech debt relic that no legitimate use cases and it's standing in the way of robust account abstraction. So one solution, and this is 76 45 1st floated by Micah, though he can speak for himself on his views of it now, is to simply alias origin to sender that is, everywhere origin appears, it would be treated as sender. This would seamlessly fix some misuses of origin because the alignment of eoas to smart contracts breaks the alignment of eoas to smart contracts and nullifies origin as an impediment to account abstraction. The downside is it breaks backwards compatibility for some other misuses of origin.
01:23:23.752 - 01:24:24.724, Speaker A: Some would argue that these patterns were already broken and that we have no obligation to protect them, especially if it's holding back EVM evolution and future capabilities. So 76 45 is a straightforward proposal to do this aliasing. If 76 45 proves too harsh for the community to adopt immediately, I floated a precursor plan, no eIP yet, to simply ban any new appearances of the origin opcode in new smart contracts as of spectrum, which I guess is a consensus layer thing. I guess the idea is to put a full stop to all uses of origin, tease out misuses of origin that have been going on and educate the community, and then eventually do the alicing of 76 45 later yesterday, Dano Farron said that this pre deployment check for origin is not possible until we get EOF. But I'm not knowledgeable enough to know to be able to confirm or deny that myself. So that's the pitch, and I was hoping to get feedback. Thanks for sharing.
01:24:24.724 - 01:25:02.388, Speaker A: And yeah, we have Dano with his hands up, so please. Daniel yeah, so the problem with the pre deployment check is there's multiple uses for the code, not just EVM code people are using it for. Whether you think it's legitimate or not, they're using the code just as data contracts. That's one use, and the second because of the way solidity compiles EVM, it puts signature data after the code. And even some cases without the signature data, there's just some code data that exists in the EVM. There is no reliable way to differentiate the code from the data. And that's part of the problem that EOF is meant to solve, is to separate the code from the data.
01:25:02.388 - 01:25:41.376, Speaker A: So if banning origin is something that's valuable, it's something that can very easily be added to the EOF spec. I had considered it frozen to this point, but that's a very small addition and a very small change to the reference tests. I guess I didn't put my request in to speak about it on this call in the agenda, but a quick update on EOF, the specs frozen. We're doing final implementations, reference tests are being written. So that's a quick update there. But I don't think that banning an opcode in legacy EVM is in any way possible. Increasing the gas cost is one way to make it unprofitable.
01:25:41.376 - 01:26:09.612, Speaker A: That's the tricks we would have to do. Thanks, Peter. Yeah. Firstly, I would like to say I thought you explained issue b well there. I think that trying to ban it, as Dano has explained, is just really complicated, whereas turning it into sender is like pretty much the most trivial change you could make. Like, it's hard to imagine a more trivial change to the EVM. So I would be tempted to do that.
01:26:09.612 - 01:27:01.626, Speaker A: The main question is like to what extent have you investigated the patterns that are going to be broken? Because the challenge you're going to have is someone's going to say, well, potentially there might be some contract somewhere that is broken if origin always equals sender. And I wondered how much you'd investigated that. The auditing firm DDob did a study on this when it was investigating 374. So you can probably Google search that pretty quickly. Dedaub was the company, although I think there's been some disagreement about the conclusions they reached on that. And honestly that gets beyond my knowledge to be able to defend or whatever. Okay, thank you.
01:27:01.626 - 01:27:56.054, Speaker A: We only have two. Oh, Charles? Yeah, last comment, I was just going to say that I think generally changing semantics of opcodes is pretty dangerous because people could be relying on it for some particularly important thing and something else like just increasing the cost so that people know that it's like quote unquote deprecated oprode is like maybe a slicker change from a compatibility standpoint. Great. Okay, we have two minutes left. I think it's probably worth pushing back the state growth analysis to next call so that we have time to properly go over it. So I have a link in the agenda. I can put it here.
01:27:56.054 - 01:28:47.414, Speaker A: I strongly recommend everyone have a read at this. It's really good work by the paradigm team and I think it probably makes sense to have this high in the agenda next call so that we can go over any questions or comments on the research. But with 1 minute left before we close, I guess the one last thing I wanted to cover is we've had these fork testing calls happening every two weeks that have sort of petered out as we got closer to the fork. Does it make sense to keep doing them now? Would we rather cancel them and start them up again when we're sort of farther in the fork process? Any thoughts there? I'd rather cancel. Okay, perfect. Cancel confirmed in the chat. We'll do that then.
01:28:47.414 - 01:29:38.646, Speaker A: So on Monday there's the IL breakout, but we won't have the interop testing call. I'll delete that after this is over and everything else on the agenda that we couldn't quite get to today. I'll just bump to the next call. So again, state growth research, a couple eips for EVM changes, and then this discussion of the retroactively applied eips. And hopefully, yeah, by the next AcDe we have a good feel for what inclusion lists are looking like, maybe a better sense of the community's readiness around 30 74 or something like that. And then I think it probably makes sense to make decisions about additions to Pektra on the El side then, rather than over time today. And we'll see.
01:29:38.646 - 01:30:01.200, Speaker A: We might even get experimental Devnet by then. Looking at the chat. Yeah, thanks everyone for coming on. Again, congrats on the fork. Ethereum still running smoothly. Yeah, excited for this and talk to you all on the breakout Monday. Thanks everyone.
01:30:01.200 - 01:30:09.930, Speaker A: Thank you, thank you. Thanks team. Thanks everyone. Bye.

00:04:18.790 - 00:04:20.260, Speaker A: Think we're live.
00:04:21.190 - 00:04:57.380, Speaker B: Great, thanks. Welcome to awkward Devs consensus layer. This is call 119. This is issue eight seven four in the pm repo just shared the link. Seems like we have a light agenda today. No one added anything so I made sure to add a couple of things. So on Deneb, if there's any Devnet updates, any testnet updates or discussion, these are kind of the things on the critical path to continue moving forward on this.
00:04:57.380 - 00:05:30.810, Speaker B: And we might have a quick discussion on timing with respect to forking public testnets because that was discussed on ACde last week and it'd be good to see if there's any additional people here that want to echo or add some input. Then we can talk about research back, et cetera, if there are items and then open discussion on Devneb. On Deneb, are there any updates regarding devnets?
00:05:32.850 - 00:06:15.530, Speaker C: I can give a quick recap of Devnet nine. Devnet nine is now running for six days. We launched it last week, Friday and we've been quite good at participating. We have 90% participation right now. We found a bug this morning with rat. It was producing invert blocks and Bezu also has an issue that they're working on right now and there was some latency issues with Nethermind regarding max blob count. Maybe these teams can give an update on a bit more details.
00:06:19.580 - 00:07:03.930, Speaker B: Yes, today I performed spamming experiment like with sending large amount of fixed blob transactions to the Devnet nine. And in netermind we had bug with blob building like we were doing too many reads from DB like unnecessary ones. It's already fixed and right now we are building blocks perfectly fine. And yes, this experiment with spamming is not finished. Like it's about five k transactions to be sent more. So we will see if there will be some more issues.
00:07:12.740 - 00:07:55.980, Speaker D: So I also did some manual transaction work for all of the eips. So I sent some transactions to call the pre compiled some transactions for the blob hash opcode eleven 555-6567 515. So all of everything that is kind of within the EBM. So all of those transactions should be on definite nine. So if you can sync definite nine then you should be able to like it kind of verifies that you have all of these features enabled.
00:07:58.420 - 00:08:10.980, Speaker B: Nice. Anything else on devnet nine?
00:08:11.990 - 00:08:51.040, Speaker C: Yes, Mev testing has begun so I have deployed now Mev flood which will spam some juicy transactions that could be basically harvested by Mev boost and currently it's running on Lodestar but we still don't really see any mev transactions. There's a relayer run by flashbots now for Devnet. Here's the URL for it. There's still some bugs here and there and hopefully we can resolve it by the end of this week.
00:08:55.640 - 00:09:04.970, Speaker B: Great. Will we up the amount? What percentage of the network is actually connected in a web boost right now?
00:09:06.460 - 00:09:11.050, Speaker C: 265 out of 1325.
00:09:11.820 - 00:09:12.570, Speaker B: Cool.
00:09:14.160 - 00:09:15.550, Speaker C: About 20%.
00:09:20.340 - 00:09:32.580, Speaker D: I also plan to update the El bad block generator to also produce bad blocks in the execution layer with bad blobs.
00:09:38.680 - 00:09:46.010, Speaker B: Great. Anything else on Devnet nine?
00:09:48.780 - 00:09:52.250, Speaker C: Is anyone from Bezu here by any chance?
00:10:01.560 - 00:10:02.950, Speaker B: Doesn't seem like it.
00:10:07.170 - 00:10:09.920, Speaker D: Is anyone from Ethereum js here?
00:10:16.030 - 00:10:17.660, Speaker B: Does not seem like it.
00:10:30.960 - 00:10:51.830, Speaker D: So there's also some issue with Ethereum js sometimes encountering a bad branch and just being stuck on a bad branch. But I think they said they're working on it.
00:10:55.080 - 00:11:01.400, Speaker B: Got it. Fabio. Yes.
00:11:01.470 - 00:11:41.520, Speaker E: Talking for Bezu since Justin that is following Devnet nine is not here, but yesterday he found a problem with the production of blocks that contain blob transaction that after aria.org. So the problem should now be fixed, but I don't think is deployed in Devnet. So this is the status update for Bezu.
00:11:46.220 - 00:12:24.020, Speaker B: Thanks. On the consensus layer side, anything of note going on? Things stable? Cool. Is there an intended timeline on doing the limited run devnet ten that will test 70 514 the max inbound activation queue?
00:12:25.800 - 00:12:35.610, Speaker F: I think it would be nice to try and do that next week. If we have all the fixes for Devnet nine in by then, we can also deploy the padlock generator by then.
00:12:36.620 - 00:12:53.330, Speaker C: I would like to see all clients being able to participate and no more bugs really found for devnet nine before we proceed with the larger test. So we should have a very stable like 100% participation before we move on.
00:12:57.610 - 00:13:02.070, Speaker B: Are any of the issues and participation related to the consensus layer? Teams.
00:13:08.620 - 00:13:10.080, Speaker C: You please repeat.
00:13:10.260 - 00:13:16.380, Speaker B: Are any of the issues and participation consensus layer issues at this point, or is it execution layer?
00:13:17.280 - 00:13:20.524, Speaker C: I'm fairly certain most of it is execution layer. Yeah.
00:13:20.642 - 00:14:03.540, Speaker B: Cool. Yeah, I guess if the purpose of Devnet ten was solely to test the queue, then it'd be okay to move forward. But I agree that just it tests the queue and does just an interesting load test, so we might as well if we can have everyone on both sides. Okay, anything else related to Devnets? Mario?
00:14:04.280 - 00:14:29.550, Speaker G: So we added a single test case for the Evolteku scenario, but we are also working on expanding this idea to more test cases. We're planning on writing a tool that will probably help us reach more of the coverage with the timing of the blobs. But this is work in progress. But just wanted to let people know.
00:14:31.360 - 00:14:52.368, Speaker B: Cool. Yeah. Testing updates is the next thing, so thank you for the update. And, Terrence. Yeah, so I know Sean from my house brought this up. Have we started testing equivocation blob? Meaning that a block could have multiple blobs on the same index. They're equivocating, but they're not slashable.
00:14:52.368 - 00:15:39.052, Speaker B: But we definitely have seen some issues, if that plays out that way. So we're working on some features to mitigate this issue. But you will be due to test it. I can also help testing it, but I don't want to step on someone's toe if people are doing that already. So is this in relation to recovery when there was a bad one, or is this in relation to, like, DOS or both? It's relation to dos. So, say today you have a block, and then it points the KCG commitment to a blob, but someone sends a duplication of blobs with the same index, but the KCG commitment is different. So the P two p validation filter will filter the second blob.
00:15:39.052 - 00:16:29.870, Speaker B: And in that case, you should use RPC request to request it. But I guess some clients don't do that today. Got you. Yeah, I do think that some of the stuff Mario is attempting to do in hive is directionally like this. But more about do you get the messages that you need, rather than did you do the DOS mitigations that are going to make you safe? So there might be some complementary work to do in relation to getting some of these messages on a devnet. Point being is I wouldn't not do some testing here that you think is valuable, because I think Mario, they're trying to capture some of it, but I don't think they're going to capture all of it. Enrico.
00:16:29.870 - 00:16:31.006, Speaker B: Yeah.
00:16:31.028 - 00:18:11.120, Speaker E: I just want to say that the heavy tag that was implemented a couple of days ago was just in that direction, trying to produce these equivocation blobs. So the first block sent over the gossip was the one that is kind of malicious. And then just after half a second, the tech web will publish all the blob sidecars and blogs that are correct. So in case your client is not able to recover from that, it's because the first blob that have bad proof in it kind of hide the good one coming later, and you're not able to recover even by RPC call just later. So we fixed a thing on our site and Tekun now is able to request and recover from that. But yeah, I don't know how easy is to actually implement and include this Avil taco in a testnet because I don't know if there are clients that suddenly downscore the avil for some reason and simply disconnect from it. And since this will be the only one having the good blobs, you're not able to recover in any case.
00:18:11.120 - 00:18:15.120, Speaker E: Yeah, that's my issue.
00:18:18.480 - 00:18:50.820, Speaker B: Yeah. So hopefully we can capture the. Like, I see all these messages and I'm able to follow the fork on Hive. But yeah, I guess in terms of spamming the network, the options would probably be to hard code this as a peer that can't be downscored, which maybe I think some clients are able to do. But maybe I don't know if that's valuable to put on Devnet nine or more in more of an isolated environment.
00:18:52.280 - 00:19:40.480, Speaker E: Yeah, I was thinking also expanding on that. I realized that while we were doing the validation of the blobs, we were not checking that the key DG commitment inside the blob cycle was actually matching the one inside the block. So while doing the validation, we were keeping the commitment from the block and the poof. And the blob from the blob sidecar, effectively ignoring what was inside the blob sidecar. So everything was going fine. So we should maybe try to build some fuzzy logic spamming with weird blobs. Igard to capture.
00:19:40.480 - 00:19:57.930, Speaker E: To capture, if clients are correctly, correctingly discarding these weird blobs, because the gossip rules doesn't cover all the cases because the block is not available at that point.
00:20:02.910 - 00:20:04.570, Speaker B: Right Mario?
00:20:04.910 - 00:20:56.270, Speaker G: So yeah, one nice thing about adding this to hive is that we can probably just keep will like a list of every single bad blob that we are sending to the network. And then we can just go through every single CL client connected to the testnet just to verify that we don't have the bad blob in any of the responses, for example, from the beacon API. I think that should suffice to test what you're saying. The first thing is to get us a way to actually send these bad blobs into the, into the, into the clients. Once we are able to do that, we can, we can just simply make the verifications of the, of the bad blobs not being available anywhere in the clients.
00:20:57.810 - 00:21:19.590, Speaker E: Yeah, sounds good to me. Because in our case, I think we could have stored in our database a blob sidecar with the wrong commitment at the end. So by requesting via beacon API those blobs, you should be able to get those weird blobs from the DB.
00:21:24.690 - 00:22:03.450, Speaker B: Yeah, I was just checking to make sure. Blob sidecar by root. You're requesting by the block root so you wouldn't actually be able to respond to requests unless you actually got the block and then verified that your blobs are correct in relation to it on the blob sidecar by range. Will you respond to such a request if you haven't gotten the block yet to validate those blobsidecars? I would imagine not, but if you could, then that might be like a weird accidental send invalid messages around path.
00:22:04.990 - 00:22:17.520, Speaker E: At least in Tego we don't serve any of those blobs that are completely in a separated area, so it's kind of in a cache and not served at all.
00:22:17.890 - 00:22:44.560, Speaker B: Yeah, I would assume that. I'm just going to scan this and make sure that we make a note that the availability of the sidecar in relation to the block need to be satisfied. But yeah, I would imagine that just the engineering path through most clients would dictate that. Sean.
00:22:44.720 - 00:23:43.370, Speaker H: Yeah, so Michael from our team is also working on, I guess, similar to evil techu, like an evil lighthouse implementation. And the idea with it would be that it would, when it's proposing, be able to create things that are mostly valid, but maybe invalid in these exact ways we're talking about, which would be like a blob whose KZG commitments don't match blocks or whatever. So yeah, just letting people know we're working on a similar sort of tool that we could maybe use as a node that's proposing. So if we deployed it to a decent amount of the validator set on like a devnet or attack net or whatever, that could be pretty useful to get to a lot of scenarios pretty quick where it's like partially valid. Yeah.
00:23:48.630 - 00:24:44.048, Speaker B: Got it. Yeah, just a quick. I did look at the blobs by range spec and that it mentions that the sidecars must come from their view of the current fork choice. And blobs don't enter into the fork choice unless they've been matched up with a block. So it's good. Okay. Anything else regarding testing, Mario?
00:24:44.224 - 00:25:33.236, Speaker G: Yeah, I think I will just share the link to the document that I'm preparing for the blobs here too, so everyone can take a look. So the idea is just to keep on adding tests to this document. So please just jump in, read what we have written, and if you have more suggestions, please just comment on it so we can consider them if we end up adding this to hive when we end up adding this to hive. But yeah, the main ingredient of those tests is basically just having a tool which capacities to interject blobs and then just send that blobs to the network. So we're working on that. We have a possible solution, but nothing is definitive. But yeah.
00:25:33.236 - 00:25:37.240, Speaker G: In the meantime, please just add your comments if you have more ideas.
00:25:40.960 - 00:26:02.120, Speaker B: Thanks. Mario. Can you drop that in I guess the awkward devs or the consensus layer channel on the discord with a quick comment just so that people have it out of this transient chat?
00:26:02.860 - 00:26:04.010, Speaker G: Yeah, of course.
00:26:04.620 - 00:26:05.370, Speaker B: Thanks.
00:26:09.870 - 00:26:10.330, Speaker G: Tim.
00:26:10.400 - 00:26:28.338, Speaker B: So last week you were talking about sensitive timelines with respect to beginning to fork public testnets. I believe there were a number of layer devs there. Do you want to give a quick recap of that just in case there are additional people on this call?
00:26:28.504 - 00:27:47.690, Speaker A: Yeah, so I think last week it seemed like we wanted to do devnet ten and then move to forking gorely and ideally do that before dev connect so that we can have at least one testnet and potentially some time seeing it live before it happens. So I guess if based on what Barnabas was saying a bit earlier around, wanting to see the clients run clean on Devnet nine and then launch Devnet ten, I don't know how realistic it is to do all of that next week. If we could get it done before all core devs, I mean, we could then figure out when we want to fork Gordy on all cordevs. And then I think pretty much if we can't do that, then the next CL call. So on the 19th is when we really need to have done it if we want this to happen before dev connect. Because if we picked a time on the next awkward devs, then it could happen sometime late October, like two weeks or so after that, and then the CL call after that starts pushing into early November. And we probably want to get this done before people start heading out for Devconnect.
00:27:47.690 - 00:28:36.620, Speaker A: So I guess, I don't know, how do people feel about potentially being ready to move to Gordy in say like a week or two? And I think a question as well is how close to having everything on master and packageable in a release are different clients? Because ideally if we pick a date, say on the Thursday, then we can have the blog post out on the Monday or Tuesday. So give a couple of days to clients to put out a release. But it would be ideal for that. That stuff is already in master and it's more a question of what we put out than trying to bring a bunch of separate branches back into master and potentially having to spend a lot of time on.
00:28:38.110 - 00:29:24.346, Speaker B: Yeah, Andrew? Yeah. In terms of Aragon readiness, everything is merged into our development branch so we could release reasonably quickly. I have a question about the KZG ceremony. Is it complete for production and do we want to have our proper final KZG set up for Devnet ten? If not, at least I suggest to do it for Gorley. Yeah, I think we certainly want it on Gorely. Carl's not on the call. Does anybody have a view into where we're at on that? Yeah, I know Carl's working on it.
00:29:24.346 - 00:30:09.660, Speaker B: He had hoped to get it into the previous Devnet, but had some issues that needed to be resolved and is still working on it with the intent of getting it into Devnet ten, I believe. I think maybe Alex was also working on some of it or helping him. So if there's anything else, Alex, please add me. Alex, that sounds like you were not. Well, very tangentially, but yeah, as far as I know that's on the way. I thought that he had sorted it out, but is he on the call? I guess not. But yeah, I can follow up even later today and see what's going on there.
00:30:09.660 - 00:31:00.920, Speaker B: Yeah, I just pinged them too. Terrence. Yeah. I think my naive intuition is that I think we're a bit early in talking about 14 testnet or even a testnet schedule. Timeline aside, I think what I would want to see in the dead net before I put confidence in 14 on Testnet is that we test more relayer infrastructure, which is good. Today we have a relayer that's set up 20% using a relayer, but I would like to bump up the number and test that slightly longer. And another thing I would like to see play out more on the deaf net is just the blob scenario testing that real was sharing that if we can run more tests through that, we'll have more confidence.
00:31:00.920 - 00:32:16.980, Speaker B: Then again, clients still have bugs today. So I think it's like personally take is that we're still too early. Talking about 14 testnet are these things that if you saw over the next week, week and a half and things look stable, then it's time to have that conversation? Or do you think that it's a time horizon that is longer than that in terms of seeing bam and stability around that? I think one to two weeks, maybe too soon might take us like two to three weeks ish, that we should see improvement because you suspect that there is going to be stuff that falls out of it. Right. We're going to see bugs. Okay, so I guess we're in the phase where we need to be revisiting this on each of our calls to kind of get the updated status on testing and subsequent bugs so that we don't let it slip, but that you have low confidence that especially next week, that you're going to be ready to do so. And potentially on the two week time horizon, we're beginning to get some clarity, but no commitment yet.
00:32:20.110 - 00:32:45.220, Speaker E: Enrico, I just want to echo what Terrence said and also add the fact that I don't think we have tested any interoperab between clients, considering the fact that we have a new block v three API and Teco has not completed the implementation of that yet.
00:32:45.910 - 00:32:49.322, Speaker B: This is beacon node to validator client interrupt.
00:32:49.486 - 00:33:19.450, Speaker E: Yeah. So if there are out there guys that are using mixed deployment to run Gurley and, well, whatever testnet we decide to go to, we should have all the use cases more test on the builder flow plus all the API DCBN API tested.
00:33:20.050 - 00:33:30.590, Speaker B: Has everyone implemented v three? I know a couple of weeks ago that was not 100% clarity on that. Has any team not implemented the new methods? Sean?
00:33:31.030 - 00:33:31.346, Speaker E: Yeah.
00:33:31.368 - 00:34:03.680, Speaker H: So for Lighthouse, we have an implementation that's unmerged. It's like far along, but it's not in yet. And just to give like a broader lighthouse status update, we're in the process of getting DNA merged into our unstable branch, but I think we still need another week to get it in. And then after that, we'd like to have a decent amount of time before we actually cut a release to do regression testing on that, because it's just like a massive set of changes. So similar timeline with other teams outside.
00:34:07.400 - 00:34:44.450, Speaker B: Got it, thanks. Would it be valuable to do a BNBC interop related short term Devnet once people have all of those changes Merged? Is that something we've done in the past? How do we usually test that's. Have we ever tested that?
00:34:52.310 - 00:34:53.940, Speaker G: So hive is using.
00:34:55.190 - 00:34:57.634, Speaker B: Sorry, go on.
00:34:57.832 - 00:35:06.022, Speaker G: So hive is using Beacon plus validator set up everywhere. So is this something else that we are talking about?
00:35:06.156 - 00:35:23.002, Speaker B: Well, it's mixing the two. There's a common API between the two, so I could have Teku be in light health validator and some people presumably do so on mainnet, at least in the past.
00:35:23.056 - 00:35:39.780, Speaker F: We haven't really tested that on devnets, but if there was an issue, it usually spills out when we fork the first testnet because there's also like a million different combinations you can run everything in. So there's only so much you can test.
00:35:42.550 - 00:35:46.050, Speaker B: Well, there's a very finite amount of combinations.
00:35:47.830 - 00:35:49.286, Speaker F: Once you start adding all the.
00:35:49.308 - 00:35:50.840, Speaker B: External layer as well.
00:35:51.450 - 00:36:03.274, Speaker F: Yeah, but now we also have the builder API directly connecting to the relays without map boost, and we have third party software like, vouch. So there's kind of.
00:36:03.392 - 00:36:19.360, Speaker B: The matrix keeps expanding. Is it worthwhile at least doing some sanity tests around the NVC combos on Hive, or is that not a path we should open?
00:36:20.530 - 00:36:52.470, Speaker G: I think it's possible right now. It's hard coded, so if you start ateku beacon node, it will automatically start ateku validator client. But we can make that configurable. And I think it should be easy just to do all the combinations. But given that we are focusing on blobs right now, I'm not sure if we can do this in the next couple of weeks. But, yeah, it's doable in Hive.
00:36:53.770 - 00:37:05.390, Speaker F: Actually, if we want, we can just do this in Devnet nine right now. I don't think it would be overly difficult to change our ansible setup. We can just add a bunch of validators and spin up more instances.
00:37:07.810 - 00:37:08.222, Speaker B: Which.
00:37:08.276 - 00:37:12.910, Speaker F: Clients claim to be ready so that we know who to test for interrupt.
00:37:17.110 - 00:37:33.240, Speaker H: So all clients still support the block v two endpoint, right, with dynaptypes. Because we don't have the v three endpoint in Lighthouse, our validators will only call it v two, though.
00:37:44.880 - 00:37:51.890, Speaker B: Three endpoints. We have one, and we are currently implementing three.
00:37:59.320 - 00:38:08.740, Speaker H: Okay, well, we'll work on getting V three in pretty soon so we can test interrupt with other consensus teams.
00:38:11.420 - 00:38:49.604, Speaker B: Yeah. And, Mario, in terms of the criticality of this getting into Hive, I'd say agreed. There are much higher and more important things to get in there. I do think in the long run, having a few sanity tests that do test these different configurations of BNVC would be valuable. I don't know the load and run times on Hive necessarily, but I wouldn't necessarily run them through all the tests. I would run them through. Can an attestation be made? Can a block be made and call it a day, maybe a few others? Yeah.
00:38:49.642 - 00:39:13.864, Speaker G: There's one perfect test suite, which is basically just the sanity. Just starting the nav just starts the blobs. You see, everything works. You wait for final session, and that's it. So I think that should be the ideal one. Yeah. The problem right now is that there are a lot of assumptions in the way that the clients respond.
00:39:13.864 - 00:39:27.920, Speaker G: So there are a couple of important changes to be made. If you want to do like the combinations. But once we do that it should be easy enough to prepare this combination testing.
00:39:31.220 - 00:41:14.270, Speaker B: In terms of Hive. Let's put this on ice and pick it up in a couple of weeks and see if it can be prioritized at that point. Okay. Any other comments with respect to testnet planning in relation to testing in relation to readiness, et cetera? I would second the opinion that the builder infrastructure is kind of the most lacklink aspect right now. Okay. So we definitely want to ramp that up over the next week or so and to begin to see a lot of messages channeling through there. Anything else on this one? Anything else related to Deneb? Okay, any other discussion points for today regarding research specification or anything else? Okay great.
00:41:14.270 - 00:41:24.480, Speaker B: Thank you everyone. Keep the good work. We'll sync, many of us will sync in a week on the execution of your call. Bye. Take care. Bye.

00:00:26.905 - 00:00:27.445, Speaker A: SA.
00:02:29.245 - 00:03:01.275, Speaker B: Okay, we should be live everyone. Welcome to ACDC. This is call 138. I just put the agenda there in the chat and yeah, let's go ahead and get into it today. So first Electra, we just launched Devnet one a few days ago. Very exciting. I wonder if there are any updates with the latest there.
00:03:01.275 - 00:03:13.675, Speaker B: Last I looked it looked like participation was quite low and there were a few forks of the chain. So not looking super great. Anyone here have any more to share?
00:03:16.345 - 00:04:14.749, Speaker C: Yeah, maybe I can give a short update. So Philip set up the network earlier on Tuesday and I think Aragon had some issues around Epoch 64 and haven't been participating since. But I think the team is aware and are looking into it. And then some external users started sending transactions, some point around slot,800 or so and then the chain forked into about three parts and then it looks like there's an EIP 7702 transaction that caused a split, but we haven't been able to fully debug it. Netherman and Bezu seems to be building a consistent chain. Ret and get seems to be consistent in their chain, but these two chains have a lot of forking and reorgan amongst themselves and Ethereum GS pairs are not proposing since a while. So yeah, I think that's the latest status.
00:04:14.749 - 00:04:18.505, Speaker C: But yeah, I'm just getting caught up as well.
00:04:21.365 - 00:04:42.835, Speaker B: Cool, thanks. So yeah, sounds like there's some fun debugging on the horizon. Yeah, nice work though. It's exciting to see Devnet one up and yeah, just keep iterating from here. Anything else to say there? It sounds like yeah, clients are busy figuring out what's going on with the DevNet.
00:04:53.455 - 00:05:00.285, Speaker C: Yeah, in case client teams need something for debugging, please text on the interop chat and we're happy to help get you whatever you need.
00:05:02.705 - 00:05:38.661, Speaker B: Cool, thank you. Okay, we can move on to the next item then. Let's see. This is from potus and essentially, I mean maybe he can chime in a bit more, but it sounds like a suggestion to move some of these request data that we're introducing in Petra outside the execution payload. Type in the beacon chain in the CL broadly and yeah, it sounds like there are some reasons to do this. Is Produs on the call? Let's see. It looks like you're here.
00:05:38.661 - 00:05:40.245, Speaker B: Would you like to give us a summary?
00:05:40.285 - 00:05:48.581, Speaker D: Sorry, I just. I just logged in. It seems that on time. Are you talking about this? The issue of the execution payload and a container.
00:05:48.773 - 00:05:49.101, Speaker E: Right.
00:05:49.133 - 00:05:50.465, Speaker B: And the request. Yep.
00:05:51.295 - 00:07:21.385, Speaker D: Okay, good. So Let me quickly describe the issue. Since Bellatrix, since Shanghai, the beacon block contains inside its beacon block party, the full execution payload that the block itself is broadcast and is transferred on the consent on the P2P layer for the consensus clients. And the consensus client gets this payload, it sends it to the EL for verification. Capella introduced a new thing, which is that the fact that the payload has withdrawals that were honored in that payload on the execution layer and at the same time these withdrawals needed to access the beacon state to honor the deduction of those balances from the beacon state. So this was the first time where we actually had to synchronize information some state transition that was happening on both layers at the same time. However, since Bellatrix and this was not modified in Capella, the consensus clients would get this full block, would send the payload for the execution layer for validation, and then they will completely forget about this payload they will save in their DB in the database, will save the full block minus that payload, because that payload anyways is being saved in the execution layer database.
00:07:21.385 - 00:08:25.315, Speaker D: In Capella, when we added these withdrawals, in principle, we could have saved the payload, I'm sorry, not the payload, but the withdrawals part of the payload. But since the withdrawals are deterministic from the beacon state, this didn't present any problem. You could grab a very old beacon state, a very old block, without the payload, and you can perform the beacon state transition function without ever getting the payload. Electra changes this. In Electra, the execution payload is needed on the consensus layer to perform the state transition because the requests that are included in the execution payload are needed as input. These are external inputs to the beacon state transition function in the consensus layer. This was again, I repeat, this is not the case for withdrawals, even though withdrawals are in the execution payload, because the beacon state already knows what withdrawals should have been in the payload.
00:08:25.315 - 00:09:44.563, Speaker D: So what I am proposing, this presents a problem now for consensus clients, because consensus clients oftentimes have an old state, have an old beacon block and they want to perform the state transition to get the new state in the current status. Either the consensus client saves this information in whatever schema for the database they want to do this information, meaning the Electra fields, there are no fields that the consensus client requires to perform the state transition function or they they send the payload, as we do now, to the execution client and then later on when we need to perform this state transition, we request the payload again. This makes it very inefficient and clients will not catch up if they need to sync a block that requires this old state transition functions. So my proposal is to transform the way that the consensus two changes. One is on the consensus side, the structure of the beacon block body. Another is in the engine API, the structure of the message that is exchanged between the consensus client, the execution client. What I'm proposing is that the beacon block body on the consensus layer contains an envelope.
00:09:44.563 - 00:10:29.055, Speaker D: In this envelope you find these fields that are required for the state transition. On the consensus side, this meaning that requests and a payload, the execution payload. But this execution payload doesn't include again the same fields. So this means that the consensus client would be able to hash the payload and just blind it and just save that. This will make it compatible forward compatible with SSZ when the execution clients move to ssz. Because then the hash that we're going to keep for the tail would be the actual hash for the block. If eventually the consensus client moved to SS on the engine.
00:10:29.055 - 00:10:50.845, Speaker D: We will need this change that the pay the calls for get new payload and the calls to inform that to notify a new payload would send this full envelope. And then the execution client will need to add these fields from the container to the payload compute the block hatch. So that's what that's. I think, I hope that it was clear what the problem is.
00:10:52.785 - 00:11:12.895, Speaker E: One clarification here. As far as I understand, you don't drop the entire payload. You just store, keep. Keep the payload header. Anyway, otherwise you. Yeah, actually chatting about this in the chat. I mean, yeah.
00:11:16.035 - 00:11:17.811, Speaker D: I'm gonna have to read that chat.
00:11:17.963 - 00:11:41.775, Speaker E: Yeah. So this is because you have to serve requests from other peers to get the full block. And you can get. Can use get payload that is to get transactions and withdrawals if you need withdrawals for from el. But the header should be kept in the database.
00:11:41.815 - 00:11:44.479, Speaker B: Yeah, yeah, that's right. We keep the header.
00:11:44.527 - 00:11:44.927, Speaker F: Right.
00:11:45.031 - 00:11:47.567, Speaker B: And then today the issue is that.
00:11:47.631 - 00:11:50.182, Speaker E: Through P2P requests we only request from.
00:11:50.261 - 00:11:51.795, Speaker A: The Yale through P2P.
00:11:52.295 - 00:12:14.905, Speaker E: But for state transition we're okay. But then for like. But then for like Eletra now we also have to request from the EL just for state transition. And we are worried about the performance penalty here. Yeah, sure. So if. Yeah, let's just imagine if we don't have this envelope at all.
00:12:14.905 - 00:12:24.745, Speaker E: So what then would you have to do in the database? Would you need to introduce execution payload without transactions?
00:12:25.405 - 00:12:42.305, Speaker D: You would need to. You would need whatever you do because these clients would handle this in a different way. Each client. But whatever you do, the consensus client will need to save in the database, in whatever schema, these new fields, these requests.
00:12:43.605 - 00:13:08.411, Speaker A: Yeah, so like usually you have just the header and you don't need any of the objects that go along with it because you have the. Usually you only need the root of these requests, but now you need actually the requests. And usually we're just storing the header. So we'd have to have some. Either some sidecar pattern which makes the code quite. Or. But yeah, you'd have to.
00:13:08.411 - 00:13:13.655, Speaker A: You'd have to store it on the consensus side or request it from the EL every time you want to do a state transition.
00:13:15.035 - 00:13:25.335, Speaker D: Exactly. That's the point. Yes. And it seems to me that the change of just the changing the structure into an envelope, it's a very simple change.
00:13:28.685 - 00:13:31.345, Speaker B: Right? Yeah. Go ahead, Mikael.
00:13:32.045 - 00:13:45.865, Speaker E: Yeah, I have another question. So you mentioned that whenever you validate the payload, you then drop the transactions from it. So it happens even for non finalized blocks, Right?
00:13:46.765 - 00:13:47.545, Speaker D: Correct.
00:13:48.365 - 00:13:58.051, Speaker E: Okay, I see. I didn't realize it was quite aggressive as that. Yeah, but makes sense because you don't.
00:13:58.243 - 00:14:06.571, Speaker A: Yeah, the whole reason we have the payload bodies method is so that the CLS can drop the bodies and just have the headers.
00:14:06.683 - 00:14:40.001, Speaker E: But yeah, this. Yeah, for sure. I was just, you know, kind of like under impression that it happens for the. The finalized prefix of the chain. So if it happens for every payload, then I see initial problem. Okay, so what if clients introduce execution payload without transactions? I know it sounds ugly, but would that solve the problem? So you can just.
00:14:40.033 - 00:15:20.975, Speaker D: I think it's not. So it's the other way around. For me, the problem is not about transactions or not. The problem is about what information each client needs to perform their state transition. So anything that the consensus layer actually needs to perform a transition should not be at the same tree level as a Z tree level from things that the consensus layer does not need. So anything that we do not need, if we keep it one level below in the hash tree, we can just hash that thing, keep the hash of this and only save the objects that we need that the total hashtag would be the same.
00:15:23.075 - 00:15:39.135, Speaker E: Yes, I can understand that. But as far you have this header anyway. So it's like header plus two new fields with requests that I. Maybe more in the future.
00:15:39.515 - 00:16:18.715, Speaker A: Like if we don't change this on the P2P layer and we just try to do it internally, which we can kind of. But the problem is you. You'd have this extra object that has the extra information that you need, but it needs to hash to the object without the extra information. Because, because that's not on the, you know, that's not in the specs. So, like, that turns into something really ugly where, like, the thing you get from the network is different than the thing that's not complete. I don't know. The ways around that are quite difficult to deal with.
00:16:19.615 - 00:16:20.287, Speaker E: Right.
00:16:20.431 - 00:16:21.095, Speaker B: But also.
00:16:21.215 - 00:16:34.191, Speaker D: Misha, why is it that. I mean, what, what worries you about having this in an envelope? The envelope comes with the block itself. So what, what, what is, what is the pushback against having an envelope?
00:16:34.303 - 00:16:58.585, Speaker E: Yeah, I, I'm just trying to understand how big the problem is. I'm not against this change. It's just, you know, we used to have the execution payload representing all the fields and containing all the fields that are required to recreate the execution layer block. Now we want to break this.
00:16:59.965 - 00:17:26.845, Speaker D: No, no, no, I do not want to break this. The envelope. Call the envelope payload if you wish. From the point of view of the elderly, the EL will get the envelope. Not only the payload, the L gets the envelope. And if they want to hash it as ss, they can just hash it immediately. If they want to hash it as rlp, they need to move the requests alongside the rest of the field and then hash it.
00:17:27.425 - 00:17:52.935, Speaker E: Yeah, I see, I see. I can understand that. Okay. Okay. If I would say that if this problem is common to all clients, then we should probably, you know, do the change or this is the change to the API and el clients will need to change these.
00:17:54.555 - 00:17:55.395, Speaker A: Yeah, I don't.
00:17:55.475 - 00:18:02.255, Speaker D: It's. It's not only the API. I'm. I'm proposing that the beacon block body structure changes.
00:18:03.205 - 00:18:18.065, Speaker E: Yes, that's correct. I see. Because we kind of already have the envelope. Right. Which is called execution payload now, and we need one. Another abstraction level here.
00:18:19.245 - 00:18:20.265, Speaker D: That's correct.
00:18:20.965 - 00:18:35.915, Speaker E: So. Yeah, I understand that, but. Yeah, let me think on it. Could you please, I don't know, could you please outline this in the issue?
00:18:36.575 - 00:18:52.831, Speaker A: I mean, I pasted it in the chat, but. Yeah, but I don't think the actual proposal has been like, laid out somewhere other than maybe in discord. But yeah, I pasted it from what POTUS had sent me that I can.
00:18:52.863 - 00:19:08.625, Speaker D: Open a CLREPO issue because anyways, this pattern is already used in my PR for EIP 7732, because then it's mandatory to have the envelope, so it's just repeating what we already do on epbx.
00:19:14.805 - 00:19:17.837, Speaker B: We also need changes for the engine API as well.
00:19:17.941 - 00:19:39.155, Speaker E: I presume a co issue will also talk about engine API changes. Yeah, we would need those this is why I just want to see the proposal so we can discuss it there asynchronously.
00:19:41.935 - 00:20:16.375, Speaker A: Yeah, I think it needs more discussion and a proper proposal. But yeah, I think it's good so far from what I've seen, because we didn't have a way of dealing with this either that was at all. I know the problem that he's talking about, and it was something that was missed in Devnet zero because technically MEV Boost is broken right now on every client. If you include. If you test me Boost with the transactions that are in Electra. We just haven't tested it, but we would find that if we did. And this is the problem that awaits us.
00:20:17.035 - 00:20:27.531, Speaker E: Right, But I just want to mention that fixing Math Boost does not sound like an appealing argument for me to make a change to the core protocol structure.
00:20:27.563 - 00:20:30.979, Speaker A: But it's broken because of this problem, whether Map Boost is there.
00:20:31.027 - 00:20:32.531, Speaker B: Oh, yeah, yeah, yeah.
00:20:32.563 - 00:21:02.085, Speaker E: And actually this proposal can help to solve this problem. Like it will introduce a structure that could be used by MEV Boost and will be kind of like. Yeah, but anyway, Math Boost could be fixed without this by introducing the same structure in the Builder API level. Right.
00:21:02.905 - 00:21:14.537, Speaker A: Yeah, yeah. Technically, this issue is actually just caused by the fact that we dropped the payloads, but it arose. It was easy to see with ME Boost. Anyway.
00:21:14.721 - 00:21:16.205, Speaker E: Yeah, got it.
00:21:19.865 - 00:22:08.805, Speaker B: Okay, so to summarize, the cls prune the EL data, because generally they can. But given the way that we have these request structures in petra, this is no longer sufficient. I think that makes sense. The suggestion is to essentially solve this at the type level, if only just to make it sort of clean, to still drop the payloads while having their quest data you need for the state transition at the cl. Yeah, I mean, when I first saw this, I was thinking like you could just pull out the request and just put them, say, in the DB next to the payload, or rather the block. But it sounds like everyone would much prefer this actual sort of, you know, more specific SSZ structure. Does that sound right?
00:22:11.505 - 00:22:23.005, Speaker A: Yeah, because it all just comes down difficulty of having something that has extra information that doesn't get hashed in. That not having to do that makes it way easier.
00:22:24.465 - 00:22:25.137, Speaker B: Right.
00:22:25.281 - 00:22:26.005, Speaker E: Okay.
00:22:27.265 - 00:22:31.857, Speaker B: Yeah. Potus, if you don't mind opening an issue. I think that's a good next step here.
00:22:32.041 - 00:22:35.765, Speaker D: Already typing it. I'll paste it here before the end of call.
00:22:36.225 - 00:22:36.665, Speaker F: Perfect.
00:22:36.705 - 00:22:37.361, Speaker E: Yeah, great.
00:22:37.433 - 00:22:37.785, Speaker B: Thank you.
00:22:37.825 - 00:22:59.101, Speaker E: A little bit. Yeah, sorry, one more thing. A little bit of pushback that I have is that we are trying to solve implementation complexity with Changes to the protocol, which are just, you know, not necessary for the protocol itself is probably why I have a kind of like a pushback on it and want to think more.
00:22:59.133 - 00:23:21.795, Speaker D: Yeah, but I would argue the other way around. I would argue that the current design is just philosophically wrong. The current design mixes in the same level, in the same message data that is needed on the CL for the state transition, that is purely on the CL side, with data that is not needed in the CL at all. So I would say that the current design is just wrong and we're trying to fix that mistake.
00:23:22.415 - 00:23:22.799, Speaker F: Right.
00:23:22.847 - 00:23:40.355, Speaker E: It's not wrong. I would say it has just different philosophy because, yeah, it has all data that are comprising the EL block and that's it. That's the basic stuff that we had before. But yeah, I completely understand your argument.
00:23:41.575 - 00:24:09.025, Speaker A: And the other reason that we didn't run into this with the version hashes was that we put those in the CL block, but they technically came from the execution layer. And so, yeah, it's what POTUS said, like they removed one layer higher in the tree and so it worked out nicely. But since we'll presumably be adding more cross LCL transactions in the future, we should have them at the correct level.
00:24:10.045 - 00:24:24.509, Speaker E: Yeah, that's interesting. Maybe we probably. Maybe we can really, as Gajinder suggested, just have those requests in Beacon block body and, you know, send them.
00:24:24.557 - 00:24:36.589, Speaker A: Yeah, that other proposal that you made on the engine API of moving everything into the Beacon block body would have also worked, but it does have those corner cases around new payload, but.
00:24:36.637 - 00:24:38.705, Speaker B: Right, those corner cases.
00:24:39.925 - 00:24:44.893, Speaker E: You mean like those that are related to Optimistic Sync edge cases? Yeah, yep.
00:24:44.989 - 00:24:58.865, Speaker A: In not sending new payload to. For every payload, that is the only reason that we found at least that not to do that. But this is actually a strong argument to do that if we don't do what POTUS is saying.
00:24:59.405 - 00:25:01.705, Speaker E: Yes, but I don't actually.
00:25:02.365 - 00:25:34.745, Speaker G: Sorry, I don't actually think that there is a problem in Optimistic Sync because when CL sends an fcu, basically you construct the chain based upon a trusted latest route. So basically the entire chain before that is all trusted. And when you are sending new pinloads, then you obviously are sending the data for that particular route to be verified. So I mean, I don't really see it as an issue with respect to Optimistic Sync.
00:25:36.845 - 00:26:05.625, Speaker E: Yes, I agree with that. So as long as EL has EL Block has all the data to sync, you know, and to verify, we are not removing these requests from EL Block, we're just sending this request to EL in a different way, so it should work. They will be hacked. They will be, yeah. They will be checked by the block hash anyway.
00:26:12.725 - 00:26:25.665, Speaker B: Okay. Yeah. I will echo what Mikhail is saying. Like, it seems like there are a couple different ways to solve this. POTUS has one solution. Yeah. So I think if we get something written, then we can continue the conversation there.
00:26:25.665 - 00:26:59.825, Speaker B: Anything else on this topic? Okay, cool. Next up, we had an item for an Engine API update. This is from light client for Devnet 2. I haven't had a chance to look into this in detail.
00:27:01.965 - 00:27:03.065, Speaker E: Let's see.
00:27:04.245 - 00:27:08.045, Speaker F: I think this is similar to this question that we've been talking about.
00:27:08.205 - 00:27:08.985, Speaker B: Okay.
00:27:12.525 - 00:27:18.265, Speaker F: So I don't know if we can really make a decision before we decide where the requests actually need to live.
00:27:19.975 - 00:27:22.915, Speaker B: Okay. That would influence this PR you have here.
00:27:23.895 - 00:27:38.355, Speaker F: I mean, I guess, like, you could still have the request encoded in a similar way, but it sounds like we're probably going to have some sort of. Are people wanting to do this, like, union of requests, or will we still keep them separated at the cl?
00:27:40.135 - 00:27:49.115, Speaker A: Generally it makes it easier to deserialize when they're. That's. I can't say for sure.
00:27:51.375 - 00:29:16.727, Speaker F: Basically, I'm proposing that over the Engine API, the requests are sent as an array of the requests as a request object, not like the individual type. Because right now on the el, we're converting the list of requests that exist in the EL block into individual lists of individual request types. Unfortunately, this adds some requirements to the EL to understand from just a individual block whether a request type is enabled or not. Because if I just give you an EL block and there's no request of a certain type, and we've added like we're three or four forks down the road and we've added some more types of requests. Like, you can't tell just from the block anymore if the request is enabled or if there's just no request for that block. And so I think it makes the Engine API on the execution layer side a bit more annoying. So I'm basically proposing that we send over the request object as it is on the Elite, and if on the CL you use the union of that, then that would kind of directly pipe into that data structure.
00:29:16.727 - 00:29:30.675, Speaker F: If you are separating them out, then you would be able to just separate them by reading the list of typed requests and deserializing them into the list that they should go to.
00:29:37.825 - 00:29:44.805, Speaker B: Okay, so this is related, but it sounds like we'd still possibly want to do something like this even if we end up changing the structure on the cl.
00:29:50.345 - 00:30:00.025, Speaker F: I think they're related. But yeah, it is. It can be done either way for wherever it lives on the client.
00:30:01.555 - 00:30:03.395, Speaker B: Right. So yeah, I mean, so my proposal.
00:30:03.435 - 00:30:18.255, Speaker F: Is, My proposal is for the request to come through as a single list of all of the requests and for the type of request to be identified by the type JSON field, just as it is with types transactions currently.
00:30:22.555 - 00:30:36.325, Speaker B: Yeah, that makes sense. Right? Like we have these set of cross layer features and we need to figure out exactly where the boundary is across el, engine API and cl. That makes sense. You have your hand up.
00:30:37.825 - 00:30:38.249, Speaker E: Yeah.
00:30:38.297 - 00:31:40.319, Speaker D: So I mean these problems are related, but they seem to address a different area, different problem itself, which is we currently have a type on the cl, a type on the el, and then we have these messages that are being exchanged on the engine API. What my proposal was, was about the type on the cl and this doesn't contradict Matt's proposal. I would still suggest that the type on the CL has this level structure and then we put in that on what level the requests and this request can be a list of requests, can be a union, can be separated, I don't care. On the EL side, it seems from what Matt says that it would be better to have the Type 1 request object, which is a list of unions which may have different type of requests, list of lists. This would be fine as long as the engine API puts them at a different level. This already solves my problem. And then the object that goes in the level up, we could handle it.
00:31:40.319 - 00:32:07.575, Speaker D: Either the EL has the problem of trying to interpret it and separate them, or the CL has the problem of trying to interpret and separate them. It seems from what Matt is saying that it's better for them if the CL interprets them and separates them in different objects. That's fine by me. Well, we already need to know what those objects are, so I don't see any problem with what Matt is suggesting into putting out on the envelope one object which is the requests.
00:32:12.795 - 00:32:18.541, Speaker B: Yeah, that makes sense. Yeah.
00:32:18.653 - 00:33:02.045, Speaker E: One of the affiliate arguments that Light client made is like, let's just have on the API level the data structure that maps on the core data structure to avoid potential edge cases in the future. One, one. I don't know if it's a problem or not, but now CL will have to, if this proposal accepts, CL will have to kind of handle request mapping from different lists to just one. But it does not seem like a big surface for bugs and those bugs can be found easily.
00:33:06.865 - 00:33:22.405, Speaker A: I think it's just that the different types have to be, I think Carefully thought of. If we have different kinds of requests, such that it's not ambiguous on which kind it's deserialized into.
00:33:23.065 - 00:33:42.415, Speaker F: Well, the type. The type field should disambiguate what, like what type to deserialize into. So even if some fields are reused across different types, then you can just look at what that type value is and then put them into the correct SSE object.
00:33:43.915 - 00:33:50.731, Speaker A: Okay, so there's a byte or there's a. Is there something that marks it? You said a type value.
00:33:50.923 - 00:34:26.627, Speaker F: Yeah, I mean, it's the same as how we represent transactions over the rpc. So if you request a block with transaction values filled in, then you'll get a list of the transactions and the fields are sort of reused in this generic transaction. But there's a type field that says whether it's type one, transaction, type two, transaction, type three, whatever, and then you can use that to differentiate. So that way you don't have to just look at the fields and infer based on the presence or non presence.
00:34:26.771 - 00:34:29.451, Speaker A: As long as we got something like that, I think we'll be fine.
00:34:29.603 - 00:34:30.375, Speaker F: Okay.
00:34:34.035 - 00:34:37.387, Speaker B: Terrence, I guess one thing to.
00:34:37.411 - 00:34:44.555, Speaker E: Notice that when we get payload as a proposer, that we also have to parse this request on the CL side.
00:34:44.635 - 00:34:45.115, Speaker A: Right.
00:34:45.235 - 00:35:23.465, Speaker E: Because we have to put those on the envelope or become block body ourselves. Depends on what the. Depends on what the decision is. Small comment here. I believe that cl, while sending those requests to el, may not respect the order of those requests by type, as it is in the eip. I guess this is true.
00:35:31.205 - 00:35:35.265, Speaker B: I don't. Yeah, I don't know if there's an order on spec.
00:35:38.525 - 00:35:54.895, Speaker F: I mean, the order should be inferred just from the engine API message. So as you're pulling out the values, you can just keep it in order. And the EL would have placed it in the order that it was already on the execution layer.
00:35:55.635 - 00:35:58.895, Speaker B: Right. But is it sorted by the type byte?
00:36:00.155 - 00:36:18.165, Speaker F: It would be sorted by the type byte and then intra type byte. Like each proposal has a different way of ordering and the EL will have already ordered all of that. So as long as you take it from the engine API and interpret it as it's ordered from the engine API, it should be the same.
00:36:18.945 - 00:36:21.885, Speaker B: Right. Does that address your concern, Mikael?
00:36:22.465 - 00:36:31.365, Speaker E: No. Yeah, I'm just thinking that CL should respect this order or not. Yeah, but that's a detail. Maybe not worth talking about it.
00:36:33.865 - 00:36:55.475, Speaker B: Well, the order is important. Important at least Intratype. Yeah, so definitely should go in the same order as given. I'm.
00:36:55.515 - 00:37:01.015, Speaker H: I'm wondering, like, what is the simplification on the EL side here?
00:37:04.765 - 00:38:10.525, Speaker F: When EL converts the block into an engine API message, it doesn't know from the block data how to fill out the presence or emptiness of a request, because in the request object on the el, it's a list of typed values. And so if in a future fork we add another request type, then I can't tell from the block itself whether that request type is empty or if we haven't activated that request type yet on a fork. So propagating that information in is not that simple. We can do it, but it's kind of weird for us to represent on the engine API this data in a different way than it's represented on the execution layer. I think that this is just like a much better simplification and the CL can much more easily differentiate whether the request is empty or whether the app fork is not active.
00:38:15.945 - 00:38:22.765, Speaker H: You don't know what your. What fork you're in or what the block fork the block was in.
00:38:24.435 - 00:39:18.795, Speaker F: Yeah, I mean, usually we don't plumb the fork information through every code path in the engine API. It's kind of at the top level of verifying, like the method that's coming in. But then when we're dealing with the block itself, the block doesn't have the concept of this is a Bellatrix block. Like on the cl, I think you guys are very good about separating the different types of fork blocks from each other. But on the el, I think this is how pretty much all clients have implemented it. We have one block that represents all of the block types, and we use the presence, like the nullness of a value, to sort of determine if that thing is active. And so this is again, like part of the reason why requests were added in the first place in this format was to take advantage of how ELs have been built historically.
00:39:18.795 - 00:39:34.435, Speaker F: And this is just a continuation of trying to avoid re architecting a lot of the client or doing things that might be like, bug prone just to represent things in a certain way on the engine API.
00:39:37.175 - 00:39:44.175, Speaker H: Okay. Fundamentally, this is fragile heuristic.
00:39:45.115 - 00:39:45.547, Speaker F: The.
00:39:45.611 - 00:40:17.275, Speaker H: The idea of. And I don't think this goes against anything you're saying, but the idea of checking for the presence or absence of specific fields. Look, we in Nimbus do it for certain things too, unfortunately, because, yeah, we have to, but. But that is one of the worst parts of reading certain of these JSON objects, because it is a heuristic. And I would say doubling down on that is maybe not super great.
00:40:18.895 - 00:40:53.685, Speaker F: Yeah, I mean, we're like 12 forks into this design. So it's a little bit difficult to just like turn the ship around and change how we have architect a block. So I agree it's fragile, but I don't really know if there's much that can be done at this point. Unless some ELs also agree that they want to like, sit down and change the way that they represent the block. It seems like this is not a difficult modification to the engine API and makes things simpler for all of the els.
00:40:57.835 - 00:41:02.935, Speaker B: Can you not infer which fork you're in from the engine API method version?
00:41:04.475 - 00:41:07.695, Speaker F: I mean, you kind of can, but.
00:41:08.555 - 00:41:11.655, Speaker A: Like that those are decoupled.
00:41:13.875 - 00:41:39.785, Speaker F: Well, I think now they're sort of coupled Again, like now we're pretty strict about checking what fork the person is requesting. So if you call like fork choice updated v4 with a non prog block, I think it should return error. So I think that you can kind of infer now.
00:41:41.725 - 00:41:47.869, Speaker A: I think we do. I'm not sure I have to check.
00:41:47.917 - 00:42:18.755, Speaker F: No, with the parameters, like you can't build. I don't think you can build a Cancun block with fork choice updated v4. I might be wrong on that. But nevertheless, propagating this information down into like, our block type is different. I mean, if other execution clients don't have this problem at all, or think this doesn't make any sense, then maybe I can go look at it some more and figure out. But I think that this is the case for a lot of different teams.
00:42:23.145 - 00:42:45.809, Speaker D: Why do we really need to care about typing here on the API? Why would it be. It sounds, from what you're saying, Matt, that it would be fine for you if we send you, for example, a list of lists which are just interpreted as row bytes, and then you make the interpretation and change into your internal type. And we constructed that list from our internal type.
00:42:45.977 - 00:43:02.205, Speaker F: Well, then you would need. Well, if you send a list of bytes, and we would need to figure out what the byte structure is, and then it would have to probably be rlp, because we haven't done SSE yet. So it's like you have to interpret the data like the actual data, not just the bytes. So it's different from the transaction data.
00:43:05.825 - 00:43:14.685, Speaker D: So then probably it might be an issue for us, because I don't think we have unions correctly implemented in ssz.
00:43:14.985 - 00:43:44.547, Speaker F: I mean, you don't have to implement SSE unions. I'm just saying that if you happen to end the SSE union, then this format would map very closely to what the union like you can still, during deserialization of the engine API message, determine where in the individual fields, like the list of withdrawal requests, the list of consolidation requests, where those requests should go from that message. That's not a problem. I'm just saying, like, if you wanted to have. If there was a desire, it wouldn't.
00:43:44.571 - 00:43:49.107, Speaker D: Be against like we keeping them separated in our internal type, like the vl.
00:43:49.131 - 00:44:10.335, Speaker F: I don't really. Yeah, it's not for me to say, like, whatever you feel is right on the cl. I just think over the API, it's simpler for ELS to just send what the block data already is, rather than doing some interpolation of the block data and combining some fork logic. Like, we can do it. Don't get me wrong.
00:44:10.755 - 00:44:16.175, Speaker D: No, that sounds correct to me. It's fine, you're just moving the interpretation. But seems to be easy on our side.
00:44:16.715 - 00:44:18.375, Speaker F: Yeah, that was my take.
00:44:21.035 - 00:44:36.241, Speaker A: Just to. We. We do call like new payload and get payload V4 before the fork. And I haven't seen any errors from any. Like, I think we're running devnet one. It's fine. And I'm pretty sure the API was designed that way.
00:44:36.241 - 00:44:46.885, Speaker A: That's why these fields are nullable in the first place, because they have to be null before the fork. So we've decoupled those. I think they're still decoupled.
00:44:50.225 - 00:44:52.365, Speaker E: At least the spec requires.
00:44:54.865 - 00:44:55.777, Speaker G: The Alphabet.
00:44:55.841 - 00:44:57.285, Speaker E: So the errors should.
00:44:59.795 - 00:45:23.015, Speaker F: I mean. Yeah, it says engine new payload v4 spec. The client must return unsupported fork if the timestamp of the payload does not fall within the timeframe of the prog fork. So if you're calling new payload v4 before prog, technically that should return an error.
00:45:30.765 - 00:45:37.745, Speaker B: Okay. Yeah. Mark, you have something to say? No.
00:45:38.725 - 00:45:41.585, Speaker F: Same with get payload. So I don't know.
00:45:42.485 - 00:45:42.917, Speaker B: Right.
00:45:42.981 - 00:45:48.265, Speaker F: I mean, you may not be implementing it that correctly, but that is like the letter of the spec, I think.
00:45:50.295 - 00:46:16.977, Speaker B: In any case, it sounds like this would be helpful to ELs and CLs have liberty to kind of just take the data and then do what they would like with it. So I think it makes sense from here. I think. Yeah. So we have this pr and then the other issue we will iterate on and then. Yeah, I think just having them all together is the next step. And then, yeah, we can go from there.
00:46:16.977 - 00:46:33.997, Speaker B: But generally it sounds like both of these seem like directions moving. Any other comments on this? Otherwise, we will move.
00:46:34.061 - 00:46:36.745, Speaker H: Yeah, I guess I'll say that.
00:46:40.885 - 00:46:47.875, Speaker B: Go ahead. That.
00:46:48.215 - 00:46:48.911, Speaker F: What?
00:46:49.063 - 00:46:49.399, Speaker E: This.
00:46:49.447 - 00:47:28.323, Speaker H: This does make a certain style of JSON decoding a little more, a little trickier, let's say. So right now Nimbus does the best it can to decode JSON. It receives according to as strict a schema as the specs sort of support in each case. And these variant types just utterly fake this. I mean we can't. We can then all the usual, we read it and figure type out to a new object, I assume. I don't think there's any realistic alternatives.
00:47:28.323 - 00:48:06.945, Speaker H: This is what JSON supports because it's not ordered, but it's a mess no matter how it happens. So I mean, as long, as long as people are basically just upfront that it is not particularly less messy for CLS to do this than for EL to do this, that's fine. This is just a move of complexity and messiness from the EL to the CL and it's feasible either place. But this does not. Moving it to the CL does not solve this problem, let's say as maybe how I'll frame it. It just moves it.
00:48:09.085 - 00:48:43.675, Speaker B: Sure. But then clients I think are more equipped with just the types they have at hand to handle the problem. So this does seem like the direction to move into. Okay, next up, Eton has an update on SSC and stable containers. Essentially he's asking if we want this in Devnet too. There's a link to the IPs here. Let me just grab a link to this.
00:48:43.675 - 00:49:37.287, Speaker B: There's a very nice comment here on the agenda. So yeah, link to the IP's specs here, test and then I believe this is linked to kurtosis network they have running. So yeah, that's all super exciting to see. The question is if we put it in devnet 2 or not just like process wise Generally we would formally include these things into the fork and then DevNet would be downstream of that. So if we want to consider SSE and this double container update for Petra, that's a conversation we will have to have. Maybe I'll just pause there. So how do we feel about including these EIPs? Well, okay, actually maybe Etan.
00:49:37.287 - 00:49:40.155, Speaker B: Is there anything else you'd like to add before we get into that?
00:49:41.895 - 00:51:04.141, Speaker G: Yeah, I have minimized eips to the minimum like that I think we should put in Electra because we have this opportunity now because BeaconState reaches a new power of two number of fields so gets re indexed. So if we don't do this change now then like Rocket Pool mainly, but also other staking pools. We'll have to do yet another redeployment of their contracts every time that this happens again and also when we would introduce this table later on. So this what's in this PR today, it does not have SSE transactions or any of the other SSE stuff. I think that the other stuff like SSE transactions can be moved later down into Verkal so that the Verkal fork is the one that changes data types more strictly. But we still can do the CL only changes today so that EIP4788 becomes practically useful. I have also obtained support from Rocket Pool.
00:51:04.141 - 00:51:29.405, Speaker G: I just linked it this Discord link where they support this EIP and I can also obtain more similar statements from other staking pools if that's required. So yeah, the PR consensus specs is linked in the comment that Stokes linked and I have also generated consensus spec tests.
00:51:34.065 - 00:51:53.385, Speaker B: Cool. Right? Let's see. I think if I'm interpreting correctly, there are some clients Taku here, Lodestar, who are saying plus one for the SS feature. Any other clients want to chime in?
00:52:00.765 - 00:52:03.109, Speaker A: I'll say for Prism we were ready.
00:52:03.157 - 00:52:10.869, Speaker F: To say let's try Devnet 2, but I think including in specs like merging into Picture is more of a surprise.
00:52:10.917 - 00:52:12.117, Speaker A: So I don't know if the rest.
00:52:12.141 - 00:52:15.345, Speaker F: Of the team wants more time to consider that.
00:52:20.125 - 00:52:21.225, Speaker B: What mean.
00:52:22.405 - 00:52:25.985, Speaker H: Yeah, Devnet 2 is picture Devnet 2, right?
00:52:26.365 - 00:52:39.957, Speaker A: I think he was. Did you mean that Prism is ready for Devnet too, but if we add stable for stable containers it would take longer. Oh, sorry, no, I meant that I guess like there's. I thought, I thought it was more.
00:52:39.981 - 00:52:49.385, Speaker F: Experimental, like a finality of inclusion. But yeah, so I, I haven't stick to the rest of the team on it, but. But yeah, I think we can do Devnet too.
00:52:55.005 - 00:52:56.245, Speaker A: So I don't know if there's opposition.
00:52:56.285 - 00:53:03.265, Speaker F: To including stable containers for any other reason but. But I'll say from implementation side, like we're working on it on track.
00:53:03.655 - 00:53:54.985, Speaker B: Right? I mean I think the obvious thing is just that Picture is incredibly large already. I mean especially if we end up with Pirados in the fork. So at a certain point we do need to be very realistic about how big the fork is and the risk that entails for actually shipping this thing. Again, I agree with the justifications Etan gave around this feature being valuable in a vacuum. That being said, this is I think the biggest hard fork or one of the biggest that we've ever done and that should not be taken lightly. Perry had another comment here in the chat that essentially, okay, maybe an EL person can help me here, but it sounds Like EOF is in Pectra, but it hasn't been on a Devnet yet. And so that's all and good.
00:53:54.985 - 00:54:14.005, Speaker B: But then what that would mean then is. Yeah, it's also another really big change. And again, just looking at devnet one today, it doesn't seem like devnet one is going super well. So I do want to caution against kind of. Yeah, biting off more than we can digest, so to speak.
00:54:19.545 - 00:54:33.655, Speaker A: I, at the risk of saying something wrong, I believe the cl. I mean, this is a CL change in CL has less stuff than the EL at this point, I think, but.
00:54:36.635 - 00:54:37.163, Speaker E: Right.
00:54:37.259 - 00:54:59.835, Speaker C: I only partially agree with that. I think there's still a massive change and there are a lot of shared resources between EL and cl. For example, we have combined testing teams. I do think at some point we have to get realistic that we can't just have every EIP in and at the same time just keep increasing the scope. There is a bottleneck.
00:55:02.415 - 00:55:40.925, Speaker B: A very real. Okay. I mean, unless someone wants to make a very strong case here right now, I would suggest the following. Yeah, like, let's work through DevNet1 and then I would even say wait on DevNet2. And yeah, we can reconsider this in the future.
00:55:41.505 - 00:56:14.835, Speaker C: But again, one point I do want to make. Would adding SSE to a devnet actually change anything? Like, for example, we have SSE devnets, so don't we kind of have all the data we need to decide if SSE goes into Petra or not? And once we decide if it goes into Petra or not, then we can talk about DevNet scheduling. To me, that sounds like the workflow we kind of need to have. So the question right now is not when SSE or stable containers is in a devnet, but rather, should it go into pectoral or not? And what data do we need to make that decision?
00:56:16.415 - 00:56:17.155, Speaker B: Right.
00:56:20.385 - 00:57:36.245, Speaker F: So I feel like an important part is understanding, like, how big of a pain breaking Merkle proofs is for app player teams. We definitely, like, I've heard from like smart contract auditors at Sigma prime about how this impacts their clients and they're avoiding bugs, I guess, kind of narrowly by realizing an upcoming fork is going to break their contracts. So that's an anecdote that I can speak to. But if it's easily telegraphed that we're going to break proofs for beacon states in Pectra and then once more for stable containers, and that's it. Like, how much worse is that than just having, like stable containers in Pectra? So pretty much app layer Input, I feel like is really important in deciding this one. As far as like work for client teams in Lighthouse we have like a pretty far along implementation. The changes in the client code isn't very large.
00:57:36.245 - 00:58:01.855, Speaker F: It's more impactful on the SSC libraries obviously, but I don't think it's like crazy. Definitely sympathetic to the fact that the fork's very big and I want to include pure desk, so would definitely lean towards like. Would rather pure desk and non stable containers if I were to choose. But it's also like they're not really weighted equally like stable containers is definitely smaller than Beard S.
00:58:04.725 - 00:58:05.085, Speaker B: Would.
00:58:05.125 - 00:58:26.105, Speaker A: Also on that case, on that point about messaging, like they're also app. App developers are trying to develop apps, so knowing sooner rather than later or telegraphing sooner rather than later is also helpful to them because they know what they can build now and get audited. Now.
00:58:28.295 - 00:58:41.431, Speaker C: Would that mean if we have like a public SLC devnet, would that allow app devs to play around with it enough to know what breaks or not breaks? Or does it need to be PETRA plus SSE for them to actually get this data?
00:58:41.583 - 00:59:19.185, Speaker A: They actually just want to know what's in the fork because they've been bugging us about. I mean just an example, like eigenlayers, they're trying to get their things audited and they've been bugging us about whether or not the fields that are in the beacon state for Pector right now are likely to be the final fields that are in the beacon state. But that question is irrelevant if we don't know whether or not we're putting in stable containers. So it's, it's more like what Sean said. Like it's about knowing what the real for what the real schedule is for when what is going in what fork that makes it easier on them.
00:59:22.805 - 00:59:36.785, Speaker B: Sure. But like we can tell that, you know, you could look at Vector today without the stable containers and you would know, right? Like I don't. Just from what you said, it doesn't sound like they're asking about oh, will this be stable forever? They just want to know what to target for the fork.
00:59:39.765 - 00:59:41.185, Speaker A: I think so, yeah.
00:59:41.765 - 00:59:47.781, Speaker B: All right. Enrique. Yeah, I just want to add that.
00:59:47.973 - 00:59:53.915, Speaker E: So what, what's been targeted for being included in Electra is let's say, simplified.
00:59:54.655 - 00:59:57.295, Speaker G: Version of stable container implementation, which does.
00:59:57.335 - 01:00:01.327, Speaker E: Not cover all the full spec that.
01:00:01.351 - 01:00:03.755, Speaker B: Is in the stable container eip.
01:00:04.575 - 01:00:12.119, Speaker E: So it's also possible that the client team could implement the quick version, just.
01:00:12.167 - 01:00:14.983, Speaker B: Enable stable container and then have the.
01:00:15.039 - 01:00:18.195, Speaker E: Full implementation for networks.
01:00:25.315 - 01:00:37.855, Speaker C: So basically the cls would like to have it included in Petra, have a public DevNet so that app devs can give them feedback and then decide if it's actually included in Petra. Is that kind of the workflow I'm getting?
01:00:38.435 - 01:01:02.585, Speaker B: Well, they can get public feedback from SSZ nets. Right. Like it sounds like what has been surfaced on this call at least is like the. These applications just want to know what's in Pectra, not necessarily that this, you know, XYZ are in Pectora and that will be stable forever. These are two different things.
01:01:06.005 - 01:01:40.455, Speaker F: Well, I personally don't know which of those is true. So it could be that application teams actually really hate these like Merkle proof breaks. That could be true. It's more. They're like, yeah, I feel like we just need more input from there and like maybe other teams have other input for, for like from application layer devs they interact with. But I personally like, I don't know how critical this is.
01:01:44.195 - 01:03:17.745, Speaker B: I mean, do other CL teams feel that it would not be disastrous to increase Spectroscope beyond what it already is? Like, do you not feel that it's already quite big? Okay, sounds like then maybe we'll take some time to think about that and then how can we move forward? So yeah, again, unless someone feels the pressing need to make a decision right now, it sounds like we can decide in the future. Again, I think we should focus on devnet one for the time being. In the meantime, I think we should get more information from app developers to the extent we can. And yeah, I would recommend each CL team to think very seriously again about like Pector Scope and what that means for a successful hard fork. Every IP we add is just going to, you know, add more code, more risk for bugs, generally complicate testing and, you know, all of the usual bucket of things. Ethan.
01:03:19.805 - 01:03:56.625, Speaker G: One thing I'm wondering about Peer does is its CL spec. I think right now it has an optional in there, so I'm not sure if that one is still there, but if it's there, it's sort of. That's a dependency there because if the peer does is activated before optionals become a thing, then that design needs to change as well, right?
01:03:56.745 - 01:04:50.505, Speaker B: I don't recall an optional. Anyone else I can look? Yeah, yeah, I guess we should go take a look. I don't recall there being one. Generally we avoid them again because there's limited support in SSE libraries for them. Okay, I think I'm going to call it on that one. I do think we have a Few things we can do to get a clear picture of ss. But again, I will just call out yet again, think very carefully with your client team again about Pector Scope.
01:04:50.505 - 01:05:38.155, Speaker B: I know that, you know, hard forks come very infrequently and so it's tempting to try and get as much in as we can, but at the same time, if it's, you know, if there, if there was a problem rolling out a hard fork, that would be worse than waiting another fork or two for whichever feature we have under consideration. Okay, thank you. Yeah, Eaton followed up. It's actually a Verkal usage of optional and not peer loss. Okay. And speaking of that was the next item on the agenda. Auxiliary.
01:05:38.155 - 01:05:45.333, Speaker B: Guillaume, I can't hear you if you're speaking, but it looks like you unmuted.
01:05:45.389 - 01:05:46.749, Speaker E: Oh, can you hear me now?
01:05:46.797 - 01:05:48.145, Speaker B: Yeah, yeah, yeah, you're good.
01:05:48.845 - 01:05:49.621, Speaker A: Okay.
01:05:49.773 - 01:06:04.585, Speaker E: Yeah, I was just going to say don't get out of your way to support optionals just for vertical because we're currently looking at other options. We would still like to have it, but yeah, it's not the end of the world for us if it's not there.
01:06:08.045 - 01:06:33.599, Speaker B: Okay, good to know. I think we're early enough in the vertical development process that, yeah, there's plenty of time to handle that. Okay, let's move to peer dos. So, yeah, I think there's a couple of things here. We do have some time left on the call. Okay, good. So let's see.
01:06:33.599 - 01:06:57.895, Speaker B: Yeah, first, I don't know if anyone here has been working on the peer DOS devnets. If someone has and give a small update, that would be very helpful. The last time I looked there were devnets but they had a number of bugs and generally, yeah, the network was not stable. Does anyone have any later information on that work?
01:07:03.965 - 01:07:27.445, Speaker F: So I talked to Jimmy from our team and he said on the last breakout call people decided to focus on just like fix fixing existing bugs and stabilizing clients as opposed to like focusing on another text test net, for example. So I think there's like a test net delay while things stabilize the clients.
01:07:30.945 - 01:07:32.405, Speaker B: Yeah, that makes sense.
01:07:33.865 - 01:08:18.425, Speaker G: Yeah. From on the. I was also on the breakout call and I think we also discussed that maybe we want more cleaner spec in the sense. For example, we would want a metadata PR that is out there to be included in the next devnet so that we can have a devnet which has sort of it's all moving parts together rather than missing data where we assume something and then we don't have a very good peering. So I think, yeah, so for now, we also want to focus to get the spec right and to sort of make sure that we have everything that is required to have a very stable network.
01:08:21.965 - 01:09:13.205, Speaker B: Yeah, certainly. Right. And so kind of on this note, taking that all into account, and again, myself and, you know, others in the chat here, like, there's very broad support for Peer DOS as soon as possible. As soon as possible here means in Pectora. So the question then becomes, can we ship here to Austin Pectora if it becomes the case that there's difficulty with Peer DOS is specified? I did want to bring up an alternative in terms of simplifying the initial Peer DOS rollout. So this would kind of be like, let's say, like a modification to the roadmap, so to speak. I'm talking with Francesca and a few others and I think we've really identified another path.
01:09:13.205 - 01:09:53.195, Speaker B: And so, yeah, let me summarize that. So with Petra, or, sorry, with Peer dos, there are kind of three core functions that the client performs, right? So the first one would be distribution. So that's taking, you know, at the very beginning you have a block with many blobs. The blobs get split up in these columns, the columns that are gossiped in Peer dos. This is a distribution phase. There is next, then a sampling phase where you then in turn ask your peers for these samples. That then gives you sort of your availability, sort of, you know, evaluation or assessment of a given set of blobs.
01:09:53.195 - 01:11:07.265, Speaker B: Then this third part of the pipeline is reconstruction, which is required in the event that there is some issue with distribution or sampling. So right now, the way Peer DOS is specified in PETRA is that it's essentially doing all three of these tasks, distribution, sampling, and reconstruction. And my intuition is that this middle part, sampling, is going to be where most of the complexity is. It might even be good to hear on this call if clients think otherwise. But essentially the suggestion would be to drop sampling from the initial Peer DOS rollout. This should essentially, yeah, I think there will be a few other parameter changes to maintain the same security level, but it would be possible to essentially just have the distribution phase along with reconstruction and then we could drop sampling. And the idea here is that if sampling does become this sort of hairy implementation concern, then we can get to a place where we could very realistically consider increasing blob counts with this reduced or like modified peer scope in PACT trial.
01:11:07.265 - 01:11:23.545, Speaker B: Okay, that was a lot. Do any clients have any takes so far or. Can I clarify something from what I just said? Any responses? Yakuza here.
01:11:26.375 - 01:12:08.335, Speaker G: Yeah, I just, I think that is a good thing that we can basically later on add sampling or basically we can also initially launch with having full custody of all the data columns because the blob count has not increased and so there is not much data and bandwidth blow up. Anyway, also what I wanted to add was that the PR in which we are able to the CL can specify the blob target or blob count. I think we should also get that PR in pectoral if it's not already in the scope and we should basically include it in specs or. And in DevOps.
01:12:10.395 - 01:12:42.505, Speaker B: Right. And so I think the actual numbers would be somewhat dependent on what peer loss looks like. But yeah, I agree, that's a good point and yeah, I think it's time to yeah, do that very soon. Right. And yeah, something that I think would be helpful. There's a question in the chat just essentially asking for a written down version of what I just said. I'm happy to put something together and I can elaborate a bit more and make this more of a proper proposal for consideration.
01:12:42.505 - 01:13:11.275, Speaker B: Essentially this would just be a way to hedge like, again like development uncertainty of peer DOS. It could be the case that we do peerDOS as specified and it's all in time per picture and everything's good. This is just an option worth considering especially if we feel like the peer DOS implementation is not moving along as far or as quickly as we wanted to. So yeah, something to get on the radar now.
01:13:15.785 - 01:13:36.081, Speaker A: Just wanna, I think a while back we were still considering pure dos might maybe make it in before Electra and that was maybe why we decided not to rebase it on top of the electrospect. But I don't remember if that was the reason because I think that's something.
01:13:36.113 - 01:14:26.735, Speaker B: That, yeah, that I think was. I mean, yeah, so that's a slightly different thing but essentially that was to just simplify development. If Electro is moving target then it makes it harder to then rebase peer DOS on top, which is moving target. So they were left separate. For example, for the devnets that we've had so far we will at some point need to put peer DOS into electropropper. To that I would just point to the previous conversation around again it's the sooner that we can finalize, really the sooner we can finalize the pectoral scope that we have, the better at least if only to unblock peer dos, which again is, I think everyone agrees, an incredibly important target to aim for Eton.
01:14:27.395 - 01:14:38.255, Speaker G: And we also need Petra devnets running smoothly without any forks before we decide to rebase. Because then the debugging for pls would become difficult.
01:14:41.075 - 01:14:41.815, Speaker B: Right.
01:14:42.395 - 01:15:39.865, Speaker G: For Peer does like the current design I think still has this special activation epoch like to make it appear as not a fork. If peer does is actually enabled on Electra like at the same for keypoc it also allows me to like make the stable container PR even more simpler because right now a lot of the changes in there are because the blobside cars need to be updated because the beacon block body gets re indexed and if Peer does activates on Electra there is no more blobside car. Right. So that the inclusion proof doesn't break. So it's. If we can align it, it makes it more simple as well.
01:15:43.805 - 01:16:16.785, Speaker B: Okay, yeah, I mean that's good to hear. Right. So then yeah, I mean maybe we go ahead then and we. Well yeah, there is a bit of a chicken and egg here but. But yeah, because essentially we want to have enough confidence in Peer to us that we can then put it on top of Electra. But we also want Electra be stable enough to do that. So that was kind of the issue and that was also why we had this sort of special epoch activation idea.
01:16:16.785 - 01:16:31.995, Speaker B: But yeah, I mean if everyone's on board then yeah, let's go ahead and just go for Electra and move from there. Does anyone feel opposed to moving ahead with that right now?
01:16:36.375 - 01:16:48.475, Speaker C: Would this mean we do combined Peer das Electra defnets in the future or do we just want to activate on Electra for Epoch but keep the keep like the branches used etc separate?
01:16:50.465 - 01:16:55.925, Speaker B: Yeah, that's a good question. I mean I think the simplest thing would imply yes, it's all together now.
01:17:00.025 - 01:17:07.885, Speaker C: Considering we haven't had any stable devnets on anything, I think this is going to be really, really hard to debug.
01:17:11.945 - 01:17:19.775, Speaker B: Acknowledged. So then maybe this is a little premature and yeah, we should just focus on Devnet one.
01:17:21.315 - 01:17:50.485, Speaker C: If it's just for activation, I'm on board. We've also done this in the past. I think for certain features we've had Electra Devnet as the activation epoch. We just keep them as separate DevNet cycles. For example, a 7702 bug shouldn't then lead to all CL devs having to debug what happened to their network. So we can still keep the test separate. We can just change how the features are activated, I guess or how they're interpreted by the client.
01:17:53.025 - 01:17:53.765, Speaker B: Right.
01:17:55.065 - 01:17:56.193, Speaker A: We had some distractions.
01:17:56.209 - 01:17:57.805, Speaker H: Well, the current issue.
01:17:58.385 - 01:18:01.725, Speaker D: Oh, go ahead, go ahead.
01:18:02.905 - 01:19:12.319, Speaker H: Okay, go ahead. The Current issue here with the fork schedule, one of them is that it redefines Deneb like so I understand that some cls apparently are treating this as a flag, a feature flag of some sort or I'm not sure precisely what the code structure here, but in Nimbus we tend to refrain from these for any longer term usage. And the result is that the fact that this has to activate in Deneb, this is how the dev nets are defined right now means that we cannot incrementally merge this. And so I would actually say this 10. I mean this tension that's being brought up about. Okay, well we can have for testing purposes separate DevNet or combined DevNet. And a separate DevNet is though, is that the separate DEF nets also create this artificial breakage and it is breaking break.
01:19:12.319 - 01:19:55.787, Speaker H: It breaks our breakage. That is a broken fork schedule. I'm sorry, but I'm gonna that it just is that that breakage in the fork schedule is sort of makes hinders that testing in certain ways. And it hinders. It means that even if, let's say two or three months from now we all agree, yeah, pure DOS is great, you know, move forward as quickly as possible, but now it has had to, at least in Nimbus, stay outside of that main development trunk because of this broken fork schedule. Because we cannot risk redefining Deneb, the production fork for this purpose to have columns like it's not. That's non starter.
01:19:55.787 - 01:20:05.705, Speaker H: So I mean, so I would say it's actually more effective and more efficient for testing as well overall at some point to combine the two. So this is my claim.
01:20:08.285 - 01:20:34.267, Speaker C: Yeah, I agree as well it should be combined. My question is just when we do that, if it's more advantageous to do it right now. Sure, if there's still open questions, for example, deciding some parameters that peer does still needs to, or some parameters that we think peer das might still change by then we could wait until those are changed and then merge it through. But if it feels like it's stable enough, then yeah, I'm on board for doing it.
01:20:34.291 - 01:20:34.855, Speaker F: Earlier.
01:20:37.235 - 01:21:04.265, Speaker A: In a previous call we discussed having like a pure DAS epoch type parameter and I think we've got a PR for that. I'm not exactly sure the current Devnets are just doing pure DAs from Genesis or. Or how it's being done currently, but I don't think that was ever decided either. And that, I mean having a pure doss epoch is one way to avoid that issue of not being able to test, having the test get in the way of each other.
01:21:16.735 - 01:22:00.929, Speaker H: So I'm skeptical of the idea of the separate epoch overall, but I agree that for testing it's maybe plausible. However, I would say in terms of isolating things, it would at least be possible to separate out the fork epoch so that it starts at. In Electra, like so. So there's sort of separate things here. One is, is there a delay in terms of, I guess in my question. Right. So when you're saying like this activation epoch, one is sort of activating at Deneb or Electra or sort of far future epoch as a pure testing thing.
01:22:00.929 - 01:22:18.805, Speaker H: And another is that people were seriously considering at least some weeks ago, well, maybe we'll activate, you know, 50 epochs after Electra starts. So the first I think is a testing concern and we can work with that. The second I think is doesn't make any sense.
01:22:29.785 - 01:23:17.475, Speaker B: Okay, that's helpful. So one other point that was brought up in the chat is essentially that I think many of the peer dose implementers are not here right now. There is an implementation call that they have. This is probably, or rather that's probably the right forum to get into this further. We are also almost at time on this call. So yeah, again I would suggest let's focus our attention on the devnets for Pectra and yeah, it sounds like we're going to need a little more discussion around exactly how to move forward on this issue. It sounds like if we have, you know, if we get a very stable Pector devnet going, then I think that simplifies a lot of the decision around.
01:23:17.475 - 01:23:59.635, Speaker B: Yeah. Do we rebase peer DOS on Electra and you know, get rid of this activation epoch and all of these types of things. Yeah, Ferry's asking like schedule it during the paradox breakout. That's the idea. Okay, we just have a few minutes, let's see. I think Daplion had one last minute thing. Let's take a look.
01:23:59.635 - 01:24:10.395, Speaker B: Beacon blocks by range V3. Here's a link to the PR. Is dapline on the call?
01:24:11.975 - 01:24:12.959, Speaker E: Yeah, I'm here.
01:24:13.087 - 01:24:15.195, Speaker B: Oh, great. Oh, there you are. Cool.
01:24:15.895 - 01:24:16.223, Speaker E: Yeah.
01:24:16.239 - 01:24:17.595, Speaker B: Would you like to give us an overview?
01:24:19.265 - 01:25:16.151, Speaker E: Yes, very quickly. There is an issue with the current rpc. If you want to sync a situation where you want to pull a long fork of blocks from which you don't know which peers consider them canonical or not. The current blocks by range route is spec in a way that you just submit a range of slots and the node will provide whatever the node considers canonical. You can query that information with status message, but that there is some asynchrony on getting those status messages and it forces you to basically pull this status message every time you want to request. If you want to be sure that you're pulling the right branch. This has not been an issue because we haven't had like crazy forking on mainnet, but if hit the fun, this could be an issue.
01:25:16.151 - 01:26:35.341, Speaker E: So what blocked by range V3 introduces is changing the request from just hey Pierre, give me range of slots to hey Pierre, give me, give me a range of slots on this specific branch that may be your head or may not be your head. In my opinion, that makes it much more resilient to the types of sync that we are implementing in Lighthouse at the moment for these very foggy situations. And yeah, I think it's a no brainer. I'm not, I'm not sure why this was not introduced at the very beginning and I don't see much downsides. I'm just curious for comment if other clients have specific ways to handle syncing long forks that may not be canonical, otherwise this route would be a good addition. Like as a caveat, something that you could do now is use the blocks by root. But with blocks by root you are forced to do reverse sync and that's really easy to be attacked because you cannot verify chain of blocks that you backwards sync until it gets rooted somewhere and the chain can be very long.
01:26:35.341 - 01:26:56.465, Speaker E: So a PR can just give you garbage and DOS you. So you need to forward sync somehow. That's why this route. So yeah, if you can check the pr, let me know if it makes sense. I think the implementation should be simple, so maybe you can target Electra. It's not terribly urgent, but would be nice. That's all.
01:27:00.125 - 01:27:52.595, Speaker B: Thanks. Yeah, I haven't had a chance to look at this yet myself. Yeah, thanks for bringing it up. And yeah, please everyone take a look. Okay, we're almost at time and I think that was essentially looks like that was everything on the agenda. Any closing questions, comments, remarks to wrap up the call? Okay, then, let's call it. Thanks everyone, I'll see you on the next one.
01:27:56.735 - 01:27:57.855, Speaker F: Thanks, bye.

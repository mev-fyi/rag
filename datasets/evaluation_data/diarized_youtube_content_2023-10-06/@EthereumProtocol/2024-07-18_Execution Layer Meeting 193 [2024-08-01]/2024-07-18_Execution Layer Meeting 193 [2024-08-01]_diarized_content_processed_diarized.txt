00:00:25.800 - 00:02:34.900, Speaker A: Sadeena. Sadeena. Sadeena. And we are live. Welcome, everyone, to acde number 193. A bunch of things to talk about today. Lots of updates on the Petra front.
00:02:34.900 - 00:03:17.820, Speaker A: So we went from Devnet one to Devnet two this week. We can discuss that and the issues we encountered. Then there was the aa 7702 breakout yesterday. We can chat about that. And then there's two engine API related topics, one around the encoding and one around a new endpoint for git blobs v one. So, yeah, let's get through all of that then. Last call we had this 7212 discussion where we couldn't quite get to like a final decision about whether we wanted to include it in pectra.
00:03:17.820 - 00:03:55.910, Speaker A: And so let's. Yeah, try to wrap this up today. And then if we have time, there's a couple more topics that are a bit less pressing but less urgent, but worth going over. So Andrew had something on quantum resistance and the implications potentially on the vertical roadmap. There's a new state expiry proposal. And then if anyone has updates on four, four, we can cover those too. But yes, to kick us off, Perry, do you want to walk through what happened with Devnet one, what Devnet two is, and kind of where we're at around that.
00:03:56.770 - 00:04:46.238, Speaker B: Yeah. So with Devnet one, we had the launch last week and we did have a few 7702 tests that were run. We're sort of working with a bunch of people who are working on 7702 to help us get our testing stack up. And that seems to have broke the clients in ways that we will call the forking. Because of the forking, it was quite hard to actually figure out which bugs were treated where on Devnet one. So we decided it was a bit easier to keep 7702 out of the picture for now and relaunch the Devnet and focus on testing the other eips. So we had the relaunch on Tuesday and since then we've had like a few bugs that have been already caught and fixed and a few more open.
00:04:46.238 - 00:05:18.010, Speaker B: So there's a bunch of open threads on the interop channel in case someone's interested. On a high level, there was an Aragon block production issue that's since been fixed. There's still an open prism issue and an open ret issue and both the teams are looking into it, uh, for grandeen. So the network was non finalizing for a while. And during that time Grandeen seemed to have issues. But now it's fine. So I still need to look into if that was during non finality or if there was some other reasoning for it.
00:05:18.010 - 00:05:35.650, Speaker B: But yeah, those are most of the open topics. So a backup to relatively healthy percentage. But the idea to first get all of these bugs sorted out so that we have like a clean baseline and then we can testing whatever we want on Petra.
00:05:36.790 - 00:06:42.404, Speaker A: Awesome. Thanks. Any of the client teams want to chime in with more details on their end? Okay. If not, then I guess one thing that's is it worth trying to spec Devnet three today or do we want to wait another two weeks for that? Do we want to try and run basically as is? I know there's been some changes on the 7702 side, so we can discuss those right after. But then I guess more broadly, would we feel ready in bringing say, something like EOF and the next Devnet or do we still need a couple weeks to be ready for that? I think for EOF, a lot of us are focused on the fuzz testing part of it. We got fuzzers working on the various.
00:06:42.452 - 00:06:49.060, Speaker B: Clients fuzzing differentially the other clients. So I would want to see successful.
00:06:49.220 - 00:06:52.108, Speaker A: Keratosis assertor before I would propose putting it in the Devnet.
00:06:52.164 - 00:06:53.596, Speaker B: So holding off two weeks, we could.
00:06:53.628 - 00:06:55.502, Speaker A: Be there, it might work, but I.
00:06:55.526 - 00:06:57.490, Speaker B: Feel better seeing it work in ketosis first.
00:06:57.790 - 00:07:11.250, Speaker A: Okay, so then yeah, we can reopen this thread in two weeks. And worst case, if we launch a Devnet before then, we can launch a new one in two weeks with EOF. Mario?
00:07:12.470 - 00:07:20.484, Speaker B: Yeah, so I'm still worried about the interactions between EOF and the rest of EIPs because we are still in the process of writing these tests.
00:07:20.582 - 00:07:21.260, Speaker A: Yeah.
00:07:21.560 - 00:07:33.216, Speaker B: So, yeah, I would like, I mean, generally EOF and 7702. I think that's my main worry. So we're still writing those tests and I think they are not ready.
00:07:33.408 - 00:08:04.642, Speaker A: Okay, so let's table eof for another two weeks. We can discuss it on the next call whether we want to bring it in or not. And I think this is kind of a good transition to talk about 702 some more. So there was a breakout yesterday. Nico led it. I don't know if Nico is on the call, but otherwise. Anyone want to give a recap about the conversation there? If not, maybe I can try and summarize it.
00:08:04.642 - 00:09:12.916, Speaker A: But my biggest takeaway from listening to it afterwards was that seems like we've reached consensus on not having 7702 Beverenne like migration, like a full migration to smart accounts. And I know a lot of the potential design changes had to do with enabling that. So yeah, I think keeping the scope of 7702 to, like, temporary, like giving temporary extra. Extra functionality to the account seems to be what. Yeah, we've landed on. I'm not sure, though, in terms of specific specs, prs, what that would mean is this the currently merged 702 spec, or whether there's an extra pr we'd want to merge and see as part of the EIpDeh. I have one plus one from Julian.
00:09:12.916 - 00:09:23.252, Speaker A: Is this. We keep the EIP as is, from.
00:09:23.276 - 00:09:30.932, Speaker B: What I remember from attending, yes, we decided to keep it as is for now. There are some minor discussions that we.
00:09:30.956 - 00:09:37.438, Speaker A: Want to have maybe a little bit later at the point that EOF has made a decision on what they're going.
00:09:37.454 - 00:09:46.330, Speaker B: To do with code introspection features. Because there was discussions around if we should allow code introspection to the delegated account.
00:09:48.910 - 00:09:59.326, Speaker A: Yeah, to the delegated account. Like, what happens when you do exit code hash exit code size and exit code copy of a delegated account currently.
00:09:59.438 - 00:10:02.326, Speaker B: As spec, it just delegates those calls.
00:10:02.358 - 00:10:21.020, Speaker A: To the delegated account so it returns the hash and the size of the delegated account. As far as I know. Not sure if that changed, but, yeah, as far as I know, that's how it's picked right now. So there was some discussions around changing that behavior or not. Yeah.
00:10:22.760 - 00:10:35.090, Speaker B: Waiting on decision on the EOf side. I wasn't aware that was something that was blocking an Eof to the side of. But my off the cuff thought is, whatever the ultimate resolved byte code is.
00:10:35.390 - 00:10:36.790, Speaker A: That'S where we apply the EF zero.
00:10:36.830 - 00:10:38.118, Speaker B: Zero rule and make the decision about.
00:10:38.134 - 00:10:55.490, Speaker A: The exe code, introspection, so that if it's delegated to an EOF smart account, then it cannot introspect. But if it's delegated to non EOF contracts, then it can introspect. Is that correct?
00:10:56.160 - 00:10:57.952, Speaker B: Exactly. If it sees an EOF account, it's.
00:10:57.976 - 00:11:04.984, Speaker A: Still going to think it's nothing more than Ef zero zero. Yeah. There was discussions last on the chat.
00:11:05.032 - 00:11:11.020, Speaker B: Yesterday that we want to potentially only restrict delegation to EOF accounts.
00:11:13.840 - 00:11:14.696, Speaker A: Yeah.
00:11:14.888 - 00:11:18.504, Speaker B: But we still want to go through.
00:11:18.632 - 00:11:21.912, Speaker A: More Devnets on Pictra, probably with EOF.
00:11:21.976 - 00:11:32.910, Speaker B: To see if this is actually what we're gonna do with 7702, just in case. By restrict delegation, you mean not allowed EOf accounts to be delegated to.
00:11:34.730 - 00:11:40.698, Speaker A: No, only allow EOf accounts to be delegated to contract.
00:11:40.794 - 00:11:44.550, Speaker B: Sorry, that's. That's an interesting idea.
00:11:45.090 - 00:11:57.252, Speaker A: Okay. Okay. Yeah. But all of these are, like, not anything immediate. All of them, as far as I.
00:11:57.276 - 00:12:02.800, Speaker B: Know, or as far as I understood from yesterday meeting, is something to look into at a later stage.
00:12:04.420 - 00:12:44.986, Speaker A: Okay. So I think it makes sense to then move forward with 7702 in like the next Devnet and then. Yeah, keeping the eof stuff in mind, basically. And then when we, when we actually, like, when we've actually shipped the Devnet and whatnot, we can make a decision about potentially tweaking the spec with regards to EOF and maybe do that after we bring EOF in. One question I do have, though. So looking at the Devnet two specs, it links the Devnet two specs. I'll put them in the chat right here.
00:12:44.986 - 00:13:19.260, Speaker A: So the Devnet two specs link relatively old commit of 7702, which is like two months old, whereas lite client merged something like 19 hours ago. So just to make sure we're all on the same page, like should what we have in Devnet two. I know Devnet two is already live, so it doesn't make sense. Talked about Devnet three, actually. But like, is the thing that we want, is the thing that we want this latest pr that lite client just merged for 7702 or do we want the thing from two months ago?
00:13:20.520 - 00:13:27.392, Speaker B: So for Devnet two, we decided two things. We decided to keep the exact spec of Devnet one, because it's just basically.
00:13:27.456 - 00:13:29.296, Speaker A: A basic relaunch of Devnet one.
00:13:29.408 - 00:13:35.128, Speaker B: And second is to not proc any 7702 transactions because the spec is going to change.
00:13:35.184 - 00:13:36.312, Speaker A: So we felt like there is no.
00:13:36.336 - 00:13:37.860, Speaker B: Need to test an old spec.
00:13:39.530 - 00:14:04.630, Speaker A: And so, okay, so Devnet three, we have the latest 7702 spec. And just to make sure we're all on the same page here, the spec would be including the pr that was merged 19 hours ago that I just posted in the chat. And no other, or, I don't know, minimal other changes to Devnet to like, we're not including EOf or anything like that.
00:14:06.280 - 00:14:12.528, Speaker B: Yeah, exactly. So we wouldn't include EOF, but we would just bump up whatever spec releases are there besides that.
00:14:12.704 - 00:15:06.092, Speaker A: Okay. Okay, I think this makes sense. So, yeah, so I posted the pr in the commit in the chat here, so we can bump Devnet three to use that for 7702. And then we'll see if there's other tiny tweaks, but no other major additions. Anything else on that? Okay. And then one other thing that was proposed that might affect Devnet three. So Felix, Felix from the get team said that we should discuss encoding the EIP 611 6110 request objects in the engine API using SSD rather than RLP.
00:15:06.092 - 00:15:07.660, Speaker A: I don't know if Felix.
00:15:07.740 - 00:16:07.486, Speaker B: No, no. So basically at the moment so this came up a couple times during the code review of the 6110 implementation, Geth. So we kind of noticed that basically there's a lot of code now in Geth to specifically serialize the requests. And more specifically, there's only the deposit requests right now, and the deposits, we have to serialize them to the JSON, but we also have to basically be able to decode them from JSON. And it's kind of the same issue we have in other RPC APIs, where we get a JSON object, and then depending on the fields in that object, we have to figure out like what type of object is this? Because there can be more than one type of request. And we kind of thought that it's a bit silly to have all this complexity on the API layer, when these objects ultimately have to be handled as SSE by the consensus layer. So we thought that maybe it will be, would be wise to just handle them as SSE, like all the way.
00:16:07.486 - 00:17:08.384, Speaker B: So basically make the execution layer in charge of encoding them as SSE, and then we would just relay them over the engine API as opaque hex encoded blobs, just like we do transactions now. So when it comes to transactions over the engine API, we actually don't and call them as JSON, but we just pass them as a hex blob. And we were suggesting to do the same for these new request objects. The downside to this proposal is just that the execution layer will now have to perform the SSE coding, which they haven't really had to do before. However, we will have to start using SSE at some point. So we feel like this is very minimal entry into the world of SSE for the ELS. Because in the absolute worst case, where no suitable libraries available, you could always, because these objects are purely fixed size, they could just be decoded like by hand.
00:17:08.384 - 00:17:43.720, Speaker B: Basically. It doesn't require, like if there's no library available that you can trust, then you could probably just wing it and implement it like in a different way. And it wouldn't be too much code either. I guess it would be about the same as just using Jason. So that's why I think we were making this proposal, and this was specifically me and Peter Shidagi, who's not here today. We're thinking like, you know, why don't we just start with this? Because we gotta add the SSE at some point anyways, and we just wanted to hear like what do other people think about it? Or is it a bad idea or.
00:17:45.100 - 00:17:47.360, Speaker A: Thank you. Yeah. Mikhail?
00:17:48.380 - 00:18:46.808, Speaker B: Yeah, one potential issue is not only the SSD support on Yale, but also SSD union support by all SSD libraries. I'm not sure the union is not used anywhere else at this moment, so that might be an issue as well. We need union because for different requests we have these type fields, fields, and we need to decode them differently. They have different fields. Yeah, I understand this, but at the same time I think it is a pretty, again, this, the, we are, we also talk about this, this union problem. However, in the end, this is such a simple, these types are so simple that it makes sense to start with this. I mean, we were discussing adding like encoding transactions as SSE at some point, and we've also been discussing just generally converting the whole engine API over to SSE at some point.
00:18:46.808 - 00:19:12.390, Speaker B: But for now just as sort of minimal starting point, we could just like try to get this in and then just see how it feels. Prep like the libraries and stuff to make it work. And then. Yeah, I don't know, I just wanted to hear it from maybe the clients as well. Anyone has an opinion about it?
00:19:26.970 - 00:19:40.860, Speaker A: This is maybe a dumb question, but I assume given that 6110 is on the devnet, everyone's already implemented it with JSON, right? Like there's no team who hasn't done it with JSON, correct?
00:19:41.720 - 00:19:43.392, Speaker B: No implement, it's already implemented.
00:19:43.416 - 00:19:43.656, Speaker A: Okay.
00:19:43.688 - 00:19:56.660, Speaker B: Yeah, it's more like a cleanliness question. I mean, on both sides of the API we have to deal with these objects in JSON which are not really, I mean, they are just internal consensus internal objects.
00:19:59.810 - 00:20:48.750, Speaker A: So I guess my proposal, if no one feels strongly about it, is I would maybe keep it as JSON for now, at least for the next couple devnets, because we still have some pretty big things we have not tested yet. It feels like something we can also choose to add basically, like later on if we want to do it. But yeah, given we're still working on 7702, we're still working on EOF. My sense is team's bandwidth is probably limited to like take on another piece of work. And if we can effectively just add it later on. Yeah, I personally feel more comfortable seeing the rest of Petrae.
00:20:50.240 - 00:21:21.740, Speaker B: I mean, like I said, if it's not, I just wanted to hear, I mean, we can totally live with it being Jason for now. For the future. We definitely have this plan to work on converting the whole engine API to SSE. So sooner or later, and at that point we probably also, we will redesign maybe some of the functions to have a slightly different structure or something. And then so I guess maybe we will get another chance then to like really clean this up. We just felt like it would make our life simpler anyways. But it's fine.
00:21:25.880 - 00:21:37.960, Speaker A: Anyone else have thoughts or answers on this? Okay.
00:21:38.040 - 00:21:38.296, Speaker C: Yeah.
00:21:38.328 - 00:22:27.990, Speaker A: And then there's a good comment by Bayesu that they just haven't had time to evaluate it so we could decide this in the future. For that I just thought, yeah, so let's review it async and then we can decide this on the next call or the call after that. It doesn't seem super urgent, but if it's something that we want to do, we can do it later in the for process. Okay. Anything else on SSD? Okay then next up, there was a proposal by Michael on the lighthouse team for get blobs v one. I believe. He's not on the call, unfortunately.
00:22:27.990 - 00:22:50.170, Speaker A: So I don't know if anyone else has the context around this or is able to talk about it. I see. I guess, Mikael, you approved it about a month ago, so I don't know if there was anything else we were waiting on or any feedback we wanted specifically before merging this.
00:22:53.470 - 00:23:32.976, Speaker B: Yeah, the change looks good in terms of the sPac. It's just, you know, adoption and consensus of core devs is needed to move forward. I think it's pretty good optimization. We have discussed some caveats, some potential issues with Michael Sproul about using this optimization in the sense when. Yeah, when it can hinder, you know, blob propagation. So. Yeah, but I think it's viable optimization.
00:23:32.976 - 00:23:35.820, Speaker B: Use carefully should be quite helpful.
00:23:38.520 - 00:23:39.540, Speaker A: Enrico?
00:23:41.320 - 00:23:42.980, Speaker B: Yeah, I just want to say that.
00:23:44.880 - 00:23:47.688, Speaker C: We like that and we probably use.
00:23:47.744 - 00:23:49.860, Speaker B: This optimization.
00:23:51.600 - 00:23:57.830, Speaker C: Because we tend to try to get from peers pretty, pretty soon.
00:23:58.450 - 00:24:04.190, Speaker B: Blobs that we missed or we are receiving late.
00:24:04.570 - 00:24:07.490, Speaker C: So it would be very nice if.
00:24:07.530 - 00:24:10.178, Speaker B: We can try first on our local.
00:24:10.234 - 00:24:13.470, Speaker C: El to get those before trying to.
00:24:13.930 - 00:24:29.400, Speaker B: Get it from the peers and will be a nice thing for us. But I also think that this should not be abused from the CL side. I think I was thinking lately, because.
00:24:29.520 - 00:24:36.552, Speaker C: If CL pretends to get a lot of those blobs from the l, I.
00:24:36.576 - 00:24:37.340, Speaker B: See, like.
00:24:39.240 - 00:24:47.928, Speaker C: We should not do something like that. Affects the dissemination on the p two p. Like a super optimized way of.
00:24:48.024 - 00:24:49.512, Speaker B: Trying to get it and.
00:24:49.656 - 00:24:55.040, Speaker C: And response. I don't want to all the messages.
00:24:55.120 - 00:24:56.760, Speaker B: That I received because you are not.
00:24:56.880 - 00:25:01.700, Speaker C: Actively participating on the p two p anymore if you abuse that channel.
00:25:05.960 - 00:25:13.180, Speaker A: Thanks. Is there a way we can add a limit or. I guess not really.
00:25:15.610 - 00:25:32.670, Speaker C: I think like we should be at some more clean way of clean usage context. Let's say the honest validator should use this in such cases, but not maybe in others.
00:25:33.970 - 00:25:48.780, Speaker A: I see. POTUS. So what is the problem? The problem is that you're not going to be gossiping those blobs. But can you just get it from the l? If you haven't, you consider the DA already satisfied and you gossip them anyways.
00:25:48.820 - 00:25:51.820, Speaker C: On the p two p side, image that you.
00:25:51.980 - 00:25:57.572, Speaker B: You receive a block first and the blobs come, come after.
00:25:57.636 - 00:26:09.578, Speaker C: So you, you know in advance a way to look up your local el for all the blobs and then you construct. And I don't want message over the.
00:26:09.594 - 00:26:12.178, Speaker B: P two p because you say, I.
00:26:12.194 - 00:26:15.230, Speaker C: Already have those, so don't even send to me.
00:26:15.650 - 00:26:18.674, Speaker B: And it means that you're not even.
00:26:18.802 - 00:26:24.230, Speaker C: Disseminating anything, so you're not participating in the dissemination of the blobs.
00:26:24.530 - 00:26:30.298, Speaker A: But can you just send the I have messages and just gossip them anyways because you have them?
00:26:30.394 - 00:26:32.914, Speaker C: Yeah, I mean, if you do that, it's.
00:26:32.962 - 00:26:33.674, Speaker B: It's okay.
00:26:33.722 - 00:26:52.620, Speaker C: But I. It should be in the honest behavior of the validator. You say, if I get it from the L, I disseminate and then give, give the. Send the I don't want. If you ascend only the I don't want, I'm cheating essentially, I think.
00:26:53.000 - 00:27:11.218, Speaker A: Yeah, that seems reasonable. I guess the weird thing is, it would be we need to open a pr in the Cl specs that effectively mentions that. Correct? Yeah, it can be done on the honest validator guide or on the P.
00:27:11.234 - 00:27:12.666, Speaker B: Two P network, perhaps.
00:27:12.818 - 00:27:13.546, Speaker A: Got it.
00:27:13.658 - 00:27:43.630, Speaker B: Mikael, I just wanted to add that disregarding. Yeah, we need Cl to use it first. So it makes sense to implement this method, but el tabs should implement this. So words also check temperature on this, whether it's easy or not, and how much of the efforts it requires to get implemented on the outside. Probably not that much.
00:27:46.970 - 00:28:39.942, Speaker A: Anyone on the El side have thoughts on this? Okay, I guess if there's not a ton of feedback now, what I would maybe do is. I don't know, Enrico, if you'd be able to open a pr against the specs, like the honest validator specs, to kind of describe the gossiping behavior. If we can have that pr open by, like, early next week, we could bring it up on the call, on the Cl call next week, and then if people are happy with that pr, then we can merge both the specs PR and the engine API one. And if there's any objections on the El side with regards to complexity, we can also have last week be like the final place to have next week be the last place to raise them?
00:28:39.966 - 00:28:43.022, Speaker C: Yeah, I can open the pr, but.
00:28:43.086 - 00:28:45.606, Speaker B: I will be off from next week.
00:28:45.638 - 00:28:49.810, Speaker C: So maybe will be carried on by someone else.
00:28:50.590 - 00:29:22.152, Speaker A: Okay, great. Yeah. If you have the time to do it before you leave, that'd be valuable. And so, yeah, let's try and get this resolved in the next week or so and then worst case, make a final decision on this. Yale call. Anything else on this? Okay, yeah, thanks a lot, everyone, for the context. So that's everything we had around Pektra.
00:29:22.152 - 00:30:01.512, Speaker A: Anything else people wanted to discuss about the current devnets? Current forks? Okay. And then I guess one thing we can also decide next week is assuming we did merge this engine API change, do we want this to be part of Devnet three? But yeah, for now we'll keep definite three as Devnet two and the change on 7702. Sweet. I guess, yeah. Moving on, next thing on the agenda. So seven. I always forget the number 7212, the r one precompile.
00:30:01.512 - 00:30:41.230, Speaker A: We discussed it a few times already. There's some desire, I think by some of the teams to bring it into l one in large part because it's already implemented on l two s at the same time. Pictra is already huge in scope. We don't have it implemented. There is some concerns around the complexity of different eips being tested together. So I guess, yeah, the people think we should be including this. Is now the right time to make a final call on this.
00:30:41.230 - 00:31:12.682, Speaker A: Do people want to see how Petra goes and then potentially push this back a bit more? I know we've pushed it back over and over again, but we're also in a spot where we don't have all the texture implemented and so we're nothing necessarily. Yeah, we're not necessarily like waiting to implement stuff. So, yeah, I guess ansgar is in favor. There's another mine in favor, like client. Yeah.
00:31:12.706 - 00:31:16.554, Speaker B: I kind of would like to see how Petra plays out over the next couple months.
00:31:16.642 - 00:31:23.564, Speaker A: I feel like we're in the process of restarting devnets. The things that have been accepted into.
00:31:23.612 - 00:31:25.880, Speaker B: Pectra aren't in the depth nets fully yet.
00:31:26.620 - 00:31:28.364, Speaker A: It feels a little bit like, yes.
00:31:28.412 - 00:31:31.228, Speaker B: 712 7212 is very easy to do.
00:31:31.284 - 00:31:41.348, Speaker A: But we're not on top of Petra right now and it doesn't feel like the time right now is a good time to be adding additional stuff onto.
00:31:41.364 - 00:31:43.452, Speaker B: It, regardless of the simplicity.
00:31:43.636 - 00:31:47.692, Speaker A: So I would rather make that call in three months. Like if picture is going great and.
00:31:47.716 - 00:31:48.724, Speaker B: It'S easy to add great.
00:31:48.772 - 00:31:52.900, Speaker A: But if not, then, you know, we haven't added more stress to our testing.
00:31:52.940 - 00:31:55.080, Speaker B: Load, which is already being pushed to limits.
00:32:00.340 - 00:32:32.330, Speaker A: Yeah, Besu seems okay waiting as well. Perry's highlighting we have 20 eips, I guess. Yeah. Does anyone feel strongly that we should add this, you know, now? Otherwise, I am inclined to agree, I guess. I don't know. Ansgar, do you want to explain why you think we should make a decision now? I'm kind of inclined to agree that we can wait three months with this, and it doesn't really change anything. But is there a reason why it's.
00:32:32.330 - 00:32:34.890, Speaker A: Yeah, there's, like, some urgency.
00:32:36.510 - 00:33:01.798, Speaker B: So, I mean, I think in general, I just think it's valuable to make the decision as early as possible because there's a bunch of things that depend on it. Specifically with this, there's a lot of tooling, a lot of wallet developers and whatnot that I think would really appreciate knowing as early as possible, at least that some sort of preliminary decision towards. Yes, and then even if we can still walk that back, but at least that they have some signaling that they can rely on.
00:33:01.974 - 00:33:08.490, Speaker A: Isn't the EiP on l two s, though, like, for tool engine wallets?
00:33:09.160 - 00:33:44.410, Speaker B: Yeah, more like in terms of strategy of, like, do you forever basically have to maintain two separate, like, the chains that do support and the chains that don't? Or. I mean, I don't have a strong preference if people really want to keep it out for now and make the decision later. It just feels to me unrealistic that three months from now we'll add any ip in, and so I would just make the decision now to add it in, at least on a preliminary basis, and then just look at a later point, which Devnet, it would be a good fit for bringing it into the process formally, but I'm happy to be overruled. I don't feel strongly about it.
00:33:49.390 - 00:33:53.050, Speaker A: Anyone else have strong opinion?
00:33:55.710 - 00:34:00.850, Speaker B: Yeah, I think I'm slightly in favor of including it.
00:34:08.280 - 00:34:57.840, Speaker A: And I guess, yeah, maybe on the client implementation side. Like, do all the teams already have this done? I guess, yeah. Does any team not have an implementation of this already, or does everyone have it done? So beige Zoo has an open pull request on the EIp rip process. Anziar, I know there's some stuff in the dock. Yeah. That Ula shared, but, like, can you give a quick summary of what the core things are?
00:35:01.300 - 00:35:52.270, Speaker B: Yeah, and I'm also happy if Ulushmay wants to explain a little bit. In my mind, it's several things. So for one it's just like, more procedural questions. So, like, what do we do about numbering? Do we create a new Eap copy of the specs? How do we physically reference the kind of the status between the two, but then also in terms of actually just making decisions, do we ship it at the same address so that is within the L2 pre compile range, or do we move it over to the l one precompile range on l one? How important is it that basically Dapps can just use them as is across the different layers? Do we want to make small changes to the spec, or are we okay with using the absolutely identical spec? Like, I think those are questions. They're not terribly, like, hard to figure out, but I would just hate to have them, to have to do them on a rushed call three months from now. Yeah.
00:35:52.810 - 00:36:54.534, Speaker A: Yeah, that makes sense. I think Daniel has a good question around reference tests. Does anyone know? Like, it does feel like we are bottlenecked on l one by testing because there's just so much stuff already. So, like, is this in a spot where if we include it, like, the testing work is already done, or, like, would we expect there to be fair amount of testing? Because I think that's probably one of the things as well that should play. Like, do we include it now versus three months from now? Like, if there's a bunch of testing work? Yeah, it feels kind of unreasonable to add more now, but if, you know, the testing coverage is pretty much complete. Yeah, I think that's interesting. Okay.
00:36:54.534 - 00:37:12.500, Speaker A: Ulas, do you have a link to the testing coverage? Yeah. And I guess. Oh, yeah. Mario?
00:37:13.640 - 00:37:31.920, Speaker B: Yeah. Even if it's already covered, I don't think it's going to be so easy just to merge it into the l one tests. There's. There's still going to be. We're still going to have to review this eventually. Merge it. Yes, but it's not like, it's not free, is what I mean.
00:37:32.000 - 00:37:40.336, Speaker A: And the tests. Yeah, and the tests that Ulyss just shared are like, get tests. They're not like, specs tests.
00:37:40.448 - 00:37:41.140, Speaker B: Yeah.
00:37:41.680 - 00:37:42.016, Speaker A: Yeah.
00:37:42.048 - 00:37:54.300, Speaker B: So, no, no. Yeah, so we. So, so the process would be that we have to review them, then convert them, then merge them to l one tests. So it's not free. It's definitely not free. Definitely extra work.
00:37:55.720 - 00:38:22.402, Speaker A: So I don't know. I think given that, I probably lean fairly heavily against including it now. I think if the 7212 folks want to continue pushing for it, it seems like there's support, but having proper l one level test coverage. Yeah. I think what I would suggest is.
00:38:22.426 - 00:38:59.300, Speaker B: That to help push this on the testing side is just start converting. If someone that is championing this EIP could help port these tests into the execution spec test repository, that would be a very good help. And that can be done in parallel because right now the testing team is focusing on Prague accepted eips. So if someone that is championing this EIP could help us out to Porto stuff, that would be. I think that will help the EIP to get. To get to get into Prague.
00:39:00.840 - 00:39:02.736, Speaker C: Yeah, I guess me and my team.
00:39:02.768 - 00:39:42.386, Speaker A: Can help, but I think. Yeah, yeah. Like Mario, do you want to just share the two repos? But basically like, yeah, we can kind of show you where we'd need to get the cross client testing and what it would look like. And I assume something we'd want to do as well for this pre compile is like pretty extensive fuzzing of the implementations against each other, like we tend to do for other precompiles. I don't know if there's been any work done there as well. I guess. I assume not.
00:39:42.386 - 00:40:27.160, Speaker A: But yeah, I think if we want to add this on top of the already sort of really huge fork that we have. Yeah. Effectively having, yeah. Having very thorough test coverage coming from the champions of the EIP, I think is what we'll need. And yeah, there's also some comments in the chat, Tony, around concerns about the quote unquote government curve. I don't think most client teams have raised it, but yeah. Do you want to just maybe give a quick overview so that everyone has a context?
00:40:32.350 - 00:41:06.840, Speaker B: Yeah, I can do that. I hope you can hear me well enough. Yeah, so I'm basically against EAp just because. Yeah, sector fifty six k one was initially chosen for certain reasons, and r1 is different when it comes to the parameters of the curve and also the kind of second reason would that this is kind of a perfect example what we can ship on l two. And yeah, in my opinion, not needed for l one.
00:41:09.060 - 00:42:27.640, Speaker A: Thanks. Yeah, I don't know if there's any comments or thoughts about that. Okay, then I guess, yeah, on the testing front, it probably makes sense for the 7212 champions to kind of get it into a spot where it wouldn't be an additional burden on the testing team. Yeah, it's still CFI, so we can reconsider it like in a few months when we've done a bit more progress on Petrae. But yeah, it seems like the main objection from the client team side is really just, or the main objection, I guess, from including it is do we actually have the bandwidth to test this property? So to the extent that you can help with that, Ulyss and your team, then I think, yeah, it might make it more likely to. It will make it more likely for it to be included in Petra, but yeah, I think not making a decision today is probably the right call, given how early we are. Anything else? I don't know.
00:42:27.640 - 00:43:11.780, Speaker A: Ansgard like client. Both your hands are up, but are they still up from last time? Ansgar is gone and if you have final comments, you can see it now. Okay, I'll just assume your hand is still up. Okay, sweet. So next up, Andrew, you wanted to chat about quantum resistance. So do you want to give a bit of context there? And I think it's worth breaking this into two different topics. So, first, just the risks and concerns around quantum, and then I second, if that has implications on Verkle and what they are.
00:43:11.780 - 00:43:14.020, Speaker A: Yeah.
00:43:15.920 - 00:44:10.620, Speaker B: Right. So it's like what Vitalik highlighted at. A lot of experts forecast that in the 2030s, quantum computers will become powerful enough to break non trivial cryptography. So, I mean, it's difficult to forecast, especially the future, but assuming that there is a good chance of that happening. So we are essentially, with Verkle being quantum resistant, we are replaced. Sorry, not being quantum resistant, we are replacing the commitment scheme in Ethereum with the current commitment scheme, which is Patricia, try with something that is potentially vulnerable. So, two questions.
00:44:10.620 - 00:45:13.750, Speaker B: I am no expert on quantum computers and cryptography. So it's a genuine question, like that vulnerability of vocal to quantum computers. Is this super theoretical and. Yeah, so it's something that we can sleep well and not worry too much or is it a very real thing? That's one question. And assuming that it is real, then maybe we should actually change the cryptography in Virko to something quantum resistant, because I imagine that. Well, so the cryptography will have to change, of course, but things like maybe the embedding scheme and the migration strategies, a lot of work there can be reused. So it will not be like a total waste.
00:45:13.750 - 00:45:54.280, Speaker B: So yeah, it will have something like assuming that this vulnerability of Virko is real, then we perhaps should move to something like quantum resistant vehicle rather than. Because it will be a massive change, not only for the protocol, but for the clients, but for the entire ecosystem. And if we are asking for this bigger change, we shouldn't ask for another massive change in five years. Yeah, that's my. I just want us to start thinking strategically about it.
00:45:54.660 - 00:46:04.880, Speaker A: Thanks for the context. And yeah, Sudeep shared the talking question in the chat as well. For reference people. Yeah, Felix has your hand up.
00:46:05.500 - 00:47:13.890, Speaker B: So basically, one thing to understand is, from what I understand about it, the vocal implementation is very vulnerable to quantum computing should it come to pass, because it's like 100% based on the elliptic curve cryptography. However, currently ethereum is generally reliant on elliptic curve cryptography and it's built into the protocol at a very low level. So basically it is, if an exploit, like if a quantum computer comes to pass, which is capable of breaking this cryptography, then we are screwed generally, because I mean, in the future there are these long term plans to introduce full account obstruction, but until this is done, we are going to be vulnerable to these types of things and we are very, very far away from implementing forward count obstruction, I think. Thanks. So this is just something to keep in mind.
00:47:15.470 - 00:47:16.730, Speaker A: Yeah, Ignacio.
00:47:20.230 - 00:47:26.770, Speaker B: Yeah. So just to add on what Felix said, I want to also remind that.
00:47:27.070 - 00:47:29.430, Speaker A: Like three months ago we included blobs.
00:47:29.470 - 00:47:56.872, Speaker B: In the protocol, and blobs used PCG commitments, which also use self decorous. So as far as I know, the strategy there was considering in the future, changing KC commitments to starks to make blobs be quantum resistant. So yeah, I just want to make the point that unless something really relevant changed in the last three months regarding.
00:47:56.976 - 00:47:59.160, Speaker A: A real risk of quantum computers being.
00:47:59.200 - 00:48:40.728, Speaker B: Real, I think maybe the overall sentiment around this risk shouldn't change. But what I know is that George has started talking with the research team in the EF, so they can start talking with experts in the field so we can get a more updated, I wouldn't call it forecast, but sentiment around this risk, which usually like people always think is ten years away, but at some point that will be actually true.
00:48:40.784 - 00:48:43.664, Speaker A: And we should have a more like.
00:48:43.712 - 00:48:49.832, Speaker B: Overall plan on this topic, not only for Burkel, but as said before, for.
00:48:49.856 - 00:48:51.448, Speaker A: A lot of other things, for blobs.
00:48:51.504 - 00:48:56.020, Speaker B: For signatures or having account destruction, things like that.
00:48:58.000 - 00:49:03.900, Speaker A: So, yeah, just that. Thanks Guillaume.
00:49:05.720 - 00:49:57.442, Speaker B: Yeah, I just wanted to try to answer all the questions by Andrew in order. So one of them is can we rescue verkle? Not really, because yes, like others said, it's based on elliptic curves and in fact it gets a lot of properties from elite elliptic curves. Unfortunately, elliptic curves rely all that cryptography relies on the defie Hellman assumption, which is broken by quantum algorithm, namely some form of Dushkor algorithm. So if quantum computers come like become a reality, which is still a big if, even in the thirties, it would break Verko. And like Ignacio and Felix pointed out, other areas of Ethereum that are probably just as important as the state is not. It's not. The state is big.
00:49:57.442 - 00:50:59.870, Speaker B: But yeah, there's a lot of security assumptions in Ethereum that are beyond the state that also rely on that. One thing I wanted to add is, or at least to dispute, is the idea that if we switch directly to quantum resistance, quantum resistant feature, well, first we lose a lot of the features of the verkle was created. There's a lot of things like smaller proofs. This is something you will lose homomorphism, things like this that are extremely useful for building, for stemming stick growth and doing other things. But what I'm getting at is if we go straight to the final product, it assumes we know what the final product is. And that's a really tall order because, for example, we expect to use binary trees for starks. But the stark, like the concept of Stark, the security of Starks is mostly conjectured.
00:50:59.870 - 00:52:04.270, Speaker B: So in a 15 years frame, let's say quantum computers happen mid thirties, we might discover something that is going to break starks or even some hash function we use. So I think it's a bit optimistic to say we should go straight to the last tree model because we don't know where the tree model is. We will have to upgrade the tree no matter what. This is not the last time we upgrade the tree. And the advantage of Verko is that we are currently developing all the techniques to update the tree, which can be reused later on. So I don't think if we go to verkle now or let's say in two years, and we find in ten years that quantum computers are approaching fast, which is, I mean, I haven't really heard any experts say that. I hear a lot of stuff on the news, but I don't see any actual progress.
00:52:04.270 - 00:52:36.690, Speaker B: We still don't have big registers, like big enough registers that this would be quantum registers, that would be a danger. But even if it happens, we'll be able to react because we'll have all the tools already. So I'm not worried about having to change in a rush. Well, in a rush, in a relative rush. Of course, if it happens from one day to the next, we'll be taken by surprise. But if it's like a two year process, we'll be ready to do this. And on top of that, there's no guarantee that.
00:52:36.690 - 00:53:16.126, Speaker B: I mean, yeah, it's a bit naive to expect that we will never upgrade the tree ever again. It will happen. The MPT tree. It was created in 2013, 2014. Since I joined the EF people have been talking about replacing the tree, so there's nothing guaranteed. There's definitely no guarantee that we will never have to replace the, the tree, whatever it is. So that doesn't mean we want to ignore everything that is like, that doesn't mean we want to ignore quantum resistance.
00:53:16.126 - 00:53:34.250, Speaker B: We should have this conversation, but I think we should separate it from the question of vertical. It should really be, is Ethereum quantum resistant? Is the Internet quantum resistant and then not make that a showstopper for verkle.
00:53:38.790 - 00:54:18.854, Speaker A: Thank you. Yeah, so I guess I agree. Yeah. So I agree that separating out the quantum risks broadly from, like, vertical and possible vertical alternatives is probably the best way to think about this. And, you know, there's a lot of different ways in which, you know, quantum computers could affect Ethereum and more things beyond that. So I guess what's the right place for people to discuss this? Like, we're not going to figure out Ethereum's quantum strategy in the next 35 minutes. Yeah.
00:54:18.854 - 00:54:27.300, Speaker A: Is there some place that people are discussing this or people would want to discuss this or some concrete thing that people would want to see happen?
00:54:34.080 - 00:54:42.220, Speaker B: I was hoping for Josh to answer that, but if he's not around. Oh, yeah, Josh is here. Do you want to.
00:54:44.040 - 00:54:44.464, Speaker A: Yes.
00:54:44.512 - 00:54:53.140, Speaker B: So I'm creating a group where we can continue discussions around this, if anyone would like to join. I guess I'll drop a link in the discord.
00:54:53.640 - 00:54:57.300, Speaker A: Should we, should we create just a discord channel for quantum resistance?
00:54:58.400 - 00:54:59.940, Speaker B: Can also do that? Yeah.
00:55:00.800 - 00:55:30.270, Speaker A: Do we have actually. So we have a cryptography discord channel. Does it make sense? And it's not, I don't know, it gets a couple messages every now and then, but like, yeah. Does it make sense to use that and then just direct people there? And I see Vitalik is among the frequent posters. So if we want to, like, ask him for more context on the talk, it might be a good place to have that.
00:55:31.970 - 00:55:34.990, Speaker B: Yeah, that sounds good. We can continue the conversation there.
00:55:36.130 - 00:55:55.360, Speaker A: Cool. Okay, so let's do the cryptography discord and, yeah, continue there. And I think trying to figure out, like, yeah. Specifically what the estimates are based on and then, you know, what. Yeah. Like, what the actual risks are. Yeah.
00:55:56.420 - 00:56:26.250, Speaker B: If I may add something regarding design itself, it's also been built in a way that we can swap less minutes of vertical tree with a binary tree. But, yeah, like I said, we would lose something, but it's still an option. We can take our time to study the thing and make a decision when, you know, first we identify that the danger is present and that we have the, yeah, we have the response to that danger.
00:56:27.710 - 00:57:23.810, Speaker A: Thanks. And yeah, I guess that is. So there's a couple comments in the chat as well. Like this is kind of, the second thread is, you know, given this and potentially other things like different, you know, developments on different type of trees and whatnot, what's the best place to discuss whether Verkle is the right next thing? So we have sort of scheduled it for the next fork already. We decided this, I think early this year because we wanted to make sure we would keep it as a priority. I know there's a vertical implementers calls, but obviously those are focused on actually working on the vertical implementations. But yeah, like are those the best place for people to come and discuss, you know, potential alternatives to Virko? Should we, should we do this here? And if so, what are like the, what are like the factors we want to consider?
00:57:26.550 - 00:57:47.430, Speaker B: Yeah. So to be clear, there is no alternative to verkle currently. There's a couple ideas that maybe in three years will be a correct, like an acceptable competitor to Verkle. But if you want to discuss those ideas, yeah, we are happy to discuss that on the, on the Verkles implementer call just because, yeah, if those ideas are relevant, we want to hear and discuss them.
00:57:50.050 - 00:59:18.420, Speaker A: Okay, anyone else have thoughts on this? Okay, so if people have, you know, alternatives for vertical, we can, we can, yeah, we can discuss them on the vertical call. And then obviously, yes, once we ship Petra, we should make sure that Verkle is still the right thing for the fork after. But I think that will be late. If what we want is to ship a state, try transition and use a different approach to the verkle. So like if we arrived after Pektra and we said there's this other completely different urgent thing to ship, and maybe it's more urgent than verklite, you know, that seems reasonable that we could make that decision. But if we arrive to Osaka and we think like Verkle is the thing, we still think we should ship, but it might be worth exploring another type of tree that feels like the type of thing we'd want to start doing now, so that by the time we get to Osaka we actually understand what the trade offs are very deeply. So if people do have like candidate alternatives, yeah, I think it'd be worth looking into it now and we can discuss those on the verkle calls.
00:59:18.420 - 00:59:33.526, Speaker A: POTUS, can we phrase the commitment of the form by Osaka? We're changing the tree and if there's any alternative to verkle that wants it to make it to Osaka, then it should be at a level that we.
00:59:33.558 - 00:59:35.430, Speaker B: Feel confident, as we feel today about.
00:59:35.470 - 00:59:41.126, Speaker A: Berkeley being in Osaka. So this might sound impossible, but what.
00:59:41.158 - 00:59:42.974, Speaker B: Would be a tragedy would be to.
00:59:43.062 - 00:59:49.622, Speaker A: Delay changing the tree because of some statements about being in early research at the time.
00:59:49.726 - 00:59:55.170, Speaker B: So we should probably commit to changing the tree in Osaka with the candidate today being virtual.
00:59:56.710 - 00:59:59.730, Speaker A: Anzgar, do you want to expand? Why? You don't think it's a reasonable commitment?
01:00:01.480 - 01:00:48.870, Speaker B: Yeah, I think physically making that commitment would very strongly restrict the design space. It basically only realistically would allow for virtual and maybe one or two potential alternatives. I think what very realistically could happen is that we basically agree that, hey, given these advances in decay or something, we think that vertical already has decent, these downsides that we don't like and that within the next three years or so we will be at a point where we will have these superior alternatives and we will not make two upgrades. So we would rather wait for a few more years, I think. I'm not sure, I'm definitely not confident that that's where this conversation will end up in, but I think it should definitely be a option, that should be one outcome that we might land on. And so I think making this commitment now seems arbitrary and no, I don't see a strong reason for.
01:00:56.300 - 01:00:59.520, Speaker A: Okay, I guess. Josh, when is the next Virgo implementer call?
01:01:03.060 - 01:01:05.600, Speaker B: So we had one this week. The next one is in.
01:01:05.980 - 01:01:36.370, Speaker A: Not this, not this upcoming Monday, but the following Monday. Okay. So I guess, yeah, it might. Every two weeks. Yeah, I think, yeah, it probably makes sense to discuss specific alternatives there. I don't know if anyone wants to do this in the next two weeks. It doesn't feel like the most super urgent thing, but yeah, it would be good to not wait six months to do this if we think there are other options.
01:01:36.370 - 01:02:24.340, Speaker A: But yeah, I agree that having the discussion there and people having time to prep and actually read up on things is the most valuable way to approach this rather than trying to like come up with alternatives right now on the spot. Yeah. So I guess, yeah, moving this to the vertical calls and then if, I don't know, nothing has happened in like three, four months. Three, four months, we can follow up on it here again. Yeah, maybe one last question. So like, what's the urgency to making the change in the three, in the next 24 months? I know we talked about this a few months ago around the state size growth, but I don't know if Guillaume or Josh, do you have a quick answer? To that.
01:02:26.360 - 01:02:53.780, Speaker B: I mean, yeah, it's a state side growth. It's also unlocking a lot of things with statelessness, including smaller proofs to do many communication, like improve the way we communicate, for example between shards. Sorry, roll ups. If they. If they choose to adopt, there's a lot of. There's a lot of features we want to have and yeah, it's also, like you said initially, it's mostly a state growth thing.
01:02:57.640 - 01:03:34.820, Speaker A: Thanks. Anything else on vertical or quantum? Otherwise, next steps are the cryptography channel for quantum and then add a vertical implementers call for. Okay, next up then we had an EIP by a few different authors, Guillaume and Wei, a leaf level state expiry. I'll post it, I guess, the draft EIP, but yeah, Guillaume, you want to give some overview?
01:03:36.950 - 01:03:38.078, Speaker C: I think I can take this.
01:03:38.134 - 01:03:39.210, Speaker A: Yeah, perfect.
01:03:40.030 - 01:03:42.622, Speaker C: Yeah, sure. Is it okay if I share my screen?
01:03:42.726 - 01:03:43.410, Speaker A: Yes.
01:03:44.550 - 01:04:21.776, Speaker C: Okay, so just going to do that. And I've also put the link to the EIP in the chat, so I'm just going to spend like ten minutes going through this EIP. So please bear with me everyone. So thanks for having me here. I'm going to introduce this EIP called 7736, leaf level state expiry. It's written by Guillaume and Laihe. So the goal here is to get some feedbacks on this EIP and at the same time to reintroduce the concept of salespiratory to everyone, because the progress on state expiry has been stagnant in the past few years due to different complications and research paths.
01:04:21.776 - 01:05:14.596, Speaker C: So we not only want to make this EIP work, but we also want to spark discussion on the concept of state expiry, how we can integrate different ideas into the protocol. Yeah, so without further ado, let's get right into it. So the motivation for this EIP, as I said, the previous CSV solutions are very complicated and complex to implement, and they usually require heavy changes in the ethereum structure, that is address based extension. So because they are so complicated, people are not motivated to proceed with the research. So hence we came up with this EIP, 7736, which is a much simpler approach to Cxpiri, and it's also better compatible with Virgo tree. So this EIP is a state expiry solution that can be enabled after Virko three is implemented.
01:05:14.708 - 01:05:15.400, Speaker A: Yeah.
01:05:15.980 - 01:05:54.698, Speaker C: Let's talk about specifications and the specific details on how this EIP work. I'm just going to talk briefly on the constants that we introduced in this EIP, but I want to highlight on three particular constants. Here we are going to introduce a new concept, or a new domain, or a new field, whatever you want to call it, called epoch. But this epoch is not the epoch that we know in the current protocol, but you can think of it as an expiry epoch. So you have like epoch link which is the duration of the epoch. Here we denote it as six months. Then you have the initial epoch counter, which basically the initial epoch when we implement or execute this EIP.
01:05:54.698 - 01:06:47.840, Speaker C: Then we have num active epochs, which is the number of concurrent x by epochs, which is in which the default value is two. So if you combine this information together, you can just think of it as these values denotes when a state is considered as active or not. We will look into it in the next few slides. So changes to the vocal tree. So the current vocal tree structure is like internal nodes, you have internal nodes, you have extension nodes and users have lived node. After this EIP is implemented, we are going to make a change to the extension node in which we'll add a last epoch field or variable to the extension node. So this additional field is going to denote if set of value is considered as expired or not, and the exact expiry rule which I'm going to show here is as follow.
01:06:47.840 - 01:07:46.320, Speaker C: So for every react event, the last epoch field is going to be updated with the value of the current global epoch that we have the epoch. Here again I'm referring to the expiry epoch. And for any read or write events, if the current epoch, the current global epoch is greater than or equals to the last epoch plus the num active epochs, then is this particular event or this particular operation is reverted because the set of values or this particular extension node is deemed as expired. So this is the expiry logic that we have. Um. Um, in regards to the, um, how can teams want to do the expiry logic? Like, put in a way the expiry nodes, it can be implemented themselves like whichever logic guys prefer. But minimally, for each extension node, uh, data that needs to be kept are, um, the stand value of the leaf node, um, sorry for the extension node.
01:07:46.320 - 01:09:07.256, Speaker C: Um, this needs to be kept because we need to find the location of the extension node, and we also need to keep the commitment of the expired extension node which is used for validation when we do resurrection. So talking about resurrection of the extension node, we will need to introduce a new transaction type called resurrect dx type, which essentially contains the encoded form of a vector which contains the stem, the last epoch, and the values, right. So this tree simple field, we are also going to introduce a new form of course which is based on resurrection gas course based on the constants introduced in EIP 4672. The brief logic of how this works is that you just send a transaction, then you want to resurrect a certain state. We are going to charge the guest cost. After the guest is charged we proceed with the validation and the validation process is on a high level is something like to just reconstruct the extension node and from there you can validate against the one that is in the database and you can do a comparison between the commitment to check if they are valid or not, why or rational of this EIP. So again no ERC is required is simple.
01:09:07.256 - 01:09:50.240, Speaker C: It only references the vocal tree that we have right now except for the additional field that we add to the extension node. And we don't have to introduce multiple per epoch trees as compared to the previously expiry solutions. We are going to have smaller resurrection proofs because we just need to provide the necessary data through the transaction. The gas cost for the reservation is clear. Overall we only need to expire the cold data, the hot data or the active data will still remain in the state. It's for compatible. So in the future if you want to do like ESE or multiple epoch trees is still possible, right? And some questions that we have while writing this proposal.
01:09:50.240 - 01:10:41.510, Speaker C: Most important question how effective is the expiry? So it's a simple approach, but we expect that most, but not all data are deleted. We still have to do the simulation to check against the corner cases. So we need to post the statistics when we have done that. And the second question kind of also the important one is why only write events update the last epoch counter? Because if you think about if we include read events as well, it will refresh the last epoch in the extension node. Then essentially it's considered as a write event because you have to recalculate the commitment of the essential node, then you have to update your database so it potentially adds a DOS vector. So some potential solutions that we have is to increase the read event for the initial epoch read to match that offer write event. But we are still exploring other solutions as well.
01:10:41.510 - 01:10:59.230, Speaker C: So feel free to give your opinions. Yeah, that's it for my introduction of this EIP. Again, I welcome everyone to go to the discussion page to give your opinions and feedbacks on this EIP and hope to spark some more discussions on CSBR as a whole. Thank you.
01:11:01.090 - 01:11:43.890, Speaker A: Thank you. That was a great presentation. Yeah if you can share the slides either here on the agenda, that would be great. I had a question and then there's another one by like client. But basically this is clearly more efficient on like flatter trees. But is there, is there, aside from like the efficiency gain, is there any other like, reason why this has to be closely coupled with verkle? Like if we switch to like some other type of tree in the future, or if we did it on the merkel Patricia tree, would it still work but just be sort of less efficient? Or are there some other like dependencies or type coupling with verkle?
01:11:44.630 - 01:12:28.588, Speaker C: Yeah, understood. So I think the nice thing about Virgo tree that led us to this proposal is that in Virgo tree the values are sort of like, you can think of it as group under an extension node. So when they are grouped, we can expire all of them at once if all of them are not being accessed together. So if you compare that to MPT, it's not the case. So it's harder to do that on MPT currently. Based on what I know for other types of tree, it depends on what kind of data structure that you're referring to. But if you have the sort of feature of grouping elements together, then maybe a similar proposal would work.
01:12:28.588 - 01:12:34.240, Speaker C: If not, then I think we have to consider other alternatives. So that's my take on that.
01:12:35.140 - 01:12:48.450, Speaker A: Awesome, thanks. Then there was a question by my client asking, does this stop the state from growing, or does it just means it keeps growing but slower forever?
01:12:50.430 - 01:13:21.544, Speaker C: Yeah, I think that's a good question. So definitely we are not bounding the state completely. Definitely the state is going to grow slower, but at what rate it's going to grow at and how efficient it is again, at expiring the values. We still have to do a simulation against or the entire state that we have and do the expiration and get the statistics. So I don't have the exact answer for that. We have to do more analysis on that.
01:13:21.592 - 01:13:24.096, Speaker A: Yeah, thanks.
01:13:24.208 - 01:13:59.910, Speaker B: Let me add something. Yes. It's not necessarily tied to vertical trees, but it's really special interesting with vertical trees, because the verkle tree is very shallow and has very extensive nose. The nodes are very large, but their storage on disk is very small. So while you're not bounding the disk, sorry. While you're not bounding the size on disk, you only retain long term. The smallest part of the tree, like the structure that remains on disk long term, is much smaller than it would be in an MPT.
01:14:02.220 - 01:14:10.800, Speaker A: Got it. Thank you. And then there's a last question by Lukesh asking, would client teams be expected to prune expired nodes in the background?
01:14:12.980 - 01:14:25.040, Speaker C: Yeah, I think that's a logic that you guys determine. It really depends, like some client teams, you can choose not to put in at all. So it really depends on your implementation.
01:14:27.710 - 01:14:31.370, Speaker A: Got it. Thanks. Any other questions, comments? Oh, yeah. Daniel?
01:14:32.750 - 01:14:37.142, Speaker B: Yeah, so I just wanted to say that the EIP, from a technical point.
01:14:37.166 - 01:14:39.830, Speaker C: Of view, I think is very good for me.
01:14:39.870 - 01:14:44.078, Speaker B: It's just really the questions. I mean, every sort of state expiry.
01:14:44.134 - 01:14:49.078, Speaker C: Comes potentially with very bad ux, because I think it's very hard for users.
01:14:49.094 - 01:14:56.322, Speaker B: To understand that whatever state they have disappears after some time if they do.
01:14:56.346 - 01:14:58.322, Speaker C: Not write it in the last year.
01:14:58.426 - 01:15:01.058, Speaker A: Something like this, I mean, for me.
01:15:01.074 - 01:15:03.754, Speaker C: Is more the question if you really.
01:15:03.802 - 01:15:06.630, Speaker B: Want to do that in the first place.
01:15:11.010 - 01:15:32.600, Speaker A: I guess this is more dev ux than user ux thing in a way. Right. Like, because as a user, you would expect that your wallet would sort of handle this for you. Right? Like, you tell them you want to interact with this contract, make this transaction, and then the wallet will have to figure out, like, you know, what. What is it? I mean.
01:15:33.300 - 01:15:35.044, Speaker B: Yeah, but there are some cases, you.
01:15:35.052 - 01:15:37.412, Speaker C: Know, people are losing their phones with.
01:15:37.436 - 01:15:46.972, Speaker B: The wallets, or they. I don't know, they just uninstall their old wallets and reinstall a new one. And it might not have all the data for the.
01:15:47.076 - 01:15:48.400, Speaker C: For the resurrection.
01:15:49.300 - 01:15:52.796, Speaker B: So, I mean, it's not impossible that.
01:15:52.868 - 01:15:59.412, Speaker C: There would be users who cannot resurrect the state anymore. The only. The only thing would be if there's.
01:15:59.436 - 01:16:01.636, Speaker B: Like, a third party where you can.
01:16:01.668 - 01:16:05.132, Speaker C: Go to, like, archive notes or something like this.
01:16:05.196 - 01:16:53.970, Speaker A: Yeah. And I think that's always been the assumption that, like, either you can restore, you can save, you know, your, like, copies of the state, or you rely on some third party to give you a proof. Yeah. And then this is, like, many, many years ago, the other idea that we had was, like, state rent, where you can think of a way you can think of, like, state expiry as, like, an out of protocol market for the state, where either you manage it yourself or you pay some third party, and state rent is effectively an in protocol market for the state, where you could pay Ethereum to keep it for you forever. But, yeah, I think we would need to discuss this, but I don't think there's a way to resolve that. It's kind of like the core trade off. Yeah.
01:16:53.970 - 01:17:24.260, Speaker A: Any other comments or thoughts? Okay, Anzgar has some comments around just understanding the density of the nodes, which might be worth looking into where. Yeah, so there's the discussion thread on each magician. Is that the main way for people to continue the conversation and reach out to you?
01:17:26.960 - 01:17:34.500, Speaker C: Yeah, I think just going to the discussion link, we can continue our discussions there. Yeah.
01:17:36.610 - 01:17:41.154, Speaker B: Cool. Maybe I missed this, but was this something that needs to really go in.
01:17:41.202 - 01:17:43.106, Speaker A: With Verkl from the beginning, or was.
01:17:43.138 - 01:17:45.306, Speaker B: The expectation that this would be something.
01:17:45.378 - 01:17:47.550, Speaker A: That is added in at a later point?
01:17:47.890 - 01:18:03.490, Speaker C: No, we can do both. If we choose that we think that this EIP is good to go with vocal directly, then we can do that. Or we can do that. We can decide when we want to enable this EIP after virtual is implemented. Yeah, so that's one of the good things as well about DCIP.
01:18:04.030 - 01:18:10.238, Speaker B: What do you mean by the latter? Like we can just decide to enable it at a later point, like we.
01:18:10.254 - 01:18:17.134, Speaker A: Have the same similar situation with the MPT. We could decide to change it or to change the format of the account.
01:18:17.302 - 01:18:20.670, Speaker B: Header, but we don't ever end up doing it because this is a complicated.
01:18:20.710 - 01:18:26.850, Speaker A: Piece of code and we're afraid to change it. So is there something about vertical that makes it different in that sense?
01:18:27.520 - 01:19:00.806, Speaker C: Yeah, I think this is mentioned in the EIP as well, under the backward compatibility section. So it's backward compatible with vocal, because in the default value for the fourth evaluation point, if you check the extension node structure, it's zero, is default to zero. So even if we add this new EIP, this new counterfield to the extension node, when we recalculate the commitment, it's still going to be the same, and hence it's better compatible.
01:19:00.918 - 01:19:02.262, Speaker A: Yeah, okay, I understand.
01:19:02.326 - 01:19:35.060, Speaker B: Thank you. Yeah, just to chime in, like Hans said, it's been built to be very backwards compatible because, yeah, the value is zero. All you need to do next time when you activate the EIP is to add the timestamp on every write, and then the older tree values, the values that were not written since the fork are automatically seen as old. But we will definitely not do this during the vertical fork, because the vertical fork is complex enough. So that would come in a later fork.
01:19:39.960 - 01:19:41.300, Speaker A: Thanks, Luke.
01:19:42.680 - 01:20:34.550, Speaker B: So my two cent here is that if the portal network, the devs, managed to start the state network before we go to vertical trees, and I supposedly heard that they planned to start in alpha or beta stage this year, well, then I'm all for, for this kind of expiration and pruning, because there would be a good decentralized way to resurrect that. For example, the wallets or anyone could integrate too. So just my two cent here would be good to catch up with them. How are they going? How is it going for them with the state network?
01:20:39.700 - 01:21:05.290, Speaker A: Yeah, we can definitely do that. Okay, anything else on this EIP? And okay if not, last thing I had on the agenda. So I know we've wanted to prioritize EIp four. Four more. Anyone have updates on this?
01:21:11.390 - 01:21:31.292, Speaker B: Yeah, there was just one tiny update. I had made an ether search post on using torrents for EIP four fours and there was a request to add the proofs in the torrents. So I've done that and published a new torrent file. So in case someone wants to, I guess, download it or use it, make sure you use the latest version of the torrent of thanks.
01:21:31.356 - 01:21:32.640, Speaker A: Can you share the post?
01:21:34.460 - 01:21:35.240, Speaker B: Yeah.
01:21:36.300 - 01:22:00.410, Speaker A: Anything else? Okay then. Otherwise we can wrap up here. Yeah. Thanks everyone. We'll talk to you all on the Cl call next week. Cheers, everyone. Bye.
01:22:00.410 - 01:22:02.862, Speaker A: Thank you.
01:22:02.886 - 01:22:03.530, Speaker B: Bye.
01:22:21.440 - 01:23:16.310, Speaker A: Sadeena. Sadeena.

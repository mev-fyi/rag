00:00:14.650 - 00:01:43.600, Speaker A: So we're interested in low latency instead of high throughput. And we're interested about small pieces of information, not like films. From an application programmer's point of view, what it does for you is, you know the hash of some piece of information, you ask for it and you get it as fast as possible, like preferably from the ram of your own computer, slightly worse from the hard drive or the SSD of your computer, and in the absolute worst case, from the network. But we close, so the design goes integrity, so the information stays immutable, and you can be sure that you get what you asked for, a measure of permanence. So once something gets there, it's impossible to delete. It's resilient against both random failures and malicious adversaries, where of course, if it's resilient against malicious adversaries, it's automatically resilient against random failures. But we sort of keep both in mind.
00:01:43.600 - 00:02:43.954, Speaker A: Speed is very important, and by speed, I mean low latency and an optimal utilization of available resources. So network storage, and to some lesser extent processing power. But mostly we're interested in network resources and storage resources. How do we ensure integrity each time you receive a piece of data, if it comes from any other source but your ram, you check the hash. That's just a rule. And because of that, in order for that to be feasible, we need to make sure that there are no long unchecked downloads. So if something is long, then it needs to be chunked, and we should maximize the chunk size in something like 4 kb, not more.
00:02:43.954 - 00:04:13.020, Speaker A: And there are two kinds of chunks. There's a leaf data fragment, and there's a Merkel tree node, which has hashes of other chunks. And this of course, means that the hash is really a Merkel hash. And I really recommend that we should probably discuss it, that everything, when we say hash inside Ethereum of stuff that needs to be stored, then we always calculate this Merkel hash, because even if the purpose is not immediate storage in this archive, still, calculating a Merkel hash in a multi core machine is actually faster. And it's nice if the hash always refers to the same thing, but the underlying assumption is that the vast majority of data that is going to be stored here, it fits into a single chunk. So we're thinking about things like parts of the state, transactions contract, things like that, which are typically not very long. So how do we go about being resilient and redundant? So this is where DHT comes into play.
00:04:13.020 - 00:04:34.850, Speaker A: So this is going to be a little bit of an introduction to what ADHD is and how they work. Maybe for some of you, it will be a little boring. So, node addresses. So the addresses of the machines that form the network and the keys of the pieces of data, the hashes.
00:04:36.890 - 00:04:37.206, Speaker B: They.
00:04:37.228 - 00:05:16.260, Speaker A: Are the same type of object. So in this particular case, it's probably going to be 256 bit hashes, because the addresses of the nodes are just the hashes of their public keys. And there's a particular distance measure defined on this space. And by distance measure, I mean the mathematical definition of a distance measure. So it's symmetric. The distance from a to b is the same as the distance from b to a. It satisfies the triangle inequality, and the distance from something from itself is zero.
00:05:16.260 - 00:06:05.986, Speaker A: So what you get is that, suppose this is an illustration where the distance is like the euclidean distance on the plane. The black dots are the machines. They are randomly and uniformly distributed because the address is a result of a hashing, and the big black circle is the entire space. So that's where the data can live. So a piece of data can be anywhere. And nodes are keeping, each node is keeping the information that is closest to them. Now, of course, as long as they can afford to store something, they just store it.
00:06:05.986 - 00:07:06.470, Speaker A: But when their storage resources get full, first their ram and then their background storage, then they sort of delete what is furthest away from them. So basically, there's a radius in which they are responsible for the data. And as the volume of the data inside the DHT increases, then these Radi, they get smaller and smaller. And there are like two situations depicted here, the green situation. When these radi are fairly big, they completely overlap the entire space. And of course, if the system gets overwhelmed, meaning that the total storage resource inside the system is insufficient, then we get to this rep situation when there are uncovered places, this is a failure mode. It's a graceful failure, but it's a failure.
00:07:06.470 - 00:08:11.660, Speaker A: And this system provides a natural load balancing, because since both addresses and addresses and keys are result from hashes, they're uniformly distributed. It means that all the nodes are exposed to roughly the same load. So this is how we address redundancy. So in the normal situation, which is depicted with green here, if one node goes offline, then its circle is removed, of course. But still all the other circles still cover the entire, all the green circles still cover the entire black circle. So that's how every DHT works like that. And basically, the difference between the different dhts largely boil down to how these nodes are connected and what the distance measure is.
00:08:11.660 - 00:09:08.780, Speaker A: So let's first talk about the desirable network topology, how to connect these nodes before we go there. So suppose this node is interested in this piece of information, then they need to follow the path through the network topology. So that's why network topology is important. So we are building a scalable network of n nodes where n can grow indefinitely. The first thing that we want is a low diameter that comes directly from our requirement of low latency. So the theoretical minimum is order one. So for example, if you think about a complete graph, when every node nodes, every other node there, the diameter is exactly one.
00:09:08.780 - 00:09:53.574, Speaker A: The definition of the diameter is the longest, shortest path. So you take every pair of nodes, you find the shortest path between them, and the longest of these across all the pairs of nodes is the diameter of the graph. So theoretically it can be as low as one or order of one. So it can be a fixed number and the acceptable maximum, I would say that it's probably log n. So you don't want the diameter to be longer than log n. As the network grows. The other thing that you want to limit is the degree of the nodes.
00:09:53.574 - 00:10:27.510, Speaker A: So how many other nodes a particular node is connected to. Again, the theoretical minimum is order one. So it is possible to achieve even logan diameter with a fixed number of nodes. I will show you an example. So that's the theoretical minimum. And the acceptable maximum is basically something proportional to the size of the network. For a while, probably over a long time, that would be less and less acceptable.
00:10:27.510 - 00:11:40.842, Speaker A: And the problem, of course, with a large number of neighbors is that the housekeeping overhead, maintaining that network, will become, it will grow and it will become a sizable part of what the nodes do instead of performing their direct duties. Then another thing that you want is uniform centrality across all nodes. So what centrality is, centrality in a graph is defined as the number of shortest paths that go through one particular node or one particular edge. You can define edge centrality and node centrality as well. Actually, this property, centrality was introduced in applied research, which was interested in preventing sexually communicable diseases. And the question was, if we have a limited number of condoms, whom are we going to give them? So this sort of shows you what this centrality really means. So if you take out the most central nodes from a graph, the graph will fall apart.
00:11:40.842 - 00:12:55.542, Speaker A: The connectivity of the graph will be broken. So the centrality needs to be uniform in order for there not to be some vulnerable nodes. So for the cost of bringing down the network should be high, because if the centrality is not uniform, then there's a small subset of nodes that if you take out that subset of nodes, then your graph falls apart, which is bad both against random failures and even worse against a dedicated adversary, because all the adversary needs to do is to map out the network, calculate the centrality, and then dos the most central nodes. And of course, you also want to keep the housekeeping overhead low. So you want some network topology which is easily maintained. So I will show you a few examples of how these trade offs can play out. So, for example, we currently have a peer selection algorithm, which is that simple.
00:12:55.542 - 00:13:37.810, Speaker A: You connect to the nodes that you know, you ask them about other nodes and you connect to those without giving it too much consideration. Perhaps you stop after you reach a certain node limit. So these completely ad hoc networks, they go through a phase transition. In the beginning, they form an almost complete graph. Every node knows a sizable subset of the network, maybe even the majority of nodes. So it's almost complete. So the number of neighbors is in the order of the size of the network.
00:13:37.810 - 00:14:43.922, Speaker A: The diameter is more or less fixed. You can reach everybody in one or two hops. The problem is that in this phase, the housekeeping overhead is Ballooning, because when you are think about just pinging all the other nodes, you need to keep track of their addresses, you need to see which one is alive. So a lot of traffic on the wires is just pings. So the housekeeping overhead is actually the traffic generated by housekeeping is growing with the square of n until you transition to this other phase, when the number of nodes that one particular node knows, the neighboring nodes is relatively small compared to the size of the network, then what you get is what mathematicians call a scale free graph, where you have a wildly different distribution of degrees. Actually, they follow a power law. So it's a long tail distribution.
00:14:43.922 - 00:15:44.700, Speaker A: That's usually how natural social networks work. So if you look at, for example, whom people friend on Facebook, so you look at social networks like this, or you look at front to friend computer networks, or you look at, for example, the social graph of sexual relationships, then they are typically these scale free graphs. So in nature, these scale free graphs, they are very common. Their diameter statistically is pretty low. So these are this famous six degrees of separation. So it's actually smaller than log n, it's log n over log log n, but that just statistically, the other undesirable property of scale free graphs is that their centrality is not uniform at all. Typically, scale free graphs have a very small number of very central nodes, which is interesting.
00:15:44.700 - 00:16:44.350, Speaker A: This fact is widely used in all sorts of social engineering, from marketing to politics, that they're these influencer people, that if you find the right people to influence, you can spread information or disease or whatever very fast. Or when you want to bomb a railway network, then a few well placed bombs can bring an economy to a halt. So it's well studied property, and it's a well known property of scale free graphs. So basically, this is another argument against this kind of ad hoc infrastructure, that in addition to the large housekeeping costs, we will have centrality problems. The network will not be resilient. There will be some nodes which will have high centrality because of their high centrality. They will have a high load, a disproportionately high load.
00:16:44.350 - 00:17:45.940, Speaker A: Okay, yes, here we are. They will have a disproportionately high load, and the network will be vulnerable. And there's another problem which is not mentioned here, that, okay, we have a distance measure which follows the triangle inequality. But in an Atho graph like this, there's no guarantee whatsoever that if you go along the gradient like you always take the hop that brings you closest in one hop to your destination, then you will actually follow a shortest path. There's no guarantee for that at all. Actually, in practice, it's not that bad. So there is an upper bound that in the majority of cases, the number of hops will still be fairly low.
00:17:45.940 - 00:18:57.846, Speaker A: So it's not catastrophic, but it's definitely not optimal. And you can have rare but very painful searches. So I would not like to change the basic strategy of connecting to a network. So we can keep the pattern that you connect to one node, you ask about its neighbors, and then by some clever algorithm, you select to which ones to connect further. And actually, when somebody asks you about your neighbors, you can also be clever and not tell them everything. So by tweaking these two things, you can even stay compatible with the original peer finding algorithm, but be somewhat more clever and achieve some completely different topology. So here's another example.
00:18:57.846 - 00:19:43.394, Speaker A: These are the quasi hierarchies. So they are similar to hierarchies, but not completely. So this is an illustration. Of course, if you are doing it in a real world scenario, it will never be this nice and regular. But this is a good example of the kind of graph that you will achieve if you have a limited small number of neighbors. So this graph is, for example, three regular, it can grow indefinitely and it still will have a logarithmic diameter. So what it is is that there's a central node, it has three neighbors, these neighbors grow binary trees, and the leaves of those binary trees are connected.
00:19:43.394 - 00:20:37.926, Speaker A: So this is a three regular graph, logarithmic diameter, constant neighbor number. You can achieve this. The problem is with this is also that the centrality of the nodes is highly variable, but the housekeeping overhead, on the other hand, is really short. So just to tell you how these kinds of graphs are maintained, it's very similar how real armies maintain their chain of commands. So if a general is killed, the army does not collapse immediately. So all the soldiers have a rank. They always know that if two soldiers who have not previously met this subordination is immediately established and they have some site connections about where to connect in case some nodes fall out.
00:20:37.926 - 00:21:25.080, Speaker A: So it's doable. So you can build in a decentralized fashion by each node, only caring about its own surrounding. You can build graphs like this, but I think that they're still too vulnerable and they place too high a load on some central nodes. Unfortunately, if you keep the degree of the nodes low and you want to maintain a logarithmic diameter, you cannot avoid this. That's a mathematical result. So what I propose is, and what gab also proposes is taking a page from Kadamlia. Kadamlia is not optimal in the sense that it doesn't take.
00:21:25.080 - 00:22:02.686, Speaker A: So for a logarithmic number of neighbors, it has a diameter that is larger than necessary. And for the logarithmic diameter, it has a number of neighbors that is larger than necessary. So it doesn't take anything to the extreme, but both values are sort of acceptable. And for this, like, this is an example, it's a hypercube. Hypercubes are also like that. So cadmlia results in hypercube like topologies. So here, every node.
00:22:02.686 - 00:22:59.830, Speaker A: So there are 16 nodes here, and each one has four degrees. Cadmlia has a low housekeeping overhead. It has a perfectly uniform centrality. And I think what's most convincing is that it already operates in a highly hostile environment, because cademlia is used as the DHT for bittorrent, for the trackerless torrents, and there are many highly funded organizations trying to disrupt that network, and they don't generally succeed. So it looks like a good idea. So we would like to take many ideas and maybe quite a bit of code from Kadamlia. It has the notion of the routing table.
00:22:59.830 - 00:23:49.480, Speaker A: The routing table is basically how the node structures its neighbors. So it has short lists of live neighbors. The length of each list is maximized at some small number, which is typically between five and 20. So it's not really a large number. And for each bit of the address, they have at most one list. So the bits means that each of these lists correspond to nodes whose address is the same up to that bit. So the first list doesn't require any.
00:23:49.480 - 00:24:47.160, Speaker A: It differs even in the first bit and the last list, which is where it is almost always empty, of course, but the last list contains nodes which contains the node which differs in only one bit. Of course, it never happens in practice that even that list has something in it. So Cadmlia has a very peculiar distance measure. It's the XOR metric. So they take the XOr of the two addresses and treat it as a binary number. It's a good exercise to check that it's really a distance measure. When a node asks another node about the neighbors that they know, you don't tell them the entire routing table, you tell them only one list.
00:24:47.160 - 00:25:53.610, Speaker A: So for each lookup, for each lookup that another node makes, lookup request makes at you what you do, you try to place that lookup on your lists. So which list corresponds to that lookup, and you reveal only that list. You don't upload your entire routing table. And when you are updating your routing tables, because some new nodes come in, you learn about some new nodes. Then what you do is when a list gets full, then if the list is for longer matching prefixes, so there's some space in longer matching prefixes. So for example, you have a list for three matching bits, but you don't have a list for four matching bits. Then what you do is you split this list into two and you start a new list for the longer prefix.
00:25:53.610 - 00:26:47.150, Speaker A: Otherwise, if the list is full and the new node is on the far end, then what you do is you simply forget the node that is diversed by some criteria. What Cadmlia does is it regularly pings the nodes and from whichever it heard last, it will delete. We might do something similar, or we might have some other criteria by which to rank the nodes. It doesn't really matter all that much, but it provides some way to control the quality and the resilience of the network. So how do you join a network like this? You learn about one bootstrap node. You connect to it, you register with the bootstrap node. So basically the bootstrap node adds you to the list where you belong.
00:26:47.150 - 00:27:37.374, Speaker A: Then you do a self lookup. With the bootstrap node. You try to look up yourself. So you download that particular list in which you have been to which you have been placed. You download the entire list, and then you insert those nodes one by one into your routing table and handle it the way they should be handled. And then you generate a random address in the range which is one bit further than the bootstrap node, and you make a lookup for that address, and that also gives you some nodes. And this way you have joined the network and you have established yourself as an equally central node as everybody else.
00:27:37.374 - 00:28:44.398, Speaker A: So the point of this exercise is that when you join this network, it's not that you're going to be somewhere on the outskirts of the network, but you will establish yourself with deep enough connections so that you're just as central as any other node. So it provides a uniformity. And there are some big open questions about what we do. So first there's this thing that are we going to do this over UDP or TCP? Now, since all the packets that we are sending around, they are short, and since UDP is much easier to send around send through firewalls and nats and things like that, I'm actually leaning towards UDP. And that means that maybe this thing should have a separate layer with a separate network layer from the peer to peer protocol that has been presented two talks ago. Then there's the second question. These two are somewhat related.
00:28:44.398 - 00:30:05.822, Speaker A: So, nat tunneling, when you're tunneling through Nat, you either do it by routing your traffic through some third node, which is really bad, or you really try to burrow a hole through the nat firewall. You do that by spraying each other with udps with random source and destination ports, and rely on the birthday paradox on one of the requests being an answer to another request. And from that point on, the routers will pass that specific source port and that specific destination port right through the NaT firewall. But the problem is that in this case, the establishment of a connection is slow, so it's really not something that you want to change. So in this case, what Cadmlia does and what the bittorrent's implementation of it does is that it never routes data through nodes. It always gives you an address that if you're interested in this particular piece, here's an address, go ask that guy. But if we're doing nat tunneling, then this is an expensive and slow step.
00:30:05.822 - 00:30:36.520, Speaker A: So we might not want to do that. Maybe we want to pass around the information, and maybe we even need to be somewhat adaptable, like distinguish between nodes behind nat firewalls and other nodes which have a public ip address. Another good question is, what are we going to do with spam, because if we implement this directly, then anybody can force it to store forever information.
00:30:39.550 - 00:30:39.866, Speaker C: To.
00:30:39.888 - 00:31:11.694, Speaker A: Which it knows the hash. But whether this information is useful or not is anybody's guess. And this also leads us to the question of incentives, which really depends on what this thing is going to be used for. And there are many other open questions. So I think that at this point, we start the q a session, and maybe on Friday we should have a discussion about what to do.
00:31:11.732 - 00:31:30.700, Speaker C: Okay, so a little bit to elaborate about how I joined to network and what information the field that I joined should provide me. Like maybe the level of the centrality it has, like a general or.
00:31:31.710 - 00:31:59.298, Speaker A: No, no. In this case, when you're in Kademlia, there's no rank, everybody's equal. So what you do is you connect to one node that is already a member. That's how you bootstrap. Then you register with that node. So you give your address to that node, and that node puts it into the appropriate list where it belongs. Then it gives you back the entire list.
00:31:59.298 - 00:33:16.410, Speaker A: So you will have a list of addresses of valid nodes from the bootstrap node. You insert all those addresses into your own routing table. And then with this routing table, you do a lookup of a random address which differs from the. So you look at the prefix which you share with the bootstrap node, and you flip the bit that comes afterwards to the one that you have, but not the bootstrap node. And you fill up the rest of the bits with some random binary values and you make a lookup. Now how a lookup looks like with the lookup, you go to a node, to the nearest node that you can find in your routing table, and then you ask that next node to give you the corresponding list. You insert all those nodes into your routing table, and then you keep continuing until you find the nearest node.
00:33:16.410 - 00:33:30.570, Speaker A: And of course, if along the way you find the actual content, then you download that content. You don't continue, but with a random lookup, the chances of that happening are negligible.
00:33:30.650 - 00:33:38.820, Speaker C: So, visualization of Kadembla lookup, it's like a circle. Everybody stays in circle, right?
00:33:39.590 - 00:34:32.210, Speaker A: No, it's not a circle, it's a hypercube. So what you do when you're looking up a node is that a lookup is basically you always go one bit closer and you always go along the bit which has a highest, higher order bit. So it's always like, let's suppose this direction, the vertical direction, is the high order direction. So whenever you go from this node to this node, you always go along one dimension closer, but you always follow the same order of bit. That's how you do the lookup. And you're guaranteed to have a logarithmic number because with each hop the number of common bits increases at least by one. So it gives you a guarantee on the diameter.
00:34:32.210 - 00:34:35.720, Speaker A: Okay, next question.
00:34:38.810 - 00:34:42.150, Speaker C: What is the strategy against stamp?
00:34:44.490 - 00:35:25.254, Speaker A: Well, in case of BitTorrent, since it's mutable, so it's not the same as here, it just overrides the key and it forgets gracefully old keys. In case of the bitTorrent, the information is not really valuable, so they just throw away information that hasn't been queried for a long time. That's all they do. And it's sufficient for their purpose. And it might be sufficient for our purpose as well. I don't know, it depends on really what we are going to use it for. So what are we going to use it for?
00:35:25.412 - 00:35:31.670, Speaker B: Yeah, most of the life clients use it in order to query things like transaction receipts.
00:35:34.970 - 00:35:58.670, Speaker A: No, but you can even store the state in it. So if you have a full node, but you don't have the storage space for storing everything that the full node needs to store, it might dump things that don't fit into its storage, into this DHD. So it's kind of like a public utility.
00:36:00.930 - 00:36:04.610, Speaker C: Yeah, if the bootstrap dies.
00:36:07.270 - 00:36:36.506, Speaker A: Well, you need to find one. So for example, there are some botnets that also organize themselves into kadamblian light networks, and what they do is they just probe random IP addresses until they find. Well, or you download a recent list from a website and you go through it and the first node that you find is okay, so you need to find one node that is member of the network and then you're done.
00:36:36.608 - 00:36:45.310, Speaker B: Don't forget it's on the same network as ethereum whisper. So if you know an ethereum node, you'll eventually find a swim.
00:36:47.330 - 00:36:49.390, Speaker C: Remember, from past connections.
00:36:51.330 - 00:37:01.300, Speaker A: Yeah, of course you don't forget your routing table. So when you're switched on, then you renew your routing table, but you use the one that you had.
00:37:03.780 - 00:37:06.400, Speaker C: Second statue already has a bunch of nodes.
00:37:09.720 - 00:37:10.470, Speaker A: Yes.
00:37:10.840 - 00:37:15.590, Speaker B: How much greater latency, proportionally is.
00:37:17.400 - 00:37:17.716, Speaker A: A.
00:37:17.738 - 00:37:22.120, Speaker C: Hypertube network to a scale free network?
00:37:22.460 - 00:37:58.390, Speaker A: It really depends on how much information you store. So the latency in this setup really depends on how large your diameter is, how large your radius is. But once your radius has been exhausted, then it depends on the diameter. And actually Cadmlia is slower, like on a general scale free network, the diameter is log n over log log n, whereas here it's log n, so it's slightly slower. But the log log is not that big a deal.
00:38:02.190 - 00:38:03.770, Speaker C: Are you going to talk tomorrow?
00:38:05.150 - 00:38:10.666, Speaker A: No, because it's the same talk. I didn't realize that this talk was also me.
00:38:10.688 - 00:38:21.214, Speaker C: Can you elaborate? Because you mentioned lots of times before that mutable and non mutable DHT, very different.
00:38:21.332 - 00:38:57.302, Speaker A: Yes, they're different. So about this, the interesting thing is that you never need to revisit. You don't need to keep querying. Flooding the network with new information is not an issue. So here you can get away with. If something is asked of you that you don't know, then you find it and you store it for later reference. And how to flood the network with new information is not an issue here because it never gets overwritten.
00:38:57.302 - 00:39:32.706, Speaker A: It propagates slowly and it's okay. Basically any stupid tactic. For example, if you get some piece of information, you send it to the nearest two nodes that you can find. That's good enough of, because that will flood like it will go in the general direction where it needs to be. And it's okay for you. So you don't have to be very clever about how to make sure that new information propagates through the network. It's half of the code of Kadamlia.
00:39:32.706 - 00:39:37.080, Speaker A: You can safely leave that out. Yes.
00:39:40.030 - 00:39:54.010, Speaker C: In this team, could the entries expire and be removed when they expire or with regard to spam?
00:39:56.190 - 00:39:59.886, Speaker A: Good question. Because to keep it in there, you.
00:39:59.908 - 00:40:03.280, Speaker C: Have to refresh it or somebody has to refresh it for you.
00:40:06.310 - 00:40:24.150, Speaker A: Well, refreshing the spam costs, right? You need to query it continually. So do look up. So if you want to spam that way, it's probably doable. I don't know. It really depends on what we're going to use it for. How do you incentivize?
00:40:25.530 - 00:40:35.020, Speaker C: This is an open network. Basically it stores anything you give to it. It doesn't even have to split into. 4 can split it up. You can store anything in it.
00:40:36.910 - 00:40:39.242, Speaker A: Yes, but the question is to put.
00:40:39.296 - 00:40:44.186, Speaker C: Something in this network, then you can keep it alive. And I don't think it costs too much to keep it alive.
00:40:44.298 - 00:41:16.838, Speaker A: No, it doesn't. So basically what happens is shown here. So this is the relevant figure that if there's too much stuff and the notes cannot keep up, then there will be some blanks here. And then you need to decide what to throw out. Because if you throw out information, then these circles will grow again. So basically you need to decide what to throw out when you're full. I mean when you're really full, when things get really bad.
00:41:16.838 - 00:41:21.900, Speaker A: So when not only are you full, but your radius is too small.
00:41:23.950 - 00:41:25.962, Speaker C: Can you detect that this is happening?
00:41:26.096 - 00:41:55.810, Speaker A: Yeah, you can detect because again, because the key value pair is not arbitrary. So it's a hash. So it's a uniform randomness. It's uniformly randomly distributed. So from that you can be sure that the density of information in your neighborhood is the same as the density everywhere else. And from that you can make very accurate assumptions of how much information is stored in the whole network.
00:41:56.170 - 00:41:59.110, Speaker C: But that still doesn't tell you whether there's.
00:42:04.660 - 00:42:32.920, Speaker A: No, you can make educated guesses about how bad the situation is. So that's another thing, just referring back to your question that because of that, because you can be sure that the keys are distributed uniformly and it's immutable, you can actually, from a local point of view of a node, has a fairly good estimate of how full the whole network is. Yes.
00:42:32.990 - 00:42:36.584, Speaker B: How does this study, so will it.
00:42:36.622 - 00:42:38.480, Speaker C: First be implemented using just a torn.
00:42:38.500 - 00:42:40.510, Speaker B: Diary and then switch over to this?
00:42:41.440 - 00:43:03.136, Speaker A: I think so. So I think that it will not be in the next proof of concept, it will not be there, but in proof of concept number eight it might, right. That's where it belongs. That's entirely feasible. So I think the target for this is concept eight. Yes.
00:43:03.238 - 00:43:22.250, Speaker C: Just a use case if you want a static website. But if I always stolen, they will always be there for other ones to download. Right? That's how I would do this. I'm the server of my website store this stuff and even if no one's using it, it's always there. It's kind of a use case for this.
00:43:23.100 - 00:43:31.152, Speaker A: Yeah, you can use static content there. Actually it would be like, yeah, sure, but that's also kind of spam.
00:43:31.316 - 00:43:39.550, Speaker C: Kind of, but I stored for me at least so they can drop it out from time to time, but it's still tinable for someone else you're seeing.
00:43:41.700 - 00:44:25.788, Speaker A: It's possible. It is. Actually I'm thinking about adding a HTTP interface, just for fun, that when you enter a hash in the URL, then it will collect the corresponding paces and push out the entire content, but only for the local node. So no, it's only accessible from one twenty seven zero zero one. It's not accessible from the outside. So one idea for spam prevention is just use proof work and keep the highest before stuff in the table and target kind of like not overflowing. And that way blocks will always stay in there because they always have the.
00:44:25.794 - 00:44:34.610, Speaker B: Proof work, of course, blocks and transaction receipts and so on will always be hosted by archive nodes because they will store the data anyway because they use it.
00:44:36.900 - 00:44:50.390, Speaker A: Yeah, well, if the proof of work is such that they need to look it up. So if a Hashimoto style, in hashimoto style proof of work, you need to.
00:44:52.440 - 00:45:08.600, Speaker B: Yeah, there's a bit of weird. So there's full nodes which keep this stuff. For the last end blocks, there's super light nodes that don't keep anything really. And then there's archive nodes that keep everything. And the idea is that the foundation runs a few archive nodes and they do some mining.
00:45:08.680 - 00:45:57.060, Speaker A: But actually with this, you don't even need archive nodes because with this in place, you have a common archive, and as long as you keep randomly checking the past, it will stay up to date and it will be fairly distributed. And this kind of proof of work can be actually a contract. So you can actually offer ether in exchange for checking the thing, for making spot checks. So it can be done on top of ethereum. That here's a contract that if you maintain, if you sweep around the archives, then you're going to get paid and that's it. You don't even need full archive nodes.
00:46:00.710 - 00:46:08.402, Speaker C: What's the behavior if you have like two concurrent requests for writing the same.
00:46:08.456 - 00:46:14.900, Speaker A: Hash, but you will write the same thing there? That's the point that here the value.
00:46:16.390 - 00:46:18.442, Speaker C: What is this mutable task?
00:46:18.526 - 00:46:51.190, Speaker A: If it's mutable, it's a lot harder. It's not designed to be mutable. We might, but it will be a thick layer on top. That's a lot more work than an immutable one. And actually, for a mutable one, I would probably just use bitter and scadamlia because it's already there and it's mutable, and they have solved all the problems.

00:00:07.050 - 00:01:04.000, Speaker A: Okay, we are live. Welcome, everyone to Acde one six two. Okay, so today, I guess, to start, we've commissioned an impact analysis by DDOB around self destructor movel. So they'll be here to give us an overview of the analysis. And there's already been some conversations in the last day or so about it and some potential issues with the proposal of EIP 67 80 and then some counterpoints to those issues so we can have all of that conversation. Then there's a bunch of stuff around EIP four four four that's in the works, so it makes sense to cover all of those. And after that, I think thinking about how Cancun shapes up to be.
00:01:04.000 - 00:01:46.990, Speaker A: So whether there are some things we want to add or remove from CFI. There's already some comments about that in the chat. And then Dano has put together a proposal to just align the upcodes that are used across all of the proposed eips for both Cancun and the next forks, and then a couple more updates on some other eips. So hopefully we get through all of this in 90 minutes. But yeah, to kick us off. Sorry, Neville, do you want to give us a rundown of your impact analysis of self destruct removal and I'll post a link in the chat?
00:01:47.730 - 00:01:50.750, Speaker B: Sure, yeah. Can I share my screen as.
00:01:50.900 - 00:01:52.080, Speaker A: Yes, yes, please.
00:01:52.550 - 00:02:22.540, Speaker B: Okay, cool. Yeah, so thanks for hosting. Yeah. So I'm Neville Gregg from DDOB. We were commissioned to do a study for the team foundation regarding the removal of the self destruct opcode, or the chain and semantics of that opcode. The team was basically me, Leah Satiris, Sivis Lagovartos. All three of us are on the call, so feel free to ask us questions.
00:02:22.540 - 00:03:33.054, Speaker B: All right, so the scope of the study was basically to determine the impact of change in semantics of self destruct. And self destruct has recently been used, or throughout its lifetime to either save the transfer eat or to perform upgrades ever since create two came about. But there are also some question marks, things like, is it actually being used to burn ERC 20 tokens, things like that. So, wanted to find the affected projects, wanted to find the impacts. And all of these things are colored by the fact that some projects have not been recently used or they don't have a high balance, they're not part of a known contract. So the impact has to be considered against all of these factors. And the other thing is that we have two different proposals and we want to see which one or help determine which one to select, if any at all.
00:03:33.054 - 00:04:35.640, Speaker B: Right, out of these two. So, just to give a little bit of an overview of how self destruct currently works for those who are external, there's a bit of nuances here, because self destruct pops one element from the stack that's an address, and what it does is it sends all the eth in the current contract to the beneficiary address. But unlike call, it does not actually create a call frame to execute the beneficiaries code. So it can be used in a way that even for smart contracts that block the receive function, that block the receive function, then subtract is still going to work. It also clears the runtime bytecode of the current address, resets the nons to zero, and resets all the storage bars to zero. It does not issue a gas refund. So that's changed, I think, one and a half or a couple of years ago.
00:04:35.640 - 00:05:48.378, Speaker B: So how is this going to change in EIP 47 58? So very simply, right, it's going to be renamed send all, it's only going to send the eat to the beneficiary address, but it's not going to clear the runtime bytecode, it's not going to reset the nons, and it's not going to reset the storage bars. So that's a simple proposal there. And the way I remember which one is simple, which one is more complicated, is by the first number. So the simple one starts with a four, the more complicated one starts with a six. So in EIP 67 80, the semantics of cell destruct are essentially the same as they are now, except that there's a condition that if the address, and by address, I mean specifically the opcode address, right, is created in the same transaction, then you do the same thing as in self destruct. You clear the runtime bytecode, reset, the nons resets all stored vars. Otherwise these things will not work, they will not happen.
00:05:48.378 - 00:06:44.906, Speaker B: Right. Okay, so now that we know which each one of these proposals, what each one of these does, here's a little bit of a summary of what we found in the study. First of all, some of these things are subjective. So these are protocols which we think are affected. Some of them are, we estimated the impact too low because they're more likely to be a false positive. So we have to clarify, for instance, in the case of seller over here, because we've seen some weird behavior if the self destruct instruction is going to change, but essentially the impact is quite minimal, especially in the more complicated proposal.
00:06:45.018 - 00:06:45.294, Speaker A: Right?
00:06:45.332 - 00:07:44.026, Speaker B: So, 67 80. So yeah, I'll go through these one by one, just give a little bit of a summary of what we saw there. So, in the case of Axler network, Axler creates contracts and then it destroys the contract in order to do some safe eat transfers. Now, we think that it is upgradable, so impact is high, but it is upgradable, so that can be fixed. There is no impact in the case of the axler network, if the second EIP is chosen, that's 67, 80. So it can remain operational without any upgrades. With the second EIP, in the case of sorbet, similar to gelato, it's not upgradable, but that's part of the smart contract that uses self destruct.
00:07:44.026 - 00:08:12.330, Speaker B: But it really isn't used much. Right? In the case of gelato, it's used in conjunction with Pine finance. Again. So pine finance, you know, we think it's affected as well. Now, I've skipped seller. In the case of seller, that one's interesting, because it seems to replay messages from another chain. But the messages ought to be unique.
00:08:12.330 - 00:08:48.038, Speaker B: And the uniqueness of this message is used as part of the salt. When creating a smart contract using create two. And then those smart contracts are subsequently destroyed. So we think that in this case, if the messages are indeed unique, then that's not going to be affected, but it's going to take a while obviously, to go through the entire seller protocol. It's very complicated. We'd have to look at the way it interfaces with other chains as well. But that's what we think at this point.
00:08:48.038 - 00:09:49.258, Speaker B: We'll try to confirm with the developers chain hop actually works in a very similar way to seller. The part that has this issue, JPEGD is affected and then thousand ether homepage is also affected as well, in theory. But we haven't seen an instance in the past where if we had to replay these sequences of transaction, we would find the same effect. But it is impacted by this. Okay, so note that all of these things are subjective in the case of estimated impact. But from the point of view of finding potential protocols that are affected, that is not subjective. We conducted this by looking at past during transactions, by doing in some cases, static analysis of the contracts bytecode as well.
00:09:49.258 - 00:10:36.280, Speaker B: So we did cover a little bit mev bots as well, even though there weren't sources available. Now, if we look at this from a quantitative point of view, right, so the usage patterns. So we looked at blocks between block 15,000,017.23 million. We measured the number of times, for instance, that create or create two is used quite a few times, as you can see over here, much dominates. There's an order of magnitude fewer self destructs. But interestingly, most of these self destructs are used in conjunction with short lived smart contracts creations, as you can see.
00:10:36.280 - 00:11:35.450, Speaker B: Now potentially this can be impacted by EAP 47 58 because there's a short lived smart contract, it's not going to be removed at the end of the transaction and so someone else can interact with it. But then this is even more worrying. So metamorphic patterns where a contract is created at an address and then it's destroyed in the same transaction. And then in another transaction, it could be like weeks or months. After that the same smart contract is recreated and then this one is destroyed. Now there's been 22,000 instances of this. Now this pattern will not be impacted by EAP 67 80, but it will be outlawed by this other proposal.
00:11:35.450 - 00:12:28.474, Speaker B: And actually Axler network, it's responsible for a few of these. And then finally, this is what we were kind of like mostly worried about so long lived metamorphic patterns where long lived referred to the fact that a contract is destroyed in one transaction and then recreated as another transaction. When I say short lived, it means that a contract is created and destroyed within the same transaction. In this case, as you can see, it's like two orders of magnitude, almost two orders of magnitude less than in the previous case. Like the number of times that this has happened. Just looking at this quantitatively, it seems.
00:12:28.512 - 00:12:29.100, Speaker A: Like.
00:12:31.810 - 00:13:19.482, Speaker B: Especially if EIP 67 80 is selected, most of these usage patterns will be valid and this will not be. But then we'll see. Kind of like most of these 735 upgrades are not actually done in mainstream protocols. They are done in unknown or mev bots or things like that. Okay, so let me give you an example here of an example of a short lived metamorphic contract. So a contract which is created and destroyed at an address and then created and destroyed at another one. I'll share these slides with you guys.
00:13:19.482 - 00:14:10.070, Speaker B: So you can see, but basically these slides are just a summary of the full document. So you can see here destruct here. So this contract is created and destroyed. And in the next transaction, same contract is created and destroyed. So these two are separate transactions. But as you can see, like the same smart contract is created and destroyed. So this is just an example in axlear network.
00:14:10.070 - 00:15:00.262, Speaker B: Yeah, we've also looked at some protocols where this thing is done or could potentially be done according to how the smart contract code operates. But for instance, in this case, this is a protocol revest. We can look at sample transaction. But there's no need. Basically what happens is that revest creates a smart contract and then I think it transfers an NFT to that when you withdraw. And it uses actually within the create two sold the NFT ID. So again, this is just an example.
00:15:00.262 - 00:16:06.700, Speaker B: If you want to see more of these examples, look at the full report. Let's wait until this loads up. But essentially what we think is because of. So over here, this clone deterministic call over here is going to pass the, you know, some entropy from the NFT ID. And then at clone deterministic down the line, it creates a new smart contract and it's going to use the NFT ID as part of the salt. And we think that since the NFT ID is monotonically increasing, there's not going to be clashes in the smart contracts that are created. So even though the smart contract cannot be destroyed, if the proposal goes true, there are always going to be new smart contracts that are created because of that.
00:16:06.700 - 00:17:02.078, Speaker B: So it takes quite a while, I mean, this study was conducted over two weeks. It takes quite a while to go through all of these protocols and verify. But all we need to do, essentially, now that we have this discussion going on is just confirm that the ones that we thought were false positive are indeed false positive. Okay? So one of the other things that we try to do is to use static program analysis to find possible behaviors that we haven't seen on the blockchain so far, but they may potentially happen. For instance, someone deposits tokens to a smart contract or to some address. And for some reason with the proposal, they cannot be retrieved. Right.
00:17:02.078 - 00:17:49.674, Speaker B: These tokens. So someone asked a question on one of the forums that is used to discuss these proposals. So what we did for this is, first of all, we found all contract factories. So for this thing, we performed static analysis to find contract factories. Because what contract factories do is that they create a smart contract. So they use something like create two, but they actually, within the init code, they would have certain patterns there. Okay, then out of these, so we find the ones that do create two.
00:17:49.674 - 00:18:39.290, Speaker B: And then we applied static analysis. And static analysis in a nutshell, I mean, this is not the real code. This is a pseudocode. But in a nutshell, what it did is if it finds a self destruct in a contract that was created by these factories and it doesn't have, for instance, an ERC transfer, an arbitrary call like contracts call and allows you to pass in any data or there's no delegate call, then potentially you can have funds stuck in this smart contract after the EIP goes through. So we looked at many of these examples. I mean, many of these were MEV bots. Of course, MeV bots don't have verified smart contracts, sorry, verified sources.
00:18:39.290 - 00:19:49.090, Speaker B: So I had to use our decompiler. It takes a while to go through these implementations and there's trial and error here, so it's not going to be an exact science. But we thought that all of them were false positives for this particular pattern. So we haven't found any examples of this. Okay, so what was surprising is that there's been a lot of discussion about create two and self destruct being used to perform upgrades, but in mainstream protocols we haven't actually found this anywhere. But if you look at the fine print in some of the libraries that are used to do these metamorphic contract upgrades, the UX is a problem when you do metamorphic contract upgrades using subdestruct and create two, because you cannot do this atomically, so you have to do this in two separate transactions. Now imagine doing a governance proposal where you propose in one transaction you do something, and then second one you have to recreate the smart contract.
00:19:49.090 - 00:20:28.430, Speaker B: And then in the meantime people might go in and use the protocol with the smart contract not recreated. So that can cause all sorts of issues. And then the other thing is that the state setup, a mainstream protocol would have quite a bit of state that needs to be recreated when you do a self destruct and create two. So that's not used much. It's mainly used in MEV bots. And obviously there's arguments to be made as to why, for instance, Mevbots would use that, because it's more efficient to do it that way. You don't have proxies.
00:20:28.430 - 00:21:09.420, Speaker B: But maybe we'll hear about this in the rest of the meeting. So in summary, we think the impact is moderate, and especially so with EIP 67. Eightyp 67 80 is not going to affect mainstream protocols. Metamorphic contract upgrades are low. One thing that we found is that even though there's a lot of discussion about self destruct being deprecated, people are still using it equally. So irrespective of the uses of the Ethereum blockchain, again, but very rarely. Right.
00:21:09.420 - 00:21:34.260, Speaker B: And also throughout the study there was a coincidence that there was some evidence of self destruct being harmful as well. That concludes just the summary here, and I think we'll be discussing a few things throughout the call, and if you have any questions, just ask me or my colleagues on the call.
00:21:34.650 - 00:22:18.978, Speaker A: Thank you, thanks a lot for the presentation. That was very good, I guess before. William. Oh, thanks, William. I see you have your hand up. Before we go into the set code stuff, I just want to ask, does anyone, I guess, on the client teams or others, have questions about the presentation or the report in general? And then after that, we can go about next steps for the specific proposals. But just any questions, thoughts, comments on the report or presentation? Okay.
00:22:18.978 - 00:22:53.900, Speaker A: And then if not, I guess where we were at prior to this report was that we included 67 80, which is basically the second proposal mentioned in the presentation, and allows self destruct if it's within the same transaction as create call. And so, William, you raised a couple cases where this could break things. Do you want to take a minute to walk through those? And, yeah, we can take it from there.
00:22:54.990 - 00:23:34.182, Speaker C: So, I'm a user of the create to upgrade pattern. I have a prepared statement. So the report skims over meV, but doesn't speculate why this upgrade pattern is common among mev bots who wrote their contracts in assembly. The reason is broader than MeV and applies to normal dex trading. Indeed, any actor trying to get competitive transactions included with any urgency must participate in priority gas auctions. Off chain systems are being built to allow anyone to participate in these auctions. Such auctions are denominated in gas used, so any upgrade mechanism with any gas overhead whatsoever cannot be used competitively.
00:23:34.182 - 00:24:13.634, Speaker C: That leaves code replacement as the only viable mechanism for traders. Suppose I want to be able to upgrade my code in order to trade on the newest protocol. It is much simpler now when I'm able to replace the code. Without this ability, I would need to redeploy to a new account instead. Every NFT, every token balance, every token protocol approval, every staking deposit, every registration, indeed, my entire presence on the chain has to move over to this new account. Accounts are identities, and moving all your possessions to another account is painfully expensive. If your account is a smart contract, having a secure way to upgrade, it can avoid such a migration.
00:24:13.634 - 00:25:01.254, Speaker C: Indeed, this is the purpose of several of the mechanisms identified in the report. Such systems are inventing ways to secure the upgrade process for the masses. Selfdestruct removal destroys their work. Setcode inclusion renews it. We can preserve the ability of accounts to change their code by including set code in the same fork systems anticipating the fork can prepare by including setcode. If set code is not included in the same fork, we cannot securely anticipate what the semantics will be. It is critical for adoption of smart contract wallets that we preserve code mutability aside, I've had some discussion in the topic channel on discord, and it seems that it would be a significant improvement for static analysis if we also disabled set code during delegate call.
00:25:01.254 - 00:25:21.020, Speaker C: And this would indeed limit the scope and risk and make it much easier to identify potentially mutable contracts because you would just be looking for the opcode. Another note is that there's. I forgot that. Anyway, I'm going to read your responses now.
00:25:22.590 - 00:26:00.550, Speaker A: Thanks. And then. Okay, we had it all happen in the past. Joav put like a set of security concerns he had about said code in the discord. I just shared him here. He unfortunately couldn't make the call. And then I think what it boiled down to in the discord right before I hopped on this call was that basically, if we want to introduce set code as a mitigation for some issues caused by 67 80, there are some security concerns with that.
00:26:00.550 - 00:26:18.430, Speaker A: The worst of them have to do with using set code within a delegate call. And maybe we could enable setcode without enabling it in delegate call, and that would resolve some of the issues. Maris, go ahead.
00:26:18.500 - 00:26:32.820, Speaker D: Yeah, I have a quick question. Can we add set code later on? Is it possible to add this opcode later on?
00:26:35.670 - 00:26:42.614, Speaker A: Assuming we do remove self destruct, right? That's what you're asking? Yes.
00:26:42.812 - 00:27:09.470, Speaker C: So in order to allow contracts that are currently upgrading with self destruct to remain upgradable through the upgrade, it would be better that we don't have downtime in which code immutability is not possible. And also it's important to solidify that opcode so that at the time of the upgrade, the contracts that are frozen are able to be prepared for the set code upgrade. So it's better that they happen in the same hardboard.
00:27:10.290 - 00:27:14.880, Speaker D: Is it technically impossible for them to be separated out?
00:27:17.350 - 00:27:19.380, Speaker A: What do you mean by separated out?
00:27:22.390 - 00:27:25.890, Speaker D: Is it possible for them to be in separate hard forks?
00:27:26.550 - 00:27:36.114, Speaker A: Well, I guess if I understood correctly, this means yes, but the contracts that are affected are basically bricked between those hard forks.
00:27:36.162 - 00:28:16.210, Speaker D: Right of it. And I don't really think we should include this opcode now. And I also don't really think we should include this opcode in the future, but we can have a debate about that in order to unstuck or make it cheaper for mev bots to extract mev. I don't think. I think this opcode has a huge amount of security implications and we shouldn't.
00:28:21.030 - 00:28:43.486, Speaker A: Guillaume? Yeah, I mean, basically a lot of it. Marius already said yes. I think it's a huge security issue, but my question still would be, if any of the arguments that were just given in the statement were true, or.
00:28:43.508 - 00:28:47.006, Speaker D: At least were significant enough to make.
00:28:47.028 - 00:28:49.120, Speaker E: Us consider including set code.
00:28:51.970 - 00:29:05.940, Speaker A: Would simply not removing self destruct be the superior solution? Does set code offers something that not removing self destruct would not solve in a better way?
00:29:08.150 - 00:29:45.866, Speaker C: Yes. So the weakness of the self destruct upgrade pattern is that there's a downtime in the upgrade itself because the self destruct takes place at the end of the transaction rather than during it. So you must self destruct in one transaction, and then in another transaction, recreate the contract. Setcode would allow us to upgrade safely and securely in place. If you all want more time to analyze set code, please just postpone self destruct.
00:29:46.058 - 00:29:50.910, Speaker A: Thank you. Thanks, Ben.
00:29:53.010 - 00:30:32.160, Speaker D: If set code and self destruct depreciation happened, wouldn't set code need to be in a fork before self destruct? Because otherwise, you couldn't upgrade the contracts to use set code without putting invalid op codes, because if self destruct happened first, then you can no longer upgrade the contracts and set code didn't exist beforehand, so you can't upgrade it to use set code?
00:30:34.290 - 00:30:40.350, Speaker C: Yes. So I think it can be in the same hard fork, because contracts can contain invalid opcodes.
00:30:43.500 - 00:30:54.910, Speaker A: Okay, so people would basically deploy the contract with an invalid opcode prior to the fork, and then the opcode would become valid after the fork, is that right?
00:30:57.300 - 00:31:01.010, Speaker D: Yeah. But they would be dead contracts during that time.
00:31:02.260 - 00:31:58.240, Speaker A: Yes. Yeah. I guess I'd be curious to hear generally from client teams, given all of this. How do people feel about 67 80 set code? Do we want to? Basically, I think that the first question is, we agreed to have 67 Ali in, pending the results of the impact analysis and making sure that not too many things would break our teams comfortable leaving it in, regardless of what we do with set code and analyzing that separately, or do we feel like the remaining inclusion of 67 Ali should be dependent on set code?
00:32:14.770 - 00:32:24.210, Speaker B: I think we should leave 67 80 in Cancun and analyze set code separately.
00:32:25.990 - 00:32:26.740, Speaker A: Okay.
00:32:31.040 - 00:32:41.100, Speaker D: I feel the same way. We should have 6780 as soon as possible and think about set code more thoroughly.
00:32:45.380 - 00:32:55.860, Speaker C: Could we perhaps finalize the opcode reserved for set code such that bricked smart contracts might eventually be unbricked in a future upgrade?
00:32:58.760 - 00:33:41.744, Speaker A: Yeah, we have a whole section about opcodes later on. Daniels put a full list, so I assume we can at least quote, unquote, reserve one for set. Yeah, and we can discuss that as part of. Yeah. Okay, so Aragon gets on board with leaving self destruct as anyone else, I guess. Does anyone disagree with that. Does anyone disagree that we leave the EIP 67 80 in? We keep discussing set code.
00:33:41.744 - 00:34:29.440, Speaker A: It may or may not be included in this upgrade. And clearly just in the last like 12 hours, there was a ton of discussion. So there's still a lot of back and forth, but does that make sense to people? Okay, so let's do that. Yeah. So no actual changes to the fork inclusion list, and, yeah, I'll make sure to share. Well, I guess if anyone wants to read the full impact analysis for self destruct, it's linked in the agenda until people can see it from there. Okay, next up, EIP 4844.
00:34:29.440 - 00:34:56.490, Speaker A: There's a ton of prs, some devnet updates, some potential changes for the next devnet, and then some RLP and SSD changes that might affect our currently CFI aps. So I guess to start off light client you had pr 70 62 that adds data gas used to the block header. Do you want to briefly discuss this?
00:34:58.940 - 00:35:12.030, Speaker F: Yeah, I just wanted to see if there was any interest from other El devs. I'm not sure if Peter is on the call, but while he was implementing some things related to sync, he just kind of noticed that.
00:35:14.000 - 00:35:14.520, Speaker B: It was a.
00:35:14.530 - 00:36:08.880, Speaker F: Little bit different interaction with the sync code than he was expecting. And after digging into it, we kind of realized that the excess data gas and the base feed are not as similar as we initially would have anticipated them to be. So ultimately, the issue is that for excess data gas, that number is going to be used in the block, the descendant block. And so the value that you need to compute the cost of the data transactions is actually the excess data gas from the parent header. And for base fee, it's slightly different. The base fee in the header is actually the base fee that's used during the execution of transactions. And so whenever you do your header validation, that's when you are checking that the base fee is computed correctly from the header.
00:36:08.880 - 00:37:10.020, Speaker F: This is kind of just a proposal. I was sort of sketching out what it would look like to bring those two things in line so that they both are representing the value for the currently executing block. And so that's kind of what that PR is. They both do essentially the same thing. I think ultimately the question is just, do we care enough about having these similarities to try and make this sort of minor change, or are we okay with the status quo? Personally, it's just like one of these things. It's another one of these things where if we have the formatting slightly different, it increases the overall code complexity of clients. Like we saw as Peter was implementing the syncing code, whereas if we had a similar mechanism already and we just reused that mechanism in mostly the same way, it would have kept things a bit simpler.
00:37:10.020 - 00:37:25.370, Speaker F: So that's my thoughts. Probably slightly favor the data gas used approach in the PR, but I'm curious what other people think about it. Oh, Peter's here too.
00:37:25.900 - 00:38:11.264, Speaker G: Yeah. So perhaps just a slight thing, maybe just an expansion to what Matt said that I think the complexity comes from the fact that previously the fee is defined by the base fee. And so essentially we have two header fields. One of them tell us how much gas we consumed and based on that we can validate the base fees from header to header and the base fee itself. If I want to run the transaction I only need to look at the current block, base fee and with the block transactions we kind of merged these. How much we use and how much does the next one cost into a single field. And because it is a single field, it makes basically everywhere where previously.
00:38:11.264 - 00:38:49.170, Speaker G: So previously when we validated the header chain, we just looked at the header fields. We didn't care about the block content at all. And then when we ran the block content then we just needed to look at the current header. And since this field somewhat got convoluted, it somehow means that I need to be able to both look at. So when I'm running the blocks I somehow need to both look at the current header and the parent header. Similarly when downloading via snapsync. Because even if I'm not running the block or executing block, I still want to verify the block body.
00:38:49.170 - 00:39:44.240, Speaker G: And the thing is that it doesn't really matter how we interpret access data gas, whether it's for pre execution or cushion. The thing is that if I convolute these two fields together I will have this extra complexity that all validation code will all of a sudden need both the parent header and the current header. Yeah. Whether this is something worth one solution is to go with the current status quo and make the code around this structure a bit more complicated. The other solution is to split out the two fields so that it follows a similar pattern to base fee and gas used. And if you have the two fields, then the code around will become a bit simpler. Yeah, it's not that complicated.
00:39:44.240 - 00:39:50.280, Speaker G: It was just something that was surprising to me, that it's a new mechanism, something that was kind of unexpected.
00:39:52.700 - 00:39:54.840, Speaker A: Thanks Andrew.
00:39:56.220 - 00:40:29.270, Speaker B: Yeah, I think in Aragon we have separate stages for headers and bodies. So I would be very much in favor of making the change so that we don't need a parent's body to verify a block. I'm totally in favor because just to double check. So with this change, we only need parents header, not parents body, correct?
00:40:30.760 - 00:41:02.060, Speaker G: No, actually. So what the current thing requires, if you want to verify the current block's body, you need the parent header. So that's the weird thing that the current transactions require, the parent header. That's what the weirdness is. With the proposed change you could verify the headers completely separately. And then when you want to run or execute a block, you only need to look at the current header. You don't need to look at the parent header at all.
00:41:02.060 - 00:41:10.450, Speaker G: So that's how currently everything else works. But it requires this field being split out. So that's the cost.
00:41:12.260 - 00:41:13.250, Speaker B: I see.
00:41:16.290 - 00:42:21.134, Speaker G: So for example, for us the complexity was that when we are snap syncing, we essentially also have this two phased thing where we download the header separately. And then for every header, if the transaction hash is not empty, meaning that there are transactions, then we download the body block body and just fill the header. And up until now we just said that, okay, I want to fill this header, I downloaded the body contents and then I just match it. Does this transaction list match what the header wants? And if yes, great. And now with the blob transactions, what I need to do is that after I'm downloading the list of transactions, what I need to do is that, okay, but now does the access data gas also get computed correctly? For which I think I need the parents access data gas, it gets a bit funky. It's doable. So the way we did it is that from now on our downloader instead of a download task is a single header.
00:42:21.134 - 00:43:15.720, Speaker G: It's actually a header and it's parent. So I mean it's not specifically complex. But for example, if you interrupt synchronization and resume it, then you will of a sudden need to dig up the parent of the first header. And just these little tiny weirdnesses all over the place where up until now you just had a single header and now you just need two and it makes things wonky. But again, the question is, is it worth it to add an extra integer to the header field or is it too much? And I don't want to make this decision really because the current design isn't that painful. So if people say that it's not really worth it to stir up the wasp nest for it, then I can live with the current, whatever its design is.
00:43:24.760 - 00:43:48.110, Speaker F: Yeah, I mean I think this one simple thing is really not that big a deal, but it's more this mindset. And I'm worried what will happen if every fork, there's that one small thing that doesn't really align nicely, and we could have just fixed it. If we have that mindset, then, like five or ten years, how many special edge cases are we really going to have? I think a lot.
00:43:52.470 - 00:43:59.800, Speaker A: Right. I guess given that, given Aragon's comment, does anyone think we should not do this change?
00:44:02.570 - 00:44:20.140, Speaker H: So Dankrod had a point about sort of refactoring the execution gas in a way that might make the current thing with four make more sense. I don't understand what he's envisioning well enough to really defend it, but I wonder if anyone else has.
00:44:20.510 - 00:44:22.960, Speaker F: Is it written somewhere? I don't think I've seen it.
00:44:24.450 - 00:44:25.054, Speaker D: Yeah.
00:44:25.172 - 00:44:48.398, Speaker H: Well, so I guess I'm also a little confused. There's maybe two things here. One of them is just changing how this is computed and moving to a nicer sort of math to better approximate exponentials separately. It sounds like this change that we're bringing up right now is unrelated to that, and it's just more about how do we actually validate these things. Is that correct?
00:44:48.584 - 00:45:15.230, Speaker F: Yeah, I think it doesn't have anything to do with the exponentials, but more like, what is the order of validation? Where do you get the data for validating? And I don't think what Dankrad is looking at doing involves getting rid of the gas used field, which is kind of what allows us to make the base fee and the header, the base fee for that header's block. And that's kind of what we're missing for excess data gas.
00:45:20.100 - 00:45:31.830, Speaker H: Yeah. So maybe if there was pushback, it was a miscommunication. I'm not sure, but yeah. Does anyone think this is going to push back for four timelines too much?
00:45:40.170 - 00:45:41.030, Speaker A: Andrew?
00:45:41.530 - 00:46:08.080, Speaker B: Yeah, I just wanted to say because I think it doesn't. I misunderstood it in the beginning because I thought it eliminates the need to get. So it's not relevant to parent bodies. So I need more time to look at the proposal. So I don't have a position on it at the moment.
00:46:08.930 - 00:46:20.050, Speaker A: Does it make sense? We have the 4844 call on Monday. Does it make sense to give people the next two, three days to look over it and make a decision on the Ford four four call Monday?
00:46:21.610 - 00:46:23.014, Speaker H: Sounds good to me.
00:46:23.212 - 00:46:42.648, Speaker A: And if people can't make that call, just leave your comments on the pr directly and we can consider those on the call. Okay. Next up, another pr, please.
00:46:42.734 - 00:48:02.510, Speaker G: Sorry, can I just add one more thing? Georgia actually asked how this whole thing relates, for example, to light clients. If you want to just verify the headers, but don't have the bodies, because obviously you don't download the bodies. And the short answer is that a light client will not be able to verify the access data gas in its current form. So the same way that a light client cannot verify the gas used field, because you need to run the transactions the same way a light cannot verify the access data, the part of it which tracks how many blobs were included. And this is one of those weaknesses, because even the light client can verify the base fee, but it won't be able to verify the blob fee because of this dual nature of the access data gas. So for lie clients, you would just need to take it for granted that that field is correct. But yeah, again with lie clients.
00:48:08.470 - 00:48:08.834, Speaker A: If.
00:48:08.872 - 00:48:37.020, Speaker G: We assume that the consensus network is on a semi good chain, then a lot of validations could be omitted. I mean, you could even debate that. If the consensus client tells you that this is the header, why even bother validating anything? Just roll with it again. So it's not really end of the world. It's just a quirky thing that we have to decide which quirk we want to live with.
00:48:40.990 - 00:49:10.040, Speaker A: Got it. Thanks. Okay, next up, this is like an old pr that recently has a movement. So refactoring the validity conditions for blocks. So I believe. Was this a thing where the blocks didn't actually check whether the blob cap was exceeded and only the individual transactions did.
00:49:12.410 - 00:49:36.570, Speaker H: Yeah. So Ansgar is working on this. I don't think he can make the call. So I will answer any questions on this pr and, yeah, that's basically it. Some things kind of got dropped. And I think the main change at this point is exactly what you said. So there's no way currently in four four to specify that there's only so many blobs per block.
00:49:36.570 - 00:49:53.460, Speaker H: If you look at the current spec, I could send maybe only a few blobs per transaction, but I could send as many transactions as I can pay for. And then now there's like 30 megabytes of blobs. So it'd be nice to have this defined at the El. And that's what this change does.
00:49:55.910 - 00:50:21.240, Speaker A: Got it. Anyone opposed to this? Like, it seems pretty straightforward. Then I guess we could probably.
00:50:22.330 - 00:50:55.754, Speaker G: Sorry, I was trying to find the button. I think it was Dan yesterday who said that this field is already validated by the consensus client. My two cent. I already wrote it on the channel too. That in my opinion. It would be nice to have it validated by the execution client too, simply because, well, one, it is simpler, and I mean safer. And the other is that I think it would be useful to have the validation somewhat self contained.
00:50:55.754 - 00:51:16.950, Speaker G: So basically have everything. So that if the execution. If I just give a batch of blocks to the execution client, then it can do as much validation as possible. Maybe it cannot do chain selection, but it should be able to verify everything else. And this extra check is needed to forbid blocks containing hundreds of blobs.
00:51:20.650 - 00:51:43.840, Speaker H: Yeah, I think we all agree. And so, yeah, it seems to make sense to me to keep this in line with execution gas, where it's like, yeah, there's a limit at the El, and that's sort of the ground truth. There is a cap at the Cl, but that's more a networking thing at this point. And again, as we've discussed, you could imagine those kind of varying independently subject to each layer. Be uncomfortable with that.
00:51:47.910 - 00:52:14.810, Speaker A: Okay, so I guess we can go ahead and merge this whatever and scar is ready. Okay, next up. Okay, so, devnets. So Barnabas, you wanted to give a quick update on Devnet five. And then, Gajinder, you had three prs related to Devnet six. So let's do that, Barnabas.
00:52:15.310 - 00:52:49.442, Speaker D: Yeah, sure. To recap it, in the past two weeks, we had a long period of non finalization on Devnet five. And it ended up draining 900 validators accounts to force them to exit. And we managed to get into a final estate again with lighthouse and Nethermind. And at that point, we had 100 validators running on a single node. And everyone was able to catch back to that using checkpoint sync. And I decided to make some new deposits.
00:52:49.442 - 00:53:32.020, Speaker D: So we can still see if any of the validators go offline now. So I made 1000 deposits yesterday to it, and these are being processed right now. I noticed something that everyone get ejected about at balance of 31.7, which is a bit strange, because in the config, I have set it to being ejected at 31. So I'm not quite sure why that happened. Here, you can see the config for this. And in the interrupt channel, we had some discussion about it.
00:53:32.020 - 00:53:35.940, Speaker D: And what's up is that.
00:53:39.430 - 00:54:07.900, Speaker A: Ben says hysteresis. Can you expand on that? If my microphone is working, yes. Yeah. It would be based on the effective balance. And when the node's balance drops below 31.75 e, the effective balance drops to 31 e. So if you set the ejection balance to 31, then when the actual balance reaches below 31.75,
00:54:07.900 - 00:54:12.700, Speaker A: then you'll trigger the ejection, which sounds like what you're seeing.
00:54:13.870 - 00:54:28.642, Speaker D: Okay, yeah, that makes sense. I have no idea. Anyway, right now we are finalizing and we have 500 on the chain. Right now it's looking quite nice.
00:54:28.696 - 00:54:29.300, Speaker A: Now.
00:54:31.830 - 00:55:10.526, Speaker D: We also have a beacon chain expert running with. No, another thing is Devnet six specs are being collected right now. And I'm open for including anything or not including anything else. We have a link for that too. There's quite some prs that I would like to include in Devnet six. And this would still be a 4844 specific Devnet. And then hopefully Devnet seven be a Bencon devnet, which would combine other prs that are not related to eight.
00:55:10.548 - 00:55:11.022, Speaker A: Four. Four.
00:55:11.076 - 00:55:17.600, Speaker D: Also saying that Devnet seven would come in a.
00:55:20.690 - 00:55:21.054, Speaker A: First.
00:55:21.092 - 00:55:22.970, Speaker D: We should focus on Devnet six launch.
00:55:23.050 - 00:55:57.440, Speaker A: Yeah, that sounds good. And I see. Okay, so I'm looking at your docs now and I think some of the prs. Yeah, basically a lot of the red prs are the same ones Gajinder had up. And I think it makes sense to probably take most of the call on Monday to go over this list that you have. But Gajinder, do you want to discuss the three that you brought up on the agenda for today? So first of all was 70 38.
00:56:00.690 - 00:56:44.998, Speaker B: Yeah, hi, Tim. Okay, so what 70 38 does is it basically refactors a little bit how the network payload is built. So it's now first the transaction payload, then blobs, then commitments, then proofs. Earlier it was transaction payload, then commitments, then blobs and proofs. So it feels nice this way. And the second thing, it also adds clarification that the blobs are flat otherwise. There was this interpretation that we also had discussion in the discord that each blob itself is a list of field elements.
00:56:44.998 - 00:57:06.770, Speaker B: So this pr also flattens out the blobs and in a big indian way. And then it just clean up some references and add some validation conditions that were missing.
00:57:10.390 - 00:57:47.640, Speaker A: Okay, yeah, I see there's been a couple of comments on this, but any other thoughts from anyone on the call? Okay, next up. So this is following our discussion last time, following our discussion from last time about the precompile inputs to be encoded as big indian. Any thoughts?
00:57:52.500 - 00:57:58.980, Speaker B: I think in the consensus specs, the KZG big indian change has already been merged.
00:57:59.400 - 00:58:02.950, Speaker D: Okay, this is quite natural then.
00:58:06.180 - 00:58:33.100, Speaker A: Sorry, someone else was trying to say something. Okay, yeah. Assuming there's no more issues, we can probably merge that as well. And then this one was to the execution APIs to basically add data gas, use data gas price to receipts in four, four, four transactions.
00:58:39.330 - 00:58:43.330, Speaker B: It just has those fields in the RPC response.
00:58:47.270 - 01:00:00.330, Speaker A: And I guess anyone have strong opinions about this? Okay, so it probably makes sense to include it. And I think my client had a comment there saying that we want to wait until we effectively have the full set of changes for Cancun so that we can merge them all at once. But that seems to be the only concern. And Roberto saying that some Yale clients already have prototypes for this. Okay, so I think that's all we had in terms of prs for today. And yeah, let's go over Barnaves's list for Devneck six in more depth on Monday's call, as well as the pr that Matt opened, which I'm now forgetting what that one was about scrolling up. Sorry, I have way too many tabs open here.
01:00:00.330 - 01:00:19.040, Speaker A: Okay. Yeah, the data gas used to the header. So let's discuss that more thoroughly on Monday as well. Cool. Okay. And then last thing for 4844. So we agreed to move it to RLP.
01:00:19.040 - 01:01:11.254, Speaker A: That said, we had basically included the SSZ optional EIP in Cancun. And we'd also CFI 6493, the SSZ transaction signature scheme. There were some comments that we should remove those. Yeah, there were some comments that we should remove those given we've moved four four four to RLP instead. Yeah. Does anyone think we should keep any of the SSZ eips, either CFI or included in Cancun? Okay, no objections. So, okay, I'll do this after the call.
01:01:11.254 - 01:01:32.344, Speaker A: I'll take 64 75 out of the included list. And I'll remove 64 93 from the CFI list. Okay. Anything else on 4844? Okay then next up. Yes, please go ahead.
01:01:32.382 - 01:02:07.040, Speaker D: Small question. Should we again, we have empty two field in block TX. As far as I remember, we didn't want that because of SSD uncertainty in terms of encoding and so on. But for now we can have it like mt two in RLP. Do we need still to prohibit mt two hild?
01:02:15.250 - 01:02:27.060, Speaker A: I'm sorry, I'm not sure I quite understood. Is this about the contract creation? Yes. So banning contract creation from block transactions, right?
01:02:28.230 - 01:02:30.450, Speaker D: Yeah. What is the reason?
01:02:30.520 - 01:02:31.300, Speaker A: Could you.
01:02:33.190 - 01:02:40.470, Speaker D: Some words. Someone who has great motivation to ban this ability.
01:02:42.090 - 01:03:57.390, Speaker F: I can take a step. So the original reason was partially motivated by the fact that this thing was not well specified in SSD. But I think that there's still a good reason to do it. And that's that we have these two opcodes for creating contracts. And there's not really any particular use case that I'm aware of where we have to have the ability to create a contract via an EOA and through the hard forks we've seen that this is one of the least frustrating things to test because for every kind of change to the transaction and often for new opcodes new functionality of the EVM we have to test in the context of both just normal execution and then always in the context of a knit code both in the context of with create opcodes and in the context of the create transaction. So I would like to start moving away from using having create transactions in general and simply rely on just the create functionality within the EVM.
01:04:04.790 - 01:04:06.100, Speaker D: That makes you sense.
01:04:12.950 - 01:04:44.356, Speaker A: Okay, anything else on for if not okay so Dano, you put together this document because we're proposing a bunch of opcodes for Cancun and Prague and it's all starting to be a mess. And you have a proposal for how we can make it a bit cleaner. I'm not sure if you're speaking but you're okay now.
01:04:44.378 - 01:04:44.992, Speaker I: I'm unmuted.
01:04:45.056 - 01:04:47.110, Speaker A: Yes, you're unmuted now. And we see your.
01:04:49.000 - 01:05:31.552, Speaker I: Is like Tim said there was a lot of opcodes coming in and a lot of space being occupied and moved around. Part of it, I'd have to say was the early responsibility of the EOF because they were occupying three key opcodes, the last of the five series. So here's a quick overview of the opcode blocks we currently have right now. Five is what was basically filling up having the storage memory control flow. And that's where the initial EOF control flow opcodes went in. So the proposal starts with a couple of philosophies. One of them is to move all EOF only opcodes that only make sense in the UF opcode containers to a separate block, the e block.
01:05:31.552 - 01:05:55.576, Speaker I: And that moves the 500s out of the five x's out of there. And then move everything back to the block where it makes the most sense. So that would then move t load and t store back in the five c and 5d probably m copy. If it passes into five e this does not affect blob hash or beacon root. Beacon root might be out. That's a late breaking change overnight. And then some proposed changes in the f series.
01:05:55.576 - 01:06:25.236, Speaker I: F series is filling up. There's another proposal for another series of call tos later on in this meeting. So reserve space for those, reserve space for pay. And I guess we need a reserve space for set code as mentioned earlier in the meeting. But the purpose of this is to get a more sensible packing and grouping of the opcodes and to fill in the space left by Eof moving into its own block. So this is what's proposed. T store and t load are currently in and everything else blob hash is in.
01:06:25.236 - 01:06:30.890, Speaker I: Everything else is speculative to be added at some point, if it added at all.
01:06:33.500 - 01:06:38.360, Speaker A: Thank you. Anyone have thoughts, questions, comments?
01:06:46.240 - 01:06:48.524, Speaker C: Can we assign set code in this.
01:06:48.562 - 01:06:49.260, Speaker A: Meeting.
01:06:51.360 - 01:07:09.330, Speaker I: Again until it ships? It could move away, but my thought is it should be in the f series rather than the four series. And I think the last f series available is FC. So we could put that in as the current location for it.
01:07:11.400 - 01:07:13.780, Speaker A: Okay. Alex?
01:07:17.160 - 01:07:38.030, Speaker E: Yeah. Regarding the UF side, we have been discussing these upcodes in the last two or three UF breakout calls. I think we're going to do this in any case for mean. There's no question about that. We were really in favor of moving it from the US side.
01:07:40.080 - 01:08:07.060, Speaker A: Sweet. Anything? There was a bit of discussion of putting m copy at zero x four f, which is like slightly before the zero x five series. But I don't know if that really makes so much sense. It was just an idea.
01:08:07.210 - 01:08:44.550, Speaker I: So the reason I wouldn't want it in four f because those are all focused on block data ones stuff that might come in from the environment. What's in your block headers? The only reason that push zero got put into five f is because of some fun math relating to the push series operations. Otherwise I would have put it somewhere else rather than in five f. So putting m copy at four f I don't think makes quite the same sense. I think a better home with it would be at think five e is where it would be at.
01:08:48.760 - 01:09:17.388, Speaker A: Yeah. Okay, cool. Is this something we should try and put somewhere better than the hackmd under your handle? Yeah, we have something similar for transaction types somewhere execution.
01:09:17.484 - 01:09:45.820, Speaker I: So that's exactly what I was thinking. I wasn't sure if the right place for this was for the execution specs or is it informative EIP. So to get the discussion rolling I just did my own hackmd, put it into the link and then we can move it in an app and if it's kept there, it should be kept a live document. As proposals become non viable they should be removed from the list. And as they become viable maybe some speculative opcode placings. But again, shipping opcodes get priority over discussed opcodes.
01:09:47.360 - 01:09:55.570, Speaker A: Yeah, I think are the transaction types in the execution specs, is that where we.
01:09:56.100 - 01:10:17.930, Speaker F: Yeah, they're in a folder called listsignature types and there's a readme in there and that also keeps track of tentative signature types. So this is this pretty similar thing. I don't think it would go in the folder. Lists maybe, but yeah, it makes sense in execution specs in general.
01:10:18.780 - 01:10:21.450, Speaker A: Yeah, I kind of like lists because.
01:10:22.460 - 01:10:24.644, Speaker F: I guess it is a list of opcodes.
01:10:24.772 - 01:10:37.470, Speaker A: And the thing is it's a list of semi reserved opcodes. Right. It's not the spec. Like once they get merged they become the spec. Right, right. But this is like a tentative list.
01:10:39.200 - 01:10:50.140, Speaker F: Yeah, I mean I think it fits well within other stuff like having CFI eips and just having an idea of proposed changes for forks. This is just a different way of looking at the proposed changes for forks.
01:10:50.220 - 01:10:50.850, Speaker A: Yeah.
01:10:53.140 - 01:11:07.880, Speaker I: Okay, I'll make up a pr for execution specs that includes all this and I'll try and follow the signature types. But are there any objections if I were to open up prs against t store to move the opcodes for Cancun?
01:11:14.880 - 01:11:55.300, Speaker A: All right, I'll do that today too. Cool. Yeah, thank you. This is a really great doc. Okay, a couple more things. So on the last call we briefly discussed trying to make some decisions on this call about any other Eips we might want to include in Cancun. I guess 4788 has had some updates since the last discussion.
01:11:55.300 - 01:12:24.880, Speaker A: And then I believe there's a new proposal for revamped call instructions and there's a whole bunch of other proposed eips. So I guess quickly maybe. Alex Stokes, you want to give a quick overview of the changes to four seven eight. Then Alex Barragasi can give a quick overview of the call Eips and then we can hear from clients about what they feel might make sense to include in Cancun.
01:12:27.560 - 01:13:04.430, Speaker H: Sure. So this kind of continues from AC DC. Last week, the way that four seven eight was before the current update was that it would add a new opcode, something like beacon route, and that would basically call out to some storage in the execution state where these blockers would be. This is like kind of merging two different mechanisms with some sort of pre compile like thing and an opcode like thing. So we kind of decided it would just be cleaner to bite this bullet on a staple. Pre compile. And so that's what the current update does.
01:13:04.430 - 01:13:56.530, Speaker H: Yeah, basically it's just a pre compile like we're all familiar with. It happens to have access to the execution state and that's where this data is stored. This is a bit different from say like how block hash works today, where rather than read the execution state, there's this history buffer that just happens to also be there. And the idea is that in an ideal world, the state transition function for Ethereum would be a pure function of the state and not rely on this other little history thing. And this has implications for data's clients and things like, well, at least people who have engaged with us so far. I think generally, like the stateful pre compile direction, Marius has an implementation in geth, I think for both things, but definitely the staple pre compile. And yeah, I think the change has been merged already.
01:13:56.530 - 01:14:47.600, Speaker H: So yeah, I think that's not too controversial. The other big thing was, and probably the last question on this was just discussing how we actually want to key these routes. So we assume then we have the stateful pre compile and now we basically need some input data to figure out, okay, at this slot or maybe this timestamp, what was the actual beacon route. Yeah. So from here those are probably the two big contenders, is like either using the El timestamp, which is sort of a proxy for slots, or introducing some way to map into the Cl slots while we're writing this thing into the El state and doing that. So the catch there is that we don't want to violate the barriers of abstraction between the El and Cl. So it's a little tricky.
01:14:47.600 - 01:15:21.210, Speaker H: Yeah, I guess maybe I'll just pause there. Does anyone have any questions so far? Okay, the one thing from here then is maybe if I can just ask Marius directly because he had some feedback via the prototype. Yeah, I can grab it. Is Marius on the call?
01:15:21.360 - 01:16:52.600, Speaker D: Yes, I'm here. So the prototype is very prototypey and it has both the stateful pre compile and the opcode implemented. In the beginning it was specified as an opcode, but I think basically the opcode, the idea is that this data is going to be in the state because otherwise we would have a separate storage storage segment that nodes would need to maintain, which would complicate the state transition function. Basically the state transition function would then be the state, the transactions, the header chain for the last 128 headers for the block hash opcode, plus this additional storage field storage segment that keeps the beacon routes. And so what we decided on is to move this, what Alex proposed was to move this into the state. It feels kind of weird to put something from outside into the state, but I think the best, it needs some getting used to. But in the end I think it's kind of fine.
01:16:52.600 - 01:17:56.778, Speaker D: And the. So why we decided against the prototype or why I am against not the prototype the opcode is that this opcode would read storage slots from a specific address. But that would mean we have this kind of address that has some storage slots that is not really a pre compile. And so that it would introduce a new paradigm. So we have to introduce a new paradigm somehow. And so I think the best way to do it is to just add a pre compile that returns this data. And now the only open question for me is how are we going to key this data? Basically?
01:17:56.864 - 01:18:13.070, Speaker H: Yeah. So in the prototype I think you just wrote the timestamp from the header, which at least to me is like half of the problem. So the problem with this is that if there's skipped slots, it's very unclear to the caller how to find the actual next route.
01:18:16.390 - 01:18:20.098, Speaker D: Um, why?
01:18:20.184 - 01:18:58.160, Speaker H: Because there would be gaps, right. So like basically you're saying, you know, timestamp, let's say t zero, I write the root, let's say there's like four missed slots and then now there's some timestamp much greater than just 12 seconds. And then if I want to find the block root for the next thing, it's just like. Because the way that it's written is I would read back basically zero as the route and then I would not really know what to do. I would need to jump forward some amount that I just really don't know and then have to search through the contract, basically.
01:19:03.640 - 01:19:13.560, Speaker D: Yeah. I'm not really sure how this would be used by contracts.
01:19:15.180 - 01:19:49.620, Speaker H: Yeah, that's a good question. So one example would be I have a slot and I guess where I'm coming from is I don't know if it's missed or not. I just have some slot because I know there are 64 bits and I can just pick one out of that typespace. So I have some slot and then I want to know what the root is. And that would be the API I would like. The thing that you were kind of suggesting is more like I as a caller also need to know kind of ahead of time that there was already a block there, which might be an okay relaxation.
01:19:51.800 - 01:20:18.510, Speaker D: Or we could even turn it around and say that it's keyed by beacon route and the value is the timestamp. So the caller could say, I have this beacon route. What is the timestamp for it if it's only about needing to know that a specific beacon route was there at some point.
01:20:21.220 - 01:20:34.180, Speaker H: Right. So yeah, let's zoom out a bit just to respect everyone's time here. Has anyone else looked at this and or feel strongly about including this in Cancun?
01:20:38.730 - 01:20:49.370, Speaker D: Oh, I don't feel strongly about including it in Cancun, by the way. I think it's nice and it should be included, but I'm not sure if we should include it in Cancun.
01:20:52.430 - 01:21:40.380, Speaker H: Okay. Does anyone else have any input? Because I think we can resolve this key question one way or another, and then from there, just a question of do we want to also include it in Cancun. It would help a lot of different applications that people want to use. Like for example, in the chat, Georgia has called out all sorts of things around accessing beacon state and execution layer. And the other thing is this does kind of tee up other things in future forks, like El initiated exits. So there's ways in which this tightens up the staking model that are really valuable, and this change kind of lays the groundwork for that. So in that sense, I think the sooner the better, just because it unboxes other stuff we want to do.
01:21:49.040 - 01:22:09.460, Speaker A: And I guess, yeah, maybe if no one has strong opinions on this, do client teams have strong opinions on if they want to include anything else at all or not for now? And if there are things that are not for seven, eight. Eight that they want to include.
01:22:15.850 - 01:22:23.270, Speaker B: We would like to include 5920 pay opcode. It's simple usability improvement.
01:22:28.040 - 01:22:36.100, Speaker A: Okay, anyone else have thoughts, proposals?
01:22:42.780 - 01:22:54.670, Speaker H: I mean, it might be helpful just to hear beyond what we currently have, which is what 4844 t store and one of the self destruct things, do we feel like there's room for another eip at all?
01:23:00.290 - 01:23:47.226, Speaker A: Could we discuss M copy and pay? Okay, 27 as well, which is the BLS recovery. Okay, so I guess we have four minutes. Yeah, maybe if we can do, like, if anyone has thoughts, we can do m copy pay. And then, Alex, if you want to do the calls off codes. But, yeah, let's start with M copy. Charles, do you have an update on it, or do you just want to get the feeling from people? There's no update on it. I brought it up a couple of calls ago, and I think you said you wanted to give everybody time to review it, and I think people have had time to review and think about it.
01:23:47.226 - 01:24:17.170, Speaker A: So I guess maybe we should discuss if there's any reservations. I think, you know, along with t load and t store. It's too complicated, which my personal feeling is. I don't know about that. Know, they're affecting completely different separate regions of the EVM. But if anybody else has similar or other concerns, I think we should discuss those, Dano.
01:24:18.310 - 01:24:35.594, Speaker I: So M copy is relatively easy. It's kind of like the return data copies. There's a lot of well worn testing path on that. So I want to hear Mary's opinion. But for pay, I think we need to discuss it in context of the new call two series. And as to why pay is needed. If it's just to make things cheaper, I think call two will handle it.
01:24:35.594 - 01:24:41.134, Speaker I: But I don't think we have time on this call to discuss the pros and cons of pay versus call two.
01:24:41.332 - 01:24:56.450, Speaker A: Pay is not just for guests. There's a number of high profile reentrancy attacks involving sending ether that would be easily prevented if people had a way to transfer ether without transferring an execution context.
01:25:02.130 - 01:25:54.800, Speaker D: So I think the pay up code kind of enables. I think it's kind of good. It's something that we should do, but it warrants a whole new, like, we really need to look at the implications of it. Basically, it enables a new way of a contract touching another one. This is usually where most of the bugs are. I personally don't think we have enough time in Cancun for testing this, with all its implications. It has on the other things.
01:26:00.580 - 01:26:22.260, Speaker C: William, regarding the payoff code, we already know that contracts can receive ether in other contexts, such as from mining new blocks and from self destruct. So the payoff code shouldn't introduce any new security considerations, because anything that it allows is already allowed.
01:26:25.880 - 01:26:50.220, Speaker D: It's not about security considerations on the smart contracts. It's more about how is it implemented. And basically, we need to test this opcode with every combination of everything ever. And this kind of makes it very complex.
01:26:53.540 - 01:27:04.560, Speaker A: Okay. And we're already at time. Alex Bergassi, do you want to give a quick overview of your eips, just so people have the context?
01:27:09.390 - 01:27:41.480, Speaker E: Yeah. So it is called revamped call instructions. And it was pushed into the IP repo only today. But the work has been. And the number is 76 to nine. But the work on this has actually started in January during ghetto vice, where the requirement for UF was brought up to also try to eliminate gas observability. And we designed the replacement call instructions at the time with that in mind.
01:27:41.480 - 01:28:38.182, Speaker E: But then maybe like three UF breakout calls ago, we realized that these instructions are actually not dependent on UF. And they could be just introduced in the current EVM. And there are two benefits to doing so. One, if you read the specification, it actually simplifies a number of rules regarding gas. And there's a number of cases where it would be actually much cheaper and better to use these new kind of call instructions instead of the current ones. So existing legacy contracts who choose to do so would benefit. And the second reason why it would be beneficial is if this would be introduced in a different hard fork than UF, then the UF changes would be much smaller because the only change there would be to reject the current call instructions.
01:28:38.182 - 01:29:33.370, Speaker E: And these new proposed call instructions would be already there. And then what these instructions actually do, basically there is the gas observability, which is one big push we wanted to get rid of. So here we remove the gas limit input and we just rely on the 63 64 rule. We also changed the way the stipend works. It is much more simplified. There's no output buffer address because return data copy and return data size can be used instead of that. There has been a number of discussions with solidity how it actually uses the call instructions, and some discussions with Wiper.
01:29:33.370 - 01:30:40.180, Speaker E: And then the last changes, the return value, it actually returns more. It returns success, revert and failure. And back when the revert feature was introduced, there was a plan to add that status code to the calls. But it couldn't have been done at that time in the legacy call instructions because contracts were depending on the behavior, and introducing that would have been a breaking change. I guess I don't really have time to go through everything, but there's one more comment I wanted to make. So there's this version of the EIP, which is in draft mode, but as we went through it, we realized that there would be another option as well, which would mean that these call instructions, they would check whether the target is an actual contract. So it would do an excode size check and the call would fail if it's not a contract on the other side.
01:30:40.180 - 01:31:21.790, Speaker E: Doing so would simplify the rules even further because these call instructions would only be usable to interact with contracts. What this would mean is that something like a transfer or pay instruction, a separate transfer or pay instruction would be needed in order to establish value transfer to aoas, or non executing transfers to code accounts. I think that's in short, and ideally something like this would be included in Cancun, and then UF would be much more simplified for a fork afterwards.
01:31:27.090 - 01:32:41.810, Speaker A: Thank you. Okay, we're already quite past time. I don't know if people have comments on this specifically. If not, I guess what I'd suggest is, clearly it seems like we're probably not in a spot to make the final decisions about smaller eips a day, and we're not even in a spot where 67, 80 and 44 four are fully implemented in clients. So I would suggest, I don't know if we want to cfi them, but it seems like m copy pay these call upcodes as well as the existing BLS precompile and 4788 eips are sort of the ones we're considering. So should we move those three other ones so like 5920-5656 and then the call one to CFI and sort of restrict the discussion at those and we can see in the next couple of weeks how things progress. Does anyone object that.
01:32:43.620 - 01:32:49.764, Speaker H: That sounds fine? I don't think we should add more. And if anything, we should probably bias towards just freezing the current set, right?
01:32:49.802 - 01:33:13.470, Speaker A: Yeah. So that's what I'm saying is we freeze the current set with those things. Everything else is de facto sort of excluded. Obviously, if there's some last minute issue, we can always change things, but that gives us like three eips currently in the fork and we'd be up to, I believe, five CFI ones because we have three now. Adding three and removing one.
01:33:15.760 - 01:33:16.764, Speaker H: Right. And four.
01:33:16.802 - 01:33:17.004, Speaker B: Four.
01:33:17.042 - 01:33:20.200, Speaker H: Four is a big one. Just so we're all aware.
01:33:20.360 - 01:33:39.110, Speaker A: Yes. Okay. We will let them know by client. Sweet. Let's wrap up here. We're already over time. Appreciate everyone sticking around and talk to you all on the next one of these.
01:33:40.760 - 01:33:41.956, Speaker F: Thanks, Tim.
01:33:42.138 - 01:33:43.670, Speaker D: Bye. Thank you.
01:33:46.280 - 01:33:48.820, Speaker B: Thank you. Bye.

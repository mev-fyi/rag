00:04:06.660 - 00:04:42.300, Speaker A: Okay, welcome to ACDC 114. This is issue 830 in the PM repo. If you're following along on the agenda. Cool. We we'll go over a bunch of Daneb stuff. We have a placeholder for the estar upgrade. Does that have a name? Was it decided? When I was gone, I saw there was a name that seemed to be potentially decided upon.
00:04:42.300 - 00:05:03.240, Speaker A: That's a question. All of y'all were on that call and I wasn't. Okay. Yeah, we went with Electra. Just no vote taken. It was just decreed. Great.
00:05:03.240 - 00:05:28.394, Speaker A: As long as it wasn't me. Decreeing was great. Electra. Okay, so we have a placeholder for Electra. I have some comments and we'll get there and then a handful of kind of spec updates and presentations. So we'll get into it on Daneb. Just some space for a general update.
00:05:28.394 - 00:05:34.110, Speaker A: DevOps testing. Anything people want to share with respect to progress?
00:05:40.200 - 00:06:28.810, Speaker B: Yeah, we had a spoiler shadow fork last week. We loomed the validator set a little bit so that we'd have some spending eth since withdrawals are enabled now and used that spending eth to spam it with blobs. Didn't really find anything useful on the network, so yesterday we tore it down. But other than that, we've just been updating tooling, et cetera, to make it a bit easier to test for Devnet eight. And I think Barnabas has posted a rough timeline of when we'd like devnets eight related things to happen on the interrupt channel. So hopefully by late next week, worst case, early week after, we should have Devnet eight up and running.
00:06:31.420 - 00:06:55.730, Speaker A: Right? And showay had a comment on the consensus spec release is likely Monday, which is one we need to figure out an item in here, but there's also some renamings that are going into there. Cool. Any other general updates for.
00:06:59.560 - 00:07:29.180, Speaker C: The folk choice test format? Have a new pr here. Thanks POTUS and Mikhail for their previous reviews. The current proposal is simpler than the previous one, so hopefully it will get included to the next release and phonekind to test. And if you have some feedback, please comment.
00:07:29.920 - 00:07:30.670, Speaker D: Thanks.
00:07:32.000 - 00:07:36.880, Speaker A: Meaning the release on Monday or the nebulous release after Monday.
00:07:38.340 - 00:07:42.370, Speaker C: Hope it will be on Monday one.
00:07:44.420 - 00:07:45.410, Speaker A: Got it.
00:07:46.500 - 00:07:49.890, Speaker C: Only three more test cases or review.
00:08:00.430 - 00:09:09.596, Speaker A: Okay, any other general comments that are not on the NAb agenda? Okay, I think there's been a lot of discussion about this over the past week. Essentially testing we are, as we transition into full featured test nets with what we expect to be relatively stable features, data structures, et cetera. It's time to begin to integrate additional testing around this piece of software. So I'm curious, is Alex folks on the call? Yeah. So maybe do you have an update on kind of where we're at both in terms of. I guess there's two things. One is the minimal amount of software and stubs, such that contest layer clients can do testing in these new types and contexts, and then more fully featured, such that people on the other side of the party can test their setups.
00:09:09.596 - 00:09:10.930, Speaker A: The builders in real life.
00:09:11.620 - 00:09:12.588, Speaker D: Sure. Yeah.
00:09:12.694 - 00:09:56.268, Speaker E: So Mario has, I believe it's essentially like hive testing for mocking the builder API. I don't know. I haven't looked yet. So I'm not sure if they fully support the Denab specs, but it should be pretty straightforward to do if they don't. Perry's been working on more hype testing to actually run at least like the flashbot software, which would be amazing. I've been helping him some with. So generally things are moving along, I don't think the updates to the builder specs that, for example, flashbots would need in their relay, I think even web boost right now aren't merged, but that works very much underway.
00:09:56.268 - 00:10:06.900, Speaker E: So should all come together in time. But, yeah, this is something we should focus a lot more on over the next month or so as things stabilize.
00:10:10.050 - 00:10:37.266, Speaker A: Yeah. Cool. I think the main reason to get on the agenda is it's kind of that time to transition into having this type of testing. So just primarily a signal. But thank you for the update and any questions or further comments on this one. And we can certainly continue to discuss it in subsequent calls. Tam, you're unmuted.
00:10:37.266 - 00:10:45.814, Speaker A: Did you mean to say something? Oh, no, sorry. Accidentally unmuted myself. Oh.
00:10:45.852 - 00:11:04.350, Speaker E: I may be jumping the gun into the next topic, but I would say the sooner we can actually freeze the spec, the better, because, for example, a lot of the flashpod stuff is just going to wait until the thrash is settled. So that would unblock sort of finalizing network with the builders and relays.
00:11:14.460 - 00:11:45.456, Speaker A: Okay. Other than we are kind of entering into boost testing time. Any other comments or questions? Okay, cool. Thank you, Stokes. Thank you. Others that are putting some effort into that. Shaoi, you had a pr open with some naming and consistency between the EIP and the consistency specs.
00:11:45.456 - 00:11:47.030, Speaker A: Do you want to go over that real quick?
00:11:47.980 - 00:12:37.030, Speaker C: Yeah. So it's still just an issue here because we didn't decide which place we should change. So one is about in Cl spec, it called version hash, version KZG. And the EIP has a different name and another one is the custom type description for blob. They also have different definition. Please see the issue ticket there. So my preference is updating the EIP and there are some El client devs here.
00:12:37.030 - 00:13:46.986, Speaker C: I don't know if does anyone have some strong opinion? So by the way, this is not a blocker for the definite eight because this two naming can be changed without the stake. I mean, it's not a consensus logic so it's fine. So just post sharing here and I hope it will be resolved very soon and we can finally freeze the Dennis fakes. Any suggestions? Yeah, if no, then I will try to open a pr on the EIP side on Monday and we can keep discussing there.
00:13:47.168 - 00:14:20.746, Speaker A: Thanks. Yeah cool. So if you have comments, jump in on this issue. I think a pr being open and circulated for discussion before the execution layer call would be a good way to keep it moving. Thanks. Okay cool. Next up we have the pr from Gogender that we thought we might be able to get some consensus on early in the week, but we're not able to.
00:14:20.746 - 00:15:25.070, Speaker A: We do have a number of comments since we did discuss this last Thursday. A lot of them are in a negative light that we had not previously seen in the calls. I really think that we should make a decision on this today and be done with it again for context, the parent beacon route is obviously committed to in the beacon block. It is not independently in the execution payload, the data structure on the consensus layer, but obviously all of the fields that the execution layer needs are committed to within the beacon block, so you can kind of reconstruct it from the piecemeal components. The execution payload plus this additional field which is passed into the engine API as of today, it works. There was definitely some discussion before we made the decision one way or the other. Gujinder brought it up that beyond just kind of aesthetic reasons, it's a bit annoying with debugging.
00:15:25.070 - 00:16:34.970, Speaker A: We've since reopened the conversation. We've since seen Enrico light, client Terrence, Mikael and Julio Echo that. They don't really want the data duplication in this pattern. We should be able to just utilize the fields as they come and stokes in the chat says mio we should leave it alone. Are there strong opinions one way or the other that want to be voiced beyond kind of the distillation of the thread that I just gave? I think at this point, given this is what people are working on, and given some of the integrity and counterarguments brought up in the thread that the default is, we're going to do nothing here but there are ways to echo otherwise.
00:16:35.390 - 00:16:42.590, Speaker D: Yeah, I'm curious, what is the reason to add this field actually to the consensus based data structures?
00:16:45.010 - 00:17:22.220, Speaker A: The arguments presented were that having the execution payload as kind of a self contained thing from what is on the consensus layer, being able to map that directly to the execution layer allows for kind of this one to one mapping such that when you're debugging, when you're grabbing things to maybe check hashes or whatever, it's just like a very self contained thing. You don't have to think about gathering pieces of data from other places. Obviously, if pieces of data exist in other places, tooling is just going to be built to be able to get it, but it kind of adds an additional thing you have to think about.
00:17:22.750 - 00:17:36.800, Speaker D: I don't get this because. Yeah, I don't understand how you can read the execution payload aside from the beacon block that wraps it, that envelops it. So I mean, like this field should always be around.
00:17:39.770 - 00:18:01.760, Speaker A: Yeah, but you probably then have some sort of function or script that combines in a way to check it. But sure, if go gender wants to echo some of that. But when I did say the default is going to be do nothing, I did see a thumbs up from Gogender. I saw a thumb up from Sean and maybe a few other people.
00:18:02.850 - 00:18:32.550, Speaker B: I think, Danny, you have covered it. I don't really have anything more to add apart from the fact, yeah, it's basically self contained and then you can just grab it and use it. And also this particular field impacts the state, basically state that is calculated in the El. So aesthetically also it makes sense, but I'm fine with not including it and doing a few more operations to just construct it while debugging.
00:18:34.910 - 00:18:38.140, Speaker A: Got it. Okay.
00:18:39.070 - 00:19:27.706, Speaker D: I was just trying to think about this duplication from the perspective of a client that has both Cl and DL in one binary. And this looks a bit weird from that perspective because we have this redundant check that the parent beacon book root corresponds to the one that we have in the beacon block. And we have this field duplication because the engine API is basically one of the ways that connects two layers together. So the other one is just, as I've said, using the same binary, which does not exist today, but probably will exist at some point in time. So I mean, from that perspective, I think that this is really, this duplication, really weird thing. This is one of the arguments that I'm having.
00:19:27.888 - 00:19:33.622, Speaker A: Right. Like the engine API leaking even more so into the consensus structures.
00:19:33.686 - 00:19:34.460, Speaker D: Yeah, exactly.
00:19:37.490 - 00:20:33.150, Speaker A: Okay. I think we're going to do nothing unless anybody says otherwise. Okay, we will close the pr and move on. Thank you for bringing back up for discussion, good gender, and thank you everyone else for taking some time to consider the arguments here. Okay, next up, this is PR 3431. Roberto and a number of others have been doing quite a bit of work in getting the new confirmation rule specified. There is a minimal change to the store and how the store is utilized.
00:20:33.150 - 00:21:48.230, Speaker A: I believe it was a change to the store. Certainly how it's utilized to enable this new confirmation rule, to enable the functions and the analysis, the security analysis, it's actually relatively simplification, but it's something that is necessary and the confirmation rule is very high value to get in. So there was a discussion point on again, confirmation rule aside, which can be done and implemented independently when and where we should be thinking about the confirmation rule prerequisites, the fork choice filter change. Should this be something that is specified, tested and attempted to be rolled out into Neb? Does this need to be rolled out in a high coordination point, like a fork? Can this be rolled out more iteratively? There's just some things that we should be thinking about in the context as we prepare for the next fork. Can someone maybe give us the TLDR on the changes and someone give us a perspective on how this should be thought of in relation to upgrade?
00:21:50.190 - 00:22:53.838, Speaker D: I'll try to. So basically, this change is relaxing the filtering and the difference between what we have currently and what is proposed can only be visible in some really edgy cases that are unlikely to happen on Mainnet. So basically the difference can occur when, for instance, canonical chain does not have a witness of the previous epoch justified, while the other side chain has this evidence. So in this case, this new change will allow to remain canonical. Chain to remain canonical. So while today it's not going to be the case, so it will be filtered out and yeah, about the rolling out this change. So this is what we should take into account.
00:22:53.838 - 00:23:39.820, Speaker D: As I've said, this is quite unlikely to happen on Mainnet, but we don't want to, this is my personal preference and probably the preference of other people, that we don't want to have this rollout take for a month or whatever. And from that perspective, it is reasonable to use a hard pore coordination, at least for releasing the software, the clients, at the same time, all clients will support this change. And when the software is upgraded, this change takes into effect.
00:23:40.990 - 00:24:12.630, Speaker A: Right. So there's two ways to use the hard fork as a coordination point, right? There's the actually do a conditional logic change at the fork boundary. And the other is to, because there's maybe a three week lead time to hard fork, cut it into that release and know that there's a transitionary period where there might be disagreement during that lead time, but to not have to support both logics in a single release. Which one are you suggesting?
00:24:16.090 - 00:24:52.034, Speaker D: That's the question to client developers. I don't know if we have this fork obstruction for the fork choice rule. I mean, can one version be discerned at a fork boundary from the other? And the first point, like the first question, what do people think about rather now that than kun at all, how big of this change it is? Oh, there are tests basically. So it should be fine. I mean, this feature is ready to be implemented. Ready for implementation. I'm just curious how people think about.
00:24:52.072 - 00:24:58.850, Speaker A: It in terms of bencom and there are tests, but there are not like fork boundary tests.
00:25:00.870 - 00:25:22.410, Speaker D: Yeah, right, correct. I'm taking silence as at least there is no stronger position to do this at Denkun.
00:25:25.460 - 00:25:56.680, Speaker A: Speaking for Deku, we discussed it a little earlier. I don't think we'd object to doing this at Deneb, but would prefer the option not to enable it at the fork so that we can enable it earlier so that we're not supporting two versions of the fork choice in one release, if that makes sense, which we don't have a history of doing so right now. So that likely represents a lot more engineering complexity.
00:25:57.260 - 00:26:13.250, Speaker D: Right? Yeah. So the question is, does any client support this working, the fork choice rule?
00:26:24.560 - 00:26:27.304, Speaker A: Yeah, it's not something we've done, so I doubt.
00:26:27.432 - 00:27:04.420, Speaker D: Yeah. Okay. And kind of related question is whether we want an eap for it or not to comply with the process. So it's probably straightforward to do in a way that some small changes already in Denobe or can we merge it without an eap?
00:27:10.300 - 00:27:51.190, Speaker A: This is an interesting one because it's in the fork choice. We haven't really done a lot of vip stuff in the fork choice. It's also an interesting one because we're just changing phase zero instead of, we're kind of saying this is the new correct logic rather than. And coordinating at the NEB, but not necessarily putting it in DNEB solely. Yeah, I understand. But this is also, we usually do eips and we change past behavior, but this is also not networking. But it almost feels like changing Dev P to P.
00:27:51.190 - 00:27:54.344, Speaker A: Yeah, it's not a.
00:27:54.382 - 00:27:59.112, Speaker D: Change to the state transition, so this.
00:27:59.166 - 00:28:03.240, Speaker A: Makes a difference, but can certainly cause disagreement.
00:28:06.160 - 00:28:28.480, Speaker D: Yeah. Though actually some network and updates can also cause disagreement and split use. So probably no EIP for this one. It's fine from my side.
00:28:30.370 - 00:28:57.400, Speaker A: Yeah, I'm not fundamentally opposed, but it would be a bit different than the way we've been doing them for Daneb. Maybe it would be an EIP and then an annotation in the phase zero spec on the line that this line has been changed since Genesis via this EIP. Cool. Yeah, I think we can go either way on that.
00:29:00.030 - 00:29:12.410, Speaker D: So probably it makes sense to create an issue for including this change into the note so people can buy their hands there on GitHub.
00:29:13.630 - 00:30:17.690, Speaker A: Yeah, let's do that. And then we would have to think about when this actually makes it into the canonical test vectors and whether we want to cut kind of future branch test vectors, because clients likely would want to wait until t minus a few weeks from the fork to actually have it in their main net release. Right? Gajinder, I guess the problem with including in the spec release at least the problem worth discussing is that that would kind of begin to force the hand of the client by its CI to just get this out immediately, rather than potentially waiting until just a few weeks before the fork to get it out. So there's certainly some considerations on how this would impact main net releases and test generation in in relation to each other.
00:30:22.200 - 00:30:31.370, Speaker D: I think we can't. Yeah, I mean, like it is, it would be too late to include it into Devnet eight. Probably not. Yeah, I think I agree with that.
00:30:40.790 - 00:30:53.430, Speaker A: Okay, Mikael, can you open up an issue so we can surface any potential pushback and or discuss a bit more about the strategy on how this is going to go into test vectors and releases?
00:30:54.730 - 00:30:55.980, Speaker D: Yep, sure.
00:30:57.870 - 00:31:48.546, Speaker A: Thank you. Any other comments or questions on this one? Anything else on Daneb? Great. So the next work is an e star name Electra. There is an issue up. We're cataloging things that people want to have for discussion for Electra. I personally, and I'm open to discussion debate on this, I think we should be in the mode where we're maybe presenting these ideas and making sure people understand them. But I don't really want to open up the electra fork.
00:31:48.546 - 00:32:47.784, Speaker A: What's going to go into the fork conversation, at least until Daneb settles down a bit more. So, for example, there's a quick update on 60 914. There's a 6110 overview today, but those are more in the context of sharing technical information than getting into the debate of what goes in. Is that cool that we push this back the electorate inclusion debate until we have a bit more insight on Danab timelines and Denab stability silences agreement. Cool. Moving on, research spec and other discussion points. Pop had a quick update to 60 914.
00:32:47.784 - 00:32:55.330, Speaker A: If anybody's following that EIP, is pop on the call? Yeah, Pop, do you want to just give us a quick on that?
00:32:57.220 - 00:33:37.390, Speaker B: Yes, the EIP six 9114 is about using the Verita index. Yeah, and actually we already have the EIP to truly use the index that is not used anymore. And there is an update on that EIP because previously we didn't update the index in the Fox choice store. So this PI is about updating the Verita index in the fork choice store.
00:33:41.160 - 00:34:11.170, Speaker A: Right. So once you overwrite an index, the past transgressions should be cleared with respect to fork choice store. And so there's an additional handler called on reused index. Essentially abstractly, when you reuse an index, you need to make sure to discard the associated index and equivocating indices in the store. Pretty straightforward. But if you're following 60 914, definitely a very important update. If anybody's doing prototyping and stuff.
00:34:16.790 - 00:34:35.320, Speaker D: I have a small question here. So the intention is to call this on reused index whenever a validator with a reused index is created, right? Or whenever get index when you start to return this. So yeah, it's basically probably the same.
00:34:38.100 - 00:35:33.960, Speaker A: Yeah, I mean abstractly you're calling this handler anytime between the validator being fully exited and the validator being reused. But it's not like hooked into the state transition function. It's more like upon reusing the index trigger, cleaning up the store. I think that's better than trying to have the dependency of the fork choice store and the state transition being explicitly integrated. Again, this is kind of an R and D EIP. So open to alternatives and different ways to think about this.
00:35:35.610 - 00:35:42.170, Speaker D: Is there a reason that the EIP isn't in the EIP repo right now? Is it just waiting in a pull request somewhere?
00:35:43.230 - 00:36:02.594, Speaker A: Is it a draft? I think it's maybe a pr, I would have to open up. Yeah, so it's pull request 60 914 and I opened the pull request and it's still sitting there, which means it's my fault. I'll go clean that up.
00:36:02.792 - 00:36:04.820, Speaker D: No worries, I was just looking for it.
00:36:06.870 - 00:36:40.410, Speaker A: Yeah, cool, I can get to that today. There's like typos and stuff. Great. Roberto and a few other people have worked on a document kind of thinking about how to improve spec compliance across clients in this kind of unique domain. Roberto, would you like to explain this?
00:36:48.660 - 00:36:51.430, Speaker D: I believe Roberto is not on the call today.
00:36:51.800 - 00:37:36.028, Speaker A: Oh, and Adich is not on the call today. Okay, cool. So there's this doc. I think Roberto Adicha and Alex Lassov have been thinking about our unique challenges in this distributed context, especially thinking about some things like work choice, et cetera, where we probably don't have super high assurances on spec compliance. And I've produced this doc and outlining the challenges and also potential things that we could continue to do. I am not the one to present this doc, so I will leave it at that. This doc exists.
00:37:36.028 - 00:38:03.624, Speaker A: There are people that are thinking about these hard problems and people that might be proposing additional solutions, pieces of software and strategies to enable better spec compliance. I invite certainly those folks to continue to come to the call and discuss these, but given they're not here, I don't have much more on that.
00:38:03.662 - 00:39:42.260, Speaker F: Salius yeah, so there is one thing that actually we discussed here in terminal that related with spare compliance, and I hope I can take a couple of minutes to express that. And maybe this could be in line with what is in the doc. So essentially we kind of often get to this interesting problem where we see that there is a written specification and there is test vectors. And in reality clients, they are kind of complying to something in between written specification and test vectors, because all the client seems, at least my knowledge, all the clients targets to run test vectors and pass them. However, there are multiple optimizations in each client that slightly or sometimes more and sometimes less diverges from the written specification. And so for us, the problem here is that if we have a highly optimized code for the optimizations that at some point for ourselves it looked that it makes sense. Just for example, this latest non finality incident where clients implemented various optimizations that often involve with discarding the attestations that according to specification shouldn't be discarded.
00:39:42.260 - 00:41:17.560, Speaker F: So for us, the problem is that if after these optimizations, test vectors are changed and they covered some case which was not covered before, then sometimes we lead to huge refactorings like that takes even months to accommodate some new test vector that was added recently or something like that. Actually, we are thinking to make two modes in a client. So the horn mode is less optimized, that tries to fully target or target as much as possible the written specification. And another mode is optimized mode which targets test vectors like a little bit stripped down version in terms of the cases that are handled. So this would allow us to quickly bring back the functionality that is closer to the written specification. So my question is, is there some other team that experiences something like that and see the issue in the thing that we think that it's an issue or we're just going somewhere else from the mainstream with this approach.
00:41:19.020 - 00:41:27.980, Speaker A: Yes. The question is, has anybody tried this kind of dual approach where you maintain highly optimized and much more straightforward version?
00:41:29.760 - 00:41:34.540, Speaker F: Yeah, this rewarded version is more like written specification compliant.
00:41:38.870 - 00:41:45.190, Speaker D: Does it mean that the optimized version will be actually used by users.
00:41:47.690 - 00:41:48.054, Speaker A: And.
00:41:48.092 - 00:41:52.810, Speaker D: Not optimized one like straightforward one, will be used for compliance testing?
00:41:54.110 - 00:43:21.830, Speaker F: No, I would say this straightforward. It wouldn't be just a very straightforward, I mean, the idea is not to just repeat the written specification. The idea is to have also pretty fast code, but the code that handles these edge cases that are let's say covered with a more general written specification, because test vectors are pretty limited in the cases that they cover, because these are specific cases, not a general specification. For us, this written specification mode, let's call it that for now, would work just for the proposed that we have a code in our code base that is spec compliant. So if test vectors changes and our optimized version needs a huge refactoring, then we can easily switch back to this general mode. And from the engineering perspective, this would be much faster than to refactor this optimized version. But the users would be running optimized version.
00:43:22.170 - 00:43:29.240, Speaker D: Yeah, but that also means that in some cases user will run the client that does not comply to the spec, right?
00:43:30.330 - 00:44:22.470, Speaker F: Yeah, but if you see, at least from our understanding that I would say probably all the clients debates from the spec, I'm actually not sure. Did all the clients implement the optimizations for the last non finality incident where those varied attestations are discarded. But if yes, then I think all the clients are not compliant to the spec, at least from this perspective. So I mean, I think that probably there is no client that is fully compliant to the specification. Or am I wrong?
00:44:35.310 - 00:45:31.248, Speaker A: Yeah, I think there are heuristics used by all clients on antidos considerations around which attestations to actually consider. I guess depending on where your view of the spec compliance is, you could say divergent or not. Right. If you're looking at just the fork choice in the context of which messages were given to the fork choice, then there's probably a higher compliance. But then if you're now kind of expanding that scope too, and then which messages are you going to give? There's more divergence. Yeah, so I don't think anyone is doing the dual maintenance strategy. I think it would certainly be interesting to investigate and write about more if you do get on that path.
00:45:31.248 - 00:45:55.390, Speaker A: Another nice thing there, potentially at least is you could actually have some intra client conformance testing. You could fuzz the interfaces of the optimized and non optimized and see if you get the same results. So there's maybe a few other things that come out of there other than the refactoring speed and stuff.
00:45:58.740 - 00:46:08.150, Speaker F: Okay, I think I'll probably try to check this doc that you, Danny mentioned. Maybe they are talking about something like that.
00:46:14.470 - 00:47:33.130, Speaker A: Yeah, cool. So take a look at the doc. Any other comments or questions in this domain right now? All right, cool. If you do have anything in this domain, certainly reach out to the authors and we can bring up points of discussion from the stock anytime subsequent calls. Thank you. Okay, next up, Mikhail and a couple of people that have been working on prototyping EIP 6110 would like to give us an overview and open it up for questions just so we can better understand this feature as we're making decisions in the future. Again, I think that certainly over the next handful of calls we do have some time if you have an EIP that you want to get some feedback on or you're potentially considering for discussion for electra, it would be a good time to just take 1015 minutes out of these calls to explain these things to each other so we can get on the same page just in general.
00:47:33.130 - 00:47:35.870, Speaker A: But Mikhail, take it away.
00:47:36.400 - 00:48:22.520, Speaker D: Yeah, thanks Danny. So Kevin, NC and myself have been working on the prototyping the CIP for months. And yeah, of course we received tons of help from Bezotim and Lighthouse team which clients we used to implement this. This changed to the design. Also many thanks to peritosh and the DevOps team. We had prepared a document that is a compilation of our goals, accomplishments and challenges, all the other stuff. So I'll just share my screen now and we'll go over this doc.
00:48:22.860 - 00:48:23.610, Speaker A: Great.
00:48:24.640 - 00:48:32.350, Speaker D: Okay, cool. Yeah. Can you see my screen?
00:48:33.200 - 00:48:33.950, Speaker A: Yes.
00:48:35.440 - 00:49:13.108, Speaker D: Yeah. So to remind what this Eap is about is basically supplying the deposits on chain. So the way the deposits deliver it to consensus payer is going to be changed by reading them directly from the execution payload instead of relying on it. One data pool, the thing that we have to date. So there is the detailed motivation section in the cap for those who are interested why. So there are many points why this change is really desirable. So in this project we pursue several goals.
00:49:13.108 - 00:50:26.770, Speaker D: One is just obviously prove the design by implementing it and also estimating the engineering complexity, looking for blind spots in the specification and incorporating a feedback from the development process into the spec, also covering the specification with tests, having additional stress testing and just making sure that the design work works in general. So this EAp has a transition period, transition from the twan betafall to the new machinery. We tested that as like just briefly go over the accomplishments. We have implementations, we have spec tests, we have kind of like I would say ready for implementation spec now. We ran several multiper devnets, did stress test and did deep and EEP on that. So like the conversation is quite impressive on that. So I'm deferring it to Kevin and about to go over the implementation side.
00:50:28.500 - 00:50:49.130, Speaker G: Yeah. So on the Cl side, EIP adds a deposit receipt container and this is now an additional field of the execution payload. And to process those deposit receives we basically reuse the applied deposit function. And these are like the main changes on the CL side.
00:50:53.900 - 00:50:54.472, Speaker D: All right.
00:50:54.526 - 00:51:45.508, Speaker H: On the el side pretty much we are extending the execution payload v three to be like v 61 ten and have the deposit receipts to be in it as such. Like the engine API, the new payload and get payload will have a new version of it as well. And also the change to the block structure. We have deposits roots and deposits to the header and body respectively. So similar to Shanghai with the. So for the block validations we are comparing the deposits receipts against the deposit receipts we extract from the transaction logs. And as such we need to have a API decoder because those logs were from the Cl site.
00:51:45.508 - 00:51:49.740, Speaker H: So this is something that's very new to the execution layer client.
00:51:51.840 - 00:51:52.910, Speaker D: Right? Yes.
00:51:53.520 - 00:52:16.710, Speaker H: So the current implementation that is Shanghai based is already implemented on Besu. And last night I saw that the Justin Florentine has been merged. So we are going to rebase the current implementation to be on Cancun. This is something that's going to be done next week.
00:52:18.520 - 00:52:19.860, Speaker A: Yes, go on.
00:52:20.010 - 00:53:09.670, Speaker D: Yeah, I just wanted to add here that we used Cancun basically as the basement for this change, because the Cancun is the fork that this change presumably will be rolled out after. And for Bezu, we used a separate branch to have this implementation based in Cancun for testing. And now the question is about moving this implementation to the main branch, which is actually great, at least in the main. So we ran several multi peer devnets, which was really exciting. And Kevin, Nancy, do you want to say few words about it?
00:53:10.040 - 00:53:31.500, Speaker G: I can say that for local devnets we used kotosis for testing some basic functionality. And then we quickly ran multiper devnets and received help from the EF DevOps team for that. I don't know, NC, maybe you want to say something about block scout.
00:53:34.000 - 00:54:20.670, Speaker H: Yeah, because of our inexperience with having block scout working nicely with BEsu. So there's a lot of parameters that we need to juggle with and as well, because block scale relies on track transaction to populate the historical blocks, there is like a limit of 512 blocks that we can look back on BesU when we're on bondsite. So as such, we need to switch the storage option over to forest to get over this limits. So this is something that's very tricky to discover this issue. I don't think there's anything else to be mentioned.
00:54:22.240 - 00:54:42.500, Speaker G: Okay, so for stress testing, we first used a FASA which allowed us to make like 100 deposits per slot. And to maximize the gas limit, we deployed a batch deposit contract to handle like 725 deposits per slot with one single transaction.
00:54:45.520 - 00:55:35.064, Speaker D: Yeah. And here is kind of results from this stress testing. There is a block delay parameter that output in lighthouse log. So what we've seen is that there is like 1.3 seconds to impert a block with 700 deposits versus like several milliseconds for an empty block. This block delay parameter should be taken as the grain of salt because the breakdown of this timing is not kind of visible and requires more deep investigation. Obviously 725 letters have been created during this process after processing this block.
00:55:35.064 - 00:56:45.680, Speaker D: So some portion of this time taken by the hashing of the state, but obviously most of this time taken by signature verification. We're also not sure if the patched signature verification used for deposit processing in lighthouse. So that's kind of a question worth investigating if we want to implement this EIP. I think that some optimization are worth doing on that front. So I should also say that 725 deposits is really a huge number which we should not ever seen on the main net. But that stress testing was like trying to estimate and see what kind of DOS attacks can be employed via this new mechanism. And the DOS analysis in the EIP, outlined in the EIP shows that basically the maximum number for 30 million gas block, the maximum number of deposits in block is around 1200.
00:56:45.680 - 00:57:30.252, Speaker D: So it's quite huge number. But yeah, the attack does not seem to be sustainable long term. There is also a Bezo section of really deep analysis on the performance done by Amazian from Bezoteam. So there are some charts here. So for those interested, we'll share this document. You can take a look. So the conclusion of this section, mainly so this new validation logic on deposit does not introduce like a lot of an overhead and surprisingly we had challenges during the work on this prototype.
00:57:30.252 - 00:57:33.090, Speaker D: So guys, do you want to cover on that as well?
00:57:35.460 - 00:57:47.190, Speaker G: Yeah, so overall, the biggest challenge of the whole prototype was finding compatible beso and lighthouse versions of Dancun, because our implementation is based on that.
00:57:53.390 - 00:59:11.934, Speaker D: Yeah. So my main takeaway and my main lesson learned from that part is that you don't want to try to build a prototype or whatever feature on top of a feature that is in active development. So we had to chase for Bezu and most of Bezu and Lighthouse as well in their implementation of four eight four, because at some stage they were at different status on this and was just incompatible with each other. So the reason for that was like we have SPAC based on Cancun, so it is obviously reasonable to base the implementation on Cancun as well. But that's really damaged the progress on this project. So that's to bear in mind for the future prototypes of this kind. So the open questions that are still open for this EIP, this EIP currently, I mean like this design suggests the Qs approach.
00:59:11.934 - 01:00:14.790, Speaker D: So there is no queue for deposits. Alternatively there could be a queue in the beacon state to rate limit the deposits per block. Sorry, not per block, but rate limit deposit processing per epoch. It does not affect the signature verification at all. It's more about affecting the number of deposits that can be applied to the active weather, like to the active balance as well, because there are top ups, and with this approach quite a decent number of top ups can bypass the churn, which one of the things that we might want to consider. And also this queueless approach, we tried to do it because we don't want to introduce any queues to the beacon state. We previously tried on that, but failed withdrawals.
01:00:14.790 - 01:01:13.020, Speaker D: So there is a pushback from client developers. But also on the other side, we have been exploring the max effective balance. The exploration of max effective balance increase suggests that queues are not that bad actually. So we might revisit this design point design consideration, especially if max effective balance will be considered for inclusion probably at the same time, or, I don't know, at around the same time. So we definitely need to do like a deeper performance analysis on cl side to look for potential optimization in the signature verification. So basically that's the remaining open questions on that and there is a gratitude section. Thanks everyone who made this project happen.
01:01:13.020 - 01:01:56.310, Speaker D: Guys, do you want to add anything on that? Cool. So we are happy to answer any questions that people might have on the call if any questions will arise around this prototype or around this Eip we are in discord can find us there.
01:01:59.000 - 01:02:36.400, Speaker A: And mars you said yay more validator churn, which I know was slightly injust. Just to clarify, this does not change the rate of validator induction, it just changes how quickly they kind of deposits appear to the beacon chain to then be decided to how to put into queue. And so like hitting that 700 or something number changes the amount of processing that might happen in a single block, but doesn't change the mechanics of the induction queue. So just to clarify.
01:02:37.460 - 01:02:55.928, Speaker D: Yeah, thanks Danny, for clarification. I was not clear on that. So what we might care is top ups without the queue, they can bypass the churn. Not bypass the churn. They bypass the churn today. But they are eight limited. That's important.
01:02:55.928 - 01:02:57.290, Speaker D: Probably important.
01:03:02.220 - 01:03:14.190, Speaker A: This is awesome. Thank you to the entire team. I mean, it's really badass to see these things prototyped end to end before we're trying to make decisions on them. So thank you very much.
01:03:19.070 - 01:03:20.240, Speaker D: Thanks everyone.
01:03:23.610 - 01:03:57.310, Speaker A: Okay, great. 61 ten is on the electra discussion list, so we will be discussing in due time any other discussion points for today. Okay, great. Thank you everyone. Talk to you very soon.
01:03:58.980 - 01:04:00.050, Speaker E: Thanks, everyone.
01:04:00.820 - 01:04:01.680, Speaker D: Thank you.
01:04:01.830 - 01:04:02.956, Speaker A: Thanks, bye.
01:04:02.988 - 01:04:03.472, Speaker C: Thank you.
01:04:03.526 - 01:04:23.210, Speaker A: Bye. Sa.

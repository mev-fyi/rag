00:00:00.160 - 00:00:29.054, Speaker A: So in that transaction you've sent to me, you are trying to like sent from yourself to yourself or what is actually happening there? Because there is like from address to address and it's like, sorry, and it's like the same address. And then you give it max fee per gas, but you don't give it like amount to land or anything like that.
00:00:30.674 - 00:00:31.694, Speaker B: Which one?
00:00:31.994 - 00:01:00.984, Speaker A: So you sent a link to me today, it was the last link in our discussion on telegram. And so you have in there like calls, you have the two calls in each you set explicitly max flipper guess while in the block there is like 10, how much it would be like.
00:01:02.004 - 00:01:15.100, Speaker B: So the max fee per gas in this transaction is higher than the base fee. So they should succeed. But yeah, there's no value being transmitted. So those transactions shouldn't do anything, how.
00:01:15.132 - 00:01:27.076, Speaker A: Much except increase the nonce. The default value of like gas that is expected to be transmitted, 21,000 is.
00:01:27.100 - 00:01:47.064, Speaker B: The smallest amount of gas I think you can send. So that, I think the transaction should consume 21,000 gas. But yeah, no value has been transacted. And for that same one get crashes. But I don't know why get crashes to that.
00:01:49.654 - 00:01:59.314, Speaker A: Because when I look at the logs, it says that it is at index one. So the first transaction went through and the second transaction was like out of gas.
00:02:02.134 - 00:02:05.194, Speaker B: That's, I think the balance should be high enough for that.
00:02:06.294 - 00:02:14.934, Speaker A: But yeah, what is the calculation, I wonder, for the max gas per block.
00:02:19.274 - 00:02:27.450, Speaker B: In this case it should be the pre, I think should be always coming from the previous block. So whatever is the previous block depends on that.
00:02:27.602 - 00:02:29.334, Speaker A: Are you running it on Hive.
00:02:31.154 - 00:02:40.264, Speaker B: That example? Well, I'm running that on the hive as well. But then I usually try to see if the mainnet produce the same issue. And with the mainnet I'm getting the same issue.
00:02:40.434 - 00:03:13.324, Speaker A: All right. All right. And yeah, by the way, I was really wondering what should be the like error code for the cases we don't like, expect beforehand. So this can be example of say, imagine it's a case of something we didn't knew beforehand would happen. So is there like error code that you would prefer us to use for such cases?
00:03:14.464 - 00:03:21.524, Speaker B: I think there's the internal node error. I think something went wrong with that node.
00:03:22.224 - 00:03:36.914, Speaker A: But what if something, but if we think that something went wrong with the processing of a block, so it's not something wrong with the node, it's something wrong with the request. But we just like haven't investigated that specific case.
00:03:38.414 - 00:03:42.514, Speaker B: Does she know ideas on that? I'm not sure. How that is handled.
00:03:44.374 - 00:03:48.034, Speaker C: I kind of didn't. I missed which case you're talking about.
00:03:51.294 - 00:04:14.774, Speaker A: So on trailer, I think it's last at the bottom of the trailer, found issues. There's gas crashes to invalid nonce and Nethermind just caches that as an exception. But still it is not to the form.
00:04:17.994 - 00:04:22.974, Speaker C: I mean, crash is definitely not good.
00:04:25.274 - 00:04:40.094, Speaker B: I shared in the chat get crashes that and the Nethermine pollution error zero. And I feel that the node should never return error code zero because we don't have that kind of error code.
00:04:44.554 - 00:04:49.454, Speaker C: Um, is it this one? Nevermind treats gas zero weirdly.
00:04:51.314 - 00:04:52.714, Speaker A: No, it's last guess.
00:04:52.794 - 00:05:04.714, Speaker C: One last guess. One. Gas crashes with invalid loans method handle crashed.
00:05:06.734 - 00:05:11.794, Speaker A: It's not exactly the same as, as the request for Nethermind, by the way.
00:05:12.774 - 00:05:25.214, Speaker B: There's a couple case where get crashes. One is the nonce and then one is the one I paste in the chat. There's no nonce error there, it just crashes to that. And I feel that query should succeed, but it crashes in both.
00:05:27.514 - 00:05:31.054, Speaker C: There seems to be just something about validation mode maybe, or.
00:05:32.954 - 00:05:38.970, Speaker B: Yeah, it's, if you put validation often, then it succeeds. It's about the validation, validation makes it fail.
00:05:39.162 - 00:05:43.854, Speaker C: Yeah, yeah, gonna look into it.
00:05:47.514 - 00:05:56.584, Speaker B: But yeah, the Olex question was, if there's a case that something fails, but we didn't know what it is, I think it should be an internal node error or internal.
00:05:56.964 - 00:06:16.156, Speaker A: Yeah, but what if we really, really think that it is not a node error, but it's an error of the input. So example, input is not valid on the main net, or input is just not valid somehow. For this like block processing that we are expected to perform, I think we.
00:06:16.180 - 00:06:19.354, Speaker B: Have invite input error.
00:06:21.294 - 00:06:45.354, Speaker A: Yeah, but the input is valid. The thing that we like try to do with it is not. So we don't know before we start processing of this block that the input was somehow wrong. And when we started possession of a block we like find it out, but it's not transaction not guess not, something like that we've managed to figure out beforehand, but something unexpected happened on possession of that block.
00:06:49.364 - 00:07:12.664, Speaker C: Can you give a more concrete example? Because I think we have error cases for most validation checks. And if the node tries to do something that should work but doesn't, then yeah, I guess it's internal error, for example when decoding, or, I don't know, something from database and yeah, all right.
00:07:12.824 - 00:08:25.924, Speaker A: Yeah, that would be good enough. So let's begin today, probably on our side. We've finished up first review of Lukash, got some stuff to fix not too much began the process of initiation of a review by some other peers on Netherland side and we are beginning to do performance check before being able to merge it in. And we would really really want your help killary on this because the idea is imagine we are doing ten or around that concurrent requests to eth simulate. And each request contains something really really performance heavy performance like encouraging. And we would like to test a few at least cases where we can actually see that nodes perform as expected when like say ten concurrent or 100 concurrent requests come in. And for that we need basically three.
00:08:25.924 - 00:09:11.716, Speaker A: We devised that we would need something like three cases. The one simplest one. It is quite easy to make just transfers. It is easy but there are a few hard cases. So first one would be transactions that try to use as much EVM opcodes as possible. So like diverse EVM opcodes randomized that are all valid and all somehow like just stressing EVM as hard as possible. And the other one is blocks interconnecting with each other like information heavily referenced throughout the blocks for all 256 blocks if possible.
00:09:11.716 - 00:09:30.664, Speaker A: So something like that would be really really helpful for us to understand the performance characteristics of this method. And if we really need or do not need to lower the like basic amount of gas or amount of blocks that are allowed per this method.
00:09:33.644 - 00:09:40.544, Speaker B: Yeah that sounds good. Except with the diverse opcodes. And I'm not exactly sure how I could generate test cases.
00:09:41.684 - 00:09:47.716, Speaker A: Yeah, that's an issue for us too. Sadly I'm not very familiar with opcodes.
00:09:47.740 - 00:10:14.622, Speaker B: And all of my tests are written with solidity. But I guess with 30 would write them in assembly. But I was wondering if you could somehow just generate random bytes. And then you make that kind of test that you try to execute random stuff and then some of would be invalid and some wouldn't be invalid but it would still. But yeah, I don't know what is the likelihood that you produce something in a way that is doing something instead of just failing?
00:10:14.678 - 00:10:31.554, Speaker A: Sadly it will be extremely hard to produce anything valid from like just random stuff. Maybe we can like gather good transactions from the real network. And just bundle the contracts in the cold data. Sina, you wanted to say something?
00:10:36.334 - 00:10:48.544, Speaker C: Oops sorry, wrong button. Yeah I think that will turn into a EVM benchmark. Not necessarily is simulate benchmark.
00:10:49.324 - 00:11:44.324, Speaker A: Yeah but the issue is that before is simulate. We had no such thing as like possibility of direct EVM benchmarking done in concurrent way onto the single client. Because normally you would have your single line of blocks and even in like anywhere you would test it sequentially. And here we can have concurrent access, concurrent forks, and thus different performance characteristics when data is accessed from the past, because one could imagine that, say you are on an archive node and somebody is performing in simulate, and is accessing some part of the regions from the past, and somebody else is accessing another part of the regions from the past, and you know, just gets, gets crushed due to the fact that there are too many random accesses.
00:11:45.344 - 00:11:52.084, Speaker C: I mean, I think it was possible with east call as well, if I'm not mistaken.
00:11:52.744 - 00:12:27.044, Speaker A: It I think would be much harder, because in east call you would just like make one call and that would be it. And if you had for example say eight concurrent threads, each one allowing you to make one concurrent request, it would like end quite quickly. And here, if you would have like eight longest, 200 blocks long ETH simulate calls, your EVM could really struggle so like in expectancy, that every of these calls would take at least 30 seconds.
00:12:27.384 - 00:13:08.238, Speaker D: So my understanding is that if we'll have the same protections against ddos as Ethcall does, meaning there's like a gas limit on how much you can execute before it just stops you. Is that not like an ethcall? You can, there's some limit hard coded into the client. I think you can change it via command line parameter when you start. Nevermind that. If you try to execute an ETH call that is bigger than in the sense that it uses more gas than that number, then it will just hard fail when it reaches that amount. I thought we were going to use that same value for.
00:13:08.326 - 00:13:10.634, Speaker A: Yes, we do. Yes, we currently do.
00:13:11.094 - 00:13:18.118, Speaker D: So I think both of them, in both cases, a single request can in theory, consume the same amount of resources, whether it's need, call, or resimulate.
00:13:18.246 - 00:13:19.194, Speaker A: That's true.
00:13:20.174 - 00:13:45.720, Speaker B: We can generate those 256 blocks, and that's probably heavier. And then I was thinking of that with the state overrides. I don't think we have any limit on how many state overrides can you can do. And I guess, I don't know how much those abuse denote, but I could create a, I could create a transaction that had huge amount of state overrides, but I would imagine that those are just that there are settings of value, but those are not actually very heavy to operate.
00:13:45.792 - 00:14:08.856, Speaker D: Yeah, yeah. The state overrides generally should just be in memory, I would assume. No, no disk access. And so, worst case scenario, you could consume a huge amount of memory. I think there's also limits on the JSON payload size. I'm guessing that's going to be what ultimately limits how many state overrides you can do. And my guess is the JSON size limit is way lower than any meaningful state overrides.
00:14:08.856 - 00:14:10.888, Speaker D: It's like five megs or something like that, right?
00:14:11.016 - 00:14:20.088, Speaker A: Yeah, I think we looked into it like a bit earlier. Yeah, there is a limit, and it's.
00:14:20.136 - 00:14:22.524, Speaker B: A bunch of state overrides. That's still fine.
00:14:23.464 - 00:15:12.704, Speaker D: Yes, because the five megabytes of JSON is going to turn into much less in terms of just raw data, just due to JSON being not encoded particularly efficiently. And all you can really do is just, again, it's setting in memory, there's no disk access. And so you're going to use, what, five to 50 on the high end is my guess, megs of memory, which is negligible for ethereum. I mean, I don't know exactly how much I'm guessing here, but my guess would be somewhere between one and ten times the JSON limit. And I think in the past for other things, if I remember correctly, JSON deserializing actually is the most expensive part. Often of these requests, the actual execution is sometimes cheaper, especially when you have these really large requests. And I would not be surprised that's the case here as well.
00:15:14.844 - 00:15:43.814, Speaker A: So I get you. So, basically, as ETH Col. Haven't get, haven't like any problems, we probably are more or less safe as long as we have similar boundaries and guarantees on its execution. So. Yeah, but still, I would love to have at least a few, like few cases where we would try, like to push it, try to see how one would hack Eth simulate.
00:15:44.114 - 00:16:15.812, Speaker D: Yeah, I do think there are some differences. So ETH simulate, in ETH call, you do your call, and then everything is basically just EVM execution, which is very tightly controlled by EVM gas pricing. Like, there are people who spend a lot of effort getting EVM gas pricing to be, you know, at least the right order of magnitude. With ETH simulate, there are some things that we're doing that aren't costing any gas. Like, you know, generating blocks is functionally free. As far as this goes. I do think we have, we have a limit on the upper number of blocks you can have, though.
00:16:15.868 - 00:16:16.744, Speaker A: Yes, we do.
00:16:17.404 - 00:16:55.714, Speaker D: And so I think just, you know, having a test to test 256 blocks and make sure that it's not like obscenely resource intensive for some reason might be useful. I don't know how exactly we'd analyze the resource utilization, but just, you know, generating the blocks is pretty easy. But that would be, I think the area that I would if I was going to do some testing for this performance wise I'd look at the block generation because that isn't accounted for in the gas pricing and I guess transaction even, even transaction count is still 21,000 gas per transaction. So it's just the blocks that are free.
00:16:59.364 - 00:17:41.038, Speaker C: I posted a tool from Marius that does this thing where like it generates random looking transactions. It could be used for not a for not for maybe consistent benchmark that can be reproduced but just to see maybe we find worst cases or something like that. Anyway I just discovered it recently. I think it's pretty cool. Is it just like testing correctness though? Like I don't know if it's been used so much for performance measuring and.
00:17:41.086 - 00:17:51.994, Speaker A: It'S just generating like transactions from peer a to peer b. Or it is like some EVM upcodes also involved.
00:17:52.334 - 00:18:00.794, Speaker C: Yeah no, it's EVM upcodes and it generates as far as I know, valid EVM bytecode.
00:18:01.734 - 00:18:06.794, Speaker A: Does it require any contracts to be posted before it would be actually usable?
00:18:07.334 - 00:18:25.174, Speaker C: I think it's pretty standalone and self contained. This was used recently to find box in the in Devnet zero of Prague and it did manage to find a few.
00:18:30.154 - 00:18:46.304, Speaker D: I'm always terrified when a fuzzer finds bugs because to me it's an indicative of some other deeper problem. Because you can find bugs via random testing. How many bugs did you miss? Because random testing is notoriously bad at hitting everything.
00:18:49.204 - 00:18:52.024, Speaker B: Humans are also very bad at hitting everything. So.
00:18:53.924 - 00:18:57.584, Speaker D: This is true. Humans are very bad at everything. I agree.
00:19:03.324 - 00:19:05.944, Speaker B: I thought you trust machines more than humans.
00:19:06.524 - 00:19:24.208, Speaker D: I do trust machines. It's just this particular machine is basically doing a random walk of a search space that is nearly infinitely big. And if you can find bugs by randomly searching an infinitely large space then it means there's a lot of bugs out there. And that's why it's terrifying.
00:19:24.376 - 00:19:47.244, Speaker B: But it's not usually not uniformly random. So usually add that kind of edge case. Like zero for example is that kind of edge case or negative one or plus one or that kind of like thing. And like it's generating also valid opcode so it's removing those non valued opcodes. So you kind of like try to make it to generate that kind of meaningful stuff as possible.
00:19:47.984 - 00:20:06.020, Speaker D: So I'm a huge fan of parameterized testing which it sounds like what you're describing where you basically define a human looks at the code and says here are the edge numbers. Test the combinatorial set of all the edge cases together in various combinations. That is super useful, in my opinion, for the exact reason you describe.
00:20:06.192 - 00:20:06.708, Speaker A: Fuzzing.
00:20:06.756 - 00:20:18.104, Speaker D: Historically, though, has just meant randomly throwing stuff at the wall until something breaks. Now, maybe, maybe what they're doing is actually parameterized testing. They just call it fuzzing because fuzzing is funner to say. I don't know.
00:20:22.164 - 00:20:30.344, Speaker B: Well, fuzzing includes that you add some randomness to it. And I guess you are just saying that you would bruise flush through all the kind of combinations that you are given.
00:20:30.684 - 00:21:03.734, Speaker D: Yeah. Like if you're doing. If you're doing edge cases, you can usually narrow the set down to something that is searchable within finite time, finite human time. So it might take like a day or two to run. So it takes a long time, but you can usually get the combinatorial set down pretty low. It's once you introduce that randomness that I start getting scared, because like I said, if the search space is so big that you need randomness in order to even start to search it, then it means that if you hit something that's terrifying because you've hit something in a search space that's so big that you couldn't actually search it in reasonable amount of time.
00:21:06.474 - 00:21:21.202, Speaker A: Corner case combinations are a mess. Always. It is extremely hard for a human to see all the combinations of corner cases. So if you even would have three, it would be too difficult to cover them. All right.
00:21:21.258 - 00:21:43.784, Speaker D: Like I said, I'm a big fan of the human goes through and defines. Here's a corner case, here's a corner case. Here's a corner case, here's a corner case. And then you set up a program that will test, okay, corner case a without corner case b or c corner case a with corner case b, corner case a with corner case c, corner case a with b and c. Corner case b with c, et cetera. Like the whole combinatorial set. And it takes a very long time to run, but it covers the entire search space.
00:21:43.784 - 00:22:10.584, Speaker D: It's only when you start randomizing that you cannot cover the search space in finite time, and you do not have enough insight to choose which space to search. And if so, if you find something, it means you're finding something in a massive search space. And if you hit something in a massive search space, that should never happen. It's basically a guarantee that there's a lot more that you missed that you didn't hit.
00:22:11.484 - 00:22:45.744, Speaker B: Well with each simulator, I'm sure there's a lot of cases that I have missed and I haven't thought of, and I think it would be useful to have faster running and comparing get and entermind to each other. I'm quite confident that the fuzzer would find stuff there because, well, at least I'm smart enough to figure out all the edge cases that to think of, to test. But Mike, if you want to volunteer thinking of all the edge cases, then I appreciate that.
00:22:49.524 - 00:23:22.944, Speaker D: It's usually just, you know, test zero, test negative one, test positive one, test uint max, test you and minus, minus max, like. And then if you've got conditionals that are on some borderline, test those numbers as well, like test max gas minus one max gas plus one max gas exact. You just basically go through and define all of those, and then you set up a parameterized test that just does the combination, like combinations of all of those things. And that is super useful. I'm a huge fan of that type of testing. I think it's, in fact, I think it's one of the best kinds of testing that you can do.
00:23:26.784 - 00:23:30.604, Speaker B: If you just do it, then I'm fine with that.
00:23:36.224 - 00:24:11.674, Speaker D: There is a C hash tool a long time back that I really wish Microsoft continued working on that actually founded this for you. And so you would give it your code and then it would go through and find all of the boundary conditions, and then it would automatically generate tests that hit all those boundary conditions and automatically generate tests that were combinations of various boundary conditions being hit. And it essentially generated code that would ensure that every possible code path in your code base was reached. It was very cool. I don't know why they dropped it. It was incredibly useful. It's just a prototype, unfortunately.
00:24:12.494 - 00:24:15.022, Speaker B: Was this ethereum related or something else?
00:24:15.158 - 00:24:25.014, Speaker D: This is like ten years ago, 15 years ago from Microsoft research called HEZ or something like that. I forgot what it's called.
00:24:29.394 - 00:24:30.654, Speaker A: How it was called.
00:24:32.434 - 00:24:33.290, Speaker D: Let me see if I can find.
00:24:33.322 - 00:24:46.094, Speaker B: It in the entering foundation. Is it, would it be possible to use some resources that could do fast testing on the heat simulate, or is it something that we have to do or nobody else does it?
00:24:51.634 - 00:25:12.654, Speaker C: I think there is few people who do fuzzing. I'd have to ask around and see. Maybe I can get some help to at least set up the process and then we can take it and run with it.
00:25:13.984 - 00:25:59.804, Speaker B: Yeah, if someone can set all those things up, and I'm always, I hate setting things up, but if somebody can set them up, then I can also fiddle up with it and try to think of inputs and that kind of things that could be needed to be tested. And now when we have nethermine and get, then it would be kind of useful, easy to do in a way that we can just compare those inputs to each other and then if they find some differences, then we can check those, see what's going wrong. But still there's a lot, no difference between get a nethermine. So I don't think we would benefit from the fastest testing that much yet. But after we get all those, after we have those human tests all matching, then we benefit from them.
00:26:02.104 - 00:26:17.824, Speaker C: Yes. First take the low hanging fruit and then. But I think it would be interesting because if you have a tool that works very similar, then it probably would very easily work for other methods as well.
00:26:21.004 - 00:26:38.534, Speaker B: Basically we want something that would generate random blocks and then if it generates random blocks, then we could convert those to each simulate calls and then run those. And I would guess that kind of tool could be something that exists already. I don't know if that TX fuzzing is doing that kind of stuff.
00:26:40.114 - 00:26:43.654, Speaker C: No, TX was not. I don't know.
00:26:44.834 - 00:26:48.214, Speaker B: TX was generating one transaction, not multiple ones.
00:26:49.594 - 00:26:59.054, Speaker C: Yeah, I mean multiple, like a lot of them, but not sequential transactions. They're kind of independent of each other.
00:27:01.004 - 00:27:13.196, Speaker B: But I guess we could use to generate 100 transaction and then we make a block out of them and multiple blocks and then we run those and compare the results.
00:27:13.300 - 00:27:20.504, Speaker C: I think the devil will be in the other parameters as well. Like not only the transactions, but like all the override fields and everything.
00:27:21.444 - 00:27:43.094, Speaker B: Yeah, but for those we can also generate some random stuff. Maybe not for something doesn't make sense to generate random stuff, but somewhat random stuff. You can generate all those. Do we have anything else?
00:27:44.514 - 00:28:31.654, Speaker C: I don't. I don't have much. Didn't end up doing a lot last week. But in one of the discussions, I don't know if I mentioned this, but in one of the discussions something interesting came up. Basically we. It seems like either 3074 or 7702 for account obstruction are likely candidates for Prague. And given that one of their main features is batch transactions, I think if simulate can play an interesting role in testing those methods.
00:28:31.654 - 00:28:43.034, Speaker C: Well, if my task, if they brought it back, I think 3074 is probably like. There was a lot of community pushback against it.
00:28:43.194 - 00:28:47.704, Speaker D: I was referring to what? Like pasted. Oh, sorry.
00:28:52.404 - 00:29:04.464, Speaker C: So yeah, I think like. Yeah, assimilate can be possibly interesting. Like the intersection of assimilate and account abstraction. I think there's room to explore there.
00:29:07.004 - 00:29:20.284, Speaker B: Yeah, I see that right away. It should be useful and used there. We don't anyone like in patches you just simulate them first and then send it. Do those add something that we need to add to it. Simulate. Is there some features that are missing from us?
00:29:22.064 - 00:29:31.804, Speaker D: I think the only requirement is being able to simulate from a contract address. And we can do, we can do that already. So I think that's all it's really needed.
00:29:33.384 - 00:29:38.604, Speaker B: And the patches are actually multicolored, I guess, and not multiple transactions.
00:29:40.584 - 00:29:43.204, Speaker D: So 430, are you talking about 430? 74.
00:29:44.624 - 00:29:48.000, Speaker B: Whatever is getting included? I guess that's what it is.
00:29:48.192 - 00:30:38.526, Speaker D: So either way. So whether it's 3074 or 70, whatever the latest version is, essentially they all allow an EOA to execute code. And if an EOA can execute code, then it means an EOa can execute multiple, a series of things, like execute an approval followed by a swap on uniswap as a simple, simple example. Right. And so you could use something like esimulate to simulate a series of actions using your, using some tool like interceptor, for example. And then those would get bashed up into, or compiled into a call to some sort of multicall contract that is executed from the point of view of the EOA. So the EOA is the message sender, but you're executing a series of things.
00:30:38.526 - 00:31:15.734, Speaker D: And so there's an interplay there in the sense that you can use eth simulate to prepare the transactions you want to do. And then once they're all prepared, then you could use an invoker for 3074 or custom code for the other one in order to actually execute that on chain atomically. Either of them would be super useful for us, assuming people start using invokers. Yeah.
00:31:22.114 - 00:31:27.694, Speaker B: Was there some discussion that you were mentioning each simulate? Sina, about those?
00:31:28.854 - 00:32:07.514, Speaker C: Yeah, well, basically I was bringing up simulate as something that people should implement. And someone mentioned this interplay between 3074. And so basically they were saying, yeah, simulator will be very useful for testing and basically simulating these batch of transactions. So when, when we have account abstraction. Sorry, I need to go to the door.
00:32:17.094 - 00:32:18.834, Speaker E: Hey guys, sorry for being late.
00:32:29.914 - 00:32:43.574, Speaker B: But I guess that load testing is something that should be done. I don't know how much heavier it multicol is or it's similar this compared to ETH call for example. That's probably something that should be done for both get and ethermind.
00:32:44.154 - 00:32:59.746, Speaker E: So for testing there are two things. One, we need to make sure that the timeouts work well. Right? And there are two ways of time, I think at least for another mine, there's a just time timeout and there's gas timeout, let's say depleted.
00:32:59.810 - 00:33:00.034, Speaker D: Right.
00:33:00.074 - 00:33:21.234, Speaker E: And that it covers across blocks. And the second one is that the actual mechanism of ETh simulate itself should be fairly light, but we need to confirm it, right. That when we do an amount of blocks, that this itself is not heavy.
00:33:22.294 - 00:33:27.514, Speaker D: Right. Because the blocks are the one, the main piece that's not accounted for was gas accounting, right?
00:33:28.614 - 00:33:29.394, Speaker E: Yes.
00:33:34.894 - 00:34:05.494, Speaker B: Is it heavier to reference that kind of block that is in there currently generated by each simulator, or is it heavier to kind of reference block that is kind of in that 256 blocks? Or should that be the same? Like if I create 100 blocks and then I refer all those, generate 100 blocks, is that heavier than just try to look up the blocks which already happened in the blockchain? I guess it would be somewhat same.
00:34:05.944 - 00:34:07.924, Speaker E: To be honest, I didn't understand that.
00:34:08.664 - 00:34:26.484, Speaker D: I think the question is, is it more expensive to work with simulated blocks in memory versus blocks that are actually part of the blockchain? And I think the answer is, unless the block happens to be in memory already, it's almost certainly more expensive to go to disk to get it than deal with simulated blocks in memory.
00:34:26.944 - 00:34:35.724, Speaker B: Aren't all those blocks in the not in memory or they are all those 256 that each simulate can access those appropriate memory already?
00:34:37.064 - 00:34:38.444, Speaker E: Yes, they should be.
00:34:38.944 - 00:34:39.416, Speaker D: Yeah.
00:34:39.480 - 00:34:43.244, Speaker B: So I would imagine it would be the same that there shouldn't be really difference.
00:34:45.664 - 00:35:25.128, Speaker D: For access, for building off of blocks. I think you're correct. So the same as ETH call Ethcall can be derived from, can build off of any block in history that the node has access to. And so that part will be the same for each simulate. The issue, the potential issue, which I agree with Lucas is unlikely, but worth verifying, is that if you simulate 256 blocks, then it means the node has to, you know, generate 256 blocks in memory. And, you know, the node wasn't necessarily designed to with the idea in mind of having lots of blocks being spawned at the same time. And so maybe there's some performance degradation there.
00:35:25.296 - 00:35:40.314, Speaker E: I would more say about, you know, preserving state with those blocks between those blocks, et cetera. Right. Because it's all in the memory temporary. So, for example, just making sure that we don't blow memory somewhere too much.
00:35:43.134 - 00:35:51.646, Speaker D: Sure. My guess is probably not. I can't really think of anything that the EVM gas accounting wouldn't already account for that you could blow up.
00:35:51.670 - 00:35:56.474, Speaker E: Yes, I do agree that it's just a safety.
00:35:58.874 - 00:36:06.174, Speaker B: Well, there's this. We have. We can generate 256 different states of the blockchain. I guess those are going to be different.
00:36:07.754 - 00:36:33.934, Speaker D: Yeah. So just generate two or 56 blocks. Each one maybe do some state changes and each one, do some contract calls that mutate state, just the kind of normal operations that each do a little bit of work. And then I don't think it needs to be a super complicated test. We just want to kind of verify that at the edge it doesn't cause problems. If I'm understanding Oleg and Lucas correctly.
00:36:34.514 - 00:36:43.654, Speaker E: Yeah. Just a sanity check that it doesn't blow up in any suspicious way.
00:36:46.474 - 00:36:59.414, Speaker B: How should we go with this? I can do some of the tests like this, but then I don't know how we should be running those. Like I don't want this kind of test to that test suit in a way, because then it just takes longer time to process.
00:37:00.274 - 00:37:46.634, Speaker D: So I think my recommendation would be we generate a test that just, you know, is big, so to speak, where big means it actually simulates 256 blocks. Each block has some state changes and so state overrides and some contract overrides and some contract calls of those overridden contracts with overridden state. And then just like one test like that, and then Lucas, Oleg, and Sina or whoever else can then just run that test manually. Like maybe it can be marked as skip or something. I don't know how the test framework works, but mark as skip and then someone on a dev team can just run that manually and just kind of monitor performance, performance metrics externally as it's executing.
00:37:49.094 - 00:38:01.154, Speaker B: I guess that needs to be run many times on multiple concurrent requests to kind of like really overload the node. Unless you want to analyze if that something in that transaction takes longer than should be.
00:38:02.174 - 00:38:24.234, Speaker D: I don't think we'd need concurrency. Like I said before, I think the concurrency issue is the same as should be the same as ETH call. Do you guys disagree? Do you think that the, if there's a problem, it may only be noticed if you do like, you know, 10,000 simulates simultaneously? Or would you notice the problem if there's just one?
00:38:25.934 - 00:38:38.264, Speaker E: So generally we rate limit how many heavy state access calls can be done in parallel and we queue them. So there is a limit for that.
00:38:42.884 - 00:38:49.144, Speaker B: If you want to hit the timeout, then you need to somehow make that it loaded the node so that it couldn't process those in time.
00:38:53.404 - 00:38:55.284, Speaker E: So those in queue can also timeout, right?
00:38:55.324 - 00:39:03.904, Speaker B: So sure, but yeah, then you should add huge amount of things to the queue. So to get the timeouts, I guess.
00:39:08.334 - 00:39:13.074, Speaker D: That should be easy enough, right? You just copy and paste 100 times the request.
00:39:20.454 - 00:39:24.274, Speaker B: Yeah, but then you also need to monitor the node and do that kind of stuff.
00:39:24.654 - 00:40:09.004, Speaker D: Yeah, so I would leave the actual monitoring side. I would leave that to leg. And Sina, I don't think we have the expertise or skills and even know what to look for, but I think we can at least generate the, you know, the test data so the big, the big eth simulate payload that kind of maxes out as much as we can in one simulate call. Like I said, I think the critical things are lots of blocks. So all 256 blocks, state overrides, contract overrides, and then transactions that actually call those overridden contracts. And each block maybe is also full. Like full enough that we can reach, almost reach the default node gas limit.
00:40:09.624 - 00:40:15.964, Speaker E: For the system wide 100 probably, right. Mega gas or. I don't know if it's for gas. It's different.
00:40:16.504 - 00:40:18.244, Speaker D: Is it 100 million for the.
00:40:18.584 - 00:40:20.644, Speaker E: It's for nominees. 100 million.
00:40:21.224 - 00:40:41.694, Speaker D: Okay, so, yeah, so basically 100 million gas worth of transactions spread out across 256 blocks. Each transaction touches code that maybe a mix or half transaction touch code that was provided via an override and half the transactions touch code that was not overridden. So we get a good mix of data there, some of us going to disk, etcetera.
00:40:44.474 - 00:40:45.334, Speaker B: Okay.
00:40:50.554 - 00:41:04.684, Speaker D: That sound reasonable to everybody. And then once we get it, once we generate the transit test data, Oleg, you can run it in Nethermind and monitor performance, however you guys do that. Great.
00:41:10.904 - 00:41:12.084, Speaker B: Do we have anything else?
00:41:13.904 - 00:41:15.044, Speaker D: Nothing for me.
00:41:20.604 - 00:41:22.784, Speaker A: All right. Thank you all for coming.
00:41:24.964 - 00:41:25.668, Speaker B: Thank you.
00:41:25.756 - 00:41:26.716, Speaker A: Next week.
00:41:26.820 - 00:41:28.024, Speaker E: Thank you. Bye.

00:01:48.464 - 00:03:39.254, Speaker A: Sa transition. That doesn't. Yeah. Okay. I don't know. Is anyone watching the YouTube stream? I feel like it should have zoom up, but there might be an audio issue. Does anyone know stream is playing pre meeting audio and video? Okay.
00:03:39.254 - 00:04:17.504, Speaker A: Yeah. Okay. As far as I can tell, it should be streaming the zoom screen. Maybe I can try this. Let's see what this does. It is a screen. It is.
00:04:17.504 - 00:04:31.568, Speaker A: No. Yeah. Okay, let's try this. It's a little wonky, but I think this will do. So. Yeah. Good morning, everyone.
00:04:31.568 - 00:04:54.444, Speaker A: Let's. Yeah, this is going to be annoying. Anyway, let's go ahead and get started. I can try just to do this. So there's the agenda. This is consensus layer. Call 134.
00:04:54.444 - 00:05:29.414, Speaker A: And yeah, we have quite a bit to talk about with Elektra. So let's just go ahead and dive into it. Actually, let me just check one thing, because what I don't know is if this is staying on zoom. Yeah. Okay. This is just really lagging. Hmm.
00:05:29.414 - 00:05:39.666, Speaker A: Okay. Sorry, everyone. Yeah, but. Okay, anyway, we'll go ahead and get started. I guess. This is what I want to know. Okay.
00:05:39.666 - 00:06:14.854, Speaker A: That's going to be weird, but that's okay. Yeah. The first thing is just to recap net zero and all the things that interop. So maybe just to get started, we had an open question with EIP 7549, essentially how to handle attestations at the fork boundary. And after discussions with the various client teams, we just decided to keep that as is. That was pretty easy. Let's see, next up, we can go ahead and move to EIP 7251.
00:06:14.854 - 00:06:50.634, Speaker A: So this is Max Ev and. Yeah, I mean, I think generally things went pretty well. There was a Devnet zero. I think all the CL client teams joined and it went pretty well, given it was the first Devnet. That being said, yeah, there were a few things to consider with Maxv, one of them being consolidations. We said originally we were going to aim for El consolidations. I don't know if anyone has thought any more about this or how we want to handle this.
00:06:50.634 - 00:07:29.342, Speaker A: I think later on the call we'll discuss fork scoping. And I think some people have even suggested taking consolidations out. Obviously that makes the feature a little bit less useful, but that's an option on the table. Yeah. Does anyone have any thoughts here on this one? Just having el triggered consolidations, I think. I think Lighthouse had some alpha implementation that Mark was hacking on. I think he had.
00:07:29.342 - 00:08:16.514, Speaker A: Yeah, yeah. He had a fork that had the API as well. But I'm not sure if anyone else tried tackling consolidations? Yeah, I'm not sure Mark's status on it, but I know he did like a polling of applications to see whether they prefer Yale or steel triggered consolidations. And there's definitely support for El. And yeah, I think we should include them if we can. Okay, sounds good. So I don't know if we want to aim for Devnet one for that or something later, but yeah, let's just keep that in mind.
00:08:16.514 - 00:09:13.360, Speaker A: I can briefly provide the status from the Yale side. So we have the smart contract for el triggered consolidations works. One question, kind of. The next natural step would be to outline the El spec for them. And before doing this, I'd like us to come through the proposal of treating el triggered requests as a sidecar to make a decision here because it can affect the spec of this thing on the outside. So this kind of on a critical path to outlining the spec for yield rigorous consolidations and for consolidations in general. I think that was agreed that we want them and we want them triggered from Yale.
00:09:13.360 - 00:10:20.754, Speaker A: So. Yeah, sounds good. Does someone have maybe an overview on how complicated the el triggered consolidations would be from, I don't know, from a Cl or Yale implementation perspective. So I haven't worked directly on it, but I think it's about as like it's very similar to any other yield triggered operation. So since we already have like an idea of how to do this, it's not really that much extra work. Right. So we'll need the logic for consolidations either way, assuming we have the feature and then the source.
00:10:20.754 - 00:11:07.094, Speaker A: If it's El or Cl, doesn't make too much difference, I think, if anything else simpler. Okay, so let's move on to something else then. Sounds like we're pretty much in agreement there. The next thing, just to round up some of the Devnet zero stuff was. Let's see. So there was a question around handling deposit finalization with EIP 6110. Let's see if I can grab the link to this comment here.
00:11:07.094 - 00:12:17.944, Speaker A: Again, there were various conversations at Interop and Mikhail summarized, I think generally the path forward here in this comment I just linked in the chat. So yeah, update is just generally we move forward on that some and you can check out the comment for the details. So from there, let's see, the other stuff is going to be additions to Electra. Was there any other Devnet zero things or stuff from the interop that people wanted to bring up kind of around the existing stuff? Yeah, I actually had something that was related to the getpayload bodies requests in the execution engine API. So the v one and v two versions of these are both fully backwards compatible. So I was thinking we might as well just extend the v one rather than adding v two. Yeah, just a thought.
00:12:17.944 - 00:13:20.230, Speaker A: Is that in line with how we usually handle this? I'd have to go look at the comment to say more, I think. Well, so with this particular endpoint, we use it during sync and the types we're getting are going to change at forks and be better not to switch at boundaries. I think that's why it's specified as fully backwards compatible with other endpoints. I think we usually do actually increment the version as the type changes. So it's kind of different in that sense. Um, I guess from my point of view though, like if this one's specified as backwards compatible, we might as well not increment the version. Yeah.
00:13:20.230 - 00:14:33.948, Speaker A: So um, adding a bit the context on, on this, we usually pump the version as Sean said, and makes sense because usually it either the new fork and the new logic should be applied. The new logic is implemented by this new version or the structure. Yeah, it's just mostly about the fork, but with this method it's kind of fork agnostic and used by sync, as Sean mentioned already. So actually we could bump the version, we could add a new structure, but this structure would have a couple or three more new fields that will just be set to null for those blocks that do not have withdrawal requests, for instance. So probably it just be easier to keep the same version and just extend the structure. Yeah, that makes sense. Great.
00:14:33.948 - 00:15:08.016, Speaker A: If everyone would take a look. Just go ahead and chime in on the. I think this is a pr there. Yeah, 545 in the execution APIs, repo. Okay, so from there, there were a number of agenda items raised for electra, essentially either changing the eaps we have. Yeah. And even some new ones.
00:15:08.016 - 00:15:33.500, Speaker A: So let's just start with the ones that were changing the existing included eips. So first up, we have this pr here. It's 3768 in the consensus specs, and essentially it's just changing the order of the fields of the new committee bits. So let's see, I think. Who raised this? Eton? I don't know if Etan's on the call. I'm here. Cool.
00:15:33.500 - 00:16:27.342, Speaker A: Do you want to give some, just a quick overview. Yeah, it's about stability for generalized indexes. So when we add a new field in the middle of a container, it means that the subsequent fields get assigned a new index which breaks proofs based on EIP 4788 in the El. And it's also a bit misleading the way how committee bits originally were placed before the signature. It sort of suggests that the signature signs over them, but that's not the case. The signature in the attestation only signs over data. So that's why I suggested to move the new field to the end, to avoid both of these problems.
00:16:27.342 - 00:17:31.114, Speaker A: And there is also a comment in the same PR that suggests that we should also consider a new name for the aggregation bits because we changed the length on that list. And if we reuse the old name but change the type, it can lead to subtle bugs in implementations that forget to update one of the usages or still consider it based on the old length. So yeah, it's a small thing, mostly for interoperability and forward compatibility. Yeah, I love to comment that it kind of breaks this like schema pattern we have of having the signature be after everything else. But yeah, I think generally rationale makes sense. Yeah, take a look at the PR generally. I think it sounds like a good idea.
00:17:31.114 - 00:18:48.494, Speaker A: I'll add just a little note to that, which is that for attestation maybe it's not the most important thing, but broadly, adding fields at the end of a container allows you to use a trick where you read the common parts with a single deserializer. And this is useful. We use that in blocks, for example, to determine the slot so that we can determine which concrete serializer to use. So it's kind of like always good practice in SSD to add things at the end, not just for numerical stability, but just for general ease of use when trying to upgrade from one object or from one container to the other. Yeah, that makes sense. So the next one, this was, I believe it's suggesting to change how we are handling shuttling all of these El triggered requests from the EL to the Cl. This is PR 551 non execution APIs.
00:18:48.494 - 00:19:58.416, Speaker A: Mikhail, you open this? Would you like to give us an overview? Yeah, sure. So this proposal. Thanks Felix and light client for the idea. And this proposal is about to remove deposits and withdrawal requests from the execution layer block. And instead of that, the execution layer client will surface these requests into response to the get payload method call. After that the consensus layer will include these requests into the beacon block body so they are moved from the El block to the CL block structure structure wise. And then when the new payload method is being called, the requests are dropped, are passed to this method call as a separate parameters, kind of as a sidecar parameters to the payload.
00:19:58.416 - 00:21:18.374, Speaker A: And if the EL has fully synced, so it's online and can fully execute a block. It will need to execute a block, obtain those requests from the block execution, and ensure that the requests given from the CL matches the one that are obtained from the execution of the block. It's kind of the way it is supposed to work is similar to block KCG commitments, where we obtain them from the get payload and send version hashes in the call to the new payload. The major difference here is that the requests can only be validated when EL is fully synced, but it does not introduce any new assumption in terms of whether the CL can or cannot apply deposits and withdrawals during the withdrawal request during the optimistic sink. With respect to the optimistic sink, actually, nothing is changing. This proposal does not affect anything. Yeah, that's the description of what is proposed.
00:21:18.374 - 00:22:37.604, Speaker A: And yeah, it would be great if we think through this and whether we like it or not, on the consensus and execution layers side, in my opinion, it's really quite nice design solution which simplifies the El part. Yeah, and I forgot to mention that this basically an alternative to generalizing requests in the execution layer block. So I'll stop here for any comments or questions. I commented on it before, like, I don't yet understand how, like, how the optimistic sync would work in this new proposal. Because if you only have a Cl alone, how does it know which of these requests are legitimate if they are not part of the El block hash? I don't think it changes anything else. Is basically an El commitment to the data contained in a blockchain. In this case, we just moved from El commitment to the CL commitment.
00:22:37.604 - 00:23:40.154, Speaker A: So we'll have them as a part of pick and block body. And it does not change anything. When you receive a block and it contains a couple of these execution layer triggered requests, how do you know as a validator whether these requests are the expected ones, whether they are legitimate? If you're in the optimistic synth mode, you can't know that for sure. And you can't know that for sure even with the existing logic. With the existing logic, you can recompute the MPT and check that it is part of the block hash. And eventually, when the El syncs up, it can tell you that this chain is invalid, actually. Yeah, but you can do the same, that the chain can be invalid even when you're.
00:23:40.154 - 00:24:35.414, Speaker A: Yeah, even after this change, I really. I don't. Maybe I'm overseeing something, but I don't think that it changed anything. Because today you can't execute. You can't validate that deposits that or withdrawal requests that you have in the execution payload are, are the same as it would be obtained from the block execution during the optimistic sync and when the sync is over. So you can tell that again, the block hash commitment does not, a malicious party can produce the valid execution payload in terms of a block hash, but with invalid withdrawal requests included into. Yeah, I'm not seeing it yet, but maybe we can follow up in the thread of that pr.
00:24:35.414 - 00:25:44.864, Speaker A: I also understand that if we accept this proposal, then it would probably require some decent amount of engineering efforts to switch from the, the general request to this approach. Mostly. Yeah, on the l side, what would the l need to change? L they would need to drop the deposits and withdrawals from, from the block structure and they would need to surface this information in the response to the get payload and also would need to accept this data on the new payload and do this matching after executing a block. So. Okay, yeah, I haven't had a chance to look at this pr. I will soon and I suggest everyone else to do the same. If you have a few moments.
00:25:44.864 - 00:26:31.944, Speaker A: Yeah. Since this change is kind of like really important for how do we handle requests, it would be great to have it sooner than later if we even want it. If we don't want it. And yeah, then we can just proceed as is. But from my perspective, I don't know if it's worth discussing on the El call as well. But if anyone from the Cl side or El side or listening to this call can think on it and comment out if they are opposed or not, that would be great. Yeah, it feels like something we can make a decision on the next sale call.
00:26:31.944 - 00:27:22.814, Speaker A: Cool. Let's see. So from here, the rest of the agenda items are discussing new things that we'd want to put in Petra, which is going to tee us up for a fork scoping conversation, which is probably why you are all here. So the first one I think will be simpler than pure DoS. It's EIP 7688. This is essentially using part of the stable container EIP. We had a conversation about this at Interop and the basic rationale was essentially we're making these breaking changes with the attestations.
00:27:22.814 - 00:28:12.474, Speaker A: If you want this forward compatibility with respect to SSD layout, we'll have to make more breaking changes in the future. And so the argument is essentially to make all of the breaking changes now at one time. So that makes sense. What it implies then though is that everyone needs to go and add this new SSD functionality into their library, which is not a huge ask given the scope of this particular SSD feature, but it's definitely non trivial. So yeah, Cayman or Eton, I think you guys were kind of leading the charge on this. Would you like to say anything further? Sure. Kemen already posted into the chat a link that tracks implementation progress.
00:28:12.474 - 00:29:14.134, Speaker A: I hope that I have collected an exhaustive list of all the relevant SSE libraries there. I think the biggest challenge is on the go one, because fast SSC was a bit of a concern there about its performance and maturity that the teams there considered making an entire new library instead of just patching the stable container support into it. But yeah, let me know if, if anything is missing or if you need any guidance. We also have a pr in consensus specs report that adds a lot of tests like SSE general tests. And there is also the remarkable implementation which also has a pr with even more tests. So there's that. There is grandine with hands up.
00:29:14.134 - 00:30:48.474, Speaker A: Yes. So Solis from grandin team. So one question we have regarding the particular implementations of stable containers. So we are thinking, because of the rust language, and essential of the nature of the rust language, we are thinking to keep version and containers at the application, at the code, essentially. So then in this way we can keep the code safety, because otherwise all the like, or most of the fields will be optional in the structs. And I just wanted to ask, so for more dynamic languages, it's probably not an issue, but for more static languages, was there some, some research or some, you know, some different attempts to implement different way this? And is there some, you know, some conclusions on that? Because once we, we get to this stable container sphere, then the structs are, you know, it becomes structs full of optional fields, which is not very good in terms of safety that compiler can ensure. So I just wanted to ask, maybe there was some conclusion on this thing.
00:30:48.474 - 00:31:52.472, Speaker A: Like you have two new things. One is this merkelization layout, which is indeed full of optionals, but then you also have these profiles which like have all the fields that are required as required fields. All the fields that are no longer used are completely gone, and you can also keep them as optional if you want. Like sometimes it makes sense, for example a withdrawal request. When you want to request full withdrawal, then just omit the amount. So in the implementations, I know what you mean. One approach that could be used if you want to avoid copying is that you just wrap it like you have the internal memory layout which is full of optionals, but then you have a typesave wrapper that just provides accessors that access directly into these optionals like into the backing store.
00:31:52.472 - 00:33:19.684, Speaker A: But the types that we are discussing here are quite like small, like you don't have to convert them between profiles a lot and it's more like comparable to when you read something from JSON into SSC. Like you first look at what fields are there and decide dynamically which type you need and load it in there. So yeah, would be interesting to see how the different implementations evolve. I think in typescript, ironically they don't even have this type that's full of options, but just provide a bit vector that sort of tells you how many holes there are in the merkelization. So there are different approaches that can be used. Okay, so currently we, we likely will go with the approach where we will keep this versioned containers and we will see how it evolves, because at the moment seems that it will be the smallest change needed right now for us. So we can keep with this version of containers like before, but we add on top of that we add stable containers.
00:33:19.684 - 00:34:16.884, Speaker A: So we will see. But if anyone from more statical languages will have some conclusions on these approaches, I'm happy to hear. I just posted in the chat an example of what Mac from our team has been working on in rust, the stable container strapped with optional fields. But then like Aton was mentioning the profiles there, no option fields. Yeah. So take a look at you on what is the progress right now just to track like what implementations have already started for the, like that, that was the rust, the Ethereum SSE, right? That library, that's what we use in Lighthouse. Okay.
00:34:16.884 - 00:35:06.378, Speaker A: And Crandine I guess as well started looking into it. Yeah, we have our own SSE implementation and we started to look how to add the stable container. But that's why I was asking here, what about the Teko library and fast SSE or the one that prism is trying to build? Tegu we haven't started yet, planning to do it very quickly. Okay. And prism I don't think we've started yet. Casey would probably be one looking at it. Yeah.
00:35:06.378 - 00:36:20.062, Speaker A: There's another thing where it will be useful for the optionals there. But if we are considering 7688 for just to do it now to avoid breaking the smart contracts all the time, then that will be before worker. So they can also take advantage of that for the optionals that they need. Okay, another thing that we have to think about is to go through all the containers that exist right now in the beacon chain. Like there are not that many, maybe 50. And to consider which of them do need future extensibility, which of them would benefit from optionals? Like for example for deposits. There was a discussion at the interop where this activation eligibility epoch would no longer be useful in the validator struct.
00:36:20.062 - 00:37:24.040, Speaker A: So for example, making the validator structure also a stable container would allow to deprecate and remove those unnecessary fields. Yeah, just think about what containers need extensibility because if we don't do these moves now, then when we later decide to extend them, then it will break again. Right? So yeah, right. I mean the one caveat is we might not know today which needs that in the future. Sure, which is totally fine. It is always possible to just remove a field of a type and to add a new field like we did for previous epoch participation in Altair where we stored full attestations before, and now we switch to these bit fields or the historical routes that got replaced with historical summaries. So that happened a couple of times already.
00:37:24.040 - 00:38:08.364, Speaker A: And if you use just a new field, it is possible with the stable container to just replace the old field with a hole so that no indices get reshuffled and then introduce a new field at the end. That's fine. Right? And I think this conversation just highlights. So, you know, if you are curious about this EIP, we should probably start doing implementation work soon. Just to surface any of these things like Soleus was talking about. Yeah, please take a look. And yeah, otherwise nice work on the devnet.
00:38:08.364 - 00:39:09.444, Speaker A: And yeah, is there anything else on that? Otherwise we can move to peer dos. Okay, Pyrados. So there was a ton of progress over interop on Pyrados, which is very exciting to see. Is anyone here on the call who was closer to that? And could you give an update? I could say a few words about peerjas Devnet zero. We launched peer net zero during the interop event. Since then we have reached an unfinality event and we have about 14% participation. I think lots of clients have discovered lots of issues in that and we could potentially relaunch anytime when we have something substantial.
00:39:09.444 - 00:40:29.806, Speaker A: Okay, sounds good. I mean, I think especially given how early it was and it being the kind of first Devnet for Pyrados, that's to be expected. Yeah, I think that then just kind of tease us up into the next big question, which is, you know, do we want to include peer Dos in Electra and generally thinking about the scope for the fork? I think we'll all be happier in the future if we can finalize Electra as soon as possible, possibly even today. So yeah, does anyone have any thoughts on including Pyrdos, given the recent progress? There's some stuff in the chat. Let me take a look. But yeah, I mean, maybe to kickstart the conversation, like, I think there's a chance that we could ship pectra this year, kind of as is. But then obviously that probably means that we'll do Pyrdos in the fork after.
00:40:29.806 - 00:41:24.514, Speaker A: And then, you know, that could be sometime into 2025. Otherwise we could say, hey, maybe it's like a bit more of a lift, but we could reach and include Pyrados in Electra. That would delay Pektra some amount of time, but I think it might be worth it. Yeah. Does anyone have any strong feelings about this? Yeah, I had a question. Wasn't the plan to like, decouple the pure dos fork from Electra so you'd set electride epoch x and, you know, peer dust, like two months into the future? But we would have like a point where all clients agree that this particular epoch is when peer dust gets activated. Right, so you mean like a Cl only fork? Yeah, exactly.
00:41:24.514 - 00:42:02.622, Speaker A: I mean, that's the same as including it just with a delay. It doesn't really matter. Like, the point is that all the users have to upgrade before that point in time. So we'd have to decide it with the hard fork. Well, there's also the eof stuff and there are the SSE transactions, which are also. They could be combined with peer dust, so that it's both El and Cl. Right, right.
00:42:02.622 - 00:43:18.054, Speaker A: But then that kind of opens the fork scope quite a bit. And that almost suggests that there's a fork after Petra, where we do all of this, which I think was kind of the original thinking. The question is just, yeah, what are things? Do we delay? And how quickly can we get to this next fork after Pektra? And all of these types of questions. Do you know from the El's whether, like, how important is it that they do verkl in isolation without any other changes? Like, as I understand, verkle only touches the state. Try and some consensus tracking there, like some data structures there, but are they willing to add orthogonal features? Or is it like, if we have vertical, it has to be alone and everything that's not in there, in Pektra has to come after? Or what's the sentiment there? I think that's generally the sentiment that Virko would be an independent thing. Guillaume, you have your hand up? Yeah, yeah. The thing is, for example, Uf can definitely not ship with vertical because it touches the exact same.
00:43:18.054 - 00:43:48.034, Speaker A: Okay. Some of the state that is being touched by vertical will be. Will also be touched by us. When it comes to. What's the name? When it comes to SSD roots, that doesn't really matter because it is indeed completely, completely orthogonal. Same thing with peer desk, by the way. If it doesn't really touch the state, it doesn't matter as much.
00:43:48.034 - 00:44:20.244, Speaker A: So the only thing that would have to come before is Eof. Or like, if it. If it's not in there before, then it would be after Berkeley. Right, exactly. I mean, it's not the only thing, but it's one example of such thing that either has to go before or after. Yeah. ATD.
00:44:20.244 - 00:45:23.676, Speaker A: Yeah. So my broad feeling is that the stuff that we currently have planned for Elektra are kind of unexciting and not worth bothering, you know, everybody's time with. So I'd be very interested in getting peer Das in, just to have something interesting to ship in it. A lot of the work is also kind of feels unfinished at this point. Almost every eip that we've done for the Devnet zero, it felt janky and undeveloped. We did a lot of discussions and changes in Kenya to them, where we changed literally quite significant things about them, or should, at least in order for them to be good aips. So I think throwing Pyrrha's in there is in line with polishing the existing eips, polishing pair, that's.
00:45:23.676 - 00:46:12.924, Speaker A: And then shipping, like, a really interesting hard work that users will be happy with, rather than just some cosmetic changes. Like, ah, where do withdrawals come from? Right. I mean, the one caveat or pushback, I think, to that is just MAXCP as a big thing. I personally lean towards including pure dos and Electra myself, just because I think we'll be happier down the line, even if it delays Pectra by a bit. That being said, pectra is already quite big, just in terms of a variety of cross layer things. And that means, you know, more risk, much more to test, maybe not so much a complicated rollout, but definitely increases, like, security and testing scope. So that's something to keep in mind for sure.
00:46:12.924 - 00:46:43.104, Speaker A: Dragon, you had your hand up. Yeah. Hello. I just want to say that Yale clients are most positive about inclusion of Uf inside Prague, but having two forks seems okay. Just want to say I'm not sure how much complexity is there. We have it. Two forks in regards just having everything inside Prague and just pushing it for like, three months.
00:46:43.104 - 00:47:08.244, Speaker A: Just want to mention that. Thanks, Nishant, you had your hand up. Yeah. So I would also be in agreement with, you know, adding peer dust to Pictra. I feel like it's quite separate from the other eips that we have. So it's easy enough to test separately. Also in a.
00:47:08.244 - 00:47:42.174, Speaker A: I don't think this fork is going to be small. So I think peer does, which we have already had quite a bit of work on. I think it's fair. Yeah, yeah, I agree with that. It's kind of separate. I would say that having one for two months after the other is kind of insane. If we're going to coordinate everybody upgrading their clients, we don't want to coordinate everybody upgrading their clients.
00:47:42.174 - 00:48:33.034, Speaker A: Again, two months down the line, that's like not enough time to even, you know, go through a release cycle often. So that means that all the features that we would have in the plus two month fork ish, they'd already have to be there in the previous one. And then it's just the technicality, whether we call it a fork or not, everybody, like, I don't really see that working. Right. Salius, I think you had your hand up next. Yes. So if there is strong consensus on adding peer dust, uh, to Electra, then I just wanted to check temperature.
00:48:33.034 - 00:50:09.554, Speaker A: Uh, maybe it makes sense to remove the attestations factoring what, which exactly. It was the one that moved the index makes everything, makes a huge refactoring because I think it also falls under this not so exciting features, which was previously in this chart, in this call discussed. So is there a strong dance removing this huge refactoring if peer dos is added? Because I think it's good if peer does is added and we have this huge attestations refactoring. And during the interop there was some good ideas that I agree that if attestations refactoring is done, then maybe we should combine that with stable containers. Because anyway, it's a huge change. So I would like to hear reasons against not removing attestation refactoring if pyrdas is added. Right.
00:50:09.554 - 00:50:43.394, Speaker A: So you'd suggest take out 7549 and essentially swap with peer dos. Yeah, yeah, that would be my. Right. I mean, and then you could imagine the next fork on the Cl, we do that change along with all the stable container stuff. So yeah, that would be my. Yeah, yeah, that would be my suggestion. Because at least for myself it looks just two huge things if we are the pirdas and unstable containers at, at one fork soon.
00:50:43.394 - 00:52:25.864, Speaker A: Anyone have any thoughts on that swapping peer to ask for the attestation EIP? I think the attestation one is like a lot of code and community changes, but it's not really impactful from a security point of view. I find them kind of orthogonal. It's just, it's just a massive pain in the ass and maybe not that much utility and that would be the reason to not include it. But I don't think it conflicts or interferes with peer dias in particular. But in terms of utility, I would say that we discussed in interop that there are very good side effects of having that included, which is much more space in block and very better reorg handling. So yeah, that was the one reason to have it and I agree with that. But like it's also like it's a lot of work for the community, which has been well for us, has been already kind of done for probably most of the client already implemented, excluding the APIs.
00:52:25.864 - 00:53:16.880, Speaker A: But if we have it, if we have enough time to also include the stable container with it, I see it as a good thing. Yeah, my point was more not to link it to peer Das. I would link it to stable container and do both in one because they indeed are very linked. I do think that that change needs a few more improvements. I don't think it's ready in its current shape. I do think that the confusion between network, the network form of attestations and the on chain or in block form of attestations needs addressing at type level. And if you think like this.
00:53:16.880 - 00:54:46.364, Speaker A: But if we do, if we throw in stable container, I think we might as well do the attestations as well. And it doesn't really add a significant burden. Do you mean that we should rather have a different attestation type for network and for the on chain? Yeah, totally. And also for the single attestation, single voter topic, so that when you create an attestation with just one validator signing it, we should have that as a separate type because then we can have the validator index there instead of the index incommittee, which means that we can increase security of the gossip validation or at least reduce, make it easier to validate those. And that's quite a win because we have a lot of attestations to process. Yeah. So you mean you would not need to have a state to compute the shuffling in order to validate this administration? Yeah, I could pick out the public key without, without the shuffling and do that before the shuffling and that's always good.
00:54:46.364 - 00:55:57.248, Speaker A: Yeah. But what would be the reason to have different types for network aggregate and for on chain aggregate? I don't the argument, the points on the single attestation, but they are semantically different, so you, you interpret them in different ways. One of them has a large list, the other one has a small list. It's just very easy to confuse the two in code flows. So in doing security audits on the code base, like regardless what happens at the spec level, we are going to do two types for them just to keep them apart. And there's really no benefit of having the same type for them. The network variant, it kind of, it appears in places that are completely separate from, from the on chain version.
00:55:57.248 - 00:56:58.004, Speaker A: So like there's no spec burn and it's just, it's not increasing complexity, it's clarifying complexity in my eyes to have two types. Yeah. I almost default that if we have just one type and we can reuse it here and there, that would just reduce the complexity. But if it's not just. Yeah, sorry Sean, I was just going to say in lighthouse we had a few bugs that probably would have been avoided if we had separate types. I don't see any big problem from this vEC perspective to introduce separate type, I mean like to have the old attestation for know the other station for the network aggregates to keep it and to introduce the new one for unchain aggregates. Enrico, you had your hand up.
00:56:58.004 - 00:57:52.234, Speaker A: Yeah. So having a single type, I see that is more future. So open up possible future in which we don't have to change the type and we enable earlier aggregation. If we change the way we do that, I mean we don't force to have only single committee aggregation in the first place. And you could potentially have very different way of aggregating in early stage. So the type will be exactly the same. My feeling is that in order to do that we would have to have a hard fork and introduce some kind of incomparable changes.
00:57:52.234 - 00:58:53.554, Speaker A: Also because the gossip rules dictate that we have to send single vote attestations on the topic. So like anything that only goes on the network is entirely ephemeral and this only affects the encoding of the object on network. On one topic I feel that it's entirely discardable this type in any future hard fork, like a single attestation and the same really for the aggregate. Yeah, I see your point now. So the only thing that is really matter is what goes on chain and the other thing is just SSD types that are floating around network and doesn't really affect the validation of block. Yeah, exactly. Yeah.
00:58:53.554 - 00:59:54.564, Speaker A: So to summarize a bit, if we see that introducing the on chain aggregate separate type for it and to not change the attestation data type and use it for network aggregates as it is today would be easier, would alleviate some engineering complexities and potentially reduce the risk of introducing box. Then from my perspective, it should be relatively easy to do on the spac side. So if. Yeah, if we come to agreement on that. So I would be open to do this change. Well, I'm in favor. I'm in favor theoretically, but on practice, I don't know how much will be the code base of tech will be affected by such a change.
00:59:54.564 - 01:00:35.594, Speaker A: Might be painful, but I don't know at the moment. Yeah, I kind of feel the same way as Enrico, where it's like, it seems like it would have made more sense from the start, but now it's like we sort of hashed all this out and would have to redo a lot of work to support it. But I'm not entirely sure. I'd have to think on it more. Yeah, it's kind of a roll back on some say on some things. And then we already have felt the pain of making this working. And yeah, I have mixed feelings.
01:00:35.594 - 01:01:05.774, Speaker A: I thought about this a bit and this change mostly affects the gossip layer. The reason I want to do it is really the single attestation security argument. I really like that one. Yeah, I like that one as well. To have the index in there, it's much better. Okay. I feel like we kind of went off on a bit of a tangent on the attestation thing.
01:01:05.774 - 01:01:58.894, Speaker A: Is there a place we can follow up async on this topic? Because then I kind of want to jump back to the chat. Mikhail, if you're able to make the pr, I can commit making the change in numbers, and then everybody can look at the code and see how much it changed. I mean, the pr to the spec. Yeah, exactly. Or if that's too much, Miguel, even just like an issue with the change that you can just describe, that would even be the starting point. Yeah, but I think it should be relatively easy. Okay, great.
01:01:58.894 - 01:03:24.638, Speaker A: There was a lot of chat in parallel, and essentially we were discussing two fork sources. One, does someone there want to maybe explain what they mean with two forks? Like, is this essentially keeping pector as is and then just putting peer dos in a fork after? Or were we talking about something else? I thought that's what we were discussing, but. Sorry, I thought that's what we were discussing, but then people were saying an even smaller fork than Petra, and I'm not sure what that would even represent. So that's maybe where. Okay, I also kind of lost track through all the chat, so maybe people had different ideas of what two forks meant. Does someone want to argue for a specific to fork configuration? Us here at Lodestar, we did publish a blog post in regards to a two fork proposal. Basically we just want to keep the scope of Petra with most of the stuff that we've already implemented as is, and try to ship something within 2024.
01:03:24.638 - 01:04:15.354, Speaker A: And then the stuff that's being worked on in parallel, which still has like implementation details and stuff that needs to be worked on, which would delay having a 2024 fork, would hopefully go into this second fork is sort of the way that we've outlined it. So that includes stuff like pure Dos and. Yeah, and how about MaxcB? Sorry I don't have your post ahead of me, but. Oh, I'll repost the link, but MaxCB is mostly, it's just like slight implementation details outside of consolidations. I believe that needs to be worked out. But that would get included in 2024 in the first four. Yeah, yeah.
01:04:15.354 - 01:05:05.398, Speaker A: And then you'd also want to add some SSD stuff, but yeah, generally keeping it as correct. We were advocating really for stable container to really get pushed into this first work because some of the teams like Nimbus and us have already implemented it didn't take too much work, our opinion. So that's why we were pushing for that to get included in the first work. Okay, so then we could imagine essentially pectra as is with the intent to ship this here. Then there's Pectora part two, which is really just whatever the f star Osaka fork is. And then that would have peer Dos, but you know, it might be mid next year or later. Right.
01:05:05.398 - 01:05:44.494, Speaker A: And I guess that's kind of the decision to make is like how okay are we with having peer Dos potentially roll out, you know, much later, much higher than what. Sorry, I just feel like if we said, okay, Petra this year and then pier Das in the next fork, the next fork will probably be a year from whenever Petra ships. Right. We can tell ourselves it'll be six months. Right. And so, I mean, I guess that's hard fork. Right.
01:05:44.494 - 01:06:51.644, Speaker A: But the time between that one and Chappello is quite long. I mean, in the elite, I think it was ref that raised a good point, which is basically that shipping in November is bad, so we'd have to ship it before November. And that's tight. And peer Das is like a really exciting feature compared to pretty much most of the other things. Yeah, go ahead. One thing I do want to mention is that if we are thinking about splitting it into two forks, we have to be really careful that we don't then just overload the next fork with new eips. Yeah, I have no idea if we're ever going to be able to do that if we can actually commit to something a year and a half in advance, because we're always coming up with new ideas, priorities change and so on.
01:06:51.644 - 01:08:03.794, Speaker A: So yeah, there's also an argument to be made if, for example, we swap maxib and peer dust so that there's more focus on peer dust. But yeah, I think those are all just points I wanted to have out there, right? I mean, we can commit today to saying, hey, only peer dos in Dev star fork. But as you point out, you know, we'll feel differently in twelve months. I mean, I do think having less stuff in one fork is better, right? So everything is like severely de risked if there's two versus one. And that does argue for Petra essentially as is. And then having peer dos in the next work, we just have to be okay with the world where, you know, it's next summer before we get peardos or work faster. We should probably always be working faster.
01:08:03.794 - 01:09:30.853, Speaker A: Francisco says that sounds like a pretty bad world, says in the chat, if Peerdos is so exciting, we should focus on that. So then, you know, that gets us back to pectoral pyrados. And then the question is, do we want to make pyrados smaller by swapping something out? And then the question is what? Yeah, my argument would be that we still have some debate on multiple apes in Tektra. The good thing about pyrdas that it's one thing, not multiple. So if the focus would be shifted completely to pyrdas, then I think pyrdas could happen soon. But if we keep focusing on pectra and then in parallel peer dust, I think this is maybe something that keeps us dragging. Mm hmm.
01:09:30.853 - 01:10:59.174, Speaker A: Yeah. So onsgar is basically suggesting we include pure dos and then reevaluate down the line, which might be a good way forward, I guess, from the spec and testing side. What I like to better understand is, is it more work to combine these things in one spec and then split them out if it takes too much time? Or is it less work to like, have them be two forks and worst case, activate literally at the same epoch or one epoch after each other? My sense is like untying everything will be much more work than like having two clean, separated things that we want to merge. And if we don't even want to merge them, we can just activate them. You know, I don't know if on the same block probably causes some weird issues, but like you could literally do one epoch after or, you know, 8192 epochs after or something, but have it in a single release. From a user perspective, on the el side, we've had bugs historically, when we take stuff out, things end up like interacting with each other, and it's like a non trivial amount of work to safely remove something. So yeah, I'm not a client implementer, but my sense is it might be easier to like spec them as two forks and decide later on if we want to ship them combined.
01:10:59.174 - 01:11:27.998, Speaker A: Yeah, yeah. The issue is having like one fork dependent on another. I mean, the all teams please chime in, but I think that would generally be the catch. But maybe we decide it's kind of worth the pain because it means you can't test anything on Petra until you have stable specs for anything on pure das. Sorry. Until you have single finalized specs for Petra. Yeah.
01:11:27.998 - 01:12:03.272, Speaker A: Any change in the prior fork is going to impact the fork after. These two pure das versus rest apex, I think are pretty segmented, though. Maybe I'm wrong, but I can't think of like interfort dependencies there. But that would like, typically be an issue. But like, I can't see it here. Right. So we'd have pectorizes and then just for sake of argument, there's like the f fork and the Cl's that's essentially off of the pector stuff.
01:12:03.272 - 01:13:08.516, Speaker A: And then f has pure dos. We kind of had the scenario also with 4844 and Chappella, where we wanted to ship 4844 in Chappelle, and then we pulled it out. So maybe client teams can see if that was in retrospect a good idea, or if it would have been smarter for us to have just waited because we're kind of agreeing on doing the same thing right now. We're saying we ship everything together and then a few months decide if we have to rip something out with the caveat that I mean, a separate fork. So it might be a bit easier just to have it disabled. I'm going to put this in real easy terms for everybody, which is basically that we're trying to pack a block here, right? Which transactions go in, and the way you pack transactions is whether they affect each other. I think pretty much everybody is agreeing here that peer Das is orthogonal to everything else.
01:13:08.516 - 01:14:00.414, Speaker A: It doesn't conflict with any other of the transactions that we're trying to pack into. This block. And that's the main reason why shipping it together with this fork makes sense, whereas some other changes that have complex interdependencies perhaps should go out. That's why we wouldn't ship, you know, Verkle and Uf and everything in one. So in those terms, I think all the items that are on Devnet zero plus pear dice plus stable container nicely can be tested, almost isolated until they're just put together and we shouldn't see much risk in putting them together. So that's the suggestion for, for Megafork, including peer dos and Pectra and then just charging ahead. Yep.
01:14:00.414 - 01:14:52.344, Speaker A: Barnabas. Yeah. My point for testing peer Das and Pectra at the same time is currently they are being activated at a different activation fork epoch, and we could keep that potentially even till we hit picture. So what we could do is keep these two features absolutely separate till the last second and then we would just activate it on the same epoch in the end. So instead of triggering the peer des on picture of fork Epoch, we would just trigger it on its own for epoch. So this way we can, even in the last minute we could just decide, hey, we, we are not ready with the appear desk, let's delay that. And let's not include that in the picture for book.
01:14:52.344 - 01:15:46.144, Speaker A: Right. So is everyone okay implementing it that way where essentially there is pectra and then there's a separate epoch for pure dos activation and then we can, this is already the case right now, so nothing really has to change. It will be effectively a parameter of the Petra network. It could be, I mean, it could also not be like it's not today, right? Yeah. So I think this would be the best way going forward. We say that we want to include it and we see how scientists are done with the implementation, or they are not done, and if they are done by Pictra time, then we include it. And if they are not done, then we just delay it.
01:15:46.144 - 01:16:26.304, Speaker A: I think the complicating part in this is that both Pectra as well as peer dust would be re based off of a DNAP starting point. And both Pectra and peer Das are changing at the same time. So one of them would have to be rebased on the other ones itself considered complete. I guess. So it depends on client teams if that's an easy thing to do or if it's a hard thing to do. Since we're not changing consensus types in peer to us, it doesn't seem hard to me to rebase the two. Yeah.
01:16:26.304 - 01:17:14.814, Speaker A: So the same for us, it's purely a networking change. So it can be cleanly separated or joined together. But one question there was wasn't peer Das changing fork choice as well? Because there's now sampling before a block is considered valid as opposed to right now, the current paradigm being that you get all the blobs and then it's valid. So wouldn't that touch some amount of consensus code and not just networking, but the current electra code or current electra spac does not touch any fort choice code. So that part is completely independent. Well, for peer dust it only just touches justification. So that'll be the only edge case.
01:17:14.814 - 01:19:04.084, Speaker A: Okay, so then suggestion would be to have Pectra as is there's now a separate fork epoch for Pyrdos, but then Pyrdos is on top of Pectra, not done up. Does that sound good to everyone? I think there were arguments where introducing an entirely new fork in client code is difficult just for one feature. So I think, yeah, that's why I was thinking it was not an actual fork, but actually not an actual fork, a feature that enables at a particular point in electro fork it was to be something like that for tech could work. Okay, so it's all not an entire new fork, right, it's all Petra, but then there's just a different fork epoch for pure enabling epoch. Yes, feature enabled epoch peer. Does epoch enable? And why everything? Why is that different? Like other Cl clients, because when you do a fork, you actually have completely different domains and signatures and everything, everything changes. So it's not gonna work for bitcoin again.
01:19:04.084 - 01:19:49.574, Speaker A: Yeah, so we'd have to like resubscribe to different gossip topics. For example, change how we scan everything and like, okay, got it. Okay. Usually change types, but since there's no types changing here, that's why we can do this. Just running this through. What happens if we do end up putting pure dos in f? Is that going to cause any issues if we go with this approach that we're discussing right now? I think it would be pretty easy to bump it out with this approach. Okay, so what you're saying is like you can do peer dos as part of Petra with a different activation epoch.
01:19:49.574 - 01:20:43.004, Speaker A: This saves you the like overhead of all the new fork implementation details. But then if we wanted to move pure dust to its own separate fork, the only additional work is effectively that like fork scaffolding overhead, is that right? Like, I mean, scaffolding overhead would be required by the new fork anyway, so it's kind of like, right? Yes. Yeah. So it's like we can hold off on doing that implementation work until we decide, basically. Yeah. Like from my perspective, if we just have picture as a separate enable epoch or whatever, we can either set it to the picture epoch or disable it and then just like wait till we implement f on top and then just set it to the f star epoch. Yeah, makes sense.
01:20:43.004 - 01:22:01.700, Speaker A: One thing though is, I think, especially if we do it fork quickly after the electric epoch, I guess if we don't do it as separate forks, we run the risk of people being able to run an electric client that isn't peer document by the time the peonosphere happens. No, I mean the code would have to be there in Electra if we, I feel as if what we're saying here really is that we want to provisionally put it into Electra, but it's easy to pull out if we don't want it in Electra. That's like the story we're selling. And from a technical point of view, the way we solve that is with a separate constant for pearls activation epoch. Right. Which I think maps onto the thing everyone wants on this call today. So then I guess that we do rebase the results back on top of electrode for now, and then we can decide whether to combine it later, essentially.
01:22:01.700 - 01:22:19.160, Speaker A: Yeah. We would just have this activation epoch and then that could be whatever we want. The constraint that that introduces is that pear does must come after electrode. And I think something else that makes sense. Well, after equal. Right, which is what we're going to have. You.
01:22:19.160 - 01:22:59.306, Speaker A: Yeah, after equal. Yeah, yeah, yeah. This is an actual problem though. No, it's not a problem. I'm just saying that like, for the fork rules to make sense, we would, that paired as Epoch would have to be higher or equal than whatever we use in electro epoch intestines, for example, which is fine. It's totally fine. Terrence, I think there's one thing that we probably missed that we should be careful of is that when you activate electra before peer does.
01:22:59.306 - 01:23:32.222, Speaker A: Right. Like which for choice rule should you be using? Should you be using a four choice rule that is specified in p or should you use the fortress route today? Right. So that's something that's probably worth thinking about and whether there is risk there by going either way. Right. But don't you only change the implementation of is data available in SPAC? I haven't, I haven't looked at the latest portrait spac. I suppose there's changes. Yeah.
01:23:32.222 - 01:23:50.674, Speaker A: I think Francesco is best. I answered that saying no, as in it's not that encapsulated. Yeah, I don't think. Oh, sorry. Okay. Is it okay now with the echo? You're good? Yeah, yeah. So it's, it's not just change in implementation.
01:23:50.674 - 01:24:36.580, Speaker A: Is data available? It's a bit more complicated than that, but not, not really that complicated. Like I think someone already mentioned before, the actual peer sampling part of things is really basically restricted to checking for justifications. So it's something that you have a lot of time to do and doesn't really get in the way the critical path. But there is a change in the fourth choice. So yeah, there is something to consider there. I don't see what it would even mean to switch to the peer dust for choice before peer dust is live because you're not doing sampling. Yeah, I think it would make sense to just keep using the regular for choice until you actually switch to the peer.
01:24:36.580 - 01:25:46.464, Speaker A: Das networking. Okay, we only have a few minutes. Carl, how are you gaining here by having it as a separate epoch after the fact? It seems to me we're just assuming the worst, that things might not work out timing wise and putting in all the effort of splitting it ahead of time, which means you kind of have to just take the loss on that time delta to implement separating them out anyway. It just seems like we take a pessimistic route or no particular gain. Well, the game, we want to ship pector in time. I think all we're really doing is just uncoupling this activation epoch and so we could decide that's equal to pectora or we could have it later if we need the option and adding that option. How bad is it to add that optionality? Because if it's not that bad to add that optionality, then truly it's not that bad to add it down the line.
01:25:46.464 - 01:26:59.608, Speaker A: To me this just seems like a thing that complicates testing and a bunch of client work and stuff between now and then. This is not something we really had before, I don't think, for any features, or am I wrong? I think the difference though is you're saying you're adding like this huge new feature to the fork and the base case shouldn't be, it's going to ship super quick, not going to cause any issues and going to go smoothly. The base case should be, it's going to add some complexity. There's stuff we don't know yet about it that we're going to figure out, and it's probably easier to hedge not delaying all of Tektra because we've added this huge thing and if we turn out to be surprised that it's actually easier than we thought, which I don't think has ever happened for any large feature, then we can couple it easily. But yeah, it does seem worthwhile to have some separation to not hide the fate of everything else that has higher certainty to this. I mean, to me it doesn't seem much worse than just stripping it out. If we just, if we reach the point where this is not going to work.
01:26:59.608 - 01:28:12.880, Speaker A: But if everyone disagrees with me on that, that's totally fine. I kind of get what you're saying, and I kind of agree. You have like a little bit more flexibility where you can just like enable peer to s at like an arbitrary epoch. Maybe that's good for testing or something, but yeah, don't I get that we could just package it in this fork and we can do this work. If it ends up not being able to do this work, because the work to actually make it enableable based on the epoch is not much. Yeah, like basically, doesn't it come down to testing? Like either be we tie Hector readiness to having tear Das adequately tested and then we activate tear Das, or if we decide that, like, tear Das isn't ready and then we let, we don't, we don't have extra weight, then we need to implement pure desk as a second fork just to force clients to update. Yeah.
01:28:12.880 - 01:29:18.974, Speaker A: So with peer dots, do we also want to increase the target blob count? I think generally, but that's a whole different conversation. Okay, so to summarize Tektra as is, there's some threads to follow up on the existing EIP set. We'll move ahead with pure DOS with a separate activation epoch, with the idea being that it will go live in Pectra and then we'll see how peer DOS implementation goes to determine if, you know, Pyrados activates. Right, apextra or maybe some later date. Does it sound good to everyone? I think the 7688 still needs to be added to the list that was stable containers. Exactly. The Cl portion of it.
01:29:18.974 - 01:30:00.216, Speaker A: Do we feel confident that implementations will be ready? I have a working devnet. Okay. Everyone named. Yeah, I mean, that to me feels like something we could discuss on the next Cl call. We're also at time, so we will close soon. I'd probably personally like to see a little more implementation progress across all of the production implementations before including it formally. We have a lighthouse implementation, sorry.
01:30:00.216 - 01:30:42.348, Speaker A: We have it in the library we use. We haven't yet tried to integrate it into Lighthouse. Is anybody against including it. The concern is just making the fork even bigger than it already is. That didn't answer my question. We haven't even started working on it, so it's a question for us. Okay, we're at time.
01:30:42.348 - 01:31:17.154, Speaker A: Why don't we table stable containers until the next Cl call? And in the meantime, if you want to support the CIP, you should work on implementation. Okay, thank you, everyone. We're at time. That was a lot of different conversation. But thank you all for joining and, yeah, I'll see you on the next call. Thanks, Alex. Thanks.

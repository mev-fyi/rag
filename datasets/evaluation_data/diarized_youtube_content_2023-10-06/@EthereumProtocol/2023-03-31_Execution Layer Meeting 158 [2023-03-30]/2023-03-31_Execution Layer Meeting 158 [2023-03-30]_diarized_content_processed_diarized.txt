00:01:47.410 - 00:02:35.434, Speaker A: Okay. Welcome everyone to Acde one five eight. Couple things today. Quickly, I'll go over Shanghai and that, which is a plan, in the next two weeks. But then most of the call we got some big updates on pretty much all the largest potential eips for Cancun. So we can go over those, and if there's anything else people want to bring up, we can do that at the end, I guess, to start. So we announced Chappella earlier this week I linked a blog post in the agenda.
00:02:35.434 - 00:03:12.250, Speaker A: I can put it here in the chat as well. And I think Aragon is the only client for whom the version has changed since the original announcement. So if you had originally downloaded version two four, you now need to change to 242. Otherwise everything that was originally listed is still valid. Anyone from any client teams or testing or whatnot have any updates or thoughts they want to share on the announcements or their client release?
00:03:13.870 - 00:03:34.610, Speaker B: Prism is thinking about another minor release probably sometime next week to fix some API RPC issue. This is slightly optional, unless you're like this operator, you are pulling this API that you probably don't need to update. But yeah, anyway, watch out for our announcement.
00:03:35.110 - 00:04:16.880, Speaker A: Okay, anyone else? Yeah, we started doing some EVM fuzzing for Shanghai and I have not looked at the results yet, but I'm currently doing it with Gath Bisu and Nethermind and I'm going to add Ericon and nimbles El to it as well. Cool. Anyone else have anything they want to share about releases or upgrades?
00:04:19.140 - 00:04:39.560, Speaker B: We have the last shadow fog planned for next week. It'll go through the transition either Tuesday or Wednesday, and the idea is that relays are up and running then, and we can test the transition with relays. If someone wants to test release they're planning to have in the next couple of weeks, let me know. Otherwise I'm just going to use the recommended releases.
00:04:45.870 - 00:05:15.670, Speaker A: Got it. Anything else? Lodestar has 1.7.1 out. It's a minor update for people using Gorely for testing with Lodestar. We may also do a minor bump with a fix for our BLS pool, but that's it. Keep an eye out for that. Okay, but the 1.7
00:05:15.670 - 00:05:20.212, Speaker A: is still correct if people just want to keep that correct, correct.
00:05:20.266 - 00:05:22.230, Speaker B: Yeah, that'll still work. Okay.
00:05:28.140 - 00:05:29.370, Speaker A: Anything else?
00:05:36.910 - 00:06:13.762, Speaker C: Maybe a small reminder related to the eips. So now Shapela upgrade is in public testnet, and obviously we do have the main net date announced. So ideally we should have all the proposals which are going to be deployed on main net in the last call. So this reminder is for the authors for proposals 3855-3860 and 4895. Please go ahead and create a pull request to move the proposal to the last call ending on April twelveth. Yeah, please reach out to ech if you want us to create a pull request and you are okay approving it. Otherwise.
00:06:13.762 - 00:06:17.320, Speaker C: Yeah, do let us know if there is anything we can do for that.
00:06:24.100 - 00:07:11.132, Speaker A: Okay. Anything else if not, just as a reminder. So the fork is scheduled for April twelveth at 10:27 p.m.. UTC. That's epoch one nine. Upgrade your node before that, and for all the validators, we have a withdrawals FAQ that's linked in the announcement that you should check out to make sure you're properly ready for withdrawals. And then similarly, Alex, you made a small update to the withdrawals EIPS 4895 just to add the actual timestamp of the fork into the EIP.
00:07:11.132 - 00:07:13.170, Speaker A: Anything else to add on that?
00:07:14.920 - 00:07:20.260, Speaker D: No, that was it. It was just TBD. And so I just put in the main timestamp.
00:07:20.760 - 00:08:00.290, Speaker A: Cool. Anything else on Chappella? Okay, so for Cancun, we have updates on EOf self destruct, the beacon state route, and the engine API. So we can go through each of those, starting with EOF last week or this week, there was the mega EOF Endgame spec that was put together. I don't know, Alex Powell, either of you want to give context on that and kind of share the latest on EOF?
00:08:06.500 - 00:08:10.868, Speaker E: Yeah, absolutely. You can hear me?
00:08:11.034 - 00:08:12.950, Speaker A: Yeah, yeah.
00:08:14.760 - 00:09:42.880, Speaker E: So just like a bit of background with UF, we had a fairly stable version last December, and then we had this proposal to avoid code inspection introspection and may also potentially avoid gas inspection capabilities. And so basically we have worked since then. The work mostly started at adobes to redesign EUF in order to support these requirements. And also, meanwhile, a number of smaller requirements arose. And so basically over the past, like two months, we have been working on fleshing out these questions, and we took the unified spec, which many of you may be familiar with, and we made the changes to the unified spec in order to support these requirements. I also have like a gist with the diff between the two, and the diff actually isn't that big. I think it's around like 200 lines, just to show that this may look like a lot of features or a lot of new things compared to last time, but actually the diff isn't that significant.
00:09:42.880 - 00:10:59.080, Speaker E: So the requirements we had is to avoid code inspection, and I think we successfully accomplished supporting that requirement what that means is that creation has to change significantly, and it also means that we want to remove operations like code copy and Xcode copy. And we figured out a way how to deal with Xcode copy, especially for the direction of going from legacy accounts to EUF accounts. It's described in the document what should happen in that case. And beyond that, the create instructions and the create transactions are the biggest changes. So what we came up with is actually not that far away from the initial proposals back in, I think end of December or early January. I would say it's a refined version of that. We have two create instructions.
00:10:59.080 - 00:12:03.996, Speaker E: The first one is create tree, which takes an index for a sub UF container, and the sub UF container would be part of the creator contract, and the sub Uf container is the runtime piece. So this create tree instruction can be deploy time validated that it has correct payload for the runtime. And then it's described how the creation process works. It's not really any different to how it works in legacy. The main important difference is that we only have create two style creation which uses a code hash, and we don't really have a need for a nons. And then the create for instruction is a bit more interesting, because with this create tree you can imagine that somehow this runtime payload has to, I mean, this init code has to enter the system. And there we have two options.
00:12:03.996 - 00:13:11.224, Speaker E: We can either create a specific create transaction, or we can introduce this create four instruction which works a bit differently. So what we do is instead of having a specific create transaction, we only extend the basic transaction format. And in fact we only want to extend the 4844 transaction format with a new field which is a list of init containers. And this list of init containers can only be inspected through the create for instruction. So the create for instruction either takes the index into this init container list, or it could take this is the only question we haven't settled on yet. It could take the hash of an entry, and that's the only way to inspect this data. And at runtime this data is validated to be correct uf.
00:13:11.224 - 00:14:21.610, Speaker E: And then the creation process is the same as it is in create tree. So that's the only difference between the two. There's also an interesting side effect of this. We could have basically a creator contract or even a creator pre compile. But when I say pre compile here, it doesn't need to be written as a pre compile. It only means that having this EVM code at a known address, there's an example what such a creator contract would look like at the end of the document, and it basically would take the index of this init code list and the transaction and some additional data as the input would perform the creation and return the address. The interesting effect here is that if we do have such a creator contract, then instead of having a create transaction, one can just send that regular transaction to this creator contract in order to deploy code.
00:14:21.610 - 00:15:59.240, Speaker E: And then the rest of the additions is instead of the return instruction, returning the payload, we have a return contract because that only has an auxiliary data which is appended to the runtime payload. The only reason we need this append option is to support this feature of solidity of immutables. This feature in solidity is basically you have two options today on legacy code, how to access data. You could just create storage slots, or if you don't want to spend all that gas on s loads, you can use this immutable feature in solidity which basically translates into appending constant data at creation time and then code copying those data sections instead of s load. So return contract is not returning the entire payload, it is only returning a payload which is appended to the runtime container. So that is the only piece which can be inspected. And since we don't have xcode copy or code copy, if we do want to support this immutable feature, we need a way to inspect the data section.
00:15:59.240 - 00:17:31.670, Speaker E: And for that we have a number of instructions such as data size, data copy and data load. And there's one specific instruction called data load n, which instead of taking a stack item for the offset in the data section, it takes it as an immutable, as an immediate. And the main benefit of this is this basically replaces, this could be used instead of pushing constants in solidity, you could just data load from the data section, where the constant is something like an immutable. So this piece is really just an optimization, this data load and instruction. But the other instructions would be needed to perform this feature set. There are a number of other smaller changes, but I think this would be, I think the important ones. And maybe I would close out with saying that every other question which was an open question during earlier discussions in December and January, and anything which has been brought up by the community has been addressed at this specification, and then they'll lastly, beyond the specification, we have an implementation of each of these features in EVM one, and we are in the process of creating state test for them.
00:17:31.670 - 00:17:45.360, Speaker E: Yeah, sorry, this was a super thank you. Didn't expect.
00:17:47.650 - 00:17:49.920, Speaker A: Yeah, does anyone have thoughts? Questions?
00:17:56.520 - 00:18:13.610, Speaker F: Yeah, I think it's great. But I worry that if we try to deliver it in Cancun, it's too big a change. So I would definitely want to have it in Prague, but I just think Cancun is stretching it.
00:18:17.360 - 00:18:37.050, Speaker A: Got it. Thanks. Any other thoughts either on the spec itself or overall timing? Okay, I guess where's the best.
00:18:37.120 - 00:18:38.458, Speaker G: I have a question, please.
00:18:38.624 - 00:18:39.740, Speaker A: No, go ahead.
00:18:40.270 - 00:18:57.218, Speaker B: One of the design decisions calls for adding a field into the transaction. I'm interested to solicit the opinions of the other core devs of their appetite for that addition. Does it feel good? Feel bad? Great. Awesome. Some sort of a signal as if whether or not this is the right direction, they would expect a transaction like.
00:18:57.224 - 00:18:58.340, Speaker E: This to move in.
00:19:08.370 - 00:19:12.880, Speaker A: Oh, sorry, I lost audio for a sec. Daniel, I don't know if anyone answered to you.
00:19:15.650 - 00:19:26.210, Speaker B: No one answered. No one raised hands. So there's no concerns with adding an extra field into one of the new transaction objects to handle the new create approach?
00:19:32.390 - 00:20:00.970, Speaker A: I do have concerns. One concern is that I didn't really fully understand the proposal yet, so I cannot really comment on it. Not raising concerns right now doesn't mean that I might not have concerns in the future. So we shouldn't take not saying anything as as no concerns by default.
00:20:02.430 - 00:20:10.910, Speaker B: That's fair. But I do want to bring that to people's attention to please read it and not just wait until two weeks before we're supposed to ship it on the testnet.
00:20:22.710 - 00:21:09.920, Speaker A: And there's some comments in the chat about basically vercol being another thing we want to do after. Obviously if we push eof out of Cancun and potentially do it in the fork after, that also means we might push something like vercol out of the fork after and do it in the fork after that. Potentially we could do them together, but that risks being a lot of big changes at once. Yeah, I guess. Where's the best place? Clearly I think teams probably need some time to look into this more and kind of digest it. Where's the best place to share feedback, comments, questions?
00:21:13.350 - 00:21:36.710, Speaker B: There is an EVM channel in the Ethereum R d discord. Everyone who's implementing it is there. We also have an EVM implementers call on the Wednesdays that are not el. So it's the day before the consensus call. Calling into that call, it's about the same time. Just on the day before is an excellent time to come in and drill down with your questions and seek understanding.
00:21:44.520 - 00:21:46.020, Speaker A: Okay, Alex?
00:21:50.520 - 00:21:50.932, Speaker B: Yeah.
00:21:50.986 - 00:22:40.816, Speaker E: So generally we had a number of different options had to split up. Because you may remember in January I said that I felt like doing all of this at once may be quite big. I tend to think now that the change set isn't actually that big as I expected in January. That being said, it is possible to break it up by skipping some of the create features and rolling out. Like for example skipping create four or skipping even create three. And having an intermediate separate legacy creates Uf code. We did review these options and they are feasible.
00:22:40.816 - 00:23:12.000, Speaker E: So it would be possible to also launch this in two pieces. But if we postpone all of these, I would still favor that we introduce at least the transaction field together with 4844 and just it would be a field which cannot be really used, but you would still pay the gas for it because that way we can avoid the prolification of new transaction types.
00:23:22.040 - 00:23:36.970, Speaker A: Any thoughts on that? Okay.
00:23:41.980 - 00:24:22.680, Speaker B: Yeah, I just verbiable want to say that my intuition would be that if we end up not bundling full euf with. I'm not very opinionated on the specifics, can we have some small things already in that fork still? But what I would say is that probably it would be better to then just give Uf its own fork afterwards in between, before the worker fork and just try to make it like a quick follow fork. Because if we keep basically trying to bundle it with another big change, but then we keep prioritizing the other big change over Uf, we will just keep pushing it. So I feel like if we don't end up combining it with virtual fork, it should really get its own fork afterwards.
00:24:23.340 - 00:25:06.052, Speaker A: Got it. I think in theory I also agree. But one risk, I don't know if it's a risk, but there will be other stuff that people want to do at the same time as this EOf fork. So we're just saying the next fork is EOF. And maybe there's not like cl changes that come in at the same time. But I think there is some overhead to having these forks. We can try to keep it minimal and not have too many other things, but we don't sort of get a fork between EOF or between Cancun and Prague for free.
00:25:06.052 - 00:25:36.720, Speaker A: Right? It just means we prioritize EOF before whatever we would have done next. Which is fine, but I think realistically you end up with there will be other things that will be included along that. And it's another like, I don't know, three at least, if not four or five, six months to put out a fork. So basically EOF would be the big thing of that fork, Lucas.
00:25:37.780 - 00:26:01.400, Speaker H: Yes. So we were actually discussing it internally. Never mind. And what looks sensible to us is not doing eof in Cancun, but doing schedule another fork for that. The driving force of the fork would be EOF and ssfication. So that looks sensible to us. Right.
00:26:01.400 - 00:26:25.440, Speaker H: And then on the next, for example, if the veracle trees will be going in, that would be for the vertical trees or something else. But I think those two things are big enough to themselves that if we want to do them, they occupy most of the fork. If we want to do them fairly soon after Cancun.
00:26:27.380 - 00:26:27.984, Speaker B: Got it.
00:26:28.022 - 00:26:33.200, Speaker A: Thanks, Guillaume.
00:26:34.820 - 00:27:03.070, Speaker B: Yeah, I'm missing the part where eof is more advanced than vertical and therefore should be scheduled first. I really don't see. I mean, maybe I get the wrong impression, but yeah, I don't want to push vertical again when it's way more ready than other things. If Uf needs more time, I don't see the point. Delaying vertical is what I'm saying. And I'd like to understand why this is not obvious to everybody here.
00:27:04.960 - 00:27:19.010, Speaker A: So there's a comment about EoF being much more ready than vertical. Does it make sense to maybe, I don't know if on this call you have that you're ready, or maybe on the next call give a proper update on vertical trees so that people can understand where it's at?
00:27:20.980 - 00:27:24.704, Speaker B: Sure, I can do that. I mean, I can even do that now if you want.
00:27:24.742 - 00:27:31.792, Speaker A: Okay. Can we wrap up eof first and then we can definitely do vertical today as well. But I just want to make sure we wrap up eof.
00:27:31.856 - 00:27:35.910, Speaker B: Yeah, no, but if you have an agenda, let's do it next time. No problem.
00:27:36.440 - 00:27:45.240, Speaker A: Yeah. Okay. If there's time today, let's do it today. But we can do it next time for sure. Anskar?
00:27:46.940 - 00:28:15.360, Speaker B: Yeah, I don't want to say anything about whether workload ufos is closest ready, but what I would say is that actually, it seems like bundling them would really not make sense. Right, because they're both very heavy el site changes. So I feel like if we are bundling something, then it should be uf and four for Cancun. But if that doesn't happen, we should definitely have them in separate folks because that would just be a big mess in my opinion.
00:28:22.940 - 00:28:23.412, Speaker A: Andrew?
00:28:23.476 - 00:29:17.180, Speaker F: Yes, I'd like to say I'm totally for Verco, but I suspect that actually switching to Velco, it's a huge, massive change on the l side and it will take other teams a lot of time to be, in terms of the engineering, to be ready for Verco. So I kind of urge everybody to start looking at Verco and doing the necessary engineering work. And it took Aragon like years to change the data model, so it's a big and long change. So I'm just thinking that realistically, I'd love to be wrong, but I think realistically, it'll take a lot of time, just on the engineering front, to be ready to switch to Virko.
00:29:21.440 - 00:30:44.350, Speaker A: Got it. Okay, so let's make sure to cover, if we have time today, we can do more Virko, but otherwise, next call, let's make sure to go over it and get an update from Yom and the different kind teams. Any other thoughts on EOf specifically? Okay, in that case, next up, we also have an update on self destruct. So Guillaume, Vitalik and Denkrad have put together a spec for the basically self destruct, but allow it if it's called in the same transaction as a contract creation, which addresses a bunch of the edge cases we've discussed previously. Yeah, Guillaume, Denkrad, do either of you want to give an update on that? You're completely breaking up. Yeah, we can't hear you super well. Is this better? Yeah, much better.
00:30:44.350 - 00:32:12.328, Speaker A: Okay, so basically it's a new version of deactivating self destruct. We've had a few iterations, so this one, what it does is it mostly works just like the complete deactivation, which just makes it basically only send all the funds, except in the case where it's called in the same transaction where a contract was created, in which case it will clear all the storage and everything about the contract. So it will be, from the EVM point of view, actually, at least it will behave exactly like the current self destruct. You cannot detect that there was any contract deployed at that address. And so the reason why we suggest this is that, at least for one of the examples we know, that has at least some amount of TVL in it, which is the spine finance contract. That would solve their problem, because what they basically do is they use self destruct to limit who can call that contract. Basically, they have a contract that anyone can call, but because it only lasts at that address for the duration of a transaction and is then self destroyed if nobody else can ever actually call it.
00:32:12.328 - 00:33:43.658, Speaker A: So it's basically using this pattern for access control. That kind of functionality would be unaffected by this change. Yeah, and the reason for this is that basically we had the different versions, and all of them we ran into, like, either a security problem, which is the one where we don't hear the storage which was suggested previously, or the other possibility would be of course to have fully functional self construct where we introduce full contact versioning by having this reincarnation column. And I think that would be, from what I've heard, significantly more complex to implement. I think lion had a go at it and basically, at least for gas, it seems to reach solution that hopefully doesn't break. Thank you. Okay, there's a first question in the chat and then we can do Andrew, but there's a question from Dano about if there's pending storage rights in the destructed contract, will those storage rights be persisted as part of the contract finalization? Sorry, what is the pending storage? Right.
00:33:43.824 - 00:33:54.990, Speaker B: So if you're doing a self destruct in a contract that exists, and before you do the self destruct, you wrote to one of the storage slots. Do those storage slots get committed before the contract is marked as self destructed?
00:33:56.050 - 00:34:07.698, Speaker A: No, the storage will be empty. So what the client will have to do is have to track all the rights that the contract does. And if it does get self destructed in that transaction, then rights will not.
00:34:07.784 - 00:34:14.120, Speaker B: This is the case where it's not the same transaction where it's an existing contract and the logic in their code. Write some stuff.
00:34:16.010 - 00:34:22.940, Speaker A: Okay. I would assume that in that case, because at least the way it's specified right now.
00:34:27.460 - 00:34:29.730, Speaker B: It'S not clear the way it's specified right now.
00:34:31.460 - 00:34:37.510, Speaker A: I would say it is, but we can happily add another bullet point to clarify this detail.
00:34:37.880 - 00:34:38.244, Speaker B: Right?
00:34:38.282 - 00:34:38.964, Speaker F: Either way, it's fine.
00:34:39.002 - 00:34:40.340, Speaker B: I just think it should be clarified.
00:34:40.840 - 00:34:44.230, Speaker A: Okay, sure. Yeah. Feel free to add a bullet point on that.
00:34:46.540 - 00:34:47.192, Speaker B: Cool.
00:34:47.326 - 00:34:48.200, Speaker A: Andrew?
00:34:49.660 - 00:35:05.900, Speaker F: Yeah, I think this version, it hits the sweet spot between reducing complexity and not breaking too many things. So I think it's a great option and I would see fired for Cancun.
00:35:08.400 - 00:35:43.620, Speaker A: Got it. And do we know on your second point about not breaking too many things, does anyone know if and what would break based on this? I know we've done a bunch of analyses, but I don't know if we've had one where we specifically look at what would potentially break from this. So I'll take this as a no.
00:35:45.350 - 00:36:10.380, Speaker B: Yeah, sorry. I'm only aware of two contracts that would be broken by just a simple removal of self destruct, and this fixes their problem. So we need a new analysis to make sure this solution fixes it all. But as far as I can tell, it's the good enough solution. No one else has come up saying this is not good enough for me. So.
00:36:12.190 - 00:37:33.980, Speaker A: Okay, so, and there were two people at least who asked about making this CFI. I feel like what might make sense is to actually make this CFI for Cancun to sort of signal that it's happening and then in parallel to that to run a more thorough scan on the chain with this, potentially with a prototype client implementation and try to analyze if anything breaks that we did not expect. But I think just to signal that this is happening to the community and that if somebody, application or contract is affected by it, they might reach out. Yeah, I think CFI will help with that. Does anyone disagree with that? Okay, so I'll make that change after the call. So yeah, the EIP number is 6780. If people want to review this, and if you are listening and are potentially affected by this, please have a look to make sure that you can raise an issue with us.
00:37:33.980 - 00:38:04.230, Speaker A: Anything else on self destruct? Ok, next up, Alex, you wanted to talk about giving access to the consensus layer state route on the EVM. You wrote a little doc giving some context, but please walk us through it.
00:38:05.340 - 00:38:05.752, Speaker E: Sure.
00:38:05.806 - 00:38:53.270, Speaker D: Yeah, so the doc Tim dropped in the chat is here and basically is know just written form of what I'm about to say. But essentially I just wanted to get some opinions on a path forward for verifying SSD proofs. So there's like kind of two big pieces to this. And the first piece is having some accumulator from the consensus layer in the execution layer. So the way we usually think about this is having like the state route or the block route for each block or state have some opcode or something that exposes that into the VM. And then you have this thing that you can make proofs against. That's generally the approach of EIP 4788.
00:38:53.270 - 00:40:17.164, Speaker D: Yeah, so the thing is though, there's one other thing which is that the way SSD works is that you basically have these things called generalized indices, and basically they're just like pointers into this whole merkel tree structure that you need. The problem is that they theoretically can change. And so now the question is like how do users of the system deal with that change? The straightforward answer is like the protocol gives them nothing and they just have some governance. But if you're like a staking pool using this stuff, that's not ideal because now you need some governance answer to change this technical thing. And one other option that gets around this is just having say a pre compile for these things that can be updated as we need it to be. And then essentially it becomes, you can imagine there's like immutable contracts using this stuff because they just have the changing state behind the pre compile. So I think for now my question is first, does anyone have any takes on this problem? And in particular does it make sense to maybe add a new pre compile for this generalized index thing? We can instead, the way we have it right now is with the IP 4788 that would expose the root.
00:40:17.164 - 00:40:43.130, Speaker D: And then you could imagine a different precompile for this generalized index accessor. Let's call it the question is, do we want to have two pre compiles for this? We could imagine fusing them and just have like a generic SSZ proof verification thing that does it all. Or yeah, maybe some other option. So yeah, I wanted to bring this to the floor and I wonder if anyone has any thoughts on that.
00:40:59.500 - 00:41:00.250, Speaker A: Anyone?
00:41:02.620 - 00:41:04.116, Speaker D: Do we understand the problems?
00:41:04.238 - 00:41:56.750, Speaker A: Yeah Decrad, yeah, I would generally prefer having some way of getting generalized indices inside the protocol just to avoid the upgrade problem. But yeah, there's not going to be a super elegant solution because it also changes, right? So the pre compile will at least have to also take fork versions and I don't know what else to know for each specific state would how to interpret it. Any other thoughts?
00:41:59.250 - 00:42:17.830, Speaker D: Yeah, I'll take this for now as just evidence that no one has any particular preference. And yeah, sometime later maybe the next all core devs are going after that. I'll have some updates for 4788 and maybe I'll also have another EIP for some pre compile here for generalized indices.
00:42:18.730 - 00:42:19.480, Speaker B: Cool.
00:42:24.350 - 00:42:35.850, Speaker A: Sounds good. Next up, Mikhail, you wanted to talk about get payload v three with the builder override flag?
00:42:39.010 - 00:44:30.610, Speaker B: Yeah, thanks. If I understand correctly, during one of the previous calls there was a kind of rough consensus to have this feature of builder override plug and there was an agreement that we want to implement heuristics on the El side and it will suggest CL to switch to local execution to block obtained from local execution engine rather than going to builders and get a block from there. If we see some censorship is happening, there is a rough consensus that we want this feature and this proposal is in the field of when do we want it to be implemented. So this particular proposal creates like a separate document and makes it in a way that makes the specification in a way that it can be implemented separately from the next work. So right after Shanghai for instance. And the main question here is that if there is anyone from El client teams who wants to really work on it right after Shanghai and before Cancun, then it does make sense to spec it out separately and do it this way. When I'm talking like work on this, it implies that really work on heuristics and really make this feature enabled, not only change the format of the response of the get payload and stab out this for the next update with real heuristics.
00:44:30.610 - 00:45:11.840, Speaker B: And the other option is that nobody wants to is willing to work on it before, say before Cancun, then it would make sense to not do it separately and just spec it out as a part of Cancun specification. So that's the kind of main question. And this proposal suggests that, right, we will do it right after Shanghai, before Cancun. I just wanted to bring this to everyone's attention. And there are any opinions right now from your client developers mostly. Great to hear them.
00:45:19.470 - 00:45:35.120, Speaker D: I think it'd be nice to have this functionality for reasons you gave, and if it's as simple as just adding this extra boolean field, that should be pretty straightforward. And yeah, that being said, we don't want to, I think block Shanghai for that change. So pulling it out into like a separate stream makes a lot of sense.
00:45:41.590 - 00:45:42.498, Speaker B: Go ahead.
00:45:42.664 - 00:45:49.940, Speaker A: I was just going to ask, is this something that all the clients need to have implemented at the same time? I assume not, right?
00:45:52.650 - 00:46:31.060, Speaker B: No, it's not really. So we can do it really in uncoordinated fashion, but if nobody will really implement heuristics for censorship that potos has outlined, or maybe some algorithms before Cancun, it doesn't make sense to spec it out separately. Yeah, I mean like prism will do it, I'm pretty sure. But we need some El client to kind of say that yes, we are willing to work on it as soon as possible, and then it makes.
00:46:34.310 - 00:46:43.250, Speaker G: The beginning. So why do we need the CLS to do anything? I mean, for the CLS, the change is absolutely trivial, right? We either accept the recommendation or we don't.
00:46:45.830 - 00:46:46.580, Speaker B: Yes.
00:46:47.050 - 00:46:54.380, Speaker G: So for us it's just a one liner. And for the ELS, well, it depends on how much of a heuristic they want to add.
00:47:01.910 - 00:47:13.300, Speaker D: I mean, it's probably more than just one line, but either way, one thing you could do is work with, say, gath. If you want to write go and prototype it out. Just like build out the idea.
00:47:15.430 - 00:47:15.842, Speaker A: Yeah.
00:47:15.896 - 00:47:34.540, Speaker G: So already Marius put out a couple of prs with a proof of concept for one of the two heuristics, which is forking censorship. And it doesn't seem to be such a large line count at least.
00:47:38.370 - 00:47:57.140, Speaker H: Yeah, I would have to look into who does what and who can potentially help her. But I think never mind, can also do it. Like I mentioned on some other call, I'm a bit not sure about coming up with proper heuristics, but I see that there are some already.
00:47:59.830 - 00:48:36.270, Speaker A: So I actually think that the eldest coming up with their own heuristics is really good because we don't really want everyone to like, I don't know if the heuristic can be attacked. We don't want everyone to stop doing math stuff at the same time. So I think if we all come up with our own mechanisms, then it's kind of plant diversity improvement.
00:48:53.190 - 00:49:44.850, Speaker G: I laid out two or three heuristics that seem very simple in the issue or in the pr, which is just tell us if transactions are being reorved consistently, if blocks are being invalid when they include particular transactions, or if transactions are being delayed consistently. It'd be nice if someone comes up with something better to add it to that PR, or to add it to that description. I can't think of more that I would like to see, and all of them seem to be easily implementable. I'm actually willing to write the prs if the ELS go ahead and put up the boolean in the get payload, I can actually try to help them writing some prs for some els. If there's lack of people writing.
00:49:57.890 - 00:50:01.140, Speaker H: Never mind, we'll pick it up and we'll prototype something.
00:50:04.360 - 00:50:38.510, Speaker B: Cool. It would be great. We can definitely can't decide something right away right here on the call, so it would be great if just all client developers look into it and then we come to some consensus that one or two teams are willing to work on it before Conc and have enough capacity to do that in one of the next calls. Doing some prototyping may really help to answer this question, whether it's difficult or not.
00:50:40.160 - 00:50:55.460, Speaker A: And I guess, yeah, if we can have one client at least show that on the El side they can implement something before Cancun, then it makes sense to spec it independently of the fork. But then if no one sort of has the bandwidth, maybe we bundle it with Cancun. Is that what you're.
00:50:56.440 - 00:50:58.790, Speaker B: Yeah, exactly. Exactly that.
00:51:00.040 - 00:51:06.920, Speaker G: Okay, are we talking about specking the actual heuristics, or just the specification is going to be just include the boolean.
00:51:08.140 - 00:51:21.790, Speaker B: I'm talking about the specification includes the boolean because it doesn't make sense to just add a Boolean to the specification if no one will really effectively use it.
00:51:22.880 - 00:51:34.848, Speaker G: Consensus that someone will write some nontrivial heuristic and that's going to be good enough to specify the Boolean. What's going to be specified is only the Boolean, right?
00:51:35.014 - 00:51:42.480, Speaker B: Yeah, definitely. I'm trying to understand whether it makes sense to specify this Boolean separately from Cancon.
00:51:43.220 - 00:51:45.044, Speaker G: Perfect. That makes a lot of sense to me.
00:51:45.082 - 00:51:51.582, Speaker B: Thanks. Yeah.
00:51:51.636 - 00:52:39.960, Speaker A: Does anyone disagree with that? Okay, so yeah, let's do that. Obviously we can keep this pr open and yeah, as we have more El clients implement things, if that happens before Cancun, we can just merge it in and otherwise we'll add it as part of the Cancun specs. Okay, so that got us through all the stuff we had on the agenda today. We can discuss Vercol in more depth. Guillaume, if you want to give an update.
00:52:43.340 - 00:53:28.020, Speaker B: I mean, vertical has been going along fine. There's been two testnet that were produced. One of them is called Beverly Hills and this one is closer to what well, hopefully Prague would be, which is just using a vertical tree without producing the proofs. So on this type of network you don't need to have any work on the CL side. So that would be a fork that would not require any change on the CL side. And then there's another testnet called Calstinin, which this one adds the proofs to the execution payload or execution data. So this one is also working.
00:53:28.020 - 00:54:42.956, Speaker B: Nethermine has just joined the two testnets last week. I mean the last one was today, but casting and was today, but Beverly Hills was last week or two weeks ago. And yeah, there's been some progress in the performance as well. I think we're only currently 40% slower than regular MPT and yeah, we still have a few things in the pipe, so I'm not saying it's ready to ship in Cancun, but I still get the impression at least the spec has been stable. Transition is okay. Still an open question, but yeah, I don't really want to share stuff about the transition because it's improving greatly. I'm in great strides at the moment, so I hope to share something about this soon, but I don't see why it would not be ready for the next fork after Cancun, simply because I think most of the questions have been answered over the last two years and it's just a matter of implementing.
00:54:42.956 - 00:55:14.808, Speaker B: So I understand that for arrogant, the database model is a bit more complicated, but I would say the real problem is that people don't look into it, but Nethermind has implemented it in less than a year. So I think at this point it's quite clear it's looking realistic to be shipped in Prague. And, yeah, I don't know if there are questions about the current status, but overall I think it's getting close to ready.
00:55:14.974 - 00:55:17.448, Speaker H: I have seven questions already.
00:55:17.614 - 00:55:18.040, Speaker A: Amazing.
00:55:18.110 - 00:55:18.890, Speaker B: Go ahead.
00:55:20.480 - 00:55:25.580, Speaker H: Okay, so have you tested the implementations against Reorgs?
00:55:26.320 - 00:55:28.830, Speaker B: Against Reorgs? Yes.
00:55:30.480 - 00:55:37.550, Speaker H: Okay. JSon RPC, does it have any degradation in, like, eth call? Things like that.
00:55:38.500 - 00:55:41.440, Speaker B: Right. So. Okay. JSOn RPC hasn't been tested.
00:55:42.180 - 00:55:48.100, Speaker H: Okay. Have you tested Mainnet? Okay. Mainet, like blocks?
00:55:49.400 - 00:55:50.150, Speaker B: Yes.
00:55:51.720 - 00:55:54.420, Speaker H: Have you managed to do a mainet shadow fork?
00:55:55.160 - 00:55:55.572, Speaker A: Right.
00:55:55.626 - 00:56:18.350, Speaker B: So this is the problem. But when you're doing a main net shadow fork, you're pretty close to the end. There's a new design that had just been decided yesterday. So, no, it hasn't been done, but it will be done this month.
00:56:23.480 - 00:56:38.876, Speaker H: Sorry. Multiple client transitions. So good to have more than one client doing the transition. Right? Generating things on the transition, or is it fine, just have one client do that.
00:56:39.058 - 00:56:42.060, Speaker B: No. Yeah, we should have that. Agreed.
00:56:43.040 - 00:56:54.480, Speaker H: Okay. That will take a long time, so it's good to maybe work on it earlier in power, but just highlighting problems. And last one. And that is a big one. Snap sync for vertical trees?
00:56:55.780 - 00:57:00.640, Speaker B: No. Yeah. There wouldn't be any snap sync for vertical trees. It would be a vertical sync.
00:57:01.460 - 00:57:06.100, Speaker H: Okay. How would it perform compared to snapsync?
00:57:07.480 - 00:57:13.750, Speaker B: Yeah. Presumably better, but yes, we don't know until we have tried it.
00:57:14.540 - 00:57:19.770, Speaker H: Okay. So quite a few question marks, right?
00:57:20.540 - 00:57:21.048, Speaker B: No.
00:57:21.134 - 00:57:21.432, Speaker E: Okay.
00:57:21.486 - 00:57:30.328, Speaker B: Yes. I said it's not ready. Getting closer to being ready. I said it's definitely not ready. Like, it can be shipped in Canada.
00:57:30.344 - 00:57:42.290, Speaker H: No, don't worry. I'm probing where we are. Right. On the decision when to ship it. Right. Yeah. I still think it's far away.
00:57:42.290 - 00:58:00.756, Speaker H: It's a lot closer than it was, like, a few months ago. And so, yeah, I'm reluctant to rush it. Right. Until those questions are, we have answers and we are happy with those answers for those questions.
00:58:00.938 - 00:58:13.240, Speaker B: Fair enough. At the same time, I think that doesn't change what I said. The spec is stable, so it should definitely get more interest than it does now. People should look at it. That's the point.
00:58:13.310 - 00:58:18.716, Speaker H: Yeah, fine. I'm just a bit cautious. That's what I want to say.
00:58:18.818 - 00:58:24.830, Speaker B: Okay, fair enough. I think there was five questions.
00:58:25.920 - 00:58:32.284, Speaker A: You want more? I counted six questions in my notes.
00:58:32.332 - 00:58:34.050, Speaker B: Okay, my bad. Yeah.
00:58:35.620 - 00:58:39.184, Speaker A: Andrew, you have your head up as I just.
00:58:39.222 - 00:59:27.680, Speaker F: I'd like to at least. My understanding is that it's easiest for Aragon, so I'm not worried about Aragon implementing Verco trees. I'm worried about other clients because how I see it, I don't understand how you can do it without moving to the data model with unhashed keys. Maybe I'm wrong, but I just don't get it. And the last time, when I spoke to Peter, Geth is still using hashed keys. So maybe Marius can comment. I just don't understand how Geth is going to implement vocal trees with either not moving to unhashed keys.
00:59:29.060 - 00:59:30.480, Speaker B: You need to rehash.
00:59:33.570 - 00:59:38.370, Speaker F: So where do you get pre images from? Or you don't need pre images?
00:59:38.870 - 01:00:02.810, Speaker B: Well, I mean, yes, you need to distribute the pre images, but what happens is, we're looking at a solution where only a smaller number of nodes. I mean, talk to Julio about it. He has worked on that topic. The idea is that some nodes that do have the pre images, typically arrogant, will share the converted database with other nodes.
01:00:04.990 - 01:00:09.980, Speaker F: Okay, yeah, that's fine, but it's still.
01:00:13.470 - 01:00:13.942, Speaker B: Yeah.
01:00:14.016 - 01:00:23.040, Speaker F: Again, my point is that for Aragon, it's easy, but other clients should be happy with this plan.
01:00:25.670 - 01:00:56.140, Speaker H: Yeah. To comment on that, I know that you can verify it and it's verifiable, et cetera, et cetera. But I have an unease on this topic, too. Right? So I somewhat agree. But this is like, maybe just a feeling that is wrong, but I'm unease about it. That's to get the state from one node, for example. But how verifiable is that? How easy verifiable is that?
01:00:58.350 - 01:01:28.180, Speaker B: Well, I mean, that would be very easily verifiable. You just have to check if your data can be reconstructed. But. Yeah, no, I agree with you that this is not my favorite method either. But that seems the simplest at this point. Although I might change my tune in just a couple of days. Yeah, actually, I lost the point of your question.
01:01:28.180 - 01:01:33.712, Speaker B: Could you repeat your question?
01:01:33.766 - 01:01:37.428, Speaker H: Sorry, was it really a question? Just was a comment more.
01:01:37.594 - 01:01:38.116, Speaker B: Okay.
01:01:38.218 - 01:01:47.800, Speaker A: Yeah, that's. Relying on Aragon only to distribute the database is concerning.
01:01:49.020 - 01:01:53.690, Speaker F: We can do something. Sorry, go on.
01:01:58.140 - 01:01:58.890, Speaker B: And.
01:02:01.280 - 01:02:02.910, Speaker F: You'Re breaking up.
01:02:03.360 - 01:02:13.692, Speaker A: Yeah, we. No, we can't hear you at all. Decred.
01:02:13.836 - 01:02:15.170, Speaker B: It's the same.
01:02:19.000 - 01:02:42.570, Speaker F: What I was also thinking is that we can have a special small subprrotocol for just pre images, and we can implement it in Aragon. And then our other clients can just get the pre images they want. But we need to test that.
01:02:46.240 - 01:03:08.240, Speaker B: Sure. Just to address another comment. So far, the best implementation we have is with arrogant. I never said it was only going to be arrogant that would do this. It makes sense that everybody tests, everybody tries to produce the same image and needs to verify that it matches.
01:03:15.790 - 01:04:33.570, Speaker H: So Nethermind is in the process of reworking its state DB, and we have actually two streams, one like more proven to work and one very experimental. So I think we would be after if we manage to ship it and we can ship it this year question when this year we might be able to do that migration more easily. But yeah, this is still an open question. This more experimental layout, it's also done in this way that then later could be with lot of changes applied to vertical trees. So it's called paprika, if anyone is interested, and it's direct storage of the Patricia Melkel tree on the disk using the memory mapped files in a way. So there are some good docs being produced by shimon. So if someone wants to check it out, I encourage.
01:04:40.820 - 01:05:20.940, Speaker A: Thank you. Any other questions? Thoughts on Rickle trees? Okay, I know, Guillaume, you said not to ask about this, but I'll try anyways. But I'm curious, even if you don't have a full spec yet about the transition, if you can share just a bit about your thinking about that and maybe like the trade offs, just because we have plenty of time now to talk about vertical trees, so it's probably worth going over as much of it as we can.
01:05:23.070 - 01:06:52.120, Speaker B: Yeah, sure. Once again, we're having some results that are coming in that might make us change our claims. But so the idea is that indeed, because so far the translation was taking so much time, you have to rehash everything except arrogant, that you have to do it offline, like you need some powerful machines to do it. And from our benchmark so far, to be updated soon, it takes about 18 hours in the case of arrogant, and much longer for Geth to produce a conversion that then is sent all over to all the clients on the network and, well, more exactly, all the clients on the network download it, and they start replaying blocks on top of this conversion and catch up with the MPT head. And they have to do this before a given fork block. And at the fork block, the MPT is no longer updated, it's jettisoned, and the vertical state becomes the official state. So, yeah, that's roughly the plan so far.
01:06:52.120 - 01:06:55.466, Speaker B: We're having some.
01:06:55.648 - 01:06:55.946, Speaker A: Yeah.
01:06:55.968 - 01:07:25.490, Speaker B: Okay. Now, I don't really want to talk about this yet, because it sounds too good to be true, but yeah, the idea is that we would somehow be able to ensure that everybody is able to do their conversion themselves. But currently, with all confirmed benchmarks, this is not realistic. So we need to help some very powerful nodes need to help less powerful nodes to do the transition.
01:07:26.870 - 01:07:55.020, Speaker A: Got it. Okay. And so at least, I guess the thing I was worried about is the earlier specs of vertical trees required the network to stop producing blocks for a while or something like that. But with this spec, you would not have this issue. Correct. Obviously, you need to figure out the way to do it efficiently, but you're sort of swapping in the background from the merkel. Patricia, try to the Verco try when the fork happens.
01:07:55.020 - 01:08:00.494, Speaker A: Got it?
01:08:00.532 - 01:08:11.218, Speaker B: Yeah. It has never really been seriously considered. It was more meant like a joke. Maybe there was a joke that was too catchy, but it wasn't clear that.
01:08:11.224 - 01:08:43.580, Speaker A: There was an easy way to do it without downtime, basically. And so I just wanted to make it clear that there is, or wouldn't necessarily call it lazy, but there is a way to do it without any other questions? Okay. There's a question about do zkevm make vertical tries redundant? I don't know. Guillaume. Dankrad, you want to take that?
01:08:46.320 - 01:09:20.410, Speaker B: I don't know if Dankrad is closer to a connection. My understanding is that, yes, well, ZKVM, the long term plan is to get rid of to replace vertical trees with a ZK construct. I don't think it will be made completely redundant, because some of the choices we have are specifically designed to be ZK friendly. But yeah, that's just my understanding I don't have yet. Dancret should be able to answer that better.
01:09:22.940 - 01:10:15.704, Speaker A: Can you hear me now? Kind of. So, yes, like a full ZK VM that can, in a decentralized enough fashion, prove in, say, a second that a block is correct, would indeed make worker trees not necessary. But I think we are quite a few years from that. I'm willing to be proven wrong, but that is my current assumption that, yes, zkvms are coming, but they still have much higher latencies. They also have massive prover costs. So I kind of have my doubts that they would currently get, say, majority from the score. Like, say, oh, it's okay to just rely on them to know whether l one blocks are valid.
01:10:15.704 - 01:11:07.890, Speaker A: So, so far, I think we still need worker trees. Got it. Any other questions on vertical trees? Okay. Anything else anyone wanted to bring up? Okay, well, yeah, then I guess we can wrap up. So we'll move the self destruct eip to CFI. And I think, yeah, if in the next couple of weeks people can review the stuff around EOF, the 4788 and the other beacon state proposals and look at SSZ as well. We can continue those conversations on the next call.
01:11:07.890 - 01:11:36.102, Speaker A: And the next call, I believe, will be right after Chappella. So, yeah, last time. I guess this is a time for users to upgrade and we'll go over how the fork went on the next one of these. Yeah, I guess we can wrap up. Thanks, everyone, and see you on the Cl call next week. Thank you. Bye.
01:11:36.102 - 01:11:36.890, Speaker A: Thank you.
01:11:37.040 - 01:11:37.942, Speaker F: Bye bye.
01:11:38.086 - 01:11:40.090, Speaker B: Thank you. Bye.

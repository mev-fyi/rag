00:00:00.730 - 00:00:44.620, Speaker A: Welcome to another roll call breakout call. Today we have a very interesting episode. We have Justin Drake here to host and lead the call on basically all things shared sequencing, pre confirmations based roll ups, basically this entire PA call theme complex that he's been thinking about quite extensively. I'm very much looking forward to that. And I'll just mean, I don't think I have to introduce Justin much. He's one of our star researchers at the Ethereum foundation, has been doing a lot of work in this in the past and. Yeah, Justin, do you just want to take it from here?
00:00:50.180 - 00:01:33.950, Speaker B: Yes, thank you Anzgar. So yeah, today we have a lot of time, an hour and a half. So I hope to make it very interactive. This talk is really for the roll ups. So Ethereum sequencing and shared sequencing more generally is all about roll ups, opting in to some sort of shared sequencer. And I think there's a bunch of technical issues that we can discuss, but I think the bulk of it is actually an education and a coordination and an incentives problem, more so than a technical one. So I hope to go through a lot of content and please interrupt me as the presentation goes along.
00:01:36.640 - 00:01:46.036, Speaker A: Just maybe if we can wait a few more seconds, because someone just mentioned that the zoom link was never actually shared in the telegram group. I just did that. But it could be that a few people might need a few seconds to see that and.
00:01:46.058 - 00:01:51.110, Speaker B: Come on. Okay, perfect. Let me know when it's good to get started.
00:02:03.480 - 00:02:05.830, Speaker A: Yeah, you can probably go ahead.
00:02:06.620 - 00:02:38.032, Speaker B: Okay, perfect. Thank you Anskar. So the talk will be split into three parts. First I'll talk about shared sequencing generally, and in my opinion, the killer feature of shared sequencing, which is synchronous composability. And then I'll talk about pre confirmations specifically because I think pre confirmations is a feature that every single roll app wants. It's a feature that users demand. And there's a question of how do we do preconfirmations in a decentralized setting as opposed to having a centralized sequencer.
00:02:38.032 - 00:03:48.890, Speaker B: And then finally I'm going to talk about base sequencing, which is a special type of sequencer, which also has these decentralized pre confirmations. So one of my, I guess, visions is that we have these united chains of ethereums, similar to a union of states like the United States, where there's freedom of movement and freedom of commerce. I'm hoping that on ethereum we're going to have this diversity of chains of roll ups and validiums, but the friction from moving from one to another, the friction of doing business with one another is extremely low. I think in order to achieve that we need shared sequencing. So what is the killer feature of shared sequencing? In my opinion, it's this idea of synchronous composability. So right now what we have is independent roll ups that are siloed. And what I want you to think about is basically time progressing from top to bottom.
00:03:48.890 - 00:04:58.524, Speaker B: So execution roll up a is siloed from execution roll up b, which is siloed from execution in roll up c. And one of the things that shared sequencing allows is for synchronous composability, meaning that for some period of time you actually have the roll ups be synced with each other. You can think of it as locking from the perspective of state. Basically, if a user finds it valuable to have synchronous composition across multiple roll ups, what I call a super transaction, then they have the option to pay for that privilege. And the shared sequencer who has monopoly power to build blocks for all the roll ups in parallel, can actually fulfill this demand from the user. And so in some sense, shared sequencing is about going from asynchronous composition to synchronous composition and kind of capturing this delta of value creation in the process. And the synchronous composition doesn't have to happen at the very top of the block.
00:04:58.524 - 00:05:45.600, Speaker B: It could happen midway through the block. And it doesn't have to be something that is permanently happening. And actually almost by necessity, we can't have every single roll up locking on every single other roll up. Otherwise we would only have the scalability of a single roll up. So what I expect will happen is that the vast majority of the time the transactions will consume resources in one single roll up. Everything will be processed in a purely parallel way. But then every once in a while, when there's some sort of an economic opportunity that mandates that there's actually additional value to synchronous composition, then there's going to be these virtual locks that are basically placed by the shared sequencer on these executions.
00:05:45.600 - 00:06:39.104, Speaker B: So if we zoom in to this little section of the diagram, so we have the two roll ups roll up a and roll up b. What do I mean by synchronous composition? So I'll basically give an example. Imagine a supertransaction which is made of three subtransactions. So you have a subtransaction a, which kind of starts the super transaction, and then you have this middle subtransaction on roll up b, and then you have this final transaction subtransaction on roll up a. And the important feature here is that there's these strong synchronous relationships between these subtransactions. So for example, you could have a withdrawal of asset here from a to b. You could have a withdrawal of asset from b to a here.
00:06:39.104 - 00:07:28.476, Speaker B: You could also have some action here on roll up a, which depends on the result of a call on roller b. So for example here you could be reading some state on roller b. And then you're basically passing some sort of state route to roll up a. And then depending on what's happening here, you do an action here. And one of the things to notice here is that in order to have these synchronous kind of calls between roll ups in a totally trustless way, meaning that roll up a shouldn't be able to trust b and roller b shouldn't need to trust roller a, you basically need ZK proofs. So this subtransaction here produces some sort of proof. It's settled immediately, there's a withdrawal.
00:07:28.476 - 00:08:01.470, Speaker B: And then same thing here. When this subtransaction here executes, there's a corresponding ZK proof that allows for this withdrawal to happen immediately. Or if you're reading data, same thing. It happens immediately. And then now they can have an action that depends on this data. And once you have this kind of really luxurious setting of synchronous composability, which we enjoy today at layer one, right, any contract can synchronously call any other contract. Then in my opinion, you're unlocking value.
00:08:01.470 - 00:08:42.516, Speaker B: So yeah, feel free to stop me at any point in time if something is confusing. Now one of the things that we need to ask ourselves is around these zero knowledge proofs that I talked about. It takes time to produce zero knowledge proofs. And so let's look at a specific example. Let's say that we want to do synchronous composability within these three roll ups at the very top of the block. So this, it turns out to be the simplest case. And the reason is that, let's say the shared sequencer has 12 seconds.
00:08:42.516 - 00:09:12.944, Speaker B: That's the slot duration. It doesn't have to be 12 seconds, but let's assume it's 12 seconds. Well, the computation here, let's say, takes 1 second. Well, basically you have 11 seconds to produce the proof for settlement. I mean all the zero knowledge proof for settlement. So here you have quite a lot of time to produce the zero knowledge proof. But on the other hand, here at the very bottom.
00:09:12.944 - 00:09:58.690, Speaker B: If you want to do synchronous composability, like, very, very close to the end of your slot, then you have almost no time to produce the snark proof. And so what I expect will happen is that initially, the synchronous composability will be kind of more towards the top of the slot. But then as we get faster and faster, proving it will unlock value towards the end of the slot. Like, notice that the colored execution, which kind of doesn't depend on execution from other roll ups, it's okay for the proof to come in the next slot. It doesn't have to come in immediately in the current slot. Now, one of the things I want to highlight is that I'm extremely bullish about low latency proofing. I think that within the next two, three years.
00:09:58.690 - 00:10:21.290, Speaker B: Go ahead. Can I interrupt and ask? Yes, for sure. Yes. Why it doesn't have to come in that slot. Right, sorry. I need to configure my zoom so I can see if he's asking a question. But why doesn't it have to come in that slot? So the reason is that just like today, you basically have a decoupling of.
00:10:21.290 - 00:11:18.120, Speaker B: You can have a decoupling of the data and the proof. So you can post the data on chain, and then settlement can be delayed. Some number of slots. And basically, if you have a roll up, which is progressing independently, meaning that the execution doesn't depend on inputs from other roll ups, then it's actually okay for this settlement to be delayed because it's just like the same situation as today, where you can put the data and then you can prove it later on. Yeah, thanks. But as soon as you start depending, basically, you're adding these dependencies between roll ups. Well, if you want things to stay trustless and you don't want to do, like, these massive reorgs and rollbacks, then you need this real time proving to keep the trustlessness.
00:11:18.120 - 00:12:07.684, Speaker B: I have one more question on this trust. So if we have Holly A and Holly B that has this cross transaction, but call up a did not finalize the blue blocks because one of the previous block is invalid. And this we will learn like, a while after the block is produced, because the finality in the rollup is not instantaneous, it means that the block is reverted. So for Holly B, we will have a dependency on Holly A for its own finalization. Right. So that's a good point. You need basically fast settlement.
00:12:07.684 - 00:13:13.272, Speaker B: So what I'm claiming is that either you need real time settlement, meaning that you have settlement in the current block, or you can delay it to the next block. So, basically, if you're the shared sequencer in slot n, then you can mandate that the shared sequencer in slot n plus one needs to provide the proofs for the execution that hasn't been proved in slot n. But yeah, you're right, we don't want to be building on top of unsettled roll up execution. And so at most, you want the proof to be delayed by one slot. But one slot today seems like very short, right, because these zero knowledge roll ups sometimes take minutes or sometimes hours to produce a proof, but we're getting that at a very fast pace. So I guess there's two types of real time proving. There's real time proving on the order of one slot, and then there's like the super fast real time proving on the order of milliseconds.
00:13:13.272 - 00:14:17.510, Speaker B: And I think we're going to see this first type of proving happen relatively quickly, like maybe this year even. Okay, thank you. Now, why are there reasons to be optimistic about real time proving? One of them for me is this notion of folding schemes. So Nova, which is a paper published in 2021 and it was largely ignored for a couple of years, is kind of in some sense a revolution, in my opinion, because it allows for maximally parallel and maximally efficient snark proving. And it kind of led to this whole class of literature around folding schemes. And in my opinion today, if you're working with elliptic curves, then it's almost a no brainer. If you're starting from a fresh code base, it's almost a no brainer to start with folding schemes, given how mature they are and how efficient they are.
00:14:17.510 - 00:15:13.716, Speaker B: They seem to be efficient not just as a dottedly, but down to the constant. So basically, roughly speaking, the prover cost is one msm of the size of your statement. That's it, just one MSM. So the constant is one, you can't improve it, and there's no ffts, and it's a really nice proving scheme. And then the other reason to be kind of bullish on low latency proving is that we're starting to finally see proving asics. So the first one was released this year, this month actually by axial, but there's two other teams, Scisik and Fabric, that are also working on AsiCs, that should come this year. So basically, what these AsiCs will unlock is this really super low latency, like 100 milliseconds or less.
00:15:13.716 - 00:15:38.028, Speaker B: And so you can have synchronous composability very, very close to the end of the slot here. Okay. Part two. Unless there are questions regarding part one. So, yeah, I have a question. For 100 milliseconds, you mentioned per block or per transactions or per super transactions. Yeah.
00:15:38.028 - 00:16:48.756, Speaker B: So, basically what I expect will happen is that these proving schemes will operate on the order of one cycle or one opcode, like some very small amount of computation, and then basically use this recursive technique to process one cycle at a time. And what we need is that the proving latency is on the order of 100 milliseconds. So the proving will happen in real time. So as the sequencer kind of chooses which transactions to sequence, as execution happens, basically, and sequencing happens in parallel, the proving also happens. So, actually, as a consequence of this, I think it's relatively likely that we're going to see a merging of the sequencer and the prover, so that you have minimal latency between these two things. And what you want is the proof system to have very low latency. So, from a throughput perspective, obviously, you need to have the proving capacity to prove 12 seconds worth of execution within 12 seconds, like every single roll up does that.
00:16:48.756 - 00:17:08.010, Speaker B: Otherwise the prover would stop falling behind. But now that we can catch up in terms of throughput, we need to kind of optimize latency. And I think there's already, like, massive strides that are being done on that front, but I'm expecting way more in the months and years to come.
00:17:09.920 - 00:17:10.670, Speaker C: Thanks.
00:17:18.960 - 00:17:32.000, Speaker B: Okay, great. Now, one of the open problems a couple of years ago was, how do we decentralize pre confirmations? Oh, Mohammed, do you want to ask a question?
00:17:32.070 - 00:18:00.910, Speaker D: Sorry, I was wondering, why do you need these proofs really real time? Like, suppose you have a super transaction, and it calls into the other roll up and it expects something back. Why we can't provide this intermediate state or value of the callback or whatever, optimistically, and only at the end of the whole slot, we prove the whole thing.
00:18:02.080 - 00:18:59.870, Speaker B: Yeah, so, a few things here. One of them is that you do want to provide one proof at the very end. Just because imagine that you're processing thousands of transactions per second, you don't want to have 10 notch proof every time you make a deposit and withdrawal. So what I expect will happen is that for each roll up, there's going to be one proof, and it's going to be an aggregation of all the subproofs that you need in order to have all the execution. And from a computational standpoint, this proof will arrive at the end of the slot. But what the sequencer can do is that they can basically stuff it at the very beginning. So once they've computed it and they build the actual block that goes on chain, they put it at the very beginning and they verify it at first.
00:18:59.870 - 00:19:36.250, Speaker B: So upfront they kind of make a claim that this execution is correct, kind of prestate one, post state one, presate two, postate two, pre state three, postate three. So it's a proof about all these prestate and pro states, one per roll up, and then nothing has to happen optimistically, because it's all kind of proven up front. So does that answer your question?
00:19:37.980 - 00:20:18.280, Speaker D: Yeah, it's kind of answered, but basically I was wondering, the way I understood your scheme is that when a super transaction happens, we are going to have this micro snark proofs that assured you about what happened on the other roll up. Yes, exactly. So the green Arrow back, I expect, is carrying a snark proof. Yeah, I was wondering why this is necessary. Yeah, I understand if you want to be really real time, like doing execution and proving at the same time this is what you want, especially with Nova unfolding.
00:20:18.780 - 00:20:56.176, Speaker B: Yeah, so the sequencer has full control over what the sequence will be for roll ups a, B and C. So you're right, they can work optimistically because they trust themselves. Right. Let's say that the proof latency is 2 seconds. Well, then for 2 seconds they're kind of going to optimistically sequence things without a zero knowledge proof. And then the zero knowledge proof only comes at the variant. But if the latency is, let's say, 2 seconds, what it means is that in these last 2 seconds, there can't be any synchronous transactions.
00:20:56.176 - 00:21:24.348, Speaker B: Like the synchronous transactions have to be in the first 10 seconds. Great. You have the thumbs up, which means that you're liking this answer. Makes sense, I guess. One thing that I'll mention, which is really cool here, is that we're actually using mev to incentivize low latency proving. Right. Because one of the problems that ZK Rob have is like, how do we incentivize proving? And the really cool thing here is that sometimes you have to do nothing.
00:21:24.348 - 00:21:44.180, Speaker B: Like, Mev does the job for you, because the faster you are, the less latency you have, the more synchronous composability you are going to be able to sell to users. And so that's kind of a nice property to have Lisa.
00:21:46.840 - 00:21:56.020, Speaker E: Understood if this shared block will happen at the same time, each slot, or it's kind of on demand.
00:21:58.620 - 00:22:44.096, Speaker B: Yeah. So it's on demand. And what I expect will happen is, because there is an overhead to locking, the user kind of has to explicitly opt in to pay for it, or it can happen implicitly if you have an arbitrage or whatever. Now, one of the things that's interesting is how much do we expect users to have to pay? So let's say that here, while this transaction on roll up a is executing, you see nothing's happening in roller B. It's like this black stuff. So roller B is basically blocking on roll up a, and here, vice versa, you have this transaction happening on roller b, and roll up a is just twiddling its funds. It just is waiting.
00:22:44.096 - 00:23:28.230, Speaker B: It can't progress. And so what will happen is that, let's say this corresponds to 100,000 gas, and this also corresponds to 100,000 gas. Then, at a minimum, the user will have to pay 100,000 gas on roll up b and 100,000 gas on roll up a. So basically pay on both of them simultaneously, plus potential overhead for even just creating the lock in the first place. And so, economically speaking, if you're going to be consuming resources on multiple roll ups at the same time, you're going to have to pay for it. And if there's this blocking aspect, then, yeah, you're definitely going to have to pay for it.
00:23:30.440 - 00:23:40.804, Speaker E: How then do roll ups communicate with each other on agreeing that this is the right moment for a super block?
00:23:40.932 - 00:24:18.900, Speaker B: So the roll ups are not in control of sequencing, the roll ups are in control of execution, and they're basically delegating sequencing to some shared sequencer, and the shared sequencer for their slot. They have monopoly power to do whatever they want, and what they're going to do, in my opinion, is they're going to act rationally, and so they're going to try and sequence blocks in such a way that they maximize the value of the block, and they're going to use signals from users saying, I have such and such intent, and I'm willing to pay for it. And so they will honor these intents if that maximizes the value of the block.
00:24:19.480 - 00:24:25.670, Speaker F: But presumably they're maximizing their own revenue, not the value of the block, right?
00:24:28.620 - 00:24:45.230, Speaker B: Yes, they're maximizing their own revenue, but there's a very strong correlation between these two things. But, yeah, happy to have this discussion offline, for sure. Got freed. Sorry, Andreas, you had your hand earlier. Sorry.
00:24:46.160 - 00:25:00.992, Speaker G: Thank you. Appreciate that. Really quickly. So when you lock, let's say, on the super transaction, and b locks a. Right, so then a has an opportunity cost of like up to 10 seconds. Correct. Right.
00:25:00.992 - 00:25:32.110, Speaker G: Because if you allow a to process any other transaction, one of those transactions might modify the target state of the super transaction, which can't be because I need to rely as an issuer of a super transaction that my target state is not modified. Isn't that correct?
00:25:33.360 - 00:25:36.270, Speaker B: I didn't completely understand the question.
00:25:38.960 - 00:25:48.960, Speaker G: Let's say I see an arbitrage opportunity on uniswap. On arbitram, right?
00:25:49.110 - 00:25:49.810, Speaker B: Yeah.
00:25:50.420 - 00:25:55.540, Speaker G: And I'm on DK sync. Right. Let's make it really concrete.
00:25:55.960 - 00:25:58.484, Speaker B: Arbitrum and base. Yes.
00:25:58.602 - 00:26:13.064, Speaker G: Arbitrary and base, whatever. Yeah. I want to put a swap on arbitrum with my funds from base. Right.
00:26:13.262 - 00:26:14.010, Speaker B: Okay.
00:26:16.140 - 00:27:38.544, Speaker G: So I submit that transaction with a commitment that it's going to be executed against the current state of the uniswap liquidity pool at that point in time, because I'm like buying now, that means that arbitrum needs to identify all the transactions that are going against that liquidity pool during the locking period and put them after that super transaction, because the super transaction paid for or is paying for the privilege of having locked target state. If that target state is modified by a transaction that happens during that lock period, then the user with the super transaction. So me wanting to do the swap on uniswap gets the worst price. So you're basically, you can do sandwiching attacks and front running attack. Right. If you see that, because you have a shared mempool at that point. So that gets really tricky.
00:27:38.544 - 00:28:01.720, Speaker G: So you have to basically lock down the roll up for the super transaction for that period of time, or they must be able to identify the transaction that are coming in that target, the target state. Otherwise you're basically telling the issuer of the super transaction, why have you paid for it? Tough luck.
00:28:02.400 - 00:28:46.280, Speaker B: Okay, so I still didn't completely understand the question, but let me try and say something that hopefully is helpful, and maybe we can talk about this more offline. One of the things I'll say is that, yes, there is some sort of shared mempool, but that doesn't have to be a public mempool. So just like today, when you have a centralized sequencer, there's no public mempool. Right. The user and the shared sequencer are communicating directly with end to end encryption, and no one sees the transaction. And actually as a service, the centralized sequencers provide the mev protection. And so one way that you can kind of replicate this, well, the end to end encryption with the sequencer is very easy.
00:28:46.280 - 00:29:20.372, Speaker B: Right. Because we're going to know who the shared sequencer is. And so there's going to be an IP address that you can call as a user, as a wallet. The other thing I'll mention is that you can use account abstraction to make sure that your intent is properly expressed. So let's say you have a super transaction which involves three legs. Leg one on roll up a, leg two on roll up b, leg three on roll up a again. And you might want these three things to happen either altogether or none of them.
00:29:20.372 - 00:30:14.480, Speaker B: So basically you're creating some sort of super bundle. That's the kind of thing that you want to constrain as a requirement so that you don't get unbundled. And one of the things that's really cool is this idea from polygon called the aggregation layer, where you can do exactly that. Yeah, another thing I'll say is that this super transaction should execute extremely quickly, right on the order of microseconds, because each constituent transaction takes just a few. So there shouldn't be like multiple seconds of opportunity cost. But yeah, more than. Happy to continue this discussion offline, Godfrey.
00:30:14.640 - 00:31:00.500, Speaker D: Yeah, maybe it's a stupid question, but there is one thing that I'm wondering. I mean, in Ethereum, basically, where we have synchronous calls, we have everything is on a single state, basically, and we have the opportunity to roll back in case of error. Here, if you imagine the situation like one year on the slides, where basically roll up a does something, passes approval to roll up b, roll up b does something, depending on whatever the proof says. Then there's a proof going back from roll up b to roll up a. But now imagine that in the third transaction on roll up a here, there is some kind of error happening which would necessitate basically undoing whatever happens on roll up b. Is there any way that this can be sort of achieved without basically enshrining some kind of chain rollbacks, right?
00:31:00.570 - 00:31:56.390, Speaker B: So as I said, with the polygon aggregation layer, you can basically have these three subtransactions either all execute or the whole thing is invalid. Like each of these three are invalid. Now, if, let's say the super transaction is invalid because the last leg happened to be garbage, then the sequencer is just paying for the data to get these three subtransactions on chain, but it's not getting paid for anything because it will just be rolled back. And so really what the shared sequencer should be doing is that at the execution and sequencing level, they should build these optimal blocks and potentially reverting whenever the transaction fails. But then once it's made a decision, I'm actually going to sequence this. And I have confidence that it's a value transaction, it's fee paying. Then at that point does the proving process start.
00:31:56.390 - 00:32:31.570, Speaker B: And again, you don't need the proofs to come in real time here. The proof basically needs to come by the time the block is published for settlement. So from a time perspective, it only needs to be generated towards the end of the slot here. Calmen. So just to make sure, we are trying to enforce synchronicity on the protocol level and not just the economic builder level. Right. Only the economic sequencer and builder level, not at.
00:32:31.570 - 00:32:55.480, Speaker B: Okay, thank you. So each roll up in some sense is just the same as it is today. The roll apps don't have to do at least the ZK roll ups. They don't have to do that much. They stay sovereign and independent. There's no polluting of security assumptions. If roll up a blows up and then the hacker withdraws everything, then roll at b is completely isolated.
00:32:55.480 - 00:33:44.020, Speaker B: These are like totally trustless relationships. Okay, decentralized pre confirmations. So it's saying that, yeah, two years ago I would have said this is an open problem, but in some sense there's this obvious solution, which makes sense. So the obvious solution is, let's imagine that we have a decentralized sequencer. What is the definition of a decentralized sequencer? It's one where at every slot you have some sort of rotation of who's doing the sequencing. So in a centralized sequencer, it's the same entity, every single slot doing the shared sequencing. Decentralized sequencer, just like at Ethereum, layer one, you have a rotation of the layer one proposer.
00:33:44.020 - 00:34:27.380, Speaker B: Here you have a rotation of who's doing the sequencing. But in any given slot, it's the exact same situation. There's one single well defined actor who has monopoly power to do the sequencing. And so in some sense, it's the same situation as a shared sequencer within those 12 seconds. And so what a user can do is that they could say, okay, please pre confirm my transaction and sequence it. And then whoever the shared sequencer is for this lot n, well, they can make a promise that they will execute this transaction at specific position. And I use the emoji 1234 here because it's kind of ordering the transactions.
00:34:27.380 - 00:35:48.380, Speaker B: And you have this look ahead here, which means that you know who will be the shared sequencer at any given future slot. But really you only need a look ahead of one slot, right, because the user slot n only needs to know who the shared sequencer slot n is in order to make this request and get a pre confirmation promise. Now, the way that shed sequencing is, sorry, pre confirmations is done today, is using reputation as collateral. So you might have some sort of entity, some sort of labs, maybe the team that built the roll up initially, that has a lot of reputation at stake. Arguably, their reputation is worth hundreds of millions, if not billions of dollars, because if they were to start rugging users, then all their users would leave and the value of their token would go down. But in a decentralized sequencer, you don't have entities with reputation, and so you kind of have to use direct economic incentives with slashing. So basically the deal is that if as a shared sequencer, I provide a pre confirmation, a promise of a pre confirmation, and the user is not happy because their pre confirmation was not honored, then there's going to lead to slashing.
00:35:48.380 - 00:36:27.660, Speaker B: And there's two types of slashing faults. One is a safety fault, meaning that as the shared sequencer, I promised to sequence a transaction, but instead I sequenced another one. So it's like completely different. What actually happened is completely different to what I promised. And then there's this more subtle edge case fault, which is a liveness fault, where the sequencer made a promise, but then when it was time for them to honor their promise and to actually build a block, they went offline. So they got really unlucky. Within the few seconds that they had this responsibility, they kind of went offline.
00:36:27.660 - 00:37:16.664, Speaker B: And here they also have to suffer a penalty. But that's more of an edge case. Then this first one should never happen. The safety fault should never happen if you have an honest shared sequencer and pre confirmer. Now, if you have one entity who has monopoly power over one slot, like a very natural economic outcome is for whoever has monopoly power to maximize the value of that slot. And that leads to MeV boost and PBS being one of, I think, in my opinion, like the most natural outcome. But various other people might disagree.
00:37:16.664 - 00:38:19.436, Speaker B: But I'd like to keep that for a separate discussion in terms of, okay, how do we modify mefboost to make it work with pre confirmation? So the way that mefboost works today is that we have blocks kind of traveling in one direction. So the builders build the blocks, they give them to relays, and then the relays relay those blocks to the proposer. But now we have this new entity in the picture, we have the user, and the user has received promises from the proposer, and really we want the blocks to respect these constraints from the users. And so what needs to happen is that these promises need to travel all the way from the user to the builders through the relays. And so what I expect will happen is that, sorry, this should say shared sequencer, not proposer. What will happen is that the shared sequencer really should be communicating every single promise that they make to the. To the relays and to the builders.
00:38:19.436 - 00:39:12.860, Speaker B: And then at the end of their slot, they basically ask the builders, given all these constraints, build me the most valuable block possible. So it's possible that at the very end there's some back running or something that extracts a little bit of mev. And the builders are the most natural players to do that. And you just need to modify Mev boost a little bit. So again, there's no need for any enshrining or hard forks or anything. You just need to do a simple modification to mefboost so that builders can be aware of these pre confirmations and build blocks that adhere to them. One kind of detail here is that if the sequencer is collateralized, let's say they have 1000 ef of collateral that will back the pre confirmations.
00:39:12.860 - 00:40:06.100, Speaker B: Well, the builders also need to be equally collateralized. And the reason is that the builders might build a block that doesn't respect these pre confirmations, and the sequencer will get slashed. And now the sequencer needs to get compensated by the builder because it's not their fault. And so the builder would also get slashed, but the slashing, the collateral would go to the proposer. And when the sequencer gets slashed, there's two possible things. Either you can just completely destroy the collateral, or you can have more of an insurance mechanism where you give it back to the users that were affected by these violated pre confirmations. Okay, so this is kind of my summary slide on centralized versus decentralized pre confirmations.
00:40:06.100 - 00:41:08.330, Speaker B: The big difference is that with a decentralized sequencer, you have this rotating sequencer on a slot by slot basis. The slashing is reputational for centralized sequences, and I think it will become like purely financial in a decentralized setting. And then kind of one thing that kind of changes pretty dramatically is how MeV is handled. So right now, we basically have an encrypted mempool, which is potentially first come, first serve. And because you can rely on reputation, you can have these policies that are enforced. But when you move to a decentralized setting, it's possible that these policies can't be enforced so cleanly. And so you fall back to PBS, at least as one of the options here which ends part two.
00:41:08.330 - 00:41:12.490, Speaker B: Any questions?
00:41:17.420 - 00:41:35.600, Speaker F: Just could you clarify, what is the promise that a pre confirmation is making to the user? Is it a promise that their transaction will be in an l proposed block, or is it a promise that their transaction will be in the canonical l two chain?
00:41:36.660 - 00:42:22.440, Speaker B: Right. So the sequencer has full control over the contents of the block, and so they can give the strongest possible promises available, which is a promise on an exact state route. So basically, I will execute your transaction, and when your transaction executes, this is the post state route. Of course, the user might not need such a strong pre confirmation. They might only need some sort of intent to be satisfied. So, for example, they want to know what the they might place some sort of limit order. Like I'm willing to pay x for this swap and I'm willing to pay y for fees.
00:42:22.440 - 00:42:48.650, Speaker B: And so long as you can satisfy this intent, then I'll be happy. Some users might have something even weaker, which is, as you said, just inclusion. Like if I'm doing a transfer, let's say a simple transfer of eth from a to b, then I care about getting the green check mark on my wallet, but I don't care what the post date route is, because my transaction is totally independent from all other transactions. Sure.
00:42:50.460 - 00:42:59.444, Speaker F: Could I clarify the question? The question really is, how can an l one proposer guarantee inclusion in the l two chain?
00:42:59.492 - 00:43:00.090, Speaker B: Right?
00:43:02.060 - 00:43:09.980, Speaker F: What if their l one block that they propose, which is consistent with their promises, turns out not to be canonical on the l one chain?
00:43:10.720 - 00:43:41.892, Speaker B: Okay, so at this point in time, there's no l one. At this point in time, we talk about shared sequencing, and it's like some abstract virtual shared sequencer. There's not l one, like the l one comes in in part three, where we talk about base sequencing. But the way that it works is that basically every roll up has opted in to give sequencing rights to this shared sequencer. And so by construction, they have monetary.
00:43:41.956 - 00:43:47.880, Speaker F: Power to the individual proposer has the power to make a black canonical.
00:43:48.940 - 00:44:06.560, Speaker B: Yes, I apologize. It should not say proposer, it should say sequencer. So whatever the sequencer is, whatever black box the rollups have opted into for sequencing, that entity here has malapoli power to sequence.
00:44:07.460 - 00:44:21.844, Speaker F: I see. So there's some kind of consensus protocol wrapped around this, and the individual proposer promises that that consensus protocol will reach consensus on a block that contains this user's result.
00:44:22.042 - 00:44:46.940, Speaker B: Yes, again, I apologize for putting the word proposer here. It should really say sequencer. There's no proposal. Forget proposers. This is a typo. The proposals come in in part three. So, imagine it's a sequencer, like all the roll ups have given through their settlement contract, the priority access for the sequencer to sequence transactions.
00:44:46.940 - 00:44:55.068, Speaker B: And therefore, that entity has multiple power. And therefore, they can give pre confirmations of the strongest form possible, which is pre confirmations on execution.
00:44:55.244 - 00:45:06.420, Speaker F: But if you have these rotating proposers or rotating entities, how can one of those entity make a promise that anything will be canonical in the consensus?
00:45:09.080 - 00:46:08.376, Speaker B: Right? Well, okay, one of the things that they can do is they can give pre confirmations that are conditional on some sort of parent. So that's one possible outcome. Another possible outcome is that there's some sort of single slot finality, fancy consensus. And this is what espresso was building initially, where you have this off chain consensus with ultra fast finality. And so I, as a sequencer for slot n, I have very strong confidence that slot n minus one will be canonical, because it's been finalized in very low latency. These two approaches are kind of complementary. So you want fast finality, because that gives you more confidence on what the parent is.
00:46:08.376 - 00:46:57.690, Speaker B: But you also, as a sequencer, only want to give pre confirmations on the things that you have power over, like, you don't have power over what is canonical. And so the pre confirmations can be conditional on the parent. Now, if you look at things in practice, you can design consensus algorithms that, where you have very strong confidence on what the parent is, meaning that very high probability there won't be a reorg. And so there's basically two cases like the case. A, the happy case will happen 99% of the time, and the user will be completely happy. And then the 1% of the case, something weird happened. There was a reorg or miss slot, or high latency, or whatever.
00:46:57.690 - 00:48:01.720, Speaker B: And one of the services that the sequencer can provide is basically insurance against this 1% edge case. And so, for example, let's say the user wants to trade on Uniswap, and they want to know exactly how much they're paying, both in terms of execution price and in terms of fees. And they'll get that for 99% of the time. And in the 1% of the time where there was some strange event, a reorg, for example, the sequencer can basically provide a second pre confirmation on this other event, where it says, I will actually guarantee you the same price. And if there's a delta between the two, I will pay it out of pocket. So I think from a UX perspective, it would be a bad outcome if every time you ask for pre confirmation, there's these two cases. Like case one is, the parent block is counter nicole, and case two, the parent block kind of got reorganged and it's an empty slot.
00:48:01.720 - 00:49:13.680, Speaker B: And the good news is, because one of the events happens 99% of the time and the other one only happens 1% of the time, you can kind of abstract away this edge case with insurance. But one of the things I'll say here is that these are the kind of problems that need to be solved regardless of the shared sequencer. Now, I have a very specific thesis, which is that we should consider using the l one as the shared sequencer in some sense. All of these details around pre confirmations are details, implementation details, that are orthogonal to the broader thesis, I guess, of base sequencing. Connor, you have your hand up. In this case specifically, I guess there won't be any value to capture for the builders in the shared sequencer case. So, yeah, I don't really see why you need the proposer aside, why they need the builder or the relay.
00:49:13.680 - 00:50:23.592, Speaker B: Right, I see. So basically what you're saying is that if transactions are kind of handled almost first come, first serve, like they're kind of pre confirmed in real time, then there's very little relevance for the builders, and that might be the case. I guess one of the possibilities is that the promises that are made are kind of these weak and fluid promises. So, for example, I promise you a certain price, but I don't promise you a certain position in the block. And so there could still be opportunities for builders to reorder things and do some back running and do some arbitrage or whatever it is, in order to just squeeze out a little bit of drop of mev. But you're right, like, maybe this is not worth it and we can just radically simplify and just remove the relays and remove the builders and only be left with this sequencer. Sorry, you're moving to intense based shared sequencers, is what you're saying? Yes.
00:50:23.592 - 00:50:55.760, Speaker B: No, sorry, I said jokes. I think intense. Yeah, makes sense, actually. One thing I'll say here is that if you're providing promises on execution with a post state route, then this is extremely non scalable. And the reason is that the user comes in with the requests. It requests a specific postdate route and that's blocking. So if it takes 100 milliseconds just for the communication between the user and the sequencer, then you can only process one transaction every 100 milliseconds.
00:50:55.760 - 00:51:24.830, Speaker B: Which is really bad. And so at a minimum, you want access lists, right? So that every user only cares about the little piece of state that they read and write to. But you can do even better where sometimes you don't care about the exact value of the state, you only care about some abstract intent being satisfied. Payment.
00:51:25.440 - 00:51:57.936, Speaker H: Hey, could you please go to the next slide? Yes, in this one, in the MEV one I'm pretty confused about, because like you mentioned that for centralized sequencing we have encryption, and for decentralized one, we don't need encryption and PBS works. But to me they are not really exclusive. They solve different problems with encryption, we have execution, privacy, and PBS can work for both of them. Just wanted to hear your thoughts.
00:51:57.968 - 00:52:41.780, Speaker B: Okay, let me clarify. You're right, this is sloppy. So in both cases, the user is dealing with a well defined entity for that one slot, and they can use SSL to have end to end communication. So I guess SSL should be there in both cases. But the real difference is in terms of incentives. So for example, the centralized sequences, off chain labs or something, they don't want to be rugging their users, they don't want to be sandwiching them, they don't want to be exploiting them. And so they've just decided as a policy that they won't be extracting this type of toxic meV.
00:52:41.780 - 00:53:46.490, Speaker B: But in a decentralized setting, it's much, much harder to enforce that. What tends to happen in decentralized settings is that you have these much more locally rational actors. That in this one slot I want to maximize as much as possible because I only get selected once every few months, for example, and I want to make the most of the slot that I just won. So in some sense, we're playing different games. In the centralized case, it's a repeated game because every single slot is the same entity, and there's these indirect incentives with billions of dollars of tokens, whereas here in the decentralized setting, you can analyze the incentives on a microeconomic level as opposed to a macroeconomic level. And as far as I can tell, if you want to maximize the value of your block, then you're going to invoke PBS in some way or another.
00:53:48.220 - 00:54:32.712, Speaker H: Yeah, I guess my confusion was, like you mentioned, encryption is for centralized and the other one is for decentralized. But in centralized one, as long as you are putting your trust in arbitram sequencer, you don't need probably encryption with PBS, but in decentralized setting, you can have encryption for preventing toxic MEV because just PBS doesn't prevent and having top of block actions for good arbitrage and good meV. So basically both of them are for decentralized setting and for centralized. You can have some kind of separation for the powers of the centralized sequencer. But it's not like necessarily the need, right?
00:54:32.846 - 00:55:19.110, Speaker B: I mean, the MEV protection here is provided using trust and reputation. And if you want the same kind of safety, then yeah, you might want a system where the sequencer never sees the plain text of the transaction until after they've done the sequencing. So you can have a threshold decryption or delay decryption or based decryption or whatever it is. Yeah, totally agreed here. But again, this is a problem with decentralized sequencing in general. In some sense it's not my problem, even though I am happy to help solve it. Any decentralized sequencer, as far as I can tell, has this issue.
00:55:19.110 - 00:55:23.140, Speaker B: Lynn?
00:55:24.120 - 00:55:48.688, Speaker C: Yeah, I have a question about the safety fault. You, I can see that you can slash when you promise to be in the third slot of a block and you can slash that. But what happens when a pre confirm lies about the state? Like how do you slash that on chain? Do you require some on chain fraud proof or.
00:55:48.854 - 00:55:49.570, Speaker G: Yeah.
00:55:52.180 - 00:56:09.320, Speaker B: Even for the promise that the position is number three, you still need some sort of on chain foolproof. So basically what will happen is that when the user receives a promise, they receive a cryptographically signed receipt, and then the receipt is the fraud proof that they submit on chain.
00:56:10.060 - 00:56:28.620, Speaker C: Yes, but for state, you actually need knowledge about the VM to actually verify the fraud proof. So it sounds like for every single vm, for every roll up, you need a fraud proof system for them. And it sounds like pretty complex things to implement.
00:56:31.280 - 00:57:18.472, Speaker B: So, no, the fraud proof Inc. And the pre confirmation collateral can be separate. So you could have n roll ups that have each opted into a shared sequencer, and then you have this additional contract for pre confirmation specifically. And this contract can read state routes that are settled. So let's say that the promise was that this state route is x on roll up a, and then it turns out that roll up a settled state route Y. Then now the user can submit on chain a receipt, which is cryptographically signed by the sequencer, saying that he promised that the state route on roll up a would be x, but it turned out to be y, and therefore he gets slashed.
00:57:18.616 - 00:57:32.080, Speaker C: Well, your transaction can be between these settlements. So the state route that the sequencer or the preconfer signed can be like in the middle of these two commitments.
00:57:33.540 - 00:57:52.010, Speaker B: Yeah. So you can unroll the state route. So once you have the post state route for the whole block, then that fully deterministically gives you the whole chain of intermediate post date routes. And then you can match.
00:57:53.900 - 00:57:57.160, Speaker C: Arbitrum style, like full blown.
00:57:59.680 - 00:58:30.980, Speaker B: You can actually do it in a single round. So basically, you could have the user say, the user submits the receipt as a fraud proof, and then the sequencer is now challenged to prove consistency of the receipt and what was settled. And that could be like a one shot snark, for example. And so you don't need many rounds of interaction, just one round of challenging.
00:58:31.400 - 00:58:47.496, Speaker D: It could be simpler than that too. If the proof include a mercalized commitment to the intermediate state, then you just point out to one of those and provide a merkel proof and say, this is my transaction. But the pre estate is something.
00:58:47.678 - 00:58:56.060, Speaker B: Yeah, you could do it in like one shot. Like the user just provides a one shot proof of malfeasance from the sequencer.
00:58:57.760 - 00:58:58.910, Speaker C: I see. Thanks.
00:59:00.880 - 00:59:11.292, Speaker B: POTUS. Yeah, I also had a question about the slashing. I left it in the chat. I don't understand the difference between safety and liveness.
00:59:11.436 - 00:59:14.496, Speaker D: If I hold two consecutive slots and.
00:59:14.518 - 01:00:20.970, Speaker B: I gave a preconf for slot n, and I just happened to go offline and I cause a safety fault in n plus one, how much do I pay? Yeah, that's a great point. So in some sense, from the point of view of view of the user, they don't care if it's a safety fault of life missile. They got rugged either way. I think it's just a bit of a technical distinction and maybe also a probabilistic one like, this should never happen. If you're honest, this will happen, but with low probability. And so, yeah, I mean, one of the things you could do if you want to be super fancy is you could have some sort of consensus mechanism, like espresso is trying to do, where the slot n plus one is constrained by the pre confirmations in slot n, even if slot n happens to be reorged. But yeah, I agree that from the point of view of the user, these are both equally bad.
01:00:20.970 - 01:01:25.932, Speaker B: And one way to size the collateral is to think of the maximum value of a block if there was no constraints from pre confirmations. And actually we have historical data on this from mev boost, which is that the maximum amount of mev in any given slot is less than 1000 e. So this is why I keep using the thousand e number, because if you reneg on all your pre confirmations, then you can make up to 1000 e in mev. And you're right that if you have a missed lot slot n and now the proposed slot n plus one can do whatever they want, then that's effectively the same as a safety fault. And so what I would do is I would also punish maybe the liveness fault for 1000 e. But what I expect will happen is that these sequences will get sophisticated and they'll be able to price this risk. That's one.
01:01:25.932 - 01:02:06.570, Speaker B: But also they'll be able to minimize the risk of liveness fault. So on ethereum l one the reason why there's missed lots is because people submit too late. That's basically the reason. In some sense it's the fault of the proposer of the operator. In theory you could have these periods of very high asynchrony with the testers, but in practice that basically doesn't happen. It's basically always the fault of the operator. And so if you have a lot of value at stake from missing a slot, then you're going to be damn sure that you're going to be online and you're going to submit your block on time.
01:02:06.570 - 01:02:16.524, Speaker B: And we have Daniel with your just.
01:02:16.562 - 01:03:05.404, Speaker I: Wanted to hear a little bit of how you're thinking about the centralization of the builders. Because right now we have polygon, Zksync, arbitram. In the future we're going to start having more and more of these hyperchains or CDK chains or op chains. And the sort of de facto situation starts being that any builder should start running every single chain that exists in the entire ecosystem to maximize their mev, to maximize the chance of them being able to propose. And I'm just kind of curious of your thinking behind that, because with mev boost you can decentralize that, or you can distribute that with open source, with server resources. You can't really distribute that. So it just ends up being a few entities in the world that pay a shit ton to be able to run these.
01:03:05.404 - 01:03:07.630, Speaker I: And I just wanted to hear your thinking on that.
01:03:09.200 - 01:03:56.024, Speaker B: Right. So one of the observations is that you have extreme centralization, even if you have to deal with one virtual execution environment or one virtual machine. So if you look at the EvM l one evm today, there's extreme centralization at the builder level. You have beaver build with like 40 or 50%, and then there's titan and rsync that have almost all of the rest. So basically three entities are controlling the vast majority of blocks, two of which are censoring, by the way. So it's not a pretty situation. What I'll say is that what we're trying to do is to design the consensus layer in such a way that the builders can't do harm.
01:03:56.024 - 01:04:52.140, Speaker B: So we can try and list all the pieces of harm that they could do. Like they could censor, they could go offline, they could try and do all sorts of things. And it turns out that for every single bad thing that I'm aware of, primarily censorship, but there's other things that they could try to do, we have solutions for. So, for example, inclusion list helps with censorship. And so one of the, my philosophy, I guess, is that we've kind of accepted build decentralization as a natural market outcome, but we've segregated it from the validators. So we want to make sure that, for example, decentralization of the builders does not leak or pollute the validator set. So the validators can still be running on the raspberry PI on a smartwatch, like they need almost no computational resources.
01:04:52.140 - 01:06:25.212, Speaker B: Now, one of the questions that is very reasonable to ask is, what if every chain has its own independent kind of PPS? And so now the builders only have to run one full node. Well, I actually think that's not kind of economically to be expected. And the reason is that the amount of MEV that you can extract is a function of how much information you have about the world. And in some sense, the builders, they want to be maximally connected to centralized exchanges, for example, because they have more and more price information. But they also want to be maximally connected to all the other chains, because there's going to be economic activity happening there, and there's also going to be interactions where there's going to be bridges, and there's going to be asynchronous transactions. And not only that, even if the rollups don't explicitly opt into a shared sequencer, what we might see is a market that kind of naturally emerges, kind of at higher level, something like Suav, where the proposers can trustlessly sell, the sequencers can trustlessly sell their sequencing slots to the highest bidder. And in some sense, this mega builder, which builds all the roll ups simultaneously, is an outcome that's going to happen either way, whether or not the roll apps explicitly opt in to this.
01:06:25.212 - 01:07:04.920, Speaker B: So my philosophy is that I accept the builder centralization, but I want to make sure that there's no negative externalities to that centralization. The one thing that I will say that remains in terms of negative externality is mimetic. It's a really bad look that 90% of block is built. Our blocks are built by three entities. And I think the best answer to that is education. Making people understand that actually is not so bad because they can't cause liveness failures, they can't cause safety failures, they can't do front running, they can't do censorship. But yeah, it's going to be an uphill battle.
01:07:04.920 - 01:07:23.330, Speaker B: And in some sense, it's similar to the centralization of the mining pools in bitcoin, right? There's like three mining pools that control everything. It's really a bad look for bitcoin, but they moved on. And whoever's interested in bitcoin understands that actually the mining pools don't have that much power in the grand scheme of things.
01:07:27.780 - 01:07:55.480, Speaker I: I guess the only concern is it removes the, it removes the optionality of me being like a medium block builder. I understand the centralization. I understand if we can stop censorship through CR list, if we can have threshold encrypted mempools, I understand these concepts, but it removes me the option of me being an irrational economic actor, not always accepting.
01:07:56.220 - 01:09:00.920, Speaker B: So what is a medium sized builder? It's a searcher, right? What is a searcher is one that specializes in a specific subset of the overall world state. Now, searchers nowadays, they specialize in individual contracts or individual strategies, but they can specialize in individual roll ups. And so in some sense, you're just moving up the stack of abstraction and you have the mega builder, but within the mega builder, there's sub builders, which you could call like roll up searchers. And then within these roll up searchers, you have contract searchers that work on a contract by contract basis, for example. So yeah, I do expect that PBS extends further to build a searcher separation. As you add more and more levels, it is fine for relatively less sophisticated entities to specialize in one thing and be very good at that. And actually that's what we see in practice.
01:09:00.920 - 01:09:59.040, Speaker B: So what tends to happen is that searchers, there's no searcher that's good at everything. Every searcher tends to be good at one or two things, and there's like 100 searches. And then as a group, they build optimal blocks. Okay, we have about 20 minutes, so I'll use that to talk about base sequencing, which in some sense is like the big finale of this vision. So we have part one and part two, which in some sense is orthogonal to this last part. So if you think from the point of view of a roll up, there's kind of two resources that you're consuming from Ethereum. There's Ethereum settlement and Ethereum data availability.
01:09:59.040 - 01:11:01.104, Speaker B: And the claim that I'm making today is that there's actually a third resource that you have the option to consume if you want to as a roll up, and that is Ethereum sequencing. And the reason I put this little new emoji is because it's kind of this mental unlock where you realize, yes, this is something I can go consume, but actually it's been there from Genesis, it's been there all along. And it's only now that we've realized that you can consume it. And in some sense this is similar to Ethereum data availability, right? There's cold data, and for many, many years, like half a decade, people didn't realize it could be consumed by roll ups. And then suddenly we realize, yes, roll ups can consume that for data availability. Now the question is, why would you want to consume Ethereum sequencing? And basically, in some sense, the answer is very similar to why you would consume settlement and data availability. So you get best in class security, you get best in class credible neutrality.
01:11:01.104 - 01:11:45.984, Speaker B: Credible neutrality is especially important with shared sequencing because you want some sort of sequencer where every roll up and their competitor feels comfortable opting in. So arbitram and optimism and whatever base and scroll. Let's take an example. Let's say that arbitram launches a shared sequencer and they say, okay, our sequencer is credibly neutral. Well, guess what scroll is going to say, well, you built it. That alone makes it non credibly neutral. And so the fact that we have this sequencer, which has existed since day one, it has the same branding as Ethereum, it has the same security, is a big upside.
01:11:45.984 - 01:12:53.624, Speaker B: And then I think a really cool unlock is that not only can we have synchronous composability across the roll ups, but we can have synchronous composability with the l one as well. Now, if you really zoom out and you look at the big picture of TVL, the vast majority of TVL is on the l one. So there's about half a trillion, $500 billion of TVL on l one, with e, with ERC, twenty s and with NFTs. And if you look at the next kind of largest sequencer by TVL, that's the arbitram sequencer, I think they have on the order of 10 billion or 20 billion. So it's like orders of magnitude between one and two orders of magnitude less than l one. And there's these network effects with TVL and shared liquidity. And so I think we're potentially going down this dangerous direction where in order for the roll up to be successful, they kind of need to start eating into the TVL of the l one.
01:12:53.624 - 01:13:57.180, Speaker B: And you start breaking these network effects, especially when you have these super linear economic effects like the quadratic effect of damn, I forget the law, Meltcaff's law. There you go. So Melkaf's law is a very simple model, saying that the economic value grows quite dramatically with the number of nodes or the number of some notion of size. Anyway, this is why I claim that using ethereum sequencing is valuable. Another question is, can we actually do it concretely in practice? And also can we do it without a hard fork? And I think the answer is yes to both of these questions. We can have rollups consume ethereum sequencing as a shared sequencer, and we can do it today without a hard fork. So how do we do it? Well, basically we have a subset of the l one proposers.
01:13:57.180 - 01:14:45.180, Speaker B: So this is where the l one comes in that opt into becoming shared sequences. And the way they do so is by exposing themselves to slashing conditions. So they put forward collateral and they become shared sequences in this protocol. And so if you look at the look ahead, there's 32 proposals in look ahead, and only some subset of those 32 will be shared sequences. So for example, imagine the proposal at slot n plus one and the proposal at slot n plus 31 have exposed themselves to these slashing conditions. Now, those who have not exposed themselves to slashing conditions, we're going to give them a different name. We're going to call them includers.
01:14:45.180 - 01:15:50.092, Speaker B: And the sequencing rights are going to be given to sequencers, as we'll see. So let's say you have a user at slot n who wants to get a pre confirmation from this new set from basically the base sequencer. So what they do is that they communicate with the first sequencer in the look ahead. So that would be the one n plus one, and they get the request and promise from them. And then once they have this promise, what they can do is that they can share it. Some party can share it with the includo slot n and the includo sl n can immediately settle it. So even though at slot n, none of the sequencing rights are given to that proposer, that proposer still has the option, if they want to, to immediately include and settle transactions.
01:15:50.092 - 01:17:06.360, Speaker B: So what I expect in practice is that you're going to get a 100 millisecond pre confirmation and basically next lot settlement, which is optimal for ethereum. And yeah, this is the same picture that we had, like, how do we modify mifboost? We basically have these promises shared upstream to the builders that will constraint how the blocks are built. And one of the things I want to highlight here is that when the sequencer is a proposer, there's a bit of a potential problem, which is that the l one proposer is running on a raspberry PI, is very decentralized, and has very small amount of resources. How can they be a sequencer? Because we said that a sequencer, they need to be running all these four nodes at the minimum. They need to have enough bandwidth to support thousands, tens of thousands, hundreds of thousands of transactions per second. They need to have very high uptime, very low latency, all of these things, which goes against them being running on a raspberry PI. And so this is where the idea of execution tickets comes in.
01:17:06.360 - 01:17:54.660, Speaker B: So there's this great write up by Mike that I encourage you to look up. It's ET execution tickets, hence why there's this alien. And the idea of the execution ticket is that there's a new entity called the execution proposer, who explicitly opts in to buying these execution tickets. And when they win the execution ticket lottery, they are the l one execution proposer. And they can be extremely sophisticated because they've actually opted in to buying these tickets. And then the validators can no longer be responsible for sequencing at l one. And everything is good, but this requires a hard fork, and so we need some sort of solution in the short term.
01:17:54.660 - 01:18:45.720, Speaker B: And the solution that I'm proposing here is basically to introduce a new entity called the pre confirmation gateway. Matthew came up with this name, the gateway, and I guess it's a distinguished name from relay. And the idea is that the proposer, who has sequencing rights here, is delegating their sequencing rights to the gateway. So the gateway has the sequencing right. So, for example, the proposer ahead of time kind of signs a message saying, I'm giving my sequencing rights to this gateway. And now the users, when they want pre confirmations, they go and interact directly with the gateway. And then again, just like before, the gateway kind of interacts with the relays, and then ultimately, behind the scenes, the builders.
01:18:45.720 - 01:20:07.456, Speaker B: And so now the gateway is collateralized against safety faults, and there's this edge case that we need to handle, which is liveness faults, because now there could be, whenever there's a liveness fault, we don't know who is at fault. Is it the gateway that's at fault, or is it the proposer that's at fault, because now there's like two entities that need to collaborate in order to honor the pre confirmations. And it turns out that this can be solved with trust, in the exact same way that there's a trusted relationship between the proposer and the relay. So in Mevboost, the proposer is actually trusting the relay to be online for the get payload request. So basically, there's this potential edge case where the relay responded to the header, the proposer signs the header, and then the relay goes offline in the few milliseconds, and then they can't respond with the payload. And it's the exact same thing here. Basically, the gateway provider signed all these pre confirmations, and then they go offline just before the proposer is meant to build that to propose their block.
01:20:07.456 - 01:21:24.024, Speaker B: And so now the proposer can't honor these pre confirmations. And basically what I'm suggesting is that we have a similar trust relationship between the proposer and the gateway. And actually, maybe the most natural solution here is to collapse these two and have the gateway be a preferred relay by the proposer. So I believe that the relays are already very well suited to be a gateway here. Now, I have one final slide, but only you have ten minutes, so I'm happy to answer questions now or go to the final slide. I guess my final slide is a bit of a philosophical one, which is that we have sequencing that we need to solve as a community, and I think we all agree that we want to move to decentralized sequencing. And the vast majority of open problems, from a technical standpoint, are specific to, to decentralized sequencing.
01:21:24.024 - 01:22:04.040, Speaker B: Now, within decentralized sequencing, there's some problems that are specific to shared sequencing. Shared sequencing is a specific type of decentralized sequencing. And then even more specific, we have base sequencing, which is a special type of shared sequencing. And I believe that most of the problems, let's say 80% of the problems, are specific to decentralized sequencing. You have to handle mev, mem pools, intense ofas, pre confirmations, data compression, all of these things. And then with shared sequencing, there's a few new problems that come up, but most of them are specific to decentralized sequencing. So one very good example is mev sharing.
01:22:04.040 - 01:23:20.000, Speaker B: When a rollup opts in to a shared sequencer, they are basically giving away mev to the shared sequencer. And one of the things that espresso is working on is identifying where the MEV originates from and kicking it back, kind of giving it back to the rollup that created it. So with shared sequencing, you have new problems like Mev sharing, and that's something that's being tackled. There's also something called deposit sharing, which is this really cool idea by Zksync, which is that if you have two roll ups and you want to do withdrawals and deposits across these roll ups, well, it's kind of wasteful to go through the l one every single time. And so what if we had a shared deposit contract where all the assets were deposited? And now whenever you do a cross roll up transaction, you don't touch the l one. It's all settled through the l two, and it's extremely cheap and efficient from a gas perspective. And then there's this idea from Polygon, which I briefly mentioned ahead of time called the aggregation layer, which gives you this level of safety for cross roll up bundles.
01:23:20.000 - 01:23:56.990, Speaker B: And then there's the base sequencing, which I kind of went through the design here. And in some sense, it's only opinionated on one thing. It basically says that the very end of the mev pipeline terminates with the l one proposer. And the cool thing is that most of the problems are not at the base sequencing level. They have to be solved at other layers, and there's no fork required. And that's the end of my presentation. And we still have a few minutes for questions.
01:24:04.160 - 01:24:17.344, Speaker C: Lynn, so I have a question about the includer that you mentioned. So when you say the includer settles, you mean that they settle as in like the l two state route, correct?
01:24:17.462 - 01:24:17.888, Speaker B: Yes.
01:24:17.974 - 01:24:31.732, Speaker C: Okay. So in that case, if the preconfer lies about the position, not only is the pre conference invalid, but the settlement will be invalid. Then in that case, what would happen?
01:24:31.786 - 01:24:32.390, Speaker E: Right.
01:24:33.740 - 01:25:35.944, Speaker B: So the sequencing rights are given to slot n plus one, and the sequencer says, I'm going to promise to put transactions ABC in positions one, two, three. And then these promises are gossiped. And so now it's perfectly safe for the includer to go settle transactions ABC at positions one, two, three, because that's what the sequencer said they wanted to sequence. Now, one of the things that is definitely possible is that the sequencer equivocates, right? Like they made promises for transactions ABC. But then it turns out they also sign off transactions a prime, b prime, c prime. And in that case, they would get slashed for a safety fault, and the includer would have the option. If they're aware of both of these, they have the option to either settle ABC or a prime, B prime, c prime.
01:25:35.944 - 01:25:43.170, Speaker B: It's up to them what they want to settle. In either case, they're completely protected because the fault came from the sequencer, not from them.
01:25:46.020 - 01:26:00.500, Speaker E: Lisa, do we have any constraints on how many blocks from different rollups each gateway can promise?
01:26:03.800 - 01:26:48.660, Speaker B: Right? So let's say that we're in this situation, we're in slot n, and the next proposer is in slot n plus one. Then actually the proposer can make promises for two slots. They can make promises for slot n and for slot n plus one. So in some sense, they can cover 24 seconds worth of mev and 60 million gas at most. Now, one of the things that you need to be careful of is making sure to not over promise. So because this sequencer only has 60 million gas to work with, they shouldn't promise more than 60 million. If they were to promise 70 million, then they're guaranteed to get slashed.
01:26:48.660 - 01:27:27.840, Speaker B: Now, another thing that they need to make sure is only start providing promises for 30 million Gus and above. After the includer has included the first batch of promises, what the sequencer needs to do is basically provide a small tip to incentivize the includer to settle the transactions so that now they can start providing pre confirmations for 30 million gas and above. Between 30 and 60 million gas.
01:27:30.180 - 01:27:54.680, Speaker E: We can end up like, if there are not too many gateways, we can end up in the situation when there are blocks from roll ups who have to wait because we just don't have gateways within these 32 that are defined.
01:27:56.540 - 01:29:13.584, Speaker B: Great question. So are you saying that it's possible that in the look ahead, which is 32 slots, there's zero shared sequences? None of the proposers here have opted in. And so basically there's no sequencer, in which case pre confirmations break down. Now, one of the things I do want to highlight is that the includers, in addition to settling transactions that have been sequenced and pre confirmed, they also act like an inclusion list. So they can just include arbitrary transactions that have to be executed by the end of the slot of this executor. So, for example, if this shared sequencer is censoring for whatever reason, well, the includer here can make sure that any transactions are being censored, will go in here, and therefore will get executed by slot n plus one. Now, in terms of making sure that there's at least one preconfirmer in the look ahead, you need about like 15% in order to have high probability that there will be at least one pre confirmer and shared sequencer in the look ahead.
01:29:13.584 - 01:29:50.536, Speaker B: One of the things that, I guess there's two things that are good news. Like one is that it's very easy to change the look ahead. We can change it to 64 slots or 128, and that's just a constant. That's a super easy hard fork. The other thing I'll mention is that there's actually an incentive in the very early days to become a shared sequencer. And the reason is that you get to control many slots, and therefore you get lots of Mev for these roll ups. So for example, here, this shared sequencer would get two slots of MeV, and this one here, assuming this is all gray, would actually get 30 slots of MeV.
01:29:50.536 - 01:30:20.600, Speaker B: So in the very early days, you're making a ton of money from Mev because you're one of the few providing the service. And another, I guess, piece of good news is that 15% potentially can be handled by one actor. So if Coinbase, for example, says, from the goodness of our heart, we're going to bootstrap this pre confirmation infrastructure, even if there's going to be very little fees or whatever, they can single handedly do that. Or maybe Lido could help out with the initial bootstrap.
01:30:21.180 - 01:30:22.890, Speaker E: Yeah, makes sense. Thank you.
01:30:27.980 - 01:30:45.970, Speaker C: I still have a question about the includer. So when there's a transaction ABC, and the pre confirms ABC, but actually posts the data of a prime, b prime, c prime, which one is the canonical, which one is the correct.
01:30:47.140 - 01:31:14.120, Speaker B: The includer can only settle transactions if they've been signed off by the sequencer. So if they say, please include a prime, b prime, c prime, then they can force inclusion, just similar to an inclusion list if they're censorship, for example. But they can't guarantee that a prime, b prime, c prime will be in position. One, two, three. That will be up to the sequencer to choose the positions of transactions. A prime, b prime, c prime.
01:31:15.180 - 01:31:21.644, Speaker C: So if they don't do a prime, b prime, c prime, then yeah, then.
01:31:21.842 - 01:31:40.044, Speaker B: That is a slashing violation. So that would be a liveness fault because they wouldn't be able to build a block which satisfies the inclusion list, and therefore it would have to be like some sort of empty slot from the point of view of the roll ups, and they would get slashed.
01:31:40.172 - 01:31:43.890, Speaker C: So that batch will be invalidated in that case.
01:31:45.640 - 01:32:37.780, Speaker B: Yes. I mean, there's a bit of a design detail here, which is that if the shared sequencer kind of has a liveness fault, do you execute the transactions in the inclusion list or do you just trash them? There's reasons to do both. Well, either one reason to do it is that you have more of a liveness guarantee and better sensory resistance. But a reason to not do it is that now you're having mev within the inclusion list itself. I mean, maybe the best design is to keep them around, but now put the constraint on execution on this shared sequencer, basically the next shed sequencing.
01:32:38.840 - 01:32:40.310, Speaker C: That makes sense. Thanks.
01:32:50.860 - 01:33:10.232, Speaker B: Okay. Amazing. I think we're actually at time now. There is a dedicated call for base sequencing and pre confirmations with about 100 people in it. That's happening every couple of weeks. So do let me know if you want to join these calls. There's already been three calls.
01:33:10.232 - 01:33:40.240, Speaker B: They're all recorded on YouTube. There's also dotes, and there's also a telegram group if you want to join that as well. Thank you so much for your time and looking forward to chatting more. It's.

00:00:00.090 - 00:00:24.950, Speaker A: Berkele implementers call number 14 and issue nine seven two. In the PM repo a link to the agenda will be shared in the chat as well as in the notes on YouTube. If you are watching the recording. We have a pretty light agenda today so this may be a shorter call. Let.
00:00:24.980 - 00:00:26.790, Speaker B: Well okay.
00:00:26.940 - 00:00:32.440, Speaker A: Any client teams want to start with sharing quick updates since the last call?
00:00:43.310 - 00:00:48.382, Speaker C: I think I can go ahead. Yeah, you go ahead. Yeah.
00:00:48.436 - 00:01:08.530, Speaker D: So there is no big updates on Nethermind. Last two weeks, most students spent running status execution on the current testnet to identify the problematic blocks and find any more issues that might be there that we did not see in the initial blocks. So we are just working on straightest processing and that's.
00:01:16.450 - 00:01:51.900, Speaker E: The I'll do on the Bizu side very light as well. So we managed to follow testnet till some block number that I forget but stopped waiting for the relaunch. And meanwhile we've been working on optimization because the timings were not so great, they were not so bad, but not so great. So we're working on that at the moment and making implementation as much generic as possible.
00:02:00.080 - 00:02:58.872, Speaker C: Yeah, I'll go next. Yeah, so we had the shadow fork last time, so now we've been working on, well, first helping other understand bugs when they try to sync the testnet. Also cleaning up code. I started on the Dancun rebase, it's going to take forever so might as well get started early. And yes, basically working on the gas accounting layer because currently the gas model is a bit, definitely not following the spec. So trying to clean up in the hope of making the next testnet use the standard gas accounting. It's been more difficult than anticipated, but yeah, we're getting somewhere.
00:02:58.872 - 00:03:05.410, Speaker C: So I'll have a question about this later. And Ignacio, do you have anything to add?
00:03:07.940 - 00:03:29.210, Speaker F: Not much, but we made the replay of the chain work again on the rebase branch and we discovered two panics related to some bugs that we have in Geth and yeah, some extra maybe costalian bugs that were found by others that we fix in too.
00:03:34.100 - 00:04:14.540, Speaker G: On Ethereum Js side, we basically wanted to sync constant info in the way that to hop over the invalid blocks that we see. And so we were able to achieve that and we are basically now waiting for new network so that we can test the fixed network and evaluate against it. Because for the few blocks that we randomly inspected, it seemed like we were seeing the old issues which have already been discovered. So for us, next step would be to test on the new network.
00:04:29.390 - 00:04:30.140, Speaker B: Hello?
00:04:32.450 - 00:04:54.450, Speaker H: Yeah, I just wanted to ping Tanish and Nimbus person to modify the patterson hash function. There are currently PRs in Bezu, Gaff and Ethereum Js, but there's none in Nevermind and Nimbus.
00:05:03.320 - 00:05:05.764, Speaker I: Is there a change in the way.
00:05:05.802 - 00:05:10.920, Speaker D: We calculate bit of anatch or the output is also changed now? Or just an optimization?
00:05:12.300 - 00:05:21.900, Speaker H: It's a breaking change. Yeah, pedestal hash is a bit confusing, but it's like gettree key hash. It changes the output.
00:05:25.600 - 00:05:27.630, Speaker D: Okay, I'll have a look at it.
00:05:43.570 - 00:06:07.330, Speaker A: Anyone else? We have anyone from Aragon? I'm not sure if Samnath is here. I don't think so. Any other updates? Okay, if not, we can move on to agenda item two, testing updates. Mario.
00:06:09.030 - 00:07:29.782, Speaker B: Yes, hello. So last week there was no that much work from our side to Berkele, but I think one important topic that we can cover today is the changes to the way that we fill tests and the way that the clients will consume Berkeley tests, I mean, normal tests, blockchain tests, and state tests after Berkele has happened. So the main change that we've been working on the past weeks with Gilam is that since Berkele can no longer output the postal lock, we have to make some changes to how we receive this information from Berkele, from the transition tool, and how we process it internally while filling tests. If anyone is not familiar with the transition tool, it's basically just a tool that in this case, Geth provides for us to be able to do the transition function and get the output allocation. So the nice thing before Berkeley is that we have the pre alog. So it's basically just a dictionary with all the addresses as keys, and we have all the storage and balance information available for us. And this is the same as the output.
00:07:29.782 - 00:08:30.510, Speaker B: So you give a prealog and the postalog and you get all the changes out for us, and we can then, according to our tests, check the storage of every key and make sure that everything makes sense in accordance to what we have written in our tests. So now the big change here is that we provide a pre alog, a pre Berkele, but the output is going to be the Berkele key. And also Gilam, stop me if I make some mistake. Just let me know. You can intervene if I say something that is not correct. But yeah, anyway, the output is going to be the dictionary that contains all the Berkeley tree structure. We're going to have to make some big refactoring in the way that we write our tests, because we now have to check the pedals and hash to get the actual position of the storage keys that we need to check in every single one of our tests.
00:08:30.510 - 00:09:49.910, Speaker B: So we're working on that and we're working on some refactoring to make this easier for us in the long term. The change to transition tool, I don't think they concern most of the clients, but the output of the blockchain test and the status are going to slightly change too. And these do concern most of the clients because how they're consumed. So the idea is that now on the blockchain test, the blockchain tests are basically just, we have the genesis, the block one, two and three and so on, and we do some postal verifications. And the idea now is that with Berkeley we can also introduce a witness in every single block. And what this will allow us is at least on Hive, we can run the tests with the normal client and we can consume the blocks one through N, but also we can run with the stateless clients. So in Hive we can configure maybe the same or a different simulator, and we can just start parsing the test that we already filled with the transition tool before.
00:09:49.910 - 00:10:43.354, Speaker B: And then depending on whether we are running with the full client or the stateless, we can run one test with the full client and a stateless test with the stateless client. This will allow us to just write a test once, but it will be able to be consumed and verify both types of clients. So yeah, this is very good and this is the main idea. The disadvantage, maybe in this case, is that probably that the consumers of the current blockchain test format are going to be affected. So there will be some modifications to the consumers that every single client implements. And it's going to be important for all clients to adhere to these changes in the blockchain test format. It's not going to be big changes.
00:10:43.354 - 00:11:22.600, Speaker B: I think it should not matter. For example, if you're running a full client, you can ignore the stateless or the witness part. I'm not sure it doesn't necessarily, but it shouldn't be a breaking change. And yeah, I think that's basically the two important things that I wanted to share. And also just to open to discussion, if anyone has concerns about these two ideas, they're still being worked on. So they're probably going to be changes. But if you have some feedback, just let us know.
00:11:25.050 - 00:11:40.410, Speaker C: Just to add, I have two bugs that I need to fix for you. I will try to do them this week. But yeah, I can't promise it just yet, but that would be nice to be able to test the full chain.
00:11:48.160 - 00:12:10.630, Speaker B: Yeah, cool, thanks. We're still working on the refactoring, so it's going to be a little bit, maybe a week or two, so it's not a problem. But if anyone else has feedback or has any questions about mainly the fixture test consumption, if you have questions, just let us know.
00:12:20.160 - 00:12:37.180, Speaker A: Thank you, Mario. Cool. Next up, we have a follow up from the last call discussion on potential DOS vector around tree branch attacks, either Gati or inaccio.
00:12:38.480 - 00:13:05.924, Speaker I: Yeah, I mean, just can basically say a bit of this. This was a bit cut short because I had Microsoft home problems last week and just wanted to give a bit of an update on this. Yeah, this is basically a bit of a follow up to what Josh has basically shared in the chat. I mean, Ignaci has made a write up. I have started a write up of my own. We'll just link to it. This is work in progress.
00:13:05.924 - 00:15:00.696, Speaker I: I mean, at least both documents that were basically shared are work in. I haven't yet written up this in full detail, but one thing that we have to bit concerned is that basically an attacker who wants to basically dos the tree could just create very deep branches in the vertical tree. And there is a bit of a distinction that one needs to make whether the attacker actually targets a particular tree key, essentially, and that is or whether we actually consider a multitarget attack. I mean, if an attacker is basically willing to spend $1 million on basically searching for tree keys that basically collide with large prefixes of our hash function and thereby pushes something down below the tree, they can actually also clearly make a lot of excesses to whatever trees they insert themselves into the tree. So I think that depends a bit on how we actually model the coast for this, but we need to actually take these kind of multitarget attack points more seriously. I have explained this a bit in the second link that I've posted in the chat. I said this is work in progress, but just to repeat what was said last time, the upshot is that if we have a two to 380 attacker, which seems like a completely reasonable thing to do with an attacker that has a budget in the millions, given that an individual evaluation of the hash function that is basically better than hash function is essentially a single group operation, that's super ASIC.
00:15:00.696 - 00:15:56.188, Speaker I: Permission denied. Oh, sorry. Have to probably share this. Yeah, can you try the link now? I'm just writing the chat. Okay, thanks. So the thing is that the single individual hash function evaluation is basically a single group operation, and the attack that it is in fact super ASIC friendly with an ASIC design that probably already exists because actually the same that one would use to break ELOC. So the million budget of millions, you can basically expect to have something like 2380 or so evaluations.
00:15:56.188 - 00:16:59.744, Speaker I: And this in fact allows to basically create a branch that has a depth of something like 14 in the burkel tree. It's not possible to do this for a chosen target, but it's possible to do this for an attacker, for the attacker's own targets. And in fact the attacker can create not just one such deep branch in the tree, but a lot of them. Something like two to the. Yeah, I don't know, something like say two to the 16 to two to the 32 of them. And of course then an attacker can basically just, if you have a million of budget, I can just write, I can just make transactions that access them heavily, which I guess since we are not doing this within the gas price model, we do not take the actual witness sizes. And all of this into account actually may cause for a massive gas mispricing.
00:16:59.744 - 00:17:19.324, Speaker I: Unless we are sort of willing to assume that basically as a worst case, that well, basically branches into vertical tree have a depth of something like 14, which may be doable. I hope so. But this is kind of the ballpark that we need to target if you want to sort of make this work.
00:17:19.362 - 00:17:22.990, Speaker C: In the worst case. That's just my side.
00:17:32.900 - 00:17:37.270, Speaker A: Thanks Katie. Any questions?
00:17:37.880 - 00:17:52.970, Speaker C: Yeah, I'm just trying to formulate it, but basically just to confirm if we manage to do a depth of 14 in an acceptable time, we would be fine.
00:17:54.140 - 00:18:04.460, Speaker I: Yes, pretty much. I mean 14 acceptable time, maybe 15. I mean this is really, probably, really feasible. 814, maybe 1516 would be a bit better. But yeah, that's basically the target.
00:18:05.120 - 00:19:06.850, Speaker C: Right. Because in guest we have this thing where we try to share as many of the calculation as possible. So it's not that we only care about the depth only and we don't care about a wide attack, but it's less likely it would have to be really worst case. I'm not sure if an attacker can actually target this use case. Find a lot of keys that are not in the same location in the tree, but really do not share anything in common, any computation in common. Yeah, I guess it's doable too. Okay, so what would be the next steps you advise for us to settle this?
00:19:09.540 - 00:19:14.770, Speaker I: I mean, as you make sure, probably really assume this worst case, I guess.
00:19:16.420 - 00:19:17.170, Speaker C: Okay.
00:19:23.860 - 00:19:34.810, Speaker F: So one extra thing that you mentioned, Gotti, is that an attacker wouldn't have a problem to not only generate one, but potentially a lot of. Right?
00:19:35.420 - 00:19:36.170, Speaker I: Yes.
00:19:37.820 - 00:19:38.184, Speaker C: Okay.
00:19:38.222 - 00:19:56.428, Speaker F: So the worst case will be actually a lot of branches of Dev 14 that probably don't share that many common internal nodes. So it's not only like one really deep branch, but potentially many of them.
00:19:56.594 - 00:20:21.488, Speaker I: Yeah, I mean, some kind of back of the envelope calculation. I mean, two to the 80. Attacker can basically create something like two to the 32 branches. Completely separate. Completely separate branches. Each of the depths to 14, two to the 32 is a lot. I mean, you probably would go for less because then you can basically optimize your attack to be more ASIC friendly.
00:20:21.488 - 00:20:42.150, Speaker I: But still, two to the 20 or something is completely feasible. Of course he would still need to actually write all of them to the state, which takes a bit of time, but it's probably within the budget.
00:20:50.390 - 00:20:57.860, Speaker F: I think that Kev had a question on what machine? What do you mean Kev? On what machine? The attacker can do this thing or.
00:21:03.670 - 00:21:24.160, Speaker I: What is it? I mean, I'm assuming here that the attacker can carry out two to the 80 group operations. Basically the attack is super parallelism friendly. So probably an attacker that is that determined would build an ASIC for the group.
00:21:27.650 - 00:21:44.020, Speaker H: I think Guillaume said that if we can do 14 levels really quickly, this becomes not a problem. Or 15 or 16. So I was referring to what machine are we talking about when we say really quickly?
00:21:47.110 - 00:21:58.760, Speaker C: When we say really quickly? Yeah. I don't know. Our tests were on inacios machine. I'm not sure. I don't remember what it was. It was some Ryzen from a few years ago.
00:22:01.790 - 00:22:02.298, Speaker I: Yeah.
00:22:02.384 - 00:22:35.362, Speaker F: I will put in the chat a link to a section in my document where I run a benchmark for updating a branch of different depths in my machine. And in a rock five B one. So yeah, we can run this benchmark in other computers too. To have an idea of what is like a reasonable, low set up, low hardware machine that we should target and see the times there.
00:22:35.416 - 00:22:36.020, Speaker A: Maybe.
00:22:42.780 - 00:23:13.520, Speaker C: Yeah. I mean, that would definitely spell the doom of the rock five B, although nanosecond. Yeah, actually not even maybe, but I think we have some leeway. I don't want to say it's not a problem, but I shared with the timings with Peter, he was like, yeah, if it's a worst case scenario, it's manageable.
00:23:17.000 - 00:23:21.300, Speaker F: I think that maybe the concern is if we have a lot of these branches.
00:23:22.520 - 00:23:53.070, Speaker C: Yeah, I understand. I just assume we wouldn't have more than 1000 branches being touched, so that would be okay still. But yeah, it's better to have even better numbers to be completely safe. I'm just saying it's not preventing me from, I won't lose sleep over that, but I would sleep more comfortably if we had better numbers.
00:23:59.170 - 00:23:59.486, Speaker I: Yeah.
00:23:59.508 - 00:24:05.070, Speaker F: And also it will be useful to run this kind of benchmark in other implementations other than guest.
00:24:18.140 - 00:24:29.330, Speaker A: Anything else on this topic. If not, we can move on to the final item, the testnet relaunch.
00:24:33.050 - 00:25:11.330, Speaker C: Thank you. So I have a very bare bones presentation. Always looking for my window. Okay, here it is. Can you see my screen? Okay, so, yeah, there's been a few things going on on the testnet. People have tried syncing it, really found some bugs, and there's actually a lot more. Okay, there's a lot more blocks that clients seem to have an issue syncing.
00:25:11.330 - 00:25:59.280, Speaker C: At some point, Besu stopped trying because as they find bugs, they were patching their code to follow Geth, but some stuff had to be fixed in geth, so they gave up. And that makes sense. They're waiting for the relaunch. They're keeping busy doing other things in the meantime, which is fine. And then Tanish and Gajinder, I think, I think those were the two, tried to do a sync. Maybe Gabriel too tried to do a sync to stateless sync to figure out which ones of the blocks were causing problems. And they found not a huge list, but a significant one.
00:25:59.280 - 00:26:13.400, Speaker C: So from what I understand, if I understood your update correctly, Gajinder, you say let's worry about the amount of blocks differing after we relaunch. Is that what you said?
00:26:14.810 - 00:26:21.298, Speaker G: Yeah. Because it seems like the same issue is cropping up in most of the blocks.
00:26:21.394 - 00:26:48.400, Speaker C: Okay. Yes, that makes sense. Thanks. In the meantime, something else happened. We had a network split that actually happened shortly after the last Vic, but because half the network was still holding, we didn't really notice. So I guess we should get this kind of information. Like we should get paged when something like this happened.
00:26:48.400 - 00:27:57.766, Speaker C: But yeah, the testnet was still holding and so the suspicion, given the block height, is that happened when Openzeppelin deployed some of their test contracts to the testnet. So it looks like Geth got overwhelmed, some of the machines missed their slots, and this thing happened. But we relaunched everything, it's back to normal, except ticks first stopped working as well. So, yeah, the only reason we keep the Testnet alive currently is because there are some things that some people, myself included, that want to try some new code for the relaunch and want to keep syncing, but it's going to be terminated soon. So this is the series of updates I would like to have in this new testnet, if everybody agrees. So there's all the known bugs. So all the bugs that.
00:27:57.766 - 00:28:26.266, Speaker C: Can I show this or is it going to open in? No. Okay. I click, nothing happens. Great. But yeah, if you go to the spec page, you will see the list of bugs that have been known, identified and fixed. So those are fixed on the testnet and then. Yeah, my question is, this question has already been answered by Gajinder.
00:28:26.266 - 00:28:57.100, Speaker C: At least Gajinder and Ethereum Js are not going to bother syncing anymore. There was a couple of blocks that we thought would reveal more problems, but those blocks did not reveal anything. So that's fine. And namely those blocks were those who split the network. There are two things I would like to add to this relaunch. The first one is fairly simple. After the discussions we've had about.
00:28:57.100 - 00:29:39.382, Speaker C: Well, okay, we just had the discussion again, but I think it makes sense now to go with a circular buffer in 29, 35 if everybody agrees. The first question I have for that is what is the start offset? Like, do we want to have an offset of zero at the fork or do we just take the last byte and this is where we put the first block and then we fill the parents. We will presumably be in the middle of a group and then we put the parents in the circular buffer. We fill it in a circular buffer this way.
00:29:39.516 - 00:29:39.910, Speaker I: Or.
00:29:39.980 - 00:30:06.640, Speaker C: I think that's the simplest solution. Or do you want to start with offset zero at the fork height at the fork block. So if anyone has an opinion otherwise, I would go with the default star offset, which is just the last byte of the fork block number.
00:30:08.050 - 00:30:14.180, Speaker G: Yeah, I think the modular ring size is the correct way to go for it.
00:30:15.110 - 00:30:55.546, Speaker C: Cool. Okay, well, unless anybody dissents, then this is what we're doing. And then I would like to also use the gas cost. So until now it's entirely because of me. We were just adding the EIP 2029 cost to the vertical cost. So that would inflate the gas cost even more. And we would also not pay any attention, not treat the sender of the transaction and the recipient of the transaction any differently.
00:30:55.546 - 00:32:03.540, Speaker C: So basically the, the payer, the, the user would have to pay the gas cost for the intrinsic gas cost of the transaction plus the witness cost for his two address and his from address. And that was a bit unfair. So we've had a series of discussions over the past few vics. I think we should go and have this new gas cost. I still want to leave the chunk fill cost part out, because that requires a lot more coding on my part. But yeah, otherwise I propose that we go with the pure vertical cost, everything that has been inspect except chunk fill cost that would be set to zero before I move on. Is everybody okay with that or is there a reason not to do? Yeah, so the next thing, it's Kev's change.
00:32:03.540 - 00:33:06.310, Speaker C: So now Inacio has actually just pushed an update to the EIP this morning. We would not use the serialization, I forgot what the name of the function was called. But there used to be one way to serialize the commitment in the Pedersen hash, the values in the Pederson hash. When hashing a commitment we would use, I'm trying to remember, but the two bytes and now we would use map to field. So yeah, just be aware of that because if we're going to relaunch, this is what we. Yeah, so the question is Denkun. So this meme, courtesy of Barnabas from the guest, is not ready to do this.
00:33:06.310 - 00:34:03.830, Speaker C: So I suggest we don't do that for the relaunch, although that's what I'm going to work on. I mean, me and Inasio presumably are going to work on in the next weeks, get the rebase on top of not. It's not going to be easy. So since Besu for example, at least is waiting for relaunch, we should not consider Denkun just yet, but hopefully in the next iteration. And yeah, is there anything else people want to add to this testnet, any timeline? I can't promise it will be done this week because I need to finish the gas accounting layer, but yeah, it would be nice to have it in the next two weeks if everybody agrees and yeah, that's pretty much it. Yeah. Tanish.
00:34:05.370 - 00:34:47.834, Speaker D: Just one thing that I'd like to propose is for the new testnet in the starting at least now. So Ethereum is also another one can process statelessly and hop over invalid blocks. So at least in the first week we can just try to figure out if there are some issues and if we find some issues we'll relaunch the Testnet because this Testnet was a huge one, it has a lot of blocks. So it was a very good opportunity to test vocal sync, but due to issues I was not able to. So for the new testnets it will be good if we can in the initial phases just figure out if there are some major problems or imaginations that require a lot of change on other client side to sync and then we just rebound the testnet if we find.
00:34:47.872 - 00:35:05.280, Speaker C: Some issues right, because the sound was a bit garbled for me. You said that you would like to launch all the test features as early as possible, is that correct?
00:35:07.170 - 00:35:29.666, Speaker D: No, I was saying that whenever we start the testnet, and since Ethereum, JS and Netherland both has now capabilities to process stateless blocks and also hop over invalid blocks. So let's say for one week we let the testnet running and if in a week we find any kind of issue, we relaunch the testnet and we don't wait this much longer. Like this time.
00:35:29.848 - 00:35:30.580, Speaker I: Okay.
00:35:32.810 - 00:35:46.806, Speaker D: In the last testnet it was a big testnet and it was a very good opportunity to test vocalsync. But due to all the issues, I was not able to. So in the new testnet, if we just relaunch with the issues we sign, that'll be good for testing.
00:35:46.998 - 00:36:13.838, Speaker C: Cool. Yeah, absolutely. That would be nice to find those bugs. Yeah, I agree. It doesn't have to be long lived. Let's just make sure it has as much content as possible so that we can find potential bugs as quickly as possible. Which means that, for example, I didn't mention that, but we have a block hash issue on the current testnet.
00:36:13.838 - 00:36:51.120, Speaker C: But because no one called block hash, it has not been found. So we would need to make sure, and I have to talk to Adrian from openzeplane about this. If he could just create a script for us to release all that stuff right off the bat, I think that would be a good way to indeed just figure out if there are some problems early on. And indeed we don't need a very long running test net if we can identify bugs right off the bat.
00:36:53.670 - 00:36:54.130, Speaker I: Or.
00:36:54.200 - 00:37:19.130, Speaker G: What we can do is basically have a very short lived iteration or a couple of them before basically launching the next version. So we basically keep the constant info running and have these short iterations where we basically do sort of bug hunting. And maybe after two iterations or three iterations, we again relaunch.
00:37:23.460 - 00:38:02.140, Speaker C: Sorry, I was muted. Yeah. I wonder, is barnabest still around? No. Yeah, I was just wondering if we could just be like, if there would be an easy tool to be notified if an error happens so that we can build a list this testnet, I had to insist that people should try to sync statelessly all the way, and indeed it was very long, et cetera, et cetera. If we could somehow automate this and get the list of blocks right off the bat, that would be quite useful.
00:38:06.090 - 00:38:09.590, Speaker G: But do we need to get the list of the failing blocks?
00:38:11.310 - 00:38:36.580, Speaker C: Yeah, I mean, that's the point, isn't it? Yeah, exactly. Just failing blocks like to figure out if our testnet is stable and everybody is in agreement, which I figure it will not be because the gas layer changes. So there will definitely be some discrepancies. And yeah, it would be nice to identify the failing block as quickly as possible.
00:38:38.390 - 00:38:44.340, Speaker G: I think we and Nethermind, ethereum, Js and Nethermind should be able to do it.
00:38:46.310 - 00:38:50.450, Speaker D: Not sure about automatically, but we can definitely get periodic updates.
00:38:52.230 - 00:39:23.470, Speaker C: Okay, yeah, good enough. Thanks. Just adding that maybe one week is a bit short as a turnaround, but yeah, we should be able to do it every two weeks at least. Cool.
00:39:23.540 - 00:39:26.118, Speaker A: Thanks, Gil. Anything else?
00:39:26.164 - 00:39:26.760, Speaker C: Us?
00:39:28.090 - 00:39:35.320, Speaker A: If not, I think that is it for this week. Thanks everybody. See you next time.
00:39:37.290 - 00:39:38.386, Speaker C: Thank you. Bye.

00:00:00.170 - 00:01:34.134, Speaker A: And so the idea is that today the topic will be pre compiled in the kind of context of ips and a little bit more general beyond that kind of using that as because the first ip that we have brought to condensation of course 7212 introduces in your pre compiled. So talking a little bit about the process as well for finalized ips to make it onto L2s, how to track that, maybe what pain points are there still does it even. The whole idea was that the IP process with standardization should give late with more confidence that implementing these features is derisk. So basically checking in, is that so far, does it feel like we're on track with that, all these kind of topics? So to get going basically with the agenda, I just wanted to very briefly kind of summarize where we are at so far. So basically we for now just copied the way eaps work in terms of the different statuses that they can be in. So basically the last status that an IP breaches is finalized. The idea there being that at that time there are no further changes to the ip allowed.
00:01:34.134 - 00:03:20.170, Speaker A: And that should give teams then confidence that if they implement that feature exactly by the spec, then all teams implement doing that will end up with the exact same version. Of course, as I was saying, seven to twelve is the only IP in final for now. And then in terms of pre compiled specifically, you might remember we were talking with cordevs on Mainet with regards to how they think about kind of avoiding collisions in terms of pre compile addresses. Also making sure that if they ever want to chip an IP pre compile as well, that that kind of is done in a good way. And the consensus there was that we were handed a separate pre compile range, so at basically addresses 256 and up, and that Mainet wants to basically wait with talking about reusing IP precompile addresses until they are ready to ship the first IP precompower themselves, which also very plausibly could be seven to twelve. So that's kind of where we are at currently with pre compiles. And then of course there are a few interesting questions we can get into in this call, but I thought it might be, might be a good idea to start by having someone from the faith team from the seven to twelve authors briefly kind of summarize basically what has happened since finalization.
00:03:21.970 - 00:03:56.594, Speaker B: Sure. Thanks for the intro. I guess for now there are three roll ups that are committed to implement the rip, and they also started implementation in their code base. The first one was a polygon site. They requested a polygon improvement proposal and we have prepared it. It's PiP 27. Then we have discussed it in a few of the community calls.
00:03:56.594 - 00:04:56.090, Speaker B: Then they have included the proposal in their next hard fork. It's Napoli hard fork I guess. The testnet release was this week and the main net release should be the following weeks. And the next one is the casing. They are ready in the implementation of the pre compile and its circuits, but it's waiting the next vm upgrades and they say that it might be in this April and the circuits and all requirements for the pre compiler is done, but we are waiting the next VM upgrade in their side. And also the optimism team started their implementation in their code base. There is a draft pr in the code base.
00:04:56.090 - 00:05:17.300, Speaker B: I think it's also ready and scheduled for one of the next hard forks. It's I guess fjord hard fork. I hope I'm not missing any of the roll ups. And I have seen that the Elmos has done an implementation in the cosmos side.
00:05:23.830 - 00:06:14.670, Speaker A: Okay, yeah, thank you. I guess it also already brings us this time. I only have a few kind of parts that I prepared on the open questions section, then we can go to open discussion. But one of those specifically I think fits very well here. And that's kind of the question of how to keep track of implementation status in l two s. Once an ip reaches final, of course the question is how fine do we want to be there? I don't think it makes sense to necessarily distinguish between interest and then commitment, but at some point basically we have to indicate, okay, this is about to be shipped and then this is now live on a specific. And Carl, I think we talked about this briefly.
00:06:14.670 - 00:06:22.600, Speaker A: Could you briefly kind of summarize our thinking so far and kind of the idea for tracking we had?
00:06:25.540 - 00:06:27.424, Speaker C: Yeah, I mean basically it would be.
00:06:27.462 - 00:06:28.930, Speaker A: Nice as a.
00:06:31.540 - 00:07:56.684, Speaker C: Developer who's wanting to deploy a contract to multiple Altus to be able to have a single place they can know whether they can use a feature and have better oversight if they should ship something that supports a pre compile or not, that kind of thing. And so the idea is that as a part of the rip repo we can also have a small registry which basically only contains finalized rips. And when they are finalized that we can show who has implemented what, exactly what's in there and how that is formatted is still something that's kind of open currently. I just have a little JSON file, but it's very empty because there's one rip and no one has shipped it to mainnet yet. And so that is not super helpful, but as Ulas was pointing out, we already have many implementations of this, and I see in the chat there's some more, so it would be nice to have insight into that with reasonable ease. And so that's hopefully what this will be. And then as it gets shipped from all two sites, everyone's welcome to just make prs to add themselves to this.
00:07:56.722 - 00:07:59.276, Speaker A: Registry of hey, we've shipped it, but.
00:07:59.298 - 00:08:05.840, Speaker C: Again, it's only if you have exactly implemented said rip as per the specs.
00:08:12.330 - 00:08:22.220, Speaker A: Awesome. You said you already created that file. Is it already in the repo so we could link it or if there's a pr or something.
00:08:24.350 - 00:08:31.246, Speaker C: I'll drop a link in the chat, it's a branch. I'll open the pr today, but just.
00:08:31.268 - 00:08:40.480, Speaker A: For people to take a look. Absolutely. Yeah. How that will look like awesome I have a question. Yes.
00:08:40.930 - 00:08:48.530, Speaker B: How should be the decision of which chains or roll ups should be included in this registry?
00:08:51.670 - 00:09:01.560, Speaker C: I think that's going to be one of the most difficult questions of the poll roll call and rips process in general. The idea is basically.
00:09:05.210 - 00:09:05.766, Speaker D: If you're in.
00:09:05.788 - 00:09:11.018, Speaker C: The greater ecosystem and you vaguely look like a roll up, then I think.
00:09:11.024 - 00:09:12.426, Speaker A: The answer is going to be we're going to include you.
00:09:12.448 - 00:09:14.026, Speaker C: So sort of default inclusion as to.
00:09:14.048 - 00:09:15.050, Speaker A: Exclusion.
00:09:16.910 - 00:09:18.540, Speaker C: And for some things where.
00:09:20.350 - 00:09:20.714, Speaker A: Even.
00:09:20.752 - 00:09:50.286, Speaker C: If for example, Rip is not getting shipped on other EVM chains, not necessarily l two s, I would even consider including that in there. So yeah, in general just default inclusion as opposed to exclusion up to the point where it starts becoming too noisy to interpret. The point of this process is not to define who is and isn't a roll up, l two, but more just.
00:09:50.308 - 00:10:52.790, Speaker A: To be a useful resource. Right. One question that I would have maybe briefly on this point or not the point of who is in the l two that maybe we don't want to talk about. But in terms of tracking which l twos have shipped this of course on the ERP side we have like a somewhat fine grained difference between draft and then review and final call before we get to final. So is there any use, would people here think, that they would basically be used to for tracking, starting to track basically as l two s start to either consider shipping in Ip or say once they have made that decision, but are still in the process of implementing it and bringing it to the l two? So we said too fine grained and basically it only makes sense to track once it goes live.
00:11:01.010 - 00:11:03.810, Speaker C: My personal stance on this is that it's too fine grained.
00:11:05.590 - 00:11:06.798, Speaker A: Just that there's.
00:11:06.814 - 00:11:50.000, Speaker C: A lot of status changes and many different levels of staging, and I think it becomes something that would need to be policed a lot more or just have a bunch of attention paid to it. Whereas if it's just like is this on main net? I think that's much easier. I guess one exception, like a week of formula, this would be, is it on a testnet? And then we can include testnets. There's a separate thing which I would be open to. I guess the question becomes who are we trying to serve with us? Because I feel like testnets are mostly used internal to all the various roll ups as opposed to main nets, which are external. But maybe I'mistaken. About.
00:11:57.240 - 00:12:29.570, Speaker A: Yep, sounds reasonable. We have a question in chat. Vice is asking whether there's something equivalent to the test suite that we have for Mainnet EVM for this IP. So of course this is the first time we kind of have some standardization around a feature that's not equivalent to what we do on Mainet. So I personally haven't kind of thought about this much yet, and I think it's a really good question.
00:12:30.100 - 00:12:30.704, Speaker E: I don't know.
00:12:30.742 - 00:12:46.532, Speaker A: I see we have Ari on the call. Of course you're on the DevOps side. I don't know, how close are you to testing? Could you briefly talk about maybe what it would take for features like that?
00:12:46.586 - 00:12:47.108, Speaker D: I mean, I don't know.
00:12:47.114 - 00:12:50.688, Speaker A: I don't want to put you on the spot, but if you have thoughts on this maybe.
00:12:50.794 - 00:12:52.840, Speaker F: Yeah, could you just repeat the question one more time?
00:12:52.910 - 00:13:24.850, Speaker A: Sorry, of course. So it's basically the question from Chad. So of course we have Ethereum tests for eips and for changes to the main net EVM. How open would that be to basically adding as the canonical place to also have IP tests? Or is it something that your intuition would be that you would need our own testing suite for non main net for ips? Basically.
00:13:27.640 - 00:13:57.870, Speaker F: I'm not sure if we should add it in the same place, but definitely could probably fork the repo and implement whatever that needs to be done in the fork. I think that's probably an easier way to go, especially I haven't gotten deep into the l two world yet. Is most of the testing happening? Are we talking about the spec tests or hive or testnets or which layer of testing are we talking about?
00:14:05.480 - 00:14:14.200, Speaker A: Maybe Eliza, if you wrote the comment, do you have some perspective on kind of how you think about testing?
00:14:17.500 - 00:14:45.244, Speaker G: I'm not sure. It's just as roll ups maintain compatibility, but add new features and eagerly implement new eips I wonder what's the best way to validate that everyone has a consistent implementation? I would imagine that it would sound reasonable to add these tests in the Ethereum test repo under a specific folder.
00:14:45.292 - 00:14:46.050, Speaker E: Such as.
00:14:47.880 - 00:15:13.870, Speaker G: I don't know, roll ups or prospective eips, mainly because all the logic has been implemented, like the runner and so on. And they do extensive pre compiled tests mainly also because I don't know how we would do it otherwise. I mean, the fork sounds reasonable, but then we have to rebase every time. But I guess it's an implementation detail.
00:15:16.800 - 00:15:17.324, Speaker A: All right.
00:15:17.362 - 00:16:12.972, Speaker F: I think there'll be like one or two things, so the first one would be generating the tests themselves. I think the test execution tool in question would then be retest eth, and I guess for that one it does make sense to probably fork that and support it. The higher level test part is hive, which usually takes in an expected input, expected output, and then asserts what's going on. And I think that would also probably make sense as a fork, because then you can add the definitions for all the L2s in there, and any change in the definitions of an EL in the L1 wouldn't affect you guys. So it probably does make sense to like you said, it's an implementation detail, but I think most of the infrastructure is built such that you can fork it and probably continue supporting the same thing.
00:16:13.026 - 00:16:17.196, Speaker A: But for roll ups that sounds reasonable.
00:16:17.228 - 00:16:42.740, Speaker G: But for example, for techout we don't use RS tests. I don't know how to pronounce it, the runner for the EF test, we have a custom runner, but we still use all the JSON and all the, as you said, the prestate and post state assertions. So even this kind of standardization somewhat has differences.
00:16:49.610 - 00:17:14.500, Speaker D: I would recommend not using retest apps and using either that custom format or looking at the execution test specs so that the real output is the test file, not necessarily the fillers. And that's just because from core devs we're looking at trying to get rid of retest death and just use the execution tests. So retest death might not get maintained much longer.
00:17:17.110 - 00:17:24.374, Speaker G: How about just then the execution test, the JSON files that have the pre.
00:17:24.412 - 00:18:05.540, Speaker D: And post assertions, I mean, that's ultimately what test harnesses will consume. So however we get there is fine. You could have a custom program that outputs it, as long as it's repeatable and verifiable. And if we're doing something like verifying not just the layout of a pre compiled call, but the actual math behind it backing those tests by an implementation that is, the quote unquote implementation would be great. And we could use like if it's in Python or C or whatever to generate test vectors from that. That I think would be fine. I don't think we need to obsess with creating retest death quality fillers as long as we have some way to regenerate them and can verify what each step means.
00:18:09.110 - 00:18:38.320, Speaker F: I definitely think having Mario in one of these spells would probably help there, because he's also looking at how to best move away from retest Ethan, where execution spec tests, et cetera, fits in perfectly. And additionally, he's been thinking of how to set up this whole workflow for vertical tests where there are quite a few things that are drastically different from how things happen right now. And probably inheriting that same logic for rips would make sense.
00:18:45.330 - 00:19:19.290, Speaker E: On the last call there was like a discussion about fees, and so I was just wondering what if different roll ups when they implemented certain AP, for instance, this one of a pre compile, they have different costs for it. Will that still be considered as supported pre compile or not? And if it will be, then I'm not exactly sure whether if tests will work, because if I recall correctly, though I've never worked closely with them, I think they would require fully gas equivalent behavior to work correctly.
00:19:22.690 - 00:20:16.410, Speaker A: Right. So for now this is actually a really good question. But for now we still basically do the lazy thing where the ips fully specifies all behavior, including the exact gas pricing. And so if ll two would be uncomfortable with that gas pricing, then that would technically not count as shipping the same ip. And then I think it would be a really good conversation to have, like what do we do in these cases? Technically, if there was any other type of behavior change, what we would recommend is just shipping it at a different address because it's a slightly different pre compile, of course pricing. That's what we talked about last call. In principle, we would want to get to a world where you could have the same features and just different pricing.
00:20:16.410 - 00:20:42.710, Speaker A: We just don't have a system for that yet. So if there's an l two right now, for example, that does consider doing that with l one, then I think there would be an interesting conversation to have, whether to still ship that at the same address or not. And then how to keep track of that is a modified version. But in general, with maybe the exception of gas pricing, the idea would be that modified versions should be shipped at different addresses because they're not quite identical.
00:20:43.290 - 00:21:14.580, Speaker H: I think maybe a way to solve this is if the rip for each pre compile specifies the maximum cost, the one that no one would be charging more, and then others can have a refund mechanism at the end of the transaction, just like when refunding or other things. And this way the code is not disrupted by the different pricing, but they can still make it cheaper on their roll up if they're able to sustain it.
00:21:15.750 - 00:21:23.780, Speaker G: And how would we pick the highest price? Sorry? How would we pick the max price?
00:21:26.090 - 00:21:57.760, Speaker H: Yeah, this has to be agreed by everyone. No one thinks that this needs to be more expensive in order to be sustainable on their chain. And then other chains that can make it cheaper can just have a post transaction refund. It's not ideal, but. It's not ideal, but we should be able to reach a certain price that no one thinks that it should cost more. Wouldn't it be possible?
00:22:02.850 - 00:22:03.262, Speaker A: Okay.
00:22:03.316 - 00:22:14.340, Speaker H: I mean, no one, no one would. No one would say that it has to be more expensive than. I'm taking it to extreme. No one would say that it's more expensive than an EVM implementation of the same functionality. Right.
00:22:15.030 - 00:22:19.960, Speaker D: I think some zks would want it. For example, like if Kachek were pre compiled, they'd absolutely.
00:22:21.050 - 00:22:23.590, Speaker H: Oh, right, yes. Okay.
00:22:23.660 - 00:22:23.894, Speaker A: Yes.
00:22:23.932 - 00:22:38.634, Speaker H: So you're right. So maybe refund is not sufficient here. We will separate address, like a different address for this, but it kind of negates the value of having an rip to begin with.
00:22:38.832 - 00:23:38.830, Speaker D: So I'd like to add two points to this. First, we've changed the price to pre compile on mainnet before Modi. XP has had two different versions, and it's even got issues depending upon how you implement it, whether or not how you handle your even moduluses. But I think that gets a second issue in that I think we should seriously consider mechanisms to disconnect the gas schedule from the EVM execution. And that would include pre compiles, because with zks, for example, there might be systems, there might be evms that are more efficient on some operations, some that are less efficient, they might want to distinguish themselves by gas schedule. And as we've learned in the past, when we've had to manipulate the gas schedule for things like storage, it's broken contracts before and it's ready a recommendation among auditors never to depend on specific gas costs. So I really think we should get in a direction where the gas cost is separated from the actual execution of the pre compile.
00:23:44.500 - 00:23:53.236, Speaker A: Yeah, I think you go ahead, right? I'm not sure. Were you on last week's call when we talked about fee markets, I had.
00:23:53.258 - 00:23:55.670, Speaker D: Another call that I couldn't make at the same time.
00:23:57.160 - 00:25:10.910, Speaker A: No worries. Yeah, so basically we also talked a little about that and indeed kind of. I also brought up UF as of course a way to remove gas observability. And then especially say I could in the future imagine that there might be l twos that only support UAP mandatory, and in that world would be much easier to then indeed kind of disconnect the specific schedule from the EVM implementation. And yes, and that was mentioned as one desirable outcome. I also separately, like my takeaway from last week's call was that for most teams, this is lower priority even on the ZK side people, while a little grumbling about different kind of efficiencies of different precomplants and whatnot for now are fine with making it work. The more principled approach in general, specifically for say ZK proving, would be to basically introduce a way to just have kind of like a multidimensional fee market that could basically give pre compilers an extra kind of prover gas cost or something.
00:25:10.910 - 00:26:20.548, Speaker A: But in either of these cases, basically whether we do the very simple, just agree on a maximum, whether we have remove gas observability, and we basically get to a world where you can just do more free repricing in general, or we do like multimedia pricing or some mix of those, and none of those are basically in a point right now where they can be shipped. Right. And so basically if we talk about say, where are we at with one week compile and whatnot, the idea is basically for now within the standardization process, we would have to stick with exactly agreed upon fees. And then this is basically something to follow up on now as a research process of how do we then move to a better and more principled world that allows more freedom for all tools that incur different costs. Yes, I think one of the takeaways here that needs to research and then to briefly follow up on the computational testing side as well. This is a similar situation. I just wasn't aware testing was not on my radar as a topic for today.
00:26:20.548 - 00:27:00.796, Speaker A: Otherwise we could have invited some testing people as well. But I think this is a really important topic that we should definitely follow up on. On a future breakout call maybe. And in particular, I think it is a question that will become more relevant as we have more ips that reach final. And as we have this distinction, like the r one pre compile we might bring to Mainet. So I would over time expect it to be implemented in all the main EVM clients and then over time also just be part of even the main net testing suite and everything. But there might well be ips in the future that just never get support in the upstream clients themselves and whatnot.
00:27:00.796 - 00:27:47.010, Speaker A: So I think basically testing is a part of a broader question around how do we think about support in all the levels of the stack, right, and all the different tooling, the different clients testing everywhere. How do we kind of maintain proper standardized support across all of these if they are no longer just we don't get them for free, because all the main tooling just implements that by default. So I think that's a question that deserves its own breakout call. Yeah, it was good to see that come up as well. Do we have anything further on that kind of general set of topics that might make sense to talk about now?
00:27:50.000 - 00:28:21.750, Speaker G: I just had one question about EOF, because we mentioned it as probably not this magic solution, but a good solution to remove gas from the application layer. And I wonder if anyone here that we know has started implementing it for roll ups and what it would look like. Because as I understand what you mentioned, EWF would remove the need to standardize gas cost between roll ups, like for eips or just in general gas pricing. But maybe I misunderstood this from last call.
00:28:23.820 - 00:28:46.396, Speaker D: So EOF is a candidate for Prague, the q three q four release. They haven't finalized scope. It might be out, it might be in. I'm pushing fridge to be in basis. We're working on final implementation of it. But when Geth gets an implementation, a lot of the roll ups are geth derivatives. So it's just going to be an issue of just updating the code.
00:28:46.396 - 00:29:11.110, Speaker D: And it works parallel with the other evms. It's actually just a container format for the EVM that's still the same underneath it. So for roll ups to get it, they would just need to update the geth code or do significant changes to the geth code to bring it in early. But I'm not aware that any implementations have seriously gone down the path of multiple schedules between the two. So a lot of gas schedule divergence just hasn't happened yet.
00:29:13.740 - 00:29:22.312, Speaker G: As I understand it, it's not ritual compatible, right? Or it removes the gas introspection from the code.
00:29:22.366 - 00:29:22.970, Speaker A: No.
00:29:26.640 - 00:30:10.170, Speaker D: The container itself. The EVM would run both legacy or EOF. You could probably configure it to say only EOF is accepted, but as far as code that is tagged as EOF, you don't have access to the opcodes that would allow you to do introspection for gas or allow you to do introspection for code. Now the legacy stuff that you could call into could also do that, just not through delegate. So in a way you could say that EOF, it's not backwards compatible to do those if you're going to go forward with EOF. And the only way a chain won't be able to do those is if the chain is entirely eoF. Otherwise you could call into a legacy contract and do gas introspection and your code, introspection and the legacy code.
00:30:10.170 - 00:30:15.930, Speaker D: So it's kind of know ring zero ring one stuff in intel. Probably a better way to think about.
00:30:17.500 - 00:30:32.400, Speaker G: Okay, because Kakot is still not in testnet, but probably mainnet is like within a year it would make sense to directly leapfrog to EOf then. But then kind of like alone in this state of Eof only chain.
00:30:33.780 - 00:30:38.050, Speaker D: I'm a huge advocate of EOf only chains. I have dreams about that.
00:30:38.420 - 00:30:40.470, Speaker G: That would be good, right?
00:30:42.040 - 00:30:45.270, Speaker D: Yes, there's a long list of things I think would be awesome.
00:30:46.760 - 00:31:41.364, Speaker A: Okay. Of course, just to mention that, right, because I agree that for the researchers, right. And from that point of view, it would be amazing to see that for the chain themselves, you do have to take into account that if you were to launch as UF only, and this is already assuming we ship it to Mainnet so that in general it's broadly supported, if we don't end up shipping it to Mainet, then I think it'll be more of an opinionated decision anyway, because then you'll have to rely on somewhat less broad support in the ecosystem. But even in the case of that, it already went live on Mainnet. Launching UF only means that a lot of projects that have already written their contracts not using UF would have to actively move on to newer versions using UF before they could be deployed. So it is not a very opinionated choice. And I agree.
00:31:41.364 - 00:32:55.230, Speaker A: I would also love to see this, but I just want to flag it because otherwise you might run into issues down the road. And just to very briefly clarify, how does this relate to changes? Daniel, you already mentioned that of course. The point is that even if you are on a chain that has both UF and legacy code that can do gas interspection, or even if you're on a chain that does not tip Uf at all, and you only have legacy code, and so all code can do gas introspection. The point is not that moving away from the main net gas schedule necessarily is impossible or breaks anything if we are in that world, it is just that contracts might have been written in a way inadvertently violating best practices of not relying on gas pricing that now breaks. Right. So basically if you have gas interspection as something you can use, it's just much easier to inadvertently write code that relies on specific relative gas prices being a specific way that then break. And so it's much harder to reason about will anything on the chain break as we move to a different gas schedule? Or even will just legacy contracts that want to be deployed that are not yet deployed be.
00:32:55.230 - 00:33:19.990, Speaker A: So basically the idea is with UF in the long run, once we are in a world where most contracts are UF contracts, independent of whether or not these chains still support legacy, the risk of systems breaking goes further and further down over time, as most contracts basically are just by their design, not possible to be vulnerable for this, if that makes sense.
00:33:22.220 - 00:33:50.690, Speaker G: I think it makes sense, especially if EOF dominion is like years away. But then I think it means rips could have gas cost up to implementers like roll ups. Or as you have mentioned, this idea of refund, which I'm not sure if someone refuted it or not, but we could just have rips have no gas in the specification. Is that what you mentioned?
00:33:54.530 - 00:34:38.320, Speaker A: Well, basically what I'm saying is there for now, just because we already have an IP, so we have to kind of ship this now somehow. I think for now it makes sense to stick with the default rule of everything has to be specified, including gas pricing. So for now we have a specific gas price for the r one pre compiled. If you want to support this pre compile, you have to use that specific gas price. Otherwise you can still chip it modified, but then ideally at a different address. But it is definitely something I think that we should just look into whether to what extent we can have flexibility there in the future, in what form. But I think it's important to make the distinction between what to do right now if you want to ship something right now, and what is more of a research question for the IP process.
00:34:41.570 - 00:35:29.550, Speaker E: Yeah, I just wanted to say that maybe one of the other options is what we're now basically discussing is whether or not to consider roll up supporting an rip. Maybe it's the same as with EVM, it's not like black and white. Besides just saying in repo where we will say okay, this rip supported by this and that roll up, besides the name of the roll up, we can say type of support, just reuse the same type system which Vitalik used for different zkvms and say, okay, if it supports absolutely the same interface but it has different gas costs, then we call it like type three or type four support. Don't remember the number, but you get the idea. Maybe that would be a better approach.
00:35:35.380 - 00:36:03.850, Speaker A: Yeah, I personally would be hesitant to basically do this now, I think because it's harder once you do something like that to move back away from it. So I think I would just basically want to put that on the list of approaches to consider. Once we kind of try to move away from. Just once we investigate moving away from. You have to use the exact same gas pricing if you want to support a pre compiler. But that's basically, I think, the default date we are in today.
00:36:04.780 - 00:36:41.750, Speaker E: The reason why I bring it up is why I didn't bring it up on the call about fees is because the KsynC error, it has inherently different fee model, it has very different gas pricing. So we didn't even attempt to maintain the same gas costs in the VM. So we didn't have problems that some costs in the VM are bad for us. And so I think it would be better and more representative for users if. Yes, it was mentioned that gas costs are not the same, but it is mentioned that a certain pre compiler can be fine, there, can be found there.
00:36:44.680 - 00:37:17.330, Speaker H: If I recall correctly, it even brong shortly after you launched there was a project that I should say carelessly deployed on Mainet without testing and could not transfer because the gas stipend for transfers was not enough. So projects tend to have, even if it's the wrong thing to do, projects seem to have these unexpected dependencies on gas prices. I don't remember which project it was. But you remember there was a project that broke this way.
00:37:17.700 - 00:37:24.400, Speaker E: Yeah, I remember. But maybe we should drive forward to not encourage this dependence.
00:37:25.000 - 00:37:35.910, Speaker H: Yes, I'm 100% with you on that. We don't want to encourage it, but we also don't want to break it if we can avoid it.
00:37:38.060 - 00:38:08.610, Speaker E: Okay, so for old opcodes like a store and et cetera, changing behavior can be dangerous. And instipants for transfers as the example which you brought up. But at least perhaps for new things we can explicitly say that okay, for this gas may or may not be supported. And as I already said, we can even add a certain disclaimer that okay, here it is supported, but gas pricing is different. So users are aware of that.
00:38:12.590 - 00:39:13.534, Speaker A: Yeah, you definitely have a point in that. Of course. Basically projects that want to use an ip pre compile or in the future, whatever opcode or whatever other features we standardize via ips, they will have to write their code more l two aware anyway because it can only run on l two s. So if in that context we already give guidance for hey, on this l two, you can't rely on the same gas pricing or something that actually might help. And in general it's good feedback because I just didn't think of that in thinking about what counts and does not count as having supported a specific IP that we just have to make to be aware that there are EVM systems that just don't use the main net gas pricing model at all. So we have to have some sort of system for what counts as support then in that context, and I guess just you have to use the exact same gas pricing of the IP does not work. I was not aware of that.
00:39:13.534 - 00:39:22.180, Speaker A: So we'll look into that. Good feedback. Anything else on this point of pricing in general?
00:39:26.790 - 00:40:01.150, Speaker D: So something to keep in the back of your mind, probably not related to precompile specifically, but when vertical ships, gas storage charges, particularly around storage, are going to change in the way they work. So we are going to have multiple worlds where roll ups will have the old world unless they move to vertical, which will be a big shift, but there'll be a time where they'll be on the old and the new. So there are going to be variations. Vertical is targeting 25 right now. It's considered the next merge. I think there's going to be a lot of effort to get it shipped.
00:40:05.680 - 00:40:11.790, Speaker G: Do you have a sense of if roll ups should adopt Veracle trees as well?
00:40:14.240 - 00:40:26.450, Speaker D: Some rollups have already done their own thing with storage, like going to sparse merkel. So I think diversity and storage tree implementations is going to be a feature of roll ups. Some may go to vertical, some may not.
00:40:28.500 - 00:40:42.628, Speaker G: Will it be visible from the application layer like the underlying because you said you would change gas cost, so maybe then it will break. Depending on the roll up and the storage layout, gas would probably be the.
00:40:42.634 - 00:41:02.716, Speaker D: Only way to do it if you were to check the gas before and after a store and see if it matches the old schedules. But like I said, most auditors consider such testing an anti pattern and I question if there is a need for it in smart contracts. I don't see how knowing whether you're on vertical or sparse or Patricia adds value to it, but I've been wrong.
00:41:02.818 - 00:41:23.830, Speaker H: So if I understand correctly, with vertical, the issue will not be only storage in the sense of s store, it's also loading contract since you are paying per chunk. So some things will unexpectedly cost more gas as they load more code.
00:41:25.560 - 00:41:35.880, Speaker D: I think the code loading overhead is probably going to be factored into the intrinsic. It might be figured into call as well. I think that's TBD.
00:41:38.460 - 00:41:39.210, Speaker H: Yeah.
00:41:41.740 - 00:41:47.020, Speaker G: And as it stands, Uf will ship before or after vertical, probably in terms of priority.
00:41:48.320 - 00:41:52.060, Speaker D: If you know the answers to that, let us know, because that's, we're currently debating.
00:41:52.400 - 00:41:53.150, Speaker A: Okay.
00:41:57.220 - 00:42:46.604, Speaker C: So just a little bit on timelines, on all of this, as I just mentioned, there is a lot of debating happening on the main net side, and as we speak, we're trying to hash these things out, things like vocal. The large problem with them from an implementation standpoint is it basically blocks all features for probably at least a year and a half on the execution layer side, possibly more. And so it becomes very hard to make a case for it when we have to hold off on features. And so just the decision needs to make sense in the greater context of what needs to be shipped. And so making a case for it also means making a case for not everything else for the next long time. And I think that's where the complexities are coming in. I think everyone wants vocal.
00:42:46.604 - 00:43:04.304, Speaker C: It's just a question of when exactly. And so I wouldn't immediately make, it's very hard to have insight into timelines here, and I wouldn't make any commitments or major plans based on presumed timelines quite yet. But I think in a few months time we'll have a lot more confidence.
00:43:04.352 - 00:43:07.590, Speaker A: In what the plans are here.
00:43:09.320 - 00:43:20.440, Speaker G: You said in order to ship Berkeley, one should stop, ethereum should stop shipping features for 1.5 years or right after Verco ships. We need to hold features just to stabilize.
00:43:20.780 - 00:43:48.100, Speaker C: No, before, just from a development standpoint, it's going to be very hard to get anything else done. I mean, there are arguments that we can do parallel work, but I think that only delays vertical and the other things. So I think in a realistic world, given all the testing requirements and whatever that come along with the hard fork, if we do do vocal, we're going to block features shipping until vocal. Like from the point where we commit to duvocal until vocal is shipped, most features will be blocked.
00:43:48.600 - 00:43:49.350, Speaker E: Okay.
00:44:00.300 - 00:45:34.980, Speaker A: I have one more topic on my kind of broad draft for the agenda. Is there anything else on this point? Otherwise I'd move on to that. Okay, right. So basically the other question was, well, there was this proposal a while ago about progressive pre compiles, but I would just want to take that as a general question of how do we make it easy for projects to write code across l two s that takes advantage of native implementations of features on the l twos where that is live and easily supports them, having some sort of fallback logic in case that is not. And ideally of course that would be forward compatible, where if it's deployed on an l two that does not yet support something natively, then it automatically can switch over once that support is shipped there. Of course the default, if we do nothing, could be that every app developer just has to manually write logic to check whether a pre compiler's life at a specific address, and if not just themselves, have to bring some alternative, just raw like solidity implementation of that same feature. The question is what kind of alternatives would we have? There is the lightweight approach of basically just having that some sort of lightweight erc feature.
00:45:34.980 - 00:47:01.590, Speaker A: So where basically we just have some sort of standardized, community maintained kind of equivalent implementation of IP pre compiles and stuff like that that people can use alternatively. And the question is, is there something more principled, more structured that we could do to do this? So just to briefly summarize the idea behind the progressive pre compiles that was basically saying that we could do it the other way around, we could have the solidity implementation be part of the official flows. Basically you could either just using normal universal deployers, I understand they don't work on all chains, but on most chains you could basically have a common address that just the solidity implementation lives at. And then you could manually go in. In this part of deploying the pre compile, you could basically just swap out the solipsy code at that address for the native implementation. Of course that's not where the path we are on right now with our dedicated pre compile address range, but I think it's important, kind of like as an idea that motivates this entire conversation. So I'm just wondering, do people have thoughts on how we can make support across multiple l twos that may or may not have shipped a specific feature yet, as seamless as possible? Is this something that has come up yet for people?
00:47:03.000 - 00:47:35.570, Speaker H: I think even though every contract could check for the existence of precompile it wants to use, maybe from gas perspective it might make sense to have one pre compile that lets you query whether certain rips are or not supported on the current chain, so at least it's going to be one call. And then if your contract uses multiple things, you just check what you can or cannot use there. Does that make sense?
00:47:44.620 - 00:47:55.550, Speaker A: Yes, that seems like a good building block to have, and to me that seems just like a good candidate for an IP in itself, for precompile like that.
00:47:58.480 - 00:48:33.370, Speaker G: Talking about rips, do we have a way to choose at which address the precompile should be deployed at? Because I noticed, for example, Aurora was using like a hash of some stuff, so it could not collide with l one. And then Anakar, you mentioned before that we don't know which eips are going to reach magnet and which are not, but you would ideally want to. For those that will reach, you would want the same address as Mainnet, and then for those that won't, then you want something that cannot collide. Is there standardization on this?
00:48:36.300 - 00:49:37.532, Speaker A: Right, so the status basically is that we talked with people on the quarter process side, on the mainnet side about this. Initially there were two ideas. One, to basically be opinionated about going into the same pre compile range as Mainet, and basically just then asking Mainnet to just skip the specific addresses used. But we ended up deciding that it would be easier to keep that separated. So of course all the kind of the very lowest addresses are mainet pre compiled. And the idea now was to limit this to explicitly say that only the first 256 addresses on Mainet are reserved for pinger piles, and then have the next for now 256 addresses above that be the dedicated l two IP standardization precompile range. So that's kind of what we're going with so far.
00:49:37.532 - 00:50:10.950, Speaker A: So the r one, seven to twelve IP, also as part of its specification, has a specific address that it is supposed to be deployed at, which is exactly number 256 because it's the first one in this IP range. So ideally all L2 wanting to ship this, should ship this at this address? Maybe. This is a good question, General. Is there anyone on this call that knows about maybe an l two that would not be able to ship it at that address?
00:50:22.070 - 00:50:39.560, Speaker G: To ship at this specific rip range we need, who says, okay, this pre compile is now accepted as an rip range. Is it accepted? Have we standardized the voting process to accept one?
00:50:41.450 - 00:51:44.358, Speaker A: So very importantly, the IP process and the governance, this is all strictly opt in. Just because we would accept an IP two or an RP pre compile to that range would not mean that now all the l two s are accepted to ship it, right? So you can still then pick and choose which ones you want to support and otherwise you just skip those addresses. Of course, there's still a somewhat limited number of addresses, although that is artificial. We could go up a lot, there's a lot of addresses before we start to have to worry about collisions. I think for now the idea is that we want to be very permissive. So any IP that comes with pre compiles that reaches finalization status can reserve an address if it ever becomes a problem. If someone proposes an IP that wants to ship 20 pre compiles and maybe we have to revisit that decision, but for now, as long as it's not an issue, we want to be just permissive.
00:51:44.358 - 00:51:50.160, Speaker A: But in general this should just be part of the IP process and we have to figure out the details out.
00:51:50.530 - 00:52:32.218, Speaker G: Okay, but then I guess on your other point, which was like someone proposes an RP with a pre compile and then in the meantime someone proposes like a yule or like a raw solidity implementation of it. For those who haven't had time to implement it in their ZK secrets or something else, then it might be prohibitively expensive. No, it will break the gas scheduling of the someone might have had low level secrets that are somewhat not so expensive, and then the implementation of solidity is prohibitively expensive for the roll up itself, but then they have to respect the pricing. Maybe, I don't know, just thinking out loud, right?
00:52:32.304 - 00:53:29.322, Speaker A: So any just solidity implementation would not benefit from special treatment and would not get special pricing. It's just a normal contract deployed somewhere with just normal pricing that it has to pay. So that might mean it's provitively expensive to use for applications, right? Just because it might be much more inefficient. So I think, for example, with r one, I'm not sure if we have anyone on here that remembers the details, but I think it's something like 300,000 gas for even the most efficient limitations versus I think 3000 or 4000 that the native version would cost. So that might make it prohibitive for some applications to use. But it's not a problem for the roll up itself because it just charges for normal contract execution. And the only way in which this contract might, there might be, might be an aspect that you don't just want to treat it normally.
00:53:29.322 - 00:55:15.290, Speaker A: Could be if we want to have a standardized address for the solidity implementation, and then we have these universal deployer systems that allow you on all unmodified EVM versions to deploy at the same address using create two logic. But of course there are some roll ups, especially ZK roll ups, that can't support this because they have different hashing systems. So like for example, I think Zksync is one of these examples. And so then the question is, do we just accept that on those roll ups we don't have the solidity implementation equivalent, solidity implementation of an preconfile at the same address, or would they maybe want to with features they don't want to implement natively, just physically manually deploy a contract at an address that matches the sanitization or something that I think is one of these open questions of how to best approach this. Yeah, I think maybe at some point we can also have either breakout call or just some sort of separate effort where we kind of bring in people that are actively on, on the, the user side kind of thinking about using say r one or whatever other ips we might be close to having. Primal actually bullish, given that you're doubling in role here between the AP author, but then you also have the claith app. Do you have intentions? I know that you're already live now on networks that don't yet of course have the r one pre compile.
00:55:15.290 - 00:55:29.460, Speaker A: How do you think in the long term about basically, I don't know whether you have thoughts, but about kind of the routing between the native implementations and just solidity equivalents for r one.
00:55:31.030 - 00:55:54.250, Speaker B: I think the missing part might be that we cannot provide the same address in every roll up. For example, in the case, in case the crate two gives different address than the rest of the EVM. So I feel like there is a lack of standardization for this kind of address selection.
00:56:01.990 - 00:56:57.590, Speaker A: Yeah, I think that is indeed a problem. So we have to figure out how to best do this. But maybe this is best led to the ERC side of things, right? In principle, the question here was more is there something kind of from the base layer from the EVM side that we could chip and we could change and we could specifically introduce this behavior that makes it easier for application developers. Otherwise we can always just leave it to the ERC process to have some sort of standardized logic of how to do all of this kind of routing in the absence of specialized features. And I agree with you from the very beginning of this conversation that it would be worth looking into shipping and sort of pre compile that exposes just information about what other features are live on any given chain.
00:56:59.770 - 00:58:14.814, Speaker G: Yeah, I think maybe we mentioned that some projects might want to deploy on many l two s, but if say two l two s have a specific rip and it's priced because it's priced low because they implemented it in their native ZK system, maybe the project chose them for this specific feature because it's cheap and this desire to standardize so that every roll up can have at least a solid implementation of it is maybe overkill because the projects will have chosen them for this specific feature because it's cheap and available, and maybe the project will not want to go in a roll up that has the solid diversion. We would have to validate thesis that projects would want the precompact to be available on every chain, even though on some chains it might be 20 times more expensive or ten times more expensive. Maybe they don't actually want that. And the work to get a solidity implementation audited and valid is a lot of work for something that is inherently some roll ups have some niche use.
00:58:14.852 - 00:59:12.284, Speaker A: Cases, I don't know. Yeah, that's a good point. I think the reason why this came up in the past was that specifically for this first ip that we had as a specific case study, there are one pre compile. They have indeed be projects, and largely all the projects that are also very interested in the pre compile, a lot of them are already live on several l two s and are using just politically implementations for the equivalent functionality. But that could be an artifact of, I mean a maybe the specifics of r one that is at least somewhat feasible to do that, and then b also just the timeline that a lot of those projects got started before it was clear that there would be such an ip, and so that just waiting was not an option. It could well be that for future changes. That's a pretty uncommon situation that there's even interest in that at all.
00:59:12.284 - 00:59:21.170, Speaker A: And so you might be right, that could be worth just revisiting once we have more real world experience with other ips in the future.
00:59:30.190 - 00:59:49.700, Speaker B: Have we done the decision of when to assign a new pre compile address for a new pre compiled rip? How many of the roll ups should accept the implementation, or every rip should get a next address?
00:59:52.230 - 01:00:55.288, Speaker A: Yeah, I think Eliza brought that question up a couple minutes ago. I think for now, just because we don't yet have such a thing as before finalization, having L2, signal support or anything. So I think for now we want to just be permissive and as long as there's a clear not spam, good faith IP that moves to final, we would assign addresses in that range, because there's also no issue in just skipping some. And in principle the range can grow relatively large. If we ever see that this becomes too popular and just becomes a problem, then I think we have to have a more proper mechanism in place. But for now, I think the idea is to earn the side of being permissive and permissionless. It's fun.
01:00:55.288 - 01:01:56.020, Speaker A: We always have a lot of people hop off the call on the hour mark, which makes sense. So the important topics should always be in the first hour of any roll call session. That's good to know. But also, I think we probably already, because those were the only topics that I had prepared to talk about. Of course, we have an open section in case there's anything else that hasn't come up yet, but otherwise, also, I think it's perfectly fine if this call does not run up quite on the 90 minutes. Are there kind of any remaining topics to talk about now? Okay, yeah. Then I think this is probably a good stopping point.
01:01:56.020 - 01:02:46.786, Speaker A: I think this was helpful. Again, I think, again, takeaway, kind of is that the a? We just have to really figure out the pricing situation. What does it mean to ship an IPU unmodified? Apparently just enforcing the same gas price is not a viable option because some EVM systems just have different pricing models. And then also in more longer term, kind of seeing how these are used, and then possibly adapting the system. But yeah, okay, that's end of that. Thanks everyone for showing up, and see you all next week will be a main role call again. So then we'll also have a brief retrospective of to what extent these breakout calls were useful and whether we want to keep having them in the future.
01:02:46.786 - 01:02:49.620, Speaker A: So, yeah, thanks everyone, and have a nice day.
01:02:50.870 - 01:02:51.860, Speaker C: Thank you.
01:02:52.950 - 01:02:53.970, Speaker A: See ya.
01:02:54.310 - 01:02:56.270, Speaker G: Bye too. Bye.

00:00:00.410 - 00:00:30.920, Speaker A: Hey everybody, welcome to the 24th EOF implementers call. This I think is the last EOf call before the all court does where we wanted to present. So I'm sure there's a lot of things to talk about with respect to that. In the meantime, maybe we just go through some updates from client teams really quickly and then move into that discussion. So does anybody have an update they want to share from the last few weeks?
00:00:32.090 - 00:00:46.586, Speaker B: Guido has been working on a new fuzzing framework. All the clients are working on it basis got support for it. So I think there's going to be a lot of great fuzzing support for whatever we propose because EF thing for some really good stuff on it.
00:00:46.608 - 00:00:48.490, Speaker A: So that's update from basic.
00:00:49.070 - 00:00:49.674, Speaker C: That's cool.
00:00:49.712 - 00:00:56.222, Speaker A: Do you happen to have a link to the interface he was proposing or is it not public?
00:00:56.276 - 00:01:00.160, Speaker B: Writing custom stuff into each client and writing it that way.
00:01:02.290 - 00:01:04.820, Speaker A: How do you add support for it?
00:01:05.270 - 00:01:07.700, Speaker B: He contacts you. He already has geth working.
00:01:09.270 - 00:01:10.610, Speaker A: Okay, cool.
00:01:10.760 - 00:01:18.070, Speaker B: Basically the question is do you have efficient APIs to get at just the EVM and not the entire data stack?
00:01:23.100 - 00:01:23.850, Speaker C: Awesome.
00:01:26.300 - 00:01:32.440, Speaker A: Anyone else updates from the last couple of weeks on implementation?
00:01:35.530 - 00:02:34.262, Speaker D: Yeah, in medium one we've implemented grade four as discussed last time, so it doesn't depend in any way on four eight four anymore. And it's a new kind of transactions that just based on 1559 transactions. This one is a bit more testing, but I think we'll be ready soon. We've also merged the EC recover implementation using EVM Max primitives, which was proof of concept work to see how EVM Max primitives work in practice, which we did during its proc hackathon. And I think that's mostly it. Regarding UF, we've also support running blockchain tests now. That's another thing related to testing.
00:02:34.262 - 00:02:35.360, Speaker D: That's it.
00:02:36.850 - 00:02:51.220, Speaker A: That's awesome. Thanks for that update. That's probably all of the client updates. Charles, do you have anything you want to share from the Viper side updates from the last couple of weeks?
00:02:52.230 - 00:02:55.700, Speaker C: No compiler updates. Cool.
00:02:56.070 - 00:03:02.360, Speaker A: Let's move on to spec updates and questions. Does anybody want to kick us off?
00:03:13.220 - 00:03:59.440, Speaker C: I was looking at the note that Andre put together. I think swap Mn would be good. And there's a couple different variations of it. Kind of you want to think about because the most general one requires kind of four immediates actually because you're like swapping anywhere in the stack, any two items in the stack, but usually you don't really want to do that. So I think that you can get better code size compression with a couple of different variants of swap.
00:04:02.260 - 00:04:04.560, Speaker D: Why would you need four immediate?
00:04:06.020 - 00:04:08.976, Speaker C: Because there's 1024 addressable items in the stack.
00:04:09.088 - 00:04:17.700, Speaker D: I see. But we limit swap and to 256 or 128, I think max.
00:04:21.500 - 00:05:20.970, Speaker C: If you allow one byte immediate, that already allows you to address 16 items for 256 total combinations, which is like one nibble per item. And then I think actually a lot of the swap and dupe operations can actually be dropped. I think if you look at EVM code, most swap and dupe operations are like through six maybe. So you can drop dupe seven and swap seven up and then you can add like swap Nm with. And then you can maybe add swap 23 as a specific instruction I think would be good. And then swap. Sorry, these are just kind of off the top of my head, actually.
00:05:20.970 - 00:06:10.020, Speaker C: Swap two three and then the swap with one immediate byte and then one with two immediate bytes. And I think that covers most cases. I. I'm trying to think if swap two m is useful. Yeah, you could get rid of swap two three and give swap two n instead. But the easiest thing to do is just have swap Nm with like two variants.
00:06:10.520 - 00:06:24.280, Speaker B: I've got a custom build of Besu that tracks live opcode usage and there are some higher order swaps that are used by current contracts all the way up to 16 ers that are actually executed.
00:06:24.620 - 00:06:34.990, Speaker C: I know that they're used, but I think the frequency is. There's a code versus usage versus opcode slot usage. Trade off, right?
00:06:38.640 - 00:07:02.100, Speaker B: Yeah. We're talking like ten hundred times less than some of them. But right now I'm looking at billions of operations and there's like 10 million calls of some of these high ones. Swap 16 is sub million, but you get to swap ten and eleven and they're still up in the tens of millions.
00:07:03.180 - 00:07:07.530, Speaker C: Right. I mean, that's like 1% of all swaps, right?
00:07:08.220 - 00:07:12.890, Speaker B: Right. And that's considering there's like almost 100 operations, that's not too bad.
00:07:16.780 - 00:07:20.300, Speaker C: I mean, they can be replaced with swap with one byte immediate.
00:07:21.600 - 00:07:22.350, Speaker E: Yeah.
00:07:23.520 - 00:07:32.350, Speaker C: I think another way to think about it, Dano, is like what if you were designing this from scratch? How many?
00:07:34.160 - 00:07:50.864, Speaker B: That's, I think where the friction in my mind is coming is if we design it from scratch, we're going to get more resistance. And they say we don't want to do this. We've already tried that before and we got pushback. So while you are right, if we design it from scratch, there's lots of great things we could do. There is going to be less likelihood.
00:07:50.912 - 00:07:55.450, Speaker C: We'Ll ship, it is trimming outputs very.
00:08:00.380 - 00:08:09.390, Speaker B: The more this differs from legacy EOF, the more testing surface we create and the more testing surface we create, people are going to be less and less comfortable with these changes.
00:08:10.400 - 00:08:30.880, Speaker C: Okay. In that case, I think the minimal useful swap Nm is like a single one which takes one byte immediate and you can adjust the top 16 items in the stack. And if one more app code, it would be swap Nm with two immediate bytes.
00:08:33.620 - 00:08:41.350, Speaker B: What if we just had swap Mn with two immediate bytes and didn't have the one byte variant? How would that work out? Code size?
00:08:42.440 - 00:08:46.680, Speaker C: I think that the one byte variant is actually more useful than the two byte variant.
00:08:47.100 - 00:08:54.680, Speaker B: Okay. But we would keep swap in that has full depth as well. Not full depth, 256 depth.
00:08:58.650 - 00:09:06.680, Speaker C: I think it's better to drop that one and add the two by immediate variant instead.
00:09:15.660 - 00:09:40.576, Speaker B: Yeah, and when you have the dupen and swap n as an EIP forever, and that also is some weight that grants opens up acceptance of the changes we're doing. So, I mean, that is the risk. If we go too far from that old EIP, we got a certain credibility says, hey, people have been asking us for literally years and then he's actually on this call.
00:09:40.598 - 00:09:42.050, Speaker C: Maybe he can chip in.
00:09:43.140 - 00:09:43.890, Speaker B: Yeah.
00:09:44.900 - 00:09:46.770, Speaker C: With his opinion on that.
00:09:50.040 - 00:10:05.470, Speaker B: If you and Asic go in with a combined front on this, I think that would help. If you both agreed on that, we could dispense with the year ago. It's like, well, we didn't even think of this years ago, so I think that would be a good argument if, you know, say we want this instead of that.
00:10:11.890 - 00:10:20.530, Speaker C: I mean, I'm not in ipsilon, so I can't even change any eips if I want. So all I get to do is provide feedback.
00:10:25.600 - 00:11:21.900, Speaker E: You can certainly push a pr to the IP repo for review. But specifically regarding swap n versus swap mn, I hear Dano's argument, but I think I would extend it that. I think at that time, for many of those years, we didn't truly have feedback from Viper. What would be the preference from Viper's perspective? From solidy's perspective, just the swap n was good enough. They don't actually see, like to be given a reason to have Mn, but it doesn't. I mean, apart from using one more immediate. It doesn't seem to have a downside to solidity.
00:11:21.900 - 00:11:48.630, Speaker E: But regarding all these other exotic variations of swaps and removing some of them, I think that probably is something we don't want to attempt at this stage. As Dano said, people are really afraid to take in any changes and the more we propose the less likely it is. But removing the highly specific ones.
00:11:50.940 - 00:11:51.208, Speaker B: I.
00:11:51.214 - 00:13:01.820, Speaker E: Guess kind of goes against the code density argument right? Because you already have these specific ones and if you remove them then you're going to replace it with a larger instruction in terms of bytes and just one more note regarding all of this is we had some earlier discussions how to handle opcode allocation in the sense that would we rename an opcode or change semantics or would we rather retire the opcode and introduce a new one? And I think for most of these cases in EOf we have chosen to do the second route which means we disable opcodes and we introduce new ones to avoid confusion. But I guess even in this case once the UF would go live in the future after that we could start reusing those old disabled opcodes if we would run out of space but I guess the current idea is that we don't try to repurpose opcodes and so just removing these old spots seems to be not very useful.
00:13:07.170 - 00:13:08.080, Speaker C: I see.
00:13:08.530 - 00:13:25.510, Speaker B: And leaving the old opcodes one of the advantages of retiring opcodes is if we get an assumption wrong like gas observability is actually important we could unretire the opcodes with a minimum of fuss. So that's one argument for not reusing old opcodes.
00:13:29.050 - 00:13:49.400, Speaker C: I think that the specialized variants are probably actually more useful than like swap 16 but I think it's not worth. Like I said the important one is swap nm at all.
00:13:54.450 - 00:14:18.630, Speaker E: I think you mentioned actually two different pieces. One is wifi would definitely prefer the MN to have the ability to swap any two locations but the second you mentioned is we actually go above the 256 limit. How strong are you feeling with the second case? What is the usual stack layout in viper?
00:14:19.930 - 00:14:22.440, Speaker C: Sorry, can you repeat that?
00:14:24.890 - 00:14:45.950, Speaker E: You want to access the entire stack, not just the top 256 items. And at some point we reduced it to the top 256 items to have a single byte immediate. I'm just wondering what is the stack layout of viper which would necessitate having access to the entire stack?
00:14:50.930 - 00:15:26.090, Speaker C: That's the four byte immediate one and I don't think that's super useful. Like in any case at some point you need to start spelling into memory and having more addressable stack just kind of pushes that out further the limit at which you need to do that. But in terms of stack scheduling being able to swap arbitrary, being able to generally swap two items in the stack is useful.
00:15:35.830 - 00:15:38.420, Speaker B: But how deeper typically need to go.
00:15:42.650 - 00:16:23.810, Speaker C: I think we're moving more things into the stack. So I think within 128 items would be good. But like I said, it's actually kind of not. The issue is like how much stack needs to be addressed. So I think that being able to address 256 items is plenty. And barring that, I think that being able to address 16 items is actually quite good already, because most of the time that you're doing stack scheduling, you're doing things that are kind of local, things that are kind of near the top of the stack.
00:16:33.420 - 00:17:21.080, Speaker E: Yeah, I think generally our assumption was that maybe that's the reason why initially there was little feedback from Viper. The assumption was that wiper is more memory heavy and uses the stack less. And maybe it didn't occur to us, but on this call, I guess just conscious of time, maybe we should move some of the swap discussion to the end. But probably we should also discuss this more async just to understand the requirements better. But to answer your original question, I personally don't really have any strong opinion whether it's swap n or MN. What I care about is that it becomes useful.
00:17:29.640 - 00:18:19.340, Speaker C: Yeah, my feedback is that the most useful thing, and I think solidity may or may not find this out eventually, is that swap NM is the most useful thing to have just because of how stack scheduling works. Like when you start to write a stack scheduling algorithm, it becomes very useful to be able to swap two things that are not at the top of the stack. But yeah, I think we can move on.
00:18:27.840 - 00:18:35.550, Speaker A: Andre, do you want to talk about the updated list of questions that you have or is there something else we want to talk about?
00:18:38.720 - 00:19:44.930, Speaker D: Can maybe let me share my screen. So first one was swapman, second one is deploy time validation of the subcontainers. And in general, I like the idea if we can elegantly achieve this. Originally we started with this before we realized data load in problem, and we were validating subcontinents recursively in the container during normal validation. And so ideas there were so far Charles suggestion to drop data load in completely, then we don't have a problem and we just validate data load argument at runtime. And another idea that we had is somehow also Charles also mentioned this somehow to provide the final deploy size.
00:19:48.680 - 00:19:49.044, Speaker B: In.
00:19:49.082 - 00:20:32.610, Speaker D: The container, I guess at factory deployment time, I guess, so that we can still validate data load in without having full data section. So it can be either we somehow add full subcontainer expected size in the header maybe, or data section expected size. That's just an idea. But yeah, no concrete proposals about this yet.
00:20:33.940 - 00:20:38.804, Speaker B: Has there been any thought of the security implications of recursive validation, I think.
00:20:38.842 - 00:20:59.560, Speaker D: It should be fine because we still validate every byte. It's still linear time. I think because it's still bound by full container size, it will just call the validation recursively. But in the end the size of the code being validated is bound by the outermost container.
00:21:03.780 - 00:21:07.510, Speaker B: And when you're deploying an inner container, would you then validate it again?
00:21:11.520 - 00:21:19.340, Speaker D: I think it's enough to validate that the size of the aux data is the same as expected or as declared.
00:21:22.570 - 00:21:22.934, Speaker C: Okay.
00:21:22.972 - 00:21:50.100, Speaker B: I mean, I'm fine with this. Just my concern is that we're going to hit some performance issues, and not just on exponential versus linear time, but I think even the linear time may be too expensive. Even though we're doing it one per byte, we're raising the constant of how much time we need to consider for each byte. Potentially there is a cap, but actually we're considering each byte multiple times because we have to step through it for each outer container and then come back and check it again. And my concern is security.
00:21:51.670 - 00:21:52.420, Speaker D: Good.
00:22:03.130 - 00:22:36.000, Speaker C: I think there's an argument to just also dropping data load. And like if we're looking for things to prune, I mean, I just, because it's kind of, it was already kind of causing this issue with recursive validation. And so, and I'm not sure that it's that useful that it merits thought.
00:22:37.090 - 00:23:37.092, Speaker B: Right. We can totally work around it with a push end data load. It's just code size expansion. But I don't know that that's worth the issue with the other complications it causes. So I could get behind it. So we already have container size encoded into the header for each subcontainer. So I think we implicitly get the subcontainer size.
00:23:37.092 - 00:24:01.420, Speaker B: And we could presume that extensions were fine, but dropping data load end solves the whole problem right there. We could presume that all data load ends are valid on subcontainer loads, but that's an extra validation mode. So first option solves most problems.
00:24:18.510 - 00:24:21.740, Speaker D: Yeah, it's simpler change for sure. I agree.
00:24:45.950 - 00:24:49.680, Speaker C: By the way, what is the behavior of data load on out of bounds data?
00:24:53.670 - 00:25:02.050, Speaker D: I think we opted for exceptional halt, similar to return data copy.
00:25:04.170 - 00:25:09.480, Speaker C: If it did the same thing as code copy. Well, actually, what does data copy do?
00:25:13.150 - 00:25:14.890, Speaker D: The same. Exceptional halt.
00:25:18.450 - 00:25:21.598, Speaker C: Does call data change in EOF?
00:25:21.774 - 00:25:28.430, Speaker D: No, you asked the data. If you meant call data, then call data stays the same, it returns zeros.
00:25:28.590 - 00:25:33.574, Speaker C: Because if data load just returned zeros, then I wouldn't have to validate data.
00:25:33.612 - 00:25:42.150, Speaker B: Load n, but return data copy ready respects the boundaries and exceptional halts. We have both solutions ready in opcodes.
00:25:43.630 - 00:25:57.440, Speaker C: Right. But code copy right now does return the zeros. So I'm just saying that if data load n returned zeros, then it wouldn't need to.
00:26:04.120 - 00:26:11.092, Speaker B: Is return data copy exceptional halting considered a plus or minus in the solidity.
00:26:11.156 - 00:26:32.830, Speaker C: And the smart contract community we discussed a couple weeks ago, or maybe four weeks ago now that it's a good thing because it helps with ABI validation and it doesn't change things. I think pavel was on that call.
00:26:36.020 - 00:26:54.310, Speaker E: I think it depends on who you ask, because a lot of people say it's a negative, it's irregular. That's why you also have to take care of return data size and all that.
00:26:55.720 - 00:27:45.630, Speaker C: Yeah, I originally thought it was a negative, but then after thinking about the alternative is actually good because you're always validating externally, like data that some other contract is giving back to you. So you need to validate it anyways that it's like within bounds. And so the exceptional halt is good, but data is always something that you have control over. Right now, I think solidity and Viper both use call data loading zeros past the end as like a zeroing trick. Like you can zero memory that way. So it's actually not a bad thing always to return zeros.
00:27:51.340 - 00:27:56.620, Speaker B: But if you still have it from call data copy, then you still have access to the zeroing trick.
00:28:00.400 - 00:29:08.420, Speaker C: Yeah, I'm aware of that. I'm just saying that one kind is not necessarily better than the other. And if data load n loads zeros, then first of all, you don't have to validate it. And second of all, you get actually very cheap way of loading zero data, which is cheaper than the call data thing, the call data copy thing. And same with data copy. And another thing is that the relative cost of code copy versus call data copy might change. So I don't know which direction they would change, but it might be beneficial in the future to be able to choose between the two.
00:29:08.420 - 00:29:25.450, Speaker C: Or we could just add an m zero opcode and then we wouldn't have to think about it. I was kind of joking. That's kind of a joke.
00:29:33.610 - 00:30:10.110, Speaker E: I think we actually did discuss m zero somewhere at some point. I think generally it's nice to have tricks, but I think with these tricks we get just too entangled in the tricks, which then in the end puts us in a position where it's hard to change or even change any kind of instructions or just exactly what came up here. Do we want to have tricks on an instruction, or do we want the instruction to be more like, pure? So following that logic, maybe m zero would be the right approach.
00:30:16.690 - 00:30:43.470, Speaker C: You can't actually do it for call data size, because normally you're loading the first four bytes of call data, like, the first thing every single contract does is like, call data load zero, and then figure out what to do with that. You can also do call data copy with four bytes, but that's more expensive.
00:31:04.280 - 00:31:30.670, Speaker E: With the deploy size of the subcontainer. What are the main questions and downsides? Would we error out if the auxiliary data plus the actual data doesn't end up matching the expected deploy size? Would we zero fill in that case?
00:31:37.940 - 00:31:40.770, Speaker C: I think the best behavior is to error out.
00:31:49.720 - 00:31:51.030, Speaker D: I think so too.
00:31:55.650 - 00:32:09.510, Speaker B: Also, consider the impact on auditors. If we have to refer to something as a trick, is it necessarily the right thing for a code auditor or opcode auditor to look at? Stuff that encourages simplicity, I think is valuable in that regard, but not a blocker.
00:32:11.050 - 00:32:21.676, Speaker C: I'm wondering, why does the existing code copy load zeros past the end? Does anybody here know everything?
00:32:21.778 - 00:32:23.420, Speaker B: Zero padded in the beginning.
00:32:32.980 - 00:33:01.370, Speaker E: Including division by zero. So with this deploy size, we would just put it into the. Would it be in the subcontainer header or the init code? I guess the subcontinent header.
00:33:03.730 - 00:33:17.730, Speaker D: Yeah, I'm thinking either subcontinent header. So it would have two sizes in, or maybe it could be data size of the subcontinent, but that's a bit weird.
00:33:18.790 - 00:34:19.880, Speaker C: Yeah, I'm thinking more about this, and I think for both return data and data load, like right now, they both kind of depend on the fact that everything is 32 byte padded. Like ABI always returns 32 byte padded stuff. And generally stuff that's in the data section is easier to work with if it's 32 byte padded. But if you were to have a scheme which packs data more tightly than if you return, like, un eight or something that's packed to one bit. So you just return one bit of return data, then return data loads, and data load start to have problems. And the only way I can see around that is if there's some weird wrapping behavior, like you allow data load of negative five or something, or return data load of negative five or something.
00:34:31.200 - 00:34:38.960, Speaker D: Not data load. And it allows addresses by single bytes, so you can read from any offset.
00:34:40.260 - 00:34:45.760, Speaker C: Yeah, but if the data section is only one byte, then data load will always fail.
00:34:46.520 - 00:34:54.556, Speaker D: All right. You would have to pad it.
00:34:54.578 - 00:34:55.310, Speaker E: I guess.
00:34:57.200 - 00:34:58.510, Speaker C: You would have to use.
00:35:09.510 - 00:35:13.342, Speaker D: Data copy is also working on auto.
00:35:13.406 - 00:35:16.040, Speaker C: Yeah, you can data copy. One byte. Exactly.
00:35:23.270 - 00:35:39.590, Speaker E: I'm sorry, I'm lost. What is the main concern we are having is that the data load n should be able to read less than words. Or are we afraid to put in the size into the header.
00:35:45.160 - 00:36:03.776, Speaker C: That the data section, that you might want to read some data towards the end of the data section. And the clearest example is the data section is only one byte. Yeah.
00:36:03.798 - 00:36:15.430, Speaker E: I mean, the data load then is a trade off and prefers the regular case. But there's always data copy, right?
00:36:16.920 - 00:37:31.860, Speaker C: Yeah. And I'm saying that the issue actually kind of is still there with return data load, and it kind of hasn't been uncovered by accident, which is that the ABI always has 32 byte padded data. Everything in the ABI is word aligned. But if we wanted to have some version of the ABI, which is not word aligned, which packs data more tightly, then return data load starts failing whenever the return data size is less than 32, which is kind of the same thing as what's going on with call data. Everything in the ABI is 32 byte padded except for method ids. And so with call data, you kind of need this zero padding behavior, actually to deal with cases where functions have no arguments and you only have the method id in call data. And so it's kind of, you can't really make call data load start airing out at this point.
00:37:56.300 - 00:38:28.790, Speaker E: You can also always manually zero petit the data section. And then even if your payload is one pipe, you can still use data load end. But I think getting into a position where we want to have multiple versions of data load in, I think we will lose the fight there. The answer would be then not have any data load in. I imagine that would be the answer, which I think would be in a worse position.
00:38:32.040 - 00:38:42.410, Speaker C: I'm not really proposing multiple versions of data load, and I'm just talking about the zero padding versus exceptional behavior for data loan and data load end.
00:38:43.180 - 00:39:00.684, Speaker E: But I don't see like a single byte has that with the zero padding useful because you can have it on the high byte. Right. So then you need to shift it, then it's cheaper. I think it's cheaper to pay the one time deploy cost as opposed to always paying the deploy cost to shift.
00:39:00.732 - 00:40:13.300, Speaker C: It's. You have to consider the deploy cost, which I think it's still probably cheaper to shift it than pad with zeros. And the issue also applies to return data load. And the issue is kind of more about whether you need to start to have edge cases to start padding data sections that are less than 32 bytes. And I think this is more a question of forward compatibility because right now I'll return data and probably all data sections are going to be 32 byte padding, but I think as code size, state size gets and gets more and more valuable, we are going to want to start packing stuff as much as possible.
00:40:28.050 - 00:40:45.860, Speaker A: There's about 15 minutes left on this call. I want to make sure that we resolve the things that absolutely need to be resolved on this call. Is it basically just these questions here or is there anything else that we really need sorted before all cortex next week?
00:41:03.790 - 00:41:15.760, Speaker E: Can we maybe spend like five minutes just going through this list and just making quick decisions so at least we have something to go with?
00:41:16.130 - 00:41:17.920, Speaker A: That sounds good. Yeah.
00:41:20.790 - 00:42:10.830, Speaker E: Maybe it's like raising hands. Anybody strongly against not including the deploy size and the subcontinent header. All right, then I guess let's try edit approach. Okay. Create f withdrawn. Create for the base cost of same as create two. Any strong reasons we should change these in any way? And if so, then any ideas what should be the cost? Be.
00:42:29.260 - 00:42:40.430, Speaker B: Those reflect, create one and create two prices. So I think they're reasonable unless performance dictates otherwise. And I think late gas schedule changes are a lot easier to handle. So I think we should just start there.
00:42:52.480 - 00:43:41.388, Speaker E: Yeah, I don't fully remember the reasoning around these prices. I think they were hiked because creation was too cheap and it was just like one of those random numbers which guess retroactively somebody fitted a model onto them. But yeah, I wouldn't try to change them at this point. However, there's one thing we did discuss changing is some of the init code pricing because Uf already charges for that and the limits. Maybe there could be some different handling compared to legacy there. The return contract pricing. I don't know.
00:43:41.388 - 00:43:42.990, Speaker E: Andre, do you want to.
00:43:48.400 - 00:44:13.540, Speaker D: I started with price zero because return is zero. But return contract is very different because it appends the data section. So it's all a fine operation, basically, and should probably charge for each word appended as copy instructions. At least.
00:44:34.530 - 00:44:59.720, Speaker E: Isn't all of this already loaded? So we're not loading it and then we are paying for. Yeah, it's loaded container plus the data pass, which is already in memory. So we pay for the expansion and then we are paying for storing the contract for byte. Right? I mean, I'm torn on this one.
00:45:01.790 - 00:45:29.300, Speaker C: Isn't it similar to return where the caller already kind of paid for memory expansion because like, return contract can only happen in a nit code mode. So you're already going to be paying per byte?
00:45:31.480 - 00:45:38.150, Speaker D: Actually, yeah. We are getting the aux data from memory. So memory expansion should be included too.
00:45:39.240 - 00:45:47.640, Speaker B: And I thought we were copying this into memory. So I don't know that we should do the memory expansion cost for the contract extension. We should charge for it separately.
00:45:53.230 - 00:46:05.730, Speaker C: I think all you need to do is make sure that the memory expansion is paid for. I think it should be consistent with the return rules.
00:46:08.070 - 00:46:20.600, Speaker B: So these contract, unlike legacy, the contract is not going to be sitting in memory when you load the contract. It's going to be somewhere else. So we're not getting return contract, we're not getting memory expansion paid for already.
00:46:22.250 - 00:46:25.370, Speaker C: Doesn't return contract refer to a buffer?
00:46:27.230 - 00:46:36.880, Speaker B: It doesn't refer to anything in memory that would violate code observability. It's going to refer to either something in the EOF container and create three or something in the transaction and create four.
00:46:39.410 - 00:46:39.774, Speaker E: Yeah.
00:46:39.812 - 00:46:45.870, Speaker D: It only returns to a section of data section that will be appended. And this is in memory.
00:46:47.250 - 00:46:54.260, Speaker B: Oh yeah. Okay. The data where dependent cost. Got it. Never mind, that was on the next line. I didn't read that far.
00:46:55.990 - 00:47:02.178, Speaker C: Yeah, it concatenates with the oxdata offset memory segment.
00:47:02.354 - 00:47:03.080, Speaker D: Yeah.
00:47:04.650 - 00:47:12.150, Speaker C: I think you just need to pay the memory expansion cost on that buffer, like if it's not already paid for, and then I think it's fine.
00:47:12.220 - 00:47:41.070, Speaker D: I mean, thing is, we are creating a new container by this appending. So we're doing a copy, I think that's how I look at, and that's how it is in implementation so far. Maybe not super optimized, but this is the straightforward way we copy from the original container to EVM's memory, to implementation memory, and copy this appended data appending it. I think it's a copy operation.
00:47:41.830 - 00:47:44.930, Speaker C: Aren't you already paying 200 guests per byte.
00:47:46.870 - 00:47:52.520, Speaker D: For deployment? Yes. Maybe that could cover it to you.
00:47:54.730 - 00:48:18.730, Speaker C: Yeah, because I think the workflow is like you call create three and then the unit code runs and then at some point you hit return contract, and then that just returns a slice to a buffer. Right. So that it's not actually copied until the code is actually deployed, at which point you pay 200 gas per byte.
00:48:35.230 - 00:49:25.920, Speaker E: But the reason you want to pay for some costs here if this would be a DOS vector. Right. But you're already paying 32,000 in order to execute code which can return return contract once. And I guess mostly the case of like create four. Well, the case of create three and create four. When we load this container, then we need to make sure that it's fairly priced. I think one thing you mentioned that for the Aux data, I think for the Aux data we do want to do memory expansion because they may just point to some large offset for Aux data.
00:49:25.920 - 00:49:45.960, Speaker E: Made a quick calculation with the current code size limits with zero aux data, this would be like a 2.3k like 2300 gas dispracing model here.
00:49:58.760 - 00:50:25.630, Speaker C: Yeah, I don't think there's a DOS thing because it just works the same as return, which returns a pointer to a buffer which has already been allocated and paid for expanded. So you do need to pay the memory expansion cost, but you don't need to pay for additional copy like with return data. The cost of copying is borne by the collar, and in this case it's borne by the collar of create three or create four.
00:50:31.780 - 00:50:46.470, Speaker D: Yeah, I'm still not very sure they are different because return contract does this appending. This is the different part, so it creates the new buffer with the deployed container cop is there.
00:50:48.300 - 00:51:54.820, Speaker E: I would suggest that maybe we avoid the cost, but explain this clearly in the security considerations of the relevant tip, and then I think that would be like a good starting point for all cordefs to actually understand it. And yeah, I think more eyes could easily decide whether this is a high enough risk to charge for it or not. I mean, I'm personally fine charging for it, but I think we need to review this more carefully. That's why I suggest that we document it in security considerations. But don't charge yet, because removing the charge I think it will be kind of impossible because we never remove anything, but adding it will be possible. Do you think this is a good idea as a suggestion?
00:51:59.240 - 00:52:00.790, Speaker D: Sounds good to me.
00:52:04.920 - 00:52:05.670, Speaker C: Same.
00:52:13.230 - 00:52:15.466, Speaker E: Andrea, do you want to go through the list?
00:52:15.648 - 00:53:00.802, Speaker D: Yeah, just to mention the next point. We discussed this internally and it was a bit unclear in the spec, and this is related to how creation transactions relate to EOF in general. And now the idea is that legacy creation transactions will not be valid with UF. So any transaction that has empty two and UF code in the data is invalid. And to deploy Uf you would always need to go through this. Create a contract which uses create form. So you will always need this new type of transaction and send it to create a contract.
00:53:00.802 - 00:54:38.830, Speaker D: And create a contract would need an irregular state change, probably to be deployed because there is no other way. If no question about this, then another create four thing is so this is during implementation, I stumble upon these limits are not defined for the create for transactions, for how many init containers we allow and how big are they. So for this size, maybe we can just rely on implicit limit of the container size or like section size. Actually not sure now, because this one is in the transaction. So maybe we still need a limit or at least define the cost. So the spec currently, yeah, it suggests to use the same cost as for call data. And the limit for the number of init codes in a transaction and for the size of each init code is not clear yet.
00:54:42.580 - 00:54:51.600, Speaker B: I think we should just rely on the external init code size restrictions rather than coding it in. Those I expect will be continued to be fairly global. Restrictions?
00:54:55.960 - 00:54:58.820, Speaker D: You mean the IP 38 60 restrictions?
00:55:01.560 - 00:55:09.980, Speaker B: Like the restrictions that say that init code can only be forty eight k and contracts can only be 32. And if you try and do a create four that violates those, the create four fails.
00:55:34.250 - 00:56:20.320, Speaker D: Yeah, I'm not sure. We had some discussion that this AP 38 64 should apply only to legacy creations, but not to AOF. But I'm not sure anyone what to do with transactions. What about the count of them? Do you have any idea how to limit it? We have a code section count limit to 1024 you could use that for. That's kind of a lot.
00:56:21.030 - 00:56:25.490, Speaker C: Aren't they kind of naturally bounded by the block gas limit?
00:56:30.490 - 00:56:51.440, Speaker B: Yeah, because there's a block gas limit and then there's the 128k limit that geth imposes for gossiping the transaction as well. So there's gossip will implied that, but it won't be hard and fast because nodes could still emit their own. And then the gas limit would force that to be a limit as well, because it all gets costed as call data.
00:56:54.210 - 00:57:03.860, Speaker C: Each create costs at least 32,000. Just real quick, 15 million into 32,000 is 469.
00:57:07.910 - 00:57:21.110, Speaker B: Plus call data cost of each create transaction, which probably less than 32,000. I mean that is an extreme case. We'll need to test the limit when we do testing.
00:57:39.980 - 00:58:17.730, Speaker E: Yeah, I think the only main argument to be had because the create four is like the specific blobs in the transaction. So the existing eIp for the init code limit, I guess, doesn't naturally cover it. So we need to either explicitly make it cover it, or we can make up specific limits based on the container sizes we have. And maybe that could be like one incentive for people to use us.
00:58:19.960 - 00:59:14.020, Speaker B: So here's another angle and that goes into the next step. Right now, the initial specs as we reference init codes by index. But for things like 4337, we may not be able to guarantee the index when bundled transactions get rebundled. What if we set the index limit to 256, thus any create four where that field has 31 leading zeros means that by index, but if it doesn't have 31 leading zeros, I mean, probably just say it doesn't have 20 leading zeros based on ODS. But if we set the limit based on that, then anything above that limit must be treated as a hash. So that way you could still put in your random list of contracts in there, and you could have your bundler reorder them in whatever order it chooses and then access those by the hash. If the opcode comes across with insufficient leading zeros, it then becomes a hash.
00:59:14.020 - 00:59:28.570, Speaker B: So based on that, 256 is a nice limit. Meaning if only the lowest byte is in use and all the other bytes are zeros, then that creates some rationale why we pick 256 out of the air.
01:00:03.720 - 01:00:07.240, Speaker E: I'm just doing some calculations in the awkward silence.
01:00:19.790 - 01:00:26.700, Speaker B: The awkward silence makes me concerned. This is too crazy of an idea, but people don't want to step up and say no.
01:00:30.230 - 01:00:40.280, Speaker E: Actually, I was considering like 256 for many of the limits. Then the code size was that because then it's just one byte, but it turned out to be too low.
01:00:44.000 - 01:00:57.410, Speaker B: But this is the number of different contracts you can put inside a single transaction. Unless we're talking like layer twos that have billion gas blocks or something.
01:01:02.030 - 01:01:17.760, Speaker E: Well, 256 with the 48K limit, it's like 48 million gas. So I guess 256 is as good as any other.
01:01:22.050 - 01:01:32.830, Speaker B: And it's got some rationale why we picked it rather than just fits in 15 million block or doesn't fit in 15 million block.
01:01:36.740 - 01:01:55.590, Speaker E: I mean, it depends on the size. But assuming most contracts are around the size limit, because people are constantly complaining, then it comes around like 40 million over 40 million. So yeah, it doesn't fit. It's high enough in that sense.
01:02:10.860 - 01:02:11.272, Speaker C: But.
01:02:11.326 - 01:02:19.310, Speaker E: At the same time, it kind of goes against the earlier argument, how much cleverness we want. Right, right.
01:02:27.350 - 01:02:35.110, Speaker B: Because we could just make crate for do only by hashes rather than by index, and then the size limit, the transaction is irrelevant.
01:02:36.490 - 01:02:44.010, Speaker C: By the way, what happens if you have a duplicate any codes in the transaction that have the same hash?
01:02:45.390 - 01:02:48.300, Speaker B: Then they're the same code and it doesn't matter which one we pick.
01:02:57.470 - 01:03:07.190, Speaker E: Yeah, unfortunately, with the indexing, we cannot deduplicate it. You would just pick the first matching one.
01:03:09.000 - 01:03:12.710, Speaker B: Which would be fine because it's indistinguishable from any later matching ones.
01:03:15.020 - 01:03:18.890, Speaker C: Yeah, but you're paying extra for the call data.
01:03:20.860 - 01:03:51.250, Speaker B: You're the fool. You're the one that assembled it. I mean, the downside of making all of them addressed by hash codes is it would make all to create fours longer because you'd have to have 32 bytes for each or have whatever hash we would use to look it up with. So index, if you know you're not going to be bundled in hash, maybe we could change the code that if an index lookup fails, then you look by hash. That might be another approach.
01:03:53.830 - 01:04:02.694, Speaker C: I think it's fine as long as you never want to expose the index in the EVM, like transaction index or something.
01:04:02.892 - 01:04:25.360, Speaker B: I'm actually concerned about exposing the index in the EVM because that presumes stuff about how you have to structure your transaction based on smart contract code. But I mean, you would also be actually passing it in through the stack, which could then be put in through external data. So it's not necessarily a bad idea. But if you're going to be passing in external data, you may as well pass in a hash as well.
01:04:27.410 - 01:04:27.774, Speaker C: Is.
01:04:27.812 - 01:04:34.100, Speaker E: The only concern with the hash addressing is the size it takes.
01:04:35.670 - 01:05:01.586, Speaker B: That's one negative. And then you'd have to index all of the addresses that come in. But more than just layer one use, I think there is layer two use for this. And then a layer two could have an entire stable of default smart contracts available by hash that you can instantiate that you don't have to reference in your transaction. So the whole index by hash is broader than layer one in full disclosure.
01:05:01.778 - 01:05:12.000, Speaker E: Yeah, but I mean, is the main concern for not going only with the hash is that it takes more space in the init code or were there any other concerns we found?
01:05:16.450 - 01:05:22.340, Speaker B: I don't think you'd want it in the init code. If you're going to put doing the init code, just load it in as a factory and create three.
01:05:23.590 - 01:05:49.126, Speaker C: I just think it feels a little weird that you're going through this bundle. Run the first init code, and then you run the second init code, but you're actually running some other init code, which is like, I know it's byte for byte identical, but I don't know if there's some weird statefulness that could come in that kind of has some weird behavior.
01:05:49.318 - 01:06:32.298, Speaker B: You'll have a new contract and new storage addresses to work off of. But that's a problem with existing creates anyway. I mean, thinking about how people are going to use create for, I really don't see them hard coding addresses or indexes. Well, maybe indexes into the transaction, but definitely not addresses. And indexes are much too brittle. So I think the typical use case we would see from create four is it would be passed in by call data, and then that's just a hash being passed in by call data. And that's not terribly expensive concern compared to the whole cost of the create four, because it's not occupying space in the code, it's not running up against your code limit.
01:06:32.298 - 01:06:35.040, Speaker B: Call data can be ridiculously large.
01:06:38.010 - 01:06:42.010, Speaker C: Can you disallow in the code with duplicate hash?
01:06:46.430 - 01:06:48.886, Speaker B: That would be a transaction validation rule.
01:06:49.078 - 01:06:51.580, Speaker E: If you don't have indexing, then yes.
01:06:56.210 - 01:07:01.730, Speaker C: Yeah, I think because they're referenced by hash, it makes sense to only have one in it code with that hash.
01:07:02.710 - 01:07:32.690, Speaker B: And I think another transaction validation rule would be it has to be an increasing order of the hash to make searching easier, which would implicitly there's something you would get out of your duplication check hanging anyway. You would need to order it. It would also make MeV searching against these a lot easier because you could validate that it's a valid transaction. Much easier if you require the hashes to be incrementing.
01:07:48.720 - 01:08:08.290, Speaker E: Yeah, I wonder, because we're like ten minutes over, not sure how much time people have. I mean, I should have left ten minutes ago, but should we still at least briefly discuss what is the plan for next all core devs? Or should we have an exceptional UF call next Wednesday as well?
01:08:15.760 - 01:08:19.250, Speaker B: I like the idea of a call next Wednesday. Gives us more time.
01:08:24.580 - 01:08:26.610, Speaker A: Sounds good. I can set it up.
01:08:33.780 - 01:08:58.612, Speaker E: Then. I think we should try to close off all these questions by then. Maybe async. I think we did close many of them. This big debate is the transaction limits and whether we go only with hash. I personally like the only hash idea, but I think we never invested enough time to see any of the downsides it may have. I do buy into the upsides.
01:08:58.612 - 01:09:13.010, Speaker E: I do like those, and especially like the transaction simplification parts. I just have no idea if there's any downside we haven't thought about, because I think nobody ever spent too much time on that.
01:09:22.100 - 01:09:23.090, Speaker A: Makes sense.
01:09:23.460 - 01:09:23.872, Speaker C: Yeah.
01:09:23.926 - 01:09:50.040, Speaker A: Let's look at these questions async and try and discuss them and resolve them via the EVM channel in the discord before next call. I just put it onto the protocol call calendar and I will add another agenda shortly for that call, and we can post any questions or specific things we want to talk about with respect to the Allcore devs meeting.
01:09:51.660 - 01:09:52.410, Speaker C: Cool.
01:09:54.300 - 01:09:59.690, Speaker A: I guess with that, let's just go ahead and end it. Thanks a lot for the discussion, everybody. We'll see you next week.
01:10:00.060 - 01:10:00.520, Speaker C: Thanks.
01:10:00.590 - 01:10:02.396, Speaker E: Bye. Thank you. Bye.

00:00:00.330 - 00:01:07.460, Speaker A: You okay? Hey, everyone. Welcome to our 24th 4844 call. I guess the main thing for today is chatting about Devnet six, where teams are at. Yeah, I had, like, a separate spec updates agenda point, but I guess we can but handle it all together under Devnet six. Maybe to kick us off, let's just go over any open issues as part of Barnabas's doc, and then we can go over your two prsinder and then any client main. Yeah. The first PR, the big change we agreed to oncodevs last week was updating the blob count to three and six.
00:01:07.460 - 00:01:37.738, Speaker A: So I know it was still contentious whether we want to do this on main net, but I guess for now, just want to agree that we are including this in the Devnet. The PR is still open, but the PR that's there is for the subnet. Okay, sorry, my bad. The PR was merged, I think, to the Eap. Yeah, sorry, I was looking at the wrong one. Okay. Yeah.
00:01:37.738 - 00:01:57.426, Speaker A: Okay, so this was the subnet one. So I guess it just got approved. We can probably just merge this. I'll post a link here. So there's that. And then there was another one for the engine API, which. Okay, sorry.
00:01:57.426 - 00:02:09.480, Speaker A: This is seven. Okay, so that one was the last change. And then 7123. Gizinder, you also posted about this one, but it's merged. What was that one? Sorry.
00:02:13.920 - 00:02:59.390, Speaker B: 7123 was just a clarification to how to basically pack the transaction payload in the network payload. So basically the transaction. So, network payload has four items. The first is the normal transaction payload, followed by blobs, commitments, and proof. And the normal transaction payload is the original payload that was defined on the top of the EIP. So people were getting confused how basically that transaction payload was to be packed. And this EIP just clarifies that.
00:03:03.900 - 00:03:22.460, Speaker A: Okay, and so this is already merged in. It's not listed explicitly in the specs for Devnet six, but I'm looking at it now. Does it actually change the semantic or it just changed the name to clarify? Right. It doesn't change any semantics.
00:03:22.880 - 00:03:26.400, Speaker B: It doesn't change any semantic, and it's just a clarification.
00:03:26.900 - 00:04:16.584, Speaker A: Got it. Okay. I also included it, so not author everything there. Okay, so is there anything we feel is missing from the Devnet six spec aside, this pr we just mentioned that's going to get merged? Okay, if not, then, yeah, I guess I'd be curious to hear from the different teams where they're at in terms of implementing things for the devnet. Or maybe, I guess. Barnabas, do you want to start with the current state of restarting Devnet six, and then we can hear from the different teams who maybe aren't already running on the devnet. Yeah, sure.
00:04:16.584 - 00:05:05.880, Speaker A: So the current devnet seems to be quite healthy, but this is just the pre six and we to be relaunching the net six with the three and six maximum blobs tomorrow morning. So that's the timeline and which clients do actually. Yeah. Shawi has a question. Why should the subnet count be six rather than the target size of three? Because there is a maximum of six. So in some blocks zero, one, two or three might be sent, but in some blocks up to six might be sent. And so you need the mesh available to send.
00:05:05.880 - 00:06:12.898, Speaker A: Otherwise you'd have to send multiple blobs on the same mesh, which is not the intent of decoupling. That makes sense. Sorry, I have another question, which is why we have to have these constants instead of just use the mix blobs per blob. Yeah, so we have the analog and attestations, and the number of attestation subnets is the same number of committees. But actually the needs of the consensus protocol might be different than the needs of the mesh. So for example, you can imagine where sending two blobs on per subnet actually is the optimal path given the constraints of the mesh. Even if you doubled the blob count.
00:06:12.898 - 00:07:12.710, Speaker A: That said, we could have the constant and just map it to. So we could have blob sidecar subnet count and map it to the max number of blobs for the time being. To be clear, this isn't just theoretical. Like for example, with the attitation subnet count, I have been considering in light of attestation load ways to kind of map or remap, or either have more or less subnets in relation to committees. So again, it's something that I think is a nice to have. We can just set it to the other constant there. Right now I feel like it should be a configuration and we can add the invariant test in the unit test.
00:07:12.710 - 00:08:02.890, Speaker A: If we want to make them the same for a while, then yeah, I think it doesn't look like a constance to me at the moment. Right. So I would have it as a configuration value. And I think having the unit test that just asserts that these configuration values are the same will help us because for now they're going to be the same. And so we'd want to explicitly change that test if we were explicitly changing that relationship. So I think that's okay. Sounds good to me.
00:08:02.890 - 00:08:11.750, Speaker A: Enrico, you also had a question.
00:08:13.160 - 00:09:01.300, Speaker B: Yeah, I was thinking about having those two different values was actually for having two different parameters to play with. And it's not immediate to me that is currently the right thing to do is rising them in parallel, always having them the same. Because maybe the needs of the mesh is a little bit different by just having more blobs on the network and maybe you want to lower down the bandwidth overhead, but still increasing the blobs. So I was thinking in the beginning that arising the maximum to six and leaving the number of subnets to four was actually intended.
00:09:05.660 - 00:09:43.668, Speaker A: Right now that's not intended. So everyone relays all the blobs. So having separate meshes and separate pathways per blob is the default intent. Unless we had indication that reusing one of the meshes or reusing some of the meshes for repeat blobs, that made sense. But by default we want them on separate meshes. So by default these values will be the same, but having those configuration values slightly separate so that we can adjust them if we want to, I think makes sense. Yeah.
00:09:43.754 - 00:10:02.900, Speaker B: Just thinking about the edge case where we want to have, let's say, 64 blobs. So at that point, do we really want to have dedicated 64 subnets and just having, let's say, eight at that point, or 16 and then reuse subnets for multiple blobs.
00:10:03.060 - 00:10:45.268, Speaker A: Yeah. And that's why the configuration values are separate, so that we can do that. When Shawway says she wants to add a test to the invariance, it's because by default we expect these things to be equal. And so we want to catch the error we had with the release the other day by default. And in the event that we do change it, then that would force us to have to change the test because we're no longer using that invariant. I think we're good on this. Tim.
00:10:45.268 - 00:11:14.270, Speaker A: Yeah. Shall we? Do we want to do a hot fix on this release or what? I missed the beginning. Are we intending to have this on Devnet six? Yes. Okay. I think it would make sense. Sorry. I think it doesn't change the test vector at all.
00:11:14.270 - 00:11:56.648, Speaker A: Very quick. Hot fix. Maybe just include this PI and focal from master Branch. Great, that's cool. Okay, so anything else on the specs? If not. So, Barnabas, you shared the fork. One for Devnet six.
00:11:56.648 - 00:12:25.252, Speaker A: So we have take who load, star, Lighthouse, Besu, get nethermine, Ethereum, JS. Which means we're missing nimbus, Prism and Aragon. I guess I'd be curious to start to hear from those teams if you have any updates or sort of expected timelines on when you think you can join the devnet. Yeah, I can give an update from. Sorry, interrupt you. Yes, give update from Prism side. So we're working towards more like production quality code.
00:12:25.252 - 00:12:56.572, Speaker A: So everything is taking slower now. I mean, we can participate in definite sales today, but we kind of want to make the code looks have more production grade before we join. So our timeline is like one to two weeks. But, yeah, feel free to start without us. I mean, at the same time, we can also try a hacky branch to join as well. I don't feel very strongly either way, so let me talk to my team and I will get back to you guys. Okay.
00:12:56.572 - 00:13:10.290, Speaker A: Barnaba proposed hacky branch, so. Yeah, we can start on that. Yeah. For Aragon. I haven't had a lot of time to update the fork. However, I am working with others on the. I don't know if Andrew's in the call to start up streaming some of that.
00:13:10.290 - 00:13:19.190, Speaker A: My goal anyway was to participate with the Aragon team on the mainline branch if at all possible. But we're a little bit behind on that.
00:13:20.360 - 00:13:48.430, Speaker B: Yeah, I am on the call. Roberto and Kairat and myself are working on some bits and pieces. So we still have to switch transactions to rop. And then also just double check that all the small changes are implemented and there are no missing bits. I reckon it will take a couple of weeks.
00:13:52.670 - 00:14:18.158, Speaker A: Okay. And I expect that's probably more like definite seven, then you'd be joining. Is that right? Right. Yeah. Cool. And then Nimbus, I think, is the other one. Yeah, I'm here still.
00:14:18.158 - 00:14:45.260, Speaker A: The big missing thing we have is block proposals that's made some progress. I have a pr that gets us part of the way that's up right now. I think if we want to join before proposals like we did for the previous Devnet, then we'll be good. Sometime this week. There's a few, just small. I mean, we've mostly tracked all the other changes, so we'd be ready sometime this week. I'd want to say, well, to be safe, end of the week, but maybe before.
00:14:45.260 - 00:15:27.722, Speaker A: So we can do that and then add proposals later. But I don't have a strong feeling as to whether we wait and join with proposals which would push that out to the following week or if Barnabas, if you want to have everyone join the can with or without proposals, then we can do that later. Yeah, I would push for that. I would want as many clients as possible to join this devnet, and then we can figure out proposals later. Cool. Okay. Because we have some stable clients to be able to produce enough blocks for finalization.
00:15:27.722 - 00:16:09.018, Speaker A: I'm not really worried about this. Just going to assign the validator keys to different clients. Cool. Anything else on the devnet or client implementation? And if not, it might be worth reopening up the conversation around the blob count. I know, Dengrad, you ran some other tests this weekend as well and we have some time, but yeah, before we do that, we would still want to hear from Bezu and guest, possibly for their. Yes. Yes.
00:16:09.018 - 00:16:43.702, Speaker A: Okay. Is there anyone from Baseu? I don't think there's anyone from Beisu on. Oh, sorry, sorry. Siri went crazy on my computer. Okay. I don't think there's anyone from Beisu. Marius, do you have a view on can you give an update on get or Roberto perhaps?
00:16:43.846 - 00:16:59.054, Speaker C: Yeah, so we're following, but I know that our current version has a bunch of bugs. One of them is that we probably will fail once the precomp file is.
00:16:59.092 - 00:16:59.680, Speaker A: Called.
00:17:03.170 - 00:17:28.390, Speaker C: Because we haven't updated the one dependency yet. Yeah, and I'm also not sure if we can actually create blocks and some of the engine API changes are not implemented yet. Yeah, I'm going to take care of that tomorrow morning, so I should be done by tomorrow.
00:17:32.010 - 00:17:54.646, Speaker A: Awesome. Thanks, I guess. Yeah. Any other client teams want to share an update? Even some of them already on the devnet? I wanted to give a small update on hive if that's. Yeah, please do. Yeah, we are currently in the process of updating the test. The engine API tests for three and six blobs.
00:17:54.646 - 00:18:26.080, Speaker A: So if anything wants to test their engine API changes in any way, just reach out and we can run this test for you. That's it. Okay, nice. And yeah, there's a comment. Nevermind. Is ready for the next Devnet or for the relaunch of v six? Anyone else?
00:18:28.210 - 00:18:34.260, Speaker B: Ethereum, js and lobster will be ready by tomorrow. We'll give the image to one of us.
00:18:35.990 - 00:18:40.020, Speaker A: Awesome. Yeah, lighthouse will be ready by tomorrow too.
00:18:43.680 - 00:19:04.710, Speaker B: Taco is ready. Just need to update subnet count. Should not be a problem. And yeah, the builder flow is in progress, but it's not strictly related to v six. But this is what we are currently working. Yeah.
00:19:11.950 - 00:19:55.544, Speaker A: Sounds good. Anyone else? Okay then I guess maybe for the blob count. Dankrad, do you want to start by giving an overview of the last set of tests you ran? And then Marius, maybe we can then chat about what you would like to see. To be convinced that three and six is a good target for main net and take it from there. Yes. Sorry. There's a thunderstorm in the background, so it might get a bit loud, but this is actually when you've sounded the cleanest in, like, the past five calls.
00:19:55.544 - 00:20:51.264, Speaker A: Well, wait for it. On Alex Stokes's suggestion, I wanted to run more experiments at 768 weekend, so I did a couple more runs. We have dashboards for them. I had a cursory lock. So far, I think all looks fine to me. I didn't see anything crazy happen, although what did happen was that, unfortunately, our endpoints seemed to have sinked over the weekend, so they were less reliable, and so the tests were a bit more randomized. So while we did hit the right average, I think on the second test, it was more like alternating between zero and 1.5
00:20:51.264 - 00:21:22.980, Speaker A: megabytes, I guess, which is also a good test. But, yeah, looked all okay to me as far as I could see. There are also some tests which I had to interrupt early because they went too crazy again because of the syncing nodes, also with very large blocks. Yeah. So I will send the link to those dashboards around, and you can have a look at these as well. Awesome. Thanks.
00:21:22.980 - 00:21:36.614, Speaker A: Okay. And I guess, yeah. Marius, do you want to kind of expand a bit on what you were sharing on Cordev? What would it take for you to be confident with? Three? Six.
00:21:36.812 - 00:22:38.890, Speaker C: So I had a bit of a think this last couple of days, and I came to the conclusion I still don't like it, and I would vote against it. But I came to the conclusion that it's not really my place to argue because I'm not a consensus layer developer. And I think the consensus layer devs, they are doing the block propagation. If they think that this is fine, then they should go for it, and it's on them. I just want to make clear that this is not coming back to me in any way, shape, or form. I said what I wanted to say, and I still think we should go the safe route and then increase it over time. But again, it's a decision that the consensus layer people have to do.
00:22:38.890 - 00:22:42.330, Speaker C: And if it breaks, it's on the consensus layer and not on the extension.
00:22:44.290 - 00:23:55.020, Speaker A: To add to that, I think that what you want to make sure when consensus layer devs are evaluating this is the interplay between the blob size and the block size that can be impacted by call data. Right. And the interplay between these two things does exist, and they might not think about that. And so I think your arguments are valid, even if you do then say to consensus devs, now make your decision. I guess just to point out, at least from the last call and subsequent conversations, I don't think the decision has been made by the relevant networking experts at the consensus layer. On the consensus layer, I think they're thinking about the data, thinking about the implications and other things. So I think this should be a continued conversation rather than a fixed point at this point.
00:23:55.020 - 00:24:06.420, Speaker A: Yes, that makes sense. Anyone else have thoughts or comments they want to share about this?
00:24:08.310 - 00:24:26.040, Speaker B: Just one thing, maybe it would have been nice to have the Lib p two p announcement in before going live with this. So having more efficient networking could help in this area.
00:24:27.770 - 00:24:30.230, Speaker A: Sorry, you say lib p to p announcement?
00:24:31.210 - 00:24:44.490, Speaker B: Yeah, the new lip to p spec announcement. I don't have all the choke messaging to have a more efficient network.
00:24:44.570 - 00:24:54.080, Speaker A: Right, okay, but you mean is there an announcement to be happening or is there just more discussion to happen around refinements to the spec?
00:24:56.230 - 00:25:23.770, Speaker B: Well, I haven't looked specifically on that, but looking at the overall benefit we could have on that area, I see a nice to have before actually going live and definitely increase bandwidth usage. So we have nice ideas and solutions there and having them, I see the benefit.
00:25:24.430 - 00:26:09.000, Speaker A: Right. So for some context there is I guess a working group of people both on synthesis layer teams and some discussion with the broader the PDP community on various spec enhancements and modifications to handle to try to reduce deduplication and a number of other things. I guess it would be important to figure out what of those are actually viable to ship soon versus ones that are going to take a long time in terms of conversation, refinement and testing. Do you have an intuition on that or is that something maybe we can talk about on the next call?
00:26:14.710 - 00:26:20.900, Speaker B: Well, not yet at the moment. Definitely something to still discuss.
00:26:21.830 - 00:26:30.790, Speaker A: Yeah, I know Anton's working on a doc that compiles all the various things, so we should bubble that up once he refines it a bit.
00:26:30.940 - 00:26:51.180, Speaker B: Yeah, definitely. We rely a lot on Anton because on our side he's taking care of that layer on networking. So once everything settles down there, definitely having our networking layer upgraded to reflect those specs changes.
00:26:59.640 - 00:27:54.250, Speaker A: Thank you. We could also have at least a simulation with this I don't want message, which is the new one to Lipido B, and try to see how big blocks, blocks and a number of blobs are affecting the network, at least on the simulation. Very concerned about the bandwidth or latency. Right. And I suppose if we are picking a number, assuming that people think three six looks safe based off experimental data and showing that in simulations, the spec improvements strictly improve things. Then that would be a movement towards strictly making three six safer. But there's a lot of little pieces to do between here and there.
00:27:54.250 - 00:28:12.140, Speaker A: Okay, anything else on the blood count?
00:28:12.830 - 00:28:38.530, Speaker D: Just another point. Has anyone reached out to Ethereum on arm, for example, to see if they have data collected for the call data test durations? Because I'd assume the main affected parties are going to be smaller nodes, and I don't think any of the EF nodes were resource constraint in any way. So perhaps it makes sense to also have some insight into their nodes.
00:28:40.630 - 00:29:12.790, Speaker A: Yeah, one thing that we do have at least the chain data for is things like attestation, correctness, inclusion, et cetera. So we don't see exactly arrival times, but if we don't see a precipitous dip in correctness and things like that, we know that at least validator nodes were seeing it on time. But I would certainly be down to talk to them or anyone else that has data. Yes.
00:29:12.880 - 00:29:38.680, Speaker D: Main reason is. Well, there's two things here. One is that at least according to a lot of stats, solo validators comprise like 10% ish of the network, which means even this change would most likely affect that percentage. So even if we do choose three six, it's not going to take the network down. But at least in the past, we've always made decisions keeping these 10% in mind.
00:29:53.500 - 00:30:00.170, Speaker A: Is there a way we could try to get them to run? I guess even on the Devnet it would really help.
00:30:00.700 - 00:30:13.116, Speaker D: Yeah, I think the Devnet ones won't really help just because there's not enough load. But they should have some sort of monitoring stack. I can reach out to them and see if we can get the data.
00:30:13.298 - 00:31:10.110, Speaker A: Yeah, that would be amazing. Any other comments on the blobs? So where does it stand right now? So I think we should keep 36 for now. That's sort of what we agreed to even at the end of the call that we would at least use it on the devnet. Yeah, but we're not really being that clear. We're saying we agreed to it for the Devnet, but we didn't agree to it for main net, but we merged it to all the specs and now we're kind of not clear. I don't like that it was merged to all of the specs because now it's just a lot harder. And one, two months to undo it.
00:31:10.110 - 00:31:55.800, Speaker A: Well, I guess, yeah, it'll be clear what we're going to do, but I don't know that we have the data or the confidence to make that call now. Right, right. But we're not going to get it after the Devnet, so it's just like. Right, but we do have data. We did run another experiment, and people that wanted to look at the data will continue to look at the data and think about it. I don't know if we can do much better than that, other than have a time limit on discussion and data analysis, I suppose. Yeah, I agree.
00:31:55.800 - 00:32:55.534, Speaker A: I think it's just weird, this whole situation with the Devnet doing three six on the Devnet is not going to help us in any way and doesn't move us closer to answering this, but instead just creates a lot of around what is the actual value? I don't understand that statement. For one, I disagree that it gives us no data. This is all running on a couple of data centers. This is not anywhere close to the actual topology of the network. So there's not much useful information we're going to get out of dealing with blobs, other than maybe the actual cpu processing of six blobs being bundled into the block. I disagree that it gives no data. I agree that it's not a test under mainnet condition.
00:32:55.534 - 00:33:39.982, Speaker A: And that is exactly why I ran these experiments, because that is the only thing that I can think of that gives us main net data. If you have something else that you can think of that gives us better data for Mainnet, then please suggest it. This is the thing that I could think of, and I did it right, and I think it was a great analysis. I'm just saying that we had a weird thing on the last all core devs where we kind of backtracked the decision to make it for Mainnet, but then we still did it for the Devnet. Well, it doesn't give us any networking information on the Devnet. Okay, but I mean, I kind of disagree with you here, because you seem to be suggesting that the default decision is to keep it at 24. And I don't know if that's right.
00:33:39.982 - 00:34:04.600, Speaker A: I mean, we just currently don't have a consensus on which of the two it is. I mean, two four was the original, and we didn't agree to that. Also wasn't reached in a consensus, in my opinion. So I'm not sure if that really is a valid thing. In my opinion, that was reached in the same kind of process. So I don't see how that's any more legitimate than three six. I don't think it is.
00:34:04.600 - 00:34:30.800, Speaker A: Sure. Okay. Yeah, I mean, two four has been around for a lot longer than three six. And this is what people have been expecting, and I think it's a lot less of an increase. I expected that, and I have vehemently opposed all of this time. To be fair, two four was put in as something of a placeholder while we were to conduct main net experiments. Experiments never happened.
00:34:30.800 - 00:35:09.310, Speaker A: So even before the main net experiments that DACA just conducted, I was worried if two four was safe. So I feel like now that we have that, and we should be having the conversation as to what the value is, because we failed to have that conversation at the start of the year, because we failed to get the data. Yeah, I agree. We weren't going three six. I'd want to be confirming two four right now. Right, I agree. That's kind of what I'm saying, is that we don't have a great idea for either two four or three six, but I don't think that we should continue increasing it before this conversation resolved.
00:35:09.310 - 00:36:03.034, Speaker A: So just pushing it forward to three six, it's like why we should just resolve the conversation about what the blob limit should be. And so far, I'm still waiting to hear what the consensus layer thinks on this. So I guess. Sorry, Ansgar, you had your hands up for a while. Is there anything you want to add? Yeah, I just wanted to briefly mention, I did mention in chat as well, that I think, to me, it's very important that we distinguish between the average case concerns and the attack concerns. Because I think before Marius came on to OrcaRdF plus core, the main considerations were always around average case and being able to basically handle the block side of things. And I think people felt reasonably confident that three six would at least be realistic enough to make it the default, then the kind of the concerns for basically the more tech case came in.
00:36:03.034 - 00:36:37.414, Speaker A: So what if the normal block also gets really big because people basically abuse the call data? That was just basically not the main considerations. If this is indeed a new concern, if we cannot address that, then I think it makes sense to fall back to two four again. But I think it's just too early in this process to say whether or not we have good ways to address this. I think there are really good ideas around just adjusting the quality pricing, and there are different flavors of this. Do we do it immediately? Do we do it in a light way? These kind of questions? But given that, I think we are still on track to make three six work by addressing these extra additional concerns. But we are not. Just not there yet.
00:36:37.414 - 00:37:20.044, Speaker A: But I think, again, the goal is still to get it there. I think it makes sense to move forward with it with the understanding that still there's things to be proven for us to not revert back to. I agree. You know, we might figure out something is actually wrong on the Devnet and that'll be useful. Yeah, Terrence? Yeah, I just want to chime in. Right. In terms of consensus layer feedback, it's kind of a chicken and egg problem because consensus layer cannot give feedback until we run like three, six or even higher blobs on a deaf net testnet under more stress environment.
00:37:20.044 - 00:38:04.316, Speaker A: The things we kind of worry about the most is when the blob doesn't arrive on the subnet. Then because of that, then we cannot import the blob to four choice. Then the node has to manually request the blob by root or something like that. But that's not something we can tell unless we have a devnet testnet under a war stress environment. Right. Which might argue for actually running a devnet with either low resource nodes so that those code paths for retrieving missing things are exercised. Or running a devnet for a day with 816 or something like that.
00:38:04.316 - 00:38:24.660, Speaker A: But again, that's less of can the network handle it? That's more of can consensus layer clients. When you hit these exceptional scenarios, exercise the code paths as intended, which is a very important thing, obviously. Yeah, I think it would be great to run that on a devnet with that type of environment.
00:38:28.350 - 00:38:33.470, Speaker D: Would it make a difference if it's a shadow fork or is this just a pure cl devnet?
00:38:36.280 - 00:38:55.782, Speaker A: I don't think that needs shadow fork. It's about finding for the given network, finding the blob threshold that is like right on the cusp, if not higher, so that these kind of exceptional code bounds are exercised. Got it.
00:38:55.836 - 00:39:47.414, Speaker D: So yeah, we can work on just setting up a low resource devnet. And I think there's a couple of Linux tools we could use to try and simulate some latency delays. It won't be perfect, but it'll tell us something. Also I'd make the case that we should probably use this to find not just the optimal, but also the highest we're willing to go and use. Holste. Whatever testnet exists as the time, as the place we're testing it. Because even though it won't give us the exact same network split as mainnet, it's way better than anything one team can spin up.
00:39:47.414 - 00:39:58.080, Speaker D: And if it doesn't work out so well on the testnets, then we could always scale it back down and we should probably do this earlier in the cycle rather than waiting later on.
00:40:03.780 - 00:40:04.960, Speaker A: Enrico.
00:40:08.070 - 00:41:18.070, Speaker B: Sorry, I was mute. Yeah, just one thing to add, like Terrence, some days, probably weeks ago mentioned. So the machinery and the logic in the consensus client to deal with the edge cases where the client sees partial blocks and blobs not completed. So those cases needs data actually to be fine tuned. So we have hard coded a couple of deadlines in the code where when we don't see stuff up to that time, we try to look up by route and they are just hard coded timings based on nothing but just pure ideas on the air. So having those data on real usage help us to fine tune those stuff and also try to see the limits and put the numbers like it should be for Mainnet.
00:41:35.380 - 00:41:38.370, Speaker A: I'm not sure I understand the suggestion. Sorry.
00:41:39.080 - 00:41:46.820, Speaker B: Oh, it's just a comment on the needs of data, because there are fine tuned.
00:41:47.560 - 00:42:19.116, Speaker A: So there's essentially exceptional code paths for when you don't get the expected data at the expected times. And there's tunings and configurations and different things like that. And if we're running only on devnets that get everything on time because they're just easy, we're not going to run into those. So regardless of main net parameter tuning, we need to be in test environments that have these, push them to exercise these code paths so we can tune, tweak and make sure that works. Yeah, I think we're all in agreement.
00:42:19.228 - 00:42:36.630, Speaker B: To be honest, I was looking at the logs during the pre devnet six and I saw a couple of situation where these exceptional code pass has been triggered. So maybe it's easier than we think. Once numbers goes up.
00:42:42.700 - 00:42:58.010, Speaker A: And there's a comment by Perry that's saying maybe we can also use Gorli as the actual gordy fork to test a potentially larger value. But that does.
00:43:03.950 - 00:43:23.480, Speaker D: Yeah, it's not something we can do right now, but maybe in a few months where we feel like, okay, we kind of have everything ready for main net. The thing that's missing is a true test of knowing which size we're going with. Then we can try the worst case scenario on Gorli and it's scheduled for deprecation anyway.
00:43:24.010 - 00:44:53.134, Speaker A: I think if we went that route, we'd want to have a clear invalidation criteria. Like what's the thing that Gorli will show us that we haven't been able to see that we can use to make a decision before running the experiment? I guess so. Danny, you mentioned a couple of minutes ago, folks are still reviewing the data from the test and want to look into that more. When do we think we need to have a high confidence understanding of the data about this? I don't mean to imply we have a low confidence of understanding the data, but we do have new data and we do have additional people that I want to sit on this. Right. There are people that I think have high confidence, but there's also a number of just the networking folks across teams that are thinking about it in terms of when on not the consensus layer call this week, but in plus two weeks from then, people, if they have concerns, voice them. That would be my preference.
00:44:53.134 - 00:45:37.286, Speaker A: Because then we also get at least some amount of Devnet work as well. Right. So if Enrico is seeing lots of these, what we think are exceptional code paths exercised over on Devnet six, that's also going to give us information. So I really think that plus two weeks from this Thursday, we should be able to bubble up most of the concerns from the data that we do have. Yeah, I think that's like a reasonable timeline. Anyone have thoughts, concerns about this? Okay. Yeah.
00:45:37.286 - 00:46:38.666, Speaker A: Perry says for a successful Devnet six launch, agreed. So hopefully, I mean, obviously if it takes longer, it takes longer, but if things go well, then by the CL call on June, I think, 29th or 20 eigth or something, then we've had time to have everyone review the data and hopefully run a couple of stress tests on Devnet six. Yeah. And we can take it from there. Anything else in general on 44 four before we wrap up. So there was an issue that RICO brought up in the last ACD that based on the spec today, when you start a validator from checkpoint syncing, you have to backtrack all the blobs before you start doing your duty. And the UX, I mean, that's fair, that's honest, but the UX of that is just that.
00:46:38.666 - 00:46:58.080, Speaker A: Okay, now I have to request perhaps like 66, assuming four blocks. Why would I move to 66gb of blobs, assuming the worst case before I can start doing anything? And the UX of that is a little cumbersome. And I wonder, anyone has more thoughts on this particular issue?
00:47:04.760 - 00:47:46.512, Speaker B: Yeah, my thought was that definitely from the UX perspective is a step backward because now the user are used to do the checkpoint sync and then in just a couple of minutes you can start doing stuff. And we are going a little bit backward here to say now you have to do a similar of a full sync where you have to really wait and download a lot of data. And if we move to three six, the number of gigabytes goes up. Even more than 33gb has been calculated for two, four.
00:47:46.566 - 00:48:09.770, Speaker A: Now. Sorry. Why is there a worst case? We know exactly how much data it's going to be, right? Yeah. The target over that time period will be essentially the amount of data. Yeah. So if anyone computed that using six blocks per block, that can't happen. It's not enough ether to pay for that.
00:48:09.770 - 00:49:08.360, Speaker A: So I do think that the security argument of having all of that data and not being able to reorg to a branch that doesn't have that data is very important. I do also think that turning the node online and having it be able to operate as it's doing its initial backfill is probably not like a crazy security concession. I think that that's okay. Likely. Unless it leaks into other modes like reorgs, it leaks into other things like that. So maybe, I think it's worth having the conversation on, if that UX is worth preserving. But I would not let that UX allowance leak beyond that mode.
00:49:08.360 - 00:49:39.060, Speaker A: That said, it is something of a concession, right. If you have large amounts in the network that are all coming online at once, which maybe happens because of compounding of another attack, then you end up in kind of a security concession zone. So it's worth thinking about. I don't have a terribly strong opinion. I guess something worth thinking about is that, okay, you trust your RPC provider. No. To give you the checkpoint state.
00:49:39.060 - 00:50:19.090, Speaker A: So you have that trust assumption, right? It's tender trust assumption to trust the RPC provider to provide you the blobs where that you can also verify it along the way. Right. So maybe you trust your checkpoint sync. So start get the blobs from there and start a testing, and then backfill. If you have an issue in backfilling, abort, and then do not allow that assumption to leak beyond the weak subjectivity checkpoint that was provided. I hear you. You're right.
00:50:19.090 - 00:50:47.300, Speaker A: The assumption of correctness is strong. So I think as long as you do backfill, and as long as you don't allow that assumption to leak into other places, I think it's probably okay. Anything else?
00:50:50.470 - 00:51:15.046, Speaker D: Just a clarification question. Does the Cl send the El the fork choice update before the blob data is done being fetched during checkpoint sync? Or does it wait for having all the blob data before it sends the folk choice update? Because the EL won't start syncing until it sees the fork choice update. It would wait till it has all.
00:51:15.068 - 00:51:18.534, Speaker A: The blob data to send a fork choice update. Yeah.
00:51:18.572 - 00:51:25.450, Speaker B: The block needs to be fully imported, so you have to have validated all the blobs to send forth choice.
00:51:26.750 - 00:51:40.720, Speaker D: Okay, but that's definitely going to increase sync times by a decent bit because we're going to have to checkpoint sync state, then download 68 gigs of data and only then will the ER start downloading its couple of hundred gigs of data.
00:51:41.250 - 00:51:50.740, Speaker B: So the way checkpoint sync, for example in loads of work is you download the state and then you sync the first block after the state.
00:51:52.470 - 00:51:53.026, Speaker A: After the.
00:51:53.048 - 00:52:07.270, Speaker B: Checkpoint you have synced the state from. And when you get that first block and blobs along with it, then EL will receive the FCU. So you will not download the entire past block.
00:52:11.530 - 00:52:35.950, Speaker A: And I'm pretty confident that if you say had a wake subjectivity state checkpoint sync from two days ago, sync forward to head and have the blobs from that point and send your fork tourist updated that you're in a pretty good state and you're not really in a degraded security mode. You should still backfill because that's the honest behavior of a network node.
00:52:40.460 - 00:53:00.456, Speaker B: Just as an FYI. So the blobs will not be available before a window. So everyone will be forced to do a checkpoint sync once the current slot goes beyond 409696 epochs.
00:53:00.488 - 00:53:59.148, Speaker A: I think from the network I mean backfill to the network pruning point. I don't mean. Okay, I. Anything else? Okay, well thanks everyone. Yeah, talk to you all on the Cl call later this week. Yeah, let's get the net six up. Talk soon.
00:53:59.148 - 00:54:04.920, Speaker A: Thanks, bye.

00:02:52.770 - 00:03:39.840, Speaker A: Okay, we should be live. This is condensed layer call ACDC 10 eight, issue seven seven one on the PM repo. We're starting at number today, apparently says the markdown Daneb, then some general stuck discussions, and then some time for any other discussion points people have. Let's see. So, last call, both in the execution layer call and the 10th layer call. We're kind of like trying to shuffle towards a final feature set for Daneb. Seems like we're getting close on this end, so a couple of updates and a couple of discussion points.
00:03:39.840 - 00:04:25.426, Speaker A: Alex is not on the call today, but 4788 is CFI on the execution layer. There's a lot CFI, so it's not 100% clear exactly what's going to make it into the final list. But I think we will be moving forward with the 4788 building into the Daneb fork, given that signal. So we'll have testing and other things like that. It is on the consensus layer on the minor range, but we'll work on getting that built into the fork and released relatively soon. Let's see. Stokes had a summary.
00:04:25.426 - 00:05:22.240, Speaker A: Let me scan real quick to see if there's any relevant stuff. Okay. Yeah, so there's a little bit of discussion on the execution layer, how that actually shows up, but he also comments that it's pretty straightforward. So any questions or comments on that, or on the process or how things are moving forward here? Great. Okay. The other item that two weeks ago there was general consensus on this call. This is not a cross layer feature to get into Daneb, is that validators cannot be proposers, which is a minor change to the proposer shuffling function.
00:05:22.240 - 00:05:47.400, Speaker A: We were able to greatly reduce the diff with a slightly different place on where this was being called. That is in that PR 31 75. Mikhail did open up a corresponding EIP. That's still like in a pretty early draft status, but it now has a number 69 eightyle. Do you have any other comments on this one?
00:05:48.170 - 00:06:36.230, Speaker B: No. Yeah, the PR, I think that we should settle this down into the features directory to make it a proper change to the CL mentioned this in the EIP as well. And as you mentioned, the footprint, the diff of the changes has been reduced, which is great suggestion on the way to do it. Testing is also kind of ready, so it's just about more shaping the spec in the best way. Now, what's left to my observation?
00:06:38.350 - 00:07:38.290, Speaker A: Sounds good both on this and 4788. We'll keep things moving such that it gets into the DNEB full fork build and tests soon. Any questions on these two items? Okay, great. There's an open pr that's had some active discussion. This is 3338 on the consensus specs, repo essentially techniques for potentially allowing additional slack in the blob constants on the consensus layer, such that you don't have to do a cross layer fork when updating the gas limit on the execution layer. Does anybody want to give an update on the status of this conversation? It's been a lot of back and forth.
00:07:40.470 - 00:07:43.374, Speaker C: Yeah, I can give a little bit of update.
00:07:43.502 - 00:07:43.842, Speaker B: Great.
00:07:43.896 - 00:09:29.762, Speaker C: So the original proposal was that, okay, we keep max blobs per block a little higher on the execution API so that El clients can basically increase their data gas independently and henceforth increase the throughput of the blobs. Basically, over the conversation, it was discussed that putting it to a much higher bound, like one zero twenty four was not a good idea. So maybe 16 blobs per block was. Okay, so even over there we have some discussion going on. But what has, one other thing that has come out on it is that we should have another variable like max commitments per block, which basically, and keep it to a high level, like 100:24, which basically means that the Merkel proofs that are generated even now would be valid to a point when, for example, we kick up the blobs per block to a high number in sharding. So basically the block inside the block, we have the list of commitments based upon this high value, but we still basically have four or 16 blobs right now that the Claer can handle. And depending upon what we feel like, maybe we want to kick up the current max blobs to 16.
00:09:29.762 - 00:09:38.040, Speaker C: I mean, that is an independent question from max commitments per block. So these are the two discussion points being discussed in that PR.
00:09:39.210 - 00:10:18.360, Speaker A: Okay, so we get, Yasick proposed an additional variable that gives us the shape of the block, shape of the merkel tree with respect to the block that would be forward compatible, and then an additional constant to bound the actual amount that we're willing to accept currently. And that could be synonymous with the value that's in the execution layer, or that could have some growth baked in, like up to 16, up to 2 mb. If we wanted to give a little bit of elasticity to the execution layer without the consensus layer needing a fork. That's where we're at.
00:10:20.810 - 00:10:21.654, Speaker C: Yes.
00:10:21.852 - 00:11:12.040, Speaker A: Okay, great. Thank you. Yeah, I just want to bring this to people's attention. This is something that has had active discussion and might have tiny changes with respect to constants and how they're configured are there other discussion points on this or questions on this? Otherwise, if you are interested in this topic, please jump into this pr. I think this is one of those minor details, but one that we should get ironed out maybe by the next call and maybe the next release that might include some of these other minor features that are going to get in. Okay, check it out. Three, three, eight.
00:11:21.630 - 00:11:25.210, Speaker D: Can you mute unmute?
00:11:26.910 - 00:11:51.840, Speaker A: Oh, somebody else. Great. So those are our general denab discussion points. Are there any other items that we want to discuss with respect to Dnab? Any ongoing issues or any updates with the testnets, anything? Devnet.
00:11:54.180 - 00:12:15.940, Speaker D: Basically, this morning when Mario started the. We saw some problems unfold. Aragon is crashing with some very massive principles. And netherminds were unable to propose blocks. We had a short period of unfinanization.
00:12:16.020 - 00:12:19.556, Speaker A: Also, and this was a transaction fuzzer.
00:12:19.588 - 00:12:23.196, Speaker B: You said it was, but it was.
00:12:23.218 - 00:12:25.820, Speaker D: Not working correctly as far as I understood.
00:12:26.560 - 00:12:26.972, Speaker B: Yeah.
00:12:27.026 - 00:13:04.010, Speaker D: So I have no idea what I did. I basically just started the fuzzer. And because I was not using my own node, I don't know how many transactions I sent. I don't know what transactions I send. And I'm also not sure if this is actually me causing chaos. I'm going to set up my own node so I can better see what's happening and what I'm actually doing. What my code is, actually.
00:13:04.010 - 00:13:14.030, Speaker D: Yeah. It's very fuzzy at the moment. But I'm glad that there have been some issues uncovered already.
00:13:14.400 - 00:13:16.220, Speaker A: Are you okay, Marius?
00:13:20.240 - 00:13:23.230, Speaker D: Kind of, but yeah, thanks.
00:13:25.620 - 00:13:34.960, Speaker A: Okay, cool. That's exciting. Good to see that stuff now rather than later. Okay. Any other on the Devnet?
00:13:38.180 - 00:13:39.490, Speaker B: Not right now.
00:13:40.100 - 00:13:52.390, Speaker A: Okay. Tim did threaten to hijack a fortune's call to talk about SSz. Tim, do you want to give a status update or any time on that?
00:13:53.560 - 00:13:54.116, Speaker B: Sure.
00:13:54.218 - 00:14:16.712, Speaker E: So, basically, the status with SSZ and 4844 is that, as I think the El client teams have started to implement this, there's been questions around, is the amount of SSD we're introducing. Would 4844 actually helpful to getting.
00:14:16.766 - 00:14:16.996, Speaker B: Yes.
00:14:17.038 - 00:14:48.150, Speaker E: Towards full SSZ on the El? And if it isn't, then does introducing sort of partial SSZ now and not being able to fully leverage it, actually make things worse than simply sticking with RLP to encode the 4844 type three transactions. And I know that light client Roberto and Eton have been discussing this a lot on the discord. So I don't know if either of them have an.
00:14:53.320 - 00:15:12.760, Speaker A: If we're. Right now, SSD kind of like flat hash is kind of in the worst of both worlds. Like we add a new dependency and don't really make it look like it's going to look in the future. So then the question becomes, try to make it look like it looks in the future or move to RLP to not be in this unhappy medium.
00:15:12.920 - 00:15:25.176, Speaker E: Right. And I think Ethan had changed his EIP 6493, I believe, based on part of that feedback. But yeah, Matt, I saw you came off mute.
00:15:25.208 - 00:15:28.624, Speaker A: I know you have some feedback. Yeah, please. I was going to say, I think.
00:15:28.662 - 00:15:38.516, Speaker F: This is one of those things where it's hard to make it look like what we think it should look in the future without having an extremely clear idea of what the future should is.
00:15:38.538 - 00:15:39.604, Speaker A: Going to look like.
00:15:39.722 - 00:16:08.530, Speaker F: And I think in the past we've done this thing where we think we're being forward compatible with the world, but then the way we understand the world, the world changes a lot in the one to three or four years it takes to complete the thing. So it's just really hard for us to actually put SSD here in a way that we know is going to be forward compatible. And I think the reality is that it's almost certain that we'll either constrain the design space in the future, or we just have to straight up change what we choose today.
00:16:12.880 - 00:16:32.240, Speaker A: And I will make a quick comment that this does primarily affect, solely affect the execution layer. So we don't have kind of a full consensus of people that might be interested in making discussions. This is a bit more of a status update, but we can have more discussion if anyone has additional points.
00:16:32.390 - 00:16:46.470, Speaker E: Actually, one thing I'd be curious to understand better Shaoi, you made a comment in the chat about how this would affect the CL specs if we move completely to RLP. Do you mind maybe just sharing a bit more on that?
00:16:47.320 - 00:17:21.250, Speaker G: Yes. So in the danet we have a function to assess the block version hashes. So right now it's SSZ and we use the SSZ logic to pass the bytes into and to found the version hashes. So that function has to be changed. If we use the full iop transaction, I will share the link.
00:17:22.180 - 00:18:20.308, Speaker F: I had one idea. I'm not sure if this is possible, but if we are able to have the version blob hashes of the transaction in two places, whenever it's being propagated among CLS, where we have it represented in the RLP transaction, and then we have it outside of the RLP transaction in a structure that the CL can understand. And what we could do is then we could verify the blobs and all the information against these version hashes that are outside the rop transaction. Once all the checks are complete, we give the RLP transactions and those hashes to the execution layer over the engine API. And the first thing that the execution layer does is it just checks to see if the hashes in the RLP transaction match the hashes that were provided outside of the RLP transaction. That way you don't actually need to do any kind of RLP work on.
00:18:20.314 - 00:18:32.650, Speaker A: The CL, and an upgrade to the encoding would be opaque to the CL at that point, or transparent wherever the word that is meaningful there. But we wouldn't have to do anything.
00:18:36.230 - 00:18:52.170, Speaker F: Yeah, it's slightly more complicated, but it seems like that would allow you to avoid having any RLP on the click.
00:18:52.190 - 00:19:11.742, Speaker B: In regards to the forwards compatibility argument, two things. First of all, with RLP we're definitely not forwards compatible. And the second thing is that SSD kind of brings features today already, right? You can build nice merkel proofs over them and stuff like this.
00:19:11.796 - 00:19:13.326, Speaker A: So it's not like not in the.
00:19:13.348 - 00:19:21.470, Speaker F: Way that we're using it now. We're only serializing SSD, so there's no hash tree roots.
00:19:23.350 - 00:19:33.140, Speaker B: I mean, why are we doing that anyway? Why are we just using the hash tree route? Like the arguments for that seem rather weak to me.
00:19:38.630 - 00:20:04.800, Speaker F: We can use the hash tree route. I think there's just like more strange things that start end up happening. If we use the hash tree route, then what goes into the merko? Patricia try. Is it the type transaction prefix with the hash tree root? Is it the SSD root? Like the transaction hash comes out of the fact that it's like the hash of the transaction that goes into the merkle Patricia try. And so we start opening the box of all these weird things that we have to figure out.
00:20:10.710 - 00:20:57.710, Speaker A: And the why it's a flat hash. I think if I remember correctly, it was an attempt to get SSD in there in a very minimal way. But again, in retrospect, or maybe it should have been clear at the time, it's kind of the worst of both worlds. We can continue to discuss this. I think it's maybe more appropriate that now we've just kind of highlighted that this issue exists, and to engage the conversation between now and leading up into the execution air call next week where we'll have more of the relevant parties. Any other comments on this one today?
00:20:58.720 - 00:21:08.930, Speaker E: Yeah, hopefully we can resolve this in the next week or so. It does feel like on the El side, it's like the biggest spec issue with regards to four, four, four.
00:21:18.060 - 00:22:48.490, Speaker D: So one thing that kind of like we have to, we have to, we have to change the transaction types at some point anyway. And I think it would be better to have them all RLP until that point and then figure out something where we can convert all of them. And one thing that if we were to go this route of having the plop transactions in RLp, one thing that I would really like us to do is to create this conception that this transaction type will not be there forever and we are going to drop it at some point in favor of the full SSC prop transaction type once we have the SSC transaction route. And so because we suspect only roll ups are going to use this transaction type, it will most likely see very little usage. And so if we go this route of having it RLP, I would like to state from the beginning that this is like a temporary solution and we are going to drop this transaction type fully at some point.
00:22:52.860 - 00:22:55.880, Speaker A: Essentially a deprecation notice at the creation.
00:22:56.460 - 00:23:38.330, Speaker D: Yes, well, we are going to like, this is the thing, right? This transaction type will only live for a very limited amount of time either way. Like if we do the SSC stuff or if we do the RFP stuff, once we go to the full SSC transaction route, this transaction type will be changed anyway. In my opinion, it would be way easier to make it as close to the current transaction types that we have. So we don't have to have.
00:23:41.980 - 00:23:42.488, Speaker A: Another.
00:23:42.574 - 00:23:47.080, Speaker D: Special case when we do the transition to full SS.
00:23:47.420 - 00:24:13.810, Speaker A: I have a question. When we plan on for any transaction type that exists, if we're going to migrate from RLP to SSD, would that be actually the deprecation of a transaction type fully or a mutation of the transaction types? So we take type one and then kill it and make type four. Or would type one mutate? This might not be satisfied. I realize I haven't thought of the answer before.
00:24:14.260 - 00:24:30.760, Speaker D: So like with the other transaction types, we don't want to fully deprecate them because we still want to allow for this use case that you signed a transaction at some point in the past and this transaction should still be valid.
00:24:31.420 - 00:24:34.040, Speaker A: So be in the creation of new types.
00:24:35.180 - 00:24:49.630, Speaker D: Yes. Maybe we can get rid of them. If we provide, for example, a pre compile that you can send this transaction to, that then executes the transaction for you. Something like this.
00:24:50.480 - 00:24:51.470, Speaker A: Got it?
00:24:51.840 - 00:24:54.130, Speaker D: Yeah, there are workarounds around it.
00:24:56.260 - 00:24:56.624, Speaker A: But.
00:24:56.662 - 00:24:59.490, Speaker D: Yeah, that's the basic idea.
00:25:03.680 - 00:25:58.308, Speaker A: Thank you. Okay, I propose that this active conversation continues the next week and we get all the relevant parties on the executionary discuss in one week's time. Thank you. Other Deneb related discussion points for today. Okay, great. We have a number of items in the specification not related to NEb that we'll go through now, just a heads up, the atnet revamp that's been spearheaded by age that was discussed two weeks ago will be merged soon after this call and we'll make it into a release. This is backwards compatible.
00:25:58.308 - 00:26:41.720, Speaker A: This does not include the downscoring so that people can roll it out over time. And we would add the option for downscoring at a hard fork in the future. Any final points on that? Cool, thank you age and others that have kept this one moving. Okay, is Michael Sproul on the call? I don't think so. Michael Sproul brought up the beacon APIs. Three one seven. This is add broadcast validation to block publishing.
00:26:41.720 - 00:27:38.870, Speaker A: This is essentially, I think we've discussed this. Now there is APR. This essentially allows for, let's see, for relays to do a full verification before broadcast. In light of the unbundling attacks, this helps prevent relays from having to use a forked version of a client, which would help prove client diversity for this use case. I believe there's not been much contention around this, but open it up for discussion now if you have discussion points. Otherwise, please take a look at this pr and we will probably aim to get it ironed out and merge relatively soon. Any thoughts here?
00:27:40.600 - 00:28:30.580, Speaker H: So we have some thoughts, right? So let's just take a step back on why we are doing this, right? Because the first thing is that having client fork is not ideal, right? Because now Prism has its own fork, Lighthouse has its own fork. And then the second thing is that fully importing the block is not ideal either, because currently we broadcast and we fully import the block. By fully import, I mean you also do execution check, you import the block to the DB and then you import the state of DB. And that's pretty slow. And then the whole idea is the relayer wants this out as fast as possible. So we found out that, hey, we can actually skip all those steps, we can just verify the consensus side only. And then that turns out we were able to reduce like 80% of the latency by doing that.
00:28:30.580 - 00:28:34.808, Speaker H: And therefore it does make the builder and the relayer very happy.
00:28:34.894 - 00:28:35.576, Speaker A: Right?
00:28:35.758 - 00:29:36.110, Speaker H: But the downside with this is that we're kind of like working with the relayer versus working on Insham PBS first, because now it kind of becomes this white and war game that we're just like, keep adding this feature to support MVP boost or PBS, that's out of band. And that's probably the biggest concern here, for example, because now if they want some sort of equivocation, check to check for slashing, and then we probably have to provide that, blah blah blah. So that is another angle to it. So from our end, we're pretty torn because we can be like, yeah, this is nice to have, but at the same time, we're slightly worried that we may be moving away from just doing hmpbs. But then I can see the argument of having both working on both at the same time. So yeah, this is just some two cent from our side.
00:29:36.880 - 00:30:43.640, Speaker A: Got it. Thanks, Terrence. Yeah, I guess the way I view those arguments is like, we live in a world where exists and we could see some degeneracies in client diversity and usage and other things if there are not some faculties to make it work appropriately. But I definitely sympathize the other argument. Yeah, it seems like age on lighthouse side kind of agrees with the issues at hand as well. Okay. Yeah, I guess have some discussions with your team to make some sort of opinion about whether this should or should not go in and whether this path in general should or should not continue to be supported.
00:30:43.640 - 00:31:20.710, Speaker A: And please bring any comments you have to PR 3117 on the beacon APIs so we can continue to have this conversation. Any other points on this one? And thanks, Michael Sprout, for getting the PR up. Okay, Michael, you have an open pr on the consensus specs. Send store finalize block hash to El. Can you give us an update on this one?
00:31:21.640 - 00:31:37.530, Speaker B: Yeah, this is a pretty old pr and basically it states that CL client must use must read the finalized block hash from the store instead of.
00:31:40.140 - 00:31:40.504, Speaker A: To.
00:31:40.542 - 00:32:51.250, Speaker B: Specify this explicit statement saves us from the case where the had state might be used to read this block hash while sending to el client, which in some very age cases can lead to finalized block hash being reverted back into the block history, which would potentially cause some ux issues. And apparently all seal clients already follows this logic. So there is an intention to finish the work in this pr and I would like to just bring it for client Dev's attention. If there are any objections, please write them in the pr and that's basically it. So the idea is to probably work on the test, if it is possible with the current testing framework that we have to test this particular thing and get it merged in the coming weeks.
00:32:57.960 - 00:32:58.896, Speaker A: Yeah, thank you, Miguel.
00:32:58.928 - 00:33:00.230, Speaker B: That's pretty much it.
00:33:01.720 - 00:34:18.260, Speaker A: Any comments on this one? And I think there's maybe one or two people that are unmuted and I'm having trouble muting them. So if you can please mute yourself. Thanks. Okay, there's one other dineb item that I forgot to bring up. There is not a spec for this already, but in process attestation for the security proofs around the fork choice in relation to some of the recent patches and for the I think very exciting confirmation rule that is in eth research post right now. There needs to be a slight one line modification to process attestation. Right now there's kind of this rolling 32 slot window for a given attestation.
00:34:18.260 - 00:35:00.144, Speaker A: For a given slot to get in. The modification would be to rather than for the previous and the current epoch, or for n and n plus one where the attestation is from n it has just a rolling 32 slot window that it can be included. The modification would be if it's from epoch n, it could be included up to the entirety through the entirety of epoch n plus one. This modification helps with the security proofs and helps with the confirmation rule. So that is a one line change. We're going to get a spec up for soon. This is probably the addition of a few tests and modification of a few tests on our end.
00:35:00.144 - 00:35:16.180, Speaker A: So very small on the consensus spec. It's security related so I think it should be expedited, but I will open it up for conversation if anybody has any discussion points today and then by the next call we'll have a spec up for further discussion.
00:35:21.080 - 00:35:28.230, Speaker B: What about gossip? We limit by the same 32 slots if I remember it right.
00:35:30.600 - 00:35:40.600, Speaker A: Yeah, I'll have to take a look at that. But you're right, we need to probably make sure those are under the same conditionals.
00:35:42.940 - 00:35:58.160, Speaker I: In the telegram we also discussed about rewards. Are there also discussion point about making them valuable when including in the block?
00:36:06.410 - 00:36:17.450, Speaker A: Do you have particular details? Is there essentially like a degradation of rewards prior to the epoch that would make them be ignored?
00:36:20.030 - 00:36:47.460, Speaker I: Yeah, if I remember correctly, at some point those at the station actually become worthless. And since we filter out at the station that are worthless in the beginning, so we are not going to select them when we produce blocks. So I'm guessing if there are impacts also in this area to.
00:36:51.670 - 00:37:00.920, Speaker A: Ben, you have I think the graph of degradation of value of attestation more at the forefront of your head. Can you explain where we're at?
00:37:02.010 - 00:37:15.594, Speaker H: Yeah, so correct target expires after 32 slots. So as Enrico said, the attestation becomes valuable. It's actually penalized after 32 slots is.
00:37:15.632 - 00:37:19.600, Speaker B: Equivalent to missing it.
00:37:21.330 - 00:37:52.714, Speaker A: Got you. Okay then we'll open that up as well when we're taking a look at this. Pulling up the p to p real quick. Yeah. Okay. It also has the 32 slot bound on the appetite propagation slot. Arrange so.
00:37:52.752 - 00:37:53.062, Speaker B: Yeah.
00:37:53.136 - 00:38:50.148, Speaker A: Age, not one line. Nonetheless, we'll get the spec and try to get a kind of complete view of the necessary changes here. It's a pretty important security improvement, so hopefully we can figure out a simple path forward. Any further comments on this one? Great. Thank you. Any other discussion points for today? Great. Okay.
00:38:50.148 - 00:38:53.510, Speaker A: Thank you everyone. Take care. Talk to you all soon.
00:38:55.960 - 00:38:56.564, Speaker G: Thank you.
00:38:56.602 - 00:38:58.208, Speaker A: Thanks, guys. Bye.
00:38:58.304 - 00:38:59.044, Speaker E: Thank you.
00:38:59.162 - 00:39:00.420, Speaker C: Thank you. Bye bye.

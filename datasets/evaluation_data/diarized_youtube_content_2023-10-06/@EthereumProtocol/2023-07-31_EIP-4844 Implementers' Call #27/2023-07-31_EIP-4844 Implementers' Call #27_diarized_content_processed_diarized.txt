00:00:00.250 - 00:00:24.014, Speaker A: It. Yes. So welcome to four four, call number 27. Bunch of prs that we discussed previously to quickly review today. Any updates on the Devnets as well. And then Roberto had a doc on the state of transaction pools. Yeah.
00:00:24.014 - 00:01:10.430, Speaker A: So we can go through that. And then I think there was some comment by pop in the agenda about whether we should restrict conversation on this to 4844. But as it's all starting to merge into one big Dan coon thing, it might be worth just rethinking how we want to either name or approach these calls because I guess it's going to become more and more combined with everything else that happens. But, yeah, I guess to kick it off, I know we discussed this on awkward devs last week, but any other updates on Devnet seven or kind of new things that came up in the past couple of days? Okay.
00:01:13.460 - 00:01:21.430, Speaker B: I could just say for Lighthouse, we're debugging a sync issue where.
00:01:23.240 - 00:01:23.652, Speaker A: I.
00:01:23.706 - 00:01:32.212, Speaker B: Think we're either rate limiting or we're canceling requests when peers don't respond quickly enough.
00:01:32.266 - 00:01:32.870, Speaker C: So.
00:01:33.260 - 00:01:35.930, Speaker B: Still just doing debugging, that type of stuff.
00:01:39.740 - 00:01:43.400, Speaker A: Cool. Any other time, team want to share updates?
00:01:50.010 - 00:02:12.190, Speaker C: An update from Teku. We're good with Devnet seven. Mason zero port. We're getting ready for Devnet eight. We're still working on the v three block endpoint and the parent beacon block route. Moving to the execution payload.
00:02:13.730 - 00:02:19.230, Speaker A: Got it. Anyone else?
00:02:23.680 - 00:02:39.250, Speaker C: We should be basically ready for Devnet eight. Never mind here, but just checking this pr move parent pick on blockroots. So I'm not sure if we did it. And what is the status here? That's all.
00:02:40.020 - 00:02:40.752, Speaker A: Which PR.
00:02:40.806 - 00:02:44.508, Speaker C: Sorry, move parent peacon block.
00:02:44.604 - 00:02:45.250, Speaker A: Okay.
00:02:47.880 - 00:02:48.630, Speaker C: Yeah.
00:02:52.370 - 00:02:52.926, Speaker A: Okay.
00:02:53.028 - 00:02:54.462, Speaker D: I can jump in on that real quick.
00:02:54.516 - 00:02:56.480, Speaker A: Oh yeah. If you have. Not. Perfect.
00:02:58.290 - 00:03:49.754, Speaker D: So we left the call on Thursday. Awkwardevs saying, okay, it seems like people are neutral to in favor of this on the consensus layer. Obviously at the cost of duplicating a field by having it both in the block and in the execution payload, even though both are committed to with the proposer signature and are in the data structure already. And then we put up the PR, asked for some more feedback so that we could try to expedite a release and got a moderate amount of negative feedback. So I don't think that we can cut a release before Thursday before we can make a synchronous conversation on it. So point being is I feel like maybe a coin flip. I couldn't say better one way or the other at this point.
00:03:49.754 - 00:03:53.650, Speaker D: So we will be discussing that on Thursday.
00:03:57.290 - 00:03:58.040, Speaker A: Okay.
00:03:59.290 - 00:04:15.900, Speaker D: Yes, the main thing that affects on the execution layer is the engine API. Pretty much just if the data structure is separate or if it's in the payload in there. But either way we need to figure it out.
00:04:20.560 - 00:04:28.572, Speaker A: Okay, sounds good. So we can keep discussing it on the pr. Basically. Yeah.
00:04:28.626 - 00:04:36.448, Speaker D: Please, if you have opinions one way or the other, jump in because we will talk about this on the Thursday call and we're going to make a decision that day.
00:04:36.614 - 00:05:09.630, Speaker A: Yeah, there will not be a breakout room specifically for this Pr. Marius. Okay, anything else on that specific pr? Okay, we sort of jumped ahead of it, but were there other client teams? I wanted to share updates on either seven or the work that they're doing towards Devnet eight.
00:05:10.240 - 00:05:27.810, Speaker E: Yeah, prism here, I was going to add not much from us on deafness seven. We're focusing on definite eight. So I think we're pretty much ready except for four, seven, eight. So yeah, whatever decision we decide, we can quickly implement that. So yeah, looking forward to definite eight.
00:05:28.580 - 00:05:37.350, Speaker A: Cool. Anyone else? That's why. And ethereum js is also almost ready for Devnet eight.
00:05:38.380 - 00:05:41.956, Speaker C: So as soon as we decide upon.
00:05:41.988 - 00:05:50.890, Speaker A: The prs, we finalize the Devnet eight spec. We should be able to cut images for Devnet eight. Cool.
00:05:53.340 - 00:06:21.700, Speaker F: So for gas, in theory we have everything for definite aid, but it's in multiple prs and I'm going on holiday next week, so probably someone else from the team, maybe Matt will take over and they would need to rebase and create a definite eight branch.
00:06:25.960 - 00:06:27.620, Speaker A: Awesome. Andrew?
00:06:28.620 - 00:06:57.650, Speaker G: Yeah, sorry, I've just returned from holiday and the opposite to Marius, so I think we still need to finish some bits and pieces for eight four four, as I mentioned on the Okodev. So I assume that in one, but probably in two weeks we'll be ready for Devnet eight.
00:06:59.620 - 00:07:00.690, Speaker A: Got it.
00:07:05.060 - 00:07:14.870, Speaker B: For Lighthouse, we've implemented the Devnet eight spec and we're just in the process of reviewing it. So I think we should be able to merge it in the next week.
00:07:20.460 - 00:07:58.780, Speaker A: I've sort of lost track of if there's any more clients that have updates, please go ahead. Okay, but it seems like, yes, some teams are pretty far along the implementation and basically just waiting on the final specs. Others need maybe like another week or two. So potentially we can try to launch Devnet eight, if not by late this week, maybe early next week with like a subset of the clients, see how that goes. And potentially add more clients in the week after that. Does that seem reasonable to people?
00:08:02.450 - 00:08:22.146, Speaker F: I think the spec needs to be pretty much concrete before any digital would launch. And we were also discussing that we would like to run Hive test for every client. And we're going to be launching the devnetate only once we have a decent amount of hive coverage.
00:08:22.338 - 00:08:33.340, Speaker A: Okay, got it. So that means then we agree on the spec, get the Hive test written, make sure the clients pass the Hive test, and then launch Devnet eight. Is that right? Yes, that's right.
00:08:33.790 - 00:08:53.300, Speaker F: Maybe mid next week is more reasonable for Devnet. Yeah, if we can get approved by Thursday, then maybe we can have clients releases by Friday. And then Monday, Tuesday we do hive testing and Wednesday we can do a limitate launch. I think that's really simple.
00:08:54.230 - 00:09:07.180, Speaker A: Yeah, that sounds good. Any other thoughts on that? Otherwise we can go through these open prs that we had. Okay.
00:09:09.090 - 00:09:16.880, Speaker F: From Hive here. Sorry, is anyone from Hive around to maybe comment on the test?
00:09:23.660 - 00:09:45.110, Speaker A: Spencer, I know you and Mario have been working on the execution tests in Python. Do you know who, if anyone, has been looking at Hive? Can you hear me? Yes, we can. Yeah. Cool.
00:09:45.880 - 00:10:19.516, Speaker H: So the 4844 tests for Ethereum js on the PI specs simulator, there is a timer issue that I've been looking into. I've been putting it off. I need to fix that. It's kind of been me and Mario, mostly for Devnet eight. I'm still working on the beacon block route tests. They're mostly done. I just need to get them properly generating with tantal for spec tests.
00:10:19.516 - 00:10:27.700, Speaker H: But getting the hive tests ready and running on Monday, Tuesday, next week sounds doable.
00:10:28.760 - 00:10:29.510, Speaker A: Okay.
00:10:30.920 - 00:10:37.510, Speaker D: Would you mind dropping the link to the file or files where the beacon block root tests are? I'd love to take a look.
00:10:39.900 - 00:11:17.460, Speaker A: Sure, that sounds good. Okay. So yeah, for the spec, we had a bunch of open issues we covered already. The first ones, I'll go through the list. There's four more. So the builder override flag. I'm sorry.
00:11:17.460 - 00:11:30.806, Speaker A: We discussed this last week and now for some reason it got merged. Okay. Yeah, actually, sorry, I don't have the context of this one.
00:11:30.988 - 00:11:39.000, Speaker D: Yeah, we talked about this on a few different calls. I think everyone agreed to have it in for Devnet eight.
00:11:39.450 - 00:11:40.200, Speaker A: Okay.
00:11:40.650 - 00:11:49.820, Speaker D: And likely almost everyone will just have it return false by default on execution layer and be a no op on the consensus layer and they can add functionality over time.
00:11:50.190 - 00:11:51.370, Speaker A: Okay. I think actually.
00:11:51.520 - 00:11:52.502, Speaker D: For definite.
00:11:52.646 - 00:11:59.518, Speaker A: Yeah, I copy pasted it from last call. Okay. This is why it was already merged. Okay.
00:11:59.604 - 00:12:00.400, Speaker D: So sorry.
00:12:02.050 - 00:12:23.560, Speaker A: Three that we wanted to discuss. So the block v three endpoint, there is still a bit of comments on this today, but generally it seems like everyone was in agreement around it. And whether we want to have this in Devnet eight is the open question.
00:12:29.520 - 00:12:49.700, Speaker B: So this one only affects communication between the beacon node and the validator client. So you would need it for using different consensus layer clients together. But it's not necessary for interrupting on the network. We don't necessarily need to have it or not for the Devnet.
00:12:51.320 - 00:13:12.170, Speaker A: Got it. And I assume we're not going to be at the point where we're setting up like a prism beacon node and trying to get other validator clients to connect to it. I don't know if you've ever even done that on the devnets. No.
00:13:12.560 - 00:13:16.300, Speaker D: Yeah, pretty low priority for this type of testing.
00:13:17.440 - 00:13:53.160, Speaker A: Okay, so, yeah, let's just leave it open and people can discuss it. Next one was PR four two six, which everyone seemed in favor of. And again, a question. Do we want this in the definite spec? I think it mostly changes some error codes.
00:13:55.820 - 00:14:01.688, Speaker C: So even if client will not implement it, it should be more or less fine.
00:14:01.854 - 00:14:05.432, Speaker A: Yeah, sorry, go ahead.
00:14:05.566 - 00:14:11.630, Speaker C: Yeah, of course we'll be better to decide what we want to do, but generally it should be fine.
00:14:13.280 - 00:14:39.290, Speaker A: Okay, so I wouldn't definitely not have it as a blocker on the Devnet. And then the last one. I doubt that this blocks anything as well, but client had a pr just renaming data gas to blob gas. Right. Are any of these a blocker for Hive? That's a good question, Barnabas.
00:14:40.990 - 00:14:50.190, Speaker F: If it's like some very specific error message that Hive would check for, then I guess it's going to be a blocker for Hive.
00:14:50.610 - 00:15:07.000, Speaker A: Yeah, I don't know, Gizinder. I saw you commented on it. Or Alex, do either of you know if Hive would cover the stuff in four two six?
00:15:09.210 - 00:15:24.090, Speaker C: Yeah, four two six indeed covers non defined behavior for some cases. So it would be cool to have on the next dino.
00:15:30.590 - 00:15:37.150, Speaker A: So, do you know. Sorry, if Hive. Is this something that will be tested in Hive?
00:15:38.210 - 00:15:50.340, Speaker C: Yes. Okay. It appears that the current specification doesn't cover all the return.
00:15:52.470 - 00:15:55.160, Speaker D: Like pieces. And.
00:15:56.970 - 00:16:04.630, Speaker C: This pr covers this. It seems critical to include.
00:16:06.910 - 00:16:43.250, Speaker A: Got it. Okay, so then four two six, we should try and get for Devnet eight. But then the previous ones, basically the block v three endpoint. I doubt Hive would check this, so I don't think we could do anything there. But let's add four two six to the actual spec. Okay, so next one. So we had PR by client renaming blood gas to data gas.
00:16:43.250 - 00:17:02.190, Speaker A: I doubt this would be checked anywhere in Hive, but it's probably something we can agree to here. Yeah, I guess. Does anyone feel strongly against this change?
00:17:08.120 - 00:17:08.900, Speaker F: I don't know.
00:17:08.970 - 00:17:18.660, Speaker C: Strongly, but yeah, I'm somewhat against it. Feels like blob gas is clearer.
00:17:20.920 - 00:17:23.380, Speaker A: Do you think blob gas is clearer?
00:17:24.520 - 00:17:26.470, Speaker B: That's what the change.
00:17:37.920 - 00:17:38.670, Speaker A: Yeah.
00:17:39.520 - 00:18:11.770, Speaker C: I also don't have a strong opinion on it. I think in general, blockcast seems clearer. The only reason why we initially went with theta gas is that of course we might in the future want to use this gas type for something else in blobs. Otherwise. Also we wouldn't have had to go through all the direction of even having it in the first place. We could have charged for blobs directly. So if there's a potential scenario where in the future we use the same gas type for charging for something other than blobs, it might be confusing because then we won't be able to change them again.
00:18:11.770 - 00:18:23.500, Speaker C: Once it's life, it's life. I think I'm a little worried about this. But on the other hand, I can see the argument with the confusion with call data, so I don't know. I don't have a strong opinion.
00:18:28.680 - 00:18:29.620, Speaker A: Danny.
00:18:31.400 - 00:19:05.570, Speaker D: Yeah, I mean, I parroted Anzgar's initial arguments in the pr just to make sure that we understood why the decision was made originally. Blob gas is probably fine. If I didn't care about the length of names, I might call it data availability gas. But long names suck, so I'm not going to get in the way of this one. The main thing is there's going to be a big diff on the consensus specs that we have to do and a big diff or not big, but touch a lot of things. But if people want it, we can get it out, no problem.
00:19:12.920 - 00:19:37.230, Speaker A: Got it. Okay, just in favor of moving this forward, does anyone want to blot the blob data or blob gas or should we just go ahead, get this merchant, decide to rename it data availability gas in a few years?
00:19:40.240 - 00:19:43.180, Speaker D: People like acronyms. Da da gas.
00:19:45.380 - 00:19:52.160, Speaker A: Okay, so Maris doesn't want to name it that, right? Oh, my friend hates acronyms.
00:19:53.640 - 00:20:02.870, Speaker D: We try to never use them in naming on the consensus layer, at least have for years. So we probably would stick with not doing it again.
00:20:06.240 - 00:20:16.656, Speaker A: Okay, let's just move forward with blob gas. I don't know. So you said it causes a large diff on the consensus release. Is that something?
00:20:16.838 - 00:20:39.210, Speaker D: No, it's going to be a few lines in the spec and then it's going to touch a bunch of testing. So this is going to be pr that changes it. And then it's going to be some work for any team that wants to be named conformant across the board. So there's just going to be a diff in every software that does it. Again, not a big deal.
00:20:40.060 - 00:20:54.510, Speaker A: Okay. So I think, yeah, let's just go ahead with it. There's a question. Why data availability gas too long? I don't know, like clients. Do you want to answer.
00:20:57.540 - 00:21:00.528, Speaker C: Why data availability is too long?
00:21:00.694 - 00:21:03.260, Speaker A: Yeah, why not data availability gas?
00:21:03.420 - 00:21:04.960, Speaker C: I mean, it's just really long.
00:21:05.110 - 00:21:09.520, Speaker A: Yeah. Okay. It's not a very nice thing.
00:21:09.590 - 00:21:11.920, Speaker B: I realize I'm talking to a Java developer.
00:21:13.300 - 00:21:16.310, Speaker D: Yeah, you all can't even really have a conversation about this.
00:21:16.920 - 00:21:22.600, Speaker B: It's hard because go is know minimally small names.
00:21:23.260 - 00:21:35.710, Speaker A: Okay, so I think Roberto says, roberto's comments of Max fee per data availability gas. That becomes very long.
00:21:36.480 - 00:21:37.864, Speaker E: What if we made a decap.
00:21:37.912 - 00:21:39.820, Speaker B: Data availability gas.
00:21:43.180 - 00:21:45.370, Speaker D: Okay, we got to keep moving.
00:21:47.180 - 00:22:28.098, Speaker A: Yeah. And Roberto's comment. Okay, let's merge the blob gas. Anything else on this? Okay, back to more substantive issues. Roberto put together a doc looking at the different approaches to the transaction pool design. Based on some conversations in the last four call. Where it seems different teams have taken different approaches.
00:22:28.098 - 00:22:41.130, Speaker A: I saw there was also a conversation with Peter this morning about this on the discord. But yeah. Roberto, do you maybe want to give a bit of background on your doc. And kind of share the takeaways from the chat with Peter?
00:22:41.650 - 00:23:06.690, Speaker G: Yeah, sure. I just wrote it up in response to the discussion last week. Where it sounded like teams had only just started, I guess, getting to implement rules in the transaction pool around blob transactions. There's a lot of additional considerations for blob transactions. Because they're expensive to validate cpu wise. Expensive to broadcast or not broadcast. Simply just send around.
00:23:06.690 - 00:23:26.826, Speaker G: And it opens up a lot of avenues for denial of service attacks. So we've discussed this kind of on and off. Sort of piecemeal in different meetings. And I just sort of wanted to consolidate the discussion. Unbeknownst to me, there's a large pr in the geth repo. Which Peter pointed me to this morning. So I've linked to that in it as well.
00:23:26.826 - 00:24:01.314, Speaker G: It contains a lot of the same, similar rationale. So anyway, I think it's just worth looking at and making sure that we're all more or less on the same page. With the rules that we're implementing. I guess what I'm a little concerned about is that one client will implement one thing, another client will have it completely different. And then the software then interacts with the nodes to submit blob transactions. Won't really know kind of what is the appropriate behavior. How should we set priority fees? How should we set the resubmission rules? What should we expect to happen on reorgs? So things like that.
00:24:01.314 - 00:24:18.780, Speaker G: So it's a short read. It's pretty easy. If there's anything. I guess my proposal is just, let's do what Geth is doing, because it seems to address all the concerns I laid out there. If there's any issues with that, I guess be a good time to raise them.
00:24:24.620 - 00:24:34.540, Speaker C: So I have a concern about block transactions building on each other before they are confirmed. I think they should just not be in the mempo.
00:24:37.340 - 00:24:39.790, Speaker G: Yeah, that certainly simplifies things a good deal.
00:24:40.240 - 00:25:10.950, Speaker C: Yeah, that would be my suggestion, because that's already a big problem with the current transaction pool, as we've discussed before, and I think it's safer to just not allow it, and I don't see a lot of reasons to require it. If a roll up actually wants several blobs in one block, it can easily send them from several accounts as well. There's no reason to having to use the same EOA to send the.
00:25:19.890 - 00:25:23.554, Speaker A: But wait, so you're saying they should not be in the public mempool at all?
00:25:23.752 - 00:25:32.482, Speaker C: No, I'm saying, like, each EOA should be able to have just one in the public mempool.
00:25:32.626 - 00:25:35.560, Speaker A: Yeah. And guest does not already do this. Correct.
00:25:37.130 - 00:25:53.850, Speaker C: I understood what Peter sent earlier, that currently you can have several transactions just like it is for classical transactions, and I would just remove that capability.
00:26:00.930 - 00:26:10.640, Speaker A: Yeah, that seems reasonable. I guess we can continue the conversation in discord with Peter there, but, yeah.
00:26:12.690 - 00:26:26.520, Speaker G: Conversation discord. I mean, Peter seemed pretty adamant that they wanted to stick with the way they're doing it, but he did suggest, if you have other opinions, to let them know.
00:26:26.890 - 00:26:37.030, Speaker D: Yeah, certainly there's, like, a UX strictness trade off in adding the additional condition. But my read is he might be open to tightening rather than loosening.
00:26:37.390 - 00:26:37.706, Speaker A: Yeah.
00:26:37.728 - 00:26:45.898, Speaker G: I guess the other question to ask is, if clients implement this differently, is this particular issue a challenge? Seems like this one, it seems like.
00:26:45.904 - 00:27:20.310, Speaker D: It might be right ux wise. I guess there's two things, right? Like, can I submit it to my node to broadcast? And then if I submit it to my node to broadcast, is it going to generally make it across the network? And it's like, if Gath is 50, 60% of the network, then maybe you don't get full propagation. But once you get included, maybe gath then fills in the gaps with announcements, but maybe not. So you're right, some of these things could make things a bit more finicky.
00:27:20.890 - 00:27:52.306, Speaker A: I think another way that this would make things different is if basically the roll up operators and whatnot. If the transaction pool only effectively works with gets, then it means anyone submitting blobs would end up just using gets. So I think there's value, even though the approaches are not the exact same, to at least documenting the best practice or something, so that all the clients can have a good option, which is.
00:27:52.328 - 00:27:59.518, Speaker D: Going to end up looking like the tightest, whatever the kind of tightest subset of set of the rules or superset.
00:27:59.534 - 00:28:00.702, Speaker C: Of the rules is going to be.
00:28:00.856 - 00:28:03.110, Speaker D: Is going to be what best practice becomes.
00:28:11.490 - 00:28:26.920, Speaker A: I guess. Any thoughts from any of the other client implementers? Okay, if not, then yeah, let's just continue the conversation.
00:28:28.300 - 00:29:14.100, Speaker C: Yes. In nethermind, it's like our transaction pool changes are in development phase. Like end of it, probably this week will be reviewed by other team members. But generally we are planning to be more or less in line with gaff. Like we have implemented 100% fee increases. So the same like gas, we will allow senders to have block transactions or other types, not both at once impending. So it's the same torch.
00:29:14.100 - 00:29:39.470, Speaker C: And we are planning to keep included block transactions until finalization. So we will support reorg as well. And for now we don't have minimum priority fee requirements for one way. But it's good idea. So I will add it tomorrow probably. And it's like just our implementation is very similar to gav one.
00:29:43.380 - 00:29:49.650, Speaker A: Got it, thanks. Any other time, team, thoughts that I want to share.
00:29:57.830 - 00:30:31.850, Speaker E: I guess I have a question whether anyone has thought about this, right? Because if you look at manned today, about 95 or 90% of the blocks are proposed using builder and the mat boost, right? So basically in this model, say assuming blob, there's not much data, PSC blah blah blah, it's very cheap. What are the builders incentive to basically including blob from the public man pool versus just prioritizing their own stuff?
00:30:31.920 - 00:30:32.154, Speaker A: Right.
00:30:32.192 - 00:30:39.920, Speaker E: So that's something that I'm not sure. I think it's worth thinking about under that model. How does this work?
00:30:43.170 - 00:30:54.018, Speaker C: They'll just prioritize whatever makes the most money. Yeah, but whether it's public man pool or that private one. Yeah, for sure.
00:30:54.184 - 00:31:00.120, Speaker E: I was wondering, if the blobs are basically free, then why do they care?
00:31:03.390 - 00:31:08.860, Speaker G: Well, I mean, you could always set a much higher priority fee to pay them for the blob. Effectively right.
00:31:11.410 - 00:31:11.822, Speaker A: Yeah.
00:31:11.876 - 00:31:12.382, Speaker C: That's fair.
00:31:12.436 - 00:31:16.560, Speaker E: I guess it's also worth looking into the common side effect.
00:31:21.010 - 00:32:18.186, Speaker A: One thing we did look at in 1559 a while back is, like, as the block gets bigger, there's a slightly higher chance of being uncooled on proof of work, which doesn't apply on proof of stake. But it's like, the only case where it doesn't make sense for them to include a blob at all is if they think that they can't get their block in time because it's going to be bigger. The gossip. But if there's a small number of blobs per block, that shouldn't be a huge factor. Yeah. And obviously, if there's too much competition, if there's a blob today, validators can choose to include their transactions even though they're not the most profitable ones in the mempool. Right.
00:32:18.186 - 00:32:49.370, Speaker A: And builders can do the same. So I think with blobs, you basically have the same thing where they get this degree of freedom where they're not forced to pick the highest paying one. But if they want to maximize fees, then that's the strategy they should adopt. Does this answer your concern, Terrence, or is there something else that.
00:32:51.220 - 00:32:54.450, Speaker E: Yeah, for sure it does. Definitely.
00:32:54.820 - 00:32:55.570, Speaker A: Also.
00:32:57.780 - 00:33:02.592, Speaker E: I just don't trust the builders. I think builders are weird sometimes they do things their own way.
00:33:02.646 - 00:33:03.152, Speaker A: Correct.
00:33:03.286 - 00:33:15.590, Speaker E: Versus just using clients doc software. It's way more predictable what's going to happen, but, yeah, it's definitely something worth paying attention moving forward.
00:33:18.060 - 00:34:23.690, Speaker A: Got it. Any other thoughts on the transaction pool? Okay, last thing then. These calls are starting to encompass more than just 4844 stuff, and Devnet eight is going to contain some non 4844 things as well. So I guess I'm curious to hear from people. Do we think we should keep this call? If so, should we just broaden it to Denkun testing in general? Yeah. How do people feel about this? I guess. Does anyone feel we should stop having this call every two weeks? No.
00:34:23.690 - 00:35:02.870, Speaker A: Okay. So keeping and broadening seems to be the consensus. Okay, we can keep them. Just rename them to, like, dencoon testing calls or something, and have them until the fork. I think it's good to have an extra spot where we can just discuss more of the kind of granular details around different Devnets and whatnot. And, yeah, we do still have a lot of work to do. On that note, anything else anyone wanted to cover today?
00:35:04.600 - 00:36:02.810, Speaker D: We have a lot of work to do front. We're in this typical phase where things are generally decided and we know what we're doing and we're testing and we're iterating and we're refining. And I think it's kind of hard to tell when you're not in your own client what else is going on with everyone else in terms of the path to productionization. And I'm not going to sit here and ask for timelines, but is it feeling good? Are we finishing the productionization other than some of these new features that are added to Zankoon for Devnet Eight? Or does it feel like there's still a long slog to go? Again, I don't want to ask the question in a way that puts people too much on the spot, but I guess I don't personally have clarity on that. So I was wondering if others have of perspective here.
00:36:06.850 - 00:36:09.120, Speaker A: Justin. Yeah.
00:36:10.450 - 00:37:04.350, Speaker I: Danny and everyone else, our situations. Yeah, we feel pretty good about the 4844 stuff and also pretty good about the remainder of what's going into Cancun. We do have a decent amount of cleanup and a decent amount of refactoring and merging and some regressions that we're still stumbling into. So we have a little bit of cleaning up the house that we see as not necessarily a blocker for anything on the schedule, but we'd feel a whole lot better about having that in order before we started merging into broader test nets, the sepolia and Shadow forks, et cetera, et cetera. I appreciate you not asking for a date, therefore, I will not throw one out. So we're happy with how we've been performing in a 4844 perspective and have a little bit of concerns. Otherwise, I'm not sure if that's helpful or muddies the waters further.
00:37:05.890 - 00:37:27.980, Speaker A: No, that's helpful, at least to me. And I think also confirms that we should keep these calls and broaden the scope so that we can start addressing not just the four, four, four specific issues, but potentially the other vips with more focus. Terrence. Yeah.
00:37:28.050 - 00:38:13.276, Speaker E: So to add my thoughts for Dennis'question, I think we're at this phase that we feel pretty good for net, we feel like we can do all the nets, blah, blah, blah. But I also feel like we are still a bit early for Testnet, mainly because all the builder and relayer testing infrastructure are not there. So for this time, I like to see them being there first. And I like to do more like backfill testing, for example, sinking and vacuum fill blobs over the last 18 days. I think that part is slightly less tested. And I also see a few issues with the rate limiting as well. I think that's going to be something that client team will run into issues with.
00:38:13.378 - 00:38:14.030, Speaker A: Also.
00:38:16.480 - 00:38:29.920, Speaker E: For the edge cases where the blob goes missing from the gossip net and then you have to manually request. So there are definitely a few more tests in there that I like to get done before going for Testnet.
00:38:32.260 - 00:38:42.740, Speaker A: So do you think this is the time to start reaching out to people working on mev boost and whatnot and get this tested?
00:38:43.400 - 00:38:45.590, Speaker E: Yeah, of course.
00:38:47.960 - 00:38:48.756, Speaker A: And on that.
00:38:48.778 - 00:39:06.670, Speaker D: But we do have our kind of failsafe fallback tests in hive that carry forward. So at least we get some sort of assurance that even if the Mavboost workflows fail, the network doesn't fall over. Right?
00:39:08.080 - 00:39:28.420, Speaker E: Yeah, but we have seen from the christian chapala incident. Right. So what happens with that is that say today your max skip slot, it's like five per epoch, then you basically will just get four skip slots per epoch. It's still not ideal.
00:39:29.800 - 00:39:30.550, Speaker D: Yeah.
00:39:35.610 - 00:40:15.940, Speaker B: So from Lighthouse, I've mostly been focusing on just trying to productionize what we have the past like two or three weeks now. The scope of the changes is pretty huge though because every part of the client ends up being affected at some point. So there still is a decent amount of work there. I think generally we're pretty comfortable with all of the 4844 features. The one still work in progress is the builder flow like Terrence just mentioned. But we have like Jimmy from our team has been working on, so.
00:40:27.350 - 00:40:31.570, Speaker A: Got it. Any other client teams want to share your thoughts?
00:40:35.770 - 00:40:50.330, Speaker C: So from Nethermite's side, we are pretty good in terms of implementation and hive testing of all eips. One potentially missing point is a transaction pool that we are still implementing.
00:40:55.310 - 00:40:56.380, Speaker A: Got it.
00:40:59.250 - 00:41:23.780, Speaker C: Transaction pool. It's like the current implementation. It's like key points are we have implemented. We are not sending full block transactions and like basic logic is implemented, we just don't have the separated block pool finished yet.
00:41:48.050 - 00:42:25.928, Speaker A: Okay. Anything else before we wrap up? Okay, well, yeah, thanks everyone. Talk to you all this week on awkward devs and I'll change this calendar invite and issue name and whatnot to refocus it on, then koon testing, but I'll leave the time and everything else the same. So see you all two weeks on this call under a different name. Yeah.
00:42:26.094 - 00:42:27.130, Speaker C: Thanks everyone.
00:42:29.260 - 00:42:32.490, Speaker A: Thank you. Bye bye. Thanks.
00:42:34.300 - 00:42:38.340, Speaker C: Bye everyone. Bye, everyone. Bye.

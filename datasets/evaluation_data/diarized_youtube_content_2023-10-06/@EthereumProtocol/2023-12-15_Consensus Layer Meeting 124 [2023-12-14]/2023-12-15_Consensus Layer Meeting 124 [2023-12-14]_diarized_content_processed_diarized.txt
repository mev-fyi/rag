00:05:31.320 - 00:06:04.830, Speaker A: We should be live. Welcome to all core devs layer. Call one two four. This is issue nine two two in the pm repo light schedule it seems, but we shall see. We'll quickly talk about DNEB status testing, et cetera. A server side event being discussed for the block and how it changes in Genev, and then open discussion from there. Let's go ahead and get started.
00:06:04.830 - 00:06:13.760, Speaker A: Deneb general testing and Devnet updates I think I saw new client pair syncing.
00:06:15.780 - 00:06:51.950, Speaker B: Yes, so Devnet twelve is now onboarded all the different clients and all the different client combinations, and we currently have Prism syncing to the head. We didn't want to enable checkpoint sync for that because we wanted to go through a genesis sync just to be able to make sure that Genesis sync still works. We have enabled MeV for most of the different cls, except for Prism at this point, and everything seems to be on track.
00:06:58.620 - 00:06:59.380, Speaker C: Cool.
00:06:59.550 - 00:07:03.630, Speaker A: So there's just one instance of prism, or was that many?
00:07:04.480 - 00:07:13.840, Speaker B: So this morning I have added all instances. Yesterday we added one with gas, but now it's with all the different EF.
00:07:18.000 - 00:07:18.750, Speaker C: Cool.
00:07:19.120 - 00:07:26.830, Speaker A: And other than Mev, are we kind of putting the testnet to the ringer or is it moderately kind of just stable functionality right now?
00:07:28.260 - 00:07:57.608, Speaker D: A little bit of stable functionality for now. There was this one lighthouse bug with Mev for local payloads that's been fixed and just patched I think, like an hour ago. Besides that, there seems to be an issue with one Bezu node. We're not particularly sure how it got to the state, but it's trying to convert an invalid block to a valid one. So maybe someone from Bezu can have.
00:07:57.614 - 00:07:58.970, Speaker C: A look at that one.
00:07:59.820 - 00:08:01.560, Speaker A: What do you mean by convert?
00:08:02.140 - 00:08:02.890, Speaker C: Sorry.
00:08:05.020 - 00:08:06.068, Speaker D: As an italian?
00:08:06.164 - 00:08:06.970, Speaker E: Good question.
00:08:07.520 - 00:08:08.430, Speaker C: Go ahead.
00:08:09.600 - 00:08:13.870, Speaker E: No, I was just agreeing with Danny. That's a good question. This is basic team here. I'd like to hear more.
00:08:15.760 - 00:08:18.960, Speaker B: We have put all the error messages in our chat.
00:08:19.620 - 00:08:21.250, Speaker E: I've got those, thank you.
00:08:25.490 - 00:08:50.680, Speaker D: But tldr there could not persist world for root hash for a certain block. And then I think Bezu tried doing that like twice and then I guess the node restarted. But at that point teku then says, cannot change node validity from valid to invalid. Sorry, from valid to invalid. And then teku gets stuck as well.
00:08:51.530 - 00:09:05.370, Speaker B: We started another sync in a totally different machine with the same pair also on arm, and it passed by that block. So it might be just some corrupted DB element?
00:09:05.710 - 00:09:09.580, Speaker D: Yeah, could be. That's why we're still not sure how we got that node into that state.
00:09:10.370 - 00:09:19.120, Speaker B: We used to have blobber running on it and lighthouse validator. So it's a bit different than what you would normally have.
00:09:21.820 - 00:09:25.130, Speaker A: Are we purposely sending bad blocks or not?
00:09:26.620 - 00:09:31.790, Speaker D: Not yet. We need an updated bad block. We don't have one yet.
00:09:35.360 - 00:09:40.320, Speaker B: Is anyone from prism can confirm that we should be good to go with the shadow fork?
00:09:42.260 - 00:10:05.480, Speaker F: Yeah, we can try it. The only thing I did not test is the builder path for the proposal, but given that there's not much change since the last commit, I think we should be fine there. But do let me know if you see an issue. At the same time, I will also monitor the setup.
00:10:07.420 - 00:10:22.780, Speaker A: Yeah Terrence, it might be nice to have some color know is this prism thinking but needs a lot of work? Or is this like prism getting close to what you all feel like is stable and might need some iteration but isn't?
00:10:25.360 - 00:10:28.990, Speaker F: Wait, I'm sorry, is there a syncing issue?
00:10:29.360 - 00:10:42.704, Speaker A: No, sorry, I just meant like prism. The thing that we currently have on Testnet is that like prism is working but there's a lot of kind of productionization to do. Or is that like it's pretty stable and doesn't need.
00:10:42.822 - 00:11:01.770, Speaker F: Yeah, no. So right now the only thing we're missing is basically bad feeling blob and some more verification check on the syncing path, the syncing to head, but other than that it's pretty production. Nice.
00:11:02.140 - 00:11:03.930, Speaker C: Yeah. Cool.
00:11:11.480 - 00:11:26.900, Speaker A: Any other questions or discussion points on the devnet? Any other testing related discussion points?
00:11:29.350 - 00:11:42.710, Speaker G: I haven't run the hive test for prism but I will do as soon as possible and just report. But I think we can go ahead and prepare for the shelf fork. If I find anything I will raise it immediately.
00:11:49.830 - 00:11:50.562, Speaker C: Cool. Yeah.
00:11:50.616 - 00:11:53.780, Speaker A: Anything testing and Devnet related other than that.
00:12:02.300 - 00:12:02.952, Speaker C: Okay.
00:12:03.086 - 00:12:14.590, Speaker A: Dapline did raise two points. It looks like the former is merged, which is adding proposer slashing and a tester slashing to the server side event. So dapline, we don't need to discuss that, right?
00:12:16.320 - 00:12:46.550, Speaker G: Yeah. First point, issue three, seven, six. It's closed so I think that's fine. If there is any objection, just do on the PR itself. So let's go for point number two, issue three, four, nine. This was originally raised by paritosh, so the context here is them. And we're not sure if other consumers are using the SSE events for timing data.
00:12:46.550 - 00:13:26.324, Speaker G: They, and we are aware that this is not ideal, but that's the best they can do at the moment when we add blocks to the mix. If the event is emitted after importing, that means waiting for all the blobs so now the data would be heavily distorted. So the discussion is around should we change the event definition such that it is emitted after gossip validation or add some timing data? Or if anyone else wants to provide any other option for timing data via server sent events, that's the context. Yeah.
00:13:26.362 - 00:13:45.530, Speaker A: Okay, so just to clarify, when we add blobs, the point at which we would admit this event might be delayed even more because the dependencies in the network, and so it deviates further from when you actually receive the block on gossip, which is a valuable piece of information.
00:13:46.060 - 00:13:46.810, Speaker G: Exactly.
00:13:48.380 - 00:13:49.290, Speaker C: I see.
00:13:56.310 - 00:14:36.770, Speaker G: So, okay, I can recap the discussion so far. I think what seems the easiest option is to emit the event after full import, but attach a new property where it's a scene timestamp where each client has perceived the event. It's not incredibly important for that definition of scene to be uniform across implementations because at least EF DevOps they do correlation timing. So as long as these timings are consistent within an implementation, it's fine. And this seems to satisfy all concerns.
00:14:38.710 - 00:14:46.520, Speaker A: Okay, the alternative that you originally suggested was two separate events rather than bundling the timing into the previous event.
00:14:47.290 - 00:14:53.800, Speaker G: Yeah. So we could have an event after gossip validation, a second event after full block import.
00:14:56.510 - 00:14:59.850, Speaker A: But you think the additional field is.
00:14:59.920 - 00:15:24.750, Speaker G: The better path right now with the current requirements? I think yes, because it's not clear who really wants this blog gossip event acceptable timing data. And if they can just get it from this one event, then it seems simpler. But both options would work.
00:15:27.440 - 00:15:28.190, Speaker C: Great.
00:15:31.200 - 00:15:40.290, Speaker A: Yeah, Enrico, we can barely hear you.
00:15:41.380 - 00:15:42.976, Speaker H: Sorry. Maybe now is better.
00:15:43.078 - 00:15:44.050, Speaker A: Yeah, perfect.
00:15:45.540 - 00:16:35.360, Speaker H: Yeah, I was thinking that adding the timestamp in the data itself would be better for two reasons. One is that, well, this event can be served with low priority, so it doesn't mean that when you receive, on the other hand, on the other side, the event itself, it is the correct timing. And also adding another event that says this is when I received the gossip, this is when I imported it. Maybe it's just an overkill for the use case that we are thinking about, so maybe it's just easier to leave things like are now just adding the arrival attribute.
00:16:40.990 - 00:16:55.060, Speaker A: I know you said there could be a little bit of implementation detail on the definition that timestamp, but will it be defined as gossip validation conditions have been completed, or is there ambiguity on whether they could be pre or post that?
00:16:56.710 - 00:17:12.230, Speaker H: Currently we take also the arrival before the gossip validation, so it's closer to the real message arriving over the wire, but I don't know other clients.
00:17:17.350 - 00:17:30.840, Speaker A: Real quick and then we'll go to Sean Dapon. Do you intend to specify if that's pre or post executing the gossip conditions, like immediately upon wire or otherwise, or do we not care?
00:17:34.350 - 00:17:46.254, Speaker G: I'm not sure I'm on the fence. I think whatever is easier for implementation. To be honest, I think for this use case it doesn't matter, but it would be good to specify it.
00:17:46.292 - 00:17:49.250, Speaker A: Yes Sean.
00:17:51.510 - 00:18:14.650, Speaker E: So maybe I missed this, but if we're thinking of just submitting an event when we import a block, would we then not get any indication about what happened to gossip blocks that we didn't import? Like a block that filled consensus somewhere or wasn't available? Maybe that would be a reason to maybe have two events.
00:18:21.150 - 00:18:32.720, Speaker G: Right? That would be the point of having the second event. There has not been demand for that. We can add it, but it seems like a bit of a scope grip for this specific issue.
00:18:34.610 - 00:18:49.970, Speaker A: You could also put a may emit upon block failure at any point in the pipeline or must. I don't see how it precludes emitting a failed block.
00:18:50.630 - 00:19:01.270, Speaker G: I would say this event carries the idea that this block has been fully validated. If you break that assumption, at least you should indicate that downstream somehow.
00:19:04.250 - 00:19:07.740, Speaker A: Sean, does Lighthouse emit invalid blocks right now?
00:19:09.630 - 00:19:21.582, Speaker E: I'd have to check. Yeah, I don't know. If we do emit events on gossip box then that would mean we would potentially be emitting events on invalid box.
00:19:21.636 - 00:19:22.240, Speaker C: But.
00:19:24.210 - 00:19:32.080, Speaker G: I'm pretty certain at least you guys emit the event at the end of the import routine. So definitely not for imalita, right?
00:19:33.190 - 00:19:54.230, Speaker H: I think taco has recently added an option to also emit the event before import. I might be wrong, but I remember something like that. But it's an option that needs to be enabled. Otherwise by default is omitted afterwards.
00:20:06.040 - 00:20:17.830, Speaker A: Are there any further comments on that? Do we have enough information to keep moving with maybe a suggested pr at this point?
00:20:18.520 - 00:20:37.870, Speaker G: In my view, it seems we should first figure out if there is a use case for consumer of events to learn about invalid blocks. If that's the case, then maybe we should consider the two events or extending event in that way. Otherwise, seems that we should go for the timestamp property.
00:20:39.040 - 00:20:50.690, Speaker A: Anyone opposing does valid invalid or valid true false property also satisfy this use case in the event that we wanted to have that use case.
00:20:54.660 - 00:21:15.280, Speaker G: So if we have a single event with valid property and the timestamp, yes, that satisfies the original issue. I think that's all from me.
00:21:17.890 - 00:21:26.864, Speaker C: Thank you. Very cool.
00:21:26.982 - 00:21:37.860, Speaker A: Sean added a couple of things. Let's do that PR 3561. 1st Sean, if you want to give a quick explanation.
00:21:39.000 - 00:22:31.300, Speaker E: Yeah, sure. So I just noticed the gossip conditions for blobs sort of lead to some, I guess like unexpected consequences. I don't think it's like negative or anything. It's just if you were, for example, using the Beacon API with the broadcast validation of gossip, it might be unexpected what messages were valid and invalid. And the reason for that is because technically it's okay to gossip. Two blobs with different blob indices that have slashable headers associated with them. So you're allowed to gossip those, but you're not allowed to gossip them if they're the same blob index.
00:22:31.300 - 00:23:43.820, Speaker E: So initially I was thinking maybe it'd be easier to just sort of disallow gossiping of any block or blob message that's like quote unquote slashable. But then Danny brought up the point that we don't necessarily like elsewhere, we don't look between different message types to try to cross validate what should be sent. So what we could also do is just think about this ability within any blob index that would make it make somewhat more sense. And then Yasik also brought up the point of we could instead just allow propagation of like block blob messages, because you're more likely to gossip to a node running a slasher in that case. And I think the final point Danny brought up was we could sort of do like a hybrid thing where we propagate slashable messages until a slashing has been seen on gossip. Yeah, that's the general cldrs.
00:23:48.940 - 00:23:49.352, Speaker C: Yeah.
00:23:49.406 - 00:24:45.230, Speaker A: My suggestion at the end is you do want to reduce how easily a message can be gossiped from n to one, hopefully meaning you want caches or something to make it difficult to send repeat in messages once you're willing to be slashed. And so if you're instead monitoring for a slashing message in relation to the message, then you can drop. And that can be either you created the slashing message if you have the faculty to do so, or you've seen it because somebody else saw it and created the message. What are the consequences of doing nothing here?
00:24:46.080 - 00:25:45.980, Speaker E: I don't think there are consequences. I just personally found it confusing when I was trying to implement the broadcast validation function in the beacon API, because you can have messages that are like, you get messages to this endpoint with all block blobs and the block, so that message can be slashable, but you would still technically publish all parts of it return to. So I thought that was weird. But I don't think there's anything like any detriments apart from it being somewhat unexpected in my point of view. I think my personal preference, I guess, would be to I don't think we have to make these changes for Deneb necessarily, but at some point having.
00:25:48.030 - 00:25:48.490, Speaker A: Clear.
00:25:48.560 - 00:25:54.170, Speaker E: Rules around how we should handle slashings and maybe allowing them to propagate further, I think that'd be betting.
00:25:58.010 - 00:25:58.760, Speaker C: Right?
00:26:05.750 - 00:26:43.550, Speaker A: I suppose there's also the option to upgrade this after dynam launches with thinking about the analysis of does that put us at like network partition risk if someone's willing to spam full messages? I guess my preference would be if this is secure, but leads to weird or confusing scenarios that we take a minute to think about how we want to do this kind of holistically rather than changing the spec at this point. But if it's insecure, then I feel otherwise.
00:26:44.530 - 00:26:47.280, Speaker E: Yeah, I think that sounds good to me.
00:26:52.710 - 00:27:07.240, Speaker A: Okay, I would propose maybe towards mid late January if you or anyone else has a design they want to propose and feel comfortable with to pick it up then.
00:27:16.850 - 00:27:17.310, Speaker C: Cool.
00:27:17.380 - 00:27:35.310, Speaker A: Are there any other further comments on this one before we move on? Next up, Sean, I don't want control message.
00:27:37.140 - 00:27:56.756, Speaker E: Yeah, so I'm not super familiar with this change, but I believe it can be used as like an optimization and gossip to reduce the amplification factor. I think it's because you can tell nodes not to send you a block or a blob you've already seen, for.
00:27:56.778 - 00:27:57.350, Speaker D: Example.
00:27:59.880 - 00:28:28.290, Speaker E: And I think both age and Yasik have looked at this and then Anton raised it. But I think we're waiting for consensus to merge it, perhaps for it to be moved along a little bit more. But I think it's something that's useful for Denev and people are looking to implement it if possible.
00:28:31.810 - 00:29:23.230, Speaker A: Yeah, and this can also be kind of upgraded transparently, I believe. I guess the problem here is if the PDP spec maintainers want it like bundled in a big one version one two, I guess even if it's merged sensitively, we could potentially start using it. And I believe, if I remember correctly, this helps more when they're large message sizes than smaller, meaning you're more likely to kind of reduce the amplification factor if there are slower, larger messages being sent around rather than tiny messages, or maybe more like attestations. I feel like the assessment was that it wouldn't do much, but it would do a lot for blob.
00:29:28.720 - 00:29:42.370, Speaker E: I don't know enough to comment, but I think that is the case on the pr, it says this reduces bandwidth by 30%. Seems pretty good.
00:29:46.670 - 00:30:22.820, Speaker A: Yeah, I just left a comment that it looks good. I'll try to hit up viso in a separate forum as well. I mean, at a certain point, if we want this and we're blocked on lipidd spec maintainers, we're going to have to figure out a different path. So let's see if we can get this moved along in there and have the conversation on the next call if we cannot.
00:30:23.800 - 00:30:24.164, Speaker C: Okay.
00:30:24.202 - 00:30:29.450, Speaker A: And Michael did echo that. It makes sense for the large messages only.
00:30:43.590 - 00:30:44.690, Speaker C: Thanks, Sean.
00:30:47.450 - 00:31:49.350, Speaker A: Okay, those are the only items that we have on the agenda for today. Are there any other discussion points? Okay, call schedule next and census layer call is in between Christmas and New Year's. I will not be available. I do not intend to host this call. I was thinking if there is demand for a call, it could be labeled more of kind of like a testing and kind of devnet check in call. If there's people that want to get on a call on that date, is there demand for that SC one heart emoji.
00:31:49.690 - 00:32:18.480, Speaker I: We can also decide this. So next week we should have awkwardevs. So on the 21st we can also decide this then because this came up as well on the testing call Monday, where the next testing call is on December 25, we're obviously going to cancel that. So yeah, I think if next week people feel like we should have something. Yeah, we can make that a sort of combined call.
00:32:18.850 - 00:33:09.030, Speaker A: Very cool. So if we do do something on that week, it would be at the 02:00 p.m. UTC slot on Thursday. It would not be a full all core devs, but anyone that is working on Devnets and things on the holidays and wants to check in or chat about anything, we can make that decision in one week on whether we haven't host that. And even if the decision is no, people can certainly jump on the discord, drop a call link or jump in some of the audio chat at that time. Okay, cool. So we will have Acde in one week, and if there's any further things to figure out on calls, we can do so then.
00:33:09.030 - 00:33:15.880, Speaker A: All right, any other discussion points for today?
00:33:30.560 - 00:33:31.068, Speaker C: Great.
00:33:31.154 - 00:33:39.728, Speaker A: Well talk to you all next week on Acde and enjoy the end of the year.
00:33:39.894 - 00:33:40.770, Speaker C: Take care.
00:33:41.620 - 00:34:03.530, Speaker A: Bye bye. Sa.

00:00:35.820 - 00:00:36.076, Speaker A: Great.
00:00:36.148 - 00:01:16.940, Speaker B: Hey, everyone, this is Acde number 191. Tim is out today, so I will be filling in for him. And yeah, I dropped the agenda in the chat here. It's issued 1080 on the pm repo and let's get started. So first up, let's just jump into Petra, and in particular, if there are any updates for Devnet one, there's a link to a spec here with the latest and greatest eips. Yeah. Would anyone like to give an update on their clients progress or anything like that?
00:01:22.610 - 00:02:11.210, Speaker A: I can maybe start with some overarching progress update. So we do have local testing done for two els and three Cl's. And there's a bunch of happy case scenarios. And the clients seem to all agree on the happy case scenarios, which is great news. I've posted the kurtosis config link to reproduce that. So in case someone wants to test if they're following along the chain, then you can have two clients, either producers, and you can just check if your client is forking off based on the happy case tests. And the open question right now is do we want to wait for more clients to be ready before we launch Devnet one, or do we want to just launch Devnet one and retroactively add clients as and when they're ready?
00:02:21.489 - 00:02:22.389, Speaker B: Andrew?
00:02:23.009 - 00:02:50.740, Speaker A: Yeah, I can talk about Ergon's progress. We are still working on 7702. That's work in progress. But I think launching Devnet one now might be. The timing might be a bit unfortunate because next week is. Is FTC and a lot of people will be there. So I'm not sure whether we'll be able to work because of the ECC on the net one.
00:02:55.400 - 00:02:56.260, Speaker B: Daniel.
00:02:58.400 - 00:03:42.530, Speaker A: I can give an update for Bessel. So we were running the execution tests that were released last Friday. We are still fixing some bugs that we found with the test. I think we will be a bit slowed down because part of the team now is on holidays because of July 4. So I would guess we would be ready around mid to end of next week. But I think for us it would not matter so much if we start fnet one already, now or not. So if not, we would just join later.
00:03:45.950 - 00:03:47.770, Speaker B: Okay, thanks. Maddy.
00:03:49.030 - 00:04:01.728, Speaker A: An update from Deku. We're ready for Devnet one. We have all the reference tests passing, so. Yeah. Okay, great.
00:04:01.904 - 00:04:02.620, Speaker B: Mark.
00:04:03.800 - 00:04:23.300, Speaker A: We are working on this happy path scenario Barry mentioned. We will update image before Devnet one because we have one bug in 7702, but we should be ready pretty soon with this fix as well.
00:04:28.450 - 00:04:40.190, Speaker B: Okay, cool. It's kind of sounding like, to me, we could wait another cycle of ACD to launch. I don't know if Barnabas or Perry feel differently.
00:04:45.570 - 00:04:54.060, Speaker A: Yeah, I mean, we're fan to wait. We still are missing a couple of happy case, so we'll probably just be working on those in the meantime.
00:04:55.560 - 00:05:44.324, Speaker B: Okay, cool. But it does sound like soon we'll be ready with Devnet one, which is super cool. Anything else on Devnet one there for pectra? There was a call out on the agenda for 7702, so we'll move to that next. Unless there's anything else more broadly with pectrade that anyone would like to discuss. Okay, so let's move to 7702. So I think Tim had this on the agenda just to ask for general updates. I think the, there were still some open questions around the Eip that would kind of be blocking its inclusion in Petrae.
00:05:44.324 - 00:05:53.032, Speaker B: That being said, I think we have some updates on those open questions. Maybe like client, if you'd like to call out this pr that you had.
00:05:53.056 - 00:06:09.590, Speaker A: LinkedIn.
00:06:09.620 - 00:06:10.230, Speaker C: Hello?
00:06:12.250 - 00:06:13.030, Speaker B: Hello?
00:06:14.170 - 00:07:23.606, Speaker C: Hello? Okay, I just posted the link to this pr in the chat. Basically, this is something that we've talked about offline and in the last breakout call, people were mostly supportive of this change, both on the wallet side and the client side. The TLDR. For those who haven't had a chance to review, we're essentially changing 7702 to be less of a ephemeral deployment of contract and more of a deploying a contract more permanently into the EOA's code. And it allows the EOA to continue operating as an EOA because the code that's deployed in their account isn't exactly the code which the user wants to delegate to. It's a designator that has a prefix and then an address to the code which the user would like to delegate to. So that sort of gives us the ability to see that that EOA is a special type of account that can both originate transactions and act as a contract.
00:07:23.606 - 00:08:57.746, Speaker C: This lets us get around the restriction in 3607, I think, where we banned eoas with code from originating transactions. It also helps us get around a fundamental problem that we've had since 3074, which is dealing with these permanent authorizations and replay protection and authorizations. The fundamental problem there was that to get the functionality, which we felt was really important, which was things like signing one message and then reusing the authorization over and over again, required us not having replay protection functionality in the authorization. This circumvents that by, instead of the permanency of the authorization coming from the message, it's being stored in a place in the account and that feels like the ideal path. So now not only do the message, do the authorizations get to have the nonce and get to be only single use, but potentially other tools like other wallets that are interested in acting as the eOa, because maybe the user has put their private key or their mnemonic into multiple wallets, they can then just look on the chain and see if the account has already delegated to a specific, um, to a specific piece of code. So I think that this is addressing most of the concerns that were outstanding. If I'm missing something, someone please chime in.
00:08:57.746 - 00:09:07.150, Speaker C: But I'm curious how people feel about this and if people feel that it would be okay to move towards the merge this and move towards this for Devnet to.
00:09:14.250 - 00:10:10.920, Speaker A: Yeah, I just wanted to briefly expand on what Matt just said, because on the record call we discussed with at least the people present there and general feeling there was that indeed this PR would be a really good candidate for basically definite two, with the one caveat just being that just everyone should be aware, should understand this as given that seven seven two is so new, we're still iterating towards the final spec. Like, I don't think it's very likely that this PR will get us quite to a final spike yet for pectra. So smaller changes might still be coming. We already discussed potential ones. It's just that we all agree that it's likely that basically this PR gets us significantly closer. So it seems like a better target for definite two than the old spec, but just for people's expectation that there will be future small changes by in all likelihood to the IP.
00:10:17.740 - 00:10:27.280, Speaker B: Okay, there was a question in the chat. It looks like the chat is there. Daniel?
00:10:29.140 - 00:10:51.390, Speaker A: Yeah, I was just wondering, because we said that we are going to move the net one, maybe one or two weeks in the future. Does it make sense that we implement directly the latest version of 7702, the one that is proposed right now, or should we still go with the original one?
00:10:52.730 - 00:11:13.156, Speaker B: I would say to keep it as is, just because this latest pr is not merged yet and there could be some last minute feedback. Let me go see what was in here. So yeah, the devnet one specs just linked directly to the EIP. So I would just target that as is. Unless anyone else would like to argue for something differently.
00:11:13.188 - 00:11:23.080, Speaker C: Right now I feel like we should have Devnet one ASAP, but I don't think we should change Devnet one necessarily.
00:11:25.180 - 00:11:26.760, Speaker B: Yeah, that makes sense to me.
00:11:27.330 - 00:11:36.310, Speaker C: I think most clients have already implemented everything, more or less. So it's not like clients haven't implement 7702 at all.
00:11:38.730 - 00:11:42.910, Speaker B: Right? Joking.
00:11:43.290 - 00:11:53.120, Speaker A: Ethereum, yes, has actually implemented it, so we have it. Great.
00:11:54.460 - 00:12:05.800, Speaker C: So is there any feedback on including this in Devnet two? It seems like we're talking a bit about timing, but it feels that most people are generally positive on accepting this for Devnet two. Whenever that ends up being.
00:12:22.910 - 00:12:26.854, Speaker B: Yeah, I would lean towards just getting it merged first and then we can discuss scheduling.
00:12:26.902 - 00:12:32.570, Speaker C: But I mean, it's not merged because we're waiting to include it in Devnet too.
00:12:34.270 - 00:12:35.170, Speaker B: Okay.
00:12:36.550 - 00:12:53.460, Speaker C: Like I can merge it right now. Alright. Unless someone feels strongly or says something in the next six to 12 hours, I'll merge it at the end of today and we should plan on doing that for Devnet two.
00:13:05.320 - 00:13:12.860, Speaker B: Okay, yeah, sounds good. And there doesn't seem to be any negative feedback, so let's move ahead with that plan.
00:13:13.160 - 00:13:14.752, Speaker A: Consider for a moment that most americans.
00:13:14.776 - 00:13:16.832, Speaker C: Out are on vacation. Should give a couple days for people.
00:13:16.856 - 00:13:19.360, Speaker A: To reply in chat before proceeding.
00:13:19.480 - 00:13:23.580, Speaker C: But I think a couple days, they've had a week and a half.
00:13:26.000 - 00:13:30.180, Speaker A: True, but you're actually pulling the trigger here. A couple days would be nice.
00:13:36.010 - 00:14:20.150, Speaker B: Yeah, I don't think we discussed this on the last ACD, so, you know, process wise it would make sense to give people some time, a reasonable amount of time after, say, announcing on the call. But generally I think moving towards Devnet two makes a lot of sense. Cool. So I think that was it on Pectra. Oh, maybe this tease us up the next thing, actually. But yeah. Is there anything on 7702? Otherwise we will go to the next EIP 7212, which I think is the r1 curve.
00:14:21.290 - 00:14:44.930, Speaker C: I think the last thing on 7702 is that if we're moving towards changing this spec for Devnet two, I'm curious what people think about our testing strategy for 7702 and Devnet one. Like, we do have some tests, but I'm not sure if we're planning to build out more or if people are comfortable sort of leaving testing where it is for devnet one on 7702.
00:14:50.950 - 00:14:51.262, Speaker A: Can.
00:14:51.286 - 00:14:58.370, Speaker B: We just test common subsets, like whatever would apply to devnet one and also devnet two we could just focus on for devnet one.
00:15:04.440 - 00:15:17.980, Speaker C: I don't think that there's as much common subsets. Like there is still a transaction type. We are still setting these authorizations. I'm just not really sure like what test would work in both cases.
00:15:23.970 - 00:16:21.698, Speaker B: Gotcha. So yeah, I mean, if it's going to change and kind of be breaking in that way, I would probably say just to test like whatever test we have now, we'll use for Devnet one, and then otherwise we'll focus on Devnet two for donet two. Okay, thank you for that, everyone. Please take a look at the pr four 7702. Next, we had a topic for EIP 7212. So this is adding a precompile for the SEGP 256 r one curve. And I think there's a few questions here.
00:16:21.698 - 00:16:32.510, Speaker B: Let's see. Is Andrew on the call you had the comment, it looks like you are. Yeah. Would you like to give us a little context here?
00:16:36.770 - 00:17:36.500, Speaker A: Yeah, I think there was a discussion on discord and that EPO was CFI'd and it's also used on polygon already. And because it's CFI, basically we need to decide soon, sooner rather than later, whether we deliver it in pectoral or not. And if we do, do we actually take what's already on polygon or do we implement a slightly different version of it using polygons? Say the precompiler address is like 256 or something, and so it's not, it's in the range reserved for l two s, as far as I understand. Yeah. And the question is whether we keep that or modify it somehow for ethereum.
00:17:37.800 - 00:17:42.820, Speaker B: Right. Is that the only difference between the rep and the EAP is just it's at a different precompile address?
00:17:43.530 - 00:17:55.890, Speaker A: I think somebody had a comment that the return value is unorthodox, like it's not aligned with what the other precompilers do. But I don't remember who that was.
00:17:56.050 - 00:18:17.930, Speaker B: Okay. Yeah. How do clients feel? This would pretty much be a purely El change. So how do any El clients feel about this eipde? Daniel?
00:18:19.630 - 00:18:45.920, Speaker A: Yeah. So for Basel, we are definitely in favor of including it. I mean, in the end, every mobile phone is supporting this EC curve. So it's like every most user already have like a built in hardware wallethead. For us, it definitely makes sense to allow them to use that instead of a traditional one. So I think for ux it would be great to have it.
00:18:47.740 - 00:18:48.680, Speaker B: My client.
00:18:52.060 - 00:19:43.570, Speaker C: I think on Geth we're generally pretty positive. Like adding the r one curve is pretty easy since we already have the k one curve. I think in general there's just still questions like why add another cryptographic precompile? Is this the right cryptographic precompile to add? You know, I think we would feel a little bit better if there was more work towards something to allow people to write their own efficient cryptography in EVM, that's something that hasn't seen a lot of progress in the last year or two, and there's still questions about, like what address to use. We sort of carved out an address space for rollups, and now we need to figure out are we going to use the roll of address space for precompiles a main net, or are we going to deploy it at the regular address? And there's reasons to do both.
00:19:46.830 - 00:19:47.570, Speaker B: Mark.
00:19:48.350 - 00:19:51.170, Speaker A: We are in favor of including the CIP.
00:19:54.030 - 00:19:55.730, Speaker B: Great, Dano.
00:19:57.350 - 00:20:00.538, Speaker C: So to address the why not do it generally in the evm on, there.
00:20:00.554 - 00:20:05.770, Speaker A: Is a proposal called EVM Max, and that's not shipping until at least Amsterdam. So if we want the R curve.
00:20:05.810 - 00:20:15.970, Speaker C: Anything sooner than a year and a half to two years, to three years out, we just need to ship it as a precompile. So that's why I support it, even though I think the correct solution is to move it all to the EVM.
00:20:16.090 - 00:20:18.150, Speaker A: It'S not going to ship in reasonable timeframe.
00:20:21.730 - 00:20:31.830, Speaker C: Right. But even if it's not going to ship in a reasonable timeframe, is the r one curve the right curve to be shipping? Like some people are saying that the r1 curve is already starting to be replaced with Edwards curve.
00:20:35.610 - 00:20:37.282, Speaker A: There's broad support for the r curve.
00:20:37.306 - 00:20:39.594, Speaker C: In a lot of places, like passkey.
00:20:39.642 - 00:20:44.938, Speaker A: From Google, so I'm satisfied there's always going to be new curves.
00:20:45.074 - 00:20:50.170, Speaker C: And when average curve is ready, I mean, there's been a proposal for netters precompiled, but we could probably do an EVM one max.
00:20:50.210 - 00:20:52.310, Speaker A: It'll probably be relevant then, when Max is ready.
00:20:58.220 - 00:21:41.750, Speaker B: Yeah. Personally, I think there's enough value around this curve, given its broad deployment in all these different contexts, that it wouldn't quite make sense to block on something like EVM Max. Although generally there is value in EVM Max. But yeah, it's unclear what those timelines will look like. It looks like the EAp has the precompile address at the, you know, the typical one, meaning like the next lowest address free on Ethereum and EVM. And that does sound like something we need to resolve if we want to keep that or mirror what is used, say, on l two s. There was a comment in the chat to please, please, please keep the same dress in both places.
00:21:41.750 - 00:21:47.800, Speaker B: Matt Lycline, do you have something else to say, or was your hand up?
00:21:49.140 - 00:22:57.580, Speaker C: Yeah, I mean, separately from the specific concerns about one, I get it's not a difficult thing to implement, but Petra is already mega and at some point we need to ship pectra and stop adding things and it feels like we're already way past that point. So I feel a little bit weird that we're trying to add things when we're talking about when to ship the second Devnet of this fork. Again, it's not like a big feature, but eventually we have to just stop and ship. And there's a lot of other things that we want to do that aren't in the hard fork, that aren't really being encoded. Like doing history expiry, maybe improving the situation with the public mempool for blobs that we just have no bandwidth to do because we are spending a lot of time figuring these forks out. So r1 is kind of a, I don't know, a little bit of a different thing since it is very easy. But generally I would prefer to reduce the scope of pectora and focus on some of this other stuff, including like not accepting r1.
00:23:05.210 - 00:23:47.574, Speaker A: Yeah, I just wanted to briefly clarify with the address in general because this is the very first time that we shipped pre compiled as an IP. There was a little bit of confusion on the procedural parts, specifically because this was first created as an EIP. Right now we just copied it over as an IP. So the IP has the exact same number. Normally we basically don't want this should be one EAP address space. So basically the idea was to just delete the EAP and then create one with a new number if we ever want to bring it to mainnet. We just never ended up doing this.
00:23:47.574 - 00:25:08.218, Speaker A: But this now means that we are in this weird position where basically the EAP that still exists at the same number is now in an outdated version. So if you go to the IP with the same number, seven to twelve, it actually, for example, is now at a different address because that's the address where it was actually shipped on L2 s, which is the first available address in the L2 specific address space that we reserved a couple of months ago. I decided to reserve for L2 use a couple of months ago in all cadets. So yeah, I think we should basically just ideally, if we decide to add this to vector, we should use it as an opportunity to really make general decisions around how we want to handle these L2 first features in the future if we may decide to make any spec changes to the IP whatsoever. For example, there have been some concerns about the return value of the precompile, that it doesn't give a return value instead of giving a zero return value in terms of, in the case of a verification failure. So for example, if you wanted to make that change, then we should definitely ship it at a different address because it would deviate from the L2 version. If we want to ship it completely unchanged, I think we should make a general decision whether we want to always in these cases retain the L2 specific address or ship it at the layer one specific address, and then also in that connection should make a final choice on how we handle this IPIP situation.
00:25:08.218 - 00:25:26.950, Speaker A: I think my preference would be to just completely delete the EIP because it's outdated anyway and has the weird numbering collision, and then create a new EIP that add a new higher number, whatever the first available is today and just copy over the spec. But yeah, so just to flag that, there are these open questions that we would have to solve.
00:25:30.250 - 00:25:48.000, Speaker B: Right Adrian looks like he maybe disconnected iPhone, whoever that is.
00:25:48.940 - 00:25:50.356, Speaker A: Oh sorry, I was muted.
00:25:50.468 - 00:25:52.420, Speaker B: Oh sorry. Yeah, please go ahead.
00:25:52.580 - 00:26:49.084, Speaker A: Yeah, so sorry. I wanted to give a user's perspective here. For the record, I work at Openzeppelin and we just merged a library that supports verification and the recovery of signatures. The demand for that comes from the account abstraction world where people want to be able to use 437 and other account abstraction systems using smartphone as hardware wallet. Basically the way we implemented it is we have a solidity implementation and we also have a version that checks the precompile from Rip 7212. The solidity implementation is way more expensive and if people could avoid pending that code, that cost, that would be better. So for our implementation tries to go to the precompile and if that is not successful, then we go on to the solidity implementation.
00:26:49.084 - 00:27:44.150, Speaker A: We have big concern about this feature being available on multiple chain at different addresses in terms of pre compile, because we think that for user is better to not have to write code specifically depending on which target chain you are targeting, and changing the precompiled address depending on what you're targeting, it should be better to have one single version that works on as many chain as possible. And unless this code starts checking multiple precompiled one after the other, before then falling back to solid implementation, it would just be better for all the user if there was one address that the library could go to. I understand that from a client perspective it may feel, they may feel differently, but from a user's perspective people are trying to write code that uses precompile. That functionality is better if all chain provide it in a similar way.
00:27:48.290 - 00:28:22.170, Speaker C: Yeah, I think I generally agree with that. I think maybe the only argument I could see against it, which is probably not the best argument for r1, because it's so simple. But there is a possibility that we get into a world where we need to change the precompile. And if we have the roll ups precompile that they've decided upon, and on mainnet we end up needing to change it. Whether it's in the fork that we originally ship it or in a later fork. Now we have maybe even a worse problem, which is the same address being used for two different precompiles.
00:28:33.160 - 00:28:40.528, Speaker B: Yeah. IPhone, you had a comment? Yeah, I was just going to ask.
00:28:40.584 - 00:28:44.180, Speaker A: About the readiness of r1 and client libraries.
00:28:53.490 - 00:28:56.150, Speaker B: I think most. Oh yeah, go ahead.
00:28:56.890 - 00:28:57.202, Speaker A: Yeah.
00:28:57.226 - 00:28:57.906, Speaker B: Joachim?
00:28:58.058 - 00:28:59.170, Speaker C: Oh yeah, sorry.
00:28:59.330 - 00:29:09.990, Speaker A: Like I've just been searching with we do not have it implemented and it also does not seem that there's a quick JavaScript bang. So I'm not really sure how long this will take, but that's just.
00:29:12.290 - 00:29:13.190, Speaker B: Marius.
00:29:15.260 - 00:29:27.996, Speaker A: For us. It's part of the Go standard library, so the implementation is really easy. Just add the guys costs and that's it. And we also have a pr for.
00:29:28.028 - 00:29:31.812, Speaker B: It already from someone who proposed it.
00:29:31.836 - 00:29:33.400, Speaker A: For the rfps.
00:29:36.220 - 00:29:36.996, Speaker B: In general.
00:29:37.068 - 00:29:40.444, Speaker A: I'm in favor of it. It's just.
00:29:40.612 - 00:29:44.252, Speaker B: Yeah, I think there's an argument to.
00:29:44.276 - 00:29:58.572, Speaker A: Be had that we should like. It's nice that the roll ups did this first, and so I don't know.
00:29:58.596 - 00:30:01.748, Speaker B: If we actually need it that much on Mainnet.
00:30:01.924 - 00:30:04.916, Speaker A: No one is really doing these kind.
00:30:04.948 - 00:30:14.140, Speaker B: Of things on mainnet anymore, using like smart contract wallets on Mainnet. And it's not because.
00:30:16.160 - 00:30:17.256, Speaker A: It'S impossible or.
00:30:17.288 - 00:30:30.296, Speaker B: Anything, just because it's too expensive anyway. So I don't think that adding this precompile will really change that, at least in my opinion.
00:30:30.368 - 00:30:32.088, Speaker A: I think it's great that we have.
00:30:32.104 - 00:30:33.696, Speaker B: This on roll ups and people can.
00:30:33.728 - 00:30:52.150, Speaker A: Use it on rollups. It feels again like one of these things where we. I don't know. In my view, we should focus on.
00:30:53.890 - 00:30:56.710, Speaker B: Getting functionality and stuff.
00:30:59.570 - 00:31:24.580, Speaker A: Onto roll ups and focus l one on blob scalability and these kind of things, and not focus too much of the evm feature set on l one. But I would be fine either way.
00:31:27.560 - 00:31:48.316, Speaker B: Okay, Richard, Richard, you have your hand up, but you're not unmuting.
00:31:48.428 - 00:32:30.186, Speaker A: Damn it. Sorry, forget to unmute the typical unmute. I wanted to say from the standpoint of safe, right, like since we are one of these smart contract wallet projects that we would like to do stuff like this on l one, because at least currently a lot of liquidity, a lot of teams are still on l one, they are still there. And this is where, at least in the current state, l one is not perceived as this. We want to move away from l one. If we as an ecosystem agree on this, I think this would be a little bit of a mindset shift, which I'm not generally against, but it's at least not the agreement of everybody in the ecosystem. We had this discussion actually in one of the AA breakout rooms where it was not that clear that everybody agrees to.
00:32:30.186 - 00:32:55.790, Speaker A: Yes, let's move away from l one where l one is just basically this blob space layer of Texas roll up chain. Unless we agree to this, there is still a lot of values where a lot of teams are still on l one, and a lot of teams do prefer also to have better ux and r1. Just enable this just as a general context.
00:33:00.550 - 00:33:53.386, Speaker B: Okay, thanks. So Asgar has a proposal to move forward on this point. It sounds like there's a few things we'd want to do. So then I would suggest doing those things and deferring the actual inclusion decision to the next acde. Just to echo some other comments in the chat, because I have the same view. Like Petra is already very, very big and we should really be deliberate about including more at this point. Okay, let's move on then.
00:33:53.386 - 00:34:28.269, Speaker B: So actually, Andrew had one other comment here. Let's just knock this out quickly. The question was if we can, sunset Gourlay. So I'm not sure he had the question if we had like a blog announcement or something like this. I don't know if Tim was planning to do anything there in terms of following up, but generally my understanding is that clients already have started to deprecate gorilla support. So yeah, should be fine to drop from your client and we will wave goodbye.
00:34:31.729 - 00:34:46.960, Speaker A: And click is not used anywhere like for hive testing or anything like that because girly uses click and with girly gone, we can potentially remove click as well.
00:34:50.500 - 00:34:52.840, Speaker C: Yeah, I think the testing is.
00:34:53.860 - 00:35:01.000, Speaker A: Sorry. Yeah, we already started removing click from the get code base, so.
00:35:12.070 - 00:35:45.980, Speaker B: Okay. No more gorley, no more click. Great. So then the next agenda item was a proposal to change the pre deploys. We have these system contracts for various functionality. In this case that goes from when we want to move information from the EL into the CL. There's two eips that use this type of functionality in Pectra 7002 and 7251.
00:35:47.360 - 00:35:48.376, Speaker A: Let's see.
00:35:48.488 - 00:35:56.900, Speaker B: I don't know if PK is on the call. Yeah, would you like to give us a summary of your proposal?
00:35:57.520 - 00:36:14.138, Speaker C: Yeah, hi everyone. As said, I would like to suggest a small change to these both contracts, because right now both of these contracts do not trigger any event on successful invocation. And the problem is, while this is.
00:36:14.194 - 00:36:25.666, Speaker A: Technically not required for a new functionality to transfer this to proceed the information, it makes it really hard for external.
00:36:25.698 - 00:36:48.280, Speaker C: Toolings like explorers to track back the origin of these execution. There are triggered operations. So if something appears on consensus layer, you would like to trace back where this operation comes from. So which transaction hash basically triggered that operation?
00:36:48.440 - 00:36:49.768, Speaker A: And for that it would be really.
00:36:49.824 - 00:37:00.280, Speaker C: Helpful if both contracts could trigger an event that the explorers or external toolings can simply follow on. So yeah, that's basically the request there.
00:37:06.820 - 00:37:07.600, Speaker A: Thanks.
00:37:08.940 - 00:37:16.000, Speaker B: Let's see, are any of the authors of those contracts on the call? Maybe they could chime in?
00:37:16.980 - 00:37:47.680, Speaker A: Yeah, I think we have discussed this before and this change makes sense and it should not result in a big spike of in gas costs for the smart contract call. So makes sense to do, and I've been discussing this with late client previously and planning to have this change. One of the concerns might be that they will produce logs for.
00:37:49.540 - 00:37:50.292, Speaker B: Just more.
00:37:50.356 - 00:37:56.520, Speaker A: Chain date historical chain data, but it should not be a problem soon and will be expired.
00:37:58.540 - 00:38:15.290, Speaker C: But it would also align it a bit with the deposit contract because we have to lock there and we are basically introducing new operations that are triggered on execution layout without that doc event. So yeah, it aligns it a bit, both contracts.
00:38:27.430 - 00:38:30.038, Speaker B: Right. I mean I can, I think we.
00:38:30.054 - 00:38:36.370, Speaker A: Should just work on it if there is no other opinion and opposition to.
00:38:40.360 - 00:39:00.780, Speaker B: The only thing I would ask is just like, you know, again, if we keep changing Petra, Petra will never ship. So there's some argument for leaving it as is, just because it's not critical and invariably it will delay other things. Yeah, I do think this is like a pretty small change in scope. So it's not the end of the world.
00:39:01.520 - 00:39:19.100, Speaker A: Yeah. Fortunately this is handled by the smart contract itself. So we just need to modify smart contracts and then deploy a new code to the next Devnet. So it should be quite opaque to client development process.
00:39:23.120 - 00:39:23.860, Speaker B: Right.
00:39:26.200 - 00:39:37.930, Speaker A: The only one thing probably is oh no, it's going to be a regular call and client will handle those log messages as usual. Log messages, log events, sorry.
00:39:53.150 - 00:39:59.330, Speaker B: Okay, so then we need to update the pre deploy implementations, but generally sounds like we're all in alignment here.
00:40:06.320 - 00:40:07.032, Speaker A: Cool.
00:40:07.176 - 00:40:19.980, Speaker B: So next up on the agenda, we have EIP 158 deactivation. I think Guillaume has an EIP or at least, let's see, this might just be a PR 2158.
00:40:20.880 - 00:40:21.320, Speaker A: Yep.
00:40:21.360 - 00:40:23.008, Speaker B: Yeah. Would you like to give us an overview?
00:40:23.064 - 00:40:56.382, Speaker A: Can you guys hear me? Yep. Yep. So yeah, a couple comments before because people started giving me feedback. So as it turns out it's referred to as 158 inside the guest code but it's actually EIP 161. So thanks for catching that. And so, yeah, as a quick reminder, we already had the conversation about it on LCD a couple months back. One of the things that was being said is I should create an EIP to support this.
00:40:56.382 - 00:41:43.512, Speaker A: So I did. It's EIP 7733 and it's about deactivating. Yes, EIP 158, 161. So it's actually not the whole EIP that needs to be deactivated. It's only the deletion of an account if it's code hash. Well, if it's the empty code hash, if the balance is zero and if the nonce is zero, that is impossible to do in verkle simply because an EOA could have some storage slots and in verkle you cannot figure out where an account slots are. So that needs to go.
00:41:43.512 - 00:42:29.490, Speaker A: It's the same reason why self destruct was removed or nerfed. We have the same problem that can happen in the context with 7702 in which an account has funds. So a non zero balance. An EOA has a nonzero balance so it has an empty code hash and it's got an empty nonce. So it's just the result of a transfer. Then with 7702 someone can call into this account, execute some code and the code transfers all the funds to a different account in which case the EIP 161. I have to get used to it.
00:42:29.490 - 00:43:51.888, Speaker A: The EIP 161 rules say you have to delete the account, which is not possible because like I said, and just to make sure it's clear, if you execute some code you could potentially create some storage slots. So there will be potentially states and you will not be able to find it. So yeah, the simplest way would be either to set the nonce of that account to one or to deactivate the IP 161. The proposal is about deactivating Eipnasone one six one and. Yeah, that's pretty much it. Oh yeah, there's one extra remark about it. It's that why am I talking about it in the context of Prague? We already had a conversation about it and initially I thought, well, we probably don't need it for Prague but there's one reason to include it in Prague and that is if people want to give some pushback against the overlay method in the future, that means you will be able, you will have to replay like to do the conversions at a given block height and replay blocks in what I call a counterfactual history until that replay chain becomes the official chain.
00:43:51.888 - 00:44:49.460, Speaker A: If during that period between the conversion and the replay and the fork, one of those things happen, one account gets deleted, that means you do have the existence of a deletion happening in vertical mode. That is going to be what? That's a potential bug that's potentially breaking the conversion. And so I think it's safer to deactivate it at the fork before if we want to do well, if we want to give some pushback on the overlay method. I am a proponent of the overlay method, so, personally, I don't care, but I want to make sure that everybody knows that if you don't include this EIP in Prague, you're effectively cancelling this. Like, removing this possibility. Yeah, that's pretty much it.
00:44:55.930 - 00:44:58.710, Speaker B: Okay, thanks. Yeah, my client.
00:45:00.490 - 00:45:15.390, Speaker C: I was just going to say this isn't really a problem with 7702 after the spec change, so I think we should focus on this for its merits of Verkl, since it's not related to 772 now.
00:45:17.290 - 00:45:21.470, Speaker A: Okay, so I'm not aware of the change in the spec, but that means this could no longer happen.
00:45:23.900 - 00:45:24.680, Speaker C: Yes.
00:45:26.340 - 00:45:30.480, Speaker A: And what was the fixed for my personal defication?
00:45:32.620 - 00:45:46.960, Speaker C: Now, with the new pr for 7702, the auth message is consumed by updating the accounts nonce. So the auth message is only valid for the nonce it's signed, and then once it's consumed, account nonce bumped. So you can't have zero nonce. It counts with code.
00:45:48.030 - 00:45:57.110, Speaker A: Okay, cool. Yeah, that works. I think, in general, we can just.
00:45:57.150 - 00:45:58.190, Speaker C: Accept this ERP, right?
00:45:58.230 - 00:46:32.120, Speaker A: Because currently, this whole situation of deleting these accounts is not really like empty accounts with storage. That's not really possible anymore, right? It's not currently possible, yes. And in fact, come to think of it, if the 7702 EIP no longer leaves the nonce as zero, then there's no problem to begin with. So we can even withdraw the EIP altogether, which is fine by me.
00:46:43.310 - 00:46:45.810, Speaker B: Okay, so then we do not need 7733?
00:46:48.670 - 00:46:49.530, Speaker A: Nope.
00:46:51.230 - 00:47:12.300, Speaker B: Okay, great. Okay, that was easy. That was it. On the agenda for today. Is there anything else we would like to discuss? Otherwise, we'll go ahead and wrap up a bit early today.
00:47:15.320 - 00:47:38.160, Speaker A: Otis, I just wanted to shield that. We have a breakout room tomorrow for 7732. This is number four. And the agenda is kind of packed. So if you're working on epbs, come tomorrow. And if you're not, take a look at 7732. That is already open and the Cl repo has is an only Cl tip and the repo has the Pr.
00:47:41.980 - 00:48:05.170, Speaker B: Great, thanks. Yeah, I dropped the issue for the breakout call in the chat. It's 1083. If you are interested, please attend. My client has a question. Did Guillaume have more to discuss on system contracts?
00:48:09.070 - 00:48:38.688, Speaker A: Yeah, good question. Not really. I mean, maybe just announced that we reached an agreement. So yeah, there is an update to the EIP. I made an update pr to the EIP to say in Prague everything behaves like, everything in 29, 35 behaves exactly like 4788. And then there's another EIP to talk about how things change. But once vertical is activated.
00:48:38.688 - 00:48:47.580, Speaker A: So that is a bridge that we have to cross when we get there. Yeah, no need to hold Prague for this.
00:49:00.250 - 00:49:13.350, Speaker B: Okay. And there's a little more discussion in the chat. Are we 100% certain there are no mainnet accounts which are empty but which have storage? I'm not sure if that is going to impact 7733.
00:49:15.010 - 00:49:46.890, Speaker A: So there's actually a few that were created before, before EIP 161. But we agreed on some call some time ago that during the conversion those accounts will be deleted. So yes, then we will be sure. Unless a new mechanism gets introduced, of course that will be able to create those, those new, those new accounts. My understanding is that no, we cannot, we cannot create new empty accounts at this time or in Prague.
00:50:00.390 - 00:50:07.010, Speaker B: Okay. Like client would you have, do you have some things you'd like to bring up around spectroscoping?
00:50:10.760 - 00:51:44.310, Speaker C: Yeah, I mean, I feel like we are, we go through phases of being heads down, focused on forks, focus on devnets. But there are these things that don't have the strictest, like Devnet deadlines that don't have the strict hard fork deadlines which are important and we aren't discussing them that much. And I'm just like hoping to maybe get some more clarity from other client teams about where these things stack up in our priority list. I think history expiry is something that is super important and we talked about it at the interop and it felt like we wanted to move forward with it and I haven't really seen a lot of work or thoughts or progress on that since then. So do we need to start implementing portal? What's the next step here? Should we have a call where we have updates about what we're doing and try to do some devnets? I really don't know. And another thing that I think is not being talked about really at all that is important is that if we're going to be doing peer dos and increasing the blob count and packtra or some fork soon after, then we need to have a better idea of how to deal with blobs in the public transaction pool because we don't want to just two or three x the total blob count and do nothing for the public mempool because then the public mempool will eat away all the bandwidth improvements that we got from peer dos. So these are things that I think we need to.
00:51:44.310 - 00:52:33.610, Speaker C: Yeah, and Marius is right. We also need to revamp some things if 7702 goes in as it is. So there are, there's a lot of stuff that we need to be working on and we're just talking about the like surface level eips going into pectra. And so it would be good to hear when people want to start talking about these other things and when we might expect some of these things to be updated. I see everyone is very excited to talk about these topics.
00:52:36.190 - 00:52:54.330, Speaker A: So late time. We are experimenting with portal network integration. We have a developer working on it at the moment, but we'll see how it goes. It's like experimental research right now.
00:52:54.910 - 00:52:55.582, Speaker C: Okay.
00:52:55.686 - 00:53:05.080, Speaker A: About eradic exports import. We are working on it as well. So generally we are working on history expiring.
00:53:07.380 - 00:53:49.140, Speaker C: Sweet. How can we like surface more of the work? How can we. I feel like this is an important priority, and I think most other people agree it's an important priority, but I don't think that it's receiving the same attention, at least on this call, as if it were going into a hard fork. What's a better way to make sure that the progress is being surfaced and that the progress is sort of being a forest? For better or worse? We do have a bit of a call driven development cycle, and maybe that just means that we need to talk about our progress on history expiry every, all core devs. I'm not sure if people have other suggestions.
00:54:01.410 - 00:54:03.298, Speaker B: I think my.
00:54:03.394 - 00:54:20.760, Speaker A: So my biggest problem was that we don't have the scope of tech cut down. And since we don't have this, we cannot really focus on other things because we're still working on some stuff that might go into pectoral or might not.
00:54:21.180 - 00:54:24.556, Speaker B: And maybe it would be nice to.
00:54:24.588 - 00:54:39.760, Speaker A: Say we stop now. We go with this spec that we have right now. We ship it on Devnet, one, two, three, whatever. And this gives us a bit of breathing room to work on other stuff as well.
00:54:40.540 - 00:54:46.216, Speaker B: Once, once the stuff is on the Devnet, it's not that much time anymore.
00:54:46.248 - 00:54:47.820, Speaker A: That we have to spend on it.
00:54:52.720 - 00:54:53.540, Speaker B: Thomas.
00:54:54.920 - 00:55:56.590, Speaker A: Yeah, so regarding blob transaction propagating, I have a general comment, which goes a little bit beyond ACD, but I think it's probably a mistake to try to start looking into changes to the protocol without having all the information at hand. I sat down in a war room on a roll up of a major roll up, and I saw how the gas price was spiking, even though the base fee was still at one way. And this happens when you have a series of builders, for example, that are averaging three blobs per block, and home stakers that are actually committing the six blocks transactions. And we have data for that. We have data that home stakers are sending more blobs and builders. This breaks the 1559 market that we have for the gas, that price. So if we don't have really good data onto how this market is working, how are the transactions are propagating, and even how the miners are calculating the tips.
00:55:56.590 - 00:56:09.340, Speaker A: Because we see transactions with lower tips that are getting included before transactions with higher tips, then it's very hard to try to think that we're going to solve this here at the protocol level. We probably need to have more data on how the market is actually working today.
00:56:18.920 - 00:56:20.300, Speaker B: Mark, did you have a comment?
00:56:25.720 - 00:56:44.440, Speaker A: I wanted to just ask my client, did you guys start working on something related to blob takes pull for peer dust or. Not yet. We are not working on that right now, but we will start if you are exploring.
00:56:45.740 - 00:57:36.516, Speaker C: Yeah, we haven't started any development of anything. I've basically just been having some conversations with, mostly with Piper since he has looked into this idea of propagating transaction within the portal network. And as you know, in the portal network, you have very light nodes who only have a very specific view of the network. And so he sort of come up with an idea of having an over, basically an overlay that says where to propagate certain transactions to. And that feels like the right path, at least for blob transactions, where you sort of based on your node id, you know, where you know what transact, like what accounts transactions, you're going to need to keep track of. And I don't see necessarily a blocker for it. I think it's something that we just have to implement and see if it works.
00:57:36.516 - 00:58:27.870, Speaker C: Okay. But I just don't really know when to do it because we have a pretty high cadence of Hector devnets and adding things. And it would be good if we had a way to make room to work on this stuff that isn't specifically fork related. That needs to be done. And that's what I'm trying to figure out is what is that thing? Because it's really nice with the Eaps, because we got the Devnets, the EAP numbers, the testing team makes some tests and then we can just run it in kurtosis or we can run it on the Devnet that's forcing us forward. But a lot of this other stuff, these are just ideas and we just keep saying this is important, but we don't make a lot of progress on them because there isn't the forcing function.
00:58:45.290 - 00:58:47.230, Speaker B: So is the answer more breakouts?
00:58:48.980 - 00:59:17.278, Speaker C: I mean, I don't think it's just more breakouts. I think that we need to have something at the all core devs level. I think we need to be sharing updates on how things are progressing. Yeah, probably we need more breakouts to discuss and move things forward. But I also feel like, I mean, it needs to basically be a requirement. It needs to be something that is part of the devnets. Like clients are implementing the older version of 7702 because it's in the Devnet one spec.
00:59:17.278 - 01:00:06.490, Speaker C: And if we didn't have these things, if it was just more free flow, we probably wouldn't have started implementing seven 7.2 and we would just start looking at this new version. And yeah, there's a little bit of extra work that's done there, but it is forcing us to move things forward and it is forcing people to get the context they need to make more informed decisions. I think right now everybody is saying these all sound great, but we don't have enough context to make really good decisions and have technical debates, whether it's in a breakout here or youth magicians. And so we need to like be building that up. So I kind of feel like if we really truly want to make progress on this stuff, then we need to start saying like, okay, here's a Devnet target that's going to have this functionality. Let's start working on some tests to make sure that that functionality is working and, you know, not move forward until those things happen.
01:00:06.490 - 01:00:50.650, Speaker C: And I think part of it is, you know, even if we do have those things, there's just like a finite number of people and time to do this stuff. And we're like pretty saturated with Petra. So I would like to maybe talk about either, if not capping Pectra, then even reducing the scope of pectra bit from what it currently is. Because at this rate, Pectra will not ship this year. And if it doesn't ship this year, then it will ship sometime next year, probably without these things, history expiry and improved blob transaction propagation. So then that stuff will only start bubbling up like mid to late next year.
01:01:04.160 - 01:01:05.460, Speaker B: Yeah. IPhone.
01:01:08.280 - 01:01:08.704, Speaker A: Yeah.
01:01:08.752 - 01:01:16.300, Speaker B: So I agree that with history expiry, if it's not a hard port, it doesn't seem like there is any pressure to get it done.
01:01:19.960 - 01:01:49.730, Speaker C: I mean, yeah, with history expiry, like it is an Eth wire upgrade. So it feels like something that we should be doing in a hard fork. Like no, we can do it without a hard fork, but because we are going to bump the eth wire for the requests anyways, we might as well bundle these things together. It's been my opinion and part of it is me not pushing forward these things and updating these specs and making them happen. But again, part of the reason is because there has been a lot of work on Petra instead.
01:01:53.430 - 01:01:58.582, Speaker B: Okay. Yeah, I think given that you said that it probably would make sense to have another breakout room because I thought.
01:01:58.606 - 01:02:00.546, Speaker A: It would just be sort of a.
01:02:00.578 - 01:02:09.750, Speaker B: Add on to the nodes. At least that's one of the ideas that has been going about. So it wouldn't actually affect anything to do with the normal p two p network.
01:02:22.970 - 01:02:31.220, Speaker C: Is anybody interested in capping the scope for pectra or reducing the scope or up only?
01:02:33.720 - 01:02:35.088, Speaker B: Well, let's not do up only.
01:02:35.184 - 01:03:20.540, Speaker A: I am interested in that. Yeah, I think if we start revisiting our decisions like for no good reason, that's a bad practice. So we've been discussing the scope of Paktra quite a lot, and I don't think it's a good thing to regurgitate the same discussions again and again. I am fine with not increasing the scope of pectra, but I'm totally not fine with kind of revisiting and reducing it for no good reason.
01:03:25.330 - 01:03:26.190, Speaker B: Thank you.
01:03:28.890 - 01:03:50.880, Speaker A: Yeah. Quick question. If we don't need a fork for EIp four force, why not just let people implement like what's preventing us from letting just clients implement it on their own time? Like some clients might be able to have it right off the right of the bat. It will take years, but that's fine. Is there something blocking us from doing?
01:03:51.050 - 01:04:42.870, Speaker C: Well, I think we need to have a ethwire protocol that says I am not going to have that historical data, because if we were to just ship it in the current Ethwire protocol, you're going to have very heterogeneous set of nodes where some nodes have the History and some nodes don't. But there's not an identifier in the handshake that sort of says do I have the history or not? And there's been proposals about having an identifier that says how much history I have. I would prefer to just say whether or not you have the one year of history as this binary thing. But yeah, I think that we have to have some way of saying that so it doesn't have to go into a hard fork. But if Geth implements it and no one else does, then it's going to be harder for those nodes that are still full syncing the history to go and find that history because there will be less nodes on the network to serve it to them.
01:04:44.730 - 01:04:46.026, Speaker B: Wait, I thought that if you didn't.
01:04:46.058 - 01:04:47.578, Speaker A: Have the history, you just proxy to.
01:04:47.594 - 01:04:50.800, Speaker B: The portal network so nothing really changes.
01:04:51.140 - 01:05:00.880, Speaker C: I mean, you can't really proxy to the portal network for network queries because the portal network isn't really designed for these range queries that the P two P would request.
01:05:02.340 - 01:05:03.468, Speaker B: Right, right.
01:05:03.644 - 01:05:17.040, Speaker C: It's more for if the RPC receives a request for like one off blocks, then it could go and get that one off block. But if you're, if the node requests for like 10,000 headers, you're not going to want to download 10,000 headers from portal.
01:05:31.240 - 01:05:32.180, Speaker B: Marius.
01:05:34.560 - 01:05:57.640, Speaker A: Yes, this is unrelated to the discussion that Guillaume and Matt just had, but related to the discussion that we were having in the chat around the blob transaction. One thing we noticed basically today is that there are some issues around.
01:05:59.820 - 01:06:04.640, Speaker B: The order in which we propagate block transactions.
01:06:06.620 - 01:07:12.622, Speaker A: So what we need to do is we need to propagate the block block transactions, arrive at our node in the wrong order, we might actually throw some of them away. And that leads to issues. If a roll up sends multiple block transactions. We operated under the assumption that rollups don't need to send multiple block transactions per block, but apparently some of them are still doing it if it might be out of box for out of necessity. Anyway, we need to make sure that we are sending and receiving block transactions in the same order, in non ordered order, so that we don't throw them away in the transaction, in the transaction portal. Just, just an FYI to, and we.
01:07:12.646 - 01:07:14.558, Speaker B: Are not doing that in Geth, there's.
01:07:14.574 - 01:07:45.222, Speaker A: A bug right now where we are not receiving them in order, and so we might actually throw some of them away. So yeah, this is something that we're going to fix. And it would be good if other clients also took note of this and checked their block pool implementations to make sure that they are also only sending transactions and receiving block transactions in order. And this will make block propagation quite.
01:07:45.246 - 01:07:46.942, Speaker B: A bit less painful because you don't.
01:07:46.966 - 01:07:50.570, Speaker A: Need to resend block transactions all the time.
01:08:00.960 - 01:08:09.660, Speaker B: Okay, so there's a client issue to be aware of. But then also, blob users should be careful about how they send the transactions as well.
01:08:13.520 - 01:08:41.145, Speaker A: Yes. They should be aware that if they are sending multiple transactions, that these transactions might arrive at other nodes in the wrong order. And so some of them might be thrown away. Because we only allow non order transactions and not ungapped transactions in the block pool. So that we only allow transactions that.
01:08:41.177 - 01:08:42.629, Speaker B: Have no non scap.
01:08:45.009 - 01:08:52.230, Speaker A: In the block pool. Not in the normal transaction pool, it's fine. But in the blob pool, it's not.
01:08:56.530 - 01:09:06.910, Speaker B: Right? I mean, I guess, how would you know? As a roll up or like, you know, let's say I'm making a blob. Like, I might not necessarily know that there's a nons gap somewhere else. Right?
01:09:12.130 - 01:09:26.649, Speaker A: You should know it because you know which. Which nonce to put into your blob transaction. So you know that there was a non scap to the current state that you have.
01:09:28.669 - 01:09:36.949, Speaker B: Okay, but that kind of implies I need to either only make one transaction at a time. Like, I essentially have to wait for. If I make a transaction, I have to wait for it to be included.
01:09:37.029 - 01:09:37.649, Speaker A: Right?
01:09:38.189 - 01:09:41.209, Speaker B: I can't make like three, four, five.
01:09:41.859 - 01:10:17.846, Speaker A: You can actually make multiple transactions. Just that. So what people kind of tended to do is basically wait a couple hundred milliseconds between sending them out so that the previous one has time to propagate. In the case of blob transactions, it might take a bit more. It's definitely something that we will attempt to fix in Geth, but it's still. The problem is that the transaction announcement protocol is very dumb. It just says that, hey, here's a hash, and you do whatever you want with it.
01:10:17.846 - 01:10:44.216, Speaker A: So what we can do in get, we can make sure that we download announced hashes in the order that we have received those announcements. But we have absolutely no idea what those hashes belong to. So we don't know what order we should download. If we have, I know, 3000 hashes, which one of them are. I mean, okay, we know which one are blob transactions because we also include that. But we don't have the nonsense. We don't have the accounts.
01:10:44.216 - 01:11:29.070, Speaker A: So we can't actually prioritize or sort downloading the blob transactions in order. So even if we take care to do a better job in keeping the announcement orders that we see the hashes in, there's still no guarantee if some other client announces them in a bit yolo y way. So GATT does take care not to announce them gapped or out of order, but we can't really rely on other clients doing the same thing. So there can always be some weirdness there. But that's a whole new can of worms as to what could be done with the full transaction propagation to make it more stable. So.
01:11:30.050 - 01:11:35.790, Speaker B: Right, yeah. I wonder if you could just include the nonce along with the transaction announcement.
01:11:36.930 - 01:12:03.160, Speaker A: I mean, the thing is, you need to include the nonce and then you need to include the account. But the problem is that you cannot really verify it until you download it. So I mean, it's still, somebody can still feed you feed. Basically, I can just watch what kind of accounts are announced on the network and just try to clash with fake nonsense and fake addresses. So it's like, it's kind of hard to make anything that's really robust.
01:12:04.940 - 01:12:14.920, Speaker B: Yeah, that makes sense. Otis, did you have your hand up from earlier or was that resolved?
01:12:16.180 - 01:13:08.178, Speaker A: Just wanted to mention that batch. Posting on a roll up is quite complicated and you changed a tactics on the run as other roll ups also are changing their tactics. If you have a transaction, if you're posting batches at six blobs per transaction, and you see that none of your batches are being posted because some roll up is posting and paying more than posting only one blob, and then the builder cannot include a transaction with six blobs because they already have that one blob there. Then roll up, start resending batches with less blobs. So I'm not saying that geth should do this or do that, but definitely there aren't that many users of blob transactions today. And those are the guys that are being affected. And roll ups are being forced to try to talk to the relays to see how are they going to get their transactions to the builder because the public mempool is not getting those transactions to the builder.
01:13:08.178 - 01:13:49.116, Speaker A: So this conversation should be happening with the roll ups and not among ourselves only. I feel like there's this thing that get is doing something to protect the mempool. And I understand, I mean, there's a DoS attack there. But then on the other side, there's the users there that many users, and they have their own problems into, and they try to adapt to whatever geth the size of the mempool should be. And this conversation should be happening with them. Yeah, I think we would be curious to know how roll ups operate. I mean, how they send their transactions and what they would like supported and not supported.
01:13:49.116 - 01:14:22.050, Speaker A: So I think that's a perfectly valid. We're open to that. But again, I don't think it's fair to say that geth needs to do this. I think basically all ers needs to be aware of these and do it properly. I also don't necessarily agree that we, we need to talk to the roll ups.
01:14:22.130 - 01:14:23.870, Speaker B: I think it's kind of.
01:14:24.450 - 01:14:37.316, Speaker A: We are not providing the service that we are claiming, and so we need to fix it. It's not really. Yeah, like we should, we should do.
01:14:37.348 - 01:14:39.412, Speaker B: Something about it and we are going.
01:14:39.436 - 01:15:01.860, Speaker A: To do something about it. But I just wanted to mention that there are some issues there. Yeah, for sure. So this is something that affects the normal transaction pool too in a bit. So it's an issue, we're going to fix it. But I'm not entirely sure that is going to make too big of a difference. But we can definitely see.
01:15:24.970 - 01:15:39.550, Speaker B: Comment in the chat that essentially roll up should think about how many blobs they put per transaction. If you have a transaction with six blobs, it becomes this like very bulky thing to pack in alongside other blob transactions. And if you.
01:15:39.970 - 01:16:15.740, Speaker A: There's a lot of literature to this. This is not something that rollups have been thinking about this way before we shipped 4844. They have a lot of literature as to what is the optimal strategy. And also, depending if there's two, three players posing at the time, roll ups know much more than we know about how to post batches. The thing is that there's also this external constraint, which is how the public mempool actually acts. And that breaks the assumptions of that body of literature. But I would say that the rollups, they know much more of what are the better strategies for batch posting than what we know.
01:16:22.240 - 01:16:40.790, Speaker B: Maybe. I mean, if you, if I make a six blob transaction and then there's some like min pool issue, that means I don't see it in time, you know, like another roll ups transaction, then I just wouldn't know. Right. And I think if you take this to the limit, like you should actually only put one blob per transaction because that's the most flexible way to tag.
01:16:45.130 - 01:17:39.120, Speaker A: So another thing that I think people need to be aware of is that six blobs means 1 data. What is it, 1 mb? Maybe a little less, little less. But essentially that's a huge latency to propagate over the entire network. So, yeah, it's kind of. We're entering in this weird territory. And there's also this talk that people would like to even further increase the capacity of block transactions and blocks. But yeah, I mean, it's probably not really super healthy to create transactions that are that heavy because they just strain everything through the entire pipeline and then weird things start happening.
01:17:39.120 - 01:19:08.050, Speaker A: So your suggestion would be to increase the maximum number of blobs in the block while keeping the limit of blocks per translock per transaction the same or something like this? No, I'm not suggesting anything. I'm just saying that it's another dimension that people, everybody needs to be aware of. That latency starts to play a role here. Yeah, but I'm suggesting this now that we should think about whether we want to limit the number of blocks per transaction with a different limit than the number of flops per block. I like a limit of one. No.
01:19:08.630 - 01:19:38.100, Speaker B: What? Yeah, I'm just going to say that. Yeah, it looks like there are plenty of open issues with bobs, so. Yeah, everyone keep thinking about it. Generally the feature end market is immature. So, you know, we'll work out these kinks as time goes on. Is there anything else? We have a few minutes left on the call. I don't think there are any other agenda items for the day.
01:19:38.100 - 01:19:58.990, Speaker B: Okay, let's go ahead and wrap up then. Thank you, everyone.
01:20:01.730 - 01:20:03.626, Speaker A: Thank you. Thanks. Bye.

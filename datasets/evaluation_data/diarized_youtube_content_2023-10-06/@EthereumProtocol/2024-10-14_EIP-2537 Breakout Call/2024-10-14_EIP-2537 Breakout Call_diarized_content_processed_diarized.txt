00:00:00.720 - 00:00:52.165, Speaker A: Let's go ahead and get started. I'll grab the agenda here for the call. I think the main thing that we'll discuss for the day is just settling the gas pricing. I think that was like kind of the big open question for this EIP and Petra. But then I think settling the gas pricing opens up a lot of different questions attached. There is also a proposal to remove the mole precompiles and instead use the MSM to signal mole of just one element rather than multiple. So yeah, I guess to kick us off, there was some discussion already on the issue around these different, yeah, I guess gas prices for things.
00:00:52.165 - 00:00:57.455, Speaker A: Jared, you had a recommendation here. Do you want to give us a little context on your thinking?
00:00:59.315 - 00:01:23.095, Speaker B: Yeah, sure. So basically what I the the argument I'm making is that if we're going to change the MSM GAS model, we might as well repress other pre compiles that are pretty simple to reason about. And I came up for with.
00:01:25.155 - 00:01:25.539, Speaker C: Just.
00:01:25.587 - 00:01:42.095, Speaker B: A suggestion to reprice those. Just an example repricing using the performance of EC recover, scaling them to the performance of Easy Recover and the get implementation of EC Recover. So.
00:01:46.085 - 00:01:53.505, Speaker A: Yeah, is there a reason for EC recover? Like is that how we thought about the alt, the end curve?
00:01:57.165 - 00:02:34.025, Speaker B: I'm not sure about that one in particular but I do know that when they repriced the MODX P pre compiles it was used in the EIP as a justification and it's. I don't know, it's. It's. I would say with lack of access to a bunch of different benchmarking machines from my side, it's the easiest, easiest way for me to make pricing suggestions.
00:02:34.325 - 00:02:41.395, Speaker A: Yeah, that makes sense I guess. Barnabas. Oh mommy. Do you have something to say?
00:02:42.935 - 00:03:48.745, Speaker D: Yeah, I made some suggestions in April back on the benchmark I had based on Constantin. One of the easy repricing to do is make sure that the KCG Precompile and the EIP2537 have the same price for the pairing like this is. It's the same operation basically so they should be the same and actually currently there is like 20,000 gas of difference or 10,000 gas of difference and then yeah, I mean I've put a link with my benchmark on my own machines to give you a sense like when it's using the same library for everything because when you use Geth for example, it's implemented ecrecover is implemented in SECP20 and things are implemented in other languages or manner. So I guess this will give you a Better holistic view of the price.
00:03:52.125 - 00:04:27.365, Speaker A: Okay, thanks. Well, okay, I mean I see you have here, you have a section called out with subgroup checks. I thought I saw somewhere. Yeah, okay. I mean I guess that's like one place to start. So we had kind of, we had gone back and forth on this and I believe where we settled last was that we would have them, you know, where appropriate, which I think is like most of the precompiles. Does anyone want to argue for something else?
00:04:40.245 - 00:04:46.105, Speaker E: I'm sorry, I missed that last bit, to be honest. Are you saying that we would price pairing specific to.
00:04:46.645 - 00:05:48.309, Speaker A: Well, it would apply to like I think most of the pre compiles. So essentially like. So yeah, there's this question of I can pass in like say the points can be like U256 and they're like a U256. So it turns out that you know, for all valid integers in that range only a subset are, you know work or make sense with the actual way the curves are constructed. And so you know what usually is done and maybe someone can correct me if I'm wrong but usually what's done is if you have some number you do a subgroup check either to say hey, this is an okay number to proceed with or I feel like there's also like a reduction you can do but there's like a security issue if you allow sort of quote bad inputs. And so then the question is like for the pre compiles that we exposed everyone on Mainnet, you know, do we want to prefer the security and or like the safety of this. And the trade off then is like these type group checks do add computation.
00:05:48.309 - 00:06:11.085, Speaker A: So they are you know, more than zero expensive. So there's sort of like a security versus cost trade off to navigate. And you know, I feel like we had said a few months ago, basically hey, like let's go for security. So even if it's more expensive, you know, the misuse is, you know the risk of misuse is much, much lower this way.
00:06:14.985 - 00:06:22.151, Speaker E: And potentially the the risk of consensus failure. If these edge cases are handled differently.
00:06:22.263 - 00:06:31.355, Speaker A: I don't think it would be consensus failure. Like this is something we can test for and it's more like you know, the clients would all do the same thing. It's just not with these or wants.
00:06:37.655 - 00:06:39.235, Speaker F: OOP this working.
00:06:41.945 - 00:06:43.217, Speaker E: Yeah, we hear you Kev.
00:06:43.401 - 00:07:03.085, Speaker F: Oh, sorry. Yeah, I guess it just depends on who the user is. Once we sort of say this is the user then it's sort of easy to say whether we should include them or not does anyone have a candidate sort of user slash use cases?
00:07:03.425 - 00:07:22.505, Speaker D: Well there is obviously rollups because there will be likely the main consumer of cryptography and we can assume that they will aud their contract and that they know what they're doing. But yeah.
00:07:25.325 - 00:07:36.105, Speaker F: Right. Is there any other use cases or users because rollups we can assume that they're going to do the subgroup checks.
00:07:37.245 - 00:07:42.825, Speaker D: Alex mentioned validating BLS signatures from validators. So I guess that involves bridges.
00:07:44.865 - 00:08:04.005, Speaker A: Yeah. And I mean I just feel like there's a whole host of applications you can imagine that come down to validating, you know, what validators have signed over. So those to me I think are like the two big ones. But also yeah, I guess that's almost another one is like bridges from other chains as well could imagine using this.
00:08:04.425 - 00:08:19.939, Speaker D: Possibly people like I guess Flashbots or Eigenlayer if I want to do restaking and verifying some of the consensus stuff.
00:08:20.107 - 00:09:11.025, Speaker A: Yeah. So yeah and point being is just like okay, can we validate snarks in like a nice way? That would be the real use case and then can we validate BLS signatures in a nice way? And I think those are like kind of the two buckets of things. I don't know. Like what I would say is start from let's make like assume the most sort of secure thing we can AKA like expose the safest API and see what it costs. If it's you know, way too expensive for anyone, then we can evaluate like ways to make it cheaper. Probably at the same time making it less safe. But even with roll ups it's like okay, like if it's only going to cost like a little bit extra gas to do sub check groups the subgroup checks for them.
00:09:11.025 - 00:09:13.445, Speaker A: Like I don't see why we wouldn't just go ahead and do that.
00:09:14.345 - 00:09:23.925, Speaker F: I think the argument is that if you call the precompiles multiple times, you're doing redundant subgroup checks.
00:09:27.345 - 00:09:53.325, Speaker C: Exactly. That's also in my opinion the most important reason that it should be possible to turn off the subgroup subgroup check for these precompiles. Because in other case, in my opinion in very, very, very in a lot of cases it will be just useless because they will be paying for unnecessary checks. So.
00:09:56.545 - 00:09:56.977, Speaker A: Right.
00:09:57.041 - 00:10:27.255, Speaker D: So should we like the art, two ways if we want to turn this off? Assuming we're okay with security implication. One way is to create a separate subgroup check opcodes WordPress compiles. Or the other way would be to add a flag like a boolean to say a skip subgroup check for example. Yeah, forces People to think about it.
00:10:27.735 - 00:10:58.125, Speaker C: Yeah, this will complicate a little bit the GAS model for this precompiling but that's one of the flag also can be added to not in a globally to all the sets, all the points in the set, but also for each point specifically. So with additional flag for example using the spare bits at the beginning of the point but. Oh sorry of the point here.
00:10:58.705 - 00:11:04.045, Speaker B: Just to be clear, are we only talking about removing subgroup checks for the msm?
00:11:06.105 - 00:11:09.005, Speaker D: I think it's also scalar multiplication.
00:11:10.345 - 00:11:12.833, Speaker C: Yeah, I agree.
00:11:12.929 - 00:11:14.285, Speaker D: So Aaron.
00:11:17.345 - 00:12:14.011, Speaker B: So when I when I did some benchmarking on was Friday just looking at gar the cost to perform the subgroup checks and then the GLV multiplication was not all that much more than doing the whatever the naive like double and add method that can take any input. So it seems like there should be no reason to remove the subgroup checks on scalar mole. Like there's and this is just one library of course but yeah, it just doesn't seem like we gain anything from removing them for scalar mole from scalar molecule.
00:12:14.153 - 00:13:16.335, Speaker C: Yeah. On the other I also made the benchmarks for the multiplication for G1 and G2 and then maybe not naive method but the method with windowing and without subgroup check comparing to the method with using GLF and subgroup check which is required for glf. So I get the same results or very similar for G1 and for G2 in using I'm talking about the BLST library and for G2 even so for G2 the GLS algorithm is used there for G2 but basically it was much faster and even with subgroup check it was faster than the naive method without subgroup check. I mean by naive method I mean the window method which is. Which is subgroup check. Resistance. Resistance.
00:13:19.675 - 00:13:46.115, Speaker F: Right. So I think the only reason to have the subgroup check on the scalar model will be for consistency. So if you do MSM with one input and then you do a scalar model, it may give you different results depending on like if one of them has a subgroup check and the other doesn't. I'm not sure if this is important for people.
00:13:50.695 - 00:14:18.715, Speaker G: Yeah, I mean it seems good to have the ability to disable the subgroup checks, but I think we need to ensure that we're going to have a deterministic result with all the different implementations that we have. If I understand correctly, if some implementations might use endomorphism acceleration and some might not. So yeah, something interesting to try.
00:14:21.295 - 00:15:01.255, Speaker D: It's not safe to use endomorphism without subgroup checks. So when I Implemented the precompiler when subgroup check were required. I use endomorphism and if it's not, I just don't use them. And in msm, well, I don't think people are doing MSM of over a thousand points in the evm but who knows. Endomorphism are not worth it in my benchmarks and GNARC does not use them at all for MSM anyway.
00:15:04.875 - 00:15:30.435, Speaker C: Yeah, I have, I have, I'm not 100% sure but also BLSD doesn't use, doesn't. Doesn't use the endomorphism acceleration for MSM at all. It is just pipenter algorithm for windowing so it should be. It should work on whatever points from the curve you take.
00:15:38.255 - 00:15:57.235, Speaker F: So I guess do people agree with the consistency issue and is it an issue at all? So essentially if the scalar multiplication has the subgroup check, it's inconsistent with an MSM of size 1. If the MSM doesn't have a subgroup check.
00:16:00.855 - 00:16:09.875, Speaker G: We could combine this with the other proposal of just getting rid of the mul to simplify things and just using MSM.
00:16:13.255 - 00:16:35.085, Speaker F: In that case that would be the same as having the scalar mul but without the subgroup check and not using the endomorphism. It's just that we have one less precompile because Internally I think EVM1 they just did an if statement on the MSM size and then they're just doing a scalar model.
00:16:45.465 - 00:17:12.465, Speaker C: Yeah, I think, I'm not sure if Pavel can, can hear us now because. And yeah, so, so that's a proposal by, by Pavel to change this precompiles list and remove the moles and we have some, I think PR draft PR with which implements the multiplication using just MSM with one point.
00:17:18.285 - 00:17:29.075, Speaker F: Right? So does anyone, I guess the high level question, does anyone think that MSM of size 1 and a scalar model should be different?
00:17:31.055 - 00:17:56.835, Speaker D: They should give the same result and same error message. But I don't know if removing the simple scalar mill is useful for audit code readability. You don't have to double check how many inputs you have when you are reading the code. So not too sure if removing it is worth it.
00:17:58.895 - 00:18:32.865, Speaker F: Right? I'm not super convinced on removing it either, but yeah, so I think everyone sort of agrees that MSM of size 1 should be equal to a scalar model of a scalar mul. Which means that if we remove, if we keep the, if we keep the subgroup track plus Gov for scalml, then we'll need to add it For MSM as well, or at least for MSM of size 1.
00:18:40.805 - 00:18:48.447, Speaker A: When you say same result, I assume you're talking about the actual output, but also are you talking about performance or like cost?
00:18:48.631 - 00:19:04.275, Speaker D: No, I think if you have an error because something is not in the proper subgroup, both the MSM and the scalar mill of size one should give the error. But it's not the case if one has subgroup checks and the other does not.
00:19:05.655 - 00:19:11.675, Speaker A: Right. Would the scalar mole cost the same as the MSM with input one?
00:19:14.495 - 00:19:19.475, Speaker C: Yeah, I agree on that. That it should be the same cost, exactly the same errors.
00:19:21.695 - 00:19:22.439, Speaker B: Right.
00:19:22.607 - 00:19:56.195, Speaker F: So if we keep subgroup checks, then the MSM will have an if statement that that does the GLV endomorphism plus the subroute check. If we remove subgroup check, then I think the MSM would probably still have to have an if statement, but it just does normal scalar multiplication. Because pipping of size one is probably going to be a bit more expensive than just doing a regular scalar model. I haven't checked.
00:19:57.215 - 00:20:04.355, Speaker D: It's not really that much more expensive. I don't have a special path in Constantine. And the speed is the same.
00:20:05.815 - 00:20:08.471, Speaker F: Okay, so then we probably don't need an if statement.
00:20:08.663 - 00:20:12.955, Speaker D: This is like implementation detail. People can do whatever they want.
00:20:14.495 - 00:20:19.111, Speaker A: Well, it wouldn't matter. Yeah, I mean, but we need to like the gas cost have to make sense.
00:20:19.223 - 00:20:19.955, Speaker D: Yeah.
00:20:23.535 - 00:20:51.085, Speaker F: Okay, cool. Yeah, so if we remove or keep them, then they'll be the same. It's just all about the behavior. And I think most people agree they should be the same behavior. So that goes to Jared's question on why we want to. What's the point of sort of keeping the GLV plus subgroup versus not having it? It's whether we want the MSM to have subgroup checks or not.
00:20:54.465 - 00:21:16.055, Speaker A: Right. So if I, let's say I'm like, you know, a roll up or just maybe some user, like what does it look like for me to do the subgroup check myself? Is this something I do off chain? And then does it matter? Like would I ever want to like prove on chain that I was inside the subgroup? I guess is the question.
00:21:17.235 - 00:21:38.885, Speaker F: So it's pretty, it's for most it's context specific, depending on whether you trust the input. If you trust the input, then you can have a reasonable. Then you will know if it's like in the subgroup or not. If you don't, you probably want to do it at the beginning of your computation and then not do it again because all the operations should keep you in the subgroup.
00:21:41.305 - 00:21:43.765, Speaker A: And so how expensive would it be to do on chain.
00:21:45.865 - 00:21:55.645, Speaker F: The subgroup check? Yeah, I'm not sure we have any gas pricings for them at the moment, but it depends on like how many points you have as well.
00:22:04.135 - 00:22:34.245, Speaker G: I haven't benchmarked the subgroup checks alone, but it does make like a very significant difference to the overall gas costs. Wait, so Kev, do I understand correctly? So you're saying that it would be easier to keep them the subgroup checks for Scalamul because they're used by more implementations and so we'd have to keep them for MSM of size one.
00:22:35.985 - 00:23:14.375, Speaker F: Oh, sorry. What I was saying is that if you look at scalamal in isolation, it doesn't really make sense to remove the subgroup check because without the subgroup check you have this sort of basic Scalamull algorithm that's roughly the same performance as with the subgroup check plus the optimization. But if you look at the consistency between scalar mul and msm, if you keep subgroup check for scalaml, then it makes sense to keep it for the msm. But we've just seen that keeping it for MSM is actually adding a lot of costs. Um.
00:23:16.195 - 00:23:25.091, Speaker A: And is that cost because we're doing like, is there like we're still only only doing the subgroup check once per input, right? It's not that we do it like many, many times.
00:23:25.163 - 00:23:56.755, Speaker D: Yeah, but the thing is MSM is sublinear, but if you, the subgroup check, you have to do one per point, so it's linear. If you do the subgroup check. So the slowdown, it's big, but it depends on the size of input. Like I don't know if there is enough gas costs to do a thousand points in msm, which would be noticeable, like the difference between linear and sublinear.
00:24:01.775 - 00:24:27.215, Speaker B: I think for G1, the absolute worst test case that either Martin or Marius was able to come up with that would fit within a 10 million block gas limit was 4800 points. But that doesn't factor the cost to set up the call to the pre compile. So it seems like maybe a thousand could be doable, but.
00:24:34.405 - 00:24:44.345, Speaker A: Right. I mean, do we have a sense of like, you know, let's say I have like a nice snark scheme that's relatively modern. Do we have a sense of how many points I would need to verify?
00:24:50.205 - 00:25:00.545, Speaker D: One other thing that might use this for verification would be maybe the vertical trees. I'm not too sure. But do they use this.
00:25:02.805 - 00:25:19.825, Speaker F: Ver tre? I would assume that there might. There would be a pre compile for it if we was to do verification of it for Most snarks.
00:25:22.005 - 00:25:22.613, Speaker E: For gross.
00:25:22.669 - 00:25:31.835, Speaker F: 16, there's not points. Yeah, there's not a lot of points anyway. So it just gets limited by pairings for long.
00:25:35.495 - 00:25:43.235, Speaker A: I guess that's my question is how realistic is it going to be for a user to come and need to multiply, like verify, you know, feed thousands of points into the msm.
00:25:46.735 - 00:26:19.206, Speaker F: Oh, I see. It's a good point. Not sure if I check just normal plunk. There is one. Sorry. 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16. Like about 16.
00:26:19.206 - 00:26:29.395, Speaker F: We can just say 20 MSM of size 20 for like regular plonk.
00:26:30.095 - 00:26:30.559, Speaker A: Okay.
00:26:30.607 - 00:26:32.955, Speaker F: I don't think you'll get up to like a thousand.
00:26:37.855 - 00:26:57.185, Speaker A: Right. And I guess my other question then is like, is it actually. So I guess, yeah, like let's assume we keep sub checks for everything. There's no way to toggle them off or on. Like is it actually like for inputs that people are going to use, say in the next, I don't know, even five years, is it really going to matter?
00:27:01.405 - 00:27:10.105, Speaker C: I think we, we don't know because we, we don't know that we don't know the users of this of this year so.
00:27:10.285 - 00:27:12.365, Speaker D: Well, there is ZK sync.
00:27:12.665 - 00:27:31.445, Speaker C: Yeah, yeah, I'm in touch with them but I sent them email and also asked them to join the call but not sure if anybody from them joined. Sorry, I cannot see the list of the attendees and yeah, so I can only wait until they answer. But we can also try to reach someone else.
00:27:33.185 - 00:28:36.165, Speaker D: Yeah, another question that might help to solve this is. So let's say we launch with subgroup checks. Would it be possible in the future to keep the recompile ID and remove the subgroup check and add it separately? Like would it break people if the contract didn't work before? I assume that with the subgroup check they won't deploy it because it wouldn't pass the subgroup checks. And for those that work well, they would need to modify the contract to explicitly do the subgroup check. But I think it might be forward compatible to add them later and remove them from the original precompiles.
00:28:38.835 - 00:28:58.815, Speaker A: You mean add as a separate precompilator? Yeah, yeah. I mean I think we should try to keep the APIs the same. So it would be weird if you had written a smart contract that you know, has some knowledge of this bit for turn, like turning them off or on and then yeah, in a future hard fork that just becomes invalid.
00:28:59.115 - 00:29:06.325, Speaker D: Although I guess you could, I mean without A flag without bits like you just keep the precompile as is.
00:29:07.065 - 00:29:15.885, Speaker A: Okay, but then. So why do we do this? Because we deployed it. It turns out this was way too insecure and so we need to fix it in a later hard fork.
00:29:18.945 - 00:29:39.855, Speaker F: No, I think it would be that it's deployed with subgroup checks and then people are like, this is too expensive. And then I guess you remove it and then everyone who is previously deployed is still safe. It's just that newer contracts now need to explicitly do the subgroup check. Is that. Is that. Is that right, Mommy?
00:29:41.155 - 00:30:11.455, Speaker D: Well, I'm not sure if they are safe because previously they would. They might need to be modified. That's. But I mean the question, can we. Can we do something today so that we can keep. We can be forward compatible if we decide to do subgroup check separately.
00:30:12.475 - 00:30:25.655, Speaker F: Oh, I see. Oh, okay. Yeah, that's correct. I guess the only way to do that would be that the contracts deploy today and let's say we add a flag and that flag always has to be true.
00:30:26.675 - 00:30:27.495, Speaker D: Okay.
00:30:29.725 - 00:31:05.115, Speaker F: So they get the option to put a flag in, but it just always has to be true. It just means that if you change the behavior then it doesn't break their contract. Once it's like once you allow false. Yeah. It's a bit hard to make a decision because the use cases or users who will be using it are sort of not present.
00:31:06.215 - 00:31:14.795, Speaker A: Right. So like. Yeah, who would be good to talk to them? Like ZK Sync? What about like Scroll? Or maybe even Tyco.
00:31:16.855 - 00:31:28.585, Speaker D: Taiko is using. It would be more like SP1 RISC0 because Tyco is integrating them basically.
00:31:30.085 - 00:31:30.865, Speaker A: Okay.
00:31:32.965 - 00:31:43.545, Speaker C: Yeah, as a joke. We have also. We have also additional options so to postpone it and wait until the EVM max will be ready and implement everything in VV max.
00:31:46.655 - 00:31:49.115, Speaker D: You mean postponing the eip.
00:31:49.495 - 00:32:03.315, Speaker C: Postponing, exactly, postponing the eip because again. But do we really know who really does need it and why are we adding this?
00:32:03.975 - 00:32:30.385, Speaker D: If you look at the. I think it's one of the EIP where people are always asking, wow, this has been proposed in 2020. It was almost shipped and actually shipped in parity by mistake in 2021 in Berlin. And yeah, people really want this. So if only to have MSM available as a precompile.
00:32:31.645 - 00:32:31.957, Speaker E: Yeah.
00:32:31.981 - 00:32:45.431, Speaker C: So let's reach out to these people and ask them if this specification is okay for them and we can decide if the subgroup check is needed or not. And we want to implement this or.
00:32:45.463 - 00:33:08.555, Speaker D: This other way because one way to view this is that Whatever we do, whether we use subgroup check or not, it will be much faster than doing things on chain at the moment. So. Yeah, and maybe we can just sweeten the deal with gas price.
00:33:11.035 - 00:33:45.215, Speaker C: Yeah, that's also an option. Or to at least for now implement the pre compiles which does not require. Which don't require the subgroup check. So they cannot use the super fast algorithms. And then with this additional flag, for example, which now is zero and then allow people to define a flag which will. Which will mean that the subgroup check needs to be done before something like that. I don't know.
00:33:50.355 - 00:34:21.495, Speaker D: Ken, to answer your question, is slower than BN254 but the BN254 gas price is very overpriced with the current state of pairing library speed. And yes, there is a security argument of the number of security bits of BN254 which is kind of inadequate today.
00:34:23.355 - 00:34:26.695, Speaker B: Is it only the pairing that's overpriced?
00:34:28.995 - 00:34:32.735, Speaker D: Not only. Let me look at my.
00:34:33.565 - 00:34:48.145, Speaker F: I think most of them were. I have a PR on gaff that switches out the Cloudflare implementation and I think it's like a 10x for some of them but all of them have an improvement.
00:34:50.245 - 00:34:51.025, Speaker C: Wow.
00:34:52.605 - 00:34:59.065, Speaker D: I think everything was overpriced on the BN254 precompiles cost.
00:35:00.885 - 00:35:16.905, Speaker B: I ask because I feel like there was already years ago there was already an A repricing to reduce them by a large factor because I think like Zach Williamson implemented EC Mole cheaper on chain.
00:35:17.725 - 00:35:20.305, Speaker D: Yeah. With virus Trudel.
00:35:21.445 - 00:35:23.905, Speaker B: Okay, but. Okay, so there's still.
00:35:25.635 - 00:35:33.015, Speaker D: But that was already back in 2019 or 2020. So it was five years ago.
00:35:39.555 - 00:36:12.285, Speaker F: I guess the point is that people are currently using BN254 like the roll ups and they're not doing it sort of inside of the evm. And I guess if, if this is too expensive, do they still stay on BM254? There's a security argument, but I, I don't know if most of them have brought this up. Like do they. Do they really care about the security argument right now?
00:36:15.905 - 00:36:56.605, Speaker A: I would hope so. So I don't know. Yeah, like I think there's grounds to ship this curve in the EVM. The security argument is one again. Also I think this, the BLS12 curve is just sort of a newer curve that more people are using. And also there's a very important use case again of the consensus layer. So I think, I mean, yeah, I don't think we should really dig into shipping this pre compiler or not on this call but yeah, I can try to get in touch with some of the people we listed and figure out like API wise what makes sense to them.
00:36:56.605 - 00:37:16.345, Speaker A: Another thing to think about or ask then is are there other questions around the gas benchmarking that we have? I think there might have been one around the MSM and how it works because there's a question of like multithreading and then how that bundles into how we think about benchmarking the gas cost.
00:37:24.565 - 00:37:37.781, Speaker F: What were people's thoughts on multi threading? I think Jared mentioned that you, you're going to ship with multi multiple threads but benchmark on single threads. And I think EVM once said, I.
00:37:37.813 - 00:38:25.545, Speaker B: Think the, the Geth team thoughts were along the lines of it being hard to have a benchmarking environment where you can accurately simulate like so. So when the node is running live, we don't just have it's noisy. Right. The, the CPUs may be like drawn in for other things and it's hard to replicate that in a benchmarking environment. And then yeah, I think just beyond that it's just work that is not paid for by the gas model.
00:38:27.925 - 00:39:01.745, Speaker F: Right. I guess one consequence of this is that it, there is no rationale to then increase, sorry, decrease the gas costs in the future. Right. Because let's say all nodes go up to like eight cores because we're only ever benchmarking on a single core. Even if MSM has become twice as faster in production, you can't argue to then decrease their cost. Right. Because on a single thread they're the same.
00:39:03.725 - 00:39:07.505, Speaker B: Yeah, sure, yeah.
00:39:08.325 - 00:39:42.235, Speaker G: If we're thinking about the worst case, then, you know, even if you have eight cores, it could always be that, you know, they're busy doing other stuff. So for the worst case, I think we'd still have to think about the single core performance. Yeah, we did the same thing for benchmarking as well. And MSM runs very slowly with one core. Like I think based on those results we have to increase it, but without the subgroup checks it seems fast enough even on one core.
00:39:45.415 - 00:40:10.685, Speaker F: Okay, I see. And I guess just out of curiosity, if someone was to push an MSM algorithm that was fast on a single core, meaning the latency was pretty low, but on multiple cores it wasn't fast. How do we gas benchmark that? Like it's slower on in production because it's not made for multiple cores.
00:40:14.425 - 00:40:19.325, Speaker D: Fast on one core serial and slow parallel.
00:40:19.715 - 00:40:20.455, Speaker F: Right.
00:40:24.835 - 00:41:05.825, Speaker D: I think today it would be safe to let's say bench on two cores because even the Raspberry PI 4, which we kind of memed when launching, the consensus layer, was already four cores. So this brings a question. What is cpu? The earliest CPU that we want to support, the slowest would be Raspberry PI 4. Raspberry PI 5 that we kind of use to do. We want to make the Ethereum decent on this hardware.
00:41:07.045 - 00:41:14.985, Speaker F: So I think Mark and Jared were saying that even if you have four or eight cores, they could just be busy doing other stuff.
00:41:17.775 - 00:41:18.635, Speaker B: Yay.
00:41:22.135 - 00:41:46.605, Speaker D: This happens when you, for example, you sync and you have some cores that do gossip, but at one point they get stuck waiting. Like maybe the processing is waiting for the network or the network wait for the processing to be done as well. But I guess for me, I prefer to bench on one or two cores to be conservative.
00:41:50.305 - 00:42:05.605, Speaker A: Another data point here is the sort of like standard machine that we do all of the DevOps testing on is four cores. So I believe I left a comment to that point on the PM repo. And yeah, that was kind of where that was coming from.
00:42:06.385 - 00:42:16.731, Speaker D: But if you bench with Go, you can add CPU one and you. It will run on a single core, right?
00:42:16.803 - 00:42:34.095, Speaker A: Yeah, no, I mean we can bench with any number of cores. The question is like, how many do we want to target? Um, and like. Yeah, I guess there's a question of like. Well, yeah, okay, if your other cores are busy, that's a complicating factor. But that's really hard to predict.
00:42:36.315 - 00:42:36.859, Speaker D: Yeah.
00:42:36.947 - 00:42:56.805, Speaker G: Kevin, in response to what you're saying about if there was a version that was slower with multiple cores, I think we would still just have to think, to think about the worst case. So whatever's worse out of one core or like multiple core scenarios, just like the worst of all cases, you have to price based on that.
00:42:59.545 - 00:43:05.005, Speaker A: And Mark, you're saying that there was an issue with the subgroup checks. Like, that was real events to the benchmarking that you've done.
00:43:06.815 - 00:43:29.155, Speaker G: Yeah, so benchmarking on one core with the subgroup checks is. MSM is too slow. Sorry. G1 MSM specifically is too slow. So if we were to disable it, then that would bump it up to sort of an acceptable level. Or alternatively we could just increase the price and keep the subgroup checks.
00:43:30.585 - 00:44:09.775, Speaker D: Yeah, so in my benchmark, the G1 MSM with two inputs, I was doing 120 megacasts per second. And with 128 it fell down to 40. So yeah, it wasn't scaling as expected. While pairing for BN254 was always 200 MHz powers per second. So the Formula was really good for this one.
00:44:17.715 - 00:44:29.215, Speaker C: Yeah, but for pairing. For pairing input, you don't do. Sorry, you do the subgroup check only for the second point.
00:44:29.795 - 00:44:32.739, Speaker D: You have to do subgroup check for every points with pairings.
00:44:32.867 - 00:44:43.965, Speaker C: Yeah, but for G1, in pairing the group is equal basically the points on the curve. So for G1, but of course for.
00:44:44.073 - 00:45:11.865, Speaker D: G2 you have to do the. Even the BLS 12 3, 81 pairing precompiler has good pricing. It's very. It's constant even up to eight. From one to eight points. It's just that it's a bit highly priced because I do 220 megagas on a laptop CPU.
00:45:23.975 - 00:45:48.475, Speaker A: Okay. I guess where I'd want to start from is if we have, you know, the pre compiles, mandatory subgroup checks and even on a single core, it sounds like if we do this then it sounds like the EIP is out of date in the sense that some things will need to become more expensive guest cost wise. Does anyone know what those numbers would look like?
00:45:52.295 - 00:46:04.595, Speaker D: I give some in the price suggestion question. I can relink directly to the. Oops to that part.
00:46:05.495 - 00:46:38.325, Speaker A: Okay. Because then from there I would then try to get, you know, one of these ZK rollups to just give us like sort of a test vector of what they would expect to, like how they would expect to use this. And we can give final numbers on the actual gas cost. And then, you know, it could be the case that this is fine and we're good. If it's too expensive, then we can think about ways to make it cheaper. And that seems like the way forward to me because. Yeah, it just sounds like there's too many unknowns to really make a call right now.
00:46:38.325 - 00:46:41.245, Speaker A: Does anyone disagree with that approach?
00:46:46.935 - 00:47:08.085, Speaker G: Yeah, I think maybe my preference would be to increase the price of G1 MSM and then maybe just add these. These a flag even like if it's just a dummy flag to MSM and pairing to have the option maybe to disable it in the future even if we don't implement it now.
00:47:12.345 - 00:47:28.645, Speaker A: Yeah, that's reasonable. I win. Once the pre compiles. I mean, yeah, the main thing there is just like the more we have, the more complex they are, the harder they are to test. And then it starts touching on hard fork timelines.
00:47:29.985 - 00:48:05.605, Speaker D: It's also a pain to implement in ZKVM if you do flags because one thing I forgot is that when you do a ZK VM or evm, you have to prove all the possible paths. So if you implement the flag, you'll have to do both with and without subgroup check for in the zkevm, a circuit that does both, which is complex.
00:48:07.905 - 00:48:23.285, Speaker G: Okay. So I guess equivalently if we just kept things as they were, then we could always just add an identical operation or identical operations without subgroup checks and that would have the same effect.
00:48:23.825 - 00:48:38.405, Speaker D: That's true, but it means we have more precompiles. I'm not sure how comfortable people are with adding what, four more precompiles?
00:48:41.985 - 00:48:55.725, Speaker G: Well, I mean if we're worried about the number of precompiles, then we could always get rid of the scalar model and then we could just add the two more and then that would be the same amount of pre compiles overall.
00:49:01.175 - 00:49:53.785, Speaker A: So I think it just becomes like a timing question. Like if we get to a point where we're ready to ship Pectra and this EIP is holding things up, it will be pulled out. So I'd rather like not really touch the high levels of this EIP at the moment, at least personally. And then I guess like I, in that case I would kind of want to think about this other option of relaxing constraints in the future so that yeah, maybe if it becomes an issue then we can say okay, for the precompiles we have that are already deployed, you can take the subgroups out and we also have the option to have, you know, yes, possibly other precompiles for subgroup checks. And I think that would also work in terms of the Ford can the forward compatible notion we were talking about earlier.
00:49:58.965 - 00:50:16.705, Speaker G: Yeah, I mean, I guess the only thing is you'd have to be careful about removing them when contracts have been built. Kind of assuming that they're there. Which is kind of why I prefer the idea of having identical ones that are different. They're just sort of a drop in replacement.
00:50:17.225 - 00:50:27.657, Speaker A: Yeah, right. So then maybe we should ship without subgroup checks so people don't get used to them.
00:50:27.721 - 00:50:33.041, Speaker D: But. But then people will. Some might make mistakes and.
00:50:33.153 - 00:50:33.617, Speaker A: Right.
00:50:33.721 - 00:50:34.645, Speaker D: Blame us.
00:50:35.585 - 00:50:38.245, Speaker A: Yeah, yeah, yeah. No, okay.
00:50:41.105 - 00:50:56.135, Speaker F: Could. Can't people use like, what are they called like Open Zeppelin libraries like Acrecover I guess also has some foot guns that and isn't a recommendation to just use Open Zeppelin.
00:50:59.435 - 00:51:29.125, Speaker D: But it's extra mental load to oh, be aware that you need to use checked arithmetics for you in 256, be aware that you need to check etc etc and at one point where people are trying to get their audit ready, they forget thing if they do the audit or sometimes they just ship to production and it's the intern that pushes the button or whatnot.
00:51:31.465 - 00:51:50.839, Speaker F: Yeah, I guess that there. It's just that when I think of anyone using these pre compiles I think of someone who knows what they. I guess I don't know who the use case but the users are. I just.
00:51:50.887 - 00:52:10.995, Speaker D: Yeah, but if you look at for example, let's pick Monero, Monero Dev are they know Cryptography etc and back in 2017 they had a bug that could have broken their blockchain because they missed subgroup checks.
00:52:21.765 - 00:53:13.055, Speaker A: So we're almost at time also by the way, that's very scary for Monero. We're almost at time. So I will do my best to find people who give us somewhat of a target in terms of things we should actually build towards like use cases. I would then try to take the most conservative approach that I laid out, essentially saying yes, there are subgroup checks that the precompiles do, we're on core and then kind of go from there just to see, you know, if it's actually too expensive for the users we have in mind. And I think that will give us more information to know which direction to go in. Yeah. Does that sound okay to everyone? Okay, cool.
00:53:13.055 - 00:53:17.255, Speaker A: Any other closing comments?
00:53:21.115 - 00:53:23.975, Speaker C: When, when next breakout then.
00:53:25.875 - 00:53:44.125, Speaker A: Yeah, well, so what, what can we do? It sounds like we can think about updating the eip, right? Because it sounds like the EIP is a little out of date with this sort of set of constraints that we agreed on, that's something we can do.
00:53:44.705 - 00:54:07.371, Speaker D: And I think also trying to find some formulas for msm well for the costs of everything would be helpful as well so that we can discuss specific formulas for the repricing the gas price.
00:54:07.523 - 00:54:09.535, Speaker A: Do we need different formulas?
00:54:12.155 - 00:54:38.825, Speaker D: Well, for MSM the scaling is wrong for pairing, the cost is too high and I think it's fine to focus on BLS 12 curve because even if they end up priced lower than BN254, this will encourage people to switch, which is a bonus for security.
00:54:41.205 - 00:54:52.395, Speaker A: Right? I mean, yeah, I'm not really thinking about the other curve but yeah, if it was somehow more attractive, say economically that would be great.
00:54:56.935 - 00:55:04.195, Speaker E: So do we want to target EC recover then as when we're coming up with these gas cost formulas.
00:55:08.095 - 00:55:29.675, Speaker D: For me I worked with like a target million gas per second and try to price to get those assuming like a laptop CPU from. Trying to get good performance on a CPU from five years ago, let's say.
00:55:34.815 - 00:56:01.195, Speaker B: So I mean we. There's also other pre compiles than EC recover that we could potentially base this against to get a wider range of comparison. And I think you were mentioning for be that there were issues with the granularity of EC recover in terms of the overhead of FFI.
00:56:01.535 - 00:56:37.605, Speaker E: Yeah, actually we bumped our version of SEC P256K1 recently and that gave us a little bit, a little bit of a performance boost there. And really, I think some of the, some of the benchmarking test suites that have been, you know, pointing fingers at besu's EC Recover performance are perhaps not, not as accurate as they could be. And we're seeing pretty consistent EC Recover performance. So that's why we went ahead and, and based our initial cut at the MSM gas costs off VC recover.
00:56:39.865 - 00:56:40.645, Speaker D: Cool.
00:56:44.825 - 00:56:53.805, Speaker B: I think Geth is fine using EC recovery as a base, but yeah.
00:56:56.745 - 00:57:13.275, Speaker A: We are at time and at least I have to hop. But yeah, hopefully this was helpful and yeah, we'll at least get to this on the next ACD if nothing else. And then from there we can coordinate on if we need another breakout or not.
00:57:15.815 - 00:57:20.795, Speaker F: Okay, cool. Yeah, see you. Good.
00:57:22.615 - 00:57:25.175, Speaker D: Okay, bye. Thanks.

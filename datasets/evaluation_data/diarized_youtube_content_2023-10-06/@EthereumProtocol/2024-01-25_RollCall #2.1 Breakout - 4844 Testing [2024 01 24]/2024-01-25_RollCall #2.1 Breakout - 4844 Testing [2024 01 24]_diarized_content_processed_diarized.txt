00:00:00.650 - 00:01:24.774, Speaker A: Okay, yeah. Welcome everyone. This is the four eight four readiness check roll call breakout. So the idea is to just basically, hopefully bring most of the l two teams together that are already kind of actively working on starting to move over to blobs once they'll be live on mainet, and in that process also have already either at least looked into testing that, or maybe are already actively doing so on any of maybe the old devnets or now on Gurley, or maybe are getting ready for the upcoming sympolia fork. So basically we have a relatively light structure for the call to leave just room for conversation for specific kind of questions or issues that teams might have. We have some people from EF DevOps on the call, which is really nice because they've been very, of course, actively involved in testing, both in the Devnet stage and now also with the testnets. And so to start with, it would be really nice if one of you all could maybe just give an update of basically how the girly fork went, how the situation there looks now.
00:01:24.774 - 00:01:30.460, Speaker A: What specifically kind of the blob testing on Gurley looks like that would be a good start.
00:01:31.150 - 00:02:08.114, Speaker B: Yeah, I can start with just what we have running right now and then go into Gurley. So since December we've had Devnet twelve running. There is already blob expiry. Like, we've passed the Blob expiry window. So if anyone's building tooling where it would make sense to test blob expiry, please use Devnet twelve. In case you're having any issues getting funds for the network, just ping either barnabas, me or PK or anyone and we'll make sure you get the funds you need to test. We do have a public RPC there, so feel free to use that one.
00:02:08.114 - 00:02:58.680, Speaker B: And we do have some quick start guides if you want to just spin up a node, especially since it's just like a month old testnet. If you're starting off with testing, it's a great place to just sync up a node and start using it. That being said, we had the girly fork last week and the fork is now stable. We're seeing a healthy number of blobs, but the blobs are being artificially induced right now. We did have a non finality period for the first few hours where we found a bug in the prism client, but that has been patched and the network is perfectly fine now. We still haven't passed the blob expiry window, so we're still within the 18 day period we have gumi blob, which is a blob spamming tool. Maybe PK can just quickly link that or see what it is.
00:02:58.680 - 00:03:27.760, Speaker B: And using this tool, we're inducing between three and six blobs. Ideally, we'd like to stop doing this and hand over to more organic blob traffic because the main purpose is to understand how the peer to peer network behaves with organic blobs. So it would really help if L2 start deploying blobs themselves. And same as the previous network. If you need funds to test or if you need help getting your node up, or if you notice anything funky, please feel free to reach out and we'll help you out.
00:03:35.030 - 00:04:18.578, Speaker A: Great. Thanks, Pari. I was going to next go into maybe like a round where all the roll ups that are on the call, all the teams that are on the call can maybe briefly just give a very quick kind of summary of to what extent they've already started actively looking into kind of testing or basically how close they are to that. Of course, there's a lot of names here and not all of them I can map to L2. So maybe if you just raise your hands and then I can kind of call on you. Yeah, Roberto, I see you first. So you want to go first?
00:04:18.744 - 00:04:52.330, Speaker C: Yeah, sure. So we are activating what we're calling the ecotone fork on op stack on our devnets at noon today. At which point we will be enabling blobs on the batcher. So if all goes well, in about 6 hours or so we'll have some initial results of starting to take advantage of, obviously on gorely. So that's kind of where we're at right now. And this is for both base as well as op's devnet.
00:04:56.110 - 00:05:00.780, Speaker A: Okay, great. Peter, next.
00:05:02.510 - 00:05:34.810, Speaker D: Yeah, hey, this is Peter from Scroll. We also have a few more people from scroll on the call. So we have a development plan and publish an article. Our initial thoughts as to how the circuit implementation for 44 four look like. And we're actively working on the contract and circuit implementation, but we're not ready for testing yet. Also, we are in the process of deprecating our early testnet. So I think for us, realistically, our testing will start on sepolia and then on Mainet.
00:05:39.190 - 00:06:02.700, Speaker A: That makes sense. And yeah, it seems reasonable that on the ZK side, of course, there's more work needed for integrating with blobs. Yeah. Next, I'll call on all of you. And by the way, if there's any specific of course issues you've already ran into something or specific topic you'd want to later on in the open section want to discuss, feel free to also already mention it. Zach, you want to go next?
00:06:03.470 - 00:07:04.270, Speaker E: Sure. Hi Zach from Zksync. So we've finished development and audits for our contracts and circuit side of changes. We're currently working on the changes to the sequencer that need to be done, so we're planning on getting everything ready for Devnet, I would say for the Sepolia fork. Hopefully we can try to get it for the end of early, but that's the current working target. One thing I was kind of curious about chatting on after is just the overall the number of blobs that are going to be supported. I know that blob traffic has been kind of artificial and spammed, but as we were trying to do some manual testing, we did see the fee market jump up to about 3600 quay, which was a little bit high.
00:07:04.270 - 00:07:17.300, Speaker E: So just curious, once all these l two s start to implement it, if the target of three with the max of six is going to be enough to handle everyone's data.
00:07:22.870 - 00:07:30.840, Speaker A: Thanks, and yeah, that's a good topic. I made a note. We'll touch on that. Lee, you want to go next?
00:07:31.770 - 00:09:05.810, Speaker F: Hello, yeah, I'm from off chain Labs integrating 4844 to arbitrum nitro. Our current status is that we've deployed a Devnet two grilley with Blob support and have posted some blobs, but we don't have yet any sort of automated spamming or much activity going on there yet. We've also tested out the fraud proof integration with KCG proofs. The two sort of issues that we've run into so far, I'd say, are that go Ethereum's dev flag doesn't seem to support Cancun, or at least in it on the last version I checked, and this is a slight impediment to testing, because we use that to do a lot of our testing of the one step proofs. We could spin up a local devnet and CI, but using get dev flag generally makes this easier. The other thing we ran into is that the latest Go Ethereum release doesn't support the blob version hash field for eth estimate gas, so there's not a good way to estimate the amount of gas a transaction with blobs will take. I'm not sure if other execution clients support this, and I know that Ethereum has merged in support for these RPCs to master, but I just thought I'd flag those two things we encountered in testing.
00:09:11.120 - 00:09:24.370, Speaker A: Thanks. Yes, that's very helpful. I do know we have at least one guest, Dev on the call as well, so we can circle back to this. Jody, you want to go next?
00:09:24.760 - 00:10:01.310, Speaker G: Yes, we are actively working currently in the circuit for verifying the blobs and we expect to start actively testing in testnet in three weeks, a month more or less. We probably do some spot testing because all this part of sending the transactions, we probably start before maybe next week or in two weeks, but the full testnet working, we expect about a month more or less.
00:10:06.770 - 00:10:07.854, Speaker A: Okay, sounds good.
00:10:07.892 - 00:10:12.430, Speaker B: And would you guys be targeting Gurley or would you be targeting one of the other networks?
00:10:12.850 - 00:10:14.750, Speaker G: We're targeting Sepolia.
00:10:18.930 - 00:10:19.886, Speaker E: Actually we have two.
00:10:19.908 - 00:10:41.350, Speaker G: Testnets running in Guerley and Sepolia, so we could activate in both, but the idea is to go early to obsolete that and keep the testnet in sepolia. And for internal mean we probably deploy something internal. But in general we work in Sepolia. That's our main testing network.
00:10:42.810 - 00:10:44.700, Speaker B: Yeah, thanks. Sounds good.
00:10:48.440 - 00:11:08.250, Speaker A: Okay, is there any further teams? Those were already quite a few. So anyone, maybe? Even if you're not the main person responsible for something, go ahead.
00:11:09.100 - 00:11:43.860, Speaker D: Sorry, my local setup of Zoom is buggy. I could not raise my hand. So I'm from linear. And so the update is that we are currently finishing the deployment of our circuit and we are targeting yearly with an intermediate release that does not directly use 4844. And the only missing step is the CASAG evaluation, which we will start integrating and we will be targeting first both sepolia and Jolie.
00:11:50.730 - 00:12:25.938, Speaker A: Okay, awesome, thanks. Yeah, as expected, I would say it's basically self selection. The people that the teams showing up here are the teams that are already relatively far in the process and sounds like most are actually kind of targeting to start testing actively on the testnets before we reach mainnet. That's good to hear. Yeah, Harry, I just wanted to like.
00:12:26.024 - 00:13:37.340, Speaker H: Zach posted in the chat, but I just wanted to reiterate because I think it's a useful point, the lack of blob hash opcode in solidity or any decent way of calling the blob hash opcode is definitely like a pretty annoying pain point where at least for our use case, basically we were forced off into deploying a separate Yule contract that then gets called, which introduced a variety of annoying sort of extra complexity, basically kind of all due to the fact that the combination of essentially solidity not supporting the verbatim block to allow you to call it unsupported opcode in your main solidity code, along with the fact that solidity not adding Cancun support in a version supported. This has come up on the last few hard forks where last couple at least I remember where there's new behavior that teams are sort of hoping to adopt. And it's pretty painful because the language tooling support isn't there yet. It's definitely an interesting issue in terms of kind of the timing of how things come together.
00:13:42.650 - 00:14:29.254, Speaker A: Yeah, I do remember this coming up in other contexts as well. That's quite interesting. I don't think we have anyone from solidity on. I didn't think of inviting anyone, but that's a really good kind of topic to follow up on. Yeah, so before maybe we go to the open section, there was already a few points raised that we can talk about, and then whatever else people want to talk about. Maybe just very briefly parry or anyone on the testing side, if you want to just very briefly summarize kind of from here, basically the remaining steps before we'll reach Mainnet. Just we have that as background in your mind.
00:14:29.254 - 00:14:32.950, Speaker A: I mean, I guess everyone kind of knows, but still. Yeah.
00:14:33.020 - 00:15:14.526, Speaker B: So the next step is forking sepolia, and then we have Holski as the last testnet. After that, the dates have been set and the last releases are being made either today or tomorrow. You should expect EF blog post by the end of the week as well. So Sepolia will be forking on the 30th and Holskey will be on the 7th. The idea is that we want to still wait to see Blob expiry, at least on one network. And the earliest we can do that is with Curly. That should be in the first or second week of February, which means we should have all the data that we need to decide on a main net date, some point in February.
00:15:14.526 - 00:15:37.370, Speaker B: And the fork itself would probably be some point a couple of weeks after that once releases are made. I think that's the critical path right now. So we want to see block expiry, we want to collect data from networks, and we want to make sure that at least some l two s have tested their framework so that we know that we're shipping something that's useful.
00:15:41.570 - 00:16:06.900, Speaker A: Sounds good with that. Yeah, we can go to the open section maybe to start with. Matt, I see you're on the call. There were some kind of questions about the get kind of readiness with the deflag and everything. Do you happen to know kind of the status of that and when that will be kind of ready?
00:16:07.610 - 00:16:10.600, Speaker I: Yeah, I need to look on the dev flag I'm not sure.
00:16:13.850 - 00:16:14.326, Speaker A: If we.
00:16:14.348 - 00:16:32.240, Speaker I: Allow people to configure developer mode for different forks than what's live on Mainnet. I was just trying to check that right now, but as for the RPC, I think those were merged to master and we had a release about 3 hours ago, so the estimate gasto should be available.
00:16:34.690 - 00:16:56.420, Speaker B: I think one hacky way of going through Dev mode without the fork being configured at Genesis is to start dev mode in the previous network and a previous fork and use override Cancun and just set the timestamp to now. So dev mode will start in the previous fork and just do the fork immediately. And I don't see any reason why that wouldn't work.
00:16:56.790 - 00:17:18.890, Speaker F: So I tried setting override cancun equals zero. The issue is that block production failed because the beacon, sort of the simulated beacon node in the dev mode, doesn't support Cancun, or at least doesn't seem to. I think it was responses with zero.
00:17:18.960 - 00:17:24.400, Speaker B: You trigger out of order of work execution. You should try time now.
00:17:24.930 - 00:17:27.022, Speaker F: Okay, I'll try that out.
00:17:27.156 - 00:17:35.150, Speaker B: Yeah, we've been trying that with workers, so I think there's no fundamental reason it shouldn't work, but maybe some config is missing for Cancun.
00:17:35.490 - 00:17:40.500, Speaker F: Yeah, I'm just worried that the simulated beacon node is missing Cancun fields, but thanks.
00:17:45.390 - 00:18:18.920, Speaker I: Yeah, I mean, the simulated beacon is definitely missing the field, so I don't think even if you do trick it to get into the right fork, you're not going to be able to utilize any blobs. So I don't know what the timeline for getting that updated is. Generally, we've sort of kept developer mode up to date with whatever the latest fork is on main net, and so that's something that we should talk about as a team to see if we can support these fringe cases where people are trying to test for that next fork that's coming up.
00:18:25.010 - 00:19:50.342, Speaker A: Yeah, it seems almost that's because we have had that topic now in two different contexts that separate from void for specifically kind of basically tooling readiness for testing upcoming forks and features. That seems to be something in general we could look into and further improve. I've definitely heard that also in the solidity context in the past, as we heard with the blob hash opcode now and figuring out a good strategy there. And ideally of course something that once we start talking more about ips and possibly having features over there that are not on mainet, but that of course also teams want to use and test and everything and having kind of good ways of doing all of that seems like a good topic to look into in the. Then just to briefly kind of finish what the points that were already raised. I think, Zach, you mentioned kind of a question or possible concern around for throughput. Of course, maybe if you can clarify, you said when you were testing a little bit, you saw kind of relatively high fees.
00:19:50.342 - 00:20:34.738, Speaker A: Is that specifically, was that on Gurley? Of course. The point being that, yes, we have limited throughput with for it before. It's not in itself necessarily a scaling solution. It's mostly just kind of this fee market innovation so you don't have to compete with NFT drops for fees. So of course at some point this will hit its capacity limit. But I think specifically, if you're testing on one of the testnets where there is active blob spamming by the DevOps teams going on, then that basically means it already saturates the available throughput. So any additional marginal throughput that you would cause would of course then lead to a fee raise.
00:20:34.738 - 00:20:40.250, Speaker A: So can you maybe briefly kind of clarify under which conditions you saw very high fees?
00:20:41.310 - 00:21:53.940, Speaker E: Yeah, sure. So it was happening on Gurley, and after looking into it, I think it was in combination with blob spamming that was happening. But it basically raised the question for myself of is this going to happen on main net once all l two s are basically adopting 4844? I don't know how many blobs other l two s are planning on using, but we're in the boat of targeting, I would say two blobs per batch for us, which is already two out of the maximum of six per block. So if we have multiple l two s who are all kind of, I would say, committing batches with anywhere from like one to two blobs, then this is behavior that we could potentially see on main net. And yeah, just having overall the fees go up, I just brought up some concern whether or not a target of three blobs was going to be enough to handle all of the data for all the l two s.
00:21:57.990 - 00:22:19.160, Speaker F: Maybe I can jump in for the fee. We are currently spamming girly with blobs up to a blob fee of 200 to 300 gray. So that's pretty high to just get blobs in, but we can obviously lower it to make more usable for you guys.
00:22:20.830 - 00:22:29.260, Speaker B: Yeah, I think we should also just set a target to maybe fill one so that we don't have blocks without anything and then let the organic load take over.
00:22:33.940 - 00:23:04.700, Speaker A: Yeah, of course, the problem is if you do that, and while there is no organic load yet, then we'll basically go down all the way to the minimum fee. So I think actually setting some sort of relatively low floor for gray, but then actually making sure that at that floor, you'd always fill three on average, and then just starting to throttle down. Once we're above that, that would, I think, be ideal behavior. I'm not sure. Maybe that's a bit too complicated. But basically, floor flow for three, and then if we're above that, then you only do one or something. That could be a good kind of compromise.
00:23:04.700 - 00:23:08.620, Speaker A: Lee?
00:23:09.460 - 00:23:57.230, Speaker F: Yeah, I just wanted to quickly mention in that context, sort of what we're developing for arbitram behavior, which is likely going to be that a batch, if there's enough activity on a network, especially with arbitram one, a batch would probably include all six blobs. And this is just for efficiency in terms of overhead, smart contract layer. So what that would look like is probably one blob would consist entirely. The blobs would consist entirely of arbitram blobs, and then it would go back to. Obviously, that wouldn't be true of every block, but that's sort of the profile that we would be looking at for likely looking at for arbitram one.
00:23:59.840 - 00:24:08.080, Speaker B: Just a quick question. I haven't gotten deep into the l two world yet, but how often are these batches, or is that varying per implementation?
00:24:08.580 - 00:24:57.436, Speaker F: So it definitely depends on how much activity you have. It's a direct function of that. How many blobs you need is how much activity is going on in the l two. That said, I need to double check my map and math here, but I think we'd be looking at a blob like every six minutes, I want to say, because one blob is about 130 kb, which is about the maximum call data link that you can post to go Ethereum's current mempool per blobs. So that means that one arbitram batch would likely consist of six blobs, which would be about six current batches today. So, yeah, we'd be looking at about one every six minutes, maybe a bit more frequently than that. For a current arbitram one load.
00:24:57.436 - 00:25:11.510, Speaker F: Of course, that's subject to which network it is. Others might not be as congested as that. And also, arbitram one is still not at congestion yet, so there's definitely room for it to increase the data posting rate.
00:25:18.090 - 00:26:03.766, Speaker A: Right. And of course, it's clear that even with four, there will still be limited throughput. So if multiple l two s of course start reaching their own capacity limits and they all start posting very frequent batches on mainet. So I personally am less worried about say per block kind of saturation because it's fine if there's the occasional block that is fully filled by arbitrum, and then there's the occasional block that's kind of filled by just a different one there too. And then there's blocks that are split, split up between multiple ones. With the base fee kind of mechanism, it's totally fine. It could even be that it's always 60 60 alternating or something that's perfectly fine.
00:26:03.766 - 00:27:02.770, Speaker A: So there's no kind of worry, I think, on the zoomed in per block kind of composition level. But of course once we reach overall, there are two usage levels where the data needs become higher than the throughput we can provide with a target of three. That means that we'll start to just see kind of raised prices until basically the demand levels off, which at that point, of course we are very actively working on increasing the throughput. Just maybe, I don't know for context image of how actively people have been following this. On one end, of course, hopefully there's a little bit of headroom we would have, once we see everything stable on main net, to go a little beyond three, six, say in the next fork or something. But that would probably be a relatively small increase and also like of course a one time increase. So it's not really useful to allow you all to scale much further.
00:27:02.770 - 00:28:01.658, Speaker A: But there is this very active kind of research testing direction called peer Das where the idea is that we will go to actual sampling techniques for basically checking for the availability for blobs. And that seems to be relatively far along. Obviously, I don't know, it's always problematic to talk about timelines, but let me put it this way. I think if you all would basically start to voice your, make your voices heard, that there's a lot of urgency to getting this shipped as soon as possible. I think that would really be helpful because a lot of the CL teams that would be the people implementing kind of this sampling technology, they are looking right now at what to do after Dankoon and what to focus on. And I don't think they have a big sense of urgency yet around this. So I think there's a world where this becomes the next big priority and then there's a world where other things are maybe focused on first.
00:28:01.658 - 00:28:39.910, Speaker A: And I personally would really like if there was some sense of urgency created around the sampling technique, because once we move from the current perform mechanism of everyone still downloading all the blobs to sampling, then we can really kind of scale. I don't know. I don't want to make any promises. And so maybe in the initial rollout that would not be the case. But relatively soon we could see something like a ten x to even more than that throughput increase just like a little to do. If you all can try and just go to the Cl team of your convenience and just talk with them about PDS, that would be very helpful. Peter.
00:28:41.870 - 00:29:14.500, Speaker D: Just a question somewhat related to this topic that I'm curious about. So I think short term we probably won't exhaust all the throughput that 44 can offer. But I think the conservative approach that we would probably take is to also retain the ability to use call data, so be able to commit to either blobs or call data. I'm just curious how their teams think about it. You just directly only use blobs or do you still kind of keep the call data logic of your roll up?
00:29:17.130 - 00:30:14.390, Speaker E: Yeah, I can jump in from what we're thinking on the Zk sync side. So our contracts handle the ability to do both blobs and call data. The difficult part there is just because if we're filling a blob fully, that basically is the same amount as the maximum pub data that we could fit within call data. So once we start utilizing two blobs, the system falls apart a little. But because of that, when we first start testing, we'll probably opt for doing a single blob so we can actively switch between the two. But definitely something that we're looking into and want to have a better plan for when it gets closer to mainet or soon thereafter.
00:30:20.940 - 00:30:21.768, Speaker A: Great lead.
00:30:21.854 - 00:31:10.276, Speaker F: Yeah, there's a similar thing going on for arbitram right now. The way it works is the batch poster will look at the blob, fee and base fee at time of posting and figure out which it should post with. But there's the problem of you can't replace by fee blobs to a non blob transaction. And even if you could, as Zach mentioned, the call data limit for the get non blob min pool is much lower than the amount of data you can fit in blobs. Multiple blobs, that is, even one blob. It's slightly lower, but that's not a huge issue. But basically there's sort of this awkward situation where you can get stuck in blobs.
00:31:10.276 - 00:31:42.710, Speaker F: And if something happens where the blob fee escalates, well above the base fee comparatively per byte. It's a bit unclear. There's definitely some ideas we have of how to recover from such a scenario, but it may just be that you have to pay for a couple of blob transactions to get out of it in the common case, and I don't have a great answer there to what should be done.
00:31:46.950 - 00:31:48.290, Speaker A: Thanks Roberto.
00:31:48.710 - 00:32:17.500, Speaker C: Yeah, similar situation with op stack. We've made it so you can post either call data or blobs and the change revolution rules will allow either. However, the batcher config supports either one or the other. You either are always posting as call data or you're always posting as blobs. But that can be changed in the future once we figure out some of the issues that were just mentioned around replacement rules and things like that.
00:32:20.110 - 00:33:34.740, Speaker A: Sounds good. And maybe just briefly mention how we have been thinking about it from the research side. Of course this is a concern. It could be that if all the L2s start to only be able to consume blobs, then in principle the price could go higher on a comparable per byte level. The nice thing is that as long as there's a few teams with reasonable throughput that are still able to use both, then they basically will make sure that that never happens, right? So there's a bit of a free rider situation where it's fine if 80% of the L2s can only consume blobs because then on the margin that would always mean that the few that can would basically make sure that they would always consume call data if it becomes cheaper ever than blob data and so would keep the equivalence there. But of course that should not mean that you as a team should not do that because not the entire network profits benefits from at least a few teams being able to have that kind of compatibility with either format. And of course while minimal bulbs are not super tested yet in production, at least for a while, it's probably good to be able to fall back to normal call data anyway.
00:33:34.740 - 00:35:07.770, Speaker A: Okay, anything further on the kind of pricing side that people would want to talk about? Okay then. One more topic that at least people touched upon a little bit was expiry. I'd be curious. So I think kind of in terms of our testnet timings, Pari already mentioned that the idea was to wait with Mainnet, kind of setting a main net target before we at least saw expiry blob expiry on the first testnet, meaning Gurley of course then by the time mainnet would fork, we would have already also seen it on, say, Sepolia and whatnot. To what extent are teams here kind of also specifically looking at testing around expiry? I'm not super familiar with within individual architecture of all the teams. It could be that for most of you all, that's not relevant at all, because by that time you've long copied the data over into your own networks and no longer rely on it anyway. Or something specifically like how do teams think about expiry? That would be good to know if anyone thinks about expiry at all.
00:35:07.770 - 00:35:12.990, Speaker A: Harry?
00:35:14.770 - 00:36:00.190, Speaker H: Yeah, one thing to say is certainly kind of one nice property is that at least for roll ups, basically we can support a mode of syncing where basically you only need. Where basically you use the latest confirmed snapshot, that kind of either when this presumably is true for either Zk or optimistic roll ups, given that the blob expiry time is long enough, that basically there will always be the blobs guaranteed to be available on the network between sort of the latest finalized checkpoint and the latest state, which is nice. I think that assumes data availability of kind of whatever the latest confirmed.
00:36:02.930 - 00:36:03.342, Speaker A: Whatever.
00:36:03.396 - 00:36:44.970, Speaker H: The latest confirmed state is, which is certainly like a shift in security model from the current day, since right now, of course, if you can just sync from Genesis by just following Ethereum and relying on kind of. I mean, obviously Ethereum doesn't have formal security guarantees around ancient data availability, but in practice, certainly that's kind of quite an easy assumption to make. There's certainly kind of some interesting gray area now on kind of how ancient blob data availability will work, whether or not there's going to be kind of reliable service providers, whether or not roll up teams are going to want to be expected to archive their own blobs, or kind of generally how that will work in practice.
00:36:54.100 - 00:36:55.120, Speaker A: Beta.
00:36:56.520 - 00:37:33.250, Speaker C: Yeah, so we have a sort of a multipronged approach. One is simply state sync, the other is providing a blob archiver service that you can use to persist your own blobs or all blobs. And in fact, we're actually looking into sort of providing a coinbase instance of this that archives all blobs that people could use. Obviously there's a trust assumption there, but it is one option if you do need to sync from scratch and state sync for whatever reason isn't an option.
00:37:38.900 - 00:37:39.632, Speaker A: Sounds good.
00:37:39.686 - 00:37:40.400, Speaker B: Lee.
00:37:41.060 - 00:38:51.770, Speaker F: Yeah, so I think this sort of touches on a point I've been thinking about more broadly, which is I'm not sure how available consensus layer rpcs will be in general, blobs are somewhat unique in that you need to query them from the consensus layer itself, not the execution layer. And popular RPC providers, to my knowledge, usually don't provide consensus layer rpcs, they only provide execution layer rpcs. So I think it's sort of an open question for us at Optim labs how this is going to work in practice if users aren't running their own nodes, if we're going to see more support from third party RPC providers for this kind of thing, or if there will be some alternative service that offers the same RPC, there isn't a huge trust assumption there. Luckily there's trust assumption in terms of availability, but there's not a trust assumption in terms of correctness because you can verify the blob proofs that it matches with the commitment. But that's sort of a yeah, I don't have a great answer there yet.
00:38:56.460 - 00:39:19.440, Speaker B: One point I do want to make for anyone looking into blob archiving in general, blobs don't have the same issue with high iops requirements that state does, which means if your CR client of choice does support it, please dump the blobs on a hard drive and that should reduce your cost by a massive order of magnitude.
00:39:30.600 - 00:40:28.872, Speaker A: Yeah, that's a good point. And also I have heard the question around kind of RPC access on the sealed side before. Clearly data availability is a new kind of concept that we're only now introducing. I would expect that in the long term, as this also becomes more and more important and we start introducing further things like DS and everything, that there will be more broad kind of support and providers, either same RPC providers as today, that also more and more provide access to clrpcs or new ones specialized on this popping up, but that might not immediately happen. So I think that is an open question. I don't personally I'm not super involved with that world. I don't know if there's RPC providers to go talk to about this, but that seems like something that needs to be figured out.
00:40:28.872 - 00:40:29.720, Speaker A: Indeed.
00:40:35.840 - 00:41:01.828, Speaker B: Also in case you guys are running your own node and relying on your own infrastructure for the beginning, until RPC providers support the features. Because I think as of now most RPC providers are used to providing you an El RPC, not a beacon node RPC. We've built this beacon node load balancer so you can have a high availability set up if you wanted. And we've been running it locally for.
00:41:01.834 - 00:42:14.892, Speaker A: A while and does quite well. That's nice. And yeah, and just to mention, of course, the whole point of data availability and kind of the expiry period is that in principle the idea is that the network only wants to guarantee basically an availability in the flash of the moment. In a way the expiry period is more convenience feature because then it's easy for at least short look backs to just use a mainet. But in principle, every L2 of course is its own chain. And so for say syncing all the way from Genesis or something, that is something where the ultimate responsibility for kind of history, availability and whatnot, that does lie on the specific l two p two p. So it could easily be that, say, if someone uses blobs for just inscriptions in the beginning and you just put in hello mom in there or something, that that kind of blob over time just gets forgotten and is not persisted anywhere because it's just not relied upon by any party and that would be just fine.
00:42:14.892 - 00:43:25.230, Speaker A: Right. So basically if you as lay two want to keep one blob around forever, then it's kind of your responsibility to have some sort of persistence mechanism to do so, or to just to hope that, say, I don't know, some coinbase run service will forever persist it. Okay, so that's that topic. Let me see if there was any other kind of topics from kind of the first section of the call to touch upon. Took some notes, but I don't see anything right now. So then maybe that's a good point to just open it up. Are there any kind of other topics either problems people have run into or just challenges things to figure out or maybe just questions that came up that are not very concrete yet that people would want to bring up? Yeah, Harry.
00:43:25.230 - 00:43:26.634, Speaker A: Yeah.
00:43:26.772 - 00:44:26.660, Speaker H: Less a question, more just, I guess like a thing to flag. Overall development on kind of preparedness for 4844 has definitely been pretty tricky in that obviously kind of the overall l one ecosystem has been sort of relatively heavily in flux. I mean there was just the big spec change even in the core, which was a great change, but was pretty recently. And obviously overall sort of support has been kind of picking up, which makes sense, but kind of fundamentally sort of, it puts l two s in a position of developing on top of kind of a pretty unstable base as kind of the overall kind of ecosystem is sort of evolving. It's kind of interesting because none of us.
00:44:28.710 - 00:44:29.718, Speaker A: To me, I think that's kind.
00:44:29.724 - 00:45:47.440, Speaker H: Of fundamental to kind of having the main net hard fork and the actual kind of overall and testnet hard forks happen sort of like relatively on top of sort of finalization of kind of the various core implementations of sort of the necessary l one infrastructure and kind of jumping immediately from essentially that stuff being done to rolling it out, which generally works well and is fine. Although I think that for roll ups there's a bit of a weird thing also, which is that sort of like obviously there's a huge incentive I think for everybody here to support 4844 early. In a perfect world from my point of view, there'd be some number of months actually to actually have 4844 live before it started getting heavily used, just because it could actually stabilize and tooling could catch up and all of that. But of course there's a pretty huge incentive for all roll ups to support it early since I don't think anybody wants to be the roll up that's not supporting four eight four and their users are all paying much higher fees. And so it creates a sort of just like weird situation. Yeah.
00:45:54.850 - 00:46:59.234, Speaker A: That'S actually a really good point. And actually proto brought from optimism side kind of brought up kind of similar concerns on last alcohol devs as well. It's a bit tricky. I don't think mainet of course can really kind of wants to actively kind of take these concerns into consideration. I think they're basically delaying rollout to alleviate this competitive pressure to maybe be a bit reckless or basically have to go through a lot of extra hassle of support. I totally understand that point, but I don't think that's something that mainnet would necessarily ever do. So basically, given that that route is probably not realistic for future changes like this, I do wonder whether maybe the next best thing we could do is to just try and have a forum like this.
00:46:59.234 - 00:47:39.634, Speaker A: Right? Like the roll call kind of to be a bit more bi directional with Orchodev. So right now, I mean even this call, that's the very tail end of the development cycle for four. And this is even more of a, hey, now that it's done and set in stone, we are here to maybe just coordinate a little bit on how you all are dealing with this. I could totally see that in the future. Like for example, one question I have is maybe it would be useful to have a call like this in a month or two where we bring in the people working on the data availability sampling specs and kind of check in and see. I mean the nice thing of course with data availability sampling is that actually the interface will be unchanged. So there is not much that actually will probably change.
00:47:39.634 - 00:48:17.840, Speaker A: But still maybe some trust assumptions, some sort of actual kind of practical things might still change. And so instead of just waiting and then telling you all when it's. Or having this call only to clean up in the end, actually have this be a bit more of a proactive thing where now that we have the roll call and L2 is involved, that we can actually inform the processes as it's ongoing and before it finalizes future changes. I think that would actually be really, it seems like a step in the right direction and probably the best we can do here. I don't know if anyone else.
00:48:21.570 - 00:49:06.780, Speaker I: What are some concrete things that you guys are running into that is making you have this feeling? Because if there are specific things that we could be working on or collaborating on to make sure is a little bit more stable, I think it's possible to do that. I know, for example, the RPCs, we've been asking for a couple of months, how do people want to interact with blobs over the RPC, getting the blob base fee, getting the estimate gas, and there's been like no interaction from l two s. And so I don't know if, I'm just curious, what exactly are you guys seeing that's making you feel like things are moving underneath you?
00:49:08.370 - 00:50:05.566, Speaker H: Yeah. And to be clear, by the way, I'm not really advocating for any particular, specific change other than just kind of flagging the general, sort of the general vibe almost. But to be concrete, I think that we had done kind of an early wave of four development quite a while ago, like four months ago maybe, which is kind of would have been ideal from my perspective, if we had been able to sort, know, had a number of, you know, a good number of months in advance of sort of stabilized libraries at, at the time. I think there was a bunch of weird stuff going on with the KZG implementations, if I remember correctly, and kind of a whole lot of sort of instability in terms of. I mean, I think that was before the most recent large spec change. Yeah. So I could come back with when.
00:50:05.588 - 00:50:08.066, Speaker I: Was the large spec change? Or what was the large spec change?
00:50:08.088 - 00:50:15.860, Speaker H: You're referring to the blob sidecar change. When was that?
00:50:16.950 - 00:50:19.666, Speaker B: We had one change in November, I think.
00:50:19.768 - 00:50:20.510, Speaker H: Yeah, November.
00:50:20.590 - 00:50:23.750, Speaker B: That was consensus level change as far as I'm.
00:50:24.250 - 00:50:25.240, Speaker H: Yeah, exactly.
00:50:25.610 - 00:50:27.074, Speaker I: Was that the sidecar?
00:50:27.202 - 00:50:27.880, Speaker F: Yeah.
00:50:32.730 - 00:50:44.570, Speaker H: Um, which I think was a great change. And so I'm happy it was done, but certainly just as an example of kind of the degree to which things have been pretty core things have been in flux relatively recently.
00:50:51.920 - 00:51:22.260, Speaker I: Yeah, I don't know. I guess I just don't really quite follow what to me, the interface between the consensus protocol and using blobs is kind of a fixed thing. I don't really see why the sidecar specifically, I don't really see why underlying changes of the P to P would be affecting roll ups ability to integrate the proposal.
00:51:23.320 - 00:51:27.140, Speaker H: Oh, I'm just talking about in terms of overall stability of the dependencies.
00:51:30.140 - 00:51:56.972, Speaker I: Yeah. Don't know if I quite follow, because it's like we're trying to ship the thing and things are going to be changing underneath, but the only thing we can really provide and make the guarantee on is the interface. And I feel like the interface has been pretty standard and clear for quite a while for people to test on. I mean, I'm not trying to call you out or anything, I'm just like.
00:51:57.026 - 00:51:58.512, Speaker F: Yeah, I want to make it better.
00:51:58.566 - 00:52:26.490, Speaker I: For the next fork. And I agree with Onscar. I don't think that we can make a commitment necessarily to have a very long period once things are stable and ready to go to mainnet to let everybody implement. But what we can do is we can try and communicate better early on and make sure that the interfaces are correct so that even if the underlying thing is changing the interface that you're using to put blobs in, verify blobs, all that stuff stays the same.
00:52:28.460 - 00:53:07.220, Speaker F: Yeah, it's possible we misidentified where the issue was coming from. We submit transactions using Go Ethereum's transaction library. I believe at least that there were significant changes in the API of creating a blob transaction with sidecars and submitting it. But it's possible that we've misidentified that, and that just came from the Go Ethereum version. That said, I think we did have issues with incompatibilities between the Go Ethereum version we were using to try to submit the blobs and the Go Ethereum version that was receiving the blob transaction.
00:53:08.300 - 00:53:12.520, Speaker I: Okay, sorry, you're talking about the sidecars that was added into Go Ethereum.
00:53:14.380 - 00:53:27.070, Speaker F: I'm not sure. I think there's two separate changes here. There's the consensus change in November, and then I think the blob transaction in version 1.130 and Go Ethereum was reformatted a bit.
00:53:27.520 - 00:53:28.412, Speaker A: Yeah, definitely.
00:53:28.546 - 00:53:50.740, Speaker I: There's definitely been changes to those types of things. This is something that we can do better at, but frankly, there's no communication from upstream users of this stuff yet, which is the thing that's causing us to not. This is why we don't have dev mode ready for Cancun, because this is the first time that we're hearing that people are like, we need this for Cancun.
00:53:51.960 - 00:54:20.350, Speaker F: Yeah, definitely. I think it's sort of a catch 22 because we were trying to develop this stuff into November. In November, I don't know exactly when, but as Harry mentioned a few months ago and we were running into a significant number of incompatibilities between various go theorem prism versions and issues where APIs weren't ready. But we can definitely try to communicate better those concerns at the time that we have them.
00:54:22.640 - 00:54:42.150, Speaker H: I think getting a better community, getting more communication and. Sorry, definitely not. Didn't mean to. I think to me a lot of this is just kind of relatively fundamental to sort of trying to kind of develop the underlying tech simultaneously with trying to develop tech running on top of it is just a really hard problem.
00:54:43.000 - 00:55:11.932, Speaker I: Yeah, don't take me the wrong way. I don't want to sound like I'm putting you guys on blast because what you're doing is extremely difficult because we got ten developers building this go Ethereum library and we just change it like every month because we don't know how people are using it, who is using it. And it's a really hard thing for you guys to deal with. But I think the best thing that could be done on your end is to just communicate with us when you are using things or having problems with using things. It's more work for you.
00:55:12.066 - 00:55:13.776, Speaker F: But I think that that would let.
00:55:13.798 - 00:55:29.860, Speaker I: Us do some stuff earlier on. If you guys drop an issue and you're like, hey, we're using this library and there's this incompatibility. And hopefully with that communication we can get to the point that we're getting to today, three months ago in terms of interfaces.
00:55:31.640 - 00:56:01.390, Speaker H: Sounds great. Absolutely. Yeah. I think in general, sort of setting up better communication pathways is probably one really good to take away from all of this, in that I think it'll still be pretty hard to kind of pull off this sort of thing, of developing kind of concurrently on multiple levels. But it's certainly to the degree that it's a shared problem that everybody faces. And definitely we can't completely make everything perfect, but we could certainly, I think, get things a lot better than they are today, at least.
00:56:04.160 - 00:56:31.448, Speaker A: Yeah. And in the future we could of course, also have had a call like this where we specifically say, also have the get people, just the general, the El people say the programming language people and whatnot. And the lettuce already a couple of months before it's ready for mainet and kind of talk about what remaining changes there might be what people are starting to rely upon, all these kind of things. So, yeah, I think there's definitely a lot to improve for future changes.
00:56:31.614 - 00:56:58.396, Speaker H: By the way, I could be off here. I don't know how much is kind of specific to our development process, although I'm assuming kind of based on the fact that it seems as though sort of everybody is in a relatively similar position, that we are of kind of getting closer to being ready, but not sort of being. But not having only kind of getting there now as opposed to getting there sort of weeks ago, that there's a relatively similar pain point being felt, although.
00:56:58.428 - 00:56:59.104, Speaker A: I could be off.
00:56:59.142 - 00:57:05.120, Speaker H: There's.
00:57:06.100 - 00:57:55.510, Speaker B: Yeah, I think one thing we did during the merge that worked out well was merge community calls. We had a couple of them spaced out throughout the year while we were doing the dev process, and we could give an easier update as to what the current status was, point to latest documentation on how to use stuff, et cetera. And very often we just point to whatever we were using for testing. And maybe that would have been a smart idea to do for 4844 as well because, like you mentioned, targeting the right go ethereum library or using the right interface, et cetera. That's stuff we've kind of kept up to date with and we had to because otherwise you wouldn't have any load on or testing on the devnets. And I guess if we had had those calls, we could have just showcased, hey, we're using this script, we're using this library. Use it as a jump off point and tell us what you want us to change.
00:57:55.510 - 00:57:58.470, Speaker B: Should definitely bring that back next time.
00:58:14.180 - 00:58:55.176, Speaker A: Okay. Yeah, that's probably. Those were all good points on the future of that kind of interaction, and definitely something to follow up on for any future kind of changes that might affect their twos, which probably most of them will in the future. Yeah. Other than that, there's one more topic I really wanted to touch upon that was most basically just like girly versus sepolia in terms of what's going to be mostly targets for testing. Let's maybe just briefly do that. So, of course, people have already kind of talked about a little which networks they're targeting.
00:58:55.176 - 00:59:46.076, Speaker A: It sounded like basically for now, it's mostly a function of how ready you are. Like the teams that are already ready are of course using Gurley now because that's the only thing that's already fucked over. Sounded like teams that needed a few more weeks anyway were then going to target Sepolia mostly out of the gates, of course, given that Gurley will be sunset kind of soon after ten kun. It seems like sepolio in the long run, will be the more important network in general. I just wanted to briefly check in with. So I think the two teams that are already actively kind of targeting Gurley were op the op stack kind of chains and earthchain labs. You are also kind of planning to focus more on sepolia once.
00:59:46.076 - 00:59:53.120, Speaker A: Once that's live or how do you think? Basically between those two chains.
00:59:56.180 - 01:00:05.940, Speaker C: Yeah, I think for our testnet, we'll definitely be doing sepolia as well. But right now our devnet is only. At least the superchain Devnet is only active on garlic.
01:00:12.280 - 01:00:15.670, Speaker A: Okay, that makes sense. And on the off chain lab side.
01:00:20.220 - 01:00:55.270, Speaker F: I don't think we have a fixed plan for future devnets and testnets just yet. We definitely prefer sepolia in general due to the availability of ETH, continued support and such. I think the plan would be if we do any future devnets, but by the time Sepolia is upgraded, they would definitely be on sepolia. I think at some point, of course, the arbitram guilly and arbitram sepolia testnets will also be updated. I don't have an exact sense of timeline there yet, though.
01:00:58.230 - 01:01:23.834, Speaker A: Okay, sounds good. Yeah, I just wanted to check, but it sounds like there's no one specifically on this call. That's like no for it before. We're just not all ready to focus on sepolia, and we would really, for us, early is the main network, so that seems healthy. Okay. We're kind of a bit over an hour into the call anyway. We would have like a good 20 more minutes or so if we want to.
01:01:23.834 - 01:01:29.674, Speaker A: Is there any more topics that people have that we should talk about, or is it.
01:01:29.712 - 01:01:33.422, Speaker C: Yeah, what was the estimate gas issue.
01:01:33.476 - 01:01:34.350, Speaker A: That someone had mentioned?
01:01:34.420 - 01:01:37.440, Speaker C: I missed the details on that. I don't think we've hit that.
01:01:40.050 - 01:02:01.080, Speaker F: Unless another one was mentioned. I think just that the blob versioned hash field or blob versioned hashes field of estimate gas was not added to at least go Ethereum. Probably other execution layers as well until very recently. So there was no way to estimate the amount of gas that a blob carrying transaction would take.
01:02:03.290 - 01:02:04.280, Speaker C: Got it.
01:02:07.140 - 01:02:08.556, Speaker A: Which I think has now been resolved.
01:02:08.588 - 01:02:10.210, Speaker H: In the latest version, which is awesome.
01:02:10.820 - 01:02:12.980, Speaker F: Oh, is there a new version released.
01:02:13.320 - 01:02:14.660, Speaker H: A few hours ago.
01:02:14.810 - 01:02:15.750, Speaker B: Oh, nice.
01:02:16.600 - 01:02:17.350, Speaker F: Thanks.
01:02:33.640 - 01:03:01.016, Speaker A: Okay, well, it looks like some people are starting to have to leave anyway. I guess that's a good stopping point then. I hope this was useful for you all it definitely was very informative for me. Kind of phrasing a lot of these kind of issues and whatnot. Yeah. And hopefully we can have things like that in the future as well. I think there will be several different kinds of breakout calls.
01:03:01.016 - 01:03:46.636, Speaker A: I hope some like this we can do in the future as well, with future changes. Maybe even, as I was saying earlier, a little bit more proactively, not just once they're about to hit Mainet and then we will also have other types of breakout. Again, we're just experimenting a little bit with this breakout call. So next week there will be a breakout on just fee markets for L2s that will probably be a bit more just brainstorming, exploring, kind of figuring out how teams think about this. So if anyone on this call is also interested in that, feel free, of course, to join again for that. And then I think on the next roll call in three weeks, we'll basically have a bit of a retrospective of which types of breakouts work and which ones to maybe continue, how frequently to have them and everything. But I don't know.
01:03:46.636 - 01:04:00.316, Speaker A: I'm very personally surprised both how well this one went. And so thanks so much, everyone, for showing up and actually contributing and making this useful use of time. So thanks, everyone.
01:04:00.498 - 01:04:01.630, Speaker G: Thank you very much.
01:04:02.920 - 01:04:04.292, Speaker B: Thanks for having us.
01:04:04.426 - 01:04:04.964, Speaker D: Thanks.
01:04:05.082 - 01:04:05.490, Speaker H: Thank you.

00:00:00.800 - 00:00:12.085, Speaker A: Okay. Yeah. Hello everyone. Welcome to the. Let me just briefly make it so I can see the screen. Okay. Welcome to the Kind of the breakdown call.
00:00:12.085 - 00:01:17.375, Speaker A: The idea is to basically talk a little about kind of our general thoughts on the topic of EVM equivalence in particular. And that's kind of a big part of what we've been thinking about from the roll call side, the motivation behind roll call to begin with and how we basically see the path forward. So yeah, I want to basically split it up into kind of chronologically, kind of first talk a little bit about like how we got to the concentration and then a little bit about our vision forward and specific next steps. A few quick disclaimers just to mention it. So all of this is just our perspective, right. So if I'm ever sloppy and like wording it a little bit too definitive, really this is all just about kind of how we see things and we would love to kind of get feedback. And obviously this on the second half of the call there's going to be like an open discussion section.
00:01:17.375 - 00:02:16.253, Speaker A: But yeah, it's really just kind of like our view on things and our here also very explicitly being just like Carl Jorf and me not representing anyone else, not df, not any other larger group. Carl and I in particular have been kind of had been kind of thinking about this for a long time and then Jorf kind of specifically had very similar thoughts. And so we kind of aligned on the thing, but it's really just us. And then specifically on the scope as well here specifically we're talking about the EVM and execution broadly. Like I'll use the term evm but what I mean with that for the call is really more like anything kind of execution related, but specifically not touched by that. Like there are two specific concerns or interoperability standards, this kind of thing. And then also last disclaimer from my side, my apologies.
00:02:16.253 - 00:02:58.353, Speaker A: This presentation won't have many graphics or anything. It's a little bit text based, but if you keep the attention up it's hopefully going to be interesting. And then just to get it out of the way, we have an announcement and I don't want to basically throw that on you like halfway through the presentation. So I'm going to mention it now already briefly. And there's a new team, a new client team specifically called Rollup Geth, which will maintain fork of get that is more specifically aimed towards the L2 setting. It's a team within Nethermind. I'll talk a little bit more throughout the presentation of like what the specific Vision for them is.
00:02:58.353 - 00:03:28.793, Speaker A: But I wanted to basically already start with the announcement itself to get it out of the way. Yeah. And also by the way, if you. I think actually it's best if we do questions maybe at the end of the presentation. Okay, so quick history. How did you get here? So basically three sections. First the EVM itself and then I want to talk a little about the AL tool side and the client side.
00:03:28.793 - 00:05:03.795, Speaker A: So on the EVM itself before kind of the Beacon chain launch, there were all these ideas for a more comprehensive kind of Eth2 setting, including execution sharding and all these things. And the idea back then was to basically have eth1 basically just retire and specifically also like the EVM tied to that kind of more or less retired and have Eth2 launch with new execution environments and basically overhauled execution. And that all only changed with the kind of the pivot to the rollup centric roadmap roughly I don't know, four or five years ago, where basically people where the idea was basically hey, we already have an execution chain, it's good enough for the settlement requirements that you need from a base chain in a roll up centric world, let's just reuse it. And so that's how kind of the idea of the merge came to be. But implicitly with that also basically came like a basically giving up on these at least on the L1 side on this kind of this work we had the EOSM team and now it's called the Ipson team. That's not then end up focusing on other things, but basically we stopped working on the next generation of kind of execution. And not only that, but also since the merge basically we've really kind of slowed down progress specifically on new EL centric features.
00:05:03.795 - 00:06:01.805, Speaker A: It doesn't mean the execution layer on Ethereum doesn't ship things anymore, but the things that we ship are mostly focused on like execution layer, consensus layer interoperability and these kind of things and not so much anymore like actual execution improvements. And for example, I just mentioned here like two specific features that I worked on in the past, for example where we for a while kept going on this research on more advanced execution things like satix battery, native account abstraction. We also did like 30 ERP 3074. All of these basically just ended up in this category of hey, those are nice features. And in a more kind of like high throughput or otherwise more ambitious EVM chain we would probably ship them. But basically on the L1, at least for this moment, we don't see a need for them anymore. So really the L1 EVM has been kind of ossifying quite, quite rapidly.
00:06:01.805 - 00:07:18.713, Speaker A: So now why is that relevant? Relevant in the L2 context, of course, that's kind of the topic of EVM equivalence. So how did we get there for the L2s? Well, from basically the L1 point of view, the initial expectation was that L2s basically would all focus on experimentation with novel execution environments, basically take off where Wave two left things. But it turned out, I mean, of course there have been especially alcohols in the first wave of roll ups. There were a few experiments like that, but. And it became very obvious very clearly that basically while Ethereum as a whole could have with some effort pivoted or like, like, like iterated to a new execution system, any individual like L2, especially one that only just now got started, just didn't have the, the network effect and the kind of the weight to actually get anyone to, to care or support any, any kind of novel features. And so really kind of the only choice was to stay to, to, to, for, for, for, for many L2s was to go with EVM equivalence and basically just make sure that you have feature parity with the L1 because that's the only way to really make it convenient for users and developers to onboard. Since then, of course, we've seen a lot of L2 innovation.
00:07:18.713 - 00:07:58.267, Speaker A: I mean it's been really quite the success story. It's been amazing. But on the L2 side that has really kind of like mostly avoided this specific topic or this specific area and for the same reasons. So L2s have heavily innovated on like most specific functionality and on the EVM side on things like EVM extensions, you know, things like stylus, just to name an example. Right. But not really kind of the core execution system itself so much. And then the third part of the history that dawn briefly touch on is kind of the client picture.
00:07:58.267 - 00:09:13.555, Speaker A: So historically for the L2s that has been very heavily dominated by Gath and that was just for kind of obvious reasons. By the time that most of whose got started, Geth was kind of the strong L1 majority client, kind of the obvious choice, very, very stable, it made sense and so ended up as kind of chosen as the primary client by Mosul Twos. But actually yeah, it turns out this is not necessarily an ideal fit specifically because the Geth team is very opinionated about wanting their primary and more or less sole focus to remain on the L1. And so basically they just don't usually aren't usually willing to implement or support any kind of features that are only relevant in the L2 context. And so basically the client as a whole is very much basically still L1 centric to this day. So that's kind of like the three history pieces. So basically the EVM as a whole kind of ossifying, but at the same time being the kind of the shared target across at least the L2 equivalent, the EVM equivalent part of the L2 ecosystem.
00:09:13.555 - 00:10:22.855, Speaker A: And then geth itself also as the main client, not, not particularly L2 focused. And so that gets us kind of to today. I would say what I just described was more like the situation, say as of the beginning of the year, kind of like covering the first few years of the Rob centric roadmap. Since then, things have started to shift a little bit and in particular, but many things are still kind of in a similar spot. So on the L1 we continue to basically only ship new EL features with relatively low frequency. There are a few now though that are basically in the pipeline that I would call a little bit bigger changes again, but they would also say that even there it's not an ideal fit for this kind of tight coupling of L1 and L2 specifically, because when we ship those on the L1, they're always very specific, specifically kind of like tailored around what we need out of them. On L1, I picked kind of three examples of like the three main kind of bigger upcoming LSight changes that I see.
00:10:22.855 - 00:11:16.481, Speaker A: And I think they might also cover the next three hard fogs, basically. And I would say that the first one, 7702 might be the one that's the most kind of also reusable on the L2 side. But again, that also still was very much standard around the fact that on L1 the vast majority of users still use UAS, which might not be true, at least on many of the L2s. And then a little bit later down the timeline we have eof, which I personally am quite hopeful for, also in the L2 context. But for example, we've already heard feedback from some of the L2s, especially on the ZK side, that are quite worried about the implications of EOF. And again, point being that it's not an amazing features for F2s, it's just that basically L2 compatibility, or say ZK compatibility, was not a primary design concern. And so now it potentially causes issues.
00:11:16.481 - 00:12:53.009, Speaker A: And I think even better examples of that is Verkle, where we've had kind of roll call conversations in the past about Will L2 is one to move over to Verkle as well once one does. And that situation is very, very unclear. And again, one more of these features that changes the EVM, but changes the EVM based on what L1 specifically needs. Now if we kind of look at the situation with EVM equivalence, there definitely is still this lock in effect. In particular, I just wanted to briefly kind of categorize the ways in which I think this specifically really leads to a mismatch of kind of priorities or like not priorities, but basically just like a mismatched in setting and kind of differences in what would be optimal for each layer. And in particular the four that I think are dominating here for one, just like the long term throughput levels, I think many L2s really would in principle want their chains to go to just to basically giga gas levels or something on that order at least L1 definitely does not have equivalent ambitions. And that partially or to very weak part is also kind of driven by the fact that the full node requirements frankly are just very different, right? Like L1 needs to basically be able to run on bit more or less on a Raspberry PI or at least some similar machine.
00:12:53.009 - 00:13:46.745, Speaker A: And that then I mean that's the whole point of kind of the roll up center roadmap, the execution compression that specifically gives us the trustlessness on the L2 that then enables the L2s to have say even if you go to the extreme, you could have an L2 where in order to run a full node you need to basically be in a data center. And that would still of course now you have to that make you have to answer some other questions around how can users basically then get specifically kind of get assurances. But in principle you could have a setup like that that's still safe. But that only works because the L1 runs on such a diverse node set. But of course what kind of VM you run optimally would be different in these settings. And then there is kind of the topic of block building. And in one, of course we have this, the rotation every 12 seconds different bug producer.
00:13:46.745 - 00:14:48.036, Speaker A: It's a very specific, very opinionated setup, which just frankly obviously is already not how L2s do today. But again, it's basically a lot of these assumptions are kind of baked into the EVM at the base layer. And then last point, of course that's a very big one and very obvious one. A subset of the L2 space and of course a growing subset over time probably like all of it is K based. And that brings its own kind of set of requirements in which DeBM is very much not optimal there and things that would be done differently if one were to tailor the VM around that. And then as a last one, I just wanted to mention it's not all just the differences in settings. There's actually one more factor or like that I see that also really kind of drives this tension between the kind of L1 needs and L2 needs.
00:14:48.036 - 00:15:28.975, Speaker A: And that is just that L1 by its very nature is extremely conservative. Right. We very, very, very much never want to kind of do ship change features that not just break the L1, but even just like put us in a position where we are not 100% comfortable having covered all the edge cases and everything. It leads to very slow moving L1. And that's just like. And not quite the same kind of level of willingness of risk tolerance that we see in the L2 space. And then on the client side they actually, it's that I would say it's the part of the picture where we have seen the most kind of improvements recently.
00:15:28.975 - 00:16:54.295, Speaker A: And that's been primarily driven by rethought which basically as a new major kind of L1 client came in and started to be more explicitly L2 focused, we've also more recently seen other long clients as well kind of express more explicit interest in kind of like supporting L2s. So we now have like a basically a broader base of clients and clients that are basically natively focused on the space. But for now at least most L2s are still based on Geth and don't have immediate kind of plans to either kind of add support for other clients or even like deprecating Geth support. And in particular, what we've heard even from those that are looking into kind of support for a new client, a lot of them have expressed strong, I guess I can say a lot of you, a lot of you have kind of expressed in principle interest in basically even if you were to move to a to client that's more like focus on the needs of L2s that you'd prefer to still then in that world be multiclient and so have a way to keep GU support. Yeah. And that's basically kind of the picture of how we see the situation today. Those are kind of the dimensions that I think are relevant regarding the kind of the situation of the evm.
00:16:54.295 - 00:17:54.773, Speaker A: And that's kind of the basis for how we kind of made our plans or like might kind of have our perspective of what to do, how to unlock L2C in some sense. So that's kind of the next section and just to now basically go back to the initial announcement specifically kind of roll up Geth and start there. Right. Like start basically on the client picture side. So as I was saying, like a lot of the L2 ecosystem is still based on get the idea here and it's basically to get this set up and started was basically a collaboration between the nethermind organization and kind of us from the roll call side. So the idea is to basically have a longstanding, long lasting, kind of L2 focused fork of geth. Nethermind seemed like an ideal fit basically because of their own client.
00:17:54.773 - 00:18:46.051, Speaker A: They have a lot of kind of strong experience around the EVM and have already worked in the past with L2, have some view on these things as well and so really seem like an ideal partner there. And basically they will kind of host this team going forward. Also after the presentation, we have some of them on the call here as well. So they all kind of briefly introduce themselves afterwards as well. The idea really is to basically have a client, have this client, have like this fork, have a collaborative relationship with Geth. We already kind of have talked with Marius, for example. I'm not sure actually, I can't see right now the participation participants listed if Marius is on the call as well.
00:18:46.051 - 00:19:31.827, Speaker A: But basically we've already talked with Marius and had in principle kind of got the feedback that Gath actually would appreciate. Right. Like basically having kind of that diversion of focus basically taken away from them. And there would be one streamlined team that they can basically interact with, talk about upstreaming features, these kinds of things, but basically have. Have this connective tissue between them and the L2s. And so. And then of course the idea would be that this could then basically become a basis to support more L2 specific functionality.
00:19:31.827 - 00:20:18.825, Speaker A: And that can be someone's unmuted. Okay. Yeah. So basically that would cover both just like convenience functionality, more tailored around what L2s would need out of a client. And then of course also going forward, basically L2 specific features, IPs, these kind of things. But of course, but I want to stress there just that like all of that will very much then be opt in. So if you basically think this is interesting, you would like to have a client team you can talk to, but you're not sure yet whether you'd actually want to have a move beyond the scope of L1 in terms of feature set.
00:20:18.825 - 00:20:34.913, Speaker A: That would not. Basically that would be a separate question. Right. So that's not a. It doesn't Come this client doesn't come with a commitment to some sort of new feature set. Yeah. And in particular I want to talk about that point a little bit more.
00:20:34.913 - 00:21:54.185, Speaker A: So basically we, and the hope would be that this way we can establish a kind of like a basis across the L2 ecosystem of basically several of like a set of L2 native clients. And that way we can really, basically we then have a kind of practical path to get around to actually shipping some more advanced IPs. In the past we basically, we, when we launched Roll Call, we already were thinking that probably until we figured something like this out, we'd mostly be blocked from actually doing meaningful things. And indeed, if you've, if you've attended any of the kind of the last months of Roll Call, it was quite obvious that, well, there were quite a few interesting kind of IPs presented by different teams that had interesting ideas. And most of that is blocked by the fact that most L2s just have clients that have a client that would not implement and maintain a feature that's only relevant in the L2 context. And so if everyone has to in their own kind of branch, in their own fork of geth, maintain a feature that that's basically non starter. So up to this point we haven't really been able to support kind of shipping any IPs.
00:21:54.185 - 00:23:23.679, Speaker A: But the one caveat here, and I'll get back to this right on the next slide, but basically on its own, this of course does not change that specs wise there's still the same kind of forcing function of the kind of L1EM equivalence where basically just because now we on the client side have this unlock and can basically start looking into more advanced features. On its own this would only be a good fit for like say isolated small features like precompiles these kind of things and then more like under the hood features that might make bigger changes, but in a way that's not exposed to dapps or users directly. Because that way you could still kind of remain a one EVM equivalent. But and this is basically the second part of our vision, we have thoughts on this as well because we really think, for the reasons kind of that I outlined, we really think that kind of discontinued L1 EVM equivalence is not the right path forward for the L2 ecosystem. This again is just our perspective. But so basically what we're proposing here in addition, so basically the roll up guest team will get started, it's already set up, they'll be around no matter what. But like this part is more opt in this part here, the L2 EVM Common Core that I like to call it, and I personally am very excited about this.
00:23:23.679 - 00:24:19.985, Speaker A: I think it would really be a crucial building block for bringing EVM innovation back to the L2s. But this part is Opt in. If you don't think this makes sense, then by all means. The idea here is that basically we think it would make a lot of sense to basically have some sort of shared set of IPs or otherwise EVM changes that, that everyone who wants to opt into this Common Core would commit to supporting, right? So basically you have some sort of shared base, so shared extension of the L1 EVM. And that way basically you could really think of it, right? Like it basically gets you the best of both worlds. You still are equivalent with everyone else. It's just that everyone else is also now equivalent with you and your kind of enhanced feature set no longer with DL1, right? So basically we are.
00:24:19.985 - 00:24:38.021, Speaker A: The idea would be to really create a basically L2 EVM, which is basically a superset. I mean, of course over time there might also be some changes from the breaking changes from the L1 EVM. But basically, like, it's. It's mostly. You can mostly think of it as a superset of features from. From. From mainnet.
00:24:38.021 - 00:25:23.647, Speaker A: And that becomes the de facto kind of new basis for. On the L2 side. And so that means that like, because. Because of the combined weight of. Of the participants, it would become the primary kind of target for wallets, for tooling, for things like solidity, basically everything in the ecosystem, which would really kind of take away these concerns around the inability to make changes. Because now we would have the basis for that. One aspect of that is also would be that then that would be a good platform to kind of harmonize the way to how to handle these upcoming L1 changes that I mentioned.
00:25:23.647 - 00:26:38.593, Speaker A: For example, Verkal, that would be a group where these decisions could be made and just to kind of like give a little bit of an intuition of like, how we think about this or like, would think about this. The idea here would be to have basically the best of both worlds, right? Like have the standardization that you get from the L1, but the ambitiousness that we see today or in the individual L2s in terms of kind of like a rate of new features, kind of ambition and scope of new features. And basically on the spectrum sit kind of in between, in between those, like in between L1 and L2. The one caveat or the one kind of point I wanted to mention here is if we indeed go down this path, the path of the Common Core. And of course by the way, none of this in a Common Core world, just as today every L2 or every L2 stack would then still on top have their own additional features, things that aren't specific to an individual L2. This is just really about the shared base. But as such a shared base it would require some sort of governance mechanism.
00:26:38.593 - 00:27:24.569, Speaker A: Right? Because it would not just be a one time kind of list of changes, but over time kind of keep iterating and this kind of, this question of how do you kind of come to agreement on like which new features to include into this kind of set of globally supported features. And that needs governance. Of course, at any point, if you're part of the Common Core set and then a feature gets added that you really hate, you can always leave. But of course then we're back to kind of the fragmented world. So really kind of the governance side of things is something that would need to be figured out. Just to give you a little bit of an impression of. Because I've been talking for the entire talk now about the ways in which the L1 kind of EVM equivalence holds the L2 ecosystem back.
00:27:24.569 - 00:28:25.415, Speaker A: I just wanted to give you some impression from my side of topics that I see. Those are really kind of mostly kind of things from my, from my wish list that, that, but that I've been mostly thinking about in the L1 context so far. But just, just, just examples that none of none of this would, would end up having to, to be say in the Common Core set. Some of these could just be ips that, that separately are supported by the clients if, if, if any L2 swans ship them. But it's things like right say basic repricing right now even most decay roll ups really feel the need to strongly follow the pricing schedule of L1. But of course it's in many ways quite mismatched if you compare it to the actual research usage. But it's not only the ZK context, it's also for example the relative balance between execution cost and execution and data cost where this trade off is very different in the context than in the context.
00:28:25.415 - 00:29:20.527, Speaker A: These kind of things just like, like a kind of like a one time way or like maybe even like a more general kind of mechanism that, where individual L2s or chains can have their own kind of pricing table. Something that I personally think would be a great unlock for the L2 ecosystem. Of course that depends on to what extent people would want this. But I think basically having Some sort of basic two dimensional transaction type that natively expresses both the execution within the L2 chain but then also the L1 settlement cost basically as a two dimensional kind of cost vector within one transaction type. I personally think that would having something this standardized across the L2 ecosystem, this would not replace existing transaction types at least unless you would want to deprecate your existing transaction types. It would just be a new one to support that basically would be standardized. I've been hearing a lot from people I don't know.
00:29:20.527 - 00:29:55.615, Speaker A: Maybe I have a bias sample of people I talked to but like that that really are struggling with having to basically support different, different transaction formats on different L2s. So that's something that also I think could be exciting in the short term. And then things like it's just like a topic that recently came up on the L1 side. I'm sure that would also be interesting to look into on the other two sides. Something like state route computation. But really those are more maintenance examples in the long term. There's even more examples to mention here.
00:29:55.615 - 00:30:55.535, Speaker A: Like I think native counter abstraction is a big one. We have an IP that's actually how the like there was a big part of like how the Oracle IP process got going. Kind of you off coming, coming to Karl and me and specifically with this, this idea and also expressing the basically the need for, for the IP process. But as we've seen it's one of those features where if, if the main client used by Altus does not implement it then there's. It's kind of completely infeasible to ship now kind of already say as just based on roll up get that that might change but, but, but most importantly of course it could be a very natural fit as part of the Common Core. Then things transaction parallelization I mean meaning guaranteed one of course clients have already experimented with with, with optimistic parallelization statelessness. There's the different kind of the flavors of course the statuses you get from something like verkle trees.
00:30:55.535 - 00:31:45.183, Speaker A: But then also say ways in which you can, you can manage the state size even for stateful nodes. Specific kind of state expiry maybe in combination with state rent. We basically out of the L1 context we have a fully kind of functional spec or not fully spec yet spec out yet. But we have a version of state expiry that would work and maybe there could be newer ones now but we just decided never to ship it on L1. And then things I've been looking in the past into multidimensional pricing that would further basically just allow L2s to or any chains really, including L1.2 to basically just make more efficient use of the available resources. So yeah, these are just again to give you some examples.
00:31:45.183 - 00:33:06.179, Speaker A: I think the idea would be that there would be a lot that could be done and I assume most of the things actually to be done would actually come out of existing L2 needs and not just from our side. Then one more quick topic there on the vision side and that's kind of the role of Roll Call in this kind of now going forward. I called it season two because I just want to kind of like illustrate that like basically because of these constraints that we have had so far that basically there was not really a way to specifically to ship IPs other than the ones that are trivial to maintain. Basically Roll Call in the past in season one was pretty toothless. And so going forward it would both kind of retain its existing role. So kind of overall L2 coordination and a platform for IPS. But there's this extra one that we've been trying recently to lean more into, which is kind of like trying to be this connective tissue between L1 and L2, report a little bit from the L1 governance process, bring feedback from the L2 side back into the L1 governance process, these kind of things.
00:33:06.179 - 00:34:14.425, Speaker A: But of course now going forward it would also be a platform for coordination across the clients that want to focus on the L2 kind of topics. If we go down the path of Common Core, it would also kind of like be the kind of the anchor for the governance there and for the kind of the research process and the process for these kind of more advanced features to now bring into the L2 EVM. Although just to mention this, it could be that like maybe this is a bit too much of a scope for kind of one process for one call. So once we kind of get this into a mature state, it might, might be time to kind of split that up into individual processes. And yeah, that's kind of our vision. I hope I did a kind of decent job presenting that. It really kind of like the two main kind of takeaways there are the a roll up geth, the team that that one will, will be a thing.
00:34:14.425 - 00:34:47.851, Speaker A: It is a thing now. It's something you should pay attention to. And then of course the Common Core is something that's more ambitious, more optional, say and requires opt in, but that we're also very excited about and next steps concretely on those two topics. On the roll up geth side, if you are an LL2 that's currently using Geth. You should internally kind of like decide your strategy around this. Would you move to want to move to robot Geth? And one what basically what reassurances would you first want to see these kind of questions. You should connect with the team again.
00:34:47.851 - 00:36:08.735, Speaker A: They'll briefly intro themselves in a second once I'm done and start figuring out the kind of the migration process. And for other clients, if you are reth, for example, I think it would be a good moment in time to start kind of like establishing some, some kind of ways of some, some ways for collaboration across these, these clients. And then last slide on the Common Core side, I think the most important thing would be initially for us to just determine. We've, we've talked with a lot of you individually in the past about, about this and felt like some general kind of interest. But of course, and that was all very non committal. Now the question is with this more concretely kind of now scoped out, is this something that, that actually makes sense for you? How, how viable is we? Obviously this makes only sense to go forward with if the group of virtues that are willing to join the Common Core set would basically have enough traction and then if so basically there's this governance to be figured out and kind of on the research side kind of like to the idea here would by the way, not just not be to like necessarily have all the research on kind of new features live within this coordination process. It's really more to just have a platform where the individual researchers from the from the EL tools can come together and talk about their individual work and perspectives.
00:36:08.735 - 00:37:02.395, Speaker A: And so kind of like there are the questions of like what would be an initial scope for the Common Core? Again, the relationship between ZK and optimistic, I kind of only touched on it a little bit throughout the talk that the question is, does it even make sense to have a shared Common Core set there? Like how to basically handle that question. And for all of this, just one announcement there we will have a kind of a kickoff call that's more focused on like hey, what would be a good kind of initial scope? What are the kind of the burning topics, what to focus on there for the Common Core. And that's going to be after DEFCON December 4th and then the next roll call, I think because the upcoming one will be right during defcon, so that will be canceled. So then the next roll call will be the week after basically. Yeah. So that's all from my side. Again, I'm terribly sorry that there was Not a single picture in the entire slides.
00:37:02.395 - 00:37:23.775, Speaker A: I don't know. That's kind of more my style for presentation, but I hope it was still possible to follow and yeah, then that would be all from my side and I guess we could first briefly have the roll up geth team into themselves and then we can have questions and open discussions and feedback these kind of things. Thanks.
00:37:27.315 - 00:37:50.065, Speaker B: Hello everyone. Or have another mine here. So I'll be part of the rollup guest team along with Nicola who is also part of the netherminecore team. Yeah, we support with the rest of the team. So yeah, we expect to move forward with this project long term and actually grow the team as we go.
00:37:56.725 - 00:38:36.415, Speaker A: Awesome. Yeah. So now would be a good time to just basically open it up and get some feedback like talk about to what extent does this make sense for the individual teams? Maybe ways in which you disagree with our perspective there, how we presented it, these kind of things. I think Adili, if you raise your hand and then you can. Nicola.
00:38:37.595 - 00:38:38.107, Speaker B: Yeah.
00:38:38.171 - 00:39:03.155, Speaker C: Thank you for the presentation. Just maybe a quick feedback. If you are to. To do the same presentation at defcon, make sure to include some pictures in the slides and yeah, don't forget to submit the presentation. I'm hijacking the call for a quick reminder but yeah, the DEFCON team is waiting for your presentation.
00:39:03.815 - 00:39:40.175, Speaker A: Yeah, that makes sense. And to be clear, this one I really focused on the content more because it's more like a technical audience. We'll have a kind of more general kind of version of the talk of like the roll core vision for EVM equivalents at defcon and that one will be very normie friendly with a lot of pictures. Thank you. Thank you. I see a question in chat vision slide, slide 18. Should I briefly.
00:39:40.175 - 00:40:03.907, Speaker A: I don't know. Let me, let me first read some of these examples. Great. But what happens if one L2 team protests one feature is more valuable than co differentiation? No. So basically the idea here would be to really have this be the kind of the only. The absolute subset of full agreement. Right.
00:40:03.907 - 00:41:01.405, Speaker A: So basically the idea is if there's features on there that now that say the. On the client side you're no longer blocked and you have a client that is very. That's willing to. To basically support a new IP that, that you are interested in. But by all means the idea is that if you are comfortable with going live with that feature, Even if other L2s are not and so then you basically in that sense have some sort of subset of features or behaviors where you are kind of have different behavior from other L2s. But if you're comfortable with that and kind of like users having to be aware of that or developers, then the idea is always that you're supposed to ship that and that basically you still get the benefits of now having clients that are focused on supporting these types of features. And the Common Core set would only ever be basically the subset of these features that L2s broadly kind of agree that they want to support.
00:41:01.405 - 00:41:41.525, Speaker A: So that for these features, basically just for depth developers, for users, it is clear that all chains that are part of the set will support that feature. Right. So basically it removes that headache, but it's really just trying to extend the current situation. Like by no means is basically the idea that now you'd be more restrained in shipping features on your own. The follow up questions, what about the cases where we all agree but the order is not agreed upon? Yes. So of course there's a lot to be figured out here. I think.
00:41:41.525 - 00:42:14.885, Speaker A: Again, I don't think it would be on us to be too opinionated here because clearly we don't want to make decisions here for the ecosystem. There could be many different variants of this, right? You could imagine, let's say the Common Core releases a new version once a year, once every two years or something it comes with. Or once every six months. I don't know. It comes with some expectation of what timeline else who could ship the set of features. This all would be tbd.
00:42:18.195 - 00:42:39.575, Speaker B: I think maybe if there are. I wanted to go over questions first, but maybe I can present something that I had. Not sure if I can even share my screen, but I can go over a few things that I wanted to say about the approach that we're taking for rollup get in general and how we envision the future. Is that okay or do we want to take a few more questions?
00:42:43.645 - 00:42:46.661, Speaker A: Yeah, no, I think it would be very valuable. So go ahead.
00:42:46.733 - 00:42:53.265, Speaker B: Okay. I will try to share my screen, although I'm not really sure if I can.
00:42:57.525 - 00:42:59.225, Speaker A: I think you should be able to.
00:43:02.725 - 00:43:06.265, Speaker B: Okay, I'll have to rejoin. Sorry.
00:44:03.075 - 00:44:03.499, Speaker D: Yeah.
00:44:03.547 - 00:44:06.555, Speaker A: Yes, you can see your screen. Okay.
00:44:06.715 - 00:45:02.623, Speaker B: So yeah, this is what I wanted to kind of COVID Anska already covered most of it, so I probably only wanted to go over our approach to roll of Geth. So yeah, just to reiterate a little bit on what Anskar just said. Yeah, we saw this growing interest in the ecosystem in having like a Common Core repository where we would have basically will serve as the base for all of the work that Layer Twos have so yeah, the idea was to create a fork of Geth that will serve this purpose. So assignment as got explained. So yeah, basically roll ups that decide to use Rob Geth as their base, they will be basically getting all of these features kind of for free. And then they would only have to implement their own unique features. Like for example, maybe Arbitrary will implement something like stylus or.
00:45:02.719 - 00:45:03.151, Speaker A: I don't know.
00:45:03.183 - 00:45:50.513, Speaker B: Each L2 has their own thing that they implement on the roll up. That is not necessarily something that we as a community want all L2s to have. So yeah, that's the idea. Long term, short term. We're currently focusing on basically gaining a good understanding of the GET code base at this point. So where we come from, core development, but mostly within the nethermind client, I have some previous experience with Geth, but we're basically right now trying to improve a lot our understanding of the Geth code base, improve our understanding of how the different L2s are using Geth. So we have been looking at the code for multiple layer 2s out there, how they use Geth, how they fork it, what, what they modify.
00:45:50.513 - 00:46:58.085, Speaker B: So what are the things that they need and trying to identify these different challenges that rollup get will have to face in the future. Right at the same time, yeah, we're trying to figure out where the EAPs the RP is that make sense. Trying to get feedback from the community, from different L2 teams to understand what are the things that we should focus on and we should put other energy because Most of these ERPs are actually not in their final form. So we're trying to prototype them, figuring out what are the things that need improvements, the things that need more work and so on. So yeah, that's kind of the goals our approach right now, the things that we're doing. So we're trying to follow an approach where we are as less disruptive as possible with different L2s. So basically we're doing this thing where we try to whenever we can, we're trying to basically implement different EIPs in the way that minimizes the amount of conflicts that the layer 2 would have to solve when merging with rollup get, if that makes sense.
00:46:58.085 - 00:47:58.245, Speaker B: So basically whenever we want to implement an eip, we go through the GET code base. We figured out what is the how, how we could try to tackle this EIP in a way that has the less amount of modifications to the core to the core parts of the client. So maybe we create new files rather than modifying existing files, or we try to create hook Functions that then we can implement in different files or implement in different modules so that, you know, we're as less disruptive as possible. We are also, after implementing these EIPs, we right now are going through multiple of the L2 forks. We are trying to. We're creating a PR that kind of merges the L2 changes with the rollup get changes. And basically this PR will serve as a showcase of what this L2 would have to do if they wanted to integrate with rollup get today.
00:47:58.245 - 00:48:33.175, Speaker B: Right. So we have implementations right now in the repo for EIP 7706 and then remember the name, the number which is the L1S load. And we have the implementations for these CIPS in NPR for rollup get. But then we also have PRs that try to merge different layer 2 forks with the branches that contain the CIPS. Right. These PRs are also kind of like tested. We run the roll up code to make sure that we can still sync the roll up network, that everything works fine.
00:48:33.175 - 00:49:18.175, Speaker B: But we're minimizing conflicts. So the amount of conflicts or the things that you would have to change in your code are minimal with respect, if you want to actually integrate with rollup get today. So it's not like you would have to just go over hundreds of files solving merge conflicts or anything like that. So that's our main focus at the moment. Yeah. So that is to say, so regarding this third point, like I said, we're trying to test everything, make sure that the roll up code still works. Although at this moment testing is not our focus and we will have to develop good strategies for how to go about testing for all the different L2s in the future.
00:49:18.175 - 00:50:09.015, Speaker B: So this is a diagram for how branching strategy looks like. I think this is something we're putting a lot of thought into because we want to. Basically we don't want. So we want to bridge this gap that exists between the Geth core team and multiple Layer two teams. Not only the big L2s, but also there are smaller L2s and maybe don't have like such a big team. So we want to help everyone kind of like have this repository that can showcase how different implementation of different EAPs would look like, not only for Rob get, but also how different layer 2s could integrate with this code and how we think they should integrate with this code so that it's the least disruptive for them. Right.
00:50:09.015 - 00:51:09.727, Speaker B: So that we're putting a lot of thought into that and we would appreciate your feedback with that. Yeah. So for the future how do we see this roll of GET on different Layer two's synchronization process? So from our perspective this would have to be something like a governance process similar to the or cortex when we reach some form of consensus on which features we actually want to merge. Like we said, we hope, we expect that in a couple months, maybe whenever we want to actually start getting Roll up Geth included in L2s, we what we plan to do at some point is we want to agree on a set of EIPs. We maybe want to agree to on some kind of prioritization of these EIPs. And then we'll put up PRs for the implementation of these EIPs. PRs for how the merging of this roll up new rollup GET code would look like with the different L2s.
00:51:09.727 - 00:52:07.555, Speaker B: And then we would put those PRs just on hold until there is consensus that we want to merge the different features into the main branch and that we might even be there to help Layer two teams integrate with the code. So that's the idea, right? That we will be kind of like the team that's there to help you out with anything that you need with the GET code, with the roll of GET code, with anything. Like I said, Sample PRs for the integration of multiple L2s, one can go over. So yeah, so yeah, basically just regulating the same thing. You can go over the PRs in the layer 2s and see the changes required to implement this. So yeah, maybe from time to time there will be things that, for example, there might be an EIP that we decide that in order to implement. It introduces a lot of changes, core parts of the client.
00:52:07.555 - 00:53:13.671, Speaker B: So maybe we might be in touch with the GET team, we might try to submit a patch upstream that somehow refactors part of parts of the code so that it allows us to implement the feature in a way that is less disruptive with the code base and allows better integrations for different layer 2s. I think this is something that the GET team might be open to accepting VRs from time to time that makes our lives easier. So yeah, that's part of kind of our plan, right? Yeah. So as part of this roll up Geth initiative, I guess one other important thing is that we would be basically pulling updates from Geth. So basically, in case you wanted to integrate with Rollup Geth, you would basically change your upstream to be Rollup Geth. And then we'll be the ones that in a timely manner like every, every few months or every couple of weeks or whatever, we will be pulling the latest upgrades from get. We'll be making sure that if there is a security fix, we will ship it as soon as possible.
00:53:13.671 - 00:53:40.631, Speaker B: It's all of this, right? So yeah, we'll kind of like Ansker, say, try to bridge the gap that exists right now between the GET team and all of the different Layer two teams. Yeah. And with that, what do we need from you in case you're interested in the project? Well, we'll need feedback. In general. We have a repository that you can go over right now. You can take a look at the code that we'll be doing. You can also get feedback.
00:53:40.631 - 00:54:40.123, Speaker B: From the approach that we're following, you will be very much appreciated. So, yeah, and in general, we would like to hear from you. What would you see as a blocker if you wanted to make the switch tomorrow to from GET to Roll up get, what would be a blocker for you? Why not do it? Like, what's holding you back? What are the things? Do you see that there are no gains or maybe the gains are not enough and those sort of things. And the most important thing I would say also is getting a list of these rips. I guess this is part of the governance process that we agreed that had to be put together somehow. We are coming from the layer one in general. I have some experience already with L2s, but I'm sure that each Layer two has a unique set of features that they would like to see implemented.
00:54:40.123 - 00:55:07.695, Speaker B: And it would be very good if all of you shared what are the features, the main features that you would like to see implemented in this Common Core, so that we can take a look at all of them, explore them a little bit and maybe come up with a prioritization somehow which are the ones that should be implemented first. So, yeah, I guess that's everything. So yeah, we can keep taking questions if you have any.
00:55:08.555 - 00:55:53.025, Speaker A: Thank you very much. And one thing before we go to questions, I wanted to mention because I already got the feedback privately that this was not clear when I said in the presentation that basically I'm not representing the EF in kind of like in these general kind of thoughts. I was talking more about the broader approach here specifically. I think it does make sense to stress that like the Roll up guest team specifically is a collaboration between nethermind and the ef. And so basically it comes with like a kind of longer term commitment to basically to make sure that this team is in a place to do its job. So I just wanted to stress that. So that part actually that does Come with overall EF endorsement.
00:55:53.025 - 00:56:05.345, Speaker A: Kev, you wanted to say something also, by the way, we are running up towards the end of the hour. If people have to drop off, that makes sense. I think we can otherwise run over a little bit.
00:56:08.605 - 00:56:24.685, Speaker D: Yeah. Could you explain the difference between as a L2, if I wanted to use opref versus rollup gaff, is it that now I'm relying on one code base in order to implement a particular feature?
00:56:26.225 - 00:57:14.583, Speaker B: So, okay, so Rollup Geth is. So, for example, right now if you wanted to run on OP stack, you have basically three choices. You could use either opreth, OP gethsemane or OP nethermind, for example, right? If we implemented Rollup Geth. So Rollup Geth would basically bring a common set of features that, for example, now OP Geth, rather than being a fork of Geth, will basically be a fork of Rollup Geth. Right? So we would implement a set of features on Rollup Geth that OP Geth will basically be getting for free. These features will be available in opgeth if they decide to. If you decide to switch to rollup get, it's not like you're using rollup get to launch your rollup, it's like you're using OP Geth still.
00:57:14.583 - 00:57:24.755, Speaker B: But now OP Geth is based on rollup get and it's inheriting all of the features that are implemented in Rollup Geth. Is that Anjali your question?
00:57:25.975 - 00:57:45.915, Speaker D: I think somewhat I was more getting at. Like, if there are two different L2s who have forked GAV, then they have two different implementations. Whereas now it seems like if they all rely on Rollup gif, is there one implementation that we need to make sure it doesn't have any bugs?
00:57:46.455 - 00:58:35.705, Speaker B: No. So, for example, let's say that right now everyone needs account abstraction. Let's say everyone was interested in account abstraction, right? So, but account abstraction maybe is a huge implementation effort and no one has actually had the time and the resources to implement an account instruction on their execut. So what we would do is that rollup Geth might implement account abstraction in the Rollup Geth and then all of these L2s that are fork of Geth, they would basically start, you know, merge the updates from Rollup Geth and now these, all of these different forks will still exist, but now they would have account abstraction. Right, because they inherited it from product get. Does that make sense now?
00:58:37.165 - 00:58:43.865, Speaker D: Yeah, yeah. So they, they're relying on Rollup GE in this case to get account abstraction in their forks.
00:58:44.405 - 00:58:45.185, Speaker A: Yes.
00:58:56.975 - 00:59:18.035, Speaker D: I haven't heard any L2s speak. Is it possible for someone from an L2 to sort of say what are your general thoughts on this at the moment? I see Proto DC don't mean to call you guys out if you don't want to talk.
00:59:18.855 - 01:00:07.181, Speaker E: I'm happy to comment. It's very new. I think I want to see the outputs before committing to anything. This can go very well, or maybe not as well. I do think the pattern of having a version of gav upstream that layer 2s can take from as a way to standardize layer 2 features is powerful. That shared development process makes sense. But then we do have many more clients, many more implementations, specifically Ref, netherminds, Aragon, all these things have to be maintained as well.
01:00:07.181 - 01:00:46.645, Speaker E: And I'm a little bit concerned about enshrining Gaff too much. And I'm also worried about not being able to establish or how to put it, not keeping up with the performance needs of layer 2s. And other efforts to try and provide this bleeding edge experience like Ithaca are in a way competing with this design. And I'm not sure if that type of competition is what we want, if we are trying to standardize.
01:00:50.225 - 01:02:04.185, Speaker B: So regarding different implementations, I think this roll up Geth is coming because the need for roll up geth is coming because most layer 2s are started as a Geth fork and when you wanted something implemented in all of these L2s, basically the easiest, the easiest way would have been to have it merged upstream. But the get theme is not like it's not one to merge things upstream that are only like relevant to L2s. So that's the gap that probably GET is coming to bridge. But the other implementations, like for example I can speak for Nevermind, the. NET and Mind client would support automatically all of the features that we decide to implement in rollup Get. So if particular layer 2 uses Netemy client 2 as part of their client stack, they would get the features that rollup GET gets pretty much at the same time because we'll make sure that everything that goes into product get goes into the netem client. So that Layer two is using the Netmine client can also you can keep using the Netmine client and be compatible with all of these features.
01:02:04.185 - 01:02:31.543, Speaker B: I'm not sure about ref, for example, but I expect that if layer 2 decides to start to use crawlab get as an upstream, it's just now you're basically inheriting features in the same way as if you would have implemented them in OP get, for example, and these other Clients would be just keeping up with OP Geth in a sense, right. The same way that they have been doing so far and.
01:02:31.679 - 01:02:36.007, Speaker E: All right. And just one question about sir. Go ahead.
01:02:36.151 - 01:03:16.429, Speaker A: No, I just wanted to say just to be very explicit, right. Like the idea here is not that rollup get would be the client for Roll Call or the client for the IP process or something. It's really just to make sure that L2s that A either today are in a position where they rely on get specifically and don't yet have a choice. Don't you have an option to go multi client or that choose to want to have Geth as one of the supported clients that they have a way to participate to the extent possible kind of at least on the Common Core set side. But it's totally fine. For example if one of the outcomes is that over time a different client say Reth I think is kind of the frontrunner in that space. Just basically has many advantages.
01:03:16.429 - 01:04:28.319, Speaker A: And L2s just naturally choose to over time discontinue their Geth support and are exclusively based on that is totally fine. Like the client basically is here to have as large or as little of a role as it is useful for and it is in no sense trying to basically like long term have any specific role for Geth or Geth based code base in the L2 ecosystem. Very much just how where the demand will basically lead. This and on the other point you said earlier, I just wanted to briefly say I totally agree that this can basically go well go not so well. I think from our side we would just very very much appreciate any kind of feedback in the form of like hey this effort both say on the roll up Geth side but then also on the Common Core side, hey, this would be useful for us if it turns out this and this in this specific way. Right. So basically like anything that we can, we can do to now to guide it into a direction that ends up useful for the ecosystem we would be more than happy to do and then just again try to find a way like a that that requires minimal kind of opt in by everyone to basically just fill a useful slot and to the extent that you always want to continue having your own features in a more kind of like individual way or something, that's totally fine.
01:04:28.319 - 01:04:34.595, Speaker A: This is really just trying to basically build some extra role that right now is just unfilled.
01:04:37.015 - 01:05:16.485, Speaker E: All right, about the go Ethereum like client asset base. Do we still maintain the execution layer specifications? What does that look like? Do new rips go to rollup Caf first or do they go to the execution specs first? Because I see you know more prototyping, more of a feedback loop of users if it goes to rollupgraph because you can test run it. But I think that then harms the multi client idea of Ethereum too.
01:05:19.545 - 01:06:03.015, Speaker A: I agree with that. That one we would have to figure out but I would say, I mean a. I'm already expecting like you know with Ithaca I think Reth for example is already doing a lot of like prototype implementations of features as well. I think the healthiest thing. I mean yes, of course if we can have a more specs based kind of approach there that would also be great. I think alternatively also if we just basically over time have a some sort of collaboration forum across the kind of the clients that are most actively kind of targeting the L2 and have coordination there on like which kind of new and advanced features they are kind of implementing and testing. That also I think would be useful in that context.
01:06:03.015 - 01:06:31.885, Speaker A: But yeah, I think having having roll up get now have play some sort of outside role in the ecosystem or basically some. Some role beyond what beyond any other client that that would explicitly be a failure case. That that specifically is. I mean it's good that you're pointing out because I do do agree that like it's easy to. To just forget about but I, I really think that this very importantly would be a failure case.
01:06:33.825 - 01:07:09.115, Speaker E: Also you mentioned or I think you hinted at a way to compare which L2s adopt which RIPs and EIPs is comparison type of website or something like that. Is somebody working on this? Like where do we track the this type of thing and also will we track the rollup gaff diff in a similar way? Is that the same type of project or like how does this come together?
01:07:10.095 - 01:07:23.195, Speaker B: So the question is whether we have like a website where you can track the different basically the changes that we're making to roll up geth on different branches that we say we have for the interaction with rarities so we don't have.
01:07:25.135 - 01:07:26.315, Speaker E: Those changes.
01:07:26.855 - 01:08:28.773, Speaker B: Yeah so we do not have at the moment such a website. We could put it together actually I think we run the. I think it's optimism that has this div generating websites thing that we can use and we used it locally to kind of go through the divs of a few L2s. We can probably put that up without too much work right now the closest that we have to that is prs so you can go through the div in the PR because we haven't Merged anything. So you can basically go through the div in a PR that implements EAP7706 and then you can go through the diff in APR basically merges op geth with the rollup geth EIB 7706 implementation. So PRs are the things that we, that we have right now and I think it wouldn't be too hard to put together some kind of website and we could work on that.
01:08:28.829 - 01:09:29.225, Speaker E: Potentially the main thing seek out wrong is that between OP Stack and between Ethereum layer 1 there's just one dev to keep track of. But then once there are many different rips and it starts to look more like a tech tree where there's a tree of changes that might have some dependencies on one another and then keeping track of how that all fits together and what is needed to adopt a certain change might, you know, it's something that I think needs dedicated support to do well in the long term. Compare this to ecosystems that use plugins, for example. You can browse the plugins like a marketplace. It's a lot more documented in that sense. Whereas if it's just git diffs it might become very messy very quick.
01:09:31.325 - 01:10:22.325, Speaker A: Yeah, I think with a lot of these questions it's really the case where like we have to figure, figure this out as we go. I think it's hard to set this up in advance because we just don't know yet what the demands are. But, but I in general, totally agree, but I think this will be unavoidable if we end up ramping up kind of EVM execution side innovation overall on the L2 space. This will be a problem we'll have to face and we'll have to find solutions for. I, you know, I think, I think the alternative of basically just like the alternative of course would be that we just only ever have innovation in each individual like L2Stack, which also works. But I think kind of the having some sort of at least shared base would be desirable enough to warrant figuring all of this out.
01:10:33.795 - 01:10:42.763, Speaker D: Dc, did you have an opinion on this? Like not representing World Coin, obviously.
01:10:42.899 - 01:11:22.505, Speaker F: Yeah, I mean like for us the, I mean this is like. I have a very different view of this because of like more of like app driven development. Like for us we want to. We obviously care about the OP stack, right? Like we're part of the super chain, therefore we have to upgrade as everybody else does in the super chain. So this is sort of like standardization effort. My personal worries are the ones that have been voiced like in the chat as well like all the dependency tooling like solidity et cetera all the downstream effects to the effect of this. I mean I'd like to see just like the some form of diff that is curated and then distributed to all the respective tooling.
01:11:22.505 - 01:11:36.465, Speaker F: I don't know my abuse of this. I just need to think about it a bit more. I don't have anything specific just yet, but we would love to move to anything that makes the L2 EVM experience faster. I'm happy to support wherever possible.
01:11:41.955 - 01:11:48.455, Speaker A: I think Nico, you still have your hand raised. I'm not sure if that's from an old question or if you want to say something else.
01:11:49.195 - 01:12:21.155, Speaker C: Yeah, that was from an old question. But yeah actually I think the there is a lot of unanswered question and it's good if we could have a tread on Ethereum magicians and discuss further there because it's going to raise a lot of different topics and yeah maybe some of them can can be even side projects like the website to track everything but it would be great to have a follow up dedicated topic on his map.
01:12:24.655 - 01:12:28.835, Speaker A: Yeah that seems very reasonable I guess.
01:12:29.215 - 01:12:39.935, Speaker D: Oh sorry, I don't have to inherit that. I think it is if you. If it is, do you have an opinion on this?
01:12:40.915 - 01:13:44.785, Speaker G: Hey Kev, yeah, I mean I'm very supportive of this initiative. One of the things we've been worried about on the base side is we think we're going to outgrow Geth, at which point will be potentially no longer multi client dependent entirely on wrath. So I would love to see a fork of Gethsemane that keeps up with the performance goals that we have. I'm glad to see you're thinking about things like delayed state Ruth I'm also really excited about an L2 specific transaction type which I don't ever see making it into Geth so and I would prefer that to be in a more standardized repo rather than purely an op stack specific extension because obviously if you introduce a new transaction type needs to be supported by multiple wallets and I don't think that would happen unless it's a standard that's accepted by not just op stack chains but you know, the other prominent roll ups as well. So for those reasons I'm pretty eager to follow along. Also still thinking about this digesting what it means but initial impressions pretty positive.
01:13:50.605 - 01:14:15.235, Speaker A: Thanks Revana do we have any maybe other it's funny now that the three people talking op stack which is great but do we also have anyone from any of the Other ecosystems would be curious to basically see if those are similar concerns or then maybe from a different perspective, other concerns.
01:14:25.265 - 01:14:29.785, Speaker C: I think Derek from Off Chain Labs had to drop the call.
01:14:29.905 - 01:14:35.473, Speaker F: Yeah, yeah, he's not here anymore. I was just about to, to ping him, but then I came here.
01:14:35.529 - 01:15:12.265, Speaker A: Yeah, same. Yeah, I think he had some concerns in the chat about like, how this basically could slow down new features because now, say, there would have to be agreement on, even if there's general agreement on like, which features, say, to add to the Common Core set. But it could be that there's disagreement on ordering or timeline or things like that. And there I just wanted to reiterate that this is really like, this is supposed to just like fill a role that purely adds value. Right. This process. So if there ever is disagreement or an individual L2 would prefer to ship something on a faster timeline.
01:15:12.265 - 01:15:45.115, Speaker A: Of course this is always a choice. The idea here is really just that this could be a great platform for features that otherwise don't make it at all or where basically there's specifically high value in sanitization. So if you prefer to ship any specific features on your own. Absolutely right. And ideally now you have one more client that is willing to, to implement and support IPs that you need for that.
01:15:58.335 - 01:16:06.875, Speaker E: What is the first course of action for Rollup Gaff? What, like how many team members are there currently and what feature will be implemented first?
01:16:12.695 - 01:16:51.647, Speaker B: I would say we're still on experimental phase. So what we're doing right now is, and I think that's what we wanted to focus on at least until close to end of the year. So we couldn't. We. We chose a set of EIPs just from a list of EIPs very pretty much arbitrarily and started implementing EIPs that touch different parts of the GET code base so that we could give us some insights. Like, we're trying to identify challenges like in EIPs that, for example, touch the state transition code or EIPs that judge the mempool code or whatever. Right.
01:16:51.647 - 01:18:08.745, Speaker B: So we're trying to. Trying to get a set of EIPs that implementing them would basically cover different parts of the code base so that we would get an understanding of what are the different challenges that we would face with implementing different types of EIPs in some sense, and also familiarize ourselves with the GET code base. So that's the idea right now. So it's more like understanding, learning, experimenting with everything, breaking things a little bit for a couple of months before we actually get to okay, we want to implement the CIP for real. Let's get it working, let's test it, let's do everything. So I guess this is the time where the best contributions, the best contribution from the layer 2 side would be reviewing our process. So taking a look at what we've done, you know, giving us feedback, what do you think we could do better? What things would you like to see changed? How would you like this to look like in the future so that maybe we can move in that direction?
01:18:14.405 - 01:20:00.133, Speaker A: Yeah, and in terms of new features, I do think that like say the, if we have the breakout call early December, that would be a good place to like specifically talk a little about. Are there any specific features that maybe are low hanging fruit that don't require like a one year kind of research exploration first that L2 many L2s are interested in that basically could be good features for not just roll up get, of course, but like all clients that are willing to spend attention on the L2 side to implement and support even before say we get some sort of formal Common core off the ground just to basically have these features there and available. And I think again it makes much more sense to actually go by what people want, what teams want, rather than to just be opinionated about which features to implement and chip. Okay, do we have anything more for the score? We also 23 minutes over the official window. Otherwise again, I think what would be very valuable for us in general, like I think we've now heard at Proto. Thank you very much. That was very useful feedback also from a few people in chat from Roberto and from D.C.
01:20:00.133 - 01:20:57.545, Speaker A: here, any continued kind of feedback of like skepticism is probably the best. Like what are the reasons for why you might not be interested in either like you know, say roll up get or also some sort of common core participating in kind of like ever moving off of say the L1 as your target at all. But also maybe beyond skepticism. If you think in general this is interesting and you maybe specifically under some specific conditions, you think this would be something you want to participate in, then that's of course also very, very interesting to hear. So basically any thoughts, any uncertainties, any kind of ways in which this could work best for you all? I think we would be very interested in hearing. And yeah, there's a question, maybe Jorge, with you, if you could.
01:20:58.125 - 01:21:46.035, Speaker B: I think, yeah, I saw the question. Yeah. So I think in general if for example, one thing that would be super helpful at the moment going over the, we have two PRs and they're not that big, taking a Look, seeing the things the way we implemented them, looking at for example if you're from the super chain, looking at the PR that tries to merge OP get with the features implemented in prologue get and you know, taking a look at, seeing if you see some kind of red flag. So we wouldn't merge this because there is a change here that you create these other things for us. Right. So this type of thing and also giving us like some kind of hint of where the EAPS things. Not necessarily EAPs.
01:21:46.035 - 01:21:54.335, Speaker B: Right. But anything that you would like to see implemented in this role of geth. I think those two things would be tremendously valuable for us.
01:22:10.245 - 01:22:52.945, Speaker A: Yeah. And I mean I think from, from our side, the. The primary thing is really just basically the feedback on primarily the Common Core. Basically the. The specific, specifically the idea of the Common Core is that something like. Because at some point there will have to be a decision like at some point reasonably soon there will have to be a decision point of like hey, this is kind of like some initial set of features that people would want to be part of the Common Core and then which roll ups actually want to support that those features. And so it would be nice to kind of get a feeling for under which circumstances would would people be willing to participate in that.
01:22:52.945 - 01:23:44.115, Speaker A: Yeah. Okay, I think then this is probably a good stopping point for now. I think we will set up some sort of discussion place as well over on Eth Magicians or something. But I think this is a good place. But also of course we have the telegram group as well. So feel free to then continue that conversation asin for now and hopefully see many of you in person. DEFCON and then on the breakout call on December 4th.
01:23:44.115 - 01:23:46.395, Speaker A: Thank you.
01:23:49.385 - 01:23:50.285, Speaker C: Thank you.
01:23:50.705 - 01:23:50.985, Speaker A: Bye.

00:00:14.330 - 00:00:40.700, Speaker A: So welcome to day number four of Defcon. We use zero indexing here. We're a civilized company. Yeah, no, the first day was day zero. So today we're going to be talking about scaling and interoperability. Well, today in general, we're going to be talking about Ethereum 1.1 and Ethereum 2.0
00:00:40.700 - 00:00:57.966, Speaker A: and the general blockchain protocol related stuff. So first presentation we have is on scaling and interoperability. So I guess to start off, first of all, what is scalability? What do we want out of scalability? Sure.
00:00:58.068 - 00:01:33.980, Speaker B: So in an ordinary blockchain we have is that every node processes every transaction and updates every full node anyways, processes every transaction. And so the scalability of the system is kind of limited by the fact that every node needs to do everything. So we want to do is relax that assumption, but still have the properties of consensus, like non repudiation, like source authentication, contract calls, et cetera. And so scalability solutions are kind of trying to make it so that not every node processes every transaction, but that we still have security in some way.
00:01:37.630 - 00:01:59.586, Speaker A: Right now, just for statistics, right now, bitcoin one transaction per second. Mastercard processes 2000 transactions a second. If bitcoin goes up to that level, then we'll basically have full nodes processing about 1gb every 3 seconds. So not exactly sustainable for any kind of normal computer.
00:01:59.768 - 00:02:01.630, Speaker B: So we'll have ten full nodes.
00:02:01.790 - 00:02:38.762, Speaker A: Yeah, ten full nodes. And they'll probably won't be run by blockchains and influencoinbase. They'll be run by Amazon and Google, who people seem to consider as being more evil than good local companies. So, yeah, what we want is we basically want a system that know, as Dominique Williams from Pebble put it, we want a system that works by scaling out and not by scaling up. So instead of making the system continue working by having full nodes be more and more powerful, you figure out some way for it to work, even if no single node processes more than a small portion of all the transactions.
00:02:38.906 - 00:02:47.330, Speaker B: Another way, you see that is instead of just stacking blocks on top of themselves in one chain, we hope to maybe have like another architecture where not all blocks go in the same chain.
00:02:49.910 - 00:03:22.206, Speaker A: Right now, what we have as far as scalability goes, is the scale up approach, which is we say, okay, the blockchain is going to grow a little big, but we're going to make sure that light clients can still be secure and that kind of works until, of course, the whole thing just gets way too big. It might not even be possible for a single node to process all the crypto transactions that people potentially might want to do, especially if we start thinking about crypto not just as a payment system, but also for a whole bunch.
00:03:22.228 - 00:03:58.114, Speaker B: Of these dapps, and also for not just people, but also for programs and hardware. So there's basically three broad classes of scalability approaches. There's building on top kind of scaling one chain by sharding the state space and having multiple blockchains and interfacing them to gain some of the properties of one blockchain. So we're just going to kind of go through them and talk about kind of the state of research on those topics and what the trade offs are and maybe what the disadvantages and advantages.
00:03:58.162 - 00:03:59.266, Speaker C: Of each approach is.
00:03:59.388 - 00:04:01.340, Speaker B: So as far as scaling on top.
00:04:02.430 - 00:04:50.342, Speaker A: So the idea with building on top is basically keep the blockchain exactly as it is. But we try and figure out some ways for as much stuff as possible to happen off the chain, but still be secured by the chain in the long term in some fashion. So this is the first practical example is this, well, I guess micro payment channels is actually one that you don't even need ethereum for. You can do it on plane on bitcoin. And the way that works is there is a sort of special two party protocol that you can use to create, it's called a micro payment channel going from a to b. And the idea is there's a two party protocol for updating the channel. So the channel starts off containing some quantity of bitcoin, let's say one BTC and a initiates the channel.
00:04:50.342 - 00:05:13.586, Speaker A: It starts off with a puts a bitcoin into the channel. The channel starts off giving the entire bitcoin back to egg. And then there's a sort of off chain update protocol where the channel updates, let's say point 99 to 8.1 to be, zero point 98 to 8.2 to be, and so forth. And the idea is you have a network with a bunch of these channels. And if you want to make a payment, you just sort of find the path going through all the channels, update all the channels along the way.
00:05:13.586 - 00:05:21.662, Speaker A: And you use the blockchain only for eventual settlement when a channel fills up frog. Ballistic payments.
00:05:21.726 - 00:05:51.790, Speaker B: Yeah. So fraud, ballistic payments basically work by, okay, say for example for a file storing application. Instead of making a payment on the blockchain for every file transfer that you do, like every upload or every download, what you do is make a payment provably with some probability so that the people still have the same expected return from sharing those files. But you don't put as many things in the blockchain. Kind of the issue with that is that increases volatility of the return, but over time it should kind of be the same, and there's much less stuff in the blockchain.
00:05:54.210 - 00:06:54.834, Speaker A: So those two approaches work for payments. There's also a third category, which is this idea of off chain auditable challenge response computation. So just as an example of that, in some cases there's going to be a lot of computations that need to have the security of the blockchain, but which might be too expensive to do on the blockchain itself. The property here is the data involved in the computation is not necessarily too large, but the computations are very large. So zero knowledge proof is one example. So something like verifying skip takes six milliseconds inside of CRT plus plus might end up taking 60 milliseconds inside of the Ethereum jit vm. Another truth coin is actually another really good example, because what they need to do is truth coin is like this decentralized oracle that does sort of shell and coin like stuff, but for many bets, many decisions at the same time.
00:06:54.834 - 00:07:15.106, Speaker A: And the way it works is that it uses these matrix algorithms to try and figure out which voters are more sort of globally compliant with the entire consensus, so they can reward them more in order. And doing that matrix math, as you know, takes o of n cubed operations, which for fairly large matrices is pretty expensive.
00:07:15.218 - 00:07:38.862, Speaker B: Yeah. So basically the idea there is that the blockchain acts as something for punishing these oracles. If they don't come up with the right result, then you can basically check it on blockchain and remove a security deposit from them. And if they do, then you don't need to do anything. And the computation happened off chain. So basically on chain everyone does everything, and so you only really need that for when things go wrong. That's kind of the paradigm there.
00:07:38.916 - 00:07:52.210, Speaker A: Yeah, by default you trust, but you have some period during which anyone can challenge. If someone audits and they find something wrong, they can sort of pull the computation down to the blockchain. And if that ends up being wrong, security deposits lost.
00:07:53.750 - 00:07:54.354, Speaker C: Cool.
00:07:54.472 - 00:07:57.362, Speaker B: So we're going to move to sharding.
00:07:57.426 - 00:07:58.040, Speaker A: Sure.
00:07:59.770 - 00:08:22.698, Speaker B: So one idea for blockchain scaling is to take kind of one blockchain and take the state space and split it up into subspaces, still have the same digital asset on all the subspaces, and have a protocol for moving funds and doing contract calls between the subspaces as well as a protocol for making sure that all subspaces have enough nodes in order to not introduce any faulty state transitions.
00:08:22.874 - 00:09:23.838, Speaker A: So the general sort of intuition is that if you, you could have make a new pad. So the intuition is you have a bunch of sort of substates. You could think of them as being vertices and they're arranged in some kind of dense graph structure. So we talked a bit about graphs yesterday, and then you have this sort of, sort of header chain in the middle. And so the idea is that if you are a miner on this kind of system, what you're actually doing is you're mining an edge. So when you mine an edge, what it means is that you can process transactions that happen inside of here, you're processing transactions that happen inside of here, and you're also processing the movement of messages going from here to here and from here to here. So let's say if you have a sort of multichain dap or that has some state in this little sector and some state in this little sector, then it sends off a message and the message gets stored in the outbox here.
00:09:23.838 - 00:09:49.330, Speaker A: Eventually someone mines this edge. When someone mines this edge, it gets kicked out of the outbox here. It gets moved to the outbox here. When it mines this edge, it gets moved from the outbox here, the outbox here, and eventually it sort of makes its way over here. And then for the header chain here, the idea is that basically all of these sort of mind edges all make their way into the header chain. And the header chain just sort of maintains the global order of what order? Of the entire thing just by keeping track of all the headers.
00:09:49.410 - 00:10:28.514, Speaker B: Yeah. And so the reason that the header chain is really important for this type of architecture is that because everyone uses the same digital asset, if you were to have, say, one of these substates not really coordinated with the other ones, you'd have one substate that has much lower security than the other ones. And then you would basically by introducing a multi state transition in that substate, impact all the other ones because they're all using the same digital asset. So the fact that everyone shares some piece of consensus is important because that's what you use to make sure that kind of all your checks, to make sure that you don't have insecure substates occurs, right?
00:10:28.552 - 00:10:28.754, Speaker A: Yes.
00:10:28.792 - 00:10:44.218, Speaker B: So we call this kind of like the fragility problem. If something goes wrong in one substate and not every node is processing everything. So for any given node's perspective, you'll never know 100% that something didn't go wrong in one of the substats that you didn't process. What you can do is kind of challenge response protocols, right?
00:10:44.304 - 00:11:46.574, Speaker A: So that's the first approach. So the idea behind challenge response protocols is that if you think about a block, a block, you have a header, then you have some set of transactions, and then you have a state tree over here. Then there's going to be some subset of state nodes that the block ended up modifying while processing, processing each one of these transactions. So what you realize is that if a block is invalid, then what that means is, first of all, it could be just be that the block is badly formatted, which is just very obvious to detect. But it could also mean that one of these transactions at some point has some state transition that's invalid. And so the idea is that if an attacker makes a block on one chain and that block is invalid. So first of all, if the block is actually invalid, then what some good guys can do is they can basically provide a merkle tree proof of the exact set of changes that transaction was supposed to make.
00:11:46.574 - 00:12:28.618, Speaker A: And people can see that the changes that the attacker made are not the same as the changes that the attacker was supposed to make. Now the other problem, of course, is, well, what if the attacker just publishes a block, but does not publish all of the data? So that's going to be very obvious to people on that chain. But the problem is if the data is not there, then there's no way to come up with a direct proof that it's invalid because there's just sort of no data. Theoretically, if Bill Gates turned out to be generous and give the attacker $100 million, there could theoretically be something legitimate that happens to give the attacker $100 million. But if the attacker doesn't supply the data, then there's sort of no way to know. So that's where challenge response comes in. Yeah.
00:12:28.624 - 00:12:59.346, Speaker B: And so the idea would be that if you issue a challenge of some particular state transition and the response is never provided, that you kind of would assume that that state transition is not valid. But kind of the issue with that is that you basically require people to be giving these challenges and looking for where it went wrong. But if there's no cheating, then there's no incentive to do that. So kind of an active delivery ends up being that there is a non zero amount of invalid state transitions.
00:12:59.458 - 00:13:17.690, Speaker A: That's one problem. The other problem is this sort of fragility issue, which is that if an attacker DDoS is the network, then the default state is for blocks to get processed and therefore blocks might end up surviving whatever the entire challenge period is without getting challenged, even if there's actually something wrong.
00:13:17.760 - 00:13:31.598, Speaker B: And then if you have an invalid transition that's only discovered much later, then the effect of that transition could have propagated to many, many things. And we might have to roll back like 100,000 locked if you want to kind of fix that. And so that's kind of like bad.
00:13:31.764 - 00:14:29.042, Speaker A: Yes. So the somewhat more stable algorithm for dealing with this problem is this jury selection approach. So idea behind jury selection is that, let's say that, okay, I mine this edge, then what the heterochain, then what the protocol says is, okay, randomly from all of these little subsets together, I'm going to randomly select 200 nodes weighted by stake. So this is a proof of stake mechanism. There's actually no way to translate it into a proof of work paradigm, which is actually, by the way, another reason why proof of stake is superior. The idea is you weighted by stake, you randomly choose some 200 nodes, and basically a majority of those 200 nodes have to sign for the block's validity. And the way that those 200 nodes know if the block is valid, because there might be a node from here and that node might not be ebitdrack of the state at all.
00:14:29.042 - 00:14:54.314, Speaker A: The way you do that is that the voter provides the block with the state route transactions. But right now in ethereum over the network, the thing that gets sent is block header plus transactions. But here the thing that's going to get sent is block header plus transactions plus whatever subset of the state ends up being manipulated during that block. And then this whole chunk by itself can be validated even by someone who has no prior information at all.
00:14:54.512 - 00:15:02.734, Speaker B: And kind of theoretically that has no cheating in the natural blue room because it's basically like forcing a challenge response on every block, kind of, yeah.
00:15:02.772 - 00:15:30.420, Speaker A: So the idea is in order for an attacker to be able to successfully cheat on this thing, just purely by statistics, the attacker has to have something like 30 or 40% of the entire active stake in the network. So you have sort of the benefit of only 200 nodes validating each block, but without the cost of there only being sort of 200 nodes protecting the system, because every node is like statistically protecting the system, even though it's not actually protecting it each and every time.
00:15:30.810 - 00:15:42.022, Speaker B: So you have like a probabilistic rather than deterministic guaranteed, but it's still quite good because you can increase the number of nodes required and that will make the amount of stake required to attack it larger.
00:15:42.086 - 00:16:26.898, Speaker A: Basically the probability of the thing screwing up is negatively exponential in the number of nodes involved. So that's one. So the last thing with the hybrid keyboard approach is need a protocol for growing and drinking the thing. So you could just fix it to twelve dimensions and say, okay, there's 4096 substates. But the problem is that what happened, first of all, initially that 4096 might be way too sparse, and then eventually it might end up not being enough. And so one thing that needs to be figured out is some kind of mechanism for growing the graph. So one option is to just, if it gets big enough, then eventually you add a dimension.
00:16:26.898 - 00:16:44.010, Speaker A: So then if you just sort of keep on adding dimensions, the choice that you have is, first of all, when you add a new dimension, do you make the new cubes empty by default and sort of just use incentive mechanisms to try and subsidize new people being on those cubes instead of on other, or on those vertices instead of on other vertices?
00:16:44.090 - 00:16:52.730, Speaker B: Or you could wait for each substate to have twice as many nodes as necessary and split each one in two and basically add another dimension to the hypercube.
00:16:52.810 - 00:17:24.298, Speaker A: Yeah. So the choice is do you start a new one empty or do you actually try and split them in half? Problem with split. So splitting them in half feels more elegant and automatic in some respects. The problem with it is that you might have daps that were very tightly connected, but now they're suddenly much less connected and so their gas costs suddenly go way, way up, which is kind of annoying because the contracts are kind of stupid autonomous agents and they have no way of figuring out how to deal with the problem. Cool.
00:17:24.384 - 00:18:25.760, Speaker B: So we're going to move to multichain. Yes. So the idea with multichain scaling solutions is that instead of taking kind of one consensus group with one digital asset and trying to split it without losing the properties of it, what we do is we take many consensus groups with many different assets and try to interoperate them in order to gain some of the properties of scalability. So basically there's different types of interoperability. You can have this type of interoperability called atomic interoperability, which is basically based on this tier Nolan primitive, which is this really cool idea where you'd basically make a contract on one of the chains that says if X, such that the hash of X is equal to some y that's in the contract is provided, then you would do something.
00:18:27.650 - 00:18:27.966, Speaker A: And.
00:18:27.988 - 00:19:46.230, Speaker B: Then otherwise, if some time pass time passes, then do something else. So the idea is that if Alice and Bob wanted to exchange tokens between the two blockchains, and they kind of know each other, and they know that they want to do this, but they don't trust each other so much that Alex would just send Bob tokens on her chain, and then kind of trust that Bob would send her back tokens on the other chain. This kind of forces either both trades to go through more than either. So the way it works is basically, Alex will make a contract that says if the pre image of some hash is provided, then send money to Bob, and she makes that hash so she knows the pre image. Otherwise, if some amount of time passes, I'll send the money back to myself, and then Bob will see this contract and make another contract on Bob's chain, chain B, and do use the same hash he did, another pre image, send money to Alice if that pre image is provided, and otherwise it'll send money back to Bob. So basically, what will happen is if Alice wants a trade to go through, she'll provide the pre image of the hash and to take her funds on Bob's chain. And then Bob will therefore have the pre image of the hash and be able to take his funds on Alice's chain.
00:19:46.230 - 00:20:10.190, Speaker B: So basically, without having to either the consensus groups do kind of any SVB proofs, or the other consensus groups, we're able to do kind of functionality that will only happen on one, if it happens on the other, by using this kind of common secret that if it is provided, some functionality in the contract is on one part. So this type of interoperability is called atomic interoperability.
00:20:14.310 - 00:21:32.118, Speaker A: So the other kind of interoperability is the protocol level interoperability. So the difference is with atomic level interoperability, the things that you're trying to do is trying to mediate sort of cross chain interactions between users. So decentralized exchange is one example, or potentially, like cross chain operations, where something happens on this chain, only if something happens on that chain. A protocol level interop is where you would have some kind of DAp or some kind of protocol that actually on one chain that actually needs to get services from the other chain as a protocol on the whole. One example of that is, let's say that you have Ethereum, on Ethereum, you have a contract, and then that contract basically is a stable coin, and it uses a sort of contract for difference, whatever interest rate target mechanism to try and keep a dollar value of. One problem is, it has no idea what the exchange rate of a dollar to its volatile coin is. So what it does is first of all, would maintain an internal decentralized exchange to figure out the exchange rate of its own volatile coin to ether.
00:21:32.118 - 00:22:44.046, Speaker A: And then you need the exchange rate of ether to the US dollar. But the situation is, let's say that over here you have truthcoin. And truthcoin just happens to be a decentralized oracle, because it's the decentralized oracle network, and it has a much larger set of users to vote, so it has more security. So this app over here might want to ask Truthcoin, what is the price of ether in us dollars? And the idea is that this chain needs to have a way of sort of directly asking this chain some question. So the way that you generally do that is you would have the Ethereum here maintain, basically maintain internally inside the chain, a light client of truthcoin. And then in Truthcoin you would have some active set of voters that are just continuously voting on the question of what's the value of ether and dollars. Then if the truthcoin blockchain records some particular result, then the light client protocol can determine what the result is.
00:22:44.046 - 00:23:35.406, Speaker A: So the result would be stored in the state tree. And then basically the lite client protocol would ask some node to provide a merkle tree proof of what is the value of a dollar and this Merkel tree inside of transaction data. The lite client protocol would reward whoever provides the proof. And then that's how it would know what the value of ether to a dollar is. And then the other thing that you can do is that based on who provided, who said the transaction, or rather based on the other thing you can do is you can also peek into the Truthcoin blockchain and you can determine who contributed to this particular vote. And then you can give them Ethereum assets inside of Ethereum. So you're sort of buying services from Truthcoin users inside of Ethereum, and you're getting back this truthful feed of what the result is.
00:23:35.406 - 00:23:39.886, Speaker A: And then given the results, the DaP would be able to do whatever it needs to do with the price of a dollar.
00:23:40.078 - 00:24:29.540, Speaker B: So that's kind of an example of, so that's kind of an example of sub protocol level interoperability, where you would build in an Ethereum contract an SPB client of some other chain, so that people on Ethereum would be able to know some facts about people on another chain. But if you wanted to have chains actually share security, you would need to build that in on the protocol level, where not just kind of nodes who know what these subcontracts are doing would know what it is, but the actual consensus level protocol would know. So the idea with protocol level security sharing is that you would build the consensus of another chain into your own chains. Consensus so that you could, for example, buy checkpoints, buy timestamps. You could use another chain of services in order to.
00:24:30.710 - 00:25:15.214, Speaker A: So the general idea with sharing security, I think, is more that, let's say you have ten chains, chains c one through c, ten. Each one of those chains has 500 users and $500 million of capital. The problem is, how do you make each. If you just do this multichain approach by default, if the whole thing has $5 billion of capital, or if the whole system has $5 billion of capital, then if you have more applications, if you go from ten to 100, then each of them is down to $50 million of capital, and each of them is down to $50 million worth of security and so forth. So, problem is, how do you have chains that are only processed by a few, but that are only processed by relatively few nodes without having this problem that each chain only has a small amount of security.
00:25:15.332 - 00:25:59.310, Speaker B: Right. One thing that we haven't mentioned yet, one of the benefits of multichain scaling, is that if a chain is compromised, it won't necessarily affect other chains as much. And you can provide services on chains at a given level of security, which means at a lower cost to some users who don't need as much security on that chain. So if you want to provide a lower cost and still have high security, what you can do is basically buy security from other chains. And to do that, you would basically need to interoperate your chain with this other chain at the protocol level, and basically have kind of light clients and full clients agree that they'll use some checkpoint on some other chain in order to authenticate.
00:26:03.170 - 00:26:38.138, Speaker A: Challenge response, jury selection. We already discussed those in the context of hypercube, in the context of multi chain, actually. Well, challenge response, in my opinion, is not nearly as good as jury selection. So probably talk more about how jury selection works in multichain. So the idea is you would have a chain, and then on that chain you would have this kind of shelling coin consensus thing, and you have a bunch of users that participate in it. And by participating, we basically just mean having a security deposit on here. Then you have some chain x.
00:26:38.138 - 00:27:59.730, Speaker A: And that chain X wants to leverage this little contract for its security because x isn't big enough by itself. So what it would do is basically this consensus contract is kind of like truthcoin. It's this decentralized, sort of massively multi shelling coin type oracle, except the thing that it's voting on is it's voting on the first. So what it provides is it provides a block, and the block provides, it's got a state route, it's got transactions, and it's also got a timestamp. And from the transaction tree it's got a merkle tree here and it's got a Merkle tree here. So the question that this thing is voting on is it'll take the and of three things. Number one is, does the timestamp on the block equal to the actual time by is data available? Do we mean if you descend from the Merkel route, is your data floating around somewhere in the network corresponding to all of the leaves of this, going all the way down to the bottom level? So the idea is that this big thing uses votes on this statement.
00:27:59.730 - 00:29:08.950, Speaker A: Did the block come at the right at the time that it said that it came at? And does the block have data available? So then what you have is you would have a trustworthy source of blocks that have data available and that came at a particular time. Now, given that, if you assume that that mechanism is trustworthy, then in turn out consensus becomes trivial. Because your consensus algorithm basically is that if you imagine blocks that are at some particular height, your algorithm is a block at a particular height is only valid if it is the first valid block at that height. So if it's over here and then some new one comes along, this one automatically gets rejected, even if it eventually grows longer. And the way that you defend that is, well, the way you sort of make this work is that, first of all, you know that the way you determine the time is by checking the URL to see if the timestamp match, to see what the timestamp is. The way that you determine validity is first of all, if the data is not available, then you say it's invalid. Now it could be that the data is available, but the block is invalid.
00:29:08.950 - 00:29:16.590, Speaker A: But then because the data is available, anyone can audit the block and anyone can come up with a merkle tree proof that it's invalid if it is invalid.
00:29:17.250 - 00:30:10.240, Speaker B: So this is kind of like full client security. This does like all of the securities of a blockchain. One thing to note is that full clients and light clients have different amount of information that they can use to authenticate different things. If you have security for full clients, not for light clients, then you can do something kind of much less than this in order to help the like clients find the authentic chain. So basically, one thing that's important for multichain solutions in my view, and this is kind of like my vision for Ethereum 2.0, is that we would have like one light client protocol, at least for all of these chains, so that a single light client can access surfaces from all these chains. And so for example, if we have some chain that's kind of secure as far as all the full clients are concerned, but the light clients can't tell whether some fork came later or not because there's no cryptographic proof of that.
00:30:10.240 - 00:30:58.640, Speaker B: What you could do is basically have the people on this chain, whenever there's a fork, or every so often buy a checkpoint from a shelling coin game on another chain, which would basically, instead of going on this block and checking the timestamp, it would basically just ask what is the consensus block 1000 blocks ago? Because that's kind of longer than the fork length. And then light clients who somehow managed to get on here can find a checkpoint on this one, which you can then use to authenticate the current state there. So in this kind of model, we can make like a tree of checkpoints so that light clients who only has one or a handful of checkpoints could authenticate the current state of other chains. And even though if those chains are secure for full clients just by themselves.
00:30:59.490 - 00:31:38.406, Speaker A: So the point is here is there's a bit of a trade off between to what extent you support white clients and what level of standardization do you want. So the nice thing about this kind of data availability protocol is that here you actually need to standardize almost nothing for all of these chains to share security. The only thing that you need to standardize is the Merkel tree protocol because you need to have a way of voting on data availability. Everything else is potentially completely open. You're not standardizing whether you're using proof of work or proof of stake. You're not standardizing whether you're using ghostern or some other mechanism. You're not standardizing any kind of state transition rule.
00:31:38.406 - 00:31:45.786, Speaker A: But if you want to go into supporting more sort of light client functionality, then you might need to end up standardizing more things like checkpoints.
00:31:45.818 - 00:32:09.086, Speaker B: Yeah. So for example, if you wanted kind of ultimate light client functionality, what you would do is have all of the chains be EVM and have the consensus algorithm be embedded in EVM code so that all the light clients can just use EVM to authenticate the state transitions and to authenticate anything that they need. And basically that makes their code base smaller than say, if they had to interoperate between chains that have different protocols.
00:32:09.118 - 00:32:09.410, Speaker A: Right.
00:32:09.480 - 00:32:29.580, Speaker B: If you had a light client to interoperate bitcoin and some other chain who pack the services from both, it'll need more code than if bitcoin or VVM, because then it would just kind of use the same code base to authenticate transitions on both chains. So the more you standardize, the more lifetime friendly you can be, which we're already.
00:32:30.210 - 00:32:54.740, Speaker A: Yeah. So the last point here, first of all, this idea of checkpointing. And so the question is, in this multichain context, can we come up with some kind of litecoin protocol that allows proof of stake clients to still be secure or to still securely determine the current state of some particular chain, ideally with a very low amount of information.
00:32:56.390 - 00:33:44.430, Speaker B: Yeah. So something else that we haven't talked about yet is so one cool idea is that you might be able to use not the checkpoint between the chains at the protocol level to satisfy, to do the like client protocol, but actually the interface chain that's on top. Actually, have we even talked about interface? No. So basically, if we want to do atomic interoperability between two chains, so basically those two chains have the Cheernolan primitive. What you can do is you can make a third consensus. That consensus group that includes is basically a side chain for both of those consensus groups. And that can be used to pair up different people who want to do interoperability using this journal and primitive.
00:33:44.430 - 00:34:37.326, Speaker B: And so I'm basically thinking and hoping that we can use the exchange here to help light clients figure out where to go, because light clients are going to, in a multi chain context, will probably not keep their tokens on all of these chains. You keep your tokens on a small number of chains which are more liquid, more stable, and then you kind of sell them for the tokens that you need in order to purchase services from some chain. And you have to go through an exchange to do that anyways, need to authenticate that exchange. And so then you might be able to use that exchange which isn't even on the protocol level in order to authenticate which fork on these chains to choose as a light client. So basically, if we build the interoperability kind of on top using atomic interoperability, it's less fragile than if you were to extend one of these consensuses to include the other one. Because if this chain died in this case, it wouldn't affect this chain. This chain doesn't know about this chain.
00:34:37.326 - 00:35:41.450, Speaker B: It just knows about some tirnolum contract that it has on itself. And it doesn't know what chain that's interoperating with. But if this chain's consensus was actually extended to that chain's consensus, and this chain died, this chain would now have to switch from buying services from this chain to buying services from another chain, which is kind of a whole other problem. One way to handle that, that I've kind of thought of is if you don't have contract creation on an EVM chain, and all the contracts are in the genesis block, then two chains with exactly the same contracts in the Genesis block are going to be providing the same service. And so you would be able to switch from asking a service chain to another chain that has the same contracts. Kind of another paradigm with this multi chain stuff is that instead of having kind of ethereum like general purpose chains, you'd have ethereum like application specific chains where basically only some contracts will be there, you wouldn't be able to create contracts. And the idea with the application specific chains is that basically, if you know that your application doesn't need any more interoperability with anything else, then you could have consensus groups just around those contracts, and you don't need to have the same consensus group do all these other contracts.
00:35:45.310 - 00:35:48.700, Speaker A: I think that's basically all that we wanted to discuss. So, questions?
00:35:52.530 - 00:35:54.894, Speaker B: Could we get the camera real quick?
00:35:54.932 - 00:35:55.326, Speaker A: Sorry.
00:35:55.428 - 00:36:03.070, Speaker B: Hold that thought. Thank you for your understanding.
00:36:15.690 - 00:38:00.280, Speaker C: Okay, so in the very important special case where the state is just a bunch of account balances, there's a common and very old idea for scalability, is that instead of atomic transactions, which take some value from here and credit some other account, you split these transactions into two, into a debit and a credit transaction. And whatever service needs providing in exchange for this transfer, you make it only conditional on the debit transaction, and then you settle the credit transactions later when you have time. And this way you can do interoperability between different chains. Because on one chain, if you compartmentalize by accounts, then you can basically generate debit transactions as fast as you need to, and then you can do the debits. And one of the genius ideas of bitcoin, which I think didn't receive as much attention, is that what they did is that they put together the credit and the debit, but the other way around. So it's not atomic in the sense that something is taken from here and deposited there, but the other way around, they noticed that you don't need the credit transaction before you actually want to spend that amount. So what a bitcoin transaction actually does is that it deposits the amount and immediately takes it away.
00:38:00.280 - 00:38:37.050, Speaker C: So they don't even have their explicit balance state. So in the bitcoin network you don't have. In the state you don't have the explicit balance. And I think that in ethereum, since the balances are part of this state, maybe we should consider splitting up transactions that modify more than one variable. In particular, in case of transfers, they modify two balances to split them up into two transactions and make one transaction conditional on the balance and make the other transaction conditional on the success of the first transaction.
00:38:37.130 - 00:39:00.414, Speaker B: So that is kind of what the atomic protocol does. It basically makes sure that one transaction can only go through if the other one can go through, but it does it without requiring any information from one instance group. In the other instance group, except for the supreme hash, which is kind of more lightweight than having this chain check if some transaction went through on the other chain, because all you need to know is whether or not something that hashes is provided.
00:39:00.562 - 00:39:20.880, Speaker C: But that's interactive. But here you can carry the proof with you. So basically, if you have a successful deposit, a successful debit on one chain, if it gets confirmed, it's a finite package of information that you can carry away and you can present it at that chain and it gets deposited without.
00:39:21.490 - 00:39:25.140, Speaker B: So that's either a sub protocol level or a protocol level thing.
00:39:25.990 - 00:39:30.850, Speaker A: That's more like the sort of intra chain scale sharding type approach. Yeah, sure.
00:39:30.920 - 00:39:34.366, Speaker B: But you can do that also by extending consensus in between chains.
00:39:34.398 - 00:40:02.010, Speaker A: Yeah, you could, but it fits more in the sort of single chain paradigm. Yeah, it's a sharding approach. It has, I guess, similar properties to other sharding approaches. The main issue, of course, is that what if you have a debit somewhere and then you try and use that as a proof to generate a credit twice? Or what if you're ineligible spending and so forth?
00:40:02.430 - 00:40:33.714, Speaker C: But that's a local thing, right? So if you want to debit twice using the same, you want to credit twice using the same debit transaction, the debits of that target account, they're on that chain. So you prevent double deposits and there you prevent double withdrawals. Instead of preventing double spends, you prevent double withdrawals and double.
00:40:33.842 - 00:40:39.970, Speaker A: So what if on some local chain I make a withdrawal and then I immediately double spend that withdrawal locally?
00:40:40.130 - 00:40:43.414, Speaker B: Well, forks are, we haven't talked about force in this.
00:40:43.452 - 00:40:43.798, Speaker A: Yes.
00:40:43.884 - 00:41:50.426, Speaker B: So force always basically lead to you having to wait for interoperability functionality because anything can be rolled back in a fork. So that's why having non forgive chains, if they're possible would really help interoperability solutions and blockchain scaling solutions. One thing that I haven't mentioned yet, which I really like to mention, is this idea that one of the things that I find really helpful for thinking about blockchain scaling is that the client is serving the user and the client uses chains to serve the user. It's not that the client is serving the chain. And so if a user has a consensus group here, I think they would prefer to not have SPV proofs of some other consensus group. They're not interested in being injected into their consensus. That's kind of why I prefer this idea of atomic level kind of interoperability on top rather than interoperability in protocol, because it kind of lets the client have more specific narrow consensus that it's keeping and it is kind of more restricted.
00:41:50.426 - 00:42:47.220, Speaker B: There's less you can do if you don't have this kind of proof of information about what happened in other chains. But the insight is basically that clients can get SVP proofs from both chains without having to get them from one chain, right? So any client that's looking at both chains will know whether something went through on the other chain. But that doesn't mean that you necessarily need to force every client that's on one chain to know about what happened on the other chain. Some of the idea of these interoperability kind of interface chains that know about both chains is that those clients that are watching for both chains can form their own consensus group in order to interoperate these two chains without actually injecting information from the consensus into other consensus, which I kind of regard as inconsiderate unless it's necessary. I haven't found many people to agree with me on that, though in particular in light of kind of like block stream, two way pegging stuff which you haven't talked about yet.
00:42:50.230 - 00:43:14.620, Speaker A: Is that the side chain discussion supposed to be later. Okay, how do you see the upgrade or migration path from Ethereum 1.0 to 2.0, specifically in regards to original blockchain? So from 1.0 to 1.1, first of all, 1.1 is just going to introduce some moderate things like proof of stake and event trees for that.
00:43:14.620 - 00:44:02.866, Speaker A: The approach is to have a. Is to have a sort of mechanism of voting on protocol upgrades. So it's not going to be a minor based mechanism because it's going to be in miners interest to keep proof of work forever, but something stakeholder driven, where if you have your coins in a contract that has a storage at some particular key correspond to some particular value, then you're basically voting for the protocol to get upgraded. And once there's some majority in favor of an upgrade, then I think the idea is that the original chain was sort of suicide after some particular amount of time. So all blocks after block numbers, say 1.3 million, will just be invalid, and the clients would have time to download a new client, and that new client would support the new chain in some fashion.
00:44:02.898 - 00:44:10.474, Speaker B: And so that would work for Ethereum going from 1.0 to 1.1 and 2.0 if we're using starting, yes, but if we're using multichain, well, if we're using.
00:44:10.512 - 00:44:17.038, Speaker A: Multichain interrupt and Ethereum 1.1 will be Ethereum 2.0. The only difference between one one and 2.0 will be just a set of tools for.
00:44:17.124 - 00:45:04.240, Speaker B: Yeah, and also kind of like client protocol or full client protocol that you serve all these chains or buy services from all these chains. So then basically that's the direction that we're going then. Theory of 2.0 is kind of an interface layer between all these blockchains. Kind of. Imagine if this browser let me buy services from a whole host of chains where most of the chains are actually application specific, as in specific to some DAP, rather than being this kind of general purpose chain where you kind of put everything, the chain sharding and the atomic, atomic multichain, are those two.
00:45:05.170 - 00:45:08.080, Speaker A: There's sort of competing approaches, I would say.
00:45:09.490 - 00:45:10.830, Speaker B: Could you have both?
00:45:10.980 - 00:45:11.982, Speaker A: Yes, you could.
00:45:12.116 - 00:45:16.698, Speaker B: Could you have the sharded chain but.
00:45:16.724 - 00:45:21.634, Speaker A: Then use this for, as an interrupt thing? Yes, you could.
00:45:21.752 - 00:45:43.020, Speaker B: Okay. And I think that that might well be a good idea, because if clients are going to want to keep their digital assets in some stable token, then we're probably going to want them to be a lot of transactions on the chain where they hold their tokens. Right.
00:45:44.110 - 00:46:02.080, Speaker A: If we want to have a stable currency across the entire system, the other approach is that we don't necessarily need the units to be actually be transferable. We just need a whole bunch of stable coins. And we need to make the stable coins all target the same standard. And then it'll just be an exchange. It'll be a floating exchange rate, but the floating exchange, it will just always happen to be one.
00:46:02.850 - 00:46:47.790, Speaker B: But then some chains will kind of have any more stable than those. Yeah, so people will tend to keep their money on those, right, true, because most of my clients don't want to be exposed to speculating on the success of some DAP. They just want to be using it another nice thing about atomic transaction that we have in that engine is that you could pay for a contract call or some functionality on another chain using fees on one chain. So basically someone would see that you want to call some contract and they'd be like, yeah, okay, I want tokens on the chain that you're paying me on. And then they'd run the contract for you in exchange for those tokens. So you might not actually need to change to buy tokens on some Dapps chain or to use the DAP. You could just pay for it on your chain and have the contract happen on the Dapps chain.
00:46:47.790 - 00:47:17.410, Speaker B: Can people running on the other chain provide that service for you? They would have to interact on your chain as well. The clients would have to watch it. The consensus wouldn't necessarily. So only the clients that are providing that service would have to watch it, basically because they have to get the hash value on the provider, but they have to want your chain currency.
00:47:17.490 - 00:47:49.966, Speaker C: That's right. Something more primitive. For example, you form a special contract where as soon as it gets deposited the right amount, then a new chain is started where there's no mining. You're just using that deposit and you can only unlock that contract in the original chain if all the tokens are destroyed in the first chain, in the small chain.
00:47:50.158 - 00:47:52.020, Speaker B: And how would that other chain know?
00:47:53.030 - 00:47:54.722, Speaker C: Well, there's a proof that you can.
00:47:54.776 - 00:47:55.380, Speaker A: Right.
00:47:57.830 - 00:47:59.470, Speaker B: And they don't have to wait for confirmation.
00:47:59.550 - 00:48:03.160, Speaker C: Yes. Which is, okay.
00:48:07.210 - 00:48:12.090, Speaker B: So I'm not sure that's necessarily more primitive. It seems a little bit more sophisticated.
00:48:15.430 - 00:48:17.570, Speaker C: Well, it doesn't require an exchange.
00:48:18.710 - 00:48:19.460, Speaker B: Right.
00:48:21.830 - 00:48:48.540, Speaker A: This kind of approach is nice because it's also a way of doing cross chain exchange without ever having actual basic, without ever actually having an exchange of different tokens that are just across different chains at the same time because you can expect on chain exchange to be very efficient, but then interchange stuff will probably have higher fees. But here it's between the same currency and here it's the same currency. So because the rate will always be like one, the spread will probably be very low.
00:48:49.710 - 00:48:51.926, Speaker B: So you said the same currency.
00:48:52.118 - 00:49:06.100, Speaker A: Well, no. So I'm saying you have a here, you have b here, and you have a here and you have b here. Exchange between these two is just on chain. So it's very efficient. Here the exchange rate is always one. So there's an opportunity for variable risk arbitrage and same here.
00:49:07.830 - 00:49:18.086, Speaker B: Another thing you do though is just have security deposits and matching here and basically require people to be online when they do the exchange. So you can do atomic transactions here rather than peg transactions here.
00:49:18.108 - 00:49:20.022, Speaker A: We can do security deposits for everything, can't you?
00:49:20.076 - 00:49:20.758, Speaker C: Yeah, you can.
00:49:20.844 - 00:49:41.056, Speaker B: So, security deposits are the best because it lets you make an ash equilibrium really strong. Because you can basically say that if you deviate from it in a detectable way, your security deposit goes away. And we'll probably talk about that during an approved state panel. Yes, definitely it.
00:49:41.238 - 00:49:41.776, Speaker A: Okay.
00:49:41.878 - 00:49:42.850, Speaker B: Anything else?
00:49:43.620 - 00:49:44.670, Speaker A: That's it. Cool.

00:09:28.805 - 00:09:29.345, Speaker A: Hello.
00:09:31.085 - 00:09:31.825, Speaker B: Hello.
00:09:32.325 - 00:09:33.105, Speaker C: Hello.
00:09:42.525 - 00:09:43.305, Speaker D: Hello.
00:09:45.765 - 00:09:46.865, Speaker C: Hey Manny.
00:09:47.735 - 00:09:48.475, Speaker D: I.
00:10:44.475 - 00:10:45.295, Speaker E: Hello.
00:10:48.675 - 00:10:49.455, Speaker C: Hey.
00:10:51.155 - 00:10:51.975, Speaker A: Hello.
00:11:23.925 - 00:11:25.265, Speaker E: What can you say?
00:11:30.535 - 00:11:32.755, Speaker C: Yes, the gift that keeps on giving.
00:11:33.335 - 00:11:35.435, Speaker E: What kind of language is that?
00:11:39.855 - 00:11:43.555, Speaker C: As long as you do everything to go language it works.
00:12:24.595 - 00:12:41.335, Speaker B: Hello everyone. Welcome to the peer desk. Breakout call number seven I think so that's the article. Do we have any client updates?
00:12:47.615 - 00:12:49.595, Speaker A: Yes, thank you.
00:12:50.215 - 00:14:16.745, Speaker D: Yes. So for Prism actually so when we change the 32 data column subnets to 128 it goes on kind of lot of issues on Prism Basically we had a race condition when we had a lot of gossip subtopic and a very few nodes like during like in a cultosys DevNet with only two or three nodes. So yes, we had rise conditions. This rest condition didn't trigger before but now with 128p it's used to trick not always, but quite often and so we were not able to sync fullnode it was okay for super node but not for full node as well we had issues where with initial sync because of that so we were not able anymore to start a node not at Genesys but after this is fixed and the request is in review. But also we work on the DAC column validation pipeline. Before we had multiple places in our code where we used to check if a data column was valid. Now everything is centralized only one pipeline as this pipeline is used everywhere across Prism.
00:14:16.745 - 00:14:47.135, Speaker D: And also with Kev here it's more yes with Kev really have many work on for us on the replacement of CKZG library to by go by the go KZG library for Prism and it seems very promising. Maybe initial has other thing to add but for me it's. That's pretty that.
00:14:49.395 - 00:15:32.585, Speaker F: Yeah. So one of the main things I've been focusing on is measuring our data column building performance in Prism. So over the past two weeks when we have run Kutosys devnets we've run into a lot of issues with block building. So with a lot of help from Kev I think we managed to narrow it down to the CKZG library. So we're still not sure yet on why it's so inefficient for Prism but when shifting over to Go KZG Prism performs a lot better. The devnet can run in a much more stable manner. So I guess we'll have to look further why that's the case.
00:15:38.805 - 00:16:02.225, Speaker E: Do we sorry just to intersect but maybe we can do that later. I don't know. Shall we but do if gokczg fixes that do we still care? Do we care why it didn't work with CKCG for academic reasons or because you want to have CKCG as a fallback.
00:16:04.565 - 00:17:01.445, Speaker F: Well, right now we use gokzg by default so we can. You can use CKZG in Mainnet with the flag, but you know, by default it uses gokzg so. But what we want we wanted to find out is that like why Prism can't perform to like an acceptable manner with ckzg in the sense that just building the cells and the proofs took, you know, like in the. In some worst case scenarios it was like five to eight seconds which is, you know, not reasonable. So with, with gokzg the numbers are a lot more reasonable at least compared to the benchmarks that have been done on why it has been bad on our on for Prism we would I pass Kev some profiles that I took. Maybe he has some ideas. But yeah.
00:17:03.945 - 00:17:22.275, Speaker C: Yeah, I guess it's just the personal curiosity for me as to why it's not working. The pr, the flag that switches between CKZG and gokazg is currently in a pr. Sounds good.
00:17:22.355 - 00:17:24.095, Speaker E: We can discuss it more later.
00:17:25.515 - 00:17:26.335, Speaker C: Yep.
00:17:36.355 - 00:17:40.415, Speaker B: Thank you. Lordstar.
00:17:46.405 - 00:18:30.297, Speaker G: Yeah, so we tried doing ketosis testing last week with other clients. So Lotsa supernote to Lotstra is working and but we. So it was not successful. Lordstra was requesting so it was not getting all of the data columns. So I for example tried Lotsa supernode with I think Tegu supernode as well as Nimbus supernode. I did not try it with Prism so I try so I did that separately. So just two nodes devnet on kurtosis and it was not work.
00:18:30.297 - 00:19:03.485, Speaker G: It. It didn't. It was not successful. At least since both were supernodes it should have been successful. And so then there was this change by Barnabas regarding CSC in metadata, CSC type in metadata and now I think we need, I need to revert it and then maybe try with some of the client that is compatible and then basically move forward from there.
00:19:09.275 - 00:19:17.015, Speaker B: Thank you. And Lighthouse.
00:19:19.075 - 00:19:43.085, Speaker A: Yep. Yes, Jimmy here. So in the past two weeks we've managed to merge our DAZ branch changes into our main branch. So we have everything on our unstable branch now. And we've also fixed a few minor issues with Lecturer so we should be able to test Lectra soon. I think the code is ready. We just haven't tried out on Lecturer.
00:19:43.085 - 00:20:33.825, Speaker A: We've also updated our spec test to work with Alpha Pipe. That's all working. We've got metadata v3 implemented so we have DevNet 2 ready. I think at the moment the one's working on getting the next log block configurable and I'm hoping to get checkpoint sync working the next week or so. We've also worked on other small things like caching, error handling more thing. I've done a bit of testing on the Fetch fetching blog from EL test mentioned previously so that the super node can fetch blob on the EL and computer data columns on behalf of other nodes. I've tried testing that increased flop count.
00:20:33.825 - 00:21:11.259, Speaker A: I tried 32 blobs and tried 16 blobs as well. 32 seems that seems like a bit of a stretch. I managed to have a few blocks created suppose before that session deadline and that was okay. But I think the open rail miss rate is pretty high. It seems like 16 blobs seems to perform much better than the current setup. Yeah, I'm going to do a bit more testing on this, hoping to test the results so we can think about having increased block count in the near future.
00:21:11.427 - 00:21:12.507, Speaker G: But at the moment it seems like.
00:21:12.531 - 00:21:22.205, Speaker A: The main bottlenecks is the computation time and the network bandwidth. But I think we're pretty close. That's all from Lighthouse.
00:21:26.825 - 00:21:27.765, Speaker B: Thank you.
00:21:30.105 - 00:21:36.645, Speaker C: Oh, so the bottleneck at the moment is compute cells and KCG proofs, is that correct, Jeremy?
00:21:37.465 - 00:22:18.075, Speaker A: No. So I think it's both the computation and the network bandwidth. So that's going to basically going to be how we decide how much blob count we're going to increase to 16 blobs seems okay with some with the machine that I was testing with. So I'm keen to try out on some more low capacity machines to make sure that it also still works for like four cores and eight core machines. Okay, so if we increase the 32 blobs I think the time takes a bit longer and we've got sometimes we'll miss some blocks but 16 blobs seems fine so far. My testing.
00:22:19.455 - 00:22:20.595, Speaker C: Okay, I see.
00:22:22.095 - 00:22:35.715, Speaker A: Yeah. So we basically need to get the block proposed and published within the 4second mark service so the other validators can attest to it. Right.
00:22:36.055 - 00:22:53.005, Speaker C: Yeah. I guess we could possibly add in that flag for parallelism because if you can spare like 2 to 4 threads then the time to compute like 32 blobs then goes down quite a bit.
00:22:54.585 - 00:23:05.953, Speaker A: Yeah, we've already doing. We're already doing parallel processing at the blob level. I guess you're talking about even more parallelization within the blob, right?
00:23:06.009 - 00:23:20.187, Speaker C: Yeah, I'm still not completely. This is sort of out of my expertise but it seems like maybe the scheduler is doing something smarter if it has intra parallelism. I'm still not completely sure.
00:23:20.291 - 00:23:20.975, Speaker A: Yeah.
00:23:30.475 - 00:23:32.615, Speaker B: Thank you. And then.
00:23:35.995 - 00:24:21.425, Speaker H: Yeah we were working on two big tasks. First is implementing for choice according to the spec this data availability check and we almost finished it but maybe we are going to refactor it before merging. And the other thing we were working was refactoring custody. It was too much prototype style before and we want to make it more suitable for production. And also we had changes with custody subnet count in ENR and metadata. That's all for Taco.
00:24:25.535 - 00:24:30.195, Speaker B: Thank you. Granting.
00:24:32.415 - 00:24:33.195, Speaker E: Hello.
00:24:33.615 - 00:24:36.567, Speaker D: So yeah, the guy that was working.
00:24:36.631 - 00:24:41.295, Speaker A: On feared us from the fellowship program.
00:24:41.375 - 00:24:50.687, Speaker D: He got some progress but he seems still cannot get cannot get Gradina to sync with the rest of the client.
00:24:50.751 - 00:24:51.233, Speaker E: So.
00:24:51.359 - 00:24:55.461, Speaker D: So we'll see depending on when the next devnet will start.
00:24:55.533 - 00:24:57.885, Speaker E: We either will give him a bit.
00:24:57.925 - 00:25:14.785, Speaker D: More time or otherwise we'll just take over take this feature and we'll try to get it get it ready for the devnet. So yeah, so the update is not very happy now.
00:25:21.895 - 00:25:53.595, Speaker B: Thank you and bus here. No. Okay, so let's move to the definite discussion. So I think Banabas can't make it today. So is anyone. Can anyone give a quick update about what is the current status of definitely 2? Is this still alive?
00:25:59.095 - 00:26:05.235, Speaker A: I don't think it has been launched. I think one of us was doing a bit of local testing and he ran into issues.
00:26:07.055 - 00:26:18.365, Speaker B: I see. And for Devnet 2 are you using what is the size of CSS? CSC. Sorry.
00:26:20.945 - 00:26:29.485, Speaker A: I think the latest discussions that we agreed that we're going to revert back to the previous U64 metadata.
00:26:30.465 - 00:26:30.993, Speaker B: Right.
00:26:31.089 - 00:26:36.165, Speaker A: I think once that PR is merged and then everyone's implemented, we should be ready to.
00:26:38.705 - 00:26:56.296, Speaker B: See. So was the DEFNET 2 was launched with 64. Right. So it's. There was no change of DEFNET 2 at all.
00:26:56.436 - 00:27:01.930, Speaker A: I mean during the past two weeks. Yeah.
00:27:02.071 - 00:27:30.295, Speaker G: So as Jimmy mentioned, DEVNET 2 has not started. I think we are still trying to get the local devnets working with kurtosis and I think we are hitting issues over that. And once the kurtosis local devnets basically we are able to run them successfully then it makes sense to go towards Devnet to.
00:27:34.015 - 00:28:39.455, Speaker B: Thank you. So yeah, so we have PR here which is reverting the previous changes and also add more comments to clarify the the type of esc. So I think I will already got many approvals there and if there's no objections then I will merge it after this call. All good, thank you. Okay, so I guess that's the latest defnete situation or do we have any other topics to discuss around defnet?
00:28:45.275 - 00:29:06.485, Speaker C: I had a question as to what was the status of just clients syncing with themselves. I think Barnabas had a message in the discord about it. So just starting up a devnet and syncing just with your nodes, one super node, I think it was in one regular node.
00:29:12.585 - 00:29:55.325, Speaker G: So basically the testing, so they're testing, testing is happening in for example two, three steps. And one of the first step is that each client super node and normal node pair should be working in kurtosis. And then basically we try other. We try that with other clients, that one client supernode and another client as a normal node. So they are these kind of combinations that sort of we need to try before we need to move move to devnet. So that is I think what Barnabas must have posted about. And for example LordStar Supernode and lots of normal node kurtosis pairing is working.
00:29:55.325 - 00:30:36.307, Speaker G: And for me the next step was to try lots of supernode with some other client supernode and obviously then with a supernode, one client supernode and then a normal node and vice versa. So basically I think these are the steps we are following. And so I am waiting, for example, first of all I need to include this new PR 3908 and then I would like to try it with another client whose supernode and normal node pairing is working. That that's the way basically we can.
00:30:36.331 - 00:30:53.575, Speaker C: Move forward on this for Lodestar. Does it do verific verification? I think I remember seeing just the compute cells and KZG proofs, but not verifying like columns being done yet.
00:30:54.395 - 00:31:32.311, Speaker G: So I think we have validation but we don't do reconstruction as of now. In my opinion, adding reconstruction is not really a big step. So basically when I'll have some sort of. So my focus right now is to make sure that there is some working that working configuration with other client. And then basically I'll add the reconstruction step on it. But most probably we are doing verification, but if we are, we are doing the validation and I'll recheck.
00:31:32.383 - 00:31:56.405, Speaker C: Although yeah, I think I might have just missed it then. Okay, cool. Oh, so it seems Prism is also the same. Is that also the same for Lighthouse? As in they can sync with a full node, Lighthouse full node and a Lighthouse normal node?
00:31:58.785 - 00:32:07.925, Speaker A: Oh yeah, between super node and full node in Lighthouse we can sync. We can sync. Yeah, we just don't have checkpoint sync yet? We're working on.
00:32:10.225 - 00:32:32.625, Speaker D: And if, for example, as I wrote in the chat, we can sync between Supernova and full node, but only from Genesis on the peer DAS branch. And we have a branch which is called fixed pure DAS discovery on which yes, Prism is able to sync full NPR node, not from Genesis.
00:32:32.665 - 00:32:33.245, Speaker A: For.
00:32:34.945 - 00:32:35.305, Speaker E: When?
00:32:35.345 - 00:32:37.205, Speaker D: Starting after Genesis.
00:32:39.385 - 00:32:43.845, Speaker C: Okay, after Genesis. Does that just mean like from some checkpoint?
00:32:44.395 - 00:33:01.375, Speaker D: No, no, no, no. It syncs from Genesis, but sorry, I don't know exactly the exact words for that. I think there is one. Just you start a new node when the network is already running, but not from a checkpoint.
00:33:01.675 - 00:33:03.011, Speaker C: Okay, I see.
00:33:03.163 - 00:33:03.763, Speaker A: Right.
00:33:03.899 - 00:33:04.975, Speaker C: That makes sense.
00:33:08.195 - 00:33:12.685, Speaker D: Maybe it worked for my checkpoint sync, but I didn't. I did not check.
00:33:13.745 - 00:33:19.845, Speaker C: Right, okay. Yeah, that makes sense. So is that the same for tech as well?
00:33:22.105 - 00:33:36.885, Speaker H: I'm not sure. We have not tested it for a while. It worked before, but I'm not sure with the current build. We should test it. It worked like two weeks ago.
00:33:38.615 - 00:33:47.355, Speaker C: Okay, so it's currently a bit unknown as to whether the one super node and one full node currently works. But it was working two weeks ago.
00:33:49.495 - 00:34:01.395, Speaker H: Yeah, if sync in the middle, if it starts in the same time, no issues, definitely. But the sync, I'm not sure.
00:34:03.105 - 00:34:05.685, Speaker C: Okay. Okay. Yeah, thank you.
00:34:15.465 - 00:34:54.755, Speaker B: Other issues, topics around the if not, then any spec discussion, if not any open topics here.
00:35:01.975 - 00:36:06.445, Speaker F: Yeah, I wanted to discuss the bottlenecks of computing KCG proofs for Peerdos in comparison to 4844. So right now in mainnet, the Blob KZG proofs are computed in the EL and are fetched by the CL, you know, when proposing a block. But with peer DAs, this thing, this path is basically done in the CL while it is building a block. So even with, you know, just six blobs, you could reasonably expect it to take up to one second just to compute the cells and all these proofs. With how mainnet is running right now, do you guys think it's reasonable to have potentially such a large lag before you can broadcast the columns out into the network?
00:36:17.555 - 00:36:37.215, Speaker E: I have two questions. First of all, why did you mention which layer does what? Like for the purpose of this discussion, what does it matter whether the proofs are computed by the OR cl? Apart from. Yeah, I guess that's my first question.
00:36:39.225 - 00:37:27.975, Speaker F: Yeah, so the reason I'm bringing up the fact that it's completed in the EL is because it is out of the critical path. So like now let's say it's a time to propose a block and you know, I fetch the blob transactions from the el, the EL has all the commitments and proofs ready to go. I don't have to do anything from the sales point of view. So I just, you know, do an engine call, get the blob bundle and pack it into a block and then just broadcast it out. So with peerdos, this changes. We get the blobs from the el, but we have to again compute all the cell proofs. And this is not cheap, so if you have six blobs, it can take a while.
00:37:28.435 - 00:38:13.895, Speaker E: Yeah, I understand it. Okay, I see. I was wondering, because if this is an expensive operation in general, it doesn't matter whether it happens on the EL or cl, because maybe you did your engine code and you've got nothing. So I was just wondering why we're discussing it from this lens. Now, with regards to the time, I think we also touched on this. Maybe I'm wrong, maybe I'm getting this wrong, but I feel like we touched this on the previous call as well, where Francesco was making a point on that the blobs are arriving even from the previous slot. So you can start off like work already.
00:38:13.895 - 00:38:27.615, Speaker E: You don't have to do the work in the critical 4 seconds window. You can pre work on the blobs you've been receiving on the mempool. Does this make sense? Didn't we discuss this last time as well?
00:38:28.805 - 00:38:56.865, Speaker F: I mean, I understand that, but like, from the sales point of view, how would I do that? So, like, let's say there's a blob that comes through the execution mempool and it's the how do I, you know, before I know the time to propose is next slot. So how do I know that I have to compute proofs for these specific blobs?
00:39:03.405 - 00:39:31.195, Speaker E: I see. Okay. I actually don't have a good answer to this. However, it feels like it has moved. With this observation, we're moving from a I don't have enough time for compute problem to what is the right API problem? Am I right on that, or.
00:39:32.815 - 00:39:43.155, Speaker F: Well, I guess you could frame it that way, but wouldn't this be better to be done in the EL rather than.
00:39:44.575 - 00:39:45.479, Speaker E: I see.
00:39:45.647 - 00:40:00.785, Speaker F: Because we're doing this right now with 4844 law. Proofs are computed and verified in the EL and with peer DAs. We were taking this all out and, you know, we're putting this in the cl so it is kind of a, you know, big change.
00:40:01.325 - 00:40:54.151, Speaker E: Yeah, right. I see. I see why you're. I see why you're saying this. You're saying this because you're like, okay, the EL sees the blobs at the earliest time possible. Why doesn't it spend the compute then? But yeah, I will have to think about this because. Because it feels like even though the EL takes the has the information earlier, the CL has knows which blobs should be computed.
00:40:54.151 - 00:41:06.435, Speaker E: Like otherwise the EL just has to do everything kind of. Or I'm not sure actually my knowledge kind of runs limited. Yeah. Of how this should be done, but it is worth discussing.
00:41:10.015 - 00:41:45.885, Speaker A: Yes. I think the idea to compute the proofs in advance is interesting. We have actually explored that. But like you said, could potentially be a bit of waste if the block transaction doesn't get included. The other experiment I've been doing, I think I mentioned the last call, is the distributed blob building. I think it's probably not a good name for it because it seems a bit confusing how that solved this problem. But this approach, we also fetch the block from the EL mempool.
00:41:45.885 - 00:42:39.609, Speaker A: So whenever we receive a block from up here, that's like a new block and we can fetch the blob from the Elman pool. And then once we get all the blocks we can immediately make the block available. And then for the super node they could even compute the dark home sidecars and publish out the network to help with the proof building. The supernode should have better resources and bandwidth to propagate it quicker than any regular nodes. But the older nodes can also try to fetch block from the er, manpool. If it's already there, then they can immediately make their block available. And that's the experiment that we've been doing with 16 blob and 32 blob and it seems to work pretty well so far at the moment with local testing.
00:42:39.609 - 00:42:46.365, Speaker A: We're hoping to do a bit. A bit more realistic testing. More nodes and distributed setup.
00:42:48.985 - 00:43:24.665, Speaker F: Yeah. So like the issue with having this super node wait for it is that you have this 4 second critical path and no matter how highly powered the node is, you still have to wait for it to basically compute all these proofs and send it out all in time. It would be better if we can compute the proofs outside the block proposal time because that is what happens right now in mainnet.
00:43:35.375 - 00:44:24.413, Speaker E: I see. Okay. Yeah, it feels like I, I agree with you. It feels like what we have right now is not very well suited to use the advantage of the blobs coming earlier. Basically it feels like there is at least two approaches here. One is the one you're kind of suggesting where they computations and then when the CL asks it at the block proposal window, the CL receives everything prepared, basically. And so the CL does not need to do anything.
00:44:24.413 - 00:44:49.877, Speaker E: I think this is what you're suggesting. The other is. Yeah, this is prepared. Sorry, sorry. No, sorry, sorry, Kev, I thought you were referring to something else. Okay. The other approach is some sort of API thing which I cannot really think about right now, where the CL can ask for blobs ahead of time.
00:44:49.877 - 00:45:06.885, Speaker E: Time and the CL still does the proof computation. I don't know which one makes more sense. I also agree the first one looks a bit simpler, but it feels like these are at least two ways we can exploit the earlier time window. Right. Does this make sense?
00:45:07.425 - 00:46:07.555, Speaker F: Yeah, I mean, both the solutions would make sense. Although for the first one I suspect we would need like buy in from all the EL client themes to do that. Right. So that might be a good thing. I'm guessing the second one might be easier because in some ways we already do this right now. So basically, from the sales point of view, if we know we have to propose a block that's in the next slot, we send a call to the engine and the engine prepares a payload. So if in that time we can also find out which blob transactions are most likely to be included, we can just build the proofs beforehand before it's time for us to propose on the client.
00:46:07.555 - 00:46:20.665, Speaker F: But it requires some sort. Yeah, it requires some sort of API where the CL can see, okay, these are the most high value blob transactions in the pool.
00:46:23.965 - 00:46:54.275, Speaker E: Right. Okay. I don't know which solution is best, neither in terms of complexity nor in terms of more economic advantage, basically. So let me discuss this later on with Francesco and other people who understand that side better and I can report back what was discussed, if that works for you.
00:46:56.535 - 00:46:57.715, Speaker F: Okay, great.
00:47:00.335 - 00:47:34.395, Speaker E: Kev, it doesn't seem like we will need the CL blob mantle. I think it may. I think the two solutions we're discussing is in both of them, the EL gets the blobs and then passes them to the cl. But in different times and maybe different. Like in one case the EL prepares the proofs beforehand, in the other, not. I don't feel like there is a need for blob mempool if I get it right, if I'm getting this right.
00:47:35.335 - 00:47:44.515, Speaker C: All right. Okay, I see. Yeah.
00:48:08.185 - 00:48:18.405, Speaker B: So we'll move it to offline discussions. And do we have any open topics to discuss today?
00:48:23.145 - 00:48:31.421, Speaker F: Yeah, just one housekeeping thing. Band bus is on vacation this week as well as Next week. So if you guys need something, let me know.
00:48:31.573 - 00:48:33.037, Speaker G: I'm not fully up to date with.
00:48:33.061 - 00:48:34.985, Speaker D: Pure dust stuff, but I'll try my best.
00:48:38.405 - 00:48:39.825, Speaker B: Thank you, Perry.
00:48:42.325 - 00:49:12.765, Speaker C: I had a general question to CLS about how they control Fred resources Is it basically just deploy as many threads as possible and have the scheduler figure out what's the best way to sort of handle the resources? I looked at a few code bases and I couldn't see anywhere that was like explicitly saying this thing should only use 5 threads or something like this.
00:49:18.185 - 00:49:38.735, Speaker F: Well, for golang it'd be done by the go runtime. So for us it's pretty straightforward. You just spin up a go routine and do whatever you need to do and then it shifted off into another thread. Maybe for, I think other languages it might be more explicit.
00:49:48.965 - 00:50:29.875, Speaker A: So for Lighthouse we currently don't have this explicit allocation of how many threats we want to use for the computation. I think that's something that we wanted to have in the future to have more control over the resource allocation. Because at the moment in Lighthouse we have this scheduler that basically allocates threats to different tasks, but the KZG computation is currently on its own and it can do whatever you want at the moment. So at some point we probably want to have some control over it. But at this moment there's no explicit location. Right. Okay.
00:50:34.175 - 00:50:35.635, Speaker C: Fred Tacker.
00:50:38.215 - 00:51:13.265, Speaker H: In tech of the calculate how many queries available and use some function to use part of them for the threads. But we don't use in KZG parallelism for block production yet. We use it only for recovering the extended matrix. When we have more than 50% of data columns and want to restore whole metrics, we plan to add parallelism for block production.
00:51:14.855 - 00:51:26.435, Speaker C: Okay, that makes sense. And I guess for load star I don't know if Java script allows you to have the same access like that.
00:51:28.455 - 00:51:30.155, Speaker G: Access like what?
00:51:30.495 - 00:51:34.995, Speaker C: To control the number of threads for a particular function.
00:51:37.415 - 00:52:14.435, Speaker G: I don't think so, but I think we if there is an underlying library, if there is, for example nappy kind of execution that is happening in the. In the. In the. In the library, then maybe over there one can figure out how many threads are there. But I think Matthew will be more knowledgeable on this and I think you are in touch with him. Kev.
00:52:17.015 - 00:52:19.275, Speaker C: Okay, that makes sense. Yeah. Thank you.
00:52:27.655 - 00:52:29.795, Speaker B: Any other open topics?
00:52:34.585 - 00:53:19.615, Speaker A: Well, I've just mentioned one in the chat. There's a open consensus spec PR on clarifying usage of the execution. Get block v1 endpoint. I'm not sure if there's an if everyone's look at this yet, but it's been there for a while. So I want to see if there's any feedback on this and whether we could include this because I feel like that's quite critical if we want to. I mean if we don't have a solution to the problem that we're discussing earlier regarding doing the proof earlier. This is the alternative where the CEOs could just fetch the block from the EL mempool and immediately make the block available in their view.
00:53:19.615 - 00:53:24.015, Speaker A: So I think this could be useful if you want to ship peer as they increase.
00:53:26.805 - 00:53:36.625, Speaker F: I had a question. So for this engine API call, does it only retrieve the commitment that you asked for? Can you like ask it for all the blobs?
00:53:38.525 - 00:53:56.165, Speaker A: I think at the moment it's just, it takes I think version hashes and so if you have the KG commitment and you can throw out the version hashes and make it both the block. So you can't just get any, any block.
00:53:57.465 - 00:54:12.245, Speaker F: Oh, okay. Because if there was a way to also like you know, get all or you know, a subset of like the highest value blobs, you know, it would fit like I guess the situation we were discussing earlier.
00:54:12.905 - 00:54:34.525, Speaker A: Yeah, I think that's being explored but it's, it's a bit more involved because at the moment the CLN doesn't know much about the transactions. We could like if we really need to, we could like the EL can, could expose an endpoint that allows the fetch flow by transaction id, but the doesn't currently know anything about transactions.
00:54:36.745 - 00:54:37.645, Speaker F: Gotcha.
00:54:46.995 - 00:55:02.215, Speaker A: I'm hoping to get some metrics on how quick other nodes can make the block attestable and available before waiting for data column cycles to arrive and hopefully you have something next couple of weeks.
00:55:04.795 - 00:55:13.875, Speaker F: Well, like for reconstruction the numbers I've seen it takes quite a while. So like what numbers are you seeing with Rust KZG?
00:55:15.575 - 00:55:43.865, Speaker A: I think it's mostly around for 16 blobs. It's around 500 milliseconds to 1 to 1 second. We don't have a more granular metric, but at the moment it's both between 500 milliseconds to 1 second for 16 blocks. And I think with this change we might actually do less of construction because most of them knows that gets the block from the EOMP who will be doing the compute sales call instead of reconstruction.
00:55:45.765 - 00:55:48.105, Speaker F: Oh, okay, yeah, that's a good point.
00:56:10.175 - 00:56:26.035, Speaker A: Oh, by the way, I think so we've got a. Michael's got an open here on ref for the execution API. And it looks like Nethermines also already merged their changes. So if anyone wants to test it out, there are at least two clients that you can test with.
00:56:37.185 - 00:56:56.575, Speaker B: Thank you. Jimmy, Any other topics for today? Thank you for attending. Have a nice day. Goodbye.
00:56:58.195 - 00:56:58.975, Speaker C: Bye.
00:56:59.315 - 00:57:03.075, Speaker A: Thanks. Bye. Thanks.

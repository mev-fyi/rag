00:00:52.085 - 00:00:52.745, Speaker A: Hello.
00:02:58.615 - 00:02:59.395, Speaker B: Hello.
00:03:03.775 - 00:03:04.555, Speaker A: Hello.
00:03:04.855 - 00:03:05.715, Speaker C: Hello.
00:03:08.175 - 00:04:16.495, Speaker B: Let's wait for a couple of seconds. I believe at least one of us will join, right? Ah, just go. Okay. Welcome to the 6th Peer Desk breakout code. The gender and mini notes is here. We can start with the client updates. Anyone want to share the recent updates from the client site?
00:04:19.165 - 00:05:12.775, Speaker D: Yeah, I can give an update for us. We have been working on clearing up some tech debt from basically trying to get a peer DOS into a mergeable state to a developed branch. So we've been trying to improve our test coverage and a lot of the peer das specific paths. We have implemented the Blob sidecar support for Peerdos. So if you have at least 50% of the columns, any API consumer can just get the BLOB from that. We've also been looking on strengthening our data column validation. So improve pipelines so that any columns that we get from Gossip or that we get from other peers are correctly validated.
00:05:12.775 - 00:05:39.485, Speaker D: And also lastly, we have been fixing a few bugs with Electra that came up. So Electra with Peer das flushed some bugs out in Prism with regards to how blobs were used. So we had a bug where Prism would drop blocks with blobs and the chain would stall. So that was one bug that we focused on last week and yeah, that is all for now.
00:05:43.025 - 00:05:52.085, Speaker B: Thank you. Testing if the very best lecturer works for the Peer desk.
00:05:53.505 - 00:06:20.495, Speaker D: Yeah. So for us what we did was that we try to make it extensible in that you could have Prism start with either the NEP or Electra and it should work fine. But last week when we tried with Electra, there were a few bugs that we found which had nothing to do with peerdas but actually with our Electra branch. So that's been fixed now and with the current peeras branch you can start indineb or Electra.
00:06:24.035 - 00:06:33.945, Speaker B: Thank you. And any other clients. Lodestar.
00:06:36.205 - 00:06:37.933, Speaker E: Yeah, I can go for Lodestar.
00:06:38.029 - 00:06:47.933, Speaker C: So as such we are working on the PR to dissociate the subnet from.
00:06:47.989 - 00:06:52.709, Speaker F: Groups and that is something that sort of we want included in the next.
00:06:52.757 - 00:06:56.159, Speaker C: DevNet and based upon what the consensus.
00:06:56.207 - 00:07:03.035, Speaker F: Is for rebasing peer DAs on Electra. We'll also work on that then.
00:07:10.175 - 00:07:15.715, Speaker B: Thank you. And then Lighthouse.
00:07:17.655 - 00:07:57.665, Speaker C: Hello. We have fixed a few bugs building range sync so Lighthouse can now sync network. And we've also fixed an issue with sampling which was sending excessive requests to a single peer. That's fixed now. So we've now disabled sampling by default. Other than that, we have been focused on merging our SAS branch changes into our Main branch, I think we're probably around 50 to 60% through. Hopefully we can have that done in the next two weeks, even the better so we can speed up our progress.
00:07:57.665 - 00:08:11.557, Speaker C: And other than that, we've made some progress on the optimization to fetch blobs from the el. It's also known as decentralized blob building.
00:08:11.621 - 00:08:11.839, Speaker D: So.
00:08:11.877 - 00:09:02.154, Speaker C: So for supernodes we fetch blobs from the EL and we build the data column sidecar in the publisher network. We've done some testing on this and the testing shows that even proposer with limited bandwidth they don't publish all the data columns, they can still propose a blob. Fine. With the help from supernode on block building and block propagation. So that's looking quite promising. I think our next step on that will probably try to increase the blob count. It might be slightly challenging because of the way we currently compute data columns and proof takes about 200 milliseconds per blob for my machine and I think there could potentially be some memory allocation issues on stack.
00:09:02.154 - 00:09:45.583, Speaker C: So yeah, so increasing that block count could be something that's. That's a bit challenging. With KG library, I'm not sure if any client has tried testing increasing blob counts, but I think it's it kind of sucker kind of stuff a little bit in the. In the 1D 1 dimensional PS case because we need to build the entire column. So it means we can only compute or reconstruct when we have all the blobs. We can't just partially do it because with the 2D scenario we can have each node just randomly select subset of all blobs and compute just the subset rather than computing the entire blob. So that's going to take a long time for 32 blobs.
00:09:45.583 - 00:10:08.005, Speaker C: So that's something we got to solve. But again with one DP address, that's a bit challenging. Yeah. So this week we will focus on finding our checkpoint sync working again for peer and also put down next estimates. That's all from Lighthouse.
00:10:10.625 - 00:10:16.965, Speaker B: Thank you. So regarding the blab count, what was the parameter you used?
00:10:19.065 - 00:10:53.309, Speaker C: I've tried to change it though too but I haven't got it working yet. But I can see that it's going to be slightly challenging because I look at the benchmark for the Rust case view library and it takes 200 milliseconds per blob and currently we don't do any parallel processing. So like 200 per blob if we make it 32, that would be like 6 seconds or something without any parallelization. So we probably want to do some parallelization there if we can. Yeah, I think. I think it just needs a bit more testing. Just a potential challenge.
00:10:53.309 - 00:10:55.065, Speaker C: I thought it's worth raising.
00:10:57.685 - 00:11:02.825, Speaker B: Thank you and granting.
00:11:05.125 - 00:11:40.035, Speaker F: Hello. So yeah, our fellow that was working on peerdesk made some fixes and essentially we are. We are waiting until the state and likely it will be the next Devnet which will not where there will not be a requirement for sampling if this is still the plan and then we will try to join the network on the next devnet. So that's all.
00:11:44.825 - 00:11:57.525, Speaker B: Thank you. So just to be clear, the next definite is the next the one you are joining will be definite three, right?
00:11:59.065 - 00:12:09.585, Speaker F: Yes. Is this still the plan to kind of remove or not make a requirement of sampling in DevNet3?
00:12:10.165 - 00:12:14.037, Speaker B: I think we will finalize it today, but.
00:12:14.141 - 00:12:17.545, Speaker F: Okay, okay. Okay, thanks.
00:12:17.885 - 00:12:35.515, Speaker B: Thank you. And then Nimbus here today? No.
00:12:39.935 - 00:13:49.975, Speaker G: Yeah, we finished adding full metadata with free support. We'll merge it today. Also we make reconstruction of lot size cars so you could get it from Rest API but only if you are super node if you have first 50 persons of data columns merging it today probably too. And we fixed it a bug. We had an issue when we were trying to retrieve column we were not trying to retrieve it from all the peers, only trying first two or something like this fixated two and we have added all validations and now working for choice to be spec compliant with Alpha 4 version when we check on the custody and regarding Electra we have not started to move to Electra so we will start probably after Devnet 2 launch. That's all for us.
00:13:57.565 - 00:16:09.205, Speaker B: Thank you. Any questions for the client updates gone through all the clients so the next one is the definite discussion So I reposting Banabas proposal summary here for one second Please check the chat there's a link so basically the proposal is to for definite two we have this the previous we have based on the previous spec alpha 4 and then use dynamic Genesis no Electra repairs. So one important item I want to check again in the chat is we okay with including PR3A7 0 indefinite 2 this is the link of the PR. So yeah I think for the reactions from the this code is people who want to have this feature and the choice update is trivial compared to the previous version so it's okay to include the whole feature into definite two. If you agree or disagree please give some reaction here. Now.
00:16:15.995 - 00:16:37.455, Speaker D: I had a question. This PR also includes a config change One issue for us is that we always test with the consensus spec config. So if this is not in Alpha 4, our tests will start to fail with this.
00:16:38.005 - 00:16:59.185, Speaker B: Right. So I think two discussion one is do we want to include this configuration change into DEFNET 2? And if the answer is yes, then I will cut the release for it.
00:17:01.045 - 00:17:03.985, Speaker D: Okay. Yeah, that'd be good enough for us.
00:17:05.064 - 00:17:11.164, Speaker B: Okay, good. Yeah. And any objections?
00:17:17.744 - 00:17:23.044, Speaker E: So you're saying we will include the config change or is that a separate discussion?
00:17:23.384 - 00:17:37.995, Speaker B: I think we will. We will include it if people are okay with it. But Francesco, would you like to explain the parameter? I mean changes.
00:17:40.655 - 00:17:54.671, Speaker E: Yeah, I mean this is actually something that's been kind of. Yeah. In a bunch of PRs I think since Kenya and it just never ended up being in a PR chat PR that was merged. It's just that.
00:17:54.783 - 00:17:55.023, Speaker D: Yeah.
00:17:55.039 - 00:18:37.195, Speaker E: We needed to increase the number of subnets because we want to increase the custody requirement originally because we wanted to do this trailing for choice and we kind of needed the custody part to already basically give enough security and now we literally don't have sampling. So the custody part really does need to be kind of secure in itself. So I think it would make. Yeah, it wouldn't make sense to still leave this for a future update. It's quite central to how custody is supposed to work and like. Yeah, it's something that we kind of had agreement on like basically already in Kenya. So I think yeah, we should just include it.
00:18:41.375 - 00:19:39.895, Speaker B: Thanks, Francesco. Okay then. So we now finalize the definite to scope with Alpha 4 plus it's net based and then including this PR and we will cut the Alpha 5 release soon and clients agree with the timeline proposed. I think it's by the end of this week. Good kids. Should be a small release and I can make it. No, stay in 24 hours because the new release for suspects.
00:19:39.895 - 00:20:14.435, Speaker B: Okay so any objections for. Okay, definitely two by the end of this week. Okay then it's definitely three. So it would be another spec release number. We will do we want to. To make it as a collector repaired version.
00:20:20.575 - 00:20:30.075, Speaker F: I think all client teams indicated that in two or three weeks they could do a lecture rebase. So I would actually push for DevNet 3 to be based on an actual.
00:20:39.425 - 00:20:40.925, Speaker B: Any objections?
00:20:47.505 - 00:20:56.245, Speaker C: Yeah, we. Yeah, I agree with Bernard and we just need to test out on our side. Yeah, should be. Okay.
00:21:01.345 - 00:21:35.057, Speaker B: Great. So definitely three will be the Electra best version and we discussed previously it will be a means of name decoupled version. Yeah. Can someone link the PR to the chat or. Trying to sound It. Ah yes, the couple network subnets. Thank you Jimmy.
00:21:35.057 - 00:21:49.925, Speaker B: So we will include this pr. Yeah and Panabas, you want to launch it in two or three weeks?
00:21:51.305 - 00:22:04.655, Speaker F: Yeah, I. I guess that's just an estimate timeline. Let's see how Devnet 2 is going to go. If Devnet 2 is not very stable, then I think we're going to need to delay it a bit further.
00:22:06.355 - 00:22:12.255, Speaker B: Now, would you like to talk about the activation flags?
00:22:13.915 - 00:23:00.685, Speaker F: Right, so we had I think a couple of months ago we were talking about possibly activating peer death with a. A different way. Instead of doing a EIP whatever fork version and fork epoch, we could do just pure desk activation epoch. I'm not sure if this is still under discussion or what should we do about that, but I think if you do an electricity based then we should have a way to trigger Electro. Sorry, trigger peer desk independently still not just automatically activate peer desk with Electra.
00:23:07.825 - 00:23:30.695, Speaker D: Yeah. So for us the peer does activation epoch is still separate from Electra Just said in the testing configure we have it the same as the Electro fork epoch but if you do need to, you could have it electra plus 20 epochs in the future or something, it will work the same way.
00:23:34.635 - 00:23:39.696, Speaker C: Are you using the gear that activation epoch or are you using ERP 7594?
00:23:39.907 - 00:23:50.745, Speaker D: So from what I understand EIP 7594 is what is in all the configs. So that is what we're using.
00:23:54.925 - 00:23:55.333, Speaker A: Right.
00:23:55.389 - 00:24:29.855, Speaker F: So currently the spec says EIP 7594 fork version and EIP 7594 fork epoch. And the way we do the peer desk activation is by setting the fork version to denab denab's fork version and setting the fork epoch to denapse fork epoch. And in the future when we do a rebase on Electra then we're going to trigger it with the IP7594 fork version equals to Electra's fork version and the fork epoch should be equal or be greater than Electra's fork version.
00:24:31.755 - 00:24:32.427, Speaker C: Epoch.
00:24:32.491 - 00:24:52.425, Speaker F: Sorry, but the fork version should be the same. So the question is, do we want to keep it this way or do we want to possibly get rid of these two variables and introduce a new one called something like peer death activation.
00:24:52.845 - 00:24:53.825, Speaker C: Epoch.
00:24:56.765 - 00:25:00.715, Speaker F: And get rid of the fork bit completely.
00:25:03.015 - 00:25:20.715, Speaker C: I think eventually we can get rid of get rid of the bulking bulk Right when we raise the launch here that through Electra. I don't see any clear benefit of changing it at this point unless I'm Missing something.
00:25:23.295 - 00:25:39.455, Speaker F: It would be just a cleanup. But yeah, we can totally keep it like this. Then let's not change anything how we activate it. Let's just keep all the same stuff as it was before. Okay.
00:25:43.395 - 00:26:22.235, Speaker B: Thank you. All right, so now we move to the spake discussion. Does anyone want to talk about some specific PRs for spec changes and any questions to the KVG libraries?
00:26:32.935 - 00:26:34.275, Speaker C: How many blobs.
00:26:39.615 - 00:26:43.919, Speaker B: Sorry, Jimmy, you will cut it bit Now.
00:26:44.047 - 00:27:10.635, Speaker C: I was wondering, has anyone tested like, how many. Like what's the number of blocks we can realistically support in a. In a block if we just ignore that, the networking stuff. Just, just to focus on the crypto library in terms of CPU memory and time. Sorry. Hmm.
00:27:12.135 - 00:27:19.915, Speaker A: I mean, I think at least the C library should be like, which, which functionality are we talking about here?
00:27:22.055 - 00:27:29.155, Speaker C: I'm talking about compute sales. Compute sales improve and reconstruct recovery. Sorry. Recovery cells improve.
00:27:30.735 - 00:27:32.395, Speaker A: I see. Okay.
00:27:35.345 - 00:27:36.113, Speaker C: Let'S see.
00:27:36.209 - 00:27:59.045, Speaker A: So I think. Okay, I mean, I'm not sure. I think. What numbers are you interested in? Like, like you. You want arbitrarily, arbitrarily many blobs and you want to know the time it takes or what, or when the library is going to explode or what.
00:28:00.695 - 00:28:27.825, Speaker C: Yeah, basically, like, I don't need arbitrary numbers, but if we're aiming for something like 32 drop, I think it'll be interesting to know like how much time it takes and CPU memory requirement. Because I think at the moment I've tried running the ref. Sorry, the Rust EKZG library, benchmarking my machine and each blob take about 200 milliseconds to. Right compute and to recover.
00:28:28.365 - 00:28:50.325, Speaker A: Yeah, yeah. And you're wondering. Okay, so. And you are wondering like without, like you want. Without parallelization. I think without parallelization it's going to be a linear thing. Like, you know, you put two blobs, you're going to get 400 milliseconds.
00:28:50.325 - 00:28:55.305, Speaker A: But you are hesitant about using parallelization?
00:28:57.165 - 00:29:17.585, Speaker C: No, I'm not hesitant. I think we probably need to figure out how to like, to see like how parallelization help. I think the benchmark for the Rusty casual library also tests parallelization, but it doesn't seem to improve a lot. So maybe I was looking at the wrong number, but I try to confirm afterwards.
00:29:18.815 - 00:29:37.795, Speaker A: I would imagine it's like completely parallel. Like if you have two cores and you split it, you split two functions into two cores. They're just going to take the same. Like you're going to do 200 milliseconds for two things. If you do them in parallel.
00:29:39.255 - 00:29:49.131, Speaker C: Right. So if we have 32 blobs and we can do 18 parallel, then will need at least then 800 plus milliseconds, right?
00:29:49.243 - 00:30:03.215, Speaker A: Yeah, yeah, that would be what should happen in theory. If this doesn't happen, it's something we should know.
00:30:04.595 - 00:30:15.635, Speaker C: Okay, cool. Cool. Yeah, I'll test it out. Yeah, I think maybe I was reading it wrong. I think the numbers just throw me 200 milliseconds. I guess it's for one single block. So.
00:30:15.635 - 00:30:20.035, Speaker C: Yeah, I'll try to. I'll try to confirm. Maybe I was looking at it wrong.
00:30:20.775 - 00:30:44.595, Speaker A: Yeah, I think, I think, I think after a certain number of blobs, we will need to do parallelization anyway. So I think figuring out what's the right parallelization strategy is needed. And then if the numbers you get out of that strategy are not good enough, then we should figure out something out.
00:30:47.055 - 00:31:19.985, Speaker C: Yeah, because I think if we try to increase above maybe 32, then it feels like we would probably need like distributed blob building. Because if we try to build on one machine and each machine, let's say if a limit is up to 18, so eight parallelizations, then it may still take a long time. Unless we assume that every node can parallelize more than eight. So I think it's something to think about. Yeah.
00:31:21.565 - 00:31:22.385, Speaker A: Yep.
00:31:24.325 - 00:31:45.465, Speaker F: Do we have a way now to decouple the blobs, by the way? Because we now have the max blobs per block config parameter in the config YAML and we have added support for this parameter in kurtosis as well. So you should be able to just play around and just pass in more blobs. But I'm not sure if the ELS was for that.
00:31:48.685 - 00:31:59.799, Speaker C: Yeah, I think the EL will need some changes as well. I've been trying to play around with Lighthouse and Rift. I haven't got it working yet. But I think the EL side should be quite straightforward just to change a constant.
00:31:59.847 - 00:32:01.623, Speaker F: I think we have.
00:32:01.679 - 00:32:11.915, Speaker E: It depends on the el. Some of them have it baked into the library, so it's compile time. So they might have to make a change there. And you might need to use a different image each time.
00:32:12.535 - 00:32:24.261, Speaker F: But we also had a PR that would change how the blob count would be passed around from between the CL and. Yeah, I'm not sure if that made in to exactly.
00:32:24.293 - 00:32:31.145, Speaker E: I think Alex was working on that. I think that's also the right way to do it. But yeah, I'm not sure where it is right now.
00:32:45.765 - 00:33:35.555, Speaker C: Yeah, just so it's Just one more thing to add, I think with the limits on computing the blob proof, if we really want the distributed blob building, I think that would be a lot more efficient in the 2D peer DAS case, because we don't. Because each node wouldn't have to build the entire metrics. They could just like select a render subset of the entire blob set and then just compute cells on those and publish those individually. So we kind of have like many nodes doing that at the same time. And we kind of get parallelization by default with that approach. But with one dp. With one DP it does.
00:33:35.555 - 00:33:40.375, Speaker C: It's a bit hard to do that. So we would need to do parallelization on each machine.
00:33:41.925 - 00:34:31.029, Speaker E: So I don't quite understand this because for reconstruction, like definitely for 2D, it's more. It's easier to see how to distribute it. That's kind of one of the reasons why we want to do 2D, that you can just reconstruct single rows instead of basically needing to have everything to reconstruct. But for constructing the matrix in 1D, you actually can just encode each blob, like by itself, basically. Like you could even, for example, say you're a local blog builder. As the blobs come in the mempool and you know that you're about to be the proposer, you can just start encoding them and computing proofs for each blob. Like, you don't need to have all the blobs to be able to compute the encoding and the proofs.
00:34:31.029 - 00:34:58.745, Speaker E: But for 2D, you actually need to have everything before you do anything. Or like you can extend each blob, but the vertical extension for the 2D thing, you can only do it once you have all of the blobs, basically all the extended blobs. So you can only do kind of half of the work in a. In a clearly distributable manner. Like at some point you need to do also the vertical extension. And that seems like it's. It's harder to distribute.
00:34:58.745 - 00:35:07.389, Speaker E: I don't quite understand why you say that block construction is more easily distributable into the. Yeah.
00:35:07.437 - 00:35:37.145, Speaker C: So the experiment I'm doing right now is to have super nodes special blob from El and construct the cells and the column cycles. But the problem right now is that we transmit the blobs in the unit of data columns by themselves. So if you want to send one data column to up here, then we need to have all the blobs. Does that make sense?
00:35:37.445 - 00:35:52.021, Speaker E: Yeah. Okay. Yeah, sure. In terms of propagation. Yeah. I mean you, you do need to, yeah, get the whole column, but you can do all of the computation blob by blob. Like all of the actually encoding and computing proofs though.
00:35:52.021 - 00:36:40.455, Speaker E: Yeah, you can send them out. But I mean one thing that I don't think that this would necessarily change with 2D just because. Yeah, the idea was that 2B would have sampling being by cell so that you could send these small parts. But still I think distribution will very likely be with bigger chunks. It was still meant to be by rows and columns in the original design. But another thing is that to even have the cells to begin with, you still need the whole matrix and have done the computation on the whole matrix, which is I think harder to distribute actually. Like you can't, you can't do, you can encode all the blobs, but then only once you've done that you can even start doing the vertical extension.
00:36:44.435 - 00:37:42.135, Speaker C: Right, I see. Is it, would it be beneficial if we could like break down like the data columns so that we can just send whatever cells we have in that column rather than having to send the entire unit at once? Because I think what you're talking about is what's happening on the proposal, right. The proposer can start preparing for the cells as soon as they have the blob in the el. But if you want to do like distributed construction, then the other node could, can, can only start building once they have the block and they have the block in the el, so they will have to do everything at once.
00:37:44.075 - 00:37:44.667, Speaker H: So in.
00:37:44.731 - 00:37:45.335, Speaker C: And.
00:37:47.955 - 00:38:42.345, Speaker H: So in the version that we were playing with, we always do distribution cell by cell. I mean we've been playing with doing cell by cell versus column by column. But when you start to do recovery based on the 2D structure, you anyway need the cell by cell distribution. So just based on that, we usually said let's do it cell by cell from the beginning. But that will allow us doing more low end column based distribution in the 2D case and then kind of doing cell by cell for recovery and for sampling. That's for the networking part for the generation. I think the difficulty is that you need the KZG commitment against which you verify on the column dimension.
00:38:42.345 - 00:39:02.225, Speaker H: And to have that commitment, I think you need all the, basically half of the elements of the column. So basically all the column. Yeah, but I have to think about it.
00:39:03.365 - 00:39:43.451, Speaker A: I'm a bit confused on what we're talking about here because we don't have commitment column commitments, we only have row commitments and Also I feel like if we start propagating cells instead of columns, we're gonna run like propagating entire units is nice because you don't have to worry about all the race conditions and all the edge cases of what happens if I get some but not all. Whereas if we start sending just cells we need to start like we will get, there will be much more complexities.
00:39:43.523 - 00:40:26.395, Speaker H: I feel like, okay, so, so one thing is whether we have permanent commitments and it's only the commitment. So you can verify actually individual says just based on that. So that's not an issue. On the, on what is being propagated. I mean cell by cell might seem like more complex than only rows and columns. Like rows and columns might seem more complex than distributing the whole block. I don't see a huge difference in complexity, but yeah, but let me know what complexity you see in cell by cell distribution.
00:40:26.395 - 00:40:36.755, Speaker H: It's. I mean from my point of view the efficiency gain was the complexity and the complexity is not that huge. But yeah, views on this might be different.
00:40:38.415 - 00:41:07.755, Speaker A: Yeah, I'm not sure. I think it is very similar to when in 4844 we had to decouple the blobs and that came with its own complexities. But yeah, I don't want to make a statement about this because I just felt like when we decoupled things in 4844 it was more complicated. But I think, yeah, I'm not sure where to draw the line.
00:41:11.055 - 00:41:53.895, Speaker H: Yeah, I mean I think it's a state of a compromise that we have to understand well later on when we are potentially going into this direction. The we have been running simulations, but those are high level simulations first on cell by cell versus line by line. So those in columns and there are efficiency gains if you do sell by cell for a few reasons of peer to peer networking. But these are simulations with a few assumptions which, you know, how it plays out at the end is still to be verified.
00:41:58.235 - 00:42:15.685, Speaker A: I think. I'm not quite sure. I have kind of lost the connection between this discussion and the original question which was about local block building and stuff. Yeah, I don't know if we have gone a bit side.
00:42:19.905 - 00:43:05.775, Speaker C: Yeah, I think it's kind of related. But the original question was like how many blobs can we realistically produce on a node in a block? I think when we hit 32, going above is going to require like more than parallelization on a single machine. But it's worth experimenting. I think if we do 64 degrees and we don't have 64 cores, then that means there will be batches of computations. So it will take longer to compute the proof. So I think I was trying to think of ways to see if we can distribute the workload. So that's how we kind of drift away from that initial question.
00:43:06.555 - 00:43:26.135, Speaker H: Yeah, so it's, it's, it's scaling at one point requires distribution, especially if you want to have also enable smaller nodes to build somehow and that's that house it fits in. But yeah, I think it's longer term research.
00:43:28.595 - 00:44:02.589, Speaker E: So I think one thing is worth differentiating though is like there's kind of two components to local block building or block building in general. And like the complexity that blobs introduce. One is the networking part and one is the computation part. And the computation part at least there is nothing in the current structure that makes it harder. Like actually I think the way it is right now, it's as easy as it can be. Like it's perfectly parallelizable. And I mean of course, yeah, if you hit the limit of you have more blobs and cores, yes, you will have to still do it in batches somehow.
00:44:02.589 - 00:44:39.679, Speaker E: But there's kind of no way to do better than this. Like there's no way that, you know, doing going to 2D doesn't help with the computation. It can perhaps help with the networking or at least like changes like you know, not distributing columns could help with the, with the propagation part. But on the, on the at least computation part maybe. Yeah, the one thing that you can still do is even if you don't have enough cores for the amount of blobs, you can still distribute the workload over time. Just because blobs will not come right as you're proposing. Like you're not going to get like 32 blobs immediately.
00:44:39.679 - 00:46:05.919, Speaker E: The second that you're proposing, you get them in the mempool over a few seconds and you can just kind of distribute a computation over, over that period of time. So I think in principle, yeah, even, even a node that doesn't have too many cores should be able to do a lot more blobs than would think just based on the number of cores. Like you can, you know, you get blobs at six seconds into the previous slot. You have a lot of time to do the computation for those in advance basically. But yeah, but I mean these things I guess eventually like there's like a bunch of like of these tricks that probably eventually should be implemented for the propagation part. One thing that we've kind of discussed is that eventually it would be nice to basically allow nodes to just send out the block first without trying to immediately propagate blobs and like basically, you know, once they've sent out the block to all their mesh peers, then only then start trying to propagate blobs and basically trying to use the fact that there will be nodes that have all those blobs already. Like if you have any kind of super node peer or like super node in, in the propagation path, they will be able to get all the blobs from their mempool.
00:46:05.919 - 00:46:46.725, Speaker E: If you're like a local block builder and have been building stuff from the mempool and they'll be able to basically just do the reconstruction and start propagating things for you. So I think eventually it would be nice to, yeah, basically try to use this as a way to have local block builders not have to do all of the propagation work or like basically be able to rely on other nodes to help them with propagation and yeah, only kind of being able to do as much to go with as many blobs as they can deal with on the computation side, even if that's not necessarily what they can deal with in terms of propagation.
00:46:50.995 - 00:47:34.935, Speaker C: Yeah, thanks, Francesco. I've just linked up here that basically does exactly what you just described. So I think you. So there's actually two different angles that you can, you can, you can think about this. So one, from a proposal side, we can definitely distribute the computation over time, like during the entire duration of the slot. But if we want to use the distributed computation, like using other supernodes to help with the block building and distribution, then basically each super node that helps with the computation will have to construct all the cells. So I think there's a limit on how much we can scale in terms of number of blobs.
00:47:34.935 - 00:47:54.845, Speaker C: So that's why I was kind of thinking if we can just have each supernode construct a subset of all. More sales. But I guess that's, that's like further research required, I think. But yeah, I think, I think we'll probably hit this problem once we get to 30, 32bl. Be interesting to see what happens.
00:47:58.345 - 00:48:39.735, Speaker E: At least. I, I would suspect that the networking problem would be, would be. We would hit the networking problem much sooner than the computation problem. Just because I don't know if you have 32 cores you can, you know, in. Even if the blobs were, I don't know, 128, you could do this in less than a second still, I mean, of Course, like using all of your core time, but like it seems at least like, you know, fairly manageable numbers, especially because we're not going to have 120 blobs for a very long time. So it seems to me that in like the foreseeable future, it's unlikely that the computation part would be the bottleneck, even for like pretty low power nodes.
00:48:54.715 - 00:49:02.845, Speaker C: Yeah, thanks. Sorry. I think probably when. I think that's good discussion.
00:49:09.265 - 00:49:14.165, Speaker B: Thanks, Jimmy. Any other topics for discuss today?
00:49:20.105 - 00:49:30.655, Speaker F: Just want to make sure that V3 metadata should be in. NET 2. Does everyone ask, does anyone disagree?
00:49:46.915 - 00:50:02.065, Speaker B: We have metadata version 3. Any other topics?
00:50:08.885 - 00:51:06.085, Speaker E: Yeah, I have like a small question for something like a potential maybe eventual spec change related to validator custody. If it was useful for this validator custody thing, would it be a big deal, like much of a problem to basically replace the custody subnet count thing with like a bit field? Like I think we have that for attestation subnets, right? Like something where you just say which subnets you're part of instead of like this custody thing where you just say I'm in 10 subnets and then deterministically compute which ones. If it was helpful to explicitly state which, would that, I don't know, be like an easy thing to do? Are there any challenges really that kind of come from that? I'm just curious if it's something that I can consider as part of the design space or not.
00:51:07.025 - 00:51:08.445, Speaker C: What do you get from that?
00:51:11.715 - 00:51:41.575, Speaker E: Right now? Nothing. Like in the current spec, there's no reason to do that. It's. Yeah, it's related to if you wanted to do this accountable validator custody, which works a bit differently. And the assignment that each person, that each validator have wouldn't be public and yeah, it wouldn't basically would not necessarily be able to compute deterministically what some. Which subnets someone is supposed to be in based on their node id. But like I guess.
00:51:41.575 - 00:52:03.961, Speaker E: Yeah, don't worry too much about the why for the. For the moment it doesn't do anything. I'm just wondering if. Yeah. If there's reasons to like not want to do this were it to be useful for other things. I think one downside is that it will become easier for the attacker to.
00:52:03.993 - 00:52:09.625, Speaker C: Map the validator to the node. Right. So it's like because you put more.
00:52:09.665 - 00:52:52.855, Speaker E: Information in the enr, but in this case it's, you know, the custody subnet count still allows someone to exactly know which subnet someone is in this thing. It would be the same just that you're explicitly stating which subnets you're in instead of stating something that then has to be fed into a function. And it wouldn't be. Actually the idea would be that it's private what a validator is assigned to, so there's no public assignment of a validator. So it's. Yeah, I'm kind of really just won't mean to ask about this bit field thing like if that in itself has some downside.
00:52:53.475 - 00:53:26.115, Speaker H: So with the current assignment it would be the same information information disclosure as a bitmap. If you think of a potential future where you have 500 plus 500 rows and columns, then you are having a bitmap of 1000 bits which I don't know if it's a problem or not, but it's definitely more data than the current count, for example. So it's a question of YNL size, I suppose.
00:53:29.175 - 00:54:15.495, Speaker D: Well, for us it won't be an issue. We already do this for decisions and sync subnets, so it's pretty much I think the same thing. I also think in some sense it would be better to do it this way rather than having a subnet count because for all the other decision sync subnets we have a bit field for those topics. So you know, standardizing it on just having bit fields for all of them is I think it is a rational idea.
00:54:40.565 - 00:55:09.355, Speaker B: Any other comments? Okay, so Francesca, we move on from here. Good. Okay. Any other topics for today?
00:55:16.855 - 00:55:30.595, Speaker E: No, sorry. Actually another quick question. I'm just curious. What. What is the roughly like ratio of super nodes to non super nodes that's been done in devnets or like that you plan to do in this devnet.
00:55:32.975 - 00:55:33.995, Speaker C: Pop up?
00:55:37.055 - 00:55:38.395, Speaker E: Okay, sounds good.
00:55:39.775 - 00:55:44.839, Speaker F: We can do any other. If there's a request to do some.
00:55:44.927 - 00:55:59.915, Speaker E: Something I just think. No, I think that's fine. I think it's just probably. It doesn't make sense to do like something super low just because eventually if we do have validator custody, there should be like a reasonable number supernova in the network. But yeah, half. Half sounds perfectly fine.
00:56:01.205 - 00:56:25.619, Speaker F: Yeah, we don't have too many nodes right now, so that's another possible bottleneck that we have very few nodes and it's going to be very hard to have all the custody requirements fulfilled with the number of nodes that we run. Basically if they are not super node.
00:56:25.777 - 00:56:45.875, Speaker C: Does it make sense to increase the custody requirement before we have validated custody? Because right now we don't have validated custody and the default is four. I think there's four for the custody subnets. I was wondering if it makes sense to increase it to 8 before we have the validity. Custody?
00:56:53.505 - 00:57:07.385, Speaker E: I don't know if the question is to me, but yeah, I guess to me it. It seems like it could make sense, but. Yeah, I think. I don't know. I'm not sure what the specifics of the. Like, how many nodes are there in the network?
00:57:07.545 - 00:57:21.375, Speaker F: Roughly 10 to 12. Like, we can maybe bump it up to like 20, but I, I don't know if you're going to see any benefit if. Unless we run like hundreds of nodes, but it's just very expensive.
00:57:22.075 - 00:57:25.707, Speaker E: Okay. Yeah, I mean it's. Yeah. I don't know. I. It's hard to. I.
00:57:25.707 - 00:57:26.475, Speaker E: I have to think.
00:57:26.555 - 00:57:27.203, Speaker B: What.
00:57:27.379 - 00:57:32.455, Speaker E: Yeah. How do things map to this kind of world? I'm not sure.
00:57:34.595 - 00:58:02.895, Speaker C: Yeah, I've had to come in the chat. I think the biggest like problem on a small devnet is that most of the requests go to Super Node, so there's less pressure on the regular full nodes and we're always sending stuff to supernodes. I'm not sure if it helps if we increase it as all the full nodes share the load. That's something to think about. It's a conflict change in the ketosis.
00:58:13.365 - 00:58:19.865, Speaker F: Sorry, so you want to do context switching or what? What did you, what did you mean by that?
00:58:21.685 - 00:58:42.725, Speaker C: Sorry, I was just wondering if it's worth having the network have a default custody requirement of 8, which is the default default for bio custody in the future. Just because we only have 10 to 12 nodes and currently all the RPC requests go to Super Node.
00:58:46.225 - 00:58:49.845, Speaker F: Wouldn't it still be the case though, if we have higher custody?
00:58:52.145 - 00:59:03.095, Speaker C: If we have a higher custody, then there are more peers that we can request from for a given column, but I guess that doesn't really make a lot of difference. Yeah.
00:59:05.395 - 00:59:26.575, Speaker F: We could, we could totally do that for the devnet, but I don't know if we need to change the spec for this. Like, we could just override that value and then. Yeah, unless this is hard coded to any client, which it really shouldn't, but you can also modify this value in. Kudos in each of your runs. There's a flag for that.
00:59:27.395 - 00:59:27.683, Speaker B: So.
00:59:27.699 - 00:59:45.575, Speaker F: Yeah, we can, we can definitely play around with that. Yeah. Because I remember last time when we were running some syncing test and all the supernodes got like peer limited. I'm not sure if this was like the root cause of that.
00:59:47.475 - 00:59:57.295, Speaker C: Yeah, hopefully that's fixed now. Hopefully we don't scan any other super nodes now, but it'd be nice if we had more peers to try from. Yeah.
01:00:09.115 - 01:00:34.585, Speaker B: For any other topics for today? No. Okay, so we have the. Okay, update the definite document at the end of this week.
01:00:37.605 - 01:00:54.325, Speaker F: Please let me know if I should use a different branch than whatever we defaulted to, and then I can run some local tests, and then we can launch Devnet in by the end of the week, hopefully.
01:00:57.305 - 01:01:07.965, Speaker B: Thank you. Okay. Thank you for attending. And let's go back to work. Thank you. Bye. Bye.
01:01:09.755 - 01:01:12.335, Speaker C: Hey, thank you. Bye.
01:01:14.755 - 01:01:15.735, Speaker D: Bye, guys.
01:01:17.275 - 01:01:17.715, Speaker H: Goodbye.

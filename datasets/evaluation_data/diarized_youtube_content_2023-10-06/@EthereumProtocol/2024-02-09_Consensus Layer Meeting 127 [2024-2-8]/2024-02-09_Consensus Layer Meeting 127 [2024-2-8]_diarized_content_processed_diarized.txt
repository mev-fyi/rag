00:03:10.170 - 00:04:05.366, Speaker A: It. Okay, we should be live YouTube people. Let us know if you cannot hear us. Well, you can't hear me anyway. All core devs consensus layer call one two seven. This is issue nine nine. Repo.
00:04:05.366 - 00:04:48.470, Speaker A: There is link. We have quite a bit to talk about. I have a feeling that we're going to have to, again, keep continuing this conversation over the next couple of calls, but hopefully we can make some good progress today. Generally on the agenda, we're going to go over to Neb. Anything we must discuss, as well as some discussion around Mainnet scheduling. There was what I would call pretty minor incident on Mainnet, but one that might have significant things to talk about. So I don't know if there's a post mortem out, but I do want to just give us room to talk about that in the event that there are critical things to discuss.
00:04:48.470 - 00:05:32.114, Speaker A: Now, I'd like to keep that relatively independent of the discussion of epbs, which would come a bit later. Then we'll talk about a lecture again. Maybe we're settling on a joint name and have already, but let's talk about that briefly. EIP 7549, which has been agreed to be included, has a bit, just some, I think, minor design considerations that won't escalate. Then the conversation around various things that may or may not go in the continued conversation, then open discussion. Okay, let's go ahead and get started on Danab. I believe we have forked another public testnet.
00:05:32.114 - 00:05:38.870, Speaker A: Is there a general status update or anything that we want to discuss in related to testnets and testing?
00:05:42.730 - 00:06:22.580, Speaker B: Yeah, so we had the Holsky fork yesterday, and since the fork went well, we barely lost any participation rate. And it looks like we were getting blobs from quite early on. Besides that, there's been nothing we've noticed, at least on Holski. And we've passed the blob expiry window for Gurley. So we ran a bunch of nodes and are doing a mixture of Genesis sync as well as checkpoint sync. And all the checkpoint sync nodes, el and cl, other than the archive ones, have already synced ahead, and the archive ones. We should have information within another day or so.
00:06:25.510 - 00:06:29.138, Speaker A: Terrence, something to note is that I'm.
00:06:29.154 - 00:07:09.522, Speaker B: Not sure if anyone is watching, but the slot zero, where the Fortran session block, it's actually missed. So someone didn't send that block. And then the slot one was arrived, but it was arrived at my local node. It was 11 seconds later. Honestly, this is probably not a big deal, but as a client team, it's probably worth checking. Whether this is your implementation that's causing the delay. We are also checking the background to make sure prison validator is okay under those scenario, because I suspect maybe the fort translation may take more than a few seconds here.
00:07:09.576 - 00:07:12.362, Speaker A: So yeah, this is on Holesky.
00:07:12.526 - 00:07:14.386, Speaker B: Yeah, this is on Holesky.
00:07:14.578 - 00:07:49.320, Speaker A: Got it. Any further comment or discussion on that point specifically, Terrence? Okay, I'm curious, when you're syncing from Genesis past the prune window, do you have to bring in a piece of main net information that is within the prune window, or can you do so trustlessly?
00:07:51.280 - 00:08:06.290, Speaker B: Right now we're struggling to sync Genesis on Gurley to begin with because I'm not sure there's that many Gurley archive nodes. So irrespective of block expired and the checkpoints, it notes they work fine.
00:08:08.820 - 00:08:22.550, Speaker A: Very cool. Any other discussion points for Danev Dan kun in relation to testing testnets? Sean?
00:08:24.810 - 00:08:50.030, Speaker C: So we discussed this a few months ago, but in a scenario where the chain hasn't finalized for the data availability period, the way to recover would be to checkpoint sync from an unfinalized checkpoint, and also that generally just be useful for some sort of social recovery in a long period of non finalization.
00:08:53.090 - 00:09:00.006, Speaker A: By recover, you mean be able to sync during that environment? You could still follow the head in that environment.
00:09:00.138 - 00:09:36.160, Speaker C: Yeah, exactly. So we've been working on enabling this in lighthouse, and it was actually kind of tricky because we look at peers, their finalized epoch, and compare it to our own, and we treat this as sort of like a virtual finalization. So we would just assume we were ahead of all our peers and it would stall our sync on our nodes. So I would just encourage other client teams to also look into this because it was the type of thing that we thought should work until we really dug into it.
00:09:42.220 - 00:10:00.760, Speaker A: Right. So in the event of issue, don't just assume this is easy. If we run into something on main net, is there any other, any further comment or any more color on why this is difficult, bro?
00:10:00.850 - 00:10:16.384, Speaker C: Specifically, it was because of peering. We treat the unfinalized checkpoint as finalized, and this is good internally in that you're sure to never reorg and whatnot.
00:10:16.432 - 00:10:17.030, Speaker A: Right.
00:10:17.960 - 00:10:30.696, Speaker C: But your view of the chain, I guess, your view of which peers are useful, that was the specific issue, yeah, I see.
00:10:30.878 - 00:10:38.200, Speaker A: Do you end up reading finalized information from that state and using that for your peering information, or was there a different trick?
00:10:40.000 - 00:11:02.800, Speaker C: No, we're using essentially like the unfinalized checkpoint, and we assume that our node is actually further ahead in sync because we're comparing that to other chains, actual finalized checkpoint, which in this scenario would always be lower. So we end up sorting through all our peers and saying that they're all useless.
00:11:03.320 - 00:11:12.790, Speaker A: Yeah. What I'm saying is the workaround to then use the finalized information that's actually written in the checkpoint state, not the checkpoint state.
00:11:14.520 - 00:11:36.620, Speaker C: No. What we're doing is we're making sure that Lighthouse is aware of if it's in this particular mode so it's aware of whether it was started up with a non finalized checkpoint and when it's comparing itself to peers, it'll take this into account. Instead, look at the head of the peer.
00:11:38.640 - 00:11:42.856, Speaker A: Oh, does, did you have a. Oh.
00:11:42.898 - 00:11:45.280, Speaker D: No, I'll ask in the chat. It's technical.
00:11:47.460 - 00:11:49.890, Speaker A: All right, thanks, Sean. Anything else on this one?
00:11:51.860 - 00:11:56.372, Speaker C: That's about it, but if anyone runs into similar issues, feel free to reach.
00:11:56.426 - 00:12:16.880, Speaker A: Out other Deneb Dankoon testing items. Marston?
00:12:19.460 - 00:12:43.210, Speaker E: Yeah, right now I'm spamming Garly network with block transactions. As far, no issues, but it's like one third of experiment. So if there will be some issues we'll see it in a few minutes, maybe half an hour from now. But as far, everything looks fine.
00:12:46.690 - 00:13:25.250, Speaker A: Great. Thank you. Any other Dankoon testing related items? Okay, great work. I believe as has been broadly discussed over the past handful of calls and much more concretely discussed on the last acde as an intention to talk about and pick a mainet. Tim?
00:13:27.220 - 00:14:31.830, Speaker F: Yes. My feeling is on the El side, teams are generally pretty ready to both pick a date and then start putting out releases for it. I think there's not too much strong opinions about what the date should be and obviously getting Cl folks'perspectives on that is valuable. And yeah, I mean, if I can share my screen, I have a bunch of potential dates, like the next month ish. So assuming that teams are ready to put out a release in the next week or so, I think these all make sense. Generally, we probably want like two, three weeks between the announcement for Mainnet and then the actual fork. So we should pick a date that we should figure out when teams are all comfortable having a release and then pick a date that's a couple of weeks after that.
00:14:32.920 - 00:14:33.476, Speaker A: And then.
00:14:33.498 - 00:14:47.560, Speaker F: Yeah, all the times on this sheet, I'll put this in the chat. But all of these are like the epoch history accumulator boundaries and they're all sort of midweek. So between Tuesday and Thursday.
00:14:48.940 - 00:14:49.752, Speaker E: So yeah.
00:14:49.806 - 00:15:00.830, Speaker F: Curious to hear from client teams if they have any preference on or maybe. Yeah, it makes sense to hear from client teams, like when they could have a main net release out. And then based on that, maybe we can pick a.
00:15:10.110 - 00:15:15.294, Speaker A: Maybe, maybe a bit more concrete. Tim, when speaking with execution layer teams is everyone.
00:15:15.412 - 00:15:17.326, Speaker F: We could have releases out next week.
00:15:17.428 - 00:15:18.030, Speaker E: Yeah.
00:15:18.180 - 00:15:22.754, Speaker A: Meaning by Friday of next week, by sometime next week.
00:15:22.792 - 00:16:01.630, Speaker F: So I think the earliest that from the El side we could fork would be the 27th, 20 eigth, which would feel okay. So Maris is saying they can get one out this week. I think the most aggressive timeline on the El side is really like the last week of February. And Terrence has a question in the chat. So hearing about l two testing, so I reached out to all the teams that were in the top ten ish on l two beats this week. I think pretty much all of them got back to me, but no one had any major issues. All the teams are pretty much in testing phases at various stages.
00:16:01.630 - 00:16:11.010, Speaker F: I think teams will be ready on the l two side to use four on main net around early to mid March.
00:16:12.630 - 00:16:13.042, Speaker E: Yeah.
00:16:13.096 - 00:16:36.250, Speaker F: So that's basically where things are at from l two. So I don't think we should block anything based on where l two teams are at. And I think from the El side we can have people start releasing this week and then potentially the releases coming out next week for the other teams and be ready at the earliest end of February.
00:16:36.990 - 00:16:42.202, Speaker A: Real quick, your doc does not have open access. Yeah, I just changed the link shared. Okay, cool.
00:16:42.336 - 00:16:45.530, Speaker F: Yeah, I'll post an actual screenshot in the chat too.
00:16:45.600 - 00:16:49.594, Speaker A: I think it's interested. Terrence. Yeah.
00:16:49.632 - 00:17:08.500, Speaker B: So from freestyle side, we surveyed the question internally, just like when we will be ready to do this major release. So we still like two weeks because we still have to do some general cleanup and we want to test blockfield further. So I don't think we'll be ready to cut our release next week.
00:17:11.350 - 00:17:16.310, Speaker A: But would be by Wednesday, Thursday following.
00:17:18.090 - 00:17:22.860, Speaker B: Most likely, yes, two weeks will be better.
00:17:34.210 - 00:17:42.270, Speaker A: Any other perspective input on where you stand on where consensus layer teams stand on being able to release?
00:17:45.030 - 00:17:52.420, Speaker C: I think for Lighthouse, probably same sort of timeline like Wednesday, Thursday, the week after next.
00:17:57.280 - 00:18:27.624, Speaker A: Okay. On the consensus layer, is anybody not able to hit that target, which would put us at a main net blog post on that Friday of the following week at the latest if we agreed on that target, which then we'd have to pick a date that puts us in a good time frame from there. Okay.
00:18:27.662 - 00:18:28.680, Speaker E: Jortago.
00:18:30.240 - 00:18:39.660, Speaker A: Yeah. Load star in perspective. Load star Nimbus.
00:18:42.740 - 00:18:44.800, Speaker G: Yeah, we can meet those timelines.
00:18:47.400 - 00:18:48.740, Speaker C: For Lodestar.
00:18:49.880 - 00:18:50.630, Speaker A: Thanks.
00:18:53.430 - 00:19:07.766, Speaker F: So I guess then the two dates that are most reasonable is either Thursday, March 7, which would be like a straight two weeks after the releases. Or Tuesday, March twelveth, which is two.
00:19:07.788 - 00:19:09.654, Speaker A: Weeks plus like three, four days, two.
00:19:09.692 - 00:19:12.630, Speaker F: Weeks plus a weekend after the releases.
00:19:13.790 - 00:19:14.634, Speaker A: Yeah.
00:19:14.832 - 00:19:22.380, Speaker F: I don't know if there's a strong. Okay, so there's a debate in the chat between seven and twelve.
00:19:27.580 - 00:19:30.270, Speaker E: Is there a good reason not to do it as quickly as possible?
00:19:33.610 - 00:19:40.150, Speaker F: I think as long as we have two weeks ish from the blog post, that's like reasonable.
00:19:48.480 - 00:19:51.870, Speaker A: What's the shortest we've done on mainnet before, Tim, do you know?
00:19:57.440 - 00:20:00.428, Speaker F: We had one shorter than that, but that was not great.
00:20:00.594 - 00:20:04.400, Speaker A: Okay, what's the shortest we've done when we weren't an emergency?
00:20:06.020 - 00:20:54.370, Speaker F: Probably I'd have to check, but probably on the order of like two, three weeks. So if people feel uncomfortable with that, we can do the week of March, we can do like the 13th or the 14th, which is like closer to a full three weeks. From the chat that seems to be the main feedback. Twelveth is Tuesday, Wednesday, Thursday of the week of the twelveth. Each have a slot that would work. So if we want to do closer to a proper three weeks, then doing like the 13th or something is like three weeks.
00:21:05.850 - 00:21:35.194, Speaker A: Okay. I think given the constraints of consensus layer, teams wanting or needing two weeks from now, I think it's reasonable. Land on 13. Yeah. Okay. I'd prefer ball 13 over 1415. Just given some room on the post side from the weekend.
00:21:35.322 - 00:21:48.178, Speaker F: Yeah, middle of the week is nice. And then obviously if client teams have like, client teams can start putting out releases as soon as they're ready today, basically as long as we have the date.
00:21:48.344 - 00:21:49.782, Speaker E: And then we'll have the blog post.
00:21:49.836 - 00:22:00.250, Speaker F: Out in about two weeks once we have all the client releases. Okay, so I'll post the information in the chat.
00:22:01.710 - 00:22:05.322, Speaker A: What are we saying the actual deadline for client releases is? Okay.
00:22:05.376 - 00:22:13.360, Speaker F: Absolute playlist is this call two weeks from now. So that's two weeks.
00:22:14.050 - 00:22:44.940, Speaker A: Okay, got it. Okay. Any further comment or thoughts on this? Okay, Tim, should we kind of circulate that information and offer it up in discord?
00:22:45.100 - 00:22:52.530, Speaker F: Yes, I'll put it on discord and open some prs on the specs repo and tweet about it to make it property.
00:22:58.740 - 00:24:05.270, Speaker A: Exciting. Okay. Like I said, I don't believe there's been a post mortem on the opposite relay. Invalid block incident. But I think we know relatively what happened. Do people want to surface details here? Two, is there anything to do today? Obviously epbs and other things that might come in the pipeline are very valid and worth discussion, but are there particular tests that need to be added or security things that need to be layered in or really, is there anything to patch today? Okay, what do you mean by tests?
00:24:05.690 - 00:24:08.534, Speaker D: What do you mean by things that we can do right now?
00:24:08.652 - 00:24:11.286, Speaker A: Yeah, just should the surface something in.
00:24:11.308 - 00:24:30.830, Speaker D: Hive, there's an immediate one. We can just change our circuit breaker so that if we see invalid blocks, we fall back to local production. We are only doing this on missed blocks, on enough missed blocks in an epoch. But perhaps we can be much more aggressive with invalid blocks.
00:24:32.370 - 00:24:38.640, Speaker A: Is no one circuit breaking as invalid as though invalid is missed or just there weren't enough?
00:24:39.010 - 00:24:51.510, Speaker D: We are all circuit breaking on missed blocks, and we are circuit breaking. An invalid block only counts as missed. What I'm saying is that we can add another test. If it's invalid, we just increase the frequency.
00:24:55.070 - 00:25:01.020, Speaker B: But I mean, that potentially allows for DOS attacks, right?
00:25:01.870 - 00:25:04.538, Speaker A: If you give a highway to, what.
00:25:04.544 - 00:25:08.110, Speaker D: Do you mean, Dos? You're going to fall back to local production.
00:25:13.320 - 00:25:32.750, Speaker A: Right. But if you can get all of the honest players to fall back to local production with a couple of invalid blocks, then you might be able to dominate the MEV market more easily. So there's certainly a trade off between the ability to turn this thing off or how easy it is to turn this thing off.
00:25:34.400 - 00:25:47.520, Speaker H: Yeah, Sean just said this, but yeah, if you check the proposer signature and that it was invalid, those two things would be pretty strong signal. Then the only person who could send an invalid block would be like a proposer intentionally.
00:25:49.140 - 00:25:51.504, Speaker A: But if you're 20% of the network and you can turn it off with.
00:25:51.542 - 00:26:08.310, Speaker B: Two blocks for everyone, any builder can do it. Any builder can intentionally just trivially generate, and they just have to be the highest bidder. So I just have to take whatever number, the minimum number of invalid blocks after which we turn office.
00:26:12.460 - 00:26:21.850, Speaker D: But I still don't see what's really the attack here into making people fall back to local execution. I'd be happy if builders didn't exist even.
00:26:24.000 - 00:26:54.900, Speaker B: Well, okay, but I, as a pool, for example, let's say I'm a pool having 20% of blocks, and I can disable math boost for everyone else by sending three invalid blocks. The cost of those might be low enough that my 20% blocks that afterwards I get, I get so much mev out of it that it's worth it for me. So it is an attack on all the other validators who follow this rule.
00:26:55.720 - 00:27:02.120, Speaker H: Yeah. And also, you don't have to circuit break yourself, right. Like, that pool can still keep using medboost.
00:27:03.820 - 00:27:04.570, Speaker A: Exactly.
00:27:04.940 - 00:27:16.270, Speaker B: There's no enforcement for the circuit breaking. It's a local thing, so it's basically a disadvantage for you to have too aggressive circuit breaking. So, like, irrational people just won't do it.
00:27:16.880 - 00:27:18.060, Speaker H: Yeah, agreed.
00:27:20.160 - 00:27:42.740, Speaker C: So usually when we add something like this, though, we make it configurable. So it'd be hard to specifically know that you're going to be able to get some proportion of the network offline, or even certain proposers offline, and we wouldn't have to agree across clients on, like, let's do this after one bad block.
00:27:46.620 - 00:28:42.616, Speaker A: Yeah. Then again, defaults are strong, and the more that you send, the more you'd see the network switching their behavior. I agree with you, but I also agree that depending on the level of the attacker, it can still be a profitable avenue and they can kind of ratchet it up. I guess one question that's worth escalating is obviously a lot of the kind of mev boost. MEV monitoring tools are extremely aware of builders and relays. They see this information surfaced in block explorers and all sorts of analysis. You could imagine circuit breaking more specifically on actors, but the protocol doesn't know about the actors.
00:28:42.616 - 00:29:04.160, Speaker A: So is there actually a reasonable path to circuit break on a particular builder or circuit break on a particular relay? Or is that too kind of heuristic in trying to decide who those players are without a native integration? L1 integration?
00:29:06.120 - 00:29:18.580, Speaker D: Well, you could add some logic to Metboost. Arguably, everyone is using essentially the same software, and you could add some logic itself to Metboost to ban particular relays.
00:29:22.530 - 00:29:39.640, Speaker A: Right, but do I know that the relay was bad? If you're interacting with the relay, you probably know it's bad. But if you're interacting with the relay and it gives you something invalid, then do I know? Can the entire network know that?
00:29:47.190 - 00:29:59.000, Speaker B: I guess currently we don't have a proof that a particular relay created a block. Right, because just because it goes to that relay's address, someone else could fake that.
00:29:59.530 - 00:30:06.694, Speaker A: It's presumably authenticated. Talking with them is authenticated on some level. So you could share that as a proof.
00:30:06.822 - 00:30:09.450, Speaker B: Yes, but we don't currently have that.
00:30:09.520 - 00:30:10.460, Speaker A: Right. Okay.
00:30:11.870 - 00:30:18.774, Speaker C: Also, bids are signed, right? Aren't they signed by builders? Are they signed by relays?
00:30:18.902 - 00:30:28.522, Speaker H: They're signed by the builder, but the relay verifies it. And that doesn't go on chain. That's just from the relay to verify the identity of the builder that sent it.
00:30:28.676 - 00:30:32.820, Speaker C: Right. So we would have to broadcast bids or something.
00:30:33.430 - 00:30:35.534, Speaker D: Yeah, that's what Francesca's been suggesting.
00:30:35.582 - 00:30:57.754, Speaker A: Shatter these things. Yeah. Like if there were an optional gossip channel, I could drop this information to the networking.
00:30:57.882 - 00:31:20.150, Speaker H: Yeah, this kind of sounds like the optimistic v three version, which we talked about a long time ago, but the idea was like, you have a gossip channel for the headers and you have more observability there. I think the main issue here is that in terms of latency, the proposers probably won't get their bids from there because it's just a lot slower than directly connecting to the relay builder.
00:31:21.050 - 00:31:43.230, Speaker A: Right. I'm not saying utilize that channel for selecting the bid. I'm saying I, as the person that interact with the relay, can drop information about my interaction into such a channel so that people can act upon that. If I see that who you interacted with, and I see an invalid block, my local setup could say, oh, I don't want to interact with that entity anymore.
00:31:45.350 - 00:31:47.220, Speaker H: Yeah, that's fair.
00:31:55.200 - 00:32:23.670, Speaker A: Okay. I don't mean to say this group should decide what should happen. I just wanted to kind of go through the exercise of deciding if something can happen that does not require protocol changes to at least contextualize what people might be able to do soon or talk about in follow up conversation. Is there anything else that we want to discuss around this incident today?
00:32:30.410 - 00:32:51.534, Speaker H: I guess it's worth mentioning that this was a bug in the non buggy version of optimistic relaying would have only resulted in one missed slot. So it's not like the optimistic model allows for this. It was just like there was a bug in the relay end, so I don't see it as fundamentally changing anything.
00:32:51.652 - 00:32:58.290, Speaker A: And was the relay bonded, and is the relay doing something with respect to that bond?
00:32:58.710 - 00:33:17.880, Speaker H: Right. Yeah. So the builders are bonded with the relay. In this case, since it was the relay's fault, they refunded the proposers directly. Ben from blocksroute was on this Twitter spaces yesterday talking about it. So, yeah, that's already taken care of in terms of the restitution, I guess.
00:33:20.960 - 00:33:35.510, Speaker A: Which is kind of one of the attempted things to happen with optimistic relays to surface, quote, at least via trust model. Unconditional payment.
00:33:37.000 - 00:33:46.804, Speaker H: Yeah, exactly. I mean, it's not really unconditional because you have to trust that the relay will refund you. And I think that's the issue that people have.
00:33:46.922 - 00:33:55.080, Speaker A: It's trust that they'll refund you and otherwise the network probably. The assumption is people would then not use that relay anymore.
00:33:55.420 - 00:34:07.070, Speaker H: Yeah, exactly. Like if blocksroute chose not to refund the one eth worth of missed slots, then I think they lose a lot of credibility in terms of the validators connecting to them.
00:34:11.650 - 00:34:48.420, Speaker A: Okay. Anything else here? We will have some discussion around current apps designs coming up in the electra discussion. Okay. Is anyone that works kind of in the booth specs landscape interested in specking what a gossip channel around proofs of this kind of stuff would work on, or how that would work? Or is that not something that people want to dig into right now?
00:34:49.510 - 00:34:59.670, Speaker D: I'd be strongly against it because if we are going to go with a protocol change that does something like this, this is already covered in epbs. This is literally covered in epbs.
00:35:01.530 - 00:35:13.180, Speaker A: Right. I guess my argument would be, even if we're going to ship epbs as the next thing and the next fork, we're still talking about twelve months.
00:35:16.350 - 00:35:19.260, Speaker B: I don't think we've made a decision on epbs though, right?
00:35:20.050 - 00:35:22.350, Speaker A: We're not. That was a very conditional.
00:35:22.930 - 00:35:31.294, Speaker B: This depends on actually having a viable construction. So I think. I don't think we should presume anything at this point.
00:35:31.492 - 00:35:40.610, Speaker D: I agree. It's just that my point would be that having something that pollutes with epbs, I would much rather discuss epbs.
00:35:43.590 - 00:35:46.114, Speaker A: All right, and let's discuss it in a couple of points.
00:35:46.312 - 00:35:47.460, Speaker B: Why does it.
00:35:50.630 - 00:36:07.958, Speaker A: Continue to the band aids, the argument the band aids would make it such that mev boost can continue to live another day instead of actually working on kind of the native solution.
00:36:08.134 - 00:36:10.090, Speaker B: No, but that's a terrible argument.
00:36:13.570 - 00:36:52.650, Speaker A: I think the argument is not terrible. If you consider complexity analysis, like if it's 50% as complex just to patch mev boost, then do Epps rate, then maybe then we're talking about it. If it's 1% of the complexity, then that's a different world. I do want to table this. I do want to talk about a couple of things around Electra and then get into the Epps discussion in a couple of points. Okay. There is a desire to figure out what the joint name of Electra is.
00:36:52.650 - 00:38:04.670, Speaker A: Electra and Prague, it seems like. Some believe it's already been discussed and named as Petra. I believe I've seen this in testing in a couple of other don't. This is the last thing in the world that I want to be trying to use our decision making power on. But does anybody want to make a case that's not Pekra with a c? Okay, I'm going to take that as some sort of decision or desire not to talk about this and we will continue forward. Great. Okay.
00:38:04.670 - 00:38:39.210, Speaker A: Based on some discussions with Donkrad that then surfaced into and others that then surfaced into a comment on 7549. There was a desire to kind of like do 7549 all the way and be able to more unify attestations on chain than keeping the kind of residual committee index. But in a different place of the attestation, it seems like that is generally what some of the designers want to do. But Mikhail, can you give us some more context and some of the trade offs here?
00:38:40.940 - 00:39:35.550, Speaker E: Thanks, Danny. So basically this is one more step on top of what was originally proposed by 75 49. And as Denny said, it allows to pack attestations more tightly on chain in on chain structures. And what's nice about it is that considering the current validator set size, we can increase the block space in terms of attestations up to four times. So instead of currently, we can keep attestations for two slots if they're kind of ideally aggregated. This change would allow to do this for eight slots instead of two without increasing the block size in bytes. This is great.
00:39:35.550 - 00:40:58.840, Speaker E: And if attestations were kind of like aggregated really well, this change will allow just to reduce the size of a block, keeping the same information, the same number of votes in it. So basically how to achieve this is turn the aggregation bits into a list of bit lists. So basically every item of this list will represent the bit list of each committee of committee. And also the other change we would need here is to turn committee index into committee bits of the same size, which is 64 bits. And yeah, this is going to be a bit vector which will have bits of the committees that are included into the aggregation bits list. So basically it's a quite straightforward change and we can reuse the same structure for on chain aggregates where many committees will be in one station. Obviously signature will be aggregated for all of those committees.
00:40:58.840 - 00:42:59.656, Speaker E: And also it can be used on the network where just one committee will be in the attestation, in this attestation structure, which is kind of required by the network, by the aggregation algorithm that we currently have, relatively small changes to the spec will have to go over all committees when processing the attic station. And the depline made a great point about complexity of tester slashing messages. And this is really one of the kind of complexities here. So basically this tight aggregation would mean that if we want to create a tester message out of on chain data which are tightly packed, it will mean that we'll have to say if there is just a committee which will have a size of a slot of wildlife that assigned to a slot. So we'll have to keep all those in one indexes of all those, while there is in one attestor message. There is a bit of analysis linked into the comment, so we'll have an increase there. But this more kind of more of a problem for the attachedness where just one or a couple of validators, they can be much bigger than what we have now because currently we have quite good granularity testations.
00:42:59.656 - 00:43:24.340, Speaker E: But for kind of like mass slashings events, this will not be too bad. And we'll probably have to do something at least to reduce the max attestor slashings to one. So you can read about in the comments about this analysis and about the proposed change that I have gone over.
00:43:24.490 - 00:43:54.880, Speaker A: Quickly, really quickly in the proposed changes. You're suggesting reducing the number of onchain associations to eight. Given that you can handle a lot in these bit lists, that reduces the diversity of attestations that can make it on chain. Do you see an issue in the event there's high asynchrony or forking such that you can only capture kind of eight different views? Or is that, do you think sufficient?
00:43:56.660 - 00:44:23.416, Speaker E: Yeah, it's a good point. I think it's pretty much sufficient. I don't think it changes the status quo in that regard. I don't see how differs to what we have today. It might be even better because we increase the capacity of one block so it can accommodate more votes in it.
00:44:23.518 - 00:45:04.150, Speaker A: Well, it's a trade off because you increase the capacity, but you decrease the diversity of that capacity. The potential diversity of that capacity, which it seems like is the proper trade off, is a reasonable trade off, but one to consider at least, because you could do another thing. Right. You could have a more sophisticated counter here that you could have two counters where you can have many attestations that have a small number of bit lists, or you could have fewer attestations that have a large number of bitlists, but then you're adding certainly more complexity to get that trade off space between the two.
00:45:04.920 - 00:45:14.010, Speaker E: Right. But if you have many attestations from different slots, that can be. Right.
00:45:19.820 - 00:45:31.340, Speaker A: How I thought of it before I read it was like you could have essentially two counters, but then certainly more complexity.
00:45:34.260 - 00:45:55.256, Speaker E: Yeah, I think overall, I think anyway, this change requires more deep analysis and this is basically a temperature check. And if there is a desire, willingness of client devs to extend this eap, then we can invest more time in.
00:45:55.278 - 00:45:56.200, Speaker A: Analyzing.
00:45:57.980 - 00:46:15.810, Speaker E: Trade offs of this solution. But I think this changes what basically what actually the original proposal was supposed to enable and not doing it, not exploring the space.
00:46:19.380 - 00:46:54.570, Speaker A: Yeah, I think something in this direction makes a lot of sense if we're going to be cleaning up the committee index and at least the temperature check on everyone in the pr is good so far. Does anybody have any additional comments? Okay, I would say you should go for the more cleaned up version. Cool.
00:46:55.180 - 00:47:25.840, Speaker E: So I'll do some analysis and try to come up to spec changes. One other question I had is probably that we can have it as a separate Eap, but we have it in the next hard fork. I don't see it makes sense to have it as a separate eap. So it can be in this Eap, but if we consider it for a later inclusion, it could be separate Eap.
00:47:29.050 - 00:48:25.910, Speaker A: Yeah, it seems like the relative complexity is marginal on top of what was already there, so I'd hope not to do it in a two step fashion, but open discussion. Okay, great. We're going to continue the conversation around what to include or not include in electra. I believe two weeks ago we did not have our full conversation around SSE, or at least give enough time for discussion. Etan, is there anything additional you want to bring to this group, or do people have questions for Etan? Again noting that a lot of this complexity is on the execution layer. And so I do think that a decision point, certainly the contenders layer can say we don't want to prioritize this, but I think a lot of the decision point on the complexity ends up on the other side of this equation. But nonetheless SSC.
00:48:27.450 - 00:49:13.110, Speaker G: From my side, I don't think I need to add some more explanations from last week. I went through all of them. I think on the consensus side, the stable container one EIP 7495 may also be useful to have forward compatible generalized index for execution, payload, beacon state and beacon block just because those structures keep changing. And I think if we can make them forward compatible, it would help decentralized staking pools such as rocket pool to require fewer engineering to keep up to date with the various forks.
00:49:14.650 - 00:49:24.220, Speaker A: Right. And to remove a piece that might need to be governed. Engineering is one thing, and then also figuring out if and when and how.
00:49:25.230 - 00:49:27.100, Speaker G: Review and stuff for sure.
00:49:30.590 - 00:49:43.660, Speaker A: Yeah. What is the temperature check on doing kind of a one time change on these data structures to make them forward compatible, forwardly stable.
00:49:52.040 - 00:49:57.450, Speaker G: For SSC library? It's quite easy. By the way, it's not a big deal.
00:50:02.300 - 00:50:10.570, Speaker A: Right? Does adding that kind of one time break in the structure of the tree, is that a huge engineering complexity? Does anybody want to weigh in on that?
00:50:20.290 - 00:50:40.100, Speaker G: It's only for new blocks though, like from the fork, you just have a new block type and difference is that those blocks you can then use the same parser also for future blocks. I'm not sure if everyone reviewed this already.
00:50:42.810 - 00:50:50.920, Speaker A: Right? Anybody want to give any signal in one way or the other? I have pretty much zero temperature check on this.
00:50:58.320 - 00:51:15.510, Speaker C: It seems like a good thing to have. I haven't personally looked into this, so I don't really know how complicated it is. I know people are generally wary of new SSD types because the ones we have are super well tested, but it seems like a good thing to have.
00:51:22.440 - 00:51:24.710, Speaker B: In terms of engineering work.
00:51:28.120 - 00:51:29.012, Speaker A: Changing fast.
00:51:29.066 - 00:51:36.890, Speaker B: SVC library is always a pain, but if it's not too large of a change, then I guess we can handle it.
00:51:53.770 - 00:52:46.380, Speaker A: Yeah, Casey's surfacing that he'd rather wait until this is bundled with more SSC changes. Okay, is this something that teams want to do a little bit of diligence on and we can talk about again in two weeks? Okay, I will pop that on the next agenda and pop a message into discord saying, if you want to take a look at this to have a more in depth conversation, now's the time. Okay, any other SSD discussions? Great. Thank you. Potas epbs.
00:52:50.230 - 00:53:22.640, Speaker D: All right, so I don't know how to start this discussion, actually. So I think the problem that we've seen on mainnet is not like a light problem or a minor problem. It's not the issue that nine blocks were missing or that validators got refunded or not by relay. The problem is that we need to trust the relay for this. And we don't even know what the check was. We don't even know what the fix was. This closed source software and this development is happening on a black box.
00:53:22.640 - 00:54:30.770, Speaker D: And these are five players that are relaying all of our blocks, or 90% of our blocks, and ten players maximum, that are building these blocks. I think what we need to do is to decide that this is a priority that we should not have in Ethereum, a trusted player making these decisions with a closed source software being the one that is responsible for paying or not, for refunding validators, for even deciding which transactions are censored or not. Once we make this a priority, then we can discuss whether or not there are viable designs for epbs. Certainly we're not going to be discussing this in a meeting like today. I maintain that we have a viable solution for epbs that could be implemented in less than a year's time, and I am willing to defend this in an actual meeting. With the community. And these things should not be discussed in small meetings where EF research has some point of view, some biased point of view for EF research.
00:54:30.770 - 00:55:19.140, Speaker D: Some other client depths, like we are in prison, have another biases and we're focusing on different kinds of design. We should have something like the interrupt that is going to happen soon in May, and we can come up with a design there, decide whether or not the current design works or not. But what I'm asking is for this to be prioritized, and if the scope of this orc is kept for 2024, then this cannot be included. But if the scope of this fork or the next one is maintained for 2025, then I would ask that we use the time to discuss this thing seriously and to allot the time for the interrupt in May and come up with a compromise to ship this by 2025.
00:55:21.920 - 00:55:38.320, Speaker A: Thank you. I have a quick question. Can you explain, in a theoretically good EPS sound EPBS design, what would have gone differently in this incident?
00:55:41.620 - 00:56:09.180, Speaker D: There are minor things that are actually different, but some of them are the following. So the blocks would not have been missed. The blocks would have been empty. The consensus part of the block would have been included. Inclusion lists in those consensus part would have been included and enforced in the next block. No matter how many payloads were missing in the middle. Payment would have been immediate, unconditional, and for any amount and not trusted by the relay.
00:56:09.180 - 00:56:40.068, Speaker D: And finally, the payloads themselves would have been signed. So I would have gotten my valid gotten a signed payload. Exactly. The payload itself would have been signed by an entity that is in protocol, and validators can actually, now they themselves decide whether or not they have a way to ban them. Or I mean, each client could then decide if I'm going to ban those builders or not, instead of, or at.
00:56:40.074 - 00:56:43.530, Speaker A: Least like how to interact with them on an economic level. Right?
00:56:44.220 - 00:57:19.010, Speaker D: That is building the block signs it, then that entity is responsible for the block. Currently, the validator itself is responsible for something that is not producing. So even if the builder decides to go with a relay, instead of opening itself an HTTP point, so that validators ask for the builder directly for the header, even if positive bbs, the builder decides to use a relay, the relay whomever is building the block will be signing them and we can ban them, we can react to them, which is not something that the validators were allowed to do in this event.
00:57:23.490 - 00:57:42.306, Speaker A: Sure. Just real quick. Stokes does note that as we previously discussed, you could potentially map some of this transparency into a gossip channel because of the way signatures work, we can.
00:57:42.328 - 00:57:50.550, Speaker D: Continue adding small patches and small patches and small patches. Instead of actually dealing with the issue, which is relays are trusted players, let's make them trustless.
00:57:52.730 - 00:57:57.462, Speaker A: Thank you. So we got a few hands up, Terrence. Yeah, sure.
00:57:57.516 - 00:57:59.574, Speaker B: I just wanted to add on top to that.
00:57:59.612 - 00:57:59.814, Speaker H: Right.
00:57:59.852 - 00:58:14.454, Speaker B: So today, EPBS is one solution to the problem, but the fundamental problem is that today the builder API is basically not incentive aligned with the rest of the protocol.
00:58:14.502 - 00:58:14.810, Speaker H: Right.
00:58:14.880 - 00:58:23.022, Speaker B: Because you have literally 90% of the block that's relaying outside of the protocol. But the protocol does not have enforcement on that.
00:58:23.076 - 00:58:23.342, Speaker H: Right.
00:58:23.396 - 00:58:36.382, Speaker B: And there are two factors. The first factor is basically cost, right. Because relay are spending tons of money a year they're doing this work, but they have no way to monetize it. And the second factor is also the schedule.
00:58:36.446 - 00:58:36.674, Speaker A: Right.
00:58:36.712 - 00:58:37.460, Speaker F: For example.
00:58:39.430 - 00:59:02.540, Speaker B: How often when the client released already, and then we look at each other and then we're like, well, we still have to wait for Matte boost. We still have to wait for Matt boost relay. It definitely adds a lot more complexity to basically adds a lot more complexity to the process of the protocol. Basically. I think we need to do something here.
00:59:09.510 - 00:59:14.102, Speaker A: Got it, John? Yeah.
00:59:14.156 - 01:00:09.282, Speaker C: So I think the idea of separating the consensus information from the MEV incentives is. It generally makes sense. Specifically, though, I feel like a lot of the problems could be solved without as extreme a solution as bringing builders in protocol. Maybe that is good, maybe there's the end state, but for example, guaranteed validator payments. Could you do that via using inclusion lists? Like in the current inclusion list designs? You just require the builder to also include with their bid an inclusionless transaction that has the payment. Then the other thing people have been mentioning is just gossiping. Bids, I think would be valuable and we could pretty easily implement some sort of tracking with builder signatures, builder public keys.
01:00:09.282 - 01:00:12.760, Speaker C: But that's it for me.
01:00:15.760 - 01:00:23.490, Speaker A: Go ahead. Sorry, did you see me?
01:00:25.060 - 01:01:31.444, Speaker B: I didn't hear. Yeah. I'm not against epbs, but overall, I think realistically, all epbs constructions are going to be quite major protocol changes. So the potential tech debt that we're getting from these, if we don't implement a good solution, if we find out later that it has major flaws or we come up with a much better one, is actually way bigger than fixing a few things around mefus, which doesn't actually involve core protocol changes at all. So I think I would be very careful. I think my feeling is that we are not there at the moment, specifically with the constructions that I know of that have major flaws in terms of not properly protecting builders from being exploited in balancing attacks and things like that. This is actually a huge concern I have about them, and I think before those are fixed, I feel like it's not really worth implementing them.
01:01:31.444 - 01:02:22.308, Speaker B: Because to me the trust relays have two kinds of trust. They have the trust by the validators who have to trust the relays. And I think that is minor because again, we can easily blacklist them if a relay misbehaves. And for example, if said relay, I don't know, well, whoever it was didn't pay out those validators, then I think lots of validators would now say, well, I mean, that sounds terrible, I'm not going to use them anymore. So this is a minor part of the trust. A much bigger trust problem is that relays can exploit builders by analyzing their strategy, stealing their mev and so on. And if we allow validators to exploit builders, then that part is actually not solved at all.
01:02:22.308 - 01:02:37.550, Speaker B: And we will actually continue having relays because builders will still want that because they can otherwise be exploited and are not willing to include their high Mav transactions. And so then in the end, we haven't fixed anything at all. We will still have the relays and we will still have that problem.
01:02:44.410 - 01:02:44.870, Speaker A: Yeah.
01:02:44.940 - 01:03:27.042, Speaker D: So I think I know which attack Dan rec is referring to, which is something that is not guaranteed by the sort of like designs. I'm not willing to enter into a technical discussion of what is a good design of EPBs or what's not. But I do want to say that I would argue against this being a large protocol change. If you look at every design that we have, they all will have the same set of ingredients. So this is not going to change whether or not you go with PTC or another station. All of them more or less rely on the same sort of like two slots approach two reveals, two rounds of votings on two rounds of attestations one way or another. So they're all more or less the same.
01:03:27.042 - 01:03:40.300, Speaker D: And we are already discussing that. There were serious proposals of having inclusion lists and MaxDB for the current fork, even scoped for 2024. And those are the largest changes from the point of view of the CL side.
01:03:43.230 - 01:03:47.334, Speaker A: Component. You don't think is like a huge engineering?
01:03:47.462 - 01:04:19.670, Speaker D: No, actually not. I'm not. From the CL side, payload validation changes a lot because of inclusion list, but this is already part of inclusion list. The changes that are actually on for choice for the CL, on the implementation side are the minor parts I am actually already implementing for PRIsM. One design of ePbs and ePbs alone is much simpler than the rest. So adding MaxCB is the most costly one, which is the one that I'm delaying for the end of the implementation.
01:04:20.330 - 01:04:34.758, Speaker A: Okay, so my intuition here is that getting into timing and fundamental data structures of having kind of this two part data structure would be a massive engineering change. But you say otherwise.
01:04:34.934 - 01:05:07.300, Speaker D: No. Adding changes that are on poor choice are typically not that complicated to implement. Changes on processing are the things that are most complicated to implement. It's true that it's not a light change and it's not something that is going to happen this year, certainly. But I claim that the biggest part of the complexity of implementing epbs comes from Max CB changes and inclusion lists. I mean, if we go with a bonded in protocol builder, which is state.
01:05:11.010 - 01:06:15.922, Speaker A: Okay, so there has been a lot of design and research and discussion over the past more than two years on this, and you have something of a spec that you're working off of and a prototype that demonstrates a level complexity. Whenever I see this open up, there's a lot of questions as to what are we even optimizing, what is the right end goal of this? And it seems like there's a lot of varying opinions on that. And so the decision to include this first becomes the decision to figure out what is the design. And I guess, are you making the case that over the next few months, figuring out if and what a consensus design is on here should be prioritized, or are you making the case that.
01:06:15.976 - 01:06:58.000, Speaker D: Yeah, so my case has been always the same on these meetings in the last few weeks that I think we should prioritize in deciding what's the scope for the current forecast. If the scope for the current forecast is 2024, then I don't argue anything and I'll argue against any big change. And I will hope that we plan something on the interrupt in May for 2025. If the scope is 2025, then I would argue that we need to consider epds for the next four months. And either way, I would want to have by the time of the interrupt some designs so that we go there and we fix one particular design during this.
01:07:00.290 - 01:08:31.646, Speaker A: That's what I was going to argue is if there is a sense of either urgency or a sense of the ability to actually hone in on design at this point. Regardless of the lecture conversations that happen over the next however many weeks, there can be kind of a parallel thread that attempts to hone in on this design with maybe some breakout calls and hone in on this design as we meet in person in May. You know, I don't think that we can. So that's my, that's my big question is like, do, are we at that point? I believe you. You believe we're at that point that we can have a very productive three months to kind of hone in on this. Is that the general feeling, or is the feeling that there are many people from, at least a couple of people from various teams are willing to be a part of that conversation? To hone design is the next logical step to have a breakout call about this, to at least begin to answer the question of whether people are willing to be putting a lot of effort into this or even moderate and consistent effort over the next many months. Okay, I see some thumbs ups.
01:08:31.646 - 01:08:48.840, Speaker A: I see some comments. It seems like at least we'll have five people on the breakout call. Okay, Tim, do we usually schedule breakout call times on the call or do we circulate something async?
01:08:49.820 - 01:08:51.748, Speaker F: Let's try to do it in the chat.
01:08:51.924 - 01:08:52.600, Speaker A: Okay.
01:08:52.750 - 01:08:56.724, Speaker F: 14 utc is usually a good time indeed.
01:08:56.772 - 01:09:20.980, Speaker A: Eclock. Okay, cool. Let's bounce some times around in the chat, see if that we can get on call again. R and D call that's trying to bring together the threads, or at least bring together the attempt to bring together the threads. Very cool. Thank you, Pete. Thank you everyone for that discussion.
01:09:20.980 - 01:10:05.360, Speaker A: Let's move on to the next thing. To be frank, my read after the call two weeks ago was inclusionless. The general consensus was to table my read on that was challenged by a number of folks and said, no, there's still discussion to be had, and not just from the authors of inclusion lists, but from a number of folks. So it is back on the agenda. And Mike has had some, I think very illuminating, especially the spec change overview, to help us understand the complexity. Mike, do you want to reintroduce this topic?
01:10:07.060 - 01:10:42.476, Speaker H: Yeah, sure. Thanks, Danny. I guess I'll post two links in the chat. The first is this unconditional, inclusionless post on e three research. And then the second is the one Danny mentioned, which is this overview. And yeah, I guess the first doc is kind of going through this new design and kind of discussing the relationship with the Freeda post and kind of like bringing back some of these designs that we've been hashing. I think actually we're kind of converging on something that we're all happy with.
01:10:42.476 - 01:12:22.120, Speaker H: And so I started kind of just taking a look at the spec, which is that second doc. In general, it seems to me like the goal of that doc was rather than trying to iron out each of the kind of individual points fully more to kind of scope what the changes in the spec would look like, which parts of the spec it would touch. So both on the consensus layer side and the state transition function for the execution layer and in the engine API, just kind of defining the interface between the two. So yeah, I guess thanks to all the members, most of them in this call, who helped kind of scope that out and review those prs. But yeah, I think in general, trying to convey the message that it doesn't have to be a massive change and that it could be really beneficial to include it in Electra, just from both the timing perspective of that censorship could change dramatically over the next months and weeks. There's kind of one builder, one neutral builder that we depend on to include a certain subset of transactions, and that could change very quickly and also just getting some version of censorship resistance in prod and starting to collect data on its usage. And I think of censorship resistance as this defense in depth thing where this might not be the end game, but some of these farther out research ideas like multiplicity, and they could all kind of synergize well with inclusionless.
01:12:22.120 - 01:12:58.808, Speaker H: And yeah, I guess in general it feels worth trying something rather than letting it go longer with the current censorship that we're seeing on main net now. So yeah, I guess that's the pitch. That's the reason I wanted to get the spec doc out there. I think have talked to a number of different client teams, both on the execution and consensus side, just to kind of get their take. And generally people seem keen to learn more and happy to engage. So not sure exactly. I think maybe like a breakout call for inclusionless specifically could also make sense.
01:12:58.808 - 01:13:23.250, Speaker H: Xiaoi recommended that. So if that feels like a reasonable next step, we could bundle it with the. I mean, I definitely think there's a lot of overlap in terms of the themes that will be discussed there, but I also think having its own talk could be useful, potentially. So yeah, thanks for the time. I think I'll leave it there, unless there's any urgent questions, I guess.
01:13:27.100 - 01:14:06.034, Speaker A: Yeah. Has anyone been able to look at Mike's spec change overview and want to weigh in on complexity, perceived complexity? Okay. Is there an appetite to get on a call with Mike and others that have been doing R and D on inclusion list to dig a bit deeper sometime in the next ten days?
01:14:06.152 - 01:14:30.090, Speaker D: Potas so this design is essentially exactly the same as what's already included in our EPBS proposal, and I definitely want this in, but as I said before, if we're going to scope this work for this year, I think it's impossible. I think a big chunk of the complexity of epbs is included in this and in MaxB.
01:14:32.670 - 01:14:37.222, Speaker A: You keep saying Max EB in relation to epbs. Is Maxdb a dependency for epbs?
01:14:37.366 - 01:14:50.350, Speaker D: Well, not for epbs. The same thing for inclusion list. Inclusion list shouldn't be a dependency of epbs, but both of them are pretty much a requirement for my kind of epbs.
01:14:57.810 - 01:15:24.166, Speaker A: Right? I did take a look at the spec change overview and was moderately convinced that it's actually not a super complex change. But you believe that it is a large portion of the EPBS complexity already? Like you would say it's 50% of the epbs complexity or 35% no, not yield.
01:15:24.278 - 01:15:28.140, Speaker D: I think for EPBS, MaxdB is the thing that scares me the most.
01:15:36.100 - 01:16:24.610, Speaker C: I also checked out my expect and I did think it looks simpler than I was expecting, so I definitely think it's feasible to include an electra. I still think Max EB seems like a more important change to me, just because at some point the size of the validator set is going to be an issue and the migration itself could take a while. But yeah, I think right now I would lean towards trying to include both MaxCB and inclusion lists and not do full epbs. But yeah, it's just personal vibe right now. I don't know if that's too much.
01:16:26.260 - 01:16:35.430, Speaker A: And what's your perspective on, since we're here, peer dust and where that might or may not fit into what we want to do?
01:16:40.860 - 01:16:43.050, Speaker C: Like I think the peer Dos changes.
01:16:43.500 - 01:16:44.250, Speaker H: Are.
01:16:46.860 - 01:17:14.470, Speaker C: Since they aren't hard fork dependent, I'm not thinking about them as much. To me it seems like they can be worked on in parallel to a greater degree than some of these other things. But for us, I would say that's been the highest priority change, and it's got the most progress on it already.
01:17:21.260 - 01:18:57.570, Speaker A: Okay, back to the question. Is there a desire to have an inclusionless breakout? Is there a desire to have it as 15 minutes of the breakout that's scheduled for epps? How do people want to approach discussing this further, or at least wrapping their heads around the complexity and making informed decisions from here? If there was a separate one, would people attend? Seems like Francesco, Terrence, Mike, others would attend. Okay, well, a few people will be there. Let us discuss in the chat. Are we agreeing on other eips for inclusion picture? In this call we're continuing to talk about some of these big ticket items that have a difficult trade off space in terms of when to add them, if to add them, when to prioritize them, and competing complexity and priorities. So yes, I don't know if we're going to agree, but we're going to continue to talk. So the next thing is on the list of your dust.
01:18:57.570 - 01:20:56.970, Speaker A: I'll echo my opinion on one of the authors here. I think it's at least from my interpretation, a number of teams intend to put networking resources on this. It has a good degree of high parallelizability and doesn't necessarily have to be shipped with the same type of fork. The shipping peer dos without a hard fork means that there's no gas change, but that is a potential strategy to do here. Also, shipping peer dos with a tiny fork to change the gas, the data gas limit is also kind of a feasible path. I do personally think that it can continue to be on kind of an independent r and D rail that is highly paralyzed, and I guess that's at least for a few teams, seemingly the intention, because that's just what's happening is there. Does anyone want to make the case for not only having it on an independent r and D rail to be shipped when it's ready, but to also make the case for having it stated and intended to actually go out with Electra at this point? Or is that just not where people stand on this? Again, does anyone want to make the case to say peer dos should be stated and intended and put into the list for electra, or should it just remain as a high priority paralyzed rail? The default is the latter speak now if you believe the former.
01:20:59.310 - 01:21:22.580, Speaker C: So I just sort of think that if we pursue some of the bigger ticket items in electra, and I think it's possible that since pure DOS is just cl and would require smaller changes for a hard fork, then maybe it might even come sooner. So I think at least Electra is kind of my point of view.
01:21:29.930 - 01:24:39.920, Speaker A: My other strategy here is that you could say tentative inclusion for Electra, but it's because it's super cl dependent and because it doesn't touch the safe transition. It's also something that could be ripped out, meaning if it were to be the blocker, it's easy for it to not be the blocker on getting a main net. Any other opinions people want to surface on how to handle this? Okay, I would say very much agreement on high priority parallel item, but that we can have these breakout calls and continue to discuss a couple of these other things that may or may not go in before Pierdos surfaces anywhere in relation to Electra, but that we can regardless it's something that people are and will be working on, but that we can pop this up in a couple of weeks and contextualize it after the breakout calls. Reasonable. Okay. And then another fun one, maxi B. Where do people stand in relation to that? Is there further discussion that can be had today or does it need to also be contextualized by what comes out of some of the discussions that are going to happen outside of this call in the next couple of weeks? Any status update here? Any further thoughts? Okay, so this will come up in the conversation again in two weeks, and potentially there will be the ability to contextualize or foil against some of the other things that have been thought about in that interim.
01:24:39.920 - 01:25:37.530, Speaker A: Okay. Other things people want to talk about in relation to electra today, other discussion points for today. Anything related to research specification or just general open discussion? Am I live? Can anyone hear me?
01:25:38.300 - 01:25:39.450, Speaker D: You're live.
01:25:41.600 - 01:26:09.316, Speaker A: Thank you. Okay. I appreciate it. These are tough conversations to have. There's a lot of really important work to do, a lot of great research and specifications to dig through. So thank you for bearing with me and working through it all, and we'll pick it up again in two weeks. Take care, everyone.
01:26:09.316 - 01:26:11.524, Speaker A: Thank you. See you guys. Thank you.
01:26:11.642 - 01:26:13.920, Speaker H: Thanks, everyone. Thanks, Danny.
01:26:14.000 - 01:26:17.268, Speaker A: Thanks, Matt. Bye bye. Thanks.
01:26:17.354 - 01:27:18.990, Speaker H: Bye much.

00:01:07.234 - 00:01:08.294, Speaker A: And we are live.
00:01:10.754 - 00:01:24.134, Speaker B: Okay, great. Let's see here. Let me grab the agenda. Welcome, everyone. This is consensus layer fall 131. I'll drop the agenda in the chat here.
00:01:26.174 - 00:01:28.054, Speaker C: Maybe. Let's see.
00:01:28.214 - 00:01:29.634, Speaker D: Let me just close obs.
00:01:30.894 - 00:01:31.954, Speaker C: Let me see.
00:01:33.014 - 00:01:34.554, Speaker B: Are we still good with the stream?
00:01:38.854 - 00:01:40.594, Speaker C: Okay, I got a yes.
00:01:42.534 - 00:02:07.052, Speaker B: Cool, then. Okay, let's get started. Yeah, everyone, this is the call 131. And yeah, I imagine we'll have a pretty packed agenda today. So let's get to it. First, let's talk about Duneb. There are a few things that we should bring up.
00:02:07.052 - 00:02:12.964, Speaker B: The first one is. Can you. There we go.
00:02:13.044 - 00:02:17.476, Speaker C: Okay, great. Let's see here.
00:02:17.580 - 00:02:37.832, Speaker B: Yeah. First thing is clarify voluntary exits gossip topic after capella. Does someone want to take this over? I think I know at a high level what's going on. I have helped this topic.
00:02:37.928 - 00:02:43.728, Speaker C: I want just to be sure that all clients understand it on the same.
00:02:43.776 - 00:02:46.072, Speaker B: Way that we should use the new.
00:02:46.128 - 00:02:52.834, Speaker C: Topic for this and maybe change a bit burden in this line.
00:02:55.214 - 00:03:29.174, Speaker B: Okay. Yeah, I mean, I think the sort of confusion here is that we're using this old domain for verifying the signatures. But the gossip topic, I believe should be for Deneb. Does that align with everyone's understanding? We have a thumbs up, two thumbs up. Three thumbs up. Okay, so I assume everyone's doing this and we understand and then. Yeah, from there, if we can clarify the language of the pr, that works.
00:03:29.174 - 00:04:13.986, Speaker B: So we're good on this? I'll assume silence is yes. Okay, next up, we have comment here from Terrence. So I'm sure you're all aware, but there was a bit of a network outage, likely due to some interactions between the consistent clients and blocks routes, the relay. Terrence, do you want to give us an overview of what exactly happened? Sure.
00:04:14.090 - 00:04:14.754, Speaker C: Happy to.
00:04:14.834 - 00:04:48.660, Speaker E: So, yeah, so people can read my comments. I don't want to repeat. So since then, blood trust put their postmortem. Michael also has their response. And the gist of the issue is that there's definitely some, I would say, edge case with how beacon API is interpreted and used. So currently, Beacon API proposed block endpoint has this option to basically say the following. If I see the similar block, it's already gossip on the network.
00:04:48.660 - 00:05:06.376, Speaker E: I will not propagate the blocks. By propagate, I mean I will not even send the block out as the first hop. But this is to prevent unbundling attack. So basically all the clients do that, do basically implement that.
00:05:06.440 - 00:05:07.824, Speaker B: But the open question is that what.
00:05:07.864 - 00:05:54.374, Speaker E: Do we do with the blobside car? Because blocks icon doesn't have this inheritance snatching condition. So currently, I think before that, lighthouse and prison, I can say for them they do not broadcast the block side card if they see there's a similar block on the gaussian network. But because of that, bloodstroke's block cycle was not able to be caused. So since then, we have updated the behavior to basically fix that. So Michael is also working with the rest of the client team to make sure their beacon API is basically kind of working for the rest of the relay as well. So, yeah, that's pretty much the update.
00:05:55.874 - 00:07:01.554, Speaker B: Cool, thanks. And, yeah, I mean, I don't think anyone hears from box route to kind of respond, but, yeah, ultimately, I mean, ideally this wouldn't happen. We have, like, a lot of testing in place to make sure things like this don't happen, but this one kind of slipped through the cracks. So, yeah, I guess from here, we'll just work with them to try to prevent things like this in the future. Okay, is there anything else for that anyone wants to talk about? Any data, any stats on bobs, anything like that? Okay, that's good. Then next up, I want to talk about Electra. So I imagine this will take up the bulk of the call.
00:07:01.554 - 00:08:15.400, Speaker B: So just to frame things, it'd be great to go ahead and move forward on figuring out what electra looks like, even just an initial scope, especially so that we can aim for Devnet as soon as possible, you know, even ideally within, like, say, the next month. We have things ready to go. Barnabas asked about 25 37, so I was only including things for the Cl, and there really aren't any Cl dependencies for 25 37. Does that answer the question, Barnabas? Okay, we got a thumbs up, right? So I started with the four that have been included just going off of this EIP 7600 for the hard fork meta. And, yeah, I think it'd be helpful just to go through each one of these in turn, go through the status of the spec. If there's any open questions we can talk about now, that'd be great, but ultimately try to figure out what we need to do to get these to a place where we can implement Devnets again, say, in the next month, really as quickly as possible. So the first one is 6110.
00:08:15.400 - 00:08:42.054, Speaker B: This is essentially making deposits work a lot like withdrawals today, where they are sort of synchronously produced. If you deposit within a block, the deposits then passed off to the Cl, who then processes that on the beacon chain. Are there anything here? I mean, I looked yesterday. It seemed actually like it was in a pretty good shape. Is there anything anyone wants to talk about? Any open questions on this one or do we feel pretty good about it?
00:08:47.034 - 00:08:47.346, Speaker C: Yeah.
00:08:47.370 - 00:08:48.094, Speaker B: Mikael?
00:08:50.154 - 00:10:31.244, Speaker C: Yeah, so this AP has a consensus spec test with a good coverage and there is the pr to the SpeC which bundles 6110 and 7002 which is in progress. So yeah, that's also great about 6110. I was just going to raise a bit of awareness that considering the max effective balance is in electro as well, and considering that the max effective balance introduces the pending deposit skew, there was just a thought that we could leverage on having this queue to finalize the deposit flow before actually creating new validators. It is helpful for preserving the invariant of the pub key index matching. And if this can be resolved on the SPAC level, on the protocol level, could probably get rid of additional complexity in CL client implementations where they will would need to manage this cache per each work independently. So because the same pubkey can get different indexes across different ports, this just one of the things that probably could be introduced. I'm going to play with it in next couple of weeks and provide the update if it were doing or not.
00:10:31.244 - 00:10:33.444, Speaker C: We will decide later on.
00:10:36.104 - 00:11:24.766, Speaker B: Great. Yeah, that'd be great. If you want to open an issue or even make a pr to explore, that sounds good. Okay, anything else on that? Otherwise we'll move to 7002. Okay, let's go to 7002 then. So this is the execution layer, initiated exits and we'll get to this with maxvB, but we also want to include, I suppose we're calling them partial withdrawals. Does someone here want to give an update on 7002 again, I think the spec is in a pretty good place except for the partial withdrawals bit.
00:11:24.766 - 00:11:40.914, Speaker B: So it looks like the EIP would need to be updated and then also the pre deploy assembly. Litclan or Mikal, I think you guys have been working on this.
00:11:45.954 - 00:12:28.994, Speaker C: Or do you want me to share the last update? Yeah, I think you've been working on adding partial withdrawals, so maybe you can share how that's going. Yeah, yeah, sure. So there is a pr into the assembly, into actually the repository where the assembly code for the contract is sitting. So I just send the pr to the chat. Yeah. In this pr basically what we have is adding the amount field. The change is relatively small because the amount field is appended to the pub key data and stored.
00:12:28.994 - 00:13:05.330, Speaker C: The storage slot for the rest of the pub key bytes can accommodate the amount as well. Yeah, so it's relatively small pr to the code and once we finish working on it, I think it just needs review and merge. And then merge after that review. Yeah, we will update the IP. That's it basically. And. Yeah, also the corresponding change would need to be done to the engine API as well.
00:13:05.330 - 00:13:10.774, Speaker C: Um, and. But it's going to be relatively small as well.
00:13:11.314 - 00:13:17.094, Speaker B: Right. And for the engine API, it's just changing execution payload, right. There's no like additional fields that we need.
00:13:18.674 - 00:13:46.374, Speaker C: Yeah, it's changing the, we already have the back for electra, a bootstrap with 6110 and 7002, I mean, engine API spec. So we just need to add an amount field to the exit data structure and basically rename exit to withdraw request to generalize this thing. Yeah, but that's just renamed thing.
00:13:48.914 - 00:13:49.746, Speaker F: Cool.
00:13:49.930 - 00:14:04.436, Speaker B: Okay, sounds good. Okay, if there's nothing else on that one, we'll move to Max EB 7251. I think Mark is on the call somewhere.
00:14:04.500 - 00:14:05.124, Speaker C: Yep.
00:14:05.284 - 00:14:06.384, Speaker B: Can you guys hear me?
00:14:06.804 - 00:14:07.784, Speaker C: Cool. Yep.
00:14:08.324 - 00:15:11.544, Speaker D: Yeah, so we've been chugging away at Max EB for a while now. In terms of the spec, it's been merged into Dev. Most of the pieces are in place, obviously still minor changes and things being updated, and that will continue for a while. And then there are a few outstanding questions that we still need to answer before we can really stabilize it. So, first of all, when a validator opts into being a compounding validator, they are then exempt from the withdrawal suite until they hit the Max EV of 2048. And a feature that we could include are custom ceilings where auditors could configure a custom ceiling up to 2048, but potentially lower if they want to still hit the withdrawal sweep. And it's, I mean, obviously it's a little more to implement, but it depends on what the appetite is for that from the community.
00:15:11.544 - 00:16:49.542, Speaker D: We did speak with Lido yesterday, and they said it was nice to have, and it's certainly nice to have for solar stakers, but it's not something that at least Lido, I guess it's not mission critical for them. So that's something to discuss. And then the second bigger one is regarding consolidations of validators. So in the third breakout call, we were kind of leaning towards, there's basically two options for this. One is a beacon chain operation similar to BLS, to execution changes, and another is to have it be execution layer initiated similarly to the new deposits in the exits or the partial withdrawals. And so in the third call, we were kind of leaning towards have it being a beacon chain operation because it was lower complexity and we kind of made the assumption that all validators that shared the same withdrawal credentials are fungible with each other. But then in the last call yesterday, we had someone from Lido come in and they said that this kind of breaks their accounting both on and off chain and that it would be ideal for them if the withdrawal address had some ability to either initiate or gatekeep consolidating a validator because there's a risk that they wouldn't be able to update their contracts in time for the fork.
00:16:49.542 - 00:17:32.214, Speaker D: So this kind of puts execution initiated consolidations more or less back on the table and we need input from the wider community to see if this is something they have an appetite for. So like I said, Lido seems to have an appetite or is worried about that they won't have time before the fork. And I know, I don't believe it breaks anything with rocket pool, but I do know that they like the feature, just, it gives more, it's just more of a beneficial thing rather than something that would break their contracts. But yeah, basically those two issues.
00:17:34.474 - 00:17:34.762, Speaker C: That.
00:17:34.778 - 00:17:36.454, Speaker D: We need wider input on.
00:17:37.074 - 00:18:04.034, Speaker B: Gotcha. Thanks. Yeah, I agree with PoTuS here in the chat. Just like servicing on your first point, like partial draws, like with 7002 seem to get at the same thing. I guess the trade off then is, yeah, maybe there's more transactions you have to send. But yeah, I think whatever we can do to reduce complexity is at least should be very strongly weighed. Yeah.
00:18:04.034 - 00:18:31.154, Speaker B: And then the other point, yeah, I guess we'd want to add execution layer consolidation initiated. Well, execution layer initiated consolidations. So, yeah, I mean, again, I would just say let's be mindful of scope creep. If we can get away without it, then that's strongly preferable. Do we feel like we have a way forward to answer these two things?
00:18:33.454 - 00:18:54.784, Speaker D: The alternative that Lido was asking for was like, I guess execution layer gated consolidation. So it might still be initiated, but I don't know, that kind of seems like not, it just seems like worse ux and not significantly less complexity, but.
00:18:56.004 - 00:18:58.396, Speaker C: Yeah, right.
00:18:58.460 - 00:19:25.814, Speaker B: Okay. I mean, I think a path forward is we can agree to do like initial Petra devnets without these things and just work on them in parallel and then, you know, they're not going to radically change. Well, I don't know if it ripples into 7002, then that could become kind of big. But either way I would at least suggest that as an option just to move ahead and then, you know, work on these things in parallel.
00:19:30.434 - 00:19:31.214, Speaker C: Yeah.
00:19:33.914 - 00:19:40.522, Speaker B: Is this the thing where we need another breakout call? Probably, or okay. I mean.
00:19:40.578 - 00:19:44.694, Speaker D: I mean, yeah, I'm sure we could have another one next week and talk about it more.
00:19:45.634 - 00:20:02.734, Speaker B: Yeah. And it sounds like we probably want one that, you know, if it's in two weeks and we have time to like get more community members to be present. Because it sounds like that might be the path forward is just seeing how much demand there really is and then using that to weigh our decision.
00:20:06.634 - 00:20:16.434, Speaker D: Yeah, that sounds like a plan, especially if it takes two weeks and we have a little more time rather than, I guess, just the next call next week.
00:20:17.254 - 00:20:24.674, Speaker B: Right. I mean, you know, if it can happen next week, that's great. But it's more just like giving people time to be aware and then plan and show up.
00:20:26.414 - 00:20:34.990, Speaker D: Yeah, I think it's just about scoping out the complexity of execution layer initiated consolidations. I just anticipate it might take a little more than a week, but.
00:20:35.022 - 00:20:35.722, Speaker C: Yeah.
00:20:35.918 - 00:20:57.938, Speaker B: Yeah. Okay, well, thanks. Okay. Maxv. We can move on to the next eIp that's been included. 7549. So this is moving the committee index out of the attestation data into the attestation object again.
00:20:57.938 - 00:21:08.174, Speaker B: I took a look at the specs yesterday. They seem like they're in a pretty good place. Are there any open questions anyone here who's been working on this are aware of? I think Mickey might have some stuff.
00:21:10.274 - 00:22:28.854, Speaker C: Yeah, so this just for the context, this CIP also introduces notion of on chain aggregates versus network aggregates. So it allows to back signatures and aggregation bits more tightly when we include attestation on chain. And currently this design that is in this pack has one downside. So, because those aggregates will be bigger because there are aggregation bits from many committees in one on chain aggregate. So we have to reduce the number of max attestations. And currently it is set to eight versus 128, as we have it right now. And the problem here is that let's just consider that the situation where proposer wants to include many aggregates from the same committee in the same slot, which is the case according to the chain data we have, because those aggregates probably have like.
00:22:29.474 - 00:22:29.898, Speaker B: Yeah.
00:22:29.946 - 00:23:45.878, Speaker C: Have just more information and just more bits if we include like several of them for the same committee. And the problem here is that say we have ten aggregates for the same committee and one slot cannot accommodate it with this proposal, while with the status quo, it can be accommodated. Why it can't accommodate because we have just eight attestations at Marx, and each of those attestations can accommodate just one, one aggregate from the same committee. So what I. Yeah, what I'm just going to play with is to see if we can replace the committee bit, committee bit vector with the list of committee indexes. And in this case they will be possible to include, to pack aggregates from multiple aggregates from the same committee into one on chain aggregate. And basically it means that one on chain aggregate will be able to contain overlapping aggregates from the same committee.
00:23:45.878 - 00:23:50.514, Speaker C: So that's just one addition that I want to try to experiment with.
00:23:51.774 - 00:24:07.344, Speaker B: Okay. And maybe just to recap, so we lowered the number of on chain attestations per block because they're not more dense. Right. But now this makes it harder to get even more aggregates in the same block, which makes sense.
00:24:10.324 - 00:24:16.384, Speaker C: Yeah. And in some cases, in some cases we want to probably want more flexibility.
00:24:18.524 - 00:24:19.396, Speaker B: Gotcha.
00:24:19.540 - 00:24:19.836, Speaker C: Yeah.
00:24:19.860 - 00:25:02.448, Speaker E: Terrence, in this model, are you assuming there's this like aggregator that just volunteer the decide to subscribe to all these subnets and then by aggregated altruistic basically on its behave versus like the current model is more like a random selection. Right. You basically say two data 2048 committee and each committee has like 500 validators and by chances there are 16 validators, I'm sorry, 16 aggregators per community. So, so basically those are by random selection. So I guess which model does this? Okay, pull this answer.
00:25:02.496 - 00:25:03.720, Speaker D: The proposal does this.
00:25:03.792 - 00:25:05.004, Speaker C: I see, thank you.
00:25:07.304 - 00:25:30.792, Speaker B: Right. Yeah. So the way it's written right now is there's like, that's sort of an additional step from what we do today where as far as I can tell the network level stuff stays in place. But then the proposer now can do this additional thing where they can like pack things much more tightly on chain because now the attestation can like span rather than just like one committee, they can now span all of them. Right.
00:25:30.848 - 00:25:36.392, Speaker E: But this doesn't reduce the beacon attestation, aggregate subnets, bandwidth and traffic.
00:25:36.448 - 00:25:36.832, Speaker C: Right.
00:25:36.928 - 00:25:39.888, Speaker E: Which is what I thought it does. But I am running there.
00:25:39.936 - 00:25:58.024, Speaker B: Yeah, yeah. I mean it would make blocks smaller because again the attestations are just more tightly packed, which is nice. It would be like a more, much more invasive change as far as I can tell to like. Yeah, touch the network. I mean theoretically we could do it, but yeah, it would be much bigger change.
00:26:00.204 - 00:26:00.540, Speaker C: Yeah.
00:26:00.572 - 00:26:01.264, Speaker B: Potus.
00:26:01.844 - 00:26:44.906, Speaker G: Yeah, just on that. It does help in a few, in a few things. The economics of validators that are losing attestations because they can't fit after reorg and clients are dropping attestations because it's not just profitable for them to pack them. I think this is going to help on that but yeah, Sterens is. It also helps in security. We have some security assumptions in that in the worst possible attacks to pour choice, we should be able to reback attestations from other blocks into the canonical chain. So it even helps in the theoretical properties that Fort choice has.
00:26:44.906 - 00:27:03.974, Speaker G: But I think Terrence is getting into something that we should be prioritizing, which is what Giulio from Eric on tried to come up with solutions, which is change the attestation format so that we actually lower the bandwidth on the network. I think this should be a priority for networks.
00:27:05.794 - 00:27:53.414, Speaker B: Yeah, I tend to agree, but then I think that would touch subnet structure and so that's just like a much bigger thing. Cool. So it sounds like Mikael is going to look at getting more flexibility into the on chain packing. Otherwise this one seems like it's in a pretty good place. Okay, again, silence is compliance. Great. So those are the four eips on the cl that have been included in Elytra.
00:27:53.414 - 00:28:38.914, Speaker B: Yeah. Next on the agenda, I did want to touch on updates with respect to each team's implementation status. Like again, well, again, maybe taking a step back, I guess my plan now is to get all of these four, at least into some electrospec and the CL specs and have that out ASAP. Obviously then we'll work on spec tests and hopefully, ideally even by the end of the month, we have all that ready to go in parallel. It'd be great if client teams are implementing these things. Could I get a brief status update from each of the client teams on their implementation progress? Are there some of these that you've looked at, some of these that you haven't? Anything like that?
00:28:41.894 - 00:29:18.474, Speaker H: I can go for Lighthouse. Yeah, I would say we've got a lot of progress on Max EB. Mark's been working on that, obviously. 6110, we've had an external contributor implement this. I think what's lacking still is any changes related to the pub key cache. And Michal mentioned that he might be working on a design that would alleviate us having to make changes around this. That would actually simplify that a lot.
00:29:18.474 - 00:29:32.764, Speaker H: EIP 7002, I don't think we have any implementation progress on. And is that it or am I missing. Oh yeah, the attestation change.
00:29:33.304 - 00:29:34.984, Speaker B: Yeah, that one. Yeah.
00:29:35.104 - 00:29:38.004, Speaker H: Eitan from our team has also started working on that one.
00:29:39.824 - 00:29:52.744, Speaker B: Cool, thanks. Any other clients want to chime in?
00:29:53.604 - 00:30:34.044, Speaker C: Yeah, for Teco we have implemented 6110, but. So we also implemented the cache, but we may have to revert that depending if the specs which Niklio discussed are going to be part of it. 7002 is in progress. We have a pr for it and the attestation changes are also being looked at. Maxib, we haven't done any coding, but we have someone looking at it.
00:30:35.824 - 00:30:36.564, Speaker B: Great.
00:30:37.144 - 00:30:45.856, Speaker G: For lodestar 6110 we have implemented and we have mostly implemented Max EV as well.
00:30:45.960 - 00:30:55.444, Speaker B: And we might just push in other prs that are required. So yeah, we are sort of feeling confident on it.
00:30:58.584 - 00:31:18.554, Speaker D: For Prism we're pocing 7251 Max EB, but the other ones, we're still in the early phases of assigning to each of the team members. They're being discussed but not too deep into it.
00:31:20.734 - 00:32:00.890, Speaker B: Sounds good. And I think Nimbus, we're still missing if anyone is here. Okay, I can follow up offline with nimbus on that. So yeah, kind of what I expected. Some teams have different progress and different ones. And yeah, hopefully that can be top of mind for everyone over the next month. So yeah.
00:32:00.890 - 00:32:04.552, Speaker B: Terrence, are there like a general tracking.
00:32:04.608 - 00:32:16.724, Speaker E: Sheet for team progress? You can think of a table where the rows of the Eips and the college client teams and we can mark like progress, like basically milestone one, milestone two, blah, blah.
00:32:17.584 - 00:32:43.044, Speaker B: Yeah, exactly. It looks like Barnabas is already on top of it. Great. Cool. Yeah, I think that will help people understand where their clients are at. And then again, I think it'd be great to aim for Devnet in the next month, month and a half. And if client teams can do pairwise interrupt on their own when they're ready, that'd be great.
00:32:43.044 - 00:33:30.164, Speaker B: Those are the eaps that have been included. Let's take some time to talk about other eaps we might want to think about for the initial picture, Devnet, one that was CFI but not included is inclusion list. I would at least like to get to a point today where we agree on ielts. Well, yeah. Should we focus on them or not? Does anyone have any thoughts here? I'm not sure exactly what the latest status is. I know there's some complication, let's say around aa account traction with the design.
00:33:31.504 - 00:34:16.474, Speaker A: Yeah, I can give a kind of brief update. Right. So I guess the last all core dev execution call has a similar update, but. So yeah, if you want kind of more details, check there. I think protest is post is the most, the most thorough description of the relationship between 3074 specifically and inclusionless. I just sent the link in the chat. So yeah, I guess this issue came up and it's around kind of this idea that we used to have this assumption that if the transaction was valid in the pre state of the block.
00:34:16.474 - 00:34:50.614, Speaker A: It would be valid in the post date of the block, unless the only condition that would change that is if there was a transaction from that address in the block. 3074 changes this because you can spend the balance of a different account. So an account that shows up in the inclusion list could be corresponding to an invalid transaction if someone else spends the balance from that account. So that's the TLDR. And why 3074 in particular causes issues. We have a breakout room tomorrow. I'll share the link.
00:34:50.614 - 00:35:55.844, Speaker A: It's PM issue 1000. Yeah, we hopefully will cover that kind of exhaustively there. Yeah, I think the general sentiment, at least in the IL channel of the ETH R and D discord, has been that we have a few solutions. But most people are uncomfortable with both the speed at which the spec has changed. Given these solutions and the kind of aesthetics of the changes being a feel like they kind of look a little less aesthetic than the original design, I think it's still going to be something we have to face down the line. I don't think the 3074 compatibility will ever go away personally, but yeah, we can probably get more into the details tomorrow. I'll probably cut it here and yeah, definitely a bunch of other people have, have a lot of context too, if they want to chime in.
00:35:57.864 - 00:36:42.164, Speaker B: Cool, thanks. Okay, so what I would like to do today is just focus this on Devnet zero, which, given ILS, they're maybe a little up in the air. They'd also like, we won't make a decision today because we're also going to need Yale buy in. And 3074 is not even CFI. So if that's an issue for ielts, but then it's on the fork, you know, maybe that unblocks ielts. Like it seems like there's some uncertainty there. And so I would kind of suggest just putting it to the side for now, again, for like our initial or for our initial Devnet zero scope.
00:36:42.164 - 00:36:59.924, Speaker B: I think everyone else will be plenty busy with these other Fourier ips. And yeah, we can work on aisles in parallel. Was 3074 CFI? Yeah, I thought it wasn't. I think it's going to be discussed next. ACD.
00:37:01.664 - 00:37:03.524, Speaker A: It was CFI for CFI.
00:37:06.464 - 00:37:07.204, Speaker C: Great.
00:37:08.744 - 00:37:28.430, Speaker B: So yeah, I mean, there's definitely some questions here with respect to a. And yeah, I don't think we're going to decide today. What I would then suggest is. Yeah, essentially what I said. So basically let's focus on these other four again. I think that'll keep client teams busy. And, yeah, ielts can just go in parallel and.
00:37:28.430 - 00:38:00.788, Speaker B: Yeah, we'll see how they shape up. Let's see. Yeah, so Tim put the included eaps in the chat. So it's the four that we've talked about today. And then also 25 37, which I wasn't going to touch just because I believe that's only else scope. And so, yeah, none of us really need to worry about it. So.
00:38:00.788 - 00:38:23.764, Speaker B: Cool. Let's then. You know, it'd be good to hear what people think about timelines for, again, this initial Devnet. So assuming we only target these Fourier ips, do people have thoughts on when we could start seeing early Devnets? Like, is this something that's going to take one month, two months? It's too early to give estimates. Anyone have any thoughts?
00:38:31.824 - 00:39:06.534, Speaker H: I feel like we don't really have enough info for estimates yet. If 6110 and MaxcB could both have design changes, I could change the workload addition amount. So, yeah, I think we just need to focus on getting a Devnet spec, because rushing to the Devnet prior to having a spec is, I think, a bit counterproductive. It ends up with us writing a lot of code that we can't end up merging.
00:39:08.914 - 00:39:44.298, Speaker B: Yeah, totally. Okay, well, I think that's at least my and chowe's top priority over, like, the next week or two is like, getting to some electrospec. That's final. And then hopefully that gives us more clarity moving forward. Okay. I think that's all I had for Elektra. Is there anything else that we should discuss? I think it sounds like there's plenty to do and people know what to do.
00:39:44.298 - 00:39:46.974, Speaker B: But if there's anything else, let's hear it.
00:39:51.434 - 00:39:53.654, Speaker H: Oh, well, we didn't mention peer desk. Right.
00:39:54.994 - 00:40:04.534, Speaker B: Yeah, I was going to go that next. Which we can jump into. Yeah. Sorry, what was that?
00:40:06.014 - 00:40:06.494, Speaker H: Nothing.
00:40:06.534 - 00:40:07.358, Speaker C: I just gave you.
00:40:07.446 - 00:40:08.634, Speaker H: I prompted you.
00:40:09.174 - 00:40:39.864, Speaker B: Thank you. Yeah, so I put it more in, like, the research slash spec side of things. Yeah. So peer DOS, hopefully is also top of mind for everyone. You know, at a high level, we should focus on what we can hopefully call a small fork. And then I think in parallel, you know, if your team's working on this, you know, say 80% is going to Electra, maybe 20% is going to pier Das, and. Yeah, that's something that we can move forward in parallel as well.
00:40:39.864 - 00:41:04.324, Speaker B: Are there? Let's see. Yeah. Anyone here want to give an update? I know there's been some, like, proof of concept work on implementation. Also, the spec is. Well, there's a huge pr around the peer dot spec. I think the plan is to merge that as is, and then, you know, any open issues from that pr, we'll just move to another issue and. And iterate from there.
00:41:04.324 - 00:41:09.484, Speaker B: Is there? Yeah. Anything on pure DoS people want to discuss?
00:41:17.384 - 00:41:50.214, Speaker H: I guess I can give like a general update with lighthouse stuff. We've made like a lot of progress right now. We're spending a fair bit of time though refactoring existing lighthouse code to sort of support integrating pure desk more simply. So I think we're still a decent amount away from a full lighthouse implementation, but we have a lot of progress on individual pieces.
00:41:55.354 - 00:42:05.314, Speaker B: Okay, awesome. Are any other client teams actively looking at peer Dos? Yes.
00:42:05.354 - 00:42:53.674, Speaker G: I can't really speak for prism because I don't know if Nishant is here. Nishant and Manu from PriSm are looking at this and they have been looking at the specification, started thinking, I mean, brainstorming for the actual coding. But something that they pointed, that Nishan pointed is that even though technically it's not a hard fork, it's in practice it is, because it seems to be very hard to have these networking changes not affecting brutally the network if you don't ship them out of hard work. So I wonder if this has been agreed or not, because if this is going to be in a hard work, then this decision has to be made right now.
00:42:57.614 - 00:43:26.034, Speaker B: Right. So, I mean, I think the thinking was kind of that assuming it's not like. Yeah, like you're saying really complex networking wise, like clients, you know, you can imagine that I download prism and I set a flag in terms of my availability mode, and that should just be transparent. At least that's the intention with peerdos. The only necessary hard fork would be in bumping up the blob data gas limit.
00:43:26.414 - 00:43:46.354, Speaker G: I understand technically that's correct. But the problem seems to be along the lines of proposers are updated and they don't send the full blobs or peer Das nodes don't download the blobs, or they don't have the blob to serve it completely, and then non peer dead blobs wouldn't be able to get the blob. And this can create headwinds, split pews.
00:43:47.374 - 00:44:18.664, Speaker B: Right. So what I would say to that is just like, I think we keep working on implementations on the side, I think it'll become clear, you know, if we have pure Dos devnets, say six months from now, eight months from now, then like, it'll be clear if this is an issue or not, and then we can go from there. Yeah, it's. I would rather focus on shipping electro as quickly as possible. And so, like, I don't want to have this huge uncertainty appear to us, slow things down. Personally, I don't know if anyone else disagrees.
00:44:24.884 - 00:45:01.714, Speaker H: So we had sort of talked a little bit about potentially having overlap and, like, serving both, like, pure dos samples and participating in blob gossip and blob validation normally. So then we could get even on Mainnet, some degree of certainty with sampling that when you sample, the blobs are there, but there'd be a lot of redundant upload download that we'd have for a period. So unclear if it's worth it, but.
00:45:02.094 - 00:45:36.304, Speaker B: I thought, yeah, but it does greatly de risk relying on peer dos, which I think is important. So I know, like, that would be my preference is to, like, de risk as much as possible, have a more gradual rollout. And then once we're very confident, then go ahead and do, like, the hard fork to bump up the bob count. Okay, well, there's some chat, I guess that's worth surfacing. Onsgar saying, you know, Pyrdas is definitely very, very urgent.
00:45:36.834 - 00:45:37.226, Speaker C: And then.
00:45:37.250 - 00:45:42.026, Speaker B: Yeah, to put us this point next in the chat, that would change prioritizations.
00:45:42.210 - 00:45:42.482, Speaker C: Yeah.
00:45:42.498 - 00:45:44.614, Speaker B: Alan's guard. Do you want to say something?
00:45:45.234 - 00:46:29.046, Speaker I: Yeah, I mean, I think there's not, like, unanimous agreement here yet, necessarily that there is the demand on the layer two side yet to already absorb the blob throughput that we have today. And that basically it's going to be very urgent to scale. I personally predict that that will happen. Of course, we will see, by the time we basically have to make final decisions around the vector, we will have more time to see how much the demand has picked up. But ideally, at least, I'm operating on the assumption that it will pick up. I would personally like to see at least this be prioritized in the sense that clients spend attention and resources on this. And then if it's not ready in time for electro, I don't think electro should wait for it, because it's not necessarily strictly, it has to be combined with the fork.
00:46:29.046 - 00:46:42.454, Speaker I: But I would personally think it would be very unfortunate if basically everyone focuses on the electoral features and only once that's done, basically starts really working a lot on theaters. That seems like the wrong order of priorities to me.
00:46:43.434 - 00:46:43.794, Speaker B: Right.
00:46:43.834 - 00:46:44.626, Speaker D: And this is kind of my point.
00:46:44.650 - 00:46:51.694, Speaker B: A second ago where I think, you know, if client teams can split focus 80 20, let's say, I think that is a good compromise.
00:46:52.954 - 00:47:48.254, Speaker D: I also have brought up something to a few people. But is it possible in electro we could consider increasing the max pop size to something like ten or so, and then when we are closer to the electric fork, we'll have more of an idea of how much demand there is. And then potentially, you know, for like while f star is going on, maybe there's a Cl only fork and we can decide at that time whether or not maybe we just further increase max blobs per block to something like 14 or 16. Or if pure DOS has made sufficient progress, then maybe we could handle the Cl only fork that does pure dOS. But we could make that decision later. Like right now, we could plan for a small increase in capacity for electra, and then later decide on what the next increase in capacity is.
00:47:49.314 - 00:47:54.494, Speaker B: Right? And Ansgar, you had an EIP, right, to suggest bumping up the bob counts even without peer dos.
00:47:55.874 - 00:48:18.372, Speaker I: Yes, it's still in draft, but it has numbers, 7500. Basically the idea would be to have it gradually increased and electra basically like a small bump at electro itself. And then two months later, another bump. And then two months later another bump. Exact details like in this case I was targeting 816. Basically. It could of course be less ambitious initially, but something like that.
00:48:18.372 - 00:49:08.220, Speaker I: The one complicating factor here is just that. Basically we have two alternative approaches for scaling. Basically, there's still headroom for a one time pushing the existing protocol mechanism to its limits, basically just really optimizing blood propagation, seeing how well the network handles things today, and then pushing to this. Of course this will require some engineering effort. And so, of course, once we move to PSS or other forms of data availability sampling, this will basically no longer, this will become redundant work. So the question is, if we are optimistic on the timeline for das, it would basically be a waste to put engineering efforts on pushing to the limits of 444. But if we think that, say, DS P will still need a year or so to hit mainnet, it would maybe make sense to first have like one initial step of throughput increases just by pushing 444, and then a second step moving to Das.
00:49:08.220 - 00:49:10.704, Speaker I: So I feel like we just have to agree on a strategy.
00:49:13.924 - 00:49:43.162, Speaker B: Right? I mean, that makes sense. And then the questions like how do you actually get there? It seems a bit early to like commit one way or the other. So, you know, I think we see how many that goes, right? Just getting live data is going to inform our agenda to bump up the four for four blob count. If peer DOS implementation proceeds a lot more quickly than we expect then that kind of pushes us that way. So, yeah, I mean, I guess it's just something to keep on everyone's radar and then we'll address as we go.
00:49:43.298 - 00:49:52.654, Speaker D: I mean, I think. Is it true though, that either way, the pressure for electra is a small fourth or fourth block increase?
00:49:54.674 - 00:50:16.490, Speaker B: Well, it sounds like. I mean, yeah, so I think it'll just depend on peer dos implementation. Right. Like, if peer dos is ready to go and we are confident in it, then, like, great, we'll do it. If we're not, then, like, I would say, you know, das or like, you know, data scaling is sort of a soft question mark with. With a lecture right now. And what that would likely resolve into is bumping up the 4.4
00:50:16.490 - 00:51:04.838, Speaker B: counts. Yeah, I mean, luckily that should just be a constant change. So that's something we can easily do, you know, down the line. So takeaway is focus on peer dose, focus on everything, but actually, like, you know, to the extent that you have spread capacity, definitely keep eyes on pure dos. And. Yeah, otherwise, sounds like everyone will be heads down on these other eips. So that was pretty much everything I had in the agenda.
00:51:04.838 - 00:51:07.954, Speaker B: Are there any other things we want to discuss while we're here?
00:51:26.354 - 00:51:55.358, Speaker F: Like, does any client team wants to test with just basic two eips that has been pretty close to revitalized? I mean, the 6110 and 70 two. Or, like, people just want to wait.
00:51:55.446 - 00:51:57.634, Speaker B: Yeah. Tekuso's advantage in the chat.
00:51:59.294 - 00:52:19.654, Speaker F: Oh, yeah. So, like, you know, if people think, like, two weeks is too long to wait and I can generate the test vectors just early next week, but I think it won't be a formal release yet, just the test vectors. Is that okay?
00:52:26.874 - 00:52:46.046, Speaker B: Yeah. Also from Lighthouse. Yeah, test. You're good. So, yeah, I mean, I think that's a good path forward with the spec. Shall we? We can work on that initial electra PR that has 7110 and 7002 and. Yeah, then again, something I'll be working on next week is getting these other two in a place where we can merge them all.
00:52:46.046 - 00:53:30.034, Speaker B: And then. Yeah, again, my aim is by end of the month to have or even sooner to have this, like, Devnet zero electra spec with tests ready to go. Okay. Anything else? Otherwise we can wrap up a little bit early today. Okay. Seems like a no. Thanks for joining everyone and, yeah, I'll see you around.
00:53:32.934 - 00:53:33.958, Speaker C: Thanks, Alex.
00:53:34.046 - 00:53:34.518, Speaker B: Thank you.
00:53:34.566 - 00:53:34.854, Speaker C: Bye, guys.

00:00:00.570 - 00:00:32.310, Speaker A: It. Okay. I think most folks who are going to join are going to join, and we're already reporting, so let's go ahead and get started. Welcome to the Dencoon interop testing, call number 34. A couple of things on the agenda. First off, let's chat about that net ten. Are there any new updates or developments since we spoke last week on the Devnet?
00:00:35.210 - 00:01:11.134, Speaker B: Yeah, so we've been running like a series of experiments on Devnet Ten. The latest one has a latency analysis over here. So what we did was on the first version, we just had devnet ten. Nothing crazy on it, just targeting like three blobs. After we did that, we ran the stress test, and the stress test included targeting like six blobs all the time. Collected as much data as we could. Then we had the blobber that was sending invalid blobs through a percentage of the network.
00:01:11.134 - 00:01:58.910, Speaker B: And on Friday we turned that off. And then we switched a different mode that the blobber had, which is add a delay of roughly 2 seconds to roughly 10% of the blobs on the network before gossip. And then the latency analysis is the result of that one. It seems like everything's mostly stable. There's clearly edge cases. And I think Enrico said he also found something in Teku, and that tends to happen if there's a higher latency for the last blob before the epoch transition. So it also makes sense that doesn't happen very often, which could be an explanation for some of these unnatural spikes that we see in the graphs.
00:01:58.910 - 00:02:02.720, Speaker B: But yeah, that's mostly what we have on Devnet ten.
00:02:05.680 - 00:02:16.980, Speaker A: All cool. Thanks for that. Does anybody have any questions or thoughts on the analysis that was done, or any client teams want to share any insights?
00:02:22.140 - 00:02:49.300, Speaker B: One more thing to add. We got the Mav workflow set up on devnet ten. I think every single CL has proposed at least one slot with a blob with MeV on devnet ten. There is an issue that we're still actively debugging with Tersec on Nimbus and the relay. We're yet to figure out why, but yeah, I think other than that, we're mostly good on Melv.
00:02:52.900 - 00:02:53.650, Speaker A: Great.
00:02:55.220 - 00:03:03.990, Speaker C: We were going to launch Devnet eleven today, but because of the new consensus pack change, we might postpone that.
00:03:05.320 - 00:03:13.990, Speaker B: Yeah, that's kind of what we wanted to. I guess it'll be a part of the discussion and then we can talk about what the Devnet cycle should look after that discussion, maybe.
00:03:15.720 - 00:03:17.124, Speaker A: Yeah, that makes sense to me.
00:03:17.242 - 00:03:46.130, Speaker B: Yeah, we'd leave devnet ten up until probably tomorrow. Or if you guys can think of other scenarios or data that we want to collect, then let us know and we'd do our best to get that done by tomorrow. And yeah, one other tiny thing is the guys from Ethereum on arm also took part in testing this time, and their arm testing basically shows the same numbers that we found on our arm testing, which is also good news. In the future we don't have to bother them. But yeah, basically blobs in arm is fine.
00:03:48.340 - 00:03:53.990, Speaker C: We didn't run any validators, but we plan to run validators on Devnet Eleven on arm also.
00:03:57.850 - 00:03:58.790, Speaker D: Sweet.
00:04:01.370 - 00:04:45.640, Speaker A: Any questions or comments for clients teams on the analysis? Any further questions? Comments on devnet 10th up on the agenda is to chat about this consensus specs pr add Bob sidecar inclusion proof does somebody here feel comfortable giving an overview on that?
00:04:53.870 - 00:05:40.890, Speaker E: Yeah, I can give a small update or summary. So essentially the way that we were doing this before currently is kind of reflecting how we handle the attestation gossip. And yeah, what that basically means is that you get all these blob sidecars and it's not immediately clear, for example, if this message is an equivocation. And this change basically puts the signed beacon block header in the sidecar as well. So now you get slashing security. And yeah, I think everyone is pretty much in agreement that this is the right direction to move in. Does anyone have any questions or feel differently?
00:05:43.230 - 00:06:16.230, Speaker F: One thing I would add is that I started implementing it over the weekend and yeah, I would say besides I guess as we do more testing, right, thanks to all the blob of testing that we realize there is some concern with equivocation blobs because they come for free and there could be splitting attack with the fortress with that and it's just a bunch of unknowns moving forward.
00:06:16.300 - 00:06:16.582, Speaker E: Right.
00:06:16.636 - 00:06:48.160, Speaker F: And this prevents that. Aside from that is that it does make the API interactions much cleaner. And it's both beacon API and the builder API because you no longer have to sign the blob. It also makes the validator client implementation easier. We don't have to implement a different endpoint for the web3 signer, so that's also a plus. So I think overall it's a really big improvement because it basically enables clinical on the client side.
00:06:55.110 - 00:07:14.650, Speaker G: I also agree and think that this is a good addition because again, there is a lot of blocks or content handling that is sort of a code spaghetti we have out there and this will totally get rid of that as well as it makes sense to link the blobs with the block.
00:07:20.430 - 00:08:29.134, Speaker D: Yeah, so previously, a couple of calls ago I brought up an edge case that would have bricked import on Lighthouse, and it had to do with essentially constructing a blob sidecar where your block route doesn't actually contain the KZG commitments that you claim it contains. But then you can propagate these across the network and no one can tell whether they're valid or not. But you can't do that anymore if we include the block header. So on top of eliminating or adding the equivocation penalty, it's also we're making this construction of inconsistent blob sidecars. You can immediately identify it's invalid. So that's another big plus for this change. And with regard to all the APIs, they are all cleaner, but I will say they are all going to have to be changed.
00:08:29.134 - 00:08:41.510, Speaker D: So that is going to take a bit of time and coordination. So that is the drawback of making this change. But I think it's worth doing anyways.
00:08:44.010 - 00:08:53.900, Speaker E: Yeah, I agree, because it just makes everything a lot simpler so it's easier to get right and also basically just makes the whole cost of security much better.
00:08:57.390 - 00:09:06.000, Speaker G: In the PR it was mentioned there were some cons too, because this was considered before as well and was not adopted. So I would like to hear what were the cons.
00:09:16.760 - 00:09:23.620, Speaker E: I think the people who would possibly be against this are not on the call, so that's a little tricky.
00:09:28.010 - 00:10:48.160, Speaker A: Was this specific idea of having the header with the proof proposed before? Because I mainly just remembered the discussion about including the blobs with the block combining them together. Okay, I guess we don't have people. Yeah, I mean, it would be good to hear what the cons are. I will say that I think the original thought here about separating this from the original block propagation was this idea that it would make it a bit more forward compatible with another data availability sampling solution. So you wouldn't need to modify the block, the beacon block propagation at all if you were to then add full dank sharding at a later point. And I think that having a separate message here and having the blobs proof doesn't really affect the normal beacon block propagation that much anyway. So it continues to adhere to that principle that we were trying to design for.
00:10:48.160 - 00:11:18.250, Speaker A: But if this was thought previously, it would be nice to hear what people thought negatively about it back then. So maybe by the end of the day if those people, somebody could ping those people and have them share their thoughts. I know we heard from, I think, three consensus clients did teku or nimbus thumbs up this also? Okay?
00:11:19.020 - 00:11:32.110, Speaker D: Yeah, I think there was just like a little bit of reservation from Nimbus, but I'm not sure they like thumbs down or anything. I just haven't heard much feedback. Yeah, I think tech is in support of it.
00:11:33.200 - 00:12:44.100, Speaker A: Okay. It seems like there's pretty overwhelming support. And if the main downside is that this is going to take a little bit of time to get implemented and update all the APIs, I think it's the cost that we have to pay for doing the robust thing. So I think Danny will wait until the end of the day to see if there's any additional questions or concerns and try and cut the spec with the update in it. Yeah, POTUS cannot hear you if you're speaking. All right, POTUS, just pop in here whenever you get your mic working again. Any other thoughts on this? Otherwise, we can talk about Devnet planning going forward.
00:12:46.630 - 00:13:32.240, Speaker F: Well, can we talk about just. I think the beacon API and the builder API are probably the most critical path here. They will take the longest to spec out and perhaps the longest to implement as well. So do we have owners in those area? And besides that, we should also alert the relayer as well? I'm not sure when the next Mev boost code is, but yeah, I suspect most of the changes will be on their end because now they have to add this inclusion proof to the blobstite card, which before they were just kind of like, they don't have to do much, but now they have to do slightly more. So they should be alerted as well.
00:13:35.560 - 00:13:58.350, Speaker E: So I can take care of the builder specs updates and let's see. I think the relay specs are fine. And yeah, I mean, there's a little bit more that the relay will have to do, but also, I think this is like such a big improvement at the CLA that it's just going to happen and it's really not that much extra work.
00:13:59.440 - 00:14:58.990, Speaker H: I think I have a microphone now, so I can clarify a little. So this thing of mentioning Dan, Brad just came up with a private conversation of myself and Jasek, and he mentioned that this was thought of. So since I am just a third person and I wasn't there in the first conversation, I would just paint either Dankra or Jasek and just clarify this if there's any respiration. As for the relay, I do expect that this change is going to take us in a position. It's going to put us in a position that is slightly more complicated, perhaps because we're going to need to test with them. So as of today, we only make one block. We can make it in parallel and we make only one object that we build and we may or may not use it with a builder and we can just quickly swap a payload and put it in that blinded block with this change.
00:14:58.990 - 00:15:42.988, Speaker H: I think the path with the relayer is going to be quite different. We're going to send back the signed header and then the relay, I suspect, is going to build those sidecars, the blob sidecars. So clients will have to keep track of a bunch of objects on your local payload. You're going to have to have your locally built sidecars with their own proofs that you might never use because the builder is going to send you those anyways. But still, just to be prepared, you need to start building a bunch of things in parallel that we currently don't do. So I think this is going to take some time to. So I'm just echoing what everyone is saying.
00:15:42.988 - 00:15:47.470, Speaker H: This is going to take a long time actually to produce, but it's a very good change.
00:15:50.640 - 00:16:04.950, Speaker A: Sorry, I don't think I quite understood what the difficulty on the relay side was. The way I understand it is that you're saying that the CLS would have to be building proofs that they wouldn't normally be doing right now.
00:16:06.200 - 00:16:54.950, Speaker H: Yeah. So typically what you do is you build a block locally and you wait for the builder's block at the same time. And you typically just ditch your local block that you just use to compare values, to compare whether or not it's better for you to use it or not. But typically you just ditch your local block. Now we're going to have to be building the local block and proofs for the block transactions that our local blocks might use and just keep this and also build this send assigned header to the relay and then the relay is going to be responsible for building the sidecars. So there's many more objects that are going to be having to be built in parallel that we currently don't do.
00:16:56.440 - 00:17:00.480, Speaker A: And is the concern processing or is the concern just implementation?
00:17:00.560 - 00:17:18.010, Speaker H: And it's just complexity of implementation and testing. We're going to have to have a lot of unit tests and a lot of hype tests. It's going to be work for everyone. And I think everyone here agrees that in the long term it might take us one more, but in the long term this is a much better place to be.
00:17:19.500 - 00:17:27.550, Speaker G: But Cl can also build the proofs for the builder sidecars and basically send it over to the builder. So builder doesn't really have to do anything.
00:17:28.320 - 00:18:00.490, Speaker H: Well, that's kind of hard. Right. Because you don't have the blobs. So that's going to require one extra round of communication. The Cl doesn't have the blobs for the builder's payload. So what's going to have to happen? I suspect that the best way here is to rely on the relay to build those proofs because the relay doesn't want to have one extra round, neither with the builder nor with the proposer. And since we are relying on the builder to do this.
00:18:00.490 - 00:18:15.950, Speaker H: I'm sorry, on the relay to do this, then I suspect that this is going to put us in a precarious situation where we need the relay to be ready to be testing this, which is something that has been bugging us on every port.
00:18:17.360 - 00:18:24.690, Speaker G: But builder can still give the blinded sidecars like how they do in get header right now.
00:18:25.860 - 00:18:58.360, Speaker H: Right. So that would be another way so that the builder sends everything. The relay could send the proposer, everything for the proposer to propose, but that's not going to work. So I think the right way of doing this is going to be as follows. The builder is going to send everything to the relay, the relay is going to send the header to the proposer, the proposer is going to return it back signed and then the builder is going to assemble everything on broadcast. I'm sorry, this relay is going to assemble everything on broadcast.
00:19:07.310 - 00:19:31.000, Speaker E: Yeah. So put us, relay and proposer can do this both at the same time in parallel. So the KZG commitments are sent from relay to proposer because they need to make the block and then that's all they need to make the proofs. So there's no blocking on getting the blobs from the relay or something like that. It's really just a question of like. Yeah, I agree. Okay.
00:19:31.000 - 00:19:33.320, Speaker E: I don't think it'll be that bad.
00:19:33.850 - 00:19:58.990, Speaker F: I just wanted to add, we do this today already. We basically build the local blobs and then we try to sign the builder blobs. Both are happening in parallel and if the builder's bid is too low or the override flag is enabled. True. Then we'll switch to broadcasting the local blob. So that's not much difference from this perspective.
00:20:01.170 - 00:20:01.582, Speaker A: Yeah.
00:20:01.636 - 00:20:11.422, Speaker G: And instead of signing we can just build the proofs for the builder blobs and send them to the builder when the time is to submit blinded block.
00:20:11.486 - 00:20:15.940, Speaker H: Yeah, definitely. It's much better this thing that we're only signing one message now.
00:20:22.820 - 00:20:31.190, Speaker F: Do we know who the Beacon API owner is because I figure the majority of the changes will be on the beacon API side.
00:20:42.670 - 00:20:53.290, Speaker A: Was that you volunteering to be the owner, Terrence? I'm just kidding.
00:20:53.450 - 00:20:56.170, Speaker F: I was hoping that someone's more competent.
00:20:56.250 - 00:20:56.794, Speaker A: Yes.
00:20:56.932 - 00:21:03.860, Speaker D: Do this, I can volunteer as tribute to make a pr at least.
00:21:09.010 - 00:21:55.360, Speaker A: All right, you heard here first, everyone. Okay, what's the next steps? I guess for putting all of this together, I think let's just assume that this change is accepted into the spec. We'll give it to the end of the day and let Danny merge it. But assuming that does happen, where do we go from here? What kind of target are people feeling for getting back into the Devnet cycle? Is this one week, two weeks?
00:21:57.090 - 00:22:21.110, Speaker D: I mean, I think the first thing is we have to get the API changes up and have discussions around those, and then once we agree on those, we can implement them. So I feel like it's like at least a week or two for the specs, then a week or two for the implementation, and then at that point try to test it on Devnet.
00:22:22.010 - 00:22:25.910, Speaker A: Okay. We have a consensus layer.
00:22:26.430 - 00:22:40.880, Speaker G: I sort of agree because the more important change and discussion that seems to require will be on the builder side. And that is something I think is more contentious and has more design options.
00:22:45.590 - 00:23:05.160, Speaker B: If that's the case, would we be okay with just getting rid of Devnet ten? Because it's way too big to just have running for that long. We can have Devnet eleven, that's basically the exact same thing. So not including any of the changes we spoke about just now. And then we can leave that running until we're ready. Does that sound okay?
00:23:08.580 - 00:23:15.890, Speaker G: Devnets can still be used for latency kind of analysis and I don't think we need a new Devnet for it, so. Sounds good.
00:23:18.680 - 00:23:25.620, Speaker B: Do you mean compared to Devnet ten? Because the main reason of getting Devnet, getting rid of Devnet ten is it's expensive.
00:23:28.650 - 00:23:41.034, Speaker G: Yeah, I mean, if basically expenses can be brought down for Devnet eleven, I think we should go for it. Else let's continue with Devnet ten and sort of get the latency thing also figured out.
00:23:41.232 - 00:24:03.300, Speaker B: Yeah, sounds good. We'll do that. And just one more question. Is there any value in doing Shadow Fox at this time? Because that's also. It's again a cost thing, it's not an effort thing. We can do curly, Shadow Fox this week if there's something to learn from it? Or would it be better to just wait for all of these changes and then do it later on?
00:24:06.700 - 00:24:09.640, Speaker G: I think we should try just one shadow fork.
00:24:12.960 - 00:24:19.100, Speaker B: Okay, so we'll do a girly shadow fork just using the exact Devnet ten images.
00:24:19.840 - 00:24:35.280, Speaker C: Does it make sense to wait with the Shadow fork once this beacon API is merged in? I would do it post Devnet eleven. There's not much point doing it right now in my opinion.
00:24:47.590 - 00:24:57.410, Speaker G: I think we should do it even before Devnet eleven so as to get the familiarity with if there are any other issues out there lurking.
00:25:03.150 - 00:25:06.240, Speaker B: Yeah, we'll get one up this week and let you guys know that.
00:25:09.590 - 00:25:32.780, Speaker C: Okay, so the timeline now is tomorrow we going to shut down Devnet ten and launch Devnet eleven. That will be running for the next two or three weeks, then have dead net twelve to test out this new beginning API, then probably reconsider timelines for Gurley fork after that.
00:25:35.390 - 00:25:56.970, Speaker A: That seems to be the consensus right now. We do have a consensus layer call this week on Thursday. Is there any chance that we can have some initial stabs at the spec ready to discuss in that call?
00:26:00.320 - 00:26:01.550, Speaker D: I think so.
00:26:02.640 - 00:26:52.508, Speaker A: Okay. That would be good. And I think, yeah, that would give us some time to discuss some questions and concerns synchronously and hopefully sometime early next week, maybe get them merged in custom releases and then get people to start implementing them. And we will just see on the next, I guess. Yeah, we'll just take it next week and see when we want to start targeting Devnet twelve. But roughly thinking, like on the order of two, three weeks from now. Yeah, Dev Connect is in two weeks.
00:26:52.508 - 00:27:48.150, Speaker A: So we'll all be in a building that Tim will find and provide that will bring us food and water and we will be working on this. I think it's okay. Is there any other things that we were hoping to discuss on this call? It sounds like everybody's pretty pro this modification to the blob sidecar message again, we'll wait till the end of the day, and I assume Danny's going to merge it, but just to give the people who might be dissenting some time to share and try to have some specs ready for the builder and the beacon API by Thursday to discuss.
00:27:58.200 - 00:27:58.564, Speaker C: Questions.
00:27:58.602 - 00:28:11.980, Speaker A: Or comments before we wrap up. Okay, thanks a lot, everybody. I'll talk to you on Thursday.
00:28:13.360 - 00:28:14.012, Speaker C: Thank you.
00:28:14.066 - 00:28:14.940, Speaker H: Bye bye.
00:28:15.520 - 00:28:16.140, Speaker A: See you.
00:28:16.210 - 00:28:16.876, Speaker B: Thank you.
00:28:16.978 - 00:28:17.630, Speaker A: Thanks.
00:28:18.000 - 00:28:18.920, Speaker E: Thank you. Bye.

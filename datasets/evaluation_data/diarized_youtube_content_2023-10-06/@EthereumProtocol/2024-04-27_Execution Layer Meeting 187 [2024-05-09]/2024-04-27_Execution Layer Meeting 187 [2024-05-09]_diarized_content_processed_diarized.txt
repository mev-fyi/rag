00:02:31.134 - 00:03:02.634, Speaker A: Okay, take two. Now we are live with audio from me as well. Welcome to Acde number 187. Basically the only thing on the agenda today is stuff related to Pectra. We'll talk about Devnet zero progress from teams. Then there was a breakout around EIP 3074 and the broader account abstraction roadmap that happened earlier this week that we'll cover. Continuing the conversation from last call.
00:03:02.634 - 00:04:03.328, Speaker A: After that, Ethan had a bunch of comments around, basically the messaging around EIP 6110 and the generalized message bus we introduced recently. So we'll go into that and then yeah, a couple more eips to discuss if we have time, I guess. First, Devnet zero. I don't know, Barnabas or Perry. Are either of you on the call? Yeah, I'm so we are preparing some Devnet zero configuration files in kurtosis and trying to test them. We still had some hot fixes coming in this morning and probably we can be fully up and running by Monday with like a somewhat stable ish configuration. But we were missing some config files from the Netherman chain spac, but that should be fixed now.
00:04:03.328 - 00:04:42.016, Speaker A: And we made a new generator image, so we are testing that right now. Awesome. And last I checked, I believe every single client team obviously has their work in progress. It seems like Geth and Ethereum J's are the two clients with everything implemented. Anyone on the client teams want to share updates or concerns? Oh, never mind. Has everything implemented as well? It seems nice. Besu has everything in flight at the moment.
00:04:42.016 - 00:05:14.034, Speaker A: They're all being tested and about to be merged. So I would say that we're development complete, but they're still being debugged and need to be merged in the main. Got it. Any other team have updates? Yeah, in Aragon we have most of the things as work in progress except for 7002. Yeah. So it's still maybe a week or two away. Got it.
00:05:14.034 - 00:06:07.702, Speaker A: And then. Yeah, Rath still also working on it and shared the tracker in the chat. And I guess, yeah, on the Cl side scanning the Devnet zero spec, it looks like everyone is still in various stages of in progress, but NECl have everything implemented. So Grandina thinks that it has everything. And we started to do interrupt I think, yesterday. Yeah. And well, none of els that we tested works.
00:06:07.702 - 00:06:45.318, Speaker A: So we tested Nethermind, Ethereum, J's and geth. So we were not able to essentially we are not able to finalize. So. And in this part I reported a few issues and we, we keep working on that with some EL teams. Got it. Thanks. Any other CL teams have updates or have everything implemented so on Lighthouse.
00:06:45.318 - 00:07:18.912, Speaker A: We don't have everything yet, but everything's pretty close. We're hoping to pull it together tomorrow. One thing we ran into was, I think the get payload bodies endpoint and the execution engine APIs needs an update. And I don't think that's spec'd out yet. I'm not sure if Els have made changes there, but. Yeah, we ran into that yesterday. Anyone on the el side look at that call.
00:07:18.912 - 00:07:47.534, Speaker A: Yeah. Marek, what changes do you mean? In get payload? Adding deposits and withdrawal requests or something else? Yeah, just those two. Yeah. So we added them on our site, so I'm not sure if Barnabas finished the kurtosis config. We can try. Okay. Yeah, we just didn't see changes in the spec, but we haven't tested against Neal yet.
00:07:47.534 - 00:08:38.654, Speaker A: So I think in the spec, it is mentioned in execution payload, and getpayload returns execution payload. And in this way, it was mentioned. Okay, awesome. Thanks. And Mikael said in the chat that they're updating get blocked bodies in the spec, which should be done soon. Any other comments, questions, concerns from the cl side? Okay. And then.
00:08:38.654 - 00:09:19.704, Speaker A: Yeah, I don't know if on the testing team on the el. Any updates there? I know last week we had all the tests ready except 3074. Is that still the state we're in? Hey. Yes, we do have a pr for 3074 tests, but it's not filled yet. I'll try to get an update in the coming days, but so far yesterday, the tests were updated to include more tests for 29, 29, 25. Got it. Thank you.
00:09:19.704 - 00:10:31.412, Speaker A: Anything else on Devnet zero before we move on? Okay, next up. So we had an aa breakout to sort of continue the conversation around 3074 and potential other eips earlier this week. I don't know, lightclient, I believe you were on. Do you maybe want to start with a quick recap and then we can take it from there? Yeah, I can try to take a stab at it. I know a lot of people on this call were on the call Tuesday, so feel free to jump in after and add some things I might have missed. Basically, the call was separated into two parts. The first part, I wanted to try and have a conversation with all of the relevant parties about, what are we building towards? What do we think is a realistic timeline for what we're building towards? And given that, how, what should we be prioritizing on l one right now? And I don't think that we walked away with a perfect picture for every single party.
00:10:31.412 - 00:11:20.898, Speaker A: But I think one thing that we did agree on is native accounts abstraction on l one is still a few years away, and so there's definitely a reason to do something on l one in the next hard fork if we can come up with something. And we talked a little bit about what those things could be. Should we be focusing on improving EOas? Should we be focusing on trying to let EOas migrate to smart contract wallets? And there was some proponents for both sides. It felt like the louder side was decided to just improve EOAs today because there are some things that we still need to think about and figure out how to resolve with respect to actually migrating EOAs. And part of this might be due to this proposal that Vitalik had published just a bit before the call. And so people were very excited about improving eoas. So that was the main thing.
00:11:20.898 - 00:12:20.594, Speaker A: We wanted to get a picture from all the different sides, where are we trying to go? And it felt like we came away from the call and people were okay with improving EOAS if it made sense in the longer term roadmap. And then we went to the next part of the call, which was supposed to be really focused on talking about 3074 and answering some of the questions that have been bubbling up about 3074 over the past few weeks. But we ended up mostly talking about a new proposal, 7702, which I think Vitalik we'll talk more about on this call. But basically it's a different proposal for how to improve eoas. And overall, it seems like there's a lot of nice benefits of it over 3074. It fits into the 4337 account abstraction world very cleanly. And for me, most importantly, it lets us reason about, it lets us reason about more statically about what types of accounts might be drained in the transaction pool.
00:12:20.594 - 00:13:10.490, Speaker A: So I think that that was like a big question mark with 3074 that we had to answer during Devnet zero. So we talked about 7702, generally felt positive on that. And afterwards we talked about some more generic questions about the authorization of 3074 or 7702 from the perspective of the user. Like, should the user be signing a message with Nonce? Should they be signed with a chain? Id just some arguments that we had had in the past few months, but we're now with many more participants who've actually been developing smart contracts that would work under the 3074 7702 world. And I don't think that we necessarily made too much progress there. It's just an ongoing discussion. But yeah, I think, yeah, that's pretty much the recap.
00:13:10.490 - 00:13:29.224, Speaker A: If anyone else has something that I might have missed. I think we came out of the call pretty happy with the direction with 7702, but I think we should open that discussion up here at some point, I guess. Yeah. Before we go. Oh yeah. Vitalik, you want to cover 7702?
00:13:30.284 - 00:14:50.692, Speaker B: Yeah, yeah. So the basic idea behind 7702 is that it's an EIP that basically allows an EOA owner to sign over a piece of code. And if that piece of code and that signature gets included in a new transaction type, then the EOA basically turns into a smart contract that has that piece of code for the duration of that transaction. And the reason why this is interesting is because it satisfies a lot of use cases in a way that's very similar to how 3074 satisfies them, in the sense that you have some outer transaction which could be called by the owner themselves, or it could just be called by some other actor, like a paymaster or a sponsor. And then it does some author, it calls into the user account, it does some authorization logic, and then it does some execution logic. And the users like the EOA gets activated and it starts doing things from, from the inside of the transaction. And so there's a very natural way to convert any 3074 workflow into a 7702 workflow.
00:14:50.692 - 00:15:52.294, Speaker B: The big benefits that it has are that it removes the need to introduce new opcodes. So instead of doing an awesome false call, you basically just do a call into the account. It's, as like Mike mentioned, it's very static analysis friendly because the accounts that are affected just get statically declared in the transaction. And it's very forward compatible with not just 4337, but also potentially yet any kind of smart contract wallet based account abstraction strategy that we might do in the future. Basically because the code that a user needs to sign over just is a smart contract wallet. And so you can literally use smart contract wallets that exist today. And so workflows in this scheme just very naturally carry over into workflows that would also make sense in a full smart contract wallet world.
00:15:52.294 - 00:17:31.624, Speaker B: So that's the core idea, right? Basically, yeah. Like you can think of it as being 3074 esque from the perspective of how some application developers might interact with it today, but then at the same time kind of borrowing a lot of elements of style from some of the other more conservative account abstraction proposals. And so we brought that up yesterday and we discussed both the EIP itself as well as some ongoing pointer cases that are being discussed on the magicians thread and in, and in other places, like basically figs around. How do you like, what are the specific bits do you assign over? What particular features do you add for safety reasons? What particular codes do you disable? And there's a lot of similar considerations to what's been debated within 3074 in that sense, a couple of new ones as well. And so there's definitely a lot of, you know, discussion on those points happening in both on the PR and on Ethereum. Magicians so highly encourage people to look at those and participate. And, you know, if they're interested, start figuring out how this might make sense for, like, their piece of infrastructure, their use case.
00:17:35.324 - 00:17:50.980, Speaker A: Thank you. Anyone else have. Yeah. Comments, questions? Andrew? I do. Oh, sorry. Yeah, Andrew first. Yeah, I guess if, if you do, please raise your hand and zoom in.
00:17:50.980 - 00:18:13.104, Speaker A: I'll go in order. Yeah, I think I like the idea of 7702. I think it's more elegant than 3074. But my big concern is revocability, because right now it doesn't specify revocability in any, at all. And that's a big security concern.
00:18:14.744 - 00:18:29.364, Speaker B: Yeah, very valid. Revocability is one of the items that's being discussed right now. So there's a couple of strategies that have to do with either assigning over the nonce or assigning over the nonce divided by some number that are being talked about at the moment.
00:18:32.784 - 00:19:10.006, Speaker A: Got it. Nassim. Yeah, so I have a, I think I have like a, a few questions and thoughts. The first one, I just wanted to emphasize that in some, in many use cases, gas costs are probably going to be. Can you guys hear me? I have, like, someone literally just destroying the apartment right above. Awesome. So, yeah, I think that on the gasket side, I would love to hear a little bit more there because, like, 3074, I need to run some modeling.
00:19:10.006 - 00:19:54.644, Speaker A: This is like, 7702 is just very new. Need to do some modeling. That's my first question. In terms of actual gas cost per transaction, how did we think about that versus having a transaction where the costs actually scale out with the size of the contract that we approve? And with that, generally, the contract is, you know, the more features and the more safety features, the more expensive the transaction is going to be. Sorry. Whereas signing over, for example, an address that you may have checked, you know, as a user, verified the code independently and separately.
00:19:57.964 - 00:21:02.260, Speaker B: Yeah, also a very good point. I think a couple of answers there. So one is that even if we do sign over code, one option that is always available is that you get the code that you sign over can be a delegate call forwarder and delegates call forwarders can be only 44 bytes. And so that's one approach for making it very affordable, even for very large contracts. And then again, I personally am totally okay with both the code in the transaction version and the code address in the transaction version. One of the considerations that sometimes gets talked about in the other direction is basically cross chain support. Like, if you want to sign over something and have it work on multiple chains, then yeah, a hash gives you a somewhat stronger guarantee, though obviously those guarantees go away if you, if you end up using a delegate call forwarder.
00:21:02.260 - 00:21:14.264, Speaker B: So there's a couple of different ways of handling that. But this is, again, this is like one of those finer points that's still being.
00:21:17.524 - 00:22:00.024, Speaker A: Benjamin. I originally thought signing over the code address would be better, but I've come around to the idea of putting in it code in instead, because there's two separate signatures. So you've got the signature where you're approving. Here's the contract I want you to use. And then there's a separate signature outside, which is, here's the data I'm passing in. If you want that inner signature to also approve some data, then you need extra. So you could do, here's my proxy contract processing data.
00:22:00.024 - 00:22:53.124, Speaker A: And then the outer contract could. Sorry. The outer signature, which could be sponsor, could add extra data, which isn't dependent on your signature, so it's more flexible. Got it. There's another. Okay, so there's a couple questions in the chat or comments anyways, that sort of go at the same idea of, like, implementation work around this, and whether we could reuse some or part of the 3074 work, or how much more work it would be to implement this from scratch. And then also, Justin had a comment around should we consider running both on the same Devnet so that we can actually test them in production? But yeah, I guess I'd be curious to hear from some of the El folks.
00:22:53.124 - 00:24:01.146, Speaker A: I don't know how many have reviewed the EIP, but just in terms of the scope of the work, like, how big of a change is 7702 relative to 3074? Yeah, Ahmad, I don't know my personal opinion. I've read both, and we've already worked on 3074 on Nethermind. My personal opinion is that the work will not be the same. Most of the work needs other implementation for 7702. Not sure about the idea of running them both and how that interaction could be, because, like, I don't, I'm not sure how they would interact with each other, but 7702 is definitely different in implementation wise, in my opinion. Got it. Got it.
00:24:01.146 - 00:25:17.574, Speaker A: And I guess, yeah, generally, I think it probably makes sense to give people a bit of time to review this before we make a decision about what are they included in the next Devnet? And also, given teams are still not done implementing Devnet zero, we do have a bit of time skimming through eat magicians, scanning through its magicians. You know, does seem like there's a bunch of conversation happening around 7702, but, yeah. Does anyone feel like there's something we should sort of decide today about it or like, an issue we should resolve, or does it make sense to continue the discussion async and then on the next call make a decision about whether we want, effectively Devnet one to have both only 7702 or. Yeah, potentially something else. Charles, you say you have a new draft eip. Is this related to 3074? 7702? No, I dropped it in the chat so that people can look at it. Okay.
00:25:17.574 - 00:26:04.896, Speaker A: Okay, so definitely. Okay, so there's definitely some concerns about having both in the Devnet. But yeah, given we're already pretty much done with Devnet zero, it's probably more work to change the spec now and say, remove 3074 or anything like that. So I think it probably makes sense to move forward with Devnet zero and then make a decision about 7702 on the next call. Does anyone have an objection to that? Okay, so, yeah, definitely encourage everyone in the el site to review the eat magicians thread. And then it would be great if in the next two weeks we can flesh out these issues around just revocability, gas costs, and. Yeah, all these other smaller details.
00:26:04.896 - 00:27:13.904, Speaker A: And if people still. If people still think this is, you know, the best proposal to move forward, then maybe we can add it in deathnet one and remove 3074. But, yeah, gonna make that decision in a couple of weeks. Anything else on aa 3074? Okay, next up, Ethan. Yeah, please. Sorry, Tim. I just wanted to emphasize that I want to take a pragmatic approach for I know that it's not the case of everyone in this call, but a lot of companies have been kind of like wild providers and so on, have been building pretty large scale 27 71 meta transaction forwarders, and just wanted to emphasize that 3074 for us, I mean, like, we're included in this category, you know, is a lot easier as kind of like a next step.
00:27:13.904 - 00:28:00.648, Speaker A: And so I just wanted to emphasize the need for kind of either. Some kind of considering 3074 as kind of an incremental step for everyone who has right now. 27 71 infrastructure to sponsor gas costs for all the smart contracts that do support what is their providers, or having some form of joint efforts from everyone to standardize an implementation of a four, three, seven bundler. That would really help every single wallet provider essentially offer. Table stakes. Table stakes features. Because at the end of the day, 99.9%
00:28:00.648 - 00:28:35.196, Speaker A: of our user base, which is pretty large now, is really just asking for gas sponsorship and transaction batching on every single contract. And both satisfy that. But one of them is a lot easier because of the infrastructure that we already have in place. Definitely understand kind of the concerns on all sides, but just wanted to throw that out there. Thanks, Jor. Are you looking to respond to this? Yes, just one clarification. We are still looking into 7702.
00:28:35.196 - 00:29:29.990, Speaker A: It seems like there is some accounts that using it will be almost like standard accounts using the EOA and with minimal change to the bundlers, no change to the entry point. But again, this is very preliminary. We didn't. It's still hand waving, but it looks promising and quite easy to get with. Got it. And just. Sorry, I'm not super familiar with the details here, but the 27 71 EIP, or ERC, is this effectively what can be used? Like, is this the 4237 bundler? Are they like the same interface, or are they two different things? No, it's a different thing to put code inside an account to make it look like it is a smart contract.
00:29:29.990 - 00:30:06.454, Speaker A: And it can be used with the on chain contract, the entry point contract of 447, you do need a slight modification to the bundler in order to use the transaction type. Okay. Got it. Okay. Yeah, this definitely feels like something that we should figure out in the next few weeks at least. Even though we may not have a full and final implementation. If we can at least sanity check that there is no sort of blocking concern here.
00:30:06.454 - 00:30:42.508, Speaker A: Yeah, that'd be really good. Anything else on the IP? Okay, great. Yeah. Thanks, everyone, for sharing. Moving on. Ethan, you had posted a fair bit around 6110 and the whole messaging scheme there is Ethan on the call? I am, yeah. Nice.
00:30:42.508 - 00:32:13.684, Speaker A: Do you want to give a bit of context? Yeah, sure. So, for the deposits, the withdrawals, and the consolidations, there is this new scheme. I think it's 7685 EIP. And there is a problem with that, with the optimistic sync that I noticed right now in nimbus. What we do is to accelerate the sync, that we only send every x blocks to the El, like we do, like, breaks in between during sync, so that we don't continuously interrupt the Yale while syncing and we can do that because the Cl can check that the chain is consistent with regard to the block hash. Like when there is a new payload FCO, the El does, at the very least it does this block hash check, and we sort of integrated this into the Cl so that we don't have to send all the payloads. So one problem here is that with 7685, it seems that this is no longer possible because there are now fields in the EL block header that are not in the CL execution payload anymore, namely this 7685 requests tree.
00:32:13.684 - 00:33:15.310, Speaker A: So it is no longer possible to compute the block hash from CL payload. So which part is not available? This requests tree, but you can compute the request tree. You have all of the requests in the execution payload header and body. All it is is a matter of if you're going to implement the optimistic sync, you need to understand 7685, because 7685 only comes into play when you're computing the execution layer block hash. Once you know that you can compute the request header by doing the typed RLP encoding. So in the like for the consolidation, they are not even in there, but for deposits and and withdrawals, they are there as separate lists. And it would be possible to reconstruct, maybe.
00:33:15.310 - 00:34:06.266, Speaker A: I'm not even sure they could be interleaved. I'm not sure. 7685 defines the ordering, so the ordering is based on type. So if you have a type 07685 request, it would be the first thing, and then within the type zero request, whatever type zero is can define its ordering, like intra type. Then you'd have type one, type two, etcetera. So why do we have separate lists in the payload and not like where do we combine them in the EL but not in the CL? I propose 7685 because on the EL it feels a lot more cumbersome to continuously extend the header and the body. And if we're going to be adding 3456 plus types of El Cl requests, it feels much simpler on our side to do it this way.
00:34:06.266 - 00:34:44.880, Speaker A: Any els that don't agree with that, feel free to mention this. But that was how I felt, and what the feedback I was getting while we were implementing 6110 and 7002 was. I didn't specify to use requests on the CL because I got a little bit different feedback that the CL would prefer to have the list flat within the payload, and that's fine. I don't think that there's a reason to enforce the exact same format across the layers. We can do it and something to discuss, but that's why 7685 was created. Okay, that at least explains the motivation. Thanks for that.
00:34:44.880 - 00:36:37.210, Speaker A: So is there like, is this still the preferred design overall, or is there a way to explore like, just to keep it separate lists or like, how much of how far down are we in here on the El or Cl? On the El? I think most people prefer the single request list. I'm open to removing 7685, but it seems on the El we're not really built as well to continue extending our header and body. Each time we do this, we have to plumb a lot of code through, and for us this makes the request much simpler. Okay, I'm not sure if that's only geth or all of the others, but another proposal that could simplify it is if we just align them completely and do the SSC transition of the block header to match the payload header, then it's one data structure for both of them. Like, we have discussed this when withdrawals came up, and I think SSC is still like a long term goal to do as a transition. And I think it would be a good timing to use like these three new trees that are being added, as well as the 7702 transaction type to like. It's all additional stuff that would benefit from SSE in simplification.
00:36:37.210 - 00:37:23.434, Speaker A: Less data conversion, no more NDN back and forth. We could also switch the engine API to SSC, like it would unlock a lot of things, and I think getting it away before Verkle is a good timing. I know that you have mentioned that in geth that there is no good SSE library yet for go, so that's indeed a bit of a work that would be required. But I think it's better than having to redo all the plumbing over and over again. Because in SSE it's trivial to add a new list to a container. Like, we do this with every fork. It's no problem.
00:37:23.434 - 00:38:36.122, Speaker A: To be clear, I guess these are like two different concerns, right? The first is the information you get in the payload does not sort of easily allow you to skip blocks during optimistic sync. And then the second is, if we're going to add all this information, maybe we should add it using SSD. Yes. Okay, I guess just maybe just to finish on the first one before we discuss SSD. My sense just skimming through the chat is like most of the els, if not all of them do like 7685 a lot. And it does seem like, based on what client was saying, that you would be able to reconstruct the tree on the CL side, even though the information is on the block header is there a reason why this is not a viable solution for Nimbus? I would have to check how much work it would be in the CL. Right now we have separate lists for the deposits and the withdrawals.
00:38:36.122 - 00:39:16.368, Speaker A: There is no list for the consolidations, but maybe they can be extracted from the state transition function or something. Well, right now consolidations are not in the EL requests because right now we don't have El triggered consolidations. Okay. I mean, I don't know the details there, but I saw this type two request somewhere. But if they are not there, then even better. So what we would have to do is to convert the deposit receipt and the withdrawal request back to RLP to little engine. Right.
00:39:16.368 - 00:39:43.384, Speaker A: And then create amputees in the 7685 to re obtain the root hash of that tree. Right. And then we can continue to compute the block hash. Is that what you are suggesting or. Yeah, and this is about the same work you would have needed to do if we were extending the list. Like, we are still going to encode it with Bigndian. We're still going to mpt it.
00:39:43.384 - 00:40:21.940, Speaker A: Now it's just instead of having n mpts, we just have one. And when you encode, you put the type prefix on it. Sure. Yeah. It's the same amount of compute, but it's conceptually still a divergence between the two layers. Right, right. So, yeah, I think this first request to like that, it's not possible anymore.
00:40:21.940 - 00:40:57.454, Speaker A: Like that. It struggled with the optimistic sync. I think with that conversion, it's no longer a primary concern. I still think it's a bit ugly to diverge there, but that's more like for the other point with moving to SSC, but that's no longer a blocker for optimistic sync. Okay. Okay, so let's. Okay, so I guess, yeah.
00:40:57.454 - 00:42:19.114, Speaker A: For this specific thinking issue, let's assume that this works and if it's not the case, obviously we can discuss on a future call for SSD itself. This is obviously a fairly substantial change. So I guess I'd be curious to hear from EL teams given all the other stuff that is being considered right now. There's EOF, there's 7623 that we were going to talk about a bit later, and then there's a bunch of other eips as well. Do any El teams feel like converting some of the objects to SSE is something they would like to prioritize in this work? Okay. So weak, no breath. I mean, the question is also, has anyone actually looked into it? Because, I mean, I think people have generally looked into SSD over the years in like different context.
00:42:19.114 - 00:42:53.114, Speaker A: So obviously, yeah, like obviously the specifics of the implementation matter. But I think, yeah, my sense is we probably have a general feel of like, what it implies to do SSD and also what it implies to maintain both SSD and RLP on the El. RLP is fine. It's about the Merkel. Patricia tries. Right, right, sorry. Okay, so yeah, Rhett seems to have looked into it.
00:42:53.114 - 00:43:48.016, Speaker A: Would like to avoid Baizu as well. Anyone feel strongly in favor of doing it? I'd rather do it now than do it in Osaka. Great. Like one thing that we have as well is there is this EIP 4788 that put the beacon route into the state. And now with Electro, there are a couple containers that already start to break. Like if you have something that consumes a proof based on EIP 4788 after Elektra, that verifier stops working because the shape of the proof changes. Right.
00:43:48.016 - 00:44:51.512, Speaker A: And now with Electra, when we break them anyway, it's another opportunity to just do the timing. I know that it's a lot of work, it's a lot of mechanical work that does not primarily benefit as developers. But there are two questions. Like, one is, do we ever want to do it? And if we ever want to do it, then do we gain anything from delaying it? Like right now, the new fork, it adds another MPT to the El. Like this. 7685 requests three, it adds a new transaction type with 7702, and it breaks all the generalized indices in beacon state and I think also execution payload header. So like every fork adds more work that needs to be converted, right? I guess, yeah.
00:44:51.512 - 00:45:55.002, Speaker A: The trade off there is, the more we wait, the more stuff there is to convert to SSD when we finally do it. And then if we delay doing it, it means we get to do everything else slightly quicker because we get to do more things in the same amount of time. My sense is there's not really any support from the El slide to do this in this fork. Obviously if this changes, we can reconsider it. But yeah, it really doesn't seem like any of the EL teams want to include this within Petra. I don't know if anyone else. How are we on the state of SSE libraries? Is it only go that doesn't have one, or is it the same problem for the other teams on the Bayesu side? We have a moderately complete SSE implementation, but we really only exercise subset of it.
00:45:55.002 - 00:47:21.924, Speaker A: So it would probably need some more work and attention. But I don't think we have the same level of blocking as geth does currently. So on nether, my site, we written our own SC library, which is not used on production. So we will see on Devnet how it works, etcetera. Got it. Any other comments, questions from anyone else on SSD? Yeah, if we don't do this now, aren't we going to just run into the same problem next time when this comes around and the work hasn't been prioritized to get everybody to have good SSE libraries? Like, isn't this just the same problem later as it is now? Yes, and it's a question of what our priorities are now versus later. And if doing now makes us faster later, doesn't that make a pretty strong case for doing it now, even though we're not ready? Well, you know, it depends on like, what's.
00:47:21.924 - 00:48:11.314, Speaker A: What's the value of getting it done? What's the value of getting everything else done? Like, I have, you know, say that this took three, six months extra. Do we think it's more valuable to do this now or to do, you know, verkle or four? Four s or eof and. Yeah, that's effectively the trade off, I guess. Yeah. Just because we have other stuff on the agenda. Any other questions, concerns about SSD? Otherwise, I think, yeah, it probably makes sense to continue the discussion, I think. But it seems unlikely we would, we would consider it for this fork.
00:48:11.314 - 00:49:05.144, Speaker A: Okay, then moving on, I guess. Ethan. Yeah. Were these the two issues with the syncing and then changing stuff to SSD while we are doing it? That's the main one, yeah. I had some 6110 related specifics as well regarding ordering of deposits. Like, there are two parallel deposit mechanisms and deposits may get reordered, but we don't have to discuss that with everyone. And the third one in the GitHub comment was consensus related regarding attestation type.
00:49:05.144 - 00:49:42.022, Speaker A: So it's not relevant to this call either. Yeah. So I think that covers it for me. I will personally try and get SSC onto a Devnet with Nimbus El, I guess. And maybe that could, that could help us gauge the exact scope that's needed, because I don't think it's a six month thing. Yeah, I think that would actually be. It would be useful to see what the implementation was like, what things were harder than you thought it would be.
00:49:42.022 - 00:50:19.422, Speaker A: What things were easier than you thought. So, yeah, there's definitely value in that. Mikael, you have your hand up. I just wanted to add on the 6110 stuff and not the order, the processing deposit order, not in the order they had been submitted to the contract. This is really a fair concern. I think we need to do more investigation and talk to rocket pool and probably other staking pool if it breaks anything on their side. But basically the situation can be as follows.
00:50:19.422 - 00:51:31.464, Speaker A: During the transition period, the ETH one data poll will be onboarding will be filling the gap between like the last processed deposit before the fork activation and the first deposit that had been processed according to the new six 2110 logic. And those gap is like deposits that were submitted to the deposit contract before the new ones obviously. And yeah, the old deposit can be finalized already and then someone can submit a new deposit that will create a validator with different withdrawal credentials. And then the when it one day the poll fills the gap, the one that had been submitted before, the elder one will be a top up to a new withdrawal credentials. So probably the breaks some, some, some staking in some staking pool design breaks the security. So yeah, that's fair concern. Just wanted to highlight that and yeah, thanks.
00:51:31.464 - 00:52:14.660, Speaker A: Thank you. Anything else on this before we move on? Okay, next up, so two eips that we had CFI. Yes, sets of vip's we CFI for fork have some updates. So first EOF, then there were some potential issues around 760. So we'll do EOF first. I know there's been a couple breakouts since our last call, but yeah. Any notable updates to share? Not too many.
00:52:14.660 - 00:53:34.114, Speaker A: The first breakout we had on May 1, it wasn't too well attended because of a major european holiday. If anyone wants to learn more about EOF, they're always welcome to show up, and maybe not necessarily during the meeting if we got a large agenda, but you can ping me or any of the other people involved in EOF, you're trying to get a tighter grasp on it, but as far as yesterday's meeting, we're just sewing up the very final states of the spec there, as opposed to the EVM channel in the discord. The big thing that's been working out for the past month is we're formally removing the TX create and the init code transaction from the first revision of EOF is not essential to it, and we're going to rely on the existing create transactions and there's a specification there for how we're going to handle EOF without requiring a new transaction type or an irregular state change. Those are no longer required for EOF V one, but just cutting up the corner cases that everyone discovers as they do the final pieces of implementations in their clients. As far as testing, I'm writing a lot of the execution spec tests for it, using the various clients to guide where I get the appropriate coverage to make sure I cover all the pieces in the clients that I'm available to see. So yeah, that's an update from my perspective. Alex probably has more to add.
00:53:34.114 - 00:54:22.308, Speaker A: Yes please Alex. I also posted the links, but three updates, so there's a meta EIP which has been merged and which lists the older relevant eips. That's 7692. Dano mentioned the removal of TX create. For those unaware, the TX create was the way to create contracts, and that relied on a creator contract basically, which needs to exist in the state. Instead of this, we came up with a more simplified approach that doesn't require new transaction type, doesn't require the special contract. It uses the existing creation process used in legacy, but the design is forward compatible.
00:54:22.308 - 00:56:00.124, Speaker A: So we could introduce TX create in the future, but this definitely removes the transaction changing aspect of implementation and testing. So basically testing really has to deal with the EVM level and it doesn't need any new special rules for transactions. And this new transaction AIP, or like this new contract creation AIP is 7698 and the last update I wanted to highlight is we always had, or at least for the past couple of months, we had an implementation matrix which lists the eips, the tests, as well as the client implementations and language solidity and viper implementations. This has been updated this week, and if you take a look at it, it seems that there is an EOF implementation in almost every single client, with the exception of errant, but in some of them it's kind of a stale implementation. So in Ethereum J's it is definitely a stale older version of EUF, and the wiper implementation is also old, but the implementation in solidly is being worked on as of the past two weeks, and I think Goetheorem and Nethermind those are listed as work in progress. It seems there's active work going on in both of those, and those are using the latest packs, so those are not really still pieces of work. I think that's my addition.
00:56:00.124 - 00:57:05.224, Speaker A: Awesome. Thanks for the update. We've been waiting on the meta eap for a couple of weeks. I know there was some delays in getting it merged, but given EOF is CFI, does anyone object to CFI ing the meta EIP which lists all of the sort of individuals eips just so it's easier for people to reference? And if we do that, does it make sense to also include the creation transaction EIP 7698 I guess. Any objections to this? Otherwise, I'll do it. So at least it's up to date with the latest spec. Okay, any other questions, comments, concerns about EOF? Okay, well, yeah, thanks, Dano and Aksec, for the update.
00:57:05.224 - 00:57:37.844, Speaker A: Next up for EIP 7623, I believe we have William on the call who had some concerns that he wanted to raise. So. Yeah, William, do you want to take a couple minutes and. Yeah, walk through those? Oh. Oh. William, are you on the call? We can't hear you. Yeah, I had some issue unmuting.
00:57:37.844 - 00:58:14.044, Speaker A: I'm trying to present this slides. Yeah, we can see everything. All right. So I'm trying to discourage a pattern of metering gas. So I have some examples. First, consider a taco stand that charged the maximum of $3 per taco and $5 for salads. People that want to buy tacos and people that want to buy salads can work together to save money.
00:58:14.044 - 00:59:54.226, Speaker A: Similarly, if there was a discount where we charged less for combining tacos and salads, there'd be a way to make money again by combining where one person buys the discount and sells their unwanted components to the people that need them. And so this brings us to EIP 7623, which charges gas according to call data. So there's a maximum function in the gas used to try to split out the call data gas, so that it's worse for some people and the same for everyone else. This has a problem called gas sheltering, which I call it, because it's similar to tax sheltering, in that you can offset the costs by combining, for example, gains and losses and tax sheltering, and call data and execution in gas sheltering. So, because the gas is no longer marginally priced, which means that each incremental units of computation doesn't cost additional gas, it causes some economic problems with the way with the market and incentivizes some strange behaviors. First, consider the case where the call data gas is greater for a transaction. So a user's gas would be determined by call data.
00:59:54.226 - 01:00:50.214, Speaker A: Referring back to this formula, this means that they would pay twelve gas per token. And so such a user, they can add execution gas to their transaction, and it would not increase their gas use. And therefore, they can sell that gas to someone else that would like to buy it. And there's no price at which that cost is ineffective, that it's always a profitable sale. And so this combination has some dangers to it, which I'll discuss later. But there's another kind of combination, the kind of combination when the execution gas is greater in this case, you would like to pair up with someone who is using a lot of call data. So this would allow you to save two thirds of your call data cost.
01:00:50.214 - 01:01:44.334, Speaker A: So effectively you're arbitraging to save gas. And this results in a lower effective gas price for users that combine than users that don't combine because you can consider the gas that they would have paid without unlocking the gas. In the world of Mev, Mev is execution dominance. So searchers would want to batch with call data users. So they would be looking to increase the number of call data users and centralize them so that they can win the gas auction. Another topic is that l two s who post large amounts of call data would want to batch with searcher transactions. And this can cause centralization in the gas market and other kinds of problems as that's a rather monopolistic power that they would have, the free gas.
01:01:44.334 - 01:02:53.614, Speaker A: So I also compare this to gas tokens. For gas tokens, there was an efficiency of one half, which is also possible. In the first case I discussed, there's incentives for creating and destroying accounts for gas tokens, but for gas sheltering, the incentive is for additional call data. So this means larger blocks than would have happened in the organic market, just due to the incentives of attracting the call data users into the sheltering scheme. So this means higher gas prices for people that aren't participating in gas sheltering and a lower block gas limit. Therefore, because of the possibility of two x, one difference from gas tokens is that gas tokens gas can be used on anything, whereas unlocked gas must be complementary. Vitalik released a blog post discussing this today, and so I reiterate that the reason the 50% gas was removed is that it allowed larger blocks than should be possible.
01:02:53.614 - 01:03:43.274, Speaker A: And so I recommend instead a much simpler solution to just increase the call data gas for everybody. I've written this as EIP 7703, so it keeps the regular gas use formula, thereby not introducing gas sheltering. The largest potential block size is reduced by the same amount, so the worst case is the same, but everyone pays the same rate regardless of how much execution gas they're using. So as Vitalik mentioned in his blog post, a better scheme in the long term would be to separate these different components, components into different gas markets similar to blob gas, and that would preserve marginal pricing. That's all for my presentation. Thank you. Thanks, William.
01:03:43.274 - 01:03:45.514, Speaker A: Yeah. Vitalik, you want to go next?
01:03:47.494 - 01:04:36.810, Speaker B: Yeah, no, so thank you very much for that, William. So I think a couple of points in response, right? So one is that all of these downsides do need to, as usual, be weighed against the upsides. And the upside here is the pretty large upside of being able to decrease the theoretical maximum data size of a block from 1.9 megabytes all the way down to 0.6 megabytes, all not including blobs, while keeping almost all applications the same price as they are today, with extremely few exceptions. So it's important, like there are basically, you know, we keep in mind costs. It's also important to always keep in mind what the benefits are in the background.
01:04:36.810 - 01:06:09.776, Speaker B: I think more specifically with regard to these secondary market concerns, I mean, I actually fully agree that this is a valid problem in theory, and that if secondary markets like that happen, that would be a, a bad consequence. But I think the main reason why I'm not concerned in practice is that basically the total addressable market for this kind of coincidence of wants is extremely tiny, right? And the reason why I'm confident about this is because Tony and I, or actually just Tony in this case, I did some analysis of which transactions actually are called data dominant and by how much. And the answer turned out to be like especially with the 1248 pricing, as opposed to the earlier 1768 version, very few, right? So stark proofs increased by, I believe around 1.3 x and then L2 protocols that have not moved over to blobs. So things like inscriptions and scroll go up by like two x or somewhere between two and three x, though I think as of very recently scroll has switched to blobs. And basically I think all of these call data used dominant use cases are switching to blobs. And the number of remedy exceptions is like basically darknet and a couple of Merle perfusers.
01:06:09.776 - 01:07:18.570, Speaker B: And it is totally true that they could make some profit by auctioning off a tiny amount of extra execution space that they have in theory. But in practice, just like if you actually look at the numbers, if you actually divide this by the total amount of gas that's happening, the market is just not large. And that's not something that was through with the gas token market, because gas token markets were just like, they did not require this kind of two sided coincidence of what's the required people who are willing to save up gas when gas prices are high. Whereas in this case like you actually need to have this two way agreement between an execution dominant user and a call data dominant user. And the constants in this EIP were chosen as such that the number of call data dominant users is like actually extremely small. So that's the reason why I'm actually not particularly worried for the short term. But like, I do, I do accept that this is a valid downside of this EIP.
01:07:18.570 - 01:08:03.144, Speaker B: And like, I do definitely favor moving to a multidimensional model eventually. I think the reason why, yeah, we ended up moving away from just like a raw forex in cal data prices, which actually was Tony's in mind idea, like about a month or two ago, is basically because that would like, that actually would be extremely punitive for both starkware and a lot of like, layer one, L2 to layer one, bridging Merkel proof verification, use cases and a lot of other things. It would like, it would bump up stuff that's like pretty critical to layered the L2 ecosystems, ongoing decentralization by a factor of four. And so that could actually be.
01:08:21.464 - 01:11:13.922, Speaker A: Okay. I think Zoom crashed for everyone. Okay, are we back? Okay, yeah, I think Zoom crashed. Sorry about that. Okay, so, Vitalik, you were talking when it crashed, but I'm not quite sure exactly where it. Okay, Ansgar, you had your hand up, how it could sound to people, and that, of course, is not a very principled way of handling these things, but there's actually like a, like a principle behind this. That, and that's, it's like a common misconception that pricing on Ethereum is basically trying to account for the proportional cost that any compute causes for nodes in the network.
01:11:13.922 - 01:11:34.330, Speaker A: But that's not actually the case. And you can kind of realize that in two ways. One, those nodes don't actually get any of the money that you pay. That's not distributed across all the nodes that actually need to execute transaction. But also, it doesn't depend on the gas price. If there's only one way gas price, then all the cost you cost for the notes and network is basically free. And if it's like 100 gray, all of a sudden it's really expensive.
01:11:34.330 - 01:12:13.282, Speaker A: It doesn't, there's no relationship. You're not actually paying for the, for the effort you cause. It is purely a congestion pricing mechanism, meaning we have fixed resources on the network. We are just saying, hey, this amount of compute, this amount of data, this amount of bandwidth, we are willing to give to the network per amount of time. And so condition pricing system mechanism to allocate that to the person that values it the most at any given moment of time. So that's why people pay. And so actually, this one dimensional way of doing this that we do in Ethereum right now, or I guess now with two dimensional, but one dimensional in the normal evm side of things, it is really inefficient in that most of the time, we are only using a fraction of the available resource.
01:12:13.282 - 01:12:46.086, Speaker A: We always have to plan for the worst case, so we have to make its price things, so that if someone only uses compute, that the block doesn't explode too much, or if someone only uses data in an entire block, it doesn't blow up too much. But most of the time, people actually use some sort of mix of the two. And so we are way underutilizing the resources of the network. So this is just dead weight loss. It's just an inefficiency in the network. And so this basically is just a very, like a small example of a class of mechanisms that start to make this more broadly available. So now, basically, we specifically incentivize behavior.
01:12:46.086 - 01:13:12.472, Speaker A: And so this is why this funding in general, is not a bad phenomenon. That's actually a good thing. Like, we're incentivizing behavior that tries to push the usage of each individual research closer to its theoretical limit. And so, indeed, of course, details matter. And so I do agree, actually, that these concerns, to some extent apply, because, of course, it's a more pragmatic mechanism. It's not like a theoretically completely sound way of approaching this. But I agree with Vitalik's assessment that it's good enough.
01:13:12.472 - 01:14:02.924, Speaker A: And again, it's not just a pragmatic fix, but it actually has, like, a deep underlying principle that there's this huge inefficiency right now in Ethereum, and we are basically removing this to some extent here. Thank you, Tony. Yeah, I just wanted to add that I do agree with William. So there is this theoretical threat, but I also agree with Anska and Vitalik that it's not very practically viable. Especially thinking of such markets would require trust among the participants and also a high degree of coordination. And imagine you as an l two. You want to post your data down to l one, and you don't know which address will post the data or where the data will eventually be.
01:14:02.924 - 01:15:22.686, Speaker A: From practicality standpoint, you would need custom indexes and all that. So I don't think it's very viable. And regarding the multi dimensional fee market, I also agree that this might be more close to an end game solution than 7623. But I think the main goal, so the main goal of 7623 was to kind of diffuse this DOS vector of big blocks, especially thinking of increasing the block count or increasing the gas limit. And at least until Pegtra, I think it's the most viable thing that we can do. I'm Ben could do something simpler, which is the zero byte discount is only applied in the first n, say 1024 bytes of call data, after which it reverts to normal. Which also has an advantage that when the EL is trying to work out the gas price of the call data, it doesn't have to recount all the zeros in the megabyte.
01:15:22.686 - 01:16:23.114, Speaker A: If it's a megabyte long, it just has to do a thousand bytes and then use the length of the rest. Yeah, and there's a couple comments in the chat around some of the El devs who had expressed some concerns about it. So on the get side, and then on Nethermind as well. Anyone else have just comments or questions about 7623? I have a question which is, has enshrining call data compression been considered? Like, if you have like run length encoding or maybe some very simple algorithms, you could also reduce call data by a lot, but without needing to change pricing, it inflates in the JSON.
01:16:25.014 - 01:16:30.794, Speaker B: Yeah, I mean, I think everything is wrapped in snappy app protocol layer already, right?
01:16:31.534 - 01:16:38.734, Speaker A: Yeah. But is it like cheaper if it compresses? Well, with snappy, I meant from a pricing perspective.
01:16:42.154 - 01:17:10.928, Speaker B: Right? Currently, yeah. It is not. At least that's et al. And I'm not sure if any else have started properly accounting for that. Again. Ultimately, I guess any like, contracts are always able to individually decompress stuff. The question is, like, does it make sense to like, basically make snappy yank at a breaking pile? I mean, instinctively that feels like a pretty complicated thing to do.
01:17:10.928 - 01:17:24.484, Speaker B: And like, trying to enshrine that might prove to be something that we regret if we discover other compression algorithms. But I'm not against exploring it.
01:17:25.684 - 01:17:37.584, Speaker A: Yeah, because everybody's compressing it anyways. So why should you kind of punish people who are making call data that compresses? Well.
01:17:43.564 - 01:17:58.374, Speaker B: Right, yeah, that's fair. And I mean, I think like the zero byte disk in part intended precisely for that reason. Right, because lots of zero bytes are by far the most common case of data that is big in terms of raw byte count. But that does compress very well.
01:18:02.554 - 01:18:32.166, Speaker A: I'm Georgios. Yeah. Your hand up. Yes. I wonder, how does the group think about call data changes in relation to blob count increase or decrease? And I joined late in the call. So maybe this was, was discussed already, but I recall that there was a block error item that said we cannot adjust blobs if we don't do some data analysis over the impact on the network. And it seems like an increase in the call data would need to be accompanied by something like that.
01:18:32.166 - 01:19:25.286, Speaker A: So I wonder, how do people think about that? Yeah, I have looked a bit into that and I think, hard to tell. So if, for example, a blob increase would already be doable or not, but what you can definitely see already is that blocks that are bigger, I just mean three times the average. So not even getting close to the max, and they are much more likely to be reorged. Or you can also see that weak validators cannot attest to those blocks, or don't attest, or don't see the blocks, etcetera. And you can also see that builders are already discrete, discriminating against certain blocks that are just too big because they might want to deliver the block in the last milliseconds. So in the last milliseconds, they would throw out a lot of other transactions. Right.
01:19:25.286 - 01:20:32.524, Speaker A: So I'm in agreement that, like, these are all issues. I wonder, does the group think that call data increase comes with a blob count increase? And if so, is anybody doing the research required to get very clear data driven numbers for whether we can do that? Because just doing the cold data increase in the vacuum, honestly doesn't seem, you know, like it. It seems like it doesn't like solve much of a problem in a vacuum. I think Perry from the EF DevOps team had like a stub eip about this and was planning to, you know, help with some of this research in the coming months. But yeah, I don't know to, yeah, to what extent, like it's been started or anything like that. Thankrad. Yeah, I think I just wanted to say, I feel like at least we can consider increasing it so that the max stays the same if we add this eap, because that shouldn't make things any worse than they are.
01:20:32.524 - 01:21:26.914, Speaker A: Well, that's also my strong view. Right. But I wonder, just so that we can have a good process about going about these things, I do wonder if we should be coupling the two conversations and if so, if we should assign someone, a dedicated individual that goes and does that research, because otherwise it seems like we could be having this conversation three months from now and being like, hey, hasenbad done the work. And if we think the work is important, then we should prioritize it and pick a person to go and do it. Does anyone want to volunteer for this? And yes, I guess the work would be benchmarking clients using a larger blob count, potentially ideally doing multiple different counts so that you can get a sense. Basically, it will be a lot of work. It might not be glorious work.
01:21:26.914 - 01:22:11.120, Speaker A: Somebody has to do it. Like maybe we will have capacity to do it. But I'm pointing out that this work must be done. And I think having conversations around these kinds of vip's while we don't have any person doing the work is kind of like a weird use of our time on all core devs. I feel like we are aligned on the general type thing, but to move the ball forward, it seems like there's a clear block here and I feel like we need to align that. Somebody needs to go and own it. Anzar yeah, I just wanted to say that this ERP is not only about making room for block increases, but in a way patches an existing vulnerability of the network.
01:22:11.120 - 01:22:49.974, Speaker A: Just because we've already seen from the blob, from the tests from last year, that as we reach the current maximum, maximum possible block size, the network does get more stable. And so actually just having a better upper bound for the block sizes, even if we don't use that room for block increases, is already, I think, very desirable from a security and stability of the network point of view. Right. But then you gotta think whose gas prices do they make more expensive as a result of that? And so on. So there's a bunch of like stakeholder analysis that should be done, that we should take into account. I think that has been done though. Like Tony.
01:22:49.974 - 01:23:38.734, Speaker A: Yeah, I just wanted to add, I will send you the link after the call, but we have actually done a lot of analysis on not only which accounts are affected, but also which functions are most affected. So what functions are the people calling that would be affected by 7623. So I can send you a table. So we have already done some analysis on who is affected and who not. And I can already tell you, I think it was 98% of all transactions are unaffected. So if you're doing token transfers, bridging, restaking, I don't know, it's all unaffected. So the only, the only accounts that were affected are basically those that are still using Ethereum for data availability.
01:23:38.734 - 01:24:10.404, Speaker A: Then the largest part that is affected are users that are doing simple eth transfers and putting some messages in the call data. But this is very negligible. And apart from that, there were big merkle proofs and starks that are still affected. But by reducing the token cost to twelve, it's. Yeah, this increasing cost would be manageable for all those affected parties. Gradu. Thanks.
01:24:10.404 - 01:25:22.954, Speaker A: Any other comments, questions on the CIP? We only have five minutes left. Okay, if not, Charles had an EIP that he wanted to present non reentrant and reentrant opcodes. Charles, are you still on? Yeah. Hey, so you can see here, I drafted an EIP for an opcode to prevent reentrancy. I checked this morning and I was surprised to find out such a thing does not exist like an existing EIP. This is kind of like a reaction to EIP 7609 not being included in Petra, because that seems like the logical way to give application developers the ability to like prevent reengiency cheaply. But anyways, this is the alternative.
01:25:22.954 - 01:26:15.862, Speaker A: You know, it's pretty simple. We have two opcodes and it sets the re entrancy flag for a contract. I mean, it basically looks like what you would expect if you've thought about how to prevent re entrancing in the VM. You have a flag for the contract and it basically lasts for the lifetime of the transaction. It gets cleared and it rolls back when you get a reversion or something. Anyways, so if you compare this to 7609, I think EIP 7609 is a lot more elegant. It also solves kind of the basic problem, which is that engine storage is way, way overpriced and I'm not sure, sure why it was not really considered and I didn't really get any feedback or anything.
01:26:15.862 - 01:27:33.144, Speaker A: So anyways, if we don't want to do that, then like please give me another way to prevent reentrancy cheaply. And I'm happy to take questions about either this or EIP 7609 or the payoff code EIP because those are all extremely important to helping users prevent rent. And see. Charles for the ideal people that you would love to get feedback from because the room is quite diverse and honestly I don't think everybody has full context on what the right thing to do here is. So if you were to point at like a category of skill set in the room, what would that be? Core devs who are familiar with pricing for opcodes or like reentrancy prevention mechanisms. I guess there's two questions in the chat. One is proposing just using open Zeppelin's reentrancy guard and then live client is asking, did we not ask t store to address this? We did add t store to address it, but it's too expensive.
01:27:33.144 - 01:27:50.868, Speaker A: And that's why EIP 7609 is intended to also address. But I didn't get any feedback on it. Re entrancy guard, same thing. It's too expensive. Reentrancy guard is a, it's an abstraction. You can use any implementation. You can use transient storage.
01:27:50.868 - 01:28:20.184, Speaker A: You can use this non re entrant opcode, if it exists, you can use storage. It just depends what makes sense from an implementation perspective. Right now, tload and Tstore are basically too expensive for people to opt into using it by default, and it's priced the same as warm storage, which doesn't make any sense because it doesn't interact with access lists and it has kind of simpler semantics.
01:28:24.204 - 01:28:24.596, Speaker B: I guess.
01:28:24.620 - 01:29:49.272, Speaker A: Yeah, we have two minutes left. Anyone on the client teams have feedback or questions concerns about this? I assume the only worry on it would be increasing the maximum memory that you could allocate in one transaction for lowering the cost of t stuff that's addressed in EIP 7609, which I'm begging everybody to please read because it actually improves maximum memory consumption. It lowers the limit by design, so it's cheaper in the average use case in the most common use cases, and it's more effective at preventing dos than the existing pricing schedule. Okay, any other questions? Comments? We have only a minute. Otherwise, I guess people can continue this on the ETH magician thread for the EIP. Okay, anything else before we wrap up? Okay. If not, well, thanks everyone.
01:29:49.272 - 01:30:03.360, Speaker A: Talk to you all soon and I'll post a quick recap of the call on discord in a few minutes. Have a good one. Thank you. Thank you, Tim. Thanks. Thank you. Bye bye.
01:30:03.360 - 01:30:03.584, Speaker A: Thanks.
01:30:03.624 - 01:30:04.264, Speaker B: Bye. Thanks.

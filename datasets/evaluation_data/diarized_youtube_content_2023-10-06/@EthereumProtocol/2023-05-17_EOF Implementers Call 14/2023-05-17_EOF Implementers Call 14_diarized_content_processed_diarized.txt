00:00:02.630 - 00:00:32.000, Speaker A: You. Hey all, welcome to the EOF implementers call number 14. Let's just go ahead and get started with some client updates. Does anybody want to share what they've been up to the last couple of weeks? Iman.
00:00:34.020 - 00:01:00.210, Speaker B: From the mine side, we don't have that many updates. Besides we were going fixing minor problems we found in our prs and we are prototyping the three static call delegates call and call alternatives for EOF and we haven't merged that yet into the EOFPR. So yeah that's it.
00:01:02.820 - 00:01:07.650, Speaker A: Cool. Anything from AVM one?
00:01:12.950 - 00:02:10.230, Speaker C: Hi everyone. Yeah, so we kind of reached the point, yeah, I wasn't on the last call, so if something could be overlapping with the previous updates, forgive me. So first of all we had a release of EVM One and included all the Shanghai changes and all of that, but it also has kind of sealed this EOF 1.0 that we planned to have for Shanghai originally. And this is more or less reflects the state of the spec that we had some time ago. And there's also a tagged version of ethereum tests that actually agrees with this. So that's kind of like the milestone that is finished.
00:02:10.230 - 00:03:26.586, Speaker C: And on top of that we started applying so far some changes to EOF. What is think? Nothing? Well I think there was one more change that we already included. I will check it in one. But we're doing some of the modifications in polar and this is a bit of setting up some new infrastructure which means we want to be able to kind of tighten the loop of development and don't rely on this official ethereum test. So we're doing a fork of that which will be at upstream later. But we don't want to wait for this upstream to happen so we can move on with features and we're kind of doing something we mentioned for longer like delegate call restriction. Some new instructions are being implemented, like the instructions related to data access in the data section.
00:03:26.586 - 00:04:08.290, Speaker C: Create three and probably many others as well. Yeah, jump f like all of that is happening in parallel. Some of them are almost done and we'll trying to merge them in coming days. Yeah, so mostly that's the update. Yeah, I'm just checking if there's something new. I think not. The one more like EVM change was M copy was added, but that's kind of outside of eos.
00:04:10.870 - 00:04:14.310, Speaker A: That was added to Cancun.
00:04:15.370 - 00:05:49.060, Speaker C: Yes, that's added for Cancun because we kind of want to work on this and also generate state tests for that so people can take a look if it stayed or not, we don't know, but it was kind of back and forth how to exactly do it. But EVM one, it doesn't have very extensive infrastructure how to enable eips and all of that. So we decided to just put it into Cancun. So the test will be kind of done this way, but we kind of open to it, to discussion how to exactly do it. We were considering like going one more revision into the future. We also had this Eaps enabled, I think that was used some years before. I mean, this like the hard fork name plus something, and I'm not sure if that's also something people would like to continue working with because there are some changes to this official test and now the AP tests are just going into different directory, so maybe that's enough.
00:05:49.060 - 00:06:58.860, Speaker C: I assume if the M copy state test will go into different directory in the test repo. So if you want to check them, I guess you just need to point your tool to this directory and you don't have to kind of extensively configure it. But yeah, we'll see how it play out in nothing. None of the expected EOF changes has been emerged in EOF, but I think there are at least four or five different set of features that we work on in parallel. And I guess it takes longer to go from the prototype phase to something the team is happy with. And we can merge, but I think we kind of unblocked some of the obstacles, so I expect it will go a bit faster from now on.
00:07:00.590 - 00:07:22.610, Speaker A: Yeah, that makes a lot of sense. Cool. Sounds like a pretty good two weeks for you guys. I don't know if Mario, you had anything, any thoughts on if it's useful to have these fork name plus eip number tests, or is that a mechanism that you think is useful for testing?
00:07:23.510 - 00:07:55.260, Speaker D: Yeah, I'm fine either way. I think we do use it in the python test, so it's fine by me. Either way. I do find it useful because you can separate if you have the EIP number only. You can really separate your tests from the rest of the fork. If you're not entirely sure if that specific EIP is going to make it into the fork, that way is useful. But yeah, I'm fine either way.
00:07:58.590 - 00:08:03.550, Speaker E: Basu is not set up well to do the plus EIP, so the EIP directories are actually a great solution.
00:08:08.820 - 00:08:10.050, Speaker B: Same for us.
00:08:16.640 - 00:08:23.340, Speaker A: Okay, sounds good. I assume, Dana, you didn't have any updates for Beisu?
00:08:24.240 - 00:08:40.930, Speaker E: Not too many. Been focused on optimizations mostly as far as the state we're at with our mega. We have all the operations except for the call series and the create series. Mostly waiting for clarity on some of those. I don't think create is changing too much. Maybe an opcode number. The call series opcode numbers.
00:08:40.930 - 00:09:09.052, Speaker E: So that's what I'm waiting on. Before I get too invested, I do have one small test that is a smoke test for the operations. Not by any means an extensive test. It just makes sure that they operate as expected. Which was a good thing to put in because they weren't at first. But yeah, I guess it's until there's clarity on where we're moving some of the opcode numbers. And then we can get really excited about writing the tests and moving those forward.
00:09:09.052 - 00:09:11.550, Speaker E: So that's where base is at right now.
00:09:20.390 - 00:09:48.210, Speaker A: Makes sense. Cool. Okay, I guess we can switch gears. Probably no compiler updates. So we can just go ahead and jump into spec updates. Is there anything that you guys wanted to discuss on the call here? I didn't see a lot of chatter on the EVM channel over the last two weeks.
00:09:51.400 - 00:09:54.980, Speaker E: I think we've all been worrying about SSD versus RLP.
00:09:59.000 - 00:09:59.750, Speaker A: Yeah.
00:10:00.760 - 00:10:27.644, Speaker E: So one thing I would like to discuss and hammer down is there was discussion of moving some of the opcodes around. Something like moving all of the EOF only opcodes into the e series. Taking them out of the B series. And if we move stuff out of the B series do we need to move t store down to b zero or are we fine keeping it wherever it's at in the b series? And also where the. I think we did have clarity. Well there was some conflict with stuff like return contract. Where some of the final opcodes were.
00:10:27.644 - 00:10:59.220, Speaker E: So those are, I think some things we need to lock down before we can make a real serious proposal. We also need a spec for the gas free ones. I forgot who was going to take a stab at it two weeks ago. But if they don't have time I could take a stab at it myself. If there's no work progressing on that EIP spec for the gas free call series. But those are the things I think we should discuss today.
00:11:00.150 - 00:11:11.380, Speaker A: Okay. Yeah. Did you end up writing down a proposal for the exact opcode layout or did we just discuss it on the call last week?
00:11:12.950 - 00:11:20.306, Speaker E: We discussed it on the call. I thought. Did it not get captured in the chat? I think it was in the chat and the chat disappeared. So we have to go back to the notes.
00:11:20.418 - 00:11:21.080, Speaker A: Yeah.
00:11:25.150 - 00:11:36.590, Speaker E: But someone had expressed the desire that the EIP only ones get concentrated in one place. Because there's some opcodes coming in that are still useful in legacy. So those could be in a different series.
00:11:42.300 - 00:12:04.800, Speaker A: Yeah, I can't pull the notes up in front of me right now so I don't remember what the exact layouts were. I don't know how contentious these are. I think it's more important just to say this is what we think the opcode should be. We still have the opportunity to change 1153 opcodes and we should sort that out ASAP.
00:12:10.740 - 00:12:19.750, Speaker E: Okay. It might be a couple of days for me to write that up. Got my son's high school graduation this week so a lot of non work time.
00:12:20.920 - 00:12:28.150, Speaker A: Yeah. I don't know if anyone from the Epsilon team has a strong feeling about how the opcodes should be set out.
00:12:29.640 - 00:13:53.890, Speaker C: Yeah, I don't really have any strong preferences although we kind of, I mean this is kind of recurring issue and we had the same for M copy for example so it doesn't really have nice fit into considering existing grouping of opcodes and so on. I don't know how to exactly solve that. So we don't have to kind of have big coordination calls to resolve that practically if we consider this transit storage I think maybe the good solution would be to move them to this m store s store group. But we just took three slots there for air jumps and they are like EOf only. So we can move them from there. Put somewhere like to eof only section and then have a place for tstore so tstore doesn't use this b zero whatever section this number of ways we can do it.
00:13:57.940 - 00:14:01.830, Speaker D: I don't know what would be good.
00:14:02.760 - 00:15:02.520, Speaker C: Yeah, just maybe just have kind of spreadsheet with all proposed eaps and I don't know something that we can have like overview but also with enough details to understand where the opcodes are targeting so we don't have to kind of go into individual eips documents because people have the same idea where to put new instructions and they usually conflict with each other. And I kind of feel it's not like a big deal in the end. I mean it's random selection will be fine to me as well. So I think it doesn't really affect so much the software is just like probably like pedantic nature of developers.
00:15:04.780 - 00:15:05.864, Speaker A: For sure.
00:15:06.062 - 00:15:23.790, Speaker C: Yeah, but maybe have. I don't know how much you want to invest in organizing this but something like one place when you can at least see some suggestions where to put new instructions or something.
00:15:27.200 - 00:15:38.370, Speaker E: I think this is a great candidate for an informative eat a living document of it and as eips go in and out, it gets added and updated. And that's the duty of an opcode. EIP is to do their changes.
00:15:39.140 - 00:15:42.470, Speaker C: Yeah, yeah. Maybe that sounds like. Yes, I agree.
00:15:47.020 - 00:15:53.400, Speaker A: Does anybody want to take a stab at it? Did you have something to say, alex?
00:16:00.280 - 00:16:30.460, Speaker F: Yeah, I would actually suggest why don't we. But then I realized that technically it's not easy. Why don't we fork EvM code to have like a new fork there, which has tentative or whatever. It's like a nice visual representation. The technical issue is that it depends on Ethereum js and the forks in there. And it's kind of messy.
00:16:32.160 - 00:16:32.910, Speaker A: Right.
00:16:35.120 - 00:16:55.940, Speaker F: But regarding the informative eips, I think there has been like a really strong push to not have anything but technical specs in the EIP repo. And maybe people would be more receptive if we wanted to start such a list it to exist in the execution specs repo.
00:16:59.160 - 00:17:07.720, Speaker A: Yeah, that's a good idea too. Having some markdown table or something in the execution specs.
00:17:10.060 - 00:17:23.550, Speaker C: Yeah. One more idea is how to combine both of these. Maybe if the format is like something the EVM that codes can pull into the web page somehow would be nice.
00:17:28.650 - 00:17:29.014, Speaker D: Yeah.
00:17:29.052 - 00:17:31.510, Speaker A: Like some machine readable format.
00:17:32.810 - 00:17:43.354, Speaker C: Yeah, I guess maybe even if the structure. If this markdown what we've fixed structure.
00:17:43.402 - 00:17:46.714, Speaker A: I think maybe it's all machinery.
00:17:46.762 - 00:17:50.080, Speaker C: If it's a table in magdown, I guess it would work as well.
00:17:50.450 - 00:17:54.640, Speaker A: Yeah. Does somebody want to take a stab at this?
00:17:56.390 - 00:17:57.780, Speaker C: You would like to?
00:17:58.390 - 00:18:01.620, Speaker A: I would not like to. I was hoping someone else.
00:18:05.270 - 00:18:09.910, Speaker E: Give me till Monday. I'll take a stab at it. If I'm not at it Monday, hold me accountable.
00:18:10.490 - 00:18:23.400, Speaker A: Okay. Yeah. Let's record that. I would really like to have a recommendation for what we want to change t load and t store to by Thursday next week for the all core devs call, though.
00:18:24.410 - 00:18:32.940, Speaker E: That's why I want it by Monday, so we can pitch it in there and socialize it so people aren't surprised on the call. Yeah, I think I'll have time. We'll see.
00:18:33.730 - 00:18:34.670, Speaker A: Alex?
00:18:36.610 - 00:18:36.974, Speaker C: Yeah.
00:18:37.012 - 00:19:35.860, Speaker F: You also asked earlier whether anyone has like a strong opinion on where these should lie. I think I'm building up more of a strong opinion that all the Uf specific opcodes should be on the e zero range. It actually frees up, or at least solves a lot of these problems, because then all those other spaces are kind of free and we can just have deload and whatnot in the regular, whatever, 40 or 50 range. And then lastly with the calls discussion, maybe from two weeks ago. I really like the idea that it's actually not related to EUF as we discussed, and they fit nicely in the f zero range. So I think all of this kind of solves their problems if we move the EOF related or specific ones into e zero.
00:19:40.290 - 00:19:41.920, Speaker A: Okay. Yeah, that makes sense.
00:19:42.450 - 00:19:45.120, Speaker E: Is contract return eof only?
00:19:47.010 - 00:19:47.470, Speaker F: Yes.
00:19:47.540 - 00:20:28.640, Speaker C: Well, yeah, I agree, because I just took a look on the opcode table and. Yeah, kind of. EOF opcodes are kind of spread it into different places and it kind of created conflicts. So, for example, Tstor cannot go into natural place because we took it for Eof only instructions. Kind of the same issue is on the call. Whatever. So if we move uf only instructions in some separate place, I think that will solve many pending issues.
00:20:28.640 - 00:20:33.760, Speaker C: Yeah. So I think it's a good idea to do it this way.
00:20:41.270 - 00:21:22.894, Speaker A: Great. Any other thoughts on this opcode discussion? Cool. I also wanted to say that we talked maybe, I don't know if it was async or last call, about trying to get 44 four to rename their opcode from data hash to something else. And that change has been accepted and merged into four four four. So now it's blob hash. So there's not a conflict with that from elf now. Okay, the other topic.
00:21:22.894 - 00:21:55.100, Speaker A: What was the other topic? We wanted to talk about the delegate call stuff. We did not get the blob fiddled hash. Yeah, I mean, honestly, they're all pushovers. We can make it however we wanted to at this point. They just want to ship four four. They'll accept any name. Okay, do we have something to talk about on the delegate call things?
00:22:08.460 - 00:22:12.570, Speaker C: Okay, what exactly? Like, the context of that is?
00:22:12.940 - 00:22:18.250, Speaker A: I thought Dano had mentioned there was something else around delegate call that he wanted to talk about.
00:22:20.300 - 00:22:25.980, Speaker E: Don't recall. Maybe I was talking about where to put the call series opcodes, and I think that was covered in the opcode counting.
00:22:26.320 - 00:22:27.070, Speaker A: Great.
00:22:28.400 - 00:22:32.284, Speaker E: The clarity is mostly around the numbering of the opcodes.
00:22:32.412 - 00:22:40.050, Speaker A: Yeah, got it. Okay. Any other spec related things we want to talk about here?
00:22:41.300 - 00:23:17.950, Speaker F: Yeah, actually on this. I know that even on the last call I promised that we're going to have the cold cip. Yeah, we haven't finished it yet, but it's in progress. Yeah, I really hope we're going to get it done this week so that it can be discussed on all cordevs. But we'll of course, share it with the team, with the people on this call as soon as it's in a shareable form, and then we can discuss the specifics, including the opcode numbers in there.
00:23:23.480 - 00:23:34.680, Speaker A: Sounds good. Any last spec discussions? Thoughts?
00:23:47.900 - 00:24:11.220, Speaker B: Okay, I. I have just a simple question regarding the dupe n and swap n opcodes. Can we do the same thing for push opcodes or. Push upcodes are too abundant and too frequent to justify that extra byte or the immediate.
00:24:14.520 - 00:24:32.924, Speaker E: So I think the issue with push in with, not push in with swap in and Dupen is they only have 16 reserved in the opcode table and push is up to 32 and they want us to be able to swap deeper than 16 in the stack. We could do multi byte opcodes with.
00:24:32.962 - 00:24:33.580, Speaker A: Push.
00:24:35.280 - 00:24:59.430, Speaker E: But then that would be an extra byte and the registers only accept up to 32 bytes. So we've got the full space of push where that might be useful, and I don't think we're there yet, is if we need to start reclaiming opcode space in a future version of EOf so we can get more space for operations. But I think that's at least a five year issue down the road, to be honest.
00:25:00.440 - 00:25:00.852, Speaker A: True.
00:25:00.906 - 00:25:02.630, Speaker B: Yeah, makes sense. Thanks.
00:25:14.500 - 00:25:15.250, Speaker F: Okay.
00:25:17.140 - 00:25:23.580, Speaker A: Let'S move on to testing updates. I know Mario. Sorry, go ahead, Alex.
00:25:23.740 - 00:25:26.800, Speaker F: Do we even need any pushes besides pushiro?
00:25:34.550 - 00:25:36.340, Speaker E: We would need at least push one.
00:25:39.910 - 00:25:40.610, Speaker D: Right?
00:25:40.760 - 00:25:44.150, Speaker F: Or ink or incrementing.
00:25:44.730 - 00:25:53.190, Speaker E: Oh, you're right. So we could just define push one in terms of increment. All right, that would be a fun mapping. Oh, but we don't have an increment operation.
00:26:00.220 - 00:26:01.444, Speaker F: Yes, very light client.
00:26:01.492 - 00:26:14.400, Speaker A: Go ahead. All good? Yeah, let's move into testing. I know Mario has some things you wanted to talk about. Do you want to share what you guys have been up to, Mario?
00:26:15.380 - 00:27:02.540, Speaker D: Well, yes, it's not much. I just started last week on updating the python tests for UF. So basically I have this branch where it has all the python modules and constructs to easily build and compile the OS containers. And I have just baited this to the mega UF, but at the moment I haven't been able to test it because I require the get binary to be able to run these tests. And yeah, basically this branch I will share with you guys is not ready. It has most of the construct but not every single one. And I think it's compiling EOS containers correctly.
00:27:02.540 - 00:28:22.810, Speaker D: And I should be able to write more tests as soon as I fix all the remaining issues with the constructs. But basically this is work in progress. But I think it's going to be very valuable in the future that we can use. We are currently migrating to pytests from basic Python to pytest so what this does is it brings a lot of parameterization utilities to easily write tests in a parameterized way. So you can, for example, if you want to write the test for the stack in EV, you can basically just parameterize a single test case with all the opcodes, for example. And if you have the number of stack items that each upcode pops or pushes into the stack, you can very easily just iteratively just automatically create tests for every single upcode in Python format. So yeah, I think it's going to be very useful for us for EOF in general to make very quick changes to the tests and make the tests adaptable to any spec changes that might come in future.
00:28:22.810 - 00:29:14.980, Speaker D: This is not done yet. As I said, this is work in progress, but I will keep you guys updated. One thing that I noticed while writing the container, the container module in this Python construct. So yeah, basically we have this EOF container construct that it makes it very easy to build EOF containers inside these tests. And this thing is, you can put containers inside containers and it will basically construct the entire bytecode for you automatically with whichever code you want, whichever sections you need. Everything is very automatic and very easy to follow. One thing that I noticed that is making my life a little bit harder.
00:29:14.980 - 00:29:53.910, Speaker D: It's not a complaint. I just perhaps wanted to know the reason of this is that the header and body order of the data and container sections is not the same. And I mean in the header and the body, and this is a minor issue. I just wanted to know if there was any reason why the order was inverted in the header and body. But apart from that it has been smooth to update from the previous version that I had a few months ago to this new mega EOF version. Yeah, basically that's it.
00:29:58.060 - 00:30:01.800, Speaker A: Sweet. Anybody know why those fields are inverted?
00:30:02.300 - 00:30:07.064, Speaker C: You mean the order of sections in the header and in the body is different?
00:30:07.262 - 00:30:08.330, Speaker D: Yeah, exactly.
00:30:09.660 - 00:30:13.070, Speaker C: I think it was a typo in the spec and I fixed it since then.
00:30:14.000 - 00:30:19.230, Speaker D: Oh nice. Okay, then I will, what's the correct order?
00:30:19.920 - 00:30:21.950, Speaker C: Data is in the end.
00:30:23.860 - 00:31:01.490, Speaker D: Perfect. Okay, thank you. Yeah, and I will keep you guys updated on this date. I will work on the following week weeks on this new branch, and I want to prepare a guide on how to write the tests. And maybe I'd like to present when this is ready for you guys to see how easy it is to write atest, to modify atest, or write iterative or automatic test cases with this thing.
00:31:04.260 - 00:31:09.060, Speaker A: Yeah, that would be really awesome. Thanks for that update, Mario.
00:31:09.560 - 00:32:03.510, Speaker C: Yeah, I have something to add. So one thing is that evm one was getting support for this command line tools for test generation in specifically this t eight n and Radek from our team were working with Spencer for your own team I believe, and I think they got it to the point that it somehow worked. So I think that is in the context what you said that you need like GeF update updated and maybe that's not needed. But yeah, we can figure out later if that works, if you can include EvM one as the driver for the test generation and so on.
00:32:05.420 - 00:32:45.620, Speaker D: Yeah, definitely. So to give a little bit more context in the main branch, we are currently making a switch from normal Bonila Python into pytost. But I think once we have done this conversion, I think we can focus on bringing Evm one into the set of builder tools that we can use to produce tests. Definitely. As you mentioned, I'm not sure if the Spencer had that already implemented, but I think it shouldn't be a big deal and should be doable rather quickly once we finish with the pytest commercial.
00:32:46.520 - 00:32:50.100, Speaker E: Is Ethereum js in the current set of tools that are accepted?
00:32:51.000 - 00:33:12.572, Speaker D: No. Currently how we test Ethereum JS is we output the test the blockchain JSON fixtures and then we pick those up in hype and then we run with Ethereum JS. Yeah, that's the only support we have.
00:33:12.626 - 00:33:34.470, Speaker E: Right now because in my work on the tan Java startup is not that hot and I was working on some grawl stuff to try and speed it up. I don't know where that went, but there was also a request from Dimitri to include the batch mode server that I guess Ethereum Js was implementing. I wonder if that was figuring into your current tooling or not. So that's why I asked.
00:33:34.840 - 00:34:15.250, Speaker D: Yeah, I think that will come in really handy because I'm not sure what the status is, but I think I suggested something similar forget because right now for 48 four there's an issue where every time that you bring up the evm tool it has to load all this very big array that's related to the KCE commitments and all that stuff. So it's taking up to a second each startup. So to fill the test is really hard. So yeah, if we can get some support for batch and operations in this evm tool, whichever evm tool it is, I think that would be very awesome, very great.
00:34:15.780 - 00:34:22.960, Speaker E: Okay, for base it'll probably be a variation of tan since that seems to be the standard. I think we can put a sunset on retesta.
00:34:29.470 - 00:34:54.010, Speaker A: Awesome. Anyone have other testing updates they want to share any other eof things in general that we didn't get to cover yet?
00:35:14.450 - 00:35:59.820, Speaker G: Sorry, I've been a bit awol for the last few months, so I haven't been really up to speed. But I've been thinking about the stack validation rules and about outlining instead of sharing code. But I think I still need to think about the issue a little bit more. But I think me and Daniel spoke about this in the discord a little bit, and I'm wondering for duplicated code that would normally just be collapsed, like do we need to use jump f or call f going forward?
00:36:11.190 - 00:36:22.050, Speaker E: Sounds about right. And I think the new phrasing of jump f would allow you to have stack inconsistencies if you're jump f in to a terminal thing like raising a revert.
00:36:24.710 - 00:36:27.460, Speaker G: Oh, I see. Is that new added to the spec?
00:36:28.790 - 00:36:45.002, Speaker E: I think that's in the new jump f, and I know we discussed adding it. We got plenty of time to add it if we need to. If it's valuable to have jump f, disrespect some of the stack conventions if it's for functions that are terminal that.
00:36:45.056 - 00:36:57.790, Speaker G: Don'T, because there could be cases where you kind of want to share code that are not terminal, but maybe that means you shouldn't be using jump.
00:36:59.890 - 00:37:30.860, Speaker E: Right? The Stack validation rules are going to make a lot of transpolation options linear time, which makes them feasible in client infrastructure, which is why I don't really want to mess with the call f semantics. But it's the jump f that is terminal, won't return, and won't destroy the stack assumptions that are gone with it is why it's valuable for jump f and possible for jump f.
00:37:34.110 - 00:38:45.522, Speaker C: Yeah, so this jump f, and this is combined with this non returning function. So we kind of think make some restrictions invalid. You can skip some restrictions this way, but this kind of works, as you noticed, for the sleeve code blocks and for kind of branching code. We discussed that with Daniel, I think months ago. There's one more simple change we can do, which doesn't really solve the problem. But now you have to be very specific about the stack height you put in the UF container, the max stack height. That can be kind of less restrictive if you disobeyed inequality this way.
00:38:45.522 - 00:39:45.830, Speaker C: So you put some number, and when you validate the computed number must be below that limit so you don't have to precisely compute it. But I think that doesn't really affect compilers so much. It can be useful for people that want to write some opcodes by hand and can put some arbitrary limit. But there was also like a second suggestion. I think there are cases when you can modify how this validation algorithm works in a way that the stack height, it's not exactly the same at every place, but at least they are bounded. And at least what I wanted to do is present the problem as the document and how it works right now. And maybe people can collaborate on how to improve that in this context.
00:39:45.830 - 00:39:51.478, Speaker C: But not so much progress has been done on this.
00:39:51.644 - 00:40:02.380, Speaker G: Yeah, I mean bounding the stack height is not as clean, right? In a lot of ways.
00:40:04.190 - 00:40:16.654, Speaker E: And the problem with the bound stack is it makes the trivial mapping to registers more difficult, right. When it's a fixed stack, it's trivial. When it's bound, you got more complex logic and operations for options, for bugs, right?
00:40:16.692 - 00:40:30.900, Speaker G: And then you can always just do something really horrible like force the stack bound to just be 1024 all the time, which doesn't really improve the situation from where it was before.
00:40:32.950 - 00:41:54.880, Speaker C: No, I don't think it's so bad, but in terms of mapping the registers, that's why I kind of wanted to write it down and to see how it works. I think it's also not so bad, but country prove it. I think to my kind of limited understanding of the practical use of that, I think the phenodes that kind of translate different registers between basic blocks kind of work with this. But yeah, I definitely would put also like requirements to make it work for this transpires or whatever. Right? So we don't want to break it in any way, but I think it would be nice to kind of present the problem and be able to collect some ideas how to maybe modify it in the way that it just allows more programs to be. Yeah, but I said it's not so much done above the discord discussion so far.
00:41:59.890 - 00:42:13.890, Speaker G: I think, Daniel, you were saying that for jump f's to subroutines which are terminal, then you relax the stack height restriction. But how do you know if it's terminal?
00:42:16.490 - 00:42:27.210, Speaker E: If all of the exits from the function are stuff like revert or return or stop, if there is a return f call in it, then it's not terminal, it returns.
00:42:33.550 - 00:42:37.530, Speaker G: Do we want to just backhyde restriction for any terminal node?
00:42:42.190 - 00:43:10.120, Speaker E: Do we have to write up it becomes less clean because then we'd have to introduce a new class of functions that are non terminal functions. Can we quantify what we would gain and lose by relaxing it and changing it in the solidity code? How much space reduction are we going to get by removing these duplicate nodes in production, I guess would be one question I would have.
00:43:10.810 - 00:43:16.462, Speaker G: Well, it's not just solidity that people are. I work on Viper, right, and viper.
00:43:16.546 - 00:43:21.340, Speaker E: But as far as the optimizers, what's the impact from an optimizer step?
00:43:22.430 - 00:44:03.960, Speaker G: I think that there's, I have to think about it, but if you're optimizing for bytecode, there's kind of a lot of stuff that you can't do if you can't collapse jump destinations. And I haven't thought about this in a few months, but you might be able to do it with subroutines. But I'm not sure. It's been a while since I was working the implementation too.
00:44:04.730 - 00:45:33.774, Speaker E: Right. Because if we're talking 1%, I don't know if the value, but if we're talking like 20% to 50% bytecode size, absolutely, let's do it. But if we're talking like two to five, it becomes a question of effort versus return, because right now the way it's written is very simple, and simple stuff is easier to prove, it's easier for implementations to get right, the simpler the spec is. That's one thing I've learned. In these multiclient situations, if we keep it as simple as possible, there's going to be less opportunities for consensus failures the more complex we make it. I think our most recent consensus failures were around net gas metering, the more likely those bugs will pop up in different implementations. So there's also the goal of let's keep it as simple as reasonable.
00:45:33.774 - 00:46:38.646, Speaker E: But that's the question of what's reasonable. Where does this, that's where engineering happens. What trade offs do we make? So that's why I'm in favor of keeping as simple as possible, is to reduce these consensus failures. But if there's other value we brought in and we can increase our testing coverage to reduce the consensus failure risk in proportion to the specification risk, that's something we can consider. But is the return we get from it worth the increase in the test coverage, the testing effort? So that's a lot of things that balance into it, which is why some sort of a quantification of restricting the stack height checking on terminal functions would save us 80% code, then that would be great. I mean, no one's going to get that within optimization, but that's the sort of numbers we would want to get on code size, because I think code size is going to be one of the big pitches that I think will. There are still some skeptics on the main all core devs call what is this going to do for the consensus clients? But I do think that being able to say that getting rid of jump tests will reduce code size by 10% will turn a lot of heads.
00:46:38.646 - 00:46:56.800, Speaker E: And I think that's some of the numbers we're getting back from the solidity team is somewhere in that neck of the woods. I think push zero already got. They already documented a number. I forgot what the number was, but it was something on the order of two to five, which was not trivial. It was a good number to get.
00:47:03.270 - 00:47:11.154, Speaker G: Right. Well, push zero is never going to increase code size, right.
00:47:11.192 - 00:47:12.740, Speaker E: It's going to decrease it, right?
00:47:16.570 - 00:47:29.820, Speaker G: Yeah. I need to think about it more, but I'm pretty sure there's cases that may be pathological where code size does increase, and I don't really want that. I don't think anybody does.
00:47:38.750 - 00:48:00.130, Speaker E: Yeah, we don't want it to grow in the pathological cases, but that's why we have things like maximum code size. The pathological case means you got to reconsider your code before you even deploy it. So the pathological can't get too large with a 48k init code and 24k runtime code. So there's already limits. It's going to hit quite early when it gets pathological.
00:48:01.270 - 00:48:13.830, Speaker G: There may be even cases where it's not pathological, but you're not able to take the same bytecode optimization. So the code is bigger in EOf than pre uf.
00:48:14.410 - 00:48:28.780, Speaker E: Right. And those are numbers we need to know. Do you have code working that doesn't optimize yet?
00:48:31.810 - 00:48:35.600, Speaker G: I'm thinking about it. I haven't done comparisons yet.
00:48:39.330 - 00:48:42.626, Speaker E: Because I think that's where EOF is going to.
00:48:42.648 - 00:49:02.760, Speaker G: Look at the updates to jump f. Okay. All right. I think that's all we can talk about that for now.
00:49:06.650 - 00:49:07.786, Speaker A: Okay, great.
00:49:07.968 - 00:49:11.754, Speaker G: I wasn't following more regularly. Sorry about that.
00:49:11.952 - 00:49:45.202, Speaker A: All good. Glad to have you here. We usually do compiler related updates as the second thing too, so would be glad to hear more of your guys'thoughts and things that change. Cool. Any final things, guys? In that case, I think we're good to go ahead and close this call. Yeah, let's chat again in two weeks. Talk to you guys later.
00:49:45.202 - 00:50:04.090, Speaker A: And then we'll be on the lookout for the post by Dano. Hopefully on Monday or so next week about the opcode layout. So we can talk on all core devs next week about how to change Q three opcodes. So that's the main thing. Have a good rest of your day. Bye.
00:50:04.830 - 00:50:08.150, Speaker G: Thanks. Farewell.

00:05:14.580 - 00:05:36.776, Speaker A: Welcome to all core devs consensus layer. Call 10 seven. This is issue seven. Five six in the pm repo. Okay. The first agenda item is a bit ceremonial. I think that we don't have much to discuss.
00:05:36.776 - 00:06:10.990, Speaker A: The Capella fork was last week and we did have the execution layer call soon after and did a bit of a retro there just in case. There are additional discussion points on Capella before we move on. Now is the time. Anything else on Capella? Hellotan has an alart spec.
00:06:12.920 - 00:06:31.850, Speaker B: It's more about the documentation thing. Just. We displayed the owl on the Capella transition and also displayed whenever someone converts a credential, it's just a spec to document the actual behavior. But yeah, Cafela was nice.
00:06:33.900 - 00:07:00.686, Speaker A: Okay. Yeah. Vanity art specs. Take a look if you feel strongly about it, maybe we can put that in there. Thank you. Okay. Anything else in Capella before we close this off? Okay, congratulations.
00:07:00.686 - 00:07:48.194, Speaker A: Great work. Okay, moving on to Deneb, there's a couple of discussion points from Tim before we get into discussing a few features that are under consideration in addition to 4844 and a couple of engine API points. Tim, can you kick it off on you had a link to some potential blockers for the 4844 Devnet five? Yeah. So actually there's three things. They're just things that came out in the call. So the potential blockers is not that there was a blocker, but we said that we would just check in with the client teams today to make sure that if there are any issues as we're trying to stand this up, we can bring them up on the call and then hopefully have the Devnet up sometime next week. So.
00:07:48.232 - 00:07:48.820, Speaker C: Yeah.
00:07:52.070 - 00:08:03.560, Speaker A: I guess if anyone can give an update, maybe on setting up the Devnet and any potential issues you've run into, that might be. Yeah, that'd be cool.
00:08:07.050 - 00:08:32.254, Speaker C: Maybe I can speak a bit to this. Rafael is sitting next to me right now and trying a dry run of the testnet so that we can make sure that tooling is looking as expected. Currently, Lodestar and Ethereum Js are the two that said they want to be involved in the dry run. But if other clients want to, please give us your images and we'll add you to the trial. But the current plan is to have Devnet five next week. If the plans are any.
00:08:32.292 - 00:09:17.662, Speaker A: Of course. Anyone else have comments or thoughts on. Okay, and then the next one. Mikhail, I believe you put up the pr that was mentioned, but it was. Yeah. Do you want to talk about that? Mikhail here. Yeah, I thought I saw him now.
00:09:17.662 - 00:10:10.820, Speaker A: I do not see him? No, he actually said he was not going to make the call, but basically, the PR I just posted was also on the four four four call. We discussed this just to merge the get payload v three and get blobs bundle v one engine API calls, and to try and get this live on the devnets as soon as possible. So if people want to review the specific pr so we can get it merged in the next couple of days, that would be ideal. And then the last item from the four four four call, Danny, was the new payload and reorg stuff. Yeah. Do you want to give some context on that? And I think Peter is also on the call. Yeah, I can give quick context, and certainly Peter can chime in.
00:10:10.820 - 00:11:18.440, Speaker A: Yeah. So I think one of the things that came out of mempool discussions at Adelvice was how to handle and reinsert blob transactions into the mempool upon reorgs, which is the facility we can provide to users today, because all the transactions, the full nature of the transaction, is in the block. Given the decoupled nature of the blobs, you might only have blobs available to do these reinsertions from what you've seen on the mempool. But plenty of things do bypass the mempool, so you might not have the blobs. I think the two potential paths here are to have new payload insert the blobs from the consensus layer, such that the execution layer can have them and choose to do what they want with them, like cache them till finality or anything like that. The alternative is to not be able to provide this quality service to users that bypass the mempool and just leave new payload as is. And if you want to handle reorg transactions, only handle what you've seen in the mempool and can locally do.
00:11:18.440 - 00:11:24.120, Speaker A: I think those are the two paths on that. Peter, you've been thinking about this a lot.
00:11:27.370 - 00:12:10.630, Speaker C: Yeah, well, sorry, I have a sore throat and it's a bit harder to talk. Yeah. So I guess you kind of summarize it kind of correctly. In my opinion, it's kind of nicer to provide that service for everybody. So if the consensus client has the blobs anyway, the blobs aren't that big. Currently, the limit is set to two to four blobs per block, so that's 500. Don't think that's such a big overhead as to be prohibitively expensive to just give that to the execution client.
00:12:10.630 - 00:13:04.890, Speaker C: My two cent would be to just send it over. And if for some reason, we think maybe it is kind of a bit excessive. Then we can always make it a bit. We could create a ping pong API where you just tell us that, hey, this block contains these blobs, and if I don't have them, then I can return some specific error message, and then you can reissue the new payload. It gets a bit messy, so I would try to keep it simple first. And if it, for whatever reason, isn't sufficient, maybe then complicated and exit. So the whole overhead of execution clients maintaining these blobs until finality is pretty much insignificant.
00:13:04.890 - 00:14:04.090, Speaker C: The only thing you need to do is maybe create, either in memory or on disk, just a small key value store where you map block numbers to blobs. And then if there's a reorg, you just resurrect the blobs back into your blob pool. If there's a finality event, you just delete everything that's below some threshold. There might be some very weird quirks, or even that. Sorry, some of the execution layer block numbers might not correspond to finality. In a very weird situation, it can happen that you have reorgs with varying depth and finality belonging to varying block numbers. But I think protecting against that kind of weird behavior isn't really relevant.
00:14:04.090 - 00:14:28.130, Speaker C: So, I mean, we don't really expect reworks to happen at all. And if they happen, and we can handle it gracefully, that's fine. If something really wonky happens and we lose two blob transactions, then, yeah, they can just resubmit it. So my two cent is the simplest solution would be for consensus clients to give the blobs to execution clients.
00:14:30.070 - 00:14:30.730, Speaker A: Essentially.
00:14:30.830 - 00:14:52.042, Speaker C: When they send the new payload. And even now, the new payload, you can't really say that this would maybe make it a lot more expensive because the maximum permitted transaction size in a block in a new payload can be quite significant even now. So it's not like we all of a sudden permit some wild big number.
00:14:52.096 - 00:14:54.522, Speaker A: To be passed there anyway.
00:14:54.576 - 00:14:56.990, Speaker C: It's a bit random, but kind of. Those are my thoughts.
00:15:01.010 - 00:15:56.720, Speaker A: There's probably two primary counterarguments. One would be the, and I know we've hashed these out before, one is this just kind of further breaks the abstraction between these two layers. So from kind of like an abstraction cleanliness standpoint, maybe not to go down that path, the other one is more future looking. It's that on average, a consensus layer node, in the event of data availability, sampling, wouldn't actually have all the blobs and would have sampled and might have a subset. And so we're then creating a facility and maybe a user expectation that is not coherent with what we believe to be our most likely future. And I know we can push back on that and say, I don't want to design for what we think is going to happen in two years, but that's definitely the primary counter here.
00:16:00.790 - 00:16:28.730, Speaker C: So I have no idea what that future will bring. But a quick question. This whole data availability sampling, is this relevant for the next executable block? So is the expectation that in the future, consensus clients will not even have the blobs for the block just produced by the network?
00:16:30.830 - 00:16:50.580, Speaker A: Correct? Yes, the network as a whole has the blocks, has all of the blobs, whereas individual full nodes, super full nodes, people that want to download them certainly will, but it's more distributed across the p to P, and you've sampled to prove to yourself that they're available, but not have all of them.
00:16:54.870 - 00:17:23.930, Speaker C: That's kind of interesting. However, currently the expected flow apart from mev bundles is that essentially the transactions, including the blobs kind of originate from the execution layer. So my guess is that the general expectation is that most blobs will traverse your machine because they will pop into your executables.
00:17:25.970 - 00:18:13.260, Speaker A: Yeah. In such a design, if you build locally, you're likely building smaller than the potential maximum blobs, and otherwise you're asking higher powered specialized nodes that you pay to package blobs. If you move into a regime in which you have ten megabyte or 20 megabyte total blobs, then the average node is not going to be touching them all. That is, in theory, the design of extending data availability beyond the capacity of a single full node or a consumer machine is that you have to bypass touching all the blobs on the normal case.
00:18:17.070 - 00:19:00.600, Speaker C: I see. Yeah. So my gut response to that would be that maybe we should try to cross that bridge when we get there. So if we want to allow that to happen, then my guess is that it would require a bit of redesigns on the blob pools too. So we would need to change the expectations on what happens with these blobs over the network in general, across the entire network. So I don't think it would be too big of an expectation to say that, okay, until now it worked like this, from now on, it will work like that.
00:19:06.170 - 00:19:37.410, Speaker A: I agree. I don't think that's a crazy thing to make such a shift. I just, designing the APIs such that we don't even have to necessarily think about components of that shift would be nice. In my opinion, but this is not like a major sticking point. I don't think I would like to hear if other people have opinions about the API and about this handling reords.
00:19:45.770 - 00:20:15.022, Speaker D: So I and Mikhail were sort of discussing this in the sharded data channel, and so one of the points was that since the transactions that will sort of bypass mempool will most likely be MeV transactions which are directed at a particular state. So they won't mind being dropped if there is a reorg, because that state won't be valid for them. Another thing that Mikhail brought up was.
00:20:15.076 - 00:20:15.680, Speaker A: That.
00:20:18.850 - 00:20:57.130, Speaker D: If CL wants to optimize and wants to sort of send over transactions new payloads to evaluate even before they get all the blobs. So to do some sort of parallel optimization, even in that case, this assumption breaks down that the CL will be able to pass all the blobs to the El. I think it would be very clean if basically we make the assumption that the blobs that bypass the blob, transactions that bypass the mempool, they won't be included in the rewards.
00:21:11.930 - 00:21:35.520, Speaker A: Are there other strong thoughts or opinions on this? I do think that the execution layer folks who are not vastly represented on this call might have more to say.
00:21:39.960 - 00:22:56.572, Speaker C: So in general, it feels a bit strange to have this use case where certain transactions that can appear in blocks cannot be resurrected. So that's definitely what would be a new behavior on Ethereum Mainet, since currently the expectation is that if your transaction was included in a block, then okay, if a reorg happens, there's always a very slight chance that it gets lost for whatever reason. But in general, you can rely on the transactions not getting lost. Now, with regard to Mev saying that, well, if you submitted your transaction by MeB, then you don't really mind if it gets lost on a reorg. That seems like a double edged sword. So I think if you submit a transaction and an MEV where you try to take advantage of a situation, and then the situation changes and the network even helps you undo so that you don't have to pay your initial fees, that seems like a bad thing. I don't know.
00:22:56.572 - 00:22:57.870, Speaker C: It doesn't really.
00:22:58.480 - 00:23:28.032, Speaker E: I want to push back on that. I think in reality, as long as your transaction is economically valuable, which basically just means it has a tip, even if normal nodes don't push it back on the chain, someone will, right? Even if it's just for MeV, there's an incentive to simply say as a block builder, to take that transaction. If it was reorganized and put it in my blob, in my blog.
00:23:28.096 - 00:23:28.710, Speaker A: Sorry.
00:23:29.880 - 00:23:37.130, Speaker E: So I think it will still happen. There's no reason why it shouldn't happen. People are definitely sophisticated enough to do that now.
00:23:37.500 - 00:23:37.864, Speaker A: Yeah.
00:23:37.902 - 00:24:10.896, Speaker C: But then it means that essentially, people running a custom build or a custom flag, which just forces these blobs back into the execution layer, will actually have the potential for more feats. Essentially. Again, essentially, we're creating a mechanism by design where it's mev potent. It's worthwhile to run custom code versus the stock code, because the stock code, by design, discards the data it could not discard or could retain.
00:24:11.088 - 00:24:11.492, Speaker A: Right.
00:24:11.546 - 00:24:18.480, Speaker E: But I feel like we're talking about very minute amounts that already exists.
00:24:18.560 - 00:24:19.140, Speaker A: Right.
00:24:19.290 - 00:24:41.740, Speaker E: That discrepancy is already pretty huge due to existing Meb on chain. And now you're saying in the case where someone reorgs a block, then in those rare cases, you can make a little bit more money by including that block transaction. My bet would be that this is less than 0.1% or so of meV.
00:24:43.540 - 00:25:44.640, Speaker A: Yeah. I guess where I stand is by making type transaction three, be very specific, and not even be able to carry non zero blobs. We've tuned this and tailored this to a highly sophisticated user, at least in expectation roll up operators. And so if these highly sophisticated users are bypassing the pool, they're also probably sophisticated enough to resend and put their transactions in. I think one thing that Gotinder mentioned was MeV transactions often are tailored to a particular state, meaning they're sophisticated enough that they have or should have particular slots that they can be executed, and they might have particular conditionals upon state in which otherwise they would fail. And so these transactions, often replayed in other contexts, do throw.
00:25:46.920 - 00:26:11.240, Speaker C: But they do need to pay the block fees. So essentially, once it gets propagated through the network, the idea is that once you cost the network to bear the bandwidth requirements of getting your transaction all over the place, you should actually be more or less forced to cover those costs.
00:26:11.400 - 00:26:41.000, Speaker A: Yeah, which I get, especially in the mempool, because the mempool, even by you, can put that cost without ever getting into consensus if things are tuned poorly. Whereas in this Reorg situation, you did put the cost, but you put the cost in the context of blocks, which were reorgan, which in the normal case, don't. And so I think the argument is a little bit less strong than if you actually were in the mempool.
00:26:45.790 - 00:26:56.960, Speaker C: I mean, you're still broadcasting or propagating that block through the entire network, at least in the current design. So you're still.
00:26:58.930 - 00:27:09.490, Speaker A: Yeah, but if it's picked up in a reorg in another block, it's going to be broadcast again. So it doesn't matter what was picked up in that reorg because it's going to represent blob load.
00:27:11.110 - 00:27:52.950, Speaker C: Yeah, but if it gets lost, then you just broadcast it for free anyway. Yeah, it's kind of very subtle, so it's not like. Yeah, I don't know, I can definitely think about it. I guess it's kind of. If the general long term direction is to try to only have a sample of these blobs, I don't know, maybe in that world it might make sense to do this limitation now I don't have to think about it.
00:27:53.100 - 00:28:37.610, Speaker A: Yeah. Why don't you chew it on this week? And we'll also ask the execution layer folks to consider this, and we can try to make a decision on the execution layer call in one week time. Cool. Thank you, Peter, for joining us. Any other, just final comments on this before we move on? We have a pretty packed schedule today. Great. Tim, did we cover everything in the devnet of potential blockers? Yeah, that's all the stuff that was from the Ford for call.
00:28:37.610 - 00:29:39.980, Speaker A: Great. So I want to spend some time at least looking at some of the features that are sitting in the feature directories on the consensus layer specs that could be under discussion for Daneb, or at least we can start figuring out, if not Daneb, where they fit in the priorities for potential future forks. My feeling is that there might be room for one or two small things that are not cross layer, other than maybe 4788, but that the opportunity for additional cross layer things beyond that is probably low. And for example, like the deposit in protocol deposit processing. But let's take a look at some of these. So 4788 is cross layer. That is that beacon block route into the EVM.
00:29:39.980 - 00:30:06.292, Speaker A: And that was discussed on the execution layer call last week. I do not believe a decision was made. But Alex, can you give us the quick on that and then an opportunity for people to signal if this know coherent and simple and fine enough to get into Daneb, assuming that El also agrees. Sure.
00:30:06.346 - 00:30:45.520, Speaker F: Yeah. So at a high level, the idea is we want to expose some cryptographic accumulator from the consensus layer into the execution layer. So this could be like a state route or a block route. The way the features are written now is passing the previous block route into the current block, which is then just passed along to the EVM where it's exposed there. So if you want to look at the El details, you can look at the EIP. Otherwise this feature is pretty lightweight. At the consensus layer, basically you just need to get the block route and then you send it through the engine API.
00:30:51.000 - 00:31:11.770, Speaker A: Cool. And just is the general feeling on the execution layer call that this has a high chance of inclusion, or is this on the contentious zone on the execution or we're unsure.
00:31:20.280 - 00:31:34.910, Speaker F: So it's super valuable for staking pools and many other use cases for the Cl. It's like, I think a pretty lightweight lift. You really just have to send over this route and maybe like one slot number, but that's it.
00:31:36.800 - 00:32:30.060, Speaker A: Cool. I guess assuming there's an appetite for the complexity that this brings in the EL, is anyone strongly against the additional overhead this is going to take to get in in addition to four four four, which is our primary. Okay, cool. Yeah. This is about as simple of an EIP that can exist on the consensus layer. Okay, so let's continue the conversation on the execution layer with respect to this one. And if there's a green light over there, we'll do a sanity check again on this side, but generally a good feeling here.
00:32:30.060 - 00:33:25.440, Speaker A: Daplion did write a consensus layer spec and we associated with a new EIP, EIP 60 914 to reuse indices on a full sweep this. We brought up a call ago and asked if anyone can take additional look in here. It seems like there's some design discussion points that we can still have and should have, but I wanted to get a feel for a lot of this. The intention here is to reduce the unbounded growth of the validator and balances lists. I wanted to get a feel for whether this is urgent, whether this is something we should consider a couple of forks later. Does anybody have strong opinions about if and where this should be placed and when we should take on this complexity? If we do.
00:33:29.360 - 00:33:49.250, Speaker F: I personally would rather see four four four just like shipped ASAP. And it seems like this thing is complex enough that it would delay that. Maybe not, but that's just kind of my feeling. So in that case, I think this is something that's promising and we could keep developing it. But yeah, I don't really see it going to the next hard fork myself.
00:33:51.720 - 00:34:54.878, Speaker A: Yeah, we'll say there were enough discussion points on the original pr that it doesn't feel like we can click the button today, that this would be multiple, at least a couple, if not three, four weeks of discussion and back and forth and then find it to get it to a good place. So under that lens it also, I think that reinforces your opinion. But do others have opinions here? I guess in the abstract, do all of the consensus, their clients think that this or something like this must go in eventually, or is this just a nice to have even in the long term? So by not commenting, I'm just going.
00:34:54.884 - 00:35:04.110, Speaker G: To say that I think we will need something like this, but I sort of feel like maybe not in this current fork.
00:35:09.660 - 00:35:34.124, Speaker A: Okay, so we will continue to refine this and continue to have discussions around it, but no one thinks that this is pressing enough to get into the next work. Correct? Speak now. Okay. Yeah.
00:35:34.162 - 00:35:52.640, Speaker E: I also want to ask here, theoretically it should be possible to get the same gains by simply forgetting about old validators if they haven't been touched for a long time. Right. Is that just way too complicated to implement in practice?
00:35:55.460 - 00:36:09.012, Speaker A: So one issue here is that even if you're fully withdrawn, if you make even a one e deposit, it goes into there and then it would be part of the withdrawal suite again.
00:36:09.146 - 00:36:20.730, Speaker E: But that would be a very forget. Yeah, not fully, I agree, but there's like an ancient database of old validators that you almost never have to touch.
00:36:23.020 - 00:37:11.460, Speaker A: Yeah. And you need to at least know their hub keys or some sort of mapping there for the deposit. Yeah. I think one of the arguments is to potentially trade some consensus complexity for the reduction of client complexity here. There are probably management strategies in terms of caching for state root calculations. There's probably some management strategies in terms of shifting things around in and out of memory if they're old, to keep the active state size or the active validator state size bound. My intuition is the same is that it's probably possible to get the gains through engineering complexity instead of consensus complexity.
00:37:11.460 - 00:37:15.950, Speaker A: But then that has to happen five times.
00:37:18.240 - 00:37:21.310, Speaker E: Well, I mean, the EIP also has to be implemented five.
00:37:22.240 - 00:37:37.010, Speaker A: Right. I guess it's a complexity trade off in where it goes. This feels simpler, but I do not have good eyes on that. But I think that's a very important.
00:37:38.180 - 00:37:57.130, Speaker E: Yeah, I mean, that's what I would like to understand. Why does this feel simpler? Because I don't understand. To me they are very close in complexity, but having less consensus complexity at the same increase in client complexity seems strictly better.
00:38:03.840 - 00:39:12.720, Speaker A: I guess it would depend on the magnitude of complexity if they were equal. Yeah, exactly. I agree. If they're not equal and actually client complexity can lead to consensus failures. For example, if these inactive validators that you kind of keep out of memory and you mess up your pub key hit, and then you make a new validator instead of adding a new deposit, that's a consensus failure. And so by having machinery that you don't even necessarily utilize much, that represents consensus risk as well on the consensus edge cases. And those are even hard to these caches, and I'll abuse that term, they're kind of hard to test in consensus tests, because creating a state that actually would use the historic flows and historic caches and test it in that very stateful manner is not obvious on how to do in our consensus test against the execution machinery.
00:39:12.720 - 00:40:13.922, Speaker A: I can't make a full claim. My intuition is that this is simpler than some of the machinery and less error prone. But I would have to have some engineers speak to anybody. Does anybody have additional discussion points here? Otherwise, I think this is not going to go into Deneb. We'll continue to refine and certainly have to have the conversation on the complexity tradeoff here, but can have that a little bit further down the line. Okay. Another thing that we do not have a spec for, but we would like to, presumably would like to do, was kind of a follow on the historic summaries.
00:40:13.922 - 00:41:06.200, Speaker A: The creation of the new historic summaries was to backfill on a fork boundary, essentially with a static list to have them be complete from genesis. This can happen whenever. The sooner it happens, the sooner we can standardize things like epoch or era file distribution in a simple way, and other things like that. I think Yasik is probably one of the main proponents here and is not here, and nor do we have a spec yet. But I wanted to get a sense of if this is an urgent item. Silence means I do not think it is urgent. Speaking up means I think it's urgent.
00:41:06.200 - 00:41:44.684, Speaker A: Okay, I'm going to circle back with the austake and see if we can actually just get a feature spec up so that we can have the conversation. But this does not seem urgent. Okay. Another item that's sitting in a feature is to not allow slash validators to become a proposer. Essentially, if you're slash, you no longer can attest. You still get put into committees, but you can't attest. But there's a bit of a degenerate flow in that.
00:41:44.684 - 00:42:41.200, Speaker A: If you have a very large slashing, these validators get put into the exit queue, but they're still active and they can still be proposals. So if you had a 50% slashing, you'd actually have a 50% proposal rate. At that point, the get proposer can be modified to not select validators. This is likely a relatively simple change, and it does have a spec. This is something Mikhail would like to at least open up for consideration for Daneb, and if not, to highlight it as something valuable to get into the next work. Sense of urgency in relation to geneb. This is, again, it's like on the simple side of implementation, but it is a protection under a pretty high failure mode.
00:42:41.200 - 00:42:48.740, Speaker A: Any client teams feel like this should be prioritized for the next fork.
00:42:52.660 - 00:43:03.510, Speaker G: This one seems pretty important to me. And yeah, the diff looks pretty big, but the change seems like it should be relatively more simple.
00:43:05.880 - 00:43:59.664, Speaker A: Yeah, let me take a look at it. Why is the diff big? Oh, because it, because getting the proposer within the context of the block, because a proposer could be slashed within the block. You have to get it from the, I think the inserted block header. Yeah. So essentially the call to get proposer index, because this proposer could self slash, or anyone could be slashed during the execution of the block. You can't just repeatedly call get proposer. You need to get it from a more static place, which is latest block header.
00:43:59.664 - 00:44:09.130, Speaker A: And so anytime the proposer is gotten in any of these functions, those functions are copied over and used, you get the proposer from the latest block header instead.
00:44:09.660 - 00:44:13.450, Speaker E: An easy solution is to just forbid self slashing, right?
00:44:14.060 - 00:45:02.200, Speaker A: No, I don't know if it's only self slashing. No, you're right. But this is, I would argue, an easier solution. It's just that it makes the diff look big, because all these functions are copied over to use the new get proposer, and so get latest block proposer index is inserted in each of these functions, and so it's essentially a single line change that's pretty much not changing the functionality of. Yeah, I agree. I think, Sean, the diff looks bigger than the actual because of that, and we might be able to get clever and make the diff look smaller.
00:45:05.060 - 00:45:07.490, Speaker G: Yeah, this one seems worth doing to me.
00:45:14.300 - 00:45:15.640, Speaker A: Any other input?
00:45:19.230 - 00:45:20.300, Speaker D: Yeah, I agree.
00:45:21.070 - 00:45:22.620, Speaker B: I'm in favor of it.
00:45:30.650 - 00:46:40.870, Speaker A: Okay. Mikhail will clean this up and get tests built for it, and maybe keep it in a separate feature branch with tests, and in two weeks time we can do the full thumbs up or thumbs down on this. It's about as simple as you can get, because it doesn't even touch the engine API. And personally, I think we're going to always have a few pretty minor things that we want to get in, and so it's worth getting in a minor thing. Okay, great. Any other items that people wanted to bubble up for consideration under DNEB? There is the Atnet revamp although that can happen independent of DNeB. So we will discuss that a bit further down.
00:46:40.870 - 00:46:48.900, Speaker A: Etan S C signature format. Can you make sure?
00:46:48.970 - 00:47:55.230, Speaker B: I mean, we are still looking for the minimal changes to end up in this SSC world. And right now with block TX type having changed to zero x three, technically we have this problem that there used to be this, I think, starknet thing where transaction type three was used for different kinds of signatures. So having something that makes sure that there can never be a conflict, that the same hash is signed with different meanings depending on the network, could still be something that should go into the net. I mean, it's mostly a conceptual thing, not an engineering thing to develop one of these. I think it was 6493. Yeah, 6493 Eip. Don't need to discuss it right now in detail, but just keep it in mind.
00:47:56.820 - 00:48:01.296, Speaker A: This is for transactions specifically, specifically for.
00:48:01.318 - 00:48:49.440, Speaker B: The blob transaction type. The rest is already fixed, right? I mean, those are signed the same across all the networks. But the block transaction type, because it's based on SSC, means that the chain id is serialized at a different offset. So in theory, if there is an RLP transaction type that serializes the chain id at offset zero, I think, or offset one, and then there is the SSC type that serializes it at a different offset, you could craft a message that is valid in both schemes and maybe trick someone into signing it. I'm not sure if this is possible for the blob transaction type, but it should not even be necessary to think about it with a proper signature scheme.
00:48:52.020 - 00:48:59.208, Speaker A: Does this affect the consensus layer or if this is adopted on the execution layer, it ends up being opaque to the consensus layer.
00:48:59.404 - 00:49:02.180, Speaker B: This is only execution layer.
00:49:03.160 - 00:50:35.788, Speaker A: Okay, so good for us to be informed about, but maybe something that happens on the call next week. Yeah, thanks for bringing that up. Any comments on that before we move on? Okay, anything else? Discussion points for Daneb. Okay, we have one engine API, another engine API point brought up by Mikhail. This is to state payload id should be unique for each payload attributes instance. I believe there was an edge case, triggered an issue that emerged here. Does anybody have the TLDR on? What drove bringing this into the spec? Okay, Mikhail's had this up for a week.
00:50:35.788 - 00:51:43.500, Speaker A: I believe at least some of the parties, relevant parties have taken a look. If you are the engine API guy on your team, please take a look. I think this is likely to be merged before or at the execution air call in one week time. Okay, anything else on Deneb before we move on? Great. I had a placeholder from last week for the consideration for an RPC to validate the beacon header. To help with certain this, we wanted to have a bit more thought and discussion on it between last week, last call, and now. Is there any update on whether we do want that RPC and whether there's a likelihood of that being specked and put in?
00:51:55.560 - 00:52:27.090, Speaker G: I'm in support of it. Yeah, I think on the last call I said I would write up a spec, but I haven't had time yet. I can if other people are similarly in support. It seems like something that at least a few clients will have to implement, and it'd be nice to have it standardized. But the other hand is we're sort of expanding the scope of what is the beacon API? What sort of things do we support?
00:52:29.620 - 00:53:23.800, Speaker A: Yeah, and I think the argument was if this isn't supported then people are going to fork clients to support it. And if one client supports it then it will become a monoculture in some of the building relay. Okay. I don't think there's been any strong arguments against other than the expansion of scope. I would recommend we write the spec and get some final thumbs up from client teams. Thanks Sean. Okay, this is something I've been excited about for a while.
00:53:23.800 - 00:53:48.830, Speaker A: Adrian age, can you speak to PR 3312, the at net revamp, and I guess a quick on what's going on here and how the strategy can be rolled out. Is this something that we need high coordination on, or can it be done iteratively?
00:53:57.580 - 00:53:59.848, Speaker G: Not sure if age is on the call.
00:54:00.014 - 00:54:58.270, Speaker A: I see his name. He has not spoken or unmuted, but I do see his name. Oh no, can't unmute. Okay, so the motivation is right now the at nets field one is honesty based. So you add the number of at nets, random at nets in relation to the number of validators you're running. It also leaks a lot of information. Obviously we leak a lot of information in all sorts of ways, but reducing information leak and not adding additional information leak is valuable important to further secure validating nodes and the assumption that our subnets are probably much higher density than we necessarily need.
00:54:58.270 - 00:56:03.824, Speaker A: What happens here in the atnets revamp is we take the prad and sum that given a constant which is the required number of at nets per full node, gives us as a function of probably the epoch gives us, which at nets a peer should be subscribed to. The nice thing is if they're not, we can call them dishonest and stop listening to them. So we get a little bit of enforcement here where we don't currently, and gives us the ability to kind of tune the density based off of all full nodes. It also allows for every full node, I think like half the DHT right now on the layer does not contribute to at nets. It distributes that a bit more across all of nodes. I need to take a look. I believe that this is specified in a.
00:56:03.824 - 00:56:18.340, Speaker A: Oh, hey, well, Adrian, now that you can unmute, I believe. Can you tell us about how we can roll this out? Is this done in a backwards compatible way? Does this need to be done in a hard fork, et cetera?
00:56:18.760 - 00:56:37.452, Speaker H: Yeah, so in principle we can just do it backwards compatible if everyone agrees that this is something we want to do. So we can just do it in stage releases as well. Like Lighthouse could release it tomorrow if we wanted to. I guess mainly it's because it's not enforceable at the moment. Anyone can kind of subscribe to whatever.
00:56:37.506 - 00:56:38.110, Speaker A: They.
00:56:40.080 - 00:56:50.060, Speaker H: Uh, ideally, yeah, we can just have client teams as they build it, just to slowly release it, and then the network will slowly shift to kind of the new regime.
00:56:50.220 - 00:56:56.450, Speaker A: Would Lighthouse be downscoring peers that don't do this, or would you turn that on later?
00:56:56.900 - 00:57:17.530, Speaker H: Yeah, you would turn that on after a hard fork because then once all the client teams have it and you know that all the nodes are on a particular version after a hard fork, then you can start adding psoring and changing the way you do discovery, but in the meantime you can just kind of ad hoc implement it.
00:57:21.480 - 00:57:40.540, Speaker A: And what's your confidence level and analysis and whatever that this is going to be give us the stability that we need. Did you all end up running the simulations or is it generally pen and paper on density and number of nodes?
00:57:42.400 - 00:58:21.368, Speaker H: Yeah, it's generally pen and paper. So the main factor is the number of nodes, sorry, the number of subnets you subscribe to node. So we're trying to be somewhat conservative by setting it to two. It will mean that client teams are probably going to have to, because it'll be like a state upgrade as people upgrade their nodes. But client teams will probably have to have higher peer counts and probably monitor a little bit closely how they choose their peers to make sure that you have a stable set of subnets, stable set of peers per subnet, but I imagine it's tunable and it's not going.
00:58:21.374 - 00:59:20.600, Speaker A: To destroy the world. Okay. I've generally not heard much dissent on moving forward into this strategy and regime. Is that correct? Is there anyone that feels like we should not be opening this can of worms and shouldn't be doing this. Are there further discussion points that are not being highlighted on that pr? Okay, not that we have the status, but let's call it in last call, and that we're going to merge this by the next consensus layer call unless there are additional concerns in moving forward.
00:59:22.090 - 00:59:34.860, Speaker H: Yeah, it's worth highlighting that it's somewhat controversial as to how it's going to affect the network. So people, I guess doing network stuff on the consensus land, it's worth having a look, if you haven't already, and getting your thoughts in.
00:59:44.700 - 01:00:15.746, Speaker A: Okay, anything else on this one? Cool. Thanks age, for keeping this moving. Okay, we have a discussion point from Guillaume on the verge specification around the usage of a number field JSON engine API. Guillaume.
01:00:15.938 - 01:01:07.890, Speaker I: Yep. Right. Yes. So exactly in the spec for the verge, like when we put the proofs in the blocks, there's basically a structure that is very nested with a lot of arrays, and the same structure is repeated over and over again. And this structure that is repeated is basically just representing a diff. So it says this last byte, which is the suffix of the key, used to be this value before, and now it's this value. And because this type of structure is repeated a lot in the structure, it feels a bit wasteful to encode it as a string.
01:01:07.890 - 01:01:59.800, Speaker I: And from what I understand currently in the CL specs, every number is supposed to be encoded as a hex string. And I understand the origin of this requirement was that there is some Js library that does not handle exactly, some GS library does not handle big numbers, but this is a byte, so it will always be a value between zero and 255. And, I don't know, it felt a bit wasteful. So I wanted to know if there was possibility to change the specs so that only large values are encoded as strings, but smaller values that are always bytes could be encoded as numbers.
01:02:06.950 - 01:02:33.820, Speaker A: I think Mikhail would probably have the most input here. He did say we can use JSON integer type of field implementation. Flexity should be trivial, and I can't remember the exact history of the libraries that were causing the issues here. What are a couple of examples of the number fields that we're putting in hex that are a bit strange right now? Like all of the base fee and that kind of.
01:02:37.490 - 01:03:10.710, Speaker I: Understand that came from a discussion with Mac. My understanding is that everything should be in the current spec. Everything should be encoded as a hex string. And so yeah, that's true of the base C, for example. But yeah, even smaller numbers, should they exist. The block number that could perfectly fit in an integer is also encoded as a hex string.
01:03:19.870 - 01:04:37.916, Speaker A: Is that the case? Because I'm looking at the execution payload, v one under the specs, and I'm seeing things labeled as quantity. What is that type? Do you have the familiarity here? Does anybody have the familiarity with how quantity is encoded? Okay, and that's like a common jSon type that we're leveraging there, not something we made up.
01:04:38.018 - 01:04:39.500, Speaker B: No, it's a string.
01:04:45.650 - 01:05:27.594, Speaker A: Yeah, but I meant the parsing and encoding and definition of that string is a common, like. I don't have a strong opinion here. I would imagine if you make the pr to the engine, API would get a bit more discussion. I guess. Just to point out this API is optimizing a byte or optimizing a number of bytes is probably not going to make or break this, other than just the aesthetic nature of what we want out of it. Right. Because this isn't broadcast to the network.
01:05:27.594 - 01:05:33.134, Speaker A: This isn't like something that we're going to get a lot out of optimizing bytes down.
01:05:33.172 - 01:06:02.422, Speaker I: Right, agreed. Yeah. It's mostly cosmetic. It also depends how the underlying OS, if you start filling buffer sizes, you get more. It's not going to make things way slower for sure, and noticeably slower even. It's just a feeling that this is wasteful. Just to build on, I was looking block number.
01:06:02.422 - 01:06:21.440, Speaker I: So if you say it's a quantity, it is encoded as a string. I just checked. Okay, I'll create the pr then and see if there's some pushback. If no one else has anything to say, that's enough for me. Thanks.
01:06:23.730 - 01:07:19.488, Speaker A: Yeah. Anything else on that? Great. Okay, so that is the end of the agenda. Are there any other discussion points or closing remarks for today? Yeah, and thanks, Mario, for linking directly the encoding. I didn't see that initially. Okay, cool. Good call.
01:07:19.488 - 01:07:31.856, Speaker A: Appreciate you all coming. Good luck on Devnet five and talk to you all very soon. Take care. Thank you. Thank you. Bye.
01:07:32.048 - 01:07:34.032, Speaker F: Thanks. Bye.

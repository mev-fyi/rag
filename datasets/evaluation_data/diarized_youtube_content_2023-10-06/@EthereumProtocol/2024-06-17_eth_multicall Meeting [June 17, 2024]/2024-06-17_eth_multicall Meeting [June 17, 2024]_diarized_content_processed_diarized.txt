00:00:00.480 - 00:00:54.100, Speaker A: Right. So I can give my updates. So, yeah, this week we were looking into the tests with Kilari, like how to first get them working the hive test. And then because we have more details in the block results, we could kind of investigate some things which saw basically Geth was not properly assigning a default chain id, which was causing the transaction hashes to mismatch sometimes. So I fixed that. And I think there was another bug that I also fixed that we found through the tests of.
00:00:58.110 - 00:00:59.462, Speaker B: Sending transactions.
00:00:59.646 - 00:01:15.650, Speaker A: That's true. Yeah. So in validation mode, contracts can now also send, like do simulation. And I think that's it.
00:01:17.750 - 00:02:09.304, Speaker B: Yeah, that's basically what I have been doing as well, except I've been working with Oleg with those same bugs as well with the Nethermind. We are not getting the same transaction has you with the get yet, but Oleg will look into that. But I can imagine it can be something that it's not assumed or not. When you are sending a transact with call, then what transaction is generally assumed since it depends on the input you are setting on which transaction format you should be using. So I can imagine that kind of, that can cause bugs or differences between the clients. And I don't know if we need to do more specking on that, like how the transactions performed on what kind of parameters, but that feels somewhat complex to do. If you're just sending traffic to somewhere.
00:02:09.304 - 00:02:13.740, Speaker B: It can basically be in any transaction format except the blob transaction.
00:02:16.680 - 00:02:26.256, Speaker A: Will we default to UAP 1559? No, unless gas price is explicitly provided. At least that's.
00:02:26.288 - 00:03:03.460, Speaker B: Yeah, but I don't know if Netherland works like that. Yeah, yeah, but there's no one from Nethermind around. So this something maybe good business if at some point. The other thing that was what they were bringing was that what was the, that there would be second EVM and that would also affect multicore. But that's not valid or it's not in yet, but I guess it would be affecting multicol. And then what was the change?
00:03:05.330 - 00:03:06.230, Speaker A: Eof.
00:03:06.930 - 00:03:16.990, Speaker B: Yeah, the Eof thing. But is it, so that's going to be approved. That's going to be the next hard fork. I quite a lot of work.
00:03:17.570 - 00:03:21.030, Speaker A: Yeah, that seemed to be the consensus.
00:03:22.130 - 00:03:26.870, Speaker B: From last outcomes that is going in the next hardwalk.
00:03:28.530 - 00:03:29.034, Speaker A: Oh, really?
00:03:29.082 - 00:03:29.670, Speaker C: No.
00:03:30.380 - 00:03:34.200, Speaker B: So that would be probably this year, maybe still in this year.
00:03:35.540 - 00:03:38.600, Speaker A: I would guess end of this year, early next year.
00:03:39.140 - 00:03:39.920, Speaker D: Yeah.
00:03:43.020 - 00:03:55.680, Speaker A: I mean, we have to investigate and see if it affects what is simulated. I'm not sure. Like, I haven't done a deep dive in Uf yet to really be able to say.
00:03:57.630 - 00:04:07.010, Speaker D: Yeah, I don't think it will. I don't think there's any changes that would affect simulate. Mainly because we just are using the standard EVM for almost everything. Right.
00:04:09.110 - 00:04:13.254, Speaker B: But maybe one more override or something else or some new transaction format or.
00:04:13.262 - 00:04:14.250, Speaker E: That kind of stuff.
00:04:18.470 - 00:04:23.660, Speaker A: Yeah, those are the type of things that I was also thinking of.
00:04:26.720 - 00:04:56.040, Speaker B: I hope we can do it so that if it requires changes that the old method would still work, but maybe it would have some limitation on the new environment and then we would make a second version of the second version would support the new EVM. Yeah, but. Yeah, I'm not really fond of that. We will have two evms. Sounds very complex, but what. What are you gonna do about it?
00:04:58.380 - 00:05:00.320, Speaker A: Go on all cordels and complain?
00:05:03.860 - 00:05:06.240, Speaker D: I've tried that. It doesn't go anywhere.
00:05:10.340 - 00:05:13.960, Speaker B: Have you seen a war against it, but you lost or you just.
00:05:24.750 - 00:05:43.900, Speaker A: Actually. People from get are also hesitant. Were hesitant about. Yeah, so we were kind of pushing back. But seems like everybody else is on board, so it's going through. Hello, Lukash.
00:05:45.480 - 00:05:46.220, Speaker C: Hello.
00:05:48.240 - 00:05:51.340, Speaker B: Is Lucas or not?
00:05:53.960 - 00:05:55.540, Speaker C: I didn't get that. Sorry.
00:05:56.960 - 00:05:58.900, Speaker B: Are you pro or against eff?
00:06:00.720 - 00:06:14.370, Speaker C: Uh, I'm. To be honest, I'm not 100% convinced, but I. I don't. I don't think I have anything major against it. Parts a bit. Complicating the code base.
00:06:17.030 - 00:06:19.526, Speaker D: That's basically everybody's argument against it.
00:06:19.718 - 00:06:20.158, Speaker C: Yeah.
00:06:20.214 - 00:06:27.410, Speaker D: Like, I haven't met anybody that says uf is a bad idea if we were building a new blockchain.
00:06:28.670 - 00:06:42.590, Speaker C: But on the other hand, like, a lot of people are telling me it's a good thing. And they have some arguments that it's hard to me to judge, so. And some of them are. Seems quite smart. So it might be a good idea.
00:06:42.890 - 00:06:44.990, Speaker E: Sorry to complex that it's a good idea.
00:06:46.690 - 00:07:24.220, Speaker D: I think it is, as the change introduced in EOf do make for a better evm. If I was building a blockchain today, I would use everything they suggested because they are smart people doing smart things and they're all good ideas. The problem I have is that as Clary mentioned, maybe before you were here in chat somewhere, you can't get rid of the old EVM. The EVM has to live forever. And so it's not like we're getting rid of some tech debt or anything like that. It's just you're adding more complexity to everything. And having a better evm by itself while still having to maintain the old one is not obviously worth it to me.
00:07:27.230 - 00:07:38.350, Speaker C: No, this is how things kind of work. When you are doing cpu's, you add new instructions, you add new complexity. But X 86 doesn't really remove the old things, right?
00:07:38.390 - 00:08:03.120, Speaker D: So yes, but presumably the new ones give you new functionality. I don't think there's anything in Eof that gives new functionality. Like there are things that would be really useful in terms of like code analysis and whatnot that I think are only really useful if all of the code in EVM follows it. If you only have like half the code on Ethereum following it, then you can't leverage the benefits.
00:08:05.380 - 00:08:14.760, Speaker C: But you can opt out from the old code, right? You can write only new code and called only new, new type contracts and then everything uses this.
00:08:15.380 - 00:08:25.080, Speaker D: I guess maybe gas costs go down, like the new EVM is a little more efficient, perhaps. Maybe that's an argument in terms of what is, what's the benefit to users?
00:08:25.500 - 00:08:35.200, Speaker C: What's the benefit to you? So I don't think this is user facing improvement. It is developer facing improvement, right?
00:08:35.580 - 00:08:38.440, Speaker B: Is it smart contractor, developer facing?
00:08:38.940 - 00:08:43.920, Speaker D: Yeah. Okay, so let's say the smart contract developers are the user in this case. What is the benefit to them?
00:08:46.220 - 00:09:05.512, Speaker C: I think better tooling, definitely cheaper gas is a byproduct, right? It's maybe not, not the main idea, but it is there better security potentially because of better analysis? Don't know.
00:09:05.576 - 00:09:07.140, Speaker D: Okay, those are good arguments.
00:09:07.800 - 00:09:16.730, Speaker C: I'm not a developer, so it's hard to me, I don't develop on chain, right? So much. So I'm not the best person to ask.
00:09:17.310 - 00:09:39.690, Speaker D: I mean, the number one problem with developing on Ethereum right now is it's way too easy to shoot yourself in the foot and introduce security vulnerabilities. So if the EOF contracts actually do have better static analysis capabilities, that is a good thing. It feels to me like you could not change the EVM and just have solidity changes though and achieve the same result. But maybe I'm wrong.
00:09:40.320 - 00:09:44.020, Speaker C: I don't know. I'm not a solid decompiler developer.
00:09:46.160 - 00:09:48.180, Speaker D: What was the question we had for nethermind earlier?
00:09:51.080 - 00:10:09.140, Speaker B: Transaction type. So when you are defining a transaction, then what the transaction type is set, depending on what are the kind of the arguments for the call? Like if you just set two fields, for example, then is it assumed to be type two transaction or type one or what?
00:10:13.600 - 00:10:17.880, Speaker C: Can you, can you ask the question again? I'm trying. Like if you do, if you do.
00:10:17.880 - 00:10:26.984, Speaker D: An ETh call and you only provide the two field, what is the type of that transaction. Is it a type two transaction or a type one or a type legacy?
00:10:27.072 - 00:10:33.500, Speaker C: Ah, the two field. Okay. I don't provide transaction type to ETh call. Okay. That's what's what it defaults to.
00:10:34.770 - 00:10:36.914, Speaker D: It defaults to two, you said?
00:10:37.082 - 00:10:39.070, Speaker C: No, I don't know.
00:10:40.370 - 00:10:54.750, Speaker D: That's the question. What's the default and is there some heuristic you use to try to guess? Let's say access list is included. Do you do type one or do you do type two or let's say the max b for gas. Is it type two or type three.
00:10:57.850 - 00:11:02.540, Speaker B: Is something that potentially could be different between cat and letterman time?
00:11:05.840 - 00:11:08.300, Speaker C: I think it defaults to legacy currently.
00:11:10.520 - 00:11:14.020, Speaker B: That would explain some of the hash differences that we are having.
00:11:16.480 - 00:11:23.656, Speaker D: How hard is it another mind to change it for ETH simulate to default to type two or just change it for both eth call and ETh simulate to default to type two?
00:11:23.688 - 00:11:24.700, Speaker C: Very easy.
00:11:26.240 - 00:11:47.870, Speaker D: I think in general, I think type two is the best default transaction. Blob doesn't make sense for anything that's not a blob transaction. Type one was basically temporary. We don't really need it has no benefit over type two. And legacy I think is just strictly worse. Except for you could do multi chain, but in this case doesn't matter.
00:11:48.770 - 00:11:59.250, Speaker B: Would it be easy for Sinatra fetch the rules on how the type is defined and then share them and then maybe Nethermind could have the same rules if those are good.
00:12:02.710 - 00:12:05.450, Speaker C: Yeah, maybe. I don't know.
00:12:06.030 - 00:12:34.050, Speaker A: Yeah, I think it's basically, I mean we have a logic that tries to detect the type based on the fields. So if there are blobs, then it's a blob transaction. If there is the max v per gas and so on, it's a type two. If there's gas price, it's type one, but it defaults to type two.
00:12:34.750 - 00:12:35.718, Speaker C: Makes sense.
00:12:35.894 - 00:12:38.410, Speaker A: Not available or like blobs are not available.
00:12:41.350 - 00:13:00.460, Speaker C: Makes sense. I'm looking into the code for each simulate. I think it defaults to type two there, but I'm not entirely sure. Okay. Olek is not here today. He's sick.
00:13:03.400 - 00:13:09.620, Speaker B: Yeah, well, I can continue the discussion with Oleg when he gets to start developing that part.
00:13:11.040 - 00:13:18.580, Speaker C: Okay, yeah, I will keep that in mind. We'll ping him too about it. Anything else?
00:13:21.770 - 00:13:32.350, Speaker B: We were discussing about that EOF and how that will affect the each simulate, but Sino didn't know yet. Does it have an impact or not? But that's something that we probably to start discussing at some point.
00:13:34.810 - 00:13:40.070, Speaker C: But I don't think well much. It's just EVM change. Very turtle.
00:13:43.050 - 00:13:44.790, Speaker B: Yeah hopefully it's like that.
00:13:46.500 - 00:13:49.480, Speaker C: It's like adding new bytecode, new opcodes.
00:13:51.580 - 00:13:53.732, Speaker A: Is there no new transaction type?
00:13:53.876 - 00:14:20.050, Speaker C: No, no, it's all about the bytecode changes. I was reviewing that like I don't know, a year ago or something. I don't remember when. So yeah yeah it was very very deeply in the stack and DVM like not sure even if anything above changed.
00:14:20.670 - 00:14:27.270, Speaker A: So how do you deploy an EOf contract? Is it just that it starts with zero?
00:14:27.310 - 00:14:30.010, Speaker C: Yeah there's a new opcode for that I think.
00:14:31.070 - 00:14:37.130, Speaker A: But like you cannot deploy it with a normal transaction that's missing the two fields.
00:14:39.700 - 00:14:59.332, Speaker C: I don't know at the moment. Like I said I haven't look in that for a year or something. I will be doing revisit soon. But when Ayman updates our prs for UF. But I don't remember. I don't think. No, I don't know.
00:14:59.332 - 00:15:00.160, Speaker C: I don't know.
00:15:01.700 - 00:15:04.480, Speaker D: I'm pretty sure it just depends on the first two bytes of the contract.
00:15:08.810 - 00:15:32.320, Speaker B: So it's just the same way deploying that you just remove the two field and then it reads the same bytecode I guess. And I guess then changes some transactions, some transaction will behave differently if you have those two bytes set differently. Do anything else.
00:15:34.260 - 00:15:55.880, Speaker C: Have you read if we are talking about somebody from the rev team posted why EOF is good, your benefits? I can check it, I sent it to the chat.
00:16:01.840 - 00:16:11.340, Speaker B: But yeah I think many, many people agree it's a good idea. But not, not all agree that's a good idea to have both at the same time. That sounds difficult.
00:16:13.520 - 00:16:39.180, Speaker C: Not really. It's like adding some new opcodes, right? It's just adding a bunch of them. So it's not like it doesn't break anything that that was before. Right. It's just like like adding, I don't know, 1010 new opcodes that are somewhat heavy right in the logic. But it doesn't really break anything that's there already.
00:16:40.240 - 00:16:42.620, Speaker B: Well I just made a bot.
00:16:43.160 - 00:16:43.472, Speaker C: Yeah.
00:16:43.496 - 00:16:59.150, Speaker D: So if I understand correctly there are certain contracts that would be valid as pre EOF and are not valid as EOF. And so if those first two bytes are set the EVM rules are different. Like how jumps work and stuff like that actually.
00:16:59.570 - 00:17:01.186, Speaker C: Yes. Yes, yes yes.
00:17:01.338 - 00:17:05.778, Speaker D: So it's not just adding opcodes, it's changing the behavior of some opcodes making.
00:17:05.834 - 00:17:18.202, Speaker C: Some previously I mean, I mean from the node developer. Okay sorry. Didn't, didn't specify from a person who developed virtual machine or ethereum node.
00:17:18.226 - 00:17:18.790, Speaker D: Right.
00:17:19.770 - 00:17:32.670, Speaker C: From how it is executed, yet it's different. Yeah, that's true. That's true. But that's kind of on the compiler side mostly. Right. It's not something that would be visible to users explicitly most of the time.
00:17:33.050 - 00:17:53.140, Speaker D: Yeah. I think the people who are affected by this are solidity developers and whoever's building the VM for each of the clients. So I don't know who on Netherland team builds. Yes, VM, but they'll have to deal with this heavily. But I think you're right. My guess is, is that if you're just building the client itself, not the EVM portion, then it's probably almost. No.
00:17:55.400 - 00:17:57.660, Speaker C: Well, we are building our own EVM.
00:17:59.680 - 00:18:03.660, Speaker D: Right. So I'm just saying like you got. I don't know who on your team works on the evm or if you guys all do.
00:18:05.480 - 00:18:40.910, Speaker C: It's always team effort, right? So I don't want to put anyone, and I think a lot of people are adding, for example, opcodes for different daps. We have it fairly. A lot of people are working, let's say. But we have some specialists. So probably Ayman and Ben are the most specialized at the moment. Ben, maybe more from the performance perspective. Ayman, actually if anyone's interested, is building something that we call Il.
00:18:40.910 - 00:18:59.060, Speaker C: EVM. Il is a.net intermediate language. So.net byte code, you can say. So we are trying to also compile the evm to dotnet code. Like EVM contracts evm bytecode.
00:18:59.060 - 00:19:13.360, Speaker C: And we will be able to do it on the fly, for example. So if we find out that some, something is becoming heavily used, we could potentially even on the fly compile it.
00:19:14.180 - 00:19:17.960, Speaker D: Isn't the problem with that or the challenge with that gas accounting?
00:19:18.940 - 00:19:20.840, Speaker C: No, not really.
00:19:21.300 - 00:19:44.990, Speaker D: How do you do gas accounting? Because if you're compiling. Yeah, but so like a big part of what the EVM does is the gas accounting. Like when each opcode you execute, you have to account for its gas. Whereas if you convert the code to IL and then run it inside the CLR, for example. CLR doesn't keep track of which operations actually.
00:19:45.070 - 00:19:49.850, Speaker C: Yeah. We'll have to emit code that does gets of counting. Right. And then in there.
00:19:50.550 - 00:20:23.510, Speaker D: Yeah, just maybe do like I guess add tracers or something like that. And then just track the CLR tracers or something. It's always been like, I've thought about this in the past, like why build a new EVM? Every time I think about it, it's all like, why not just use the JVM or the CLR or something which already exists seems much better. And the problem is always gas accounting. Like that's always the thing that makes you say, oh, this is why we don't just use existing vm.
00:20:25.610 - 00:20:56.352, Speaker C: I would say. I don't think so. It's just easier to build something. Right. There's a lot of right now experimentation with compiling bytecode and it's a good way of having additional layer and of abstraction. And a lot of EVM opcodes like completely are not easily transferable to single or even multiple instructions easily. So.
00:20:56.352 - 00:21:05.020, Speaker C: So yeah, I would say it's more of abstraction problem. Like the gas accounting is just adding integers to each other, so it's not a big deal.
00:21:08.560 - 00:21:12.420, Speaker D: You're more optimistic than I am. I'm curious to see how it goes though, if you can pull it off.
00:21:13.280 - 00:21:45.260, Speaker C: Yeah, we already have everything, I think every opcode compiling, but we have now a bit of setback because Ayman who was implementing this is also now switching back to U of because he was the one working on U of f most. So it will be probably delayed a bit due to that because we need to make EOf stable first before we go back to that. And we probably would need to add the of to Il EVM. That will take even more time. So. Yeah.
00:21:45.920 - 00:21:49.300, Speaker D: Well, I'm very curious to see you guys succeed at it and be awesome.
00:21:50.600 - 00:21:57.696, Speaker C: Well, I think we will succeed. The question mark is what it will bring and how much optimizations it will.
00:21:57.728 - 00:22:10.432, Speaker D: Bring, how much the CLR has many many more people working on optimizing its performance than Nethermind does. So as great as you guys are, I suspect they will be better at it.
00:22:10.576 - 00:22:45.810, Speaker C: Well, I think the main thing is the branching, right. Because basically when you interpret EvM bytecode you have a big loop that interprets it opcode by opcode. And if you just emit them one by one, then potentially you can have great optimizations on the prefetcher side, et cetera. You eliminate a lot of jumps from your code, which can be the main boost.
00:22:46.160 - 00:22:46.940, Speaker D: Yeah.
00:22:50.080 - 00:22:56.020, Speaker B: We have it working on the most opcodes already, so that. Have you been doing testing on the performance?
00:22:57.080 - 00:23:21.830, Speaker C: So yeah, that's why I was asking for that. But no, we haven't been. I think the part that's currently being finalized is also interoping between the two versions because we don't really want to do compile everything. Right. It doesn't make sense to compile everything.
00:23:22.170 - 00:23:22.954, Speaker D: Why not?
00:23:23.082 - 00:23:46.950, Speaker C: Is it? Yeah, it's quite expensive. It will take a lot of time, it will take a lot of code. So in terms of bytecode, right, we have like what, few gigabytes of code deployed on the chain. So if you compile that and try to load it into memory, right, like would have to unload it, load it, unload it, etcetera. Right.
00:23:48.450 - 00:24:15.236, Speaker D: You could just say save both the so on chain. Currently you have the in storage on disk. You have the evm bytecode. You could have a copy of it. That was the precompiled one. So anytime someone deploys code, you just immediately jit it down into ClRDE Il and then load that off disk instead of loading the evm bytecode off disk.
00:24:15.308 - 00:24:26.560, Speaker C: Like I said. To be honest, it's still a bit early to how it will evolve. But a lot of people are experimenting with this, so we'll see.
00:24:27.180 - 00:24:28.868, Speaker D: Okay, I'll follow along.
00:24:29.044 - 00:24:57.120, Speaker C: Also, ref is experimenting with this. Maybe not even ref, but revm. Who else is experimenting? A lot of other like postmodel tools are experimenting with compilation and native, native code execution. So we'll see how it goes. I think it's pretty doable, right. It's just fairly complicated.
00:24:59.900 - 00:25:12.252, Speaker E: Dosing vector that if you compile everything always, then someone makes some, deploys huge amount of contracts and Netherlands would be just compiling everything, so you probably wouldn't want to compile.
00:25:12.316 - 00:25:12.516, Speaker A: Yeah.
00:25:12.548 - 00:25:41.950, Speaker C: Also there is latency, right. If someone deploys a new contract, we don't want to compile it right away because latency of compiling will be huge. We want to, if we will be ever compiling and we will probably be even live compiling based on some heuristic, you will still want to do it in the background threads in the background, right. Not, maybe even, not even doing actual block execution, but between blocks. Yeah, they're doing it smart way.
00:25:43.050 - 00:25:54.500, Speaker E: Yeah, I think the best way is that you always run the EVM bytecode as it is, and then you have some low priority thread that is compiling them all the time. And then if it's available, the combined version then used it.
00:25:54.610 - 00:26:24.100, Speaker C: Yes, exactly. Something like that. Because we always want the lowest latency on the EVM. Yeah, yeah. There's a lot of, a lot of details and will took us a, you know, more time to, to get there, but a lot of interesting things are coming. I'm also experimenting with parallel execution. I'll give you an update.
00:26:24.100 - 00:27:06.116, Speaker C: For EVM. Yes, for EVM. I have it in my model. So we recently are introduced, or are introducing because the final version is not out yet, that we run transactions in parallel and what we use it, we discard the execution results at all. But we use it to populate a big cache of state, and then when the main thread runs in the transactions, most of the state is already populated. So we have almost, well, most of the state populated. Right.
00:27:06.116 - 00:27:10.880, Speaker C: That's how we achieve our newest performance increases.
00:27:11.740 - 00:27:15.916, Speaker E: How you can pre populate the state if you haven't run the transaction yet?
00:27:16.108 - 00:27:20.600, Speaker C: Well, we run it in parallel, in the background threads.
00:27:21.580 - 00:27:24.920, Speaker E: And you assume that those transactions are not affecting each other?
00:27:25.700 - 00:27:41.960, Speaker C: Well, we not assume they are not affecting each other. We run them on like a copy of the state. Right. Similar, like you do with eth call. Right. You run it on a read only copy of the state, which actually loads from the main state. Right.
00:27:43.120 - 00:27:48.680, Speaker E: But then if one transaction is affecting the other transaction, then you cannot run those transactions in parallel.
00:27:48.840 - 00:28:10.900, Speaker C: Yeah. So it's a. Yes. Yes. So like I said, we discard the effects, the results of the execution. Right. We just populate a big cache that then is being used on the main thread, which again invokes those transactions in order in single thread like, like it was before.
00:28:12.080 - 00:28:17.208, Speaker E: Oh, sorry. So you just get everything in the cache that you need, the calculation or.
00:28:17.224 - 00:28:47.220, Speaker C: You don't know that? We try to, yeah, we try to load as much of the state we need in the parallel and just run it in the single threaded with as much state populated. And we are getting on a very fast machines, around 700 mega gas per second, sustained, because peaks are like, we had a peak of two giga gas, I think, but sustained is around 700 mega gas on a very fast machine.
00:28:47.840 - 00:28:55.408, Speaker E: But I guess you can have transactions that refer the next trans, or previous transactions, and then the cash that they are bringing is kind of completely wrong.
00:28:55.464 - 00:29:03.180, Speaker C: Because that, yeah, yeah, yeah, yeah, exactly. So it's, you know, it's a heuristic, right. You can say, yeah, it's not a guarantee.
00:29:04.680 - 00:29:06.280, Speaker D: You're just trying to warm your cache.
00:29:06.360 - 00:29:07.456, Speaker C: Yes, exactly.
00:29:07.568 - 00:29:14.504, Speaker D: You're trying to spend 30 threads at the same time all warming the correct cache, rather than one thread that's warming the cache and executing at the same time.
00:29:14.592 - 00:29:38.654, Speaker C: Exactly at the moment. But we will be trying to now evaluate if we can use the results of this execution and instead of executing it again, just committing to that state. So we will be now trying to add intelligent transaction collision logic and see if what we should be able to.
00:29:38.702 - 00:29:55.050, Speaker D: So if you keep track of, keep track of the state you loaded in for each transaction, and then when you get to that transaction in the main thread, you check to see if the state that it loaded has been touched by a previous transaction. If not, then you're guaranteed that it will execute the same, right?
00:29:57.810 - 00:30:11.870, Speaker C: Yes, but we want to make it a bit more complex. So we will be trying to evaluate if the transaction needs to be re executed earlier and re executed in parallel again. Right.
00:30:12.250 - 00:30:12.818, Speaker D: Oh, I see.
00:30:12.834 - 00:30:16.550, Speaker C: Okay. Way before the main thread catches up.
00:30:16.850 - 00:30:36.750, Speaker D: So as you're going. So you execute all of them, save the starting state for each, and then in order, you iterate through them and say, okay, this one runs, it touches these states, therefore we keep the next one and keep the next one. And you can save them all and then figure out which ones you need to rerun. And only rerun those.
00:30:37.090 - 00:30:55.740, Speaker C: Yeah, but like even those rerunning can also be done in parallel, right? If we figure it out, potentially, yeah. It's a complicated, it's not that complicated, but it's a, from the code perspective, it's not that simple. A lot of code, etcetera.
00:30:57.200 - 00:31:03.520, Speaker D: Out of curiosity, how do you basically need a ram disk for this thing, for your disk to keep up?
00:31:03.640 - 00:31:25.616, Speaker C: No, no, no. Faster VMV is fine because it's not about throughput, it's about latency. Right. So you can have a lot of parallel NVMe drive access. It's not a big deal. It's just this access will take x amount of milliseconds or nanoseconds. Right.
00:31:25.616 - 00:31:43.610, Speaker C: So if you're doing one, one access or ten times or 100 times the access, it's like the cost is almost the same. So it's actually beneficial of doing this on an NVMe drives, probably. Generally SSD's.
00:31:44.350 - 00:31:49.486, Speaker D: Is this just because nvmes are so fast? Because like we're talking, they are kind.
00:31:49.518 - 00:31:53.702, Speaker C: Of, they support like parallel fetching in some ways. Right.
00:31:53.846 - 00:31:58.598, Speaker D: Let's see. So you're leaning on modern drives having the ability to do high parallelization.
00:31:58.774 - 00:32:00.170, Speaker C: Yes, exactly.
00:32:03.390 - 00:32:12.814, Speaker E: This is something that would be nice to have an id simulator that you could make multiple parallel blocks so that you can simulate a lot of parallel stuff. And those wouldn't affect each other?
00:32:12.942 - 00:32:18.690, Speaker C: Well, parallel blocks or parallel transactions and blocks, I'm not entirely sure. What do you mean?
00:32:19.870 - 00:32:37.020, Speaker E: So that you are creating multiple parents for the first block so that you could simulate multiple stuff that kind of would be conflicting each other, but you could simulate it powerless or it wouldn't affect each other. But that's very same as sending multiple multi core requests.
00:32:37.150 - 00:32:38.260, Speaker A: Yes, exactly.
00:32:38.600 - 00:32:44.208, Speaker E: But I feel that the nodes would optimize that better if you are sending similar transactions.
00:32:44.224 - 00:33:34.400, Speaker C: No, no, not really. It's way easier to just send multiple requests. So right now we are not bringing this, and I doubt we will ever bring this multi threading into RPC calls unless you will explicitly maybe enable it. And it's your private RPC that you want the fastest execution. Because if at any point you have multiple users, you don't want probably one user to consuming too much resources. So if you have any kind of public RPC, you don't want to spin all threads for one user, it's wasteful. You want to have load balanced users.
00:33:35.190 - 00:33:36.010, Speaker E: Yeah.
00:33:39.110 - 00:33:44.730, Speaker C: Yeah. So this is mostly for block processing and potentially block production and nothing else.
00:33:47.110 - 00:33:56.510, Speaker E: Is anyone working on the state rent? I feel that we are all the time making ethereum bigger and bigger, and this is also making that resources and.
00:33:56.670 - 00:34:09.470, Speaker C: No, not at the moment. But I think I will be looking into some ideas of reducing state. I don't remember the state rent. I remember state expiry.
00:34:11.530 - 00:34:19.950, Speaker E: Similar, like, I think blobs are, for example, a good idea because the blobs are expiring and they disappear. But then that's only for the blobs.
00:34:20.530 - 00:34:34.015, Speaker D: Yeah. State, state expiry was the successor to state rent. State rent was deemed too challenging because we didn't start with it. And so we can't get rid of any of the old state where state expiry lets us get rid of the old state, which is really nice.
00:34:34.047 - 00:34:35.463, Speaker C: Ah, okay. Okay.
00:34:35.551 - 00:35:11.558, Speaker D: The problem with state expiry was address space extension. We need bigger addresses, 32 bytes ideally. And we also need address space extension for other reasons, like just the hash collision on 20 bytes is going to get dangerous soon, and so. But address based extension opens massive can of worms in the EVM because addresses are used internally and they're assumed to be 20 bytes. And solidity does some optimizations on how they do that. And so you can sometimes end up with garbage. In the first ten, it's not always zeros or, sorry, in the first twelve, it's always zeros.
00:35:11.558 - 00:35:17.610, Speaker D: And so address based extension was ultimately what blocked that last I checked.
00:35:18.190 - 00:35:19.070, Speaker C: Okay.
00:35:19.230 - 00:35:30.772, Speaker D: I wish someone could solve it. Like, the state expiry, conceptually I think is a great idea. Like everything is great about it. We just needed to make the addresses bigger, and that was where we got stuck. We couldn't make the addresses bigger.
00:35:30.836 - 00:35:41.960, Speaker C: I don't agree that everything is great about state expiry, but it might be the best thing we have. To be honest, I don't like it, but it's like, I don't have any better solution at the moment.
00:35:42.260 - 00:35:43.440, Speaker D: Why don't you like it?
00:35:44.260 - 00:35:54.570, Speaker C: No. Well, it provides pretty crappy user experience, right, because your state is not there, it deletes your account.
00:35:57.030 - 00:36:43.390, Speaker D: Sort of. It makes it so the average RPC node or light node, whatever you want to call it, may not have the old data, but if you do have an account with the old, or an RPC with the old data, then everything will work fine. Your gas costs will be a little higher the first time. When you're restoring old data, it costs quite a bit. From an end user perspective. My hope is that most end users will be communicating. I guess my hope is that we can build something in, so that if a node doesn't have some old data, they can ask a peer to peer network for it, like e wasm or just some other gossip network or something that you can be hooked.
00:36:43.770 - 00:37:07.510, Speaker C: Unless portal network solves the state. Oh yeah, portal can do it, then I'm happy to go with it more. Right. But the last time I talked with portal network guys, they said they might be able to launch the state network on portal by the end of the year, and I don't know how realistic that is.
00:37:09.320 - 00:37:16.936, Speaker D: I would expect next year maybe for the state network. I think this year, I'm hoping they get history this year.
00:37:16.968 - 00:37:19.820, Speaker C: Well, the history is supposedly already working.
00:37:20.400 - 00:37:27.064, Speaker D: Oh sure. But not in production, I'm hoping by the end of the year, I'm hoping it's stable and working well in production.
00:37:27.192 - 00:37:37.540, Speaker C: Yes, yes, yes. For example, so we'll see. We are trying to build something, but we are trying to build too many things at the moment. We'll see how it goes.
00:37:37.950 - 00:37:46.530, Speaker E: Is the expiry so that you had to poke the addresses or the data and then it stays available for like six months or something like that.
00:37:47.110 - 00:37:58.210, Speaker D: Yeah, six how, whatever the epoch size is. But yes, any data that's not touched in a certain amount of time will expire out and then you can bring it back with a proof.
00:37:59.510 - 00:38:03.970, Speaker E: Can you poke it multiple times to make the extent of time or you just need to do it periodically?
00:38:04.640 - 00:38:17.260, Speaker D: Hey, you can just, so you just, every time you touch, if I remember correctly, every time you touch the data, it moves it back to the front of the line basically. So do a write periodically if you want your stuff to survive.
00:38:18.680 - 00:38:19.820, Speaker E: Yeah, okay.
00:38:20.560 - 00:38:45.040, Speaker C: Yeah, I'm like, yeah, we need a good backups, right? I don't like waving, some node will have it, right? Maybe it will, but you know, what if no nodes have it, or what if you don't have access to any node that have it or something, right? It's like this is waving hands.
00:38:46.220 - 00:39:15.848, Speaker D: So I kind of agree with that. There's two reasons that I'm okay with it in this case. One reason is because this is a single honest backer upper requirement. Like, as long as one person in the world actually has all the data, like keeps an archive node running, then the data does exist out there and you can figure out how to get it. So in theory, that's a very low bar. Ethereum already has many people running full archive nodes, which far exceeds what you would need for this. I'm not too worried about everyone losing the data then.
00:39:15.848 - 00:39:29.316, Speaker D: The other aspect is that the problem that we have right now is no one can run a node at all. And if this makes it so people can run nodes, then I'd say that's a win, just in terms of trading one bad thing for a less bad thing.
00:39:29.508 - 00:39:39.400, Speaker C: Well, Micah, while I agree in some way, I think you're too fatalistic in some of your statements, or too absolute. I know a lot of people that run nodes.
00:39:39.780 - 00:39:42.080, Speaker D: Are any of them not core developers?
00:39:43.140 - 00:39:43.920, Speaker C: Yes.
00:39:44.540 - 00:39:54.980, Speaker D: Really? All the on core developers I know no longer run nodes. They used to and they don't anymore. I no longer know any. Anyone that's not a core dev that runs a node anymore. I was the last one and I quit.
00:39:55.140 - 00:39:55.960, Speaker C: Okay.
00:39:57.860 - 00:40:06.932, Speaker D: The reason I quit is because my server provider screwed me and blah, blah. But that was the last one of. In my social circle.
00:40:07.116 - 00:40:27.158, Speaker C: Okay, but it is possible. Yeah. So maybe if you're kind of. If you're wallet would automatically backup your data.
00:40:27.214 - 00:40:28.450, Speaker E: Yes, that makes sense.
00:40:28.950 - 00:41:00.462, Speaker D: I mean, if I was building a new blockchain right now, it would be a ZK blockchain, and storage would actually be. Each user stores their own data and so on. Chain an account just has a hash of the data. And all you have to do is prove that. Any mutations that, like when you update that hash of your user data, all you do is you provide a proof that says, I updated the data that results in this hash. According to the rules of the blockchain, you don't have to even tell anybody what you changed. All you do is you say, oh, my user data changed.
00:41:00.462 - 00:41:34.768, Speaker D: And here's the new hash of my user data. And the change was per the rules. And so in that case, this is literally users store their own data, and you can store it wherever you want. Presumably your wallet has some mechanism for backing it up and encrypting it and putting it on Google Drive or whatever it is. But the idea is the blockchain doesn't store any user data. It just stores a hash of user data and then you can do things like make it so contracts can have per user storage. So tokens, for example, would associate your balance with user accounts instead of having it in a global shared space, as an example.
00:41:34.768 - 00:41:43.760, Speaker D: And so I'm a big fan of users storing their own data. And like you said, for state x free, I think you can do something similar with enough effort and design.
00:41:47.580 - 00:42:00.840, Speaker C: Yeah, that would be kind of thing. Okay. Yeah, we'll take a look at it, but I don't know when. Maybe some, for some time late this year.
00:42:01.440 - 00:42:05.616, Speaker D: I thought Nethermind had like 400 people in the company. Is that no longer the case?
00:42:05.688 - 00:42:09.820, Speaker C: Yes, still is, but 380 are slacking.
00:42:12.120 - 00:42:15.620, Speaker D: Okay, sounds, sounds normal for a company.
00:42:17.120 - 00:42:23.380, Speaker C: I'm joking a bit, but car development is not, not, you know, it's maybe 20 people.
00:42:24.120 - 00:42:24.904, Speaker D: Okay.
00:42:25.032 - 00:42:33.258, Speaker C: And you know, not, not all of them are seniors or anything, so. Yeah, no, that's right.
00:42:33.274 - 00:42:37.530, Speaker D: You guys hired like 200 entry level people. Interns.
00:42:37.570 - 00:42:51.818, Speaker C: Yeah, we do allow a lot of interns, actually. I think it's a very good way of growing the company and everything. So I'm actually all for it.
00:42:51.994 - 00:43:07.110, Speaker D: If you can afford it, I think it's a good idea. It helps people, helps the new people grow, and when they do, they often stay in the company. And then you have someone that you can sometimes get for cheaper long term. But you need to have a good Runway to do that.
00:43:09.770 - 00:43:12.458, Speaker C: Okay. Okay, let's.
00:43:12.634 - 00:43:16.470, Speaker D: We're way off topic for. Sorry.
00:43:18.130 - 00:43:19.870, Speaker C: Yeah, cool. Good start.
00:43:21.420 - 00:43:23.000, Speaker E: I guess we don't have anything else.
00:43:25.100 - 00:43:27.172, Speaker C: Yeah. See you guys.
00:43:27.356 - 00:43:28.100, Speaker E: See ya.
00:43:28.220 - 00:43:28.636, Speaker B: Bye.
00:43:28.708 - 00:43:39.800, Speaker C: Can you, can you write a summary to also for all, like on the chat for the transaction type? I already pinged him about it, but maybe you want to, maybe I missed something.
00:43:40.900 - 00:43:45.660, Speaker E: Yeah, I can see. Not share some code snippet or somewhere where you are making those.
00:43:45.700 - 00:43:51.858, Speaker C: Okay. This is also recorded so we can. Okay, so he can just watch it. Okay, cool.
00:43:51.914 - 00:43:52.550, Speaker D: Yeah.
00:43:53.490 - 00:43:59.482, Speaker E: But I would also like to understand what are those rules? I would guess they are not that complex, but maybe there's something weird.
00:43:59.546 - 00:44:15.958, Speaker C: It should be simple. If there's something about blob, it's a blob transaction. Otherwise, if there's something about otherwise, it's probably eap 1559 transaction, that's probably pretty much it. By default.
00:44:16.054 - 00:44:16.930, Speaker E: Gas price.
00:44:17.550 - 00:44:19.970, Speaker D: If gas price is defined and Max D is not.
00:44:20.270 - 00:44:26.286, Speaker C: Okay, then it's like a sick. Otherwise it's a 1559.
00:44:26.478 - 00:44:32.318, Speaker D: Yeah. Okay, we'll get that and chat for like. Yeah.
00:44:32.454 - 00:44:33.850, Speaker E: Okay, see ya.
00:44:34.430 - 00:44:34.910, Speaker C: See you later.

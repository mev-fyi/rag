00:00:00.970 - 00:00:45.260, Speaker A: All right. Hey everyone, welcome back to the next UF call. For this one we actually wanted to, at least from Ipsilon, wanted to create an implementation readiness matrix. We did create the template for it, but it doesn't really have all the details in it yet. I'm going to share it in the chat. I think it would be good. If we agree that this is like a good approach, then this may be good to keep updated and everybody should feel free to create prs and link to the work or prs they have.
00:00:45.260 - 00:01:07.570, Speaker A: The goal of this would be to judge where the implementations, where the specs and the testing is in terms of readiness. But since we don't have this fully ready for this call, let's just do like a usual rant first and then we can come back to this discussion.
00:01:15.610 - 00:01:17.270, Speaker B: Dragon. Yeah, go ahead, Dragon.
00:01:18.330 - 00:01:22.140, Speaker A: Dragon was so maybe you should just start this time.
00:01:23.470 - 00:01:42.080, Speaker C: I'm perfect. Fine starting, but I don't have a lot to report. I still need to start working on it. I hope that this is going to be the week. The first thing that you need to do is figure out how to integrate new interpreter or new stock table inside Revm and go with that.
00:01:47.810 - 00:01:56.000, Speaker A: Yeah. Let us know if you come across any design blockers while trying to implement it.
00:01:56.450 - 00:01:58.000, Speaker C: Will do. Thank you.
00:01:58.770 - 00:02:01.700, Speaker A: Thanks. Dennis, you want to go next?
00:02:02.150 - 00:02:32.380, Speaker B: Yeah. I've been updating our old big eof into Meg. EOF, the zero based index on our jump B is something that caused us to update a lot of our tests. The addition of the non returning section flag had updated a lot of tests and a lot of unrelated tests because it changes the validity of EOF. Did some validity changes. Everything's live in our mega EOF branch. One thing I think we should add to the readiness matrix is a location of where the current branch is.
00:02:32.380 - 00:03:05.480, Speaker B: It has all these one of the columns. I don't know if that's the mega spec column, but as far as loose ends, we don't have create three and create four updated yet. We don't have exchange in yet. We don't have good tests for dupen swap end. We don't have exchange implemented. I think those are the ones that are missing. So I almost wonder if we should also list the reference tests for where each one of those are for these various spec versions, where those are located as well.
00:03:05.480 - 00:03:26.120, Speaker B: Yeah, I think it's time to start doing readiness matrix so we can plug all the holes and start going down that path. But updating the tests was more the time than updating the code for the changes that went in so far. That's my update.
00:03:27.580 - 00:03:42.880, Speaker A: That sounds promising. Yeah, we can come back to the discussing the matrix, how it should be formatted after the round. All right. Okay. Any implementation updates from Epsilon?
00:03:49.280 - 00:04:14.550, Speaker D: Well, since last week we've merged return data load and finishing up stack validation new algorithm. Now it's also mostly fixing the tests. I was updating state tests that we have for stack validation today and this is almost done. Yeah, I think that's about it.
00:04:20.960 - 00:04:26.700, Speaker A: Sounds good. Charles, do you want to give any updates from Viper?
00:04:33.300 - 00:04:41.650, Speaker E: Pretty much the whole Viper team has been out because of various illnesses or other accidents. So sorry.
00:04:46.070 - 00:04:51.586, Speaker A: I hope you're feeling better now, and the team as well.
00:04:51.768 - 00:04:52.740, Speaker E: Thank you.
00:04:54.590 - 00:05:34.590, Speaker A: All right, we have someone new, meek Saki, sorry if I pronounced it wrongly. Do you want to briefly introduce yourself? All right, let us know in the chat if you want to talk later. No worries. Okay, so that friend was quick. Do we have any brief spec updates from Ipsilon besides the implementation updates?
00:05:39.940 - 00:06:44.810, Speaker F: Some minor fixes to the mega spec went in, but nothing substantial, just some typo level errors fixed. And also we are working on updating the eaps. So the EIP 35 40, the base EOF one is up for reviews. So I encourage everyone to, if you're up for an early review, then just take a look because there's a lot of changes there. And also we're anticipating the new create eap. So a lot of content on that previous AP got removed and I just pushed the PR for the data instruction EIP update, which is much smaller. I think that's it.
00:06:52.610 - 00:07:52.690, Speaker A: All right then, so maybe we could spend a few minutes on just discussing the readiness matrix and what other information we would like to introduce or include in it. I don't think we should spend the call on updating the matrix, but we should spend some time to agree on what we want to record. So maybe just a brief response to Daniel, what you said in the beginning. So I imagine that yes, we do want to link to PRS where there's like a pr outstanding. I was wondering if we should do that. It's a separate list below the table. Or we could also do like footnote style or footnote style links where there's just a number next to the cell, just to not overwhelm belmit with all the data.
00:07:52.690 - 00:07:56.260, Speaker A: So yeah, what kind of feedback do you have there?
00:07:56.630 - 00:09:06.300, Speaker B: So I don't know that we're going to have links to separate PRS. We have a separate mega eof and we would have to rewrite some of our old prs to come up to spec with the new prs, to get a single pr for like saying 4200 or 47 50 because it's already across multiple prs with the big eof and then the changes coming from the mega spec. And also another thing we're doing in basic, we haven't pushed it out to main yet. It's being operated entirely as eof as a whole on a separate branch. So that was my request is that if there is a branch that has the mega implemented that, that's one of the things that's listed with each client. So if you want to test it, new differential testing, you know, which git repo to go to and download and which one has most everything, because some of these items, they interact very much. And so having one branch that has one spec and one EIP and one branch that has another is really difficult for differential testing because you don't know what it's going to look like when they combine and merge together.
00:09:06.300 - 00:09:19.120, Speaker B: So I mean, links to specific prs isn't going to be maybe the create three and create four. We could do that, but for anything that's evolved from big eoF, we won't have that.
00:09:26.420 - 00:10:17.120, Speaker A: Yeah, I think I agree in terms of. Yeah, I would say that the create and the stack instructions are the ones which you could, I mean, it's mostly just the stack instructions, which I think is kind of separate. But then in terms of compiler testing, you do need all of it. And I did imagine that the reason we could track all of these individual ones just to see where the given implementations are. But I do imagine that there's going to be like one mega spec branch in each of these clients, or it's just going to be merged, hopefully under some feature flags.
00:10:18.020 - 00:10:53.544, Speaker B: Yeah, so I think the columns are fine. We won't be able to delink to individual prs in each of the columns. Now for the columns, I think maybe not in this table, maybe in a breakout list below it. I think it would be useful to list where the reference tests and unique test cases for each of these are. So we can use that as our objective to judge. It's like, are we done with 35, 40? Well, it's this list of reference tests, and if you don't pass all of them, you really can't say you're done. So I think a list also pointing to, because some of these are still coming into reference tests and separate prs.
00:10:53.544 - 00:11:23.290, Speaker B: And since these won't interact in quite the same way as implementation, I think separate prs, reference to the prs that are going in for the reference tests I think are fine too, because the tests can be easily severable from the implementation. So I think that the test cases would provide some example, because then, like, say, if Basu's got an issue with one of the create threes, we could put x and do like seven out of 13 to give some indication, some finer grade rather than complete.
00:11:27.010 - 00:11:30.240, Speaker A: But what do you mean by reference test list here?
00:11:31.010 - 00:11:57.960, Speaker B: So, for example, there are tests for the r jump operations. There's actually two kind of tests. There's r jump validation, which is under the EOF test. EIP 4200 is our jumps, I think. And so those are under one directory. But there's also going to be EOF tests, not EOF tests, general state tests that will also exercise our jump. I think those are already in.
00:11:57.960 - 00:12:23.710, Speaker B: So a link to either the PR importing them or a list of which directories you find the test for those in would be what would be useful for those particular tests. So the EOF test, the test validation, and the general state test, the test execution, enumerating those, or the prs containing those I think will be valuable in a separate list below this readiness table.
00:12:24.050 - 00:12:34.660, Speaker A: But are you looking for a grouping and knowing which of these directories belong to which feature set? Or are you just looking for the complete list of tests you need to pass?
00:12:35.270 - 00:12:59.820, Speaker B: So the complete list would be the sum of all of them. But I do think that if we want to break out in columns, we should break out by group. So each column should have a list of here's the tests that constitute readiness for this feature. And it should be as easy as pointing to a single directory because the reference tests are already fairly well split out by directories. You point to a couple of directories and say you can find them here and here.
00:13:04.250 - 00:13:15.770, Speaker A: All right, any feedback or opposing opinion on that? First of all, ask ipsyon, because we are maintaining most of the tests.
00:13:18.290 - 00:13:18.654, Speaker E: Is.
00:13:18.692 - 00:13:24.590, Speaker A: This proposal linking for the specific tests feasible, or are they kind of intermingled?
00:13:27.440 - 00:13:50.950, Speaker D: Yeah, I think it makes sense. They are intermingled in some sense in the same way as implementation. PRS also cannot be one pr for one feature, but there is split to directories currently, and I think it will stay this way. So kind of at least some approximation of splitting the test exists, and I think it makes sense to link them.
00:13:58.220 - 00:14:04.700, Speaker A: All right, any feedback from dragon or charts on tests?
00:14:08.770 - 00:14:12.080, Speaker E: No, not really.
00:14:12.530 - 00:14:22.100, Speaker C: In the end does matter a lot. Some tests are going to overlap, some tests are going to be standalone. What matter is that we have tests that cover everything.
00:14:28.660 - 00:15:04.216, Speaker A: All right. I think the shape of this matrix is good. Then I suppose we will add the links to the tests and then merge it, and then it should be open for everyone to create PRS against. And. Yeah, we definitely ask all of you to create a PR and link or update your specific client or anything else in this. Yeah. Peter, do you have anything on this topic?
00:15:04.248 - 00:15:15.010, Speaker F: Otherwise, I would suggest moving the megaspec from a column to a row, and then we can put tick Marks demonstrating that the Megaspec is actually ready in 100%.
00:15:16.580 - 00:15:19.756, Speaker A: Okay. For each of those. You mean for the aips?
00:15:19.948 - 00:15:30.580, Speaker F: Yeah, we just need to make the Megaspec. Or is the specs. We have the specs row and the Megaspec column. So I would just have the Megaspec row.
00:15:33.320 - 00:15:38.500, Speaker A: Yeah, we can do that. I wasn't decided.
00:15:40.520 - 00:16:01.180, Speaker F: And then an EIp row as well. I don't know, it's maybe a bit silly, but it will demonstrate how ready the eips themselves are in terms of the content. Maybe it's easier if I do a pr or something so that we can see what I'm proposing.
00:16:02.000 - 00:16:05.070, Speaker A: Okay, yeah, we can discuss that.
00:16:05.840 - 00:16:14.620, Speaker F: Also, we should probably have an in progress icon, for example, for Kate, for even one. It is very much in progress.
00:16:18.260 - 00:17:01.324, Speaker A: Yeah, we can do that. Yeah, I mean, we have similar, it a similar icons on the epsilon website for other stuff. So, yeah, we have the work in progress icon there. All right. I think we spent ten minutes on the matrix, so we should be good. All right, so for the next call we should have this matrix ready. And the idea is that based on this matrix, we should be able to judge the progress and which areas we need to focus on in order to finish those areas.
00:17:01.324 - 00:17:50.280, Speaker A: And it should also help us guide some of the conversations we have to make because of that. So I think going forward, the goal would be that coming into the call, we should have, like, an updated version of this matrix to have a conversation starter. Is that okay? Are we able to make updates to this prior to the call? Okay, sounds good. All right, let's move on to spec discussions. Charles already posted a link, I believe, which probably is a spec. Oh, yeah. The variable length encoding.
00:17:50.280 - 00:18:07.260, Speaker A: I feel like the variable lengthen coding is a long discussion. So I will ask if there's any other spec topic we wanted to discuss. Now, we should start with like a shorter one. Anyone has any spec discussion.
00:18:19.220 - 00:18:19.596, Speaker E: Right?
00:18:19.638 - 00:18:22.420, Speaker A: All right then, Charles, floor is yours.
00:18:25.080 - 00:19:42.572, Speaker E: Yeah, I think we already talked about it a few weeks ago, but I just wanted to kind of, I think there were a few kind of minor concerns. There's some open questions, right. The open questions are, I should actually add these to the pr, but what do we do about r jump v? And I think the answer there, the concern is that each entry is a different length, right. And I think the solution there is just to make the length of each entry the same. So if you have like an r jump one, if one of the entries is like one, then you just need to pad it with enough zeros so that it's the same as the maximum length of all the entries in the jump table. And then there was the exchange and swap in. And I think really good benefit of the variable length encoding is that we don't really need to choose or add both of them to the spec.
00:19:42.572 - 00:21:17.728, Speaker E: We can just have a single master swap instruction which does some slightly clever encoding of which items to swap. And I haven't exactly figured that out yet, but I think it's going to end up being similar to that spreadsheet that Dano made very nicely a little while ago, where you just map each natural number to something in the swap triangle. And I did make a little bit of progress after the last call that I was on, which is I added a reference recommendation. And I think there was a bit of concern about speed. And I don't think it's really a big issue because it looks like in general, decoding these variable length quantities is about the same as decoding big ending things. So I think we're okay on that front. And I think there are really a lot of benefits to adopting these variable length encodings because, one, it makes the spec more elegant, in my opinion, and it also makes things a lot more future proof.
00:21:17.728 - 00:22:00.290, Speaker E: So if we want to increase contract size limits or anything like this, let's say we even want to increase them 50%, right? Then init code needs to be increased by 50%, and that's like already over 64 kb. Yeah, that's 72 kb. You need to have jumps which are like larger than two bytes, where the pointers are larger than two bytes. And it's going to be really difficult to do that unless all the pointers are already dynamic length in the spec.
00:22:17.400 - 00:22:22.890, Speaker A: Did you manage to implement some of this in Viper by any chance?
00:22:23.500 - 00:22:32.490, Speaker E: No, we didn't get to that yet, because, yeah, like I said, the whole viper team is out.
00:22:35.440 - 00:23:03.220, Speaker A: Yeah, I think last time the two conversations were, one, should the encoding mostly be for the header versus the instructions? And the second was specifically the RjamPV, where I felt like there was concern. RJMP is already kind of complex. Making it even more complex seemed like a big concern.
00:23:07.880 - 00:23:28.380, Speaker E: Yeah, I mean the, yeah, I mean it's more complication in the encoding, which I personally think is worth it, but I can understand the counterarguments here.
00:23:30.930 - 00:24:43.960, Speaker A: Yeah, probably the, I don't know. So one of the maybe differing views on the implementations come from how you would implement an evm interpreter. I think most of them are kind of like simple and they really go like byte, byte. But you could imagine an implementation where you do load the code and you translate the code into an instruction set specific to your implementation, where you don't actually go byte by byte, but you pre process each of the instructions into whatever format you have. If you have an implementation like this, then the instruction encoding is less of a concern because you're always going to translate it. But the other case where you go byte by byte in the variable length encoding, r jump v, that means that you have to parse the entire encoded instruction every single time, while current version, you can just skip ahead because it's fixed size and you know which point to skip to.
00:24:44.570 - 00:25:16.350, Speaker E: Yeah. So my idea about that was to pad everything. So if everything in the jump table needs two bytes, then you just pad everything to two bytes, because the VLQ encoding allows ambiguity in the length. So if you hit an R jump feed, you need to parse the first entry in the table to see what the variable length size is for all of the entries in the table.
00:25:18.610 - 00:25:21.730, Speaker B: Would that be the size of the table or the number of jump destinations?
00:25:22.150 - 00:25:32.546, Speaker E: The number of. I don't remember off the top of my head what rjump fee does right now.
00:25:32.568 - 00:25:47.754, Speaker B: Rjump fee has the number of jump entries, which, because it's a fixed width, you know, the length of the table. But then we have a variable width size indicator for variable width data, which each entry is. Variable width, I don't see how that can be reasonably done without parsing the entire instruction set.
00:25:47.952 - 00:26:03.142, Speaker E: So like, let's say the jump table has the entries like 12, 56, 64,000 or something. Um, yeah, I think I understand have three bytes.
00:26:03.206 - 00:26:44.460, Speaker G: What cars means by this, but seems doable. Not sure it's worth mostly you need to make sure the encoding of every entry in that table is the same length. And this is possible with this variatic length encoding, which we rather should kind of avoid in other places. But yeah, it is possible to do it this way.
00:26:48.370 - 00:27:24.010, Speaker E: Yeah, and you can make the encoding probably slightly more efficient because you can have some but the encoding would be more complicated. So you say like, okay, every entry in this jump table has like three bytes or something, or every entry has two bytes, and then you can just use a big indian encoding. I think it's okay to allow a bit of complexity in the encoding for r jump v, and you can still get this property that it's one traversible.
00:27:36.640 - 00:28:28.620, Speaker A: Yeah, I think it's technically doable, although many of the, conversely, many of the variable length encodings were aiming to have a canonical encoding, which is usually the shortest form, and this kind of goes against it. Yeah, but as Pavel said, I suppose we would need to have two numbers in the beginning, number of entries and size of entry, because just having the length of the encoding doesn't tell you anything. So you would have to need these two properties in order to decode it in the same manner. We do it right now with the pading.
00:28:30.580 - 00:29:18.220, Speaker G: I mean, you can get the length on the encoding from the first entry. Yeah, I mean, it's not very elegant, but I think technically it's possible. Looks really bad, I think, in terms of elegance, because exactly what we want to avoid in all other places is to avoid the paddock. So we probably, if we go with any kind of periodic encoding, we will just restrict the encoding to be the shortest possible. That simplifies a lot. So validation will check this and explicitly in this jump v, it will be like the opposite rule somehow.
00:29:20.740 - 00:29:54.280, Speaker E: So there's like two options, right? One is variatic, encode everything, but make everything the same length. And then the other is have this little piece of, maybe add another byte to our jump fee, which indicates the length of every entry in the jump table, which is like one, two, or three, basically. And that is probably slightly better size, because variatic encoding everything wastes bits.
00:29:58.320 - 00:30:24.020, Speaker B: What this demolishes is good chunked execution with the current fixed width bytes. If you do a vertical chunked execution, you don't have to bring the entire table in. If there's 32 bit runs or 32 byte runs or 31 byte runs that aren't used by the jump table in execution, we could skip those. With the variatic encoding, we'd have to have the entire instruction. In a chunked execution.
00:30:25.400 - 00:30:30.836, Speaker E: You don't need to pull the entire jump table into memory, but you would.
00:30:30.858 - 00:30:48.090, Speaker B: Need to have it in the witness because you can't infer the location just by doing some index math. You'd have to decode the whole table and know where each one starts to know what the correct execution number for it is.
00:30:48.700 - 00:30:55.420, Speaker E: Yeah, so that's what we're discussing. So like for our jump b, we have some special encoding which ensures that every entry in the jump table is the same length.
00:30:56.240 - 00:30:58.300, Speaker B: Then why do variatic encoding?
00:30:59.380 - 00:31:03.760, Speaker E: So that we can have larger pointers.
00:31:07.060 - 00:31:10.640, Speaker B: I would much rather see in our jump v four as a variatic encoding.
00:31:14.970 - 00:31:21.720, Speaker E: And also in the common cases, I think it's going to reduce code size.
00:31:29.600 - 00:31:59.530, Speaker C: Just want to add in the future. It seems that workload and witnesses and everything around that there is possibility that only chunks of the bytecode is going to be sent or read or used by light client, whatever they are, status client. So with encoding in place, is that possible or not possible? Basically in the middle of the bytecode, use that code, whatever that is.
00:32:06.490 - 00:32:12.360, Speaker G: Are you asking like in EOF in general or specifically to this chump c.
00:32:14.250 - 00:32:55.430, Speaker C: Specifically for the workload? Because with the vertical at least what I followed, bytecode basically bytecode is chunked in 256 like bits. And idea for the future is for witness to load only the chunks it needs. But if we encode data and need full container to decode it, that will make loading data. We would need to load a lot more data and put into the witness.
00:32:57.370 - 00:33:12.780, Speaker G: Yeah, okay. I don't think any of these prohibits using only chunks. So in general there's no issue with this. I think.
00:33:16.520 - 00:33:34.680, Speaker C: Okay, maybe question is, if we have arbitrary code, whatever it is, could we decode it or you're talking about different decoding. What I understood is like you are talking about decoding of the bytecode.
00:33:39.900 - 00:33:47.390, Speaker G: So generally you don't need the whole Eof to execute it, you need whole Eof to validate that.
00:33:49.680 - 00:33:50.044, Speaker A: One.
00:33:50.082 - 00:34:12.020, Speaker G: It's valid. You can execute individual chunks and whatever you go to what chunk you go to, you know it's valid. So you can just execute there when you go and that's how it works. So you don't need anything else. Precisely. The bytes you're going to be executing.
00:34:13.640 - 00:34:21.416, Speaker B: You'll also need the link tables of this code sections for call fs. So there is part of the header we'll need, but we won't need the types data.
00:34:21.598 - 00:34:39.010, Speaker G: Yeah, there are some details, kind of not straightforward, and probably this jump fee, it's something we have to take a look at, but I don't see currently anything breaks it very much.
00:34:41.780 - 00:36:25.710, Speaker E: Yeah, I think we just make a slight change to the normalization rule, which is that normally we pick the smallest encoding for a number, smallest width encoding for a number. But for our jump b we pick the length for all the entries in the jump table to be the same. To analyze this, by the way, I think that the most common use case for r jump fee is actually for selector tables. Like every single contract is going to have r jump fee for the selector table, basically. And selector tables more or less jump randomly into the code. So they're going to be large pointers. Um, and also the number of entries in the jump table is probably going to be around 80 for large contracts, but it could be larger if we increase contract size.
00:36:30.180 - 00:37:29.490, Speaker A: I think getting actual statistics on the selector use case, I think, would be fairly straightforward even getting it from either scan. But if you look at intuitively, at some of the big ercs, so like ERC 20, or maybe the more complex stuff like 4626 and any of the nfts, like 721. So each of those have maybe an order of like ten endpoints. And then contracts have their own management endpoints, et cetera. So maybe a good guess would be on the range of like 25, 30 entries on average is what contracts would have. So I think that's maybe like a good number to go with how many entries you would have in a selector. Maybe like 25.
00:37:30.600 - 00:37:40.020, Speaker E: Yeah, and I think contracts max out around 80 methods. That's just how many you can fit into the spurious dragon.
00:37:44.460 - 00:37:54.970, Speaker A: Yeah. So if you look at the 25 entries, how many bytes are we going to save with the variable length encoding in the selector case?
00:38:01.910 - 00:39:05.090, Speaker E: I think it depends on. Yeah, that's interesting. So there's like actually two things that we're considering. One is saving byte space and the other is forward compatibility. And if contracts get above 64, don't know. It just seems like a y, two k kind of scenario where this is going to be a blocker on increasing the code size limit, and we can fix it now. So, but for the code size thing, the best encoding, I think, well, the smallest encoding obviously, is where all the pointers are variable sized.
00:39:05.090 - 00:39:39.520, Speaker E: And we don't have this restriction that all the entries are the same length. But I guess with vertical there is this, like, I don't know. Right. So Dana was saying we need to do these 32 byte chunks, and I guess for these common sized selector tables between 30 and 80 methods, we would need two to eight chunks. Right.
00:39:41.730 - 00:40:33.818, Speaker A: So let's just make like a pragmatic calculation. You said maybe 80 endpoints. I don't think many contracts have 80 endpoints, but let's say we have 80 endpoints in the current encoding. That's 160 bytes for all the 80 jump locations. Now, if you somehow manage to put all the 80 into being fitting one byte encoding well in variable and case that's a seven bit, that means that you would have to have it in the first 128 bytes, all of them. And if you do, then likely they're going to jump further because there's not much left in the remaining like 40 bytes to do anything. But in that case, all of them would be one byte locations instead of two byte locations.
00:40:33.818 - 00:41:04.950, Speaker A: You're saving a total of 80 bytes of code sized. This tells me that optimizing for code size in RJMP with the variable length encoding is probably something not true. It's not worth it.
00:41:09.180 - 00:41:13.080, Speaker E: Yeah, so we should optimize for forward compatibility is my conclusion.
00:41:19.660 - 00:41:52.550, Speaker A: For that. Actually, there's this idea, I mean, this idea, one of the reasons EUF was kind of pushed back, this idea that the code, if there's no code in introspection, that you could practically translate the code. In that sense, even with the fixed size RJMP, we have complete forward compatibility because we could translate UF to a new encoding if we wanted.
00:41:56.040 - 00:42:00.070, Speaker E: Yes, that's true, but I'm wondering how practical that would actually be.
00:42:06.770 - 00:42:38.680, Speaker A: Yeah, maybe just one more comment. I may sound skeptical, but the more interesting part of this conversation to me would be what if we can get rid of the code size limit we have, and in that case will we extend beyond the 64k limit? That would be a more interesting medium term conversation to be had.
00:42:40.170 - 00:43:02.670, Speaker E: I don't know if runtime code would extend beyond 64 kb anytime soon, because that's like what, 2.5 times the current size, but I think a knit code is bumping up against that pretty soon. Pavel?
00:43:04.610 - 00:43:58.050, Speaker G: Yeah, I think I would suggest into this specific length encoding discussion to split this into smaller groups. I think we started with the most complicated one, which is jumps. I don't really see how much the benefit, the static jumps actually, except for the consistency. What I mean, provided we apply this veratic encoding, someone else maybe it's also worth to apply it to new jumps. But I would actually split this and maybe find the reason it makes sense for jumps, and maybe find the reason it makes sense for other places separately.
00:44:00.710 - 00:44:20.390, Speaker E: Yeah, well, I think there are actually no objections so far to using this encoding in the headers, and pretty much the only discussions have been really about jumps and basically the new instructions with immediate jumps and swaps.
00:44:20.810 - 00:44:43.914, Speaker B: The same problem with jumps also exists in the code section size header. We're already parsing it already. My main objection is not on the merits, but it's on the schedule. If we go to variatic. I don't think we're going to make eof this year. So I think this discussion is happening too late in the process. We're talking about trying to get a readiness together and trying to get this thing out the door.
00:44:43.914 - 00:44:58.580, Speaker B: And such a fundamental change is basically going to say let's not launch this year. So my objection to this is not on the merits, it's on the practicality. We're letting perfect be the enemy of better and we need better right now more than we need.
00:45:03.740 - 00:45:10.300, Speaker E: Mean. I think what I've heard from the Ipson team is that it's not that difficult of a change to implement.
00:45:12.320 - 00:45:16.770, Speaker B: As an implementer that has a lot of things on my plate. It's going to push it out of this year.
00:45:39.480 - 00:45:55.480, Speaker E: Yeah, I don't know. I mean, I've been suggesting this for quite, I think maybe over a year now and the feedback I've consistently gotten is that it's too late in the timeline. Maybe it's always too late in the timeline.
00:46:08.460 - 00:47:13.100, Speaker A: But there's always a struggle getting anything accepted by all cordevs. But now I think the stage and the potential we are in is much higher than ever before. And so the kind of late argument does apply. I mean, just like Dano said, on the merit side, even in the initial design we did have very brilliant encoding. And yeah, I would like to have it, but it just feels like without having actual numbers, the risk seems to be high. Just doing this calculation on the argent V itself, I think the size savings is not really an argument we can make in the header. I think there's a much higher chance that the savings would be more significant.
00:47:13.100 - 00:47:40.900, Speaker A: Which leads me to think that the instruction, variable length instruction encoding is something we probably don't want to pursue considering ketter changes, I think we are generally more open about. But given know, if one client like Basu is not able to implement any such changes, then I think it's definitely off the table.
00:47:47.430 - 00:48:06.760, Speaker E: Yeah, I mean, about the code size thing, I just want to point out that we've only discussed it in one place and I think in general it would save more kind of small things that add up.
00:48:08.730 - 00:48:20.410, Speaker A: Yeah, I think the case where it saves is short helper functions. Right. Because that's the only case you're going to have short jumps.
00:48:21.070 - 00:48:23.370, Speaker E: There's a lot of short jumps.
00:48:25.810 - 00:48:37.170, Speaker A: Yeah. It would be really beneficial to have some actual numbers. Right. That's the piece we are struggling with, getting numbers from compilers.
00:48:42.850 - 00:49:08.680, Speaker E: I think that's a fairly simple calculation, but yeah, I think the importance is actually more about forwards compatibility and it's also nice to have space savings and I can compute that for jumps after this call.
00:49:10.810 - 00:50:03.800, Speaker A: Yeah, I think that would be awesome. We are getting too close to the end and I did want to discuss one more piece, which is besides the readiness matrix, I think it would be nice to have one or two goals for each week and one of the goals we can focus on and make sure that there's progress made on those. Is there any goal we could put out for next week? One or two goals to reach, and I think these have to be specific. It's not like go update the specs or whatever. Does this sound like an idea we could go with? Is there some certain goals we could target for next week?
00:50:07.450 - 00:50:36.900, Speaker B: I like that idea. I mean, maybe we make a particular EIP, the focus of making sure everyone passes all the reference tests and proposed reference tests that fill holes. Validation is another category. I mean reference tests for execution and validation to make sure that we're all up to date and we feel that the reference tests have enough coverage. So I like that idea and I think it would work best if we focused on a particular category, like the jumps or the functions or create.
00:50:44.880 - 00:51:11.110, Speaker A: Yeah. Since we don't have nethermind on the call, and Dragan, you're still early in the process, I suppose you don't have any feedback on that, at least for the next. Exactly, yeah. But for the next week, I suppose this discussion is now between Italian and Besu. Yeah. What do you think? Is this a good idea?
00:51:13.320 - 00:52:12.010, Speaker B: Yeah, it's a good idea. I recently committed all the, I ran all the EOF tests, which are validation tests and the reference tests, and I just last night got all those up to passing. They were generated, whether or not they pass or fail was generated by EVM one's current implementation. But I think that's probably a good place to start, is just container validation that gets also code validation and stack validation of all the various items. One thing I don't think we have implemented is the proposed change for the code validation, the forward only references, and the accommodations we were doing for variable height stacks for things like reverts. So maybe that's what we should focus on next week is have tests ready and implementations ready for that particular change in the validation algorithm. Because I'm fairly certain the reference tests don't touch that.
00:52:21.370 - 00:52:29.400, Speaker A: Andre, Peter, Pavel, anyone else for Epsilon? Are we okay focusing on that?
00:52:31.610 - 00:53:10.610, Speaker F: I would like to see the eips update progressing. We could have the 35, 40 and maybe the create tip ready somewhat at least so that these are not so horribly outdated and then the rest probably will be smudged. The stack validation is also a big one I think. But apart from that, I guess the rest of the 80s are not that huge to update and then we would be in a better shape I guess. I don't know. That sounds reasonable.
00:53:14.120 - 00:53:24.230, Speaker A: Yeah. I mean how about focusing on the validation tests and the IPS? Everything is looking at the same thing.
00:53:29.260 - 00:53:31.530, Speaker F: Can you repeat? I didn't understand.
00:53:31.980 - 00:53:37.800, Speaker A: Yeah. So how about focusing on the validation related AIP changes and validation related tests.
00:53:39.820 - 00:53:42.924, Speaker F: This code and stack validation ones, right?
00:53:43.042 - 00:53:43.710, Speaker A: Yeah.
00:53:50.070 - 00:54:11.740, Speaker F: That'S what I as in focus more than on the create and container format once. I think the create one is also very important because this is like a new piece and has not been accounted for at all.
00:54:13.390 - 00:54:19.770, Speaker A: Yeah. Even in the readiness matrix to create this kind of like an app layer.
00:54:21.650 - 00:54:23.390, Speaker F: It leaves a bad impression.
00:54:24.450 - 00:55:06.564, Speaker A: Yeah. So we don't need to do like full project management here, just hooking back to the goal. So I think what we should try then is at least some people from ipsilon focus on the validation testing and Dyno as well and then maybe the goal would we need to set a know where do we want to get with this next week. So I guess ideally maybe Besu passing more of the validation related tests could be a goal. Yeah.
00:55:06.602 - 00:55:42.450, Speaker B: I can work on enumerating the tests on that readiness sheet too as to which ones are there and which ones are get basis update on those and then have EVM ones as well because where there's disagreement is probably where obviously one of them is not implementing the spec right. And I just need to figure out which one goes with the spec and which one doesn't because I don't think we want to get in the situation that they had on the consensus layer where gets implemented it wrong and everyone aligned with Geth just because it's geth. So I think we really need to have the, we need to change the spec in advance of everyone just aligning with the first implementer to get it done.
00:56:00.950 - 00:56:01.954, Speaker E: All right.
00:56:02.152 - 00:56:50.908, Speaker A: I think nobody is really objecting so we should try this out and yeah, we can evaluate on the next call. All right, let's get this readiness matrix updated by then and hopefully we make good progress on the validation related test. And yeah, let's try to get the creation the ips because that's like one of the blockers for the readiness matrix as well. We are also a the time. So any last comments from anyone before we conclude? All right, and thank you all. Have a nice day and see you next week.
00:56:51.074 - 00:56:51.788, Speaker E: Thanks, everybody.
00:56:51.874 - 00:56:52.252, Speaker F: Thank you.
00:56:52.306 - 00:56:53.020, Speaker C: Bye.
00:56:55.040 - 00:56:55.800, Speaker B: Thanks. Bye.

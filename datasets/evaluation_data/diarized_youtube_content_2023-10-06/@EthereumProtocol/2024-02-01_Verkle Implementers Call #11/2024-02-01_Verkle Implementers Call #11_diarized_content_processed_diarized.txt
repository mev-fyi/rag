00:00:06.670 - 00:01:07.430, Speaker A: All right, welcome to vertical implementers, call number eleven. I have shared the agenda in the chat. This is issue nine four one in the PM repo, starting off with client team updates. Would anyone like to kick things off? Yeah, I can. Go ahead. So for the Nimbus client we have been working on the virtual trail library and finally it's been ready for the past few days and the testing has been completed. We are computing the root commitment correctly and from this week we have started to look into the integration of it into the eth one client and we are talking with the person who was mainly developing the database layer.
00:01:07.430 - 00:01:34.344, Speaker A: So yeah, we don't have any perfect estimate till now. Maybe after tomorrow's call we can give an estimate till when? We are looking forward to having it fully integrated. And alongside that we are also working on few optimizations and writing the statelessness part. Go.
00:01:34.382 - 00:02:21.144, Speaker B: Next, we did some improvement on the bezunative side so we can generate the state root of the genesis block more faster. Before I think it was 15 second and now it's less than 1 second. So we still have to do some optimization, but it's clearly better. So normally we are able to import the block twelve. We did the modification for the gas cost. I'm not totally sure because the guy who is working on that is sick today. So I don't have the final result, but it seems that the last news I had, he was able to import the block twelve.
00:02:21.144 - 00:02:39.330, Speaker B: So we did some fix. We are also working on the gas cost in order to import more block and still working on performance, et cetera. So we are moving forward. No huge problem for the moment.
00:02:42.340 - 00:03:36.672, Speaker A: Yeah. Let me add on the business side where we're going as well. For now we are not able to produce new. So as Kareem said, we're going to be able to follow the chain, the testnet. But for block production we'll need a little bit more of the crypto part ready and optimization so that we have some ideas already of known optimizations that are what we get inspired by what people did on guess. So we have identified three or four potential optimizations to improve speed. And so this is the things we're going to do next.
00:03:36.672 - 00:04:48.746, Speaker A: In the next month on ethereum GS side we are working on house cleaning work, basically getting our current stuff reviewed and merged. And we are waiting for Constantin three launch so that we can try stateless executions on that. And in the meantime we are also looking at how to incorporate the proving library to verify, prestate and post state. Yeah, on the guest side? Well, I've been working on the shadow fork with Perry and yeah, there are still some issues. I mean it's a bit frustrating because there's always something going all right. But yeah, we still made a lot of progress. It's just that we're not quite there yet, but most of the work has been on maintaining or more exactly updating the code base for the testnet.
00:04:48.746 - 00:05:29.082, Speaker A: We had some merge issues that we discovered this morning so we need to fix them. But once this is done we'll be able to restart the testnet, which is quite important because there were some bugs that effectively are blocking other clients from syncing it. So yeah, we're going to fix this. So Paris said he would be able to relaunch it this week. So it's just up to us to fix all the merge issues we found otherwise. Ignacio has been nice enough to work on the replay. We have this replay benchmark that was broken after a rebase so he started tackling it.
00:05:29.082 - 00:06:24.426, Speaker A: But yeah, it's still work in progress as far as I can tell. But it's quite useful because we want to be able to answer some questions that have been asked from us like what is the average proof size and things like this. Otherwise I've done a lot of work on updating the specs so we will be discussing some of those updates today and I implemented EIP 29 35. I also have a couple of questions regarding this that I want to discuss here if time permits. And more importantly we also worked on a new proposal for the transition. So it's actually not the conversion, but I will explain all that later during the call. And right for this week we have a presentation on ACD next Thursday, so we're going to tackle that.
00:06:24.426 - 00:07:35.736, Speaker A: We're going to try to rebase on top of the latest guest to be able to support Cancun in the future and basically build everything we can to get as many information from the replay as soon as it's fixed. And yeah, that's pretty much it. I think I can go next. So from Nethermine's side I implemented the blockchain CIP that we discussed last implementers call, but game pointed out some issues when we implemented for Mainnet. But I think the current implementation works for costly, except for that I was just trying to look for performance improvements in the cryptography library and on the client side while generating proofs and basically verifying stateless commitments. That's it for everyone. We are waiting for the fixes that Geom is proposing for get and I've also tried to generate some pre images through the plane state database in Aragon.
00:07:35.736 - 00:09:03.040, Speaker A: It comes out to around 37gb. So we had a discussion, me and Jiome and Andrew from our team, which might seem like a bit longer than expected. We'll resume development on Eric on after get merges the fixes. Anyone else with updates? I can add a quick something on the Ethereum JS side. So we have kind of a smaller sister repo for WASM typescript implementation of the Bergolf cryptography. So we will be re implementing Pederson hash in typescript using the underlying rust compile to WaSm that kev has built. So it used to be that the rust had Pedersen hash directly.
00:09:03.040 - 00:10:00.580, Speaker A: That library has been changed slightly, so that's it's a bit lower level. So we're going to re implement the higher level Pederson hash implementation in typescript natively. Yeah, I've made a few changes to the rust vertical and they've been upstreamed to the Bezu native library. There are a couple changes that I think that we'd want to make, like renaming Pedison hash to be called maybe gettree key hash. I noticed the GEF library uses from bytes. I think we want to just get rid of big indian sort of from the API anywhere. It's a bit confusing because in some places we use little endion, in others we use big indian, and mostly just trying to get test vectors across the stack.
00:10:00.580 - 00:11:14.320, Speaker A: Okay, moving on to agenda item two, Testnet relaunch Guillaume, I think you had some thoughts you wanted to start with there. Yeah, maybe just the announcement. So we're going to relaunch the testnet like I mentioned during my update. I just wanted to specify so all the prs or all the changes we discussed last time are in, or should be in as soon as the merge issues are fixed. There's just a couple of things I wanted to mention for the update, except I can't read what I've wrote anymore. Oh yeah, the gas model is the same, except that we change this the same as the current state of calsthenin, except that we are going to not charge gas for the to and from. But that's the next topic.
00:11:14.320 - 00:12:30.840, Speaker A: We also not include the coinbase to the witness if it's zero, like if there are no withdrawals happening, or if there are no fees, like if the block is empty, that it's really empty, you don't have an unchanging coinbase in the block proof or in the block witness. And yeah, my interpretation of EIP 29 35 is active and it's a bit different from the one described. Well, the one that is described in the spec was created for something before mean. I assume tanish also had to get a bit creative for this. In my case at least there will be two blocks added to the witness, or two locations added to the witness. The first one is the location of the block you are interested in, and also the location of the block that is 256 blocks ahead of the current block. And that is necessary because, at least necessary in the code base because of the way the fork is activated.
00:12:30.840 - 00:13:39.120, Speaker A: And in fact I was going to cover that later in an agenda item, but I guess we can skip the agenda item in that case. Yeah. So because the fork is activated by a block number, sorry, by a block time and no longer a block number like what is described in the EIP, we need to find if the block that was 256 values before was also part of that fork. And one way to figure it out without having to read every single block from the blockchain, which is not possible in stateless, is to check if the number for that block, the hash for that block, sorry. Is present in the contract. Because if it's in the contract storage, then that means at that time that block was activated, and therefore that fork was activated. And therefore we are in the situation where we should read the block hash from the storage.
00:13:39.120 - 00:14:27.196, Speaker A: I think there's a link in the page, sorry, there's a link on the vertical implementers call eleven issue. It's the last link actually, if you want to go look at the discussion how I updated, or at least how I ask questions. Yeah, j eleven. Yeah. So basically, if to access the block with regard to whatever the index is, and it does not exist itself in the tree, then that is the direct way to know whether the fork was activated at those particular blocks before or not. Right. Right.
00:14:27.196 - 00:14:55.850, Speaker A: So the idea is exactly, if you find something that means the block was activated 256 blocks before. Sorry. The fork was activated 256 blocks before. Sorry. And as a result, you know that you're in a case where you should read the contract. If not, that means, well, in statelessness that means you have a problem. But yeah, if not, you need to be stateful basically.
00:14:55.850 - 00:16:15.040, Speaker A: But you basically don't need to check for 256, because if, for example, at the index that you are looking for, you don't have the key present, the data present, then you already know that basically at that particular index, x blocks before the contract was not activated. No, because the thing activates 256 blocks after the fork. So you need to know, what was the state of the block 256 blocks ago? Danesh. So one other question I have is right now, we are planning to enable this EIP with the vocal EIP also. So for the first 256 blocks, we'll not have stateless clients if we go with this approach, right? Yeah, that is correct. Although actually the way it's implemented in my code is just that. It will detect that the fork is not activated, but the result will be zero anyway.
00:16:15.040 - 00:17:03.370, Speaker A: Yeah, so that's actually now, come to think of it, this is incorrect. So yeah, it will not be active for the first 250 blocks. You're right. So that's another issue. So can we do something where for the fourth block we add all the last 256 blocked hashes and then from then we always will always have the last 256 block hashes from the block itself. We just have to do once on the four blocks that you add all the last one but 256 blocks, and then we can just move on as it's already been active and we'll not have to wait for another six blocks. I would say that's a bit techy because you have yet another situation where in some case something is enabled and in another case something is not.
00:17:03.370 - 00:17:32.298, Speaker A: But if there's no better option, I guess we should do that. Yeah, okay. I guess we should think that deeper might not be active on Calstonin at first, but yeah, we should fix that for sure. You're right. But on caution, I don't think so. We'll need it anyways because we are starting from genesis. Yeah, but exactly.
00:17:32.298 - 00:18:10.354, Speaker A: It still activates. It will try to read a contract that's empty. So we will say no, my 256th ancestor is missing, so I cannot use the old system. So I have to read the blockchain, which for a state full client is not a problem, but for a stateless client is going to be a problem. But in question, we'll not have any scenario, right? Where we will not have the 256 ancestor, sorry. On cost. In we'll not have this issue where we don't have the block in the database.
00:18:10.354 - 00:18:41.406, Speaker A: Right? Because we are starting from Genesis. So for every block we are adding the block hash in the state. So we don't need to do this on cost. Right. But my method of checking your 256th ancestor is not going to work in this case. So it will tell me you're missing this block. So you need to go the old method, basically no, but that's what I'm saying.
00:18:41.406 - 00:19:13.820, Speaker A: On Costne, there is no old method because from genesis itself, everything is in state. Right. So there will never be a scenario where we'll have to switch to the old method. Okay, I don't really want to hog the entire conversation on this. I think we understand the problem. Let's take it offline, if you don't mind. Yeah, but yeah, that was it for the testnet relaunch, so hopefully this week.
00:19:13.820 - 00:19:49.960, Speaker A: Cool. So next up, we have a topic on gas accounting schedule changes. Guillaume, I think you had some thoughts there as well. Also, just in the interest of time, maybe we want to try to get through this one. And agenda item four quickly to get to the transition discussion. So actually, in my view, this is the most important mean. They're all important, to be honest.
00:19:49.960 - 00:20:53.370, Speaker A: But my question is, I see Vitalik's not here, but Dankroid is. I'd like to revisit the concept of the gas costs, because I think we're at a point where there's some, at least on my end, there's some confusion. And basically, what was the point of creating, for example, something like fill cost or all those extra witness cost? My understanding was that it was to limit the growth of the block size, which makes sense. But then we have things like fill cost, which is charge every time the leaf is initialized. What witness cost first. So witness cost is everything that is charged for adding values to the witness. For example, it's defined in the AIP, they're called witness underscore.
00:20:53.370 - 00:21:29.190, Speaker A: Well, there are several of them. Witness chunk cost, witness. Try to remember the exact names, but. Exactly. Witness underscore branch, underscore cost, and witness underscore chunk underscore cost. And then there's an extra cost for the right. When you create a fill cost, which is the cost you charge, and we're not charging it on Calstinin, but it's in the spec, so it should be added eventually.
00:21:29.190 - 00:22:25.792, Speaker A: It's like every time we add a new leaf, we have to charge this cost, but that doesn't grow the witness. So that's what I'm trying to understand. Why are we charging this is the goal, to limit the state growth for the block producers? Yeah, trying to make sense, really. Or at least revisit, because I don't think my understanding of those gas costs is really clear. I see. Okay, I'm looking at this now with this branch cost, witness chunk cost, but it says it's only charged once per. Right.
00:22:25.792 - 00:23:03.844, Speaker A: If address sub key is not an access substrate. So it's only charged once. Yes, it's charged upon access. Absolutely. But the fill cost, which is in EIP 47 62. At least the way I understand the spec is that if the leaf was zero or none, actually it's called like looking for the exact line. If, ah, additionally, yeah, if there was no value stored at address sub key leaf key, I.
00:23:03.844 - 00:24:30.282, Speaker A: E. The state held none at that position charge chunk fill cost. So this is the part that is confusing. Well, if there's, it's, yeah, for reference it's line 248246, sorry, 2246 it. Right, I guess this is the cost for adding an additional subtree, right, that's chunkful cost. Actually, it just says leaf. If there was no value stored at address sub key leaf key.
00:24:30.282 - 00:25:44.090, Speaker A: So it's not about adding the subtree, it's about adding a single value. It, okay, so it's adding on the, all right, so it's basically just a cost for storing a new value. Right? In that case, sorry, I didn't quite get that, it's the cost for storing a new, I see, but, so because the EIP doesn't really say the cost for s store disappears. Actually I was double checking and I don't see being removed, so that's where I'm remove the following gas cost gas cost eip two thousand two hundred s store gas cost. Right, that's true. There's that for s load gas. Right, except for s load gas and s load gas.
00:25:44.090 - 00:26:01.810, Speaker A: Right. Change for no change reset. Okay, right, so that's fair. No, it's actually deactivated. That's true. Okay, so that makes sense. And then there's the whole question.
00:26:01.810 - 00:27:17.466, Speaker A: Okay, so this is still not great, because that chunk edit cost means that in order to charge the cost, you need to go and read the tree. And this means that, at least in the way I've seen Verco implemented in geth and other clients, the tree gets updated at the end, so we don't really hit the tree before, during EVM execution. And I don't see a way to implement this truncated cost without actually needing to read the tree to see if that value exists. Right? Yeah, but you do need to read the tree. I mean, when you have a read, for example, you do need to know anyway what the value is to perform the EVM execution, right? Yeah, that's true. You need to know what the value is, but you don't need to go through the tree. But yeah, I guess that means the same here.
00:27:17.466 - 00:27:48.742, Speaker A: You only need to know whether the value is none. Yeah, that's true. Okay, yeah, you're right. It might be possible to do it, so I would have to think about it. Okay. And the second thing I wanted to talk about in this cost thing is I just created an EIP, actually, not an EIP, an update to the EIP. Where is it here.
00:27:48.742 - 00:28:52.566, Speaker A: So it's pull request 81 38. And it's about adding, not charging the two and the from. So this is what I mentioned about the Kelstin and relaunch. So the problem with this approach is that when we start a transaction, we still charge 21,000 gas. And it feels that in the current implementation, at least on top of that, we need to add the witness cost. But then what is the meaning of this 21,000 gas if we have to add the witness cost on top of that? My understanding, or at least I think there should be a new interpretation of this 21,000 to say that covers for adding the to and from addresses to the witness. And the reason for this is because, well, first it breaks a lot of tooling, it makes simple transactions way more expensive in terms of gas.
00:28:52.566 - 00:29:18.398, Speaker A: And I for one, cannot justify this increase in costs. Yeah, no, I think I agree with that. I think that should be part of it. Previously we also didn't charge for that assess store. So, yeah, I agree. I think we should just say that the base cost includes those like three or four reads and writes. Okay, excellent.
00:29:18.398 - 00:30:15.940, Speaker A: And the next question is basically the same thing for call, which is the same thing, like when you do a call, yes, you add the code and that should be paid for, especially since you removed the 200 byte per contract code cost. Actually that's not the same thing, but yes, it still makes sense. But at the same time, you still pay a stiff upfront gas cost and to load the account, the target account. So my advice, or my suggestion would be to do exactly the same thing, not include the two like the target of the call it or, sorry, include them in the witness, of course, but not charge for it. Do the same thing for a call, basically. Right, yeah. I mean, the difference is going to be quite small, right.
00:30:15.940 - 00:30:35.020, Speaker A: Because it depends which code you're loading. Right. The code could be somewhere in the middle, it couldn't be there. So it might not be in the same subtree. Exactly. Right. Interesting.
00:30:35.020 - 00:31:12.198, Speaker A: Yeah. Right. What's the cost of a call at the moment? I don't quite remember, but it's more than the witness cost for sure. Okay, then I think that's fine. Yeah. In that case, I think it. Okay.
00:31:12.198 - 00:31:55.250, Speaker A: Yeah, I have this pr that I need to complete with the call cost and verify that everything matches. And then I will share it with everybody to make sure that everybody agrees. And if that's the case, then we'll merge it. Cool, thank you. Yeah, that's all for me. Okay, Guillaume, do you want to keep going with the next agenda item? The account header question? The account header question? Sorry, I don't quite remember what we're talking about. Oh yeah, good point.
00:31:55.250 - 00:32:33.870, Speaker A: Yes. Right. So in the spec, yeah, I should look for the spec. Which one is it? Okay, yeah, sorry, wrong window. But in the spec it says that the first 64 slots of an account are going to be in the account header group or the, I don't know how to call it the header group. Right. This is the formula that calculates it.
00:32:33.870 - 00:33:44.150, Speaker A: Let me share my screen again. Actually that's the formula. And basically what happened is that if it's below 64, then it is stored in the header group and if not it's stored in the main storage. But here the offset is not like 64 is not subtracted to the storage key. So that means the first 64 slots of the first, of the second, of the second group or the first non header group are actually unreachable. And I'm fine with that because that makes things way easier to debug when you're aware of this fact. I just want to know that everybody agrees and this is intended basically that was the Internet purposes of this approach.
00:33:44.150 - 00:34:19.058, Speaker A: What do you mean by unreachable? Right, so you see that function get tree for storage slot. Here it gets the address, right? And it gets the storage key, which is just the slot number and this value code offset minus header. Storage offset. That's 64. So if your storage key is in the first 64 slots, it will go in the header offset. So you will just add header offset, which is 64 to the storage key. So that's a value between 64 and 128.
00:34:19.058 - 00:35:06.894, Speaker A: But if it's above, so it's like index 64 and up. It just gets added to this value and this value. So that means if, for example, you're the 65th slot, so index 64, you will be at index 64 in the group that in the first non header group. So that means the first 64 slots are unreachable in that group. You're talking about the actual storage layout rather than. The EVM doesn't know anything about this. Right? The EVM doesn't know anything about it.
00:35:06.894 - 00:35:21.320, Speaker A: It's just the, you could subtract header storage offices here. Basically. That's the question. If you want. We can, yeah. Should we? That's a different question. But we can, yeah.
00:35:21.320 - 00:36:26.292, Speaker A: Interesting. Okay. If we actually like now looking at this, can this overflow. What if storage key is two to the two, five, six minus one, can this overflow? I would have to double check in the code, but I'm pretty sure not because then. Right, because we only take the 31st. Actually, when we get storage key, we get the 31st bytes because the last byte is stored somewhere else. It's this line.
00:36:26.292 - 00:37:12.870, Speaker A: Basically, we do the math in such a way, like, we delayed the cast to 256 so that we never have this problem. This is how we fix it. So. No, I see. Okay. So my suggestion would be to leave it as it is. Just make sure it's documented, because it is quite nice to debug, you know, exactly.
00:37:12.870 - 00:38:09.528, Speaker A: When you look at the witness, you have a correspondence. It's just that it might be confusing. So that's why it would have to be documented, but just wanted to make sure there's no reason to fix it. In a way, the only drawback is that if you store stuff in storage slots 65, 66, there's like, a branch in the tree that is not really, like, 50% billable in a way. I'm not sure if that's a huge problem, but for the gas cost of storing stuff in that branch is actually more expensive because you can only store half of the data that you expect to store. Something like that. But I don't know if this is, like, a big problem or not really.
00:38:09.528 - 00:38:56.292, Speaker A: And also, if we shift everything by 64, the storage slots will be kind of analyzed, corresponding to the place in the tree. I don't know if that will be a problem, but a benefit of how things work now is that everything is aligned. So if you look at the storage slot number, it is kind of aligned to the 256 group in the tree. I don't have a strong opinion. Just, like, mentioning those facts. Oliver. Sorry, I didn't quite catch.
00:38:56.292 - 00:39:36.980, Speaker A: Why could it not overflow? Because, you see, like, the address that is highlighted on my screen, it's a division by 256. So you're doing one byte arithmetic in a 32 byte word, so you're fine. Okay. Got it. Nasio is right that this might have a gas impact. I still think we should leave it as let's. Okay.
00:39:36.980 - 00:40:18.384, Speaker A: My suggestion is that we leave it as is right now. And if, as it always will, the question surfaces again. We can make a decision with better information, because, honestly, it can go either way. So I'm all for not changing it. Cool, thanks. Okay, so next up, the transition simplification proposal from you. Guillaume, right? Yeah.
00:40:18.384 - 00:41:19.552, Speaker A: So actually, before that, I hope we still have time but I wanted to maybe ask the rest people, because we didn't give them any voice last time. Are you aware of how the proposed overlay transition works? And do you have any comments on that? We are aware. Initially we thought that reads would also transition into the vertical tree, which was like something we discussed internally and we had a lot of issues with because of the way our node is assigned. It would be a mess. But I understand after we talked that that is no longer something that is part of the overlay transition method. Right. When you read things from the Merkel Patricia tree, it isn't automatically transitioned to the vocal tree.
00:41:19.552 - 00:42:07.060, Speaker A: It's only like the fixed increment using the iterator and then writes that go into the virtual tree. Yeah, exactly. After that it seems a lot simpler. So I don't actually think we have any issues with the current proposal. Yeah, it seems doable from a first glance. I've been reading some implementations like I've been skimming over Geth to try and answer some of the questions I had, and it seems pretty reasonable from what I've seen. Cool.
00:42:07.060 - 00:43:07.000, Speaker A: Well, that's good to know. So yeah, if you have any realization later. Yeah, we'd love to hear from that, I think. Erigan, I mean, I talked to them as well, but some Nat, do you have any comment as well, or are we still at the point when we discussed last time? No, I don't have any specific comments. Okay, cool. So then I can share my screen again. It's screen sharing heavy today, and I would like to propose a simplification for this overlay transition, or at least not the transition itself, but how we approach the delivering of vertical trees in mainnet.
00:43:07.000 - 00:43:49.136, Speaker A: And this is something I did some time ago to explain to my colleagues how the vertical transition works. Sorry, the overlay transition works. So you have the blockchain here you have the state of the MPT, and you have the vertical tree. And so the MPT is frozen, so it remains the same. As time progresses and the Veracle, more and more things get written into it. And at the block finalization, the internal data of the MPT gets deleted because you no longer need it really, except for sync, but other methods can be used. And then going on to the next slide.
00:43:49.136 - 00:44:55.284, Speaker A: So I'm just copying the last state of the previous slide. So the data has been deleted, you have an iterator that goes over the leaves of the MPT and just starts copying them. So at the first block a gets copied, and then the second block b gets copied and so on. And so on. And, well, it goes on until the whole iterator has been, all the leaves have been covered, sweeped by the iterator, and then you just delete the data and you have vertical tree that is converted. Now the proposal, the new proposal, because this whole conversion is risky and complex and, well, difficult to make work. As I discovered, the suggestion would be to have a first fork where we just implement the part on the first slide.
00:44:55.284 - 00:45:49.672, Speaker A: So we just start with a fresh tree, but we keep the MPT in the background, and that part where the internal data is deleted still remains. So once the fork block has finalized, you can delete the internal data, sorry, the internal nodes of the Merkle Patricia tree, but you remain indefinitely in that intermediate space where you have two trees. So why do I suggest this? Well, there are several reasons. One of them, so I summarize, well, there's some reasons not to do it. First, that means you cannot really have proofs in blocks. So that means we delay statelessness. So that's clearly a minus, or at least more exactly, we delay in protocol statelessness.
00:45:49.672 - 00:46:55.244, Speaker A: You could still work on having stateless clients that get their proofs somewhere else, and it annihilates all those fancy synchronization methods that especially Tanish worked on. So that's not great. But at the same time, these are the parts of Verco that are going to take time to implement and are going to delay vertical. And meanwhile, while we try to get everything right, the MPT keeps growing. So that's why I propose to just do the first part and focus on that. The advantage is that all the clients more or less have the code for that. I mean, they would need to create that same layer that currently exists in geth, where you have the ability to read first from the vertical tree and then from the MPT.
00:46:55.244 - 00:47:56.992, Speaker A: So there's still some code to be added, but the snapsync will still work. You would need to develop, simply update snapsync to also handle vertical proof. So it's not like we're not doing any proof, but it's still simpler. And the biggest advantage I see is that at least we stop the growth of the MPT. So while we figure all the fine details of the overlay transition or any other transition, because then maybe the state expiry becomes the best method after all. But yeah, while this happens, we stop the growth of the MPT, which is the biggest problem, and then we can already delete some of the data. Maybe the sync of the MPT can be left to EIP 44, which is also an EIP asking for attention.
00:47:56.992 - 00:49:26.370, Speaker A: So maybe it's not a bad idea to do it right after that first vertical fork and then we can still work on out of protocol statelessness. And one thing I wanted to ask, jumping back on that gas question, if we do not create a witness, I guess there's no need to create. I'd love to hear if I'm wrong, but my understanding is that if we don't add the witnesses immediately, we don't need the gas cost right off the bat to change the gas cost. So that would give more support for vertical, because some feedback that has been given to me was that changing the gas cost is what's going to provide the biggest pushback. So at least we get some of the benefits without having the, we get some of the benefits of statelessness without having to justify every single gas increase. And the other advantage is because we don't put the proofs in blocks, we don't have to bother the consensus layer to forward those block proofs for us. So, yeah, that's basically the proposal in the issue, like the PM issue.
00:49:26.370 - 00:49:55.044, Speaker A: There's a link to the proposal draft that I have here. Let me share it again. Yeah, it's right here. Exactly. But you should have access to it so you can comment and. Yeah, I see some questions. Oh, it's from Han.
00:49:55.044 - 00:50:41.400, Speaker A: How does this new overlay method give an immediate use case to EIP 44? Well, EIP 44 is about deleting the history and presumably recovering it. So that could actually be a portal network thing. I'm saying four fourth. But let's say it opens some interest towards those issues, those eips and those concepts that propose to deliver historical state over different channels than the usual sync. That's what I meant. But yeah, getting back to the EIP, there's a simple description of it, so you can read it and everybody should be able to comment. So.
00:50:41.400 - 00:51:14.744, Speaker A: Yeah, please do. Yeah, I think that's it. So if you have questions, I'm happy to answer them. But, yeah, that's pretty much everything I wanted to say. I think there's a question from Oliver in the chat too. Yeah. How will this affect l two? That requires state proofs from l one? It's basically the same thing as anything that would need get proof during the transition.
00:51:14.744 - 00:52:40.942, Speaker A: Because even if we did the overlay conversion for a limited amount of time, like, let's say it lasts two weeks or three weeks or whatever, during those three weeks you need to be able to provide two proofs. So the idea would be that you provide two sets of proofs, but only if you need to access historical state. If you don't, then only the vertical proof is enough. Any other thoughts on this proposal? Are people generally in favor? Seems like perhaps any concerns, other cons? But then how long do we wait to actually enable the gas costs, then enable the proofs and then we do the transition? Yeah, that is the question. Probably a year, probably two years, depends. We're going to have to fight to put that in. But the thing is, if we don't get in right now, I would say it's going to get much harder to handle the conversion.
00:52:40.942 - 00:53:33.846, Speaker A: So that's why I would say it doesn't really matter in this respect. Of course it does matter because you still need to be able to deliver the full product. But yeah, because of this need. All right, because one thing I didn't specify is that because this proposed change is much simpler, we could have other eips activated at the same time, namely everything that is in Prague. So we could shoot for Prague. Yes, that would delay Prague by maybe six months, but at least it would be there and the MPT state would stop growing. So yeah, I agree it's hand wavy, but what I expect is when a lot of core developers, I.
00:53:33.846 - 00:54:30.550, Speaker A: E the guest team, are going to look closer at the whole conversion, there's going to be a lot of pushback that's going to delay everything. So I would rather have this conversation after the mpts started growing. That's really the core idea behind this. Like, would it be too bad if we added, okay, I understand the conversion part is bad because that will take time, testing will take time and it will delay by a lot. But can we not just add gas costs and witnesses? Because I think adding gas costs and witnesses kind of then provides us with almost all the benefits of stateless clients. Because right now without that, without witnesses, we don't get, I think, any benefits of statelessness right now. We'll have to query third party for proof.
00:54:30.550 - 00:55:12.934, Speaker A: This way you can just download the MPT. And I'm assuming that without internal nodes and without all the other things, just the state would be a bit smaller. So if someone just downloads the MPT and they have the witnesses in the block, then they can act as a stateless line. So I have to disagree on a couple of points. But overall I agree that, yes, it would be a good idea. I just think it's also going to make things a bit more complicated and potentially cause this proposal to be pushed back to the next fork and then the next fork and then the next fork. But could we add the gas costs? Sure.
00:55:12.934 - 00:55:52.110, Speaker A: Could we add the witnesses? I guess, like I said, I think it's going to increase the proposal. There was something you said I disagreed on, I'm trying to remember, but it was basically you said you have to get proofs from a third party. I don't quite understand that part, because you would just need to. I mean, if you need proofs. Yeah, okay. You would get them indeed, from some kind of relayer, but that's what you would do in a stateless context as well. So.
00:55:52.110 - 00:56:35.086, Speaker A: Yeah, I'm not sure I understand that point. So what I'm trying to say is, right now, if we add witness is any client will just receive a block, and then they can verify the block with the data that we have already provided inside the block. If we don't add witnesses, and the client would have to query some other node or a third party service to get the proof. And using those proof, then the client will be able to verify the block. Right, but currently the proofs are not. Sorry, I'm looking for my word, the proofs are not part of the block. Right.
00:56:35.086 - 00:57:05.774, Speaker A: They're just riding along, they're not hashed in. So they could be. It's pretty much the same problem, unless I miss your point. Okay, but we are still receiving the proof with the blocks. Right? Okay. I think it's just a matter of just one other step. But I think I'll prefer having, if it does not delay vocal by too much.
00:57:05.774 - 00:57:38.534, Speaker A: Because if we don't add proofs, then we'll have to work on the healing part of vocal sync. If we add proofs, we can spend less time on working on the healing part. So that can be one trade off. But yeah, if this gas cost and witnesses delay this by a lot, then probably we can not do that in one mean. Yeah, you raised a good point. Sorry, go ahead, Denkra. I mean, I have a couple of comments on this.
00:57:38.534 - 00:58:48.640, Speaker A: I think the first one is, I feel like it's very unlikely to have that people will agree to a fork that leaves it in an immediate state that has to be fixed in the future. And the second is that I see a problem. Yeah, I don't really know if it's worth it saying that we would delay, because basically the full worker tree stuff has to be implemented. So I'm not sure if six months is even accurate. It might even be more for electra. But also, if it's such a long delay, is that trade off worth it? Because that also delays the full vocal transition implementation itself, again, so I kind of don't see it as being worthy pushing for this. Well, just to answer some of the points, yes, it will have a huge impact because the discussion about the conversion is what's going to take most of the time.
00:58:48.640 - 00:59:33.162, Speaker A: I mean, I can already tell this is exactly what I'm spending my time doing. When I mentioned that to the guest team. Yeah, it's true that most of it would be there, but the one thing, and that's what I was going to answer. Tanish, actually, if you enable, like, sync is the other big question. Not putting the proofs in the blocks would guarantee that no one tries to solve sync right off the bat. But more exactly, it's okay if people want to get sync to work. It's just delaying the fork to figure out some very smart kind of sync when snap sync already works.
00:59:33.162 - 00:59:56.878, Speaker A: Basically, this thing still needs sync. Right. Like the new tree that you're creating also needs to be able to be synced. Yes. Right. So sync still has to be figured out. But so it's just about adapting the existing snap sync to return vertical proofs.
00:59:56.878 - 01:00:50.166, Speaker A: It's not about reconstructing the tree and statelessly executing it because that is going to set. I mean, Tanishka, I believe that we had this discussion like one and a half years ago or so with a lot of people from the guest team where they were very concerned about snapsync working with. They were concerned about it. Yeah. But the problem being that in Virgo trees, all the accounts are spread evenly across the whole tree, and so you would get a lot more dirty trees and potentially never finish something. Was it the argument? I'm trying to remember. Okay, we're over time.
01:00:50.166 - 01:02:10.670, Speaker A: I can ping them for that and get back to you on that on the channel. Chugan. Yeah, I just want to say that skipping transition seems like skipping few steps, and it probably would best be included inside the workload. If you skip that transition and leave like, two branches that ask the question how the steps thing is going to work, how much data is going to be bigger, and how basically when are we going to do the cleanup. So what I would like to say is it would be cleaner and simpler for the long run to do transition when the worker happens. Yeah, but that's actually just changing the order of something because you need to figure that out no matter what. So, yeah, I don't think that's a good argument because whether you do it before the first fork or after the first fork, you will have to figure the transition out.
01:02:10.670 - 01:02:47.580, Speaker A: So yeah, the problem, the crux of the argument is the state keeps growing and we have to stop that. Yeah, but your argument of not finding solution before implementing something, it's not the greatest. There are solutions. Sorry too. There are solutions, they need to be implemented basically. Yeah, of course. But your solution basically to not do transition or just delay it in this sense.
01:02:47.580 - 01:03:38.300, Speaker A: Sorry, I missed that, I didn't quite understand. Basically what you're proposing is to delay transition. But if we already have solution that we can implement and basically work on, it should be best bet possible to do it right away with vertical transition. Because if you delay that for months, years, it will basically increase the likelihood that somebody is going to do something bad in that transition time. While if you have transition for two weeks, it becomes a lot easier, time frame is a lot smaller and potential problem can be a lot less. Yeah, I agree. But that's precisely why stopping the growth of the state matters, because then we make sure the transition is not longer than two weeks.
01:03:38.300 - 01:04:29.340, Speaker A: Even if these three or four weeks, one month, it's not comparable with year, like six months. Do you have numbers on state growth? Is this your intuition right now or do we have hard numbers that say right now it's possible and in one year it isn't? Right. It's not like a clear cut thing, but currently. So my numbers date from middle of last year. But the estimate like just continuing extrapolating would be the state growth was going to be 1 billion leaves middle of 2024. That's not relevant. What I'm asking is how many percent per year is it? 10% per year? 20% per year.
01:04:29.340 - 01:04:42.000, Speaker A: So currently it's 800. So that would be 25%. Yeah. 25% per year. Yeah. Okay. So one year extra gives us 25% extra state.
01:04:42.000 - 01:05:04.774, Speaker A: Right. I think that doesn't sound like this makes an argument that's a super urgent. Just stopping it. Yeah. If it takes two years, like some people are claiming to get everything right. Yeah. It's going to start having an impact because that's 50%.
01:05:04.774 - 01:05:33.630, Speaker A: Right. But also this EIP will also delay it. Sure. Okay. So then it's three weeks instead of two. But in order to, I think you will not make a convincing argument on ACD, say, telling everyone, hey, let's do this, we will be in this weird intermediate state after this hard fork, but we really need to urgently do this. I don't see that argument being very strong right now, if you see what I mean.
01:05:33.630 - 01:06:22.218, Speaker A: It's just like dealing with an extra 50% does feel possible. It doesn't feel like, oh, that's suddenly going to make it impossible. Yes, I agree that it's getting harder and harder. So that's an argument of doing full vertical, like earlier, but it doesn't feel like an argument that we need to pull the emergency brake, which is kind of what this proposal feels like. And I would definitely say that work is priority. So we should have some timeline in year and a half maybe, to include it. Yeah, I think it will also be hard to just.
01:06:22.218 - 01:06:58.814, Speaker A: I think unless we have the complete story about vertical, including transition and everything figured out, it will be hard to convince anyone of starting to do some partial transition to it. Right. So there is. I insist we do have a full vision of the transition. We're just offering to split it. Just a little argument here. One thing that it blocks us also from doing is actually changing anything about how we actually do our hashing and so on.
01:06:58.814 - 01:08:12.206, Speaker A: Like the discussion that we had. Oh, how do we actually work with all of these 64 bits? Do we actually shift to make everything aligned? Do we actually want to split our tree into multiple kind of domains? I think we had a discussion with Ignacio last year that maybe we want to sort of defend against these attacks where somebody makes a popular attack deep down the tree, doing a lot of stuff. It sort of would basically force us to make certain decisions that we have already made, but it would basically make it nigh impossible to actually change certain decisions that we have made for the tree layout. And that's another cost, actually, that we should actually consider that right now. We could basically say, oh, we actually do minor changes to these kind of things relatively cheaply, and we wouldn't be able to do that later. Okay, well, I think since we're over, if no one's opposed, maybe we can continue this on the next call and offline. Guillaume, what do you think about that? Yeah, absolutely.
01:08:12.206 - 01:08:30.466, Speaker A: Thank you for feedback. I'll keep thinking about it. Let's talk about it on the next call. Or not, if it doesn't make sense after all. Thanks. Yeah, we can keep the conversation going offline as well, of course. Okay, awesome.
01:08:30.466 - 01:08:40.086, Speaker A: Thank you, everyone, and thanks for staying a little bit over. We will see you next time. Thanks. Bye. Thanks, everyone. Bye.

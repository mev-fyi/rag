00:01:08.170 - 00:01:58.430, Speaker A: We are live. Welcome everyone to Acde one seven nine. We have a lot of stuff today, hopefully we can get through it. But first we'll talk about Denkun, obviously go back on how Gordy went, and then there's a couple small changes or at least items to discuss. So some things around JSON RPC, some things around 4788. Shall we link the new Cl release PR and then making sure we're still on the same page about timing for next test nets. Once we have that done, then there's a bunch of discussion around the next Prague Electra.
00:01:58.430 - 00:02:50.718, Speaker A: There were a couple specific eips that people wanted to discuss, so we can cover those. And then I think it makes sense to hear from all the different teams what they think about the upgrade as a whole and what people's priorities are. And then lastly on the next upgrade, the vertical folks want to do kind of a deep dive on the next Acde. And one thing that would be helpful is collecting feedback today on what people want to see and discuss so that they can best prepare for it. And then at the end, hopefully we have time for this. But there was a Besu mainnet incident that we'd like to discuss briefly. So I guess to get us started, I don't know, Perry or Barnabas, do we do if you want to start with like a high level Gordy recap.
00:02:50.718 - 00:03:35.178, Speaker A: And then if any client teams want to chime in, we can do that as well. Yeah, I can go. So we had the girly fork yesterday around 630 utc, and immediately after the fork we saw that there was a drop in participation. I think we went down all the way to about 40%. And on triaging we narrowed it down to one client being offline due to a failed upgrade and one client issue itself. The client issue was hot fixed soon and I think someone from the prison team can talk more about that. And once the hot fix was applied, the network did exceed 70 ish percent participation rates.
00:03:35.178 - 00:04:10.060, Speaker A: And then we were seeing finality. During the non finalizing period, we did submit some blobs. They made it through perfectly fine. And post finality we started blob spamming as well. That went on for about seven ish hours. And based on that, we've written an initial analysis that should showcase how the blobs fared in terms of propagation time and what effect they had on blocks themselves. Besides that, overnight we didn't run any other block tests, but we started the spammer again today morning.
00:04:10.060 - 00:04:50.762, Speaker A: Awesome, thanks. Yeah. Is anyone from prism on? Yeah, hello? Hi, I can give a brief update on what went wrong. So what happened was that when Prism upgraded from Capella to Danette State, we kept the historical route empty instead of carrying it over. So this issue was fairly easy to fund. We basically patched it the first few hours and then we released the high image. And then I believe the Capella state.
00:04:50.762 - 00:05:01.902, Speaker A: Sorry. I believe the net was finalized about 02:00 a.m. Pacific time. So about 4 hours after. So just give a little background. Right. So historical route is this legacy field.
00:05:01.902 - 00:05:39.318, Speaker A: It's essentially frozen at Capella. It was used before capella, so it was an old field. And then why it didn't get surfaced before the previous deafness or shadow port was that we need to run enough before we essentially need to run enough at the previous port to essentially have it as non zero. And then this is only updated for every 24 hours. So say today, if you start from Bella trips and then you harp on to Capella less than 24 hours, if the time is less than 24 hours, this is going to be zero. So that's essentially what happened before. That's why we didn't catch it.
00:05:39.318 - 00:05:59.440, Speaker A: And then spec test also didn't catch it. So we immediately surfaced that to Shao Wei. There's a pr on that. So essentially spat test will cover that. So this is just one of those very rare cases. Thanks for Gordy. Otherwise we probably wouldn't have caught it until later.
00:05:59.440 - 00:06:45.262, Speaker A: Got it. Thanks. Yeah, I guess this is also something we can not only catch in the spec test, but when we run devnets, we could explicitly have a fork happen once, sort of far enough from the previous one to allow. Yeah, or the genesis state can just have a value in that field, because always will have values in that field. And so Genesis states on our devnets just might as well. But yeah, this should be caught way upstream and just kind of the weirdness of the deprecation of that and not thinking through the fork boundary test all the way. We didn't have one in the consensus spec test.
00:06:45.262 - 00:07:39.418, Speaker A: So that is there as of the release. That'll go live right after this call. And we can spend some time making sure there's nothing else funky on fork boundary tests, although Gorley probably would have caught anything else like got it. And I think this was the only sort of major client issue that we saw on Gordy. But do any other client team want to share anything notable or interesting that they saw during the fork? I had one issue that I surfaced. It's also minor that prism are seeing client team. So this is consensus apologize bring here.
00:07:39.418 - 00:08:21.010, Speaker A: So Prisma is seeing client team requesting blocks. Sorry blobs for every index no matter what. So say today if you have a block that doesn't have any KDG commitment, we are getting requests for the block and it's slightly wasteful I would say. So yeah, I've serviced. I don't want to point name but I think it was at Taku or something like that that was doing that. So yeah, I think tech team is aware of that. Yeah so we do in some cases request blobs but it should not happen in that case specifically.
00:08:21.010 - 00:08:51.810, Speaker A: So I'm just double checking later today. But I think in the case that the block has zero commitment we should not do that. So I suspect there should be some other peer or something running over the network that does that. But I'll double check any case because we do something similar. Awesome. Thanks. And I suspect this would be an easy fix once you identify it to discriminate based on the commitment.
00:08:51.810 - 00:09:55.172, Speaker A: Any other comments? Thoughts? My client teams, one thing I did want to ask was right now we're artificially spamming Gurley with blobs and everything's kind of being submitted to the same set of nodes. So the propagation statistics will also look as if they've been submitted to the same set of nodes. We tried stopping for a bit. There's just not much native blob traffic on Gurley. It would be really nice to know when l two start to plan using it and when we should stop spamming it. Do we expect l two s to use the gorely blobs given the deprecation or are they going to focus on another test net? I don't want to speak for arbitran but I work fairly close to them. I don't think they will use Cordy.
00:09:55.172 - 00:10:34.204, Speaker A: So the likely testnet, the most likely one will be supportive for them and if not l two s. Yeah, I don't know if there's another group that we could get to spam Gordy and hit a different set of nodes. I guess if you're listening to this and looking for something to do. Oh proto. Yeah. So we are looking at testing on Gerdy starting with layer two devnet. Nice.
00:10:34.204 - 00:11:48.680, Speaker A: Once we go past internal devnet work, only then we can go to more production testnets and then towards development of final stretch for manned testing now spanning blobs. Yes. We can generate some traffic on the devnet without argue that to get real testing we want to update the public layer two testnets. That may take some time. Do you have a feel for how long it would take you. So we consider our testnets as a more production environment where users depths rely on stability of these networks and the choice to go and update the devnet first. This means that we aim for one or two weeks of testing on Devnet before we go and try any updates on Testnet.
00:11:48.680 - 00:13:01.600, Speaker A: Got it. So it's like at the earliest, it would probably take another month for Gordy to be updated. At least a few weeks a day. Yeah. The other timeline that's interesting here is how much a layer two should take for their public testnet and how much the layer one here accommodates. Since a stable layer one target here is important for layer two governance and for upgrades that do not rush a proof change or a change that affects the layer two security. So the longer running the rollout period is of a layer two, the more important it is to have sufficient layer one test time to prepare for a main net grid.
00:13:01.600 - 00:14:11.130, Speaker A: I guess. Do we see a risk that 4844 is somehow inadequate for l two s? Obviously you can imagine it being on main net for months before and l two chooses to use it. That's probably fine, but I guess what's the minimum amount of confirmation we want that this is quote unquote usable and do we sort of already have that? Because I know there were some. In terms of capacity, I think we're very close. What I'm more concerned with is tooling infrastructure around blocks. Many RPC providers, for example, they serve the JSON RPC but not the Beacon layer RPC. And so a lot of infrastructure that has been built around layer twos relies on the JSON RPC but not on this new HTP endpoint that serves the actual block data.
00:14:11.130 - 00:15:44.822, Speaker A: So there's more infrared to update outside of the layer one. Right. And I guess I wouldn't definitely not block l one on the ecosystem adopting because they can add support for it whenever. But I guess my question is more like is there something about the consensus change itself where we feel like we'd need additional validation from l two s or some other stakeholder before moving to main net? Or should we try and keep moving towards main net as quickly or efficiently as we can? And then I guess it's better, I think, to be in a spot where it's on main net and people just have to adopt it than a spot where it's not live because we're waiting on some external dependency. But yeah, I want to be sure that's like a reasonable assumption and there's not something on the l two side, that's like we may be missing. And Anzgar has a comment in the chat that there's an 4844 l two readiness roll call next Wednesday, so that they'll bring that up there as well and they can report back on Thursday's ACDC. So we should probably discuss that further there.
00:15:44.822 - 00:16:38.780, Speaker A: But yeah, I guess for now, does anyone see like, we should get l two s to test this as quickly as possible? And so optimism can do it on Gordy in the next couple of weeks. That's great. Once the Devnet has been done, if for arbitram, we're waiting on Sepolia, then we should probably get sepolia upgraded. And then if there's other l two s not on this call listening, if someone wants to start testing Gordy sooner, that's probably just some valuable data for us to obtain. So my takeaway from that would be that we continue spamming, but rather than a target of six, we'll just have a target of three. So that if someone else wants to join in, then they're not priced out. Yeah, that makes sense.
00:16:38.780 - 00:17:44.652, Speaker A: Okay, and just one more thing I do want to mention. These are alpha numbers and we kind of want to know what client teams are looking for so that we can start customizing these sort of analysis like every week or something. From the data from the last week right now, it looks like in the average case, blobs are propagated on the network under the two second mark. There are some P 95 values at the four, five second mark, but in general, attestation deadlines seem to be hit. And it doesn't matter how many blobs we have, it looks like block propagation is not affected, which is good news. And in general all the numbers look quite good so far. So yeah, I guess the question is, what else do we want to collect from here? Is something missing? Just portus's message.
00:17:44.652 - 00:18:31.740, Speaker A: Yeah, the builders being used regularly on Gurley as well. We have mapboost enabled in at least all of our validators. We haven't tried sending blobs directly through them, but they have been gossiped by our notes. But we can try sending it directly to the relay. Okay. And there's a comment saying flashbots has delivered some payloads with blobs. Nice.
00:18:31.740 - 00:20:11.084, Speaker A: Okay, any other thoughts from client teams or others about Gordy specifically, very quickly, after the non finalty was over? Oh, nice. Anything else? Ok, so next up, we had this JSON RPC discussion a few weeks ago on the testing call about adding blob gas prices to a few JSON RPC methods. We were hoping to have more discussion on it, but it does seem pretty stale, I guess. Yeah. Like kind to your last person who's commented, do you think we should go ahead and merge this? Does this need more input? This feels like something that would be nice to have, obviously before main net and potentially before one of the next test nets so that we can expose the blob based v in JSON RPC. Yeah, I think for one thing, we had this PR to 44 one and a half weeks ago trying to rename gas price to base fee with respect to blobs. And I think we probably want to move forward with that.
00:20:11.084 - 00:21:03.470, Speaker A: And so if we do that, that's going to change the name of the RPC method from blob gas price to blob base fee. So that needs to be updated. But in general, this seems like something that we need to be doing. I'm just flying a little blind because I'm not sure who the consumers of these things are and they're not really stepping up to say this is what we would like this to look like. So I'm kind of just following what has existed in the past and moving in the same direction with the blob, you know, for instance, I don't know if this is the testing call or the last call, but Roberto was saying for them they're just calculating the blob based fee using the previous header. So people are kind of getting around it. So the question is, if people are getting around it, do we need to expose this RPC method? I'm not sure.
00:21:03.470 - 00:21:47.950, Speaker A: It seems like the right thing to do, but I'm just waiting for someone to say that's what we want. So assuming we go ahead and emerge that PR with a name change on 4844, then we change those names. Maybe like somebody to ask. I know Ryan from Inferra has been in the discord following a lot of these devnets. So like Inferra might be a good basically consumer of this. If anybody else has thoughts, it's pr four eight six in the execution APIs repo. Is there anyone who like.
00:21:47.950 - 00:22:45.400, Speaker A: Sorry, go ahead. Oh, sorry. I was just going to agree with you. And I was wanting to know if anyone was opposed to eight nine five, the changing the name from gas price to base fee because I'll just merge that in the next hour. If not, great. Okay, yeah, let's merge the pr to 4844 and then maybe do one last pain on the discord and explicitly tag Brian about the JSON RPC one and assuming there's no objection, we merge that one as soon as it's updated with the new names. Sweet.
00:22:45.400 - 00:24:23.660, Speaker A: Okay, next up so there was a comment by Andrew about deploying the 4788 contract on all the other networks, so we deployed it on Holski and Sepolia this week and we weren't sure if it makes sense to deploy the 4780 contract on main net now, or if we'd rather wait to see the other testnets fork before we do that. I don't know if anyone has thoughts about this given deploy address as a function of the code, I think it's fine to deploy now and might as well deploy now. Meaning in the event that there is some last minute change to that code due to functionality change or bug or something, it would deploy to a different address so we don't shoot ourselves in the foot by already having something there. So given the manual deploy, I'd say while top of mind, just do it. Okay, does anyone want to volunteer to deploy it? I will refund your gas cost if you do. So I guess if first person who goes ahead and deploys it can post in the awkwardevs channel the transaction hash. But yeah, let's try.
00:24:23.660 - 00:25:16.366, Speaker A: Yes, Mario, I'll send back the gas cost of the first transaction, someone who deploys it and posts it in awkward evs. I will not double it though. Sweet. Next up, Shawi posted this in the chat, but there is a new Cl release being cut. I don't know if Xiaoi is on the call or otherwise. Danny, any thoughts comments on that? This was expected to go out Monday. It did not, and then the issue on Gorely came out.
00:25:16.366 - 00:26:25.274, Speaker A: So we got an additional test vectors and now it is immediately ready to go out after this call. It has the fork choice filter change. It has a number of other minor things which are not really substantive with respect to this and has the additional test. The intention would be that this is the target going forward with the fork choice filter change being the main thing to have to accomplish, but also knowing that if on the next testnet you don't have that done except in pretty crazy exceptional scenarios, you won't diverge. This has been discussed quite a bit on their call, so I don't think there's any additional context or discussion needed. Got it. Okay, so I think those were all the sort of outstanding items around Dencoon in terms of timing.
00:26:25.274 - 00:27:48.256, Speaker A: So on the last ACDe last year we'd set the schedule for all three test nets. Gordy is already done Sepolia is currently scheduled for January 30 and then Holsky is scheduled a week after that for February 7. Our plan was to have a single client release for both those testnets so that users can just download it once and be ready on both chains. And we only have to have one sort of release cycle, one announcement and so on. If we want to stick to that and give people at least a week to upgrade on Sepolia, it means we'd have to have client releases and the announcement out sometime around like Tuesday next week. Does this feel realistic for all client teams? Does anyone have a problem with that schedule? Or should we keep moving forward and announce Sepolia and Hoski around Tuesday of next week? Okay, take who saying it's okay? Yeah. And no one objecting.
00:27:48.256 - 00:28:16.364, Speaker A: So I'll take that as a sign that we're good. Plus one from nethermind. Okay, last call. Otherwise, yeah, otherwise we'll move forward. And obviously if we see something go terribly wrong on Sepolia, we can always cancel the whole ski fork. But yeah, I think this will simplify things a bit for users to have both. So.
00:28:16.364 - 00:28:49.564, Speaker A: Great. Okay, let's stick to it. All the numbers are in EIP 7569. So the epoch on Sepolia is 132608. Epoch on Hosky is 29696. And then the corresponding timestamps are linked in that table. Anything else on Denkoon at all? Okay, sweet.
00:28:49.564 - 00:29:48.436, Speaker A: Then moving on to the next slash electra. So I compiled all the proposals earlier this week that been put up so far. There's three of them that specifically or three people that asked to talk about four things specifically today. So I think it probably makes sense to go through those first and then hear from all the client teams what they're thinking in terms of prioritization, both in terms of specific eips, but also this higher level conversation around where Verco fits in and how we potentially want to approach the next two forks rather than just the next el fork. So yeah, to kick it have I don't know if Fubar is on the call. Yes. Okay, so I'll post your upgrade, your update in the chat, but yeah, take it away.
00:29:48.436 - 00:30:18.168, Speaker A: About 374. Awesome. Does screen share work for it should presentation? Okay, let me get that going. Okay, perfect. Yeah, we see. Can you see? I'll just dive into. Hey, great to meet you everyone.
00:30:18.168 - 00:30:43.760, Speaker A: I'm Fubar. May have seen me on Twitter. First time kind of touching the core dev stuff. So appreciate you bearing with me, have done a lot of sorry, your presentation is like stuck at loading so I don't know if you. Maybe it's like in another screen or something on your. Yeah, I'll just share entire screen and see if that works. Um.
00:30:43.760 - 00:31:15.922, Speaker A: All right, how's that? It's loading on my end. Let's see if it loads. Still nothing? No. Okay. Does this work? Yeah. Let me try to kick you off and see if I can. That's okay.
00:31:15.922 - 00:31:35.254, Speaker A: I can also just shoot the link here and talk through things. Okay. Some people are seeing it, so yeah, maybe just shoot the link in the chat in parallel and it might not load it on. Think? Yeah, I think we're getting there. Awesome. All right, we'll share. All right, we got the links.
00:31:35.254 - 00:32:42.320, Speaker A: Perfect. So yeah, key high level thing is, I think there's a massive opportunity for a core UX level upgrade that both increases EVM dominance relevance and saves literal hundreds of millions of dollars for users at the same time. I wrote up a more in depth article here that you can dive into, but the key idea is that batch transactions for eoas add a whole swath of benefits. They fix sale approval attacks which have taken 100 million plus from retail, including three separate attacks in the last month. They reduced a lot of developer overhead. Speaking from personal experience of people not having to embed quirky native multicalls within their protocols also reduces it's a bit of a free lunch on the state growth side of things. Currently you've got all this overhead for mempool propagation, signature verification for sequential transactions, when really you just want kind of one signature across the whole thing.
00:32:42.320 - 00:34:24.602, Speaker A: So able to get more actions, more chain usage without any additional client node burdens, and also able to remove some of the assumptions we've got on trusted intermediaries like private relays and whatnot. Most of this is just focused on the user and dev experience side, but do have a bit at the end where we can dive into the specific eips, although I think there are people more skilled than me to discuss that. So a quick example on stale approvals and how that goes bad. I think that the approval pattern in Ethereum is good for some things, but has been overused and gotten a lot of people wrecked as a result. So for something like a long standing Opensea ask, I want to sell this nFT for one eth that's a good usage of approvals for something like I just want to put my asset into a protocol, like I want to swap tether for ETH on uniswap, then it's not actually desirable on the app side or the user side to constantly be having to do this approval for it to be stale left open. A lot of apps have this dangerous infinite approval pattern, and we've seen this get exploited time and time again. Just last 30 days, for example, you had the NFT trader exploit, two year old contract, several million dollars worth of assets drained, not because they were actively participating in the exploit, just because they'd done an action two years ago and forgotten didn't have the bandwidth to revoke.
00:34:24.602 - 00:35:03.770, Speaker A: Same thing with floor protocol. And then just yesterday or two days ago, Bridge, you had a lot of people get their assets drained from stale approvals on a bridge. And these are, I picked recent relevant ones, but these are things that happen over and over again. And so these are frankly all fixed with a batch transaction pattern. So I think that there's a lot of user leakage and Ethereum experience improvement that can happen from that. There's huge on protocol UX side. I know that natively enshrining multicol is something that can be done.
00:35:03.770 - 00:35:57.520, Speaker A: Most people don't know how to do it. In my work on audits, you kind of have to manually push people to get it there. I think coalescing around a single standard for the entire space makes a much better devidex. Yeah, state growth. As we said, you've got fewer transactions floating around than the mem pool for the same level of actions, less overhead from sequential transactions that really do want to be next to each other. And I think something that's not maybe well understood as I was diving into this, is you actually get better 1559 esque gas volatility spreading. Because if a user is trying to do multiple actions in a row, like approve, swap deposit, they can't leave their computer until that final transaction is going out into the world.
00:35:57.520 - 00:36:48.140, Speaker A: So they often have to overpay on the first ones. They overpay on approved, they overpay on swap just so they can express their actual gas preference on that last bit. So I think there's a bit of spreading. If you could batch three ish transactions, send it as the mempool for a couple of hours and sit it there, then you get better queuing on that front and better state growth. And then of course there's the risk of intermediaries private relays unbundling things either maliciously or accidentally. I think this makes the relaying space a lot more open and permissionless because there's less need to rely on reputation as collateral. Enshrining batch transactions there removes it.
00:36:48.140 - 00:38:07.110, Speaker A: Basically. My strong opinion is that batch transactions for eoas of some form need to ship in the next hard fork. Massive upgrade on security on UX, on state growth, on demand limiting on kind of even obscure things like private relay trust vectors, and seems like the two key eips are 30 74 from light clients who's been amazingly helpful in talking through a lot of this and also a slimmer, simpler but less fleshed out 58 six two approaches here. I think most people on the call are familiar with Auth and Auth call you essentially provide an ECDSA signature to a trusted invoker, much like a 4337 singleton entry point, and then that invoker can execute good on your behalf. The EO Weiss has done a lot of great work on this and thought through how to mitigate some of the security vectors by assigning each specific call. I think that's also an interesting approach. And then 58 six is just kind of very simple.
00:38:07.110 - 00:39:18.556, Speaker A: No invokers, just a new transaction type that lets EOAS delegate call any contract directly and execute that delegate call code within its own context. Obviously these are all exclusive, but I think that one of them needs to get shipped and upgrade the whole EOA experience. Those are my thoughts. From a user perspective, massive security upgrade from an app developer perspective, massive UX upgrade and I think it adds some benefits to the core chain, the core chain consensus mechanism as well. So those are my thoughts. Thanks for sharing. Any questions on the presentations or write up from anyone on the call? Anskar yeah, I mean first of great presentation.
00:39:18.556 - 00:40:09.944, Speaker A: I just wanted to say that from my point of view, kind of looking at specifically the three kind of potential EIP paths proposed, two comments I would have first of all, I think those three specifically are relatively heavy handed. First of all, the alternative proposal by Bayoff as an alternative 30 74, I think that just has been underexplored. I don't personally think that makes a lot of sense. And then the other one, the heightens. While I think is interesting also those things that people have talked a lot about, delegate call UA accounts directly and it runs into similar issues. So I think out of those three probably 30 74 is the most realistic. But as we talked about for the last two years already regarding the AP, it's very heavy handed.
00:40:09.944 - 00:41:03.440, Speaker A: So I'm not sure if it's a good fit for Mainnet. So I think the most realistic, if there is a strong need for bandling, I would say the most realistic here would be to have a more new EIP or reuse one of the older ones. That was very limited in scope just to the banding use case specifically. So that's comment one. I think a narrow eip here would make more sense. And then comment two would be that I personally philosophically think that for a lot of these more user focused improvements to the EVM, we should try and more and more kind of leave this initial experimentation with new features like this to layer twos that are more nimble in shipping. Anyway, and now that we're starting to see with roll call, kind of like a standardization process around eips or vip equivalents on the layer two side, I think personally philosophically I would much rather see these kind of things shipped on layer twos and then later brought to Mainnet.
00:41:03.440 - 00:41:37.624, Speaker A: Those are my two comments. Yeah, that's helpful, I guess, to respond to the first. Definitely my desire is some form of thing get shipped. So if there's a way to slim things down, use the learnings of the past two years. It all sounds very interesting. On the second comment, push all the innovation out to the l two s. I think that's a good long term plan and works quite well on things like new cryptography pre compile.
00:41:37.624 - 00:43:27.078, Speaker A: But for things where there's a high coordination cost, good batch transactions require three actors to all coordinate. You need the core chain to support it, you also need the wallets to support it, and you also need the apps to be able to push this. I'm not sure that the fragmented approach gets the job done, and I do think that in terms of how do you spread the EVM, how do you make this a good default experience? There is some room for real winning pushes still from the coral one itself. Quick question, follow on Anskar's point though. So you said that in the three actors that you kind of need to coordinate, one of them being the l one, why wouldn't the l two sequencing their own transaction serve as a substitute? So yeah, if you rely on centralized sequencer, then you get some of the benefits of unlikely to unbundle, for example, but the user still has to sign multiple sequential transactions and so on. You train people to click click that are carefully inspecting things, and you've replaced the role of the trusted private relay bundler with the trusted centralized sequencer, and it's not super robust. William yes, I just wanted to comment that I don't think layer two should be treated like a feature testnet.
00:43:27.078 - 00:44:27.524, Speaker A: The developers making layer two s care a lot about compatibility with main net, and if they deployed a feature that had a tentative specification, then when it finally comes to Mainnet, even if it has the same opcode number, there might be differences in behavior, and those would be technical debt for them. So they aren't especially interested in doing that role for us usually. That's all right. Okay. Yeah, I think we can probably discuss that on the l two call, whether or not we'd want this in its current form, this in its current form, or potentially a tweak of it to be deployed on l two S versus l ones. And. Yeah.
00:44:27.524 - 00:45:23.916, Speaker A: Okay. I'm just reading Georgia's comments. Yeah. Is there like a clear next step that people would want to provide? Is this is an outsider's perspective, but it seems like maybe some of the confusion comes from two separate questions being jumbled. The first question being like, are EOA batch transactions desirable? And then the second one being, what's the right implementation for that? And you've got, I think, a lot of fragmented views on the second bit, but less clarity on the first one. So maybe that's the key thing to answer first. Yeah.
00:45:23.916 - 00:46:59.860, Speaker A: And I don't know if anyone has an answer right now at the top of your head, Ahmad. Yeah. So looking at the other solution that Fubar talked about, seems to be harder to secure than the current implementation of 374, as you can't really parse a delegate call easily when it comes inside the wallet, whereas with 30 74, you can parse the call data, the address, the amount of gas being used, the ethereum you're going to pay, et cetera. So it's easier to reason about for wallet to implement something for the user to actually look at when they're signing this transaction. Now, looking into the l two perspective, my personal opinion is that I agree with William. L two s are not going to introduce this EIP unless there is some kind of commitment that this EIP will eventually land in Mainnet as it is spec without any changes. That's just my personal opinion.
00:46:59.860 - 00:48:03.384, Speaker A: Thanks, Andrew. So I think there was a concern from Aragon team members about the original 30 74 that the authorization is not revocable. So we are opposed to that version of 30 74, but the other version by your vice where the permission are revocable, or like EPA 58 six seem to be more reasonable. To be clear, 30 74 is now revocable as of about one month ago, we added the nonce to the authorization message. So when that nonce is passed, the authorization is no longer eligible to be auth called. I would call that expirable, not revocable, because you said an expiration revocable is like, I changed my mind and nothing changes. But it's mean.
00:48:03.384 - 00:49:08.220, Speaker A: It is an improvement. We don't have to nitpick the exact definition here. I would not call it revocable, however. Okay, I disagree, Ben. In answer to FUBAR's first question on whether batch transactions from the users are desirable, I'd say definitely, because it's not. Having them means we have some pretty weird ux patterns that generally end up being quite unsafe. And as he mentioned, you then end up where if you've got to do three, four transactions just to do one action, you're sort of training users to blindly go, yes, in their wallet, and then they go to a phishing site and they get multiple transactions coming through, and they go, yeah, and they fall into this bad pattern.
00:49:08.220 - 00:49:56.104, Speaker A: And also, I think it's important to note that in the absence of batch transactions, apps have developed even more unsafe approaches. I'd say the status quo today is something like a c port order. That's not even a transaction. It's an EIP 712 typed, arbitrarily nested array that gets people wiped 50 apes at a time, and it's not even simulatable. You've got the same issues with things like a single malicious permit. Two signature can then take all the assets you've approved in uniswap. So what enshrining batch transactions and protocol does, it doesn't introduce new security risks.
00:49:56.104 - 00:50:54.790, Speaker A: It moves it from these opaque, 712 non simulatable messages into actual simulation core, into things that wallets can simulate. So batch transactions are already here in an unsafe way. The question is, can you improve them and enshrine them so that we're not stuck in a blurpermit two world forever. Yeah. Following up on that, where you do an off chain signature, which was sort of like an intermediary solution, that's like a very dangerous pattern, and it's off chain, and it lives there forever. And somebody can just insert your signature at a later date of their choosing, which has caused a bunch of hacks as well. Just, you have to be mindful of time.
00:50:54.790 - 00:52:10.752, Speaker A: So I think, yeah, this definitely provides context to a lot of the L one teams, and also, I think, shows that maybe some of them aren't up to speed on the latest designs for this stuff. So obviously, there's, like, the three ips that people can review, I think, in terms of next steps. One now L one teams can figure out how they feel about 30, 74 or one of the other alternatives, and whether we'd want to move forward with something like that in the next fork. Two, I think there is a discussion to be had on the L two side about whether or not we'd want to implement 3074 or again some version of it first there. And Anskar has a comment around how they are trying to figure out the right framework to do that. I guess if people have questions or concerns like we can use, is the eat magicians thread about 30 74 still the best place to do that as people sort of review it? Yeah, that's a good place. Okay.
00:52:10.752 - 00:53:11.624, Speaker A: Also, one of the channels on Discord, any of the transaction batching UX channels, just feel free to tag me and I'll respond. Got it. I'm not saying we're necessarily looking for extra feedback, Georgia, but just if some L one teams review this more deeply, like in the next week or so or whatever, and they have questions, then we can use both the channel on the RnD discord or beat magicians as the place to discuss those. Yeah, I think it probably makes sense to move on to the next ones at this point though. And yeah, thanks again, Fubar for coming on and sharing both the write up and the slides. Yeah, thank you. Sweet.
00:53:11.624 - 00:53:38.940, Speaker A: Okay, next one. Oh, sorry. Please. I just want to say one last thing on this. There is a lot of demand from the user space for something to improve the UX on L one. So if 30 74 isn't the path forward, it would be great for client teams to think a bit about this over the next couple of weeks so we can try and come up with a proposal that we can put into the next fork. Yeah, that makes sense.
00:53:38.940 - 00:54:03.746, Speaker A: Okay, next up, set code. We had another, I guess, design overview. William. Okay, yeah, go for it. And everyone hear me? Can everyone see the presentation? Yes. All right, cool. I hope this goes fast.
00:54:03.746 - 00:54:50.914, Speaker A: So the common basis for all the design of set code, we're just modifying the code at the address that's executing. So code copy and code size still refer to the executing code. Ext code copy ext code size, ext code hash refer to the stored code. It's similar to delegate call in that regard. So new call scopes will execute the stored code. So the storage effectively happens immediately and storages can be reverted like s store, and it fails inside of create context and it doesn't clear storage. These are the basic parameters of set code.
00:54:50.914 - 00:55:44.130, Speaker A: But there's a few alternative designs that have come up in the process of designing set code. The most basic set code would have no restrictions. It's a simple design. It would work the same way as s store, as store also has only the static call restriction. And so it would be difficult, however, to identify immutable code. And someone identified that it could have an issue with ERC four three seven. Because if a library that all of the validator step we're using for the alt mempool were to be toggled, then it could thrash that mempool and be a DOS vector.
00:55:44.130 - 00:56:35.460, Speaker A: So with his help developed a newer design that adds a restriction. The restriction is that you can only modify the currently executing code if it's your code. And so this allows it to be easy to prove that a contract is immutable. It would be easy for a wallet to know if it is approving a mutable contract. It would be easy for etherscan to flag mutable code. Also immutability, it can't be faked during execution, so you wouldn't be able to pretend during the scope of a transaction that you're immutable, get validated for some registry, and then change to mutable. So that's a nice property too.
00:56:35.460 - 00:57:55.070, Speaker A: And then also it would prevent set code inside a delegate call, which would address the alt mempool dos vector. And so this may be a more secure design, and it's probably a good restriction that could be removed if it was determined safe to do so, but probably a good way to launch. And the last parameter for the design of set code is that we could, instead of setting the code at the account, instead we could have the code be an immutable blob per account, and then have the accounts have a new field, the code address that would allow them to indirect the blob that is their code. And then there'd be opcodes to set the code address to read the code address. This is some other way to implement it that I'm interested in knowing how good you think this is and how compatible the code address spec is with Verkel. Because when you do Verkel trees, you're likely going to cement this field in. And so either the code address would be mutable or the code would be mutable.
00:57:55.070 - 00:59:13.458, Speaker A: Either would be satisfactory. For my purposes. The current specification belongs to specification where you can only change your code, and then it's a nice spec because it implicitly captures the delegate call and create scenarios, and it's pretty easy to know whether you're allowed to set code. Other designs were slightly more complicated. Again, the reason we need to do this is that account abstraction can't delegate call if it wants to be competitive for Dex protocols because of priority gas auctions. So if you have a proxy behind delegate call and s load, then you're not going to be able to compete for uniswap before you're going to be super late to any trade, and you're going to have a systematic disadvantage. And so if you're trading on Dexes, things like 4337 aren't really viable, whereas that's why Meb bots are using the create to self destruct pattern for their upgrades.
00:59:13.458 - 01:00:02.114, Speaker A: It's because it's a really good user experience, and I would like to preserve that user experience so that I don't have to move all of my assets to a new account every time I want to support a new callback. That's all for this presentation. Defer back to you. Thanks, William. Any questions? Marius, I see you have a comment in the chat around breaking gas estimation, so I don't know, William, if you maybe want to answer that first, and then if there's other questions, people can raise their hands. Gas estimation is already broken by sstor for the same reason you can branch according to code, just the same way you can branch according to storage. And so any change at all actually impacts gas estimation.
01:00:02.114 - 01:00:53.060, Speaker A: And this is one of the main uses of alt mem pools and relays such as flashbots. Got it. Any other questions? Comments, Guillaume? Yeah, so there was a question asked about the feasibility, in vertical, of the third option. I mean, I see no reason why this would not work. However, on a personal note, I don't really see how this whole set code story could end. Well, there's so many potential hacks with this. Yeah, I would not consider that in the Virgil tree spec for sure, but I don't think we should consider that, period.
01:00:53.060 - 01:01:41.288, Speaker A: Got it. Okay. There's a specific question by clients around. If we can do this with delegate call already, why do we need set code? Yes. So delegate call is unviable if you're trading on dexes because of priority gas auctions. So your ability to trade on a Dex if you're competing with them for storage, as you're currently saying, this is a DOS vector for nodes. It's the same if you're trying to trade and only one of those trades can win, the one that uses the least gas is going to be the one with a huge advantage.
01:01:41.288 - 01:02:22.796, Speaker A: That's because they're going to be able to bid higher and get the trade. Got it. Okay, there's a last question. Sorry. Marius has a question. So this is only about the gas usage of delegate call? No, I don't think that's all it is. Having used the self destruct upgrade pattern even when you have to wait a whole transaction.
01:02:22.796 - 01:03:17.390, Speaker A: I see its superiority. It was so good. If you don't need to use storage, you've been using this already, and dozens of power users have been upgrading this way. It saves so much gas per transaction. I don't think there's a way to price delegate call that would fix this. I think that not having to delegate call at all is just a huge advantage. I think this proposal will backfire quite badly for most users, and because people will create gotcha contracts where they will be able to set the code and then break it.
01:03:17.390 - 01:04:22.566, Speaker A: So I think it's a net negative for most people, and maybe there's an advantage for the 15 or the handful of power users that use this, but I don't think we should do this for these people and potentially bring normal user at risk with this. I don't see it as that demographic, rather that only a handful will be able to keep trading on dexes if we don't allow everyone to do it this way. Currently there's a huge cost to migrating all of your stuff, and you're only able to do that if you're a high frequency trader. Otherwise you're just going to suffer or go back to just using the one by one transaction method described. I do agree with some of the sympathies in the comments regarding how we just need better account abstraction. That is true. Okay, this is probably a good place to wrap this one up.
01:04:22.566 - 01:05:28.802, Speaker A: And again, I think if this is something client teams want to see in the fork, they can definitely signal for it. Yeah, thanks a lot, William, for coming on. Okay, last one before we get into what scientisms want into the forks, Mike wanted to talk about two Cl eips that would have implications on the El side, and so to have people be aware of those and what it would mean, I guess first, the value it would bring, and then second, what it would mean in terms of work on the El side if these were to happen. Yeah. EIP 7251-7547 Mike, do you want to give an overview? Yeah. Hey, thanks Tim, and I'll try and be super quick. I know there's still some left on the agenda, so I guess I'll give a quick overview for the two eips, talk about how they relate to the execution layer, and then if there's time to field a few questions, happy to do those.
01:05:28.802 - 01:06:05.070, Speaker A: Otherwise, please reach out offline. I should be pretty easy to connect to. So yeah, I guess both the eips I just sent in the chat. The first one is EIP 7251, which we've kind of been talking about for a while, but it's this idea of increasing the max effective balance. So just super TLDR. The current max effective balance is 32 e, which means both the minimum balance to become a validator is 32 ETH and the maximum balance that a validator can have is 32 eTh. This is a few implications on the big staking pool side of things.
01:06:05.070 - 01:07:02.122, Speaker A: It means that they have to essentially spin up many, many validators to account for all the stake that they want to put into the consensus layer. So just for an example, Coinbase has like 120,000 or more validators currently that are kind of controlled by the single entity, so they're almost redundant in that regard. On the small staker side, this means that any stake you have above 32 e automatically gets withdrawn and doesn't earn compounding rewards until you have enough to deploy another validator. So a whole new 32 e. So generally speaking, increasing the maximum you can have while also keeping the minimum at 32 both benefits the large stakers because it allows them to consolidate. And this has like overall network health implications. And it also helps the small stakers insofar as they can have balance that's above 32 EtH but not 64 e, and they can get access to this automatic compounding.
01:07:02.122 - 01:07:58.162, Speaker A: So yeah, that's kind of where I'll leave it in terms of the summary, there's a lot more written on this here. There's a kind of related work section in this gist. In terms of the execution layer, the way this relates is through EIP 7002, which asks that the execution layer withdrawal credential, which is kind of different than the signing key that's used for the consensus layer, can initiate an exit. So beyond this, one important feature of 7251 would be to allow custom withdraws that aren't necessarily full exits also triggered from the execution layer. So the kind of use case here is if you have a validator with 100 eth, you want to withdraw two eth to pay your taxes or whatever, then you can do so without withdrawing the whole 100 eth validator. And that request for that withdrawal could come from the withdrawal credential rather than from the validator signing key. And cool.
01:07:58.162 - 01:09:08.614, Speaker A: I'll just run quickly into 7547. The TLDR here is that this EIP aims to enshrine inclusion lists in the protocol. The motivation for this can be seen on Tony's awesome dashboard censorship pix, which basically shows that because of the world we live in, in terms of mev boost and block building, a huge number of blocks on Ethereum mainnet are built by a very small number of entities, and those entities usually choose to exclude some set of transactions. So the EIP itself is this kind of forced inclusion mechanism where validators, even if they aren't building the block for their slot, they can ensure that some set of transactions will get included. There's extensive research on this, mostly done by Vitalik and Francesco over the past like three years. The latest design is this no free lunch thing. So this has like a related work section and all the details you could want, but yeah, the implication on the execution layer side is that the block verification would now depend on this inclusion list.
01:09:08.614 - 01:09:56.280, Speaker A: So the block would only be valid if it included the transactions that were specified by the inclusion list. Otherwise it should be ignored and considered invalid. So yeah, this is my high level pitch. Again, these are mostly on the consensus layer side, but just wanted to kind of make sure that this audience was aware of these and kind of make sure that any questions that people have have a way to get in touch with me and there's a venue for thanks for giving me the time, Tim. Happy to take some questions now, or if we should move on to the client team discussion. Happy to do that as well. We can take a couple of questions now if there's time and if there are questions.
01:09:56.280 - 01:11:05.210, Speaker A: Aman so one question about increasing the max effective balance is how does increasing it affect an activity leak in case there is non finalization in the network? Since the increase in the balance of the validator will mean that it will be able to attest or not attest for longer and still be still affect the network in a higher yeah, so the leak would still be proportional to the balance that you have. So if you're like a 32 ETH validator, you leak at some percentage per year, and if you're a 2048 ETH validator, you leak at that same rate. That's right. I just remembered the equation. Never mind, that's actually valid what you're saying. Thank you. Cool, thanks.
01:11:05.210 - 01:12:03.840, Speaker A: Any other questions? I'm just looking at light clients. How complete is the IL spec? Last time I looked, which will only be so effective because of stake consolidation. How does stake consolidation affect this? I just mean if you're coinbase and you're building four blocks in a row, you're only going to use non empty ils whenever it's not you building the next block. If for some reason you're not allowed to include transactions in your blocks, that are considered something that should be censored. Right. So I guess this is a little speculative because we're not sure exactly how both the validator side decision process would be and also the builder side decision. Yeah, I don't want to speculate on what they would do.
01:12:03.840 - 01:12:48.844, Speaker A: I guess in general, Tony wrote a piece, I don't have it on the top, but Tony wrote a piece called cumulative non expiring inclusion lists, which kind of addresses this. And it makes it so that you could kind of specify how far in the future this thing could be enforced. I'm not sure about the necessity of that versus the complexity it adds, but it's definitely part of the discussion. Yeah, that makes sense. I think this is something we should be looking pretty closely at, if not for this fork, then hopefully for a fork soon. So, yeah, that's generally my thoughts. Yeah.
01:12:48.844 - 01:13:47.120, Speaker A: And we're kind of in this slightly delicate situation where a number of the large builders have started censoring a subset of transactions. There is a few builders that are not. If those builders decide to start censoring, then it could quickly turn into both kind of bad. Look, memetically if 90 plus percent of blocks are censored and also legit degradation in UX in terms of getting those transactions in. So right now, I would say the situation is very unstable. And the more I hear from builders and validators, the more I think that getting some enshrined inclusion mechanism feels very important, especially as regulatory stuff continues to be uncertain. Yeah, it would be better to be proactive with this than reactive in the event of censorship, like seriously impacting users.
01:13:47.120 - 01:14:38.710, Speaker A: Absolutely, yeah. Okay. I think, yeah, we could probably wrap up here, unless there's any urgent questions. Okay, thanks, Tim. Yeah, thank you, Mike, for sharing all that. Ok, so I think, yeah, the next big chunk and this might consume the rest of the call is, I guess, given all this context and what we've discussed on the previous ACDE, and just like the general set of proposals, it'd be good to hear from client teams what they think should be prioritized in the next fork where they have the strongest opinions. And I think as part of that, probably the biggest question is how we feel about Vercol.
01:14:38.710 - 01:15:29.682, Speaker A: We'll focus more of the next call going deep into Vercol, but I think, yeah, from a high level perspective, figuring out, do we want to do Vercol right now? Do we potentially want to do another fork with another set of eips prior to vertical? And if so, which eips are most urgent to include there. That seems like the biggest question to yeah, if any team wants to kick it off. Giorgio's just shared, I guess. Yeah, maybe know you have this write up already. Do you want to give a quick overview of that and then others can chime in after that? Yeah. Thank you Tim. So I shared the write up in the chat.
01:15:29.682 - 01:16:18.230, Speaker A: The TLDR that I think is that momentum is very important and we have a good jive right now of shipping things. So I think the rest team view that we should be able to ship something in 2024 and I think we should optimize for shipping something in 2024. And to that extent I think that the most important eips to ship are the staging related ones that Mike mentioned, in particular 7002. And beyond that I think we should be shooting for isolated one person jobs on the EVM side. So EOF. I know it's a painful topic for some. We took a close look.
01:16:18.230 - 01:16:57.202, Speaker A: We think it's doable by one person in a couple of months. Other ideas that we are interested in are increasing the max blobs post Cancun. But I think we need to do a lot of data work before we can see this. So we don't really want to push for anything like that. So our showman would be 7002. There was another eap about introducing deposits in the El state, which was good for the Cl, the BLS curve EIP. I think everybody knows how to use bls twelve 381 by now.
01:16:57.202 - 01:17:32.110, Speaker A: It's literally everywhere. I don't see any argument against a of let's discuss some scope and commit on something and yeah, that's where we're at. And given that we have it written down, I think worth giving time for other teams to speak more. And happy to discuss async. Thank you. Yeah, that's a really good starting point. Any other team have thoughts or perspective they want to share? Yeah, I can talk about Aragon's perspective.
01:17:32.110 - 01:18:59.898, Speaker A: I think that we should definitely deliver big, serious fundamental improvements that require a lot of engineering because I believe that Ethereum has the strongest engineering talent pool among all blockchains and if we don't do difficult things, then maybe nobody will. So I think we should deliver Virkal and EOF. And the main question whether we schedule Virkal first and then EOF or the other way around. I think Guillaume has a point that Verkel is an epic upgrade and EOF can potentially complicate it further. So perhaps it makes sense to deliver Virko first and then UF, and then once we agree on that order we can maybe bolt on some relatively isolated things if we deliver on the first upgrade, maybe say potentially. I think that tackling batch transactions is important. So say we decide that we are happy with the 58 six.
01:18:59.898 - 01:19:44.326, Speaker A: So then we can potentially bolt on 58 six on the first upgrade, say vehicle. Got it. Thank you. Any other team? So never mind. We would like to see small fork with eips such as execution layer exits, BLS precompile supply, validator deposits. Yeah, and after small fork we would like to focus on vertical trees. And additionally we would slightly prefer to focus on EIp four four than EOs if all teams have a capacity to do it.
01:19:44.326 - 01:21:15.042, Speaker A: And also we would be happy to implement any account abstraction eips if there is clear decision what eips we want to implement for account abstraction. Got it. Thank you. So for Gath, I cannot really speak for the team, but from what I would like to see is I would love to see Verkel first, but I realistically don't think that the majority is for Verkel first. So I would also go with the nethermind approach of doing a smaller hard fork first and then while working on Verkel. And the smaller hard fork, in my opinion, should contain 7726-110-2537 and another one that I don't remember, but like basically the validator deposits and exits, el deposits and exits and BLS pre compiles. Oh, the SEC P as well.
01:21:15.042 - 01:22:08.040, Speaker A: I think that would be a small set for a small fork. And we will have time for building Verkel. Just to add to this. I think actually there was some pushback on 61 ten, but yeah, I think everybody else in the team that I'm aware of at least, is for a small fork before vertical. Got it. Yeah, the besuit team here has very similar thoughts as Mariusgeth and the Nethermind team, focusing first on a smaller fork with a lot of the same eips. Like the BLS pre compile the sec 256 r one, pre compile the 61 10,002, focusing on some EL related deposit stuff.
01:22:08.040 - 01:22:39.120, Speaker A: And then between a driver of EOF or as Nethermind stated, something like four fours. It's kind of loosely kind of a toss up there. I would kind of defer to others on this. I know some on the Bayesu maintainers have strong opinions about EOF, so I'm speaking mostly for a subset of maintainers here. Yeah, I'll speak for EOF. Sorry for not being on last week's calls on a vacation. So I guess the voice wasn't loud enough there.
01:22:39.120 - 01:23:52.550, Speaker A: But as far as EOF and all these other EL deposit level ones, it's important to note that the engineering commitment is fairly orthogonal. The engineers that know the most about EOF on the client teams are not necessarily ones that know the most about the consensus layer changes. So one of the concerns that we're going to be splitting engineering effort I don't think is quite the same because as Giorgios pointed out, it's very few engineer times because we already had this mostly functioning with Nethermind, Beisu and Geth in January of last year, and they're mostly iterative changes, so the hard work's been done for. So that's, that's my opinion on EOF and those changes proposed for I'm in favor of the fork before vertical and the other scoping sounds reasonable to me. I think that was all the EL teams, but did I miss anyone? Lucas. So I would add quickly. So our concerns for EOF are mostly on the testing side because this is very consensus issue problematic.
01:23:52.550 - 01:25:00.174, Speaker A: Like it's easy to make a consensus issue. So I would really love to hear from the, for example, hive testing team what they think about EOF. Hey yes, I think we can make, we have some good ideas on how to do EOF and also Berkele, which is just to introduce more testing fixture formats for EOF specifically. So what we can do is now that we have the execution spec tests, we can generate a definition of how the EOF can fail, for example, and do this testing across all the teams by doing the fixture format for this specifically. So I think that can alleviate a lot of the testing burden on EOF and also on Berkele. We are planning on doing the same thing for these complex upgrades on the side. Yeah, and there's a couple comments on EOF in the chat around a finalized spec.
01:25:00.174 - 01:25:49.822, Speaker A: So I don't know if anyone who's familiar with just like the latest spec work can give an update. So the spec as it's written today could be closed. We're just mostly arguing over smaller, maybe one more opcode here. How are we going to do the final nibble? Integration of the exchange app code. There is a push to move everything to variable width, but I think that's come a little too late in the process because that would basically be restarting the spec and doing large things. So what we have written in the UF repository, modulo stuff found in testing could ship as know. We would want to do a final discussion with the solidity and viper engineers who are on the call, but it doesn't seem like it's a very long list at all.
01:25:49.822 - 01:26:21.846, Speaker A: So it could be done in a week or three. Got it. Guillaume. Yeah. So just maybe a reminder, the problem in deciding which one goes first is really about the complexity of Verkel and the fact that the more we wait, the longer the transition is going to take. So, yeah, if you start adding EOf before verkel. Well, first it's going to complexify vertical because now you have two types of contracts to handle.
01:26:21.846 - 01:27:23.120, Speaker A: And now with vertical, the code itself ends up in the tree and is going to be treated differently. Right. So you're going to increase the complexity of vertical unnecessarily and on top of that, you're going to make the conversion much lower and much more risky because it will be pushed back by as much time as you need to deliver EOF, which is not a simple change. This being said, we in Veracol have to go through the state and convert. If, and Pavel is supposed to get back to us on that, if it would be possible to convert all the legacy code during the vertical conversion, then I would say let's do EOF first because then we can turn everything to EOF and forget about legacy code. It's not guaranteed that it's possible. In fact, it's very unlikely to be possible.
01:27:23.120 - 01:27:57.494, Speaker A: But if it's possible, then it's totally worth waiting. But otherwise, there's no good reason to do EOf first because like I said, the state is growing. We have a very difficult problem ahead of us. We need to tackle it first. EOF is really nice, but it's just that it's nice to have. It's not like a catastrophic problem that we're going to face sooner or later. So one specific problem that EOF solves with its structure and validation is the whole notion of uncapping code size.
01:27:57.494 - 01:28:40.358, Speaker A: There's a lot of push on Twitter to increase code size from twenty four k, and that cannot safely be done in legacy code, whereas it can be done safely in EOF code. And another problem is some of the goals of EOF code are to explicitly break things that legacy does that we don't want in the future, such as code visibility. We don't want to be able to look at the executing code as part of the execution, modify it and manipulate it. We want to separate that code introspection out. And also we're taking the opportunity to remove some of the gas observability issues that are observed in prior versions of the legacy code. So one of the points of EOF is to break these things that have caused problems and get rid of them so that in EOF world, it can't be done. So because of that, you can't translate all legacy code into EOf code.
01:28:40.358 - 01:29:48.394, Speaker A: Could probably do most of it, but there's some explicit places where they're depending upon these features and those we just can't translate there. Now, the longer that we wait to put EOF in there is, the longer that we have to deal with more legacy code coming in fractured forms such as the diamond pattern, versus looking in the safer ways to uncap code size and get these app developers are begging for, just not as loudly as the DFI people for things like getting rid of revocations. But there's a lot of desire to get to increase the 24k limit, and we need a better validation system before we can do that safely. Okay, so we're basically at time. So I guess maybe to summarize a couple of things that we've heard so far. One, it seems like everyone except potentially Aragon would want to see like a small fork before Vercol. And then Aragon's view is like, if we do a fork before Vercol, it should include something substantial, not just a bunch of small things.
01:29:48.394 - 01:31:36.842, Speaker A: So we should do hard engineering work. I think in that context, the three ips that everybody seemed on the same page about were 6110-7002 so the two validator related eips, and then the BLS precompile. And then whether we move forward with Vercol or EOF or potentially something like four four s, even though it's not quite a consensus change, but have that be like the hard engineering thing we do in parallel to the small eips, that seems a bit more consensus. So would it make sense to move forward with those three eips? So 6110-7002 and then the BLS pre compile as like the basis for our small fork that's targeted for sometime next year on the next call, spend most of the call discussing the big three proposals. So eOf vertical and four four s, and then figure out which fork they would sort of fall into. So agree that there will be a small thing likely before vertical, and then the sort of minimum set that we have consensus on so far is like 6110-7002 and 2537, and then discuss the three big things on the next call and see how they can fit in. Does that make sense to people? I guess.
01:31:36.842 - 01:32:31.780, Speaker A: Any objections to this? Well, I have one question. So I think there is some opposition to UAF in maybe. Okay, maybe we can decide on the next call, but I would like to hear whether people agree that EOF is a good idea in principle or not. Right? Yeah. And I think, okay, it's probably worth getting into that on the next call. And I think in the case where we did not want to move forward with EOF and we wanted to have a separate fork before vertical, the other thing we could spend extra engineering resources on is four fours, like history expiry. Right.
01:32:31.780 - 01:33:17.150, Speaker A: Which doesn't actually require a hard fork, but it does require hard work by client teams. Does that seem reasonable? I guess, yeah. And maybe the thing I'm trying to say is it seems like everybody's, like, in favor of the three small eips. There's still some questions around what the big ones are, but at least we can set those three and then discuss the big ones more thoroughly on the next call. Potus. Oh, POTUS. We can't hear you.
01:33:17.150 - 01:34:07.762, Speaker A: Okay. We're already a couple of minutes over time, so I'll open just like a draft pr for that. And again, we can continue the discussion next call. And I think we didn't quite have time to get to the point about Vercol, but one thing that would be valuable is if people can share any questions, concerns that they'd like to discuss around either eof vertical or four four s, either on awkward devs or on the agenda for the next call so that the folks who are championing those can take them into account. Yeah. And we can discuss later. And I know we also didn't quite get to the besu incident.
01:34:07.762 - 01:34:28.460, Speaker A: Matt, would you be okay if we move that to the start of the next call so that we're sure we actually cover it? Yeah, not a problem. Cool. Okay, so let's do that. Yeah. Any final closing thoughts or comments before we wrap up? Can I just say something quickly? Yes. Oh, please. Yes.
01:34:28.460 - 01:35:05.240, Speaker A: Good. So just two unrelated comments. One of them is my only objection to your statement was that to ship to next year, and the reason being that many teams may have waited in their decisions to have a small fork. The idea that this fork will actually be small and will not delay. Berkele, if we knew that we would be shipping for 2025, then perhaps teams would have decided in a different way. So I would commit to targeting at least by the end of this year. And the second comment is a quick shout out to the rest team.
01:35:05.240 - 01:35:49.640, Speaker A: I think they set out a president that I hadn't seen before, perhaps once from the guest team, which is put out a detailed before the meeting, a detailed reasoning for all the eips that they want to be included and which ones they don't want to be included and which ones they're open to be discussed. This was late for us. We're planning to reach that internal consensus on prism and actually have this ready for the next meeting. This would be very good if everyone does the same in the next time, so this is just a quick shout out for them. Yeah, agreed. It's extremely valuable. And also, yeah, I didn't mention the Cl call, but I assume you'll all have a similar discussion next week on your side of things.
01:35:49.640 - 01:36:08.166, Speaker A: Yeah, I think this is a good place to end, so, yeah, I'll put the pr up with those three small eips. We can discuss the three big ones on the next call and. Yeah, talk to you all soon. Thanks, everyone. Thank you. Thanks. Bye, everyone.
01:36:08.166 - 01:36:11.660, Speaker A: Thank you. Thanks, Tim.

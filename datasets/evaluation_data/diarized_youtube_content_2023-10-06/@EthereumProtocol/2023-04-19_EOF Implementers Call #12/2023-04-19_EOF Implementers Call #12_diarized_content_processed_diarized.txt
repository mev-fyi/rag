00:00:00.330 - 00:00:03.390, Speaker A: You recording in progress.
00:00:04.530 - 00:01:12.050, Speaker B: Hey guys, welcome to the EOF implementers call number twelve. Before we get started with the client updates, I wanted to just reiterate really quickly what we talked about on call eleven, and maybe in the updates can mention how teams have thought about the stuff that we talked about last call, or we can talk about it in the spec updates. But the points that I put on the agenda as a summary for the last call was that we were okay with adding swap in and dupe in. If something were to be cut. This is sort of the first thing we'd look at, but we generally accepted this as something that we were happy to put into. EOF also wanted to reorder the data section to be at the end of the container versus where it is today. And then we also kind of left a note about talking about gas observability with respect to erc four three seven, since it seems like four three seven is very much the approach that people are looking forward to for count abstraction, and if EOF makes that impossible, it's important things to think about.
00:01:12.050 - 00:01:39.850, Speaker B: So with that said, we could go ahead and get started with some client updates and maybe mention how you have thought about those things in the past two weeks. Otherwise, we can chat a little bit more about it and the spec updates if we need to. Anyone want to volunteer to get started? Okay, Ayman, okay, can you hear me?
00:01:41.740 - 00:01:42.592, Speaker C: Yep.
00:01:42.756 - 00:02:17.030, Speaker D: Okay, cool. From Nethermind's side, we've been doing mostly cleanup of our prs. We implemented Dupen Swapn and we've been trying to continue our draft for mega UF endgame spec. And we are waiting for the eips to at least emerge so we can see them clearly and update our code accordingly. That's mostly it.
00:02:17.800 - 00:02:21.190, Speaker B: Thanks for that update. Who wants to go next?
00:02:22.840 - 00:02:32.910, Speaker C: I'll go next. I did some performance hammonds on baseview, but I haven't done much on EOF. Most of my time has been occupied writing slides for a conference next week.
00:02:38.260 - 00:02:59.690, Speaker B: Cool EvM one, folks. Paul, Alex, anything to say from EVM ones?
00:03:00.620 - 00:03:04.872, Speaker E: I don't think anything changed significantly last time.
00:03:05.006 - 00:03:18.700, Speaker B: Okay, cool. Alex, you said that your pressure was not to make Eaps yet, but keep using the Metaspec. Are you just referring to what I said about the swap in dupin thing? I probably just misspoke.
00:03:19.760 - 00:03:33.660, Speaker A: No. Can I respond to Iman? Because you said you were waiting for the eips before considering an implementation, right?
00:03:34.270 - 00:03:35.020, Speaker F: Yeah.
00:03:37.010 - 00:03:43.120, Speaker D: We are making draft implementation, but we prefer the aips to be there.
00:03:47.730 - 00:03:55.502, Speaker A: Yeah, but for drafts and testing it's fine this way, right? We don't expect it to be final before their eips.
00:03:55.566 - 00:03:56.340, Speaker B: Of course.
00:03:58.630 - 00:04:02.340, Speaker D: Okay, I guess. Okay.
00:04:11.280 - 00:04:27.860, Speaker B: Any other client related updates? That's probably all. Any compiler updates doesn't look like anything.
00:04:36.810 - 00:05:32.280, Speaker A: I mean it's not like an official update. But I did have a discussion with Daniel and I mentioned this. Maybe not on the last call, but the call before that for prioritization within solidity. They want to get a bit more confidence before they allocate more resources. But we did agree that they will try to merge the UF one implementation from December, which is like a complete implementation, but it changes a number of different subsystems of the compiler and try to get that merge. And then also third parties can much more easily work on the diff between UF one from December versus what we have today. I mean, right now it would be challenging because they have this massive pr for it.
00:05:32.280 - 00:06:01.730, Speaker A: Yeah, they have this massive pr for it right now and it's really hard to have any third party to make any changes on top. So the goal is to get it merged into mainline solidity and then others, even from this group, can potentially work on making the changes since December to solidity. But if there is more confidence coming from all core devs, then solidity is happy to allocate resources.
00:06:03.910 - 00:06:25.620, Speaker B: Okay, awesome. That's great. Thanks a lot for that update. I think we can move on to spec updates now. Does anyone have anything to talk about here? Ayman?
00:06:28.460 - 00:06:51.656, Speaker D: Well I think I mentioned it in the discord. I would like to suggest that we update our traces to include extra data like the immediates at least the immediates and the current code section for at least.
00:06:51.698 - 00:07:10.900, Speaker C: What basic did is we added the section when it's not zero for the initial large EOF. And I'm open to always setting the code section when it's EOF code and not set up when it's EOF code is a nice indication, but adding immediate, I didn't think of that and I think that's valuable and useful.
00:07:11.480 - 00:07:37.980, Speaker D: Yeah, well, we've been trying to build the bytecode from traces and it was pretty much impossible with the new opcodes, the new multibyte opcodes for push we can deduce it from the stack of the next trace, but for the other ones it required a lot of painful calculations. So yeah, it would make sense to have them in the traces.
00:07:40.020 - 00:07:42.720, Speaker C: As hex or decimals.
00:07:47.460 - 00:07:51.170, Speaker D: Whatever works for us, I guess. Both work, right?
00:07:53.620 - 00:08:06.520, Speaker C: Well, most of the trace spec is in decimal instead of hex when it comes to the text strings. So if you're like doing an r jump, you would want it in decimal because the pc is in decimal.
00:08:08.140 - 00:08:45.830, Speaker D: Okay. Then when we do them decimal, the format doesn't matter to us that much, as much as they exist. So we can deduce them or have them there to see them. And yeah, the other thing is about dependent swapn. I think the validation should be moved to the EOF validation context instead of just throwing exceptions in the VM while interpreting. Yeah, that's it.
00:08:52.600 - 00:09:02.760, Speaker B: You're saying that part of the UF validation that happens on deployer executing in that code should also check the validity of the swap and dupen?
00:09:03.740 - 00:09:33.700, Speaker D: Yeah, the current spec, I guess, suggests that if the stack doesn't have enough elements for dupen and swapn according to their immediate we throw either stack underflow or overflow, and the stack validation in our EOF, in the EOF context takes care of that. So we can just move those checks to the stack validation part and proceed normally.
00:09:36.600 - 00:09:49.640, Speaker B: Yeah. Guys on the epsilon team, was there a reason why you guys wrote it in this way, where it was a runtime exception versus a validation exception?
00:09:50.700 - 00:10:04.540, Speaker A: Yeah, it was written before stack validation was introduced, but as we agreed last week to integrate this into the mega spec, it has been integrated yesterday, including this deck validation.
00:10:05.120 - 00:10:05.772, Speaker C: Okay, great.
00:10:05.826 - 00:10:07.900, Speaker A: But EIP hasn't been updated.
00:10:08.560 - 00:10:16.370, Speaker B: Right. Okay, awesome. Does that resolve your question?
00:10:20.110 - 00:10:21.546, Speaker C: Yeah, perfect. Nice.
00:10:21.648 - 00:10:22.058, Speaker D: Thanks.
00:10:22.144 - 00:10:30.910, Speaker B: Excellent. Okay, any other spec updates? Spec concerns?
00:10:40.360 - 00:10:51.210, Speaker A: So actually on the spec update, Andre, I'm not sure if your mic works, but if it does, you work the most on the spec. Do you want to give an update on it?
00:10:52.060 - 00:11:46.808, Speaker E: Yeah, we made several additions. Swapine and Japan, as already mentioned, are there now. And then we added non returning functions, definition and its implication for jump f. I think jump f was already there, but now it also mentions non return functions and how they are validated, and it turned out a bit tricky. So validating whether the function is really non returning actually depends on jump f's and whether they jump f into other non returning functions only or not. But yeah, it's better to check it out on the spec. And also, this is not a new thing, but we just kind of reorganized things.
00:11:46.808 - 00:12:38.830, Speaker E: We've added this tech validation section in the doc, and this is just for completeness, I guess we moved some items from code validation into this, so they are now separate and more complete and easier to read, hopefully. And also, I think since last time we changed the order of the sections now data, oh, it's not everywhere fixed. So section kinds are now four for data and three for containers. And containers go before data section. Yeah, I think that's all I remember.
00:12:42.630 - 00:13:07.560, Speaker B: Awesome. Sounds like a lot was added to the spec. It's great. Any comments on those updates? Okay, Zane, do you want to bring up this discussion again about Xcode copy data?
00:13:08.890 - 00:13:52.354, Speaker G: Yeah, so thanks. My name is Zayn. I'm just a community member that's working in the ecosystem. So there's sort of a largest group of us that have been using data contracts. And I was listening to the call from two weeks ago, and it sounded like there was some sort of confusion as to whether or not what level of support there would be for data contracts. So just as context, some of the larger people that use these data contracts would be nouns. Dow says something like, I don't know, 45 million worth of whatever in their Dow treasury, and then art blocks uses it.
00:13:52.354 - 00:15:15.150, Speaker G: And then there's sort of a larger subgroup that you can access. And I posted this here from the evm discord called Mathcastles and like extreme Tom from coolcats and a lot of people in the NFT space, and there's a couple of people elsewhere that are using data contracts. And so I think there is some confusion because within the EIP, it seems like there's a pathway to keep using Xcode copy to retrieve data. And then when I brought this up in the discord, it seemed like maybe that's no longer on the docket to be supported where the Xcode copy opcode would fail on a data contract. Is that correct or. Yeah, am I missing things? And then finally, a lot of us want to start migrating the code over to start supporting s store. So here is basically the sequence that a lot of projects use and some sort of derivative of this, which is of course using Xcode copy to reduce gas and storing data within the code segment.
00:15:15.150 - 00:16:22.500, Speaker G: And so from the consumption side, what this looks like as a problem is that as more gas is used by the RPC providers, then the data doesn't actually get relayed back. So sstore helps reduce that for on chain storage. So if you're just like using inferior, for instance, you may not get back all the data. So from multiple angles, it becomes tricky when you can't have sort of cheap immutable storage or cheapish to return back. All right, so that's kind of like the spiel. I was curious, does that make sense? And what the general sort of thinking is, can we move forward with implementing changes to say like this s store lib to reflect the current EIP? Or is that off the table, and I think there was some confusion about x data copy as well.
00:16:29.570 - 00:17:00.330, Speaker B: Thanks for approaching the subject, Zane. I think my understanding was that we were. I don't know, I haven't looked at the mega spec in a while, but I think one idea was to have new opcodes like data copy and that would allow us to copy the data from the data section of a different contract, and that would provide this similar functionality of having data contracts. But I don't know what the latest on that is. Alex.
00:17:05.280 - 00:17:56.460, Speaker A: Yeah, I guess there's a distinction between using data within a contract versus cross contracts. So what we have in the spec is data copy, which is local to the current account. That is similar to what we had with code copy before. That is going to be supported reading from other accounts which was accomplished with Xcode copy. For that we don't have an x data copy counterpart. I see a number of different solutions if we decide to support this pattern. There could be an x data copy instruction.
00:17:56.460 - 00:19:11.750, Speaker A: The Xcode copy instruction could be repurposed if the target is an EOf account or what I like the most now is this idea mentioned, I think, by Dano on the channel, that there's nothing stopping data contracts from actually having just a regular ABI function which returns the data the caller is asking for. I think the only argument to be discussed here is what are the overheads? The cost overheads, right. Because the main reason there's a preference for Xcode copy as opposed to anything else, because that is the cheapest. And I want to close this out with some random feedback. I've been working on pricing in worker trees. My hunch was that maybe this data contract question will be changing in workal trees. My current empirical findings don't support that yet.
00:19:11.750 - 00:19:59.030, Speaker A: Data contracts will be more expensive than they are today because of the code chunking employed in oracle trees. But I was wondering, what is actually the correct pricing about any of these? So I'm not fully sure at this point that data contracts in a virtual tree paradigm should be cheaper than storage, because in the virtual tree they kind of cost the same. Um, I think that's something else to keep in mind, that maybe data contracts, they're currently cheaper, but maybe they won't be cheaper in the future.
00:20:02.030 - 00:21:47.180, Speaker G: And then I guess my sort of follow up question would be what would be the reasoning behind them not being cheaper, given that, let's say, a code copy? Two points actually, two things to just bring into the awareness. So a lot of, let's say, like DeFi and different projects are starting to lean more into diamond contracts and proxies and essentially chunking kind of a mega contract under one umbrella. So local data copy is probably going to be not as useful as external data copy just because a lot of contracts are starting to brush up against those limits. And then the sort of other thing would be from just like bytes or bytes in bits or bits perspective, it seems like if you were storing data in the code segment, and the cost is that it's not mutable storage, but immutable storage, that it would seem that the cost of storing anything in those segments would be the same. Now, when it comes to reads, I could see that as being a thing, but I wouldn't say that Coregaf is particularly optimized for the reading use case. And I think a lot of infrastructure uses indexing anyways from external systems, for instance, like Vulcan. Okay, that's my long and short of that.
00:21:52.700 - 00:21:53.108, Speaker B: I think.
00:21:53.134 - 00:22:44.140, Speaker A: Zane, these are like really awesome questions. The first point you made that there are contract size limits, I think those again originate from fixing DOS vectors. And with EOF, I think we're actually getting a different fix to many of those. You know, one of the early issue why code size limits were introduced were the jump test analysis to put a bound in it. Now with the EOF, we removed the need for that. So I could see a potential that actually uf contracts wouldn't be subject to the same code size. Maybe, you know, you could actually have much larger contracts.
00:22:44.140 - 00:23:22.840, Speaker A: Now, there is one limitation there that the data section currently is limited to. So that would be the limit. That's the limitation in the header. And then just one more response and I won't be able to answer all of your questions. I want others to also speak. But a generic response to why things are priced as they are. Essentially the pricing of both, like handling contract code and handling storage, should somewhat reflect the underlying cost of the client.
00:23:22.840 - 00:23:47.970, Speaker A: And today these costs hopefully reflect what the client has to do. But with oracle trees, the work needed to be done by the client will be different than it is today. And maybe that will mean that the cost of data contracts will be closer to storage than it is today. And I will pause here.
00:23:50.750 - 00:24:48.906, Speaker G: Yeah, awesome responses. I think that makes sense in the sense that essentially you're trying to price the storage, and then maybe the price goes up or down. And prices are always supposed to be dynamic. So I think that makes sense. I think probably from the outside perspective, from, let's say the DAP side of things, it seems as though there's been a lot of momentum towards splitting contracts just because at some point you'll hit some limit. And the jump desk current limitation makes sense. And I guess the question I would have is, from the EOF perspective, there's the code section and then there's the data section.
00:24:48.906 - 00:24:56.670, Speaker G: And I think people just looking at storing data in the code section.
00:24:58.770 - 00:24:59.134, Speaker C: Is.
00:24:59.172 - 00:25:14.230, Speaker G: Kind of the angle versus in the data section itself. Are you thinking that the EOF format will no longer sort of allow that? And you want to have a clear borderline?
00:25:17.130 - 00:26:13.482, Speaker C: Yeah, we do very much want the clear borderline to make sure that code never hits memory, never hits anything that could be evaluated in the EVM. One of the reasons has to do with zero knowledge proof translations. To be able to take the EVM and easily translate it into a zero proof system, zero knowledge proof system and have it have access to the bytecode kind of makes it more difficult, but also constrains the kind of transformations we can do on the code in the future. If we need to upgrade to a new version of EOF, or if we need to go to a slightly different system for ZK proofs that has the same effect of the code, but doesn't have the exact same code. So that's one of the reasons why we want to make the code unobservable and why we separate the data from the code. Actually, with EOF, the data section is 64k because it's two bytes. So that's more than we can get in the contract today.
00:26:13.482 - 00:27:56.890, Speaker C: If we were to lift limits, one thing that would be helpful for us to evaluate the pricing and the impact is to know for these contracts, how frequently do they call ext code copy within a transaction, and how much data do they copy from ext code copy? Because the idea that I had of if you have a contract that's serving up data, you put a function in front of it that says, give me your data, and then it can copy it there, and then you can get it back. Because even the data itself, in some of these transpiration scenarios, if you can prove that the data doesn't, quote unquote, escape the contract, there's more optimizations you can do and more stuff that you don't need to bring along with you do the transpolation to make it more efficient. So if the contract explicitly says, hey, I'm exporting data by having a contract method that actually does the copy itself and then returns it in the return buffer, those are the sorts of things that these systems going, future looking systems know, that this data is data that's meant to be shared and it can keep it appropriately, versus if it's not meant to be shared. They can copy it as a constant into the code when they see it's copied in, and just do all sorts of interesting optimizations to speed things up a lot. So when Vitalik brought these concerns, I was a little annoyed at the timing of it. But I think ultimately he's right, because if we want to make sure that these EVM contracts are very future proof, we need to put limitations on what can be shared outside of it and what can't. So if we knew how many times these contracts called Exe code copy and how big they were per transaction, we could gauge if the impact is going to be crippling to these contracts, or if it's just going to be a slight gas bump.
00:27:56.890 - 00:28:43.802, Speaker C: I think the truth is somewhere in the middle. I think it's going to be a bit of a gas bump, but I don't think it's going to make it impossible to call these in the ETH call type system with the gas limits, we'll still be under 15 million gas easy with these, which I think would be the gas limit for most of these systems. I think some of them actually have 50 million gas. So the cost imposed by having to read through a contract method, I don't think is going to be bad. But until we get actual numbers as to what these would look like, we really can't get a firm estimate on it. But as far as if we're wrong, we can always add ext data copy in, and future revisions of EOF in a compatible fashion. But if we put it in today, we basically can never take it out.
00:28:43.802 - 00:28:53.040, Speaker C: So that's one of the reasons why I'm biased towards not putting it on first pass to see if we can make it work out without it.
00:28:56.700 - 00:29:53.528, Speaker G: Yeah, it's interesting. I would say that for the most part, a lot of contracts will launch data contracts today. So they'll use s store to launch a contract that is writing into the code segment, large chunk up to pretty much the contract limit. And then from there, what will happen is a lot of these projects are like say, playing around with nfts and things like that. So the read method will stitch together multiple of these data contracts to then return back a result. So it would be something like a token uri call, and then you would see like, okay, essentially a series of Xcode copies to other contracts. That would be off the top of my head.
00:29:53.528 - 00:30:40.200, Speaker G: And then I think maybe a next step would be to try and figure out what kind of analytics we can get on this behavior. Maybe there's a way to look at the generated bytecode to just see who's calling Xcode copy. But from the top of my head, it would be generally used for marketplaces and exchanges along those terms. So you can imagine like Opensea probably will have a read call. It's a token URI, ever so often or wherever wallets want to sort of resolve this directly, et cetera.
00:30:41.340 - 00:31:26.896, Speaker C: So if you could get a copy of the ETH call RPC against Testnet or like Sapolia Goreli, I think that would be the best thing of one of the larger contracts, one of the more bigger ones. But as far as launching these data contracts, create three and create four have support for that built in. Because you say, I'm going to deploy this contract and it's going to be the little stub that says here's the read method. And then you provide auxiliary data at the time you call create three. So you don't know your auxiliary data at the time you create the subcontract. But when you actually invoke create three, you will know this auxiliary data, and that's where they can load in their data into these data contracts up to the limit. So I think the current definition still supports this use case where you create a large data known only at transaction time and deploy that contract.
00:31:26.896 - 00:32:04.470, Speaker C: It's just that data would go into the auxiliary data part of the create three and the create four calls. So it would be appended to the code that would do the ext get and stuff, and then we would read from there so we can do arbitrary transaction time, data contract contents. I'm not concerned really much about that, but I would like to see if you could send a couple of the e calls of the contracts of some of the larger ones doing these. I think that would answer a lot of the questions about the actual overhead of charging another 100 gas per ext code call is really what it would come down to.
00:32:06.040 - 00:32:51.440, Speaker G: Okay, yeah, I think that that makes sense, as long as there's some sort of provision. Is there any sort of docs on create three, create four? So I can shuffle that back to the various groups and stakeholders that are interested in these data contracts. And we can kind of stay, I guess, on top of it, for lack of a better word, or start to build the test harnesses. Because as platforms are sort of using this to launch future contracts, it's kind of important for all of us to be able to change with the times or at least pick the tires.
00:32:51.780 - 00:32:57.348, Speaker C: Create three, create four are in the mega EOf spec. Not every client's implemented it yet, so.
00:32:57.354 - 00:32:58.068, Speaker F: It'S going to be harder to get.
00:32:58.074 - 00:33:18.190, Speaker C: The test harnesses out. That's the step we're at right now is getting the clients to implement these specific instructions. I thought I'd have done by now, but I got too many interruptions. I think EVM one has it, so you could probably test against them. I don't know if there's guest code yet or nethermind code yet.
00:33:21.150 - 00:34:03.206, Speaker G: Okay, cool. Does anyone have a link for EVM one? And then I think that would pretty much answer it and just the takeaways. So that way I make sure that I've got everything covered. We'd be looking for to make Eve call RPCs with the larger contracts that are stitching together data. And then I guess what kind of format would you want? Would you want like a markdown of the results and how you could call it so you could observe it?
00:34:03.388 - 00:34:18.380, Speaker C: Markdown would be fine. And probably all I would really need is just to know which contract it is, what some of the interesting inputs are for some of the NFTs that they're looking at. I could probably tease some of the NFT data out of OpenSea if I just know which one of these contracts it is.
00:34:18.830 - 00:34:19.290, Speaker B: Okay.
00:34:19.360 - 00:34:34.160, Speaker G: Yeah, I can do like I'll ping out math castles and try and coordinate with art blocks. I think Perb hat may have some connection there and then see what's up.
00:34:40.470 - 00:34:42.020, Speaker B: Yeah, that sounds awesome.
00:34:43.750 - 00:34:58.646, Speaker F: Could I ask just one quick clarifying question here that's related to this? That's been a little bit unclear to me from the specs that I've seen so far, and maybe it's in this mega spec and I just am too dense this morning and quickly trying to read it.
00:34:58.828 - 00:34:59.960, Speaker B: Yeah, go ahead.
00:35:02.430 - 00:35:43.506, Speaker F: In the long run, I think our outlook at our blocks is like, we're going to have to update our storage contracts to be conformant with UF spec, et cetera. I think the part that's been unclear to me is the behavior for it sounds like legacy contracts being able to use legacy operations to interact with other legacy contracts will still exist. Legacy contracts can't create new contracts. New contracts can't create legacy contracts. That makes sense. Will new contracts be able to read legacy information or is that part still kind of unclear?
00:35:43.698 - 00:35:49.190, Speaker B: I don't know if I misheard you, but legacy contracts will continue to be able to create legacy contracts.
00:35:52.190 - 00:36:03.310, Speaker C: Sorry, I don't think new contracts will be able to exe code copy out of legacy contracts. I think that's one opcode we're also removing at the initial launch.
00:36:04.050 - 00:36:10.186, Speaker B: Wait, are you saying that legacy contracts deployed by legacy contracts will no longer be able to xcode copy?
00:36:10.378 - 00:36:18.450, Speaker C: No new contracts? EOF contracts won't be able to read legacy contract byte streams?
00:36:18.950 - 00:36:19.700, Speaker B: Correct.
00:36:20.390 - 00:36:21.186, Speaker C: Okay.
00:36:21.368 - 00:36:37.880, Speaker F: Is there any pattern there that is suggested as to how to make that possible, or is that just expected, a necessary kind of hard breaking case?
00:36:40.010 - 00:37:17.886, Speaker C: So that's kind of a necessary hard breaking case, but there's escape hatches you could do. You could write a helper contract that you would pass in the arguments for an ext code copy and all this helper contract would do. It would call from EOF. It would call into a legacy contract. That legacy contract would have Exe code copy and you would tell it which to copy from and bring it back. So you can kind of do an indirection to get there from the legacy contracts. If you really need an escape hatch and it's this pattern is why we're banning delegate calls from EOF calls into legacy calls.
00:37:17.886 - 00:38:15.926, Speaker C: Because if you delegate call into this escape utility, you can have this escape utility then call self destruct, which is something we're trying to totally keep out of EOF's consideration right now. So the direct call and you can get the external observable effects and not affect your own storage. That escape hatch is fine, but escape calls that will change your storage based on legacy rules is what we're trying to avoid. So I guess the pattern is maybe we could standardize a specific escape hatch contract in one location on the chain that you could call these if this becomes critical. But I think with forward planning, a better practice might be when you do these data contracts to always put in a little stub that will serve up its data. So you can just call the data contract, call the input method in the data stub that says, hey, serve me up this block of data and it'll return it to you in the return data. Oh, I see.
00:38:15.948 - 00:38:31.366, Speaker F: So that will be okay. So like EOF contract calling a legacy contract that then internally calls ext copy from a different legacy contract, that will be okay, right?
00:38:31.488 - 00:38:39.310, Speaker C: As long as the contract code executing is legacy, you have full access all the legacy codes, assuming you're targeting another legacy contract.
00:38:39.730 - 00:38:40.286, Speaker B: Okay.
00:38:40.388 - 00:39:03.878, Speaker F: Yeah, I think then maybe it depends on how people are using things like SSDR two. But I would imagine the common SSD two case is covered for most folks who are deploying that as who are using that because you have the read methods there that you're interfacing with. You're not interfacing with doing code copies directly. So.
00:39:03.964 - 00:39:04.406, Speaker C: Cool.
00:39:04.508 - 00:39:10.650, Speaker F: That makes sense and is reassuring to hear. I think that part has been a little bit unclear to me, so thank you.
00:39:10.720 - 00:39:12.650, Speaker B: Okay, Zane.
00:39:13.070 - 00:39:53.910, Speaker G: Yeah. So for that pattern, your suggestion is that we launch a legacy contract proxy that could probably take in any of our legacy contract addresses and let's say a range, and then that will then call out any of our xcode copy data that we need. So that way we can then access that data via method call to that legacy contract. Otherwise you would be stuck in the water without, let's say, a proxy to call from an EOF contract.
00:39:59.060 - 00:40:23.930, Speaker C: Right. The whole two systems at once is a pain point. And I think that's the solution, as you would call into the legacy that is designed to help you with the pain point, which in this case is ext code copy. It's just there are certain ones that we can't do. Like we can't let you self destruct your EOf code, so we won't let you delegate call into these. But a standard call or a static call, that should be fun.
00:40:27.620 - 00:40:29.090, Speaker G: Awesome. Thanks.
00:40:31.220 - 00:41:11.100, Speaker B: Yeah, thanks a lot, Zane and perpat, for being here and asking some questions. Appreciate you guys keeping up with what's going on on Eof. I do want to try and move to some testing stuff. Is there any last comments related to spec updates? Okay, let's move on to testing. Any testing updates, questions since we last spoke?
00:41:14.670 - 00:41:52.340, Speaker G: Yeah, from testing, there are two requests. They have been rewarded in order to use a new UF validation format. This way, it is reducing the amount of test files and making it clear the reason of the UF validation failure. So, yeah, I think they need to be reviewed, but, yeah, it is now less willing to review now hope.
00:41:57.130 - 00:42:20.090, Speaker B: Okay, cool. Sounds good if you get anyone had trouble hearing him. Hugo, you were a little echoey. Sounds like there's two prs that have been reworked a bit into the testing repo, and that's been finished over the last two weeks. And now it looks like those things are just waiting for review to finally go in. Any other testing updates.
00:42:23.150 - 00:42:37.620, Speaker A: From the Python test? Suddenly there's no news. We've been focusing on 48 four at the moment, but we will spend some time in the next couple of weeks to finally get into updating the EF tests for the biome test.
00:42:38.710 - 00:43:08.200, Speaker B: Okay, great. Yeah, I hear that's a pretty big eap, so makes sense. Cool. Other testing updates? Okay, that's pretty much everything we have on agenda? Are there any other things that we didn't cover that people feel like we should chat about?
00:43:17.820 - 00:43:26.140, Speaker F: All right, one more quick question. Is 35, 40 still being targeted for the next hard fork?
00:43:28.960 - 00:44:07.640, Speaker B: What is the official status? I think right now it's considered for inclusion, but they've created another level of acceptance. And 4844, for instance, is accepted to Cancun, whereas EOF is only considered for inclusion. So it's still something that people are trying to make happen. But I think personally I think it's more likely for the following fork. But yeah, people were still working on it and trying to have it ready. You never know what can happen. It might make sense to put it in this fork.
00:44:07.980 - 00:44:08.730, Speaker D: Yeah.
00:44:09.180 - 00:44:28.670, Speaker F: Is the smart or correct thing for client applications to do to be working on implementing EOF compatible solutions, et cetera, but to wait to deploy those until after the hard fork, that seems right to me.
00:44:29.040 - 00:44:58.392, Speaker B: Yeah, I would definitely say that's the right path. I think the right path also is like being here and engaging at this time because we want to build these changes so that they are supportive, as supportive as we can of developers who are building things. And it's useful to have this kind of input. So I appreciate you guys providing some of that, but yeah, I wouldn't deploy anything until it's accepted into a hard fork. And the spec is like, it's pretty clear this is what is going to change. Cool.
00:44:58.446 - 00:45:15.470, Speaker F: Okay, that's what I figured, but I appreciate the confirmation there. Yeah, we'll just say from our blocks perspective, definitely want to make sure we're managing this transition correctly. But also having a spec for how to correctly use on chain storage contracts is very exciting. So I'm really happy this work is happening.
00:45:16.580 - 00:45:33.380, Speaker B: Great. Okay, we got twelve minutes left. Let's talk a little bit about 4337 and the banning of code introspection or, sorry, of gas observability. Have you thought more about this at all, Alex?
00:45:39.270 - 00:45:53.400, Speaker A: Yeah, unfortunately I didn't really have time in the past two weeks, so no real progress. I'm not sure if anybody else had any time to think about it.
00:45:53.770 - 00:46:29.300, Speaker C: So I did have some thoughts about it. So there's two worlds we need to worry about. One is the mixed legacy Eof world and the other is the Eof only world. In the mixed EOF legacy world, if EOF doesn't have gas observability, that's not a problem because you will write all of your bundlers to run in legacy and the first thing they'll do is they'll call EOF code. We intend to have legacy be able to call anything directly in EOf code. We don't anticipate any bumps. We'll probably smooth down any bumps if we find them.
00:46:29.300 - 00:47:25.620, Speaker C: So today on main net, the bundler should just continue to work as is. Where things get trickier is in chains, layer twos, where it's eof two only. And I think that's a bit further down the road. And my thought is the future I'm hoping for is that account abstraction will be a thing that will be built in locally to the chain, rather than what is basically a second class hacked contract to emulate a feature that belongs in the protocol. Now the upside of this approach is we're socializing and standardizing the whole user operation binaries, and we're proving market acceptance and market usage of this. So when account abstraction is brought in at the protocol level, there will be existing demand and usage, and it will work much smoother. And I think it addresses the whole chicken and egg problem the way it's working right now.
00:47:25.620 - 00:48:02.910, Speaker C: My thought is if it's going to be a protocol level acceptance, that that will be the long term EOF only chain rule, is that it has to be done at a protocol level. And I don't know if that's acceptable to the 43 37 crowd or not if that's part of the vision, but I honestly don't see how we can enforce gas limits with subcalls and gain the advantages that we want to gain out of banning gas observability. I think it's a really hard problem to solve that. I don't know. There's a good answer for without protocol integration.
00:48:05.270 - 00:48:07.490, Speaker B: Thanks for that, Dano. Alex?
00:48:10.710 - 00:48:20.600, Speaker A: Yeah, I just wanted some clarification. Dano. When you said that they can just use the legacy stuff, did you mean that the legacy code going to create EOf code?
00:48:23.320 - 00:48:35.480, Speaker C: That is the trick, yeah. Legacy code would need to be able to deploy an EOF contract via a user operation. So that's one of the reasons.
00:48:37.020 - 00:48:40.136, Speaker B: Is that for wallet creation? Right.
00:48:40.158 - 00:48:41.960, Speaker C: What if you want an eof two wallet?
00:48:43.740 - 00:49:05.040, Speaker B: Can't you just have another Eof contract? That maybe is like permission? It can only be called by the entry point contract, and the entry point contract would call that. I guess it would be slightly different because your contract creation would rely on that address versus the entry point contract. But I think it could be like a small addition to the current contract architecture.
00:49:05.540 - 00:49:32.680, Speaker C: And I think that's also why I wanted to move to referring to create four contracts by hash instead of by index. So it's a bit easier to bundle. So if you need to combine the contracts and move them around, or let's say you're bundling up a bunch of contracts that are all creating the same contract, you could refer to it by hash rather than by index. It costs more bytes in the bytecode to do it, but it provides the ultimate flexibility.
00:49:36.240 - 00:49:36.990, Speaker B: But.
00:49:39.200 - 00:50:27.260, Speaker A: I don't think this fixes anything because either you have the user having the ability to submit random code, right? And then either you go the legacy route where you can limit gas but the code is going to be observable. Or even if you have like an UF proxy which creates it, ultimately I think you lose. Yeah, I guess the point is that you can limit the gas from legacy when you call the UF proxy, right? That's the trick, yes. Yeah, I guess that works.
00:50:30.750 - 00:51:06.840, Speaker B: Okay, so it seems like 457 will continue to work in these chains that have both the legacy context and UF context modulo some maybe minor changes and additions. The big concern is these worlds where you have no legacy context. There's no gas preservability in the entire execution layer. And I guess right now the only real proposal for dealing with this is saying just that this should exist at the protocol layer. Right.
00:51:08.010 - 00:51:41.810, Speaker C: And this, I think is also another reason why I think we should have different opcodes for call, delegate call and static call. We're going to take the gas out because if we get it wrong and we decide the solution is we need to return gas observability, we can't just change the call semantics of those three operations. So making like a call to a delegate call to or static call two or the call x with the immediate that sets the modes. If we put that in a different place and we figure out things don't work and we need to return the observability, we could just return the existing opcodes.
00:51:54.200 - 00:53:03.104, Speaker B: Any other thoughts on four, three, seven and eof? I guess it's something to just continue keeping in the back of our minds as we go forward because I know that that's going to be a question that comes up as we move closer to becoming accepted for a fork. But we still got some time, so let's just let that simmer a little bit. Five minutes left. Any final comments, topics to chat about? Okay guys, let's call it. Thanks for coming. We'll talk again in two weeks. I'll set up the agenda issue and yeah, talk in EVM channel.
00:53:03.104 - 00:53:06.210, Speaker B: In the meantime, have a good rest of your day.
00:53:08.340 - 00:53:08.944, Speaker C: Thanks.
00:53:09.062 - 00:53:09.744, Speaker A: Thank you.
00:53:09.862 - 00:53:10.270, Speaker B: Thank you.

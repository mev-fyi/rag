00:00:02.970 - 00:00:43.530, Speaker A: Hello. All right, welcome to vertical implementers call number twelve. This is issue nine 50 in the pm repo. Let me share the agenda quickly. In the chat here today we have, I believe five agenda items, six, sorry, six it starting off with client team updates, we have some testnet updates. We also have EIP 2935 block hash some updates there. Guillaume recently opened a new EIP for the state transition method.
00:00:43.530 - 00:01:01.200, Speaker A: There is a proposal for code packaging in Verkel and then assuming we have time and we can get through all this quickly, some testing team updates at the end and I think that's it. Cool. Client team updates. Would anyone like to go first?
00:01:11.240 - 00:01:30.410, Speaker B: I think I can give a quick update from Nanimai. So there is no big changes, just we tried to join the testnet and we found out a few issues and the same time trying to rebase changes on the Denco updates and yeah, that's it.
00:01:34.020 - 00:02:48.840, Speaker C: On ethereum JS side. So we were also able to join the Testnet and we were able to sync up till some 478 block and we sort of ran through issues on 479 block and even before that we ran through some issues which we discussed and debugged and sort of applied some patch to sync through constant info. But currently I think we would need the new network launch so that basically we can execute stateless on the witnesses which are missing in the current testnet and without which will not be able to execute further. With regard to block hash, Joham has sort of completed the block hash implementation and we'll be able to use it currently. Basically in the current syncing we were not resolving block hash properly as well. So that could also be the reason that we might not be able to execute few of the blocks of this particular testnet.
00:02:55.750 - 00:04:06.780, Speaker D: Update from the Nimbus team. So the last two weeks we put in some effort to optimize the deserialization function for Banderwagon base field points because it was pretty slow as compared to the go implementation after optimizing. Basically what we implemented is we implemented the dlog pre compute that is meant to be done for calculating square root of points, and turns out that currently, overall, the Nimbus cryptography library that is there in constantine is at least 19% faster than that we have at go. And from the integration perspective, we are almost done with the stateless primitive testing that is like inconsistency with the go implementation and we have come to a conclusion that we can start off integrating into Costian via the Nimbus execution client first. So we are currently looking into that that is pretty much the update from the Nimbus side.
00:04:14.200 - 00:04:56.900, Speaker E: For Bessu. Karim from Besu has left a message to read here, so I'll just read it. We've made changes in Beso to connect to new testnet, Ganesis configuration, et cetera. I think there's a bug about next fork block in get. Already talked to Guillaume about that. EIP 29 35 has been implemented allowing the storage of block hash history in the state gas cost modification for worker are still in progress. There are some bugs but we managed to import more blocks with contact creations and transfers.
00:04:56.900 - 00:05:31.900, Speaker E: We've also been able to fix rollback bugs in Beso important to manage reorgs. We also need to focus a lot on performance, but that's in the coming week weeks. So regarding that, we need to change the tree to compute sparsely, update the commitment not to recompute all the 256 values every time something is needed to change in the tree. So that's next for the performance.
00:05:38.950 - 00:06:24.430, Speaker B: Yeah, we have been working mostly to help other clients join the testnet. So indeed, like people already mentioned, there's a few bugs that have been uncovered, so that's good. None of them will be fixed for this instance of the testnet because it doesn't look very critical. I mean you can work around it and we can keep looking for bugs. So that's the way that seems the simplest at the moment. Otherwise we did a lot of specking. We wrote some changes for the EIP 4762, the gas cost EIP.
00:06:24.430 - 00:07:35.800, Speaker B: There's been a complete redesign of EIP 29 35 and I also created a first EIP to describe the transition, but I will cover that later. And yeah, we also worked on testing tools, so we hit a few roadblocks, but I just pushed a couple of fixes this morning and otherwise Ignacio has worked on reactivating the replay so that we can produce data from the current height of the chain. See if we can well first confirm that we have something that works with a more modern payload, like real payload, and also do more performance testing, check the size of proofs, et cetera, et cetera. There's been a bit of rework for the shadow fork code, but yeah, no bug fix, just some preparatory work and yeah, that's it.
00:07:46.820 - 00:07:53.250, Speaker F: Just to extend a bit on that update. And I won't get into the details because I think this is the next.
00:07:54.500 - 00:07:55.360, Speaker B: Jack.
00:07:59.140 - 00:08:00.060, Speaker F: For my problem.
00:08:00.150 - 00:08:04.550, Speaker G: Yeah, it's about 500k probably.
00:08:07.160 - 00:08:07.908, Speaker B: Okay.
00:08:08.074 - 00:09:52.870, Speaker F: So yeah, we kind of fixed some bugs that we probably will run in the next testnet. I think most people here already know about that, but I will just quickly mention there was like a bug for 25 three five that Kachina found regarding an undersized effect of EAP one five eight deleting stuff from the block history contract that we created. He also found some other bug regarding not recording witnessed data correctly for addresses that were, let's say, smaller than 20 bytes. Also Danish found some other bugs regarding some upcodes that were recording witness accesses such as balance and external call hash. So I fixed that too. And as Guillaume said, we are now able to replay at this moment 5 million blocks in importing a chain with Deborah tree sheet. And that allow us to find a really nasty path that caused like an integer flow, which caused an infinite loop, which caused an out of memory problem, which is one of the reasons why we like replaying these long chains because this happened like 4 million blocks after start.
00:09:52.870 - 00:10:22.290, Speaker F: So it's a bit of a nerve wracking kind of flag because an infinite loop is pretty bad, but that simply means that we have to do some extra work in testing. And this is kind of the bugs that are found with some passing and also the fact that go doesn't panic whenever you underflow or overflow. There are other languages that are much safer on that regard, but yeah, just saying that.
00:10:38.490 - 00:10:51.440, Speaker A: Cool. Any other updates? If not, next up, the testnet relaunch eom.
00:10:53.640 - 00:12:00.330, Speaker B: Yeah, so I would like to bring your attention that now, Barnabas, every time there's a new testnet, relaunch produces. So I'm sharing my screen, I don't know if you guys see it produces a spec for the testnet. So we have one active where all the bugs are currently described. So there's the block number. So most of them have already been mentioned by everybody affected really. Typically when we find a testnet, when we find a bug on the testnet, we will try to update the spec sheets to specify if it got fixed after, if we decide to fix the bug and continue, or if we just decide to wait for the relaunch. So so far all the bugs have been estimated to not require a relaunch, but since they're accumulating at some point, we will try to do this.
00:12:00.330 - 00:12:31.696, Speaker B: But yeah, one thing I forgot to mention. So we launched Devnet three last week, but we found already some bugs, so we fixed them and we relaunched after a couple of days. So number four, number four is going strong so far. So this is good. Yeah. So I just wanted to mention that, so if you have any questions or if you find any bug, go there first. Tanish has found the bug with self destruct, or at least thinks there's a bug.
00:12:31.696 - 00:13:11.170, Speaker B: We are still investigating the last one we know of, and there's also the one that's not mentioned here that Karim described. It seems that guess is sending the wrong fork next fork value, namely that it sends Prague instead of sending zero when Prague should actually already be active. But yeah, these things, you can work around them. So currently we don't fix them. I mean, we will fix them before the relaunch, but yeah, it doesn't seem to be a showstopper for now. So, yeah, that's pretty much it for that.
00:13:19.560 - 00:13:20.980, Speaker A: Yeah. Barnabas.
00:13:21.480 - 00:14:06.150, Speaker H: I would also like to mention that Curtis is now capable of doing shadow forks out of the box. So there's a way where you can test your el or Cl implementation whether it will go through the Holosky fork transition using a state that was taken before Dankoon. So this is a state that is pre dankoon, and the state is about 16gb. So it will take some time to download the state. But we offer it in an s three bucket and should be great if different client teams would be able to start using this and start testing it.
00:14:11.170 - 00:14:33.750, Speaker B: Yeah, so just to add to this. So I did start using it this morning. Works really well. And guest immediately dies immediately, like after a dozen blocks. But yeah, to run it, you need to be able to support the transition. But yeah, if you want to try to join that, that's extremely useful as well. Indeed.
00:14:35.690 - 00:14:38.120, Speaker H: You mean it dies before Electra is hit?
00:14:38.830 - 00:14:47.420, Speaker B: It dies before, I don't know, the transition starts and then it dies. It produces a block that it can't reinsert in itself.
00:14:51.390 - 00:14:57.920, Speaker H: And if you find any bugs, just create an issue or let me know because I can quickly fix it.
00:15:08.690 - 00:15:20.130, Speaker A: Cool. Okay, next up, some updates on the implementation of EIP 2935. Gajinder.
00:15:28.760 - 00:16:45.924, Speaker C: Thanks, Josh. So basically we had discussion with Tanish and we basically came to a simplification in which what we are doing is we are writing the entire. So whenever there is a fork block, the first block of the fork, we are persisting whatever required history is needed for that block to execute. So basically last 256 block hashes in the slot. And basically this solves the problem that it simplifies and solves the problem that, okay, we don't need to detect the fork height anymore. With just one access to the slot, one can figure out, okay, whether you have the block hash or not. So basically, if you look at the EIP, there is a pseudocode that basically at the start of the block you insert the parent hash of the block into the slot.
00:16:45.924 - 00:18:08.404, Speaker C: And if this is the first block of the frok, then basically you insert extra 255 years and the way you resolve it. So you can now switch the resolution of block hash directly on the first fork of the block itself to just doing a lookup in the state for that particular slot. And if you note that now, basically you can have a lookup on a bigger range which is basically the entire max history server window, which is basically all the slots that are there. So earlier you could only look for 256, last 256 blocks, but with this EIP update you will be able to look at the entire range. Whatever is there, the wraparound happens. So then there is a question regarding wraparound and that is basically what is the size of the block number? Because slot size is 256 bits and the block number is 64 bit as per my understanding as of now. So ARG is going to be of the same size.
00:18:08.404 - 00:18:30.670, Speaker C: So question is whether we take care. We basically consider that there is a wraparound that is going to happen or maybe in future when the block number size could be increased, then basically we add in this condition. So thoughts and comments are invited on this.
00:18:43.870 - 00:18:50.080, Speaker B: Sorry, there's something I didn't quite get. So you said the wraparound is going to happen at 64 bits, right?
00:18:53.010 - 00:19:16.600, Speaker C: No, wraparound will happen at 256 bits only. But our current block number size, I think is 64 bits, right. I'm not sure how that situation will pan out. Whether before we come to this situation we might increase the size of block number. I'm not sure how that is going to happen.
00:19:18.090 - 00:19:46.320, Speaker B: Yeah, I think we have for a couple of million years before that happens. I would have to write the math down. But if I'm not mistaken, we're going to be fine for a long time. The wraparound would be 256. I think we're fine. Right. Because that's more time than is left in the life of the universe, I think.
00:19:46.320 - 00:19:50.900, Speaker B: Yeah, exactly. That's a lot of time.
00:19:53.910 - 00:19:54.274, Speaker A: Yeah.
00:19:54.312 - 00:20:18.460, Speaker C: So basically maybe we can then move the wraparound condition itself that basically checks. So the condition before we actually look into the block is that the arc has to be, arc has to be less than block number and obviously it should not be wrap around. Should not be wrapping around. So maybe we can remove the wrapping around check.
00:20:19.310 - 00:20:34.160, Speaker B: But actually, no, I was just thinking because, yeah, realistically it will not happen, but you have to check the lower bound because yes, it will wrap around if you start asking for a negative block. Right. And that should be maybe what the check is about.
00:20:41.110 - 00:20:54.798, Speaker C: Okay, maybe we can. Yeah, we can check for the negative block and basically check that arc is if your arg is less than. So arc cannot be negative because the input arc is uint.
00:20:54.834 - 00:20:55.082, Speaker I: Right.
00:20:55.136 - 00:20:58.300, Speaker C: So I'm not sure how we'll get a negative arc anyway.
00:20:59.630 - 00:21:04.060, Speaker B: Okay. Yeah, I guess we just need to continue talking offline. Thanks.
00:21:16.110 - 00:21:26.350, Speaker A: Okay, next up we have an EIP for the base. EIP for the state transition method. Guillaume.
00:21:28.610 - 00:21:59.986, Speaker B: Right. So last time I made a suggestion to have a less ambitious fork. And is that the right window? Yes. So I created an EIP for that. And I'm aware that, yes, there's been a lot of pushback, so that's understood. And I also won't seek to push this any further. However, I still wanted to create the ip for two reasons.
00:21:59.986 - 00:23:28.530, Speaker B: The first one is because that's a first, let's say that can be used as a base to be extended to create the full fledged EIP, which I'm currently working on. But I need to keep learning a bit more about how eels is built because presumably we would use their terminology to describe the EIP. But so before I do this, I was like, I'm going to take the common denominator, which is basically this EIP, because this EIP is the first step that you can then extend with the full fledged transition. And the EIP number is 70 612. I just meant to have this EIP, like I said, as a base for the next EIP that's coming, but also in case during development we change our minds, we say no, actually doing just the overlay tree and taking care of the conversion later makes more sense at this time, then we have any ip to fall back to. But like I said, it's not something I'm pushing for at the moment. But yeah, if you could just have a look and give some feedback, if you can, that would be really appreciated because it's going to help with the next step, which is the full conversion EIP.
00:23:42.380 - 00:23:58.830, Speaker A: Cool. All right, next up we have a proposal for code packaging that I believe Pavel Guillaume and a few others have been working on. Pavel, did you want to start with? Any thoughts there?
00:24:04.720 - 00:24:06.364, Speaker B: I don't see him in the.
00:24:06.482 - 00:24:07.516, Speaker A: Is he not here?
00:24:07.618 - 00:24:09.470, Speaker B: No, I don't think he got the.
00:24:11.840 - 00:24:12.872, Speaker A: Maybe you.
00:24:13.026 - 00:24:58.000, Speaker B: Next week, I guess. Yeah. I wouldn't be able to present it, but the idea was that there was a couple of ideas that were quite interesting. I would prefer him to present it, but the idea was to do some packaging of do the packaging differently, namely that you would have chunks of 32 bytes and then you would have a map that says for each block, for each chunk that starts with push data, that map would tell you, okay, this is where it starts. And yeah, it has a few interesting ideas. So I encourage people to go have a look. Clearly it's EOf based.
00:24:58.000 - 00:25:22.090, Speaker B: We could also implement those ideas without EOf. Or more exactly, to prepare to pave the way for Eof. I had a couple of questions for Pavel myself, so I really don't want to be the one presenting this, but I think it's quite mean. I think everybody should have a look and try to come up with questions for Pavel next time.
00:25:36.870 - 00:25:45.880, Speaker A: Cool. Okay, then we can move on to testing team updates. Mario, are you around?
00:25:46.810 - 00:25:48.982, Speaker I: Yes, I'm here. Can you guys hear me?
00:25:49.116 - 00:25:49.800, Speaker A: Perfect.
00:25:50.650 - 00:26:44.740, Speaker I: Yeah, so we've been doing some implementations and changes to the execution spec test repo that we have to accommodate for Berkele. So far we've started with the very basics, which is the transition tool, support changes that we need for Berkele, which is the tool that we use from Geth to fill every single one of our tests. And we've been working with Galam to make this possible. It's still a work in progress, so we at the moment are not able to generate any tests, but when we do, I have some suggestions and I wanted to just share them here to make sure that we are on the right track. So this is very subtle, but I wanted to share my screen. I don't think I can. No.
00:26:45.190 - 00:27:00.960, Speaker A: Yes sir. Give me 1 second. Yeah, it's sharing my screen. Second. Sorry.
00:27:10.060 - 00:27:14.996, Speaker I: If it's not possible, it's very little information. I can just update.
00:27:15.108 - 00:27:29.152, Speaker A: Yeah, if you just give me, up to you, but if you give me 1 second, should be able to. I'm trying to find this toggle. Oh, sorry. Here you go. Sorry about that. You should be good now.
00:27:29.206 - 00:28:27.582, Speaker I: Yeah, I can see it now. Perfect. Okay, so can you see my screen? Okay, so, yeah, basically we have this definition of forks in the execution spectrum. So we started with this, assuming that the current implementation, Berkeley, is on top of Prague, and Prague is not on top of Cancun, but it's on top of Shanghai. This is what we define. So we have two important forks defined, and one is the straightforward Prague, and the other one is, I think more important is the Shanghai to Prague Berkeley transition. So these are the two forks that we plan on using to implement all of the Berkele tests and the main difference between them, and I think most of these will have to implement something in their genesis parsing tool to be able to consume our tests.
00:28:27.582 - 00:29:08.750, Speaker I: But the first one is Prague. When we start with the genesis, that will have Prague activated with Berkele. And the purpose of this is just simply from the bidder genesis. We provide a pre allocation for all of our tests. And the idea here is that the clients consume this pre allocation for the test and it will go straight to the vertical tree. I think this first approach is just to make sure that everything works. I mean, all our tests that we implement, they make the proper modifications to the Berkeley when we have already fully converted to Berkeley.
00:29:08.750 - 00:30:16.910, Speaker I: And this more interesting one is the Shanghai to Prague Berkeley transition, which is basically just, we start with Shanghai or whatever previous fork we are forking to Berkele, and then on the first block we fork to the Berkele transition. What this will allow us to test is that we have agensis that defines the pre allocation to all of the state accounts. That, for example, we use the smart contracts that we use to test every single one of our tests. We start with that on the genesis, but the genesis is pre Berkele. So we will start with the MPT tree, and then on the first block we will go to Berkele. And I think this is very interesting because it will allow us to start with the MPT, with all our accounts. And then on the first block we start sending the transactions that the tests that we write and that we have written already all do the execution when we are already converting to Berkeley.
00:30:16.910 - 00:31:11.394, Speaker I: Not necessarily converting, but also on the overlay tree. That will be very interesting to test. Another good thing about this is that we have implemented this feature on our repo that would allow us to not only produce a pre allocation with the things that we need, but we also can feed the MPT to have a lot of information, not random, but maybe we can design some interesting patterns for the conversion or for the overly tree that we can inject into the MPT. So we can test this in a regression fashion instead of having to, for example, shelf ork into something. We can first test here with a big MPT, with a special pattern, and then we can proceed to the shelf forks and more.
00:31:11.432 - 00:31:12.020, Speaker A: So.
00:31:13.210 - 00:31:40.480, Speaker I: But yeah, the problem is that this still doesn't work. We're working on it, but yeah, this is basically the main idea of how we are thinking on filling the tests at the moment. And yeah, I would love to hear if you guys have any doubts or maybe this doesn't sound reasonable or anything. Yeah.
00:31:44.530 - 00:31:57.978, Speaker B: I have a couple of questions. So one of them is. What is this interface you showed us? Is it like some tool of yours, or is it something I don't recognize?
00:31:58.174 - 00:32:32.720, Speaker I: Yeah, sorry, let me share again. This is the documentation of the execution spec test. So we have, this is basically the site that renders all of the commutation for tests. It contains the definition for all the forks that we use to test and also the fixture formats that we produce. So right now we produce three fixture formats. So the state test, the blockchain test, and the blockchain hype test. So I think we can feel using.
00:32:32.720 - 00:32:55.590, Speaker I: I mean, for the Berkele tree tests, we can feel the tree fixture formats and we can run them in different ways. I think for Berkeley transition only, blockchain tests and blockchain hype tests are interesting because Satast wouldn't be able to do the conversion at any point. But yeah, these are the two interesting ones for Berkeley.
00:32:56.250 - 00:33:21.520, Speaker B: Would it be possible when we start adding more clients? I assume clients could already join the first batches of tests, right, the one without the conversion. Would it be possible to somehow run all those clients that are available nightly and produce a result, like show a page where each client is so that we can keep track?
00:33:22.290 - 00:33:52.150, Speaker I: Yeah. So I think we can do this with, the way that we do it is for Cancun. We have the high view renderer, so we run all the cancun tests on loop every night, and this page just keeps updating. We can do a similar page once we are able to generate the hype. The blockchain hype, that's this one I think we can run on loop for Berkele with all the clients the same way that we do now for concur.
00:33:54.270 - 00:34:21.620, Speaker B: Cool. And I had another question that's related to the question I asked you on telegram. So in order to perform the conversion, I need a snapshot. So the question is, well, you said you wouldn't really be able to pass the snapshot. That's fine, I could regenerate it. The question is, how much time do we have to run those? Like, is there a timeout for these tests to run?
00:34:22.390 - 00:35:07.070, Speaker I: Not at all. That was what I was thinking. So I think we can selectively generate this test, because I think it would be very intensive to start adding a lot of stuff that is necessary for reckle, but there's no timeout. But it might take a lot because this is Python, so it's not very efficient. But anyway, I think if we need to add it, it's possible we might just generate them more sporadically as compared with every pr. For example, right now we generate every single test with every pr. So right now I think we can lower that period and just make it so that Berkele tests are generated.
00:35:07.070 - 00:36:00.560, Speaker I: I don't know, maybe release or something, but it's not a problem. Regarding the timeout, that was basically it. Yeah. If you guys have any input or ideas on what we can do with testing, we have now a vertical branch which is out of date right now. I'm going to update this branch with. Let me just share the link. I will update this branch with the track precision tool updates that we're making, but this will be the branch that we will start adding Berkele tests and everything Berkeley related.
00:36:00.560 - 00:36:08.550, Speaker I: So just so you guys know. And yeah, that's basically it.
00:36:15.060 - 00:36:17.360, Speaker A: Awesome. Thank you, Mario.
00:36:18.420 - 00:36:19.152, Speaker I: Ok, cool.
00:36:19.206 - 00:36:26.500, Speaker A: I think we had a. Or we do have a last minute addition to the agenda from Kev. Kev.
00:36:28.360 - 00:36:57.710, Speaker G: Yeah, thanks for that. Sorry, my audio is a bit bad, essentially. I think me and Ignatio spoke about it a month or two ago. It's replacing the serialized method in Patterson hash for basically mapped a scalar field. I wanted to check if anyone's against that. And yeah, basically check if anyone's against it before making it consist of breaking things.
00:37:00.800 - 00:37:06.850, Speaker B: So. Wait, I didn't get it. So you want to remove all serializations and just use map to scalar field?
00:37:10.420 - 00:37:20.790, Speaker G: I wanted to remove the serialize method for map to scalar field. So you'd still return a 42 byte value. It's just that you wouldn't be using.
00:37:30.570 - 00:38:00.090, Speaker A: I think we lost you, Kev. He may not. Okay, got it. I dropped a link in the chat. I don't know if anyone else has any questions or thoughts on that. If not. All good.
00:38:03.260 - 00:38:03.672, Speaker C: Cool.
00:38:03.726 - 00:38:12.730, Speaker A: Well, we made it through all the agenda items ahead of time. Anyone have any last minute additions, thoughts, or we can just end there.
00:38:20.660 - 00:38:21.360, Speaker I: Cool.
00:38:21.510 - 00:38:28.788, Speaker A: Well, thank you everybody, and we will see you again in two weeks. Thanks, bye.

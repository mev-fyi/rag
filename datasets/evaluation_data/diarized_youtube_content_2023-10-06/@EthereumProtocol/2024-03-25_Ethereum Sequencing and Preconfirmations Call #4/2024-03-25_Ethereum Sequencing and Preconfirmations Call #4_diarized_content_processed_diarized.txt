00:00:00.320 - 00:00:39.634, Speaker A: Welcome, everyone, to the sequencing and preconfirmations, call number four. Today we have a special guest, Brendan from Polygon, who will be talking about topics which are extremely complementary, in my opinion, to shared sequencing and base sequencing, namely the topic of cross roll up bundle safety. So if you have a super transaction which involves multiple simple transactions on different sequencing environments, how do you make sure that they can all execute as a bundle? How do you make sure that you have safety without having to trust.
00:00:41.494 - 00:00:41.806, Speaker B: The.
00:00:41.830 - 00:01:54.326, Speaker A: Sequences or the sequencer in the case of one single shared sequencer? I think Brendan will also talk about gas optimizations, which are very much relevant as well in the context of synchronous composability, namely the idea of sharing deposits. So having one deposit contract for more than one roll up, this is also something that Zksync has been thinking a lot about. And this other kind of, maybe more obvious optimization, which is the idea of shared proofs. So if you have multiple roll ups that share the same proof system, well, you can aggregate proofs and you can also save gas there. Now, before we have Brenton on, I want to give a quick update on the base ecosystem. So, as I see it, we now have multiple rollups that have either committed to become a base roll up or excited about it. So we all know Taiko, of course, one, which is very new, and I've added two slides just now, is Coinbase, is building this minimal key value store as a base roll up.
00:01:54.326 - 00:02:37.782, Speaker A: This is one of the ideas from Vitalik, and maybe we could have a presentation dedicated to that in the future. We also had a sequencing day in London, which was very well attended, and I think we've made lots of progress. In particular, we made a little mini breakthrough. So Ben Fish came up with this really clever idea to basically encrypt blobs to make sure that when a blob goes on chain, it cannot be associated with any given roll up. And actually, that kind of really helps chains like Aztec that are sensitive to censorship. And so Aztec is now considering becoming a base roll up. And actually, next week we're going to have aztec talk about base roll ups and sensor resistance.
00:02:37.782 - 00:03:24.424, Speaker A: We also have rise, as I mentioned last time, which is a small roll up, planning to become a base roll up. Then we have this mystery, like one of the top roll ups in production today that is also looking into it. And then finally, while I was in London, I had chats with one of the ENS developers, and he was saying that they want to move to an l two, but they can't pick an ecosystem like arbitrum or optimism. And the reason is that they can't be in all the ecosystems at the same time. They have to pick one for the root of trust. And if they pick one, then they'll piss off everyone else. And so they have this very high demand for credible neutrality, which is why base sequencing is very attractive to them.
00:03:24.424 - 00:04:14.230, Speaker A: Now, in addition to these roll ups, we have various builders that are building infrastructure. And I think some of these builders behind the scenes, I've been having calls with some of you. You're really stepping up your game in terms of building infrastructure around shared sequencing, base sequencing pre conformations, all of that good stuff. Then one of the other ecosystem players that I added today for the slides is actually ag layer. Because again, this is infrastructure, which in my opinion is very complementary to this whole shed sequencing and base sequencing vision. So without further ado, I will give the floor to Brendan. We have a whole 55 minutes, so feel free to.
00:04:14.230 - 00:04:16.914, Speaker A: Is it okay if. Brendan, if we interrupt you with questions?
00:04:17.494 - 00:04:37.168, Speaker B: Yeah, yeah, please actually interrupt me with questions. So both. So the presentation should be like, I don't know, 20 to 40 minutes. That's a big airbar. But yeah, interrupt me while it's going. And then I've built in time to discuss after as well. Perfect.
00:04:37.216 - 00:04:55.524, Speaker A: And I think Brendan will try and make the presentation more technical so we can dive in pretty deep. And then after the hour, we have the usual half an hour off the record conversation. So with that. Brendan, go ahead.
00:04:56.984 - 00:05:41.492, Speaker B: All right. Sorry, guys, I just have to rejoin. So I assume permissions could get to the right back. Sorry.
00:05:41.588 - 00:06:07.614, Speaker A: Okay, perfect. I guess while we're waiting, there's going to be more sequencing days organized. So at EFCC, someone is organizing a sequencing day, I believe. And I think there will also be a sequencing day at Zubalin. So sequencing and becoming a hot topic. I'm actually not organizing either of these topics, I think. Chris, do you want to give the 1 minute pitch?
00:06:08.274 - 00:06:53.474, Speaker C: Sure. So some of you might know Susaloo, which was organized by some people around Vitalik, and where we brought together different ecosystems for kind of a co living experience in Montenegro. And then we had other spin outs of that Sukhonnet in Istanbul. And so after Berlin blockchain week in Berlin, we'll have a two week residency where we bring together blockchain researchers, but also AI people, neuroscience people, and kind of people just at the cutting edge of technology. And so it will be in June, from June 8 till 22nd, roughly 100 people living here in Berlin. The possibility is to stay there for a week or for two. And we'll have dedicated days for specific research topics around mechanism design based sequencing.
00:06:53.474 - 00:07:12.034, Speaker C: And yeah, they're aligning with Justin Drake, with Barnaby, a few other researchers to organize one day, which will be on these topics as well. And yeah, suberlin City is the website. Feel free to pre sign up there. And yeah, we'd love to see many of you there.
00:07:12.854 - 00:07:19.394, Speaker A: Thank you, Chris. And we'll also have a sequencing day with a different organizer at FCC. Brandon, the floor is yours.
00:07:20.554 - 00:07:48.254, Speaker B: Okay, can everyone see that? Yes. Cool. So, yeah, so I just like to go a bit into the aggregation layer. So there will be two parts. The first part is high level and not very technical. And then the second part is maybe a little bit technical. All right, so the background, I guess, some brief history of the ag layer.
00:07:48.254 - 00:08:58.298, Speaker B: It arose from this problem that we had in Polygon that was very much a strategic one. We were working on like a multi chain ecosystem, and we were wondering, how do we actually share network effects across many chains? So we had the POS chain, and it had a flourishing defi ecosystem. It had liquidity, and we wanted to launch a ZKVM roll up. And there was no real obvious way to actually share liquidity. And for the ZKVM roll up to benefit from what already existed on the PoS chain, we needed to think about bootstrapping liquidity and doing liquidity, mining incentives and airdrops and the same games that every l two does when they start in order to actually bootstrap an ecosystem on CQVM. We realized that this was actually a broader problem and a more structural problem for Ethereum, where it's actually very difficult for ethereum to accrue network effects from l two s. I think that the network effects tend to develop around specific l two s.
00:08:58.298 - 00:10:05.354, Speaker B: So Justin brought up this nice term that Vitalik used for this, like the idea of mini empires that sort of develop around individual ecosystems rather than around ethereum itself. I think that this is not like, this is something that's very familiar to the people on this call. But I think fragmentation is a problem in three senses. For users, it means increased complexity, because you have to navigate moving between chains and accessing applications that are on maybe different chains from where your funds are. Um, there's also a lack of safety involved here. Uh, so, like often this requires, uh, third party bridging, which doesn't offer the trust minimized, uh, guarantees that native bridging does. Um, for roll ups, um, for builders, there's this issue where uh, like if you are, um, like let's say that you're building something that's, that's really interesting and great.
00:10:05.354 - 00:11:08.496, Speaker B: It could be like a new defi primitive or um, like an NFT collection or a game. And you're really, really good at building whatever it is that you're passionate about and you're setting out to build. But the problem is, in order for you to be successful and launch your app chain or your l two, you not only need to succeed in building this thing that you have a comparative advantage in building, but you also need to succeed in bootstrapping your chain. So you need to, for your NFT collection, build a marketplace and bootstrap liquidity for that marketplace, actually develop a chain ecosystem, not just your individual application or this thing that you can actually have a comparative advantage in building. And finally, for Ethereum, this isn't great because network effects aren't shared. The success of an l two ecosystem is additive in some sense for Ethereum, but it's not maximally additive. Sort of.
00:11:08.496 - 00:11:53.334, Speaker B: We don't have this collaborative environment where token incentives for one l two benefit all l two s and benefit the entire ethereum ecosystem. And so I think it's not an ideal structural configuration for ethereum. Again, this is, I think, very familiar for everyone on this call, but the goal is to unify ethereum l two s. So by that I mean two things. So we need to enable low latency composability, both asynchronous and synchronous. I think Justin is much better at terminology than I am, and he called this like super intense. So basically intents that span multiple chains in a single bundle.
00:11:53.334 - 00:13:04.534, Speaker B: And moreover, you need to provide asset fungibility across chains. So if you're on one l two, you should be able to, in a very low latency way, like take your native ETH that's represented on that l two and bring that to another l two and get native ETH without necessarily going through the l one and paying the latency penalty. So in my mind, the technical barrier to this unification is like the reliance on going through ethereum in order to um, use the native bridge between two roll ups. So if we have like rollup a and rollup b, and let's say that they're both ck rollups. Like there are a number of latency components that lead to a bad ux for, for native bridging between these two chains. So if you think about what's required for me to take, like my ETH on polygon ZKVM and move it to Zksync or to Starknet. I need to submit a withdrawal transaction on chain A.
00:13:04.534 - 00:13:52.666, Speaker B: I need to wait for proof generation for the block that contains my withdrawal transaction. So this could take like two to three minutes and like a very fast and performant ZK roll up, it could take longer for others. I need to wait for like that batch to be submitted on l one. So right now I believe that the like the lowest latency for batch submission is about 30 minutes. Just to amortize the cost of proof verification on ethereum, I need to wait until the batch or the block that verifies my proof is finalized on ethereum and so that takes between twelve and 19 minutes. I then need to submit a deposit transaction to roll up b. That takes another twelve to 19 minutes for that block to finalize.
00:13:52.666 - 00:14:32.044, Speaker B: And so finally I receive tokens on b and all in. This ends up being a more than 25 minutes latency penalty for a cross roll up transaction via the native bridge. Obviously this is the best case in an optimistic roll up. If you're using the native bridge, it's obviously much worse. The AG layer is designed to solve this problem in conjunction with coordination infrastructure like shared sequencing. Um, I think it's important to emphasize what the ag layer is not. Uh, so it's not an l two, um, it's not a shared sequencer.
00:14:32.044 - 00:15:23.814, Speaker B: Uh, it's not just a proof aggregation service. Um, so I think we will talk about this later in the presentation. But um, I think there's this misconception that uh, you know, all that we're doing is aggregating validity proofs and uh, and that aggregating validity proofs gives the safety guarantee that we aim to provide. And that's not true. So when we talk about aggregation, we're actually talking about aggregating chains. So the ag layer, as I would describe it, is neutral public infrastructure that provides safety for asynchronous and synchronous cross chain interoperability and a shared bridge. So again, aiming to satisfy these two criteria for unification, cross chain composability at lower latency than ethereum finality and asset fungibility via a shared bridge.
00:15:23.814 - 00:16:07.418, Speaker B: And as Justin mentioned earlier, we're also able to massively reduce gas costs. So the ag layer works by accepting blocks from l two s before they're settled on ethereum. And it proves like three things, I guess. So it proves first that uh, cross chain or cross l two transactions are safe, so they're consistent. Um, that super intents and bundles are, are satisfied and are consistently included across chains. Um, that interchain accounting is valid, and we'll talk about what this means exactly later. Um, and finally, it, it does aggregate validity proofs, but again, it's really important to emphasize that this is primarily a gas optimization.
00:16:07.418 - 00:16:58.114, Speaker B: So rather than needing to verify every single validity proof for every single l two on l one, we can amortize the cost of proof verification across many l two s. The Ag layer vision is an ecosystem of independent sovereign chains. The AG layer does not, there's no element of rent seeking or extracting sequencer fees or profit. It does not require a specific vm or an execution environment. It doesn't require, it doesn't place any limitations on the tokens the chains use. It doesn't require that they submit to common governance or that they use a specific or prescribed shared sequencer, or even a shared sequencer at all. Though again, the AG layer doesn't function without some sort of coordination mechanism between chains.
00:16:58.114 - 00:18:03.144, Speaker B: So the way that we think about it is that the AG layer is this very, very minimal layer that provides the safety guarantees that we discussed earlier. And it works in conjunction with a chain coordination layer that could be, again, the shared sequencer, a relay builders, they're separate ecosystems that mutually depend on one another. Shared sequencers depend on the ag layer for safety, and then the Ag layer depends on shared sequencers. And this coordination, what we call emergent coordination infrastructure to actually navigate, producing cross chain bundles and performing the coordination between chains. So in the universal, again, this is just to develop a very high level intuition about how it works. In the universal synchronous composability case, l two s would opt into using a shared sequencer. That's the only way that we know how to provide synchronous composability across chains.
00:18:03.144 - 00:18:51.080, Speaker B: Users submit atomic bundles to a proposal or a prose proposer, and a builder would then execute and build blocks across many chains. Then this is where it gets a little bit different. The chains would basically build their proofs in a certain way. That allows the AG layer to check that the builder and shared sequencer built blocks in a valid way, and that the shared bridge was basically used safely or the bridge invariant was respected across all of these transactions. The AG layer submits these three proofs. Oh, sorry. Yeah.
00:18:51.080 - 00:18:53.472, Speaker B: Yuri, another question. Yeah.
00:18:53.568 - 00:18:58.384, Speaker D: Could you explain a bit more? The user submit atomic bundles to proposer.
00:18:58.544 - 00:18:59.656, Speaker B: So far so good.
00:18:59.720 - 00:19:10.056, Speaker D: Proposer user bundles make sense. And the builder executes, builds block across many chains like I have. Like the chain is broken somewhere between the proposer and the builder here.
00:19:10.080 - 00:19:53.482, Speaker B: Could you unpack it? Yeah, so I might be using the wrong terminology here, but my understanding is that the idea is that after a bundle has been submitted to a proposer, that some builder would then create the blocks across many different chains. This is required for synchronous composability because you need basically all of those full nodes to be co located so you don't have to take locks that persist for a long time across many chains. That's just what I mean. Like the builder is actually producing those individual blocks for each chain, and then.
00:19:53.618 - 00:19:56.690, Speaker D: So we're kind of glazing over proposer builder or whatever.
00:19:56.722 - 00:19:58.154, Speaker B: I don't really care about that.
00:19:58.314 - 00:20:12.088, Speaker D: Basically, user give a bundle off actions across different chains or whatever, and then it comes somewhere between the proposer and the builder. Somebody creates a block. So the proposer could create something along these lines.
00:20:12.266 - 00:21:04.964, Speaker B: Yeah, exactly. User sends off a bundle and somehow we get all the individual blocks created by chains. Cool. The Ag layer then proves basically three things. It proves that these cross l two transactions are handled in a valid way in the synchronous composability case, that there's no unbundling, that for every transaction, like if a bundle is included by one chain, then for every chain that is included in that bundle, the transaction on that chain executes successfully. Then it proves that the bridge invariant is respected. Basically that no chain can withdraw more funds from just withdraw more funds than are deposited on that chain.
00:21:04.964 - 00:22:17.134, Speaker B: And then it provides an aggregated validity proof to l one. And so again, this is just a very high level, kind of like metaphorical view of the AG layer. It's like that very thin layer that's providing safety upon which all of this interesting and sort of rich coordination infrastructure can be built, shared sequencing base sequencing relays for asynchronous composability. But the AG layer is not providing chain coordination, it's just providing a safety guarantee so that users and chains don't need to trust this coordination infrastructure to behave in a valid way. All right, so I feel like we've run through the non technical section and looking at a little bit more technical. So what do we mean when we talk about safety guarantees for cross l two transactions? By safety, we mean that if two or more chains are interoperating at lower latency than ethereum finality, then the chain like, oh, sorry, Yuri, go ahead.
00:22:18.834 - 00:22:39.488, Speaker D: So just on summarizing the high level, the idea is that if I am a user and I want a few actions happening across multiple chains, some of them are cross chain. I create the bundle saying, oh, here are the actions that I want to take. And I actually submit this to the different or actually the shared sequencer of the different chains.
00:22:39.536 - 00:22:39.696, Speaker B: Right.
00:22:39.720 - 00:22:45.128, Speaker D: So it's kind of. And this lands on all of them. That's like the high level.
00:22:45.216 - 00:22:45.592, Speaker E: Okay.
00:22:45.648 - 00:22:50.646, Speaker B: Yeah, yeah, yeah. Which I think is consistent with. Go ahead.
00:22:50.790 - 00:23:35.424, Speaker A: Just so one thing that really helped me is that if I have a super transaction which crossed two roll ups, like roll up a and roll up b, I'm actually signing three messages. I'm signing transaction on roll up a, transaction on roll up b, and I'm also signing this super intent which basically describes how I want the relationship between transactions a and b to work. And not only that, transactions a and b shouldn't be replayable individually. And so they need, basically needs to be a transaction type with metadata that points back to the intent. And then what Aglaya does is that it verifies the consistency of these transactions, these simple transactions with metadata, plus the signed superintent.
00:23:36.044 - 00:24:28.946, Speaker B: Yeah, exactly. And I think that that's not to detour too far, but I was actually speaking with Ben about this the other day. I think specifying that transaction type and exactly how it works is something that's still, like an open item for this group. Yeah. All right. So the safety guarantee basically says that if I have a block from a chain, that block can be finalized on Ethereum. Assuming that there's some cross chain interaction that affects that block, it can be finalized on Ethereum if and only if the other chains that are, or its view of the other chains that are involved in that cross chain interaction is consistent with what is actually finalized on Ethereum for those chains.
00:24:28.946 - 00:25:28.558, Speaker B: I think that we have the, in the async composability case, let's say that we have roll up a and roll up b, and roll up a is sending a message to roll up b. And so obviously we don't want to wait for this message to be routed through l one and for the state of roll up bay to be finalized on Ethereum, because that would take too long. And so let's say that we want roll up b to accept this message from a before the state of roll up a is finalized on Ethereum. It could even be before a proof for a is generated. So we want super, super low latency across chain interaction, maybe on the order of like a second or under a second. But this can fail in a really bad way, like without the ag layer. So let's say that, like, rollup a creates a block and let's say that it's valid.
00:25:28.558 - 00:26:21.824, Speaker B: It could be invalid, but let's say that it's valid. And the message that's derived from this roll up block lowercase a is sent to b, and then b creates a block that depends on the message that it received from block lowercase a. But let's assume that at the same time that rollup a is trying to double spend or equivocate, and it sends a prime to Ethereum, and at the same time b chain b or roll up b sends this block b that depends on the state lowercase a to Ethereum. And so B has built a block that depends on a state that was never finalized, a state of a that was never finalized to Ethereum. And so this is really bad. Like b is rugged. Like you can cause really bad things to happen on b.
00:26:21.824 - 00:28:17.134, Speaker B: The bridge could become under collateralized, or there could be some like other kind of catastrophic issue that could occur in the asynchronous composability case. The question is how do we provide safety in this case, even as we're operating at lower than ethereum latency? The really simple mechanism that we use to provide safety in the async case is let's say that chain b receives a message from a that depends on block lowercase a, and then b builds block lowercase b. So in the proof for block b, we include a commitment to the received state of block a as a public input. And the idea is basically like b is valid if and only if block a is also valid if there basically exists a valid proof for a, and if block a is finalized to ethereum, we can think about the role of the ag layer as basically receiving all of these new blocks and checking for consistency between basically the claimed states or the claims about other chains and what states are actually produced by those chains themselves. So in the case, like stepping back in the case that this happens, a equivocates and submits lowercase a to b and then submits a prime to ethereum. B would not be finalized on ethereum. So there's a safety guarantee that whatever invalid transactions be built that depend on a state of a that was never finalized, those will actually never be settled on Ethereum.
00:28:17.134 - 00:29:18.016, Speaker B: The downside, which we'll talk about later, is that there's a liveness issue for b because it built this block. Maybe it built a bunch of different blocks that all depend on this state that was never valid or that never happened. And B, we'll need to resolve that but fundamentally, we are preserving the safety guarantee that if, like, the claimed state of a is never valid or is never finalized on Ethereum, that B will be safe from final, like from settling an invalid state. So we can see in this slightly nicer diagram we have block b, one that depends on this other block a one. And so the AG layer is checking that for all of these sort of claims that a one is consistent with the block a one that was actually received. So the more interesting case, I think, for this group is like the.
00:29:18.080 - 00:29:19.872, Speaker A: Brendan, you have a question from Meerut.
00:29:20.008 - 00:29:21.324, Speaker B: Oh, yeah, yeah.
00:29:21.864 - 00:29:33.404, Speaker F: So if you go back to the previous slide. So in that b prime block that doesn't get finalized, are we saying that there's a bunch of transactions that are basically invalid now?
00:29:33.824 - 00:30:02.484, Speaker B: Yeah. So they need to be reorged. So the transactions that depend on an invalid or equivocated state of a would need to be reorged. And we'll get to why this is an unavoidable property or an unavoidable trade off in operating at lower than ethereum latency. Yeah. So b would need to navigate like a's misbehavior.
00:30:03.064 - 00:30:14.044, Speaker F: If you have two conflicting sets where a and B prime and then B prime and a, basically neither will happen even though both were committed to.
00:30:14.664 - 00:30:23.082, Speaker B: So if a does not depend on a state that's invalid, then a would be finalized to ethereum, but b would not be.
00:30:23.248 - 00:30:33.286, Speaker F: But if there's a second kind of transaction request where the inverse is basically requested for neither will happen is what we're pointing out here.
00:30:33.390 - 00:30:48.150, Speaker B: Yeah, I mean, a would never really do that because a knows that it's equivocating and that it's going to delay finalization of b of chain b. But yeah, in the example that you're giving, that would happen.
00:30:48.262 - 00:30:55.030, Speaker F: And would that be determined by a first come, first serve? Like, a wouldn't do that because his thing is before the other one.
00:30:55.182 - 00:31:14.994, Speaker B: Yeah. So if you're saying that like, a is equivocating at a one and then b is producing a block, and then like equivocating back, then a knows that the block that depends on this equivocated block will never be finalized. So. Yeah. All right.
00:31:16.054 - 00:31:17.086, Speaker G: I just want to make sure I.
00:31:17.110 - 00:31:25.942, Speaker C: Fully understand the concept. Maybe we can walk through an example with like a just to ground it and I could.
00:31:25.998 - 00:31:58.714, Speaker B: Example, yeah, or like a burn mint. So like a decides to, like, you know, wants to transfer some funds and so they're burned on chain a. And then like a corresponding mint operation is triggered on chain. Beep. So let's say that there's some transaction that burns 1000 ETH on a. And so B says, okay, I've received this message. I can mint 1000 ETH.
00:31:58.714 - 00:32:19.884, Speaker B: And the problem is that if a now equivocates and finalizes a block to ethereum that doesn't include this burn operation, then the bridge for b becomes under collateralized in the case that there's no ag layer and that this can happen. Um, does that make sense?
00:32:21.904 - 00:32:23.524, Speaker G: Yeah, that was very helpful.
00:32:23.904 - 00:32:26.004, Speaker B: Okay, cool. Um, Noah?
00:32:27.064 - 00:33:09.104, Speaker H: Yeah. Also, one thing I kind of want to point out with this is, and I think it's in the next diagram, is when you be. If b one is b one is dependent on a one, and then there's a c one that depends on b one. Then you effectively have a tree of them all going up, where if a one equivocates, then b one will equivocate, and then c, one would equivocate there as well. So I think it's interesting to see, but I think that may be able to be mitigated depending on how it's set up. But the whole equipment on the entire block makes it interesting because I think most of the examples in the past have been on individual bundles equivocating. Not necessarily entire blocks equivocating.
00:33:09.104 - 00:33:13.776, Speaker H: Yeah, lots there still need be defined. Defined there.
00:33:13.960 - 00:33:49.494, Speaker B: But. Yeah, yeah, I agree. I think that's a good thing to point out. And I would just say, like, this sounds like, really bad. Like, we could have, like, reorgs, liveness issues, like cascading reorgs, depending on, like, the dependency graph of, like, interactions between chains. But we'll see that this is basically like, first of all, it's not as bad as it seems, or it's not all that bad if you consider what causes these issues. And it's an inescapable trade off at operating at lower than ethereum latency.
00:33:49.494 - 00:34:12.484, Speaker B: Basically, you can choose between having safety guaranteed, or trusting the coordination mechanism, trusting a shared sequencer. But the problem is, uh, if you just decide to trust the shared sequencer, then you have, like, no safety recourse if something like this happens. But, um. Uh, Yuri, I think you had your hand.
00:34:17.144 - 00:34:43.594, Speaker D: I'll say it this way. Does it make sense to think of it kind of like a merge between ZK roll ups and optimistic roll ups? Because you kind of like, take the z that, like, take from ZK, like, take the proofs from that, but you kind of like, build on it in an optimistic way. So it's a bit sort of, it's not a roll up, but technically it's a bit of a merge between the two. Let's get the proofs from both of them and kind of work based on that. But we're optimistically working on that. Is that the right model?
00:34:43.754 - 00:35:05.540, Speaker B: Yeah, I think, like, we hesitate to use the terminology optimistic because I think it implies that there's like, proof mechanisms. So there will be like some challenge period. And that doesn't exist. But I think that you're right in the sense that things are sort of like, there's this window of uncertainty before. Yeah.
00:35:05.692 - 00:35:21.356, Speaker D: Maybe not optimistic, but kind of like unfinalized, but basically, we're kind of using the ZK proof, et cetera, and working on that even though they're not finalized. So it's optimistic. Not with proofs and everything, but optimistic in terms of work on it despite not being finalized.
00:35:21.540 - 00:35:27.494, Speaker B: Yeah, I think unfinalized is really good. It's like a really good descriptor for it. Yeah.
00:35:27.834 - 00:35:28.614, Speaker E: Thanks.
00:35:30.674 - 00:36:13.954, Speaker B: All right, any, I'll just continue. So the synchronous composability cases is, I think, a little bit more interesting. So you can have a bundle that maybe includes like a delta neutral neutral arbitrage between two pools on different chains. And so, like, the user wants to remain delta neutral. And so each leg of the trade should execute if and only if the other does. And so we create this bundle that has few transactions. It could have n transactions, but it has two transactions that execute across two chains.
00:36:13.954 - 00:37:26.882, Speaker B: And the desired property is that the transaction that executes on rollup a is included if and only if the transaction that is included on rollup b executes successfully. We have this all or nothing guarantee that gives us atomicity. The failure would be that the shared sequencer in this case, or the builder proposer. Again, we're sort of black boxing that misbehaves and includes the transaction from the bundle on a, even though maybe the transaction that executes on b fails, or the shared sequencer doesn't include that transaction at all. But basically we have this unbundling, so we're no longer guaranteed this property that both transactions execute successfully. Instead, we, uh, we only get like a, like part of the bundle that's included on, on chains. Um, and so this might not be so good if you're doing like a big, uh, a big trade or a big arbitrage in large size.
00:37:26.882 - 00:38:48.424, Speaker B: Um, you could be exploited, um, by a malicious shared sequencer. And so in the past, the proposal has been, uh, we're going to collateralize shared sequencers, and then if they do this, we can slash them. So there's like an economic penalty for, for doing this. Um, but you could imagine a case in which it's actually, um, like profitable for a shared sequencer to unbundle transactions because, uh, there's so much size, or they can, like, unbundle so many transactions or so many bundles, um, that they're actually able to profit even though they're, they're being slashed and, and penalized economically. Um, and so the, the idea with the ag layer at a very high level is, uh, let's provide a proof that, of all of these bundles are super intense, were respected. So we can prove with the AG layer that for every bundle, we can look at every transaction that's included in that bundle and every chain that executes these transactions, and we can ensure that the bundle is included on all of these chains. And so if we assume that the chain validity proofs are sound, we enforce with the validity proof that if a chain commits to a bundle as a public input, then the transactions that execute on that chain must execute successfully.
00:38:48.424 - 00:39:17.300, Speaker B: If the bundle is included or committed to by every chain, then we have a guarantee that all of the transactions in that bundle executed successfully. This is what the AG layer proves, that these superintendents or bundles are respected, and there's no way we have a cryptographic guarantee that they cannot be unbundled. So, yeah, this is like a slightly nicer diagram.
00:39:17.332 - 00:39:48.762, Speaker G: But, Brendan, maybe, just maybe on the walk back to the last slide, and it might be just helpful to explain how. I mean, because this is solving a case where it's. So it's easy to make two transactions, not be able to be picked apart just using signatures. But the failure case that you described without the AG layer is that some other transaction could be included on one roll up before that causes one of the transactions within these bundles to fail.
00:39:48.818 - 00:39:49.010, Speaker E: Right.
00:39:49.042 - 00:39:58.386, Speaker G: So signatures allow for the bundle to not be picked apart, but it doesn't prevent, it doesn't guarantee that one transact, that both transactions will succeed.
00:39:58.450 - 00:39:58.650, Speaker B: Right.
00:39:58.682 - 00:40:13.848, Speaker G: It could be the case that both transactions are executed, but one of them fails and the other one doesn't. So can you maybe explain how the AG layer, just so it's crystal clear how the AG layer would prevent that, how the proofs are attestations over state, not just inclusion.
00:40:14.016 - 00:41:22.394, Speaker B: Yeah, exactly. So, like Ben said, like, shared sequencers give you a guarantee that the transactions are included, but not that they execute successfully, because there's no, like, claim about validity or state. And so in this case, every chain, the Ag layer, checks for each bundle, that all chains that are involved in that bundle actually commit to that bundle as a public input. Then the validity proof for each chain guarantees that if a chain is committing to a bundle as a public input, that all transactions that execute on that chain, as well as the. Well, yeah, all transactions that execute on that chain must execute successfully. So we actually have this guarantee that the, like, the state of a particular or the. Yeah, we have a guarantee about, like, the outcome of a transaction, not just its inclusion.
00:41:22.394 - 00:41:24.554, Speaker B: Is that like a little clear about.
00:41:25.954 - 00:41:26.734, Speaker G: Yeah.
00:41:27.074 - 00:41:28.010, Speaker E: Okay, cool.
00:41:28.122 - 00:41:37.054, Speaker G: I think maybe going to walk through the actual details of the, how the proof works. That could make it even more clear.
00:41:37.474 - 00:41:42.458, Speaker B: Yeah. So, like, for the, like, the ag layer proof or for the, like, the ZK.
00:41:42.506 - 00:41:42.642, Speaker C: Yeah.
00:41:42.658 - 00:41:55.854, Speaker G: Like, what exactly is the proof that's happening from each chain? And what would cause this proof to be invalid for all the chains if one of the transactions in the bundle failed?
00:41:56.194 - 00:43:21.534, Speaker B: Yeah, sure. So the AG layer proof is basically just checking that it looks at like it iterates over every bundle, and then it builds a list of chains that are included in that bundle, and it checks that each of those chains validity proof includes that bundle as a public input. And so we know that in some sense the bundle is included across all of those chains. And then we have a guarantee from the individual chain validity proof that if the bundle is included as a public input, it looks at the chains, or, sorry, the transactions that are included in that bundle that are executed on that specific chain, and it guarantees that those transactions are executed validly. This is like a modification of the standard ZKVM proof to accept a new type of public input. And it enforces that if there's a value in this public input that this specific property holds, which is that a transaction that's included in the bundle must execute successfully on that chain. And so if you think about the result, after we've iterated through every bundle and every transaction, we have a guarantee that the bundle cannot be unbundled because we have a guarantee that all transactions in the bundle executed successfully.
00:43:21.534 - 00:43:24.218, Speaker B: Does that make sense? Yeah.
00:43:24.266 - 00:43:37.178, Speaker G: And specifically, the transaction only succeeds on one of these roll ups if the proof ultimately is valid. And that can happen if all the other transactions also succeeded on the other layers.
00:43:37.346 - 00:43:50.398, Speaker B: Yeah, yeah, yeah. So the ag layer will, like, reject an unbundled transaction. All right, so a couple. So I think, Justin. Yeah, yeah.
00:43:50.486 - 00:44:24.854, Speaker A: I mean, going back to Ben's question, in my mind, the distinction is not between inclusion and execution guarantees like a shared sequencer can provide promises on either whatever they want. The real distinction is on crypto economic guarantees versus cryptographic guarantees. So if you don't have the ag layer, the best you can do is have the shared sequencer be collateralized. And if they don't honor their promise, the intent of the user, then they get slashed, whereas here it's a stronger cryptographic guarantee where the bundle can't get unbundled.
00:44:26.074 - 00:45:05.736, Speaker G: Yeah, I think it is, from a user's perspective, a difference between so execution atomicity and inclusion atomicity. So from the shared sequencers perspective, it can certainly guarantee any atomic outcome that it wants over the states of the chains, and then it can make a promise on that. But Brendan is handling the case that you don't. A user is submitting a bundle. A user doesn't trust the shared sequencer no matter how collateralized it is. So it doesn't want a promise from the shared sequencer. It simply wants a guarantee that the bundle will not be unbundled.
00:45:05.736 - 00:45:11.284, Speaker G: And that's something that ag light additionally enables. I think we're saying the same thing.
00:45:14.504 - 00:45:15.724, Speaker A: Okay, gotcha.
00:45:16.704 - 00:45:34.944, Speaker B: Sure. Okay. George. I think George just disappeared from my screen.
00:45:36.604 - 00:46:06.014, Speaker E: I was muted. I was muted. Sorry. You said that. Transaction. So essentially the proof is guaranteeing not only transaction inclusion, but also the transaction outcome, which is like portion of the talk that we just had was the way that transaction outcome is specified. Like how do you specify, like the specific outcome when it can pretty much be dynamic?
00:46:06.434 - 00:46:38.864, Speaker B: Well, so you're, you're specifying the outcome that you're specifying is that the transaction executes successfully. That's like the only guarantee that we care about for atomicity. We don't care that executes in a specific, like that it has a specific result. I think it's really difficult to, I think that there are cases where you can guarantee that you could create an intent, that a transaction has a specific result or falls within some slippage range. But in general, I think it's difficult to construct that arbitrarily.
00:46:39.724 - 00:46:53.004, Speaker E: If you have a single shared sequencer, it's pretty possible because they control the pre state. Uh, whether this is provable beforehand is, I guess, another matter.
00:46:53.304 - 00:47:06.364, Speaker B: Yeah. So I'm thinking, I thought you meant from like the user's perspective. Like a user's ability to like specify an output state, I think, is difficult. In general, it's, you can do it in certain cases, but. Yeah.
00:47:10.984 - 00:47:11.576, Speaker C: Yep.
00:47:11.680 - 00:47:31.334, Speaker E: Just a quick clarification. So when a agrees to have a block, small a, as a part of public input, are they providing any economic guarantee if they equivocate and submit a prime or that guarantee is provided by aglaya.
00:47:31.714 - 00:48:36.204, Speaker B: So yeah, so I think this is a good question, like whether. So like whether a, a chain should be collateralized in some way so that if they equivocate then they could be slashed. I think there are arguments for both. There are ways to seriously penalize chains for equivocating even if they're not collateralized. So you could remove them from the ag layer and chains could opt not to accept messages or bundles that involve them. Um, but uh, yeah, I think that's like sort of out of scope and still, uh, we're sort of like punting that decision to the chain level. So, so I think chains get to navigate um, like the trade offs that they're willing to make in terms of uh, using shared sequencers and like using relays, like accepting asynchronous messages from chains that um, where they may not have a proof or.
00:48:36.204 - 00:48:47.294, Speaker B: And so, yeah, so I think it's a good question. It's a little bit out of scope for this particular discussion. Thank you. And Mohammed?
00:48:49.994 - 00:49:26.184, Speaker E: Yeah, I have a question about what's your mental model or what's the right mental model to think about aggregation layer here? So is it correct to think about aggregation layer as just one extra proof that checks the consistency of like, like different proofs of this? Like roll up a and roll up b. And like what you're describing here is just the way that consistency check or consistency proof is structured and that's it. Like, or like it has additional components to it.
00:49:26.564 - 00:49:45.114, Speaker B: Yeah, so it has additional components that we'll get to. But from the perspective of ensuring safety for or cross chain interaction, it's, yeah, I mean it's producing a proof that gives a cryptographic guarantee that the chains are behaving in a valid way and that like the total state of all chains is consistent.
00:49:46.134 - 00:50:35.730, Speaker E: Yeah, I have a follow up question, like, and it's more about like developer experience, like from the perspective of developers. So for instance, I can, if I have synchronous composability, I can imagine like one transaction on roll up a, making it a smart contract call on roll up b, like with some new upcoming say x call or cross call or something, but, and that would that like second call can like happen or not happen depending on some state and roll up a. Would something like this be still possible here? Or does, is it going to have like too much overhead if one leg, you know, failed or something like that?
00:50:35.922 - 00:51:19.430, Speaker B: Well, so the only way that that can fail, right. Is if the chain or the operator of the chain is actually misbehaving. Like, whoever's in charge of attesting to that a particular block or state is canonical, is actually lying and equivocating. And so, yeah, so I think that what you're describing is sort of the use case for developers. Like, we call it bridge and call in Polygon. So it's the ability to, like, bridge funds and then call some function on the destination chain. And so I think that's the intent for this design, is to be able to do that safely at lower latency than through Anil.
00:51:19.430 - 00:51:21.394, Speaker B: Did you have a follow up question?
00:51:26.094 - 00:51:30.318, Speaker E: No, sorry. Follow up question I just raised hand. I need to lower it. Thank you.
00:51:30.366 - 00:52:35.584, Speaker B: Okay. Okay, thanks. All right, so I'll continue. So, the second component, to get more directly to Mohammed's question, is, we need a shared bridge to enable asset fungibility for l one and l two native assets. So we need to avoid the requirement that when we're bridging assets between chains, we either get a wrapped synthetic on the destination chain, which is not ideal, because we need to swap out of it, and we need liquidity for the native token, or we need to go through l one. What a shared bridge or a shared deposit contract allows us to do is we can take the l one native representation of ethnic and we can bridge it to a different chain in this ecosystem, and we get ETH, like the native bridge representation of ETH. And the way that we do that is by having a shared bridge and shared deposit contract.
00:52:35.584 - 00:53:49.352, Speaker B: But there's a problem here, because we also want to enable permissionless, heterogeneous execution environments. So anyone should be able to deploy like, you know, a type one or type two zk Vm, or for us, like polygon maiden, or like the Solana VM or the move VM. Like, there shouldn't be any restriction or sort of governance process for you to deploy an execution environment for your chain. But the problem here is, like, when we're just using a single vm, we have a reasonable guarantee that proverbs sound. So we might have done a bunch of audits and we might have formal verification and, and this pretty high degree of confidence that there are no soundness issues with that prover. But as we add more provers to this ecosystem and more provers that are plugging into the shared bridge, then the probability that there is some soundness issue across all of those provers goes up pretty dramatically. And that's not great, because if we have a shared bridge.
00:53:49.352 - 00:55:01.328, Speaker B: Now, if there's a prover with a soundness issue anywhere in the ecosystem, then that prover could create a transaction that, say, mints a million ETH and drains the entire bridge of all funds deposited into the ecosystem. This is obviously a very bad, catastrophic outcome, and it's something that we need to avoid. The solution is like the second cryptographic guarantee that the AG layer provides is that it tracks aggregate token balances for each chain. So it says, okay, on ZKVM, there's maybe 10,000 ETH or something that's deposited in the chain and some amount of USDC. All these tokens are tracked in aggregate for each chain. When a chain submits a block or a batch to the ag layer, we look at what we call the local exit tree of messages. These are all the asset transfers that are coming out of that chain, and we parse all of them.
00:55:01.328 - 00:56:38.492, Speaker B: We ensure that the withdrawals do not cause the chain to go negative. Then we are able to, I think it's the next slide, but we basically recursively build the cumulative deposits that flow into each chain, and we use that to update this data structure that holds the aggregate token balances for breach chain. And we call this the interchain or chain level accounting proof, or the invariant proof. And this allows us to give a guarantee that even if a particular prover is unsound, it can't withdraw more funds than are currently locked in that chain. And so we're able to mirror basically the same guarantees that would exist if that chain were just directly posting proofs to l one. If you have an unsound prover for any Zk roll up, then it can drain the funds that are deposited directly to that chain, but it can't drain the funds that are deposited to any Zk roll up on Ethereum. We are mirroring that guarantee, um, by, uh, by ensuring that, that a chain cannot, um, uh, cannot withdraw more funds than it currently has.
00:56:38.492 - 00:57:39.154, Speaker B: Um, and so, so this is different. You, you can think about this as like a proof that lives alongside the validity proof for a chain. And unlike the validity proof, which is, uh, basically arbitrary, um, it can be sort of like any execution environment, and it might be sound or it might be unsound. The interchain accounting proof is something that we specify, and it's a uniform circuit that's applied to every single chain. And so the AG layer does depend on this to be sound, but it's a much, much simpler proof, and it's compatible with any arbitrary execution environment. So what are the failure modes here. From the perspective of the AG layer, we actually just are effectively assuming that validity proofs aren't necessarily sound, if that makes sense.
00:57:39.154 - 00:58:57.880, Speaker B: But from the perspective of the users of these chains, obviously the soundness ability proofs matters a lot, because if you're on a chain with an unsound prover, your funds can be rugged by an attacker or a malicious operator, creating an invalid proof that mints a bunch of tokens and then withdrawing all of those tokens. There's also a second issue where users can still be rugged or have their funds stolen if an attacker compromises an unsound chain, or, sorry, if they're holding assets that are, that are l two native assets that are issued by a chain that has an unsound proofer. So the attacker could create a transaction, maybe you have an ERC 20 with a fixed supply, and the attacker could create an invalid transaction that mints a bunch of that ERC 20 and uses that to basically reduce the value of the tokens that you hold. And so from the perspective of the AG layer, the AG layer is still safe with respect to unsound provers in aggregate. But the sound and stability proofs matters quite a bit for users. Yeah, go ahead. Oh, yeah.
00:58:57.912 - 00:59:12.184, Speaker G: Just so you are, this whole discussion here is because you want to be able to support participation in AG layer from ZK vms that have different proof systems. Am I understanding correct?
00:59:13.564 - 00:59:19.704, Speaker B: It doesn't even have to be different proof systems, but different provers. So you can imagine.
00:59:21.564 - 00:59:22.196, Speaker A: Then, I didn't.
00:59:22.220 - 00:59:24.824, Speaker G: Understand what you mean by an unsound proof.
00:59:26.084 - 00:59:39.234, Speaker B: Just like a zkvm that allows. That's not sound with respect to the ability for an attacker to generate a proof that verifies for an invalid transaction.
00:59:39.974 - 00:59:43.798, Speaker G: So if they're sharing the same proof system, why would a different circuit, for.
00:59:43.806 - 00:59:46.270, Speaker A: Example, the circuit of a bug.
00:59:46.422 - 00:59:58.214, Speaker B: Yeah, so, like, I see, yeah, yeah. Like, like you could have like a bunch of, like, clunky three zkvms and one of them has a bug and would allow you to.
00:59:58.374 - 01:00:09.096, Speaker G: The bug would be in, like, the circuit. The circuit is incorrect for representing the, the transaction validity.
01:00:09.280 - 01:00:19.884, Speaker B: Yeah, exactly. Exactly. Yeah. Maybe the terminology is not quite right, but an incorrect implementation of the prover for an execution environment.
01:00:22.224 - 01:00:48.240, Speaker A: Brendan, one of the top voted questions in the chat is, do you support multiple proof systems? And I think the answer is a resounding yes. The whole point is that anyone can come permissionlessly register their verifier circuits with an arbitrary proof system, like arbitrary stock circuits, and if they get rugged. Well, all the deposits get rugged, but not the deposits of other chains, because of this. Interchain accounting.
01:00:48.432 - 01:00:56.204, Speaker B: Yeah, exactly. And. Sorry, I know that there are a ton of. I'm not sure how to see. Okay. I can read the chat.
01:00:56.844 - 01:01:01.504, Speaker G: I don't think it's worth it. There's way too much in there for you.
01:01:04.164 - 01:01:22.962, Speaker B: Okay. All right. So hopefully that makes sense. So, basically, the two, I think, material and interesting cryptographic guarantees are around cross chain consistency and then this interchange accounting. Okay, someone. Kalman had a question. Hey.
01:01:22.962 - 01:01:23.170, Speaker B: Hey.
01:01:23.202 - 01:01:54.612, Speaker I: So I was wondering if you saw the last reconfiguration course two weeks ago, we also presented a very similar idea. Basically, I think it's essentially the same idea. The difference was we were focused on doing this on layer one, and this would allow interoperability between different ecosystems. As I understand, this idea is only. It only works if you're using the ag layer. So if you're in the polygon ecosystem, shouldn't you do this on a wider ethereum level?
01:01:54.788 - 01:02:31.096, Speaker B: Yeah. So you can definitely. I think it's obvious that you can do it at l one, but, like, yeah, I mean, we came up with this a long time ago, but the goal is, like, you should be able to interoperate between chains without touching l one at all. That's how we can scale and how we can, uh, like, reduce, uh, gas cost and. And latency, uh, significantly. Because otherwise, if we're routing things through l one, then we not only pay gas cost penalty, but we're also paying latency penalty.
01:02:31.240 - 01:02:41.764, Speaker I: Yeah, but if you settle the proofs on layer one of what you call interchain accounting, what I last time called asset verifiers, then you similarly wouldn't have to go through layer one.
01:02:42.864 - 01:03:00.104, Speaker B: Uh, yeah, so, but I'm not clear. Like, if you're. If you're going to go between ecosystems, you're just saying, like, do all of the accounting on l one, I think that would be really expensive to.
01:03:01.044 - 01:03:19.284, Speaker I: Okay, I'm saying that you are proposing the shared bridge, which holds all the funds, and it's secured by this asset verifier, basically. So why have this on? What is an ag polygon ag layer? Layer two? Why not have it on a layer one?
01:03:20.544 - 01:03:22.604, Speaker B: Because that would be incredibly expensive.
01:03:24.184 - 01:03:56.734, Speaker A: Coleman is asking a different function, a different question. Sorry. So I think what Kalman presented and what you presented for share deposits is actually, like, basically the same idea where you have one contract where everyone makes deposits, and one of the things that you gain is this gas optimization, because you don't have to go through the r1. I think what Carmen is asking is, is this a polygon ag layer or is this an ethereum ag layer? And I think the answer, this is an ethereum ag layer where anyone, even beyond the bounds of the polygon ecosystem, can opt in.
01:03:57.154 - 01:04:05.430, Speaker B: Yeah, yeah, yeah, yeah. Exactly. So this is not supposed to be, like, specific to the polygon ecosystem, but.
01:04:05.462 - 01:04:14.674, Speaker I: You have to use the polygon ag layer to opt into your interchange accounting. Failure interchange accounting. So I was wondering why not.
01:04:15.614 - 01:04:30.460, Speaker B: So we don't call it, like, the polygon ag layer. We just call it the ag layer because there are a lot of. So, yes, you have to use this thing that we are currently engaged in building, but it's not meant to be like a polygon specifically. Okay.
01:04:30.480 - 01:04:46.844, Speaker I: But, you know, other ecosystems might also have proof aggregation, like star Coyote as the shared prover. So I'm wondering, why not put this interoperability solution that solves fragmentation on layer one instead of on this?
01:04:49.384 - 01:04:54.844, Speaker B: Maybe I'm just being, like, super dense, but I don't really see how that would.
01:04:55.304 - 01:04:57.200, Speaker I: Okay, let's discuss this later, maybe.
01:04:57.272 - 01:05:02.284, Speaker B: Yeah. Okay. So, Jonas.
01:05:03.544 - 01:05:04.184, Speaker E: Yeah.
01:05:04.304 - 01:05:07.448, Speaker B: I just want to. I want to echo a chat. Thanks for the talk, by the way.
01:05:07.576 - 01:05:18.656, Speaker G: I want to echo a question in the chat from Cooper, like, who's running the ag layer? And kind of are the roll ups that opt into this relying on liveness.
01:05:18.720 - 01:05:22.872, Speaker E: For these people that are running this, or how does it.
01:05:23.008 - 01:05:23.824, Speaker B: Yeah, how does it work?
01:05:23.864 - 01:05:24.524, Speaker E: Basically?
01:05:24.844 - 01:05:55.304, Speaker B: Yeah. So it's run by a decentralized network of nodes that are generating proofs and providing this guarantee. The liveness and censorship mechanism is not discussed in this presentation, but there are ways that I think you can very straightforwardly force inclusion or have some mechanism on l one that would allow you to, to avoid using the aglaya itself.
01:05:55.924 - 01:06:07.340, Speaker E: Can I tag one to Genesis? What are the actors that are running aglay are being paid? Like, how are they recalled for their user?
01:06:07.372 - 01:06:23.676, Speaker B: Yes. So there would need to be some mechanism where they would be compensated for the cost of generating proofs. But these proofs are very, very, very light relative to say that validity proof for ZKBM. So this is like a very, very nominal fee.
01:06:23.780 - 01:06:26.504, Speaker E: Are these actors separate from the alum proposals?
01:06:28.684 - 01:06:46.180, Speaker B: I think that they. I haven't thought about that. I think that they would. I'm not sure if they could be the same. They could certainly be, like, using, you know, e three stickers or something like that.
01:06:46.212 - 01:07:00.184, Speaker E: But is there any requirement for timeliness or censorship resistance on the people that are doing the aggregation generation and then submission into the various rollops. And I guess that one.
01:07:01.724 - 01:07:19.514, Speaker B: Yes, definitely. So they need to generate these proofs in order for batches to be finalized on Ethereum. And so there is a timeline. Yeah. Ellie?
01:07:20.294 - 01:07:29.354, Speaker G: Yeah, sorry, maybe I missed this, but with this interchange accounting, would this require that the nodes in AG layer are able to execute across all of the different vms?
01:07:31.094 - 01:07:50.738, Speaker B: No, because the only information that they need is in the list of asset transfers that's included with every batch. And so it's not like random stuff could like, crazy stuff could be happening inside each vm, but those actions produce a result that's uniform across chains.
01:07:50.906 - 01:07:53.090, Speaker G: Okay, I see that makes sense. Thank you.
01:07:53.282 - 01:07:59.614, Speaker B: Sure. Ben, I think you still have your hand up, but that might be an error.
01:08:00.034 - 01:08:02.290, Speaker G: Oh yeah, that's definitely an error. Sorry.
01:08:02.442 - 01:08:29.914, Speaker B: Okay. And I realize I've gone like way over time, uh, but I think we're basically. So it's, it's maybe worth discussing, like the ag layer failure modes. Um, so I think it's really important to, to emphasize that like if uh, if chains are using a shared sequencer, they, uh, we can have these like nasty liveness issues, um, where, like the shared sequencer, like, um.
01:08:31.774 - 01:08:32.514, Speaker E: Well.
01:08:34.453 - 01:09:15.034, Speaker B: Yeah, maybe it's better in the async case. Like if we have messages and there's a provocation or there's some issue that prevents finalization of one chain. It's really important to emphasize that this, like, if we didn't have the ag layer, we wouldn't have these liveness issues, but we also wouldn't have safety. And so the impact would just be that, uh, like the shared sequencer or some like misbehaving chain could steal funds from another chain. And so, like, we are adding a safety guarantee. We're not like introducing the possibility of, uh, liveness issues or faults. Um, that makes sense.
01:09:15.034 - 01:09:52.735, Speaker B: Um, yeah, so this basically requires zk because, uh, if you're using an optimistic roll up and, and the, uh, the latency of your finality for your native bridge is super long, then the dependency graph and possibility for liveness faults and reworks increases dramatically. But yeah, I think we can pause there and if there are any lingering questions or discussion, or we can just transition to the off the record discussion as well. Perfect.
01:09:52.799 - 01:09:59.711, Speaker A: Thank you, Brendan. We're going to end the call here and then start the off the record discussion now. Thanks again, Brendan.
01:09:59.847 - 01:10:00.263, Speaker B: Yeah, of course.
